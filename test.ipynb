{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae3af68-ce31-48f3-8b90-4b5291e443b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n",
      "2024-10-19 00:15:20.845028 +0330 | Variant:\n",
      "2024-10-19 00:15:20.845282 +0330 | {\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"min_num_steps_before_training\": 10000,\n",
      "    \"num_epochs\": 68,\n",
      "    \"num_eval_paths_per_epoch\": 10,\n",
      "    \"num_expl_steps_per_train_loop\": 5000,\n",
      "    \"num_trains_per_train_loop\": 5000\n",
      "  },\n",
      "  \"iq_kwargs\": {\n",
      "    \"demos\": 1,\n",
      "    \"regularize\": \"TD_policy\",\n",
      "    \"loss\": \"value\",\n",
      "    \"chi\": 0.5,\n",
      "    \"expert_path\": \"experts/Ant-v2_25.pkl\",\n",
      "    \"subsample_freq\": 1\n",
      "  },\n",
      "  \"env\": \"Ant-v2\",\n",
      "  \"seed\": 4,\n",
      "  \"expectation_z\": false,\n",
      "  \"use_policy_expert_obs\": false,\n",
      "  \"eval_env_num\": 10,\n",
      "  \"expl_env_num\": 10,\n",
      "  \"layer_size\": 256,\n",
      "  \"num_quantiles\": 24,\n",
      "  \"replay_buffer_size\": 1000000,\n",
      "  \"trainer_kwargs\": {\n",
      "    \"alpha\": 0.01,\n",
      "    \"discount\": 0.99,\n",
      "    \"policy_lr\": 5e-05,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"tau_type\": \"iqn\",\n",
      "    \"use_automatic_entropy_tuning\": false,\n",
      "    \"zf_lr\": 0.0003,\n",
      "    \"bias\": 10,\n",
      "    \"bias_lr\": 0.0001,\n",
      "    \"use_automatic_bias_tuning\": false\n",
      "  },\n",
      "  \"version\": \"normal-iqn-neutral\"\n",
      "}\n",
      "/home/eddie/venvs/LSIQ/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2024-10-19 00:16:47.451532 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 0 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 15000\n",
      "trainer/ZF1 Loss                       0.34207\n",
      "trainer/ZF2 Loss                       0.455216\n",
      "trainer/ZF Expert Reward               0.240122\n",
      "trainer/ZF Policy Reward               0.24632\n",
      "trainer/ZF CHI2 Term                   0.341902\n",
      "trainer/Policy Loss                    0.427745\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               0.0570242\n",
      "trainer/Policy Param Norm             14.6643\n",
      "trainer/Zf1 Grad Norm                  2.78353\n",
      "trainer/Zf1 Param Norm                32.053\n",
      "trainer/Zf2 Grad Norm                  4.053\n",
      "trainer/Zf2 Param Norm                32.0328\n",
      "trainer/Z Expert Predictions Mean     -0.174191\n",
      "trainer/Z Expert Predictions Std       0.182931\n",
      "trainer/Z Expert Predictions Max       0.395007\n",
      "trainer/Z Expert Predictions Min      -0.623261\n",
      "trainer/Z Policy Predictions Mean     -0.0704849\n",
      "trainer/Z Policy Predictions Std       0.167015\n",
      "trainer/Z Policy Predictions Max       0.447485\n",
      "trainer/Z Policy Predictions Min      -0.739282\n",
      "trainer/Z Expert Targets Mean         -0.414312\n",
      "trainer/Z Expert Targets Std           0.176706\n",
      "trainer/Z Expert Targets Max           0.200104\n",
      "trainer/Z Expert Targets Min          -1.16368\n",
      "trainer/Z Policy Targets Mean         -0.316805\n",
      "trainer/Z Policy Targets Std           0.236424\n",
      "trainer/Z Policy Targets Max           0.434744\n",
      "trainer/Z Policy Targets Min          -1.20021\n",
      "trainer/Log Pis Mean                  -5.34683\n",
      "trainer/Log Pis Std                    0.57816\n",
      "trainer/Policy mu Mean                -1.15053e-05\n",
      "trainer/Policy mu Std                  0.000916854\n",
      "trainer/Policy log std Mean            0.000368863\n",
      "trainer/Policy log std Std             0.000991307\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        10630\n",
      "exploration/num paths total           66\n",
      "evaluation/num steps total          8190\n",
      "evaluation/num paths total            10\n",
      "evaluation/path length Mean          819\n",
      "evaluation/path length Std           362\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            95\n",
      "evaluation/Rewards Mean                0.51429\n",
      "evaluation/Rewards Std                 0.298937\n",
      "evaluation/Rewards Max                 2.72082\n",
      "evaluation/Rewards Min                -1.40847\n",
      "evaluation/Returns Mean              421.203\n",
      "evaluation/Returns Std               200.228\n",
      "evaluation/Returns Max               782.937\n",
      "evaluation/Returns Min                69.4548\n",
      "evaluation/Estimation Bias Mean      -13.176\n",
      "evaluation/Estimation Bias Std        10.9975\n",
      "evaluation/EB/Q_True Mean              4.58766\n",
      "evaluation/EB/Q_True Std              12.7359\n",
      "evaluation/EB/Q_Pred Mean             -8.58838\n",
      "evaluation/EB/Q_Pred Std               5.29606\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           421.203\n",
      "evaluation/Actions Mean                0.147718\n",
      "evaluation/Actions Std                 0.325373\n",
      "evaluation/Actions Max                 0.906212\n",
      "evaluation/Actions Min                -0.982197\n",
      "time/backward_policy (s)               8.26255\n",
      "time/backward_zf1 (s)                  9.88469\n",
      "time/backward_zf2 (s)                  9.48796\n",
      "time/data sampling (s)                 1.2247\n",
      "time/data storing (s)                  0.0812267\n",
      "time/evaluation sampling (s)           2.10565\n",
      "time/exploration sampling (s)          1.80137\n",
      "time/logging (s)                       0.0103622\n",
      "time/preback_alpha (s)                 0.00552253\n",
      "time/preback_policy (s)                9.66262\n",
      "time/preback_start (s)                 0.741025\n",
      "time/preback_zf (s)                   28.5252\n",
      "time/saving (s)                        3.704e-06\n",
      "time/training (s)                     10.6682\n",
      "time/epoch (s)                        82.461\n",
      "time/total (s)                        86.5345\n",
      "Epoch                                  0\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:18:12.843048 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 1 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 20000\n",
      "trainer/ZF1 Loss                      -0.0707674\n",
      "trainer/ZF2 Loss                      -0.0157562\n",
      "trainer/ZF Expert Reward               0.984121\n",
      "trainer/ZF Policy Reward              -1.14612\n",
      "trainer/ZF CHI2 Term                   1.11239\n",
      "trainer/Policy Loss                    7.54895\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               2.84757\n",
      "trainer/Policy Param Norm             17.1392\n",
      "trainer/Zf1 Grad Norm                 29.0597\n",
      "trainer/Zf1 Param Norm                35.108\n",
      "trainer/Zf2 Grad Norm                 33.615\n",
      "trainer/Zf2 Param Norm                35.0314\n",
      "trainer/Z Expert Predictions Mean     18.0885\n",
      "trainer/Z Expert Predictions Std       0.415206\n",
      "trainer/Z Expert Predictions Max      18.7854\n",
      "trainer/Z Expert Predictions Min      14.7317\n",
      "trainer/Z Policy Predictions Mean     -8.37648\n",
      "trainer/Z Policy Predictions Std       8.46113\n",
      "trainer/Z Policy Predictions Max      11.1848\n",
      "trainer/Z Policy Predictions Min     -21.687\n",
      "trainer/Z Expert Targets Mean         17.1044\n",
      "trainer/Z Expert Targets Std           1.13022\n",
      "trainer/Z Expert Targets Max          17.8947\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         -7.23036\n",
      "trainer/Z Policy Targets Std           8.11792\n",
      "trainer/Z Policy Targets Max           9.98793\n",
      "trainer/Z Policy Targets Min         -21.0808\n",
      "trainer/Log Pis Mean                   8.25789\n",
      "trainer/Log Pis Std                    2.89261\n",
      "trainer/Policy mu Mean                 0.00245066\n",
      "trainer/Policy mu Std                  0.474586\n",
      "trainer/Policy log std Mean           -2.2575\n",
      "trainer/Policy log std Std             0.26987\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        16578\n",
      "exploration/num paths total           76\n",
      "evaluation/num steps total         14806\n",
      "evaluation/num paths total            21\n",
      "evaluation/path length Mean          601.455\n",
      "evaluation/path length Std           440.015\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            39\n",
      "evaluation/Rewards Mean                0.929994\n",
      "evaluation/Rewards Std                 0.441917\n",
      "evaluation/Rewards Max                 4.04918\n",
      "evaluation/Rewards Min                -1.29656\n",
      "evaluation/Returns Mean              559.349\n",
      "evaluation/Returns Std               378.969\n",
      "evaluation/Returns Max              1027.34\n",
      "evaluation/Returns Min                61.1077\n",
      "evaluation/Estimation Bias Mean      -16.5957\n",
      "evaluation/Estimation Bias Std        29.3612\n",
      "evaluation/EB/Q_True Mean             12.5139\n",
      "evaluation/EB/Q_True Std              30.8509\n",
      "evaluation/EB/Q_Pred Mean             -4.0818\n",
      "evaluation/EB/Q_Pred Std              12.4422\n",
      "evaluation/Num Paths                  11\n",
      "evaluation/Average Returns           559.349\n",
      "evaluation/Actions Mean                0.0601295\n",
      "evaluation/Actions Std                 0.245793\n",
      "evaluation/Actions Max                 0.950732\n",
      "evaluation/Actions Min                -0.996172\n",
      "time/backward_policy (s)               8.50828\n",
      "time/backward_zf1 (s)                 10.357\n",
      "time/backward_zf2 (s)                 10.0167\n",
      "time/data sampling (s)                 1.31425\n",
      "time/data storing (s)                  0.0818809\n",
      "time/evaluation sampling (s)           4.03156\n",
      "time/exploration sampling (s)          1.71416\n",
      "time/logging (s)                       0.013965\n",
      "time/preback_alpha (s)                 0.00549905\n",
      "time/preback_policy (s)                9.3253\n",
      "time/preback_start (s)                 0.680851\n",
      "time/preback_zf (s)                   28.6395\n",
      "time/saving (s)                        6.989e-06\n",
      "time/training (s)                     10.5024\n",
      "time/epoch (s)                        85.1913\n",
      "time/total (s)                       171.728\n",
      "Epoch                                  1\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:19:34.286984 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 2 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 25000\n",
      "trainer/ZF1 Loss                      -0.105789\n",
      "trainer/ZF2 Loss                      -0.154114\n",
      "trainer/ZF Expert Reward               1.11022\n",
      "trainer/ZF Policy Reward              -0.596092\n",
      "trainer/ZF CHI2 Term                   0.827224\n",
      "trainer/Policy Loss                   10.4663\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               3.18947\n",
      "trainer/Policy Param Norm             18.7623\n",
      "trainer/Zf1 Grad Norm                 31.5257\n",
      "trainer/Zf1 Param Norm                38.0619\n",
      "trainer/Zf2 Grad Norm                 27.0647\n",
      "trainer/Zf2 Param Norm                37.8766\n",
      "trainer/Z Expert Predictions Mean     24.1704\n",
      "trainer/Z Expert Predictions Std       2.29676\n",
      "trainer/Z Expert Predictions Max      27.4407\n",
      "trainer/Z Expert Predictions Min      11.2996\n",
      "trainer/Z Policy Predictions Mean    -10.7449\n",
      "trainer/Z Policy Predictions Std      12.7624\n",
      "trainer/Z Policy Predictions Max      16.8016\n",
      "trainer/Z Policy Predictions Min     -32.5037\n",
      "trainer/Z Expert Targets Mean         23.0602\n",
      "trainer/Z Expert Targets Std           2.31152\n",
      "trainer/Z Expert Targets Max          26.3607\n",
      "trainer/Z Expert Targets Min          10.9274\n",
      "trainer/Z Policy Targets Mean        -10.1488\n",
      "trainer/Z Policy Targets Std          12.6089\n",
      "trainer/Z Policy Targets Max          15.3837\n",
      "trainer/Z Policy Targets Min         -31.785\n",
      "trainer/Log Pis Mean                   9.18371\n",
      "trainer/Log Pis Std                    2.9105\n",
      "trainer/Policy mu Mean                 0.062771\n",
      "trainer/Policy mu Std                  0.436318\n",
      "trainer/Policy log std Mean           -2.40552\n",
      "trainer/Policy log std Std             0.253238\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        21979\n",
      "exploration/num paths total           93\n",
      "evaluation/num steps total         15679\n",
      "evaluation/num paths total            31\n",
      "evaluation/path length Mean           87.3\n",
      "evaluation/path length Std            41.6583\n",
      "evaluation/path length Max           151\n",
      "evaluation/path length Min            33\n",
      "evaluation/Rewards Mean                1.35585\n",
      "evaluation/Rewards Std                 0.937371\n",
      "evaluation/Rewards Max                 4.35631\n",
      "evaluation/Rewards Min                -1.26554\n",
      "evaluation/Returns Mean              118.366\n",
      "evaluation/Returns Std                56.7978\n",
      "evaluation/Returns Max               241.677\n",
      "evaluation/Returns Min                43.8083\n",
      "evaluation/Estimation Bias Mean       -8.85261\n",
      "evaluation/Estimation Bias Std        35.199\n",
      "evaluation/EB/Q_True Mean             15.1061\n",
      "evaluation/EB/Q_True Std              35.279\n",
      "evaluation/EB/Q_Pred Mean              6.25352\n",
      "evaluation/EB/Q_Pred Std              10.7864\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           118.366\n",
      "evaluation/Actions Mean                0.00789248\n",
      "evaluation/Actions Std                 0.383493\n",
      "evaluation/Actions Max                 0.937211\n",
      "evaluation/Actions Min                -0.965786\n",
      "time/backward_policy (s)               8.17684\n",
      "time/backward_zf1 (s)                  9.94853\n",
      "time/backward_zf2 (s)                  9.65061\n",
      "time/data sampling (s)                 1.33628\n",
      "time/data storing (s)                  0.0812648\n",
      "time/evaluation sampling (s)           1.00494\n",
      "time/exploration sampling (s)          1.66411\n",
      "time/logging (s)                       0.00479552\n",
      "time/preback_alpha (s)                 0.00539204\n",
      "time/preback_policy (s)                9.58043\n",
      "time/preback_start (s)                 0.670823\n",
      "time/preback_zf (s)                   28.5534\n",
      "time/saving (s)                        7.202e-06\n",
      "time/training (s)                     10.5556\n",
      "time/epoch (s)                        81.233\n",
      "time/total (s)                       252.964\n",
      "Epoch                                  2\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:20:55.955372 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 3 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 30000\n",
      "trainer/ZF1 Loss                      -0.118919\n",
      "trainer/ZF2 Loss                      -0.11739\n",
      "trainer/ZF Expert Reward               0.972908\n",
      "trainer/ZF Policy Reward              -0.732953\n",
      "trainer/ZF CHI2 Term                   0.839047\n",
      "trainer/Policy Loss                   11.628\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               4.22057\n",
      "trainer/Policy Param Norm             19.8802\n",
      "trainer/Zf1 Grad Norm                 36.7486\n",
      "trainer/Zf1 Param Norm                40.137\n",
      "trainer/Zf2 Grad Norm                 42.6922\n",
      "trainer/Zf2 Param Norm                40.0134\n",
      "trainer/Z Expert Predictions Mean     26.1178\n",
      "trainer/Z Expert Predictions Std       1.79511\n",
      "trainer/Z Expert Predictions Max      29.0998\n",
      "trainer/Z Expert Predictions Min      12.6308\n",
      "trainer/Z Policy Predictions Mean    -11.8066\n",
      "trainer/Z Policy Predictions Std      13.8516\n",
      "trainer/Z Policy Predictions Max      20.8129\n",
      "trainer/Z Policy Predictions Min     -39.1796\n",
      "trainer/Z Expert Targets Mean         25.1449\n",
      "trainer/Z Expert Targets Std           1.81376\n",
      "trainer/Z Expert Targets Max          28.4317\n",
      "trainer/Z Expert Targets Min          11.2931\n",
      "trainer/Z Policy Targets Mean        -11.0737\n",
      "trainer/Z Policy Targets Std          13.6603\n",
      "trainer/Z Policy Targets Max          23.246\n",
      "trainer/Z Policy Targets Min         -38.4153\n",
      "trainer/Log Pis Mean                   9.63692\n",
      "trainer/Log Pis Std                    2.78251\n",
      "trainer/Policy mu Mean                 0.0785889\n",
      "trainer/Policy mu Std                  0.467005\n",
      "trainer/Policy log std Mean           -2.44893\n",
      "trainer/Policy log std Std             0.289944\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        26984\n",
      "exploration/num paths total          115\n",
      "evaluation/num steps total         16452\n",
      "evaluation/num paths total            41\n",
      "evaluation/path length Mean           77.3\n",
      "evaluation/path length Std            48.2184\n",
      "evaluation/path length Max           198\n",
      "evaluation/path length Min            21\n",
      "evaluation/Rewards Mean                1.66944\n",
      "evaluation/Rewards Std                 0.98307\n",
      "evaluation/Rewards Max                 4.33537\n",
      "evaluation/Rewards Min                -0.851779\n",
      "evaluation/Returns Mean              129.048\n",
      "evaluation/Returns Std                82.0262\n",
      "evaluation/Returns Max               330.794\n",
      "evaluation/Returns Min                31.1123\n",
      "evaluation/Estimation Bias Mean      -10.4151\n",
      "evaluation/Estimation Bias Std        45.8531\n",
      "evaluation/EB/Q_True Mean             23.8433\n",
      "evaluation/EB/Q_True Std              46.8708\n",
      "evaluation/EB/Q_Pred Mean             13.4281\n",
      "evaluation/EB/Q_Pred Std               6.83319\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           129.048\n",
      "evaluation/Actions Mean               -0.00337853\n",
      "evaluation/Actions Std                 0.383733\n",
      "evaluation/Actions Max                 0.935641\n",
      "evaluation/Actions Min                -0.97259\n",
      "time/backward_policy (s)               8.64324\n",
      "time/backward_zf1 (s)                 10.4161\n",
      "time/backward_zf2 (s)                 10.1307\n",
      "time/data sampling (s)                 1.28377\n",
      "time/data storing (s)                  0.0837526\n",
      "time/evaluation sampling (s)           0.600992\n",
      "time/exploration sampling (s)          1.74419\n",
      "time/logging (s)                       0.0031007\n",
      "time/preback_alpha (s)                 0.00547979\n",
      "time/preback_policy (s)                9.05246\n",
      "time/preback_start (s)                 0.678313\n",
      "time/preback_zf (s)                   28.5637\n",
      "time/saving (s)                        5.788e-06\n",
      "time/training (s)                     10.2564\n",
      "time/epoch (s)                        81.4623\n",
      "time/total (s)                       334.43\n",
      "Epoch                                  3\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:22:15.892793 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 4 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 35000\n",
      "trainer/ZF1 Loss                       0.0300871\n",
      "trainer/ZF2 Loss                      -0.0475286\n",
      "trainer/ZF Expert Reward               1.08143\n",
      "trainer/ZF Policy Reward              -0.167517\n",
      "trainer/ZF CHI2 Term                   0.72735\n",
      "trainer/Policy Loss                    8.51185\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               4.93524\n",
      "trainer/Policy Param Norm             20.8699\n",
      "trainer/Zf1 Grad Norm                 28.2006\n",
      "trainer/Zf1 Param Norm                41.8705\n",
      "trainer/Zf2 Grad Norm                 27.4272\n",
      "trainer/Zf2 Param Norm                42.018\n",
      "trainer/Z Expert Predictions Mean     31.1382\n",
      "trainer/Z Expert Predictions Std       2.64029\n",
      "trainer/Z Expert Predictions Max      34.012\n",
      "trainer/Z Expert Predictions Min      14.7224\n",
      "trainer/Z Policy Predictions Mean     -8.92623\n",
      "trainer/Z Policy Predictions Std      16.7391\n",
      "trainer/Z Policy Predictions Max      27.8797\n",
      "trainer/Z Policy Predictions Min     -42.683\n",
      "trainer/Z Expert Targets Mean         30.0567\n",
      "trainer/Z Expert Targets Std           2.71349\n",
      "trainer/Z Expert Targets Max          33.2341\n",
      "trainer/Z Expert Targets Min          13.5167\n",
      "trainer/Z Policy Targets Mean         -8.75872\n",
      "trainer/Z Policy Targets Std          16.3977\n",
      "trainer/Z Policy Targets Max          27.8755\n",
      "trainer/Z Policy Targets Min         -41.9106\n",
      "trainer/Log Pis Mean                  10.6443\n",
      "trainer/Log Pis Std                    3.02996\n",
      "trainer/Policy mu Mean                 0.0457896\n",
      "trainer/Policy mu Std                  0.483907\n",
      "trainer/Policy log std Mean           -2.5432\n",
      "trainer/Policy log std Std             0.331213\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        30952\n",
      "exploration/num paths total          128\n",
      "evaluation/num steps total         16999\n",
      "evaluation/num paths total            51\n",
      "evaluation/path length Mean           54.7\n",
      "evaluation/path length Std            30.0501\n",
      "evaluation/path length Max           117\n",
      "evaluation/path length Min            19\n",
      "evaluation/Rewards Mean                1.57037\n",
      "evaluation/Rewards Std                 0.952187\n",
      "evaluation/Rewards Max                 3.97141\n",
      "evaluation/Rewards Min                -1.06286\n",
      "evaluation/Returns Mean               85.8992\n",
      "evaluation/Returns Std                61.3944\n",
      "evaluation/Returns Max               231.728\n",
      "evaluation/Returns Min                19.8618\n",
      "evaluation/Estimation Bias Mean        3.06897\n",
      "evaluation/Estimation Bias Std        41.6439\n",
      "evaluation/EB/Q_True Mean             19.2274\n",
      "evaluation/EB/Q_True Std              40.6052\n",
      "evaluation/EB/Q_Pred Mean             22.2964\n",
      "evaluation/EB/Q_Pred Std               6.45404\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            85.8992\n",
      "evaluation/Actions Mean               -0.00504348\n",
      "evaluation/Actions Std                 0.418994\n",
      "evaluation/Actions Max                 0.929701\n",
      "evaluation/Actions Min                -0.958074\n",
      "time/backward_policy (s)               7.84214\n",
      "time/backward_zf1 (s)                  9.56567\n",
      "time/backward_zf2 (s)                  9.26956\n",
      "time/data sampling (s)                 1.25142\n",
      "time/data storing (s)                  0.080088\n",
      "time/evaluation sampling (s)           0.45253\n",
      "time/exploration sampling (s)          1.71929\n",
      "time/logging (s)                       0.00283347\n",
      "time/preback_alpha (s)                 0.00535057\n",
      "time/preback_policy (s)                9.84638\n",
      "time/preback_start (s)                 0.65898\n",
      "time/preback_zf (s)                   28.3986\n",
      "time/saving (s)                        5.911e-06\n",
      "time/training (s)                     10.6442\n",
      "time/epoch (s)                        79.737\n",
      "time/total (s)                       414.17\n",
      "Epoch                                  4\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:23:40.686490 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 5 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 40000\n",
      "trainer/ZF1 Loss                       0.0997613\n",
      "trainer/ZF2 Loss                       0.257227\n",
      "trainer/ZF Expert Reward               1.16201\n",
      "trainer/ZF Policy Reward              -0.132467\n",
      "trainer/ZF CHI2 Term                   0.954675\n",
      "trainer/Policy Loss                    2.36296\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               5.47885\n",
      "trainer/Policy Param Norm             21.7311\n",
      "trainer/Zf1 Grad Norm                 49.982\n",
      "trainer/Zf1 Param Norm                43.445\n",
      "trainer/Zf2 Grad Norm                 27.3408\n",
      "trainer/Zf2 Param Norm                43.8962\n",
      "trainer/Z Expert Predictions Mean     37.3067\n",
      "trainer/Z Expert Predictions Std       2.5523\n",
      "trainer/Z Expert Predictions Max      42.1689\n",
      "trainer/Z Expert Predictions Min      22.517\n",
      "trainer/Z Policy Predictions Mean     -2.6588\n",
      "trainer/Z Policy Predictions Std      20.2627\n",
      "trainer/Z Policy Predictions Max      37.3538\n",
      "trainer/Z Policy Predictions Min     -44.7714\n",
      "trainer/Z Expert Targets Mean         36.1446\n",
      "trainer/Z Expert Targets Std           2.62415\n",
      "trainer/Z Expert Targets Max          41.5739\n",
      "trainer/Z Expert Targets Min          22.0329\n",
      "trainer/Z Policy Targets Mean         -2.52633\n",
      "trainer/Z Policy Targets Std          19.9656\n",
      "trainer/Z Policy Targets Max          34.9667\n",
      "trainer/Z Policy Targets Min         -43.7724\n",
      "trainer/Log Pis Mean                  11.7494\n",
      "trainer/Log Pis Std                    2.75062\n",
      "trainer/Policy mu Mean                 0.0847724\n",
      "trainer/Policy mu Std                  0.487998\n",
      "trainer/Policy log std Mean           -2.67804\n",
      "trainer/Policy log std Std             0.297848\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        35592\n",
      "exploration/num paths total          138\n",
      "evaluation/num steps total         20051\n",
      "evaluation/num paths total            61\n",
      "evaluation/path length Mean          305.2\n",
      "evaluation/path length Std           258.853\n",
      "evaluation/path length Max           752\n",
      "evaluation/path length Min            78\n",
      "evaluation/Rewards Mean                2.19004\n",
      "evaluation/Rewards Std                 1.01668\n",
      "evaluation/Rewards Max                 5.46907\n",
      "evaluation/Rewards Min                -1.91752\n",
      "evaluation/Returns Mean              668.4\n",
      "evaluation/Returns Std               566.189\n",
      "evaluation/Returns Max              1691.57\n",
      "evaluation/Returns Min               135.546\n",
      "evaluation/Estimation Bias Mean       -0.482528\n",
      "evaluation/Estimation Bias Std        70.3966\n",
      "evaluation/EB/Q_True Mean             36.7988\n",
      "evaluation/EB/Q_True Std              70.3443\n",
      "evaluation/EB/Q_Pred Mean             36.3162\n",
      "evaluation/EB/Q_Pred Std               9.46761\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           668.4\n",
      "evaluation/Actions Mean               -0.00696457\n",
      "evaluation/Actions Std                 0.423204\n",
      "evaluation/Actions Max                 0.948069\n",
      "evaluation/Actions Min                -0.976469\n",
      "time/backward_policy (s)               8.85224\n",
      "time/backward_zf1 (s)                 10.6743\n",
      "time/backward_zf2 (s)                 10.4001\n",
      "time/data sampling (s)                 1.30861\n",
      "time/data storing (s)                  0.0828332\n",
      "time/evaluation sampling (s)           2.81933\n",
      "time/exploration sampling (s)          1.77637\n",
      "time/logging (s)                       0.00408804\n",
      "time/preback_alpha (s)                 0.00552798\n",
      "time/preback_policy (s)                8.96522\n",
      "time/preback_start (s)                 0.685296\n",
      "time/preback_zf (s)                   28.718\n",
      "time/saving (s)                        3.338e-06\n",
      "time/training (s)                     10.2972\n",
      "time/epoch (s)                        84.589\n",
      "time/total (s)                       498.763\n",
      "Epoch                                  5\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:25:04.522163 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 6 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 45000\n",
      "trainer/ZF1 Loss                       0.286009\n",
      "trainer/ZF2 Loss                       0.222123\n",
      "trainer/ZF Expert Reward               0.871774\n",
      "trainer/ZF Policy Reward              -0.438221\n",
      "trainer/ZF CHI2 Term                   1.04597\n",
      "trainer/Policy Loss                   -2.81808\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               6.17096\n",
      "trainer/Policy Param Norm             22.4347\n",
      "trainer/Zf1 Grad Norm                 59.8963\n",
      "trainer/Zf1 Param Norm                44.7547\n",
      "trainer/Zf2 Grad Norm                 46.2082\n",
      "trainer/Zf2 Param Norm                45.4549\n",
      "trainer/Z Expert Predictions Mean     47.1155\n",
      "trainer/Z Expert Predictions Std       3.88222\n",
      "trainer/Z Expert Predictions Max      53.7547\n",
      "trainer/Z Expert Predictions Min      31.7754\n",
      "trainer/Z Policy Predictions Mean      2.29438\n",
      "trainer/Z Policy Predictions Std      25.4623\n",
      "trainer/Z Policy Predictions Max      52.5431\n",
      "trainer/Z Policy Predictions Min     -43.8666\n",
      "trainer/Z Expert Targets Mean         46.2437\n",
      "trainer/Z Expert Targets Std           3.85059\n",
      "trainer/Z Expert Targets Max          53.1528\n",
      "trainer/Z Expert Targets Min          30.815\n",
      "trainer/Z Policy Targets Mean          2.7326\n",
      "trainer/Z Policy Targets Std          25.1266\n",
      "trainer/Z Policy Targets Max          50.375\n",
      "trainer/Z Policy Targets Min         -43.2812\n",
      "trainer/Log Pis Mean                  12.5524\n",
      "trainer/Log Pis Std                    3.04649\n",
      "trainer/Policy mu Mean                 0.0440934\n",
      "trainer/Policy mu Std                  0.515479\n",
      "trainer/Policy log std Mean           -2.7344\n",
      "trainer/Policy log std Std             0.348715\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        40402\n",
      "exploration/num paths total          145\n",
      "evaluation/num steps total         23414\n",
      "evaluation/num paths total            71\n",
      "evaluation/path length Mean          336.3\n",
      "evaluation/path length Std           275.015\n",
      "evaluation/path length Max           884\n",
      "evaluation/path length Min            10\n",
      "evaluation/Rewards Mean                2.22018\n",
      "evaluation/Rewards Std                 1.04258\n",
      "evaluation/Rewards Max                 5.42972\n",
      "evaluation/Rewards Min                -1.632\n",
      "evaluation/Returns Mean              746.646\n",
      "evaluation/Returns Std               653.636\n",
      "evaluation/Returns Max              2089.62\n",
      "evaluation/Returns Min                 3.32282\n",
      "evaluation/Estimation Bias Mean       -4.49989\n",
      "evaluation/Estimation Bias Std       100.808\n",
      "evaluation/EB/Q_True Mean             55.3931\n",
      "evaluation/EB/Q_True Std              97.7662\n",
      "evaluation/EB/Q_Pred Mean             50.8932\n",
      "evaluation/EB/Q_Pred Std              11.5301\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           746.646\n",
      "evaluation/Actions Mean               -0.0224061\n",
      "evaluation/Actions Std                 0.453016\n",
      "evaluation/Actions Max                 0.970892\n",
      "evaluation/Actions Min                -0.982526\n",
      "time/backward_policy (s)               8.32956\n",
      "time/backward_zf1 (s)                 10.2311\n",
      "time/backward_zf2 (s)                  9.82786\n",
      "time/data sampling (s)                 1.36848\n",
      "time/data storing (s)                  0.0833668\n",
      "time/evaluation sampling (s)           2.29944\n",
      "time/exploration sampling (s)          1.75131\n",
      "time/logging (s)                       0.00480302\n",
      "time/preback_alpha (s)                 0.0055711\n",
      "time/preback_policy (s)                9.59844\n",
      "time/preback_start (s)                 0.697738\n",
      "time/preback_zf (s)                   28.8282\n",
      "time/saving (s)                        3.532e-06\n",
      "time/training (s)                     10.6031\n",
      "time/epoch (s)                        83.629\n",
      "time/total (s)                       582.393\n",
      "Epoch                                  6\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:26:29.430847 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 7 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 50000\n",
      "trainer/ZF1 Loss                       0.546455\n",
      "trainer/ZF2 Loss                       0.385788\n",
      "trainer/ZF Expert Reward               1.2282\n",
      "trainer/ZF Policy Reward              -0.082962\n",
      "trainer/ZF CHI2 Term                   1.27048\n",
      "trainer/Policy Loss                  -10.489\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               7.32521\n",
      "trainer/Policy Param Norm             23.0179\n",
      "trainer/Zf1 Grad Norm                 45.1547\n",
      "trainer/Zf1 Param Norm                46.0751\n",
      "trainer/Zf2 Grad Norm                 34.2552\n",
      "trainer/Zf2 Param Norm                46.8534\n",
      "trainer/Z Expert Predictions Mean     63.211\n",
      "trainer/Z Expert Predictions Std       5.43028\n",
      "trainer/Z Expert Predictions Max      71.1672\n",
      "trainer/Z Expert Predictions Min       0.661564\n",
      "trainer/Z Policy Predictions Mean      9.59442\n",
      "trainer/Z Policy Predictions Std      33.1097\n",
      "trainer/Z Policy Predictions Max      69.8337\n",
      "trainer/Z Policy Predictions Min     -40.1619\n",
      "trainer/Z Expert Targets Mean         61.9828\n",
      "trainer/Z Expert Targets Std           5.47396\n",
      "trainer/Z Expert Targets Max          69.9113\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean          9.67738\n",
      "trainer/Z Policy Targets Std          32.6437\n",
      "trainer/Z Policy Targets Max          68.5529\n",
      "trainer/Z Policy Targets Min         -41.0967\n",
      "trainer/Log Pis Mean                  12.8973\n",
      "trainer/Log Pis Std                    2.87657\n",
      "trainer/Policy mu Mean                 0.0159499\n",
      "trainer/Policy mu Std                  0.534373\n",
      "trainer/Policy log std Mean           -2.78187\n",
      "trainer/Policy log std Std             0.37146\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        45474\n",
      "exploration/num paths total          152\n",
      "evaluation/num steps total         30959\n",
      "evaluation/num paths total            82\n",
      "evaluation/path length Mean          685.909\n",
      "evaluation/path length Std           283.877\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           303\n",
      "evaluation/Rewards Mean                2.48836\n",
      "evaluation/Rewards Std                 1.30033\n",
      "evaluation/Rewards Max                 6.19133\n",
      "evaluation/Rewards Min                -2.8852\n",
      "evaluation/Returns Mean             1706.79\n",
      "evaluation/Returns Std               843.435\n",
      "evaluation/Returns Max              2863.96\n",
      "evaluation/Returns Min               534.213\n",
      "evaluation/Estimation Bias Mean       27.2539\n",
      "evaluation/Estimation Bias Std        93.7789\n",
      "evaluation/EB/Q_True Mean             34.4709\n",
      "evaluation/EB/Q_True Std              90.9529\n",
      "evaluation/EB/Q_Pred Mean             61.7249\n",
      "evaluation/EB/Q_Pred Std              33.4717\n",
      "evaluation/Num Paths                  11\n",
      "evaluation/Average Returns          1706.79\n",
      "evaluation/Actions Mean               -0.0207003\n",
      "evaluation/Actions Std                 0.461349\n",
      "evaluation/Actions Max                 0.993054\n",
      "evaluation/Actions Min                -0.995047\n",
      "time/backward_policy (s)               8.37033\n",
      "time/backward_zf1 (s)                 10.2067\n",
      "time/backward_zf2 (s)                  9.86535\n",
      "time/data sampling (s)                 1.3217\n",
      "time/data storing (s)                  0.0826514\n",
      "time/evaluation sampling (s)           3.55041\n",
      "time/exploration sampling (s)          1.67763\n",
      "time/logging (s)                       0.0111169\n",
      "time/preback_alpha (s)                 0.00549533\n",
      "time/preback_policy (s)                9.56816\n",
      "time/preback_start (s)                 0.680945\n",
      "time/preback_zf (s)                   28.6881\n",
      "time/saving (s)                        4.764e-06\n",
      "time/training (s)                     10.6837\n",
      "time/epoch (s)                        84.7122\n",
      "time/total (s)                       667.107\n",
      "Epoch                                  7\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:27:54.788719 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 8 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 55000\n",
      "trainer/ZF1 Loss                       0.738522\n",
      "trainer/ZF2 Loss                       0.737668\n",
      "trainer/ZF Expert Reward               0.901826\n",
      "trainer/ZF Policy Reward              -0.034457\n",
      "trainer/ZF CHI2 Term                   1.35854\n",
      "trainer/Policy Loss                  -21.7405\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               8.29307\n",
      "trainer/Policy Param Norm             23.617\n",
      "trainer/Zf1 Grad Norm                 91.2668\n",
      "trainer/Zf1 Param Norm                47.429\n",
      "trainer/Zf2 Grad Norm                 60.1973\n",
      "trainer/Zf2 Param Norm                48.3777\n",
      "trainer/Z Expert Predictions Mean     82.1082\n",
      "trainer/Z Expert Predictions Std       4.19519\n",
      "trainer/Z Expert Predictions Max      89.6313\n",
      "trainer/Z Expert Predictions Min      64.8051\n",
      "trainer/Z Policy Predictions Mean     20.4896\n",
      "trainer/Z Policy Predictions Std      40.0573\n",
      "trainer/Z Policy Predictions Max      85.4822\n",
      "trainer/Z Policy Predictions Min     -39.7171\n",
      "trainer/Z Expert Targets Mean         81.2064\n",
      "trainer/Z Expert Targets Std           4.04104\n",
      "trainer/Z Expert Targets Max          88.8309\n",
      "trainer/Z Expert Targets Min          63.1662\n",
      "trainer/Z Policy Targets Mean         20.524\n",
      "trainer/Z Policy Targets Std          39.4295\n",
      "trainer/Z Policy Targets Max          84.3628\n",
      "trainer/Z Policy Targets Min         -35.3903\n",
      "trainer/Log Pis Mean                  13.6189\n",
      "trainer/Log Pis Std                    2.79341\n",
      "trainer/Policy mu Mean                 0.00639562\n",
      "trainer/Policy mu Std                  0.574594\n",
      "trainer/Policy log std Mean           -2.84343\n",
      "trainer/Policy log std Std             0.386288\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        50859\n",
      "exploration/num paths total          159\n",
      "evaluation/num steps total         39733\n",
      "evaluation/num paths total            92\n",
      "evaluation/path length Mean          877.4\n",
      "evaluation/path length Std           261.779\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           182\n",
      "evaluation/Rewards Mean                2.91927\n",
      "evaluation/Rewards Std                 0.989311\n",
      "evaluation/Rewards Max                 6.07959\n",
      "evaluation/Rewards Min                -0.983611\n",
      "evaluation/Returns Mean             2561.37\n",
      "evaluation/Returns Std               801.358\n",
      "evaluation/Returns Max              3374.22\n",
      "evaluation/Returns Min               469.207\n",
      "evaluation/Estimation Bias Mean       62.6569\n",
      "evaluation/Estimation Bias Std        91.8059\n",
      "evaluation/EB/Q_True Mean             31.5846\n",
      "evaluation/EB/Q_True Std              90.2659\n",
      "evaluation/EB/Q_Pred Mean             94.2416\n",
      "evaluation/EB/Q_Pred Std              13.2047\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          2561.37\n",
      "evaluation/Actions Mean               -0.0162883\n",
      "evaluation/Actions Std                 0.479726\n",
      "evaluation/Actions Max                 0.987565\n",
      "evaluation/Actions Min                -0.980372\n",
      "time/backward_policy (s)               8.60372\n",
      "time/backward_zf1 (s)                 10.4199\n",
      "time/backward_zf2 (s)                 10.1133\n",
      "time/data sampling (s)                 1.3608\n",
      "time/data storing (s)                  0.0819354\n",
      "time/evaluation sampling (s)           3.92846\n",
      "time/exploration sampling (s)          1.61984\n",
      "time/logging (s)                       0.0118845\n",
      "time/preback_alpha (s)                 0.00549104\n",
      "time/preback_policy (s)                9.22709\n",
      "time/preback_start (s)                 0.682872\n",
      "time/preback_zf (s)                   28.6685\n",
      "time/saving (s)                        3.446e-06\n",
      "time/training (s)                     10.4299\n",
      "time/epoch (s)                        85.1537\n",
      "time/total (s)                       752.263\n",
      "Epoch                                  8\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:29:18.885114 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 9 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 60000\n",
      "trainer/ZF1 Loss                       1.30107\n",
      "trainer/ZF2 Loss                       1.17858\n",
      "trainer/ZF Expert Reward               0.796152\n",
      "trainer/ZF Policy Reward              -0.0508223\n",
      "trainer/ZF CHI2 Term                   1.81857\n",
      "trainer/Policy Loss                  -40.083\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm               8.86432\n",
      "trainer/Policy Param Norm             24.2567\n",
      "trainer/Zf1 Grad Norm                 63.1889\n",
      "trainer/Zf1 Param Norm                48.8293\n",
      "trainer/Zf2 Grad Norm                 92.9811\n",
      "trainer/Zf2 Param Norm                49.7765\n",
      "trainer/Z Expert Predictions Mean    102.788\n",
      "trainer/Z Expert Predictions Std       7.92912\n",
      "trainer/Z Expert Predictions Max     110.601\n",
      "trainer/Z Expert Predictions Min       0.513447\n",
      "trainer/Z Policy Predictions Mean     38.7676\n",
      "trainer/Z Policy Predictions Std      46.4508\n",
      "trainer/Z Policy Predictions Max     110.717\n",
      "trainer/Z Policy Predictions Min     -40.656\n",
      "trainer/Z Expert Targets Mean        101.992\n",
      "trainer/Z Expert Targets Std           7.9135\n",
      "trainer/Z Expert Targets Max         110.247\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         38.8184\n",
      "trainer/Z Policy Targets Std          45.6537\n",
      "trainer/Z Policy Targets Max         109.347\n",
      "trainer/Z Policy Targets Min         -39.0843\n",
      "trainer/Log Pis Mean                  13.7422\n",
      "trainer/Log Pis Std                    3.19995\n",
      "trainer/Policy mu Mean                 0.0378831\n",
      "trainer/Policy mu Std                  0.619699\n",
      "trainer/Policy log std Mean           -2.82049\n",
      "trainer/Policy log std Std             0.375278\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        54824\n",
      "exploration/num paths total          168\n",
      "evaluation/num steps total         47999\n",
      "evaluation/num paths total           104\n",
      "evaluation/path length Mean          688.833\n",
      "evaluation/path length Std           378.898\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            55\n",
      "evaluation/Rewards Mean                2.53629\n",
      "evaluation/Rewards Std                 1.56227\n",
      "evaluation/Rewards Max                 6.28518\n",
      "evaluation/Rewards Min                -2.2583\n",
      "evaluation/Returns Mean             1747.08\n",
      "evaluation/Returns Std              1142.76\n",
      "evaluation/Returns Max              3310.39\n",
      "evaluation/Returns Min               150.34\n",
      "evaluation/Estimation Bias Mean       92.5878\n",
      "evaluation/Estimation Bias Std        54.4439\n",
      "evaluation/EB/Q_True Mean              0.735225\n",
      "evaluation/EB/Q_True Std              24.2855\n",
      "evaluation/EB/Q_Pred Mean             93.323\n",
      "evaluation/EB/Q_Pred Std              48.7441\n",
      "evaluation/Num Paths                  12\n",
      "evaluation/Average Returns          1747.08\n",
      "evaluation/Actions Mean               -0.0368783\n",
      "evaluation/Actions Std                 0.494854\n",
      "evaluation/Actions Max                 0.996864\n",
      "evaluation/Actions Min                -0.994291\n",
      "time/backward_policy (s)               8.03009\n",
      "time/backward_zf1 (s)                  9.77815\n",
      "time/backward_zf2 (s)                  9.47298\n",
      "time/data sampling (s)                 1.34073\n",
      "time/data storing (s)                  0.0811681\n",
      "time/evaluation sampling (s)           4.05734\n",
      "time/exploration sampling (s)          1.63284\n",
      "time/logging (s)                       0.0113813\n",
      "time/preback_alpha (s)                 0.0054147\n",
      "time/preback_policy (s)                9.70404\n",
      "time/preback_start (s)                 0.666358\n",
      "time/preback_zf (s)                   28.5112\n",
      "time/saving (s)                        4.875e-06\n",
      "time/training (s)                     10.6036\n",
      "time/epoch (s)                        83.8953\n",
      "time/total (s)                       836.161\n",
      "Epoch                                  9\n",
      "---------------------------------  -------------\n",
      "2024-10-19 00:30:43.974024 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 10 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 65000\n",
      "trainer/ZF1 Loss                       1.29898\n",
      "trainer/ZF2 Loss                       1.42537\n",
      "trainer/ZF Expert Reward               1.22001\n",
      "trainer/ZF Policy Reward               0.49059\n",
      "trainer/ZF CHI2 Term                   1.89105\n",
      "trainer/Policy Loss                  -55.7952\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm              10.7669\n",
      "trainer/Policy Param Norm             24.7564\n",
      "trainer/Zf1 Grad Norm                 76.0055\n",
      "trainer/Zf1 Param Norm                50.2602\n",
      "trainer/Zf2 Grad Norm                 54.6212\n",
      "trainer/Zf2 Param Norm                51.1679\n",
      "trainer/Z Expert Predictions Mean    126.403\n",
      "trainer/Z Expert Predictions Std       5.67446\n",
      "trainer/Z Expert Predictions Max     133.448\n",
      "trainer/Z Expert Predictions Min      95.3892\n",
      "trainer/Z Policy Predictions Mean     54.9667\n",
      "trainer/Z Policy Predictions Std      56.1141\n",
      "trainer/Z Policy Predictions Max     130.607\n",
      "trainer/Z Policy Predictions Min     -37.4723\n",
      "trainer/Z Expert Targets Mean        125.183\n",
      "trainer/Z Expert Targets Std           5.70511\n",
      "trainer/Z Expert Targets Max         132.346\n",
      "trainer/Z Expert Targets Min          94.6156\n",
      "trainer/Z Policy Targets Mean         54.4761\n",
      "trainer/Z Policy Targets Std          55.349\n",
      "trainer/Z Policy Targets Max         129.125\n",
      "trainer/Z Policy Targets Min         -36.6962\n",
      "trainer/Log Pis Mean                  14.1923\n",
      "trainer/Log Pis Std                    3.11053\n",
      "trainer/Policy mu Mean                 0.0202316\n",
      "trainer/Policy mu Std                  0.622684\n",
      "trainer/Policy log std Mean           -2.87672\n",
      "trainer/Policy log std Std             0.406324\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        61533\n",
      "exploration/num paths total          178\n",
      "evaluation/num steps total         56829\n",
      "evaluation/num paths total           115\n",
      "evaluation/path length Mean          802.727\n",
      "evaluation/path length Std           281.786\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           105\n",
      "evaluation/Rewards Mean                3.1278\n",
      "evaluation/Rewards Std                 1.20593\n",
      "evaluation/Rewards Max                 5.89933\n",
      "evaluation/Rewards Min                -1.28032\n",
      "evaluation/Returns Mean             2510.77\n",
      "evaluation/Returns Std              1057.6\n",
      "evaluation/Returns Max              3591.81\n",
      "evaluation/Returns Min               274.815\n",
      "evaluation/Estimation Bias Mean      118.23\n",
      "evaluation/Estimation Bias Std        57.0559\n",
      "evaluation/EB/Q_True Mean              9.41218\n",
      "evaluation/EB/Q_True Std              35.2022\n",
      "evaluation/EB/Q_Pred Mean            127.642\n",
      "evaluation/EB/Q_Pred Std              46.6225\n",
      "evaluation/Num Paths                  11\n",
      "evaluation/Average Returns          2510.77\n",
      "evaluation/Actions Mean               -0.0255847\n",
      "evaluation/Actions Std                 0.479304\n",
      "evaluation/Actions Max                 0.993221\n",
      "evaluation/Actions Min                -0.965206\n",
      "time/backward_policy (s)               8.46793\n",
      "time/backward_zf1 (s)                 10.3424\n",
      "time/backward_zf2 (s)                  9.97468\n",
      "time/data sampling (s)                 1.37904\n",
      "time/data storing (s)                  0.0827552\n",
      "time/evaluation sampling (s)           3.84591\n",
      "time/exploration sampling (s)          1.6451\n",
      "time/logging (s)                       0.01125\n",
      "time/preback_alpha (s)                 0.00545122\n",
      "time/preback_policy (s)                9.3722\n",
      "time/preback_start (s)                 0.67775\n",
      "time/preback_zf (s)                   28.5879\n",
      "time/saving (s)                        4.506e-06\n",
      "time/training (s)                     10.4937\n",
      "time/epoch (s)                        84.886\n",
      "time/total (s)                       921.049\n",
      "Epoch                                 10\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:32:08.235973 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 11 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 70000\n",
      "trainer/ZF1 Loss                       2.14766\n",
      "trainer/ZF2 Loss                       1.75391\n",
      "trainer/ZF Expert Reward               1.49594\n",
      "trainer/ZF Policy Reward               1.08152\n",
      "trainer/ZF CHI2 Term                   2.3253\n",
      "trainer/Policy Loss                  -69.8611\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm              11.8535\n",
      "trainer/Policy Param Norm             25.1923\n",
      "trainer/Zf1 Grad Norm                 82.3059\n",
      "trainer/Zf1 Param Norm                51.6303\n",
      "trainer/Zf2 Grad Norm                 87.4003\n",
      "trainer/Zf2 Param Norm                52.5321\n",
      "trainer/Z Expert Predictions Mean    146.56\n",
      "trainer/Z Expert Predictions Std       5.26007\n",
      "trainer/Z Expert Predictions Max     153.652\n",
      "trainer/Z Expert Predictions Min     116.541\n",
      "trainer/Z Policy Predictions Mean     69.402\n",
      "trainer/Z Policy Predictions Std      67.0576\n",
      "trainer/Z Policy Predictions Max     153.087\n",
      "trainer/Z Policy Predictions Min     -45.3644\n",
      "trainer/Z Expert Targets Mean        145.064\n",
      "trainer/Z Expert Targets Std           5.59118\n",
      "trainer/Z Expert Targets Max         153.626\n",
      "trainer/Z Expert Targets Min         115.451\n",
      "trainer/Z Policy Targets Mean         68.3205\n",
      "trainer/Z Policy Targets Std          66.2331\n",
      "trainer/Z Policy Targets Max         149.913\n",
      "trainer/Z Policy Targets Min         -46.7323\n",
      "trainer/Log Pis Mean                  14.7154\n",
      "trainer/Log Pis Std                    3.24951\n",
      "trainer/Policy mu Mean                 0.0405202\n",
      "trainer/Policy mu Std                  0.658027\n",
      "trainer/Policy log std Mean           -2.91152\n",
      "trainer/Policy log std Std             0.40858\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        66284\n",
      "exploration/num paths total          184\n",
      "evaluation/num steps total         60081\n",
      "evaluation/num paths total           125\n",
      "evaluation/path length Mean          325.2\n",
      "evaluation/path length Std           267.202\n",
      "evaluation/path length Max           893\n",
      "evaluation/path length Min           101\n",
      "evaluation/Rewards Mean                3.45255\n",
      "evaluation/Rewards Std                 1.05583\n",
      "evaluation/Rewards Max                 6.04837\n",
      "evaluation/Rewards Min                -1.01703\n",
      "evaluation/Returns Mean             1122.77\n",
      "evaluation/Returns Std              1001.65\n",
      "evaluation/Returns Max              3166.34\n",
      "evaluation/Returns Min               302.994\n",
      "evaluation/Estimation Bias Mean       73.0233\n",
      "evaluation/Estimation Bias Std       153.607\n",
      "evaluation/EB/Q_True Mean             88.5187\n",
      "evaluation/EB/Q_True Std             149.834\n",
      "evaluation/EB/Q_Pred Mean            161.542\n",
      "evaluation/EB/Q_Pred Std              15.6164\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1122.77\n",
      "evaluation/Actions Mean               -0.034333\n",
      "evaluation/Actions Std                 0.51265\n",
      "evaluation/Actions Max                 0.993657\n",
      "evaluation/Actions Min                -0.972161\n",
      "time/backward_policy (s)               8.26428\n",
      "time/backward_zf1 (s)                 10.1036\n",
      "time/backward_zf2 (s)                  9.75695\n",
      "time/data sampling (s)                 1.35813\n",
      "time/data storing (s)                  0.0819027\n",
      "time/evaluation sampling (s)           3.37819\n",
      "time/exploration sampling (s)          1.60049\n",
      "time/logging (s)                       0.00703102\n",
      "time/preback_alpha (s)                 0.00545719\n",
      "time/preback_policy (s)                9.56036\n",
      "time/preback_start (s)                 0.675627\n",
      "time/preback_zf (s)                   28.6189\n",
      "time/saving (s)                        5.269e-06\n",
      "time/training (s)                     10.6435\n",
      "time/epoch (s)                        84.0544\n",
      "time/total (s)                      1005.11\n",
      "Epoch                                 11\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:33:32.971908 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 12 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 75000\n",
      "trainer/ZF1 Loss                       3.13334\n",
      "trainer/ZF2 Loss                       3.16118\n",
      "trainer/ZF Expert Reward               1.28806\n",
      "trainer/ZF Policy Reward               0.3606\n",
      "trainer/ZF CHI2 Term                   3.78496\n",
      "trainer/Policy Loss                  -99.2394\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm              13.7627\n",
      "trainer/Policy Param Norm             25.6456\n",
      "trainer/Zf1 Grad Norm                294.841\n",
      "trainer/Zf1 Param Norm                52.9219\n",
      "trainer/Zf2 Grad Norm                284.795\n",
      "trainer/Zf2 Param Norm                53.8198\n",
      "trainer/Z Expert Predictions Mean    165.3\n",
      "trainer/Z Expert Predictions Std      14.3805\n",
      "trainer/Z Expert Predictions Max     175.443\n",
      "trainer/Z Expert Predictions Min       9.36742\n",
      "trainer/Z Policy Predictions Mean     98.0982\n",
      "trainer/Z Policy Predictions Std      67.5666\n",
      "trainer/Z Policy Predictions Max     176.247\n",
      "trainer/Z Policy Predictions Min     -38.549\n",
      "trainer/Z Expert Targets Mean        164.011\n",
      "trainer/Z Expert Targets Std          15.2792\n",
      "trainer/Z Expert Targets Max         176.059\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         97.7376\n",
      "trainer/Z Policy Targets Std          66.9001\n",
      "trainer/Z Policy Targets Max         174.838\n",
      "trainer/Z Policy Targets Min         -37.3612\n",
      "trainer/Log Pis Mean                  15.4354\n",
      "trainer/Log Pis Std                    3.10088\n",
      "trainer/Policy mu Mean                 0.00189103\n",
      "trainer/Policy mu Std                  0.690998\n",
      "trainer/Policy log std Mean           -2.95409\n",
      "trainer/Policy log std Std             0.442109\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        70524\n",
      "exploration/num paths total          189\n",
      "evaluation/num steps total         68628\n",
      "evaluation/num paths total           135\n",
      "evaluation/path length Mean          854.7\n",
      "evaluation/path length Std           256.641\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           215\n",
      "evaluation/Rewards Mean                3.76762\n",
      "evaluation/Rewards Std                 0.874649\n",
      "evaluation/Rewards Max                 6.15421\n",
      "evaluation/Rewards Min                -1.70119\n",
      "evaluation/Returns Mean             3220.19\n",
      "evaluation/Returns Std               991.894\n",
      "evaluation/Returns Max              3920.47\n",
      "evaluation/Returns Min               773.103\n",
      "evaluation/Estimation Bias Mean      143.652\n",
      "evaluation/Estimation Bias Std       118.857\n",
      "evaluation/EB/Q_True Mean             41.735\n",
      "evaluation/EB/Q_True Std             117.718\n",
      "evaluation/EB/Q_Pred Mean            185.387\n",
      "evaluation/EB/Q_Pred Std              10.5534\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          3220.19\n",
      "evaluation/Actions Mean               -0.0508907\n",
      "evaluation/Actions Std                 0.515629\n",
      "evaluation/Actions Max                 0.992045\n",
      "evaluation/Actions Min                -0.979188\n",
      "time/backward_policy (s)               8.55323\n",
      "time/backward_zf1 (s)                 10.3499\n",
      "time/backward_zf2 (s)                 10.076\n",
      "time/data sampling (s)                 1.33426\n",
      "time/data storing (s)                  0.0814253\n",
      "time/evaluation sampling (s)           3.63363\n",
      "time/exploration sampling (s)          1.60882\n",
      "time/logging (s)                       0.0193547\n",
      "time/preback_alpha (s)                 0.0054773\n",
      "time/preback_policy (s)                9.20513\n",
      "time/preback_start (s)                 0.677185\n",
      "time/preback_zf (s)                   28.6337\n",
      "time/saving (s)                        3.311e-06\n",
      "time/training (s)                     10.3662\n",
      "time/epoch (s)                        84.5444\n",
      "time/total (s)                      1089.65\n",
      "Epoch                                 12\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:34:56.818282 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 13 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 80000\n",
      "trainer/ZF1 Loss                       3.73053\n",
      "trainer/ZF2 Loss                       3.15006\n",
      "trainer/ZF Expert Reward               0.231918\n",
      "trainer/ZF Policy Reward              -0.6964\n",
      "trainer/ZF CHI2 Term                   4.08278\n",
      "trainer/Policy Loss                  -99.5802\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm              12.4587\n",
      "trainer/Policy Param Norm             26.0355\n",
      "trainer/Zf1 Grad Norm                191.039\n",
      "trainer/Zf1 Param Norm                54.1897\n",
      "trainer/Zf2 Grad Norm                149.978\n",
      "trainer/Zf2 Param Norm                55.0496\n",
      "trainer/Z Expert Predictions Mean    183.665\n",
      "trainer/Z Expert Predictions Std      12.729\n",
      "trainer/Z Expert Predictions Max     193.817\n",
      "trainer/Z Expert Predictions Min       3.07962\n",
      "trainer/Z Policy Predictions Mean     98.2098\n",
      "trainer/Z Policy Predictions Std      79.205\n",
      "trainer/Z Policy Predictions Max     195.123\n",
      "trainer/Z Policy Predictions Min     -37.688\n",
      "trainer/Z Expert Targets Mean        183.433\n",
      "trainer/Z Expert Targets Std          13.0047\n",
      "trainer/Z Expert Targets Max         194.58\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         98.9062\n",
      "trainer/Z Policy Targets Std          78.3694\n",
      "trainer/Z Policy Targets Max         193.55\n",
      "trainer/Z Policy Targets Min         -35.1263\n",
      "trainer/Log Pis Mean                  15.6285\n",
      "trainer/Log Pis Std                    3.39894\n",
      "trainer/Policy mu Mean                 0.0223245\n",
      "trainer/Policy mu Std                  0.755261\n",
      "trainer/Policy log std Mean           -2.93907\n",
      "trainer/Policy log std Std             0.48379\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        76912\n",
      "exploration/num paths total          200\n",
      "evaluation/num steps total         72777\n",
      "evaluation/num paths total           145\n",
      "evaluation/path length Mean          414.9\n",
      "evaluation/path length Std           278.613\n",
      "evaluation/path length Max           727\n",
      "evaluation/path length Min            11\n",
      "evaluation/Rewards Mean                3.61566\n",
      "evaluation/Rewards Std                 0.893496\n",
      "evaluation/Rewards Max                 6.16649\n",
      "evaluation/Rewards Min                -1.70413\n",
      "evaluation/Returns Mean             1500.14\n",
      "evaluation/Returns Std              1034.65\n",
      "evaluation/Returns Max              2567.15\n",
      "evaluation/Returns Min                13.007\n",
      "evaluation/Estimation Bias Mean      144.164\n",
      "evaluation/Estimation Bias Std       125.858\n",
      "evaluation/EB/Q_True Mean             54.9561\n",
      "evaluation/EB/Q_True Std             124.022\n",
      "evaluation/EB/Q_Pred Mean            199.12\n",
      "evaluation/EB/Q_Pred Std              14.7362\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1500.14\n",
      "evaluation/Actions Mean               -0.0595818\n",
      "evaluation/Actions Std                 0.510733\n",
      "evaluation/Actions Max                 0.988957\n",
      "evaluation/Actions Min                -0.975652\n",
      "time/backward_policy (s)               8.60355\n",
      "time/backward_zf1 (s)                 10.4017\n",
      "time/backward_zf2 (s)                 10.125\n",
      "time/data sampling (s)                 1.39731\n",
      "time/data storing (s)                  0.0813581\n",
      "time/evaluation sampling (s)           2.70475\n",
      "time/exploration sampling (s)          1.62194\n",
      "time/logging (s)                       0.0111697\n",
      "time/preback_alpha (s)                 0.00545383\n",
      "time/preback_policy (s)                9.13051\n",
      "time/preback_start (s)                 0.676059\n",
      "time/preback_zf (s)                   28.5918\n",
      "time/saving (s)                        7.42e-06\n",
      "time/training (s)                     10.2821\n",
      "time/epoch (s)                        83.6328\n",
      "time/total (s)                      1173.29\n",
      "Epoch                                 13\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:36:19.865250 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 14 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 85000\n",
      "trainer/ZF1 Loss                       3.01861\n",
      "trainer/ZF2 Loss                       3.43085\n",
      "trainer/ZF Expert Reward               0.773231\n",
      "trainer/ZF Policy Reward               0.118203\n",
      "trainer/ZF CHI2 Term                   3.73276\n",
      "trainer/Policy Loss                 -130.901\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm              14.8568\n",
      "trainer/Policy Param Norm             26.4211\n",
      "trainer/Zf1 Grad Norm                172.652\n",
      "trainer/Zf1 Param Norm                55.3459\n",
      "trainer/Zf2 Grad Norm                119.952\n",
      "trainer/Zf2 Param Norm                56.197\n",
      "trainer/Z Expert Predictions Mean    202.24\n",
      "trainer/Z Expert Predictions Std      13.9054\n",
      "trainer/Z Expert Predictions Max     214.332\n",
      "trainer/Z Expert Predictions Min      -2.75704\n",
      "trainer/Z Policy Predictions Mean    129.884\n",
      "trainer/Z Policy Predictions Std      79.3452\n",
      "trainer/Z Policy Predictions Max     213.003\n",
      "trainer/Z Policy Predictions Min     -25.9964\n",
      "trainer/Z Expert Targets Mean        201.467\n",
      "trainer/Z Expert Targets Std          13.7446\n",
      "trainer/Z Expert Targets Max         215.533\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        129.766\n",
      "trainer/Z Policy Targets Std          78.8307\n",
      "trainer/Z Policy Targets Max         211.882\n",
      "trainer/Z Policy Targets Min         -25.7071\n",
      "trainer/Log Pis Mean                  16.474\n",
      "trainer/Log Pis Std                    3.12781\n",
      "trainer/Policy mu Mean                -0.0364194\n",
      "trainer/Policy mu Std                  0.738622\n",
      "trainer/Policy log std Mean           -3.02582\n",
      "trainer/Policy log std Std             0.447501\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        79078\n",
      "exploration/num paths total          203\n",
      "evaluation/num steps total         82414\n",
      "evaluation/num paths total           155\n",
      "evaluation/path length Mean          963.7\n",
      "evaluation/path length Std           108.9\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           637\n",
      "evaluation/Rewards Mean                3.65313\n",
      "evaluation/Rewards Std                 1.38195\n",
      "evaluation/Rewards Max                 5.92703\n",
      "evaluation/Rewards Min                -1.91192\n",
      "evaluation/Returns Mean             3520.52\n",
      "evaluation/Returns Std               739.8\n",
      "evaluation/Returns Max              4073.93\n",
      "evaluation/Returns Min              1776.51\n",
      "evaluation/Estimation Bias Mean      171.82\n",
      "evaluation/Estimation Bias Std       119.966\n",
      "evaluation/EB/Q_True Mean             37.0321\n",
      "evaluation/EB/Q_True Std             111.852\n",
      "evaluation/EB/Q_Pred Mean            208.852\n",
      "evaluation/EB/Q_Pred Std              50.0082\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          3520.52\n",
      "evaluation/Actions Mean               -0.0521157\n",
      "evaluation/Actions Std                 0.514774\n",
      "evaluation/Actions Max                 0.99761\n",
      "evaluation/Actions Min                -0.999286\n",
      "time/backward_policy (s)               8.04951\n",
      "time/backward_zf1 (s)                  9.78627\n",
      "time/backward_zf2 (s)                  9.49233\n",
      "time/data sampling (s)                 1.30155\n",
      "time/data storing (s)                  0.0809616\n",
      "time/evaluation sampling (s)           3.32168\n",
      "time/exploration sampling (s)          1.57573\n",
      "time/logging (s)                       0.0164456\n",
      "time/preback_alpha (s)                 0.00539941\n",
      "time/preback_policy (s)                9.62586\n",
      "time/preback_start (s)                 0.662277\n",
      "time/preback_zf (s)                   28.4059\n",
      "time/saving (s)                        7.983e-06\n",
      "time/training (s)                     10.5286\n",
      "time/epoch (s)                        82.8526\n",
      "time/total (s)                      1256.14\n",
      "Epoch                                 14\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:37:44.598487 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 15 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 90000\n",
      "trainer/ZF1 Loss                       3.55676\n",
      "trainer/ZF2 Loss                       6.16576\n",
      "trainer/ZF Expert Reward               0.778106\n",
      "trainer/ZF Policy Reward               0.342651\n",
      "trainer/ZF CHI2 Term                   5.26091\n",
      "trainer/Policy Loss                 -146.239\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm              16.6254\n",
      "trainer/Policy Param Norm             26.7269\n",
      "trainer/Zf1 Grad Norm                241.79\n",
      "trainer/Zf1 Param Norm                56.4416\n",
      "trainer/Zf2 Grad Norm                431.114\n",
      "trainer/Zf2 Param Norm                57.2908\n",
      "trainer/Z Expert Predictions Mean    218.963\n",
      "trainer/Z Expert Predictions Std       7.66391\n",
      "trainer/Z Expert Predictions Max     229.314\n",
      "trainer/Z Expert Predictions Min     178.632\n",
      "trainer/Z Policy Predictions Mean    145.057\n",
      "trainer/Z Policy Predictions Std      84.0574\n",
      "trainer/Z Policy Predictions Max     229.695\n",
      "trainer/Z Policy Predictions Min     -32.3096\n",
      "trainer/Z Expert Targets Mean        218.184\n",
      "trainer/Z Expert Targets Std           7.65401\n",
      "trainer/Z Expert Targets Max         229.898\n",
      "trainer/Z Expert Targets Min         176.076\n",
      "trainer/Z Policy Targets Mean        144.714\n",
      "trainer/Z Policy Targets Std          83.1963\n",
      "trainer/Z Policy Targets Max         226.622\n",
      "trainer/Z Policy Targets Min         -32.5867\n",
      "trainer/Log Pis Mean                  16.7549\n",
      "trainer/Log Pis Std                    2.94125\n",
      "trainer/Policy mu Mean                -0.0244535\n",
      "trainer/Policy mu Std                  0.741608\n",
      "trainer/Policy log std Mean           -3.06788\n",
      "trainer/Policy log std Std             0.474677\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        86576\n",
      "exploration/num paths total          213\n",
      "evaluation/num steps total         88577\n",
      "evaluation/num paths total           167\n",
      "evaluation/path length Mean          513.583\n",
      "evaluation/path length Std           409.467\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            11\n",
      "evaluation/Rewards Mean                3.65593\n",
      "evaluation/Rewards Std                 1.00822\n",
      "evaluation/Rewards Max                 5.75249\n",
      "evaluation/Rewards Min                -1.5315\n",
      "evaluation/Returns Mean             1877.62\n",
      "evaluation/Returns Std              1574.93\n",
      "evaluation/Returns Max              3942.85\n",
      "evaluation/Returns Min                 5.74158\n",
      "evaluation/Estimation Bias Mean      173.922\n",
      "evaluation/Estimation Bias Std       140.257\n",
      "evaluation/EB/Q_True Mean             58.3442\n",
      "evaluation/EB/Q_True Std             136.929\n",
      "evaluation/EB/Q_Pred Mean            232.267\n",
      "evaluation/EB/Q_Pred Std              16.5867\n",
      "evaluation/Num Paths                  12\n",
      "evaluation/Average Returns          1877.62\n",
      "evaluation/Actions Mean               -0.0646961\n",
      "evaluation/Actions Std                 0.510426\n",
      "evaluation/Actions Max                 0.990416\n",
      "evaluation/Actions Min                -0.977581\n",
      "time/backward_policy (s)               8.56566\n",
      "time/backward_zf1 (s)                 10.4046\n",
      "time/backward_zf2 (s)                 10.0721\n",
      "time/data sampling (s)                 1.39609\n",
      "time/data storing (s)                  0.0825178\n",
      "time/evaluation sampling (s)           3.42726\n",
      "time/exploration sampling (s)          1.63921\n",
      "time/logging (s)                       0.00861181\n",
      "time/preback_alpha (s)                 0.00547826\n",
      "time/preback_policy (s)                9.2074\n",
      "time/preback_start (s)                 0.680863\n",
      "time/preback_zf (s)                   28.5774\n",
      "time/saving (s)                        4.092e-06\n",
      "time/training (s)                     10.4541\n",
      "time/epoch (s)                        84.5213\n",
      "time/total (s)                      1340.67\n",
      "Epoch                                 15\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:39:12.596795 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 16 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 95000\n",
      "trainer/ZF1 Loss                      18.1168\n",
      "trainer/ZF2 Loss                      19.1417\n",
      "trainer/ZF Expert Reward               1.50373\n",
      "trainer/ZF Policy Reward               1.83316\n",
      "trainer/ZF CHI2 Term                  18.6502\n",
      "trainer/Policy Loss                 -167.425\n",
      "trainer/Bias Value                    10\n",
      "trainer/Policy Grad Norm              13.1919\n",
      "trainer/Policy Param Norm             27.1367\n",
      "trainer/Zf1 Grad Norm                121.104\n",
      "trainer/Zf1 Param Norm                57.4934\n",
      "trainer/Zf2 Grad Norm                141.512\n",
      "trainer/Zf2 Param Norm                58.3643\n",
      "trainer/Z Expert Predictions Mean    235.682\n",
      "trainer/Z Expert Predictions Std       6.30921\n",
      "trainer/Z Expert Predictions Max     246.075\n",
      "trainer/Z Expert Predictions Min     204.412\n",
      "trainer/Z Policy Predictions Mean    166.016\n",
      "trainer/Z Policy Predictions Std      89.2812\n",
      "trainer/Z Policy Predictions Max     247.62\n",
      "trainer/Z Policy Predictions Min     -28.3475\n",
      "trainer/Z Expert Targets Mean        234.179\n",
      "trainer/Z Expert Targets Std           6.26806\n",
      "trainer/Z Expert Targets Max         245.764\n",
      "trainer/Z Expert Targets Min         203.06\n",
      "trainer/Z Policy Targets Mean        164.183\n",
      "trainer/Z Policy Targets Std          88.5903\n",
      "trainer/Z Policy Targets Max         243.511\n",
      "trainer/Z Policy Targets Min         -26.6092\n",
      "trainer/Log Pis Mean                  17.0354\n",
      "trainer/Log Pis Std                    3.58128\n",
      "trainer/Policy mu Mean                 0.0134811\n",
      "trainer/Policy mu Std                  0.783347\n",
      "trainer/Policy log std Mean           -3.07169\n",
      "trainer/Policy log std Std             0.510778\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        89053\n",
      "exploration/num paths total          217\n",
      "evaluation/num steps total         94091\n",
      "evaluation/num paths total           177\n",
      "evaluation/path length Mean          551.4\n",
      "evaluation/path length Std           455.496\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            11\n",
      "evaluation/Rewards Mean                3.68382\n",
      "evaluation/Rewards Std                 0.933636\n",
      "evaluation/Rewards Max                 6.21907\n",
      "evaluation/Rewards Min                -1.61119\n",
      "evaluation/Returns Mean             2031.26\n",
      "evaluation/Returns Std              1741.89\n",
      "evaluation/Returns Max              3922.27\n",
      "evaluation/Returns Min                12.3939\n",
      "evaluation/Estimation Bias Mean      183.783\n",
      "evaluation/Estimation Bias Std       138.701\n",
      "evaluation/EB/Q_True Mean             62.0387\n",
      "evaluation/EB/Q_True Std             135.745\n",
      "evaluation/EB/Q_Pred Mean            245.822\n",
      "evaluation/EB/Q_Pred Std              16.3347\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          2031.26\n",
      "evaluation/Actions Mean               -0.0447487\n",
      "evaluation/Actions Std                 0.504699\n",
      "evaluation/Actions Max                 0.992372\n",
      "evaluation/Actions Min                -0.966259\n",
      "time/backward_policy (s)               8.63484\n",
      "time/backward_zf1 (s)                 10.9152\n",
      "time/backward_zf2 (s)                 10.2708\n",
      "time/data sampling (s)                 1.53779\n",
      "time/data storing (s)                  0.0892486\n",
      "time/evaluation sampling (s)           3.59404\n",
      "time/exploration sampling (s)          1.65083\n",
      "time/logging (s)                       0.00871955\n",
      "time/preback_alpha (s)                 0.00584152\n",
      "time/preback_policy (s)                9.89471\n",
      "time/preback_start (s)                 0.740865\n",
      "time/preback_zf (s)                   29.443\n",
      "time/saving (s)                        6.681e-06\n",
      "time/training (s)                     10.9882\n",
      "time/epoch (s)                        87.774\n",
      "time/total (s)                      1428.44\n",
      "Epoch                                 16\n",
      "---------------------------------  --------------\n",
      "2024-10-19 00:40:36.789938 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 17 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 100000\n",
      "trainer/ZF1 Loss                        8.50224\n",
      "trainer/ZF2 Loss                        7.25556\n",
      "trainer/ZF Expert Reward                1.04284\n",
      "trainer/ZF Policy Reward                1.11182\n",
      "trainer/ZF CHI2 Term                    8.02955\n",
      "trainer/Policy Loss                  -179.451\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               16.2621\n",
      "trainer/Policy Param Norm              27.528\n",
      "trainer/Zf1 Grad Norm                1545.51\n",
      "trainer/Zf1 Param Norm                 58.4788\n",
      "trainer/Zf2 Grad Norm                1141.66\n",
      "trainer/Zf2 Param Norm                 59.3265\n",
      "trainer/Z Expert Predictions Mean     249.018\n",
      "trainer/Z Expert Predictions Std        8.10268\n",
      "trainer/Z Expert Predictions Max      260.962\n",
      "trainer/Z Expert Predictions Min      199.296\n",
      "trainer/Z Policy Predictions Mean     177.456\n",
      "trainer/Z Policy Predictions Std       90.1167\n",
      "trainer/Z Policy Predictions Max      263.466\n",
      "trainer/Z Policy Predictions Min      -11.8207\n",
      "trainer/Z Expert Targets Mean         247.976\n",
      "trainer/Z Expert Targets Std            7.73452\n",
      "trainer/Z Expert Targets Max          259.393\n",
      "trainer/Z Expert Targets Min          200.285\n",
      "trainer/Z Policy Targets Mean         176.344\n",
      "trainer/Z Policy Targets Std           89.2555\n",
      "trainer/Z Policy Targets Max          258.834\n",
      "trainer/Z Policy Targets Min          -13.4239\n",
      "trainer/Log Pis Mean                   17.5656\n",
      "trainer/Log Pis Std                     3.65591\n",
      "trainer/Policy mu Mean                  0.00804234\n",
      "trainer/Policy mu Std                   0.928808\n",
      "trainer/Policy log std Mean            -2.97226\n",
      "trainer/Policy log std Std              0.580955\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         95872\n",
      "exploration/num paths total           226\n",
      "evaluation/num steps total         103119\n",
      "evaluation/num paths total            187\n",
      "evaluation/path length Mean           902.8\n",
      "evaluation/path length Std            291.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             28\n",
      "evaluation/Rewards Mean                 3.47744\n",
      "evaluation/Rewards Std                  1.59629\n",
      "evaluation/Rewards Max                  5.99535\n",
      "evaluation/Rewards Min                 -2.95499\n",
      "evaluation/Returns Mean              3139.43\n",
      "evaluation/Returns Std               1636.91\n",
      "evaluation/Returns Max               4021.09\n",
      "evaluation/Returns Min               -279.417\n",
      "evaluation/Estimation Bias Mean       246.257\n",
      "evaluation/Estimation Bias Std         73.4296\n",
      "evaluation/EB/Q_True Mean              -4.94284\n",
      "evaluation/EB/Q_True Std               21.6269\n",
      "evaluation/EB/Q_Pred Mean             241.315\n",
      "evaluation/EB/Q_Pred Std               67.4204\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3139.43\n",
      "evaluation/Actions Mean                 0.0012509\n",
      "evaluation/Actions Std                  0.527754\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999693\n",
      "time/backward_policy (s)                8.25988\n",
      "time/backward_zf1 (s)                  10.0439\n",
      "time/backward_zf2 (s)                   9.69207\n",
      "time/data sampling (s)                  1.38402\n",
      "time/data storing (s)                   0.0810337\n",
      "time/evaluation sampling (s)            3.52834\n",
      "time/exploration sampling (s)           1.60716\n",
      "time/logging (s)                        0.0134269\n",
      "time/preback_alpha (s)                  0.00544708\n",
      "time/preback_policy (s)                 9.54795\n",
      "time/preback_start (s)                  0.682045\n",
      "time/preback_zf (s)                    28.6359\n",
      "time/saving (s)                         3.967e-06\n",
      "time/training (s)                      10.5148\n",
      "time/epoch (s)                         83.9959\n",
      "time/total (s)                       1512.44\n",
      "Epoch                                  17\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:42:01.630766 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 18 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 105000\n",
      "trainer/ZF1 Loss                       17.6664\n",
      "trainer/ZF2 Loss                       17.1664\n",
      "trainer/ZF Expert Reward                1.00031\n",
      "trainer/ZF Policy Reward                1.19283\n",
      "trainer/ZF CHI2 Term                   17.5092\n",
      "trainer/Policy Loss                  -191.388\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               17.7071\n",
      "trainer/Policy Param Norm              27.7965\n",
      "trainer/Zf1 Grad Norm                 623.96\n",
      "trainer/Zf1 Param Norm                 59.4283\n",
      "trainer/Zf2 Grad Norm                 708.035\n",
      "trainer/Zf2 Param Norm                 60.2459\n",
      "trainer/Z Expert Predictions Mean     260.604\n",
      "trainer/Z Expert Predictions Std        7.59448\n",
      "trainer/Z Expert Predictions Max      272.064\n",
      "trainer/Z Expert Predictions Min      212.513\n",
      "trainer/Z Policy Predictions Mean     190.321\n",
      "trainer/Z Policy Predictions Std       83.239\n",
      "trainer/Z Policy Predictions Max      272.403\n",
      "trainer/Z Policy Predictions Min        8.22031\n",
      "trainer/Z Expert Targets Mean         259.604\n",
      "trainer/Z Expert Targets Std            7.67346\n",
      "trainer/Z Expert Targets Max          271.901\n",
      "trainer/Z Expert Targets Min          212.015\n",
      "trainer/Z Policy Targets Mean         189.128\n",
      "trainer/Z Policy Targets Std           81.8218\n",
      "trainer/Z Policy Targets Max          270.452\n",
      "trainer/Z Policy Targets Min            8.98842\n",
      "trainer/Log Pis Mean                   17.8735\n",
      "trainer/Log Pis Std                     3.70838\n",
      "trainer/Policy mu Mean                  0.0198378\n",
      "trainer/Policy mu Std                   0.960983\n",
      "trainer/Policy log std Mean            -3.0147\n",
      "trainer/Policy log std Std              0.5857\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         98979\n",
      "exploration/num paths total           230\n",
      "evaluation/num steps total         111885\n",
      "evaluation/num paths total            197\n",
      "evaluation/path length Mean           876.6\n",
      "evaluation/path length Std            295.159\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             21\n",
      "evaluation/Rewards Mean                 3.47422\n",
      "evaluation/Rewards Std                  1.46736\n",
      "evaluation/Rewards Max                  5.9874\n",
      "evaluation/Rewards Min                 -2.20698\n",
      "evaluation/Returns Mean              3045.5\n",
      "evaluation/Returns Std               1505.36\n",
      "evaluation/Returns Max               4064.35\n",
      "evaluation/Returns Min                 45.0186\n",
      "evaluation/Estimation Bias Mean       196.341\n",
      "evaluation/Estimation Bias Std        138.6\n",
      "evaluation/EB/Q_True Mean              42.5329\n",
      "evaluation/EB/Q_True Std              121.403\n",
      "evaluation/EB/Q_Pred Mean             238.874\n",
      "evaluation/EB/Q_Pred Std               80.8044\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3045.5\n",
      "evaluation/Actions Mean                -0.0215865\n",
      "evaluation/Actions Std                  0.496937\n",
      "evaluation/Actions Max                  0.999966\n",
      "evaluation/Actions Min                 -0.997077\n",
      "time/backward_policy (s)                8.31312\n",
      "time/backward_zf1 (s)                  10.2076\n",
      "time/backward_zf2 (s)                   9.82904\n",
      "time/data sampling (s)                  1.397\n",
      "time/data storing (s)                   0.0833161\n",
      "time/evaluation sampling (s)            3.39579\n",
      "time/exploration sampling (s)           1.63311\n",
      "time/logging (s)                        0.0112432\n",
      "time/preback_alpha (s)                  0.00549322\n",
      "time/preback_policy (s)                 9.63687\n",
      "time/preback_start (s)                  0.690151\n",
      "time/preback_zf (s)                    28.7095\n",
      "time/saving (s)                         4.274e-06\n",
      "time/training (s)                      10.7202\n",
      "time/epoch (s)                         84.6323\n",
      "time/total (s)                       1597.08\n",
      "Epoch                                  18\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:43:26.047460 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 19 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 110000\n",
      "trainer/ZF1 Loss                        5.11699\n",
      "trainer/ZF2 Loss                        4.51078\n",
      "trainer/ZF Expert Reward                0.0411266\n",
      "trainer/ZF Policy Reward                0.277584\n",
      "trainer/ZF CHI2 Term                    4.88201\n",
      "trainer/Policy Loss                  -197.003\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               16.4283\n",
      "trainer/Policy Param Norm              28.0467\n",
      "trainer/Zf1 Grad Norm                 389.824\n",
      "trainer/Zf1 Param Norm                 60.2795\n",
      "trainer/Zf2 Grad Norm                 286.282\n",
      "trainer/Zf2 Param Norm                 61.0822\n",
      "trainer/Z Expert Predictions Mean     268.832\n",
      "trainer/Z Expert Predictions Std        8.62473\n",
      "trainer/Z Expert Predictions Max      280.163\n",
      "trainer/Z Expert Predictions Min      217.563\n",
      "trainer/Z Policy Predictions Mean     195.325\n",
      "trainer/Z Policy Predictions Std       90.451\n",
      "trainer/Z Policy Predictions Max      284.004\n",
      "trainer/Z Policy Predictions Min        7.79374\n",
      "trainer/Z Expert Targets Mean         268.791\n",
      "trainer/Z Expert Targets Std            8.57714\n",
      "trainer/Z Expert Targets Max          281.518\n",
      "trainer/Z Expert Targets Min          219.005\n",
      "trainer/Z Policy Targets Mean         195.047\n",
      "trainer/Z Policy Targets Std           89.6506\n",
      "trainer/Z Policy Targets Max          279.806\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   17.6395\n",
      "trainer/Log Pis Std                     3.39227\n",
      "trainer/Policy mu Mean                 -0.00388089\n",
      "trainer/Policy mu Std                   0.870462\n",
      "trainer/Policy log std Mean            -3.03506\n",
      "trainer/Policy log std Std              0.603434\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        105755\n",
      "exploration/num paths total           238\n",
      "evaluation/num steps total         119032\n",
      "evaluation/num paths total            209\n",
      "evaluation/path length Mean           595.583\n",
      "evaluation/path length Std            372.156\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             71\n",
      "evaluation/Rewards Mean                 2.80883\n",
      "evaluation/Rewards Std                  2.29763\n",
      "evaluation/Rewards Max                  5.78216\n",
      "evaluation/Rewards Min                 -3.59165\n",
      "evaluation/Returns Mean              1672.89\n",
      "evaluation/Returns Std               1392.82\n",
      "evaluation/Returns Max               3826.02\n",
      "evaluation/Returns Min               -310.462\n",
      "evaluation/Estimation Bias Mean       190.431\n",
      "evaluation/Estimation Bias Std        135.298\n",
      "evaluation/EB/Q_True Mean              45.4598\n",
      "evaluation/EB/Q_True Std              116.497\n",
      "evaluation/EB/Q_Pred Mean             235.891\n",
      "evaluation/EB/Q_Pred Std               89.7909\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           1672.89\n",
      "evaluation/Actions Mean                -0.0780119\n",
      "evaluation/Actions Std                  0.578513\n",
      "evaluation/Actions Max                  0.999979\n",
      "evaluation/Actions Min                 -0.999506\n",
      "time/backward_policy (s)                8.24425\n",
      "time/backward_zf1 (s)                  10.0917\n",
      "time/backward_zf2 (s)                   9.72134\n",
      "time/data sampling (s)                  1.3848\n",
      "time/data storing (s)                   0.0814069\n",
      "time/evaluation sampling (s)            3.69977\n",
      "time/exploration sampling (s)           1.6147\n",
      "time/logging (s)                        0.00995584\n",
      "time/preback_alpha (s)                  0.00544263\n",
      "time/preback_policy (s)                 9.54697\n",
      "time/preback_start (s)                  0.674899\n",
      "time/preback_zf (s)                    28.5623\n",
      "time/saving (s)                         4.064e-06\n",
      "time/training (s)                      10.5755\n",
      "time/epoch (s)                         84.2129\n",
      "time/total (s)                       1681.29\n",
      "Epoch                                  19\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:44:49.349964 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 20 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 115000\n",
      "trainer/ZF1 Loss                        3.80519\n",
      "trainer/ZF2 Loss                        3.2791\n",
      "trainer/ZF Expert Reward                0.907576\n",
      "trainer/ZF Policy Reward                1.39693\n",
      "trainer/ZF CHI2 Term                    3.48747\n",
      "trainer/Policy Loss                  -219.395\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               17.724\n",
      "trainer/Policy Param Norm              28.4019\n",
      "trainer/Zf1 Grad Norm                 127.731\n",
      "trainer/Zf1 Param Norm                 61.0539\n",
      "trainer/Zf2 Grad Norm                 104.537\n",
      "trainer/Zf2 Param Norm                 61.8811\n",
      "trainer/Z Expert Predictions Mean     277.787\n",
      "trainer/Z Expert Predictions Std        8.35185\n",
      "trainer/Z Expert Predictions Max      290.731\n",
      "trainer/Z Expert Predictions Min      224.609\n",
      "trainer/Z Policy Predictions Mean     218.254\n",
      "trainer/Z Policy Predictions Std       84.9338\n",
      "trainer/Z Policy Predictions Max      292.295\n",
      "trainer/Z Policy Predictions Min       -0.432442\n",
      "trainer/Z Expert Targets Mean         276.88\n",
      "trainer/Z Expert Targets Std            8.12407\n",
      "trainer/Z Expert Targets Max          286.86\n",
      "trainer/Z Expert Targets Min          224.873\n",
      "trainer/Z Policy Targets Mean         216.857\n",
      "trainer/Z Policy Targets Std           83.9048\n",
      "trainer/Z Policy Targets Max          288.649\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   18.0779\n",
      "trainer/Log Pis Std                     3.73291\n",
      "trainer/Policy mu Mean                 -0.0595539\n",
      "trainer/Policy mu Std                   0.935466\n",
      "trainer/Policy log std Mean            -3.06332\n",
      "trainer/Policy log std Std              0.61608\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        109295\n",
      "exploration/num paths total           243\n",
      "evaluation/num steps total         129032\n",
      "evaluation/num paths total            219\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.02736\n",
      "evaluation/Rewards Std                  0.812368\n",
      "evaluation/Rewards Max                  5.97547\n",
      "evaluation/Rewards Min                 -1.32549\n",
      "evaluation/Returns Mean              4027.36\n",
      "evaluation/Returns Std                 87.8527\n",
      "evaluation/Returns Max               4113.38\n",
      "evaluation/Returns Min               3796.8\n",
      "evaluation/Estimation Bias Mean       248.959\n",
      "evaluation/Estimation Bias Std        116.355\n",
      "evaluation/EB/Q_True Mean              37.7774\n",
      "evaluation/EB/Q_True Std              116.403\n",
      "evaluation/EB/Q_Pred Mean             286.736\n",
      "evaluation/EB/Q_Pred Std               10.5284\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4027.36\n",
      "evaluation/Actions Mean                -0.0511571\n",
      "evaluation/Actions Std                  0.497258\n",
      "evaluation/Actions Max                  0.997669\n",
      "evaluation/Actions Min                 -0.989943\n",
      "time/backward_policy (s)                8.11597\n",
      "time/backward_zf1 (s)                   9.88383\n",
      "time/backward_zf2 (s)                   9.58432\n",
      "time/data sampling (s)                  1.33462\n",
      "time/data storing (s)                   0.0819438\n",
      "time/evaluation sampling (s)            3.225\n",
      "time/exploration sampling (s)           1.60532\n",
      "time/logging (s)                        0.0133519\n",
      "time/preback_alpha (s)                  0.00539863\n",
      "time/preback_policy (s)                 9.60174\n",
      "time/preback_start (s)                  0.671003\n",
      "time/preback_zf (s)                    28.4608\n",
      "time/saving (s)                         4.29901e-06\n",
      "time/training (s)                      10.523\n",
      "time/epoch (s)                         83.1062\n",
      "time/total (s)                       1764.4\n",
      "Epoch                                  20\n",
      "---------------------------------  ----------------\n",
      "2024-10-19 00:46:13.249039 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 21 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 120000\n",
      "trainer/ZF1 Loss                        9.25248\n",
      "trainer/ZF2 Loss                        7.02667\n",
      "trainer/ZF Expert Reward                1.0795\n",
      "trainer/ZF Policy Reward                0.450965\n",
      "trainer/ZF CHI2 Term                    8.63987\n",
      "trainer/Policy Loss                  -219.917\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               17.5001\n",
      "trainer/Policy Param Norm              28.6574\n",
      "trainer/Zf1 Grad Norm                1007\n",
      "trainer/Zf1 Param Norm                 61.7823\n",
      "trainer/Zf2 Grad Norm                 644.475\n",
      "trainer/Zf2 Param Norm                 62.6222\n",
      "trainer/Z Expert Predictions Mean     282.895\n",
      "trainer/Z Expert Predictions Std       16.0446\n",
      "trainer/Z Expert Predictions Max      295.636\n",
      "trainer/Z Expert Predictions Min       44.9866\n",
      "trainer/Z Policy Predictions Mean     219.538\n",
      "trainer/Z Policy Predictions Std       86.6349\n",
      "trainer/Z Policy Predictions Max      302.885\n",
      "trainer/Z Policy Predictions Min        9.97846\n",
      "trainer/Z Expert Targets Mean         281.815\n",
      "trainer/Z Expert Targets Std           18.9077\n",
      "trainer/Z Expert Targets Max          295.034\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         219.087\n",
      "trainer/Z Policy Targets Std           85.5222\n",
      "trainer/Z Policy Targets Max          293.259\n",
      "trainer/Z Policy Targets Min           10.3283\n",
      "trainer/Log Pis Mean                   17.633\n",
      "trainer/Log Pis Std                     4.07327\n",
      "trainer/Policy mu Mean                 -0.0200107\n",
      "trainer/Policy mu Std                   0.900299\n",
      "trainer/Policy log std Mean            -3.02267\n",
      "trainer/Policy log std Std              0.625064\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        115295\n",
      "exploration/num paths total           249\n",
      "evaluation/num steps total         139032\n",
      "evaluation/num paths total            229\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.85009\n",
      "evaluation/Rewards Std                  0.807081\n",
      "evaluation/Rewards Max                  5.90477\n",
      "evaluation/Rewards Min                 -1.36016\n",
      "evaluation/Returns Mean              3850.09\n",
      "evaluation/Returns Std                 42.0059\n",
      "evaluation/Returns Max               3919.45\n",
      "evaluation/Returns Min               3786.56\n",
      "evaluation/Estimation Bias Mean       253.646\n",
      "evaluation/Estimation Bias Std        109.166\n",
      "evaluation/EB/Q_True Mean              35.2361\n",
      "evaluation/EB/Q_True Std              108.797\n",
      "evaluation/EB/Q_Pred Mean             288.882\n",
      "evaluation/EB/Q_Pred Std                9.30791\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3850.09\n",
      "evaluation/Actions Mean                -0.0408442\n",
      "evaluation/Actions Std                  0.475805\n",
      "evaluation/Actions Max                  0.986003\n",
      "evaluation/Actions Min                 -0.990353\n",
      "time/backward_policy (s)                7.95643\n",
      "time/backward_zf1 (s)                   9.77962\n",
      "time/backward_zf2 (s)                   9.42677\n",
      "time/data sampling (s)                  1.34215\n",
      "time/data storing (s)                   0.0818894\n",
      "time/evaluation sampling (s)            3.74974\n",
      "time/exploration sampling (s)           1.59997\n",
      "time/logging (s)                        0.0130656\n",
      "time/preback_alpha (s)                  0.00543789\n",
      "time/preback_policy (s)                 9.83493\n",
      "time/preback_start (s)                  0.674878\n",
      "time/preback_zf (s)                    28.4836\n",
      "time/saving (s)                         3.751e-06\n",
      "time/training (s)                      10.7486\n",
      "time/epoch (s)                         83.6971\n",
      "time/total (s)                       1848.1\n",
      "Epoch                                  21\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:47:36.792135 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 22 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 125000\n",
      "trainer/ZF1 Loss                        5.60296\n",
      "trainer/ZF2 Loss                        6.32387\n",
      "trainer/ZF Expert Reward                0.264269\n",
      "trainer/ZF Policy Reward                0.283083\n",
      "trainer/ZF CHI2 Term                    6.13779\n",
      "trainer/Policy Loss                  -224.558\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               15.752\n",
      "trainer/Policy Param Norm              28.8985\n",
      "trainer/Zf1 Grad Norm                 298.856\n",
      "trainer/Zf1 Param Norm                 62.5063\n",
      "trainer/Zf2 Grad Norm                 299.946\n",
      "trainer/Zf2 Param Norm                 63.3419\n",
      "trainer/Z Expert Predictions Mean     285.523\n",
      "trainer/Z Expert Predictions Std        7.22986\n",
      "trainer/Z Expert Predictions Max      297.432\n",
      "trainer/Z Expert Predictions Min      246.787\n",
      "trainer/Z Policy Predictions Mean     222.615\n",
      "trainer/Z Policy Predictions Std       89.5766\n",
      "trainer/Z Policy Predictions Max      298.407\n",
      "trainer/Z Policy Predictions Min      -10.3575\n",
      "trainer/Z Expert Targets Mean         285.258\n",
      "trainer/Z Expert Targets Std            7.1511\n",
      "trainer/Z Expert Targets Max          297.345\n",
      "trainer/Z Expert Targets Min          246.174\n",
      "trainer/Z Policy Targets Mean         222.332\n",
      "trainer/Z Policy Targets Std           88.1223\n",
      "trainer/Z Policy Targets Max          295.397\n",
      "trainer/Z Policy Targets Min          -12.517\n",
      "trainer/Log Pis Mean                   17.4789\n",
      "trainer/Log Pis Std                     3.43731\n",
      "trainer/Policy mu Mean                 -0.0219495\n",
      "trainer/Policy mu Std                   0.861704\n",
      "trainer/Policy log std Mean            -3.06743\n",
      "trainer/Policy log std Std              0.57892\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        120015\n",
      "exploration/num paths total           254\n",
      "evaluation/num steps total         147647\n",
      "evaluation/num paths total            239\n",
      "evaluation/path length Mean           861.5\n",
      "evaluation/path length Std            277.682\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            264\n",
      "evaluation/Rewards Mean                 3.99402\n",
      "evaluation/Rewards Std                  0.805197\n",
      "evaluation/Rewards Max                  5.98217\n",
      "evaluation/Rewards Min                 -1.90892\n",
      "evaluation/Returns Mean              3440.85\n",
      "evaluation/Returns Std               1154.88\n",
      "evaluation/Returns Max               4070.01\n",
      "evaluation/Returns Min                933.057\n",
      "evaluation/Estimation Bias Mean       251.544\n",
      "evaluation/Estimation Bias Std        121.687\n",
      "evaluation/EB/Q_True Mean              42.367\n",
      "evaluation/EB/Q_True Std              119.965\n",
      "evaluation/EB/Q_Pred Mean             293.911\n",
      "evaluation/EB/Q_Pred Std                9.67626\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3440.85\n",
      "evaluation/Actions Mean                -0.0711404\n",
      "evaluation/Actions Std                  0.519443\n",
      "evaluation/Actions Max                  0.986576\n",
      "evaluation/Actions Min                 -0.992313\n",
      "time/backward_policy (s)                8.17279\n",
      "time/backward_zf1 (s)                   9.90854\n",
      "time/backward_zf2 (s)                   9.63686\n",
      "time/data sampling (s)                  1.30746\n",
      "time/data storing (s)                   0.0811715\n",
      "time/evaluation sampling (s)            3.60836\n",
      "time/exploration sampling (s)           1.58991\n",
      "time/logging (s)                        0.0158167\n",
      "time/preback_alpha (s)                  0.00542521\n",
      "time/preback_policy (s)                 9.46248\n",
      "time/preback_start (s)                  0.670467\n",
      "time/preback_zf (s)                    28.4444\n",
      "time/saving (s)                         6.756e-06\n",
      "time/training (s)                      10.4417\n",
      "time/epoch (s)                         83.3454\n",
      "time/total (s)                       1931.45\n",
      "Epoch                                  22\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:49:00.956343 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 23 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 130000\n",
      "trainer/ZF1 Loss                        3.96808\n",
      "trainer/ZF2 Loss                        4.01734\n",
      "trainer/ZF Expert Reward                0.834473\n",
      "trainer/ZF Policy Reward                0.982954\n",
      "trainer/ZF CHI2 Term                    4.10848\n",
      "trainer/Policy Loss                  -232.643\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               16.3594\n",
      "trainer/Policy Param Norm              29.1894\n",
      "trainer/Zf1 Grad Norm                 136.567\n",
      "trainer/Zf1 Param Norm                 63.2165\n",
      "trainer/Zf2 Grad Norm                 121.95\n",
      "trainer/Zf2 Param Norm                 64.0545\n",
      "trainer/Z Expert Predictions Mean     290.526\n",
      "trainer/Z Expert Predictions Std        6.25242\n",
      "trainer/Z Expert Predictions Max      301.092\n",
      "trainer/Z Expert Predictions Min      249.607\n",
      "trainer/Z Policy Predictions Mean     230.783\n",
      "trainer/Z Policy Predictions Std       89.1686\n",
      "trainer/Z Policy Predictions Max      302.379\n",
      "trainer/Z Policy Predictions Min      -13.7992\n",
      "trainer/Z Expert Targets Mean         289.691\n",
      "trainer/Z Expert Targets Std            6.41803\n",
      "trainer/Z Expert Targets Max          299.753\n",
      "trainer/Z Expert Targets Min          247.988\n",
      "trainer/Z Policy Targets Mean         229.8\n",
      "trainer/Z Policy Targets Std           88.1753\n",
      "trainer/Z Policy Targets Max          299.53\n",
      "trainer/Z Policy Targets Min          -16.7949\n",
      "trainer/Log Pis Mean                   18.186\n",
      "trainer/Log Pis Std                     3.24123\n",
      "trainer/Policy mu Mean                 -0.0324222\n",
      "trainer/Policy mu Std                   0.912441\n",
      "trainer/Policy log std Mean            -3.08474\n",
      "trainer/Policy log std Std              0.569076\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        125015\n",
      "exploration/num paths total           259\n",
      "evaluation/num steps total         154862\n",
      "evaluation/num paths total            250\n",
      "evaluation/path length Mean           655.909\n",
      "evaluation/path length Std            398.58\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             19\n",
      "evaluation/Rewards Mean                 4.00942\n",
      "evaluation/Rewards Std                  0.832276\n",
      "evaluation/Rewards Max                  6.10828\n",
      "evaluation/Rewards Min                 -1.59421\n",
      "evaluation/Returns Mean              2629.81\n",
      "evaluation/Returns Std               1641.56\n",
      "evaluation/Returns Max               4154.17\n",
      "evaluation/Returns Min                 26.089\n",
      "evaluation/Estimation Bias Mean       245.594\n",
      "evaluation/Estimation Bias Std        131.923\n",
      "evaluation/EB/Q_True Mean              50.4852\n",
      "evaluation/EB/Q_True Std              129.323\n",
      "evaluation/EB/Q_Pred Mean             296.079\n",
      "evaluation/EB/Q_Pred Std               11.659\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2629.81\n",
      "evaluation/Actions Mean                -0.054695\n",
      "evaluation/Actions Std                  0.511776\n",
      "evaluation/Actions Max                  0.982637\n",
      "evaluation/Actions Min                 -0.990216\n",
      "time/backward_policy (s)                8.14177\n",
      "time/backward_zf1 (s)                   9.93111\n",
      "time/backward_zf2 (s)                   9.60452\n",
      "time/data sampling (s)                  1.3615\n",
      "time/data storing (s)                   0.0809821\n",
      "time/evaluation sampling (s)            3.67252\n",
      "time/exploration sampling (s)           1.60544\n",
      "time/logging (s)                        0.0134531\n",
      "time/preback_alpha (s)                  0.00544385\n",
      "time/preback_policy (s)                 9.62978\n",
      "time/preback_start (s)                  0.672988\n",
      "time/preback_zf (s)                    28.5841\n",
      "time/saving (s)                         5.919e-06\n",
      "time/training (s)                      10.6553\n",
      "time/epoch (s)                         83.9589\n",
      "time/total (s)                       2015.41\n",
      "Epoch                                  23\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:50:23.502243 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 24 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 135000\n",
      "trainer/ZF1 Loss                        7.31798\n",
      "trainer/ZF2 Loss                        5.72786\n",
      "trainer/ZF Expert Reward                1.1695\n",
      "trainer/ZF Policy Reward                1.54004\n",
      "trainer/ZF CHI2 Term                    6.52903\n",
      "trainer/Policy Loss                  -232.199\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               23.1317\n",
      "trainer/Policy Param Norm              29.4525\n",
      "trainer/Zf1 Grad Norm                 802.036\n",
      "trainer/Zf1 Param Norm                 63.8291\n",
      "trainer/Zf2 Grad Norm                 508.976\n",
      "trainer/Zf2 Param Norm                 64.6965\n",
      "trainer/Z Expert Predictions Mean     292.437\n",
      "trainer/Z Expert Predictions Std       20.2037\n",
      "trainer/Z Expert Predictions Max      305.398\n",
      "trainer/Z Expert Predictions Min        1.99203\n",
      "trainer/Z Policy Predictions Mean     231.072\n",
      "trainer/Z Policy Predictions Std       97.6303\n",
      "trainer/Z Policy Predictions Max      308.995\n",
      "trainer/Z Policy Predictions Min      -13.4395\n",
      "trainer/Z Expert Targets Mean         291.267\n",
      "trainer/Z Expert Targets Std           20.1641\n",
      "trainer/Z Expert Targets Max          303.453\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         229.532\n",
      "trainer/Z Policy Targets Std           96.0571\n",
      "trainer/Z Policy Targets Max          305.623\n",
      "trainer/Z Policy Targets Min          -15.6971\n",
      "trainer/Log Pis Mean                   18.2138\n",
      "trainer/Log Pis Std                     3.5226\n",
      "trainer/Policy mu Mean                 -0.0103824\n",
      "trainer/Policy mu Std                   0.93852\n",
      "trainer/Policy log std Mean            -3.072\n",
      "trainer/Policy log std Std              0.672142\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        130803\n",
      "exploration/num paths total           267\n",
      "evaluation/num steps total         157321\n",
      "evaluation/num paths total            260\n",
      "evaluation/path length Mean           245.9\n",
      "evaluation/path length Std            209.651\n",
      "evaluation/path length Max            530\n",
      "evaluation/path length Min             10\n",
      "evaluation/Rewards Mean                 3.73958\n",
      "evaluation/Rewards Std                  1.20905\n",
      "evaluation/Rewards Max                  6.18252\n",
      "evaluation/Rewards Min                 -1.76929\n",
      "evaluation/Returns Mean               919.564\n",
      "evaluation/Returns Std                846.471\n",
      "evaluation/Returns Max               2139.24\n",
      "evaluation/Returns Min                  3.82362\n",
      "evaluation/Estimation Bias Mean       233.118\n",
      "evaluation/Estimation Bias Std        128.522\n",
      "evaluation/EB/Q_True Mean              58.7221\n",
      "evaluation/EB/Q_True Std              124.422\n",
      "evaluation/EB/Q_Pred Mean             291.84\n",
      "evaluation/EB/Q_Pred Std               22.3132\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            919.564\n",
      "evaluation/Actions Mean                -0.0571874\n",
      "evaluation/Actions Std                  0.519699\n",
      "evaluation/Actions Max                  0.983638\n",
      "evaluation/Actions Min                 -0.987103\n",
      "time/backward_policy (s)                8.20099\n",
      "time/backward_zf1 (s)                   9.97411\n",
      "time/backward_zf2 (s)                   9.6639\n",
      "time/data sampling (s)                  1.36598\n",
      "time/data storing (s)                   0.0812287\n",
      "time/evaluation sampling (s)            2.31478\n",
      "time/exploration sampling (s)           1.61339\n",
      "time/logging (s)                        0.00341162\n",
      "time/preback_alpha (s)                  0.00543569\n",
      "time/preback_policy (s)                 9.52672\n",
      "time/preback_start (s)                  0.669189\n",
      "time/preback_zf (s)                    28.4603\n",
      "time/saving (s)                         3.343e-06\n",
      "time/training (s)                      10.4556\n",
      "time/epoch (s)                         82.3351\n",
      "time/total (s)                       2097.75\n",
      "Epoch                                  24\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:51:45.165114 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 25 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 140000\n",
      "trainer/ZF1 Loss                        4.99231\n",
      "trainer/ZF2 Loss                        5.29925\n",
      "trainer/ZF Expert Reward                0.50404\n",
      "trainer/ZF Policy Reward                0.706477\n",
      "trainer/ZF CHI2 Term                    5.23498\n",
      "trainer/Policy Loss                  -238.316\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               18.4572\n",
      "trainer/Policy Param Norm              29.656\n",
      "trainer/Zf1 Grad Norm                 317.849\n",
      "trainer/Zf1 Param Norm                 64.4514\n",
      "trainer/Zf2 Grad Norm                 406.625\n",
      "trainer/Zf2 Param Norm                 65.3156\n",
      "trainer/Z Expert Predictions Mean     294.934\n",
      "trainer/Z Expert Predictions Std        9.22733\n",
      "trainer/Z Expert Predictions Max      307.823\n",
      "trainer/Z Expert Predictions Min      247.969\n",
      "trainer/Z Policy Predictions Mean     235.997\n",
      "trainer/Z Policy Predictions Std       89.5152\n",
      "trainer/Z Policy Predictions Max      307.623\n",
      "trainer/Z Policy Predictions Min      -13.2464\n",
      "trainer/Z Expert Targets Mean         294.43\n",
      "trainer/Z Expert Targets Std            9.37137\n",
      "trainer/Z Expert Targets Max          307.762\n",
      "trainer/Z Expert Targets Min          247.03\n",
      "trainer/Z Policy Targets Mean         235.291\n",
      "trainer/Z Policy Targets Std           88.6727\n",
      "trainer/Z Policy Targets Max          305.114\n",
      "trainer/Z Policy Targets Min          -14.3352\n",
      "trainer/Log Pis Mean                   17.9962\n",
      "trainer/Log Pis Std                     3.6001\n",
      "trainer/Policy mu Mean                  0.000641387\n",
      "trainer/Policy mu Std                   0.889555\n",
      "trainer/Policy log std Mean            -3.1085\n",
      "trainer/Policy log std Std              0.573872\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        134483\n",
      "exploration/num paths total           271\n",
      "evaluation/num steps total         158249\n",
      "evaluation/num paths total            270\n",
      "evaluation/path length Mean            92.8\n",
      "evaluation/path length Std             60.4745\n",
      "evaluation/path length Max            196\n",
      "evaluation/path length Min             11\n",
      "evaluation/Rewards Mean                 3.21787\n",
      "evaluation/Rewards Std                  1.44548\n",
      "evaluation/Rewards Max                  5.88757\n",
      "evaluation/Rewards Min                 -2.07057\n",
      "evaluation/Returns Mean               298.618\n",
      "evaluation/Returns Std                239.707\n",
      "evaluation/Returns Max                736.149\n",
      "evaluation/Returns Min                 11.6928\n",
      "evaluation/Estimation Bias Mean       253.509\n",
      "evaluation/Estimation Bias Std         75.3953\n",
      "evaluation/EB/Q_True Mean              28.053\n",
      "evaluation/EB/Q_True Std               62.1387\n",
      "evaluation/EB/Q_Pred Mean             281.562\n",
      "evaluation/EB/Q_Pred Std               31.0506\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            298.618\n",
      "evaluation/Actions Mean                -0.0544245\n",
      "evaluation/Actions Std                  0.511731\n",
      "evaluation/Actions Max                  0.993956\n",
      "evaluation/Actions Min                 -0.985031\n",
      "time/backward_policy (s)                8.30857\n",
      "time/backward_zf1 (s)                  10.0995\n",
      "time/backward_zf2 (s)                   9.79356\n",
      "time/data sampling (s)                  1.32335\n",
      "time/data storing (s)                   0.0809322\n",
      "time/evaluation sampling (s)            1.33399\n",
      "time/exploration sampling (s)           1.59829\n",
      "time/logging (s)                        0.00458579\n",
      "time/preback_alpha (s)                  0.00540926\n",
      "time/preback_policy (s)                 9.32914\n",
      "time/preback_start (s)                  0.670432\n",
      "time/preback_zf (s)                    28.4916\n",
      "time/saving (s)                         7.481e-06\n",
      "time/training (s)                      10.4227\n",
      "time/epoch (s)                         81.4621\n",
      "time/total (s)                       2179.21\n",
      "Epoch                                  25\n",
      "---------------------------------  ----------------\n",
      "2024-10-19 00:53:08.298219 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 26 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 145000\n",
      "trainer/ZF1 Loss                        3.42872\n",
      "trainer/ZF2 Loss                        3.86136\n",
      "trainer/ZF Expert Reward                0.721873\n",
      "trainer/ZF Policy Reward                1.13599\n",
      "trainer/ZF CHI2 Term                    3.62888\n",
      "trainer/Policy Loss                  -247.038\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               14.9246\n",
      "trainer/Policy Param Norm              29.8707\n",
      "trainer/Zf1 Grad Norm                 123.954\n",
      "trainer/Zf1 Param Norm                 65.0956\n",
      "trainer/Zf2 Grad Norm                 116.609\n",
      "trainer/Zf2 Param Norm                 65.9759\n",
      "trainer/Z Expert Predictions Mean     297.787\n",
      "trainer/Z Expert Predictions Std        8.38953\n",
      "trainer/Z Expert Predictions Max      309.201\n",
      "trainer/Z Expert Predictions Min      254.103\n",
      "trainer/Z Policy Predictions Mean     246.336\n",
      "trainer/Z Policy Predictions Std       88.1053\n",
      "trainer/Z Policy Predictions Max      312.579\n",
      "trainer/Z Policy Predictions Min      -19.2955\n",
      "trainer/Z Expert Targets Mean         297.065\n",
      "trainer/Z Expert Targets Std            8.45844\n",
      "trainer/Z Expert Targets Max          308.549\n",
      "trainer/Z Expert Targets Min          252.133\n",
      "trainer/Z Policy Targets Mean         245.2\n",
      "trainer/Z Policy Targets Std           87.0193\n",
      "trainer/Z Policy Targets Max          313.068\n",
      "trainer/Z Policy Targets Min          -24.7583\n",
      "trainer/Log Pis Mean                   18.1061\n",
      "trainer/Log Pis Std                     3.13001\n",
      "trainer/Policy mu Mean                 -0.0496872\n",
      "trainer/Policy mu Std                   0.84311\n",
      "trainer/Policy log std Mean            -3.13263\n",
      "trainer/Policy log std Std              0.591226\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        141002\n",
      "exploration/num paths total           280\n",
      "evaluation/num steps total         166024\n",
      "evaluation/num paths total            282\n",
      "evaluation/path length Mean           647.917\n",
      "evaluation/path length Std            381.229\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 4.08946\n",
      "evaluation/Rewards Std                  0.931055\n",
      "evaluation/Rewards Max                  6.16058\n",
      "evaluation/Rewards Min                 -1.66406\n",
      "evaluation/Returns Mean              2649.63\n",
      "evaluation/Returns Std               1621.69\n",
      "evaluation/Returns Max               4287.8\n",
      "evaluation/Returns Min                  9.708\n",
      "evaluation/Estimation Bias Mean       251.96\n",
      "evaluation/Estimation Bias Std        135.119\n",
      "evaluation/EB/Q_True Mean              49.3704\n",
      "evaluation/EB/Q_True Std              131.965\n",
      "evaluation/EB/Q_Pred Mean             301.331\n",
      "evaluation/EB/Q_Pred Std               15.108\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2649.63\n",
      "evaluation/Actions Mean                -0.0543555\n",
      "evaluation/Actions Std                  0.512434\n",
      "evaluation/Actions Max                  0.987907\n",
      "evaluation/Actions Min                 -0.988993\n",
      "time/backward_policy (s)                8.02607\n",
      "time/backward_zf1 (s)                   9.76983\n",
      "time/backward_zf2 (s)                   9.45566\n",
      "time/data sampling (s)                  1.32504\n",
      "time/data storing (s)                   0.0803194\n",
      "time/evaluation sampling (s)            3.55855\n",
      "time/exploration sampling (s)           1.58733\n",
      "time/logging (s)                        0.0155784\n",
      "time/preback_alpha (s)                  0.00535625\n",
      "time/preback_policy (s)                 9.59394\n",
      "time/preback_start (s)                  0.663693\n",
      "time/preback_zf (s)                    28.3809\n",
      "time/saving (s)                         3.671e-06\n",
      "time/training (s)                      10.4807\n",
      "time/epoch (s)                         82.9429\n",
      "time/total (s)                       2262.16\n",
      "Epoch                                  26\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:54:32.986353 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 27 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 150000\n",
      "trainer/ZF1 Loss                        5.26393\n",
      "trainer/ZF2 Loss                        4.67602\n",
      "trainer/ZF Expert Reward                1.11818\n",
      "trainer/ZF Policy Reward                1.55346\n",
      "trainer/ZF CHI2 Term                    4.94157\n",
      "trainer/Policy Loss                  -245.354\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               20.1328\n",
      "trainer/Policy Param Norm              30.0198\n",
      "trainer/Zf1 Grad Norm                 251.535\n",
      "trainer/Zf1 Param Norm                 65.7529\n",
      "trainer/Zf2 Grad Norm                 216.274\n",
      "trainer/Zf2 Param Norm                 66.5728\n",
      "trainer/Z Expert Predictions Mean     300.489\n",
      "trainer/Z Expert Predictions Std        8.80971\n",
      "trainer/Z Expert Predictions Max      313.839\n",
      "trainer/Z Expert Predictions Min      248.032\n",
      "trainer/Z Policy Predictions Mean     243.902\n",
      "trainer/Z Policy Predictions Std       95.6292\n",
      "trainer/Z Policy Predictions Max      316.678\n",
      "trainer/Z Policy Predictions Min      -24.5982\n",
      "trainer/Z Expert Targets Mean         299.37\n",
      "trainer/Z Expert Targets Std            8.73936\n",
      "trainer/Z Expert Targets Max          312.532\n",
      "trainer/Z Expert Targets Min          249.446\n",
      "trainer/Z Policy Targets Mean         242.348\n",
      "trainer/Z Policy Targets Std           94.6614\n",
      "trainer/Z Policy Targets Max          311.488\n",
      "trainer/Z Policy Targets Min          -20.5622\n",
      "trainer/Log Pis Mean                   18.3541\n",
      "trainer/Log Pis Std                     3.60902\n",
      "trainer/Policy mu Mean                 -0.0115843\n",
      "trainer/Policy mu Std                   0.832331\n",
      "trainer/Policy log std Mean            -3.1767\n",
      "trainer/Policy log std Std              0.579568\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        142733\n",
      "exploration/num paths total           283\n",
      "evaluation/num steps total         174132\n",
      "evaluation/num paths total            295\n",
      "evaluation/path length Mean           623.692\n",
      "evaluation/path length Std            373.394\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             59\n",
      "evaluation/Rewards Mean                 4.06656\n",
      "evaluation/Rewards Std                  0.898605\n",
      "evaluation/Rewards Max                  6.06844\n",
      "evaluation/Rewards Min                 -2.08235\n",
      "evaluation/Returns Mean              2536.29\n",
      "evaluation/Returns Std               1571.3\n",
      "evaluation/Returns Max               4275.9\n",
      "evaluation/Returns Min                172.639\n",
      "evaluation/Estimation Bias Mean       256.166\n",
      "evaluation/Estimation Bias Std        132.553\n",
      "evaluation/EB/Q_True Mean              48.0022\n",
      "evaluation/EB/Q_True Std              131.228\n",
      "evaluation/EB/Q_Pred Mean             304.168\n",
      "evaluation/EB/Q_Pred Std               14.3022\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2536.29\n",
      "evaluation/Actions Mean                -0.0521061\n",
      "evaluation/Actions Std                  0.503405\n",
      "evaluation/Actions Max                  0.991301\n",
      "evaluation/Actions Min                 -0.986872\n",
      "time/backward_policy (s)                8.46265\n",
      "time/backward_zf1 (s)                  10.2706\n",
      "time/backward_zf2 (s)                   9.95193\n",
      "time/data sampling (s)                  1.3687\n",
      "time/data storing (s)                   0.0844834\n",
      "time/evaluation sampling (s)            3.50312\n",
      "time/exploration sampling (s)           1.65788\n",
      "time/logging (s)                        0.0180495\n",
      "time/preback_alpha (s)                  0.00547033\n",
      "time/preback_policy (s)                 9.35165\n",
      "time/preback_start (s)                  0.680292\n",
      "time/preback_zf (s)                    28.6238\n",
      "time/saving (s)                         4.90699e-06\n",
      "time/training (s)                      10.5071\n",
      "time/epoch (s)                         84.4857\n",
      "time/total (s)                       2346.64\n",
      "Epoch                                  27\n",
      "---------------------------------  ----------------\n",
      "2024-10-19 00:55:58.056731 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 28 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 155000\n",
      "trainer/ZF1 Loss                       39.45\n",
      "trainer/ZF2 Loss                        7.09792\n",
      "trainer/ZF Expert Reward                1.06813\n",
      "trainer/ZF Policy Reward                1.97946\n",
      "trainer/ZF CHI2 Term                   23.0036\n",
      "trainer/Policy Loss                  -240.677\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               23.3713\n",
      "trainer/Policy Param Norm              30.2185\n",
      "trainer/Zf1 Grad Norm                3273.22\n",
      "trainer/Zf1 Param Norm                 66.4278\n",
      "trainer/Zf2 Grad Norm                 939.807\n",
      "trainer/Zf2 Param Norm                 67.2178\n",
      "trainer/Z Expert Predictions Mean     302.323\n",
      "trainer/Z Expert Predictions Std        7.23772\n",
      "trainer/Z Expert Predictions Max      312.96\n",
      "trainer/Z Expert Predictions Min      265.615\n",
      "trainer/Z Policy Predictions Mean     240.343\n",
      "trainer/Z Policy Predictions Std      101.513\n",
      "trainer/Z Policy Predictions Max      314.563\n",
      "trainer/Z Policy Predictions Min      -28.1906\n",
      "trainer/Z Expert Targets Mean         301.255\n",
      "trainer/Z Expert Targets Std            7.09024\n",
      "trainer/Z Expert Targets Max          313.068\n",
      "trainer/Z Expert Targets Min          265.91\n",
      "trainer/Z Policy Targets Mean         238.363\n",
      "trainer/Z Policy Targets Std          100.763\n",
      "trainer/Z Policy Targets Max          311.707\n",
      "trainer/Z Policy Targets Min          -22.8356\n",
      "trainer/Log Pis Mean                   17.6257\n",
      "trainer/Log Pis Std                     3.64897\n",
      "trainer/Policy mu Mean                 -0.0289184\n",
      "trainer/Policy mu Std                   0.780325\n",
      "trainer/Policy log std Mean            -3.14451\n",
      "trainer/Policy log std Std              0.519953\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        150001\n",
      "exploration/num paths total           291\n",
      "evaluation/num steps total         178795\n",
      "evaluation/num paths total            305\n",
      "evaluation/path length Mean           466.3\n",
      "evaluation/path length Std            295.377\n",
      "evaluation/path length Max            925\n",
      "evaluation/path length Min             67\n",
      "evaluation/Rewards Mean                 3.85094\n",
      "evaluation/Rewards Std                  1.11454\n",
      "evaluation/Rewards Max                  6.22325\n",
      "evaluation/Rewards Min                 -1.80572\n",
      "evaluation/Returns Mean              1795.7\n",
      "evaluation/Returns Std               1207.08\n",
      "evaluation/Returns Max               3680.85\n",
      "evaluation/Returns Min                 98.3144\n",
      "evaluation/Estimation Bias Mean       226.478\n",
      "evaluation/Estimation Bias Std        153.107\n",
      "evaluation/EB/Q_True Mean              70.9181\n",
      "evaluation/EB/Q_True Std              147.436\n",
      "evaluation/EB/Q_Pred Mean             297.396\n",
      "evaluation/EB/Q_Pred Std               21.8251\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1795.7\n",
      "evaluation/Actions Mean                -0.0593294\n",
      "evaluation/Actions Std                  0.519544\n",
      "evaluation/Actions Max                  0.999347\n",
      "evaluation/Actions Min                 -0.993144\n",
      "time/backward_policy (s)                8.72785\n",
      "time/backward_zf1 (s)                  10.6043\n",
      "time/backward_zf2 (s)                  10.2962\n",
      "time/data sampling (s)                  1.40566\n",
      "time/data storing (s)                   0.0823119\n",
      "time/evaluation sampling (s)            3.50889\n",
      "time/exploration sampling (s)           1.63758\n",
      "time/logging (s)                        0.00818683\n",
      "time/preback_alpha (s)                  0.00544259\n",
      "time/preback_policy (s)                 8.9813\n",
      "time/preback_start (s)                  0.673892\n",
      "time/preback_zf (s)                    28.6114\n",
      "time/saving (s)                         4.988e-06\n",
      "time/training (s)                      10.3141\n",
      "time/epoch (s)                         84.8572\n",
      "time/total (s)                       2431.5\n",
      "Epoch                                  28\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 00:57:21.725454 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 29 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 160000\n",
      "trainer/ZF1 Loss                        4.96621\n",
      "trainer/ZF2 Loss                        3.87345\n",
      "trainer/ZF Expert Reward                0.859566\n",
      "trainer/ZF Policy Reward                1.2334\n",
      "trainer/ZF CHI2 Term                    4.41948\n",
      "trainer/Policy Loss                  -250.508\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               21.4662\n",
      "trainer/Policy Param Norm              30.3995\n",
      "trainer/Zf1 Grad Norm                 329.999\n",
      "trainer/Zf1 Param Norm                 67.0468\n",
      "trainer/Zf2 Grad Norm                 164.206\n",
      "trainer/Zf2 Param Norm                 67.8222\n",
      "trainer/Z Expert Predictions Mean     303.255\n",
      "trainer/Z Expert Predictions Std        9.13766\n",
      "trainer/Z Expert Predictions Max      314.776\n",
      "trainer/Z Expert Predictions Min      249.44\n",
      "trainer/Z Policy Predictions Mean     249.696\n",
      "trainer/Z Policy Predictions Std       96.224\n",
      "trainer/Z Policy Predictions Max      316.394\n",
      "trainer/Z Policy Predictions Min      -28.9283\n",
      "trainer/Z Expert Targets Mean         302.395\n",
      "trainer/Z Expert Targets Std            9.07208\n",
      "trainer/Z Expert Targets Max          314.411\n",
      "trainer/Z Expert Targets Min          247.925\n",
      "trainer/Z Policy Targets Mean         248.462\n",
      "trainer/Z Policy Targets Std           94.6851\n",
      "trainer/Z Policy Targets Max          312.302\n",
      "trainer/Z Policy Targets Min          -30.5315\n",
      "trainer/Log Pis Mean                   17.4218\n",
      "trainer/Log Pis Std                     3.53975\n",
      "trainer/Policy mu Mean                 -0.0337338\n",
      "trainer/Policy mu Std                   0.723874\n",
      "trainer/Policy log std Mean            -3.19415\n",
      "trainer/Policy log std Std              0.532491\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        152847\n",
      "exploration/num paths total           295\n",
      "evaluation/num steps total         188386\n",
      "evaluation/num paths total            315\n",
      "evaluation/path length Mean           959.1\n",
      "evaluation/path length Std            122.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            591\n",
      "evaluation/Rewards Mean                 3.85512\n",
      "evaluation/Rewards Std                  1.05692\n",
      "evaluation/Rewards Max                  6.36285\n",
      "evaluation/Rewards Min                 -1.92625\n",
      "evaluation/Returns Mean              3697.45\n",
      "evaluation/Returns Std                544.249\n",
      "evaluation/Returns Max               4119.49\n",
      "evaluation/Returns Min               2115.54\n",
      "evaluation/Estimation Bias Mean       262.607\n",
      "evaluation/Estimation Bias Std        111.053\n",
      "evaluation/EB/Q_True Mean              36.2495\n",
      "evaluation/EB/Q_True Std              109.576\n",
      "evaluation/EB/Q_Pred Mean             298.856\n",
      "evaluation/EB/Q_Pred Std               15.2654\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3697.45\n",
      "evaluation/Actions Mean                -0.055002\n",
      "evaluation/Actions Std                  0.5114\n",
      "evaluation/Actions Max                  0.99679\n",
      "evaluation/Actions Min                 -0.991383\n",
      "time/backward_policy (s)                7.94912\n",
      "time/backward_zf1 (s)                   9.74026\n",
      "time/backward_zf2 (s)                   9.41489\n",
      "time/data sampling (s)                  1.33194\n",
      "time/data storing (s)                   0.0811489\n",
      "time/evaluation sampling (s)            3.70627\n",
      "time/exploration sampling (s)           1.59481\n",
      "time/logging (s)                        0.0182625\n",
      "time/preback_alpha (s)                  0.00543347\n",
      "time/preback_policy (s)                 9.78954\n",
      "time/preback_start (s)                  0.663443\n",
      "time/preback_zf (s)                    28.454\n",
      "time/saving (s)                         6.32901e-06\n",
      "time/training (s)                      10.7279\n",
      "time/epoch (s)                         83.477\n",
      "time/total (s)                       2514.98\n",
      "Epoch                                  29\n",
      "---------------------------------  ----------------\n",
      "2024-10-19 00:58:47.234120 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 30 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 165000\n",
      "trainer/ZF1 Loss                        4.9491\n",
      "trainer/ZF2 Loss                        6.16477\n",
      "trainer/ZF Expert Reward                0.748409\n",
      "trainer/ZF Policy Reward                1.19147\n",
      "trainer/ZF CHI2 Term                    5.52376\n",
      "trainer/Policy Loss                  -254.927\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               17.9617\n",
      "trainer/Policy Param Norm              30.5634\n",
      "trainer/Zf1 Grad Norm                 293.742\n",
      "trainer/Zf1 Param Norm                 67.6618\n",
      "trainer/Zf2 Grad Norm                 523.945\n",
      "trainer/Zf2 Param Norm                 68.4286\n",
      "trainer/Z Expert Predictions Mean     303.986\n",
      "trainer/Z Expert Predictions Std        7.07109\n",
      "trainer/Z Expert Predictions Max      316.686\n",
      "trainer/Z Expert Predictions Min      253.868\n",
      "trainer/Z Policy Predictions Mean     253.884\n",
      "trainer/Z Policy Predictions Std       93.4096\n",
      "trainer/Z Policy Predictions Max      315.812\n",
      "trainer/Z Policy Predictions Min      -27.2932\n",
      "trainer/Z Expert Targets Mean         303.237\n",
      "trainer/Z Expert Targets Std            7.20785\n",
      "trainer/Z Expert Targets Max          317.602\n",
      "trainer/Z Expert Targets Min          252.968\n",
      "trainer/Z Policy Targets Mean         252.692\n",
      "trainer/Z Policy Targets Std           92.5148\n",
      "trainer/Z Policy Targets Max          312.743\n",
      "trainer/Z Policy Targets Min          -22.58\n",
      "trainer/Log Pis Mean                   17.8853\n",
      "trainer/Log Pis Std                     3.39144\n",
      "trainer/Policy mu Mean                 -0.0661624\n",
      "trainer/Policy mu Std                   0.733605\n",
      "trainer/Policy log std Mean            -3.22684\n",
      "trainer/Policy log std Std              0.504719\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        159847\n",
      "exploration/num paths total           302\n",
      "evaluation/num steps total         196132\n",
      "evaluation/num paths total            326\n",
      "evaluation/path length Mean           704.182\n",
      "evaluation/path length Std            415.172\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             10\n",
      "evaluation/Rewards Mean                 3.98331\n",
      "evaluation/Rewards Std                  0.92359\n",
      "evaluation/Rewards Max                  6.13901\n",
      "evaluation/Rewards Min                 -1.935\n",
      "evaluation/Returns Mean              2804.97\n",
      "evaluation/Returns Std               1704.19\n",
      "evaluation/Returns Max               4135.02\n",
      "evaluation/Returns Min                 13.6264\n",
      "evaluation/Estimation Bias Mean       256.521\n",
      "evaluation/Estimation Bias Std        132.313\n",
      "evaluation/EB/Q_True Mean              48.1031\n",
      "evaluation/EB/Q_True Std              128.215\n",
      "evaluation/EB/Q_Pred Mean             304.624\n",
      "evaluation/EB/Q_Pred Std               14.8446\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2804.97\n",
      "evaluation/Actions Mean                -0.0693441\n",
      "evaluation/Actions Std                  0.516818\n",
      "evaluation/Actions Max                  0.992056\n",
      "evaluation/Actions Min                 -0.998867\n",
      "time/backward_policy (s)                8.55577\n",
      "time/backward_zf1 (s)                  10.448\n",
      "time/backward_zf2 (s)                  10.0645\n",
      "time/data sampling (s)                  1.41498\n",
      "time/data storing (s)                   0.0820837\n",
      "time/evaluation sampling (s)            3.74915\n",
      "time/exploration sampling (s)           1.61243\n",
      "time/logging (s)                        0.0103763\n",
      "time/preback_alpha (s)                  0.00555641\n",
      "time/preback_policy (s)                 9.3507\n",
      "time/preback_start (s)                  0.683679\n",
      "time/preback_zf (s)                    28.7392\n",
      "time/saving (s)                         4.732e-06\n",
      "time/training (s)                      10.579\n",
      "time/epoch (s)                         85.2954\n",
      "time/total (s)                       2600.28\n",
      "Epoch                                  30\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:00:10.660457 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 31 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 170000\n",
      "trainer/ZF1 Loss                        4.02242\n",
      "trainer/ZF2 Loss                        3.66598\n",
      "trainer/ZF Expert Reward                1.32106\n",
      "trainer/ZF Policy Reward                1.68618\n",
      "trainer/ZF CHI2 Term                    3.84864\n",
      "trainer/Policy Loss                  -248.592\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               13.1018\n",
      "trainer/Policy Param Norm              30.7416\n",
      "trainer/Zf1 Grad Norm                 140.021\n",
      "trainer/Zf1 Param Norm                 68.2485\n",
      "trainer/Zf2 Grad Norm                 144.244\n",
      "trainer/Zf2 Param Norm                 69.0097\n",
      "trainer/Z Expert Predictions Mean     305.638\n",
      "trainer/Z Expert Predictions Std        7.20795\n",
      "trainer/Z Expert Predictions Max      316.556\n",
      "trainer/Z Expert Predictions Min      259.965\n",
      "trainer/Z Policy Predictions Mean     247.648\n",
      "trainer/Z Policy Predictions Std      101.226\n",
      "trainer/Z Policy Predictions Max      318.433\n",
      "trainer/Z Policy Predictions Min      -33.6949\n",
      "trainer/Z Expert Targets Mean         304.317\n",
      "trainer/Z Expert Targets Std            7.32805\n",
      "trainer/Z Expert Targets Max          314.751\n",
      "trainer/Z Expert Targets Min          260.596\n",
      "trainer/Z Policy Targets Mean         245.962\n",
      "trainer/Z Policy Targets Std           99.8498\n",
      "trainer/Z Policy Targets Max          317.059\n",
      "trainer/Z Policy Targets Min          -32.7972\n",
      "trainer/Log Pis Mean                   17.7692\n",
      "trainer/Log Pis Std                     3.14965\n",
      "trainer/Policy mu Mean                 -0.0381615\n",
      "trainer/Policy mu Std                   0.685788\n",
      "trainer/Policy log std Mean            -3.22719\n",
      "trainer/Policy log std Std              0.483322\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        164531\n",
      "exploration/num paths total           307\n",
      "evaluation/num steps total         204934\n",
      "evaluation/num paths total            338\n",
      "evaluation/path length Mean           733.5\n",
      "evaluation/path length Std            372.913\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 4.14643\n",
      "evaluation/Rewards Std                  0.824768\n",
      "evaluation/Rewards Max                  6.15121\n",
      "evaluation/Rewards Min                 -1.61988\n",
      "evaluation/Returns Mean              3041.41\n",
      "evaluation/Returns Std               1573.78\n",
      "evaluation/Returns Max               4252.75\n",
      "evaluation/Returns Min                 16.3227\n",
      "evaluation/Estimation Bias Mean       264.259\n",
      "evaluation/Estimation Bias Std        123.834\n",
      "evaluation/EB/Q_True Mean              42.7781\n",
      "evaluation/EB/Q_True Std              122.727\n",
      "evaluation/EB/Q_Pred Mean             307.037\n",
      "evaluation/EB/Q_Pred Std               11.4191\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3041.41\n",
      "evaluation/Actions Mean                -0.0639531\n",
      "evaluation/Actions Std                  0.518241\n",
      "evaluation/Actions Max                  0.994261\n",
      "evaluation/Actions Min                 -0.992742\n",
      "time/backward_policy (s)                8.124\n",
      "time/backward_zf1 (s)                   9.92514\n",
      "time/backward_zf2 (s)                   9.61147\n",
      "time/data sampling (s)                  1.37109\n",
      "time/data storing (s)                   0.0811636\n",
      "time/evaluation sampling (s)            3.23566\n",
      "time/exploration sampling (s)           1.59688\n",
      "time/logging (s)                        0.0212717\n",
      "time/preback_alpha (s)                  0.00539567\n",
      "time/preback_policy (s)                 9.55439\n",
      "time/preback_start (s)                  0.669507\n",
      "time/preback_zf (s)                    28.4598\n",
      "time/saving (s)                         6.357e-06\n",
      "time/training (s)                      10.5818\n",
      "time/epoch (s)                         83.2376\n",
      "time/total (s)                       2683.52\n",
      "Epoch                                  31\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:01:34.211867 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 32 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 175000\n",
      "trainer/ZF1 Loss                       94.0266\n",
      "trainer/ZF2 Loss                       94.3061\n",
      "trainer/ZF Expert Reward                0.872404\n",
      "trainer/ZF Policy Reward                2.78972\n",
      "trainer/ZF CHI2 Term                   93.389\n",
      "trainer/Policy Loss                  -243.423\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               12.339\n",
      "trainer/Policy Param Norm              30.9036\n",
      "trainer/Zf1 Grad Norm                 158.713\n",
      "trainer/Zf1 Param Norm                 68.7992\n",
      "trainer/Zf2 Grad Norm                 139.564\n",
      "trainer/Zf2 Param Norm                 69.5969\n",
      "trainer/Z Expert Predictions Mean     305.537\n",
      "trainer/Z Expert Predictions Std        5.24981\n",
      "trainer/Z Expert Predictions Max      315.806\n",
      "trainer/Z Expert Predictions Min      275.929\n",
      "trainer/Z Policy Predictions Mean     242.753\n",
      "trainer/Z Policy Predictions Std      110.082\n",
      "trainer/Z Policy Predictions Max      315.579\n",
      "trainer/Z Policy Predictions Min      -37.6574\n",
      "trainer/Z Expert Targets Mean         304.664\n",
      "trainer/Z Expert Targets Std            5.44691\n",
      "trainer/Z Expert Targets Max          316.472\n",
      "trainer/Z Expert Targets Min          273.944\n",
      "trainer/Z Policy Targets Mean         239.963\n",
      "trainer/Z Policy Targets Std          109.837\n",
      "trainer/Z Policy Targets Max          315.333\n",
      "trainer/Z Policy Targets Min          -40.808\n",
      "trainer/Log Pis Mean                   17.6401\n",
      "trainer/Log Pis Std                     3.56047\n",
      "trainer/Policy mu Mean                 -0.0278908\n",
      "trainer/Policy mu Std                   0.751184\n",
      "trainer/Policy log std Mean            -3.17016\n",
      "trainer/Policy log std Std              0.528982\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        169553\n",
      "exploration/num paths total           313\n",
      "evaluation/num steps total         214913\n",
      "evaluation/num paths total            348\n",
      "evaluation/path length Mean           997.9\n",
      "evaluation/path length Std              6.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            979\n",
      "evaluation/Rewards Mean                 3.98453\n",
      "evaluation/Rewards Std                  0.729423\n",
      "evaluation/Rewards Max                  5.75005\n",
      "evaluation/Rewards Min                 -1.94022\n",
      "evaluation/Returns Mean              3976.17\n",
      "evaluation/Returns Std                 46.0384\n",
      "evaluation/Returns Max               4092.15\n",
      "evaluation/Returns Min               3928.22\n",
      "evaluation/Estimation Bias Mean       269.665\n",
      "evaluation/Estimation Bias Std        114.179\n",
      "evaluation/EB/Q_True Mean              36.8141\n",
      "evaluation/EB/Q_True Std              113.446\n",
      "evaluation/EB/Q_Pred Mean             306.479\n",
      "evaluation/EB/Q_Pred Std                9.13149\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3976.17\n",
      "evaluation/Actions Mean                -0.0610639\n",
      "evaluation/Actions Std                  0.506046\n",
      "evaluation/Actions Max                  0.994497\n",
      "evaluation/Actions Min                 -0.987525\n",
      "time/backward_policy (s)                7.91985\n",
      "time/backward_zf1 (s)                   9.71912\n",
      "time/backward_zf2 (s)                   9.38553\n",
      "time/data sampling (s)                  1.3758\n",
      "time/data storing (s)                   0.0819152\n",
      "time/evaluation sampling (s)            3.62743\n",
      "time/exploration sampling (s)           1.60057\n",
      "time/logging (s)                        0.012875\n",
      "time/preback_alpha (s)                  0.0053905\n",
      "time/preback_policy (s)                 9.81426\n",
      "time/preback_start (s)                  0.668494\n",
      "time/preback_zf (s)                    28.4397\n",
      "time/saving (s)                         8.287e-06\n",
      "time/training (s)                      10.6897\n",
      "time/epoch (s)                         83.3407\n",
      "time/total (s)                       2766.86\n",
      "Epoch                                  32\n",
      "---------------------------------  --------------\n",
      "2024-10-19 01:02:57.624442 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 33 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 180000\n",
      "trainer/ZF1 Loss                        3.84711\n",
      "trainer/ZF2 Loss                        3.89907\n",
      "trainer/ZF Expert Reward                0.971507\n",
      "trainer/ZF Policy Reward                1.38396\n",
      "trainer/ZF CHI2 Term                    3.85198\n",
      "trainer/Policy Loss                  -248.801\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               14.0677\n",
      "trainer/Policy Param Norm              31.0794\n",
      "trainer/Zf1 Grad Norm                 102.188\n",
      "trainer/Zf1 Param Norm                 69.3555\n",
      "trainer/Zf2 Grad Norm                 125.621\n",
      "trainer/Zf2 Param Norm                 70.1511\n",
      "trainer/Z Expert Predictions Mean     304.09\n",
      "trainer/Z Expert Predictions Std        7.38621\n",
      "trainer/Z Expert Predictions Max      315.858\n",
      "trainer/Z Expert Predictions Min      253.441\n",
      "trainer/Z Policy Predictions Mean     248.204\n",
      "trainer/Z Policy Predictions Std      105.61\n",
      "trainer/Z Policy Predictions Max      319.62\n",
      "trainer/Z Policy Predictions Min      -42.7619\n",
      "trainer/Z Expert Targets Mean         303.119\n",
      "trainer/Z Expert Targets Std            7.5224\n",
      "trainer/Z Expert Targets Max          314.282\n",
      "trainer/Z Expert Targets Min          252.137\n",
      "trainer/Z Policy Targets Mean         246.82\n",
      "trainer/Z Policy Targets Std          104.155\n",
      "trainer/Z Policy Targets Max          314.473\n",
      "trainer/Z Policy Targets Min          -35.8933\n",
      "trainer/Log Pis Mean                   17.9092\n",
      "trainer/Log Pis Std                     3.61548\n",
      "trainer/Policy mu Mean                 -0.0295279\n",
      "trainer/Policy mu Std                   0.72363\n",
      "trainer/Policy log std Mean            -3.22853\n",
      "trainer/Policy log std Std              0.533217\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        174575\n",
      "exploration/num paths total           319\n",
      "evaluation/num steps total         218309\n",
      "evaluation/num paths total            358\n",
      "evaluation/path length Mean           339.6\n",
      "evaluation/path length Std            224.74\n",
      "evaluation/path length Max            732\n",
      "evaluation/path length Min             22\n",
      "evaluation/Rewards Mean                 3.81583\n",
      "evaluation/Rewards Std                  1.00447\n",
      "evaluation/Rewards Max                  5.61408\n",
      "evaluation/Rewards Min                 -1.81057\n",
      "evaluation/Returns Mean              1295.86\n",
      "evaluation/Returns Std                877.513\n",
      "evaluation/Returns Max               2771.34\n",
      "evaluation/Returns Min                 45.8501\n",
      "evaluation/Estimation Bias Mean       239.178\n",
      "evaluation/Estimation Bias Std        134.818\n",
      "evaluation/EB/Q_True Mean              63.768\n",
      "evaluation/EB/Q_True Std              132.207\n",
      "evaluation/EB/Q_Pred Mean             302.946\n",
      "evaluation/EB/Q_Pred Std               18.4117\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1295.86\n",
      "evaluation/Actions Mean                -0.0748416\n",
      "evaluation/Actions Std                  0.513617\n",
      "evaluation/Actions Max                  0.999656\n",
      "evaluation/Actions Min                 -0.999864\n",
      "time/backward_policy (s)                7.90157\n",
      "time/backward_zf1 (s)                   9.6994\n",
      "time/backward_zf2 (s)                   9.33826\n",
      "time/data sampling (s)                  1.36212\n",
      "time/data storing (s)                   0.0816299\n",
      "time/evaluation sampling (s)            3.35096\n",
      "time/exploration sampling (s)           1.5927\n",
      "time/logging (s)                        0.0102736\n",
      "time/preback_alpha (s)                  0.00550621\n",
      "time/preback_policy (s)                 9.90657\n",
      "time/preback_start (s)                  0.679985\n",
      "time/preback_zf (s)                    28.5149\n",
      "time/saving (s)                         6.642e-06\n",
      "time/training (s)                      10.7629\n",
      "time/epoch (s)                         83.2068\n",
      "time/total (s)                       2850.07\n",
      "Epoch                                  33\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:04:23.455510 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 34 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 185000\n",
      "trainer/ZF1 Loss                        3.69882\n",
      "trainer/ZF2 Loss                        5.77433\n",
      "trainer/ZF Expert Reward                0.948342\n",
      "trainer/ZF Policy Reward                2.03174\n",
      "trainer/ZF CHI2 Term                    4.38336\n",
      "trainer/Policy Loss                  -257.109\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               15.1436\n",
      "trainer/Policy Param Norm              31.2562\n",
      "trainer/Zf1 Grad Norm                 209.411\n",
      "trainer/Zf1 Param Norm                 69.8601\n",
      "trainer/Zf2 Grad Norm                 307.641\n",
      "trainer/Zf2 Param Norm                 70.6949\n",
      "trainer/Z Expert Predictions Mean     305.3\n",
      "trainer/Z Expert Predictions Std        6.75331\n",
      "trainer/Z Expert Predictions Max      314.77\n",
      "trainer/Z Expert Predictions Min      263.324\n",
      "trainer/Z Policy Predictions Mean     256.764\n",
      "trainer/Z Policy Predictions Std       92.9629\n",
      "trainer/Z Policy Predictions Max      316.549\n",
      "trainer/Z Policy Predictions Min      -33.645\n",
      "trainer/Z Expert Targets Mean         304.351\n",
      "trainer/Z Expert Targets Std            6.76951\n",
      "trainer/Z Expert Targets Max          314.089\n",
      "trainer/Z Expert Targets Min          262.482\n",
      "trainer/Z Policy Targets Mean         254.733\n",
      "trainer/Z Policy Targets Std           91.545\n",
      "trainer/Z Policy Targets Max          314.028\n",
      "trainer/Z Policy Targets Min          -31.3412\n",
      "trainer/Log Pis Mean                   17.914\n",
      "trainer/Log Pis Std                     3.43916\n",
      "trainer/Policy mu Mean                 -0.074389\n",
      "trainer/Policy mu Std                   0.754568\n",
      "trainer/Policy log std Mean            -3.2214\n",
      "trainer/Policy log std Std              0.511913\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        179575\n",
      "exploration/num paths total           324\n",
      "evaluation/num steps total         228309\n",
      "evaluation/num paths total            368\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.07861\n",
      "evaluation/Rewards Std                  0.753385\n",
      "evaluation/Rewards Max                  5.99819\n",
      "evaluation/Rewards Min                 -1.47252\n",
      "evaluation/Returns Mean              4078.61\n",
      "evaluation/Returns Std                 50.8234\n",
      "evaluation/Returns Max               4166.71\n",
      "evaluation/Returns Min               3990.55\n",
      "evaluation/Estimation Bias Mean       270.101\n",
      "evaluation/Estimation Bias Std        116.647\n",
      "evaluation/EB/Q_True Mean              37.8971\n",
      "evaluation/EB/Q_True Std              116.582\n",
      "evaluation/EB/Q_Pred Mean             307.998\n",
      "evaluation/EB/Q_Pred Std                9.34552\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4078.61\n",
      "evaluation/Actions Mean                -0.0581372\n",
      "evaluation/Actions Std                  0.509696\n",
      "evaluation/Actions Max                  0.995392\n",
      "evaluation/Actions Min                 -0.983409\n",
      "time/backward_policy (s)                8.54896\n",
      "time/backward_zf1 (s)                  10.4541\n",
      "time/backward_zf2 (s)                  10.0568\n",
      "time/data sampling (s)                  1.37946\n",
      "time/data storing (s)                   0.0830763\n",
      "time/evaluation sampling (s)            3.99792\n",
      "time/exploration sampling (s)           1.61631\n",
      "time/logging (s)                        0.0130306\n",
      "time/preback_alpha (s)                  0.00551512\n",
      "time/preback_policy (s)                 9.46965\n",
      "time/preback_start (s)                  0.689742\n",
      "time/preback_zf (s)                    28.7019\n",
      "time/saving (s)                         3.682e-06\n",
      "time/training (s)                      10.6092\n",
      "time/epoch (s)                         85.6256\n",
      "time/total (s)                       2935.7\n",
      "Epoch                                  34\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:05:48.941793 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 35 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 190000\n",
      "trainer/ZF1 Loss                        6.01297\n",
      "trainer/ZF2 Loss                       10.1757\n",
      "trainer/ZF Expert Reward                1.07808\n",
      "trainer/ZF Policy Reward                1.28687\n",
      "trainer/ZF CHI2 Term                    8.17316\n",
      "trainer/Policy Loss                  -249.125\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               14.2709\n",
      "trainer/Policy Param Norm              31.4158\n",
      "trainer/Zf1 Grad Norm                 962.275\n",
      "trainer/Zf1 Param Norm                 70.3928\n",
      "trainer/Zf2 Grad Norm                1705.94\n",
      "trainer/Zf2 Param Norm                 71.23\n",
      "trainer/Z Expert Predictions Mean     303.273\n",
      "trainer/Z Expert Predictions Std       20.9759\n",
      "trainer/Z Expert Predictions Max      314.116\n",
      "trainer/Z Expert Predictions Min       -8.59681\n",
      "trainer/Z Policy Predictions Mean     247.839\n",
      "trainer/Z Policy Predictions Std      106.487\n",
      "trainer/Z Policy Predictions Max      316.207\n",
      "trainer/Z Policy Predictions Min      -34.1604\n",
      "trainer/Z Expert Targets Mean         302.195\n",
      "trainer/Z Expert Targets Std           20.4283\n",
      "trainer/Z Expert Targets Max          313.142\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         246.553\n",
      "trainer/Z Policy Targets Std          105.764\n",
      "trainer/Z Policy Targets Max          313.242\n",
      "trainer/Z Policy Targets Min          -34.9341\n",
      "trainer/Log Pis Mean                   17.7057\n",
      "trainer/Log Pis Std                     3.59786\n",
      "trainer/Policy mu Mean                 -0.0399031\n",
      "trainer/Policy mu Std                   0.706985\n",
      "trainer/Policy log std Mean            -3.22398\n",
      "trainer/Policy log std Std              0.503499\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        185306\n",
      "exploration/num paths total           331\n",
      "evaluation/num steps total         238309\n",
      "evaluation/num paths total            378\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.01862\n",
      "evaluation/Rewards Std                  0.754558\n",
      "evaluation/Rewards Max                  6.07903\n",
      "evaluation/Rewards Min                 -1.57706\n",
      "evaluation/Returns Mean              4018.62\n",
      "evaluation/Returns Std                 63.8062\n",
      "evaluation/Returns Max               4151.57\n",
      "evaluation/Returns Min               3916.25\n",
      "evaluation/Estimation Bias Mean       272.517\n",
      "evaluation/Estimation Bias Std        110.25\n",
      "evaluation/EB/Q_True Mean              35.5867\n",
      "evaluation/EB/Q_True Std              109.57\n",
      "evaluation/EB/Q_Pred Mean             308.104\n",
      "evaluation/EB/Q_Pred Std                8.4786\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4018.62\n",
      "evaluation/Actions Mean                -0.0517991\n",
      "evaluation/Actions Std                  0.513959\n",
      "evaluation/Actions Max                  0.993278\n",
      "evaluation/Actions Min                 -0.990999\n",
      "time/backward_policy (s)                8.58073\n",
      "time/backward_zf1 (s)                  10.4325\n",
      "time/backward_zf2 (s)                  10.0801\n",
      "time/data sampling (s)                  1.38688\n",
      "time/data storing (s)                   0.0826358\n",
      "time/evaluation sampling (s)            3.9567\n",
      "time/exploration sampling (s)           1.62818\n",
      "time/logging (s)                        0.0131069\n",
      "time/preback_alpha (s)                  0.0054795\n",
      "time/preback_policy (s)                 9.25872\n",
      "time/preback_start (s)                  0.685162\n",
      "time/preback_zf (s)                    28.6697\n",
      "time/saving (s)                         4.375e-06\n",
      "time/training (s)                      10.5017\n",
      "time/epoch (s)                         85.2816\n",
      "time/total (s)                       3020.98\n",
      "Epoch                                  35\n",
      "---------------------------------  --------------\n",
      "2024-10-19 01:07:12.803414 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 36 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 195000\n",
      "trainer/ZF1 Loss                      127.59\n",
      "trainer/ZF2 Loss                      144.291\n",
      "trainer/ZF Expert Reward                1.89382\n",
      "trainer/ZF Policy Reward                4.71947\n",
      "trainer/ZF CHI2 Term                  134.716\n",
      "trainer/Policy Loss                  -267.307\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               18.7127\n",
      "trainer/Policy Param Norm              31.572\n",
      "trainer/Zf1 Grad Norm                 816.697\n",
      "trainer/Zf1 Param Norm                 70.9517\n",
      "trainer/Zf2 Grad Norm                 928.615\n",
      "trainer/Zf2 Param Norm                 71.8429\n",
      "trainer/Z Expert Predictions Mean     305.691\n",
      "trainer/Z Expert Predictions Std        7.55687\n",
      "trainer/Z Expert Predictions Max      316.616\n",
      "trainer/Z Expert Predictions Min      254.254\n",
      "trainer/Z Policy Predictions Mean     267.005\n",
      "trainer/Z Policy Predictions Std       86.8081\n",
      "trainer/Z Policy Predictions Max      318.498\n",
      "trainer/Z Policy Predictions Min      -30.1175\n",
      "trainer/Z Expert Targets Mean         303.797\n",
      "trainer/Z Expert Targets Std            7.44739\n",
      "trainer/Z Expert Targets Max          314.905\n",
      "trainer/Z Expert Targets Min          252.76\n",
      "trainer/Z Policy Targets Mean         262.285\n",
      "trainer/Z Policy Targets Std           88.6428\n",
      "trainer/Z Policy Targets Max          312.356\n",
      "trainer/Z Policy Targets Min          -37.6788\n",
      "trainer/Log Pis Mean                   18.4673\n",
      "trainer/Log Pis Std                     2.84272\n",
      "trainer/Policy mu Mean                 -0.0441938\n",
      "trainer/Policy mu Std                   0.691596\n",
      "trainer/Policy log std Mean            -3.30607\n",
      "trainer/Policy log std Std              0.463004\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        189592\n",
      "exploration/num paths total           336\n",
      "evaluation/num steps total         246770\n",
      "evaluation/num paths total            390\n",
      "evaluation/path length Mean           705.083\n",
      "evaluation/path length Std            375.159\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             22\n",
      "evaluation/Rewards Mean                 3.09087\n",
      "evaluation/Rewards Std                  1.89298\n",
      "evaluation/Rewards Max                  6.20772\n",
      "evaluation/Rewards Min                 -3.3047\n",
      "evaluation/Returns Mean              2179.32\n",
      "evaluation/Returns Std               1636.34\n",
      "evaluation/Returns Max               3962.24\n",
      "evaluation/Returns Min               -695.815\n",
      "evaluation/Estimation Bias Mean       226.628\n",
      "evaluation/Estimation Bias Std        130.971\n",
      "evaluation/EB/Q_True Mean              41.6606\n",
      "evaluation/EB/Q_True Std              116.823\n",
      "evaluation/EB/Q_Pred Mean             268.288\n",
      "evaluation/EB/Q_Pred Std               77.1443\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2179.32\n",
      "evaluation/Actions Mean                -0.0449797\n",
      "evaluation/Actions Std                  0.534596\n",
      "evaluation/Actions Max                  0.999993\n",
      "evaluation/Actions Min                 -0.999837\n",
      "time/backward_policy (s)                8.30215\n",
      "time/backward_zf1 (s)                  10.1072\n",
      "time/backward_zf2 (s)                   9.8009\n",
      "time/data sampling (s)                  1.32267\n",
      "time/data storing (s)                   0.0803369\n",
      "time/evaluation sampling (s)            3.45314\n",
      "time/exploration sampling (s)           1.58408\n",
      "time/logging (s)                        0.0103279\n",
      "time/preback_alpha (s)                  0.00537403\n",
      "time/preback_policy (s)                 9.35899\n",
      "time/preback_start (s)                  0.674902\n",
      "time/preback_zf (s)                    28.4696\n",
      "time/saving (s)                         3.526e-06\n",
      "time/training (s)                      10.4886\n",
      "time/epoch (s)                         83.6583\n",
      "time/total (s)                       3104.64\n",
      "Epoch                                  36\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:08:36.484749 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 37 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 200000\n",
      "trainer/ZF1 Loss                        3.07192\n",
      "trainer/ZF2 Loss                        4.33175\n",
      "trainer/ZF Expert Reward                0.94613\n",
      "trainer/ZF Policy Reward                1.28058\n",
      "trainer/ZF CHI2 Term                    3.71897\n",
      "trainer/Policy Loss                  -258.751\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               12.3275\n",
      "trainer/Policy Param Norm              31.72\n",
      "trainer/Zf1 Grad Norm                  61.8768\n",
      "trainer/Zf1 Param Norm                 71.4266\n",
      "trainer/Zf2 Grad Norm                 128.114\n",
      "trainer/Zf2 Param Norm                 72.3861\n",
      "trainer/Z Expert Predictions Mean     304.117\n",
      "trainer/Z Expert Predictions Std        6.27855\n",
      "trainer/Z Expert Predictions Max      312.918\n",
      "trainer/Z Expert Predictions Min      260.167\n",
      "trainer/Z Policy Predictions Mean     258.866\n",
      "trainer/Z Policy Predictions Std       96.4509\n",
      "trainer/Z Policy Predictions Max      315.476\n",
      "trainer/Z Policy Predictions Min      -36.526\n",
      "trainer/Z Expert Targets Mean         303.171\n",
      "trainer/Z Expert Targets Std            6.43944\n",
      "trainer/Z Expert Targets Max          311.856\n",
      "trainer/Z Expert Targets Min          259.666\n",
      "trainer/Z Policy Targets Mean         257.585\n",
      "trainer/Z Policy Targets Std           95.1383\n",
      "trainer/Z Policy Targets Max          313.237\n",
      "trainer/Z Policy Targets Min          -34.4794\n",
      "trainer/Log Pis Mean                   17.9375\n",
      "trainer/Log Pis Std                     3.59007\n",
      "trainer/Policy mu Mean                 -0.045086\n",
      "trainer/Policy mu Std                   0.725789\n",
      "trainer/Policy log std Mean            -3.22441\n",
      "trainer/Policy log std Std              0.538968\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        195361\n",
      "exploration/num paths total           342\n",
      "evaluation/num steps total         256770\n",
      "evaluation/num paths total            400\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.03853\n",
      "evaluation/Rewards Std                  0.71081\n",
      "evaluation/Rewards Max                  6.16646\n",
      "evaluation/Rewards Min                 -1.29157\n",
      "evaluation/Returns Mean              4038.53\n",
      "evaluation/Returns Std                 46.9116\n",
      "evaluation/Returns Max               4148.11\n",
      "evaluation/Returns Min               3963.34\n",
      "evaluation/Estimation Bias Mean       270.37\n",
      "evaluation/Estimation Bias Std        113.724\n",
      "evaluation/EB/Q_True Mean              36.8564\n",
      "evaluation/EB/Q_True Std              113.564\n",
      "evaluation/EB/Q_Pred Mean             307.226\n",
      "evaluation/EB/Q_Pred Std                8.49802\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4038.53\n",
      "evaluation/Actions Mean                -0.054253\n",
      "evaluation/Actions Std                  0.499343\n",
      "evaluation/Actions Max                  0.99634\n",
      "evaluation/Actions Min                 -0.992932\n",
      "time/backward_policy (s)                8.09203\n",
      "time/backward_zf1 (s)                   9.89345\n",
      "time/backward_zf2 (s)                   9.54299\n",
      "time/data sampling (s)                  1.37806\n",
      "time/data storing (s)                   0.0806166\n",
      "time/evaluation sampling (s)            3.54724\n",
      "time/exploration sampling (s)           1.58686\n",
      "time/logging (s)                        0.0136839\n",
      "time/preback_alpha (s)                  0.00543642\n",
      "time/preback_policy (s)                 9.61797\n",
      "time/preback_start (s)                  0.676859\n",
      "time/preback_zf (s)                    28.5294\n",
      "time/saving (s)                         4.823e-06\n",
      "time/training (s)                      10.517\n",
      "time/epoch (s)                         83.4816\n",
      "time/total (s)                       3188.13\n",
      "Epoch                                  37\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:10:01.933299 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 38 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 205000\n",
      "trainer/ZF1 Loss                        3.84307\n",
      "trainer/ZF2 Loss                        4.66113\n",
      "trainer/ZF Expert Reward                0.751087\n",
      "trainer/ZF Policy Reward                1.32316\n",
      "trainer/ZF CHI2 Term                    4.15296\n",
      "trainer/Policy Loss                  -254.139\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               18.1038\n",
      "trainer/Policy Param Norm              31.8784\n",
      "trainer/Zf1 Grad Norm                 141.416\n",
      "trainer/Zf1 Param Norm                 71.9435\n",
      "trainer/Zf2 Grad Norm                 166.55\n",
      "trainer/Zf2 Param Norm                 72.9109\n",
      "trainer/Z Expert Predictions Mean     301.976\n",
      "trainer/Z Expert Predictions Std       20.6964\n",
      "trainer/Z Expert Predictions Max      313.826\n",
      "trainer/Z Expert Predictions Min        3.27315\n",
      "trainer/Z Policy Predictions Mean     253.411\n",
      "trainer/Z Policy Predictions Std      102.173\n",
      "trainer/Z Policy Predictions Max      315.478\n",
      "trainer/Z Policy Predictions Min      -34.0418\n",
      "trainer/Z Expert Targets Mean         301.225\n",
      "trainer/Z Expert Targets Std           20.8784\n",
      "trainer/Z Expert Targets Max          312.044\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         252.088\n",
      "trainer/Z Policy Targets Std          100.73\n",
      "trainer/Z Policy Targets Max          313.182\n",
      "trainer/Z Policy Targets Min          -37.8973\n",
      "trainer/Log Pis Mean                   18.1727\n",
      "trainer/Log Pis Std                     3.08879\n",
      "trainer/Policy mu Mean                 -0.0241242\n",
      "trainer/Policy mu Std                   0.712731\n",
      "trainer/Policy log std Mean            -3.25621\n",
      "trainer/Policy log std Std              0.499527\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        199401\n",
      "exploration/num paths total           347\n",
      "evaluation/num steps total         266659\n",
      "evaluation/num paths total            410\n",
      "evaluation/path length Mean           988.9\n",
      "evaluation/path length Std             33.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            889\n",
      "evaluation/Rewards Mean                 4.05927\n",
      "evaluation/Rewards Std                  0.783356\n",
      "evaluation/Rewards Max                  6.16803\n",
      "evaluation/Rewards Min                 -1.41967\n",
      "evaluation/Returns Mean              4014.21\n",
      "evaluation/Returns Std                172.861\n",
      "evaluation/Returns Max               4140.57\n",
      "evaluation/Returns Min               3508.74\n",
      "evaluation/Estimation Bias Mean       270.526\n",
      "evaluation/Estimation Bias Std        117.93\n",
      "evaluation/EB/Q_True Mean              38.0117\n",
      "evaluation/EB/Q_True Std              116.483\n",
      "evaluation/EB/Q_Pred Mean             308.538\n",
      "evaluation/EB/Q_Pred Std                9.3812\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4014.21\n",
      "evaluation/Actions Mean                -0.0609207\n",
      "evaluation/Actions Std                  0.511294\n",
      "evaluation/Actions Max                  0.990554\n",
      "evaluation/Actions Min                 -0.987776\n",
      "time/backward_policy (s)                8.83586\n",
      "time/backward_zf1 (s)                  10.6943\n",
      "time/backward_zf2 (s)                  10.3897\n",
      "time/data sampling (s)                  1.36397\n",
      "time/data storing (s)                   0.0828798\n",
      "time/evaluation sampling (s)            3.61404\n",
      "time/exploration sampling (s)           1.60736\n",
      "time/logging (s)                        0.0120814\n",
      "time/preback_alpha (s)                  0.00546776\n",
      "time/preback_policy (s)                 8.9298\n",
      "time/preback_start (s)                  0.684945\n",
      "time/preback_zf (s)                    28.6607\n",
      "time/saving (s)                         3.73001e-06\n",
      "time/training (s)                      10.3601\n",
      "time/epoch (s)                         85.2412\n",
      "time/total (s)                       3273.37\n",
      "Epoch                                  38\n",
      "---------------------------------  ----------------\n",
      "2024-10-19 01:11:24.612761 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 39 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 210000\n",
      "trainer/ZF1 Loss                        3.4281\n",
      "trainer/ZF2 Loss                        2.79111\n",
      "trainer/ZF Expert Reward                1.17415\n",
      "trainer/ZF Policy Reward                1.92126\n",
      "trainer/ZF CHI2 Term                    2.92335\n",
      "trainer/Policy Loss                  -264.874\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               13.7464\n",
      "trainer/Policy Param Norm              32.0183\n",
      "trainer/Zf1 Grad Norm                 109.425\n",
      "trainer/Zf1 Param Norm                 72.4711\n",
      "trainer/Zf2 Grad Norm                  65.9994\n",
      "trainer/Zf2 Param Norm                 73.4289\n",
      "trainer/Z Expert Predictions Mean     304.756\n",
      "trainer/Z Expert Predictions Std        6.50254\n",
      "trainer/Z Expert Predictions Max      312.37\n",
      "trainer/Z Expert Predictions Min      262.255\n",
      "trainer/Z Policy Predictions Mean     264.873\n",
      "trainer/Z Policy Predictions Std       89.5345\n",
      "trainer/Z Policy Predictions Max      317.338\n",
      "trainer/Z Policy Predictions Min      -25.1048\n",
      "trainer/Z Expert Targets Mean         303.582\n",
      "trainer/Z Expert Targets Std            6.70458\n",
      "trainer/Z Expert Targets Max          311.597\n",
      "trainer/Z Expert Targets Min          260.737\n",
      "trainer/Z Policy Targets Mean         262.951\n",
      "trainer/Z Policy Targets Std           88.4854\n",
      "trainer/Z Policy Targets Max          312.8\n",
      "trainer/Z Policy Targets Min          -27.6109\n",
      "trainer/Log Pis Mean                   18.2445\n",
      "trainer/Log Pis Std                     3.23593\n",
      "trainer/Policy mu Mean                 -0.0300673\n",
      "trainer/Policy mu Std                   0.712976\n",
      "trainer/Policy log std Mean            -3.29655\n",
      "trainer/Policy log std Std              0.507389\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        204598\n",
      "exploration/num paths total           353\n",
      "evaluation/num steps total         267746\n",
      "evaluation/num paths total            420\n",
      "evaluation/path length Mean           108.7\n",
      "evaluation/path length Std             81.4482\n",
      "evaluation/path length Max            281\n",
      "evaluation/path length Min              9\n",
      "evaluation/Rewards Mean                 3.46329\n",
      "evaluation/Rewards Std                  1.48957\n",
      "evaluation/Rewards Max                  6.17026\n",
      "evaluation/Rewards Min                 -1.53056\n",
      "evaluation/Returns Mean               376.46\n",
      "evaluation/Returns Std                339.132\n",
      "evaluation/Returns Max               1093\n",
      "evaluation/Returns Min                  6.06037\n",
      "evaluation/Estimation Bias Mean       241.04\n",
      "evaluation/Estimation Bias Std        110.158\n",
      "evaluation/EB/Q_True Mean              51.8814\n",
      "evaluation/EB/Q_True Std              101.317\n",
      "evaluation/EB/Q_Pred Mean             292.921\n",
      "evaluation/EB/Q_Pred Std               30.2844\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            376.46\n",
      "evaluation/Actions Mean                -0.0546247\n",
      "evaluation/Actions Std                  0.515092\n",
      "evaluation/Actions Max                  0.997659\n",
      "evaluation/Actions Min                 -0.997318\n",
      "time/backward_policy (s)                8.70042\n",
      "time/backward_zf1 (s)                  10.5489\n",
      "time/backward_zf2 (s)                  10.2496\n",
      "time/data sampling (s)                  1.33982\n",
      "time/data storing (s)                   0.0801079\n",
      "time/evaluation sampling (s)            1.27803\n",
      "time/exploration sampling (s)           1.59752\n",
      "time/logging (s)                        0.00390737\n",
      "time/preback_alpha (s)                  0.00544835\n",
      "time/preback_policy (s)                 9.02855\n",
      "time/preback_start (s)                  0.675115\n",
      "time/preback_zf (s)                    28.6155\n",
      "time/saving (s)                         6.113e-06\n",
      "time/training (s)                      10.3438\n",
      "time/epoch (s)                         82.4667\n",
      "time/total (s)                       3355.84\n",
      "Epoch                                  39\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:12:50.758983 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 40 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 215000\n",
      "trainer/ZF1 Loss                        4.88252\n",
      "trainer/ZF2 Loss                        3.31046\n",
      "trainer/ZF Expert Reward                1.33076\n",
      "trainer/ZF Policy Reward                2.35225\n",
      "trainer/ZF CHI2 Term                    3.77277\n",
      "trainer/Policy Loss                  -259.466\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               16.0638\n",
      "trainer/Policy Param Norm              32.1731\n",
      "trainer/Zf1 Grad Norm                 235.355\n",
      "trainer/Zf1 Param Norm                 73.0158\n",
      "trainer/Zf2 Grad Norm                  73.8095\n",
      "trainer/Zf2 Param Norm                 73.9927\n",
      "trainer/Z Expert Predictions Mean     305.984\n",
      "trainer/Z Expert Predictions Std        6.1573\n",
      "trainer/Z Expert Predictions Max      314.423\n",
      "trainer/Z Expert Predictions Min      263.939\n",
      "trainer/Z Policy Predictions Mean     259.383\n",
      "trainer/Z Policy Predictions Std      101.533\n",
      "trainer/Z Policy Predictions Max      316.63\n",
      "trainer/Z Policy Predictions Min      -28.9169\n",
      "trainer/Z Expert Targets Mean         304.653\n",
      "trainer/Z Expert Targets Std            6.03552\n",
      "trainer/Z Expert Targets Max          313.304\n",
      "trainer/Z Expert Targets Min          263.762\n",
      "trainer/Z Policy Targets Mean         257.031\n",
      "trainer/Z Policy Targets Std           99.8677\n",
      "trainer/Z Policy Targets Max          314.142\n",
      "trainer/Z Policy Targets Min          -28.4919\n",
      "trainer/Log Pis Mean                   18.1938\n",
      "trainer/Log Pis Std                     3.25462\n",
      "trainer/Policy mu Mean                 -0.0277354\n",
      "trainer/Policy mu Std                   0.745662\n",
      "trainer/Policy log std Mean            -3.24574\n",
      "trainer/Policy log std Std              0.524101\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        210359\n",
      "exploration/num paths total           361\n",
      "evaluation/num steps total         276873\n",
      "evaluation/num paths total            430\n",
      "evaluation/path length Mean           912.7\n",
      "evaluation/path length Std            223.086\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            253\n",
      "evaluation/Rewards Mean                 4.22263\n",
      "evaluation/Rewards Std                  0.842907\n",
      "evaluation/Rewards Max                  6.23669\n",
      "evaluation/Rewards Min                 -1.48829\n",
      "evaluation/Returns Mean              3853.99\n",
      "evaluation/Returns Std                962.491\n",
      "evaluation/Returns Max               4362.24\n",
      "evaluation/Returns Min               1004.99\n",
      "evaluation/Estimation Bias Mean       265.649\n",
      "evaluation/Estimation Bias Std        124.548\n",
      "evaluation/EB/Q_True Mean              42.4044\n",
      "evaluation/EB/Q_True Std              124.2\n",
      "evaluation/EB/Q_Pred Mean             308.054\n",
      "evaluation/EB/Q_Pred Std                9.88278\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3853.99\n",
      "evaluation/Actions Mean                -0.0497988\n",
      "evaluation/Actions Std                  0.523882\n",
      "evaluation/Actions Max                  0.996024\n",
      "evaluation/Actions Min                 -0.997839\n",
      "time/backward_policy (s)                8.83697\n",
      "time/backward_zf1 (s)                  10.8039\n",
      "time/backward_zf2 (s)                  10.4967\n",
      "time/data sampling (s)                  1.36897\n",
      "time/data storing (s)                   0.0826064\n",
      "time/evaluation sampling (s)            3.64944\n",
      "time/exploration sampling (s)           1.62114\n",
      "time/logging (s)                        0.0109273\n",
      "time/preback_alpha (s)                  0.00549109\n",
      "time/preback_policy (s)                 9.07267\n",
      "time/preback_start (s)                  0.686056\n",
      "time/preback_zf (s)                    28.7131\n",
      "time/saving (s)                         3.382e-06\n",
      "time/training (s)                      10.5996\n",
      "time/epoch (s)                         85.9476\n",
      "time/total (s)                       3441.79\n",
      "Epoch                                  40\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:14:14.399169 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 41 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 220000\n",
      "trainer/ZF1 Loss                        3.4452\n",
      "trainer/ZF2 Loss                        3.00579\n",
      "trainer/ZF Expert Reward                0.742552\n",
      "trainer/ZF Policy Reward                1.53325\n",
      "trainer/ZF CHI2 Term                    3.01574\n",
      "trainer/Policy Loss                  -267.516\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               12.2595\n",
      "trainer/Policy Param Norm              32.3555\n",
      "trainer/Zf1 Grad Norm                 109.622\n",
      "trainer/Zf1 Param Norm                 73.5491\n",
      "trainer/Zf2 Grad Norm                  80.2861\n",
      "trainer/Zf2 Param Norm                 74.526\n",
      "trainer/Z Expert Predictions Mean     303.866\n",
      "trainer/Z Expert Predictions Std       20.1546\n",
      "trainer/Z Expert Predictions Max      316.267\n",
      "trainer/Z Expert Predictions Min       -1.30177\n",
      "trainer/Z Policy Predictions Mean     266.974\n",
      "trainer/Z Policy Predictions Std       82.5477\n",
      "trainer/Z Policy Predictions Max      316.093\n",
      "trainer/Z Policy Predictions Min      -26.2808\n",
      "trainer/Z Expert Targets Mean         303.124\n",
      "trainer/Z Expert Targets Std           20.0699\n",
      "trainer/Z Expert Targets Max          312.84\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         265.441\n",
      "trainer/Z Policy Targets Std           81.4422\n",
      "trainer/Z Policy Targets Max          312.712\n",
      "trainer/Z Policy Targets Min          -27.6088\n",
      "trainer/Log Pis Mean                   18.0923\n",
      "trainer/Log Pis Std                     3.12344\n",
      "trainer/Policy mu Mean                 -0.0257627\n",
      "trainer/Policy mu Std                   0.704469\n",
      "trainer/Policy log std Mean            -3.272\n",
      "trainer/Policy log std Std              0.488925\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        213145\n",
      "exploration/num paths total           365\n",
      "evaluation/num steps total         285779\n",
      "evaluation/num paths total            441\n",
      "evaluation/path length Mean           809.636\n",
      "evaluation/path length Std            258.81\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            230\n",
      "evaluation/Rewards Mean                 4.1757\n",
      "evaluation/Rewards Std                  0.849062\n",
      "evaluation/Rewards Max                  6.05309\n",
      "evaluation/Rewards Min                 -1.75031\n",
      "evaluation/Returns Mean              3380.8\n",
      "evaluation/Returns Std               1114.06\n",
      "evaluation/Returns Max               4271.27\n",
      "evaluation/Returns Min                911.151\n",
      "evaluation/Estimation Bias Mean       265.179\n",
      "evaluation/Estimation Bias Std        126.893\n",
      "evaluation/EB/Q_True Mean              43.5132\n",
      "evaluation/EB/Q_True Std              125.739\n",
      "evaluation/EB/Q_Pred Mean             308.692\n",
      "evaluation/EB/Q_Pred Std               11.5416\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3380.8\n",
      "evaluation/Actions Mean                -0.0708572\n",
      "evaluation/Actions Std                  0.532797\n",
      "evaluation/Actions Max                  0.992762\n",
      "evaluation/Actions Min                 -0.998192\n",
      "time/backward_policy (s)                7.81945\n",
      "time/backward_zf1 (s)                   9.59145\n",
      "time/backward_zf2 (s)                   9.24998\n",
      "time/data sampling (s)                  1.3578\n",
      "time/data storing (s)                   0.0805443\n",
      "time/evaluation sampling (s)            3.79104\n",
      "time/exploration sampling (s)           1.57328\n",
      "time/logging (s)                        0.0118823\n",
      "time/preback_alpha (s)                  0.00536666\n",
      "time/preback_policy (s)                 9.94704\n",
      "time/preback_start (s)                  0.667603\n",
      "time/preback_zf (s)                    28.505\n",
      "time/saving (s)                         4.209e-06\n",
      "time/training (s)                      10.8397\n",
      "time/epoch (s)                         83.4402\n",
      "time/total (s)                       3525.23\n",
      "Epoch                                  41\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:15:40.206657 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 42 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 225000\n",
      "trainer/ZF1 Loss                        3.29606\n",
      "trainer/ZF2 Loss                        3.36666\n",
      "trainer/ZF Expert Reward                1.02339\n",
      "trainer/ZF Policy Reward                2.07271\n",
      "trainer/ZF CHI2 Term                    2.9933\n",
      "trainer/Policy Loss                  -261.759\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               17.0111\n",
      "trainer/Policy Param Norm              32.5131\n",
      "trainer/Zf1 Grad Norm                  81.9416\n",
      "trainer/Zf1 Param Norm                 74.054\n",
      "trainer/Zf2 Grad Norm                  75.4665\n",
      "trainer/Zf2 Param Norm                 75.0216\n",
      "trainer/Z Expert Predictions Mean     306.294\n",
      "trainer/Z Expert Predictions Std        5.31778\n",
      "trainer/Z Expert Predictions Max      314.84\n",
      "trainer/Z Expert Predictions Min      270.52\n",
      "trainer/Z Policy Predictions Mean     261.403\n",
      "trainer/Z Policy Predictions Std       89.7758\n",
      "trainer/Z Policy Predictions Max      315.613\n",
      "trainer/Z Policy Predictions Min      -17.5004\n",
      "trainer/Z Expert Targets Mean         305.27\n",
      "trainer/Z Expert Targets Std            5.37343\n",
      "trainer/Z Expert Targets Max          313.944\n",
      "trainer/Z Expert Targets Min          269.846\n",
      "trainer/Z Policy Targets Mean         259.33\n",
      "trainer/Z Policy Targets Std           88.4801\n",
      "trainer/Z Policy Targets Max          312.872\n",
      "trainer/Z Policy Targets Min          -15.9743\n",
      "trainer/Log Pis Mean                   18.0699\n",
      "trainer/Log Pis Std                     3.26131\n",
      "trainer/Policy mu Mean                 -0.0616599\n",
      "trainer/Policy mu Std                   0.748131\n",
      "trainer/Policy log std Mean            -3.24865\n",
      "trainer/Policy log std Std              0.513706\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        220692\n",
      "exploration/num paths total           375\n",
      "evaluation/num steps total         295779\n",
      "evaluation/num paths total            451\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.93159\n",
      "evaluation/Rewards Std                  0.844007\n",
      "evaluation/Rewards Max                  6.22247\n",
      "evaluation/Rewards Min                 -2.09167\n",
      "evaluation/Returns Mean              3931.59\n",
      "evaluation/Returns Std                 62.4897\n",
      "evaluation/Returns Max               3987.23\n",
      "evaluation/Returns Min               3800.31\n",
      "evaluation/Estimation Bias Mean       267.393\n",
      "evaluation/Estimation Bias Std        112.63\n",
      "evaluation/EB/Q_True Mean              36.4339\n",
      "evaluation/EB/Q_True Std              112.415\n",
      "evaluation/EB/Q_Pred Mean             303.827\n",
      "evaluation/EB/Q_Pred Std               10.0813\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3931.59\n",
      "evaluation/Actions Mean                -0.0548895\n",
      "evaluation/Actions Std                  0.510198\n",
      "evaluation/Actions Max                  0.994798\n",
      "evaluation/Actions Min                 -0.997775\n",
      "time/backward_policy (s)                8.59204\n",
      "time/backward_zf1 (s)                  10.4693\n",
      "time/backward_zf2 (s)                  10.1251\n",
      "time/data sampling (s)                  1.43425\n",
      "time/data storing (s)                   0.082475\n",
      "time/evaluation sampling (s)            3.85786\n",
      "time/exploration sampling (s)           1.6267\n",
      "time/logging (s)                        0.0177981\n",
      "time/preback_alpha (s)                  0.00547118\n",
      "time/preback_policy (s)                 9.30678\n",
      "time/preback_start (s)                  0.6939\n",
      "time/preback_zf (s)                    28.7618\n",
      "time/saving (s)                         6.514e-06\n",
      "time/training (s)                      10.6332\n",
      "time/epoch (s)                         85.6067\n",
      "time/total (s)                       3610.84\n",
      "Epoch                                  42\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:17:04.481036 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 43 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 230000\n",
      "trainer/ZF1 Loss                        3.53839\n",
      "trainer/ZF2 Loss                        3.8569\n",
      "trainer/ZF Expert Reward                1.00076\n",
      "trainer/ZF Policy Reward                1.75448\n",
      "trainer/ZF CHI2 Term                    3.50673\n",
      "trainer/Policy Loss                  -260.204\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               13.5195\n",
      "trainer/Policy Param Norm              32.6706\n",
      "trainer/Zf1 Grad Norm                 176.824\n",
      "trainer/Zf1 Param Norm                 74.6041\n",
      "trainer/Zf2 Grad Norm                 302.112\n",
      "trainer/Zf2 Param Norm                 75.5649\n",
      "trainer/Z Expert Predictions Mean     302.706\n",
      "trainer/Z Expert Predictions Std       27.7469\n",
      "trainer/Z Expert Predictions Max      313.519\n",
      "trainer/Z Expert Predictions Min        2.79499\n",
      "trainer/Z Policy Predictions Mean     259.747\n",
      "trainer/Z Policy Predictions Std       91.8311\n",
      "trainer/Z Policy Predictions Max      315.321\n",
      "trainer/Z Policy Predictions Min      -22.6121\n",
      "trainer/Z Expert Targets Mean         301.705\n",
      "trainer/Z Expert Targets Std           28.0465\n",
      "trainer/Z Expert Targets Max          313.219\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         257.993\n",
      "trainer/Z Policy Targets Std           90.8031\n",
      "trainer/Z Policy Targets Max          313.312\n",
      "trainer/Z Policy Targets Min          -24.0306\n",
      "trainer/Log Pis Mean                   18.1794\n",
      "trainer/Log Pis Std                     3.51278\n",
      "trainer/Policy mu Mean                 -0.0708472\n",
      "trainer/Policy mu Std                   0.750186\n",
      "trainer/Policy log std Mean            -3.23679\n",
      "trainer/Policy log std Std              0.564099\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        225291\n",
      "exploration/num paths total           381\n",
      "evaluation/num steps total         305779\n",
      "evaluation/num paths total            461\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.21246\n",
      "evaluation/Rewards Std                  0.872218\n",
      "evaluation/Rewards Max                  6.18263\n",
      "evaluation/Rewards Min                 -1.92867\n",
      "evaluation/Returns Mean              4212.46\n",
      "evaluation/Returns Std                108.077\n",
      "evaluation/Returns Max               4393.41\n",
      "evaluation/Returns Min               4033.53\n",
      "evaluation/Estimation Bias Mean       269.576\n",
      "evaluation/Estimation Bias Std        119.974\n",
      "evaluation/EB/Q_True Mean              38.7926\n",
      "evaluation/EB/Q_True Std              119.457\n",
      "evaluation/EB/Q_Pred Mean             308.368\n",
      "evaluation/EB/Q_Pred Std                9.62937\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4212.46\n",
      "evaluation/Actions Mean                -0.0576925\n",
      "evaluation/Actions Std                  0.540217\n",
      "evaluation/Actions Max                  0.99644\n",
      "evaluation/Actions Min                 -0.996934\n",
      "time/backward_policy (s)                8.10716\n",
      "time/backward_zf1 (s)                   9.9449\n",
      "time/backward_zf2 (s)                   9.60152\n",
      "time/data sampling (s)                  1.34175\n",
      "time/data storing (s)                   0.0816317\n",
      "time/evaluation sampling (s)            3.66124\n",
      "time/exploration sampling (s)           1.59669\n",
      "time/logging (s)                        0.0154043\n",
      "time/preback_alpha (s)                  0.00546254\n",
      "time/preback_policy (s)                 9.72872\n",
      "time/preback_start (s)                  0.679382\n",
      "time/preback_zf (s)                    28.5417\n",
      "time/saving (s)                         6.89e-06\n",
      "time/training (s)                      10.7643\n",
      "time/epoch (s)                         84.0699\n",
      "time/total (s)                       3694.91\n",
      "Epoch                                  43\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:18:28.899807 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 44 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 235000\n",
      "trainer/ZF1 Loss                       92.9966\n",
      "trainer/ZF2 Loss                       95.3683\n",
      "trainer/ZF Expert Reward                1.13939\n",
      "trainer/ZF Policy Reward                3.24172\n",
      "trainer/ZF CHI2 Term                   93.3202\n",
      "trainer/Policy Loss                  -264.077\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               15.5448\n",
      "trainer/Policy Param Norm              32.8428\n",
      "trainer/Zf1 Grad Norm                 424.482\n",
      "trainer/Zf1 Param Norm                 75.0869\n",
      "trainer/Zf2 Grad Norm                 443.944\n",
      "trainer/Zf2 Param Norm                 76.0626\n",
      "trainer/Z Expert Predictions Mean     307.129\n",
      "trainer/Z Expert Predictions Std        6.48672\n",
      "trainer/Z Expert Predictions Max      314.351\n",
      "trainer/Z Expert Predictions Min      256.468\n",
      "trainer/Z Policy Predictions Mean     263.202\n",
      "trainer/Z Policy Predictions Std       84.2832\n",
      "trainer/Z Policy Predictions Max      316.676\n",
      "trainer/Z Policy Predictions Min      -15.7933\n",
      "trainer/Z Expert Targets Mean         305.989\n",
      "trainer/Z Expert Targets Std            6.59872\n",
      "trainer/Z Expert Targets Max          314.333\n",
      "trainer/Z Expert Targets Min          254.484\n",
      "trainer/Z Policy Targets Mean         259.961\n",
      "trainer/Z Policy Targets Std           84.5641\n",
      "trainer/Z Policy Targets Max          315.488\n",
      "trainer/Z Policy Targets Min          -14.2312\n",
      "trainer/Log Pis Mean                   18.4416\n",
      "trainer/Log Pis Std                     3.6787\n",
      "trainer/Policy mu Mean                 -0.0535185\n",
      "trainer/Policy mu Std                   0.775372\n",
      "trainer/Policy log std Mean            -3.24117\n",
      "trainer/Policy log std Std              0.530226\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        230291\n",
      "exploration/num paths total           386\n",
      "evaluation/num steps total         314022\n",
      "evaluation/num paths total            474\n",
      "evaluation/path length Mean           634.077\n",
      "evaluation/path length Std            363.244\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 4.18247\n",
      "evaluation/Rewards Std                  0.899162\n",
      "evaluation/Rewards Max                  6.30381\n",
      "evaluation/Rewards Min                 -1.75252\n",
      "evaluation/Returns Mean              2652.01\n",
      "evaluation/Returns Std               1582.69\n",
      "evaluation/Returns Max               4368.83\n",
      "evaluation/Returns Min                  6.66539\n",
      "evaluation/Estimation Bias Mean       263.015\n",
      "evaluation/Estimation Bias Std        128.03\n",
      "evaluation/EB/Q_True Mean              45.2178\n",
      "evaluation/EB/Q_True Std              125.675\n",
      "evaluation/EB/Q_Pred Mean             308.232\n",
      "evaluation/EB/Q_Pred Std               12.1999\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2652.01\n",
      "evaluation/Actions Mean                -0.0707887\n",
      "evaluation/Actions Std                  0.535273\n",
      "evaluation/Actions Max                  0.996113\n",
      "evaluation/Actions Min                 -0.998136\n",
      "time/backward_policy (s)                8.14209\n",
      "time/backward_zf1 (s)                   9.97219\n",
      "time/backward_zf2 (s)                   9.6188\n",
      "time/data sampling (s)                  1.34425\n",
      "time/data storing (s)                   0.0804589\n",
      "time/evaluation sampling (s)            3.91779\n",
      "time/exploration sampling (s)           1.58891\n",
      "time/logging (s)                        0.010279\n",
      "time/preback_alpha (s)                  0.00543674\n",
      "time/preback_policy (s)                 9.63024\n",
      "time/preback_start (s)                  0.676098\n",
      "time/preback_zf (s)                    28.528\n",
      "time/saving (s)                         3.463e-06\n",
      "time/training (s)                      10.6969\n",
      "time/epoch (s)                         84.2114\n",
      "time/total (s)                       3779.13\n",
      "Epoch                                  44\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:19:55.118916 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 45 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 240000\n",
      "trainer/ZF1 Loss                        3.19936\n",
      "trainer/ZF2 Loss                        3.71506\n",
      "trainer/ZF Expert Reward                0.556889\n",
      "trainer/ZF Policy Reward                1.75691\n",
      "trainer/ZF CHI2 Term                    3.05073\n",
      "trainer/Policy Loss                  -270.678\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               22.7339\n",
      "trainer/Policy Param Norm              33.0042\n",
      "trainer/Zf1 Grad Norm                 116.745\n",
      "trainer/Zf1 Param Norm                 75.5981\n",
      "trainer/Zf2 Grad Norm                 108.539\n",
      "trainer/Zf2 Param Norm                 76.5518\n",
      "trainer/Z Expert Predictions Mean     304.666\n",
      "trainer/Z Expert Predictions Std       20.3935\n",
      "trainer/Z Expert Predictions Max      315.388\n",
      "trainer/Z Expert Predictions Min       -2.59965\n",
      "trainer/Z Policy Predictions Mean     269.532\n",
      "trainer/Z Policy Predictions Std       85.6318\n",
      "trainer/Z Policy Predictions Max      320.121\n",
      "trainer/Z Policy Predictions Min      -13.6309\n",
      "trainer/Z Expert Targets Mean         304.109\n",
      "trainer/Z Expert Targets Std           20.2149\n",
      "trainer/Z Expert Targets Max          314.48\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         267.775\n",
      "trainer/Z Policy Targets Std           84.9451\n",
      "trainer/Z Policy Targets Max          315.012\n",
      "trainer/Z Policy Targets Min          -13.2781\n",
      "trainer/Log Pis Mean                   18.9588\n",
      "trainer/Log Pis Std                     3.52687\n",
      "trainer/Policy mu Mean                 -0.0653692\n",
      "trainer/Policy mu Std                   0.790388\n",
      "trainer/Policy log std Mean            -3.31527\n",
      "trainer/Policy log std Std              0.515973\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        236061\n",
      "exploration/num paths total           394\n",
      "evaluation/num steps total         323922\n",
      "evaluation/num paths total            484\n",
      "evaluation/path length Mean           990\n",
      "evaluation/path length Std             30\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            900\n",
      "evaluation/Rewards Mean                 4.31323\n",
      "evaluation/Rewards Std                  0.833254\n",
      "evaluation/Rewards Max                  6.30745\n",
      "evaluation/Rewards Min                 -1.86461\n",
      "evaluation/Returns Mean              4270.09\n",
      "evaluation/Returns Std                130.539\n",
      "evaluation/Returns Max               4407.5\n",
      "evaluation/Returns Min               3934.72\n",
      "evaluation/Estimation Bias Mean       271.328\n",
      "evaluation/Estimation Bias Std        121.204\n",
      "evaluation/EB/Q_True Mean              39.4566\n",
      "evaluation/EB/Q_True Std              120.887\n",
      "evaluation/EB/Q_Pred Mean             310.785\n",
      "evaluation/EB/Q_Pred Std                9.2462\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4270.09\n",
      "evaluation/Actions Mean                -0.0714955\n",
      "evaluation/Actions Std                  0.536976\n",
      "evaluation/Actions Max                  0.994321\n",
      "evaluation/Actions Min                 -0.998271\n",
      "time/backward_policy (s)                8.86502\n",
      "time/backward_zf1 (s)                  10.8145\n",
      "time/backward_zf2 (s)                  10.4262\n",
      "time/data sampling (s)                  1.41721\n",
      "time/data storing (s)                   0.0820363\n",
      "time/evaluation sampling (s)            3.85151\n",
      "time/exploration sampling (s)           1.61461\n",
      "time/logging (s)                        0.01343\n",
      "time/preback_alpha (s)                  0.00549626\n",
      "time/preback_policy (s)                 9.04953\n",
      "time/preback_start (s)                  0.688201\n",
      "time/preback_zf (s)                    28.6917\n",
      "time/saving (s)                         4.474e-06\n",
      "time/training (s)                      10.4978\n",
      "time/epoch (s)                         86.0172\n",
      "time/total (s)                       3865.15\n",
      "Epoch                                  45\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:21:20.254367 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 46 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 245000\n",
      "trainer/ZF1 Loss                       37.2804\n",
      "trainer/ZF2 Loss                       43.1284\n",
      "trainer/ZF Expert Reward                1.14652\n",
      "trainer/ZF Policy Reward                2.19738\n",
      "trainer/ZF CHI2 Term                   39.865\n",
      "trainer/Policy Loss                  -270.054\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               12.5556\n",
      "trainer/Policy Param Norm              33.1563\n",
      "trainer/Zf1 Grad Norm                 180.092\n",
      "trainer/Zf1 Param Norm                 76.1017\n",
      "trainer/Zf2 Grad Norm                 189.071\n",
      "trainer/Zf2 Param Norm                 77.03\n",
      "trainer/Z Expert Predictions Mean     306.362\n",
      "trainer/Z Expert Predictions Std        7.49236\n",
      "trainer/Z Expert Predictions Max      314.841\n",
      "trainer/Z Expert Predictions Min      262.868\n",
      "trainer/Z Policy Predictions Mean     269.332\n",
      "trainer/Z Policy Predictions Std       79.7684\n",
      "trainer/Z Policy Predictions Max      317.013\n",
      "trainer/Z Policy Predictions Min      -11.6779\n",
      "trainer/Z Expert Targets Mean         305.216\n",
      "trainer/Z Expert Targets Std            7.52339\n",
      "trainer/Z Expert Targets Max          313.996\n",
      "trainer/Z Expert Targets Min          262.562\n",
      "trainer/Z Policy Targets Mean         267.134\n",
      "trainer/Z Policy Targets Std           80.2296\n",
      "trainer/Z Policy Targets Max          314.44\n",
      "trainer/Z Policy Targets Min          -12.5843\n",
      "trainer/Log Pis Mean                   18.216\n",
      "trainer/Log Pis Std                     3.23258\n",
      "trainer/Policy mu Mean                 -0.083604\n",
      "trainer/Policy mu Std                   0.74782\n",
      "trainer/Policy log std Mean            -3.2571\n",
      "trainer/Policy log std Std              0.505535\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        240088\n",
      "exploration/num paths total           399\n",
      "evaluation/num steps total         333922\n",
      "evaluation/num paths total            494\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.16752\n",
      "evaluation/Rewards Std                  0.956357\n",
      "evaluation/Rewards Max                  6.4284\n",
      "evaluation/Rewards Min                 -1.7236\n",
      "evaluation/Returns Mean              4167.52\n",
      "evaluation/Returns Std                102.988\n",
      "evaluation/Returns Max               4366.27\n",
      "evaluation/Returns Min               3947.22\n",
      "evaluation/Estimation Bias Mean       267.556\n",
      "evaluation/Estimation Bias Std        121.765\n",
      "evaluation/EB/Q_True Mean              38.7622\n",
      "evaluation/EB/Q_True Std              119.888\n",
      "evaluation/EB/Q_Pred Mean             306.318\n",
      "evaluation/EB/Q_Pred Std               12.393\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4167.52\n",
      "evaluation/Actions Mean                -0.0533014\n",
      "evaluation/Actions Std                  0.525109\n",
      "evaluation/Actions Max                  0.99471\n",
      "evaluation/Actions Min                 -0.997142\n",
      "time/backward_policy (s)                8.64176\n",
      "time/backward_zf1 (s)                  10.5243\n",
      "time/backward_zf2 (s)                  10.2068\n",
      "time/data sampling (s)                  1.36385\n",
      "time/data storing (s)                   0.0809574\n",
      "time/evaluation sampling (s)            3.54078\n",
      "time/exploration sampling (s)           1.60078\n",
      "time/logging (s)                        0.0143261\n",
      "time/preback_alpha (s)                  0.00547791\n",
      "time/preback_policy (s)                 9.17349\n",
      "time/preback_start (s)                  0.678036\n",
      "time/preback_zf (s)                    28.6218\n",
      "time/saving (s)                         4.286e-06\n",
      "time/training (s)                      10.4797\n",
      "time/epoch (s)                         84.9321\n",
      "time/total (s)                       3950.08\n",
      "Epoch                                  46\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:22:41.824352 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 47 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 250000\n",
      "trainer/ZF1 Loss                        3.68064\n",
      "trainer/ZF2 Loss                        3.82384\n",
      "trainer/ZF Expert Reward                1.08338\n",
      "trainer/ZF Policy Reward                2.14604\n",
      "trainer/ZF CHI2 Term                    3.40814\n",
      "trainer/Policy Loss                  -272.909\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               16.984\n",
      "trainer/Policy Param Norm              33.331\n",
      "trainer/Zf1 Grad Norm                 146.941\n",
      "trainer/Zf1 Param Norm                 76.6021\n",
      "trainer/Zf2 Grad Norm                 154.532\n",
      "trainer/Zf2 Param Norm                 77.5309\n",
      "trainer/Z Expert Predictions Mean     307.848\n",
      "trainer/Z Expert Predictions Std        6.50324\n",
      "trainer/Z Expert Predictions Max      315.972\n",
      "trainer/Z Expert Predictions Min      261.99\n",
      "trainer/Z Policy Predictions Mean     271.848\n",
      "trainer/Z Policy Predictions Std       81.9945\n",
      "trainer/Z Policy Predictions Max      319.182\n",
      "trainer/Z Policy Predictions Min       -9.41268\n",
      "trainer/Z Expert Targets Mean         306.764\n",
      "trainer/Z Expert Targets Std            6.50046\n",
      "trainer/Z Expert Targets Max          315.423\n",
      "trainer/Z Expert Targets Min          261.044\n",
      "trainer/Z Policy Targets Mean         269.702\n",
      "trainer/Z Policy Targets Std           80.8762\n",
      "trainer/Z Policy Targets Max          314.969\n",
      "trainer/Z Policy Targets Min           -9.10359\n",
      "trainer/Log Pis Mean                   18.726\n",
      "trainer/Log Pis Std                     3.22717\n",
      "trainer/Policy mu Mean                 -0.0845419\n",
      "trainer/Policy mu Std                   0.769731\n",
      "trainer/Policy log std Mean            -3.26676\n",
      "trainer/Policy log std Std              0.532582\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        246088\n",
      "exploration/num paths total           405\n",
      "evaluation/num steps total         335977\n",
      "evaluation/num paths total            504\n",
      "evaluation/path length Mean           205.5\n",
      "evaluation/path length Std            135.75\n",
      "evaluation/path length Max            419\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 3.61799\n",
      "evaluation/Rewards Std                  1.1957\n",
      "evaluation/Rewards Max                  6.20523\n",
      "evaluation/Rewards Min                 -2.1306\n",
      "evaluation/Returns Mean               743.496\n",
      "evaluation/Returns Std                539.322\n",
      "evaluation/Returns Max               1723.64\n",
      "evaluation/Returns Min                 13.3606\n",
      "evaluation/Estimation Bias Mean       236.436\n",
      "evaluation/Estimation Bias Std        133.511\n",
      "evaluation/EB/Q_True Mean              61.0625\n",
      "evaluation/EB/Q_True Std              127.351\n",
      "evaluation/EB/Q_Pred Mean             297.499\n",
      "evaluation/EB/Q_Pred Std               23.7596\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            743.496\n",
      "evaluation/Actions Mean                -0.0587222\n",
      "evaluation/Actions Std                  0.518604\n",
      "evaluation/Actions Max                  0.998112\n",
      "evaluation/Actions Min                 -0.997326\n",
      "time/backward_policy (s)                8.02091\n",
      "time/backward_zf1 (s)                   9.79621\n",
      "time/backward_zf2 (s)                   9.47751\n",
      "time/data sampling (s)                  1.33737\n",
      "time/data storing (s)                   0.0802129\n",
      "time/evaluation sampling (s)            1.40914\n",
      "time/exploration sampling (s)           1.58584\n",
      "time/logging (s)                        0.00338485\n",
      "time/preback_alpha (s)                  0.00538413\n",
      "time/preback_policy (s)                 9.78779\n",
      "time/preback_start (s)                  0.671775\n",
      "time/preback_zf (s)                    28.4515\n",
      "time/saving (s)                         3.706e-06\n",
      "time/training (s)                      10.7313\n",
      "time/epoch (s)                         81.3582\n",
      "time/total (s)                       4031.44\n",
      "Epoch                                  47\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:24:05.527978 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 48 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 255000\n",
      "trainer/ZF1 Loss                        3.93924\n",
      "trainer/ZF2 Loss                        4.49499\n",
      "trainer/ZF Expert Reward                0.630363\n",
      "trainer/ZF Policy Reward                1.21663\n",
      "trainer/ZF CHI2 Term                    4.11323\n",
      "trainer/Policy Loss                  -281.895\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               15.0191\n",
      "trainer/Policy Param Norm              33.4914\n",
      "trainer/Zf1 Grad Norm                 171.026\n",
      "trainer/Zf1 Param Norm                 77.0772\n",
      "trainer/Zf2 Grad Norm                 139.199\n",
      "trainer/Zf2 Param Norm                 77.9915\n",
      "trainer/Z Expert Predictions Mean     306.361\n",
      "trainer/Z Expert Predictions Std        8.67295\n",
      "trainer/Z Expert Predictions Max      316.208\n",
      "trainer/Z Expert Predictions Min      260.385\n",
      "trainer/Z Policy Predictions Mean     280.588\n",
      "trainer/Z Policy Predictions Std       71.2447\n",
      "trainer/Z Policy Predictions Max      322.988\n",
      "trainer/Z Policy Predictions Min       -5.95622\n",
      "trainer/Z Expert Targets Mean         305.73\n",
      "trainer/Z Expert Targets Std            8.96277\n",
      "trainer/Z Expert Targets Max          315.904\n",
      "trainer/Z Expert Targets Min          251.001\n",
      "trainer/Z Policy Targets Mean         279.372\n",
      "trainer/Z Policy Targets Std           70.3083\n",
      "trainer/Z Policy Targets Max          316.793\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   18.677\n",
      "trainer/Log Pis Std                     3.15808\n",
      "trainer/Policy mu Mean                 -0.0730175\n",
      "trainer/Policy mu Std                   0.77966\n",
      "trainer/Policy log std Mean            -3.27362\n",
      "trainer/Policy log std Std              0.56159\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        250088\n",
      "exploration/num paths total           409\n",
      "evaluation/num steps total         342757\n",
      "evaluation/num paths total            516\n",
      "evaluation/path length Mean           565\n",
      "evaluation/path length Std            363.967\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             90\n",
      "evaluation/Rewards Mean                 4.16732\n",
      "evaluation/Rewards Std                  0.919082\n",
      "evaluation/Rewards Max                  6.20796\n",
      "evaluation/Rewards Min                 -1.76464\n",
      "evaluation/Returns Mean              2354.53\n",
      "evaluation/Returns Std               1573.96\n",
      "evaluation/Returns Max               4298.79\n",
      "evaluation/Returns Min                269.265\n",
      "evaluation/Estimation Bias Mean       251.431\n",
      "evaluation/Estimation Bias Std        145.163\n",
      "evaluation/EB/Q_True Mean              57.7919\n",
      "evaluation/EB/Q_True Std              143.379\n",
      "evaluation/EB/Q_Pred Mean             309.223\n",
      "evaluation/EB/Q_Pred Std               12.0343\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2354.53\n",
      "evaluation/Actions Mean                -0.0618813\n",
      "evaluation/Actions Std                  0.52411\n",
      "evaluation/Actions Max                  0.994826\n",
      "evaluation/Actions Min                 -0.994734\n",
      "time/backward_policy (s)                8.49889\n",
      "time/backward_zf1 (s)                  10.2622\n",
      "time/backward_zf2 (s)                  10.0088\n",
      "time/data sampling (s)                  1.30123\n",
      "time/data storing (s)                   0.0809067\n",
      "time/evaluation sampling (s)            3.52076\n",
      "time/exploration sampling (s)           1.60159\n",
      "time/logging (s)                        0.0108536\n",
      "time/preback_alpha (s)                  0.00538241\n",
      "time/preback_policy (s)                 9.01055\n",
      "time/preback_start (s)                  0.672987\n",
      "time/preback_zf (s)                    28.4146\n",
      "time/saving (s)                         6.21e-06\n",
      "time/training (s)                      10.122\n",
      "time/epoch (s)                         83.5108\n",
      "time/total (s)                       4114.95\n",
      "Epoch                                  48\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:25:30.699346 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 49 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 260000\n",
      "trainer/ZF1 Loss                        4.57842\n",
      "trainer/ZF2 Loss                        7.87726\n",
      "trainer/ZF Expert Reward                1.49459\n",
      "trainer/ZF Policy Reward                2.15449\n",
      "trainer/ZF CHI2 Term                    6.08867\n",
      "trainer/Policy Loss                  -270.887\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               23.7144\n",
      "trainer/Policy Param Norm              33.6301\n",
      "trainer/Zf1 Grad Norm                 211.124\n",
      "trainer/Zf1 Param Norm                 77.5701\n",
      "trainer/Zf2 Grad Norm                 541.07\n",
      "trainer/Zf2 Param Norm                 78.4924\n",
      "trainer/Z Expert Predictions Mean     307.312\n",
      "trainer/Z Expert Predictions Std        8.66116\n",
      "trainer/Z Expert Predictions Max      317.505\n",
      "trainer/Z Expert Predictions Min      253.517\n",
      "trainer/Z Policy Predictions Mean     270.227\n",
      "trainer/Z Policy Predictions Std       78.8681\n",
      "trainer/Z Policy Predictions Max      319.026\n",
      "trainer/Z Policy Predictions Min        0.87313\n",
      "trainer/Z Expert Targets Mean         305.817\n",
      "trainer/Z Expert Targets Std            8.8535\n",
      "trainer/Z Expert Targets Max          315.911\n",
      "trainer/Z Expert Targets Min          253.17\n",
      "trainer/Z Policy Targets Mean         268.072\n",
      "trainer/Z Policy Targets Std           77.5365\n",
      "trainer/Z Policy Targets Max          315.81\n",
      "trainer/Z Policy Targets Min           -0.545133\n",
      "trainer/Log Pis Mean                   18.6196\n",
      "trainer/Log Pis Std                     3.31253\n",
      "trainer/Policy mu Mean                 -0.0604185\n",
      "trainer/Policy mu Std                   0.768842\n",
      "trainer/Policy log std Mean            -3.29478\n",
      "trainer/Policy log std Std              0.550737\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        256479\n",
      "exploration/num paths total           417\n",
      "evaluation/num steps total         350813\n",
      "evaluation/num paths total            527\n",
      "evaluation/path length Mean           732.364\n",
      "evaluation/path length Std            288.644\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            205\n",
      "evaluation/Rewards Mean                 3.7325\n",
      "evaluation/Rewards Std                  1.55424\n",
      "evaluation/Rewards Max                  6.32276\n",
      "evaluation/Rewards Min                 -2.27033\n",
      "evaluation/Returns Mean              2733.55\n",
      "evaluation/Returns Std               1445.32\n",
      "evaluation/Returns Max               4394.39\n",
      "evaluation/Returns Min                289.661\n",
      "evaluation/Estimation Bias Mean       269.036\n",
      "evaluation/Estimation Bias Std        102.047\n",
      "evaluation/EB/Q_True Mean               2.74153\n",
      "evaluation/EB/Q_True Std                8.02714\n",
      "evaluation/EB/Q_Pred Mean             271.777\n",
      "evaluation/EB/Q_Pred Std              102.535\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2733.55\n",
      "evaluation/Actions Mean                -0.0500754\n",
      "evaluation/Actions Std                  0.519973\n",
      "evaluation/Actions Max                  0.999606\n",
      "evaluation/Actions Min                 -0.999427\n",
      "time/backward_policy (s)                8.31364\n",
      "time/backward_zf1 (s)                  10.1874\n",
      "time/backward_zf2 (s)                   9.80612\n",
      "time/data sampling (s)                  1.3939\n",
      "time/data storing (s)                   0.0824246\n",
      "time/evaluation sampling (s)            4.06693\n",
      "time/exploration sampling (s)           1.62032\n",
      "time/logging (s)                        0.0111856\n",
      "time/preback_alpha (s)                  0.0054369\n",
      "time/preback_policy (s)                 9.57287\n",
      "time/preback_start (s)                  0.683135\n",
      "time/preback_zf (s)                    28.5759\n",
      "time/saving (s)                         3.824e-06\n",
      "time/training (s)                      10.6489\n",
      "time/epoch (s)                         84.9682\n",
      "time/total (s)                       4199.93\n",
      "Epoch                                  49\n",
      "---------------------------------  --------------\n",
      "2024-10-19 01:26:54.286415 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 50 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 265000\n",
      "trainer/ZF1 Loss                        4.08663\n",
      "trainer/ZF2 Loss                        6.78639\n",
      "trainer/ZF Expert Reward                1.19116\n",
      "trainer/ZF Policy Reward                2.3175\n",
      "trainer/ZF CHI2 Term                    5.06573\n",
      "trainer/Policy Loss                  -278.129\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               19.4273\n",
      "trainer/Policy Param Norm              33.7597\n",
      "trainer/Zf1 Grad Norm                 160.544\n",
      "trainer/Zf1 Param Norm                 78.0635\n",
      "trainer/Zf2 Grad Norm                 736.875\n",
      "trainer/Zf2 Param Norm                 78.931\n",
      "trainer/Z Expert Predictions Mean     307.688\n",
      "trainer/Z Expert Predictions Std        8.31626\n",
      "trainer/Z Expert Predictions Max      317.489\n",
      "trainer/Z Expert Predictions Min      271.652\n",
      "trainer/Z Policy Predictions Mean     277.682\n",
      "trainer/Z Policy Predictions Std       77.0839\n",
      "trainer/Z Policy Predictions Max      320.129\n",
      "trainer/Z Policy Predictions Min       -7.82438\n",
      "trainer/Z Expert Targets Mean         306.497\n",
      "trainer/Z Expert Targets Std            8.51018\n",
      "trainer/Z Expert Targets Max          317.585\n",
      "trainer/Z Expert Targets Min          269.728\n",
      "trainer/Z Policy Targets Mean         275.364\n",
      "trainer/Z Policy Targets Std           75.4911\n",
      "trainer/Z Policy Targets Max          316.126\n",
      "trainer/Z Policy Targets Min           -6.92594\n",
      "trainer/Log Pis Mean                   19.0449\n",
      "trainer/Log Pis Std                     3.13967\n",
      "trainer/Policy mu Mean                 -0.0730652\n",
      "trainer/Policy mu Std                   0.746394\n",
      "trainer/Policy log std Mean            -3.33782\n",
      "trainer/Policy log std Std              0.532536\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        260784\n",
      "exploration/num paths total           424\n",
      "evaluation/num steps total         358823\n",
      "evaluation/num paths total            537\n",
      "evaluation/path length Mean           801\n",
      "evaluation/path length Std            305.962\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            272\n",
      "evaluation/Rewards Mean                 4.22779\n",
      "evaluation/Rewards Std                  1.13437\n",
      "evaluation/Rewards Max                  6.19706\n",
      "evaluation/Rewards Min                 -2.69057\n",
      "evaluation/Returns Mean              3386.46\n",
      "evaluation/Returns Std               1344.04\n",
      "evaluation/Returns Max               4427.19\n",
      "evaluation/Returns Min               1035.39\n",
      "evaluation/Estimation Bias Mean       266.494\n",
      "evaluation/Estimation Bias Std        128.663\n",
      "evaluation/EB/Q_True Mean              40.0757\n",
      "evaluation/EB/Q_True Std              125.028\n",
      "evaluation/EB/Q_Pred Mean             306.57\n",
      "evaluation/EB/Q_Pred Std               30.0924\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3386.46\n",
      "evaluation/Actions Mean                -0.0618635\n",
      "evaluation/Actions Std                  0.531583\n",
      "evaluation/Actions Max                  0.999917\n",
      "evaluation/Actions Min                 -0.999968\n",
      "time/backward_policy (s)                8.12743\n",
      "time/backward_zf1 (s)                   9.90623\n",
      "time/backward_zf2 (s)                   9.60132\n",
      "time/data sampling (s)                  1.3791\n",
      "time/data storing (s)                   0.0805489\n",
      "time/evaluation sampling (s)            3.52608\n",
      "time/exploration sampling (s)           1.58599\n",
      "time/logging (s)                        0.0112196\n",
      "time/preback_alpha (s)                  0.00541062\n",
      "time/preback_policy (s)                 9.54123\n",
      "time/preback_start (s)                  0.670805\n",
      "time/preback_zf (s)                    28.4595\n",
      "time/saving (s)                         3.589e-06\n",
      "time/training (s)                      10.4913\n",
      "time/epoch (s)                         83.3862\n",
      "time/total (s)                       4283.31\n",
      "Epoch                                  50\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:28:18.413226 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 51 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 270000\n",
      "trainer/ZF1 Loss                        6.79161\n",
      "trainer/ZF2 Loss                        6.68646\n",
      "trainer/ZF Expert Reward                0.841989\n",
      "trainer/ZF Policy Reward                2.5543\n",
      "trainer/ZF CHI2 Term                    6.06823\n",
      "trainer/Policy Loss                  -273.69\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               12.0436\n",
      "trainer/Policy Param Norm              33.8891\n",
      "trainer/Zf1 Grad Norm                 110.033\n",
      "trainer/Zf1 Param Norm                 78.555\n",
      "trainer/Zf2 Grad Norm                  85.5126\n",
      "trainer/Zf2 Param Norm                 79.3791\n",
      "trainer/Z Expert Predictions Mean     309.06\n",
      "trainer/Z Expert Predictions Std        5.4127\n",
      "trainer/Z Expert Predictions Max      318.003\n",
      "trainer/Z Expert Predictions Min      275.372\n",
      "trainer/Z Policy Predictions Mean     273.554\n",
      "trainer/Z Policy Predictions Std       82.3263\n",
      "trainer/Z Policy Predictions Max      318.992\n",
      "trainer/Z Policy Predictions Min      -12.0575\n",
      "trainer/Z Expert Targets Mean         308.218\n",
      "trainer/Z Expert Targets Std            5.53541\n",
      "trainer/Z Expert Targets Max          316.882\n",
      "trainer/Z Expert Targets Min          272.974\n",
      "trainer/Z Policy Targets Mean         271\n",
      "trainer/Z Policy Targets Std           82.3666\n",
      "trainer/Z Policy Targets Max          318.283\n",
      "trainer/Z Policy Targets Min          -16.014\n",
      "trainer/Log Pis Mean                   18.1611\n",
      "trainer/Log Pis Std                     3.31271\n",
      "trainer/Policy mu Mean                 -0.0869284\n",
      "trainer/Policy mu Std                   0.751343\n",
      "trainer/Policy log std Mean            -3.23909\n",
      "trainer/Policy log std Std              0.580224\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        264784\n",
      "exploration/num paths total           428\n",
      "evaluation/num steps total         368283\n",
      "evaluation/num paths total            547\n",
      "evaluation/path length Mean           946\n",
      "evaluation/path length Std            162\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            460\n",
      "evaluation/Rewards Mean                 4.21944\n",
      "evaluation/Rewards Std                  0.746304\n",
      "evaluation/Rewards Max                  6.01523\n",
      "evaluation/Rewards Min                 -1.66362\n",
      "evaluation/Returns Mean              3991.59\n",
      "evaluation/Returns Std                690.817\n",
      "evaluation/Returns Max               4317.35\n",
      "evaluation/Returns Min               1930.41\n",
      "evaluation/Estimation Bias Mean       272.226\n",
      "evaluation/Estimation Bias Std        122.247\n",
      "evaluation/EB/Q_True Mean              40.6469\n",
      "evaluation/EB/Q_True Std              121.367\n",
      "evaluation/EB/Q_Pred Mean             312.873\n",
      "evaluation/EB/Q_Pred Std                8.98552\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3991.59\n",
      "evaluation/Actions Mean                -0.0561909\n",
      "evaluation/Actions Std                  0.50424\n",
      "evaluation/Actions Max                  0.998228\n",
      "evaluation/Actions Min                 -0.992784\n",
      "time/backward_policy (s)                8.23131\n",
      "time/backward_zf1 (s)                  10.0084\n",
      "time/backward_zf2 (s)                   9.68445\n",
      "time/data sampling (s)                  1.40049\n",
      "time/data storing (s)                   0.0811519\n",
      "time/evaluation sampling (s)            3.80424\n",
      "time/exploration sampling (s)           1.59988\n",
      "time/logging (s)                        0.0127272\n",
      "time/preback_alpha (s)                  0.00541502\n",
      "time/preback_policy (s)                 9.46352\n",
      "time/preback_start (s)                  0.674326\n",
      "time/preback_zf (s)                    28.4845\n",
      "time/saving (s)                         4.564e-06\n",
      "time/training (s)                      10.4768\n",
      "time/epoch (s)                         83.9273\n",
      "time/total (s)                       4367.24\n",
      "Epoch                                  51\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:29:43.571929 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 52 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 275000\n",
      "trainer/ZF1 Loss                       12.01\n",
      "trainer/ZF2 Loss                       14.5591\n",
      "trainer/ZF Expert Reward                0.907446\n",
      "trainer/ZF Policy Reward                1.16098\n",
      "trainer/ZF CHI2 Term                   13.3452\n",
      "trainer/Policy Loss                  -268.715\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               29.9121\n",
      "trainer/Policy Param Norm              34.0291\n",
      "trainer/Zf1 Grad Norm                 974.851\n",
      "trainer/Zf1 Param Norm                 79.0172\n",
      "trainer/Zf2 Grad Norm                1023.44\n",
      "trainer/Zf2 Param Norm                 79.8332\n",
      "trainer/Z Expert Predictions Mean     308.246\n",
      "trainer/Z Expert Predictions Std        7.54031\n",
      "trainer/Z Expert Predictions Max      319.333\n",
      "trainer/Z Expert Predictions Min      261.072\n",
      "trainer/Z Policy Predictions Mean     266.71\n",
      "trainer/Z Policy Predictions Std       91.4244\n",
      "trainer/Z Policy Predictions Max      321.963\n",
      "trainer/Z Policy Predictions Min      -69.0865\n",
      "trainer/Z Expert Targets Mean         307.339\n",
      "trainer/Z Expert Targets Std            7.57972\n",
      "trainer/Z Expert Targets Max          317.54\n",
      "trainer/Z Expert Targets Min          257.705\n",
      "trainer/Z Policy Targets Mean         265.549\n",
      "trainer/Z Policy Targets Std           88.7848\n",
      "trainer/Z Policy Targets Max          316.571\n",
      "trainer/Z Policy Targets Min          -20.1381\n",
      "trainer/Log Pis Mean                   18.3426\n",
      "trainer/Log Pis Std                     3.49777\n",
      "trainer/Policy mu Mean                 -0.0735967\n",
      "trainer/Policy mu Std                   0.727015\n",
      "trainer/Policy log std Mean            -3.28361\n",
      "trainer/Policy log std Std              0.597321\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        271911\n",
      "exploration/num paths total           437\n",
      "evaluation/num steps total         377700\n",
      "evaluation/num paths total            557\n",
      "evaluation/path length Mean           941.7\n",
      "evaluation/path length Std            174.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            417\n",
      "evaluation/Rewards Mean                 4.25559\n",
      "evaluation/Rewards Std                  0.848721\n",
      "evaluation/Rewards Max                  6.4168\n",
      "evaluation/Rewards Min                 -2.38004\n",
      "evaluation/Returns Mean              4007.49\n",
      "evaluation/Returns Std                756.848\n",
      "evaluation/Returns Max               4338.85\n",
      "evaluation/Returns Min               1744.71\n",
      "evaluation/Estimation Bias Mean       269.425\n",
      "evaluation/Estimation Bias Std        126.578\n",
      "evaluation/EB/Q_True Mean              42.0453\n",
      "evaluation/EB/Q_True Std              125.361\n",
      "evaluation/EB/Q_Pred Mean             311.47\n",
      "evaluation/EB/Q_Pred Std               10.4316\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4007.49\n",
      "evaluation/Actions Mean                -0.0551914\n",
      "evaluation/Actions Std                  0.527194\n",
      "evaluation/Actions Max                  0.996834\n",
      "evaluation/Actions Min                 -0.99574\n",
      "time/backward_policy (s)                8.38334\n",
      "time/backward_zf1 (s)                  10.2538\n",
      "time/backward_zf2 (s)                   9.86601\n",
      "time/data sampling (s)                  1.48612\n",
      "time/data storing (s)                   0.0830203\n",
      "time/evaluation sampling (s)            3.63228\n",
      "time/exploration sampling (s)           1.63405\n",
      "time/logging (s)                        0.0136166\n",
      "time/preback_alpha (s)                  0.00550993\n",
      "time/preback_policy (s)                 9.51452\n",
      "time/preback_start (s)                  0.696445\n",
      "time/preback_zf (s)                    28.7276\n",
      "time/saving (s)                         4.638e-06\n",
      "time/training (s)                      10.656\n",
      "time/epoch (s)                         84.9523\n",
      "time/total (s)                       4452.2\n",
      "Epoch                                  52\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:31:08.988382 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 53 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 280000\n",
      "trainer/ZF1 Loss                        5.35328\n",
      "trainer/ZF2 Loss                        4.52188\n",
      "trainer/ZF Expert Reward                0.979897\n",
      "trainer/ZF Policy Reward                2.40217\n",
      "trainer/ZF CHI2 Term                    4.42007\n",
      "trainer/Policy Loss                  -282.7\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               14.8846\n",
      "trainer/Policy Param Norm              34.1834\n",
      "trainer/Zf1 Grad Norm                 145.902\n",
      "trainer/Zf1 Param Norm                 79.5512\n",
      "trainer/Zf2 Grad Norm                  90.5658\n",
      "trainer/Zf2 Param Norm                 80.3769\n",
      "trainer/Z Expert Predictions Mean     307.252\n",
      "trainer/Z Expert Predictions Std       20.53\n",
      "trainer/Z Expert Predictions Max      318.347\n",
      "trainer/Z Expert Predictions Min       -0.203674\n",
      "trainer/Z Policy Predictions Mean     282.303\n",
      "trainer/Z Policy Predictions Std       71.1056\n",
      "trainer/Z Policy Predictions Max      319.844\n",
      "trainer/Z Policy Predictions Min      -11.851\n",
      "trainer/Z Expert Targets Mean         306.272\n",
      "trainer/Z Expert Targets Std           20.4664\n",
      "trainer/Z Expert Targets Max          317.564\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         279.901\n",
      "trainer/Z Policy Targets Std           70.0923\n",
      "trainer/Z Policy Targets Max          316.888\n",
      "trainer/Z Policy Targets Min           -7.11988\n",
      "trainer/Log Pis Mean                   18.966\n",
      "trainer/Log Pis Std                     2.9124\n",
      "trainer/Policy mu Mean                 -0.0918424\n",
      "trainer/Policy mu Std                   0.782083\n",
      "trainer/Policy log std Mean            -3.30404\n",
      "trainer/Policy log std Std              0.600728\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        274484\n",
      "exploration/num paths total           440\n",
      "evaluation/num steps total         387700\n",
      "evaluation/num paths total            567\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.27771\n",
      "evaluation/Rewards Std                  0.829529\n",
      "evaluation/Rewards Max                  6.38873\n",
      "evaluation/Rewards Min                 -2.44149\n",
      "evaluation/Returns Mean              4277.71\n",
      "evaluation/Returns Std                102.842\n",
      "evaluation/Returns Max               4477.52\n",
      "evaluation/Returns Min               4095.35\n",
      "evaluation/Estimation Bias Mean       273.828\n",
      "evaluation/Estimation Bias Std        117.621\n",
      "evaluation/EB/Q_True Mean              38.2915\n",
      "evaluation/EB/Q_True Std              117.858\n",
      "evaluation/EB/Q_Pred Mean             312.119\n",
      "evaluation/EB/Q_Pred Std               10.6847\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4277.71\n",
      "evaluation/Actions Mean                -0.0765965\n",
      "evaluation/Actions Std                  0.511263\n",
      "evaluation/Actions Max                  0.998276\n",
      "evaluation/Actions Min                 -0.996446\n",
      "time/backward_policy (s)                8.74264\n",
      "time/backward_zf1 (s)                  10.6315\n",
      "time/backward_zf2 (s)                  10.3325\n",
      "time/data sampling (s)                  1.38703\n",
      "time/data storing (s)                   0.0825063\n",
      "time/evaluation sampling (s)            3.59751\n",
      "time/exploration sampling (s)           1.62245\n",
      "time/logging (s)                        0.012628\n",
      "time/preback_alpha (s)                  0.00547414\n",
      "time/preback_policy (s)                 9.05764\n",
      "time/preback_start (s)                  0.684865\n",
      "time/preback_zf (s)                    28.6436\n",
      "time/saving (s)                         4.21e-06\n",
      "time/training (s)                      10.4107\n",
      "time/epoch (s)                         85.211\n",
      "time/total (s)                       4537.41\n",
      "Epoch                                  53\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:32:32.945139 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 54 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 285000\n",
      "trainer/ZF1 Loss                        3.52249\n",
      "trainer/ZF2 Loss                        3.63904\n",
      "trainer/ZF Expert Reward                1.36748\n",
      "trainer/ZF Policy Reward                2.64883\n",
      "trainer/ZF CHI2 Term                    3.13173\n",
      "trainer/Policy Loss                  -285.818\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               12.821\n",
      "trainer/Policy Param Norm              34.3305\n",
      "trainer/Zf1 Grad Norm                  65.7354\n",
      "trainer/Zf1 Param Norm                 79.9867\n",
      "trainer/Zf2 Grad Norm                  74.8734\n",
      "trainer/Zf2 Param Norm                 80.8557\n",
      "trainer/Z Expert Predictions Mean     308.118\n",
      "trainer/Z Expert Predictions Std       19.8014\n",
      "trainer/Z Expert Predictions Max      317.869\n",
      "trainer/Z Expert Predictions Min        5.8243\n",
      "trainer/Z Policy Predictions Mean     285.496\n",
      "trainer/Z Policy Predictions Std       66.8028\n",
      "trainer/Z Policy Predictions Max      320.923\n",
      "trainer/Z Policy Predictions Min      -10.9607\n",
      "trainer/Z Expert Targets Mean         306.751\n",
      "trainer/Z Expert Targets Std           20.1903\n",
      "trainer/Z Expert Targets Max          316.294\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         282.847\n",
      "trainer/Z Policy Targets Std           65.5113\n",
      "trainer/Z Policy Targets Max          318.031\n",
      "trainer/Z Policy Targets Min          -10.7109\n",
      "trainer/Log Pis Mean                   18.8107\n",
      "trainer/Log Pis Std                     2.9431\n",
      "trainer/Policy mu Mean                 -0.118927\n",
      "trainer/Policy mu Std                   0.753106\n",
      "trainer/Policy log std Mean            -3.31168\n",
      "trainer/Policy log std Std              0.592243\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        281484\n",
      "exploration/num paths total           447\n",
      "evaluation/num steps total         397496\n",
      "evaluation/num paths total            577\n",
      "evaluation/path length Mean           979.6\n",
      "evaluation/path length Std             61.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            796\n",
      "evaluation/Rewards Mean                 4.26649\n",
      "evaluation/Rewards Std                  0.827437\n",
      "evaluation/Rewards Max                  6.43868\n",
      "evaluation/Rewards Min                 -2.22322\n",
      "evaluation/Returns Mean              4179.45\n",
      "evaluation/Returns Std                269.186\n",
      "evaluation/Returns Max               4352.37\n",
      "evaluation/Returns Min               3401.47\n",
      "evaluation/Estimation Bias Mean       272.386\n",
      "evaluation/Estimation Bias Std        122.08\n",
      "evaluation/EB/Q_True Mean              39.7845\n",
      "evaluation/EB/Q_True Std              121.05\n",
      "evaluation/EB/Q_Pred Mean             312.171\n",
      "evaluation/EB/Q_Pred Std                9.91621\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4179.45\n",
      "evaluation/Actions Mean                -0.0560897\n",
      "evaluation/Actions Std                  0.530507\n",
      "evaluation/Actions Max                  0.998095\n",
      "evaluation/Actions Min                 -0.997929\n",
      "time/backward_policy (s)                8.40252\n",
      "time/backward_zf1 (s)                  10.2131\n",
      "time/backward_zf2 (s)                   9.90253\n",
      "time/data sampling (s)                  1.35213\n",
      "time/data storing (s)                   0.0807433\n",
      "time/evaluation sampling (s)            3.44165\n",
      "time/exploration sampling (s)           1.59258\n",
      "time/logging (s)                        0.0136155\n",
      "time/preback_alpha (s)                  0.00539084\n",
      "time/preback_policy (s)                 9.25834\n",
      "time/preback_start (s)                  0.675631\n",
      "time/preback_zf (s)                    28.4656\n",
      "time/saving (s)                         4.838e-06\n",
      "time/training (s)                      10.3528\n",
      "time/epoch (s)                         83.7566\n",
      "time/total (s)                       4621.17\n",
      "Epoch                                  54\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:33:56.111327 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 55 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 290000\n",
      "trainer/ZF1 Loss                        3.22947\n",
      "trainer/ZF2 Loss                        5.36603\n",
      "trainer/ZF Expert Reward                1.03611\n",
      "trainer/ZF Policy Reward                2.06533\n",
      "trainer/ZF CHI2 Term                    3.97649\n",
      "trainer/Policy Loss                  -272.569\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               13.6544\n",
      "trainer/Policy Param Norm              34.4791\n",
      "trainer/Zf1 Grad Norm                  80.7922\n",
      "trainer/Zf1 Param Norm                 80.4463\n",
      "trainer/Zf2 Grad Norm                 491.884\n",
      "trainer/Zf2 Param Norm                 81.3226\n",
      "trainer/Z Expert Predictions Mean     307.546\n",
      "trainer/Z Expert Predictions Std        9.34684\n",
      "trainer/Z Expert Predictions Max      318.36\n",
      "trainer/Z Expert Predictions Min      256.423\n",
      "trainer/Z Policy Predictions Mean     271.016\n",
      "trainer/Z Policy Predictions Std       84.894\n",
      "trainer/Z Policy Predictions Max      320.028\n",
      "trainer/Z Policy Predictions Min       -8.2741\n",
      "trainer/Z Expert Targets Mean         306.51\n",
      "trainer/Z Expert Targets Std            9.36055\n",
      "trainer/Z Expert Targets Max          317.672\n",
      "trainer/Z Expert Targets Min          256.032\n",
      "trainer/Z Policy Targets Mean         268.951\n",
      "trainer/Z Policy Targets Std           83.5625\n",
      "trainer/Z Policy Targets Max          316.191\n",
      "trainer/Z Policy Targets Min           -8.49419\n",
      "trainer/Log Pis Mean                   18.8902\n",
      "trainer/Log Pis Std                     3.5816\n",
      "trainer/Policy mu Mean                 -0.0456449\n",
      "trainer/Policy mu Std                   0.796532\n",
      "trainer/Policy log std Mean            -3.27358\n",
      "trainer/Policy log std Std              0.586763\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        284933\n",
      "exploration/num paths total           451\n",
      "evaluation/num steps total         407496\n",
      "evaluation/num paths total            587\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.32334\n",
      "evaluation/Rewards Std                  0.804667\n",
      "evaluation/Rewards Max                  6.41193\n",
      "evaluation/Rewards Min                 -2.54376\n",
      "evaluation/Returns Mean              4323.34\n",
      "evaluation/Returns Std                 66.2084\n",
      "evaluation/Returns Max               4428.62\n",
      "evaluation/Returns Min               4228.94\n",
      "evaluation/Estimation Bias Mean       272.212\n",
      "evaluation/Estimation Bias Std        125.552\n",
      "evaluation/EB/Q_True Mean              40.5725\n",
      "evaluation/EB/Q_True Std              125.03\n",
      "evaluation/EB/Q_Pred Mean             312.784\n",
      "evaluation/EB/Q_Pred Std                9.9262\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4323.34\n",
      "evaluation/Actions Mean                -0.06221\n",
      "evaluation/Actions Std                  0.523121\n",
      "evaluation/Actions Max                  0.999428\n",
      "evaluation/Actions Min                 -0.998145\n",
      "time/backward_policy (s)                8.11438\n",
      "time/backward_zf1 (s)                   9.8776\n",
      "time/backward_zf2 (s)                   9.59542\n",
      "time/data sampling (s)                  1.33368\n",
      "time/data storing (s)                   0.0805525\n",
      "time/evaluation sampling (s)            3.32034\n",
      "time/exploration sampling (s)           1.57668\n",
      "time/logging (s)                        0.0128222\n",
      "time/preback_alpha (s)                  0.00534891\n",
      "time/preback_policy (s)                 9.51971\n",
      "time/preback_start (s)                  0.660851\n",
      "time/preback_zf (s)                    28.3779\n",
      "time/saving (s)                         3.672e-06\n",
      "time/training (s)                      10.4907\n",
      "time/epoch (s)                         82.966\n",
      "time/total (s)                       4704.14\n",
      "Epoch                                  55\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:35:20.526402 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 56 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 295000\n",
      "trainer/ZF1 Loss                        4.05033\n",
      "trainer/ZF2 Loss                        3.89632\n",
      "trainer/ZF Expert Reward                0.575938\n",
      "trainer/ZF Policy Reward                1.78615\n",
      "trainer/ZF CHI2 Term                    3.56138\n",
      "trainer/Policy Loss                  -280.772\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               13.6812\n",
      "trainer/Policy Param Norm              34.6301\n",
      "trainer/Zf1 Grad Norm                  94.234\n",
      "trainer/Zf1 Param Norm                 80.9237\n",
      "trainer/Zf2 Grad Norm                  75.9637\n",
      "trainer/Zf2 Param Norm                 81.7805\n",
      "trainer/Z Expert Predictions Mean     306.936\n",
      "trainer/Z Expert Predictions Std       20.6901\n",
      "trainer/Z Expert Predictions Max      318.241\n",
      "trainer/Z Expert Predictions Min       -2.15121\n",
      "trainer/Z Policy Predictions Mean     280.148\n",
      "trainer/Z Policy Predictions Std       66.1641\n",
      "trainer/Z Policy Predictions Max      319.214\n",
      "trainer/Z Policy Predictions Min       -5.50724\n",
      "trainer/Z Expert Targets Mean         306.36\n",
      "trainer/Z Expert Targets Std           20.5839\n",
      "trainer/Z Expert Targets Max          318.046\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         278.361\n",
      "trainer/Z Policy Targets Std           64.9222\n",
      "trainer/Z Policy Targets Max          317.199\n",
      "trainer/Z Policy Targets Min           -5.29279\n",
      "trainer/Log Pis Mean                   19.1359\n",
      "trainer/Log Pis Std                     3.50451\n",
      "trainer/Policy mu Mean                 -0.0778152\n",
      "trainer/Policy mu Std                   0.830721\n",
      "trainer/Policy log std Mean            -3.27328\n",
      "trainer/Policy log std Std              0.616225\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        290630\n",
      "exploration/num paths total           457\n",
      "evaluation/num steps total         416322\n",
      "evaluation/num paths total            597\n",
      "evaluation/path length Mean           882.6\n",
      "evaluation/path length Std            196.587\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            401\n",
      "evaluation/Rewards Mean                 4.31545\n",
      "evaluation/Rewards Std                  0.827563\n",
      "evaluation/Rewards Max                  6.50483\n",
      "evaluation/Rewards Min                 -2.39043\n",
      "evaluation/Returns Mean              3808.81\n",
      "evaluation/Returns Std                847.258\n",
      "evaluation/Returns Max               4411.87\n",
      "evaluation/Returns Min               1761.84\n",
      "evaluation/Estimation Bias Mean       269.383\n",
      "evaluation/Estimation Bias Std        125.961\n",
      "evaluation/EB/Q_True Mean              43.6378\n",
      "evaluation/EB/Q_True Std              125.676\n",
      "evaluation/EB/Q_Pred Mean             313.021\n",
      "evaluation/EB/Q_Pred Std               10.5659\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3808.81\n",
      "evaluation/Actions Mean                -0.064864\n",
      "evaluation/Actions Std                  0.519613\n",
      "evaluation/Actions Max                  0.999769\n",
      "evaluation/Actions Min                 -0.998896\n",
      "time/backward_policy (s)                8.64087\n",
      "time/backward_zf1 (s)                  10.4303\n",
      "time/backward_zf2 (s)                  10.1726\n",
      "time/data sampling (s)                  1.33693\n",
      "time/data storing (s)                   0.080242\n",
      "time/evaluation sampling (s)            3.90663\n",
      "time/exploration sampling (s)           1.5838\n",
      "time/logging (s)                        0.0113326\n",
      "time/preback_alpha (s)                  0.00538681\n",
      "time/preback_policy (s)                 8.86016\n",
      "time/preback_start (s)                  0.671282\n",
      "time/preback_zf (s)                    28.448\n",
      "time/saving (s)                         3.689e-06\n",
      "time/training (s)                      10.0635\n",
      "time/epoch (s)                         84.211\n",
      "time/total (s)                       4788.35\n",
      "Epoch                                  56\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:36:46.367262 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 57 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 300000\n",
      "trainer/ZF1 Loss                        3.98714\n",
      "trainer/ZF2 Loss                        5.31795\n",
      "trainer/ZF Expert Reward                1.40834\n",
      "trainer/ZF Policy Reward                2.62644\n",
      "trainer/ZF CHI2 Term                    4.23662\n",
      "trainer/Policy Loss                  -276.29\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               15.0906\n",
      "trainer/Policy Param Norm              34.7613\n",
      "trainer/Zf1 Grad Norm                  74.1129\n",
      "trainer/Zf1 Param Norm                 81.4369\n",
      "trainer/Zf2 Grad Norm                 112.244\n",
      "trainer/Zf2 Param Norm                 82.3234\n",
      "trainer/Z Expert Predictions Mean     308.352\n",
      "trainer/Z Expert Predictions Std        7.85114\n",
      "trainer/Z Expert Predictions Max      318.922\n",
      "trainer/Z Expert Predictions Min      257.716\n",
      "trainer/Z Policy Predictions Mean     275.736\n",
      "trainer/Z Policy Predictions Std       76.1071\n",
      "trainer/Z Policy Predictions Max      322.06\n",
      "trainer/Z Policy Predictions Min        3.36761\n",
      "trainer/Z Expert Targets Mean         306.944\n",
      "trainer/Z Expert Targets Std            8.0787\n",
      "trainer/Z Expert Targets Max          318.14\n",
      "trainer/Z Expert Targets Min          256.87\n",
      "trainer/Z Policy Targets Mean         273.109\n",
      "trainer/Z Policy Targets Std           75.345\n",
      "trainer/Z Policy Targets Max          317.788\n",
      "trainer/Z Policy Targets Min            3.7397\n",
      "trainer/Log Pis Mean                   18.8806\n",
      "trainer/Log Pis Std                     3.40638\n",
      "trainer/Policy mu Mean                 -0.0630756\n",
      "trainer/Policy mu Std                   0.756929\n",
      "trainer/Policy log std Mean            -3.34005\n",
      "trainer/Policy log std Std              0.557816\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        294847\n",
      "exploration/num paths total           462\n",
      "evaluation/num steps total         426322\n",
      "evaluation/num paths total            607\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.37975\n",
      "evaluation/Rewards Std                  0.800947\n",
      "evaluation/Rewards Max                  6.54062\n",
      "evaluation/Rewards Min                 -2.44534\n",
      "evaluation/Returns Mean              4379.75\n",
      "evaluation/Returns Std                 54.8167\n",
      "evaluation/Returns Max               4447.08\n",
      "evaluation/Returns Min               4308.41\n",
      "evaluation/Estimation Bias Mean       273.814\n",
      "evaluation/Estimation Bias Std        123.1\n",
      "evaluation/EB/Q_True Mean              39.7653\n",
      "evaluation/EB/Q_True Std              122.642\n",
      "evaluation/EB/Q_Pred Mean             313.58\n",
      "evaluation/EB/Q_Pred Std                8.68215\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4379.75\n",
      "evaluation/Actions Mean                -0.0750387\n",
      "evaluation/Actions Std                  0.50455\n",
      "evaluation/Actions Max                  0.999034\n",
      "evaluation/Actions Min                 -0.998771\n",
      "time/backward_policy (s)                8.40164\n",
      "time/backward_zf1 (s)                  10.3233\n",
      "time/backward_zf2 (s)                   9.97849\n",
      "time/data sampling (s)                  1.4345\n",
      "time/data storing (s)                   0.0828232\n",
      "time/evaluation sampling (s)            3.76508\n",
      "time/exploration sampling (s)           1.61027\n",
      "time/logging (s)                        0.0142484\n",
      "time/preback_alpha (s)                  0.00551673\n",
      "time/preback_policy (s)                 9.68501\n",
      "time/preback_start (s)                  0.693212\n",
      "time/preback_zf (s)                    28.8416\n",
      "time/saving (s)                         5.363e-06\n",
      "time/training (s)                      10.7995\n",
      "time/epoch (s)                         85.6352\n",
      "time/total (s)                       4873.99\n",
      "Epoch                                  57\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:38:10.559317 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 58 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 305000\n",
      "trainer/ZF1 Loss                        4.20639\n",
      "trainer/ZF2 Loss                        4.76366\n",
      "trainer/ZF Expert Reward                0.947143\n",
      "trainer/ZF Policy Reward                2.09491\n",
      "trainer/ZF CHI2 Term                    4.10291\n",
      "trainer/Policy Loss                  -285.108\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               16.8652\n",
      "trainer/Policy Param Norm              34.8852\n",
      "trainer/Zf1 Grad Norm                 166.835\n",
      "trainer/Zf1 Param Norm                 81.9468\n",
      "trainer/Zf2 Grad Norm                 385.249\n",
      "trainer/Zf2 Param Norm                 82.8031\n",
      "trainer/Z Expert Predictions Mean     308.637\n",
      "trainer/Z Expert Predictions Std        6.22593\n",
      "trainer/Z Expert Predictions Max      317.76\n",
      "trainer/Z Expert Predictions Min      270.061\n",
      "trainer/Z Policy Predictions Mean     283.691\n",
      "trainer/Z Policy Predictions Std       67.3762\n",
      "trainer/Z Policy Predictions Max      320.541\n",
      "trainer/Z Policy Predictions Min        1.28172\n",
      "trainer/Z Expert Targets Mean         307.69\n",
      "trainer/Z Expert Targets Std            6.27516\n",
      "trainer/Z Expert Targets Max          317.979\n",
      "trainer/Z Expert Targets Min          270.079\n",
      "trainer/Z Policy Targets Mean         281.596\n",
      "trainer/Z Policy Targets Std           66.7603\n",
      "trainer/Z Policy Targets Max          317.682\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   19.0405\n",
      "trainer/Log Pis Std                     3.29266\n",
      "trainer/Policy mu Mean                 -0.0973892\n",
      "trainer/Policy mu Std                   0.781861\n",
      "trainer/Policy log std Mean            -3.32478\n",
      "trainer/Policy log std Std              0.596628\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        300764\n",
      "exploration/num paths total           468\n",
      "evaluation/num steps total         434251\n",
      "evaluation/num paths total            618\n",
      "evaluation/path length Mean           720.818\n",
      "evaluation/path length Std            419.787\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             24\n",
      "evaluation/Rewards Mean                 4.24815\n",
      "evaluation/Rewards Std                  0.915177\n",
      "evaluation/Rewards Max                  6.59175\n",
      "evaluation/Rewards Min                 -2.43963\n",
      "evaluation/Returns Mean              3062.15\n",
      "evaluation/Returns Std               1837.97\n",
      "evaluation/Returns Max               4356.65\n",
      "evaluation/Returns Min                 38.0274\n",
      "evaluation/Estimation Bias Mean       261.031\n",
      "evaluation/Estimation Bias Std        139.581\n",
      "evaluation/EB/Q_True Mean              50.3757\n",
      "evaluation/EB/Q_True Std              136.194\n",
      "evaluation/EB/Q_Pred Mean             311.406\n",
      "evaluation/EB/Q_Pred Std               13.9933\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3062.15\n",
      "evaluation/Actions Mean                -0.0671145\n",
      "evaluation/Actions Std                  0.527145\n",
      "evaluation/Actions Max                  0.999094\n",
      "evaluation/Actions Min                 -0.999023\n",
      "time/backward_policy (s)                8.33513\n",
      "time/backward_zf1 (s)                  10.1719\n",
      "time/backward_zf2 (s)                   9.80396\n",
      "time/data sampling (s)                  1.39821\n",
      "time/data storing (s)                   0.0833665\n",
      "time/evaluation sampling (s)            3.14073\n",
      "time/exploration sampling (s)           1.61477\n",
      "time/logging (s)                        0.0103154\n",
      "time/preback_alpha (s)                  0.00552123\n",
      "time/preback_policy (s)                 9.47344\n",
      "time/preback_start (s)                  0.689921\n",
      "time/preback_zf (s)                    28.6867\n",
      "time/saving (s)                         3.471e-06\n",
      "time/training (s)                      10.5682\n",
      "time/epoch (s)                         83.9821\n",
      "time/total (s)                       4957.97\n",
      "Epoch                                  58\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:39:36.722301 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 59 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 310000\n",
      "trainer/ZF1 Loss                        5.50404\n",
      "trainer/ZF2 Loss                        9.29279\n",
      "trainer/ZF Expert Reward                0.731768\n",
      "trainer/ZF Policy Reward                1.51533\n",
      "trainer/ZF CHI2 Term                    7.19732\n",
      "trainer/Policy Loss                  -281.142\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               30.0636\n",
      "trainer/Policy Param Norm              34.9987\n",
      "trainer/Zf1 Grad Norm                 578.365\n",
      "trainer/Zf1 Param Norm                 82.4223\n",
      "trainer/Zf2 Grad Norm                 984.771\n",
      "trainer/Zf2 Param Norm                 83.293\n",
      "trainer/Z Expert Predictions Mean     308.081\n",
      "trainer/Z Expert Predictions Std        9.55515\n",
      "trainer/Z Expert Predictions Max      319.132\n",
      "trainer/Z Expert Predictions Min      258.845\n",
      "trainer/Z Policy Predictions Mean     280.375\n",
      "trainer/Z Policy Predictions Std       71.0423\n",
      "trainer/Z Policy Predictions Max      320.535\n",
      "trainer/Z Policy Predictions Min        0.321926\n",
      "trainer/Z Expert Targets Mean         307.35\n",
      "trainer/Z Expert Targets Std            9.58168\n",
      "trainer/Z Expert Targets Max          318.53\n",
      "trainer/Z Expert Targets Min          256.779\n",
      "trainer/Z Policy Targets Mean         278.86\n",
      "trainer/Z Policy Targets Std           69.9403\n",
      "trainer/Z Policy Targets Max          319.24\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   18.5531\n",
      "trainer/Log Pis Std                     3.1546\n",
      "trainer/Policy mu Mean                 -0.0719508\n",
      "trainer/Policy mu Std                   0.78978\n",
      "trainer/Policy log std Mean            -3.26295\n",
      "trainer/Policy log std Std              0.589847\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        304574\n",
      "exploration/num paths total           472\n",
      "evaluation/num steps total         442996\n",
      "evaluation/num paths total            629\n",
      "evaluation/path length Mean           795\n",
      "evaluation/path length Std            241.604\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            395\n",
      "evaluation/Rewards Mean                 4.33595\n",
      "evaluation/Rewards Std                  0.895483\n",
      "evaluation/Rewards Max                  6.68607\n",
      "evaluation/Rewards Min                 -2.46314\n",
      "evaluation/Returns Mean              3447.08\n",
      "evaluation/Returns Std               1055.11\n",
      "evaluation/Returns Max               4459.86\n",
      "evaluation/Returns Min               1703.47\n",
      "evaluation/Estimation Bias Mean       267.596\n",
      "evaluation/Estimation Bias Std        130.998\n",
      "evaluation/EB/Q_True Mean              45.3215\n",
      "evaluation/EB/Q_True Std              129.73\n",
      "evaluation/EB/Q_Pred Mean             312.918\n",
      "evaluation/EB/Q_Pred Std               12.3567\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3447.08\n",
      "evaluation/Actions Mean                -0.0706693\n",
      "evaluation/Actions Std                  0.519015\n",
      "evaluation/Actions Max                  0.999546\n",
      "evaluation/Actions Min                 -0.999836\n",
      "time/backward_policy (s)                8.50665\n",
      "time/backward_zf1 (s)                  10.4772\n",
      "time/backward_zf2 (s)                   9.99919\n",
      "time/data sampling (s)                  1.48222\n",
      "time/data storing (s)                   0.0836228\n",
      "time/evaluation sampling (s)            3.77584\n",
      "time/exploration sampling (s)           1.62611\n",
      "time/logging (s)                        0.0174148\n",
      "time/preback_alpha (s)                  0.00559087\n",
      "time/preback_policy (s)                 9.57516\n",
      "time/preback_start (s)                  0.713802\n",
      "time/preback_zf (s)                    28.928\n",
      "time/saving (s)                         3.869e-06\n",
      "time/training (s)                      10.766\n",
      "time/epoch (s)                         85.9568\n",
      "time/total (s)                       5043.93\n",
      "Epoch                                  59\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:40:59.627292 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 60 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 315000\n",
      "trainer/ZF1 Loss                       97.8156\n",
      "trainer/ZF2 Loss                       97.7279\n",
      "trainer/ZF Expert Reward                1.09838\n",
      "trainer/ZF Policy Reward                3.68421\n",
      "trainer/ZF CHI2 Term                   96.6718\n",
      "trainer/Policy Loss                  -281.879\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               17.3389\n",
      "trainer/Policy Param Norm              35.1192\n",
      "trainer/Zf1 Grad Norm                 236.452\n",
      "trainer/Zf1 Param Norm                 82.9162\n",
      "trainer/Zf2 Grad Norm                 297.61\n",
      "trainer/Zf2 Param Norm                 83.7495\n",
      "trainer/Z Expert Predictions Mean     306.828\n",
      "trainer/Z Expert Predictions Std       21.0473\n",
      "trainer/Z Expert Predictions Max      317.472\n",
      "trainer/Z Expert Predictions Min        3.97686\n",
      "trainer/Z Policy Predictions Mean     281.447\n",
      "trainer/Z Policy Predictions Std       66.5531\n",
      "trainer/Z Policy Predictions Max      321.307\n",
      "trainer/Z Policy Predictions Min      -10.2874\n",
      "trainer/Z Expert Targets Mean         305.729\n",
      "trainer/Z Expert Targets Std           21.2277\n",
      "trainer/Z Expert Targets Max          317.118\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         277.763\n",
      "trainer/Z Policy Targets Std           67.6187\n",
      "trainer/Z Policy Targets Max          318.509\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   18.6382\n",
      "trainer/Log Pis Std                     3.24079\n",
      "trainer/Policy mu Mean                 -0.0795418\n",
      "trainer/Policy mu Std                   0.746319\n",
      "trainer/Policy log std Mean            -3.30091\n",
      "trainer/Policy log std Std              0.556472\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        310574\n",
      "exploration/num paths total           478\n",
      "evaluation/num steps total         452105\n",
      "evaluation/num paths total            639\n",
      "evaluation/path length Mean           910.9\n",
      "evaluation/path length Std            221.058\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            262\n",
      "evaluation/Rewards Mean                 4.32516\n",
      "evaluation/Rewards Std                  0.819924\n",
      "evaluation/Rewards Max                  6.46377\n",
      "evaluation/Rewards Min                 -2.25971\n",
      "evaluation/Returns Mean              3939.79\n",
      "evaluation/Returns Std                968.601\n",
      "evaluation/Returns Max               4442.4\n",
      "evaluation/Returns Min               1131.88\n",
      "evaluation/Estimation Bias Mean       271.23\n",
      "evaluation/Estimation Bias Std        130.145\n",
      "evaluation/EB/Q_True Mean              43.7943\n",
      "evaluation/EB/Q_True Std              128.402\n",
      "evaluation/EB/Q_Pred Mean             315.024\n",
      "evaluation/EB/Q_Pred Std               10.0149\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3939.79\n",
      "evaluation/Actions Mean                -0.0747155\n",
      "evaluation/Actions Std                  0.5222\n",
      "evaluation/Actions Max                  0.998799\n",
      "evaluation/Actions Min                 -0.999813\n",
      "time/backward_policy (s)                7.73459\n",
      "time/backward_zf1 (s)                   9.49932\n",
      "time/backward_zf2 (s)                   9.17939\n",
      "time/data sampling (s)                  1.40666\n",
      "time/data storing (s)                   0.0801936\n",
      "time/evaluation sampling (s)            3.54314\n",
      "time/exploration sampling (s)           1.59495\n",
      "time/logging (s)                        0.0115709\n",
      "time/preback_alpha (s)                  0.00537369\n",
      "time/preback_policy (s)                 9.92078\n",
      "time/preback_start (s)                  0.661431\n",
      "time/preback_zf (s)                    28.3706\n",
      "time/saving (s)                         3.771e-06\n",
      "time/training (s)                      10.6905\n",
      "time/epoch (s)                         82.6986\n",
      "time/total (s)                       5126.63\n",
      "Epoch                                  60\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:42:23.250335 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 61 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 320000\n",
      "trainer/ZF1 Loss                        4.98504\n",
      "trainer/ZF2 Loss                        5.31864\n",
      "trainer/ZF Expert Reward                1.07323\n",
      "trainer/ZF Policy Reward                2.35305\n",
      "trainer/ZF CHI2 Term                    4.70626\n",
      "trainer/Policy Loss                  -287.642\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               42.0976\n",
      "trainer/Policy Param Norm              35.2157\n",
      "trainer/Zf1 Grad Norm                 757.322\n",
      "trainer/Zf1 Param Norm                 83.4352\n",
      "trainer/Zf2 Grad Norm                 832.626\n",
      "trainer/Zf2 Param Norm                 84.2606\n",
      "trainer/Z Expert Predictions Mean     308.792\n",
      "trainer/Z Expert Predictions Std        8.72274\n",
      "trainer/Z Expert Predictions Max      319.612\n",
      "trainer/Z Expert Predictions Min      261.551\n",
      "trainer/Z Policy Predictions Mean     287.249\n",
      "trainer/Z Policy Predictions Std       62.4206\n",
      "trainer/Z Policy Predictions Max      320.792\n",
      "trainer/Z Policy Predictions Min        0.810251\n",
      "trainer/Z Expert Targets Mean         307.719\n",
      "trainer/Z Expert Targets Std            8.85884\n",
      "trainer/Z Expert Targets Max          318.564\n",
      "trainer/Z Expert Targets Min          260.876\n",
      "trainer/Z Policy Targets Mean         284.896\n",
      "trainer/Z Policy Targets Std           61.4459\n",
      "trainer/Z Policy Targets Max          317.828\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   19.36\n",
      "trainer/Log Pis Std                     2.98518\n",
      "trainer/Policy mu Mean                 -0.0870283\n",
      "trainer/Policy mu Std                   0.740889\n",
      "trainer/Policy log std Mean            -3.36796\n",
      "trainer/Policy log std Std              0.590606\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        314487\n",
      "exploration/num paths total           484\n",
      "evaluation/num steps total         462105\n",
      "evaluation/num paths total            649\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.22916\n",
      "evaluation/Rewards Std                  0.843457\n",
      "evaluation/Rewards Max                  6.46036\n",
      "evaluation/Rewards Min                 -1.7978\n",
      "evaluation/Returns Mean              4229.16\n",
      "evaluation/Returns Std                 80.8812\n",
      "evaluation/Returns Max               4325.19\n",
      "evaluation/Returns Min               4021.69\n",
      "evaluation/Estimation Bias Mean       274.289\n",
      "evaluation/Estimation Bias Std        117.967\n",
      "evaluation/EB/Q_True Mean              38.2314\n",
      "evaluation/EB/Q_True Std              117.837\n",
      "evaluation/EB/Q_Pred Mean             312.521\n",
      "evaluation/EB/Q_Pred Std                9.88606\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4229.16\n",
      "evaluation/Actions Mean                -0.0472452\n",
      "evaluation/Actions Std                  0.525354\n",
      "evaluation/Actions Max                  0.998896\n",
      "evaluation/Actions Min                 -0.998167\n",
      "time/backward_policy (s)                8.28273\n",
      "time/backward_zf1 (s)                  10.0524\n",
      "time/backward_zf2 (s)                   9.78301\n",
      "time/data sampling (s)                  1.36195\n",
      "time/data storing (s)                   0.0805556\n",
      "time/evaluation sampling (s)            3.78354\n",
      "time/exploration sampling (s)           1.57331\n",
      "time/logging (s)                        0.0121544\n",
      "time/preback_alpha (s)                  0.00534592\n",
      "time/preback_policy (s)                 9.20583\n",
      "time/preback_start (s)                  0.659052\n",
      "time/preback_zf (s)                    28.3736\n",
      "time/saving (s)                         3.438e-06\n",
      "time/training (s)                      10.2495\n",
      "time/epoch (s)                         83.4229\n",
      "time/total (s)                       5210.06\n",
      "Epoch                                  61\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:43:48.312942 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 62 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 325000\n",
      "trainer/ZF1 Loss                        5.28579\n",
      "trainer/ZF2 Loss                        4.98883\n",
      "trainer/ZF Expert Reward                1.49665\n",
      "trainer/ZF Policy Reward                2.72854\n",
      "trainer/ZF CHI2 Term                    4.71644\n",
      "trainer/Policy Loss                  -286.147\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               16.6072\n",
      "trainer/Policy Param Norm              35.332\n",
      "trainer/Zf1 Grad Norm                 169.806\n",
      "trainer/Zf1 Param Norm                 83.9185\n",
      "trainer/Zf2 Grad Norm                 147.325\n",
      "trainer/Zf2 Param Norm                 84.7659\n",
      "trainer/Z Expert Predictions Mean     310.288\n",
      "trainer/Z Expert Predictions Std        7.85482\n",
      "trainer/Z Expert Predictions Max      320.903\n",
      "trainer/Z Expert Predictions Min      256.343\n",
      "trainer/Z Policy Predictions Mean     285.858\n",
      "trainer/Z Policy Predictions Std       64.5826\n",
      "trainer/Z Policy Predictions Max      323.626\n",
      "trainer/Z Policy Predictions Min        2.7167\n",
      "trainer/Z Expert Targets Mean         308.792\n",
      "trainer/Z Expert Targets Std            7.59708\n",
      "trainer/Z Expert Targets Max          319.329\n",
      "trainer/Z Expert Targets Min          255.281\n",
      "trainer/Z Policy Targets Mean         283.129\n",
      "trainer/Z Policy Targets Std           63.2577\n",
      "trainer/Z Policy Targets Max          319.03\n",
      "trainer/Z Policy Targets Min            2.35015\n",
      "trainer/Log Pis Mean                   19.0523\n",
      "trainer/Log Pis Std                     2.93229\n",
      "trainer/Policy mu Mean                 -0.0756546\n",
      "trainer/Policy mu Std                   0.777476\n",
      "trainer/Policy log std Mean            -3.32484\n",
      "trainer/Policy log std Std              0.565134\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        319463\n",
      "exploration/num paths total           489\n",
      "evaluation/num steps total         470634\n",
      "evaluation/num paths total            659\n",
      "evaluation/path length Mean           852.9\n",
      "evaluation/path length Std            231.563\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            388\n",
      "evaluation/Rewards Mean                 4.32604\n",
      "evaluation/Rewards Std                  0.845277\n",
      "evaluation/Rewards Max                  6.53529\n",
      "evaluation/Rewards Min                 -1.72513\n",
      "evaluation/Returns Mean              3689.68\n",
      "evaluation/Returns Std               1018.38\n",
      "evaluation/Returns Max               4419.7\n",
      "evaluation/Returns Min               1614.18\n",
      "evaluation/Estimation Bias Mean       269.185\n",
      "evaluation/Estimation Bias Std        129.517\n",
      "evaluation/EB/Q_True Mean              45.5745\n",
      "evaluation/EB/Q_True Std              128.414\n",
      "evaluation/EB/Q_Pred Mean             314.759\n",
      "evaluation/EB/Q_Pred Std               10.2285\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3689.68\n",
      "evaluation/Actions Mean                -0.076599\n",
      "evaluation/Actions Std                  0.519861\n",
      "evaluation/Actions Max                  0.996762\n",
      "evaluation/Actions Min                 -0.998757\n",
      "time/backward_policy (s)                8.26646\n",
      "time/backward_zf1 (s)                  10.1441\n",
      "time/backward_zf2 (s)                   9.77646\n",
      "time/data sampling (s)                  1.39828\n",
      "time/data storing (s)                   0.0828708\n",
      "time/evaluation sampling (s)            3.63618\n",
      "time/exploration sampling (s)           1.60543\n",
      "time/logging (s)                        0.013464\n",
      "time/preback_alpha (s)                  0.0054518\n",
      "time/preback_policy (s)                 9.70985\n",
      "time/preback_start (s)                  0.691042\n",
      "time/preback_zf (s)                    28.736\n",
      "time/saving (s)                         6.69499e-06\n",
      "time/training (s)                      10.7927\n",
      "time/epoch (s)                         84.8583\n",
      "time/total (s)                       5294.92\n",
      "Epoch                                  62\n",
      "---------------------------------  ----------------\n",
      "2024-10-19 01:45:12.902285 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 63 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 330000\n",
      "trainer/ZF1 Loss                        4.52444\n",
      "trainer/ZF2 Loss                        3.94193\n",
      "trainer/ZF Expert Reward                0.890983\n",
      "trainer/ZF Policy Reward                2.0792\n",
      "trainer/ZF CHI2 Term                    3.832\n",
      "trainer/Policy Loss                  -283.797\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               14.8767\n",
      "trainer/Policy Param Norm              35.4501\n",
      "trainer/Zf1 Grad Norm                 299.757\n",
      "trainer/Zf1 Param Norm                 84.4004\n",
      "trainer/Zf2 Grad Norm                 256.253\n",
      "trainer/Zf2 Param Norm                 85.2379\n",
      "trainer/Z Expert Predictions Mean     310.397\n",
      "trainer/Z Expert Predictions Std        6.90843\n",
      "trainer/Z Expert Predictions Max      320.735\n",
      "trainer/Z Expert Predictions Min      278.932\n",
      "trainer/Z Policy Predictions Mean     283.251\n",
      "trainer/Z Policy Predictions Std       74.443\n",
      "trainer/Z Policy Predictions Max      323.291\n",
      "trainer/Z Policy Predictions Min       -4.38072\n",
      "trainer/Z Expert Targets Mean         309.506\n",
      "trainer/Z Expert Targets Std            6.61199\n",
      "trainer/Z Expert Targets Max          319.992\n",
      "trainer/Z Expert Targets Min          277.651\n",
      "trainer/Z Policy Targets Mean         281.172\n",
      "trainer/Z Policy Targets Std           73.0342\n",
      "trainer/Z Policy Targets Max          320.512\n",
      "trainer/Z Policy Targets Min            0.547188\n",
      "trainer/Log Pis Mean                   18.8145\n",
      "trainer/Log Pis Std                     3.10688\n",
      "trainer/Policy mu Mean                 -0.0779285\n",
      "trainer/Policy mu Std                   0.775626\n",
      "trainer/Policy log std Mean            -3.29611\n",
      "trainer/Policy log std Std              0.620135\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        325724\n",
      "exploration/num paths total           497\n",
      "evaluation/num steps total         480564\n",
      "evaluation/num paths total            669\n",
      "evaluation/path length Mean           993\n",
      "evaluation/path length Std             21\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            930\n",
      "evaluation/Rewards Mean                 4.41787\n",
      "evaluation/Rewards Std                  0.829794\n",
      "evaluation/Rewards Max                  6.63515\n",
      "evaluation/Rewards Min                 -2.1137\n",
      "evaluation/Returns Mean              4386.94\n",
      "evaluation/Returns Std                114.594\n",
      "evaluation/Returns Max               4577.24\n",
      "evaluation/Returns Min               4166.73\n",
      "evaluation/Estimation Bias Mean       275.614\n",
      "evaluation/Estimation Bias Std        122.843\n",
      "evaluation/EB/Q_True Mean              39.8766\n",
      "evaluation/EB/Q_True Std              122.675\n",
      "evaluation/EB/Q_Pred Mean             315.491\n",
      "evaluation/EB/Q_Pred Std                8.69544\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4386.94\n",
      "evaluation/Actions Mean                -0.067064\n",
      "evaluation/Actions Std                  0.517773\n",
      "evaluation/Actions Max                  0.995714\n",
      "evaluation/Actions Min                 -0.997734\n",
      "time/backward_policy (s)                8.48758\n",
      "time/backward_zf1 (s)                  10.3665\n",
      "time/backward_zf2 (s)                  10.0205\n",
      "time/data sampling (s)                  1.41947\n",
      "time/data storing (s)                   0.0826254\n",
      "time/evaluation sampling (s)            3.2544\n",
      "time/exploration sampling (s)           1.61377\n",
      "time/logging (s)                        0.0198496\n",
      "time/preback_alpha (s)                  0.00545264\n",
      "time/preback_policy (s)                 9.33202\n",
      "time/preback_start (s)                  0.683736\n",
      "time/preback_zf (s)                    28.6851\n",
      "time/saving (s)                         4.595e-06\n",
      "time/training (s)                      10.4191\n",
      "time/epoch (s)                         84.3901\n",
      "time/total (s)                       5379.31\n",
      "Epoch                                  63\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:46:37.884842 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 64 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 335000\n",
      "trainer/ZF1 Loss                       98.4532\n",
      "trainer/ZF2 Loss                      118.983\n",
      "trainer/ZF Expert Reward                0.565561\n",
      "trainer/ZF Policy Reward                3.94806\n",
      "trainer/ZF CHI2 Term                  107.22\n",
      "trainer/Policy Loss                  -289.077\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               22.1055\n",
      "trainer/Policy Param Norm              35.5826\n",
      "trainer/Zf1 Grad Norm                 318.004\n",
      "trainer/Zf1 Param Norm                 84.8587\n",
      "trainer/Zf2 Grad Norm                 736.641\n",
      "trainer/Zf2 Param Norm                 85.721\n",
      "trainer/Z Expert Predictions Mean     310.222\n",
      "trainer/Z Expert Predictions Std        7.81661\n",
      "trainer/Z Expert Predictions Max      320.256\n",
      "trainer/Z Expert Predictions Min      239.81\n",
      "trainer/Z Policy Predictions Mean     288.136\n",
      "trainer/Z Policy Predictions Std       61.601\n",
      "trainer/Z Policy Predictions Max      321.769\n",
      "trainer/Z Policy Predictions Min        9.22394\n",
      "trainer/Z Expert Targets Mean         309.656\n",
      "trainer/Z Expert Targets Std            8.05275\n",
      "trainer/Z Expert Targets Max          319.504\n",
      "trainer/Z Expert Targets Min          237.074\n",
      "trainer/Z Policy Targets Mean         284.188\n",
      "trainer/Z Policy Targets Std           65.462\n",
      "trainer/Z Policy Targets Max          326.13\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   18.9142\n",
      "trainer/Log Pis Std                     3.20715\n",
      "trainer/Policy mu Mean                 -0.0757673\n",
      "trainer/Policy mu Std                   0.712159\n",
      "trainer/Policy log std Mean            -3.33987\n",
      "trainer/Policy log std Std              0.550612\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        329283\n",
      "exploration/num paths total           501\n",
      "evaluation/num steps total         489836\n",
      "evaluation/num paths total            679\n",
      "evaluation/path length Mean           927.2\n",
      "evaluation/path length Std            218.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            272\n",
      "evaluation/Rewards Mean                 3.39877\n",
      "evaluation/Rewards Std                  2.07873\n",
      "evaluation/Rewards Max                  6.73588\n",
      "evaluation/Rewards Min                 -3.96886\n",
      "evaluation/Returns Mean              3151.34\n",
      "evaluation/Returns Std               1709.48\n",
      "evaluation/Returns Max               4328.24\n",
      "evaluation/Returns Min               -451.713\n",
      "evaluation/Estimation Bias Mean       232.142\n",
      "evaluation/Estimation Bias Std        146.641\n",
      "evaluation/EB/Q_True Mean              42.5868\n",
      "evaluation/EB/Q_True Std              125.607\n",
      "evaluation/EB/Q_Pred Mean             274.729\n",
      "evaluation/EB/Q_Pred Std               94.0111\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3151.34\n",
      "evaluation/Actions Mean                -0.0439066\n",
      "evaluation/Actions Std                  0.573876\n",
      "evaluation/Actions Max                  0.999981\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                8.56969\n",
      "time/backward_zf1 (s)                  10.3848\n",
      "time/backward_zf2 (s)                  10.0721\n",
      "time/data sampling (s)                  1.36457\n",
      "time/data storing (s)                   0.0823385\n",
      "time/evaluation sampling (s)            3.93844\n",
      "time/exploration sampling (s)           1.60274\n",
      "time/logging (s)                        0.0128472\n",
      "time/preback_alpha (s)                  0.00546138\n",
      "time/preback_policy (s)                 9.14788\n",
      "time/preback_start (s)                  0.677908\n",
      "time/preback_zf (s)                    28.5765\n",
      "time/saving (s)                         3.869e-06\n",
      "time/training (s)                      10.3348\n",
      "time/epoch (s)                         84.7701\n",
      "time/total (s)                       5464.08\n",
      "Epoch                                  64\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:48:02.627561 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 65 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 340000\n",
      "trainer/ZF1 Loss                       96.536\n",
      "trainer/ZF2 Loss                       96.0634\n",
      "trainer/ZF Expert Reward                0.998295\n",
      "trainer/ZF Policy Reward                3.476\n",
      "trainer/ZF CHI2 Term                   95.2592\n",
      "trainer/Policy Loss                  -285.657\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               15.8561\n",
      "trainer/Policy Param Norm              35.7061\n",
      "trainer/Zf1 Grad Norm                 153.703\n",
      "trainer/Zf1 Param Norm                 85.3329\n",
      "trainer/Zf2 Grad Norm                 154.321\n",
      "trainer/Zf2 Param Norm                 86.1971\n",
      "trainer/Z Expert Predictions Mean     310.398\n",
      "trainer/Z Expert Predictions Std       10.5591\n",
      "trainer/Z Expert Predictions Max      321.244\n",
      "trainer/Z Expert Predictions Min      235.632\n",
      "trainer/Z Policy Predictions Mean     285.613\n",
      "trainer/Z Policy Predictions Std       67.5011\n",
      "trainer/Z Policy Predictions Max      322.686\n",
      "trainer/Z Policy Predictions Min       -3.47332\n",
      "trainer/Z Expert Targets Mean         309.399\n",
      "trainer/Z Expert Targets Std           10.7172\n",
      "trainer/Z Expert Targets Max          321.328\n",
      "trainer/Z Expert Targets Min          223.554\n",
      "trainer/Z Policy Targets Mean         282.137\n",
      "trainer/Z Policy Targets Std           68.6742\n",
      "trainer/Z Policy Targets Max          319.992\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   19.4327\n",
      "trainer/Log Pis Std                     3.27248\n",
      "trainer/Policy mu Mean                 -0.0998136\n",
      "trainer/Policy mu Std                   0.840607\n",
      "trainer/Policy log std Mean            -3.27538\n",
      "trainer/Policy log std Std              0.65378\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        335303\n",
      "exploration/num paths total           508\n",
      "evaluation/num steps total         496585\n",
      "evaluation/num paths total            692\n",
      "evaluation/path length Mean           519.154\n",
      "evaluation/path length Std            358.448\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             55\n",
      "evaluation/Rewards Mean                 4.14374\n",
      "evaluation/Rewards Std                  1.05223\n",
      "evaluation/Rewards Max                  6.54138\n",
      "evaluation/Rewards Min                 -1.96537\n",
      "evaluation/Returns Mean              2151.24\n",
      "evaluation/Returns Std               1559.67\n",
      "evaluation/Returns Max               4389.37\n",
      "evaluation/Returns Min                155.79\n",
      "evaluation/Estimation Bias Mean       256.034\n",
      "evaluation/Estimation Bias Std        141.177\n",
      "evaluation/EB/Q_True Mean              56.151\n",
      "evaluation/EB/Q_True Std              138.415\n",
      "evaluation/EB/Q_Pred Mean             312.185\n",
      "evaluation/EB/Q_Pred Std               17.4312\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2151.24\n",
      "evaluation/Actions Mean                -0.0779256\n",
      "evaluation/Actions Std                  0.513368\n",
      "evaluation/Actions Max                  0.995741\n",
      "evaluation/Actions Min                 -0.998819\n",
      "time/backward_policy (s)                8.49552\n",
      "time/backward_zf1 (s)                  10.3733\n",
      "time/backward_zf2 (s)                  10.0069\n",
      "time/data sampling (s)                  1.40123\n",
      "time/data storing (s)                   0.0824685\n",
      "time/evaluation sampling (s)            3.524\n",
      "time/exploration sampling (s)           1.63205\n",
      "time/logging (s)                        0.0158166\n",
      "time/preback_alpha (s)                  0.00544662\n",
      "time/preback_policy (s)                 9.317\n",
      "time/preback_start (s)                  0.68094\n",
      "time/preback_zf (s)                    28.557\n",
      "time/saving (s)                         5.931e-06\n",
      "time/training (s)                      10.4508\n",
      "time/epoch (s)                         84.5425\n",
      "time/total (s)                       5548.63\n",
      "Epoch                                  65\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:49:29.394962 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 66 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 345000\n",
      "trainer/ZF1 Loss                      195.541\n",
      "trainer/ZF2 Loss                      197.766\n",
      "trainer/ZF Expert Reward                0.778035\n",
      "trainer/ZF Policy Reward                4.62726\n",
      "trainer/ZF CHI2 Term                  194.925\n",
      "trainer/Policy Loss                  -284.959\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               13.7069\n",
      "trainer/Policy Param Norm              35.8224\n",
      "trainer/Zf1 Grad Norm                 171.273\n",
      "trainer/Zf1 Param Norm                 85.8307\n",
      "trainer/Zf2 Grad Norm                 173.867\n",
      "trainer/Zf2 Param Norm                 86.6609\n",
      "trainer/Z Expert Predictions Mean     309.938\n",
      "trainer/Z Expert Predictions Std        8.37353\n",
      "trainer/Z Expert Predictions Max      321.72\n",
      "trainer/Z Expert Predictions Min      252.857\n",
      "trainer/Z Policy Predictions Mean     284.685\n",
      "trainer/Z Policy Predictions Std       72.5616\n",
      "trainer/Z Policy Predictions Max      325.147\n",
      "trainer/Z Policy Predictions Min       -5.42543\n",
      "trainer/Z Expert Targets Mean         309.16\n",
      "trainer/Z Expert Targets Std            8.76887\n",
      "trainer/Z Expert Targets Max          320.144\n",
      "trainer/Z Expert Targets Min          248.213\n",
      "trainer/Z Policy Targets Mean         280.058\n",
      "trainer/Z Policy Targets Std           75.7883\n",
      "trainer/Z Policy Targets Max          320.244\n",
      "trainer/Z Policy Targets Min           -4.7354\n",
      "trainer/Log Pis Mean                   19.0123\n",
      "trainer/Log Pis Std                     2.77933\n",
      "trainer/Policy mu Mean                 -0.0718009\n",
      "trainer/Policy mu Std                   0.743236\n",
      "trainer/Policy log std Mean            -3.35224\n",
      "trainer/Policy log std Std              0.553645\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        340014\n",
      "exploration/num paths total           513\n",
      "evaluation/num steps total         506469\n",
      "evaluation/num paths total            702\n",
      "evaluation/path length Mean           988.4\n",
      "evaluation/path length Std             34.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            884\n",
      "evaluation/Rewards Mean                 4.38508\n",
      "evaluation/Rewards Std                  0.876592\n",
      "evaluation/Rewards Max                  6.75273\n",
      "evaluation/Rewards Min                 -1.73931\n",
      "evaluation/Returns Mean              4334.21\n",
      "evaluation/Returns Std                180.905\n",
      "evaluation/Returns Max               4450.36\n",
      "evaluation/Returns Min               3804.04\n",
      "evaluation/Estimation Bias Mean       273.108\n",
      "evaluation/Estimation Bias Std        127.181\n",
      "evaluation/EB/Q_True Mean              41.1977\n",
      "evaluation/EB/Q_True Std              126.198\n",
      "evaluation/EB/Q_Pred Mean             314.305\n",
      "evaluation/EB/Q_Pred Std               10.0228\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4334.21\n",
      "evaluation/Actions Mean                -0.0640774\n",
      "evaluation/Actions Std                  0.526176\n",
      "evaluation/Actions Max                  0.992334\n",
      "evaluation/Actions Min                 -0.997889\n",
      "time/backward_policy (s)                8.74797\n",
      "time/backward_zf1 (s)                  10.7672\n",
      "time/backward_zf2 (s)                  10.3872\n",
      "time/data sampling (s)                  1.47522\n",
      "time/data storing (s)                   0.0848052\n",
      "time/evaluation sampling (s)            3.72969\n",
      "time/exploration sampling (s)           1.63491\n",
      "time/logging (s)                        0.0184381\n",
      "time/preback_alpha (s)                  0.00557855\n",
      "time/preback_policy (s)                 9.38546\n",
      "time/preback_start (s)                  0.706009\n",
      "time/preback_zf (s)                    28.9748\n",
      "time/saving (s)                         3.743e-06\n",
      "time/training (s)                      10.6415\n",
      "time/epoch (s)                         86.5588\n",
      "time/total (s)                       5635.19\n",
      "Epoch                                  66\n",
      "---------------------------------  ---------------\n",
      "2024-10-19 01:50:54.267077 +0330 | [ant_2024_10_19_00_15_20_0000--s-4] Epoch 67 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 350000\n",
      "trainer/ZF1 Loss                       10.1179\n",
      "trainer/ZF2 Loss                        8.64811\n",
      "trainer/ZF Expert Reward                0.289803\n",
      "trainer/ZF Policy Reward                1.67305\n",
      "trainer/ZF CHI2 Term                    8.89145\n",
      "trainer/Policy Loss                  -284.289\n",
      "trainer/Bias Value                     10\n",
      "trainer/Policy Grad Norm               14.3069\n",
      "trainer/Policy Param Norm              35.9236\n",
      "trainer/Zf1 Grad Norm                 363.237\n",
      "trainer/Zf1 Param Norm                 86.308\n",
      "trainer/Zf2 Grad Norm                 351.626\n",
      "trainer/Zf2 Param Norm                 87.1336\n",
      "trainer/Z Expert Predictions Mean     310.216\n",
      "trainer/Z Expert Predictions Std        8.97013\n",
      "trainer/Z Expert Predictions Max      319.994\n",
      "trainer/Z Expert Predictions Min      230.204\n",
      "trainer/Z Policy Predictions Mean     283.163\n",
      "trainer/Z Policy Predictions Std       80.0549\n",
      "trainer/Z Policy Predictions Max      323.105\n",
      "trainer/Z Policy Predictions Min      -15.8092\n",
      "trainer/Z Expert Targets Mean         309.927\n",
      "trainer/Z Expert Targets Std            9.67719\n",
      "trainer/Z Expert Targets Max          321.174\n",
      "trainer/Z Expert Targets Min          214.033\n",
      "trainer/Z Policy Targets Mean         281.49\n",
      "trainer/Z Policy Targets Std           79.3717\n",
      "trainer/Z Policy Targets Max          321.332\n",
      "trainer/Z Policy Targets Min          -11.7389\n",
      "trainer/Log Pis Mean                   19.5918\n",
      "trainer/Log Pis Std                     3.13069\n",
      "trainer/Policy mu Mean                 -0.0709933\n",
      "trainer/Policy mu Std                   0.793851\n",
      "trainer/Policy log std Mean            -3.39432\n",
      "trainer/Policy log std Std              0.600882\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        345014\n",
      "exploration/num paths total           518\n",
      "evaluation/num steps total         514150\n",
      "evaluation/num paths total            713\n",
      "evaluation/path length Mean           698.273\n",
      "evaluation/path length Std            295.913\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            177\n",
      "evaluation/Rewards Mean                 4.32495\n",
      "evaluation/Rewards Std                  0.89157\n",
      "evaluation/Rewards Max                  6.57819\n",
      "evaluation/Rewards Min                 -1.37911\n",
      "evaluation/Returns Mean              3020\n",
      "evaluation/Returns Std               1309.86\n",
      "evaluation/Returns Max               4448.16\n",
      "evaluation/Returns Min                755.366\n",
      "evaluation/Estimation Bias Mean       263.419\n",
      "evaluation/Estimation Bias Std        138.852\n",
      "evaluation/EB/Q_True Mean              51.6906\n",
      "evaluation/EB/Q_True Std              137.23\n",
      "evaluation/EB/Q_Pred Mean             315.11\n",
      "evaluation/EB/Q_Pred Std               12.2423\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3020\n",
      "evaluation/Actions Mean                -0.0717681\n",
      "evaluation/Actions Std                  0.531273\n",
      "evaluation/Actions Max                  0.996343\n",
      "evaluation/Actions Min                 -0.997027\n",
      "time/backward_policy (s)                8.53031\n",
      "time/backward_zf1 (s)                  10.3534\n",
      "time/backward_zf2 (s)                  10.0321\n",
      "time/data sampling (s)                  1.40553\n",
      "time/data storing (s)                   0.0828574\n",
      "time/evaluation sampling (s)            3.84855\n",
      "time/exploration sampling (s)           1.60641\n",
      "time/logging (s)                        0.0117511\n",
      "time/preback_alpha (s)                  0.0054324\n",
      "time/preback_policy (s)                 9.18652\n",
      "time/preback_start (s)                  0.682008\n",
      "time/preback_zf (s)                    28.5261\n",
      "time/saving (s)                         3.26199e-06\n",
      "time/training (s)                      10.3917\n",
      "time/epoch (s)                         84.6627\n",
      "time/total (s)                       5719.85\n",
      "Epoch                                  67\n",
      "---------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "!python train.py --env ant --demos 1 --loss 'value' --alpha 0.01 --bias 10 --seed 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79e04c-974a-437f-89b8-24d9820b6273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

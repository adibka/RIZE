{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd095125-6be1-4c22-8760-d1fba60ab86d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## experiment (tqc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603bc9d-5ced-4410-9d8b-bc74345fd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_tqc(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant['layer_size']\n",
    "    num_quantiles = variant['num_quantiles']\n",
    "    n_nets = variant['n_nets']\n",
    "    \n",
    "    zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    target_zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = TruncIDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        zf=zf,\n",
    "        target_zf=target_zf,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b40f96-5af4-4fc9-8f5d-34bacdc440d8",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df783e4e-ddf6-45d9-8b26-6863e89107f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.data_management.torch_replay_buffer import TorchReplayBuffer\n",
    "from rlkit.envs import make_env\n",
    "from rlkit.envs.vecenv import SubprocVectorEnv, VectorEnv\n",
    "from rlkit.launchers.launcher_util import set_seed, setup_logger\n",
    "from rlkit.samplers.data_collector import (VecMdpPathCollector, VecMdpStepCollector)\n",
    "from rlkit.torch.idsac.idsac import IDSACTrainer\n",
    "from rlkit.torch.idsac.networks import QuantileMlp, Critic, softmax\n",
    "from rlkit.torch.networks import FlattenMlp\n",
    "from rlkit.torch.sac.policies import MakeDeterministic, TanhGaussianPolicy\n",
    "from rlkit.torch.torch_iq_algorithm import TorchVecOnlineIQAlgorithm\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba84c8-f8f8-4272-8885-83a6c028ee37",
   "metadata": {},
   "source": [
    "# experiment (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c847e24-53fa-4f9b-850b-c7b648d30304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant[\"layer_size\"]\n",
    "    num_quantiles = variant[\"num_quantiles\"]\n",
    "    tau_type = variant[\"trainer_kwargs\"][\"tau_type\"]\n",
    "    dropout = variant[\"dropout\"]\n",
    "    drop_rate = variant[\"drop_rate\"]\n",
    "    \n",
    "    zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        dropout=dropout,\n",
    "        drop_rate=drop_rate,\n",
    "    )\n",
    "    zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        dropout=dropout,\n",
    "        drop_rate=drop_rate,\n",
    "    )\n",
    "    target_zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        dropout=dropout,\n",
    "        drop_rate=drop_rate,\n",
    "    )\n",
    "    target_zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        dropout=dropout,\n",
    "        drop_rate=drop_rate,\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M // 2],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    target_policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M // 2],\n",
    "    )\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "        zf1,\n",
    "        tau_type,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = IDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        target_policy=target_policy,\n",
    "        zf1=zf1,\n",
    "        zf2=zf2,\n",
    "        target_zf1=target_zf1,\n",
    "        target_zf2=target_zf2,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e380543-9ff2-4947-8cda-2f5b05957627",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fa2c3c-ae22-4830-bad1-8b99032cb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(dsac_cfg_path,\n",
    "               expert_path,\n",
    "               iq_cfg_path='configs/dsac-normal-iqn-neutral/iq.yaml',\n",
    "               cql_cfg_path='configs/dsac-normal-iqn-neutral/cql.yaml'\n",
    "              ):\n",
    "    \n",
    "    with open(dsac_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        variant = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    with open(iq_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        iq_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    with open(cql_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        cql_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    iq_cfg['expert_path'] = expert_path\n",
    "    variant['iq_kwargs'] = iq_cfg\n",
    "    variant['cql_kwargs'] = cql_cfg\n",
    "    return variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40faac3-2a8c-49fc-bece-f891df61d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = get_config(dsac_cfg_path='configs/dsac-normal-iqn-neutral/hopper.yaml',\n",
    "                     expert_path='experts/Hopper-v2_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00203431-e8bc-4e42-977f-298ec40d51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-08 22:01:08.448930 +0330 | Variant:\n",
      "2024-06-08 22:01:08.449708 +0330 | {\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"min_num_steps_before_training\": 10000,\n",
      "    \"num_epochs\": 300,\n",
      "    \"num_eval_paths_per_epoch\": 10,\n",
      "    \"num_expl_steps_per_train_loop\": 1000,\n",
      "    \"num_trains_per_train_loop\": 1000\n",
      "  },\n",
      "  \"env\": \"Hopper-v2\",\n",
      "  \"seed\": 1,\n",
      "  \"expectation_z\": false,\n",
      "  \"eval_env_num\": 10,\n",
      "  \"expl_env_num\": 10,\n",
      "  \"layer_size\": 256,\n",
      "  \"num_quantiles\": 24,\n",
      "  \"dropout\": false,\n",
      "  \"drop_rate\": 0.01,\n",
      "  \"replay_buffer_size\": 1000000,\n",
      "  \"trainer_kwargs\": {\n",
      "    \"alpha\": 0.01,\n",
      "    \"discount\": 0.99,\n",
      "    \"policy_lr\": 7.5e-05,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"tau_type\": \"iqn\",\n",
      "    \"use_automatic_entropy_tuning\": false,\n",
      "    \"zf_lr\": 0.0003\n",
      "  },\n",
      "  \"version\": \"normal-iqn-neutral\",\n",
      "  \"iq_kwargs\": {\n",
      "    \"expert_path\": \"experts/Hopper-v2_25.pkl\",\n",
      "    \"subsample_freq\": 1,\n",
      "    \"demos\": 10,\n",
      "    \"regularize\": true,\n",
      "    \"div\": null,\n",
      "    \"loss\": \"value_policy\",\n",
      "    \"alpha\": 2.5\n",
      "  },\n",
      "  \"cql_kwargs\": {\n",
      "    \"use_cql\": false,\n",
      "    \"cql_weight\": 0.05,\n",
      "    \"num_random\": 10,\n",
      "    \"with_lagrange\": false,\n",
      "    \"lagrange_thresh\": 10.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    ptu.set_gpu_mode(True, 0)\n",
    "    # device = torch.device('cuda:0')\n",
    "seed = variant[\"seed\"]\n",
    "set_seed(seed)\n",
    "log_prefix = \"_\".join([\"idsac\", variant[\"env\"][:-3].lower(), str(variant[\"version\"])])\n",
    "setup_logger(log_prefix, variant=variant, seed=seed)\n",
    "variant[\"device\"] = ptu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9e0ac-93fd-4003-bfd1-29f851badba5",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa21b2b4-9bf0-4965-91a7-ff8ca706fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddie/venvs/IQ/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-08 22:01:26.009195 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 0 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 11000\n",
      "trainer/ZF1 Loss                       6.5638\n",
      "trainer/ZF2 Loss                       6.72065\n",
      "trainer/ZF Expert Reward               0.470286\n",
      "trainer/ZF Policy Reward               0.535379\n",
      "trainer/ZF CHI2 Term                   4.56724\n",
      "trainer/Policy Loss                   -0.105853\n",
      "trainer/Policy Grad Norm               0.074341\n",
      "trainer/Policy Param Norm             13.4627\n",
      "trainer/Zf1 Grad Norm                 19.3267\n",
      "trainer/Zf1 Param Norm                32.1217\n",
      "trainer/Zf2 Grad Norm                 14.675\n",
      "trainer/Zf2 Param Norm                32.0922\n",
      "trainer/Z Expert Predictions Mean      0.111329\n",
      "trainer/Z Expert Predictions Std       0.183359\n",
      "trainer/Z Expert Predictions Max       0.701738\n",
      "trainer/Z Expert Predictions Min      -0.398742\n",
      "trainer/Z Policy Predictions Mean      0.0992573\n",
      "trainer/Z Policy Predictions Std       0.158773\n",
      "trainer/Z Policy Predictions Max       0.599929\n",
      "trainer/Z Policy Predictions Min      -0.558275\n",
      "trainer/Z Expert Targets Mean         -0.358957\n",
      "trainer/Z Expert Targets Std           0.287025\n",
      "trainer/Z Expert Targets Max           0.418418\n",
      "trainer/Z Expert Targets Min          -1.14036\n",
      "trainer/Z Policy Targets Mean         -0.436122\n",
      "trainer/Z Policy Targets Std           0.264739\n",
      "trainer/Z Policy Targets Max           0.40554\n",
      "trainer/Z Policy Targets Min          -1.23594\n",
      "trainer/Log Pis Mean                  -2.03019\n",
      "trainer/Log Pis Std                    0.392228\n",
      "trainer/Policy mu Mean                -0.000475456\n",
      "trainer/Policy mu Std                  0.00114585\n",
      "trainer/Policy log std Mean           -0.00105806\n",
      "trainer/Policy log std Std             0.000250634\n",
      "exploration/num steps total        10606\n",
      "exploration/num paths total          498\n",
      "evaluation/num steps total           582\n",
      "evaluation/num paths total            10\n",
      "evaluation/path length Mean           58.2\n",
      "evaluation/path length Std             0.748331\n",
      "evaluation/path length Max            59\n",
      "evaluation/path length Min            57\n",
      "evaluation/Rewards Mean                1.8214\n",
      "evaluation/Rewards Std                 0.277156\n",
      "evaluation/Rewards Max                 2.28539\n",
      "evaluation/Rewards Min                 1.00743\n",
      "evaluation/Returns Mean              106.005\n",
      "evaluation/Returns Std                 0.863706\n",
      "evaluation/Returns Max               107.202\n",
      "evaluation/Returns Min               104.859\n",
      "evaluation/Estimation Bias Mean       -5.51564\n",
      "evaluation/Estimation Bias Std        20.4799\n",
      "evaluation/EB/Q_True Mean              4.77406\n",
      "evaluation/EB/Q_True Std              16.1211\n",
      "evaluation/EB/Q_Pred Mean             -0.741576\n",
      "evaluation/EB/Q_Pred Std              10.6228\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           106.005\n",
      "evaluation/Actions Mean                0.615517\n",
      "evaluation/Actions Std                 0.432868\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.505997\n",
      "time/backward_policy (s)               1.5802\n",
      "time/backward_zf1 (s)                  1.7092\n",
      "time/backward_zf2 (s)                  1.62847\n",
      "time/data sampling (s)                 0.18139\n",
      "time/data storing (s)                  0.0135055\n",
      "time/evaluation sampling (s)           0.0973564\n",
      "time/exploration sampling (s)          0.527765\n",
      "time/logging (s)                       0.00206014\n",
      "time/preback_alpha (s)                 0.535746\n",
      "time/preback_policy (s)                0.571211\n",
      "time/preback_start (s)                 0.115176\n",
      "time/preback_zf (s)                    4.86966\n",
      "time/saving (s)                        0.00454579\n",
      "time/training (s)                      2.6358\n",
      "time/epoch (s)                        14.4721\n",
      "time/total (s)                        19.4129\n",
      "Epoch                                  0\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:01:40.205957 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 1 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 12000\n",
      "trainer/ZF1 Loss                     -33.5436\n",
      "trainer/ZF2 Loss                     -33.6654\n",
      "trainer/ZF Expert Reward              14.8607\n",
      "trainer/ZF Policy Reward              -8.8296\n",
      "trainer/ZF CHI2 Term                   7.09635\n",
      "trainer/Policy Loss                   18.9804\n",
      "trainer/Policy Grad Norm               4.96144\n",
      "trainer/Policy Param Norm             15.3343\n",
      "trainer/Zf1 Grad Norm                 42.7911\n",
      "trainer/Zf1 Param Norm                34.5559\n",
      "trainer/Zf2 Grad Norm                 36.4356\n",
      "trainer/Zf2 Param Norm                34.4346\n",
      "trainer/Z Expert Predictions Mean     63.4604\n",
      "trainer/Z Expert Predictions Std      10.6154\n",
      "trainer/Z Expert Predictions Max      65.3526\n",
      "trainer/Z Expert Predictions Min     -18.2784\n",
      "trainer/Z Policy Predictions Mean    -25.1087\n",
      "trainer/Z Policy Predictions Std       9.82096\n",
      "trainer/Z Policy Predictions Max      14.9837\n",
      "trainer/Z Policy Predictions Min     -35.7173\n",
      "trainer/Z Expert Targets Mean         48.5997\n",
      "trainer/Z Expert Targets Std           8.3225\n",
      "trainer/Z Expert Targets Max          50.3522\n",
      "trainer/Z Expert Targets Min         -13.7798\n",
      "trainer/Z Policy Targets Mean        -16.2791\n",
      "trainer/Z Policy Targets Std          10.4717\n",
      "trainer/Z Policy Targets Max          22.9068\n",
      "trainer/Z Policy Targets Min         -29.7093\n",
      "trainer/Log Pis Mean                  17.1824\n",
      "trainer/Log Pis Std                    7.07587\n",
      "trainer/Policy mu Mean                 4.02157\n",
      "trainer/Policy mu Std                  3.11249\n",
      "trainer/Policy log std Mean           -0.871315\n",
      "trainer/Policy log std Std             1.17984\n",
      "exploration/num steps total        11829\n",
      "exploration/num paths total          533\n",
      "evaluation/num steps total           995\n",
      "evaluation/num paths total            20\n",
      "evaluation/path length Mean           41.3\n",
      "evaluation/path length Std             0.781025\n",
      "evaluation/path length Max            42\n",
      "evaluation/path length Min            40\n",
      "evaluation/Rewards Mean                1.63091\n",
      "evaluation/Rewards Std                 0.411509\n",
      "evaluation/Rewards Max                 2.30322\n",
      "evaluation/Rewards Min                 1.00591\n",
      "evaluation/Returns Mean               67.3565\n",
      "evaluation/Returns Std                 1.53394\n",
      "evaluation/Returns Max                68.774\n",
      "evaluation/Returns Min                64.6794\n",
      "evaluation/Estimation Bias Mean      -17.6037\n",
      "evaluation/Estimation Bias Std        22.3136\n",
      "evaluation/EB/Q_True Mean              3.54347\n",
      "evaluation/EB/Q_True Std              11.6686\n",
      "evaluation/EB/Q_Pred Mean            -14.0603\n",
      "evaluation/EB/Q_Pred Std              17.6323\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            67.3565\n",
      "evaluation/Actions Mean                0.5918\n",
      "evaluation/Actions Std                 0.408766\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.669949\n",
      "time/backward_policy (s)               1.58958\n",
      "time/backward_zf1 (s)                  1.72054\n",
      "time/backward_zf2 (s)                  1.63286\n",
      "time/data sampling (s)                 0.193555\n",
      "time/data storing (s)                  0.0135549\n",
      "time/evaluation sampling (s)           0.0771172\n",
      "time/exploration sampling (s)          0.180394\n",
      "time/logging (s)                       0.00156585\n",
      "time/preback_alpha (s)                 0.543144\n",
      "time/preback_policy (s)                0.579062\n",
      "time/preback_start (s)                 0.117979\n",
      "time/preback_zf (s)                    4.87515\n",
      "time/saving (s)                        0.00586358\n",
      "time/training (s)                      2.60678\n",
      "time/epoch (s)                        14.1371\n",
      "time/total (s)                        33.5671\n",
      "Epoch                                  1\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:01:54.423757 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 2 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 13000\n",
      "trainer/ZF1 Loss                     -34.8299\n",
      "trainer/ZF2 Loss                     -34.6755\n",
      "trainer/ZF Expert Reward              17.3934\n",
      "trainer/ZF Policy Reward              -8.29839\n",
      "trainer/ZF CHI2 Term                   8.61136\n",
      "trainer/Policy Loss                   32.5978\n",
      "trainer/Policy Grad Norm               7.25037\n",
      "trainer/Policy Param Norm             16.5293\n",
      "trainer/Zf1 Grad Norm                 86.1924\n",
      "trainer/Zf1 Param Norm                37.4898\n",
      "trainer/Zf2 Grad Norm                 57.9661\n",
      "trainer/Zf2 Param Norm                37.2266\n",
      "trainer/Z Expert Predictions Mean    133.21\n",
      "trainer/Z Expert Predictions Std      28.7496\n",
      "trainer/Z Expert Predictions Max     140.367\n",
      "trainer/Z Expert Predictions Min     -35.4323\n",
      "trainer/Z Policy Predictions Mean    -36.5181\n",
      "trainer/Z Policy Predictions Std      11.5409\n",
      "trainer/Z Policy Predictions Max      21.8666\n",
      "trainer/Z Policy Predictions Min     -58.0768\n",
      "trainer/Z Expert Targets Mean        115.817\n",
      "trainer/Z Expert Targets Std          27.1152\n",
      "trainer/Z Expert Targets Max         123.051\n",
      "trainer/Z Expert Targets Min         -34.8604\n",
      "trainer/Z Policy Targets Mean        -28.2197\n",
      "trainer/Z Policy Targets Std          12.721\n",
      "trainer/Z Policy Targets Max          25.764\n",
      "trainer/Z Policy Targets Min         -52.9174\n",
      "trainer/Log Pis Mean                  17.8508\n",
      "trainer/Log Pis Std                    6.48867\n",
      "trainer/Policy mu Mean                 3.63434\n",
      "trainer/Policy mu Std                  3.97025\n",
      "trainer/Policy log std Mean           -1.82799\n",
      "trainer/Policy log std Std             1.97309\n",
      "exploration/num steps total        12976\n",
      "exploration/num paths total          583\n",
      "evaluation/num steps total          1055\n",
      "evaluation/num paths total            30\n",
      "evaluation/path length Mean            6\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max             6\n",
      "evaluation/path length Min             6\n",
      "evaluation/Rewards Mean                0.535519\n",
      "evaluation/Rewards Std                 0.262914\n",
      "evaluation/Rewards Max                 0.923528\n",
      "evaluation/Rewards Min                 0.148706\n",
      "evaluation/Returns Mean                3.21312\n",
      "evaluation/Returns Std                 0.0115086\n",
      "evaluation/Returns Max                 3.23629\n",
      "evaluation/Returns Min                 3.19824\n",
      "evaluation/Estimation Bias Mean      -34.7533\n",
      "evaluation/Estimation Bias Std        11.7791\n",
      "evaluation/EB/Q_True Mean              0.140754\n",
      "evaluation/EB/Q_True Std               0.536542\n",
      "evaluation/EB/Q_Pred Mean            -34.6125\n",
      "evaluation/EB/Q_Pred Std              11.666\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns             3.21312\n",
      "evaluation/Actions Mean               -0.359669\n",
      "evaluation/Actions Std                 0.840383\n",
      "evaluation/Actions Max                 0.99983\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.58343\n",
      "time/backward_zf1 (s)                  1.71401\n",
      "time/backward_zf2 (s)                  1.63305\n",
      "time/data sampling (s)                 0.190988\n",
      "time/data storing (s)                  0.0137915\n",
      "time/evaluation sampling (s)           0.0189691\n",
      "time/exploration sampling (s)          0.18344\n",
      "time/logging (s)                       0.00139125\n",
      "time/preback_alpha (s)                 0.545563\n",
      "time/preback_policy (s)                0.57761\n",
      "time/preback_start (s)                 0.118668\n",
      "time/preback_zf (s)                    4.88926\n",
      "time/saving (s)                        0.00479418\n",
      "time/training (s)                      2.68103\n",
      "time/epoch (s)                        14.156\n",
      "time/total (s)                        47.7429\n",
      "Epoch                                  2\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:02:08.848910 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 3 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 14000\n",
      "trainer/ZF1 Loss                     -32.7976\n",
      "trainer/ZF2 Loss                     -33.0433\n",
      "trainer/ZF Expert Reward              18.6149\n",
      "trainer/ZF Policy Reward              -8.43034\n",
      "trainer/ZF CHI2 Term                   9.87177\n",
      "trainer/Policy Loss                   36.8566\n",
      "trainer/Policy Grad Norm              14.577\n",
      "trainer/Policy Param Norm             17.7048\n",
      "trainer/Zf1 Grad Norm                 89.57\n",
      "trainer/Zf1 Param Norm                40.4553\n",
      "trainer/Zf2 Grad Norm                 71.4225\n",
      "trainer/Zf2 Param Norm                40.115\n",
      "trainer/Z Expert Predictions Mean    214.785\n",
      "trainer/Z Expert Predictions Std      26.5645\n",
      "trainer/Z Expert Predictions Max     220.37\n",
      "trainer/Z Expert Predictions Min     -16.4727\n",
      "trainer/Z Policy Predictions Mean    -47.2359\n",
      "trainer/Z Policy Predictions Std      25.5152\n",
      "trainer/Z Policy Predictions Max      83.9402\n",
      "trainer/Z Policy Predictions Min     -84.5247\n",
      "trainer/Z Expert Targets Mean        196.17\n",
      "trainer/Z Expert Targets Std          26.372\n",
      "trainer/Z Expert Targets Max         201.902\n",
      "trainer/Z Expert Targets Min         -19.2129\n",
      "trainer/Z Policy Targets Mean        -38.8055\n",
      "trainer/Z Policy Targets Std          25.2111\n",
      "trainer/Z Policy Targets Max          83.1399\n",
      "trainer/Z Policy Targets Min         -80.0499\n",
      "trainer/Log Pis Mean                  15.9061\n",
      "trainer/Log Pis Std                    7.08705\n",
      "trainer/Policy mu Mean                -0.515311\n",
      "trainer/Policy mu Std                  3.75847\n",
      "trainer/Policy log std Mean           -1.76626\n",
      "trainer/Policy log std Std             1.34919\n",
      "exploration/num steps total        13511\n",
      "exploration/num paths total          656\n",
      "evaluation/num steps total          2044\n",
      "evaluation/num paths total            40\n",
      "evaluation/path length Mean           98.9\n",
      "evaluation/path length Std             1.37477\n",
      "evaluation/path length Max           102\n",
      "evaluation/path length Min            97\n",
      "evaluation/Rewards Mean                2.36808\n",
      "evaluation/Rewards Std                 0.76158\n",
      "evaluation/Rewards Max                 3.4166\n",
      "evaluation/Rewards Min                 0.961299\n",
      "evaluation/Returns Mean              234.204\n",
      "evaluation/Returns Std                 3.52377\n",
      "evaluation/Returns Max               241.996\n",
      "evaluation/Returns Min               229.173\n",
      "evaluation/Estimation Bias Mean      111.963\n",
      "evaluation/Estimation Bias Std        95.3625\n",
      "evaluation/EB/Q_True Mean             10.6735\n",
      "evaluation/EB/Q_True Std              34.1402\n",
      "evaluation/EB/Q_Pred Mean            122.636\n",
      "evaluation/EB/Q_Pred Std              86.8278\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           234.204\n",
      "evaluation/Actions Mean                0.107971\n",
      "evaluation/Actions Std                 0.310123\n",
      "evaluation/Actions Max                 0.999924\n",
      "evaluation/Actions Min                -0.866189\n",
      "time/backward_policy (s)               1.70201\n",
      "time/backward_zf1 (s)                  1.81952\n",
      "time/backward_zf2 (s)                  1.75426\n",
      "time/data sampling (s)                 0.187561\n",
      "time/data storing (s)                  0.0135687\n",
      "time/evaluation sampling (s)           0.173691\n",
      "time/exploration sampling (s)          0.18138\n",
      "time/logging (s)                       0.00209903\n",
      "time/preback_alpha (s)                 0.539309\n",
      "time/preback_policy (s)                0.59428\n",
      "time/preback_start (s)                 0.116288\n",
      "time/preback_zf (s)                    4.88461\n",
      "time/saving (s)                        0.00534487\n",
      "time/training (s)                      2.38806\n",
      "time/epoch (s)                        14.362\n",
      "time/total (s)                        62.127\n",
      "Epoch                                  3\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:02:23.240673 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 4 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 15000\n",
      "trainer/ZF1 Loss                     -28.0638\n",
      "trainer/ZF2 Loss                     -27.6401\n",
      "trainer/ZF Expert Reward              18.8596\n",
      "trainer/ZF Policy Reward              -8.18259\n",
      "trainer/ZF CHI2 Term                  10.6006\n",
      "trainer/Policy Loss                   19.1281\n",
      "trainer/Policy Grad Norm              56.2523\n",
      "trainer/Policy Param Norm             18.8959\n",
      "trainer/Zf1 Grad Norm                140.599\n",
      "trainer/Zf1 Param Norm                42.5945\n",
      "trainer/Zf2 Grad Norm                114.469\n",
      "trainer/Zf2 Param Norm                42.2639\n",
      "trainer/Z Expert Predictions Mean    282.341\n",
      "trainer/Z Expert Predictions Std      53.24\n",
      "trainer/Z Expert Predictions Max     299.802\n",
      "trainer/Z Expert Predictions Min      -8.44389\n",
      "trainer/Z Policy Predictions Mean    -30.2689\n",
      "trainer/Z Policy Predictions Std      37.2624\n",
      "trainer/Z Policy Predictions Max     114.973\n",
      "trainer/Z Policy Predictions Min     -78.9868\n",
      "trainer/Z Expert Targets Mean        263.482\n",
      "trainer/Z Expert Targets Std          52.385\n",
      "trainer/Z Expert Targets Max         280.721\n",
      "trainer/Z Expert Targets Min         -20.7138\n",
      "trainer/Z Policy Targets Mean        -22.0863\n",
      "trainer/Z Policy Targets Std          37.2699\n",
      "trainer/Z Policy Targets Max         132.263\n",
      "trainer/Z Policy Targets Min         -78.3314\n",
      "trainer/Log Pis Mean                  11.5256\n",
      "trainer/Log Pis Std                    6.43318\n",
      "trainer/Policy mu Mean                 0.126337\n",
      "trainer/Policy mu Std                  2.48965\n",
      "trainer/Policy log std Mean           -1.7981\n",
      "trainer/Policy log std Std             1.99709\n",
      "exploration/num steps total        14522\n",
      "exploration/num paths total          666\n",
      "evaluation/num steps total          2991\n",
      "evaluation/num paths total            50\n",
      "evaluation/path length Mean           94.7\n",
      "evaluation/path length Std             0.640312\n",
      "evaluation/path length Max            96\n",
      "evaluation/path length Min            94\n",
      "evaluation/Rewards Mean                2.1121\n",
      "evaluation/Rewards Std                 0.574588\n",
      "evaluation/Rewards Max                 2.82347\n",
      "evaluation/Rewards Min                 0.871885\n",
      "evaluation/Returns Mean              200.016\n",
      "evaluation/Returns Std                 2.52565\n",
      "evaluation/Returns Max               203.811\n",
      "evaluation/Returns Min               195.856\n",
      "evaluation/Estimation Bias Mean      159.424\n",
      "evaluation/Estimation Bias Std       115.723\n",
      "evaluation/EB/Q_True Mean              8.72539\n",
      "evaluation/EB/Q_True Std              28.5408\n",
      "evaluation/EB/Q_Pred Mean            168.149\n",
      "evaluation/EB/Q_Pred Std             108.768\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           200.016\n",
      "evaluation/Actions Mean                0.0884191\n",
      "evaluation/Actions Std                 0.515286\n",
      "evaluation/Actions Max                 0.999618\n",
      "evaluation/Actions Min                -0.96736\n",
      "time/backward_policy (s)               1.61487\n",
      "time/backward_zf1 (s)                  1.73079\n",
      "time/backward_zf2 (s)                  1.66148\n",
      "time/data sampling (s)                 0.195357\n",
      "time/data storing (s)                  0.0137586\n",
      "time/evaluation sampling (s)           0.149873\n",
      "time/exploration sampling (s)          0.174678\n",
      "time/logging (s)                       0.00253973\n",
      "time/preback_alpha (s)                 0.544284\n",
      "time/preback_policy (s)                0.587139\n",
      "time/preback_start (s)                 0.118922\n",
      "time/preback_zf (s)                    4.88941\n",
      "time/saving (s)                        0.00480715\n",
      "time/training (s)                      2.63976\n",
      "time/epoch (s)                        14.3277\n",
      "time/total (s)                        76.477\n",
      "Epoch                                  4\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:02:37.516353 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 5 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 16000\n",
      "trainer/ZF1 Loss                      -6.71492\n",
      "trainer/ZF2 Loss                      -6.00715\n",
      "trainer/ZF Expert Reward              21.1635\n",
      "trainer/ZF Policy Reward              -8.38954\n",
      "trainer/ZF CHI2 Term                  37.245\n",
      "trainer/Policy Loss                  -16.209\n",
      "trainer/Policy Grad Norm              39.02\n",
      "trainer/Policy Param Norm             20.1432\n",
      "trainer/Zf1 Grad Norm                227.716\n",
      "trainer/Zf1 Param Norm                44.8169\n",
      "trainer/Zf2 Grad Norm                310.24\n",
      "trainer/Zf2 Param Norm                44.3047\n",
      "trainer/Z Expert Predictions Mean    345.759\n",
      "trainer/Z Expert Predictions Std      79.5277\n",
      "trainer/Z Expert Predictions Max     377.088\n",
      "trainer/Z Expert Predictions Min       5.02837\n",
      "trainer/Z Policy Predictions Mean      3.35795\n",
      "trainer/Z Policy Predictions Std      68.1057\n",
      "trainer/Z Policy Predictions Max     345.109\n",
      "trainer/Z Policy Predictions Min     -67.9783\n",
      "trainer/Z Expert Targets Mean        324.595\n",
      "trainer/Z Expert Targets Std          82.6403\n",
      "trainer/Z Expert Targets Max         357.499\n",
      "trainer/Z Expert Targets Min         -10.3903\n",
      "trainer/Z Policy Targets Mean         11.7475\n",
      "trainer/Z Policy Targets Std          67.7739\n",
      "trainer/Z Policy Targets Max         342.567\n",
      "trainer/Z Policy Targets Min         -61.4451\n",
      "trainer/Log Pis Mean                  14.1949\n",
      "trainer/Log Pis Std                    5.29295\n",
      "trainer/Policy mu Mean                 0.297059\n",
      "trainer/Policy mu Std                  2.9103\n",
      "trainer/Policy log std Mean           -2.61991\n",
      "trainer/Policy log std Std             1.76007\n",
      "exploration/num steps total        15391\n",
      "exploration/num paths total          676\n",
      "evaluation/num steps total          3762\n",
      "evaluation/num paths total            60\n",
      "evaluation/path length Mean           77.1\n",
      "evaluation/path length Std             0.538516\n",
      "evaluation/path length Max            78\n",
      "evaluation/path length Min            76\n",
      "evaluation/Rewards Mean                1.70267\n",
      "evaluation/Rewards Std                 0.588043\n",
      "evaluation/Rewards Max                 2.35491\n",
      "evaluation/Rewards Min                 0.13531\n",
      "evaluation/Returns Mean              131.276\n",
      "evaluation/Returns Std                 1.08478\n",
      "evaluation/Returns Max               133.185\n",
      "evaluation/Returns Min               129.163\n",
      "evaluation/Estimation Bias Mean      132.638\n",
      "evaluation/Estimation Bias Std       116.949\n",
      "evaluation/EB/Q_True Mean              5.51832\n",
      "evaluation/EB/Q_True Std              19.2601\n",
      "evaluation/EB/Q_Pred Mean            138.156\n",
      "evaluation/EB/Q_Pred Std             113.588\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           131.276\n",
      "evaluation/Actions Mean               -0.0204436\n",
      "evaluation/Actions Std                 0.555432\n",
      "evaluation/Actions Max                 0.999863\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.57599\n",
      "time/backward_zf1 (s)                  1.70643\n",
      "time/backward_zf2 (s)                  1.62362\n",
      "time/data sampling (s)                 0.189691\n",
      "time/data storing (s)                  0.0136962\n",
      "time/evaluation sampling (s)           0.123733\n",
      "time/exploration sampling (s)          0.174194\n",
      "time/logging (s)                       0.00233199\n",
      "time/preback_alpha (s)                 0.537367\n",
      "time/preback_policy (s)                0.571874\n",
      "time/preback_start (s)                 0.116521\n",
      "time/preback_zf (s)                    4.87672\n",
      "time/saving (s)                        0.00526712\n",
      "time/training (s)                      2.69081\n",
      "time/epoch (s)                        14.2082\n",
      "time/total (s)                        90.7109\n",
      "Epoch                                  5\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:02:52.112793 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 6 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 17000\n",
      "trainer/ZF1 Loss                      -6.8934\n",
      "trainer/ZF2 Loss                      -9.22531\n",
      "trainer/ZF Expert Reward              18.5615\n",
      "trainer/ZF Policy Reward              -7.91972\n",
      "trainer/ZF CHI2 Term                  32.6328\n",
      "trainer/Policy Loss                  -38.501\n",
      "trainer/Policy Grad Norm              37.8042\n",
      "trainer/Policy Param Norm             20.9986\n",
      "trainer/Zf1 Grad Norm                289.612\n",
      "trainer/Zf1 Param Norm                46.9174\n",
      "trainer/Zf2 Grad Norm                280.437\n",
      "trainer/Zf2 Param Norm                46.0362\n",
      "trainer/Z Expert Predictions Mean    413.141\n",
      "trainer/Z Expert Predictions Std      82.1282\n",
      "trainer/Z Expert Predictions Max     447.477\n",
      "trainer/Z Expert Predictions Min       3.1758\n",
      "trainer/Z Policy Predictions Mean     26.5176\n",
      "trainer/Z Policy Predictions Std      85.6137\n",
      "trainer/Z Policy Predictions Max     382.771\n",
      "trainer/Z Policy Predictions Min     -67.1863\n",
      "trainer/Z Expert Targets Mean        394.579\n",
      "trainer/Z Expert Targets Std          80.0584\n",
      "trainer/Z Expert Targets Max         428.8\n",
      "trainer/Z Expert Targets Min           9.46897\n",
      "trainer/Z Policy Targets Mean         34.4373\n",
      "trainer/Z Policy Targets Std          83.6425\n",
      "trainer/Z Policy Targets Max         397.107\n",
      "trainer/Z Policy Targets Min         -61.6052\n",
      "trainer/Log Pis Mean                  14.3544\n",
      "trainer/Log Pis Std                    5.50839\n",
      "trainer/Policy mu Mean                -0.396106\n",
      "trainer/Policy mu Std                  3.3757\n",
      "trainer/Policy log std Mean           -2.49358\n",
      "trainer/Policy log std Std             1.60271\n",
      "exploration/num steps total        16207\n",
      "exploration/num paths total          686\n",
      "evaluation/num steps total          4457\n",
      "evaluation/num paths total            70\n",
      "evaluation/path length Mean           69.5\n",
      "evaluation/path length Std             0.5\n",
      "evaluation/path length Max            70\n",
      "evaluation/path length Min            69\n",
      "evaluation/Rewards Mean                1.52709\n",
      "evaluation/Rewards Std                 0.651327\n",
      "evaluation/Rewards Max                 2.14494\n",
      "evaluation/Rewards Min                -0.827115\n",
      "evaluation/Returns Mean              106.133\n",
      "evaluation/Returns Std                 0.488274\n",
      "evaluation/Returns Max               107.078\n",
      "evaluation/Returns Min               105.207\n",
      "evaluation/Estimation Bias Mean       78.0168\n",
      "evaluation/Estimation Bias Std        76.697\n",
      "evaluation/EB/Q_True Mean              4.21526\n",
      "evaluation/EB/Q_True Std              15.3223\n",
      "evaluation/EB/Q_Pred Mean             82.232\n",
      "evaluation/EB/Q_Pred Std              75.2381\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           106.133\n",
      "evaluation/Actions Mean                0.0527266\n",
      "evaluation/Actions Std                 0.595\n",
      "evaluation/Actions Max                 0.99997\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.72646\n",
      "time/backward_zf1 (s)                  1.85439\n",
      "time/backward_zf2 (s)                  1.77437\n",
      "time/data sampling (s)                 0.203205\n",
      "time/data storing (s)                  0.014322\n",
      "time/evaluation sampling (s)           0.102567\n",
      "time/exploration sampling (s)          0.17795\n",
      "time/logging (s)                       0.00177286\n",
      "time/preback_alpha (s)                 0.557408\n",
      "time/preback_policy (s)                0.618597\n",
      "time/preback_start (s)                 0.122156\n",
      "time/preback_zf (s)                    4.93404\n",
      "time/saving (s)                        0.00464\n",
      "time/training (s)                      2.44102\n",
      "time/epoch (s)                        14.5329\n",
      "time/total (s)                       105.263\n",
      "Epoch                                  6\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:03:06.755108 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 7 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 18000\n",
      "trainer/ZF1 Loss                      61.1549\n",
      "trainer/ZF2 Loss                      65.1599\n",
      "trainer/ZF Expert Reward              22.5412\n",
      "trainer/ZF Policy Reward              -9.06483\n",
      "trainer/ZF CHI2 Term                 110.162\n",
      "trainer/Policy Loss                  -56.8243\n",
      "trainer/Policy Grad Norm              26.1411\n",
      "trainer/Policy Param Norm             21.5802\n",
      "trainer/Zf1 Grad Norm                456.404\n",
      "trainer/Zf1 Param Norm                48.6846\n",
      "trainer/Zf2 Grad Norm                483.125\n",
      "trainer/Zf2 Param Norm                47.4534\n",
      "trainer/Z Expert Predictions Mean    479.537\n",
      "trainer/Z Expert Predictions Std      78.2609\n",
      "trainer/Z Expert Predictions Max     511.092\n",
      "trainer/Z Expert Predictions Min      40.7026\n",
      "trainer/Z Policy Predictions Mean     42.8844\n",
      "trainer/Z Policy Predictions Std      99.0028\n",
      "trainer/Z Policy Predictions Max     423.473\n",
      "trainer/Z Policy Predictions Min     -65.8832\n",
      "trainer/Z Expert Targets Mean        456.996\n",
      "trainer/Z Expert Targets Std          86.5427\n",
      "trainer/Z Expert Targets Max         491.987\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         51.9492\n",
      "trainer/Z Policy Targets Std          99.4693\n",
      "trainer/Z Policy Targets Max         420.504\n",
      "trainer/Z Policy Targets Min         -57.8316\n",
      "trainer/Log Pis Mean                  15.5543\n",
      "trainer/Log Pis Std                    6.49277\n",
      "trainer/Policy mu Mean                 0.652098\n",
      "trainer/Policy mu Std                  3.22885\n",
      "trainer/Policy log std Mean           -2.67486\n",
      "trainer/Policy log std Std             1.28207\n",
      "exploration/num steps total        17596\n",
      "exploration/num paths total          701\n",
      "evaluation/num steps total          6129\n",
      "evaluation/num paths total            80\n",
      "evaluation/path length Mean          167.2\n",
      "evaluation/path length Std            17.6624\n",
      "evaluation/path length Max           203\n",
      "evaluation/path length Min           157\n",
      "evaluation/Rewards Mean                1.82345\n",
      "evaluation/Rewards Std                 0.400561\n",
      "evaluation/Rewards Max                 2.84904\n",
      "evaluation/Rewards Min                 0.727249\n",
      "evaluation/Returns Mean              304.881\n",
      "evaluation/Returns Std                38.0472\n",
      "evaluation/Returns Max               382.087\n",
      "evaluation/Returns Min               283.492\n",
      "evaluation/Estimation Bias Mean      116.204\n",
      "evaluation/Estimation Bias Std       119.966\n",
      "evaluation/EB/Q_True Mean             13.8293\n",
      "evaluation/EB/Q_True Std              40.1704\n",
      "evaluation/EB/Q_Pred Mean            130.033\n",
      "evaluation/EB/Q_Pred Std             109.923\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           304.881\n",
      "evaluation/Actions Mean                0.0143381\n",
      "evaluation/Actions Std                 0.567611\n",
      "evaluation/Actions Max                 0.999996\n",
      "evaluation/Actions Min                -0.999986\n",
      "time/backward_policy (s)               1.7702\n",
      "time/backward_zf1 (s)                  1.86774\n",
      "time/backward_zf2 (s)                  1.82418\n",
      "time/data sampling (s)                 0.184451\n",
      "time/data storing (s)                  0.0132941\n",
      "time/evaluation sampling (s)           0.3156\n",
      "time/exploration sampling (s)          0.170697\n",
      "time/logging (s)                       0.00292351\n",
      "time/preback_alpha (s)                 0.529626\n",
      "time/preback_policy (s)                0.599604\n",
      "time/preback_start (s)                 0.113312\n",
      "time/preback_zf (s)                    4.89402\n",
      "time/saving (s)                        0.00492281\n",
      "time/training (s)                      2.28825\n",
      "time/epoch (s)                        14.5788\n",
      "time/total (s)                       119.865\n",
      "Epoch                                  7\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:03:21.329258 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 8 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 19000\n",
      "trainer/ZF1 Loss                     130.32\n",
      "trainer/ZF2 Loss                     132.146\n",
      "trainer/ZF Expert Reward              25.0328\n",
      "trainer/ZF Policy Reward              -6.16941\n",
      "trainer/ZF CHI2 Term                 177.815\n",
      "trainer/Policy Loss                  -84.6719\n",
      "trainer/Policy Grad Norm              47.2714\n",
      "trainer/Policy Param Norm             22.1894\n",
      "trainer/Zf1 Grad Norm                781.366\n",
      "trainer/Zf1 Param Norm                49.9426\n",
      "trainer/Zf2 Grad Norm                441.207\n",
      "trainer/Zf2 Param Norm                48.7999\n",
      "trainer/Z Expert Predictions Mean    545.277\n",
      "trainer/Z Expert Predictions Std      55.4842\n",
      "trainer/Z Expert Predictions Max     566.726\n",
      "trainer/Z Expert Predictions Min      96.7779\n",
      "trainer/Z Policy Predictions Mean     70.4381\n",
      "trainer/Z Policy Predictions Std     114.675\n",
      "trainer/Z Policy Predictions Max     499.838\n",
      "trainer/Z Policy Predictions Min     -65.2534\n",
      "trainer/Z Expert Targets Mean        520.244\n",
      "trainer/Z Expert Targets Std          79.108\n",
      "trainer/Z Expert Targets Max         548.99\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         76.6075\n",
      "trainer/Z Policy Targets Std         113.613\n",
      "trainer/Z Policy Targets Max         500.984\n",
      "trainer/Z Policy Targets Min         -59.4892\n",
      "trainer/Log Pis Mean                  15.5347\n",
      "trainer/Log Pis Std                    5.78651\n",
      "trainer/Policy mu Mean                 0.555544\n",
      "trainer/Policy mu Std                  3.34594\n",
      "trainer/Policy log std Mean           -2.50289\n",
      "trainer/Policy log std Std             1.18004\n",
      "exploration/num steps total        18189\n",
      "exploration/num paths total          705\n",
      "evaluation/num steps total          7650\n",
      "evaluation/num paths total            90\n",
      "evaluation/path length Mean          152.1\n",
      "evaluation/path length Std             1.13578\n",
      "evaluation/path length Max           155\n",
      "evaluation/path length Min           151\n",
      "evaluation/Rewards Mean                2.43791\n",
      "evaluation/Rewards Std                 0.686334\n",
      "evaluation/Rewards Max                 3.56193\n",
      "evaluation/Rewards Min                 0.639971\n",
      "evaluation/Returns Mean              370.807\n",
      "evaluation/Returns Std                 3.14979\n",
      "evaluation/Returns Max               378.676\n",
      "evaluation/Returns Min               367.895\n",
      "evaluation/Estimation Bias Mean      329.366\n",
      "evaluation/Estimation Bias Std       201.478\n",
      "evaluation/EB/Q_True Mean             13.7435\n",
      "evaluation/EB/Q_True Std              43.9533\n",
      "evaluation/EB/Q_Pred Mean            343.11\n",
      "evaluation/EB/Q_Pred Std             192.647\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           370.807\n",
      "evaluation/Actions Mean                0.00388199\n",
      "evaluation/Actions Std                 0.434284\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999596\n",
      "time/backward_policy (s)               1.63497\n",
      "time/backward_zf1 (s)                  1.76046\n",
      "time/backward_zf2 (s)                  1.68135\n",
      "time/data sampling (s)                 0.20259\n",
      "time/data storing (s)                  0.0137316\n",
      "time/evaluation sampling (s)           0.239449\n",
      "time/exploration sampling (s)          0.16699\n",
      "time/logging (s)                       0.00266349\n",
      "time/preback_alpha (s)                 0.547176\n",
      "time/preback_policy (s)                0.587388\n",
      "time/preback_start (s)                 0.119644\n",
      "time/preback_zf (s)                    4.91215\n",
      "time/saving (s)                        0.00494562\n",
      "time/training (s)                      2.63631\n",
      "time/epoch (s)                        14.5098\n",
      "time/total (s)                       134.397\n",
      "Epoch                                  8\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:03:35.764035 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 9 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 20000\n",
      "trainer/ZF1 Loss                     -17.8797\n",
      "trainer/ZF2 Loss                     -19.2113\n",
      "trainer/ZF Expert Reward              18.4185\n",
      "trainer/ZF Policy Reward             -11.6739\n",
      "trainer/ZF CHI2 Term                  25.5213\n",
      "trainer/Policy Loss                  -88.4423\n",
      "trainer/Policy Grad Norm              47.6516\n",
      "trainer/Policy Param Norm             22.637\n",
      "trainer/Zf1 Grad Norm               1130.34\n",
      "trainer/Zf1 Param Norm                51.1355\n",
      "trainer/Zf2 Grad Norm                791.613\n",
      "trainer/Zf2 Param Norm                50.0221\n",
      "trainer/Z Expert Predictions Mean    600.518\n",
      "trainer/Z Expert Predictions Std      81.1423\n",
      "trainer/Z Expert Predictions Max     628.779\n",
      "trainer/Z Expert Predictions Min      75.5026\n",
      "trainer/Z Policy Predictions Mean     71.8067\n",
      "trainer/Z Policy Predictions Std     116.59\n",
      "trainer/Z Policy Predictions Max     539.586\n",
      "trainer/Z Policy Predictions Min     -68.2253\n",
      "trainer/Z Expert Targets Mean        582.1\n",
      "trainer/Z Expert Targets Std          80.5857\n",
      "trainer/Z Expert Targets Max         610.118\n",
      "trainer/Z Expert Targets Min          52.806\n",
      "trainer/Z Policy Targets Mean         83.4805\n",
      "trainer/Z Policy Targets Std         120.787\n",
      "trainer/Z Policy Targets Max         551.099\n",
      "trainer/Z Policy Targets Min         -66.0083\n",
      "trainer/Log Pis Mean                  14.1155\n",
      "trainer/Log Pis Std                    5.98262\n",
      "trainer/Policy mu Mean                 0.374562\n",
      "trainer/Policy mu Std                  3.26524\n",
      "trainer/Policy log std Mean           -2.23938\n",
      "trainer/Policy log std Std             1.31054\n",
      "exploration/num steps total        19369\n",
      "exploration/num paths total          711\n",
      "evaluation/num steps total          9141\n",
      "evaluation/num paths total           100\n",
      "evaluation/path length Mean          149.1\n",
      "evaluation/path length Std             0.830662\n",
      "evaluation/path length Max           150\n",
      "evaluation/path length Min           148\n",
      "evaluation/Rewards Mean                2.73708\n",
      "evaluation/Rewards Std                 0.855185\n",
      "evaluation/Rewards Max                 3.90861\n",
      "evaluation/Rewards Min                 0.682677\n",
      "evaluation/Returns Mean              408.098\n",
      "evaluation/Returns Std                 1.99544\n",
      "evaluation/Returns Max               410.595\n",
      "evaluation/Returns Min               405.42\n",
      "evaluation/Estimation Bias Mean      417.047\n",
      "evaluation/Estimation Bias Std       231.434\n",
      "evaluation/EB/Q_True Mean             15.18\n",
      "evaluation/EB/Q_True Std              49.0507\n",
      "evaluation/EB/Q_Pred Mean            432.227\n",
      "evaluation/EB/Q_Pred Std             223.292\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           408.098\n",
      "evaluation/Actions Mean               -0.094862\n",
      "evaluation/Actions Std                 0.490377\n",
      "evaluation/Actions Max                 0.999981\n",
      "evaluation/Actions Min                -0.999997\n",
      "time/backward_policy (s)               1.60574\n",
      "time/backward_zf1 (s)                  1.73504\n",
      "time/backward_zf2 (s)                  1.65798\n",
      "time/data sampling (s)                 0.203445\n",
      "time/data storing (s)                  0.0135369\n",
      "time/evaluation sampling (s)           0.220036\n",
      "time/exploration sampling (s)          0.169545\n",
      "time/logging (s)                       0.00360042\n",
      "time/preback_alpha (s)                 0.535256\n",
      "time/preback_policy (s)                0.581754\n",
      "time/preback_start (s)                 0.118155\n",
      "time/preback_zf (s)                    4.89022\n",
      "time/saving (s)                        0.00471939\n",
      "time/training (s)                      2.63639\n",
      "time/epoch (s)                        14.3754\n",
      "time/total (s)                       148.791\n",
      "Epoch                                  9\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:03:50.478942 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 10 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 21000\n",
      "trainer/ZF1 Loss                     -10.669\n",
      "trainer/ZF2 Loss                     -10.4927\n",
      "trainer/ZF Expert Reward              19.1235\n",
      "trainer/ZF Policy Reward              -8.73494\n",
      "trainer/ZF CHI2 Term                  30.0708\n",
      "trainer/Policy Loss                  -88.5367\n",
      "trainer/Policy Grad Norm              30.3979\n",
      "trainer/Policy Param Norm             22.9876\n",
      "trainer/Zf1 Grad Norm                355.526\n",
      "trainer/Zf1 Param Norm                52.1745\n",
      "trainer/Zf2 Grad Norm                513.965\n",
      "trainer/Zf2 Param Norm                51.1016\n",
      "trainer/Z Expert Predictions Mean    644.097\n",
      "trainer/Z Expert Predictions Std     120.234\n",
      "trainer/Z Expert Predictions Max     685.951\n",
      "trainer/Z Expert Predictions Min      32.9663\n",
      "trainer/Z Policy Predictions Mean     77.131\n",
      "trainer/Z Policy Predictions Std     129.318\n",
      "trainer/Z Policy Predictions Max     637.653\n",
      "trainer/Z Policy Predictions Min     -58.1541\n",
      "trainer/Z Expert Targets Mean        624.973\n",
      "trainer/Z Expert Targets Std         119.379\n",
      "trainer/Z Expert Targets Max         666.798\n",
      "trainer/Z Expert Targets Min          24.5409\n",
      "trainer/Z Policy Targets Mean         85.866\n",
      "trainer/Z Policy Targets Std         133.036\n",
      "trainer/Z Policy Targets Max         636.699\n",
      "trainer/Z Policy Targets Min         -57.7932\n",
      "trainer/Log Pis Mean                  12.9224\n",
      "trainer/Log Pis Std                    5.62682\n",
      "trainer/Policy mu Mean                 0.91274\n",
      "trainer/Policy mu Std                  2.53151\n",
      "trainer/Policy log std Mean           -2.68787\n",
      "trainer/Policy log std Std             1.13164\n",
      "exploration/num steps total        20096\n",
      "exploration/num paths total          716\n",
      "evaluation/num steps total         10609\n",
      "evaluation/num paths total           110\n",
      "evaluation/path length Mean          146.8\n",
      "evaluation/path length Std             0.6\n",
      "evaluation/path length Max           148\n",
      "evaluation/path length Min           146\n",
      "evaluation/Rewards Mean                2.77434\n",
      "evaluation/Rewards Std                 0.924945\n",
      "evaluation/Rewards Max                 4.40032\n",
      "evaluation/Rewards Min                 0.957545\n",
      "evaluation/Returns Mean              407.273\n",
      "evaluation/Returns Std                 2.91898\n",
      "evaluation/Returns Max               413.943\n",
      "evaluation/Returns Min               402.75\n",
      "evaluation/Estimation Bias Mean      424.216\n",
      "evaluation/Estimation Bias Std       247.659\n",
      "evaluation/EB/Q_True Mean             15.6365\n",
      "evaluation/EB/Q_True Std              50.2058\n",
      "evaluation/EB/Q_Pred Mean            439.853\n",
      "evaluation/EB/Q_Pred Std             239.571\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           407.273\n",
      "evaluation/Actions Mean                0.00637156\n",
      "evaluation/Actions Std                 0.373534\n",
      "evaluation/Actions Max                 0.999927\n",
      "evaluation/Actions Min                -0.985602\n",
      "time/backward_policy (s)               1.7574\n",
      "time/backward_zf1 (s)                  1.87525\n",
      "time/backward_zf2 (s)                  1.80611\n",
      "time/data sampling (s)                 0.204878\n",
      "time/data storing (s)                  0.0138712\n",
      "time/evaluation sampling (s)           0.251445\n",
      "time/exploration sampling (s)          0.175115\n",
      "time/logging (s)                       0.0061873\n",
      "time/preback_alpha (s)                 0.548277\n",
      "time/preback_policy (s)                0.616083\n",
      "time/preback_start (s)                 0.12068\n",
      "time/preback_zf (s)                    4.9203\n",
      "time/saving (s)                        0.0236722\n",
      "time/training (s)                      2.32982\n",
      "time/epoch (s)                        14.6491\n",
      "time/total (s)                       163.465\n",
      "Epoch                                 10\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:04:05.054081 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 11 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 22000\n",
      "trainer/ZF1 Loss                       1.06529\n",
      "trainer/ZF2 Loss                       4.29544\n",
      "trainer/ZF Expert Reward              18.5585\n",
      "trainer/ZF Policy Reward              -6.69111\n",
      "trainer/ZF CHI2 Term                  40.1747\n",
      "trainer/Policy Loss                 -107.067\n",
      "trainer/Policy Grad Norm              39.6991\n",
      "trainer/Policy Param Norm             23.2417\n",
      "trainer/Zf1 Grad Norm                309.776\n",
      "trainer/Zf1 Param Norm                53.1175\n",
      "trainer/Zf2 Grad Norm                526.109\n",
      "trainer/Zf2 Param Norm                52.1485\n",
      "trainer/Z Expert Predictions Mean    699.216\n",
      "trainer/Z Expert Predictions Std     101.319\n",
      "trainer/Z Expert Predictions Max     737.114\n",
      "trainer/Z Expert Predictions Min      53.6206\n",
      "trainer/Z Policy Predictions Mean     98.2231\n",
      "trainer/Z Policy Predictions Std     166.174\n",
      "trainer/Z Policy Predictions Max     694.877\n",
      "trainer/Z Policy Predictions Min     -60.1912\n",
      "trainer/Z Expert Targets Mean        680.657\n",
      "trainer/Z Expert Targets Std         100.33\n",
      "trainer/Z Expert Targets Max         717.732\n",
      "trainer/Z Expert Targets Min          55.1153\n",
      "trainer/Z Policy Targets Mean        104.914\n",
      "trainer/Z Policy Targets Std         163.539\n",
      "trainer/Z Policy Targets Max         688.733\n",
      "trainer/Z Policy Targets Min         -51.327\n",
      "trainer/Log Pis Mean                  12.3684\n",
      "trainer/Log Pis Std                    5.64707\n",
      "trainer/Policy mu Mean                 0.788492\n",
      "trainer/Policy mu Std                  2.36627\n",
      "trainer/Policy log std Mean           -2.97731\n",
      "trainer/Policy log std Std             1.19317\n",
      "exploration/num steps total        21251\n",
      "exploration/num paths total          725\n",
      "evaluation/num steps total         12245\n",
      "evaluation/num paths total           120\n",
      "evaluation/path length Mean          163.6\n",
      "evaluation/path length Std             0.489898\n",
      "evaluation/path length Max           164\n",
      "evaluation/path length Min           163\n",
      "evaluation/Rewards Mean                2.80713\n",
      "evaluation/Rewards Std                 0.89754\n",
      "evaluation/Rewards Max                 4.40888\n",
      "evaluation/Rewards Min                 0.973748\n",
      "evaluation/Returns Mean              459.246\n",
      "evaluation/Returns Std                 1.42293\n",
      "evaluation/Returns Max               460.797\n",
      "evaluation/Returns Min               456.928\n",
      "evaluation/Estimation Bias Mean      472.35\n",
      "evaluation/Estimation Bias Std       244.176\n",
      "evaluation/EB/Q_True Mean             16.2971\n",
      "evaluation/EB/Q_True Std              52.2436\n",
      "evaluation/EB/Q_Pred Mean            488.647\n",
      "evaluation/EB/Q_Pred Std             237.863\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           459.246\n",
      "evaluation/Actions Mean               -0.0452825\n",
      "evaluation/Actions Std                 0.438302\n",
      "evaluation/Actions Max                 0.999827\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.72582\n",
      "time/backward_zf1 (s)                  1.83023\n",
      "time/backward_zf2 (s)                  1.77785\n",
      "time/data sampling (s)                 0.191834\n",
      "time/data storing (s)                  0.0135312\n",
      "time/evaluation sampling (s)           0.264562\n",
      "time/exploration sampling (s)          0.172719\n",
      "time/logging (s)                       0.00461961\n",
      "time/preback_alpha (s)                 0.529816\n",
      "time/preback_policy (s)                0.593602\n",
      "time/preback_start (s)                 0.114936\n",
      "time/preback_zf (s)                    4.89205\n",
      "time/saving (s)                        0.00735451\n",
      "time/training (s)                      2.38119\n",
      "time/epoch (s)                        14.5001\n",
      "time/total (s)                       177.997\n",
      "Epoch                                 11\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:04:19.536571 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 12 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 23000\n",
      "trainer/ZF1 Loss                      90.2901\n",
      "trainer/ZF2 Loss                      88.8648\n",
      "trainer/ZF Expert Reward              23.084\n",
      "trainer/ZF Policy Reward              -1.75407\n",
      "trainer/ZF CHI2 Term                 127.306\n",
      "trainer/Policy Loss                 -122.281\n",
      "trainer/Policy Grad Norm              41.844\n",
      "trainer/Policy Param Norm             23.5215\n",
      "trainer/Zf1 Grad Norm                461.268\n",
      "trainer/Zf1 Param Norm                54.0446\n",
      "trainer/Zf2 Grad Norm                423.733\n",
      "trainer/Zf2 Param Norm                53.2045\n",
      "trainer/Z Expert Predictions Mean    735.923\n",
      "trainer/Z Expert Predictions Std     125.659\n",
      "trainer/Z Expert Predictions Max     786.044\n",
      "trainer/Z Expert Predictions Min      48.1035\n",
      "trainer/Z Policy Predictions Mean    113.651\n",
      "trainer/Z Policy Predictions Std     191.664\n",
      "trainer/Z Policy Predictions Max     739.46\n",
      "trainer/Z Policy Predictions Min     -63.6806\n",
      "trainer/Z Expert Targets Mean        712.839\n",
      "trainer/Z Expert Targets Std         135.22\n",
      "trainer/Z Expert Targets Max         766.545\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        115.405\n",
      "trainer/Z Policy Targets Std         189.164\n",
      "trainer/Z Policy Targets Max         728.508\n",
      "trainer/Z Policy Targets Min         -53.251\n",
      "trainer/Log Pis Mean                  13.0206\n",
      "trainer/Log Pis Std                    5.49215\n",
      "trainer/Policy mu Mean                 1.02606\n",
      "trainer/Policy mu Std                  2.42614\n",
      "trainer/Policy log std Mean           -2.78287\n",
      "trainer/Policy log std Std             1.26559\n",
      "exploration/num steps total        22439\n",
      "exploration/num paths total          733\n",
      "evaluation/num steps total         13851\n",
      "evaluation/num paths total           130\n",
      "evaluation/path length Mean          160.6\n",
      "evaluation/path length Std             0.489898\n",
      "evaluation/path length Max           161\n",
      "evaluation/path length Min           160\n",
      "evaluation/Rewards Mean                2.5904\n",
      "evaluation/Rewards Std                 0.715765\n",
      "evaluation/Rewards Max                 3.91558\n",
      "evaluation/Rewards Min                 1.00482\n",
      "evaluation/Returns Mean              416.017\n",
      "evaluation/Returns Std                 1.7868\n",
      "evaluation/Returns Max               418.855\n",
      "evaluation/Returns Min               412.321\n",
      "evaluation/Estimation Bias Mean      378.212\n",
      "evaluation/Estimation Bias Std       254.255\n",
      "evaluation/EB/Q_True Mean             14.6545\n",
      "evaluation/EB/Q_True Std              47.1742\n",
      "evaluation/EB/Q_Pred Mean            392.866\n",
      "evaluation/EB/Q_Pred Std             252.028\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           416.017\n",
      "evaluation/Actions Mean               -0.0624914\n",
      "evaluation/Actions Std                 0.413459\n",
      "evaluation/Actions Max                 0.999925\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.70456\n",
      "time/backward_zf1 (s)                  1.80306\n",
      "time/backward_zf2 (s)                  1.74923\n",
      "time/data sampling (s)                 0.185009\n",
      "time/data storing (s)                  0.0133149\n",
      "time/evaluation sampling (s)           0.249608\n",
      "time/exploration sampling (s)          0.165981\n",
      "time/logging (s)                       0.00285618\n",
      "time/preback_alpha (s)                 0.524643\n",
      "time/preback_policy (s)                0.579848\n",
      "time/preback_start (s)                 0.112708\n",
      "time/preback_zf (s)                    4.87245\n",
      "time/saving (s)                        0.00496898\n",
      "time/training (s)                      2.4493\n",
      "time/epoch (s)                        14.4175\n",
      "time/total (s)                       192.436\n",
      "Epoch                                 12\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:04:34.178934 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 13 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 24000\n",
      "trainer/ZF1 Loss                     -18.6348\n",
      "trainer/ZF2 Loss                     -18.3506\n",
      "trainer/ZF Expert Reward              17.3066\n",
      "trainer/ZF Policy Reward              -7.18294\n",
      "trainer/ZF CHI2 Term                  18.8196\n",
      "trainer/Policy Loss                 -155.879\n",
      "trainer/Policy Grad Norm              70.6899\n",
      "trainer/Policy Param Norm             23.9214\n",
      "trainer/Zf1 Grad Norm                335.15\n",
      "trainer/Zf1 Param Norm                54.9114\n",
      "trainer/Zf2 Grad Norm                332.822\n",
      "trainer/Zf2 Param Norm                54.2002\n",
      "trainer/Z Expert Predictions Mean    778.227\n",
      "trainer/Z Expert Predictions Std     116.121\n",
      "trainer/Z Expert Predictions Max     828.262\n",
      "trainer/Z Expert Predictions Min      52.3025\n",
      "trainer/Z Policy Predictions Mean    144.2\n",
      "trainer/Z Policy Predictions Std     217.213\n",
      "trainer/Z Policy Predictions Max     784.558\n",
      "trainer/Z Policy Predictions Min     -71.7192\n",
      "trainer/Z Expert Targets Mean        760.921\n",
      "trainer/Z Expert Targets Std         113.602\n",
      "trainer/Z Expert Targets Max         810.893\n",
      "trainer/Z Expert Targets Min          59.9449\n",
      "trainer/Z Policy Targets Mean        151.383\n",
      "trainer/Z Policy Targets Std         214.084\n",
      "trainer/Z Policy Targets Max         771.965\n",
      "trainer/Z Policy Targets Min         -58.1065\n",
      "trainer/Log Pis Mean                  12.9523\n",
      "trainer/Log Pis Std                    5.09196\n",
      "trainer/Policy mu Mean                 0.906449\n",
      "trainer/Policy mu Std                  2.47801\n",
      "trainer/Policy log std Mean           -2.87139\n",
      "trainer/Policy log std Std             1.30703\n",
      "exploration/num steps total        22922\n",
      "exploration/num paths total          736\n",
      "evaluation/num steps total         15919\n",
      "evaluation/num paths total           140\n",
      "evaluation/path length Mean          206.8\n",
      "evaluation/path length Std             5.07543\n",
      "evaluation/path length Max           217\n",
      "evaluation/path length Min           200\n",
      "evaluation/Rewards Mean                3.14586\n",
      "evaluation/Rewards Std                 0.99861\n",
      "evaluation/Rewards Max                 4.96607\n",
      "evaluation/Rewards Min                 1.01578\n",
      "evaluation/Returns Mean              650.563\n",
      "evaluation/Returns Std                16.0043\n",
      "evaluation/Returns Max               682.412\n",
      "evaluation/Returns Min               629.061\n",
      "evaluation/Estimation Bias Mean      541.978\n",
      "evaluation/Estimation Bias Std       258.284\n",
      "evaluation/EB/Q_True Mean             22.1164\n",
      "evaluation/EB/Q_True Std              68.4201\n",
      "evaluation/EB/Q_Pred Mean            564.094\n",
      "evaluation/EB/Q_Pred Std             249.221\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           650.563\n",
      "evaluation/Actions Mean               -0.0590648\n",
      "evaluation/Actions Std                 0.515127\n",
      "evaluation/Actions Max                 0.99998\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.83642\n",
      "time/backward_zf1 (s)                  1.92066\n",
      "time/backward_zf2 (s)                  1.89619\n",
      "time/data sampling (s)                 0.186613\n",
      "time/data storing (s)                  0.0132169\n",
      "time/evaluation sampling (s)           0.31681\n",
      "time/exploration sampling (s)          0.165268\n",
      "time/logging (s)                       0.00338169\n",
      "time/preback_alpha (s)                 0.528637\n",
      "time/preback_policy (s)                0.603446\n",
      "time/preback_start (s)                 0.11316\n",
      "time/preback_zf (s)                    4.88252\n",
      "time/saving (s)                        0.00498156\n",
      "time/training (s)                      2.11118\n",
      "time/epoch (s)                        14.5825\n",
      "time/total (s)                       207.038\n",
      "Epoch                                 13\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:04:48.701511 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 14 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 25000\n",
      "trainer/ZF1 Loss                     -21.7117\n",
      "trainer/ZF2 Loss                     -22.4057\n",
      "trainer/ZF Expert Reward              17.5218\n",
      "trainer/ZF Policy Reward              -9.0958\n",
      "trainer/ZF CHI2 Term                  17.7593\n",
      "trainer/Policy Loss                 -188.233\n",
      "trainer/Policy Grad Norm              83.8107\n",
      "trainer/Policy Param Norm             24.3961\n",
      "trainer/Zf1 Grad Norm                440.601\n",
      "trainer/Zf1 Param Norm                55.7012\n",
      "trainer/Zf2 Grad Norm                396.194\n",
      "trainer/Zf2 Param Norm                55.0675\n",
      "trainer/Z Expert Predictions Mean    788.61\n",
      "trainer/Z Expert Predictions Std     173.169\n",
      "trainer/Z Expert Predictions Max     864.562\n",
      "trainer/Z Expert Predictions Min      75.9049\n",
      "trainer/Z Policy Predictions Mean    173.625\n",
      "trainer/Z Policy Predictions Std     222.358\n",
      "trainer/Z Policy Predictions Max     787.614\n",
      "trainer/Z Policy Predictions Min     -69.6314\n",
      "trainer/Z Expert Targets Mean        771.088\n",
      "trainer/Z Expert Targets Std         170.688\n",
      "trainer/Z Expert Targets Max         850.262\n",
      "trainer/Z Expert Targets Min          65.8429\n",
      "trainer/Z Policy Targets Mean        182.721\n",
      "trainer/Z Policy Targets Std         221.477\n",
      "trainer/Z Policy Targets Max         785.032\n",
      "trainer/Z Policy Targets Min         -68.169\n",
      "trainer/Log Pis Mean                  13.3337\n",
      "trainer/Log Pis Std                    5.18218\n",
      "trainer/Policy mu Mean                 1.04946\n",
      "trainer/Policy mu Std                  2.5735\n",
      "trainer/Policy log std Mean           -2.83382\n",
      "trainer/Policy log std Std             1.34722\n",
      "exploration/num steps total        24012\n",
      "exploration/num paths total          742\n",
      "evaluation/num steps total         17716\n",
      "evaluation/num paths total           150\n",
      "evaluation/path length Mean          179.7\n",
      "evaluation/path length Std             0.458258\n",
      "evaluation/path length Max           180\n",
      "evaluation/path length Min           179\n",
      "evaluation/Rewards Mean                2.71044\n",
      "evaluation/Rewards Std                 0.781067\n",
      "evaluation/Rewards Max                 4.46505\n",
      "evaluation/Rewards Min                 0.978353\n",
      "evaluation/Returns Mean              487.066\n",
      "evaluation/Returns Std                 3.11449\n",
      "evaluation/Returns Max               491.038\n",
      "evaluation/Returns Min               480.765\n",
      "evaluation/Estimation Bias Mean      557.928\n",
      "evaluation/Estimation Bias Std       218.662\n",
      "evaluation/EB/Q_True Mean             16.4347\n",
      "evaluation/EB/Q_True Std              52.5161\n",
      "evaluation/EB/Q_Pred Mean            574.363\n",
      "evaluation/EB/Q_Pred Std             209.174\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           487.066\n",
      "evaluation/Actions Mean               -0.00906683\n",
      "evaluation/Actions Std                 0.519509\n",
      "evaluation/Actions Max                 0.999994\n",
      "evaluation/Actions Min                -0.999206\n",
      "time/backward_policy (s)               1.66884\n",
      "time/backward_zf1 (s)                  1.77066\n",
      "time/backward_zf2 (s)                  1.71521\n",
      "time/data sampling (s)                 0.191073\n",
      "time/data storing (s)                  0.0135538\n",
      "time/evaluation sampling (s)           0.269601\n",
      "time/exploration sampling (s)          0.166961\n",
      "time/logging (s)                       0.00310829\n",
      "time/preback_alpha (s)                 0.526486\n",
      "time/preback_policy (s)                0.579919\n",
      "time/preback_start (s)                 0.113217\n",
      "time/preback_zf (s)                    4.90092\n",
      "time/saving (s)                        0.0046893\n",
      "time/training (s)                      2.53394\n",
      "time/epoch (s)                        14.4582\n",
      "time/total (s)                       221.52\n",
      "Epoch                                 14\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:05:03.200699 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 15 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 26000\n",
      "trainer/ZF1 Loss                      37.2051\n",
      "trainer/ZF2 Loss                      37.4927\n",
      "trainer/ZF Expert Reward              18.0115\n",
      "trainer/ZF Policy Reward              -3.53597\n",
      "trainer/ZF CHI2 Term                  72.8195\n",
      "trainer/Policy Loss                 -209.953\n",
      "trainer/Policy Grad Norm              55.7349\n",
      "trainer/Policy Param Norm             24.9505\n",
      "trainer/Zf1 Grad Norm                890.952\n",
      "trainer/Zf1 Param Norm                56.502\n",
      "trainer/Zf2 Grad Norm                949.073\n",
      "trainer/Zf2 Param Norm                55.8143\n",
      "trainer/Z Expert Predictions Mean    822.174\n",
      "trainer/Z Expert Predictions Std     127.505\n",
      "trainer/Z Expert Predictions Max     891.425\n",
      "trainer/Z Expert Predictions Min     127.881\n",
      "trainer/Z Policy Predictions Mean    195.97\n",
      "trainer/Z Policy Predictions Std     217.476\n",
      "trainer/Z Policy Predictions Max     782.961\n",
      "trainer/Z Policy Predictions Min     -70.9901\n",
      "trainer/Z Expert Targets Mean        804.162\n",
      "trainer/Z Expert Targets Std         126.583\n",
      "trainer/Z Expert Targets Max         876.353\n",
      "trainer/Z Expert Targets Min         122.424\n",
      "trainer/Z Policy Targets Mean        199.506\n",
      "trainer/Z Policy Targets Std         215.582\n",
      "trainer/Z Policy Targets Max         804.662\n",
      "trainer/Z Policy Targets Min         -71.2738\n",
      "trainer/Log Pis Mean                  14.0637\n",
      "trainer/Log Pis Std                    5.25628\n",
      "trainer/Policy mu Mean                 1.00487\n",
      "trainer/Policy mu Std                  2.76927\n",
      "trainer/Policy log std Mean           -2.77342\n",
      "trainer/Policy log std Std             1.29343\n",
      "exploration/num steps total        25529\n",
      "exploration/num paths total          751\n",
      "evaluation/num steps total         19117\n",
      "evaluation/num paths total           160\n",
      "evaluation/path length Mean          140.1\n",
      "evaluation/path length Std             2.77308\n",
      "evaluation/path length Max           144\n",
      "evaluation/path length Min           136\n",
      "evaluation/Rewards Mean                2.35225\n",
      "evaluation/Rewards Std                 0.573098\n",
      "evaluation/Rewards Max                 3.55431\n",
      "evaluation/Rewards Min                 0.982382\n",
      "evaluation/Returns Mean              329.55\n",
      "evaluation/Returns Std                 9.60609\n",
      "evaluation/Returns Max               342.039\n",
      "evaluation/Returns Min               316.693\n",
      "evaluation/Estimation Bias Mean      339.778\n",
      "evaluation/Estimation Bias Std       235.099\n",
      "evaluation/EB/Q_True Mean             12.8068\n",
      "evaluation/EB/Q_True Std              40.8692\n",
      "evaluation/EB/Q_Pred Mean            352.585\n",
      "evaluation/EB/Q_Pred Std             234.157\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           329.55\n",
      "evaluation/Actions Mean                0.0666048\n",
      "evaluation/Actions Std                 0.51021\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.998364\n",
      "time/backward_policy (s)               1.70445\n",
      "time/backward_zf1 (s)                  1.81051\n",
      "time/backward_zf2 (s)                  1.75516\n",
      "time/data sampling (s)                 0.191377\n",
      "time/data storing (s)                  0.013176\n",
      "time/evaluation sampling (s)           0.211794\n",
      "time/exploration sampling (s)          0.165404\n",
      "time/logging (s)                       0.00254694\n",
      "time/preback_alpha (s)                 0.526229\n",
      "time/preback_policy (s)                0.588712\n",
      "time/preback_start (s)                 0.113917\n",
      "time/preback_zf (s)                    4.88345\n",
      "time/saving (s)                        0.00470684\n",
      "time/training (s)                      2.46986\n",
      "time/epoch (s)                        14.4413\n",
      "time/total (s)                       235.977\n",
      "Epoch                                 15\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:05:17.795795 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 16 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 27000\n",
      "trainer/ZF1 Loss                      -2.63291\n",
      "trainer/ZF2 Loss                      -5.92498\n",
      "trainer/ZF Expert Reward              18.1385\n",
      "trainer/ZF Policy Reward             -12.3981\n",
      "trainer/ZF CHI2 Term                  41.0564\n",
      "trainer/Policy Loss                 -251.443\n",
      "trainer/Policy Grad Norm              48.0663\n",
      "trainer/Policy Param Norm             25.3513\n",
      "trainer/Zf1 Grad Norm               1498.22\n",
      "trainer/Zf1 Param Norm                57.292\n",
      "trainer/Zf2 Grad Norm                926.665\n",
      "trainer/Zf2 Param Norm                56.6261\n",
      "trainer/Z Expert Predictions Mean    841.551\n",
      "trainer/Z Expert Predictions Std      97.7506\n",
      "trainer/Z Expert Predictions Max     912.749\n",
      "trainer/Z Expert Predictions Min     225.832\n",
      "trainer/Z Policy Predictions Mean    235.405\n",
      "trainer/Z Policy Predictions Std     237.805\n",
      "trainer/Z Policy Predictions Max     816.862\n",
      "trainer/Z Policy Predictions Min     -78.0565\n",
      "trainer/Z Expert Targets Mean        823.413\n",
      "trainer/Z Expert Targets Std          94.1649\n",
      "trainer/Z Expert Targets Max         896.46\n",
      "trainer/Z Expert Targets Min         228.911\n",
      "trainer/Z Policy Targets Mean        247.803\n",
      "trainer/Z Policy Targets Std         235.309\n",
      "trainer/Z Policy Targets Max         802.294\n",
      "trainer/Z Policy Targets Min         -74.222\n",
      "trainer/Log Pis Mean                  14.9482\n",
      "trainer/Log Pis Std                    5.87293\n",
      "trainer/Policy mu Mean                 1.36437\n",
      "trainer/Policy mu Std                  3.06622\n",
      "trainer/Policy log std Mean           -2.65073\n",
      "trainer/Policy log std Std             1.31434\n",
      "exploration/num steps total        25824\n",
      "exploration/num paths total          753\n",
      "evaluation/num steps total         21479\n",
      "evaluation/num paths total           170\n",
      "evaluation/path length Mean          236.2\n",
      "evaluation/path length Std             2.67582\n",
      "evaluation/path length Max           241\n",
      "evaluation/path length Min           231\n",
      "evaluation/Rewards Mean                2.71334\n",
      "evaluation/Rewards Std                 0.843475\n",
      "evaluation/Rewards Max                 5.31773\n",
      "evaluation/Rewards Min                 0.998626\n",
      "evaluation/Returns Mean              640.89\n",
      "evaluation/Returns Std                11.965\n",
      "evaluation/Returns Max               660.359\n",
      "evaluation/Returns Min               618.148\n",
      "evaluation/Estimation Bias Mean      405.962\n",
      "evaluation/Estimation Bias Std       173.204\n",
      "evaluation/EB/Q_True Mean             19.3607\n",
      "evaluation/EB/Q_True Std              60.1\n",
      "evaluation/EB/Q_Pred Mean            425.322\n",
      "evaluation/EB/Q_Pred Std             160.347\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           640.89\n",
      "evaluation/Actions Mean                0.00802567\n",
      "evaluation/Actions Std                 0.564695\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999735\n",
      "time/backward_policy (s)               1.79466\n",
      "time/backward_zf1 (s)                  1.87603\n",
      "time/backward_zf2 (s)                  1.84319\n",
      "time/data sampling (s)                 0.18389\n",
      "time/data storing (s)                  0.0132052\n",
      "time/evaluation sampling (s)           0.35379\n",
      "time/exploration sampling (s)          0.161446\n",
      "time/logging (s)                       0.00484922\n",
      "time/preback_alpha (s)                 0.525387\n",
      "time/preback_policy (s)                0.596237\n",
      "time/preback_start (s)                 0.111628\n",
      "time/preback_zf (s)                    4.87356\n",
      "time/saving (s)                        0.0061821\n",
      "time/training (s)                      2.19583\n",
      "time/epoch (s)                        14.5399\n",
      "time/total (s)                       250.533\n",
      "Epoch                                 16\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:05:32.324903 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 17 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 28000\n",
      "trainer/ZF1 Loss                      -6.92881\n",
      "trainer/ZF2 Loss                      -4.16844\n",
      "trainer/ZF Expert Reward              17.1832\n",
      "trainer/ZF Policy Reward              -8.95775\n",
      "trainer/ZF CHI2 Term                  35.4607\n",
      "trainer/Policy Loss                 -271.942\n",
      "trainer/Policy Grad Norm              79.1886\n",
      "trainer/Policy Param Norm             25.6326\n",
      "trainer/Zf1 Grad Norm               1168.11\n",
      "trainer/Zf1 Param Norm                57.9473\n",
      "trainer/Zf2 Grad Norm               1192.78\n",
      "trainer/Zf2 Param Norm                57.3315\n",
      "trainer/Z Expert Predictions Mean    826.133\n",
      "trainer/Z Expert Predictions Std     122.54\n",
      "trainer/Z Expert Predictions Max     927.645\n",
      "trainer/Z Expert Predictions Min     176.654\n",
      "trainer/Z Policy Predictions Mean    257.46\n",
      "trainer/Z Policy Predictions Std     226.936\n",
      "trainer/Z Policy Predictions Max     785.728\n",
      "trainer/Z Policy Predictions Min     -86.593\n",
      "trainer/Z Expert Targets Mean        808.949\n",
      "trainer/Z Expert Targets Std         119.764\n",
      "trainer/Z Expert Targets Max         907.214\n",
      "trainer/Z Expert Targets Min         169.467\n",
      "trainer/Z Policy Targets Mean        266.417\n",
      "trainer/Z Policy Targets Std         227.189\n",
      "trainer/Z Policy Targets Max         797.623\n",
      "trainer/Z Policy Targets Min         -89.2027\n",
      "trainer/Log Pis Mean                  15.0186\n",
      "trainer/Log Pis Std                    5.91625\n",
      "trainer/Policy mu Mean                 1.05424\n",
      "trainer/Policy mu Std                  3.14094\n",
      "trainer/Policy log std Mean           -2.71678\n",
      "trainer/Policy log std Std             1.302\n",
      "exploration/num steps total        26560\n",
      "exploration/num paths total          757\n",
      "evaluation/num steps total         23668\n",
      "evaluation/num paths total           180\n",
      "evaluation/path length Mean          218.9\n",
      "evaluation/path length Std             8.43149\n",
      "evaluation/path length Max           233\n",
      "evaluation/path length Min           207\n",
      "evaluation/Rewards Mean                2.2512\n",
      "evaluation/Rewards Std                 0.633857\n",
      "evaluation/Rewards Max                 4.27727\n",
      "evaluation/Rewards Min                 0.958088\n",
      "evaluation/Returns Mean              492.788\n",
      "evaluation/Returns Std                24.1888\n",
      "evaluation/Returns Max               536.163\n",
      "evaluation/Returns Min               457.97\n",
      "evaluation/Estimation Bias Mean      222.294\n",
      "evaluation/Estimation Bias Std       155.264\n",
      "evaluation/EB/Q_True Mean             16.4738\n",
      "evaluation/EB/Q_True Std              50.1478\n",
      "evaluation/EB/Q_Pred Mean            238.768\n",
      "evaluation/EB/Q_Pred Std             148.876\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           492.788\n",
      "evaluation/Actions Mean                0.0196303\n",
      "evaluation/Actions Std                 0.522308\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999765\n",
      "time/backward_policy (s)               1.58973\n",
      "time/backward_zf1 (s)                  1.71069\n",
      "time/backward_zf2 (s)                  1.64562\n",
      "time/data sampling (s)                 0.189874\n",
      "time/data storing (s)                  0.0136263\n",
      "time/evaluation sampling (s)           0.364826\n",
      "time/exploration sampling (s)          0.161413\n",
      "time/logging (s)                       0.00408537\n",
      "time/preback_alpha (s)                 0.526794\n",
      "time/preback_policy (s)                0.569581\n",
      "time/preback_start (s)                 0.114408\n",
      "time/preback_zf (s)                    4.88252\n",
      "time/saving (s)                        0.00470913\n",
      "time/training (s)                      2.69088\n",
      "time/epoch (s)                        14.4688\n",
      "time/total (s)                       265.021\n",
      "Epoch                                 17\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:05:46.852401 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 18 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 29000\n",
      "trainer/ZF1 Loss                     -10.153\n",
      "trainer/ZF2 Loss                     -11.9211\n",
      "trainer/ZF Expert Reward              18.5795\n",
      "trainer/ZF Policy Reward              -6.85234\n",
      "trainer/ZF CHI2 Term                  29.3811\n",
      "trainer/Policy Loss                 -302.513\n",
      "trainer/Policy Grad Norm              86.798\n",
      "trainer/Policy Param Norm             25.8631\n",
      "trainer/Zf1 Grad Norm               1063.8\n",
      "trainer/Zf1 Param Norm                58.4879\n",
      "trainer/Zf2 Grad Norm                380.115\n",
      "trainer/Zf2 Param Norm                57.8853\n",
      "trainer/Z Expert Predictions Mean    818.69\n",
      "trainer/Z Expert Predictions Std     113.903\n",
      "trainer/Z Expert Predictions Max     941.182\n",
      "trainer/Z Expert Predictions Min     174.362\n",
      "trainer/Z Policy Predictions Mean    284.244\n",
      "trainer/Z Policy Predictions Std     215.641\n",
      "trainer/Z Policy Predictions Max     859.859\n",
      "trainer/Z Policy Predictions Min     -80.7362\n",
      "trainer/Z Expert Targets Mean        800.11\n",
      "trainer/Z Expert Targets Std         111.8\n",
      "trainer/Z Expert Targets Max         925.563\n",
      "trainer/Z Expert Targets Min         179.295\n",
      "trainer/Z Policy Targets Mean        291.096\n",
      "trainer/Z Policy Targets Std         215.105\n",
      "trainer/Z Policy Targets Max         836.444\n",
      "trainer/Z Policy Targets Min         -80.0083\n",
      "trainer/Log Pis Mean                  15.1377\n",
      "trainer/Log Pis Std                    6.36327\n",
      "trainer/Policy mu Mean                 0.935919\n",
      "trainer/Policy mu Std                  3.14858\n",
      "trainer/Policy log std Mean           -2.75263\n",
      "trainer/Policy log std Std             1.24256\n",
      "exploration/num steps total        27016\n",
      "exploration/num paths total          759\n",
      "evaluation/num steps total         25453\n",
      "evaluation/num paths total           190\n",
      "evaluation/path length Mean          178.5\n",
      "evaluation/path length Std             1.11803\n",
      "evaluation/path length Max           181\n",
      "evaluation/path length Min           177\n",
      "evaluation/Rewards Mean                2.74353\n",
      "evaluation/Rewards Std                 0.76579\n",
      "evaluation/Rewards Max                 3.97488\n",
      "evaluation/Rewards Min                 0.863225\n",
      "evaluation/Returns Mean              489.72\n",
      "evaluation/Returns Std                 3.52376\n",
      "evaluation/Returns Max               497.184\n",
      "evaluation/Returns Min               485.505\n",
      "evaluation/Estimation Bias Mean      379.118\n",
      "evaluation/Estimation Bias Std       277.718\n",
      "evaluation/EB/Q_True Mean             16.8418\n",
      "evaluation/EB/Q_True Std              53.603\n",
      "evaluation/EB/Q_Pred Mean            395.96\n",
      "evaluation/EB/Q_Pred Std             276.611\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           489.72\n",
      "evaluation/Actions Mean                0.0119579\n",
      "evaluation/Actions Std                 0.566877\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.73869\n",
      "time/backward_zf1 (s)                  1.83088\n",
      "time/backward_zf2 (s)                  1.78826\n",
      "time/data sampling (s)                 0.18973\n",
      "time/data storing (s)                  0.0132447\n",
      "time/evaluation sampling (s)           0.265209\n",
      "time/exploration sampling (s)          0.160821\n",
      "time/logging (s)                       0.00303477\n",
      "time/preback_alpha (s)                 0.52735\n",
      "time/preback_policy (s)                0.589574\n",
      "time/preback_start (s)                 0.113297\n",
      "time/preback_zf (s)                    4.88379\n",
      "time/saving (s)                        0.00473031\n",
      "time/training (s)                      2.35663\n",
      "time/epoch (s)                        14.4652\n",
      "time/total (s)                       279.506\n",
      "Epoch                                 18\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:06:01.291248 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 19 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 30000\n",
      "trainer/ZF1 Loss                     -11.3148\n",
      "trainer/ZF2 Loss                     -12.0653\n",
      "trainer/ZF Expert Reward              15.9431\n",
      "trainer/ZF Policy Reward             -10.1386\n",
      "trainer/ZF CHI2 Term                  30.1711\n",
      "trainer/Policy Loss                 -331.563\n",
      "trainer/Policy Grad Norm              73.635\n",
      "trainer/Policy Param Norm             26.0511\n",
      "trainer/Zf1 Grad Norm               1087.24\n",
      "trainer/Zf1 Param Norm                58.9116\n",
      "trainer/Zf2 Grad Norm                905.477\n",
      "trainer/Zf2 Param Norm                58.2898\n",
      "trainer/Z Expert Predictions Mean    789\n",
      "trainer/Z Expert Predictions Std     121.784\n",
      "trainer/Z Expert Predictions Max     952.098\n",
      "trainer/Z Expert Predictions Min     179.778\n",
      "trainer/Z Policy Predictions Mean    312.027\n",
      "trainer/Z Policy Predictions Std     227.68\n",
      "trainer/Z Policy Predictions Max     821.329\n",
      "trainer/Z Policy Predictions Min     -92.1467\n",
      "trainer/Z Expert Targets Mean        773.057\n",
      "trainer/Z Expert Targets Std         119.416\n",
      "trainer/Z Expert Targets Max         942.689\n",
      "trainer/Z Expert Targets Min         185.741\n",
      "trainer/Z Policy Targets Mean        322.165\n",
      "trainer/Z Policy Targets Std         226.284\n",
      "trainer/Z Policy Targets Max         811.017\n",
      "trainer/Z Policy Targets Min         -88.1704\n",
      "trainer/Log Pis Mean                  15.9389\n",
      "trainer/Log Pis Std                    6.18511\n",
      "trainer/Policy mu Mean                 1.04206\n",
      "trainer/Policy mu Std                  3.25302\n",
      "trainer/Policy log std Mean           -2.80075\n",
      "trainer/Policy log std Std             1.30274\n",
      "exploration/num steps total        29267\n",
      "exploration/num paths total          767\n",
      "evaluation/num steps total         27052\n",
      "evaluation/num paths total           200\n",
      "evaluation/path length Mean          159.9\n",
      "evaluation/path length Std             0.538516\n",
      "evaluation/path length Max           161\n",
      "evaluation/path length Min           159\n",
      "evaluation/Rewards Mean                2.81951\n",
      "evaluation/Rewards Std                 0.859427\n",
      "evaluation/Rewards Max                 4.29521\n",
      "evaluation/Rewards Min                 0.784098\n",
      "evaluation/Returns Mean              450.84\n",
      "evaluation/Returns Std                 2.67195\n",
      "evaluation/Returns Max               456.303\n",
      "evaluation/Returns Min               447.381\n",
      "evaluation/Estimation Bias Mean      375.139\n",
      "evaluation/Estimation Bias Std       298.182\n",
      "evaluation/EB/Q_True Mean             16.4057\n",
      "evaluation/EB/Q_True Std              52.5392\n",
      "evaluation/EB/Q_Pred Mean            391.545\n",
      "evaluation/EB/Q_Pred Std             298.069\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           450.84\n",
      "evaluation/Actions Mean               -0.0361688\n",
      "evaluation/Actions Std                 0.601828\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999966\n",
      "time/backward_policy (s)               1.554\n",
      "time/backward_zf1 (s)                  1.68051\n",
      "time/backward_zf2 (s)                  1.60533\n",
      "time/data sampling (s)                 0.19491\n",
      "time/data storing (s)                  0.0133186\n",
      "time/evaluation sampling (s)           0.263324\n",
      "time/exploration sampling (s)          0.168272\n",
      "time/logging (s)                       0.00381733\n",
      "time/preback_alpha (s)                 0.526451\n",
      "time/preback_policy (s)                0.55987\n",
      "time/preback_start (s)                 0.115016\n",
      "time/preback_zf (s)                    4.88908\n",
      "time/saving (s)                        0.00844331\n",
      "time/training (s)                      2.79757\n",
      "time/epoch (s)                        14.3799\n",
      "time/total (s)                       293.905\n",
      "Epoch                                 19\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:06:15.776739 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 20 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 31000\n",
      "trainer/ZF1 Loss                      -9.26889\n",
      "trainer/ZF2 Loss                     -10.7894\n",
      "trainer/ZF Expert Reward              23.3348\n",
      "trainer/ZF Policy Reward              -5.46469\n",
      "trainer/ZF CHI2 Term                  33.4721\n",
      "trainer/Policy Loss                 -323.117\n",
      "trainer/Policy Grad Norm              55.3148\n",
      "trainer/Policy Param Norm             26.2302\n",
      "trainer/Zf1 Grad Norm                791.732\n",
      "trainer/Zf1 Param Norm                59.3762\n",
      "trainer/Zf2 Grad Norm                945.168\n",
      "trainer/Zf2 Param Norm                58.7551\n",
      "trainer/Z Expert Predictions Mean    786.429\n",
      "trainer/Z Expert Predictions Std     126.215\n",
      "trainer/Z Expert Predictions Max     960.654\n",
      "trainer/Z Expert Predictions Min     232.69\n",
      "trainer/Z Policy Predictions Mean    307.41\n",
      "trainer/Z Policy Predictions Std     219.536\n",
      "trainer/Z Policy Predictions Max     889.828\n",
      "trainer/Z Policy Predictions Min    -100.826\n",
      "trainer/Z Expert Targets Mean        763.094\n",
      "trainer/Z Expert Targets Std         125.602\n",
      "trainer/Z Expert Targets Max         952.279\n",
      "trainer/Z Expert Targets Min         229.709\n",
      "trainer/Z Policy Targets Mean        312.875\n",
      "trainer/Z Policy Targets Std         220.204\n",
      "trainer/Z Policy Targets Max         920.167\n",
      "trainer/Z Policy Targets Min        -103.791\n",
      "trainer/Log Pis Mean                  14.8503\n",
      "trainer/Log Pis Std                    6.3457\n",
      "trainer/Policy mu Mean                 1.04363\n",
      "trainer/Policy mu Std                  3.08179\n",
      "trainer/Policy log std Mean           -2.6633\n",
      "trainer/Policy log std Std             1.25134\n",
      "exploration/num steps total        29814\n",
      "exploration/num paths total          770\n",
      "evaluation/num steps total         28395\n",
      "evaluation/num paths total           210\n",
      "evaluation/path length Mean          134.3\n",
      "evaluation/path length Std             0.458258\n",
      "evaluation/path length Max           135\n",
      "evaluation/path length Min           134\n",
      "evaluation/Rewards Mean                2.50659\n",
      "evaluation/Rewards Std                 0.69987\n",
      "evaluation/Rewards Max                 3.33564\n",
      "evaluation/Rewards Min                 0.780622\n",
      "evaluation/Returns Mean              336.635\n",
      "evaluation/Returns Std                 3.23644\n",
      "evaluation/Returns Max               343.396\n",
      "evaluation/Returns Min               332.474\n",
      "evaluation/Estimation Bias Mean      608.186\n",
      "evaluation/Estimation Bias Std       187.843\n",
      "evaluation/EB/Q_True Mean             12.8642\n",
      "evaluation/EB/Q_True Std              41.9837\n",
      "evaluation/EB/Q_Pred Mean            621.051\n",
      "evaluation/EB/Q_Pred Std             180.64\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           336.635\n",
      "evaluation/Actions Mean                0.043646\n",
      "evaluation/Actions Std                 0.542157\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999811\n",
      "time/backward_policy (s)               1.64958\n",
      "time/backward_zf1 (s)                  1.75643\n",
      "time/backward_zf2 (s)                  1.69798\n",
      "time/data sampling (s)                 0.190577\n",
      "time/data storing (s)                  0.0132554\n",
      "time/evaluation sampling (s)           0.21805\n",
      "time/exploration sampling (s)          0.160005\n",
      "time/logging (s)                       0.00264953\n",
      "time/preback_alpha (s)                 0.529092\n",
      "time/preback_policy (s)                0.578612\n",
      "time/preback_start (s)                 0.114389\n",
      "time/preback_zf (s)                    4.89817\n",
      "time/saving (s)                        0.00552102\n",
      "time/training (s)                      2.60876\n",
      "time/epoch (s)                        14.4231\n",
      "time/total (s)                       308.348\n",
      "Epoch                                 20\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:06:30.148039 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 21 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 32000\n",
      "trainer/ZF1 Loss                      -4.60175\n",
      "trainer/ZF2 Loss                      -7.19943\n",
      "trainer/ZF Expert Reward              11.4583\n",
      "trainer/ZF Policy Reward             -10.9461\n",
      "trainer/ZF CHI2 Term                  31.2199\n",
      "trainer/Policy Loss                 -304.125\n",
      "trainer/Policy Grad Norm              62.9561\n",
      "trainer/Policy Param Norm             26.3629\n",
      "trainer/Zf1 Grad Norm               2464.33\n",
      "trainer/Zf1 Param Norm                59.8774\n",
      "trainer/Zf2 Grad Norm               1908.28\n",
      "trainer/Zf2 Param Norm                59.2105\n",
      "trainer/Z Expert Predictions Mean    797.025\n",
      "trainer/Z Expert Predictions Std     118.415\n",
      "trainer/Z Expert Predictions Max     976.42\n",
      "trainer/Z Expert Predictions Min     318.885\n",
      "trainer/Z Policy Predictions Mean    284.617\n",
      "trainer/Z Policy Predictions Std     222.74\n",
      "trainer/Z Policy Predictions Max     835.822\n",
      "trainer/Z Policy Predictions Min    -105.554\n",
      "trainer/Z Expert Targets Mean        785.566\n",
      "trainer/Z Expert Targets Std         115.697\n",
      "trainer/Z Expert Targets Max         963.316\n",
      "trainer/Z Expert Targets Min         294.982\n",
      "trainer/Z Policy Targets Mean        295.564\n",
      "trainer/Z Policy Targets Std         226.949\n",
      "trainer/Z Policy Targets Max         852.059\n",
      "trainer/Z Policy Targets Min        -105.953\n",
      "trainer/Log Pis Mean                  14.8647\n",
      "trainer/Log Pis Std                    5.94222\n",
      "trainer/Policy mu Mean                 0.895359\n",
      "trainer/Policy mu Std                  3.00529\n",
      "trainer/Policy log std Mean           -2.7579\n",
      "trainer/Policy log std Std             1.33226\n",
      "exploration/num steps total        31264\n",
      "exploration/num paths total          778\n",
      "evaluation/num steps total         29772\n",
      "evaluation/num paths total           220\n",
      "evaluation/path length Mean          137.7\n",
      "evaluation/path length Std             1.00499\n",
      "evaluation/path length Max           139\n",
      "evaluation/path length Min           136\n",
      "evaluation/Rewards Mean                2.51588\n",
      "evaluation/Rewards Std                 0.697273\n",
      "evaluation/Rewards Max                 3.41012\n",
      "evaluation/Rewards Min                 0.77145\n",
      "evaluation/Returns Mean              346.437\n",
      "evaluation/Returns Std                 4.2151\n",
      "evaluation/Returns Max               351.444\n",
      "evaluation/Returns Min               338.713\n",
      "evaluation/Estimation Bias Mean      603.592\n",
      "evaluation/Estimation Bias Std       175.152\n",
      "evaluation/EB/Q_True Mean             13.1769\n",
      "evaluation/EB/Q_True Std              42.899\n",
      "evaluation/EB/Q_Pred Mean            616.769\n",
      "evaluation/EB/Q_Pred Std             166.148\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           346.437\n",
      "evaluation/Actions Mean                0.112741\n",
      "evaluation/Actions Std                 0.583855\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999923\n",
      "time/backward_policy (s)               1.56157\n",
      "time/backward_zf1 (s)                  1.69445\n",
      "time/backward_zf2 (s)                  1.6202\n",
      "time/data sampling (s)                 0.192204\n",
      "time/data storing (s)                  0.0133413\n",
      "time/evaluation sampling (s)           0.224076\n",
      "time/exploration sampling (s)          0.164387\n",
      "time/logging (s)                       0.00256292\n",
      "time/preback_alpha (s)                 0.525324\n",
      "time/preback_policy (s)                0.56477\n",
      "time/preback_start (s)                 0.114192\n",
      "time/preback_zf (s)                    4.87899\n",
      "time/saving (s)                        0.00468391\n",
      "time/training (s)                      2.75132\n",
      "time/epoch (s)                        14.3121\n",
      "time/total (s)                       322.679\n",
      "Epoch                                 21\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:06:44.570851 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 22 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 33000\n",
      "trainer/ZF1 Loss                      -5.35418\n",
      "trainer/ZF2 Loss                      -7.33389\n",
      "trainer/ZF Expert Reward              16.1239\n",
      "trainer/ZF Policy Reward             -10.3491\n",
      "trainer/ZF CHI2 Term                  33.8963\n",
      "trainer/Policy Loss                 -344.461\n",
      "trainer/Policy Grad Norm              78.6456\n",
      "trainer/Policy Param Norm             26.4763\n",
      "trainer/Zf1 Grad Norm               1562.13\n",
      "trainer/Zf1 Param Norm                60.3873\n",
      "trainer/Zf2 Grad Norm               1557.16\n",
      "trainer/Zf2 Param Norm                59.6305\n",
      "trainer/Z Expert Predictions Mean    787.749\n",
      "trainer/Z Expert Predictions Std     135.145\n",
      "trainer/Z Expert Predictions Max     993.448\n",
      "trainer/Z Expert Predictions Min     263.845\n",
      "trainer/Z Policy Predictions Mean    328.85\n",
      "trainer/Z Policy Predictions Std     233.818\n",
      "trainer/Z Policy Predictions Max     858.714\n",
      "trainer/Z Policy Predictions Min    -118.644\n",
      "trainer/Z Expert Targets Mean        771.625\n",
      "trainer/Z Expert Targets Std         132.869\n",
      "trainer/Z Expert Targets Max         979.944\n",
      "trainer/Z Expert Targets Min         273.59\n",
      "trainer/Z Policy Targets Mean        339.199\n",
      "trainer/Z Policy Targets Std         231.416\n",
      "trainer/Z Policy Targets Max         897.191\n",
      "trainer/Z Policy Targets Min        -119.23\n",
      "trainer/Log Pis Mean                  13.9064\n",
      "trainer/Log Pis Std                    5.84778\n",
      "trainer/Policy mu Mean                 1.27162\n",
      "trainer/Policy mu Std                  2.6039\n",
      "trainer/Policy log std Mean           -3.05111\n",
      "trainer/Policy log std Std             1.37291\n",
      "exploration/num steps total        32345\n",
      "exploration/num paths total          785\n",
      "evaluation/num steps total         31143\n",
      "evaluation/num paths total           230\n",
      "evaluation/path length Mean          137.1\n",
      "evaluation/path length Std             0.943398\n",
      "evaluation/path length Max           138\n",
      "evaluation/path length Min           135\n",
      "evaluation/Rewards Mean                2.54404\n",
      "evaluation/Rewards Std                 0.721683\n",
      "evaluation/Rewards Max                 3.40981\n",
      "evaluation/Rewards Min                 0.698887\n",
      "evaluation/Returns Mean              348.788\n",
      "evaluation/Returns Std                 5.91227\n",
      "evaluation/Returns Max               356.704\n",
      "evaluation/Returns Min               339.645\n",
      "evaluation/Estimation Bias Mean      578.84\n",
      "evaluation/Estimation Bias Std       161.167\n",
      "evaluation/EB/Q_True Mean             13.4449\n",
      "evaluation/EB/Q_True Std              43.8991\n",
      "evaluation/EB/Q_Pred Mean            592.285\n",
      "evaluation/EB/Q_Pred Std             154.426\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           348.788\n",
      "evaluation/Actions Mean                0.0836196\n",
      "evaluation/Actions Std                 0.545716\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.99998\n",
      "time/backward_policy (s)               1.66311\n",
      "time/backward_zf1 (s)                  1.76305\n",
      "time/backward_zf2 (s)                  1.70767\n",
      "time/data sampling (s)                 0.192241\n",
      "time/data storing (s)                  0.0135795\n",
      "time/evaluation sampling (s)           0.204977\n",
      "time/exploration sampling (s)          0.164254\n",
      "time/logging (s)                       0.0029455\n",
      "time/preback_alpha (s)                 0.525056\n",
      "time/preback_policy (s)                0.578518\n",
      "time/preback_start (s)                 0.114107\n",
      "time/preback_zf (s)                    4.88463\n",
      "time/saving (s)                        0.00455239\n",
      "time/training (s)                      2.5448\n",
      "time/epoch (s)                        14.3635\n",
      "time/total (s)                       337.061\n",
      "Epoch                                 22\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:06:59.020671 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 23 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 34000\n",
      "trainer/ZF1 Loss                      -1.82415\n",
      "trainer/ZF2 Loss                      -0.109573\n",
      "trainer/ZF Expert Reward              17.9079\n",
      "trainer/ZF Policy Reward              -6.11041\n",
      "trainer/ZF CHI2 Term                  36.8944\n",
      "trainer/Policy Loss                 -335.838\n",
      "trainer/Policy Grad Norm              59.1377\n",
      "trainer/Policy Param Norm             26.5812\n",
      "trainer/Zf1 Grad Norm               1646.36\n",
      "trainer/Zf1 Param Norm                60.9076\n",
      "trainer/Zf2 Grad Norm               2007.01\n",
      "trainer/Zf2 Param Norm                60.1768\n",
      "trainer/Z Expert Predictions Mean    782.791\n",
      "trainer/Z Expert Predictions Std     150.403\n",
      "trainer/Z Expert Predictions Max     994.809\n",
      "trainer/Z Expert Predictions Min     267.318\n",
      "trainer/Z Policy Predictions Mean    319.281\n",
      "trainer/Z Policy Predictions Std     220.042\n",
      "trainer/Z Policy Predictions Max     893.159\n",
      "trainer/Z Policy Predictions Min    -130.458\n",
      "trainer/Z Expert Targets Mean        764.884\n",
      "trainer/Z Expert Targets Std         148.054\n",
      "trainer/Z Expert Targets Max         982.189\n",
      "trainer/Z Expert Targets Min         257.044\n",
      "trainer/Z Policy Targets Mean        325.392\n",
      "trainer/Z Policy Targets Std         221.202\n",
      "trainer/Z Policy Targets Max         887.07\n",
      "trainer/Z Policy Targets Min        -130.15\n",
      "trainer/Log Pis Mean                  13.9828\n",
      "trainer/Log Pis Std                    5.9699\n",
      "trainer/Policy mu Mean                 1.06355\n",
      "trainer/Policy mu Std                  2.59294\n",
      "trainer/Policy log std Mean           -3.11464\n",
      "trainer/Policy log std Std             1.35203\n",
      "exploration/num steps total        33013\n",
      "exploration/num paths total          790\n",
      "evaluation/num steps total         32515\n",
      "evaluation/num paths total           240\n",
      "evaluation/path length Mean          137.2\n",
      "evaluation/path length Std             1.07703\n",
      "evaluation/path length Max           139\n",
      "evaluation/path length Min           136\n",
      "evaluation/Rewards Mean                2.4349\n",
      "evaluation/Rewards Std                 0.646401\n",
      "evaluation/Rewards Max                 3.15849\n",
      "evaluation/Rewards Min                 0.78203\n",
      "evaluation/Returns Mean              334.069\n",
      "evaluation/Returns Std                 2.4151\n",
      "evaluation/Returns Max               337.608\n",
      "evaluation/Returns Min               330.364\n",
      "evaluation/Estimation Bias Mean      550.46\n",
      "evaluation/Estimation Bias Std       172.93\n",
      "evaluation/EB/Q_True Mean             12.6263\n",
      "evaluation/EB/Q_True Std              41.257\n",
      "evaluation/EB/Q_Pred Mean            563.086\n",
      "evaluation/EB/Q_Pred Std             170.097\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           334.069\n",
      "evaluation/Actions Mean                0.058114\n",
      "evaluation/Actions Std                 0.526758\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.997864\n",
      "time/backward_policy (s)               1.67707\n",
      "time/backward_zf1 (s)                  1.76986\n",
      "time/backward_zf2 (s)                  1.71799\n",
      "time/data sampling (s)                 0.194011\n",
      "time/data storing (s)                  0.0136875\n",
      "time/evaluation sampling (s)           0.211023\n",
      "time/exploration sampling (s)          0.165692\n",
      "time/logging (s)                       0.00258569\n",
      "time/preback_alpha (s)                 0.525813\n",
      "time/preback_policy (s)                0.579998\n",
      "time/preback_start (s)                 0.113417\n",
      "time/preback_zf (s)                    4.89182\n",
      "time/saving (s)                        0.00470461\n",
      "time/training (s)                      2.52286\n",
      "time/epoch (s)                        14.3905\n",
      "time/total (s)                       351.469\n",
      "Epoch                                 23\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:07:14.629791 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 24 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 35000\n",
      "trainer/ZF1 Loss                     -10.4545\n",
      "trainer/ZF2 Loss                      -6.81453\n",
      "trainer/ZF Expert Reward              18.6597\n",
      "trainer/ZF Policy Reward              -9.23246\n",
      "trainer/ZF CHI2 Term                  34.1135\n",
      "trainer/Policy Loss                 -358.533\n",
      "trainer/Policy Grad Norm             108.054\n",
      "trainer/Policy Param Norm             26.73\n",
      "trainer/Zf1 Grad Norm               1143.64\n",
      "trainer/Zf1 Param Norm                61.3672\n",
      "trainer/Zf2 Grad Norm                995.446\n",
      "trainer/Zf2 Param Norm                60.6291\n",
      "trainer/Z Expert Predictions Mean    787.128\n",
      "trainer/Z Expert Predictions Std     143.436\n",
      "trainer/Z Expert Predictions Max    1000.81\n",
      "trainer/Z Expert Predictions Min     286.909\n",
      "trainer/Z Policy Predictions Mean    338.823\n",
      "trainer/Z Policy Predictions Std     236.748\n",
      "trainer/Z Policy Predictions Max     951.81\n",
      "trainer/Z Policy Predictions Min    -136.211\n",
      "trainer/Z Expert Targets Mean        768.469\n",
      "trainer/Z Expert Targets Std         142.466\n",
      "trainer/Z Expert Targets Max         984.851\n",
      "trainer/Z Expert Targets Min         299.848\n",
      "trainer/Z Policy Targets Mean        348.055\n",
      "trainer/Z Policy Targets Std         235.263\n",
      "trainer/Z Policy Targets Max         937.841\n",
      "trainer/Z Policy Targets Min        -132.368\n",
      "trainer/Log Pis Mean                  15.0059\n",
      "trainer/Log Pis Std                    6.42234\n",
      "trainer/Policy mu Mean                 1.29276\n",
      "trainer/Policy mu Std                  2.93852\n",
      "trainer/Policy log std Mean           -3.07893\n",
      "trainer/Policy log std Std             1.41036\n",
      "exploration/num steps total        33419\n",
      "exploration/num paths total          793\n",
      "evaluation/num steps total         42515\n",
      "evaluation/num paths total           250\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                3.24921\n",
      "evaluation/Rewards Std                 0.559123\n",
      "evaluation/Rewards Max                 4.48832\n",
      "evaluation/Rewards Min                 0.783548\n",
      "evaluation/Returns Mean             3249.21\n",
      "evaluation/Returns Std                15.0158\n",
      "evaluation/Returns Max              3273.54\n",
      "evaluation/Returns Min              3226.68\n",
      "evaluation/Estimation Bias Mean      750.775\n",
      "evaluation/Estimation Bias Std       177.531\n",
      "evaluation/EB/Q_True Mean             30.0493\n",
      "evaluation/EB/Q_True Std              92.5254\n",
      "evaluation/EB/Q_Pred Mean            780.824\n",
      "evaluation/EB/Q_Pred Std             151.737\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          3249.21\n",
      "evaluation/Actions Mean                0.125945\n",
      "evaluation/Actions Std                 0.550345\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999729\n",
      "time/backward_policy (s)               1.79459\n",
      "time/backward_zf1 (s)                  1.87768\n",
      "time/backward_zf2 (s)                  1.84995\n",
      "time/data sampling (s)                 0.191288\n",
      "time/data storing (s)                  0.013092\n",
      "time/evaluation sampling (s)           1.35717\n",
      "time/exploration sampling (s)          0.161239\n",
      "time/logging (s)                       0.0119744\n",
      "time/preback_alpha (s)                 0.523583\n",
      "time/preback_policy (s)                0.596043\n",
      "time/preback_start (s)                 0.112067\n",
      "time/preback_zf (s)                    4.87669\n",
      "time/saving (s)                        0.00517094\n",
      "time/training (s)                      2.18877\n",
      "time/epoch (s)                        15.5593\n",
      "time/total (s)                       367.046\n",
      "Epoch                                 24\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:07:29.394561 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 25 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 36000\n",
      "trainer/ZF1 Loss                       4.24294\n",
      "trainer/ZF2 Loss                      14.6295\n",
      "trainer/ZF Expert Reward              21.2988\n",
      "trainer/ZF Policy Reward              -7.49205\n",
      "trainer/ZF CHI2 Term                  52.9043\n",
      "trainer/Policy Loss                 -366.785\n",
      "trainer/Policy Grad Norm              70.6421\n",
      "trainer/Policy Param Norm             26.8968\n",
      "trainer/Zf1 Grad Norm               1149.66\n",
      "trainer/Zf1 Param Norm                61.75\n",
      "trainer/Zf2 Grad Norm               1576.38\n",
      "trainer/Zf2 Param Norm                60.9291\n",
      "trainer/Z Expert Predictions Mean    798.263\n",
      "trainer/Z Expert Predictions Std     127.646\n",
      "trainer/Z Expert Predictions Max     991.76\n",
      "trainer/Z Expert Predictions Min     435.128\n",
      "trainer/Z Policy Predictions Mean    347.175\n",
      "trainer/Z Policy Predictions Std     237.238\n",
      "trainer/Z Policy Predictions Max     830.315\n",
      "trainer/Z Policy Predictions Min    -138.427\n",
      "trainer/Z Expert Targets Mean        776.964\n",
      "trainer/Z Expert Targets Std         127.526\n",
      "trainer/Z Expert Targets Max         981.18\n",
      "trainer/Z Expert Targets Min         424.706\n",
      "trainer/Z Policy Targets Mean        354.667\n",
      "trainer/Z Policy Targets Std         236.41\n",
      "trainer/Z Policy Targets Max         828.922\n",
      "trainer/Z Policy Targets Min        -140.106\n",
      "trainer/Log Pis Mean                  14.8255\n",
      "trainer/Log Pis Std                    6.55615\n",
      "trainer/Policy mu Mean                 1.24058\n",
      "trainer/Policy mu Std                  3.04256\n",
      "trainer/Policy log std Mean           -3.05668\n",
      "trainer/Policy log std Std             1.3906\n",
      "exploration/num steps total        33419\n",
      "exploration/num paths total          793\n",
      "evaluation/num steps total         45910\n",
      "evaluation/num paths total           260\n",
      "evaluation/path length Mean          339.5\n",
      "evaluation/path length Std             7.5\n",
      "evaluation/path length Max           352\n",
      "evaluation/path length Min           330\n",
      "evaluation/Rewards Mean                3.37837\n",
      "evaluation/Rewards Std                 0.99097\n",
      "evaluation/Rewards Max                 5.78142\n",
      "evaluation/Rewards Min                 0.724243\n",
      "evaluation/Returns Mean             1146.96\n",
      "evaluation/Returns Std                13.6276\n",
      "evaluation/Returns Max              1170.67\n",
      "evaluation/Returns Min              1128.64\n",
      "evaluation/Estimation Bias Mean      640.827\n",
      "evaluation/Estimation Bias Std       190.804\n",
      "evaluation/EB/Q_True Mean             27.2825\n",
      "evaluation/EB/Q_True Std              84.3414\n",
      "evaluation/EB/Q_Pred Mean            668.109\n",
      "evaluation/EB/Q_Pred Std             169.777\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1146.96\n",
      "evaluation/Actions Mean                0.0256456\n",
      "evaluation/Actions Std                 0.562658\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.75771\n",
      "time/backward_zf1 (s)                  1.84432\n",
      "time/backward_zf2 (s)                  1.80905\n",
      "time/data sampling (s)                 0.186573\n",
      "time/data storing (s)                  0.0133148\n",
      "time/evaluation sampling (s)           0.508285\n",
      "time/exploration sampling (s)          0.160819\n",
      "time/logging (s)                       0.00588993\n",
      "time/preback_alpha (s)                 0.525489\n",
      "time/preback_policy (s)                0.592491\n",
      "time/preback_start (s)                 0.113024\n",
      "time/preback_zf (s)                    4.87711\n",
      "time/saving (s)                        0.00465068\n",
      "time/training (s)                      2.298\n",
      "time/epoch (s)                        14.6967\n",
      "time/total (s)                       381.764\n",
      "Epoch                                 25\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:07:44.090550 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 26 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 37000\n",
      "trainer/ZF1 Loss                       8.15881\n",
      "trainer/ZF2 Loss                      14.9544\n",
      "trainer/ZF Expert Reward              16.3786\n",
      "trainer/ZF Policy Reward              -8.24032\n",
      "trainer/ZF CHI2 Term                  50.3425\n",
      "trainer/Policy Loss                 -431.665\n",
      "trainer/Policy Grad Norm              82.1661\n",
      "trainer/Policy Param Norm             27.0901\n",
      "trainer/Zf1 Grad Norm               1539.65\n",
      "trainer/Zf1 Param Norm                62.0698\n",
      "trainer/Zf2 Grad Norm               1090.95\n",
      "trainer/Zf2 Param Norm                61.1954\n",
      "trainer/Z Expert Predictions Mean    779.225\n",
      "trainer/Z Expert Predictions Std     126.562\n",
      "trainer/Z Expert Predictions Max     981.814\n",
      "trainer/Z Expert Predictions Min     342.408\n",
      "trainer/Z Policy Predictions Mean    410.523\n",
      "trainer/Z Policy Predictions Std     221.096\n",
      "trainer/Z Policy Predictions Max     917.11\n",
      "trainer/Z Policy Predictions Min    -145.238\n",
      "trainer/Z Expert Targets Mean        762.846\n",
      "trainer/Z Expert Targets Std         127.578\n",
      "trainer/Z Expert Targets Max         974.728\n",
      "trainer/Z Expert Targets Min         327.447\n",
      "trainer/Z Policy Targets Mean        418.763\n",
      "trainer/Z Policy Targets Std         219.87\n",
      "trainer/Z Policy Targets Max         917.36\n",
      "trainer/Z Policy Targets Min        -135.468\n",
      "trainer/Log Pis Mean                  14.31\n",
      "trainer/Log Pis Std                    6.66747\n",
      "trainer/Policy mu Mean                 1.14297\n",
      "trainer/Policy mu Std                  3.04994\n",
      "trainer/Policy log std Mean           -3.08183\n",
      "trainer/Policy log std Std             1.41964\n",
      "exploration/num steps total        36150\n",
      "exploration/num paths total          802\n",
      "evaluation/num steps total         47575\n",
      "evaluation/num paths total           270\n",
      "evaluation/path length Mean          166.5\n",
      "evaluation/path length Std            39.057\n",
      "evaluation/path length Max           244\n",
      "evaluation/path length Min           123\n",
      "evaluation/Rewards Mean                2.63861\n",
      "evaluation/Rewards Std                 0.816502\n",
      "evaluation/Rewards Max                 4.87351\n",
      "evaluation/Rewards Min                 0.804132\n",
      "evaluation/Returns Mean              439.328\n",
      "evaluation/Returns Std               153.95\n",
      "evaluation/Returns Max               754.485\n",
      "evaluation/Returns Min               270.225\n",
      "evaluation/Estimation Bias Mean      481.515\n",
      "evaluation/Estimation Bias Std       250.875\n",
      "evaluation/EB/Q_True Mean             31.8095\n",
      "evaluation/EB/Q_True Std              81.1257\n",
      "evaluation/EB/Q_Pred Mean            513.324\n",
      "evaluation/EB/Q_Pred Std             225.062\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           439.328\n",
      "evaluation/Actions Mean                0.0011756\n",
      "evaluation/Actions Std                 0.503791\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.80691\n",
      "time/backward_zf1 (s)                  1.89338\n",
      "time/backward_zf2 (s)                  1.86445\n",
      "time/data sampling (s)                 0.203306\n",
      "time/data storing (s)                  0.0131748\n",
      "time/evaluation sampling (s)           0.35481\n",
      "time/exploration sampling (s)          0.166984\n",
      "time/logging (s)                       0.00292308\n",
      "time/preback_alpha (s)                 0.526831\n",
      "time/preback_policy (s)                0.603683\n",
      "time/preback_start (s)                 0.114903\n",
      "time/preback_zf (s)                    4.89123\n",
      "time/saving (s)                        0.00501879\n",
      "time/training (s)                      2.18371\n",
      "time/epoch (s)                        14.6313\n",
      "time/total (s)                       396.415\n",
      "Epoch                                 26\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:07:58.662979 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 27 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 38000\n",
      "trainer/ZF1 Loss                      11.4401\n",
      "trainer/ZF2 Loss                       5.80043\n",
      "trainer/ZF Expert Reward              14.6029\n",
      "trainer/ZF Policy Reward             -11.8269\n",
      "trainer/ZF CHI2 Term                  50.4652\n",
      "trainer/Policy Loss                 -427.658\n",
      "trainer/Policy Grad Norm              64.1058\n",
      "trainer/Policy Param Norm             27.2552\n",
      "trainer/Zf1 Grad Norm               2198.75\n",
      "trainer/Zf1 Param Norm                62.3911\n",
      "trainer/Zf2 Grad Norm               1745.31\n",
      "trainer/Zf2 Param Norm                61.4448\n",
      "trainer/Z Expert Predictions Mean    778.851\n",
      "trainer/Z Expert Predictions Std     110.195\n",
      "trainer/Z Expert Predictions Max     971.89\n",
      "trainer/Z Expert Predictions Min     352.833\n",
      "trainer/Z Policy Predictions Mean    406.077\n",
      "trainer/Z Policy Predictions Std     216.708\n",
      "trainer/Z Policy Predictions Max     861.18\n",
      "trainer/Z Policy Predictions Min    -146.969\n",
      "trainer/Z Expert Targets Mean        764.248\n",
      "trainer/Z Expert Targets Std         109.603\n",
      "trainer/Z Expert Targets Max         953.717\n",
      "trainer/Z Expert Targets Min         361.686\n",
      "trainer/Z Policy Targets Mean        417.904\n",
      "trainer/Z Policy Targets Std         217.611\n",
      "trainer/Z Policy Targets Max         886.841\n",
      "trainer/Z Policy Targets Min        -133.607\n",
      "trainer/Log Pis Mean                  15.5708\n",
      "trainer/Log Pis Std                    7.06148\n",
      "trainer/Policy mu Mean                 1.21629\n",
      "trainer/Policy mu Std                  3.32633\n",
      "trainer/Policy log std Mean           -3.17166\n",
      "trainer/Policy log std Std             1.56685\n",
      "exploration/num steps total        36498\n",
      "exploration/num paths total          803\n",
      "evaluation/num steps total         49756\n",
      "evaluation/num paths total           280\n",
      "evaluation/path length Mean          218.1\n",
      "evaluation/path length Std            24.1886\n",
      "evaluation/path length Max           244\n",
      "evaluation/path length Min           185\n",
      "evaluation/Rewards Mean                3.2893\n",
      "evaluation/Rewards Std                 1.11609\n",
      "evaluation/Rewards Max                 5.93411\n",
      "evaluation/Rewards Min                 0.754799\n",
      "evaluation/Returns Mean              717.395\n",
      "evaluation/Returns Std               121.999\n",
      "evaluation/Returns Max               839.078\n",
      "evaluation/Returns Min               533.581\n",
      "evaluation/Estimation Bias Mean      527.288\n",
      "evaluation/Estimation Bias Std       213.448\n",
      "evaluation/EB/Q_True Mean             27.2539\n",
      "evaluation/EB/Q_True Std              80.9752\n",
      "evaluation/EB/Q_Pred Mean            554.542\n",
      "evaluation/EB/Q_Pred Std             196.827\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           717.395\n",
      "evaluation/Actions Mean               -0.021909\n",
      "evaluation/Actions Std                 0.548777\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.57477\n",
      "time/backward_zf1 (s)                  1.6939\n",
      "time/backward_zf2 (s)                  1.62172\n",
      "time/data sampling (s)                 0.202298\n",
      "time/data storing (s)                  0.0135689\n",
      "time/evaluation sampling (s)           0.349935\n",
      "time/exploration sampling (s)          0.159489\n",
      "time/logging (s)                       0.00429938\n",
      "time/preback_alpha (s)                 0.528592\n",
      "time/preback_policy (s)                0.564498\n",
      "time/preback_start (s)                 0.115105\n",
      "time/preback_zf (s)                    4.88857\n",
      "time/saving (s)                        0.00468484\n",
      "time/training (s)                      2.79302\n",
      "time/epoch (s)                        14.5144\n",
      "time/total (s)                       410.948\n",
      "Epoch                                 27\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:08:13.157895 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 28 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 39000\n",
      "trainer/ZF1 Loss                      -6.97916\n",
      "trainer/ZF2 Loss                      -7.85749\n",
      "trainer/ZF Expert Reward              18.5448\n",
      "trainer/ZF Policy Reward              -8.13145\n",
      "trainer/ZF CHI2 Term                  33.73\n",
      "trainer/Policy Loss                 -468.293\n",
      "trainer/Policy Grad Norm              89.1189\n",
      "trainer/Policy Param Norm             27.4397\n",
      "trainer/Zf1 Grad Norm               2219.05\n",
      "trainer/Zf1 Param Norm                62.6584\n",
      "trainer/Zf2 Grad Norm               1418.62\n",
      "trainer/Zf2 Param Norm                61.6827\n",
      "trainer/Z Expert Predictions Mean    777.211\n",
      "trainer/Z Expert Predictions Std      95.6168\n",
      "trainer/Z Expert Predictions Max     969.926\n",
      "trainer/Z Expert Predictions Min     408.434\n",
      "trainer/Z Policy Predictions Mean    445.755\n",
      "trainer/Z Policy Predictions Std     208.158\n",
      "trainer/Z Policy Predictions Max     826.348\n",
      "trainer/Z Policy Predictions Min    -113.796\n",
      "trainer/Z Expert Targets Mean        758.666\n",
      "trainer/Z Expert Targets Std          95.5268\n",
      "trainer/Z Expert Targets Max         947.985\n",
      "trainer/Z Expert Targets Min         421.964\n",
      "trainer/Z Policy Targets Mean        453.887\n",
      "trainer/Z Policy Targets Std         207.067\n",
      "trainer/Z Policy Targets Max         823.889\n",
      "trainer/Z Policy Targets Min        -112.675\n",
      "trainer/Log Pis Mean                  14.6183\n",
      "trainer/Log Pis Std                    6.69499\n",
      "trainer/Policy mu Mean                 0.996204\n",
      "trainer/Policy mu Std                  3.24741\n",
      "trainer/Policy log std Mean           -2.99247\n",
      "trainer/Policy log std Std             1.50151\n",
      "exploration/num steps total        38036\n",
      "exploration/num paths total          809\n",
      "evaluation/num steps total         51770\n",
      "evaluation/num paths total           290\n",
      "evaluation/path length Mean          201.4\n",
      "evaluation/path length Std             7.04557\n",
      "evaluation/path length Max           216\n",
      "evaluation/path length Min           194\n",
      "evaluation/Rewards Mean                2.78395\n",
      "evaluation/Rewards Std                 0.907067\n",
      "evaluation/Rewards Max                 4.59424\n",
      "evaluation/Rewards Min                 0.784082\n",
      "evaluation/Returns Mean              560.687\n",
      "evaluation/Returns Std                29.3741\n",
      "evaluation/Returns Max               621.546\n",
      "evaluation/Returns Min               531.433\n",
      "evaluation/Estimation Bias Mean      447.951\n",
      "evaluation/Estimation Bias Std       173.026\n",
      "evaluation/EB/Q_True Mean             20.5786\n",
      "evaluation/EB/Q_True Std              62.555\n",
      "evaluation/EB/Q_Pred Mean            468.529\n",
      "evaluation/EB/Q_Pred Std             161.106\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           560.687\n",
      "evaluation/Actions Mean               -0.0269361\n",
      "evaluation/Actions Std                 0.457905\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.56517\n",
      "time/backward_zf1 (s)                  1.69326\n",
      "time/backward_zf2 (s)                  1.62285\n",
      "time/data sampling (s)                 0.206684\n",
      "time/data storing (s)                  0.0133537\n",
      "time/evaluation sampling (s)           0.324088\n",
      "time/exploration sampling (s)          0.161031\n",
      "time/logging (s)                       0.00340381\n",
      "time/preback_alpha (s)                 0.526525\n",
      "time/preback_policy (s)                0.567751\n",
      "time/preback_start (s)                 0.115325\n",
      "time/preback_zf (s)                    4.88912\n",
      "time/saving (s)                        0.00466595\n",
      "time/training (s)                      2.73908\n",
      "time/epoch (s)                        14.4323\n",
      "time/total (s)                       425.4\n",
      "Epoch                                 28\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:08:28.006009 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 29 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 40000\n",
      "trainer/ZF1 Loss                      -4.95696\n",
      "trainer/ZF2 Loss                      -6.42999\n",
      "trainer/ZF Expert Reward              21.5858\n",
      "trainer/ZF Policy Reward              -4.32725\n",
      "trainer/ZF CHI2 Term                  35.6773\n",
      "trainer/Policy Loss                 -468.546\n",
      "trainer/Policy Grad Norm              84.5539\n",
      "trainer/Policy Param Norm             27.6221\n",
      "trainer/Zf1 Grad Norm                933.914\n",
      "trainer/Zf1 Param Norm                62.8721\n",
      "trainer/Zf2 Grad Norm                796.159\n",
      "trainer/Zf2 Param Norm                61.8868\n",
      "trainer/Z Expert Predictions Mean    777.484\n",
      "trainer/Z Expert Predictions Std      97.4765\n",
      "trainer/Z Expert Predictions Max     944.946\n",
      "trainer/Z Expert Predictions Min     542.794\n",
      "trainer/Z Policy Predictions Mean    445.233\n",
      "trainer/Z Policy Predictions Std     211.572\n",
      "trainer/Z Policy Predictions Max     821.719\n",
      "trainer/Z Policy Predictions Min    -131.146\n",
      "trainer/Z Expert Targets Mean        755.898\n",
      "trainer/Z Expert Targets Std          96.4742\n",
      "trainer/Z Expert Targets Max         920.739\n",
      "trainer/Z Expert Targets Min         531.68\n",
      "trainer/Z Policy Targets Mean        449.561\n",
      "trainer/Z Policy Targets Std         211.382\n",
      "trainer/Z Policy Targets Max         820.725\n",
      "trainer/Z Policy Targets Min        -112.932\n",
      "trainer/Log Pis Mean                  15.6139\n",
      "trainer/Log Pis Std                    7.14147\n",
      "trainer/Policy mu Mean                 0.858556\n",
      "trainer/Policy mu Std                  3.61784\n",
      "trainer/Policy log std Mean           -3.09352\n",
      "trainer/Policy log std Std             1.41953\n",
      "exploration/num steps total        39069\n",
      "exploration/num paths total          813\n",
      "evaluation/num steps total         54717\n",
      "evaluation/num paths total           300\n",
      "evaluation/path length Mean          294.7\n",
      "evaluation/path length Std            98.6286\n",
      "evaluation/path length Max           399\n",
      "evaluation/path length Min           144\n",
      "evaluation/Rewards Mean                2.83671\n",
      "evaluation/Rewards Std                 0.762709\n",
      "evaluation/Rewards Max                 4.98686\n",
      "evaluation/Rewards Min                 0.742839\n",
      "evaluation/Returns Mean              835.978\n",
      "evaluation/Returns Std               348.789\n",
      "evaluation/Returns Max              1237.91\n",
      "evaluation/Returns Min               312.696\n",
      "evaluation/Estimation Bias Mean      500.826\n",
      "evaluation/Estimation Bias Std       277.531\n",
      "evaluation/EB/Q_True Mean             33.6736\n",
      "evaluation/EB/Q_True Std              88.9277\n",
      "evaluation/EB/Q_Pred Mean            534.5\n",
      "evaluation/EB/Q_Pred Std             247.253\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           835.978\n",
      "evaluation/Actions Mean                0.00810319\n",
      "evaluation/Actions Std                 0.584208\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.73942\n",
      "time/backward_zf1 (s)                  1.82407\n",
      "time/backward_zf2 (s)                  1.79199\n",
      "time/data sampling (s)                 0.203005\n",
      "time/data storing (s)                  0.0133356\n",
      "time/evaluation sampling (s)           0.555108\n",
      "time/exploration sampling (s)          0.165689\n",
      "time/logging (s)                       0.00498743\n",
      "time/preback_alpha (s)                 0.526546\n",
      "time/preback_policy (s)                0.592088\n",
      "time/preback_start (s)                 0.114137\n",
      "time/preback_zf (s)                    4.88506\n",
      "time/saving (s)                        0.00995834\n",
      "time/training (s)                      2.36447\n",
      "time/epoch (s)                        14.7899\n",
      "time/total (s)                       440.208\n",
      "Epoch                                 29\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:08:43.243048 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 30 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 41000\n",
      "trainer/ZF1 Loss                     171.363\n",
      "trainer/ZF2 Loss                     170.094\n",
      "trainer/ZF Expert Reward              28.5659\n",
      "trainer/ZF Policy Reward               2.60658\n",
      "trainer/ZF CHI2 Term                 211.62\n",
      "trainer/Policy Loss                 -488.264\n",
      "trainer/Policy Grad Norm              90.8733\n",
      "trainer/Policy Param Norm             27.8039\n",
      "trainer/Zf1 Grad Norm               6244.06\n",
      "trainer/Zf1 Param Norm                63.1473\n",
      "trainer/Zf2 Grad Norm               4489.68\n",
      "trainer/Zf2 Param Norm                62.1606\n",
      "trainer/Z Expert Predictions Mean    805.018\n",
      "trainer/Z Expert Predictions Std      83.4951\n",
      "trainer/Z Expert Predictions Max     940.482\n",
      "trainer/Z Expert Predictions Min     538.207\n",
      "trainer/Z Policy Predictions Mean    465.571\n",
      "trainer/Z Policy Predictions Std     205.188\n",
      "trainer/Z Policy Predictions Max     810.582\n",
      "trainer/Z Policy Predictions Min    -113.876\n",
      "trainer/Z Expert Targets Mean        776.452\n",
      "trainer/Z Expert Targets Std          93.891\n",
      "trainer/Z Expert Targets Max         912.519\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        462.964\n",
      "trainer/Z Policy Targets Std         206.276\n",
      "trainer/Z Policy Targets Max         803.437\n",
      "trainer/Z Policy Targets Min        -114.555\n",
      "trainer/Log Pis Mean                  15.0826\n",
      "trainer/Log Pis Std                    6.54985\n",
      "trainer/Policy mu Mean                 1.03865\n",
      "trainer/Policy mu Std                  3.53095\n",
      "trainer/Policy log std Mean           -2.90837\n",
      "trainer/Policy log std Std             1.50563\n",
      "exploration/num steps total        40014\n",
      "exploration/num paths total          819\n",
      "evaluation/num steps total         59212\n",
      "evaluation/num paths total           310\n",
      "evaluation/path length Mean          449.5\n",
      "evaluation/path length Std           135.908\n",
      "evaluation/path length Max           706\n",
      "evaluation/path length Min           251\n",
      "evaluation/Rewards Mean                3.12344\n",
      "evaluation/Rewards Std                 0.924923\n",
      "evaluation/Rewards Max                 6.06624\n",
      "evaluation/Rewards Min                 0.708759\n",
      "evaluation/Returns Mean             1403.99\n",
      "evaluation/Returns Std               422.903\n",
      "evaluation/Returns Max              2191.77\n",
      "evaluation/Returns Min               824.583\n",
      "evaluation/Estimation Bias Mean      524.068\n",
      "evaluation/Estimation Bias Std       211.85\n",
      "evaluation/EB/Q_True Mean             43.3636\n",
      "evaluation/EB/Q_True Std             103.3\n",
      "evaluation/EB/Q_Pred Mean            567.432\n",
      "evaluation/EB/Q_Pred Std             179.283\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1403.99\n",
      "evaluation/Actions Mean               -0.0495847\n",
      "evaluation/Actions Std                 0.609729\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.63887\n",
      "time/backward_zf1 (s)                  1.75076\n",
      "time/backward_zf2 (s)                  1.69111\n",
      "time/data sampling (s)                 0.208237\n",
      "time/data storing (s)                  0.0133444\n",
      "time/evaluation sampling (s)           0.982157\n",
      "time/exploration sampling (s)          0.164598\n",
      "time/logging (s)                       0.0057586\n",
      "time/preback_alpha (s)                 0.52706\n",
      "time/preback_policy (s)                0.575067\n",
      "time/preback_start (s)                 0.115457\n",
      "time/preback_zf (s)                    4.8833\n",
      "time/saving (s)                        0.00514002\n",
      "time/training (s)                      2.61848\n",
      "time/epoch (s)                        15.1793\n",
      "time/total (s)                       455.405\n",
      "Epoch                                 30\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:08:57.964764 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 31 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 42000\n",
      "trainer/ZF1 Loss                      -3.12824\n",
      "trainer/ZF2 Loss                      -8.505\n",
      "trainer/ZF Expert Reward              15.8583\n",
      "trainer/ZF Policy Reward              -4.52127\n",
      "trainer/ZF CHI2 Term                  29.433\n",
      "trainer/Policy Loss                 -466.044\n",
      "trainer/Policy Grad Norm              86.3763\n",
      "trainer/Policy Param Norm             27.9476\n",
      "trainer/Zf1 Grad Norm               1266.35\n",
      "trainer/Zf1 Param Norm                63.4176\n",
      "trainer/Zf2 Grad Norm                987.048\n",
      "trainer/Zf2 Param Norm                62.415\n",
      "trainer/Z Expert Predictions Mean    798.222\n",
      "trainer/Z Expert Predictions Std      74.1936\n",
      "trainer/Z Expert Predictions Max     924.336\n",
      "trainer/Z Expert Predictions Min     531.405\n",
      "trainer/Z Policy Predictions Mean    441.671\n",
      "trainer/Z Policy Predictions Std     209.105\n",
      "trainer/Z Policy Predictions Max     784.919\n",
      "trainer/Z Policy Predictions Min     -94.7897\n",
      "trainer/Z Expert Targets Mean        782.364\n",
      "trainer/Z Expert Targets Std          69.8657\n",
      "trainer/Z Expert Targets Max         904.013\n",
      "trainer/Z Expert Targets Min         509.216\n",
      "trainer/Z Policy Targets Mean        446.192\n",
      "trainer/Z Policy Targets Std         210.541\n",
      "trainer/Z Policy Targets Max         806.784\n",
      "trainer/Z Policy Targets Min         -95.5481\n",
      "trainer/Log Pis Mean                  15.0202\n",
      "trainer/Log Pis Std                    6.14894\n",
      "trainer/Policy mu Mean                 0.706766\n",
      "trainer/Policy mu Std                  3.63573\n",
      "trainer/Policy log std Mean           -2.80917\n",
      "trainer/Policy log std Std             1.32423\n",
      "exploration/num steps total        40169\n",
      "exploration/num paths total          820\n",
      "evaluation/num steps total         61942\n",
      "evaluation/num paths total           320\n",
      "evaluation/path length Mean          273\n",
      "evaluation/path length Std            10.6019\n",
      "evaluation/path length Max           304\n",
      "evaluation/path length Min           267\n",
      "evaluation/Rewards Mean                2.93471\n",
      "evaluation/Rewards Std                 0.871731\n",
      "evaluation/Rewards Max                 6.06137\n",
      "evaluation/Rewards Min                 0.716891\n",
      "evaluation/Returns Mean              801.177\n",
      "evaluation/Returns Std                50.916\n",
      "evaluation/Returns Max               947.484\n",
      "evaluation/Returns Min               753.815\n",
      "evaluation/Estimation Bias Mean      475.899\n",
      "evaluation/Estimation Bias Std       210.551\n",
      "evaluation/EB/Q_True Mean             26.3021\n",
      "evaluation/EB/Q_True Std              76.9673\n",
      "evaluation/EB/Q_Pred Mean            502.201\n",
      "evaluation/EB/Q_Pred Std             200.68\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           801.177\n",
      "evaluation/Actions Mean               -0.00434778\n",
      "evaluation/Actions Std                 0.616346\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.76835\n",
      "time/backward_zf1 (s)                  1.8694\n",
      "time/backward_zf2 (s)                  1.81981\n",
      "time/data sampling (s)                 0.201565\n",
      "time/data storing (s)                  0.0133641\n",
      "time/evaluation sampling (s)           0.448641\n",
      "time/exploration sampling (s)          0.162212\n",
      "time/logging (s)                       0.00405568\n",
      "time/preback_alpha (s)                 0.530223\n",
      "time/preback_policy (s)                0.592178\n",
      "time/preback_start (s)                 0.115376\n",
      "time/preback_zf (s)                    4.88267\n",
      "time/saving (s)                        0.00486613\n",
      "time/training (s)                      2.24551\n",
      "time/epoch (s)                        14.6582\n",
      "time/total (s)                       470.083\n",
      "Epoch                                 31\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:09:12.688529 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 32 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 43000\n",
      "trainer/ZF1 Loss                       8.65564\n",
      "trainer/ZF2 Loss                       3.88517\n",
      "trainer/ZF Expert Reward              18.9888\n",
      "trainer/ZF Policy Reward              -3.39655\n",
      "trainer/ZF CHI2 Term                  43.2558\n",
      "trainer/Policy Loss                 -494.326\n",
      "trainer/Policy Grad Norm              78.1931\n",
      "trainer/Policy Param Norm             28.0856\n",
      "trainer/Zf1 Grad Norm               1673.6\n",
      "trainer/Zf1 Param Norm                63.7181\n",
      "trainer/Zf2 Grad Norm               1908.08\n",
      "trainer/Zf2 Param Norm                62.7024\n",
      "trainer/Z Expert Predictions Mean    820.068\n",
      "trainer/Z Expert Predictions Std      64.982\n",
      "trainer/Z Expert Predictions Max     919.366\n",
      "trainer/Z Expert Predictions Min     532.821\n",
      "trainer/Z Policy Predictions Mean    476.458\n",
      "trainer/Z Policy Predictions Std     194.085\n",
      "trainer/Z Policy Predictions Max     845.15\n",
      "trainer/Z Policy Predictions Min     -78.3591\n",
      "trainer/Z Expert Targets Mean        801.08\n",
      "trainer/Z Expert Targets Std          63.7209\n",
      "trainer/Z Expert Targets Max         896.533\n",
      "trainer/Z Expert Targets Min         528.766\n",
      "trainer/Z Policy Targets Mean        479.855\n",
      "trainer/Z Policy Targets Std         195.846\n",
      "trainer/Z Policy Targets Max         836.887\n",
      "trainer/Z Policy Targets Min         -77.2467\n",
      "trainer/Log Pis Mean                  14.7475\n",
      "trainer/Log Pis Std                    7.15495\n",
      "trainer/Policy mu Mean                 0.937857\n",
      "trainer/Policy mu Std                  3.56033\n",
      "trainer/Policy log std Mean           -3.06443\n",
      "trainer/Policy log std Std             1.29275\n",
      "exploration/num steps total        40169\n",
      "exploration/num paths total          820\n",
      "evaluation/num steps total         63402\n",
      "evaluation/num paths total           330\n",
      "evaluation/path length Mean          146\n",
      "evaluation/path length Std             2.75681\n",
      "evaluation/path length Max           151\n",
      "evaluation/path length Min           141\n",
      "evaluation/Rewards Mean                2.23998\n",
      "evaluation/Rewards Std                 0.522574\n",
      "evaluation/Rewards Max                 4.45038\n",
      "evaluation/Rewards Min                 0.749797\n",
      "evaluation/Returns Mean              327.037\n",
      "evaluation/Returns Std                10.9006\n",
      "evaluation/Returns Max               347.319\n",
      "evaluation/Returns Min               308.783\n",
      "evaluation/Estimation Bias Mean      334.718\n",
      "evaluation/Estimation Bias Std       239.936\n",
      "evaluation/EB/Q_True Mean             12.6053\n",
      "evaluation/EB/Q_True Std              40.3433\n",
      "evaluation/EB/Q_Pred Mean            347.323\n",
      "evaluation/EB/Q_Pred Std             240.018\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           327.037\n",
      "evaluation/Actions Mean                0.00539027\n",
      "evaluation/Actions Std                 0.591264\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.67234\n",
      "time/backward_zf1 (s)                  1.81277\n",
      "time/backward_zf2 (s)                  1.71717\n",
      "time/data sampling (s)                 0.240291\n",
      "time/data storing (s)                  0.0138103\n",
      "time/evaluation sampling (s)           0.22967\n",
      "time/exploration sampling (s)          0.163304\n",
      "time/logging (s)                       0.0027375\n",
      "time/preback_alpha (s)                 0.563636\n",
      "time/preback_policy (s)                0.60924\n",
      "time/preback_start (s)                 0.123872\n",
      "time/preback_zf (s)                    4.95473\n",
      "time/saving (s)                        0.00470089\n",
      "time/training (s)                      2.54956\n",
      "time/epoch (s)                        14.6578\n",
      "time/total (s)                       484.761\n",
      "Epoch                                 32\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:09:27.374140 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 33 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 44000\n",
      "trainer/ZF1 Loss                     163.175\n",
      "trainer/ZF2 Loss                     153.231\n",
      "trainer/ZF Expert Reward              21.9055\n",
      "trainer/ZF Policy Reward              -5.76821\n",
      "trainer/ZF CHI2 Term                 200.418\n",
      "trainer/Policy Loss                 -483.952\n",
      "trainer/Policy Grad Norm              92.6033\n",
      "trainer/Policy Param Norm             28.2205\n",
      "trainer/Zf1 Grad Norm               3383.54\n",
      "trainer/Zf1 Param Norm                64.0585\n",
      "trainer/Zf2 Grad Norm               2283.1\n",
      "trainer/Zf2 Param Norm                63.0435\n",
      "trainer/Z Expert Predictions Mean    832.942\n",
      "trainer/Z Expert Predictions Std      72.4206\n",
      "trainer/Z Expert Predictions Max     919.768\n",
      "trainer/Z Expert Predictions Min     525.283\n",
      "trainer/Z Policy Predictions Mean    469.472\n",
      "trainer/Z Policy Predictions Std     186.079\n",
      "trainer/Z Policy Predictions Max     852.09\n",
      "trainer/Z Policy Predictions Min    -107.957\n",
      "trainer/Z Expert Targets Mean        811.036\n",
      "trainer/Z Expert Targets Std          86.1818\n",
      "trainer/Z Expert Targets Max         902.674\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        475.24\n",
      "trainer/Z Policy Targets Std         186.837\n",
      "trainer/Z Policy Targets Max         836.858\n",
      "trainer/Z Policy Targets Min        -106.985\n",
      "trainer/Log Pis Mean                  14.6889\n",
      "trainer/Log Pis Std                    6.36065\n",
      "trainer/Policy mu Mean                 0.734096\n",
      "trainer/Policy mu Std                  3.69401\n",
      "trainer/Policy log std Mean           -2.91864\n",
      "trainer/Policy log std Std             1.29074\n",
      "exploration/num steps total        43513\n",
      "exploration/num paths total          830\n",
      "evaluation/num steps total         65033\n",
      "evaluation/num paths total           340\n",
      "evaluation/path length Mean          163.1\n",
      "evaluation/path length Std             6.23618\n",
      "evaluation/path length Max           176\n",
      "evaluation/path length Min           156\n",
      "evaluation/Rewards Mean                2.56526\n",
      "evaluation/Rewards Std                 0.662309\n",
      "evaluation/Rewards Max                 4.49685\n",
      "evaluation/Rewards Min                 0.773977\n",
      "evaluation/Returns Mean              418.393\n",
      "evaluation/Returns Std                28.9847\n",
      "evaluation/Returns Max               475.579\n",
      "evaluation/Returns Min               383.944\n",
      "evaluation/Estimation Bias Mean      411.14\n",
      "evaluation/Estimation Bias Std       237.666\n",
      "evaluation/EB/Q_True Mean             17.3621\n",
      "evaluation/EB/Q_True Std              53.1176\n",
      "evaluation/EB/Q_Pred Mean            428.502\n",
      "evaluation/EB/Q_Pred Std             234.689\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           418.393\n",
      "evaluation/Actions Mean                0.00615469\n",
      "evaluation/Actions Std                 0.599662\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.72888\n",
      "time/backward_zf1 (s)                  1.84048\n",
      "time/backward_zf2 (s)                  1.77886\n",
      "time/data sampling (s)                 0.213917\n",
      "time/data storing (s)                  0.0135339\n",
      "time/evaluation sampling (s)           0.265912\n",
      "time/exploration sampling (s)          0.172956\n",
      "time/logging (s)                       0.00288715\n",
      "time/preback_alpha (s)                 0.536413\n",
      "time/preback_policy (s)                0.59537\n",
      "time/preback_start (s)                 0.119344\n",
      "time/preback_zf (s)                    4.91123\n",
      "time/saving (s)                        0.00480458\n",
      "time/training (s)                      2.43923\n",
      "time/epoch (s)                        14.6238\n",
      "time/total (s)                       499.405\n",
      "Epoch                                 33\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:09:41.877149 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 34 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 45000\n",
      "trainer/ZF1 Loss                       2.92722\n",
      "trainer/ZF2 Loss                       3.52158\n",
      "trainer/ZF Expert Reward              16.6106\n",
      "trainer/ZF Policy Reward              -4.6707\n",
      "trainer/ZF CHI2 Term                  38.4756\n",
      "trainer/Policy Loss                 -446.777\n",
      "trainer/Policy Grad Norm             117.773\n",
      "trainer/Policy Param Norm             28.3735\n",
      "trainer/Zf1 Grad Norm               1629.6\n",
      "trainer/Zf1 Param Norm                64.4499\n",
      "trainer/Zf2 Grad Norm               1597.59\n",
      "trainer/Zf2 Param Norm                63.4965\n",
      "trainer/Z Expert Predictions Mean    833.957\n",
      "trainer/Z Expert Predictions Std      80.3455\n",
      "trainer/Z Expert Predictions Max     936.212\n",
      "trainer/Z Expert Predictions Min     509.131\n",
      "trainer/Z Policy Predictions Mean    431.193\n",
      "trainer/Z Policy Predictions Std     201.44\n",
      "trainer/Z Policy Predictions Max     844.121\n",
      "trainer/Z Policy Predictions Min    -107.167\n",
      "trainer/Z Expert Targets Mean        817.346\n",
      "trainer/Z Expert Targets Std          76.4665\n",
      "trainer/Z Expert Targets Max         916.79\n",
      "trainer/Z Expert Targets Min         512.462\n",
      "trainer/Z Policy Targets Mean        435.864\n",
      "trainer/Z Policy Targets Std         199.138\n",
      "trainer/Z Policy Targets Max         814.13\n",
      "trainer/Z Policy Targets Min        -104.615\n",
      "trainer/Log Pis Mean                  14.111\n",
      "trainer/Log Pis Std                    5.81851\n",
      "trainer/Policy mu Mean                 0.874785\n",
      "trainer/Policy mu Std                  3.51146\n",
      "trainer/Policy log std Mean           -2.96102\n",
      "trainer/Policy log std Std             1.19544\n",
      "exploration/num steps total        44441\n",
      "exploration/num paths total          836\n",
      "evaluation/num steps total         66562\n",
      "evaluation/num paths total           350\n",
      "evaluation/path length Mean          152.9\n",
      "evaluation/path length Std             3.11288\n",
      "evaluation/path length Max           157\n",
      "evaluation/path length Min           148\n",
      "evaluation/Rewards Mean                2.3743\n",
      "evaluation/Rewards Std                 0.516798\n",
      "evaluation/Rewards Max                 3.49705\n",
      "evaluation/Rewards Min                 0.856372\n",
      "evaluation/Returns Mean              363.031\n",
      "evaluation/Returns Std                14.14\n",
      "evaluation/Returns Max               380.905\n",
      "evaluation/Returns Min               338.6\n",
      "evaluation/Estimation Bias Mean      355.145\n",
      "evaluation/Estimation Bias Std       224.554\n",
      "evaluation/EB/Q_True Mean             13.5975\n",
      "evaluation/EB/Q_True Std              43.6972\n",
      "evaluation/EB/Q_Pred Mean            368.742\n",
      "evaluation/EB/Q_Pred Std             223.24\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           363.031\n",
      "evaluation/Actions Mean                0.0192576\n",
      "evaluation/Actions Std                 0.622101\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.69688\n",
      "time/backward_zf1 (s)                  1.79826\n",
      "time/backward_zf2 (s)                  1.74852\n",
      "time/data sampling (s)                 0.198139\n",
      "time/data storing (s)                  0.0132451\n",
      "time/evaluation sampling (s)           0.246125\n",
      "time/exploration sampling (s)          0.161432\n",
      "time/logging (s)                       0.00282598\n",
      "time/preback_alpha (s)                 0.529512\n",
      "time/preback_policy (s)                0.587647\n",
      "time/preback_start (s)                 0.114832\n",
      "time/preback_zf (s)                    4.89141\n",
      "time/saving (s)                        0.00469639\n",
      "time/training (s)                      2.45116\n",
      "time/epoch (s)                        14.4447\n",
      "time/total (s)                       513.866\n",
      "Epoch                                 34\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:09:57.408647 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 35 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 46000\n",
      "trainer/ZF1 Loss                       2.52728\n",
      "trainer/ZF2 Loss                      -1.52324\n",
      "trainer/ZF Expert Reward              15.0213\n",
      "trainer/ZF Policy Reward              -7.94728\n",
      "trainer/ZF CHI2 Term                  38.6074\n",
      "trainer/Policy Loss                 -445.636\n",
      "trainer/Policy Grad Norm              79.6384\n",
      "trainer/Policy Param Norm             28.5038\n",
      "trainer/Zf1 Grad Norm               1708.52\n",
      "trainer/Zf1 Param Norm                64.8723\n",
      "trainer/Zf2 Grad Norm               1935.99\n",
      "trainer/Zf2 Param Norm                64.0011\n",
      "trainer/Z Expert Predictions Mean    832.722\n",
      "trainer/Z Expert Predictions Std      92.1218\n",
      "trainer/Z Expert Predictions Max     960.475\n",
      "trainer/Z Expert Predictions Min     493.12\n",
      "trainer/Z Policy Predictions Mean    423.62\n",
      "trainer/Z Policy Predictions Std     204.624\n",
      "trainer/Z Policy Predictions Max     803.769\n",
      "trainer/Z Policy Predictions Min    -109.872\n",
      "trainer/Z Expert Targets Mean        817.701\n",
      "trainer/Z Expert Targets Std          87.9569\n",
      "trainer/Z Expert Targets Max         936.12\n",
      "trainer/Z Expert Targets Min         492.374\n",
      "trainer/Z Policy Targets Mean        431.567\n",
      "trainer/Z Policy Targets Std         204.951\n",
      "trainer/Z Policy Targets Max         800.259\n",
      "trainer/Z Policy Targets Min        -102.703\n",
      "trainer/Log Pis Mean                  15.2897\n",
      "trainer/Log Pis Std                    6.42697\n",
      "trainer/Policy mu Mean                 0.983727\n",
      "trainer/Policy mu Std                  3.79273\n",
      "trainer/Policy log std Mean           -3.09927\n",
      "trainer/Policy log std Std             1.26723\n",
      "exploration/num steps total        45061\n",
      "exploration/num paths total          840\n",
      "evaluation/num steps total         72439\n",
      "evaluation/num paths total           360\n",
      "evaluation/path length Mean          587.7\n",
      "evaluation/path length Std           150.299\n",
      "evaluation/path length Max           948\n",
      "evaluation/path length Min           454\n",
      "evaluation/Rewards Mean                3.27165\n",
      "evaluation/Rewards Std                 0.736606\n",
      "evaluation/Rewards Max                 5.45421\n",
      "evaluation/Rewards Min                 0.902144\n",
      "evaluation/Returns Mean             1922.75\n",
      "evaluation/Returns Std               487.595\n",
      "evaluation/Returns Max              3092.04\n",
      "evaluation/Returns Min              1461.42\n",
      "evaluation/Estimation Bias Mean      576.214\n",
      "evaluation/Estimation Bias Std       247.242\n",
      "evaluation/EB/Q_True Mean             48.4994\n",
      "evaluation/EB/Q_True Std             112.655\n",
      "evaluation/EB/Q_Pred Mean            624.714\n",
      "evaluation/EB/Q_Pred Std             220.79\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1922.75\n",
      "evaluation/Actions Mean                0.0774795\n",
      "evaluation/Actions Std                 0.618466\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.73028\n",
      "time/backward_zf1 (s)                  1.82679\n",
      "time/backward_zf2 (s)                  1.7807\n",
      "time/data sampling (s)                 0.195038\n",
      "time/data storing (s)                  0.0131794\n",
      "time/evaluation sampling (s)           1.25836\n",
      "time/exploration sampling (s)          0.163805\n",
      "time/logging (s)                       0.00836991\n",
      "time/preback_alpha (s)                 0.526017\n",
      "time/preback_policy (s)                0.588937\n",
      "time/preback_start (s)                 0.114335\n",
      "time/preback_zf (s)                    4.88074\n",
      "time/saving (s)                        0.0148185\n",
      "time/training (s)                      2.37722\n",
      "time/epoch (s)                        15.4786\n",
      "time/total (s)                       529.362\n",
      "Epoch                                 35\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:10:13.121762 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 36 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 47000\n",
      "trainer/ZF1 Loss                       1.83171\n",
      "trainer/ZF2 Loss                       2.93176\n",
      "trainer/ZF Expert Reward              13.4669\n",
      "trainer/ZF Policy Reward              -8.73013\n",
      "trainer/ZF CHI2 Term                  39.6366\n",
      "trainer/Policy Loss                 -414.997\n",
      "trainer/Policy Grad Norm             160.767\n",
      "trainer/Policy Param Norm             28.627\n",
      "trainer/Zf1 Grad Norm               2165.72\n",
      "trainer/Zf1 Param Norm                65.3386\n",
      "trainer/Zf2 Grad Norm               2222.06\n",
      "trainer/Zf2 Param Norm                64.5204\n",
      "trainer/Z Expert Predictions Mean    845.966\n",
      "trainer/Z Expert Predictions Std      90.6259\n",
      "trainer/Z Expert Predictions Max     969.781\n",
      "trainer/Z Expert Predictions Min     487.554\n",
      "trainer/Z Policy Predictions Mean    397.334\n",
      "trainer/Z Policy Predictions Std     217.569\n",
      "trainer/Z Policy Predictions Max     836.433\n",
      "trainer/Z Policy Predictions Min    -166.744\n",
      "trainer/Z Expert Targets Mean        832.499\n",
      "trainer/Z Expert Targets Std          86.5559\n",
      "trainer/Z Expert Targets Max         940.237\n",
      "trainer/Z Expert Targets Min         474.909\n",
      "trainer/Z Policy Targets Mean        406.065\n",
      "trainer/Z Policy Targets Std         217.451\n",
      "trainer/Z Policy Targets Max         852.534\n",
      "trainer/Z Policy Targets Min        -170.253\n",
      "trainer/Log Pis Mean                  15.2099\n",
      "trainer/Log Pis Std                    6.05227\n",
      "trainer/Policy mu Mean                 0.914492\n",
      "trainer/Policy mu Std                  3.64528\n",
      "trainer/Policy log std Mean           -2.98606\n",
      "trainer/Policy log std Std             1.39741\n",
      "exploration/num steps total        45213\n",
      "exploration/num paths total          841\n",
      "evaluation/num steps total         81889\n",
      "evaluation/num paths total           370\n",
      "evaluation/path length Mean          945\n",
      "evaluation/path length Std            86.5448\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           785\n",
      "evaluation/Rewards Mean                3.02369\n",
      "evaluation/Rewards Std                 0.53539\n",
      "evaluation/Rewards Max                 5.25735\n",
      "evaluation/Rewards Min                 0.892914\n",
      "evaluation/Returns Mean             2857.39\n",
      "evaluation/Returns Std               233.891\n",
      "evaluation/Returns Max              3084.96\n",
      "evaluation/Returns Min              2412.67\n",
      "evaluation/Estimation Bias Mean      581.06\n",
      "evaluation/Estimation Bias Std       201.835\n",
      "evaluation/EB/Q_True Mean             28.8469\n",
      "evaluation/EB/Q_True Std              86.0204\n",
      "evaluation/EB/Q_Pred Mean            609.907\n",
      "evaluation/EB/Q_Pred Std             173.703\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          2857.39\n",
      "evaluation/Actions Mean                0.0846701\n",
      "evaluation/Actions Std                 0.586212\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.69934\n",
      "time/backward_zf1 (s)                  1.79433\n",
      "time/backward_zf2 (s)                  1.73932\n",
      "time/data sampling (s)                 0.212669\n",
      "time/data storing (s)                  0.0134507\n",
      "time/evaluation sampling (s)           1.392\n",
      "time/exploration sampling (s)          0.16086\n",
      "time/logging (s)                       0.011115\n",
      "time/preback_alpha (s)                 0.531182\n",
      "time/preback_policy (s)                0.588445\n",
      "time/preback_start (s)                 0.11631\n",
      "time/preback_zf (s)                    4.88985\n",
      "time/saving (s)                        0.0052524\n",
      "time/training (s)                      2.50021\n",
      "time/epoch (s)                        15.6543\n",
      "time/total (s)                       545.036\n",
      "Epoch                                 36\n",
      "---------------------------------  -------------\n",
      "2024-06-08 22:10:28.823196 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 37 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 48000\n",
      "trainer/ZF1 Loss                       2.06167\n",
      "trainer/ZF2 Loss                       5.82608\n",
      "trainer/ZF Expert Reward              16.4279\n",
      "trainer/ZF Policy Reward              -4.61536\n",
      "trainer/ZF CHI2 Term                  39.2829\n",
      "trainer/Policy Loss                 -419.17\n",
      "trainer/Policy Grad Norm             146.165\n",
      "trainer/Policy Param Norm             28.7607\n",
      "trainer/Zf1 Grad Norm               1189.11\n",
      "trainer/Zf1 Param Norm                65.8302\n",
      "trainer/Zf2 Grad Norm               1791.17\n",
      "trainer/Zf2 Param Norm                65.0255\n",
      "trainer/Z Expert Predictions Mean    851.868\n",
      "trainer/Z Expert Predictions Std      84.4979\n",
      "trainer/Z Expert Predictions Max     972.308\n",
      "trainer/Z Expert Predictions Min     505.485\n",
      "trainer/Z Policy Predictions Mean    407.239\n",
      "trainer/Z Policy Predictions Std     192.346\n",
      "trainer/Z Policy Predictions Max     866.826\n",
      "trainer/Z Policy Predictions Min    -129.938\n",
      "trainer/Z Expert Targets Mean        835.44\n",
      "trainer/Z Expert Targets Std          83.1828\n",
      "trainer/Z Expert Targets Max         951.842\n",
      "trainer/Z Expert Targets Min         493.376\n",
      "trainer/Z Policy Targets Mean        411.855\n",
      "trainer/Z Policy Targets Std         193.241\n",
      "trainer/Z Policy Targets Max         856.803\n",
      "trainer/Z Policy Targets Min        -130.522\n",
      "trainer/Log Pis Mean                  14.4402\n",
      "trainer/Log Pis Std                    6.33488\n",
      "trainer/Policy mu Mean                 0.931022\n",
      "trainer/Policy mu Std                  3.55021\n",
      "trainer/Policy log std Mean           -2.91735\n",
      "trainer/Policy log std Std             1.33949\n",
      "exploration/num steps total        45213\n",
      "exploration/num paths total          841\n",
      "evaluation/num steps total         91889\n",
      "evaluation/num paths total           380\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                3.25581\n",
      "evaluation/Rewards Std                 0.542095\n",
      "evaluation/Rewards Max                 4.60451\n",
      "evaluation/Rewards Min                 0.901444\n",
      "evaluation/Returns Mean             3255.81\n",
      "evaluation/Returns Std                20.9361\n",
      "evaluation/Returns Max              3291.49\n",
      "evaluation/Returns Min              3232.7\n",
      "evaluation/Estimation Bias Mean      703.008\n",
      "evaluation/Estimation Bias Std       136.537\n",
      "evaluation/EB/Q_True Mean             30.433\n",
      "evaluation/EB/Q_True Std              94.0683\n",
      "evaluation/EB/Q_Pred Mean            733.441\n",
      "evaluation/EB/Q_Pred Std              98.1114\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          3255.81\n",
      "evaluation/Actions Mean                0.10025\n",
      "evaluation/Actions Std                 0.608979\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.74801\n",
      "time/backward_zf1 (s)                  1.85078\n",
      "time/backward_zf2 (s)                  1.80305\n",
      "time/data sampling (s)                 0.222359\n",
      "time/data storing (s)                  0.0138883\n",
      "time/evaluation sampling (s)           1.35619\n",
      "time/exploration sampling (s)          0.16362\n",
      "time/logging (s)                       0.0117042\n",
      "time/preback_alpha (s)                 0.531522\n",
      "time/preback_policy (s)                0.591857\n",
      "time/preback_start (s)                 0.116276\n",
      "time/preback_zf (s)                    4.90136\n",
      "time/saving (s)                        0.00541028\n",
      "time/training (s)                      2.32587\n",
      "time/epoch (s)                        15.6419\n",
      "time/total (s)                       560.696\n",
      "Epoch                                 37\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:10:44.426604 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 38 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  49000\n",
      "trainer/ZF1 Loss                       -0.823177\n",
      "trainer/ZF2 Loss                       -1.13581\n",
      "trainer/ZF Expert Reward               13.4521\n",
      "trainer/ZF Policy Reward               -8.13688\n",
      "trainer/ZF CHI2 Term                   34.209\n",
      "trainer/Policy Loss                  -391.423\n",
      "trainer/Policy Grad Norm              131.084\n",
      "trainer/Policy Param Norm              28.8826\n",
      "trainer/Zf1 Grad Norm                1910.89\n",
      "trainer/Zf1 Param Norm                 66.3408\n",
      "trainer/Zf2 Grad Norm                1929.01\n",
      "trainer/Zf2 Param Norm                 65.527\n",
      "trainer/Z Expert Predictions Mean     837.273\n",
      "trainer/Z Expert Predictions Std      103.636\n",
      "trainer/Z Expert Predictions Max      965.904\n",
      "trainer/Z Expert Predictions Min      463.057\n",
      "trainer/Z Policy Predictions Mean     378.637\n",
      "trainer/Z Policy Predictions Std      210.902\n",
      "trainer/Z Policy Predictions Max      773.667\n",
      "trainer/Z Policy Predictions Min     -151.009\n",
      "trainer/Z Expert Targets Mean         823.821\n",
      "trainer/Z Expert Targets Std          100.816\n",
      "trainer/Z Expert Targets Max          961.904\n",
      "trainer/Z Expert Targets Min          462.075\n",
      "trainer/Z Policy Targets Mean         386.774\n",
      "trainer/Z Policy Targets Std          211.856\n",
      "trainer/Z Policy Targets Max          798.85\n",
      "trainer/Z Policy Targets Min         -148.542\n",
      "trainer/Log Pis Mean                   13.7369\n",
      "trainer/Log Pis Std                     6.43861\n",
      "trainer/Policy mu Mean                  0.457236\n",
      "trainer/Policy mu Std                   3.11084\n",
      "trainer/Policy log std Mean            -3.1134\n",
      "trainer/Policy log std Std              1.29037\n",
      "exploration/num steps total         45953\n",
      "exploration/num paths total           843\n",
      "evaluation/num steps total         101889\n",
      "evaluation/num paths total            390\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.30344\n",
      "evaluation/Rewards Std                  0.59245\n",
      "evaluation/Rewards Max                  4.84786\n",
      "evaluation/Rewards Min                  0.979496\n",
      "evaluation/Returns Mean              3303.44\n",
      "evaluation/Returns Std                 17.0421\n",
      "evaluation/Returns Max               3348.68\n",
      "evaluation/Returns Min               3285.81\n",
      "evaluation/Estimation Bias Mean       710.22\n",
      "evaluation/Estimation Bias Std        145.574\n",
      "evaluation/EB/Q_True Mean              30.4829\n",
      "evaluation/EB/Q_True Std               93.8358\n",
      "evaluation/EB/Q_Pred Mean             740.703\n",
      "evaluation/EB/Q_Pred Std              115.202\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3303.44\n",
      "evaluation/Actions Mean                 0.0701426\n",
      "evaluation/Actions Std                  0.597784\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.56129\n",
      "time/backward_zf1 (s)                   1.68445\n",
      "time/backward_zf2 (s)                   1.60661\n",
      "time/data sampling (s)                  0.21169\n",
      "time/data storing (s)                   0.013378\n",
      "time/evaluation sampling (s)            1.37092\n",
      "time/exploration sampling (s)           0.163488\n",
      "time/logging (s)                        0.0116896\n",
      "time/preback_alpha (s)                  0.529384\n",
      "time/preback_policy (s)                 0.561366\n",
      "time/preback_start (s)                  0.117208\n",
      "time/preback_zf (s)                     4.89456\n",
      "time/saving (s)                         0.00474628\n",
      "time/training (s)                       2.7972\n",
      "time/epoch (s)                         15.528\n",
      "time/total (s)                        576.258\n",
      "Epoch                                  38\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:11:00.068218 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 39 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  50000\n",
      "trainer/ZF1 Loss                       -1.02795\n",
      "trainer/ZF2 Loss                       -4.47568\n",
      "trainer/ZF Expert Reward               18.6758\n",
      "trainer/ZF Policy Reward               -6.90827\n",
      "trainer/ZF CHI2 Term                   36.8287\n",
      "trainer/Policy Loss                  -394.381\n",
      "trainer/Policy Grad Norm               94.7935\n",
      "trainer/Policy Param Norm              29.0158\n",
      "trainer/Zf1 Grad Norm                1431.28\n",
      "trainer/Zf1 Param Norm                 66.8192\n",
      "trainer/Zf2 Grad Norm                1478.35\n",
      "trainer/Zf2 Param Norm                 66.0276\n",
      "trainer/Z Expert Predictions Mean     837.464\n",
      "trainer/Z Expert Predictions Std      111.2\n",
      "trainer/Z Expert Predictions Max      982.301\n",
      "trainer/Z Expert Predictions Min      437.574\n",
      "trainer/Z Policy Predictions Mean     380.758\n",
      "trainer/Z Policy Predictions Std      238.589\n",
      "trainer/Z Policy Predictions Max      896.103\n",
      "trainer/Z Policy Predictions Min     -203.219\n",
      "trainer/Z Expert Targets Mean         818.789\n",
      "trainer/Z Expert Targets Std          107.695\n",
      "trainer/Z Expert Targets Max          962.481\n",
      "trainer/Z Expert Targets Min          438.072\n",
      "trainer/Z Policy Targets Mean         387.666\n",
      "trainer/Z Policy Targets Std          236.537\n",
      "trainer/Z Policy Targets Max          879.572\n",
      "trainer/Z Policy Targets Min         -217.181\n",
      "trainer/Log Pis Mean                   14.1378\n",
      "trainer/Log Pis Std                     7.03038\n",
      "trainer/Policy mu Mean                  0.39781\n",
      "trainer/Policy mu Std                   3.41629\n",
      "trainer/Policy log std Mean            -3.0762\n",
      "trainer/Policy log std Std              1.32333\n",
      "exploration/num steps total         45953\n",
      "exploration/num paths total           843\n",
      "evaluation/num steps total         110396\n",
      "evaluation/num paths total            400\n",
      "evaluation/path length Mean           850.7\n",
      "evaluation/path length Std            184.122\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            568\n",
      "evaluation/Rewards Mean                 3.19878\n",
      "evaluation/Rewards Std                  0.585933\n",
      "evaluation/Rewards Max                  4.89174\n",
      "evaluation/Rewards Min                  0.962678\n",
      "evaluation/Returns Mean              2721.21\n",
      "evaluation/Returns Std                576.301\n",
      "evaluation/Returns Max               3253.74\n",
      "evaluation/Returns Min               1834.06\n",
      "evaluation/Estimation Bias Mean       617.061\n",
      "evaluation/Estimation Bias Std        206.016\n",
      "evaluation/EB/Q_True Mean              35.0451\n",
      "evaluation/EB/Q_True Std               99.471\n",
      "evaluation/EB/Q_Pred Mean             652.106\n",
      "evaluation/EB/Q_Pred Std              172.471\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2721.21\n",
      "evaluation/Actions Mean                 0.0427861\n",
      "evaluation/Actions Std                  0.587196\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.57652\n",
      "time/backward_zf1 (s)                   1.70197\n",
      "time/backward_zf2 (s)                   1.62793\n",
      "time/data sampling (s)                  0.206212\n",
      "time/data storing (s)                   0.0137504\n",
      "time/evaluation sampling (s)            1.37895\n",
      "time/exploration sampling (s)           0.164464\n",
      "time/logging (s)                        0.0141149\n",
      "time/preback_alpha (s)                  0.530091\n",
      "time/preback_policy (s)                 0.564559\n",
      "time/preback_start (s)                  0.116314\n",
      "time/preback_zf (s)                     4.89792\n",
      "time/saving (s)                         0.0073186\n",
      "time/training (s)                       2.78451\n",
      "time/epoch (s)                         15.5846\n",
      "time/total (s)                        591.861\n",
      "Epoch                                  39\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:11:15.774029 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 40 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  51000\n",
      "trainer/ZF1 Loss                       10.5755\n",
      "trainer/ZF2 Loss                       14.6114\n",
      "trainer/ZF Expert Reward               17.9939\n",
      "trainer/ZF Policy Reward               -4.45503\n",
      "trainer/ZF CHI2 Term                   48.464\n",
      "trainer/Policy Loss                  -401.45\n",
      "trainer/Policy Grad Norm              128.097\n",
      "trainer/Policy Param Norm              29.1408\n",
      "trainer/Zf1 Grad Norm                2040.1\n",
      "trainer/Zf1 Param Norm                 67.2869\n",
      "trainer/Zf2 Grad Norm                1348.32\n",
      "trainer/Zf2 Param Norm                 66.4905\n",
      "trainer/Z Expert Predictions Mean     820.452\n",
      "trainer/Z Expert Predictions Std      106.174\n",
      "trainer/Z Expert Predictions Max      970.402\n",
      "trainer/Z Expert Predictions Min      437.078\n",
      "trainer/Z Policy Predictions Mean     391.114\n",
      "trainer/Z Policy Predictions Std      224.909\n",
      "trainer/Z Policy Predictions Max      914.38\n",
      "trainer/Z Policy Predictions Min     -143.584\n",
      "trainer/Z Expert Targets Mean         802.458\n",
      "trainer/Z Expert Targets Std          104.685\n",
      "trainer/Z Expert Targets Max          956.309\n",
      "trainer/Z Expert Targets Min          431.184\n",
      "trainer/Z Policy Targets Mean         395.569\n",
      "trainer/Z Policy Targets Std          227.316\n",
      "trainer/Z Policy Targets Max          895.942\n",
      "trainer/Z Policy Targets Min         -125.675\n",
      "trainer/Log Pis Mean                   13.5572\n",
      "trainer/Log Pis Std                     6.10267\n",
      "trainer/Policy mu Mean                  0.609299\n",
      "trainer/Policy mu Std                   3.04996\n",
      "trainer/Policy log std Mean            -3.07747\n",
      "trainer/Policy log std Std              1.29198\n",
      "exploration/num steps total         45953\n",
      "exploration/num paths total           843\n",
      "evaluation/num steps total         120396\n",
      "evaluation/num paths total            410\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.47227\n",
      "evaluation/Rewards Std                  0.558001\n",
      "evaluation/Rewards Max                  4.51706\n",
      "evaluation/Rewards Min                  0.944081\n",
      "evaluation/Returns Mean              3472.27\n",
      "evaluation/Returns Std                  4.13572\n",
      "evaluation/Returns Max               3480.42\n",
      "evaluation/Returns Min               3465.81\n",
      "evaluation/Estimation Bias Mean       769.759\n",
      "evaluation/Estimation Bias Std        138.272\n",
      "evaluation/EB/Q_True Mean              32.1105\n",
      "evaluation/EB/Q_True Std               98.8864\n",
      "evaluation/EB/Q_Pred Mean             801.87\n",
      "evaluation/EB/Q_Pred Std               97.2306\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3472.27\n",
      "evaluation/Actions Mean                 0.0349114\n",
      "evaluation/Actions Std                  0.631431\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.57617\n",
      "time/backward_zf1 (s)                   1.71357\n",
      "time/backward_zf2 (s)                   1.63843\n",
      "time/data sampling (s)                  0.218847\n",
      "time/data storing (s)                   0.0134912\n",
      "time/evaluation sampling (s)            1.42115\n",
      "time/exploration sampling (s)           0.161536\n",
      "time/logging (s)                        0.0154178\n",
      "time/preback_alpha (s)                  0.532189\n",
      "time/preback_policy (s)                 0.568034\n",
      "time/preback_start (s)                  0.117077\n",
      "time/preback_zf (s)                     4.89976\n",
      "time/saving (s)                         0.00879798\n",
      "time/training (s)                       2.76308\n",
      "time/epoch (s)                         15.6475\n",
      "time/total (s)                        607.526\n",
      "Epoch                                  40\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:11:31.451328 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 41 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  52000\n",
      "trainer/ZF1 Loss                       -3.76123\n",
      "trainer/ZF2 Loss                       -0.43161\n",
      "trainer/ZF Expert Reward               19.2016\n",
      "trainer/ZF Policy Reward               -4.33701\n",
      "trainer/ZF CHI2 Term                   35.889\n",
      "trainer/Policy Loss                  -384.958\n",
      "trainer/Policy Grad Norm              123.534\n",
      "trainer/Policy Param Norm              29.2841\n",
      "trainer/Zf1 Grad Norm                1836.77\n",
      "trainer/Zf1 Param Norm                 67.7344\n",
      "trainer/Zf2 Grad Norm                1716.76\n",
      "trainer/Zf2 Param Norm                 66.9903\n",
      "trainer/Z Expert Predictions Mean     832.392\n",
      "trainer/Z Expert Predictions Std      100.377\n",
      "trainer/Z Expert Predictions Max      979.33\n",
      "trainer/Z Expert Predictions Min      423.163\n",
      "trainer/Z Policy Predictions Mean     370.723\n",
      "trainer/Z Policy Predictions Std      249.033\n",
      "trainer/Z Policy Predictions Max      927.366\n",
      "trainer/Z Policy Predictions Min     -150.355\n",
      "trainer/Z Expert Targets Mean         813.19\n",
      "trainer/Z Expert Targets Std           99.5423\n",
      "trainer/Z Expert Targets Max          963.125\n",
      "trainer/Z Expert Targets Min          417.668\n",
      "trainer/Z Policy Targets Mean         375.06\n",
      "trainer/Z Policy Targets Std          246.514\n",
      "trainer/Z Policy Targets Max          890.046\n",
      "trainer/Z Policy Targets Min         -155.629\n",
      "trainer/Log Pis Mean                   14.5928\n",
      "trainer/Log Pis Std                     7.14832\n",
      "trainer/Policy mu Mean                  0.530404\n",
      "trainer/Policy mu Std                   3.16908\n",
      "trainer/Policy log std Mean            -3.29534\n",
      "trainer/Policy log std Std              1.41024\n",
      "exploration/num steps total         45953\n",
      "exploration/num paths total           843\n",
      "evaluation/num steps total         130396\n",
      "evaluation/num paths total            420\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52612\n",
      "evaluation/Rewards Std                  0.58506\n",
      "evaluation/Rewards Max                  4.55118\n",
      "evaluation/Rewards Min                  0.917014\n",
      "evaluation/Returns Mean              3526.12\n",
      "evaluation/Returns Std                  2.09466\n",
      "evaluation/Returns Max               3529.18\n",
      "evaluation/Returns Min               3522.4\n",
      "evaluation/Estimation Bias Mean       786.425\n",
      "evaluation/Estimation Bias Std        141.758\n",
      "evaluation/EB/Q_True Mean              32.6343\n",
      "evaluation/EB/Q_True Std              100.584\n",
      "evaluation/EB/Q_Pred Mean             819.06\n",
      "evaluation/EB/Q_Pred Std              100.348\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3526.12\n",
      "evaluation/Actions Mean                 0.0594881\n",
      "evaluation/Actions Std                  0.614129\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.81308\n",
      "time/backward_zf1 (s)                   1.88765\n",
      "time/backward_zf2 (s)                   1.86036\n",
      "time/data sampling (s)                  0.204232\n",
      "time/data storing (s)                   0.0131807\n",
      "time/evaluation sampling (s)            1.36087\n",
      "time/exploration sampling (s)           0.158862\n",
      "time/logging (s)                        0.0116987\n",
      "time/preback_alpha (s)                  0.527976\n",
      "time/preback_policy (s)                 0.602049\n",
      "time/preback_start (s)                  0.114419\n",
      "time/preback_zf (s)                     4.87399\n",
      "time/saving (s)                         0.00520138\n",
      "time/training (s)                       2.18012\n",
      "time/epoch (s)                         15.6137\n",
      "time/total (s)                        623.158\n",
      "Epoch                                  41\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:11:47.209387 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 42 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  53000\n",
      "trainer/ZF1 Loss                       15.7709\n",
      "trainer/ZF2 Loss                       26.3561\n",
      "trainer/ZF Expert Reward               12.3741\n",
      "trainer/ZF Policy Reward               -9.87301\n",
      "trainer/ZF CHI2 Term                   57.9168\n",
      "trainer/Policy Loss                  -373.91\n",
      "trainer/Policy Grad Norm              123.517\n",
      "trainer/Policy Param Norm              29.4473\n",
      "trainer/Zf1 Grad Norm                4572.71\n",
      "trainer/Zf1 Param Norm                 68.2019\n",
      "trainer/Zf2 Grad Norm                5390.64\n",
      "trainer/Zf2 Param Norm                 67.4795\n",
      "trainer/Z Expert Predictions Mean     825.983\n",
      "trainer/Z Expert Predictions Std      108.191\n",
      "trainer/Z Expert Predictions Max      978.933\n",
      "trainer/Z Expert Predictions Min      417.236\n",
      "trainer/Z Policy Predictions Mean     356.235\n",
      "trainer/Z Policy Predictions Std      254.853\n",
      "trainer/Z Policy Predictions Max      910.056\n",
      "trainer/Z Policy Predictions Min     -148.867\n",
      "trainer/Z Expert Targets Mean         813.609\n",
      "trainer/Z Expert Targets Std          108.147\n",
      "trainer/Z Expert Targets Max          961.321\n",
      "trainer/Z Expert Targets Min          411.459\n",
      "trainer/Z Policy Targets Mean         366.108\n",
      "trainer/Z Policy Targets Std          254.712\n",
      "trainer/Z Policy Targets Max          894.932\n",
      "trainer/Z Policy Targets Min         -142.649\n",
      "trainer/Log Pis Mean                   14.7537\n",
      "trainer/Log Pis Std                     6.32829\n",
      "trainer/Policy mu Mean                  0.530222\n",
      "trainer/Policy mu Std                   3.10065\n",
      "trainer/Policy log std Mean            -3.32978\n",
      "trainer/Policy log std Std              1.38594\n",
      "exploration/num steps total         45953\n",
      "exploration/num paths total           843\n",
      "evaluation/num steps total         140396\n",
      "evaluation/num paths total            430\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.55487\n",
      "evaluation/Rewards Std                  0.604708\n",
      "evaluation/Rewards Max                  4.7194\n",
      "evaluation/Rewards Min                  0.648741\n",
      "evaluation/Returns Mean              3554.87\n",
      "evaluation/Returns Std                  4.68158\n",
      "evaluation/Returns Max               3561.88\n",
      "evaluation/Returns Min               3545.17\n",
      "evaluation/Estimation Bias Mean       796.115\n",
      "evaluation/Estimation Bias Std        138.135\n",
      "evaluation/EB/Q_True Mean              32.9516\n",
      "evaluation/EB/Q_True Std              101.499\n",
      "evaluation/EB/Q_Pred Mean             829.067\n",
      "evaluation/EB/Q_Pred Std               93.5857\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3554.87\n",
      "evaluation/Actions Mean                 0.0395174\n",
      "evaluation/Actions Std                  0.598828\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.64431\n",
      "time/backward_zf1 (s)                   1.76032\n",
      "time/backward_zf2 (s)                   1.69525\n",
      "time/data sampling (s)                  0.200551\n",
      "time/data storing (s)                   0.01345\n",
      "time/evaluation sampling (s)            1.40707\n",
      "time/exploration sampling (s)           0.161192\n",
      "time/logging (s)                        0.0113912\n",
      "time/preback_alpha (s)                  0.532218\n",
      "time/preback_policy (s)                 0.586869\n",
      "time/preback_start (s)                  0.117603\n",
      "time/preback_zf (s)                     4.91131\n",
      "time/saving (s)                         0.00584063\n",
      "time/training (s)                       2.6414\n",
      "time/epoch (s)                         15.6888\n",
      "time/total (s)                        638.874\n",
      "Epoch                                  42\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:12:02.773945 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 43 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  54000\n",
      "trainer/ZF1 Loss                      122.037\n",
      "trainer/ZF2 Loss                      114.787\n",
      "trainer/ZF Expert Reward               18.6588\n",
      "trainer/ZF Policy Reward               -8.42789\n",
      "trainer/ZF CHI2 Term                  159.539\n",
      "trainer/Policy Loss                  -400.265\n",
      "trainer/Policy Grad Norm              210.273\n",
      "trainer/Policy Param Norm              29.6156\n",
      "trainer/Zf1 Grad Norm                3645.04\n",
      "trainer/Zf1 Param Norm                 68.6585\n",
      "trainer/Zf2 Grad Norm                3415.83\n",
      "trainer/Zf2 Param Norm                 67.9405\n",
      "trainer/Z Expert Predictions Mean     829.63\n",
      "trainer/Z Expert Predictions Std       93.6799\n",
      "trainer/Z Expert Predictions Max      989.49\n",
      "trainer/Z Expert Predictions Min      415.784\n",
      "trainer/Z Policy Predictions Mean     388.005\n",
      "trainer/Z Policy Predictions Std      259.574\n",
      "trainer/Z Policy Predictions Max      859.947\n",
      "trainer/Z Policy Predictions Min     -196.518\n",
      "trainer/Z Expert Targets Mean         810.971\n",
      "trainer/Z Expert Targets Std          105.809\n",
      "trainer/Z Expert Targets Max          971.792\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         396.433\n",
      "trainer/Z Policy Targets Std          258.092\n",
      "trainer/Z Policy Targets Max          842.175\n",
      "trainer/Z Policy Targets Min         -189.504\n",
      "trainer/Log Pis Mean                   14.1822\n",
      "trainer/Log Pis Std                     6.59633\n",
      "trainer/Policy mu Mean                  0.220099\n",
      "trainer/Policy mu Std                   3.04442\n",
      "trainer/Policy log std Mean            -3.47558\n",
      "trainer/Policy log std Std              1.34397\n",
      "exploration/num steps total         45953\n",
      "exploration/num paths total           843\n",
      "evaluation/num steps total         150396\n",
      "evaluation/num paths total            440\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51509\n",
      "evaluation/Rewards Std                  0.62426\n",
      "evaluation/Rewards Max                  4.85212\n",
      "evaluation/Rewards Min                  0.652071\n",
      "evaluation/Returns Mean              3515.09\n",
      "evaluation/Returns Std                  2.43347\n",
      "evaluation/Returns Max               3518.41\n",
      "evaluation/Returns Min               3511.69\n",
      "evaluation/Estimation Bias Mean       764.035\n",
      "evaluation/Estimation Bias Std        135.549\n",
      "evaluation/EB/Q_True Mean              32.5973\n",
      "evaluation/EB/Q_True Std              100.408\n",
      "evaluation/EB/Q_Pred Mean             796.632\n",
      "evaluation/EB/Q_Pred Std               90.511\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3515.09\n",
      "evaluation/Actions Mean                 0.0677721\n",
      "evaluation/Actions Std                  0.60881\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.57178\n",
      "time/backward_zf1 (s)                   1.70068\n",
      "time/backward_zf2 (s)                   1.62728\n",
      "time/data sampling (s)                  0.194251\n",
      "time/data storing (s)                   0.0133187\n",
      "time/evaluation sampling (s)            1.3525\n",
      "time/exploration sampling (s)           0.162578\n",
      "time/logging (s)                        0.0114797\n",
      "time/preback_alpha (s)                  0.530396\n",
      "time/preback_policy (s)                 0.562194\n",
      "time/preback_start (s)                  0.116672\n",
      "time/preback_zf (s)                     4.89257\n",
      "time/saving (s)                         0.00520416\n",
      "time/training (s)                       2.76283\n",
      "time/epoch (s)                         15.5037\n",
      "time/total (s)                        654.397\n",
      "Epoch                                  43\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:12:18.698535 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 44 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  55000\n",
      "trainer/ZF1 Loss                        1.41896\n",
      "trainer/ZF2 Loss                        2.43895\n",
      "trainer/ZF Expert Reward               22.0274\n",
      "trainer/ZF Policy Reward               -1.23538\n",
      "trainer/ZF CHI2 Term                   39.5245\n",
      "trainer/Policy Loss                  -426.55\n",
      "trainer/Policy Grad Norm              118.87\n",
      "trainer/Policy Param Norm              29.7749\n",
      "trainer/Zf1 Grad Norm                2678.91\n",
      "trainer/Zf1 Param Norm                 69.0926\n",
      "trainer/Zf2 Grad Norm                3183.61\n",
      "trainer/Zf2 Param Norm                 68.3614\n",
      "trainer/Z Expert Predictions Mean     833.281\n",
      "trainer/Z Expert Predictions Std       91.2916\n",
      "trainer/Z Expert Predictions Max      991.769\n",
      "trainer/Z Expert Predictions Min      458\n",
      "trainer/Z Policy Predictions Mean     412.517\n",
      "trainer/Z Policy Predictions Std      260.952\n",
      "trainer/Z Policy Predictions Max      920.692\n",
      "trainer/Z Policy Predictions Min     -192.125\n",
      "trainer/Z Expert Targets Mean         811.253\n",
      "trainer/Z Expert Targets Std           90.5392\n",
      "trainer/Z Expert Targets Max          967.67\n",
      "trainer/Z Expert Targets Min          470.95\n",
      "trainer/Z Policy Targets Mean         413.752\n",
      "trainer/Z Policy Targets Std          256.34\n",
      "trainer/Z Policy Targets Max          901.329\n",
      "trainer/Z Policy Targets Min         -217.527\n",
      "trainer/Log Pis Mean                   14.4776\n",
      "trainer/Log Pis Std                     6.95168\n",
      "trainer/Policy mu Mean                  0.719856\n",
      "trainer/Policy mu Std                   3.26279\n",
      "trainer/Policy log std Mean            -3.35457\n",
      "trainer/Policy log std Std              1.29642\n",
      "exploration/num steps total         48953\n",
      "exploration/num paths total           846\n",
      "evaluation/num steps total         160396\n",
      "evaluation/num paths total            450\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.53456\n",
      "evaluation/Rewards Std                  0.642026\n",
      "evaluation/Rewards Max                  4.92238\n",
      "evaluation/Rewards Min                  0.626165\n",
      "evaluation/Returns Mean              3534.56\n",
      "evaluation/Returns Std                  6.93129\n",
      "evaluation/Returns Max               3548.7\n",
      "evaluation/Returns Min               3527.77\n",
      "evaluation/Estimation Bias Mean       761.681\n",
      "evaluation/Estimation Bias Std        140.766\n",
      "evaluation/EB/Q_True Mean              32.7811\n",
      "evaluation/EB/Q_True Std              101.043\n",
      "evaluation/EB/Q_Pred Mean             794.462\n",
      "evaluation/EB/Q_Pred Std               97.9077\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3534.56\n",
      "evaluation/Actions Mean                 0.103348\n",
      "evaluation/Actions Std                  0.623914\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86863\n",
      "time/backward_zf1 (s)                   1.95984\n",
      "time/backward_zf2 (s)                   1.92463\n",
      "time/data sampling (s)                  0.197385\n",
      "time/data storing (s)                   0.0136324\n",
      "time/evaluation sampling (s)            1.42077\n",
      "time/exploration sampling (s)           0.167451\n",
      "time/logging (s)                        0.0133552\n",
      "time/preback_alpha (s)                  0.535444\n",
      "time/preback_policy (s)                 0.615748\n",
      "time/preback_start (s)                  0.117595\n",
      "time/preback_zf (s)                     4.92384\n",
      "time/saving (s)                         0.00498532\n",
      "time/training (s)                       2.10324\n",
      "time/epoch (s)                         15.8665\n",
      "time/total (s)                        670.281\n",
      "Epoch                                  44\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:12:34.499026 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 45 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  56000\n",
      "trainer/ZF1 Loss                       59.366\n",
      "trainer/ZF2 Loss                       59.997\n",
      "trainer/ZF Expert Reward               13.0648\n",
      "trainer/ZF Policy Reward               -6.5056\n",
      "trainer/ZF CHI2 Term                   94.3987\n",
      "trainer/Policy Loss                  -446.211\n",
      "trainer/Policy Grad Norm              185.787\n",
      "trainer/Policy Param Norm              29.9388\n",
      "trainer/Zf1 Grad Norm                5709.98\n",
      "trainer/Zf1 Param Norm                 69.4714\n",
      "trainer/Zf2 Grad Norm                6502.94\n",
      "trainer/Zf2 Param Norm                 68.758\n",
      "trainer/Z Expert Predictions Mean     833.678\n",
      "trainer/Z Expert Predictions Std       87.7789\n",
      "trainer/Z Expert Predictions Max     1019.88\n",
      "trainer/Z Expert Predictions Min      478.723\n",
      "trainer/Z Policy Predictions Mean     424.748\n",
      "trainer/Z Policy Predictions Std      269.283\n",
      "trainer/Z Policy Predictions Max      946.674\n",
      "trainer/Z Policy Predictions Min     -231.029\n",
      "trainer/Z Expert Targets Mean         820.613\n",
      "trainer/Z Expert Targets Std           98.6326\n",
      "trainer/Z Expert Targets Max         1005.35\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         431.254\n",
      "trainer/Z Policy Targets Std          270.575\n",
      "trainer/Z Policy Targets Max          930.192\n",
      "trainer/Z Policy Targets Min         -229.275\n",
      "trainer/Log Pis Mean                   15.2998\n",
      "trainer/Log Pis Std                     7.38567\n",
      "trainer/Policy mu Mean                  0.930624\n",
      "trainer/Policy mu Std                   3.65313\n",
      "trainer/Policy log std Mean            -3.185\n",
      "trainer/Policy log std Std              1.43055\n",
      "exploration/num steps total         52953\n",
      "exploration/num paths total           850\n",
      "evaluation/num steps total         170396\n",
      "evaluation/num paths total            460\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50267\n",
      "evaluation/Rewards Std                  0.611006\n",
      "evaluation/Rewards Max                  4.60731\n",
      "evaluation/Rewards Min                  0.619938\n",
      "evaluation/Returns Mean              3502.67\n",
      "evaluation/Returns Std                  1.9202\n",
      "evaluation/Returns Max               3506.83\n",
      "evaluation/Returns Min               3500.4\n",
      "evaluation/Estimation Bias Mean       761.956\n",
      "evaluation/Estimation Bias Std        133.55\n",
      "evaluation/EB/Q_True Mean              32.4596\n",
      "evaluation/EB/Q_True Std               99.964\n",
      "evaluation/EB/Q_Pred Mean             794.415\n",
      "evaluation/EB/Q_Pred Std               88.9338\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3502.67\n",
      "evaluation/Actions Mean                 0.067745\n",
      "evaluation/Actions Std                  0.632035\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999942\n",
      "time/backward_policy (s)                1.82343\n",
      "time/backward_zf1 (s)                   1.91702\n",
      "time/backward_zf2 (s)                   1.87771\n",
      "time/data sampling (s)                  0.215526\n",
      "time/data storing (s)                   0.013457\n",
      "time/evaluation sampling (s)            1.37732\n",
      "time/exploration sampling (s)           0.173525\n",
      "time/logging (s)                        0.0128686\n",
      "time/preback_alpha (s)                  0.530256\n",
      "time/preback_policy (s)                 0.602\n",
      "time/preback_start (s)                  0.118403\n",
      "time/preback_zf (s)                     4.88718\n",
      "time/saving (s)                         0.00532379\n",
      "time/training (s)                       2.18609\n",
      "time/epoch (s)                         15.7401\n",
      "time/total (s)                        686.039\n",
      "Epoch                                  45\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:12:50.299996 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 46 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  57000\n",
      "trainer/ZF1 Loss                        9.32234\n",
      "trainer/ZF2 Loss                        5.34297\n",
      "trainer/ZF Expert Reward               17.5457\n",
      "trainer/ZF Policy Reward               -8.81386\n",
      "trainer/ZF CHI2 Term                   47.9734\n",
      "trainer/Policy Loss                  -481.586\n",
      "trainer/Policy Grad Norm              181.453\n",
      "trainer/Policy Param Norm              30.0973\n",
      "trainer/Zf1 Grad Norm                2208.84\n",
      "trainer/Zf1 Param Norm                 69.8095\n",
      "trainer/Zf2 Grad Norm                2370.87\n",
      "trainer/Zf2 Param Norm                 69.1281\n",
      "trainer/Z Expert Predictions Mean     824.177\n",
      "trainer/Z Expert Predictions Std      106.45\n",
      "trainer/Z Expert Predictions Max     1012.85\n",
      "trainer/Z Expert Predictions Min      442.393\n",
      "trainer/Z Policy Predictions Mean     462.281\n",
      "trainer/Z Policy Predictions Std      245.858\n",
      "trainer/Z Policy Predictions Max      910.876\n",
      "trainer/Z Policy Predictions Min     -154.98\n",
      "trainer/Z Expert Targets Mean         806.631\n",
      "trainer/Z Expert Targets Std          104.653\n",
      "trainer/Z Expert Targets Max          990.524\n",
      "trainer/Z Expert Targets Min          447.733\n",
      "trainer/Z Policy Targets Mean         471.094\n",
      "trainer/Z Policy Targets Std          244.04\n",
      "trainer/Z Policy Targets Max          924.401\n",
      "trainer/Z Policy Targets Min         -129.421\n",
      "trainer/Log Pis Mean                   14.4254\n",
      "trainer/Log Pis Std                     6.58408\n",
      "trainer/Policy mu Mean                  0.836397\n",
      "trainer/Policy mu Std                   3.40594\n",
      "trainer/Policy log std Mean            -3.11849\n",
      "trainer/Policy log std Std              1.26526\n",
      "exploration/num steps total         53953\n",
      "exploration/num paths total           851\n",
      "evaluation/num steps total         180396\n",
      "evaluation/num paths total            470\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.46954\n",
      "evaluation/Rewards Std                  0.587381\n",
      "evaluation/Rewards Max                  4.66709\n",
      "evaluation/Rewards Min                  0.640566\n",
      "evaluation/Returns Mean              3469.54\n",
      "evaluation/Returns Std                  6.39997\n",
      "evaluation/Returns Max               3479.82\n",
      "evaluation/Returns Min               3459.15\n",
      "evaluation/Estimation Bias Mean       787.843\n",
      "evaluation/Estimation Bias Std        137.192\n",
      "evaluation/EB/Q_True Mean              32.1488\n",
      "evaluation/EB/Q_True Std               99.1801\n",
      "evaluation/EB/Q_Pred Mean             819.992\n",
      "evaluation/EB/Q_Pred Std               94.2431\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3469.54\n",
      "evaluation/Actions Mean                 0.0413723\n",
      "evaluation/Actions Std                  0.618763\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999861\n",
      "time/backward_policy (s)                1.84839\n",
      "time/backward_zf1 (s)                   1.93601\n",
      "time/backward_zf2 (s)                   1.9031\n",
      "time/data sampling (s)                  0.22509\n",
      "time/data storing (s)                   0.0138344\n",
      "time/evaluation sampling (s)            1.37455\n",
      "time/exploration sampling (s)           0.168418\n",
      "time/logging (s)                        0.0114137\n",
      "time/preback_alpha (s)                  0.531217\n",
      "time/preback_policy (s)                 0.609377\n",
      "time/preback_start (s)                  0.116731\n",
      "time/preback_zf (s)                     4.88887\n",
      "time/saving (s)                         0.00526198\n",
      "time/training (s)                       2.10331\n",
      "time/epoch (s)                         15.7356\n",
      "time/total (s)                        701.797\n",
      "Epoch                                  46\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:13:05.957822 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 47 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  58000\n",
      "trainer/ZF1 Loss                       67.9495\n",
      "trainer/ZF2 Loss                       62.5385\n",
      "trainer/ZF Expert Reward               13.8242\n",
      "trainer/ZF Policy Reward               -9.82938\n",
      "trainer/ZF CHI2 Term                  103.917\n",
      "trainer/Policy Loss                  -487.355\n",
      "trainer/Policy Grad Norm              143.077\n",
      "trainer/Policy Param Norm              30.2066\n",
      "trainer/Zf1 Grad Norm                4520.41\n",
      "trainer/Zf1 Param Norm                 70.0907\n",
      "trainer/Zf2 Grad Norm                4164.52\n",
      "trainer/Zf2 Param Norm                 69.4222\n",
      "trainer/Z Expert Predictions Mean     810.969\n",
      "trainer/Z Expert Predictions Std      108.418\n",
      "trainer/Z Expert Predictions Max     1009.43\n",
      "trainer/Z Expert Predictions Min      503.777\n",
      "trainer/Z Policy Predictions Mean     463.983\n",
      "trainer/Z Policy Predictions Std      246.933\n",
      "trainer/Z Policy Predictions Max      910.251\n",
      "trainer/Z Policy Predictions Min     -176.409\n",
      "trainer/Z Expert Targets Mean         797.145\n",
      "trainer/Z Expert Targets Std          122.488\n",
      "trainer/Z Expert Targets Max         1007.54\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         473.812\n",
      "trainer/Z Policy Targets Std          244.874\n",
      "trainer/Z Policy Targets Max          915.595\n",
      "trainer/Z Policy Targets Min         -178.035\n",
      "trainer/Log Pis Mean                   15.171\n",
      "trainer/Log Pis Std                     5.95773\n",
      "trainer/Policy mu Mean                  1.35785\n",
      "trainer/Policy mu Std                   3.61037\n",
      "trainer/Policy log std Mean            -3.09796\n",
      "trainer/Policy log std Std              1.47258\n",
      "exploration/num steps total         53953\n",
      "exploration/num paths total           851\n",
      "evaluation/num steps total         190396\n",
      "evaluation/num paths total            480\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50388\n",
      "evaluation/Rewards Std                  0.564269\n",
      "evaluation/Rewards Max                  4.57155\n",
      "evaluation/Rewards Min                  0.667625\n",
      "evaluation/Returns Mean              3503.88\n",
      "evaluation/Returns Std                  3.3482\n",
      "evaluation/Returns Max               3510.34\n",
      "evaluation/Returns Min               3499.37\n",
      "evaluation/Estimation Bias Mean       801.463\n",
      "evaluation/Estimation Bias Std        131.307\n",
      "evaluation/EB/Q_True Mean              32.4174\n",
      "evaluation/EB/Q_True Std               99.9192\n",
      "evaluation/EB/Q_Pred Mean             833.88\n",
      "evaluation/EB/Q_Pred Std               82.9125\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3503.88\n",
      "evaluation/Actions Mean                 0.00673578\n",
      "evaluation/Actions Std                  0.608679\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999882\n",
      "time/backward_policy (s)                1.61433\n",
      "time/backward_zf1 (s)                   1.72395\n",
      "time/backward_zf2 (s)                   1.65986\n",
      "time/data sampling (s)                  0.221439\n",
      "time/data storing (s)                   0.0132638\n",
      "time/evaluation sampling (s)            1.39541\n",
      "time/exploration sampling (s)           0.161393\n",
      "time/logging (s)                        0.0114111\n",
      "time/preback_alpha (s)                  0.531383\n",
      "time/preback_policy (s)                 0.572324\n",
      "time/preback_start (s)                  0.116687\n",
      "time/preback_zf (s)                     4.89865\n",
      "time/saving (s)                         0.00523417\n",
      "time/training (s)                       2.67356\n",
      "time/epoch (s)                         15.5989\n",
      "time/total (s)                        717.413\n",
      "Epoch                                  47\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:13:21.632861 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 48 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  59000\n",
      "trainer/ZF1 Loss                        3.94349\n",
      "trainer/ZF2 Loss                       14.6684\n",
      "trainer/ZF Expert Reward               12.742\n",
      "trainer/ZF Policy Reward               -8.94743\n",
      "trainer/ZF CHI2 Term                   44.744\n",
      "trainer/Policy Loss                  -507.858\n",
      "trainer/Policy Grad Norm              134.048\n",
      "trainer/Policy Param Norm              30.2974\n",
      "trainer/Zf1 Grad Norm                2457.58\n",
      "trainer/Zf1 Param Norm                 70.3775\n",
      "trainer/Zf2 Grad Norm                3803.22\n",
      "trainer/Zf2 Param Norm                 69.7053\n",
      "trainer/Z Expert Predictions Mean     824.682\n",
      "trainer/Z Expert Predictions Std      102.827\n",
      "trainer/Z Expert Predictions Max     1012.95\n",
      "trainer/Z Expert Predictions Min      533.216\n",
      "trainer/Z Policy Predictions Mean     489.537\n",
      "trainer/Z Policy Predictions Std      247.182\n",
      "trainer/Z Policy Predictions Max      928.205\n",
      "trainer/Z Policy Predictions Min     -173.749\n",
      "trainer/Z Expert Targets Mean         811.94\n",
      "trainer/Z Expert Targets Std          103.369\n",
      "trainer/Z Expert Targets Max         1002.3\n",
      "trainer/Z Expert Targets Min          516.432\n",
      "trainer/Z Policy Targets Mean         498.484\n",
      "trainer/Z Policy Targets Std          244.934\n",
      "trainer/Z Policy Targets Max          922.96\n",
      "trainer/Z Policy Targets Min         -169.823\n",
      "trainer/Log Pis Mean                   13.8875\n",
      "trainer/Log Pis Std                     6.22595\n",
      "trainer/Policy mu Mean                  0.827361\n",
      "trainer/Policy mu Std                   3.29039\n",
      "trainer/Policy log std Mean            -3.15337\n",
      "trainer/Policy log std Std              1.17968\n",
      "exploration/num steps total         55953\n",
      "exploration/num paths total           853\n",
      "evaluation/num steps total         200396\n",
      "evaluation/num paths total            490\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.40905\n",
      "evaluation/Rewards Std                  0.55888\n",
      "evaluation/Rewards Max                  4.47161\n",
      "evaluation/Rewards Min                  0.670027\n",
      "evaluation/Returns Mean              3409.05\n",
      "evaluation/Returns Std                 10.6144\n",
      "evaluation/Returns Max               3425.71\n",
      "evaluation/Returns Min               3388.89\n",
      "evaluation/Estimation Bias Mean       785.507\n",
      "evaluation/Estimation Bias Std        128.011\n",
      "evaluation/EB/Q_True Mean              31.2738\n",
      "evaluation/EB/Q_True Std               96.452\n",
      "evaluation/EB/Q_Pred Mean             816.781\n",
      "evaluation/EB/Q_Pred Std               86.2448\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3409.05\n",
      "evaluation/Actions Mean                 0.0188537\n",
      "evaluation/Actions Std                  0.603224\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999763\n",
      "time/backward_policy (s)                1.60787\n",
      "time/backward_zf1 (s)                   1.7397\n",
      "time/backward_zf2 (s)                   1.66538\n",
      "time/data sampling (s)                  0.21585\n",
      "time/data storing (s)                   0.0134182\n",
      "time/evaluation sampling (s)            1.36228\n",
      "time/exploration sampling (s)           0.167359\n",
      "time/logging (s)                        0.0118318\n",
      "time/preback_alpha (s)                  0.531389\n",
      "time/preback_policy (s)                 0.573719\n",
      "time/preback_start (s)                  0.118363\n",
      "time/preback_zf (s)                     4.90088\n",
      "time/saving (s)                         0.0052019\n",
      "time/training (s)                       2.70005\n",
      "time/epoch (s)                         15.6133\n",
      "time/total (s)                        733.046\n",
      "Epoch                                  48\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:13:37.245340 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 49 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  60000\n",
      "trainer/ZF1 Loss                       53.2606\n",
      "trainer/ZF2 Loss                       56.7476\n",
      "trainer/ZF Expert Reward               22.4706\n",
      "trainer/ZF Policy Reward                0.816964\n",
      "trainer/ZF CHI2 Term                   89.8701\n",
      "trainer/Policy Loss                  -513.39\n",
      "trainer/Policy Grad Norm               93.8785\n",
      "trainer/Policy Param Norm              30.3727\n",
      "trainer/Zf1 Grad Norm                3075.66\n",
      "trainer/Zf1 Param Norm                 70.6709\n",
      "trainer/Zf2 Grad Norm                4340.96\n",
      "trainer/Zf2 Param Norm                 69.9827\n",
      "trainer/Z Expert Predictions Mean     827.052\n",
      "trainer/Z Expert Predictions Std      101.427\n",
      "trainer/Z Expert Predictions Max      988.257\n",
      "trainer/Z Expert Predictions Min      441.843\n",
      "trainer/Z Policy Predictions Mean     499.065\n",
      "trainer/Z Policy Predictions Std      240.627\n",
      "trainer/Z Policy Predictions Max      964.313\n",
      "trainer/Z Policy Predictions Min     -127.938\n",
      "trainer/Z Expert Targets Mean         804.582\n",
      "trainer/Z Expert Targets Std           99.9864\n",
      "trainer/Z Expert Targets Max          974.629\n",
      "trainer/Z Expert Targets Min          534.24\n",
      "trainer/Z Policy Targets Mean         498.248\n",
      "trainer/Z Policy Targets Std          240.386\n",
      "trainer/Z Policy Targets Max          954.694\n",
      "trainer/Z Policy Targets Min         -129.95\n",
      "trainer/Log Pis Mean                   13.3458\n",
      "trainer/Log Pis Std                     5.49302\n",
      "trainer/Policy mu Mean                  0.7344\n",
      "trainer/Policy mu Std                   3.0356\n",
      "trainer/Policy log std Mean            -3.25099\n",
      "trainer/Policy log std Std              1.28787\n",
      "exploration/num steps total         55953\n",
      "exploration/num paths total           853\n",
      "evaluation/num steps total         210396\n",
      "evaluation/num paths total            500\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50981\n",
      "evaluation/Rewards Std                  0.553637\n",
      "evaluation/Rewards Max                  4.32954\n",
      "evaluation/Rewards Min                  0.698835\n",
      "evaluation/Returns Mean              3509.81\n",
      "evaluation/Returns Std                  2.67614\n",
      "evaluation/Returns Max               3515.62\n",
      "evaluation/Returns Min               3506.5\n",
      "evaluation/Estimation Bias Mean       803.813\n",
      "evaluation/Estimation Bias Std        131.23\n",
      "evaluation/EB/Q_True Mean              32.4927\n",
      "evaluation/EB/Q_True Std              100.162\n",
      "evaluation/EB/Q_Pred Mean             836.306\n",
      "evaluation/EB/Q_Pred Std               84.7604\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3509.81\n",
      "evaluation/Actions Mean                -0.0119212\n",
      "evaluation/Actions Std                  0.585576\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999469\n",
      "time/backward_policy (s)                1.59826\n",
      "time/backward_zf1 (s)                   1.71693\n",
      "time/backward_zf2 (s)                   1.6477\n",
      "time/data sampling (s)                  0.220036\n",
      "time/data storing (s)                   0.0133562\n",
      "time/evaluation sampling (s)            1.34319\n",
      "time/exploration sampling (s)           0.161536\n",
      "time/logging (s)                        0.0116581\n",
      "time/preback_alpha (s)                  0.531822\n",
      "time/preback_policy (s)                 0.572692\n",
      "time/preback_start (s)                  0.117632\n",
      "time/preback_zf (s)                     4.90384\n",
      "time/saving (s)                         0.0052419\n",
      "time/training (s)                       2.70622\n",
      "time/epoch (s)                         15.5501\n",
      "time/total (s)                        748.617\n",
      "Epoch                                  49\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:13:53.016157 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 50 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  61000\n",
      "trainer/ZF1 Loss                       -3.41533\n",
      "trainer/ZF2 Loss                       -3.9187\n",
      "trainer/ZF Expert Reward               15.3163\n",
      "trainer/ZF Policy Reward               -4.71987\n",
      "trainer/ZF CHI2 Term                   30.5091\n",
      "trainer/Policy Loss                  -493.441\n",
      "trainer/Policy Grad Norm              138.622\n",
      "trainer/Policy Param Norm              30.478\n",
      "trainer/Zf1 Grad Norm                3641.97\n",
      "trainer/Zf1 Param Norm                 71.0412\n",
      "trainer/Zf2 Grad Norm                4079.83\n",
      "trainer/Zf2 Param Norm                 70.3171\n",
      "trainer/Z Expert Predictions Mean     816.744\n",
      "trainer/Z Expert Predictions Std      105.975\n",
      "trainer/Z Expert Predictions Max      996.501\n",
      "trainer/Z Expert Predictions Min      579.806\n",
      "trainer/Z Policy Predictions Mean     477.838\n",
      "trainer/Z Policy Predictions Std      264.692\n",
      "trainer/Z Policy Predictions Max      954.572\n",
      "trainer/Z Policy Predictions Min     -188.218\n",
      "trainer/Z Expert Targets Mean         801.428\n",
      "trainer/Z Expert Targets Std          103.475\n",
      "trainer/Z Expert Targets Max          997.112\n",
      "trainer/Z Expert Targets Min          570.723\n",
      "trainer/Z Policy Targets Mean         482.558\n",
      "trainer/Z Policy Targets Std          262.856\n",
      "trainer/Z Policy Targets Max          942.769\n",
      "trainer/Z Policy Targets Min         -172.021\n",
      "trainer/Log Pis Mean                   14.2827\n",
      "trainer/Log Pis Std                     6.40875\n",
      "trainer/Policy mu Mean                  0.6916\n",
      "trainer/Policy mu Std                   3.57734\n",
      "trainer/Policy log std Mean            -3.25838\n",
      "trainer/Policy log std Std              1.31942\n",
      "exploration/num steps total         55953\n",
      "exploration/num paths total           853\n",
      "evaluation/num steps total         220396\n",
      "evaluation/num paths total            510\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.38204\n",
      "evaluation/Rewards Std                  0.547618\n",
      "evaluation/Rewards Max                  4.40514\n",
      "evaluation/Rewards Min                  0.695428\n",
      "evaluation/Returns Mean              3382.04\n",
      "evaluation/Returns Std                 17.9914\n",
      "evaluation/Returns Max               3428.37\n",
      "evaluation/Returns Min               3365.09\n",
      "evaluation/Estimation Bias Mean       744.033\n",
      "evaluation/Estimation Bias Std        162.63\n",
      "evaluation/EB/Q_True Mean              31.6846\n",
      "evaluation/EB/Q_True Std               97.6706\n",
      "evaluation/EB/Q_Pred Mean             775.718\n",
      "evaluation/EB/Q_Pred Std              128.65\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3382.04\n",
      "evaluation/Actions Mean                -0.00832285\n",
      "evaluation/Actions Std                  0.550676\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999392\n",
      "time/backward_policy (s)                1.75971\n",
      "time/backward_zf1 (s)                   1.85276\n",
      "time/backward_zf2 (s)                   1.80734\n",
      "time/data sampling (s)                  0.202158\n",
      "time/data storing (s)                   0.0133335\n",
      "time/evaluation sampling (s)            1.41931\n",
      "time/exploration sampling (s)           0.159918\n",
      "time/logging (s)                        0.0113355\n",
      "time/preback_alpha (s)                  0.532318\n",
      "time/preback_policy (s)                 0.600405\n",
      "time/preback_start (s)                  0.11584\n",
      "time/preback_zf (s)                     4.89789\n",
      "time/saving (s)                         0.00524273\n",
      "time/training (s)                       2.32944\n",
      "time/epoch (s)                         15.707\n",
      "time/total (s)                        764.345\n",
      "Epoch                                  50\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:14:08.752547 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 51 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  62000\n",
      "trainer/ZF1 Loss                       19.2783\n",
      "trainer/ZF2 Loss                       26.6836\n",
      "trainer/ZF Expert Reward               15.1485\n",
      "trainer/ZF Policy Reward               -6.54574\n",
      "trainer/ZF CHI2 Term                   58.5223\n",
      "trainer/Policy Loss                  -531.031\n",
      "trainer/Policy Grad Norm              319.86\n",
      "trainer/Policy Param Norm              30.5866\n",
      "trainer/Zf1 Grad Norm                3704.68\n",
      "trainer/Zf1 Param Norm                 71.461\n",
      "trainer/Zf2 Grad Norm                4641.18\n",
      "trainer/Zf2 Param Norm                 70.7058\n",
      "trainer/Z Expert Predictions Mean     829.94\n",
      "trainer/Z Expert Predictions Std      109.114\n",
      "trainer/Z Expert Predictions Max     1014.91\n",
      "trainer/Z Expert Predictions Min      358.615\n",
      "trainer/Z Policy Predictions Mean     511.341\n",
      "trainer/Z Policy Predictions Std      254.594\n",
      "trainer/Z Policy Predictions Max      976.138\n",
      "trainer/Z Policy Predictions Min     -162.553\n",
      "trainer/Z Expert Targets Mean         814.791\n",
      "trainer/Z Expert Targets Std          105.281\n",
      "trainer/Z Expert Targets Max          991.297\n",
      "trainer/Z Expert Targets Min          389.289\n",
      "trainer/Z Policy Targets Mean         517.887\n",
      "trainer/Z Policy Targets Std          256.597\n",
      "trainer/Z Policy Targets Max          962.495\n",
      "trainer/Z Policy Targets Min         -150.841\n",
      "trainer/Log Pis Mean                   13.987\n",
      "trainer/Log Pis Std                     6.23131\n",
      "trainer/Policy mu Mean                  0.616707\n",
      "trainer/Policy mu Std                   3.30808\n",
      "trainer/Policy log std Mean            -3.37765\n",
      "trainer/Policy log std Std              1.31887\n",
      "exploration/num steps total         55953\n",
      "exploration/num paths total           853\n",
      "evaluation/num steps total         230042\n",
      "evaluation/num paths total            520\n",
      "evaluation/path length Mean           964.6\n",
      "evaluation/path length Std             95.7071\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            679\n",
      "evaluation/Rewards Mean                 3.56415\n",
      "evaluation/Rewards Std                  0.590423\n",
      "evaluation/Rewards Max                  5.03312\n",
      "evaluation/Rewards Min                  0.674044\n",
      "evaluation/Returns Mean              3437.98\n",
      "evaluation/Returns Std                325.787\n",
      "evaluation/Returns Max               3566.01\n",
      "evaluation/Returns Min               2461.7\n",
      "evaluation/Estimation Bias Mean       730.985\n",
      "evaluation/Estimation Bias Std        190.25\n",
      "evaluation/EB/Q_True Mean              34.0632\n",
      "evaluation/EB/Q_True Std              102.695\n",
      "evaluation/EB/Q_Pred Mean             765.048\n",
      "evaluation/EB/Q_Pred Std              144.167\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3437.98\n",
      "evaluation/Actions Mean                -0.0203674\n",
      "evaluation/Actions Std                  0.549929\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67685\n",
      "time/backward_zf1 (s)                   1.78381\n",
      "time/backward_zf2 (s)                   1.7234\n",
      "time/data sampling (s)                  0.197546\n",
      "time/data storing (s)                   0.013339\n",
      "time/evaluation sampling (s)            1.36117\n",
      "time/exploration sampling (s)           0.161765\n",
      "time/logging (s)                        0.0144835\n",
      "time/preback_alpha (s)                  0.53393\n",
      "time/preback_policy (s)                 0.585843\n",
      "time/preback_start (s)                  0.117235\n",
      "time/preback_zf (s)                     4.92162\n",
      "time/saving (s)                         0.00521021\n",
      "time/training (s)                       2.58207\n",
      "time/epoch (s)                         15.6783\n",
      "time/total (s)                        780.042\n",
      "Epoch                                  51\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:14:23.846004 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 52 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  63000\n",
      "trainer/ZF1 Loss                       22.4136\n",
      "trainer/ZF2 Loss                       15.8868\n",
      "trainer/ZF Expert Reward               19.0694\n",
      "trainer/ZF Policy Reward               -5.50061\n",
      "trainer/ZF CHI2 Term                   58.0786\n",
      "trainer/Policy Loss                  -498.779\n",
      "trainer/Policy Grad Norm              165.779\n",
      "trainer/Policy Param Norm              30.7149\n",
      "trainer/Zf1 Grad Norm                3372.47\n",
      "trainer/Zf1 Param Norm                 71.9045\n",
      "trainer/Zf2 Grad Norm                2788.66\n",
      "trainer/Zf2 Param Norm                 71.1164\n",
      "trainer/Z Expert Predictions Mean     823.552\n",
      "trainer/Z Expert Predictions Std       96.5451\n",
      "trainer/Z Expert Predictions Max     1025.55\n",
      "trainer/Z Expert Predictions Min      597.539\n",
      "trainer/Z Policy Predictions Mean     476.678\n",
      "trainer/Z Policy Predictions Std      287.749\n",
      "trainer/Z Policy Predictions Max      995.723\n",
      "trainer/Z Policy Predictions Min     -146.011\n",
      "trainer/Z Expert Targets Mean         804.483\n",
      "trainer/Z Expert Targets Std           99.0871\n",
      "trainer/Z Expert Targets Max         1011.53\n",
      "trainer/Z Expert Targets Min          589.477\n",
      "trainer/Z Policy Targets Mean         482.178\n",
      "trainer/Z Policy Targets Std          283.73\n",
      "trainer/Z Policy Targets Max          984.498\n",
      "trainer/Z Policy Targets Min         -152.813\n",
      "trainer/Log Pis Mean                   14.5034\n",
      "trainer/Log Pis Std                     6.53929\n",
      "trainer/Policy mu Mean                  0.719529\n",
      "trainer/Policy mu Std                   3.31449\n",
      "trainer/Policy log std Mean            -3.21777\n",
      "trainer/Policy log std Std              1.27426\n",
      "exploration/num steps total         55953\n",
      "exploration/num paths total           853\n",
      "evaluation/num steps total         233167\n",
      "evaluation/num paths total            530\n",
      "evaluation/path length Mean           312.5\n",
      "evaluation/path length Std             38.6788\n",
      "evaluation/path length Max            392\n",
      "evaluation/path length Min            271\n",
      "evaluation/Rewards Mean                 3.42715\n",
      "evaluation/Rewards Std                  0.921567\n",
      "evaluation/Rewards Max                  5.3778\n",
      "evaluation/Rewards Min                  0.694452\n",
      "evaluation/Returns Mean              1070.99\n",
      "evaluation/Returns Std                160.509\n",
      "evaluation/Returns Max               1396.25\n",
      "evaluation/Returns Min                894.988\n",
      "evaluation/Estimation Bias Mean       622.768\n",
      "evaluation/Estimation Bias Std        220.183\n",
      "evaluation/EB/Q_True Mean              36.2296\n",
      "evaluation/EB/Q_True Std              100.327\n",
      "evaluation/EB/Q_Pred Mean             658.998\n",
      "evaluation/EB/Q_Pred Std              201.743\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1070.99\n",
      "evaluation/Actions Mean                 0.0145245\n",
      "evaluation/Actions Std                  0.570139\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86091\n",
      "time/backward_zf1 (s)                   1.93248\n",
      "time/backward_zf2 (s)                   1.90564\n",
      "time/data sampling (s)                  0.209537\n",
      "time/data storing (s)                   0.0134958\n",
      "time/evaluation sampling (s)            0.638528\n",
      "time/exploration sampling (s)           0.162157\n",
      "time/logging (s)                        0.00435103\n",
      "time/preback_alpha (s)                  0.534079\n",
      "time/preback_policy (s)                 0.616063\n",
      "time/preback_start (s)                  0.117314\n",
      "time/preback_zf (s)                     4.89462\n",
      "time/saving (s)                         0.0048773\n",
      "time/training (s)                       2.12956\n",
      "time/epoch (s)                         15.0236\n",
      "time/total (s)                        795.083\n",
      "Epoch                                  52\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:14:38.576097 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 53 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  64000\n",
      "trainer/ZF1 Loss                        6.26417\n",
      "trainer/ZF2 Loss                       11.3062\n",
      "trainer/ZF Expert Reward               17.1097\n",
      "trainer/ZF Policy Reward               -3.78763\n",
      "trainer/ZF CHI2 Term                   43.9486\n",
      "trainer/Policy Loss                  -528.559\n",
      "trainer/Policy Grad Norm              182.915\n",
      "trainer/Policy Param Norm              30.84\n",
      "trainer/Zf1 Grad Norm                2952.94\n",
      "trainer/Zf1 Param Norm                 72.3606\n",
      "trainer/Zf2 Grad Norm                3062.42\n",
      "trainer/Zf2 Param Norm                 71.5671\n",
      "trainer/Z Expert Predictions Mean     833.806\n",
      "trainer/Z Expert Predictions Std      107.189\n",
      "trainer/Z Expert Predictions Max     1051.6\n",
      "trainer/Z Expert Predictions Min      564.306\n",
      "trainer/Z Policy Predictions Mean     509.097\n",
      "trainer/Z Policy Predictions Std      264.493\n",
      "trainer/Z Policy Predictions Max     1019.64\n",
      "trainer/Z Policy Predictions Min     -141.723\n",
      "trainer/Z Expert Targets Mean         816.697\n",
      "trainer/Z Expert Targets Std          106.585\n",
      "trainer/Z Expert Targets Max         1032.66\n",
      "trainer/Z Expert Targets Min          558.475\n",
      "trainer/Z Policy Targets Mean         512.885\n",
      "trainer/Z Policy Targets Std          261.041\n",
      "trainer/Z Policy Targets Max         1006.14\n",
      "trainer/Z Policy Targets Min         -126.462\n",
      "trainer/Log Pis Mean                   14.4101\n",
      "trainer/Log Pis Std                     5.77594\n",
      "trainer/Policy mu Mean                  0.884793\n",
      "trainer/Policy mu Std                   3.01049\n",
      "trainer/Policy log std Mean            -3.49058\n",
      "trainer/Policy log std Std              1.26099\n",
      "exploration/num steps total         55953\n",
      "exploration/num paths total           853\n",
      "evaluation/num steps total         235893\n",
      "evaluation/num paths total            540\n",
      "evaluation/path length Mean           272.6\n",
      "evaluation/path length Std              6.48383\n",
      "evaluation/path length Max            284\n",
      "evaluation/path length Min            264\n",
      "evaluation/Rewards Mean                 3.39419\n",
      "evaluation/Rewards Std                  1.00412\n",
      "evaluation/Rewards Max                  5.05955\n",
      "evaluation/Rewards Min                  0.688343\n",
      "evaluation/Returns Mean               925.256\n",
      "evaluation/Returns Std                 32.4412\n",
      "evaluation/Returns Max                971.549\n",
      "evaluation/Returns Min                876.297\n",
      "evaluation/Estimation Bias Mean       601.974\n",
      "evaluation/Estimation Bias Std        249.374\n",
      "evaluation/EB/Q_True Mean              26.4424\n",
      "evaluation/EB/Q_True Std               81.992\n",
      "evaluation/EB/Q_Pred Mean             628.416\n",
      "evaluation/EB/Q_Pred Std              242.717\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            925.256\n",
      "evaluation/Actions Mean                 0.00582563\n",
      "evaluation/Actions Std                  0.611372\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.59476\n",
      "time/backward_zf1 (s)                   1.72454\n",
      "time/backward_zf2 (s)                   1.65322\n",
      "time/data sampling (s)                  0.209732\n",
      "time/data storing (s)                   0.0134343\n",
      "time/evaluation sampling (s)            0.445069\n",
      "time/exploration sampling (s)           0.16205\n",
      "time/logging (s)                        0.00453423\n",
      "time/preback_alpha (s)                  0.533696\n",
      "time/preback_policy (s)                 0.574697\n",
      "time/preback_start (s)                  0.118035\n",
      "time/preback_zf (s)                     4.89398\n",
      "time/saving (s)                         0.00612874\n",
      "time/training (s)                       2.73796\n",
      "time/epoch (s)                         14.6718\n",
      "time/total (s)                        809.771\n",
      "Epoch                                  53\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:14:54.338115 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 54 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  65000\n",
      "trainer/ZF1 Loss                       11.4393\n",
      "trainer/ZF2 Loss                        9.22105\n",
      "trainer/ZF Expert Reward               14.5446\n",
      "trainer/ZF Policy Reward               -2.40454\n",
      "trainer/ZF CHI2 Term                   41.4644\n",
      "trainer/Policy Loss                  -531.766\n",
      "trainer/Policy Grad Norm              154.455\n",
      "trainer/Policy Param Norm              30.9502\n",
      "trainer/Zf1 Grad Norm                3507.59\n",
      "trainer/Zf1 Param Norm                 72.8128\n",
      "trainer/Zf2 Grad Norm                4425.68\n",
      "trainer/Zf2 Param Norm                 71.998\n",
      "trainer/Z Expert Predictions Mean     821.197\n",
      "trainer/Z Expert Predictions Std      116.622\n",
      "trainer/Z Expert Predictions Max     1046.53\n",
      "trainer/Z Expert Predictions Min      517.054\n",
      "trainer/Z Policy Predictions Mean     511.727\n",
      "trainer/Z Policy Predictions Std      277.09\n",
      "trainer/Z Policy Predictions Max      998.418\n",
      "trainer/Z Policy Predictions Min     -129.137\n",
      "trainer/Z Expert Targets Mean         806.653\n",
      "trainer/Z Expert Targets Std          116.543\n",
      "trainer/Z Expert Targets Max         1044.25\n",
      "trainer/Z Expert Targets Min          513.386\n",
      "trainer/Z Policy Targets Mean         514.132\n",
      "trainer/Z Policy Targets Std          275.591\n",
      "trainer/Z Policy Targets Max          986.844\n",
      "trainer/Z Policy Targets Min         -131.068\n",
      "trainer/Log Pis Mean                   14.3283\n",
      "trainer/Log Pis Std                     6.12506\n",
      "trainer/Policy mu Mean                  0.770946\n",
      "trainer/Policy mu Std                   3.07463\n",
      "trainer/Policy log std Mean            -3.37233\n",
      "trainer/Policy log std Std              1.24914\n",
      "exploration/num steps total         58953\n",
      "exploration/num paths total           856\n",
      "evaluation/num steps total         245893\n",
      "evaluation/num paths total            550\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.4877\n",
      "evaluation/Rewards Std                  0.598791\n",
      "evaluation/Rewards Max                  4.7792\n",
      "evaluation/Rewards Min                  0.724985\n",
      "evaluation/Returns Mean              3487.7\n",
      "evaluation/Returns Std                 12.7782\n",
      "evaluation/Returns Max               3513.75\n",
      "evaluation/Returns Min               3471.45\n",
      "evaluation/Estimation Bias Mean       765.068\n",
      "evaluation/Estimation Bias Std        153.705\n",
      "evaluation/EB/Q_True Mean              32.206\n",
      "evaluation/EB/Q_True Std               99.0354\n",
      "evaluation/EB/Q_Pred Mean             797.274\n",
      "evaluation/EB/Q_Pred Std              116.311\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3487.7\n",
      "evaluation/Actions Mean                 0.00857739\n",
      "evaluation/Actions Std                  0.56403\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999712\n",
      "time/backward_policy (s)                1.78306\n",
      "time/backward_zf1 (s)                   1.87592\n",
      "time/backward_zf2 (s)                   1.83623\n",
      "time/data sampling (s)                  0.211859\n",
      "time/data storing (s)                   0.0133689\n",
      "time/evaluation sampling (s)            1.37399\n",
      "time/exploration sampling (s)           0.166498\n",
      "time/logging (s)                        0.0120518\n",
      "time/preback_alpha (s)                  0.530848\n",
      "time/preback_policy (s)                 0.600633\n",
      "time/preback_start (s)                  0.117846\n",
      "time/preback_zf (s)                     4.9063\n",
      "time/saving (s)                         0.00526578\n",
      "time/training (s)                       2.27527\n",
      "time/epoch (s)                         15.7091\n",
      "time/total (s)                        825.499\n",
      "Epoch                                  54\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:15:10.257244 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 55 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  66000\n",
      "trainer/ZF1 Loss                      175.43\n",
      "trainer/ZF2 Loss                      175.462\n",
      "trainer/ZF Expert Reward               18.8636\n",
      "trainer/ZF Policy Reward                0.1624\n",
      "trainer/ZF CHI2 Term                  207.816\n",
      "trainer/Policy Loss                  -560.434\n",
      "trainer/Policy Grad Norm              181.233\n",
      "trainer/Policy Param Norm              31.0629\n",
      "trainer/Zf1 Grad Norm                3329.92\n",
      "trainer/Zf1 Param Norm                 73.2337\n",
      "trainer/Zf2 Grad Norm                4088.41\n",
      "trainer/Zf2 Param Norm                 72.3728\n",
      "trainer/Z Expert Predictions Mean     817.055\n",
      "trainer/Z Expert Predictions Std      133.888\n",
      "trainer/Z Expert Predictions Max     1083.26\n",
      "trainer/Z Expert Predictions Min      511.404\n",
      "trainer/Z Policy Predictions Mean     544.862\n",
      "trainer/Z Policy Predictions Std      260.584\n",
      "trainer/Z Policy Predictions Max     1050.94\n",
      "trainer/Z Policy Predictions Min     -111.504\n",
      "trainer/Z Expert Targets Mean         798.191\n",
      "trainer/Z Expert Targets Std          133.844\n",
      "trainer/Z Expert Targets Max         1070.88\n",
      "trainer/Z Expert Targets Min          495.497\n",
      "trainer/Z Policy Targets Mean         544.7\n",
      "trainer/Z Policy Targets Std          259.007\n",
      "trainer/Z Policy Targets Max         1040.8\n",
      "trainer/Z Policy Targets Min         -101.93\n",
      "trainer/Log Pis Mean                   13.8063\n",
      "trainer/Log Pis Std                     6.46381\n",
      "trainer/Policy mu Mean                  0.889908\n",
      "trainer/Policy mu Std                   3.09286\n",
      "trainer/Policy log std Mean            -3.37046\n",
      "trainer/Policy log std Std              1.29055\n",
      "exploration/num steps total         62953\n",
      "exploration/num paths total           860\n",
      "evaluation/num steps total         255338\n",
      "evaluation/num paths total            560\n",
      "evaluation/path length Mean           944.5\n",
      "evaluation/path length Std            116.419\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            644\n",
      "evaluation/Rewards Mean                 3.55509\n",
      "evaluation/Rewards Std                  0.604032\n",
      "evaluation/Rewards Max                  4.69763\n",
      "evaluation/Rewards Min                  0.694701\n",
      "evaluation/Returns Mean              3357.78\n",
      "evaluation/Returns Std                421.357\n",
      "evaluation/Returns Max               3579.04\n",
      "evaluation/Returns Min               2263.69\n",
      "evaluation/Estimation Bias Mean       712.017\n",
      "evaluation/Estimation Bias Std        191.983\n",
      "evaluation/EB/Q_True Mean              34.9574\n",
      "evaluation/EB/Q_True Std              104.282\n",
      "evaluation/EB/Q_Pred Mean             746.975\n",
      "evaluation/EB/Q_Pred Std              158.43\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3357.78\n",
      "evaluation/Actions Mean                -0.0123728\n",
      "evaluation/Actions Std                  0.561626\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999952\n",
      "time/backward_policy (s)                1.70548\n",
      "time/backward_zf1 (s)                   1.80632\n",
      "time/backward_zf2 (s)                   1.74415\n",
      "time/data sampling (s)                  0.224763\n",
      "time/data storing (s)                   0.0134288\n",
      "time/evaluation sampling (s)            1.49879\n",
      "time/exploration sampling (s)           0.173766\n",
      "time/logging (s)                        0.0117635\n",
      "time/preback_alpha (s)                  0.538324\n",
      "time/preback_policy (s)                 0.592146\n",
      "time/preback_start (s)                  0.121064\n",
      "time/preback_zf (s)                     4.90523\n",
      "time/saving (s)                         0.00546942\n",
      "time/training (s)                       2.51863\n",
      "time/epoch (s)                         15.8593\n",
      "time/total (s)                        841.375\n",
      "Epoch                                  55\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:15:25.948450 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 56 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  67000\n",
      "trainer/ZF1 Loss                       26.4275\n",
      "trainer/ZF2 Loss                       24.0004\n",
      "trainer/ZF Expert Reward               22.9778\n",
      "trainer/ZF Policy Reward               -0.620454\n",
      "trainer/ZF CHI2 Term                   62.4924\n",
      "trainer/Policy Loss                  -578.826\n",
      "trainer/Policy Grad Norm              261.016\n",
      "trainer/Policy Param Norm              31.1895\n",
      "trainer/Zf1 Grad Norm                5587.87\n",
      "trainer/Zf1 Param Norm                 73.6304\n",
      "trainer/Zf2 Grad Norm                3699.47\n",
      "trainer/Zf2 Param Norm                 72.737\n",
      "trainer/Z Expert Predictions Mean     830.107\n",
      "trainer/Z Expert Predictions Std      151.635\n",
      "trainer/Z Expert Predictions Max     1103.6\n",
      "trainer/Z Expert Predictions Min      440.358\n",
      "trainer/Z Policy Predictions Mean     566.352\n",
      "trainer/Z Policy Predictions Std      248.73\n",
      "trainer/Z Policy Predictions Max     1088.93\n",
      "trainer/Z Policy Predictions Min      -91.8463\n",
      "trainer/Z Expert Targets Mean         807.129\n",
      "trainer/Z Expert Targets Std          149.46\n",
      "trainer/Z Expert Targets Max         1092.68\n",
      "trainer/Z Expert Targets Min          432.603\n",
      "trainer/Z Policy Targets Mean         566.972\n",
      "trainer/Z Policy Targets Std          248.871\n",
      "trainer/Z Policy Targets Max         1080.74\n",
      "trainer/Z Policy Targets Min         -105.694\n",
      "trainer/Log Pis Mean                   13.8184\n",
      "trainer/Log Pis Std                     5.60129\n",
      "trainer/Policy mu Mean                  0.659777\n",
      "trainer/Policy mu Std                   2.73269\n",
      "trainer/Policy log std Mean            -3.48549\n",
      "trainer/Policy log std Std              1.28353\n",
      "exploration/num steps total         63953\n",
      "exploration/num paths total           861\n",
      "evaluation/num steps total         265338\n",
      "evaluation/num paths total            570\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48012\n",
      "evaluation/Rewards Std                  0.573106\n",
      "evaluation/Rewards Max                  4.51126\n",
      "evaluation/Rewards Min                  0.730176\n",
      "evaluation/Returns Mean              3480.12\n",
      "evaluation/Returns Std                 17.4166\n",
      "evaluation/Returns Max               3516.18\n",
      "evaluation/Returns Min               3460.74\n",
      "evaluation/Estimation Bias Mean       801.949\n",
      "evaluation/Estimation Bias Std        174.773\n",
      "evaluation/EB/Q_True Mean              32.1358\n",
      "evaluation/EB/Q_True Std               98.8777\n",
      "evaluation/EB/Q_Pred Mean             834.085\n",
      "evaluation/EB/Q_Pred Std              146.411\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3480.12\n",
      "evaluation/Actions Mean                 0.0120801\n",
      "evaluation/Actions Std                  0.562749\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999551\n",
      "time/backward_policy (s)                1.58209\n",
      "time/backward_zf1 (s)                   1.72309\n",
      "time/backward_zf2 (s)                   1.64038\n",
      "time/data sampling (s)                  0.238676\n",
      "time/data storing (s)                   0.0133899\n",
      "time/evaluation sampling (s)            1.34549\n",
      "time/exploration sampling (s)           0.164313\n",
      "time/logging (s)                        0.0117674\n",
      "time/preback_alpha (s)                  0.536108\n",
      "time/preback_policy (s)                 0.574016\n",
      "time/preback_start (s)                  0.120235\n",
      "time/preback_zf (s)                     4.90889\n",
      "time/saving (s)                         0.00531465\n",
      "time/training (s)                       2.76441\n",
      "time/epoch (s)                         15.6282\n",
      "time/total (s)                        857.025\n",
      "Epoch                                  56\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:15:41.645202 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 57 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  68000\n",
      "trainer/ZF1 Loss                       28.8397\n",
      "trainer/ZF2 Loss                       29.181\n",
      "trainer/ZF Expert Reward               21.3986\n",
      "trainer/ZF Policy Reward               -2.29836\n",
      "trainer/ZF CHI2 Term                   66.7686\n",
      "trainer/Policy Loss                  -546.229\n",
      "trainer/Policy Grad Norm              216.705\n",
      "trainer/Policy Param Norm              31.3049\n",
      "trainer/Zf1 Grad Norm                4334.7\n",
      "trainer/Zf1 Param Norm                 74.0366\n",
      "trainer/Zf2 Grad Norm                2837.47\n",
      "trainer/Zf2 Param Norm                 73.0852\n",
      "trainer/Z Expert Predictions Mean     823.442\n",
      "trainer/Z Expert Predictions Std      152.834\n",
      "trainer/Z Expert Predictions Max     1113.12\n",
      "trainer/Z Expert Predictions Min      445.626\n",
      "trainer/Z Policy Predictions Mean     533.303\n",
      "trainer/Z Policy Predictions Std      290.862\n",
      "trainer/Z Policy Predictions Max     1076.35\n",
      "trainer/Z Policy Predictions Min     -134.856\n",
      "trainer/Z Expert Targets Mean         802.043\n",
      "trainer/Z Expert Targets Std          155.697\n",
      "trainer/Z Expert Targets Max         1101.38\n",
      "trainer/Z Expert Targets Min          430.824\n",
      "trainer/Z Policy Targets Mean         535.601\n",
      "trainer/Z Policy Targets Std          289.534\n",
      "trainer/Z Policy Targets Max         1068.53\n",
      "trainer/Z Policy Targets Min         -126.234\n",
      "trainer/Log Pis Mean                   14.2034\n",
      "trainer/Log Pis Std                     6.45511\n",
      "trainer/Policy mu Mean                  0.774766\n",
      "trainer/Policy mu Std                   3.25613\n",
      "trainer/Policy log std Mean            -3.453\n",
      "trainer/Policy log std Std              1.25296\n",
      "exploration/num steps total         63953\n",
      "exploration/num paths total           861\n",
      "evaluation/num steps total         275338\n",
      "evaluation/num paths total            580\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.47617\n",
      "evaluation/Rewards Std                  0.582294\n",
      "evaluation/Rewards Max                  4.526\n",
      "evaluation/Rewards Min                  0.714164\n",
      "evaluation/Returns Mean              3476.17\n",
      "evaluation/Returns Std                  3.88209\n",
      "evaluation/Returns Max               3483.99\n",
      "evaluation/Returns Min               3471.71\n",
      "evaluation/Estimation Bias Mean       820.603\n",
      "evaluation/Estimation Bias Std        155.342\n",
      "evaluation/EB/Q_True Mean              32.1319\n",
      "evaluation/EB/Q_True Std               98.9195\n",
      "evaluation/EB/Q_Pred Mean             852.735\n",
      "evaluation/EB/Q_Pred Std              122.77\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3476.17\n",
      "evaluation/Actions Mean                 0.0366663\n",
      "evaluation/Actions Std                  0.564832\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99962\n",
      "time/backward_policy (s)                1.58258\n",
      "time/backward_zf1 (s)                   1.71031\n",
      "time/backward_zf2 (s)                   1.63832\n",
      "time/data sampling (s)                  0.235035\n",
      "time/data storing (s)                   0.0134105\n",
      "time/evaluation sampling (s)            1.35824\n",
      "time/exploration sampling (s)           0.163769\n",
      "time/logging (s)                        0.0114176\n",
      "time/preback_alpha (s)                  0.535431\n",
      "time/preback_policy (s)                 0.573547\n",
      "time/preback_start (s)                  0.118964\n",
      "time/preback_zf (s)                     4.92274\n",
      "time/saving (s)                         0.00526451\n",
      "time/training (s)                       2.7671\n",
      "time/epoch (s)                         15.6361\n",
      "time/total (s)                        872.679\n",
      "Epoch                                  57\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:15:57.366206 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 58 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  69000\n",
      "trainer/ZF1 Loss                        1.79357\n",
      "trainer/ZF2 Loss                        4.78338\n",
      "trainer/ZF Expert Reward               19.3193\n",
      "trainer/ZF Policy Reward               -3.79349\n",
      "trainer/ZF CHI2 Term                   39.6904\n",
      "trainer/Policy Loss                  -588.698\n",
      "trainer/Policy Grad Norm              151.139\n",
      "trainer/Policy Param Norm              31.4148\n",
      "trainer/Zf1 Grad Norm                2902.55\n",
      "trainer/Zf1 Param Norm                 74.4065\n",
      "trainer/Zf2 Grad Norm                2697.59\n",
      "trainer/Zf2 Param Norm                 73.4222\n",
      "trainer/Z Expert Predictions Mean     826.579\n",
      "trainer/Z Expert Predictions Std      159.366\n",
      "trainer/Z Expert Predictions Max     1132.07\n",
      "trainer/Z Expert Predictions Min      416.28\n",
      "trainer/Z Policy Predictions Mean     577.891\n",
      "trainer/Z Policy Predictions Std      261.673\n",
      "trainer/Z Policy Predictions Max     1091.38\n",
      "trainer/Z Policy Predictions Min     -136.025\n",
      "trainer/Z Expert Targets Mean         807.26\n",
      "trainer/Z Expert Targets Std          162.818\n",
      "trainer/Z Expert Targets Max         1111.22\n",
      "trainer/Z Expert Targets Min          392.621\n",
      "trainer/Z Policy Targets Mean         581.684\n",
      "trainer/Z Policy Targets Std          260.104\n",
      "trainer/Z Policy Targets Max         1078.86\n",
      "trainer/Z Policy Targets Min         -138.493\n",
      "trainer/Log Pis Mean                   13.4234\n",
      "trainer/Log Pis Std                     5.51883\n",
      "trainer/Policy mu Mean                  0.670485\n",
      "trainer/Policy mu Std                   2.7876\n",
      "trainer/Policy log std Mean            -3.40531\n",
      "trainer/Policy log std Std              1.22394\n",
      "exploration/num steps total         65953\n",
      "exploration/num paths total           863\n",
      "evaluation/num steps total         285338\n",
      "evaluation/num paths total            590\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50432\n",
      "evaluation/Rewards Std                  0.595774\n",
      "evaluation/Rewards Max                  4.63447\n",
      "evaluation/Rewards Min                  0.689378\n",
      "evaluation/Returns Mean              3504.32\n",
      "evaluation/Returns Std                 11.5768\n",
      "evaluation/Returns Max               3527.69\n",
      "evaluation/Returns Min               3489.73\n",
      "evaluation/Estimation Bias Mean       823.985\n",
      "evaluation/Estimation Bias Std        165.058\n",
      "evaluation/EB/Q_True Mean              32.6019\n",
      "evaluation/EB/Q_True Std              100.398\n",
      "evaluation/EB/Q_Pred Mean             856.587\n",
      "evaluation/EB/Q_Pred Std              131.844\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3504.32\n",
      "evaluation/Actions Mean                 0.0303688\n",
      "evaluation/Actions Std                  0.567782\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999775\n",
      "time/backward_policy (s)                1.62505\n",
      "time/backward_zf1 (s)                   1.74993\n",
      "time/backward_zf2 (s)                   1.67707\n",
      "time/data sampling (s)                  0.221731\n",
      "time/data storing (s)                   0.0135524\n",
      "time/evaluation sampling (s)            1.39563\n",
      "time/exploration sampling (s)           0.167609\n",
      "time/logging (s)                        0.0117882\n",
      "time/preback_alpha (s)                  0.530041\n",
      "time/preback_policy (s)                 0.572978\n",
      "time/preback_start (s)                  0.117707\n",
      "time/preback_zf (s)                     4.89394\n",
      "time/saving (s)                         0.0052821\n",
      "time/training (s)                       2.67781\n",
      "time/epoch (s)                         15.6601\n",
      "time/total (s)                        888.359\n",
      "Epoch                                  58\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:16:12.828184 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 59 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  70000\n",
      "trainer/ZF1 Loss                      107.361\n",
      "trainer/ZF2 Loss                      105.713\n",
      "trainer/ZF Expert Reward               21.1078\n",
      "trainer/ZF Policy Reward               -3.53963\n",
      "trainer/ZF CHI2 Term                  145.097\n",
      "trainer/Policy Loss                  -565.749\n",
      "trainer/Policy Grad Norm              218.883\n",
      "trainer/Policy Param Norm              31.5371\n",
      "trainer/Zf1 Grad Norm                4204.45\n",
      "trainer/Zf1 Param Norm                 74.7508\n",
      "trainer/Zf2 Grad Norm                6193.88\n",
      "trainer/Zf2 Param Norm                 73.7534\n",
      "trainer/Z Expert Predictions Mean     815.02\n",
      "trainer/Z Expert Predictions Std      158.178\n",
      "trainer/Z Expert Predictions Max     1119.57\n",
      "trainer/Z Expert Predictions Min      283.408\n",
      "trainer/Z Policy Predictions Mean     549.833\n",
      "trainer/Z Policy Predictions Std      279.354\n",
      "trainer/Z Policy Predictions Max     1096.28\n",
      "trainer/Z Policy Predictions Min     -160.787\n",
      "trainer/Z Expert Targets Mean         793.912\n",
      "trainer/Z Expert Targets Std          168.383\n",
      "trainer/Z Expert Targets Max         1105.02\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         553.372\n",
      "trainer/Z Policy Targets Std          277.366\n",
      "trainer/Z Policy Targets Max         1098.31\n",
      "trainer/Z Policy Targets Min         -160.063\n",
      "trainer/Log Pis Mean                   14.0531\n",
      "trainer/Log Pis Std                     6.5035\n",
      "trainer/Policy mu Mean                  0.793478\n",
      "trainer/Policy mu Std                   3.15622\n",
      "trainer/Policy log std Mean            -3.24641\n",
      "trainer/Policy log std Std              1.27594\n",
      "exploration/num steps total         65953\n",
      "exploration/num paths total           863\n",
      "evaluation/num steps total         289791\n",
      "evaluation/num paths total            600\n",
      "evaluation/path length Mean           445.3\n",
      "evaluation/path length Std            142.415\n",
      "evaluation/path length Max            796\n",
      "evaluation/path length Min            337\n",
      "evaluation/Rewards Mean                 3.41956\n",
      "evaluation/Rewards Std                  0.766402\n",
      "evaluation/Rewards Max                  5.36908\n",
      "evaluation/Rewards Min                  0.673034\n",
      "evaluation/Returns Mean              1522.73\n",
      "evaluation/Returns Std                529.597\n",
      "evaluation/Returns Max               2800.87\n",
      "evaluation/Returns Min               1107.5\n",
      "evaluation/Estimation Bias Mean       682.169\n",
      "evaluation/Estimation Bias Std        245.454\n",
      "evaluation/EB/Q_True Mean              57.0035\n",
      "evaluation/EB/Q_True Std              126.159\n",
      "evaluation/EB/Q_Pred Mean             739.173\n",
      "evaluation/EB/Q_Pred Std              214.316\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1522.73\n",
      "evaluation/Actions Mean                 0.0601345\n",
      "evaluation/Actions Std                  0.565618\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.60798\n",
      "time/backward_zf1 (s)                   1.73617\n",
      "time/backward_zf2 (s)                   1.65386\n",
      "time/data sampling (s)                  0.224441\n",
      "time/data storing (s)                   0.0133295\n",
      "time/evaluation sampling (s)            1.11043\n",
      "time/exploration sampling (s)           0.162303\n",
      "time/logging (s)                        0.0061637\n",
      "time/preback_alpha (s)                  0.534925\n",
      "time/preback_policy (s)                 0.576273\n",
      "time/preback_start (s)                  0.117746\n",
      "time/preback_zf (s)                     4.90538\n",
      "time/saving (s)                         0.00509706\n",
      "time/training (s)                       2.74083\n",
      "time/epoch (s)                         15.3949\n",
      "time/total (s)                        903.773\n",
      "Epoch                                  59\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:16:28.591944 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 60 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  71000\n",
      "trainer/ZF1 Loss                       72.9727\n",
      "trainer/ZF2 Loss                       51.8636\n",
      "trainer/ZF Expert Reward               17.966\n",
      "trainer/ZF Policy Reward               -6.24751\n",
      "trainer/ZF CHI2 Term                  100.927\n",
      "trainer/Policy Loss                  -584.749\n",
      "trainer/Policy Grad Norm              276.763\n",
      "trainer/Policy Param Norm              31.6556\n",
      "trainer/Zf1 Grad Norm                9851.14\n",
      "trainer/Zf1 Param Norm                 75.087\n",
      "trainer/Zf2 Grad Norm                5769.65\n",
      "trainer/Zf2 Param Norm                 74.0995\n",
      "trainer/Z Expert Predictions Mean     859.717\n",
      "trainer/Z Expert Predictions Std      146.944\n",
      "trainer/Z Expert Predictions Max     1106.32\n",
      "trainer/Z Expert Predictions Min      455.557\n",
      "trainer/Z Policy Predictions Mean     575.773\n",
      "trainer/Z Policy Predictions Std      271.145\n",
      "trainer/Z Policy Predictions Max     1118.07\n",
      "trainer/Z Policy Predictions Min     -163.771\n",
      "trainer/Z Expert Targets Mean         841.751\n",
      "trainer/Z Expert Targets Std          157.564\n",
      "trainer/Z Expert Targets Max         1099.48\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         582.02\n",
      "trainer/Z Policy Targets Std          272.576\n",
      "trainer/Z Policy Targets Max         1120.15\n",
      "trainer/Z Policy Targets Min         -176.456\n",
      "trainer/Log Pis Mean                   14.4398\n",
      "trainer/Log Pis Std                     6.70736\n",
      "trainer/Policy mu Mean                  0.955182\n",
      "trainer/Policy mu Std                   3.10183\n",
      "trainer/Policy log std Mean            -3.28352\n",
      "trainer/Policy log std Std              1.25384\n",
      "exploration/num steps total         65953\n",
      "exploration/num paths total           863\n",
      "evaluation/num steps total         298757\n",
      "evaluation/num paths total            610\n",
      "evaluation/path length Mean           896.6\n",
      "evaluation/path length Std            206.993\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            463\n",
      "evaluation/Rewards Mean                 3.51858\n",
      "evaluation/Rewards Std                  0.612013\n",
      "evaluation/Rewards Max                  5.0568\n",
      "evaluation/Rewards Min                  0.675811\n",
      "evaluation/Returns Mean              3154.76\n",
      "evaluation/Returns Std                733.003\n",
      "evaluation/Returns Max               3575.99\n",
      "evaluation/Returns Min               1620.08\n",
      "evaluation/Estimation Bias Mean       756.457\n",
      "evaluation/Estimation Bias Std        197.315\n",
      "evaluation/EB/Q_True Mean              36.254\n",
      "evaluation/EB/Q_True Std              105.112\n",
      "evaluation/EB/Q_Pred Mean             792.711\n",
      "evaluation/EB/Q_Pred Std              146.653\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3154.76\n",
      "evaluation/Actions Mean                 0.0243526\n",
      "evaluation/Actions Std                  0.581913\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72884\n",
      "time/backward_zf1 (s)                   1.84029\n",
      "time/backward_zf2 (s)                   1.78458\n",
      "time/data sampling (s)                  0.210073\n",
      "time/data storing (s)                   0.0135099\n",
      "time/evaluation sampling (s)            1.41806\n",
      "time/exploration sampling (s)           0.163872\n",
      "time/logging (s)                        0.0104865\n",
      "time/preback_alpha (s)                  0.530751\n",
      "time/preback_policy (s)                 0.591528\n",
      "time/preback_start (s)                  0.116993\n",
      "time/preback_zf (s)                     4.89971\n",
      "time/saving (s)                         0.00525445\n",
      "time/training (s)                       2.3959\n",
      "time/epoch (s)                         15.7098\n",
      "time/total (s)                        919.499\n",
      "Epoch                                  60\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:16:44.136157 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 61 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  72000\n",
      "trainer/ZF1 Loss                      103.538\n",
      "trainer/ZF2 Loss                      106.144\n",
      "trainer/ZF Expert Reward               19.467\n",
      "trainer/ZF Policy Reward               -1.8821\n",
      "trainer/ZF CHI2 Term                  140.135\n",
      "trainer/Policy Loss                  -577.56\n",
      "trainer/Policy Grad Norm              194.407\n",
      "trainer/Policy Param Norm              31.7455\n",
      "trainer/Zf1 Grad Norm                4026.29\n",
      "trainer/Zf1 Param Norm                 75.4122\n",
      "trainer/Zf2 Grad Norm                4744.18\n",
      "trainer/Zf2 Param Norm                 74.4407\n",
      "trainer/Z Expert Predictions Mean     859.062\n",
      "trainer/Z Expert Predictions Std      132.01\n",
      "trainer/Z Expert Predictions Max     1090.54\n",
      "trainer/Z Expert Predictions Min      491.543\n",
      "trainer/Z Policy Predictions Mean     561.666\n",
      "trainer/Z Policy Predictions Std      288.274\n",
      "trainer/Z Policy Predictions Max     1079.44\n",
      "trainer/Z Policy Predictions Min     -120.363\n",
      "trainer/Z Expert Targets Mean         839.595\n",
      "trainer/Z Expert Targets Std          136.972\n",
      "trainer/Z Expert Targets Max         1083.87\n",
      "trainer/Z Expert Targets Min          448.626\n",
      "trainer/Z Policy Targets Mean         563.548\n",
      "trainer/Z Policy Targets Std          289.208\n",
      "trainer/Z Policy Targets Max         1071.99\n",
      "trainer/Z Policy Targets Min         -112.093\n",
      "trainer/Log Pis Mean                   14.0861\n",
      "trainer/Log Pis Std                     6.11881\n",
      "trainer/Policy mu Mean                  0.896962\n",
      "trainer/Policy mu Std                   3.43482\n",
      "trainer/Policy log std Mean            -3.21865\n",
      "trainer/Policy log std Std              1.37021\n",
      "exploration/num steps total         65953\n",
      "exploration/num paths total           863\n",
      "evaluation/num steps total         302900\n",
      "evaluation/num paths total            620\n",
      "evaluation/path length Mean           414.3\n",
      "evaluation/path length Std             77.541\n",
      "evaluation/path length Max            634\n",
      "evaluation/path length Min            347\n",
      "evaluation/Rewards Mean                 3.46817\n",
      "evaluation/Rewards Std                  0.819754\n",
      "evaluation/Rewards Max                  5.43851\n",
      "evaluation/Rewards Min                  0.655123\n",
      "evaluation/Returns Mean              1436.86\n",
      "evaluation/Returns Std                286.076\n",
      "evaluation/Returns Max               2234.85\n",
      "evaluation/Returns Min               1169.54\n",
      "evaluation/Estimation Bias Mean       669.026\n",
      "evaluation/Estimation Bias Std        285.763\n",
      "evaluation/EB/Q_True Mean              41.067\n",
      "evaluation/EB/Q_True Std              102.713\n",
      "evaluation/EB/Q_Pred Mean             710.093\n",
      "evaluation/EB/Q_Pred Std              278.778\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1436.86\n",
      "evaluation/Actions Mean                 0.0440101\n",
      "evaluation/Actions Std                  0.586765\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70302\n",
      "time/backward_zf1 (s)                   1.80346\n",
      "time/backward_zf2 (s)                   1.74043\n",
      "time/data sampling (s)                  0.235182\n",
      "time/data storing (s)                   0.0136484\n",
      "time/evaluation sampling (s)            1.10579\n",
      "time/exploration sampling (s)           0.165885\n",
      "time/logging (s)                        0.00716411\n",
      "time/preback_alpha (s)                  0.539484\n",
      "time/preback_policy (s)                 0.595324\n",
      "time/preback_start (s)                  0.118768\n",
      "time/preback_zf (s)                     4.90711\n",
      "time/saving (s)                         0.0167366\n",
      "time/training (s)                       2.52943\n",
      "time/epoch (s)                         15.4814\n",
      "time/total (s)                        934.997\n",
      "Epoch                                  61\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:16:59.909897 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 62 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  73000\n",
      "trainer/ZF1 Loss                       26.7966\n",
      "trainer/ZF2 Loss                       37.5535\n",
      "trainer/ZF Expert Reward                8.75185\n",
      "trainer/ZF Policy Reward               -3.31949\n",
      "trainer/ZF CHI2 Term                   57.6119\n",
      "trainer/Policy Loss                  -614.327\n",
      "trainer/Policy Grad Norm              165.807\n",
      "trainer/Policy Param Norm              31.8309\n",
      "trainer/Zf1 Grad Norm                8197.05\n",
      "trainer/Zf1 Param Norm                 75.733\n",
      "trainer/Zf2 Grad Norm               12935.1\n",
      "trainer/Zf2 Param Norm                 74.7548\n",
      "trainer/Z Expert Predictions Mean     841.401\n",
      "trainer/Z Expert Predictions Std      137.124\n",
      "trainer/Z Expert Predictions Max     1092.64\n",
      "trainer/Z Expert Predictions Min      462.078\n",
      "trainer/Z Policy Predictions Mean     594.361\n",
      "trainer/Z Policy Predictions Std      290.015\n",
      "trainer/Z Policy Predictions Max     1047.58\n",
      "trainer/Z Policy Predictions Min     -201.079\n",
      "trainer/Z Expert Targets Mean         832.65\n",
      "trainer/Z Expert Targets Std          133.397\n",
      "trainer/Z Expert Targets Max         1081.4\n",
      "trainer/Z Expert Targets Min          468.853\n",
      "trainer/Z Policy Targets Mean         597.681\n",
      "trainer/Z Policy Targets Std          291.639\n",
      "trainer/Z Policy Targets Max         1026.69\n",
      "trainer/Z Policy Targets Min         -204.269\n",
      "trainer/Log Pis Mean                   13.5005\n",
      "trainer/Log Pis Std                     6.04915\n",
      "trainer/Policy mu Mean                  0.649259\n",
      "trainer/Policy mu Std                   3.01912\n",
      "trainer/Policy log std Mean            -3.30781\n",
      "trainer/Policy log std Std              1.25875\n",
      "exploration/num steps total         65953\n",
      "exploration/num paths total           863\n",
      "evaluation/num steps total         312900\n",
      "evaluation/num paths total            630\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48353\n",
      "evaluation/Rewards Std                  0.614592\n",
      "evaluation/Rewards Max                  4.60686\n",
      "evaluation/Rewards Min                  0.643028\n",
      "evaluation/Returns Mean              3483.53\n",
      "evaluation/Returns Std                  9.80721\n",
      "evaluation/Returns Max               3496.31\n",
      "evaluation/Returns Min               3463.35\n",
      "evaluation/Estimation Bias Mean       825.719\n",
      "evaluation/Estimation Bias Std        149.863\n",
      "evaluation/EB/Q_True Mean              32.1794\n",
      "evaluation/EB/Q_True Std               99.0633\n",
      "evaluation/EB/Q_Pred Mean             857.899\n",
      "evaluation/EB/Q_Pred Std              114.308\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3483.53\n",
      "evaluation/Actions Mean                 0.0384213\n",
      "evaluation/Actions Std                  0.577851\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.99991\n",
      "time/backward_policy (s)                1.7347\n",
      "time/backward_zf1 (s)                   1.84444\n",
      "time/backward_zf2 (s)                   1.78913\n",
      "time/data sampling (s)                  0.215334\n",
      "time/data storing (s)                   0.01384\n",
      "time/evaluation sampling (s)            1.37573\n",
      "time/exploration sampling (s)           0.16587\n",
      "time/logging (s)                        0.0123325\n",
      "time/preback_alpha (s)                  0.533655\n",
      "time/preback_policy (s)                 0.59824\n",
      "time/preback_start (s)                  0.118418\n",
      "time/preback_zf (s)                     4.91761\n",
      "time/saving (s)                         0.00539359\n",
      "time/training (s)                       2.39319\n",
      "time/epoch (s)                         15.7179\n",
      "time/total (s)                        950.734\n",
      "Epoch                                  62\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:17:15.699482 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 63 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  74000\n",
      "trainer/ZF1 Loss                       17.6412\n",
      "trainer/ZF2 Loss                       21.5626\n",
      "trainer/ZF Expert Reward               23.4245\n",
      "trainer/ZF Policy Reward               -1.43748\n",
      "trainer/ZF CHI2 Term                   57.5836\n",
      "trainer/Policy Loss                  -621.469\n",
      "trainer/Policy Grad Norm              276.926\n",
      "trainer/Policy Param Norm              31.9038\n",
      "trainer/Zf1 Grad Norm                7250.34\n",
      "trainer/Zf1 Param Norm                 76.0361\n",
      "trainer/Zf2 Grad Norm                9541.42\n",
      "trainer/Zf2 Param Norm                 75.037\n",
      "trainer/Z Expert Predictions Mean     855.919\n",
      "trainer/Z Expert Predictions Std      123.671\n",
      "trainer/Z Expert Predictions Max     1090.36\n",
      "trainer/Z Expert Predictions Min      564.077\n",
      "trainer/Z Policy Predictions Mean     611.209\n",
      "trainer/Z Policy Predictions Std      304.137\n",
      "trainer/Z Policy Predictions Max     1053.03\n",
      "trainer/Z Policy Predictions Min     -210.532\n",
      "trainer/Z Expert Targets Mean         832.494\n",
      "trainer/Z Expert Targets Std          131.217\n",
      "trainer/Z Expert Targets Max         1067.24\n",
      "trainer/Z Expert Targets Min          507.194\n",
      "trainer/Z Policy Targets Mean         612.647\n",
      "trainer/Z Policy Targets Std          301.564\n",
      "trainer/Z Policy Targets Max         1056.23\n",
      "trainer/Z Policy Targets Min         -230.591\n",
      "trainer/Log Pis Mean                   13.2523\n",
      "trainer/Log Pis Std                     5.77813\n",
      "trainer/Policy mu Mean                  0.429865\n",
      "trainer/Policy mu Std                   2.83687\n",
      "trainer/Policy log std Mean            -3.41127\n",
      "trainer/Policy log std Std              1.2124\n",
      "exploration/num steps total         65953\n",
      "exploration/num paths total           863\n",
      "evaluation/num steps total         322900\n",
      "evaluation/num paths total            640\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50358\n",
      "evaluation/Rewards Std                  0.588452\n",
      "evaluation/Rewards Max                  4.51454\n",
      "evaluation/Rewards Min                  0.623128\n",
      "evaluation/Returns Mean              3503.58\n",
      "evaluation/Returns Std                 10.6079\n",
      "evaluation/Returns Max               3527.52\n",
      "evaluation/Returns Min               3491.59\n",
      "evaluation/Estimation Bias Mean       816.61\n",
      "evaluation/Estimation Bias Std        148.657\n",
      "evaluation/EB/Q_True Mean              32.4597\n",
      "evaluation/EB/Q_True Std              100.311\n",
      "evaluation/EB/Q_Pred Mean             849.07\n",
      "evaluation/EB/Q_Pred Std              111.749\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3503.58\n",
      "evaluation/Actions Mean                 0.0507045\n",
      "evaluation/Actions Std                  0.574182\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999947\n",
      "time/backward_policy (s)                1.72745\n",
      "time/backward_zf1 (s)                   1.82318\n",
      "time/backward_zf2 (s)                   1.77672\n",
      "time/data sampling (s)                  0.23457\n",
      "time/data storing (s)                   0.0132789\n",
      "time/evaluation sampling (s)            1.37066\n",
      "time/exploration sampling (s)           0.16222\n",
      "time/logging (s)                        0.0115761\n",
      "time/preback_alpha (s)                  0.537693\n",
      "time/preback_policy (s)                 0.597345\n",
      "time/preback_start (s)                  0.119009\n",
      "time/preback_zf (s)                     4.91784\n",
      "time/saving (s)                         0.00546799\n",
      "time/training (s)                       2.42887\n",
      "time/epoch (s)                         15.7259\n",
      "time/total (s)                        966.481\n",
      "Epoch                                  63\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:17:31.610716 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 64 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  75000\n",
      "trainer/ZF1 Loss                       16.4094\n",
      "trainer/ZF2 Loss                       12.739\n",
      "trainer/ZF Expert Reward               14.8963\n",
      "trainer/ZF Policy Reward               -3.89045\n",
      "trainer/ZF CHI2 Term                   47.511\n",
      "trainer/Policy Loss                  -592.858\n",
      "trainer/Policy Grad Norm              177.137\n",
      "trainer/Policy Param Norm              31.9831\n",
      "trainer/Zf1 Grad Norm                5609.32\n",
      "trainer/Zf1 Param Norm                 76.3318\n",
      "trainer/Zf2 Grad Norm                4107.39\n",
      "trainer/Zf2 Param Norm                 75.3094\n",
      "trainer/Z Expert Predictions Mean     851.814\n",
      "trainer/Z Expert Predictions Std      112.627\n",
      "trainer/Z Expert Predictions Max     1073.16\n",
      "trainer/Z Expert Predictions Min      528.468\n",
      "trainer/Z Policy Predictions Mean     581.184\n",
      "trainer/Z Policy Predictions Std      302.24\n",
      "trainer/Z Policy Predictions Max     1065.37\n",
      "trainer/Z Policy Predictions Min     -198.978\n",
      "trainer/Z Expert Targets Mean         836.917\n",
      "trainer/Z Expert Targets Std          115.032\n",
      "trainer/Z Expert Targets Max         1048.65\n",
      "trainer/Z Expert Targets Min          539.317\n",
      "trainer/Z Policy Targets Mean         585.074\n",
      "trainer/Z Policy Targets Std          299.814\n",
      "trainer/Z Policy Targets Max         1044.92\n",
      "trainer/Z Policy Targets Min         -185.207\n",
      "trainer/Log Pis Mean                   14.293\n",
      "trainer/Log Pis Std                     6.18296\n",
      "trainer/Policy mu Mean                  0.229905\n",
      "trainer/Policy mu Std                   3.00415\n",
      "trainer/Policy log std Mean            -3.56303\n",
      "trainer/Policy log std Std              1.17457\n",
      "exploration/num steps total         68953\n",
      "exploration/num paths total           866\n",
      "evaluation/num steps total         330899\n",
      "evaluation/num paths total            652\n",
      "evaluation/path length Mean           666.583\n",
      "evaluation/path length Std            244.55\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            408\n",
      "evaluation/Rewards Mean                 3.55362\n",
      "evaluation/Rewards Std                  0.700303\n",
      "evaluation/Rewards Max                  5.43718\n",
      "evaluation/Rewards Min                  0.649945\n",
      "evaluation/Returns Mean              2368.79\n",
      "evaluation/Returns Std                874.126\n",
      "evaluation/Returns Max               3534.65\n",
      "evaluation/Returns Min               1414.96\n",
      "evaluation/Estimation Bias Mean       734.812\n",
      "evaluation/Estimation Bias Std        246.442\n",
      "evaluation/EB/Q_True Mean              40.8237\n",
      "evaluation/EB/Q_True Std              111.176\n",
      "evaluation/EB/Q_Pred Mean             775.636\n",
      "evaluation/EB/Q_Pred Std              214.188\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2368.79\n",
      "evaluation/Actions Mean                 0.0379693\n",
      "evaluation/Actions Std                  0.576865\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82989\n",
      "time/backward_zf1 (s)                   1.91545\n",
      "time/backward_zf2 (s)                   1.87698\n",
      "time/data sampling (s)                  0.22664\n",
      "time/data storing (s)                   0.0134397\n",
      "time/evaluation sampling (s)            1.36889\n",
      "time/exploration sampling (s)           0.169054\n",
      "time/logging (s)                        0.00981849\n",
      "time/preback_alpha (s)                  0.537705\n",
      "time/preback_policy (s)                 0.614305\n",
      "time/preback_start (s)                  0.119625\n",
      "time/preback_zf (s)                     4.92123\n",
      "time/saving (s)                         0.00522815\n",
      "time/training (s)                       2.24001\n",
      "time/epoch (s)                         15.8483\n",
      "time/total (s)                        982.348\n",
      "Epoch                                  64\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:17:47.417910 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 65 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  76000\n",
      "trainer/ZF1 Loss                       62.2053\n",
      "trainer/ZF2 Loss                       61.9511\n",
      "trainer/ZF Expert Reward               19.1159\n",
      "trainer/ZF Policy Reward               -2.24266\n",
      "trainer/ZF CHI2 Term                   96.6453\n",
      "trainer/Policy Loss                  -622.07\n",
      "trainer/Policy Grad Norm              244.939\n",
      "trainer/Policy Param Norm              32.0747\n",
      "trainer/Zf1 Grad Norm                4251.47\n",
      "trainer/Zf1 Param Norm                 76.5973\n",
      "trainer/Zf2 Grad Norm                6057.22\n",
      "trainer/Zf2 Param Norm                 75.5401\n",
      "trainer/Z Expert Predictions Mean     855.767\n",
      "trainer/Z Expert Predictions Std      102.042\n",
      "trainer/Z Expert Predictions Max     1062.06\n",
      "trainer/Z Expert Predictions Min      555.48\n",
      "trainer/Z Policy Predictions Mean     611.418\n",
      "trainer/Z Policy Predictions Std      291.26\n",
      "trainer/Z Policy Predictions Max      993.541\n",
      "trainer/Z Policy Predictions Min     -278.921\n",
      "trainer/Z Expert Targets Mean         836.651\n",
      "trainer/Z Expert Targets Std          103.844\n",
      "trainer/Z Expert Targets Max         1038.57\n",
      "trainer/Z Expert Targets Min          558.205\n",
      "trainer/Z Policy Targets Mean         613.661\n",
      "trainer/Z Policy Targets Std          290.856\n",
      "trainer/Z Policy Targets Max          966.534\n",
      "trainer/Z Policy Targets Min         -256.903\n",
      "trainer/Log Pis Mean                   13.342\n",
      "trainer/Log Pis Std                     6.34552\n",
      "trainer/Policy mu Mean                  0.510853\n",
      "trainer/Policy mu Std                   2.87012\n",
      "trainer/Policy log std Mean            -3.45164\n",
      "trainer/Policy log std Std              1.14469\n",
      "exploration/num steps total         72953\n",
      "exploration/num paths total           870\n",
      "evaluation/num steps total         340899\n",
      "evaluation/num paths total            662\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.4864\n",
      "evaluation/Rewards Std                  0.584093\n",
      "evaluation/Rewards Max                  4.58353\n",
      "evaluation/Rewards Min                  0.633725\n",
      "evaluation/Returns Mean              3486.4\n",
      "evaluation/Returns Std                 13.8586\n",
      "evaluation/Returns Max               3510.81\n",
      "evaluation/Returns Min               3462.42\n",
      "evaluation/Estimation Bias Mean       841.763\n",
      "evaluation/Estimation Bias Std        133.174\n",
      "evaluation/EB/Q_True Mean              32.21\n",
      "evaluation/EB/Q_True Std               99.3816\n",
      "evaluation/EB/Q_Pred Mean             873.973\n",
      "evaluation/EB/Q_Pred Std               90.2932\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3486.4\n",
      "evaluation/Actions Mean                 0.0224283\n",
      "evaluation/Actions Std                  0.563613\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.99994\n",
      "time/backward_policy (s)                1.70249\n",
      "time/backward_zf1 (s)                   1.81697\n",
      "time/backward_zf2 (s)                   1.74885\n",
      "time/data sampling (s)                  0.233344\n",
      "time/data storing (s)                   0.013324\n",
      "time/evaluation sampling (s)            1.35498\n",
      "time/exploration sampling (s)           0.172907\n",
      "time/logging (s)                        0.0148675\n",
      "time/preback_alpha (s)                  0.535518\n",
      "time/preback_policy (s)                 0.591552\n",
      "time/preback_start (s)                  0.120304\n",
      "time/preback_zf (s)                     4.90221\n",
      "time/saving (s)                         0.00798597\n",
      "time/training (s)                       2.53575\n",
      "time/epoch (s)                         15.751\n",
      "time/total (s)                        998.117\n",
      "Epoch                                  65\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:18:03.306784 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 66 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  77000\n",
      "trainer/ZF1 Loss                       80.5195\n",
      "trainer/ZF2 Loss                       84.9711\n",
      "trainer/ZF Expert Reward               14.8405\n",
      "trainer/ZF Policy Reward               -9.64057\n",
      "trainer/ZF CHI2 Term                  120.856\n",
      "trainer/Policy Loss                  -615.034\n",
      "trainer/Policy Grad Norm              300.713\n",
      "trainer/Policy Param Norm              32.1769\n",
      "trainer/Zf1 Grad Norm               10987.7\n",
      "trainer/Zf1 Param Norm                 76.8677\n",
      "trainer/Zf2 Grad Norm               11968\n",
      "trainer/Zf2 Param Norm                 75.7823\n",
      "trainer/Z Expert Predictions Mean     865.813\n",
      "trainer/Z Expert Predictions Std      109.606\n",
      "trainer/Z Expert Predictions Max     1079.27\n",
      "trainer/Z Expert Predictions Min      425.286\n",
      "trainer/Z Policy Predictions Mean     592.079\n",
      "trainer/Z Policy Predictions Std      298.227\n",
      "trainer/Z Policy Predictions Max      983.568\n",
      "trainer/Z Policy Predictions Min     -236.132\n",
      "trainer/Z Expert Targets Mean         850.973\n",
      "trainer/Z Expert Targets Std          110.94\n",
      "trainer/Z Expert Targets Max         1074.56\n",
      "trainer/Z Expert Targets Min          543.723\n",
      "trainer/Z Policy Targets Mean         601.72\n",
      "trainer/Z Policy Targets Std          293.836\n",
      "trainer/Z Policy Targets Max         1001.15\n",
      "trainer/Z Policy Targets Min         -233.879\n",
      "trainer/Log Pis Mean                   13.7674\n",
      "trainer/Log Pis Std                     5.72632\n",
      "trainer/Policy mu Mean                  0.668685\n",
      "trainer/Policy mu Std                   3.07203\n",
      "trainer/Policy log std Mean            -3.38668\n",
      "trainer/Policy log std Std              1.19363\n",
      "exploration/num steps total         73953\n",
      "exploration/num paths total           871\n",
      "evaluation/num steps total         350899\n",
      "evaluation/num paths total            672\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52701\n",
      "evaluation/Rewards Std                  0.592109\n",
      "evaluation/Rewards Max                  4.72052\n",
      "evaluation/Rewards Min                  0.604805\n",
      "evaluation/Returns Mean              3527.01\n",
      "evaluation/Returns Std                 14.6546\n",
      "evaluation/Returns Max               3555.1\n",
      "evaluation/Returns Min               3496.58\n",
      "evaluation/Estimation Bias Mean       823.579\n",
      "evaluation/Estimation Bias Std        150.963\n",
      "evaluation/EB/Q_True Mean              32.5666\n",
      "evaluation/EB/Q_True Std              100.317\n",
      "evaluation/EB/Q_Pred Mean             856.145\n",
      "evaluation/EB/Q_Pred Std              119.138\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3527.01\n",
      "evaluation/Actions Mean                 0.049377\n",
      "evaluation/Actions Std                  0.580021\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999985\n",
      "time/backward_policy (s)                1.61873\n",
      "time/backward_zf1 (s)                   1.76598\n",
      "time/backward_zf2 (s)                   1.68277\n",
      "time/data sampling (s)                  0.239439\n",
      "time/data storing (s)                   0.0140743\n",
      "time/evaluation sampling (s)            1.36992\n",
      "time/exploration sampling (s)           0.168927\n",
      "time/logging (s)                        0.0116573\n",
      "time/preback_alpha (s)                  0.54307\n",
      "time/preback_policy (s)                 0.586057\n",
      "time/preback_start (s)                  0.120574\n",
      "time/preback_zf (s)                     4.93338\n",
      "time/saving (s)                         0.0173167\n",
      "time/training (s)                       2.75344\n",
      "time/epoch (s)                         15.8253\n",
      "time/total (s)                       1013.96\n",
      "Epoch                                  66\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:18:19.182438 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 67 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  78000\n",
      "trainer/ZF1 Loss                       26.5345\n",
      "trainer/ZF2 Loss                       24.4166\n",
      "trainer/ZF Expert Reward               12.1924\n",
      "trainer/ZF Policy Reward               -7.95434\n",
      "trainer/ZF CHI2 Term                   59.1276\n",
      "trainer/Policy Loss                  -630.014\n",
      "trainer/Policy Grad Norm              304.794\n",
      "trainer/Policy Param Norm              32.2833\n",
      "trainer/Zf1 Grad Norm                7162.61\n",
      "trainer/Zf1 Param Norm                 77.1237\n",
      "trainer/Zf2 Grad Norm                7759.65\n",
      "trainer/Zf2 Param Norm                 76.0253\n",
      "trainer/Z Expert Predictions Mean     867.967\n",
      "trainer/Z Expert Predictions Std      114.31\n",
      "trainer/Z Expert Predictions Max     1105.24\n",
      "trainer/Z Expert Predictions Min      568.61\n",
      "trainer/Z Policy Predictions Mean     604.849\n",
      "trainer/Z Policy Predictions Std      287.494\n",
      "trainer/Z Policy Predictions Max     1027.49\n",
      "trainer/Z Policy Predictions Min     -261.696\n",
      "trainer/Z Expert Targets Mean         855.774\n",
      "trainer/Z Expert Targets Std          116.597\n",
      "trainer/Z Expert Targets Max         1058.42\n",
      "trainer/Z Expert Targets Min          513.639\n",
      "trainer/Z Policy Targets Mean         612.804\n",
      "trainer/Z Policy Targets Std          288.067\n",
      "trainer/Z Policy Targets Max         1002.52\n",
      "trainer/Z Policy Targets Min         -250.834\n",
      "trainer/Log Pis Mean                   13.6417\n",
      "trainer/Log Pis Std                     6.29556\n",
      "trainer/Policy mu Mean                  0.37047\n",
      "trainer/Policy mu Std                   2.99768\n",
      "trainer/Policy log std Mean            -3.37244\n",
      "trainer/Policy log std Std              1.17867\n",
      "exploration/num steps total         73953\n",
      "exploration/num paths total           871\n",
      "evaluation/num steps total         360899\n",
      "evaluation/num paths total            682\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.4947\n",
      "evaluation/Rewards Std                  0.603639\n",
      "evaluation/Rewards Max                  4.71942\n",
      "evaluation/Rewards Min                  0.567622\n",
      "evaluation/Returns Mean              3494.7\n",
      "evaluation/Returns Std                  8.07651\n",
      "evaluation/Returns Max               3509.37\n",
      "evaluation/Returns Min               3485.2\n",
      "evaluation/Estimation Bias Mean       867.169\n",
      "evaluation/Estimation Bias Std        124.989\n",
      "evaluation/EB/Q_True Mean              32.2499\n",
      "evaluation/EB/Q_True Std               99.424\n",
      "evaluation/EB/Q_Pred Mean             899.419\n",
      "evaluation/EB/Q_Pred Std               78.1418\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3494.7\n",
      "evaluation/Actions Mean                 0.039925\n",
      "evaluation/Actions Std                  0.588537\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999971\n",
      "time/backward_policy (s)                1.85838\n",
      "time/backward_zf1 (s)                   1.92469\n",
      "time/backward_zf2 (s)                   1.90184\n",
      "time/data sampling (s)                  0.229827\n",
      "time/data storing (s)                   0.0135422\n",
      "time/evaluation sampling (s)            1.38956\n",
      "time/exploration sampling (s)           0.163411\n",
      "time/logging (s)                        0.0114834\n",
      "time/preback_alpha (s)                  0.535909\n",
      "time/preback_policy (s)                 0.614002\n",
      "time/preback_start (s)                  0.117121\n",
      "time/preback_zf (s)                     4.90348\n",
      "time/saving (s)                         0.00536112\n",
      "time/training (s)                       2.14191\n",
      "time/epoch (s)                         15.8105\n",
      "time/total (s)                       1029.79\n",
      "Epoch                                  67\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:18:34.950065 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 68 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  79000\n",
      "trainer/ZF1 Loss                       16.3309\n",
      "trainer/ZF2 Loss                       33.8789\n",
      "trainer/ZF Expert Reward                6.45601\n",
      "trainer/ZF Policy Reward               -7.204\n",
      "trainer/ZF CHI2 Term                   52.1927\n",
      "trainer/Policy Loss                  -624.184\n",
      "trainer/Policy Grad Norm              223.396\n",
      "trainer/Policy Param Norm              32.3804\n",
      "trainer/Zf1 Grad Norm                4923.84\n",
      "trainer/Zf1 Param Norm                 77.358\n",
      "trainer/Zf2 Grad Norm                9026.31\n",
      "trainer/Zf2 Param Norm                 76.2403\n",
      "trainer/Z Expert Predictions Mean     857.771\n",
      "trainer/Z Expert Predictions Std      113.784\n",
      "trainer/Z Expert Predictions Max     1068.12\n",
      "trainer/Z Expert Predictions Min      567.223\n",
      "trainer/Z Policy Predictions Mean     605.96\n",
      "trainer/Z Policy Predictions Std      265.189\n",
      "trainer/Z Policy Predictions Max     1024.56\n",
      "trainer/Z Policy Predictions Min     -198.705\n",
      "trainer/Z Expert Targets Mean         851.315\n",
      "trainer/Z Expert Targets Std          112.521\n",
      "trainer/Z Expert Targets Max         1064.09\n",
      "trainer/Z Expert Targets Min          563.469\n",
      "trainer/Z Policy Targets Mean         613.163\n",
      "trainer/Z Policy Targets Std          262.292\n",
      "trainer/Z Policy Targets Max         1026.67\n",
      "trainer/Z Policy Targets Min         -213.166\n",
      "trainer/Log Pis Mean                   13.5634\n",
      "trainer/Log Pis Std                     6.00134\n",
      "trainer/Policy mu Mean                  0.408269\n",
      "trainer/Policy mu Std                   2.68501\n",
      "trainer/Policy log std Mean            -3.34117\n",
      "trainer/Policy log std Std              1.1211\n",
      "exploration/num steps total         75953\n",
      "exploration/num paths total           873\n",
      "evaluation/num steps total         370670\n",
      "evaluation/num paths total            692\n",
      "evaluation/path length Mean           977.1\n",
      "evaluation/path length Std             68.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            771\n",
      "evaluation/Rewards Mean                 3.52119\n",
      "evaluation/Rewards Std                  0.601964\n",
      "evaluation/Rewards Max                  5.39723\n",
      "evaluation/Rewards Min                  0.550665\n",
      "evaluation/Returns Mean              3440.55\n",
      "evaluation/Returns Std                231.336\n",
      "evaluation/Returns Max               3568.11\n",
      "evaluation/Returns Min               2749.16\n",
      "evaluation/Estimation Bias Mean       851.162\n",
      "evaluation/Estimation Bias Std        177.831\n",
      "evaluation/EB/Q_True Mean              33.1389\n",
      "evaluation/EB/Q_True Std              100.95\n",
      "evaluation/EB/Q_Pred Mean             884.301\n",
      "evaluation/EB/Q_Pred Std              126.386\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3440.55\n",
      "evaluation/Actions Mean                 0.0365005\n",
      "evaluation/Actions Std                  0.576732\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67573\n",
      "time/backward_zf1 (s)                   1.78333\n",
      "time/backward_zf2 (s)                   1.72315\n",
      "time/data sampling (s)                  0.223318\n",
      "time/data storing (s)                   0.0134429\n",
      "time/evaluation sampling (s)            1.36587\n",
      "time/exploration sampling (s)           0.168162\n",
      "time/logging (s)                        0.0117534\n",
      "time/preback_alpha (s)                  0.535921\n",
      "time/preback_policy (s)                 0.592962\n",
      "time/preback_start (s)                  0.119977\n",
      "time/preback_zf (s)                     4.90503\n",
      "time/saving (s)                         0.00552621\n",
      "time/training (s)                       2.58282\n",
      "time/epoch (s)                         15.707\n",
      "time/total (s)                       1045.52\n",
      "Epoch                                  68\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:18:49.804810 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 69 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  80000\n",
      "trainer/ZF1 Loss                       77.0147\n",
      "trainer/ZF2 Loss                       73.4594\n",
      "trainer/ZF Expert Reward               17.8838\n",
      "trainer/ZF Policy Reward               -3.89076\n",
      "trainer/ZF CHI2 Term                  110.486\n",
      "trainer/Policy Loss                  -663.146\n",
      "trainer/Policy Grad Norm              210.093\n",
      "trainer/Policy Param Norm              32.4698\n",
      "trainer/Zf1 Grad Norm                7480\n",
      "trainer/Zf1 Param Norm                 77.5545\n",
      "trainer/Zf2 Grad Norm                6666.82\n",
      "trainer/Zf2 Param Norm                 76.4225\n",
      "trainer/Z Expert Predictions Mean     874.762\n",
      "trainer/Z Expert Predictions Std      108.757\n",
      "trainer/Z Expert Predictions Max     1053.26\n",
      "trainer/Z Expert Predictions Min      540.759\n",
      "trainer/Z Policy Predictions Mean     649.162\n",
      "trainer/Z Policy Predictions Std      248.098\n",
      "trainer/Z Policy Predictions Max     1055.97\n",
      "trainer/Z Policy Predictions Min     -123.997\n",
      "trainer/Z Expert Targets Mean         856.879\n",
      "trainer/Z Expert Targets Std          121.045\n",
      "trainer/Z Expert Targets Max         1040.74\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         653.052\n",
      "trainer/Z Policy Targets Std          244.372\n",
      "trainer/Z Policy Targets Max         1037.24\n",
      "trainer/Z Policy Targets Min         -102.32\n",
      "trainer/Log Pis Mean                   13.6105\n",
      "trainer/Log Pis Std                     6.53462\n",
      "trainer/Policy mu Mean                  0.490765\n",
      "trainer/Policy mu Std                   2.67884\n",
      "trainer/Policy log std Mean            -3.54632\n",
      "trainer/Policy log std Std              1.0797\n",
      "exploration/num steps total         75953\n",
      "exploration/num paths total           873\n",
      "evaluation/num steps total         373921\n",
      "evaluation/num paths total            702\n",
      "evaluation/path length Mean           325.1\n",
      "evaluation/path length Std              2.21133\n",
      "evaluation/path length Max            329\n",
      "evaluation/path length Min            321\n",
      "evaluation/Rewards Mean                 3.37268\n",
      "evaluation/Rewards Std                  0.886021\n",
      "evaluation/Rewards Max                  5.2131\n",
      "evaluation/Rewards Min                  0.538286\n",
      "evaluation/Returns Mean              1096.46\n",
      "evaluation/Returns Std                  6.23577\n",
      "evaluation/Returns Max               1108.88\n",
      "evaluation/Returns Min               1085.31\n",
      "evaluation/Estimation Bias Mean       719.484\n",
      "evaluation/Estimation Bias Std        275.478\n",
      "evaluation/EB/Q_True Mean              26.3143\n",
      "evaluation/EB/Q_True Std               82.7022\n",
      "evaluation/EB/Q_Pred Mean             745.798\n",
      "evaluation/EB/Q_Pred Std              269.171\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1096.46\n",
      "evaluation/Actions Mean                 0.0292\n",
      "evaluation/Actions Std                  0.583063\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.58106\n",
      "time/backward_zf1 (s)                   1.7122\n",
      "time/backward_zf2 (s)                   1.63443\n",
      "time/data sampling (s)                  0.233952\n",
      "time/data storing (s)                   0.0142585\n",
      "time/evaluation sampling (s)            0.497141\n",
      "time/exploration sampling (s)           0.166704\n",
      "time/logging (s)                        0.00531984\n",
      "time/preback_alpha (s)                  0.538017\n",
      "time/preback_policy (s)                 0.575465\n",
      "time/preback_start (s)                  0.119161\n",
      "time/preback_zf (s)                     4.92128\n",
      "time/saving (s)                         0.00482775\n",
      "time/training (s)                       2.78419\n",
      "time/epoch (s)                         14.788\n",
      "time/total (s)                       1060.32\n",
      "Epoch                                  69\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:19:05.599340 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 70 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  81000\n",
      "trainer/ZF1 Loss                       35.5174\n",
      "trainer/ZF2 Loss                       28.7575\n",
      "trainer/ZF Expert Reward               10.3306\n",
      "trainer/ZF Policy Reward               -4.13571\n",
      "trainer/ZF CHI2 Term                   59.8782\n",
      "trainer/Policy Loss                  -662.141\n",
      "trainer/Policy Grad Norm              255.607\n",
      "trainer/Policy Param Norm              32.549\n",
      "trainer/Zf1 Grad Norm                6932.31\n",
      "trainer/Zf1 Param Norm                 77.7592\n",
      "trainer/Zf2 Grad Norm                7528.35\n",
      "trainer/Zf2 Param Norm                 76.6419\n",
      "trainer/Z Expert Predictions Mean     864.31\n",
      "trainer/Z Expert Predictions Std      125.087\n",
      "trainer/Z Expert Predictions Max     1061.14\n",
      "trainer/Z Expert Predictions Min      491.366\n",
      "trainer/Z Policy Predictions Mean     651.367\n",
      "trainer/Z Policy Predictions Std      254.453\n",
      "trainer/Z Policy Predictions Max     1018.98\n",
      "trainer/Z Policy Predictions Min     -112.263\n",
      "trainer/Z Expert Targets Mean         853.979\n",
      "trainer/Z Expert Targets Std          124.309\n",
      "trainer/Z Expert Targets Max         1036.8\n",
      "trainer/Z Expert Targets Min          481.9\n",
      "trainer/Z Policy Targets Mean         655.503\n",
      "trainer/Z Policy Targets Std          252.672\n",
      "trainer/Z Policy Targets Max         1014.7\n",
      "trainer/Z Policy Targets Min         -108.956\n",
      "trainer/Log Pis Mean                   13.4086\n",
      "trainer/Log Pis Std                     6.03304\n",
      "trainer/Policy mu Mean                  0.430712\n",
      "trainer/Policy mu Std                   2.63254\n",
      "trainer/Policy log std Mean            -3.57398\n",
      "trainer/Policy log std Std              1.09998\n",
      "exploration/num steps total         76422\n",
      "exploration/num paths total           874\n",
      "evaluation/num steps total         383921\n",
      "evaluation/num paths total            712\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52342\n",
      "evaluation/Rewards Std                  0.596852\n",
      "evaluation/Rewards Max                  4.601\n",
      "evaluation/Rewards Min                  0.557261\n",
      "evaluation/Returns Mean              3523.42\n",
      "evaluation/Returns Std                 16.5882\n",
      "evaluation/Returns Max               3551.23\n",
      "evaluation/Returns Min               3499.08\n",
      "evaluation/Estimation Bias Mean       866.307\n",
      "evaluation/Estimation Bias Std        135.892\n",
      "evaluation/EB/Q_True Mean              32.7894\n",
      "evaluation/EB/Q_True Std              101.117\n",
      "evaluation/EB/Q_Pred Mean             899.096\n",
      "evaluation/EB/Q_Pred Std               90.4846\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3523.42\n",
      "evaluation/Actions Mean                 0.0342096\n",
      "evaluation/Actions Std                  0.58262\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.99993\n",
      "time/backward_policy (s)                1.71163\n",
      "time/backward_zf1 (s)                   1.80411\n",
      "time/backward_zf2 (s)                   1.75895\n",
      "time/data sampling (s)                  0.218497\n",
      "time/data storing (s)                   0.0137306\n",
      "time/evaluation sampling (s)            1.36854\n",
      "time/exploration sampling (s)           0.165041\n",
      "time/logging (s)                        0.0118996\n",
      "time/preback_alpha (s)                  0.535857\n",
      "time/preback_policy (s)                 0.598105\n",
      "time/preback_start (s)                  0.118826\n",
      "time/preback_zf (s)                     4.934\n",
      "time/saving (s)                         0.00483522\n",
      "time/training (s)                       2.49489\n",
      "time/epoch (s)                         15.7389\n",
      "time/total (s)                       1076.08\n",
      "Epoch                                  70\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:19:21.420316 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 71 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  82000\n",
      "trainer/ZF1 Loss                       28.5902\n",
      "trainer/ZF2 Loss                       24.7349\n",
      "trainer/ZF Expert Reward               10.5092\n",
      "trainer/ZF Policy Reward               -4.51117\n",
      "trainer/ZF CHI2 Term                   55.1786\n",
      "trainer/Policy Loss                  -660.368\n",
      "trainer/Policy Grad Norm              359.273\n",
      "trainer/Policy Param Norm              32.6357\n",
      "trainer/Zf1 Grad Norm                5885.67\n",
      "trainer/Zf1 Param Norm                 77.9773\n",
      "trainer/Zf2 Grad Norm                5690.66\n",
      "trainer/Zf2 Param Norm                 76.8863\n",
      "trainer/Z Expert Predictions Mean     875.476\n",
      "trainer/Z Expert Predictions Std      112.38\n",
      "trainer/Z Expert Predictions Max     1053.87\n",
      "trainer/Z Expert Predictions Min      539.73\n",
      "trainer/Z Policy Predictions Mean     648.352\n",
      "trainer/Z Policy Predictions Std      247.372\n",
      "trainer/Z Policy Predictions Max     1033.44\n",
      "trainer/Z Policy Predictions Min     -113.027\n",
      "trainer/Z Expert Targets Mean         864.967\n",
      "trainer/Z Expert Targets Std          114.182\n",
      "trainer/Z Expert Targets Max         1059.39\n",
      "trainer/Z Expert Targets Min          490.731\n",
      "trainer/Z Policy Targets Mean         652.864\n",
      "trainer/Z Policy Targets Std          248.668\n",
      "trainer/Z Policy Targets Max         1026.23\n",
      "trainer/Z Policy Targets Min         -145.166\n",
      "trainer/Log Pis Mean                   13.6319\n",
      "trainer/Log Pis Std                     5.78635\n",
      "trainer/Policy mu Mean                  0.419116\n",
      "trainer/Policy mu Std                   2.70609\n",
      "trainer/Policy log std Mean            -3.50554\n",
      "trainer/Policy log std Std              1.13858\n",
      "exploration/num steps total         76422\n",
      "exploration/num paths total           874\n",
      "evaluation/num steps total         393921\n",
      "evaluation/num paths total            722\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51818\n",
      "evaluation/Rewards Std                  0.592895\n",
      "evaluation/Rewards Max                  4.62062\n",
      "evaluation/Rewards Min                  0.555984\n",
      "evaluation/Returns Mean              3518.18\n",
      "evaluation/Returns Std                  9.51867\n",
      "evaluation/Returns Max               3539.11\n",
      "evaluation/Returns Min               3503.45\n",
      "evaluation/Estimation Bias Mean       892.566\n",
      "evaluation/Estimation Bias Std        132.737\n",
      "evaluation/EB/Q_True Mean              32.4549\n",
      "evaluation/EB/Q_True Std              100.186\n",
      "evaluation/EB/Q_Pred Mean             925.021\n",
      "evaluation/EB/Q_Pred Std               87.5412\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3518.18\n",
      "evaluation/Actions Mean                 0.0346605\n",
      "evaluation/Actions Std                  0.582057\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999925\n",
      "time/backward_policy (s)                1.82589\n",
      "time/backward_zf1 (s)                   1.90655\n",
      "time/backward_zf2 (s)                   1.87192\n",
      "time/data sampling (s)                  0.206725\n",
      "time/data storing (s)                   0.0137321\n",
      "time/evaluation sampling (s)            1.3804\n",
      "time/exploration sampling (s)           0.166352\n",
      "time/logging (s)                        0.011255\n",
      "time/preback_alpha (s)                  0.534132\n",
      "time/preback_policy (s)                 0.608469\n",
      "time/preback_start (s)                  0.117169\n",
      "time/preback_zf (s)                     4.90815\n",
      "time/saving (s)                         0.00555054\n",
      "time/training (s)                       2.20031\n",
      "time/epoch (s)                         15.7566\n",
      "time/total (s)                       1091.86\n",
      "Epoch                                  71\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:19:37.296232 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 72 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  83000\n",
      "trainer/ZF1 Loss                      159.526\n",
      "trainer/ZF2 Loss                      138.474\n",
      "trainer/ZF Expert Reward               20.0485\n",
      "trainer/ZF Policy Reward               -4.70092\n",
      "trainer/ZF CHI2 Term                  186.87\n",
      "trainer/Policy Loss                  -647.165\n",
      "trainer/Policy Grad Norm              233.092\n",
      "trainer/Policy Param Norm              32.7304\n",
      "trainer/Zf1 Grad Norm                8838.81\n",
      "trainer/Zf1 Param Norm                 78.2558\n",
      "trainer/Zf2 Grad Norm                7856.42\n",
      "trainer/Zf2 Param Norm                 77.1402\n",
      "trainer/Z Expert Predictions Mean     875.1\n",
      "trainer/Z Expert Predictions Std      122.927\n",
      "trainer/Z Expert Predictions Max     1091.46\n",
      "trainer/Z Expert Predictions Min      505.528\n",
      "trainer/Z Policy Predictions Mean     634.189\n",
      "trainer/Z Policy Predictions Std      291.222\n",
      "trainer/Z Policy Predictions Max     1053.03\n",
      "trainer/Z Policy Predictions Min     -216.537\n",
      "trainer/Z Expert Targets Mean         855.052\n",
      "trainer/Z Expert Targets Std          143.284\n",
      "trainer/Z Expert Targets Max         1067.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         638.889\n",
      "trainer/Z Policy Targets Std          288.393\n",
      "trainer/Z Policy Targets Max         1035.07\n",
      "trainer/Z Policy Targets Min         -243.108\n",
      "trainer/Log Pis Mean                   13.2531\n",
      "trainer/Log Pis Std                     6.12208\n",
      "trainer/Policy mu Mean                  0.538492\n",
      "trainer/Policy mu Std                   2.88142\n",
      "trainer/Policy log std Mean            -3.41319\n",
      "trainer/Policy log std Std              1.14181\n",
      "exploration/num steps total         78215\n",
      "exploration/num paths total           877\n",
      "evaluation/num steps total         400802\n",
      "evaluation/num paths total            732\n",
      "evaluation/path length Mean           688.1\n",
      "evaluation/path length Std            152.223\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            481\n",
      "evaluation/Rewards Mean                 3.58126\n",
      "evaluation/Rewards Std                  0.704059\n",
      "evaluation/Rewards Max                  5.77716\n",
      "evaluation/Rewards Min                  0.568261\n",
      "evaluation/Returns Mean              2464.26\n",
      "evaluation/Returns Std                549.901\n",
      "evaluation/Returns Max               3540.62\n",
      "evaluation/Returns Min               1696.18\n",
      "evaluation/Estimation Bias Mean       732.246\n",
      "evaluation/Estimation Bias Std        289.413\n",
      "evaluation/EB/Q_True Mean              47.6271\n",
      "evaluation/EB/Q_True Std              118.921\n",
      "evaluation/EB/Q_Pred Mean             779.873\n",
      "evaluation/EB/Q_Pred Std              256.501\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2464.26\n",
      "evaluation/Actions Mean                 0.0431026\n",
      "evaluation/Actions Std                  0.596421\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.6217\n",
      "time/backward_zf1 (s)                   1.75313\n",
      "time/backward_zf2 (s)                   1.67408\n",
      "time/data sampling (s)                  0.221899\n",
      "time/data storing (s)                   0.0136568\n",
      "time/evaluation sampling (s)            1.49764\n",
      "time/exploration sampling (s)           0.170964\n",
      "time/logging (s)                        0.00880857\n",
      "time/preback_alpha (s)                  0.537721\n",
      "time/preback_policy (s)                 0.580156\n",
      "time/preback_start (s)                  0.121962\n",
      "time/preback_zf (s)                     4.92455\n",
      "time/saving (s)                         0.00525217\n",
      "time/training (s)                       2.67302\n",
      "time/epoch (s)                         15.8045\n",
      "time/total (s)                       1107.69\n",
      "Epoch                                  72\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:19:53.180885 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 73 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  84000\n",
      "trainer/ZF1 Loss                      110.571\n",
      "trainer/ZF2 Loss                      103.057\n",
      "trainer/ZF Expert Reward               13.4836\n",
      "trainer/ZF Policy Reward               -4.60721\n",
      "trainer/ZF CHI2 Term                  138.717\n",
      "trainer/Policy Loss                  -666.105\n",
      "trainer/Policy Grad Norm              280.337\n",
      "trainer/Policy Param Norm              32.8156\n",
      "trainer/Zf1 Grad Norm                7187.84\n",
      "trainer/Zf1 Param Norm                 78.5719\n",
      "trainer/Zf2 Grad Norm                6839.93\n",
      "trainer/Zf2 Param Norm                 77.4204\n",
      "trainer/Z Expert Predictions Mean     884.697\n",
      "trainer/Z Expert Predictions Std      118.798\n",
      "trainer/Z Expert Predictions Max     1064.95\n",
      "trainer/Z Expert Predictions Min      504.19\n",
      "trainer/Z Policy Predictions Mean     649.89\n",
      "trainer/Z Policy Predictions Std      273.754\n",
      "trainer/Z Policy Predictions Max     1054.42\n",
      "trainer/Z Policy Predictions Min     -123.444\n",
      "trainer/Z Expert Targets Mean         871.213\n",
      "trainer/Z Expert Targets Std          118.018\n",
      "trainer/Z Expert Targets Max         1050.14\n",
      "trainer/Z Expert Targets Min          513.277\n",
      "trainer/Z Policy Targets Mean         654.497\n",
      "trainer/Z Policy Targets Std          275.048\n",
      "trainer/Z Policy Targets Max         1050.61\n",
      "trainer/Z Policy Targets Min         -120.51\n",
      "trainer/Log Pis Mean                   13.9522\n",
      "trainer/Log Pis Std                     5.74472\n",
      "trainer/Policy mu Mean                  0.637543\n",
      "trainer/Policy mu Std                   2.89913\n",
      "trainer/Policy log std Mean            -3.41311\n",
      "trainer/Policy log std Std              1.21871\n",
      "exploration/num steps total         78215\n",
      "exploration/num paths total           877\n",
      "evaluation/num steps total         410802\n",
      "evaluation/num paths total            742\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.5007\n",
      "evaluation/Rewards Std                  0.579229\n",
      "evaluation/Rewards Max                  4.5888\n",
      "evaluation/Rewards Min                  0.602186\n",
      "evaluation/Returns Mean              3500.7\n",
      "evaluation/Returns Std                  4.71358\n",
      "evaluation/Returns Max               3511.46\n",
      "evaluation/Returns Min               3493.07\n",
      "evaluation/Estimation Bias Mean       910.154\n",
      "evaluation/Estimation Bias Std        122.418\n",
      "evaluation/EB/Q_True Mean              32.4296\n",
      "evaluation/EB/Q_True Std               99.9402\n",
      "evaluation/EB/Q_Pred Mean             942.584\n",
      "evaluation/EB/Q_Pred Std               69.0909\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3500.7\n",
      "evaluation/Actions Mean                 0.0313004\n",
      "evaluation/Actions Std                  0.581365\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999983\n",
      "time/backward_policy (s)                1.7575\n",
      "time/backward_zf1 (s)                   1.8623\n",
      "time/backward_zf2 (s)                   1.806\n",
      "time/data sampling (s)                  0.233171\n",
      "time/data storing (s)                   0.0136128\n",
      "time/evaluation sampling (s)            1.38508\n",
      "time/exploration sampling (s)           0.164432\n",
      "time/logging (s)                        0.0131966\n",
      "time/preback_alpha (s)                  0.540204\n",
      "time/preback_policy (s)                 0.609789\n",
      "time/preback_start (s)                  0.119118\n",
      "time/preback_zf (s)                     4.92942\n",
      "time/saving (s)                         0.00536909\n",
      "time/training (s)                       2.3859\n",
      "time/epoch (s)                         15.8251\n",
      "time/total (s)                       1123.54\n",
      "Epoch                                  73\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:20:09.092193 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 74 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  85000\n",
      "trainer/ZF1 Loss                       45.8638\n",
      "trainer/ZF2 Loss                       39.0141\n",
      "trainer/ZF Expert Reward               21.4476\n",
      "trainer/ZF Policy Reward                3.63913\n",
      "trainer/ZF CHI2 Term                   73.6051\n",
      "trainer/Policy Loss                  -676.965\n",
      "trainer/Policy Grad Norm              322.759\n",
      "trainer/Policy Param Norm              32.9142\n",
      "trainer/Zf1 Grad Norm                6547.07\n",
      "trainer/Zf1 Param Norm                 78.9121\n",
      "trainer/Zf2 Grad Norm                5408.8\n",
      "trainer/Zf2 Param Norm                 77.72\n",
      "trainer/Z Expert Predictions Mean     902.15\n",
      "trainer/Z Expert Predictions Std      120.291\n",
      "trainer/Z Expert Predictions Max     1081.78\n",
      "trainer/Z Expert Predictions Min      537.804\n",
      "trainer/Z Policy Predictions Mean     662.941\n",
      "trainer/Z Policy Predictions Std      281.306\n",
      "trainer/Z Policy Predictions Max     1072.79\n",
      "trainer/Z Policy Predictions Min     -161.787\n",
      "trainer/Z Expert Targets Mean         880.702\n",
      "trainer/Z Expert Targets Std          125.029\n",
      "trainer/Z Expert Targets Max         1060.87\n",
      "trainer/Z Expert Targets Min          505.358\n",
      "trainer/Z Policy Targets Mean         659.302\n",
      "trainer/Z Policy Targets Std          279.837\n",
      "trainer/Z Policy Targets Max         1064.18\n",
      "trainer/Z Policy Targets Min         -155.149\n",
      "trainer/Log Pis Mean                   13.4926\n",
      "trainer/Log Pis Std                     5.84376\n",
      "trainer/Policy mu Mean                  0.313341\n",
      "trainer/Policy mu Std                   2.65948\n",
      "trainer/Policy log std Mean            -3.5427\n",
      "trainer/Policy log std Std              1.11252\n",
      "exploration/num steps total         81215\n",
      "exploration/num paths total           880\n",
      "evaluation/num steps total         420802\n",
      "evaluation/num paths total            752\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48903\n",
      "evaluation/Rewards Std                  0.585353\n",
      "evaluation/Rewards Max                  4.50655\n",
      "evaluation/Rewards Min                  0.661849\n",
      "evaluation/Returns Mean              3489.03\n",
      "evaluation/Returns Std                 18.1534\n",
      "evaluation/Returns Max               3527.04\n",
      "evaluation/Returns Min               3466.96\n",
      "evaluation/Estimation Bias Mean       875.536\n",
      "evaluation/Estimation Bias Std        150.618\n",
      "evaluation/EB/Q_True Mean              32.2837\n",
      "evaluation/EB/Q_True Std               99.5076\n",
      "evaluation/EB/Q_Pred Mean             907.819\n",
      "evaluation/EB/Q_Pred Std              107.789\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3489.03\n",
      "evaluation/Actions Mean                 0.0179155\n",
      "evaluation/Actions Std                  0.582768\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999967\n",
      "time/backward_policy (s)                1.82976\n",
      "time/backward_zf1 (s)                   1.92983\n",
      "time/backward_zf2 (s)                   1.89346\n",
      "time/data sampling (s)                  0.232045\n",
      "time/data storing (s)                   0.0139568\n",
      "time/evaluation sampling (s)            1.38785\n",
      "time/exploration sampling (s)           0.173177\n",
      "time/logging (s)                        0.0175642\n",
      "time/preback_alpha (s)                  0.537148\n",
      "time/preback_policy (s)                 0.615128\n",
      "time/preback_start (s)                  0.120244\n",
      "time/preback_zf (s)                     4.91568\n",
      "time/saving (s)                         0.00553701\n",
      "time/training (s)                       2.18069\n",
      "time/epoch (s)                         15.8521\n",
      "time/total (s)                       1139.41\n",
      "Epoch                                  74\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:20:24.941705 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 75 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  86000\n",
      "trainer/ZF1 Loss                       26.9806\n",
      "trainer/ZF2 Loss                       22.8847\n",
      "trainer/ZF Expert Reward               13.796\n",
      "trainer/ZF Policy Reward               -4.32886\n",
      "trainer/ZF CHI2 Term                   55.6025\n",
      "trainer/Policy Loss                  -695.919\n",
      "trainer/Policy Grad Norm              279.559\n",
      "trainer/Policy Param Norm              33.0159\n",
      "trainer/Zf1 Grad Norm                8529.91\n",
      "trainer/Zf1 Param Norm                 79.2806\n",
      "trainer/Zf2 Grad Norm                3714.8\n",
      "trainer/Zf2 Param Norm                 78.0415\n",
      "trainer/Z Expert Predictions Mean     904.783\n",
      "trainer/Z Expert Predictions Std      112.878\n",
      "trainer/Z Expert Predictions Max     1102.7\n",
      "trainer/Z Expert Predictions Min      609.953\n",
      "trainer/Z Policy Predictions Mean     682.713\n",
      "trainer/Z Policy Predictions Std      261.492\n",
      "trainer/Z Policy Predictions Max     1078.38\n",
      "trainer/Z Policy Predictions Min      -98.0465\n",
      "trainer/Z Expert Targets Mean         890.986\n",
      "trainer/Z Expert Targets Std          112.173\n",
      "trainer/Z Expert Targets Max         1078.22\n",
      "trainer/Z Expert Targets Min          583.749\n",
      "trainer/Z Policy Targets Mean         687.042\n",
      "trainer/Z Policy Targets Std          260.564\n",
      "trainer/Z Policy Targets Max         1060.41\n",
      "trainer/Z Policy Targets Min          -82.6865\n",
      "trainer/Log Pis Mean                   12.6717\n",
      "trainer/Log Pis Std                     5.6738\n",
      "trainer/Policy mu Mean                  0.326934\n",
      "trainer/Policy mu Std                   2.64558\n",
      "trainer/Policy log std Mean            -3.40654\n",
      "trainer/Policy log std Std              1.13798\n",
      "exploration/num steps total         82215\n",
      "exploration/num paths total           881\n",
      "evaluation/num steps total         430802\n",
      "evaluation/num paths total            762\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.5028\n",
      "evaluation/Rewards Std                  0.592978\n",
      "evaluation/Rewards Max                  4.54869\n",
      "evaluation/Rewards Min                  0.654651\n",
      "evaluation/Returns Mean              3502.8\n",
      "evaluation/Returns Std                 15.6786\n",
      "evaluation/Returns Max               3528.58\n",
      "evaluation/Returns Min               3481.78\n",
      "evaluation/Estimation Bias Mean       902.938\n",
      "evaluation/Estimation Bias Std        132.537\n",
      "evaluation/EB/Q_True Mean              32.18\n",
      "evaluation/EB/Q_True Std               99.3492\n",
      "evaluation/EB/Q_Pred Mean             935.118\n",
      "evaluation/EB/Q_Pred Std               88.239\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3502.8\n",
      "evaluation/Actions Mean                 0.0189208\n",
      "evaluation/Actions Std                  0.602527\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999937\n",
      "time/backward_policy (s)                1.7103\n",
      "time/backward_zf1 (s)                   1.81525\n",
      "time/backward_zf2 (s)                   1.76087\n",
      "time/data sampling (s)                  0.228533\n",
      "time/data storing (s)                   0.0138632\n",
      "time/evaluation sampling (s)            1.40303\n",
      "time/exploration sampling (s)           0.168637\n",
      "time/logging (s)                        0.0123706\n",
      "time/preback_alpha (s)                  0.538444\n",
      "time/preback_policy (s)                 0.597723\n",
      "time/preback_start (s)                  0.120033\n",
      "time/preback_zf (s)                     4.91582\n",
      "time/saving (s)                         0.00582397\n",
      "time/training (s)                       2.4866\n",
      "time/epoch (s)                         15.7773\n",
      "time/total (s)                       1155.21\n",
      "Epoch                                  75\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:20:40.675831 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 76 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  87000\n",
      "trainer/ZF1 Loss                       38.2141\n",
      "trainer/ZF2 Loss                       35.6627\n",
      "trainer/ZF Expert Reward               15.7612\n",
      "trainer/ZF Policy Reward               -0.166631\n",
      "trainer/ZF CHI2 Term                   65.6542\n",
      "trainer/Policy Loss                  -700.912\n",
      "trainer/Policy Grad Norm              370.114\n",
      "trainer/Policy Param Norm              33.0996\n",
      "trainer/Zf1 Grad Norm                7432.8\n",
      "trainer/Zf1 Param Norm                 79.6388\n",
      "trainer/Zf2 Grad Norm                4723.87\n",
      "trainer/Zf2 Param Norm                 78.3645\n",
      "trainer/Z Expert Predictions Mean     907.837\n",
      "trainer/Z Expert Predictions Std      112.892\n",
      "trainer/Z Expert Predictions Max     1125.34\n",
      "trainer/Z Expert Predictions Min      589.082\n",
      "trainer/Z Policy Predictions Mean     687.358\n",
      "trainer/Z Policy Predictions Std      268.546\n",
      "trainer/Z Policy Predictions Max     1071.68\n",
      "trainer/Z Policy Predictions Min     -118.853\n",
      "trainer/Z Expert Targets Mean         892.076\n",
      "trainer/Z Expert Targets Std          111.453\n",
      "trainer/Z Expert Targets Max         1091.57\n",
      "trainer/Z Expert Targets Min          568.971\n",
      "trainer/Z Policy Targets Mean         687.525\n",
      "trainer/Z Policy Targets Std          266.886\n",
      "trainer/Z Policy Targets Max         1085.28\n",
      "trainer/Z Policy Targets Min         -113.055\n",
      "trainer/Log Pis Mean                   12.9171\n",
      "trainer/Log Pis Std                     5.28477\n",
      "trainer/Policy mu Mean                  0.307747\n",
      "trainer/Policy mu Std                   2.53583\n",
      "trainer/Policy log std Mean            -3.51406\n",
      "trainer/Policy log std Std              1.11289\n",
      "exploration/num steps total         83215\n",
      "exploration/num paths total           882\n",
      "evaluation/num steps total         440802\n",
      "evaluation/num paths total            772\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48897\n",
      "evaluation/Rewards Std                  0.600757\n",
      "evaluation/Rewards Max                  4.59494\n",
      "evaluation/Rewards Min                  0.659898\n",
      "evaluation/Returns Mean              3488.97\n",
      "evaluation/Returns Std                 15.0467\n",
      "evaluation/Returns Max               3514.78\n",
      "evaluation/Returns Min               3464.28\n",
      "evaluation/Estimation Bias Mean       882.816\n",
      "evaluation/Estimation Bias Std        139.694\n",
      "evaluation/EB/Q_True Mean              32.307\n",
      "evaluation/EB/Q_True Std               99.69\n",
      "evaluation/EB/Q_Pred Mean             915.123\n",
      "evaluation/EB/Q_Pred Std               99.6488\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3488.97\n",
      "evaluation/Actions Mean                 0.0198153\n",
      "evaluation/Actions Std                  0.587711\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999838\n",
      "time/backward_policy (s)                1.76434\n",
      "time/backward_zf1 (s)                   1.85226\n",
      "time/backward_zf2 (s)                   1.81664\n",
      "time/data sampling (s)                  0.241836\n",
      "time/data storing (s)                   0.0134257\n",
      "time/evaluation sampling (s)            1.32937\n",
      "time/exploration sampling (s)           0.165952\n",
      "time/logging (s)                        0.0113367\n",
      "time/preback_alpha (s)                  0.536146\n",
      "time/preback_policy (s)                 0.599408\n",
      "time/preback_start (s)                  0.118918\n",
      "time/preback_zf (s)                     4.90728\n",
      "time/saving (s)                         0.00522709\n",
      "time/training (s)                       2.3018\n",
      "time/epoch (s)                         15.6639\n",
      "time/total (s)                       1170.9\n",
      "Epoch                                  76\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:20:56.532873 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 77 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  88000\n",
      "trainer/ZF1 Loss                       39.4962\n",
      "trainer/ZF2 Loss                       31.1139\n",
      "trainer/ZF Expert Reward               10.6305\n",
      "trainer/ZF Policy Reward               -0.873742\n",
      "trainer/ZF CHI2 Term                   59.58\n",
      "trainer/Policy Loss                  -715.783\n",
      "trainer/Policy Grad Norm              366.797\n",
      "trainer/Policy Param Norm              33.1918\n",
      "trainer/Zf1 Grad Norm                4709.58\n",
      "trainer/Zf1 Param Norm                 80.0176\n",
      "trainer/Zf2 Grad Norm               10243\n",
      "trainer/Zf2 Param Norm                 78.7159\n",
      "trainer/Z Expert Predictions Mean     916.221\n",
      "trainer/Z Expert Predictions Std      110.523\n",
      "trainer/Z Expert Predictions Max     1096.05\n",
      "trainer/Z Expert Predictions Min      556.501\n",
      "trainer/Z Policy Predictions Mean     701.711\n",
      "trainer/Z Policy Predictions Std      260.836\n",
      "trainer/Z Policy Predictions Max     1072.11\n",
      "trainer/Z Policy Predictions Min     -198.264\n",
      "trainer/Z Expert Targets Mean         905.59\n",
      "trainer/Z Expert Targets Std          112.409\n",
      "trainer/Z Expert Targets Max         1084.53\n",
      "trainer/Z Expert Targets Min          521.071\n",
      "trainer/Z Policy Targets Mean         702.585\n",
      "trainer/Z Policy Targets Std          262.595\n",
      "trainer/Z Policy Targets Max         1061.42\n",
      "trainer/Z Policy Targets Min         -207.635\n",
      "trainer/Log Pis Mean                   12.8997\n",
      "trainer/Log Pis Std                     5.22068\n",
      "trainer/Policy mu Mean                  0.327573\n",
      "trainer/Policy mu Std                   2.31739\n",
      "trainer/Policy log std Mean            -3.66084\n",
      "trainer/Policy log std Std              1.06647\n",
      "exploration/num steps total         83215\n",
      "exploration/num paths total           882\n",
      "evaluation/num steps total         450802\n",
      "evaluation/num paths total            782\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51401\n",
      "evaluation/Rewards Std                  0.590445\n",
      "evaluation/Rewards Max                  4.61582\n",
      "evaluation/Rewards Min                  0.659826\n",
      "evaluation/Returns Mean              3514.01\n",
      "evaluation/Returns Std                 12.8564\n",
      "evaluation/Returns Max               3537.91\n",
      "evaluation/Returns Min               3499.58\n",
      "evaluation/Estimation Bias Mean       918.84\n",
      "evaluation/Estimation Bias Std        133.743\n",
      "evaluation/EB/Q_True Mean              32.5471\n",
      "evaluation/EB/Q_True Std              100.474\n",
      "evaluation/EB/Q_Pred Mean             951.388\n",
      "evaluation/EB/Q_Pred Std               87.18\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3514.01\n",
      "evaluation/Actions Mean                 0.00803163\n",
      "evaluation/Actions Std                  0.59743\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999951\n",
      "time/backward_policy (s)                1.85032\n",
      "time/backward_zf1 (s)                   1.93857\n",
      "time/backward_zf2 (s)                   1.89939\n",
      "time/data sampling (s)                  0.229807\n",
      "time/data storing (s)                   0.0133261\n",
      "time/evaluation sampling (s)            1.33745\n",
      "time/exploration sampling (s)           0.161381\n",
      "time/logging (s)                        0.0117575\n",
      "time/preback_alpha (s)                  0.534975\n",
      "time/preback_policy (s)                 0.614861\n",
      "time/preback_start (s)                  0.117318\n",
      "time/preback_zf (s)                     4.90985\n",
      "time/saving (s)                         0.00535685\n",
      "time/training (s)                       2.16957\n",
      "time/epoch (s)                         15.7939\n",
      "time/total (s)                       1186.72\n",
      "Epoch                                  77\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:21:12.354645 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 78 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  89000\n",
      "trainer/ZF1 Loss                       74.957\n",
      "trainer/ZF2 Loss                       63.6802\n",
      "trainer/ZF Expert Reward               22.6542\n",
      "trainer/ZF Policy Reward                6.42992\n",
      "trainer/ZF CHI2 Term                   98.2208\n",
      "trainer/Policy Loss                  -699.83\n",
      "trainer/Policy Grad Norm              405.76\n",
      "trainer/Policy Param Norm              33.2903\n",
      "trainer/Zf1 Grad Norm                8192.94\n",
      "trainer/Zf1 Param Norm                 80.4058\n",
      "trainer/Zf2 Grad Norm                6221.85\n",
      "trainer/Zf2 Param Norm                 79.0653\n",
      "trainer/Z Expert Predictions Mean     931.713\n",
      "trainer/Z Expert Predictions Std      107.776\n",
      "trainer/Z Expert Predictions Max     1114.59\n",
      "trainer/Z Expert Predictions Min      621.233\n",
      "trainer/Z Policy Predictions Mean     695.701\n",
      "trainer/Z Policy Predictions Std      268.702\n",
      "trainer/Z Policy Predictions Max     1084.41\n",
      "trainer/Z Policy Predictions Min      -91.2205\n",
      "trainer/Z Expert Targets Mean         909.059\n",
      "trainer/Z Expert Targets Std          109.146\n",
      "trainer/Z Expert Targets Max         1089.79\n",
      "trainer/Z Expert Targets Min          617.275\n",
      "trainer/Z Policy Targets Mean         689.271\n",
      "trainer/Z Policy Targets Std          269.978\n",
      "trainer/Z Policy Targets Max         1069.4\n",
      "trainer/Z Policy Targets Min          -94.4052\n",
      "trainer/Log Pis Mean                   12.806\n",
      "trainer/Log Pis Std                     5.32478\n",
      "trainer/Policy mu Mean                  0.41726\n",
      "trainer/Policy mu Std                   2.45389\n",
      "trainer/Policy log std Mean            -3.55669\n",
      "trainer/Policy log std Std              1.10866\n",
      "exploration/num steps total         84215\n",
      "exploration/num paths total           883\n",
      "evaluation/num steps total         460802\n",
      "evaluation/num paths total            792\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.42951\n",
      "evaluation/Rewards Std                  0.550942\n",
      "evaluation/Rewards Max                  4.39299\n",
      "evaluation/Rewards Min                  0.680908\n",
      "evaluation/Returns Mean              3429.51\n",
      "evaluation/Returns Std                 18.8003\n",
      "evaluation/Returns Max               3462.6\n",
      "evaluation/Returns Min               3400.73\n",
      "evaluation/Estimation Bias Mean       935.038\n",
      "evaluation/Estimation Bias Std        134.121\n",
      "evaluation/EB/Q_True Mean              31.6829\n",
      "evaluation/EB/Q_True Std               97.7343\n",
      "evaluation/EB/Q_Pred Mean             966.721\n",
      "evaluation/EB/Q_Pred Std               88.5853\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3429.51\n",
      "evaluation/Actions Mean                 0.00942282\n",
      "evaluation/Actions Std                  0.575049\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999876\n",
      "time/backward_policy (s)                1.69299\n",
      "time/backward_zf1 (s)                   1.79897\n",
      "time/backward_zf2 (s)                   1.73955\n",
      "time/data sampling (s)                  0.22276\n",
      "time/data storing (s)                   0.0139229\n",
      "time/evaluation sampling (s)            1.42587\n",
      "time/exploration sampling (s)           0.167482\n",
      "time/logging (s)                        0.0113837\n",
      "time/preback_alpha (s)                  0.534769\n",
      "time/preback_policy (s)                 0.592169\n",
      "time/preback_start (s)                  0.119758\n",
      "time/preback_zf (s)                     4.91279\n",
      "time/saving (s)                         0.00556531\n",
      "time/training (s)                       2.51882\n",
      "time/epoch (s)                         15.7568\n",
      "time/total (s)                       1202.5\n",
      "Epoch                                  78\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:21:28.125682 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 79 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  90000\n",
      "trainer/ZF1 Loss                       38.9151\n",
      "trainer/ZF2 Loss                       37.0373\n",
      "trainer/ZF Expert Reward               13.6356\n",
      "trainer/ZF Policy Reward               -3.59065\n",
      "trainer/ZF CHI2 Term                   68.5706\n",
      "trainer/Policy Loss                  -673.409\n",
      "trainer/Policy Grad Norm              448.499\n",
      "trainer/Policy Param Norm              33.3833\n",
      "trainer/Zf1 Grad Norm               10777\n",
      "trainer/Zf1 Param Norm                 80.7812\n",
      "trainer/Zf2 Grad Norm               13706.4\n",
      "trainer/Zf2 Param Norm                 79.4045\n",
      "trainer/Z Expert Predictions Mean     926.804\n",
      "trainer/Z Expert Predictions Std      101.556\n",
      "trainer/Z Expert Predictions Max     1102.99\n",
      "trainer/Z Expert Predictions Min      496.197\n",
      "trainer/Z Policy Predictions Mean     654.175\n",
      "trainer/Z Policy Predictions Std      322.029\n",
      "trainer/Z Policy Predictions Max     1089.42\n",
      "trainer/Z Policy Predictions Min     -308.938\n",
      "trainer/Z Expert Targets Mean         913.169\n",
      "trainer/Z Expert Targets Std          103.567\n",
      "trainer/Z Expert Targets Max         1092.62\n",
      "trainer/Z Expert Targets Min          544.256\n",
      "trainer/Z Policy Targets Mean         657.765\n",
      "trainer/Z Policy Targets Std          318.739\n",
      "trainer/Z Policy Targets Max         1079.94\n",
      "trainer/Z Policy Targets Min         -319.45\n",
      "trainer/Log Pis Mean                   13.5032\n",
      "trainer/Log Pis Std                     5.50216\n",
      "trainer/Policy mu Mean                  0.429383\n",
      "trainer/Policy mu Std                   2.73167\n",
      "trainer/Policy log std Mean            -3.6749\n",
      "trainer/Policy log std Std              1.1709\n",
      "exploration/num steps total         84215\n",
      "exploration/num paths total           883\n",
      "evaluation/num steps total         470802\n",
      "evaluation/num paths total            802\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.45528\n",
      "evaluation/Rewards Std                  0.576248\n",
      "evaluation/Rewards Max                  4.56705\n",
      "evaluation/Rewards Min                  0.678627\n",
      "evaluation/Returns Mean              3455.28\n",
      "evaluation/Returns Std                 11.5965\n",
      "evaluation/Returns Max               3474.57\n",
      "evaluation/Returns Min               3431.61\n",
      "evaluation/Estimation Bias Mean       922.919\n",
      "evaluation/Estimation Bias Std        140.537\n",
      "evaluation/EB/Q_True Mean              31.8224\n",
      "evaluation/EB/Q_True Std               98.2578\n",
      "evaluation/EB/Q_Pred Mean             954.742\n",
      "evaluation/EB/Q_Pred Std               99.1162\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3455.28\n",
      "evaluation/Actions Mean                 0.00921885\n",
      "evaluation/Actions Std                  0.590936\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99995\n",
      "time/backward_policy (s)                1.65736\n",
      "time/backward_zf1 (s)                   1.7719\n",
      "time/backward_zf2 (s)                   1.70119\n",
      "time/data sampling (s)                  0.215847\n",
      "time/data storing (s)                   0.0139561\n",
      "time/evaluation sampling (s)            1.34859\n",
      "time/exploration sampling (s)           0.165927\n",
      "time/logging (s)                        0.0112766\n",
      "time/preback_alpha (s)                  0.539235\n",
      "time/preback_policy (s)                 0.58591\n",
      "time/preback_start (s)                  0.120206\n",
      "time/preback_zf (s)                     4.91734\n",
      "time/saving (s)                         0.00504131\n",
      "time/training (s)                       2.65482\n",
      "time/epoch (s)                         15.7086\n",
      "time/total (s)                       1218.22\n",
      "Epoch                                  79\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:21:43.937880 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 80 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  91000\n",
      "trainer/ZF1 Loss                       18.9496\n",
      "trainer/ZF2 Loss                       16.9353\n",
      "trainer/ZF Expert Reward               18.2294\n",
      "trainer/ZF Policy Reward                0.925485\n",
      "trainer/ZF CHI2 Term                   48.6499\n",
      "trainer/Policy Loss                  -720.587\n",
      "trainer/Policy Grad Norm              238.414\n",
      "trainer/Policy Param Norm              33.4689\n",
      "trainer/Zf1 Grad Norm                6726.48\n",
      "trainer/Zf1 Param Norm                 81.133\n",
      "trainer/Zf2 Grad Norm                4726.27\n",
      "trainer/Zf2 Param Norm                 79.7421\n",
      "trainer/Z Expert Predictions Mean     938.378\n",
      "trainer/Z Expert Predictions Std      105.116\n",
      "trainer/Z Expert Predictions Max     1120.51\n",
      "trainer/Z Expert Predictions Min      550.605\n",
      "trainer/Z Policy Predictions Mean     709.109\n",
      "trainer/Z Policy Predictions Std      295.696\n",
      "trainer/Z Policy Predictions Max     1084.6\n",
      "trainer/Z Policy Predictions Min     -170.817\n",
      "trainer/Z Expert Targets Mean         920.148\n",
      "trainer/Z Expert Targets Std          104.142\n",
      "trainer/Z Expert Targets Max         1088.11\n",
      "trainer/Z Expert Targets Min          536.724\n",
      "trainer/Z Policy Targets Mean         708.184\n",
      "trainer/Z Policy Targets Std          289.082\n",
      "trainer/Z Policy Targets Max         1065.44\n",
      "trainer/Z Policy Targets Min         -174.84\n",
      "trainer/Log Pis Mean                   13.5388\n",
      "trainer/Log Pis Std                     5.78246\n",
      "trainer/Policy mu Mean                  0.437262\n",
      "trainer/Policy mu Std                   2.88937\n",
      "trainer/Policy log std Mean            -3.65181\n",
      "trainer/Policy log std Std              1.10417\n",
      "exploration/num steps total         85215\n",
      "exploration/num paths total           884\n",
      "evaluation/num steps total         480802\n",
      "evaluation/num paths total            812\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.47853\n",
      "evaluation/Rewards Std                  0.559904\n",
      "evaluation/Rewards Max                  4.44722\n",
      "evaluation/Rewards Min                  0.695587\n",
      "evaluation/Returns Mean              3478.53\n",
      "evaluation/Returns Std                 10.5122\n",
      "evaluation/Returns Max               3495.46\n",
      "evaluation/Returns Min               3460.86\n",
      "evaluation/Estimation Bias Mean       943.297\n",
      "evaluation/Estimation Bias Std        138.797\n",
      "evaluation/EB/Q_True Mean              32.3393\n",
      "evaluation/EB/Q_True Std               99.6582\n",
      "evaluation/EB/Q_Pred Mean             975.636\n",
      "evaluation/EB/Q_Pred Std               98.1428\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3478.53\n",
      "evaluation/Actions Mean                 0.0142963\n",
      "evaluation/Actions Std                  0.550037\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999888\n",
      "time/backward_policy (s)                1.80205\n",
      "time/backward_zf1 (s)                   1.90424\n",
      "time/backward_zf2 (s)                   1.85643\n",
      "time/data sampling (s)                  0.224363\n",
      "time/data storing (s)                   0.0135549\n",
      "time/evaluation sampling (s)            1.36613\n",
      "time/exploration sampling (s)           0.168288\n",
      "time/logging (s)                        0.0114653\n",
      "time/preback_alpha (s)                  0.536236\n",
      "time/preback_policy (s)                 0.603573\n",
      "time/preback_start (s)                  0.119173\n",
      "time/preback_zf (s)                     4.90636\n",
      "time/saving (s)                         0.00506431\n",
      "time/training (s)                       2.23208\n",
      "time/epoch (s)                         15.749\n",
      "time/total (s)                       1233.99\n",
      "Epoch                                  80\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:21:59.744487 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 81 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  92000\n",
      "trainer/ZF1 Loss                       16.4071\n",
      "trainer/ZF2 Loss                       16.3359\n",
      "trainer/ZF Expert Reward                9.99672\n",
      "trainer/ZF Policy Reward               -6.60925\n",
      "trainer/ZF CHI2 Term                   46.0746\n",
      "trainer/Policy Loss                  -712.65\n",
      "trainer/Policy Grad Norm              400.562\n",
      "trainer/Policy Param Norm              33.5424\n",
      "trainer/Zf1 Grad Norm                8244.08\n",
      "trainer/Zf1 Param Norm                 81.4841\n",
      "trainer/Zf2 Grad Norm                4365.48\n",
      "trainer/Zf2 Param Norm                 80.0604\n",
      "trainer/Z Expert Predictions Mean     933.678\n",
      "trainer/Z Expert Predictions Std      101.273\n",
      "trainer/Z Expert Predictions Max     1109.6\n",
      "trainer/Z Expert Predictions Min      554.507\n",
      "trainer/Z Policy Predictions Mean     695.899\n",
      "trainer/Z Policy Predictions Std      294.022\n",
      "trainer/Z Policy Predictions Max     1070.6\n",
      "trainer/Z Policy Predictions Min     -205.427\n",
      "trainer/Z Expert Targets Mean         923.682\n",
      "trainer/Z Expert Targets Std          101.23\n",
      "trainer/Z Expert Targets Max         1103.99\n",
      "trainer/Z Expert Targets Min          528.478\n",
      "trainer/Z Policy Targets Mean         702.508\n",
      "trainer/Z Policy Targets Std          291.39\n",
      "trainer/Z Policy Targets Max         1074.54\n",
      "trainer/Z Policy Targets Min         -190.418\n",
      "trainer/Log Pis Mean                   13.2294\n",
      "trainer/Log Pis Std                     5.43949\n",
      "trainer/Policy mu Mean                  0.312344\n",
      "trainer/Policy mu Std                   2.75444\n",
      "trainer/Policy log std Mean            -3.53921\n",
      "trainer/Policy log std Std              1.16888\n",
      "exploration/num steps total         85215\n",
      "exploration/num paths total           884\n",
      "evaluation/num steps total         490366\n",
      "evaluation/num paths total            822\n",
      "evaluation/path length Mean           956.4\n",
      "evaluation/path length Std             87.2103\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            779\n",
      "evaluation/Rewards Mean                 3.47104\n",
      "evaluation/Rewards Std                  0.589773\n",
      "evaluation/Rewards Max                  5.57503\n",
      "evaluation/Rewards Min                  0.691735\n",
      "evaluation/Returns Mean              3319.7\n",
      "evaluation/Returns Std                282.178\n",
      "evaluation/Returns Max               3493.44\n",
      "evaluation/Returns Min               2755.29\n",
      "evaluation/Estimation Bias Mean       870.278\n",
      "evaluation/Estimation Bias Std        217.615\n",
      "evaluation/EB/Q_True Mean              33.3754\n",
      "evaluation/EB/Q_True Std              100.433\n",
      "evaluation/EB/Q_Pred Mean             903.653\n",
      "evaluation/EB/Q_Pred Std              173.217\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3319.7\n",
      "evaluation/Actions Mean                 0.039939\n",
      "evaluation/Actions Std                  0.572638\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.61915\n",
      "time/backward_zf1 (s)                   1.74597\n",
      "time/backward_zf2 (s)                   1.66839\n",
      "time/data sampling (s)                  0.212259\n",
      "time/data storing (s)                   0.013391\n",
      "time/evaluation sampling (s)            1.41375\n",
      "time/exploration sampling (s)           0.163389\n",
      "time/logging (s)                        0.0130105\n",
      "time/preback_alpha (s)                  0.539748\n",
      "time/preback_policy (s)                 0.581839\n",
      "time/preback_start (s)                  0.120564\n",
      "time/preback_zf (s)                     4.92184\n",
      "time/saving (s)                         0.00522298\n",
      "time/training (s)                       2.72969\n",
      "time/epoch (s)                         15.7482\n",
      "time/total (s)                       1249.76\n",
      "Epoch                                  81\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:22:15.621753 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 82 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  93000\n",
      "trainer/ZF1 Loss                       20.0033\n",
      "trainer/ZF2 Loss                       15.4442\n",
      "trainer/ZF Expert Reward               19.0445\n",
      "trainer/ZF Policy Reward                0.227829\n",
      "trainer/ZF CHI2 Term                   49.3049\n",
      "trainer/Policy Loss                  -708.393\n",
      "trainer/Policy Grad Norm              246.264\n",
      "trainer/Policy Param Norm              33.6287\n",
      "trainer/Zf1 Grad Norm                4603.92\n",
      "trainer/Zf1 Param Norm                 81.8148\n",
      "trainer/Zf2 Grad Norm                4046\n",
      "trainer/Zf2 Param Norm                 80.3697\n",
      "trainer/Z Expert Predictions Mean     939.04\n",
      "trainer/Z Expert Predictions Std      101.233\n",
      "trainer/Z Expert Predictions Max     1123.56\n",
      "trainer/Z Expert Predictions Min      602.964\n",
      "trainer/Z Policy Predictions Mean     687.588\n",
      "trainer/Z Policy Predictions Std      320.521\n",
      "trainer/Z Policy Predictions Max     1108.7\n",
      "trainer/Z Policy Predictions Min     -252.777\n",
      "trainer/Z Expert Targets Mean         919.995\n",
      "trainer/Z Expert Targets Std          103.87\n",
      "trainer/Z Expert Targets Max         1111.08\n",
      "trainer/Z Expert Targets Min          558.087\n",
      "trainer/Z Policy Targets Mean         687.36\n",
      "trainer/Z Policy Targets Std          318.609\n",
      "trainer/Z Policy Targets Max         1091\n",
      "trainer/Z Policy Targets Min         -263.359\n",
      "trainer/Log Pis Mean                   12.8934\n",
      "trainer/Log Pis Std                     5.37035\n",
      "trainer/Policy mu Mean                  0.357313\n",
      "trainer/Policy mu Std                   2.68759\n",
      "trainer/Policy log std Mean            -3.48485\n",
      "trainer/Policy log std Std              1.20538\n",
      "exploration/num steps total         88215\n",
      "exploration/num paths total           887\n",
      "evaluation/num steps total         497918\n",
      "evaluation/num paths total            834\n",
      "evaluation/path length Mean           629.333\n",
      "evaluation/path length Std            254.443\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            397\n",
      "evaluation/Rewards Mean                 3.42007\n",
      "evaluation/Rewards Std                  0.667652\n",
      "evaluation/Rewards Max                  5.6107\n",
      "evaluation/Rewards Min                  0.699163\n",
      "evaluation/Returns Mean              2152.36\n",
      "evaluation/Returns Std                917.963\n",
      "evaluation/Returns Max               3482.93\n",
      "evaluation/Returns Min               1305.29\n",
      "evaluation/Estimation Bias Mean       791.401\n",
      "evaluation/Estimation Bias Std        302.277\n",
      "evaluation/EB/Q_True Mean              42.5798\n",
      "evaluation/EB/Q_True Std              112.254\n",
      "evaluation/EB/Q_Pred Mean             833.981\n",
      "evaluation/EB/Q_Pred Std              280.545\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2152.36\n",
      "evaluation/Actions Mean                 0.039257\n",
      "evaluation/Actions Std                  0.573662\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71106\n",
      "time/backward_zf1 (s)                   1.82598\n",
      "time/backward_zf2 (s)                   1.75895\n",
      "time/data sampling (s)                  0.226675\n",
      "time/data storing (s)                   0.0134414\n",
      "time/evaluation sampling (s)            1.41824\n",
      "time/exploration sampling (s)           0.17102\n",
      "time/logging (s)                        0.00910651\n",
      "time/preback_alpha (s)                  0.536365\n",
      "time/preback_policy (s)                 0.59294\n",
      "time/preback_start (s)                  0.120592\n",
      "time/preback_zf (s)                     4.9141\n",
      "time/saving (s)                         0.00542548\n",
      "time/training (s)                       2.50803\n",
      "time/epoch (s)                         15.8119\n",
      "time/total (s)                       1265.59\n",
      "Epoch                                  82\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:22:31.435591 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 83 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  94000\n",
      "trainer/ZF1 Loss                       39.1958\n",
      "trainer/ZF2 Loss                       46.4461\n",
      "trainer/ZF Expert Reward               14.907\n",
      "trainer/ZF Policy Reward               -0.775013\n",
      "trainer/ZF CHI2 Term                   72.6689\n",
      "trainer/Policy Loss                  -673.93\n",
      "trainer/Policy Grad Norm              302.736\n",
      "trainer/Policy Param Norm              33.6973\n",
      "trainer/Zf1 Grad Norm                5892.38\n",
      "trainer/Zf1 Param Norm                 82.1435\n",
      "trainer/Zf2 Grad Norm                6305.02\n",
      "trainer/Zf2 Param Norm                 80.6779\n",
      "trainer/Z Expert Predictions Mean     936.33\n",
      "trainer/Z Expert Predictions Std      109.439\n",
      "trainer/Z Expert Predictions Max     1140.67\n",
      "trainer/Z Expert Predictions Min      430.226\n",
      "trainer/Z Policy Predictions Mean     659.407\n",
      "trainer/Z Policy Predictions Std      357.881\n",
      "trainer/Z Policy Predictions Max     1085.66\n",
      "trainer/Z Policy Predictions Min     -341.264\n",
      "trainer/Z Expert Targets Mean         921.423\n",
      "trainer/Z Expert Targets Std          112.218\n",
      "trainer/Z Expert Targets Max         1124.81\n",
      "trainer/Z Expert Targets Min          355.875\n",
      "trainer/Z Policy Targets Mean         660.182\n",
      "trainer/Z Policy Targets Std          357.043\n",
      "trainer/Z Policy Targets Max         1089.29\n",
      "trainer/Z Policy Targets Min         -326.201\n",
      "trainer/Log Pis Mean                   14.309\n",
      "trainer/Log Pis Std                     6.49584\n",
      "trainer/Policy mu Mean                  0.183653\n",
      "trainer/Policy mu Std                   2.83518\n",
      "trainer/Policy log std Mean            -3.54487\n",
      "trainer/Policy log std Std              1.23848\n",
      "exploration/num steps total         88215\n",
      "exploration/num paths total           887\n",
      "evaluation/num steps total         507918\n",
      "evaluation/num paths total            844\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48398\n",
      "evaluation/Rewards Std                  0.571128\n",
      "evaluation/Rewards Max                  4.55996\n",
      "evaluation/Rewards Min                  0.680437\n",
      "evaluation/Returns Mean              3483.98\n",
      "evaluation/Returns Std                 18.7635\n",
      "evaluation/Returns Max               3510.27\n",
      "evaluation/Returns Min               3459.49\n",
      "evaluation/Estimation Bias Mean       902.572\n",
      "evaluation/Estimation Bias Std        155.458\n",
      "evaluation/EB/Q_True Mean              32.1492\n",
      "evaluation/EB/Q_True Std               99.114\n",
      "evaluation/EB/Q_Pred Mean             934.721\n",
      "evaluation/EB/Q_Pred Std              125.245\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3483.98\n",
      "evaluation/Actions Mean                 0.0225138\n",
      "evaluation/Actions Std                  0.570343\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.61966\n",
      "time/backward_zf1 (s)                   1.75418\n",
      "time/backward_zf2 (s)                   1.66979\n",
      "time/data sampling (s)                  0.23883\n",
      "time/data storing (s)                   0.013967\n",
      "time/evaluation sampling (s)            1.37478\n",
      "time/exploration sampling (s)           0.166124\n",
      "time/logging (s)                        0.0121069\n",
      "time/preback_alpha (s)                  0.542076\n",
      "time/preback_policy (s)                 0.583935\n",
      "time/preback_start (s)                  0.121049\n",
      "time/preback_zf (s)                     4.93074\n",
      "time/saving (s)                         0.00534458\n",
      "time/training (s)                       2.72364\n",
      "time/epoch (s)                         15.7562\n",
      "time/total (s)                       1281.36\n",
      "Epoch                                  83\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:22:47.286064 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 84 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  95000\n",
      "trainer/ZF1 Loss                       36.7011\n",
      "trainer/ZF2 Loss                       40.0886\n",
      "trainer/ZF Expert Reward               13.3021\n",
      "trainer/ZF Policy Reward               -2.84739\n",
      "trainer/ZF CHI2 Term                   67.6494\n",
      "trainer/Policy Loss                  -708.345\n",
      "trainer/Policy Grad Norm              226.386\n",
      "trainer/Policy Param Norm              33.7735\n",
      "trainer/Zf1 Grad Norm                4091.23\n",
      "trainer/Zf1 Param Norm                 82.4743\n",
      "trainer/Zf2 Grad Norm                8220.83\n",
      "trainer/Zf2 Param Norm                 80.988\n",
      "trainer/Z Expert Predictions Mean     946.543\n",
      "trainer/Z Expert Predictions Std      110.418\n",
      "trainer/Z Expert Predictions Max     1156.76\n",
      "trainer/Z Expert Predictions Min      483.522\n",
      "trainer/Z Policy Predictions Mean     690.753\n",
      "trainer/Z Policy Predictions Std      327.802\n",
      "trainer/Z Policy Predictions Max     1108.13\n",
      "trainer/Z Policy Predictions Min     -340.999\n",
      "trainer/Z Expert Targets Mean         933.241\n",
      "trainer/Z Expert Targets Std          109.637\n",
      "trainer/Z Expert Targets Max         1141.18\n",
      "trainer/Z Expert Targets Min          423.037\n",
      "trainer/Z Policy Targets Mean         693.6\n",
      "trainer/Z Policy Targets Std          324.875\n",
      "trainer/Z Policy Targets Max         1105.64\n",
      "trainer/Z Policy Targets Min         -408.079\n",
      "trainer/Log Pis Mean                   13.2375\n",
      "trainer/Log Pis Std                     5.75667\n",
      "trainer/Policy mu Mean                  0.487319\n",
      "trainer/Policy mu Std                   2.86797\n",
      "trainer/Policy log std Mean            -3.52129\n",
      "trainer/Policy log std Std              1.19253\n",
      "exploration/num steps total         91215\n",
      "exploration/num paths total           890\n",
      "evaluation/num steps total         517492\n",
      "evaluation/num paths total            854\n",
      "evaluation/path length Mean           957.4\n",
      "evaluation/path length Std            111.549\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            626\n",
      "evaluation/Rewards Mean                 3.519\n",
      "evaluation/Rewards Std                  0.594445\n",
      "evaluation/Rewards Max                  5.62401\n",
      "evaluation/Rewards Min                  0.66648\n",
      "evaluation/Returns Mean              3369.09\n",
      "evaluation/Returns Std                389.309\n",
      "evaluation/Returns Max               3556.74\n",
      "evaluation/Returns Min               2210.93\n",
      "evaluation/Estimation Bias Mean       876.163\n",
      "evaluation/Estimation Bias Std        232.206\n",
      "evaluation/EB/Q_True Mean              33.6442\n",
      "evaluation/EB/Q_True Std              101.104\n",
      "evaluation/EB/Q_Pred Mean             909.807\n",
      "evaluation/EB/Q_Pred Std              190.698\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3369.09\n",
      "evaluation/Actions Mean                 0.0264272\n",
      "evaluation/Actions Std                  0.573365\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77377\n",
      "time/backward_zf1 (s)                   1.86787\n",
      "time/backward_zf2 (s)                   1.81851\n",
      "time/data sampling (s)                  0.235784\n",
      "time/data storing (s)                   0.013571\n",
      "time/evaluation sampling (s)            1.35218\n",
      "time/exploration sampling (s)           0.168935\n",
      "time/logging (s)                        0.0124386\n",
      "time/preback_alpha (s)                  0.53659\n",
      "time/preback_policy (s)                 0.601751\n",
      "time/preback_start (s)                  0.120417\n",
      "time/preback_zf (s)                     4.91733\n",
      "time/saving (s)                         0.00511318\n",
      "time/training (s)                       2.36474\n",
      "time/epoch (s)                         15.789\n",
      "time/total (s)                       1297.17\n",
      "Epoch                                  84\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:23:03.195924 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 85 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  96000\n",
      "trainer/ZF1 Loss                      116.766\n",
      "trainer/ZF2 Loss                      127.517\n",
      "trainer/ZF Expert Reward               18.291\n",
      "trainer/ZF Policy Reward               -0.348648\n",
      "trainer/ZF CHI2 Term                  154.921\n",
      "trainer/Policy Loss                  -705.036\n",
      "trainer/Policy Grad Norm              336.061\n",
      "trainer/Policy Param Norm              33.8565\n",
      "trainer/Zf1 Grad Norm                8945.39\n",
      "trainer/Zf1 Param Norm                 82.7967\n",
      "trainer/Zf2 Grad Norm               11227.1\n",
      "trainer/Zf2 Param Norm                 81.2868\n",
      "trainer/Z Expert Predictions Mean     954.598\n",
      "trainer/Z Expert Predictions Std      107.411\n",
      "trainer/Z Expert Predictions Max     1162.71\n",
      "trainer/Z Expert Predictions Min      580.769\n",
      "trainer/Z Policy Predictions Mean     690.987\n",
      "trainer/Z Policy Predictions Std      337.825\n",
      "trainer/Z Policy Predictions Max     1123.18\n",
      "trainer/Z Policy Predictions Min     -359.235\n",
      "trainer/Z Expert Targets Mean         936.308\n",
      "trainer/Z Expert Targets Std          123.621\n",
      "trainer/Z Expert Targets Max         1147.31\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         691.336\n",
      "trainer/Z Policy Targets Std          336.655\n",
      "trainer/Z Policy Targets Max         1114.42\n",
      "trainer/Z Policy Targets Min         -359.935\n",
      "trainer/Log Pis Mean                   14.2827\n",
      "trainer/Log Pis Std                     5.80322\n",
      "trainer/Policy mu Mean                  0.404357\n",
      "trainer/Policy mu Std                   2.90293\n",
      "trainer/Policy log std Mean            -3.58864\n",
      "trainer/Policy log std Std              1.21596\n",
      "exploration/num steps total         92215\n",
      "exploration/num paths total           891\n",
      "evaluation/num steps total         527492\n",
      "evaluation/num paths total            864\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48647\n",
      "evaluation/Rewards Std                  0.570518\n",
      "evaluation/Rewards Max                  4.5773\n",
      "evaluation/Rewards Min                  0.662469\n",
      "evaluation/Returns Mean              3486.47\n",
      "evaluation/Returns Std                 20.2768\n",
      "evaluation/Returns Max               3507.98\n",
      "evaluation/Returns Min               3453.13\n",
      "evaluation/Estimation Bias Mean       925.027\n",
      "evaluation/Estimation Bias Std        138.029\n",
      "evaluation/EB/Q_True Mean              32.338\n",
      "evaluation/EB/Q_True Std               99.6602\n",
      "evaluation/EB/Q_Pred Mean             957.365\n",
      "evaluation/EB/Q_Pred Std               91.6157\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3486.47\n",
      "evaluation/Actions Mean                 0.0264581\n",
      "evaluation/Actions Std                  0.579922\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.66505\n",
      "time/backward_zf1 (s)                   1.78528\n",
      "time/backward_zf2 (s)                   1.7066\n",
      "time/data sampling (s)                  0.238924\n",
      "time/data storing (s)                   0.0139749\n",
      "time/evaluation sampling (s)            1.37878\n",
      "time/exploration sampling (s)           0.170483\n",
      "time/logging (s)                        0.011771\n",
      "time/preback_alpha (s)                  0.544875\n",
      "time/preback_policy (s)                 0.597298\n",
      "time/preback_start (s)                  0.12112\n",
      "time/preback_zf (s)                     4.95225\n",
      "time/saving (s)                         0.00530775\n",
      "time/training (s)                       2.65753\n",
      "time/epoch (s)                         15.8493\n",
      "time/total (s)                       1313.04\n",
      "Epoch                                  85\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:23:19.033324 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 86 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  97000\n",
      "trainer/ZF1 Loss                       22.8005\n",
      "trainer/ZF2 Loss                       22.9556\n",
      "trainer/ZF Expert Reward               19.7744\n",
      "trainer/ZF Policy Reward                1.15716\n",
      "trainer/ZF CHI2 Term                   55.6598\n",
      "trainer/Policy Loss                  -690.472\n",
      "trainer/Policy Grad Norm              279.509\n",
      "trainer/Policy Param Norm              33.944\n",
      "trainer/Zf1 Grad Norm                4029.93\n",
      "trainer/Zf1 Param Norm                 83.1427\n",
      "trainer/Zf2 Grad Norm                5754.06\n",
      "trainer/Zf2 Param Norm                 81.607\n",
      "trainer/Z Expert Predictions Mean     952.101\n",
      "trainer/Z Expert Predictions Std      126.705\n",
      "trainer/Z Expert Predictions Max     1171.94\n",
      "trainer/Z Expert Predictions Min      446.61\n",
      "trainer/Z Policy Predictions Mean     681.459\n",
      "trainer/Z Policy Predictions Std      347.863\n",
      "trainer/Z Policy Predictions Max     1123.01\n",
      "trainer/Z Policy Predictions Min     -414.914\n",
      "trainer/Z Expert Targets Mean         932.326\n",
      "trainer/Z Expert Targets Std          129.958\n",
      "trainer/Z Expert Targets Max         1156.84\n",
      "trainer/Z Expert Targets Min          396\n",
      "trainer/Z Policy Targets Mean         680.302\n",
      "trainer/Z Policy Targets Std          346.167\n",
      "trainer/Z Policy Targets Max         1105.38\n",
      "trainer/Z Policy Targets Min         -472.601\n",
      "trainer/Log Pis Mean                   14.3076\n",
      "trainer/Log Pis Std                     6.55101\n",
      "trainer/Policy mu Mean                  0.403648\n",
      "trainer/Policy mu Std                   3.15331\n",
      "trainer/Policy log std Mean            -3.45136\n",
      "trainer/Policy log std Std              1.21468\n",
      "exploration/num steps total         93215\n",
      "exploration/num paths total           892\n",
      "evaluation/num steps total         533340\n",
      "evaluation/num paths total            875\n",
      "evaluation/path length Mean           531.636\n",
      "evaluation/path length Std            138.616\n",
      "evaluation/path length Max            948\n",
      "evaluation/path length Min            469\n",
      "evaluation/Rewards Mean                 3.56983\n",
      "evaluation/Rewards Std                  0.800312\n",
      "evaluation/Rewards Max                  5.68476\n",
      "evaluation/Rewards Min                  0.660174\n",
      "evaluation/Returns Mean              1897.85\n",
      "evaluation/Returns Std                514.097\n",
      "evaluation/Returns Max               3439.7\n",
      "evaluation/Returns Min               1674.45\n",
      "evaluation/Estimation Bias Mean       699.98\n",
      "evaluation/Estimation Bias Std        404.538\n",
      "evaluation/EB/Q_True Mean              54.2867\n",
      "evaluation/EB/Q_True Std              126.288\n",
      "evaluation/EB/Q_Pred Mean             754.267\n",
      "evaluation/EB/Q_Pred Std              386.27\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           1897.85\n",
      "evaluation/Actions Mean                 0.0303817\n",
      "evaluation/Actions Std                  0.601694\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.64777\n",
      "time/backward_zf1 (s)                   1.77717\n",
      "time/backward_zf2 (s)                   1.70452\n",
      "time/data sampling (s)                  0.243932\n",
      "time/data storing (s)                   0.0134207\n",
      "time/evaluation sampling (s)            1.38669\n",
      "time/exploration sampling (s)           0.165272\n",
      "time/logging (s)                        0.00732129\n",
      "time/preback_alpha (s)                  0.540871\n",
      "time/preback_policy (s)                 0.588137\n",
      "time/preback_start (s)                  0.120955\n",
      "time/preback_zf (s)                     4.92518\n",
      "time/saving (s)                         0.00576292\n",
      "time/training (s)                       2.64555\n",
      "time/epoch (s)                         15.7725\n",
      "time/total (s)                       1328.83\n",
      "Epoch                                  86\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:23:34.942051 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 87 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  98000\n",
      "trainer/ZF1 Loss                       76.4801\n",
      "trainer/ZF2 Loss                       71.5617\n",
      "trainer/ZF Expert Reward               17.2986\n",
      "trainer/ZF Policy Reward                2.52946\n",
      "trainer/ZF CHI2 Term                  102.192\n",
      "trainer/Policy Loss                  -734.091\n",
      "trainer/Policy Grad Norm              363.999\n",
      "trainer/Policy Param Norm              34.0213\n",
      "trainer/Zf1 Grad Norm                6631.5\n",
      "trainer/Zf1 Param Norm                 83.4612\n",
      "trainer/Zf2 Grad Norm               10716.5\n",
      "trainer/Zf2 Param Norm                 81.8909\n",
      "trainer/Z Expert Predictions Mean     960.28\n",
      "trainer/Z Expert Predictions Std      111.209\n",
      "trainer/Z Expert Predictions Max     1175.24\n",
      "trainer/Z Expert Predictions Min      494.645\n",
      "trainer/Z Policy Predictions Mean     723.492\n",
      "trainer/Z Policy Predictions Std      288.89\n",
      "trainer/Z Policy Predictions Max     1123.52\n",
      "trainer/Z Policy Predictions Min     -281.604\n",
      "trainer/Z Expert Targets Mean         942.981\n",
      "trainer/Z Expert Targets Std          112.385\n",
      "trainer/Z Expert Targets Max         1156.41\n",
      "trainer/Z Expert Targets Min          454.225\n",
      "trainer/Z Policy Targets Mean         720.962\n",
      "trainer/Z Policy Targets Std          287.587\n",
      "trainer/Z Policy Targets Max         1115.96\n",
      "trainer/Z Policy Targets Min         -255.08\n",
      "trainer/Log Pis Mean                   13.537\n",
      "trainer/Log Pis Std                     6.26477\n",
      "trainer/Policy mu Mean                  0.351992\n",
      "trainer/Policy mu Std                   2.75031\n",
      "trainer/Policy log std Mean            -3.62793\n",
      "trainer/Policy log std Std              1.18444\n",
      "exploration/num steps total         93215\n",
      "exploration/num paths total           892\n",
      "evaluation/num steps total         541168\n",
      "evaluation/num paths total            887\n",
      "evaluation/path length Mean           652.333\n",
      "evaluation/path length Std            235.042\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            467\n",
      "evaluation/Rewards Mean                 3.56691\n",
      "evaluation/Rewards Std                  0.702901\n",
      "evaluation/Rewards Max                  5.82382\n",
      "evaluation/Rewards Min                  0.658812\n",
      "evaluation/Returns Mean              2326.81\n",
      "evaluation/Returns Std                851.815\n",
      "evaluation/Returns Max               3589.14\n",
      "evaluation/Returns Min               1677.28\n",
      "evaluation/Estimation Bias Mean       791.5\n",
      "evaluation/Estimation Bias Std        341.895\n",
      "evaluation/EB/Q_True Mean              42.4252\n",
      "evaluation/EB/Q_True Std              113.962\n",
      "evaluation/EB/Q_Pred Mean             833.926\n",
      "evaluation/EB/Q_Pred Std              312.605\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2326.81\n",
      "evaluation/Actions Mean                 0.0274215\n",
      "evaluation/Actions Std                  0.585899\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84699\n",
      "time/backward_zf1 (s)                   1.93351\n",
      "time/backward_zf2 (s)                   1.90842\n",
      "time/data sampling (s)                  0.222731\n",
      "time/data storing (s)                   0.0134073\n",
      "time/evaluation sampling (s)            1.38367\n",
      "time/exploration sampling (s)           0.164054\n",
      "time/logging (s)                        0.00935591\n",
      "time/preback_alpha (s)                  0.5379\n",
      "time/preback_policy (s)                 0.618179\n",
      "time/preback_start (s)                  0.118061\n",
      "time/preback_zf (s)                     4.91455\n",
      "time/saving (s)                         0.00550122\n",
      "time/training (s)                       2.16591\n",
      "time/epoch (s)                         15.8422\n",
      "time/total (s)                       1344.69\n",
      "Epoch                                  87\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:23:50.867649 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 88 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  99000\n",
      "trainer/ZF1 Loss                       19.7581\n",
      "trainer/ZF2 Loss                       23.1382\n",
      "trainer/ZF Expert Reward               17.7565\n",
      "trainer/ZF Policy Reward               -0.343801\n",
      "trainer/ZF CHI2 Term                   52.9064\n",
      "trainer/Policy Loss                  -714.261\n",
      "trainer/Policy Grad Norm              448.263\n",
      "trainer/Policy Param Norm              34.1024\n",
      "trainer/Zf1 Grad Norm                9903.96\n",
      "trainer/Zf1 Param Norm                 83.8078\n",
      "trainer/Zf2 Grad Norm                5179.77\n",
      "trainer/Zf2 Param Norm                 82.2162\n",
      "trainer/Z Expert Predictions Mean     972.429\n",
      "trainer/Z Expert Predictions Std      108.177\n",
      "trainer/Z Expert Predictions Max     1197.24\n",
      "trainer/Z Expert Predictions Min      496.374\n",
      "trainer/Z Policy Predictions Mean     704.489\n",
      "trainer/Z Policy Predictions Std      330.404\n",
      "trainer/Z Policy Predictions Max     1147.38\n",
      "trainer/Z Policy Predictions Min     -241.35\n",
      "trainer/Z Expert Targets Mean         954.672\n",
      "trainer/Z Expert Targets Std          110.277\n",
      "trainer/Z Expert Targets Max         1176.79\n",
      "trainer/Z Expert Targets Min          474.698\n",
      "trainer/Z Policy Targets Mean         704.832\n",
      "trainer/Z Policy Targets Std          328.981\n",
      "trainer/Z Policy Targets Max         1123.45\n",
      "trainer/Z Policy Targets Min         -227.433\n",
      "trainer/Log Pis Mean                   13.4929\n",
      "trainer/Log Pis Std                     5.86146\n",
      "trainer/Policy mu Mean                  0.508039\n",
      "trainer/Policy mu Std                   2.97659\n",
      "trainer/Policy log std Mean            -3.51124\n",
      "trainer/Policy log std Std              1.19437\n",
      "exploration/num steps total         94215\n",
      "exploration/num paths total           893\n",
      "evaluation/num steps total         551168\n",
      "evaluation/num paths total            897\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.49236\n",
      "evaluation/Rewards Std                  0.58086\n",
      "evaluation/Rewards Max                  4.55821\n",
      "evaluation/Rewards Min                  0.658741\n",
      "evaluation/Returns Mean              3492.36\n",
      "evaluation/Returns Std                 19.0201\n",
      "evaluation/Returns Max               3512.14\n",
      "evaluation/Returns Min               3460.75\n",
      "evaluation/Estimation Bias Mean       928.025\n",
      "evaluation/Estimation Bias Std        137.392\n",
      "evaluation/EB/Q_True Mean              32.5023\n",
      "evaluation/EB/Q_True Std              100.191\n",
      "evaluation/EB/Q_Pred Mean             960.527\n",
      "evaluation/EB/Q_Pred Std               94.952\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3492.36\n",
      "evaluation/Actions Mean                 0.0286182\n",
      "evaluation/Actions Std                  0.57187\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.80365\n",
      "time/backward_zf1 (s)                   1.90995\n",
      "time/backward_zf2 (s)                   1.87318\n",
      "time/data sampling (s)                  0.237938\n",
      "time/data storing (s)                   0.0136753\n",
      "time/evaluation sampling (s)            1.39411\n",
      "time/exploration sampling (s)           0.168654\n",
      "time/logging (s)                        0.0134442\n",
      "time/preback_alpha (s)                  0.54305\n",
      "time/preback_policy (s)                 0.615169\n",
      "time/preback_start (s)                  0.120761\n",
      "time/preback_zf (s)                     4.93544\n",
      "time/saving (s)                         0.0054674\n",
      "time/training (s)                       2.23329\n",
      "time/epoch (s)                         15.8678\n",
      "time/total (s)                       1360.58\n",
      "Epoch                                  88\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:24:06.808146 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 89 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 100000\n",
      "trainer/ZF1 Loss                       46.5459\n",
      "trainer/ZF2 Loss                       51.8095\n",
      "trainer/ZF Expert Reward                6.58723\n",
      "trainer/ZF Policy Reward               -7.74229\n",
      "trainer/ZF CHI2 Term                   77.3016\n",
      "trainer/Policy Loss                  -712.235\n",
      "trainer/Policy Grad Norm              367.83\n",
      "trainer/Policy Param Norm              34.1943\n",
      "trainer/Zf1 Grad Norm                8102.56\n",
      "trainer/Zf1 Param Norm                 84.1591\n",
      "trainer/Zf2 Grad Norm               10849.7\n",
      "trainer/Zf2 Param Norm                 82.5455\n",
      "trainer/Z Expert Predictions Mean     953.609\n",
      "trainer/Z Expert Predictions Std      124.481\n",
      "trainer/Z Expert Predictions Max     1173\n",
      "trainer/Z Expert Predictions Min      481.897\n",
      "trainer/Z Policy Predictions Mean     698.114\n",
      "trainer/Z Policy Predictions Std      322.81\n",
      "trainer/Z Policy Predictions Max     1104.36\n",
      "trainer/Z Policy Predictions Min     -382.579\n",
      "trainer/Z Expert Targets Mean         947.022\n",
      "trainer/Z Expert Targets Std          127.59\n",
      "trainer/Z Expert Targets Max         1158.48\n",
      "trainer/Z Expert Targets Min          455.839\n",
      "trainer/Z Policy Targets Mean         705.856\n",
      "trainer/Z Policy Targets Std          325.251\n",
      "trainer/Z Policy Targets Max         1113.51\n",
      "trainer/Z Policy Targets Min         -369.313\n",
      "trainer/Log Pis Mean                   13.9338\n",
      "trainer/Log Pis Std                     5.86615\n",
      "trainer/Policy mu Mean                  0.420946\n",
      "trainer/Policy mu Std                   2.794\n",
      "trainer/Policy log std Mean            -3.56556\n",
      "trainer/Policy log std Std              1.1904\n",
      "exploration/num steps total         94215\n",
      "exploration/num paths total           893\n",
      "evaluation/num steps total         561168\n",
      "evaluation/num paths total            907\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51379\n",
      "evaluation/Rewards Std                  0.587071\n",
      "evaluation/Rewards Max                  4.60938\n",
      "evaluation/Rewards Min                  0.663679\n",
      "evaluation/Returns Mean              3513.79\n",
      "evaluation/Returns Std                  7.19658\n",
      "evaluation/Returns Max               3522.17\n",
      "evaluation/Returns Min               3495.8\n",
      "evaluation/Estimation Bias Mean       968.914\n",
      "evaluation/Estimation Bias Std        135.987\n",
      "evaluation/EB/Q_True Mean              32.5271\n",
      "evaluation/EB/Q_True Std              100.248\n",
      "evaluation/EB/Q_Pred Mean            1001.44\n",
      "evaluation/EB/Q_Pred Std               92.8018\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3513.79\n",
      "evaluation/Actions Mean                 0.00975066\n",
      "evaluation/Actions Std                  0.587048\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.82237\n",
      "time/backward_zf1 (s)                   1.91949\n",
      "time/backward_zf2 (s)                   1.87177\n",
      "time/data sampling (s)                  0.239289\n",
      "time/data storing (s)                   0.0134698\n",
      "time/evaluation sampling (s)            1.44566\n",
      "time/exploration sampling (s)           0.165254\n",
      "time/logging (s)                        0.0114096\n",
      "time/preback_alpha (s)                  0.539378\n",
      "time/preback_policy (s)                 0.616811\n",
      "time/preback_start (s)                  0.118981\n",
      "time/preback_zf (s)                     4.91125\n",
      "time/saving (s)                         0.00529255\n",
      "time/training (s)                       2.19155\n",
      "time/epoch (s)                         15.872\n",
      "time/total (s)                       1376.48\n",
      "Epoch                                  89\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:24:21.865363 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 90 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 101000\n",
      "trainer/ZF1 Loss                       20.362\n",
      "trainer/ZF2 Loss                       27.6485\n",
      "trainer/ZF Expert Reward               12.4383\n",
      "trainer/ZF Policy Reward               -5.25051\n",
      "trainer/ZF CHI2 Term                   55.9675\n",
      "trainer/Policy Loss                  -711.015\n",
      "trainer/Policy Grad Norm              376.583\n",
      "trainer/Policy Param Norm              34.2874\n",
      "trainer/Zf1 Grad Norm                8028.16\n",
      "trainer/Zf1 Param Norm                 84.5006\n",
      "trainer/Zf2 Grad Norm                6181.53\n",
      "trainer/Zf2 Param Norm                 82.8526\n",
      "trainer/Z Expert Predictions Mean     972.316\n",
      "trainer/Z Expert Predictions Std      112.854\n",
      "trainer/Z Expert Predictions Max     1175.13\n",
      "trainer/Z Expert Predictions Min      454.594\n",
      "trainer/Z Policy Predictions Mean     694.405\n",
      "trainer/Z Policy Predictions Std      352.608\n",
      "trainer/Z Policy Predictions Max     1182.78\n",
      "trainer/Z Policy Predictions Min     -403.908\n",
      "trainer/Z Expert Targets Mean         959.878\n",
      "trainer/Z Expert Targets Std          115.616\n",
      "trainer/Z Expert Targets Max         1182.65\n",
      "trainer/Z Expert Targets Min          451.38\n",
      "trainer/Z Policy Targets Mean         699.656\n",
      "trainer/Z Policy Targets Std          346.588\n",
      "trainer/Z Policy Targets Max         1174.34\n",
      "trainer/Z Policy Targets Min         -419.082\n",
      "trainer/Log Pis Mean                   14.4177\n",
      "trainer/Log Pis Std                     6.38155\n",
      "trainer/Policy mu Mean                  0.401959\n",
      "trainer/Policy mu Std                   3.04675\n",
      "trainer/Policy log std Mean            -3.58682\n",
      "trainer/Policy log std Std              1.31196\n",
      "exploration/num steps total         95215\n",
      "exploration/num paths total           894\n",
      "evaluation/num steps total         564636\n",
      "evaluation/num paths total            917\n",
      "evaluation/path length Mean           346.8\n",
      "evaluation/path length Std             29.1884\n",
      "evaluation/path length Max            392\n",
      "evaluation/path length Min            326\n",
      "evaluation/Rewards Mean                 3.40587\n",
      "evaluation/Rewards Std                  0.899117\n",
      "evaluation/Rewards Max                  5.69971\n",
      "evaluation/Rewards Min                  0.666518\n",
      "evaluation/Returns Mean              1181.15\n",
      "evaluation/Returns Std                125.604\n",
      "evaluation/Returns Max               1377.06\n",
      "evaluation/Returns Min               1094.67\n",
      "evaluation/Estimation Bias Mean       691.631\n",
      "evaluation/Estimation Bias Std        383.596\n",
      "evaluation/EB/Q_True Mean              32.2782\n",
      "evaluation/EB/Q_True Std               94.4629\n",
      "evaluation/EB/Q_Pred Mean             723.91\n",
      "evaluation/EB/Q_Pred Std              376.831\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1181.15\n",
      "evaluation/Actions Mean                 0.0110069\n",
      "evaluation/Actions Std                  0.605024\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71063\n",
      "time/backward_zf1 (s)                   1.82471\n",
      "time/backward_zf2 (s)                   1.77441\n",
      "time/data sampling (s)                  0.242889\n",
      "time/data storing (s)                   0.0138581\n",
      "time/evaluation sampling (s)            0.571882\n",
      "time/exploration sampling (s)           0.169545\n",
      "time/logging (s)                        0.00471618\n",
      "time/preback_alpha (s)                  0.542708\n",
      "time/preback_policy (s)                 0.602341\n",
      "time/preback_start (s)                  0.121568\n",
      "time/preback_zf (s)                     4.93185\n",
      "time/saving (s)                         0.00499093\n",
      "time/training (s)                       2.47322\n",
      "time/epoch (s)                         14.9893\n",
      "time/total (s)                       1391.48\n",
      "Epoch                                  90\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:24:37.580674 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 91 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 102000\n",
      "trainer/ZF1 Loss                       13.4062\n",
      "trainer/ZF2 Loss                       21.7323\n",
      "trainer/ZF Expert Reward               16.6537\n",
      "trainer/ZF Policy Reward               -1.49746\n",
      "trainer/ZF CHI2 Term                   49.4607\n",
      "trainer/Policy Loss                  -736.654\n",
      "trainer/Policy Grad Norm              258.518\n",
      "trainer/Policy Param Norm              34.3773\n",
      "trainer/Zf1 Grad Norm                5668.49\n",
      "trainer/Zf1 Param Norm                 84.855\n",
      "trainer/Zf2 Grad Norm               13009.4\n",
      "trainer/Zf2 Param Norm                 83.1788\n",
      "trainer/Z Expert Predictions Mean     982.885\n",
      "trainer/Z Expert Predictions Std      112.977\n",
      "trainer/Z Expert Predictions Max     1214.68\n",
      "trainer/Z Expert Predictions Min      393.515\n",
      "trainer/Z Policy Predictions Mean     722.314\n",
      "trainer/Z Policy Predictions Std      330.26\n",
      "trainer/Z Policy Predictions Max     1160.54\n",
      "trainer/Z Policy Predictions Min     -392.971\n",
      "trainer/Z Expert Targets Mean         966.231\n",
      "trainer/Z Expert Targets Std          114.199\n",
      "trainer/Z Expert Targets Max         1190.08\n",
      "trainer/Z Expert Targets Min          365.226\n",
      "trainer/Z Policy Targets Mean         723.812\n",
      "trainer/Z Policy Targets Std          327.227\n",
      "trainer/Z Policy Targets Max         1145.58\n",
      "trainer/Z Policy Targets Min         -379.064\n",
      "trainer/Log Pis Mean                   13.879\n",
      "trainer/Log Pis Std                     5.72623\n",
      "trainer/Policy mu Mean                  0.678222\n",
      "trainer/Policy mu Std                   2.95913\n",
      "trainer/Policy log std Mean            -3.51785\n",
      "trainer/Policy log std Std              1.2662\n",
      "exploration/num steps total         95215\n",
      "exploration/num paths total           894\n",
      "evaluation/num steps total         574636\n",
      "evaluation/num paths total            927\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52725\n",
      "evaluation/Rewards Std                  0.607102\n",
      "evaluation/Rewards Max                  4.68901\n",
      "evaluation/Rewards Min                  0.665604\n",
      "evaluation/Returns Mean              3527.25\n",
      "evaluation/Returns Std                 10.2161\n",
      "evaluation/Returns Max               3540.08\n",
      "evaluation/Returns Min               3509.43\n",
      "evaluation/Estimation Bias Mean       962.653\n",
      "evaluation/Estimation Bias Std        145.062\n",
      "evaluation/EB/Q_True Mean              32.6926\n",
      "evaluation/EB/Q_True Std              100.73\n",
      "evaluation/EB/Q_Pred Mean             995.345\n",
      "evaluation/EB/Q_Pred Std               98.8133\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3527.25\n",
      "evaluation/Actions Mean                 0.0184067\n",
      "evaluation/Actions Std                  0.602988\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.58627\n",
      "time/backward_zf1 (s)                   1.72668\n",
      "time/backward_zf2 (s)                   1.63974\n",
      "time/data sampling (s)                  0.235194\n",
      "time/data storing (s)                   0.0134818\n",
      "time/evaluation sampling (s)            1.36799\n",
      "time/exploration sampling (s)           0.164049\n",
      "time/logging (s)                        0.0122087\n",
      "time/preback_alpha (s)                  0.538606\n",
      "time/preback_policy (s)                 0.579404\n",
      "time/preback_start (s)                  0.120161\n",
      "time/preback_zf (s)                     4.91168\n",
      "time/saving (s)                         0.00489719\n",
      "time/training (s)                       2.75903\n",
      "time/epoch (s)                         15.6594\n",
      "time/total (s)                       1407.16\n",
      "Epoch                                  91\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:24:53.362653 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 92 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 103000\n",
      "trainer/ZF1 Loss                      171.261\n",
      "trainer/ZF2 Loss                      190.73\n",
      "trainer/ZF Expert Reward                9.66231\n",
      "trainer/ZF Policy Reward                3.06133\n",
      "trainer/ZF CHI2 Term                  201.221\n",
      "trainer/Policy Loss                  -727.447\n",
      "trainer/Policy Grad Norm              438.968\n",
      "trainer/Policy Param Norm              34.4625\n",
      "trainer/Zf1 Grad Norm               12909.3\n",
      "trainer/Zf1 Param Norm                 85.2341\n",
      "trainer/Zf2 Grad Norm               20058\n",
      "trainer/Zf2 Param Norm                 83.5122\n",
      "trainer/Z Expert Predictions Mean     995.007\n",
      "trainer/Z Expert Predictions Std      108.117\n",
      "trainer/Z Expert Predictions Max     1179.42\n",
      "trainer/Z Expert Predictions Min      477.657\n",
      "trainer/Z Policy Predictions Mean     719.128\n",
      "trainer/Z Policy Predictions Std      330.858\n",
      "trainer/Z Policy Predictions Max     1130.52\n",
      "trainer/Z Policy Predictions Min     -338.037\n",
      "trainer/Z Expert Targets Mean         985.344\n",
      "trainer/Z Expert Targets Std          110.594\n",
      "trainer/Z Expert Targets Max         1202.29\n",
      "trainer/Z Expert Targets Min          449.763\n",
      "trainer/Z Policy Targets Mean         716.067\n",
      "trainer/Z Policy Targets Std          335.135\n",
      "trainer/Z Policy Targets Max         1098.73\n",
      "trainer/Z Policy Targets Min         -315.412\n",
      "trainer/Log Pis Mean                   13.7624\n",
      "trainer/Log Pis Std                     6.04998\n",
      "trainer/Policy mu Mean                  0.609023\n",
      "trainer/Policy mu Std                   2.76604\n",
      "trainer/Policy log std Mean            -3.58597\n",
      "trainer/Policy log std Std              1.14095\n",
      "exploration/num steps total         98175\n",
      "exploration/num paths total           897\n",
      "evaluation/num steps total         584636\n",
      "evaluation/num paths total            937\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50796\n",
      "evaluation/Rewards Std                  0.586515\n",
      "evaluation/Rewards Max                  4.64217\n",
      "evaluation/Rewards Min                  0.675305\n",
      "evaluation/Returns Mean              3507.96\n",
      "evaluation/Returns Std                 10.4585\n",
      "evaluation/Returns Max               3530.1\n",
      "evaluation/Returns Min               3493.39\n",
      "evaluation/Estimation Bias Mean       961.263\n",
      "evaluation/Estimation Bias Std        135.119\n",
      "evaluation/EB/Q_True Mean              32.4868\n",
      "evaluation/EB/Q_True Std              100.294\n",
      "evaluation/EB/Q_Pred Mean             993.75\n",
      "evaluation/EB/Q_Pred Std               92.1542\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3507.96\n",
      "evaluation/Actions Mean                 0.0218281\n",
      "evaluation/Actions Std                  0.589615\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.60861\n",
      "time/backward_zf1 (s)                   1.73303\n",
      "time/backward_zf2 (s)                   1.65716\n",
      "time/data sampling (s)                  0.232647\n",
      "time/data storing (s)                   0.0135238\n",
      "time/evaluation sampling (s)            1.37361\n",
      "time/exploration sampling (s)           0.173292\n",
      "time/logging (s)                        0.0125536\n",
      "time/preback_alpha (s)                  0.538234\n",
      "time/preback_policy (s)                 0.581942\n",
      "time/preback_start (s)                  0.123143\n",
      "time/preback_zf (s)                     4.92436\n",
      "time/saving (s)                         0.0224977\n",
      "time/training (s)                       2.72258\n",
      "time/epoch (s)                         15.7172\n",
      "time/total (s)                       1422.9\n",
      "Epoch                                  92\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:25:09.054069 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 93 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 104000\n",
      "trainer/ZF1 Loss                       34.0057\n",
      "trainer/ZF2 Loss                       47.4549\n",
      "trainer/ZF Expert Reward                6.71109\n",
      "trainer/ZF Policy Reward               -6.19692\n",
      "trainer/ZF CHI2 Term                   67.3186\n",
      "trainer/Policy Loss                  -725.797\n",
      "trainer/Policy Grad Norm              345.79\n",
      "trainer/Policy Param Norm              34.5436\n",
      "trainer/Zf1 Grad Norm               15304.8\n",
      "trainer/Zf1 Param Norm                 85.5928\n",
      "trainer/Zf2 Grad Norm               15006.4\n",
      "trainer/Zf2 Param Norm                 83.8437\n",
      "trainer/Z Expert Predictions Mean     995.612\n",
      "trainer/Z Expert Predictions Std      115.592\n",
      "trainer/Z Expert Predictions Max     1165.5\n",
      "trainer/Z Expert Predictions Min      460.479\n",
      "trainer/Z Policy Predictions Mean     710.797\n",
      "trainer/Z Policy Predictions Std      338.349\n",
      "trainer/Z Policy Predictions Max     1151.57\n",
      "trainer/Z Policy Predictions Min     -434.959\n",
      "trainer/Z Expert Targets Mean         988.901\n",
      "trainer/Z Expert Targets Std          115.003\n",
      "trainer/Z Expert Targets Max         1154.85\n",
      "trainer/Z Expert Targets Min          421.971\n",
      "trainer/Z Policy Targets Mean         716.994\n",
      "trainer/Z Policy Targets Std          334.193\n",
      "trainer/Z Policy Targets Max         1156.12\n",
      "trainer/Z Policy Targets Min         -417.722\n",
      "trainer/Log Pis Mean                   13.8185\n",
      "trainer/Log Pis Std                     5.67561\n",
      "trainer/Policy mu Mean                  0.365228\n",
      "trainer/Policy mu Std                   2.83064\n",
      "trainer/Policy log std Mean            -3.64839\n",
      "trainer/Policy log std Std              1.23037\n",
      "exploration/num steps total         98175\n",
      "exploration/num paths total           897\n",
      "evaluation/num steps total         589649\n",
      "evaluation/num paths total            949\n",
      "evaluation/path length Mean           417.75\n",
      "evaluation/path length Std             30.0448\n",
      "evaluation/path length Max            471\n",
      "evaluation/path length Min            397\n",
      "evaluation/Rewards Mean                 3.48336\n",
      "evaluation/Rewards Std                  0.83667\n",
      "evaluation/Rewards Max                  5.72247\n",
      "evaluation/Rewards Min                  0.665793\n",
      "evaluation/Returns Mean              1455.17\n",
      "evaluation/Returns Std                118.474\n",
      "evaluation/Returns Max               1663.35\n",
      "evaluation/Returns Min               1381.27\n",
      "evaluation/Estimation Bias Mean       703.052\n",
      "evaluation/Estimation Bias Std        406.581\n",
      "evaluation/EB/Q_True Mean              24.1941\n",
      "evaluation/EB/Q_True Std               81.2295\n",
      "evaluation/EB/Q_Pred Mean             727.246\n",
      "evaluation/EB/Q_Pred Std              403.716\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           1455.17\n",
      "evaluation/Actions Mean                 0.0090406\n",
      "evaluation/Actions Std                  0.606277\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73104\n",
      "time/backward_zf1 (s)                   1.83573\n",
      "time/backward_zf2 (s)                   1.77068\n",
      "time/data sampling (s)                  0.246689\n",
      "time/data storing (s)                   0.0140755\n",
      "time/evaluation sampling (s)            1.15192\n",
      "time/exploration sampling (s)           0.16636\n",
      "time/logging (s)                        0.00699994\n",
      "time/preback_alpha (s)                  0.540972\n",
      "time/preback_policy (s)                 0.600675\n",
      "time/preback_start (s)                  0.120396\n",
      "time/preback_zf (s)                     4.91825\n",
      "time/saving (s)                         0.00577439\n",
      "time/training (s)                       2.51265\n",
      "time/epoch (s)                         15.6222\n",
      "time/total (s)                       1438.55\n",
      "Epoch                                  93\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:25:24.795482 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 94 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 105000\n",
      "trainer/ZF1 Loss                       24.2951\n",
      "trainer/ZF2 Loss                       22.3146\n",
      "trainer/ZF Expert Reward               12.8936\n",
      "trainer/ZF Policy Reward               -0.958504\n",
      "trainer/ZF CHI2 Term                   50.0995\n",
      "trainer/Policy Loss                  -742.748\n",
      "trainer/Policy Grad Norm              400.566\n",
      "trainer/Policy Param Norm              34.632\n",
      "trainer/Zf1 Grad Norm                4746.83\n",
      "trainer/Zf1 Param Norm                 85.9884\n",
      "trainer/Zf2 Grad Norm                7230.45\n",
      "trainer/Zf2 Param Norm                 84.204\n",
      "trainer/Z Expert Predictions Mean     992.698\n",
      "trainer/Z Expert Predictions Std      128.209\n",
      "trainer/Z Expert Predictions Max     1177.56\n",
      "trainer/Z Expert Predictions Min      516.878\n",
      "trainer/Z Policy Predictions Mean     736.991\n",
      "trainer/Z Policy Predictions Std      351.421\n",
      "trainer/Z Policy Predictions Max     1139.93\n",
      "trainer/Z Policy Predictions Min     -391.593\n",
      "trainer/Z Expert Targets Mean         979.804\n",
      "trainer/Z Expert Targets Std          130.75\n",
      "trainer/Z Expert Targets Max         1184.07\n",
      "trainer/Z Expert Targets Min          479.432\n",
      "trainer/Z Policy Targets Mean         737.949\n",
      "trainer/Z Policy Targets Std          347.4\n",
      "trainer/Z Policy Targets Max         1140.1\n",
      "trainer/Z Policy Targets Min         -377.853\n",
      "trainer/Log Pis Mean                   13.0733\n",
      "trainer/Log Pis Std                     5.42094\n",
      "trainer/Policy mu Mean                  0.198554\n",
      "trainer/Policy mu Std                   2.65894\n",
      "trainer/Policy log std Mean            -3.62534\n",
      "trainer/Policy log std Std              1.11164\n",
      "exploration/num steps total        101175\n",
      "exploration/num paths total           900\n",
      "evaluation/num steps total         599649\n",
      "evaluation/num paths total            959\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52856\n",
      "evaluation/Rewards Std                  0.575284\n",
      "evaluation/Rewards Max                  4.63721\n",
      "evaluation/Rewards Min                  0.698163\n",
      "evaluation/Returns Mean              3528.56\n",
      "evaluation/Returns Std                  2.82671\n",
      "evaluation/Returns Max               3533.52\n",
      "evaluation/Returns Min               3523.36\n",
      "evaluation/Estimation Bias Mean       986.576\n",
      "evaluation/Estimation Bias Std        120.402\n",
      "evaluation/EB/Q_True Mean              32.6425\n",
      "evaluation/EB/Q_True Std              100.595\n",
      "evaluation/EB/Q_Pred Mean            1019.22\n",
      "evaluation/EB/Q_Pred Std               67.5108\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3528.56\n",
      "evaluation/Actions Mean                 0.0269854\n",
      "evaluation/Actions Std                  0.582106\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.58683\n",
      "time/backward_zf1 (s)                   1.71969\n",
      "time/backward_zf2 (s)                   1.64101\n",
      "time/data sampling (s)                  0.227769\n",
      "time/data storing (s)                   0.0135896\n",
      "time/evaluation sampling (s)            1.39545\n",
      "time/exploration sampling (s)           0.170964\n",
      "time/logging (s)                        0.0158516\n",
      "time/preback_alpha (s)                  0.53827\n",
      "time/preback_policy (s)                 0.572032\n",
      "time/preback_start (s)                  0.121761\n",
      "time/preback_zf (s)                     4.91854\n",
      "time/saving (s)                         0.0062884\n",
      "time/training (s)                       2.76147\n",
      "time/epoch (s)                         15.6895\n",
      "time/total (s)                       1454.25\n",
      "Epoch                                  94\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:25:40.810295 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 95 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 106000\n",
      "trainer/ZF1 Loss                       29.0761\n",
      "trainer/ZF2 Loss                       36.1408\n",
      "trainer/ZF Expert Reward               16.1078\n",
      "trainer/ZF Policy Reward                0.988331\n",
      "trainer/ZF CHI2 Term                   61.6867\n",
      "trainer/Policy Loss                  -755.645\n",
      "trainer/Policy Grad Norm              412.405\n",
      "trainer/Policy Param Norm              34.7175\n",
      "trainer/Zf1 Grad Norm                2962.36\n",
      "trainer/Zf1 Param Norm                 86.3615\n",
      "trainer/Zf2 Grad Norm                4191.26\n",
      "trainer/Zf2 Param Norm                 84.556\n",
      "trainer/Z Expert Predictions Mean    1025.22\n",
      "trainer/Z Expert Predictions Std      124.026\n",
      "trainer/Z Expert Predictions Max     1234.88\n",
      "trainer/Z Expert Predictions Min      464.739\n",
      "trainer/Z Policy Predictions Mean     740.236\n",
      "trainer/Z Policy Predictions Std      341.176\n",
      "trainer/Z Policy Predictions Max     1171.98\n",
      "trainer/Z Policy Predictions Min     -247.389\n",
      "trainer/Z Expert Targets Mean        1009.11\n",
      "trainer/Z Expert Targets Std          124.243\n",
      "trainer/Z Expert Targets Max         1226.08\n",
      "trainer/Z Expert Targets Min          470.542\n",
      "trainer/Z Policy Targets Mean         739.248\n",
      "trainer/Z Policy Targets Std          335.057\n",
      "trainer/Z Policy Targets Max         1168.77\n",
      "trainer/Z Policy Targets Min         -259.996\n",
      "trainer/Log Pis Mean                   14.0998\n",
      "trainer/Log Pis Std                     5.96677\n",
      "trainer/Policy mu Mean                  0.394445\n",
      "trainer/Policy mu Std                   2.82345\n",
      "trainer/Policy log std Mean            -3.71863\n",
      "trainer/Policy log std Std              1.17155\n",
      "exploration/num steps total        102175\n",
      "exploration/num paths total           901\n",
      "evaluation/num steps total         609649\n",
      "evaluation/num paths total            969\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52526\n",
      "evaluation/Rewards Std                  0.584446\n",
      "evaluation/Rewards Max                  4.62446\n",
      "evaluation/Rewards Min                  0.654241\n",
      "evaluation/Returns Mean              3525.26\n",
      "evaluation/Returns Std                 12.9448\n",
      "evaluation/Returns Max               3560.76\n",
      "evaluation/Returns Min               3513.46\n",
      "evaluation/Estimation Bias Mean       975.816\n",
      "evaluation/Estimation Bias Std        143.275\n",
      "evaluation/EB/Q_True Mean              32.5152\n",
      "evaluation/EB/Q_True Std              100.419\n",
      "evaluation/EB/Q_Pred Mean            1008.33\n",
      "evaluation/EB/Q_Pred Std              104.161\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3525.26\n",
      "evaluation/Actions Mean                 0.0294634\n",
      "evaluation/Actions Std                  0.589782\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86608\n",
      "time/backward_zf1 (s)                   1.97079\n",
      "time/backward_zf2 (s)                   1.93186\n",
      "time/data sampling (s)                  0.227956\n",
      "time/data storing (s)                   0.0138195\n",
      "time/evaluation sampling (s)            1.42996\n",
      "time/exploration sampling (s)           0.167954\n",
      "time/logging (s)                        0.0115599\n",
      "time/preback_alpha (s)                  0.5418\n",
      "time/preback_policy (s)                 0.62133\n",
      "time/preback_start (s)                  0.120007\n",
      "time/preback_zf (s)                     4.91202\n",
      "time/saving (s)                         0.00554317\n",
      "time/training (s)                       2.12699\n",
      "time/epoch (s)                         15.9477\n",
      "time/total (s)                       1470.22\n",
      "Epoch                                  95\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:25:56.715602 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 96 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 107000\n",
      "trainer/ZF1 Loss                       62.598\n",
      "trainer/ZF2 Loss                       56.8121\n",
      "trainer/ZF Expert Reward               19.1696\n",
      "trainer/ZF Policy Reward                1.76001\n",
      "trainer/ZF CHI2 Term                   90.2096\n",
      "trainer/Policy Loss                  -740.811\n",
      "trainer/Policy Grad Norm              322.434\n",
      "trainer/Policy Param Norm              34.8094\n",
      "trainer/Zf1 Grad Norm                5008.55\n",
      "trainer/Zf1 Param Norm                 86.7394\n",
      "trainer/Zf2 Grad Norm                5881.91\n",
      "trainer/Zf2 Param Norm                 84.8984\n",
      "trainer/Z Expert Predictions Mean    1037.34\n",
      "trainer/Z Expert Predictions Std      130.996\n",
      "trainer/Z Expert Predictions Max     1217.4\n",
      "trainer/Z Expert Predictions Min      486.224\n",
      "trainer/Z Policy Predictions Mean     732.979\n",
      "trainer/Z Policy Predictions Std      341.081\n",
      "trainer/Z Policy Predictions Max     1133.71\n",
      "trainer/Z Policy Predictions Min     -396.525\n",
      "trainer/Z Expert Targets Mean        1018.17\n",
      "trainer/Z Expert Targets Std          141.927\n",
      "trainer/Z Expert Targets Max         1224.44\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         731.219\n",
      "trainer/Z Policy Targets Std          337.363\n",
      "trainer/Z Policy Targets Max         1141.76\n",
      "trainer/Z Policy Targets Min         -380.439\n",
      "trainer/Log Pis Mean                   13.2272\n",
      "trainer/Log Pis Std                     5.12852\n",
      "trainer/Policy mu Mean                  0.484819\n",
      "trainer/Policy mu Std                   2.89141\n",
      "trainer/Policy log std Mean            -3.52942\n",
      "trainer/Policy log std Std              1.20243\n",
      "exploration/num steps total        103175\n",
      "exploration/num paths total           902\n",
      "evaluation/num steps total         619649\n",
      "evaluation/num paths total            979\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51992\n",
      "evaluation/Rewards Std                  0.579859\n",
      "evaluation/Rewards Max                  4.74833\n",
      "evaluation/Rewards Min                  0.686957\n",
      "evaluation/Returns Mean              3519.92\n",
      "evaluation/Returns Std                 17.6517\n",
      "evaluation/Returns Max               3572\n",
      "evaluation/Returns Min               3509.19\n",
      "evaluation/Estimation Bias Mean       980.859\n",
      "evaluation/Estimation Bias Std        161.274\n",
      "evaluation/EB/Q_True Mean              32.5409\n",
      "evaluation/EB/Q_True Std              100.24\n",
      "evaluation/EB/Q_Pred Mean            1013.4\n",
      "evaluation/EB/Q_Pred Std              126.89\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3519.92\n",
      "evaluation/Actions Mean                 0.0435538\n",
      "evaluation/Actions Std                  0.588307\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82849\n",
      "time/backward_zf1 (s)                   1.91667\n",
      "time/backward_zf2 (s)                   1.88821\n",
      "time/data sampling (s)                  0.246724\n",
      "time/data storing (s)                   0.0135911\n",
      "time/evaluation sampling (s)            1.34914\n",
      "time/exploration sampling (s)           0.169688\n",
      "time/logging (s)                        0.0114533\n",
      "time/preback_alpha (s)                  0.540626\n",
      "time/preback_policy (s)                 0.61707\n",
      "time/preback_start (s)                  0.119805\n",
      "time/preback_zf (s)                     4.92229\n",
      "time/saving (s)                         0.00476851\n",
      "time/training (s)                       2.21539\n",
      "time/epoch (s)                         15.8439\n",
      "time/total (s)                       1486.08\n",
      "Epoch                                  96\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:26:12.572035 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 97 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 108000\n",
      "trainer/ZF1 Loss                       41.5489\n",
      "trainer/ZF2 Loss                       59.206\n",
      "trainer/ZF Expert Reward               18.3792\n",
      "trainer/ZF Policy Reward                1.50771\n",
      "trainer/ZF CHI2 Term                   80.5494\n",
      "trainer/Policy Loss                  -760.545\n",
      "trainer/Policy Grad Norm              363.658\n",
      "trainer/Policy Param Norm              34.8959\n",
      "trainer/Zf1 Grad Norm               11074.9\n",
      "trainer/Zf1 Param Norm                 87.0993\n",
      "trainer/Zf2 Grad Norm               13410.8\n",
      "trainer/Zf2 Param Norm                 85.2236\n",
      "trainer/Z Expert Predictions Mean    1035.04\n",
      "trainer/Z Expert Predictions Std      129.821\n",
      "trainer/Z Expert Predictions Max     1227.17\n",
      "trainer/Z Expert Predictions Min      490.733\n",
      "trainer/Z Policy Predictions Mean     746.543\n",
      "trainer/Z Policy Predictions Std      345.793\n",
      "trainer/Z Policy Predictions Max     1195.91\n",
      "trainer/Z Policy Predictions Min     -340.518\n",
      "trainer/Z Expert Targets Mean        1016.66\n",
      "trainer/Z Expert Targets Std          128.506\n",
      "trainer/Z Expert Targets Max         1204.93\n",
      "trainer/Z Expert Targets Min          438.514\n",
      "trainer/Z Policy Targets Mean         745.035\n",
      "trainer/Z Policy Targets Std          337.97\n",
      "trainer/Z Policy Targets Max         1166.9\n",
      "trainer/Z Policy Targets Min         -336.067\n",
      "trainer/Log Pis Mean                   13.4348\n",
      "trainer/Log Pis Std                     5.68858\n",
      "trainer/Policy mu Mean                  0.0908777\n",
      "trainer/Policy mu Std                   2.64627\n",
      "trainer/Policy log std Mean            -3.64922\n",
      "trainer/Policy log std Std              1.14535\n",
      "exploration/num steps total        103175\n",
      "exploration/num paths total           902\n",
      "evaluation/num steps total         629649\n",
      "evaluation/num paths total            989\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.53059\n",
      "evaluation/Rewards Std                  0.576383\n",
      "evaluation/Rewards Max                  4.62279\n",
      "evaluation/Rewards Min                  0.689622\n",
      "evaluation/Returns Mean              3530.59\n",
      "evaluation/Returns Std                  1.34975\n",
      "evaluation/Returns Max               3532.01\n",
      "evaluation/Returns Min               3527.07\n",
      "evaluation/Estimation Bias Mean       958.499\n",
      "evaluation/Estimation Bias Std        126.684\n",
      "evaluation/EB/Q_True Mean              32.6453\n",
      "evaluation/EB/Q_True Std              100.483\n",
      "evaluation/EB/Q_Pred Mean             991.144\n",
      "evaluation/EB/Q_Pred Std               79.1435\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3530.59\n",
      "evaluation/Actions Mean                 0.0117409\n",
      "evaluation/Actions Std                  0.581882\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999986\n",
      "time/backward_policy (s)                1.81435\n",
      "time/backward_zf1 (s)                   1.89742\n",
      "time/backward_zf2 (s)                   1.86318\n",
      "time/data sampling (s)                  0.233741\n",
      "time/data storing (s)                   0.0132444\n",
      "time/evaluation sampling (s)            1.40216\n",
      "time/exploration sampling (s)           0.162059\n",
      "time/logging (s)                        0.0112908\n",
      "time/preback_alpha (s)                  0.539445\n",
      "time/preback_policy (s)                 0.609565\n",
      "time/preback_start (s)                  0.118491\n",
      "time/preback_zf (s)                     4.90879\n",
      "time/saving (s)                         0.00492232\n",
      "time/training (s)                       2.21384\n",
      "time/epoch (s)                         15.7925\n",
      "time/total (s)                       1501.89\n",
      "Epoch                                  97\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:26:28.434498 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 98 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 109000\n",
      "trainer/ZF1 Loss                      174.904\n",
      "trainer/ZF2 Loss                      146.286\n",
      "trainer/ZF Expert Reward               18.9137\n",
      "trainer/ZF Policy Reward                1.44789\n",
      "trainer/ZF CHI2 Term                  191.108\n",
      "trainer/Policy Loss                  -751.93\n",
      "trainer/Policy Grad Norm              526.375\n",
      "trainer/Policy Param Norm              34.9713\n",
      "trainer/Zf1 Grad Norm               12691.6\n",
      "trainer/Zf1 Param Norm                 87.4933\n",
      "trainer/Zf2 Grad Norm               11627.9\n",
      "trainer/Zf2 Param Norm                 85.5562\n",
      "trainer/Z Expert Predictions Mean    1036.62\n",
      "trainer/Z Expert Predictions Std      126.784\n",
      "trainer/Z Expert Predictions Max     1263.07\n",
      "trainer/Z Expert Predictions Min      647.464\n",
      "trainer/Z Policy Predictions Mean     746.399\n",
      "trainer/Z Policy Predictions Std      337.817\n",
      "trainer/Z Policy Predictions Max     1209.7\n",
      "trainer/Z Policy Predictions Min     -593.068\n",
      "trainer/Z Expert Targets Mean        1017.71\n",
      "trainer/Z Expert Targets Std          141.884\n",
      "trainer/Z Expert Targets Max         1236.85\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         744.951\n",
      "trainer/Z Policy Targets Std          337.969\n",
      "trainer/Z Policy Targets Max         1171.35\n",
      "trainer/Z Policy Targets Min         -622.466\n",
      "trainer/Log Pis Mean                   13.1787\n",
      "trainer/Log Pis Std                     5.33722\n",
      "trainer/Policy mu Mean                  0.300573\n",
      "trainer/Policy mu Std                   2.72025\n",
      "trainer/Policy log std Mean            -3.5588\n",
      "trainer/Policy log std Std              1.20015\n",
      "exploration/num steps total        104175\n",
      "exploration/num paths total           903\n",
      "evaluation/num steps total         637376\n",
      "evaluation/num paths total            999\n",
      "evaluation/path length Mean           772.7\n",
      "evaluation/path length Std            199.352\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            459\n",
      "evaluation/Rewards Mean                 3.61594\n",
      "evaluation/Rewards Std                  0.683526\n",
      "evaluation/Rewards Max                  5.6656\n",
      "evaluation/Rewards Min                  0.687818\n",
      "evaluation/Returns Mean              2794.04\n",
      "evaluation/Returns Std                718.334\n",
      "evaluation/Returns Max               3631.6\n",
      "evaluation/Returns Min               1647.22\n",
      "evaluation/Estimation Bias Mean       827.456\n",
      "evaluation/Estimation Bias Std        399.62\n",
      "evaluation/EB/Q_True Mean              42.511\n",
      "evaluation/EB/Q_True Std              113.401\n",
      "evaluation/EB/Q_Pred Mean             869.967\n",
      "evaluation/EB/Q_Pred Std              371.605\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2794.04\n",
      "evaluation/Actions Mean                 0.038185\n",
      "evaluation/Actions Std                  0.60406\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.66162\n",
      "time/backward_zf1 (s)                   1.7867\n",
      "time/backward_zf2 (s)                   1.71541\n",
      "time/data sampling (s)                  0.224709\n",
      "time/data storing (s)                   0.0139255\n",
      "time/evaluation sampling (s)            1.41829\n",
      "time/exploration sampling (s)           0.166817\n",
      "time/logging (s)                        0.00922726\n",
      "time/preback_alpha (s)                  0.54024\n",
      "time/preback_policy (s)                 0.593664\n",
      "time/preback_start (s)                  0.121091\n",
      "time/preback_zf (s)                     4.92916\n",
      "time/saving (s)                         0.00570327\n",
      "time/training (s)                       2.61065\n",
      "time/epoch (s)                         15.7972\n",
      "time/total (s)                       1517.71\n",
      "Epoch                                  98\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:26:44.390450 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 99 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 110000\n",
      "trainer/ZF1 Loss                       33.8168\n",
      "trainer/ZF2 Loss                       40.0056\n",
      "trainer/ZF Expert Reward               14.7737\n",
      "trainer/ZF Policy Reward               -3.42921\n",
      "trainer/ZF CHI2 Term                   68.1249\n",
      "trainer/Policy Loss                  -741.551\n",
      "trainer/Policy Grad Norm              406.158\n",
      "trainer/Policy Param Norm              35.0392\n",
      "trainer/Zf1 Grad Norm                4296.59\n",
      "trainer/Zf1 Param Norm                 87.8937\n",
      "trainer/Zf2 Grad Norm                3202.04\n",
      "trainer/Zf2 Param Norm                 85.899\n",
      "trainer/Z Expert Predictions Mean    1047.92\n",
      "trainer/Z Expert Predictions Std      137.975\n",
      "trainer/Z Expert Predictions Max     1277.22\n",
      "trainer/Z Expert Predictions Min      369.314\n",
      "trainer/Z Policy Predictions Mean     729.426\n",
      "trainer/Z Policy Predictions Std      353.701\n",
      "trainer/Z Policy Predictions Max     1185.97\n",
      "trainer/Z Policy Predictions Min     -265.98\n",
      "trainer/Z Expert Targets Mean        1033.14\n",
      "trainer/Z Expert Targets Std          137.162\n",
      "trainer/Z Expert Targets Max         1268.84\n",
      "trainer/Z Expert Targets Min          368.775\n",
      "trainer/Z Policy Targets Mean         732.855\n",
      "trainer/Z Policy Targets Std          349.311\n",
      "trainer/Z Policy Targets Max         1167.25\n",
      "trainer/Z Policy Targets Min         -241.93\n",
      "trainer/Log Pis Mean                   13.1421\n",
      "trainer/Log Pis Std                     5.66295\n",
      "trainer/Policy mu Mean                  0.27518\n",
      "trainer/Policy mu Std                   2.7484\n",
      "trainer/Policy log std Mean            -3.51293\n",
      "trainer/Policy log std Std              1.15371\n",
      "exploration/num steps total        104175\n",
      "exploration/num paths total           903\n",
      "evaluation/num steps total         647376\n",
      "evaluation/num paths total           1009\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51617\n",
      "evaluation/Rewards Std                  0.592693\n",
      "evaluation/Rewards Max                  4.63235\n",
      "evaluation/Rewards Min                  0.668114\n",
      "evaluation/Returns Mean              3516.17\n",
      "evaluation/Returns Std                 10.1808\n",
      "evaluation/Returns Max               3526.36\n",
      "evaluation/Returns Min               3498.46\n",
      "evaluation/Estimation Bias Mean       993.681\n",
      "evaluation/Estimation Bias Std        145.283\n",
      "evaluation/EB/Q_True Mean              32.5829\n",
      "evaluation/EB/Q_True Std              100.394\n",
      "evaluation/EB/Q_Pred Mean            1026.26\n",
      "evaluation/EB/Q_Pred Std              106.776\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3516.17\n",
      "evaluation/Actions Mean                 0.00206131\n",
      "evaluation/Actions Std                  0.587745\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.76001\n",
      "time/backward_zf1 (s)                   1.8592\n",
      "time/backward_zf2 (s)                   1.80171\n",
      "time/data sampling (s)                  0.238231\n",
      "time/data storing (s)                   0.0134859\n",
      "time/evaluation sampling (s)            1.41339\n",
      "time/exploration sampling (s)           0.164194\n",
      "time/logging (s)                        0.012487\n",
      "time/preback_alpha (s)                  0.541775\n",
      "time/preback_policy (s)                 0.607938\n",
      "time/preback_start (s)                  0.120692\n",
      "time/preback_zf (s)                     4.93271\n",
      "time/saving (s)                         0.00496307\n",
      "time/training (s)                       2.42474\n",
      "time/epoch (s)                         15.8955\n",
      "time/total (s)                       1533.63\n",
      "Epoch                                  99\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:27:00.180014 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 100 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 111000\n",
      "trainer/ZF1 Loss                      210.913\n",
      "trainer/ZF2 Loss                      202.445\n",
      "trainer/ZF Expert Reward                9.08786\n",
      "trainer/ZF Policy Reward                0.700158\n",
      "trainer/ZF CHI2 Term                  228.498\n",
      "trainer/Policy Loss                  -764.869\n",
      "trainer/Policy Grad Norm              508.269\n",
      "trainer/Policy Param Norm              35.1091\n",
      "trainer/Zf1 Grad Norm                9232.76\n",
      "trainer/Zf1 Param Norm                 88.2663\n",
      "trainer/Zf2 Grad Norm               10440\n",
      "trainer/Zf2 Param Norm                 86.2602\n",
      "trainer/Z Expert Predictions Mean    1054.26\n",
      "trainer/Z Expert Predictions Std      138.468\n",
      "trainer/Z Expert Predictions Max     1288.31\n",
      "trainer/Z Expert Predictions Min      556.673\n",
      "trainer/Z Policy Predictions Mean     752.054\n",
      "trainer/Z Policy Predictions Std      334.011\n",
      "trainer/Z Policy Predictions Max     1201.17\n",
      "trainer/Z Policy Predictions Min     -419.47\n",
      "trainer/Z Expert Targets Mean        1045.17\n",
      "trainer/Z Expert Targets Std          136.772\n",
      "trainer/Z Expert Targets Max         1270.01\n",
      "trainer/Z Expert Targets Min          540.019\n",
      "trainer/Z Policy Targets Mean         751.354\n",
      "trainer/Z Policy Targets Std          335.302\n",
      "trainer/Z Policy Targets Max         1174.85\n",
      "trainer/Z Policy Targets Min         -381.868\n",
      "trainer/Log Pis Mean                   13.5666\n",
      "trainer/Log Pis Std                     6.16609\n",
      "trainer/Policy mu Mean                 -0.108148\n",
      "trainer/Policy mu Std                   2.86261\n",
      "trainer/Policy log std Mean            -3.75629\n",
      "trainer/Policy log std Std              1.03648\n",
      "exploration/num steps total        105175\n",
      "exploration/num paths total           904\n",
      "evaluation/num steps total         652020\n",
      "evaluation/num paths total           1019\n",
      "evaluation/path length Mean           464.4\n",
      "evaluation/path length Std             79.6382\n",
      "evaluation/path length Max            688\n",
      "evaluation/path length Min            396\n",
      "evaluation/Rewards Mean                 3.52976\n",
      "evaluation/Rewards Std                  0.827404\n",
      "evaluation/Rewards Max                  5.73965\n",
      "evaluation/Rewards Min                  0.679541\n",
      "evaluation/Returns Mean              1639.22\n",
      "evaluation/Returns Std                309.557\n",
      "evaluation/Returns Max               2496.39\n",
      "evaluation/Returns Min               1361.59\n",
      "evaluation/Estimation Bias Mean       716.603\n",
      "evaluation/Estimation Bias Std        444.36\n",
      "evaluation/EB/Q_True Mean              42.0953\n",
      "evaluation/EB/Q_True Std              106.428\n",
      "evaluation/EB/Q_Pred Mean             758.698\n",
      "evaluation/EB/Q_Pred Std              442.794\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1639.22\n",
      "evaluation/Actions Mean                 0.0192752\n",
      "evaluation/Actions Std                  0.619191\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82081\n",
      "time/backward_zf1 (s)                   1.91615\n",
      "time/backward_zf2 (s)                   1.88324\n",
      "time/data sampling (s)                  0.237293\n",
      "time/data storing (s)                   0.0133747\n",
      "time/evaluation sampling (s)            1.28286\n",
      "time/exploration sampling (s)           0.165322\n",
      "time/logging (s)                        0.0060742\n",
      "time/preback_alpha (s)                  0.538897\n",
      "time/preback_policy (s)                 0.612288\n",
      "time/preback_start (s)                  0.119318\n",
      "time/preback_zf (s)                     4.91438\n",
      "time/saving (s)                         0.0055442\n",
      "time/training (s)                       2.20173\n",
      "time/epoch (s)                         15.7173\n",
      "time/total (s)                       1549.37\n",
      "Epoch                                 100\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:27:15.510667 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 101 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 112000\n",
      "trainer/ZF1 Loss                       20.4154\n",
      "trainer/ZF2 Loss                       29.7496\n",
      "trainer/ZF Expert Reward                7.25954\n",
      "trainer/ZF Policy Reward               -5.24449\n",
      "trainer/ZF CHI2 Term                   50.8979\n",
      "trainer/Policy Loss                  -772.807\n",
      "trainer/Policy Grad Norm              584.431\n",
      "trainer/Policy Param Norm              35.1877\n",
      "trainer/Zf1 Grad Norm                9378.37\n",
      "trainer/Zf1 Param Norm                 88.647\n",
      "trainer/Zf2 Grad Norm               10377.4\n",
      "trainer/Zf2 Param Norm                 86.6335\n",
      "trainer/Z Expert Predictions Mean    1087\n",
      "trainer/Z Expert Predictions Std      119.049\n",
      "trainer/Z Expert Predictions Max     1291.5\n",
      "trainer/Z Expert Predictions Min      673.062\n",
      "trainer/Z Policy Predictions Mean     762.697\n",
      "trainer/Z Policy Predictions Std      360.18\n",
      "trainer/Z Policy Predictions Max     1225.04\n",
      "trainer/Z Policy Predictions Min     -452.727\n",
      "trainer/Z Expert Targets Mean        1079.74\n",
      "trainer/Z Expert Targets Std          118.177\n",
      "trainer/Z Expert Targets Max         1289.23\n",
      "trainer/Z Expert Targets Min          670.486\n",
      "trainer/Z Policy Targets Mean         767.942\n",
      "trainer/Z Policy Targets Std          358.849\n",
      "trainer/Z Policy Targets Max         1214.17\n",
      "trainer/Z Policy Targets Min         -475.277\n",
      "trainer/Log Pis Mean                   13.4458\n",
      "trainer/Log Pis Std                     5.45495\n",
      "trainer/Policy mu Mean                  0.217297\n",
      "trainer/Policy mu Std                   2.69075\n",
      "trainer/Policy log std Mean            -3.71006\n",
      "trainer/Policy log std Std              1.11165\n",
      "exploration/num steps total        105892\n",
      "exploration/num paths total           905\n",
      "evaluation/num steps total         656507\n",
      "evaluation/num paths total           1029\n",
      "evaluation/path length Mean           448.7\n",
      "evaluation/path length Std             45.6049\n",
      "evaluation/path length Max            541\n",
      "evaluation/path length Min            383\n",
      "evaluation/Rewards Mean                 3.51048\n",
      "evaluation/Rewards Std                  0.811753\n",
      "evaluation/Rewards Max                  5.72999\n",
      "evaluation/Rewards Min                  0.674072\n",
      "evaluation/Returns Mean              1575.15\n",
      "evaluation/Returns Std                172.431\n",
      "evaluation/Returns Max               1924.06\n",
      "evaluation/Returns Min               1336.33\n",
      "evaluation/Estimation Bias Mean       747.562\n",
      "evaluation/Estimation Bias Std        436.887\n",
      "evaluation/EB/Q_True Mean              36.979\n",
      "evaluation/EB/Q_True Std              103.487\n",
      "evaluation/EB/Q_Pred Mean             784.541\n",
      "evaluation/EB/Q_Pred Std              421.636\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1575.15\n",
      "evaluation/Actions Mean                 0.0382932\n",
      "evaluation/Actions Std                  0.608567\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70142\n",
      "time/backward_zf1 (s)                   1.82826\n",
      "time/backward_zf2 (s)                   1.76085\n",
      "time/data sampling (s)                  0.212936\n",
      "time/data storing (s)                   0.0140966\n",
      "time/evaluation sampling (s)            0.82077\n",
      "time/exploration sampling (s)           0.169662\n",
      "time/logging (s)                        0.00595909\n",
      "time/preback_alpha (s)                  0.540199\n",
      "time/preback_policy (s)                 0.596849\n",
      "time/preback_start (s)                  0.120739\n",
      "time/preback_zf (s)                     4.92139\n",
      "time/saving (s)                         0.00516597\n",
      "time/training (s)                       2.57162\n",
      "time/epoch (s)                         15.2699\n",
      "time/total (s)                       1564.65\n",
      "Epoch                                 101\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:27:30.743059 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 102 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 113000\n",
      "trainer/ZF1 Loss                      322.921\n",
      "trainer/ZF2 Loss                      350.777\n",
      "trainer/ZF Expert Reward               16.0487\n",
      "trainer/ZF Policy Reward               -1.43303\n",
      "trainer/ZF CHI2 Term                  367.389\n",
      "trainer/Policy Loss                  -786.488\n",
      "trainer/Policy Grad Norm              679.715\n",
      "trainer/Policy Param Norm              35.263\n",
      "trainer/Zf1 Grad Norm               14954.5\n",
      "trainer/Zf1 Param Norm                 89.0197\n",
      "trainer/Zf2 Grad Norm               13379.3\n",
      "trainer/Zf2 Param Norm                 87.0046\n",
      "trainer/Z Expert Predictions Mean    1069.16\n",
      "trainer/Z Expert Predictions Std      143.25\n",
      "trainer/Z Expert Predictions Max     1318.73\n",
      "trainer/Z Expert Predictions Min      600.872\n",
      "trainer/Z Policy Predictions Mean     777.424\n",
      "trainer/Z Policy Predictions Std      344.83\n",
      "trainer/Z Policy Predictions Max     1217.25\n",
      "trainer/Z Policy Predictions Min     -491.91\n",
      "trainer/Z Expert Targets Mean        1053.11\n",
      "trainer/Z Expert Targets Std          166.258\n",
      "trainer/Z Expert Targets Max         1316.51\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         778.857\n",
      "trainer/Z Policy Targets Std          340.871\n",
      "trainer/Z Policy Targets Max         1201.44\n",
      "trainer/Z Policy Targets Min         -530.12\n",
      "trainer/Log Pis Mean                   13.1895\n",
      "trainer/Log Pis Std                     5.503\n",
      "trainer/Policy mu Mean                  0.320415\n",
      "trainer/Policy mu Std                   2.63026\n",
      "trainer/Policy log std Mean            -3.81952\n",
      "trainer/Policy log std Std              0.993487\n",
      "exploration/num steps total        108892\n",
      "exploration/num paths total           908\n",
      "evaluation/num steps total         660365\n",
      "evaluation/num paths total           1039\n",
      "evaluation/path length Mean           385.8\n",
      "evaluation/path length Std             61.9384\n",
      "evaluation/path length Max            554\n",
      "evaluation/path length Min            327\n",
      "evaluation/Rewards Mean                 3.48608\n",
      "evaluation/Rewards Std                  0.874737\n",
      "evaluation/Rewards Max                  5.77932\n",
      "evaluation/Rewards Min                  0.67088\n",
      "evaluation/Returns Mean              1344.93\n",
      "evaluation/Returns Std                235.74\n",
      "evaluation/Returns Max               1956.57\n",
      "evaluation/Returns Min               1099.4\n",
      "evaluation/Estimation Bias Mean       721.856\n",
      "evaluation/Estimation Bias Std        472.247\n",
      "evaluation/EB/Q_True Mean              43.8185\n",
      "evaluation/EB/Q_True Std              111.388\n",
      "evaluation/EB/Q_Pred Mean             765.675\n",
      "evaluation/EB/Q_Pred Std              470.299\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1344.93\n",
      "evaluation/Actions Mean                 0.0385431\n",
      "evaluation/Actions Std                  0.610628\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.65987\n",
      "time/backward_zf1 (s)                   1.78068\n",
      "time/backward_zf2 (s)                   1.71477\n",
      "time/data sampling (s)                  0.238456\n",
      "time/data storing (s)                   0.0146044\n",
      "time/evaluation sampling (s)            0.786852\n",
      "time/exploration sampling (s)           0.179423\n",
      "time/logging (s)                        0.00528949\n",
      "time/preback_alpha (s)                  0.542067\n",
      "time/preback_policy (s)                 0.595472\n",
      "time/preback_start (s)                  0.122414\n",
      "time/preback_zf (s)                     4.91327\n",
      "time/saving (s)                         0.00550741\n",
      "time/training (s)                       2.61204\n",
      "time/epoch (s)                         15.1707\n",
      "time/total (s)                       1579.84\n",
      "Epoch                                 102\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:27:46.596647 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 103 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 114000\n",
      "trainer/ZF1 Loss                      162.163\n",
      "trainer/ZF2 Loss                      171.217\n",
      "trainer/ZF Expert Reward               10.3048\n",
      "trainer/ZF Policy Reward               -6.74588\n",
      "trainer/ZF CHI2 Term                  197.502\n",
      "trainer/Policy Loss                  -786.027\n",
      "trainer/Policy Grad Norm              378.801\n",
      "trainer/Policy Param Norm              35.3438\n",
      "trainer/Zf1 Grad Norm               11002.1\n",
      "trainer/Zf1 Param Norm                 89.3936\n",
      "trainer/Zf2 Grad Norm               12460.1\n",
      "trainer/Zf2 Param Norm                 87.3569\n",
      "trainer/Z Expert Predictions Mean    1059.61\n",
      "trainer/Z Expert Predictions Std      151.09\n",
      "trainer/Z Expert Predictions Max     1285.04\n",
      "trainer/Z Expert Predictions Min      521.655\n",
      "trainer/Z Policy Predictions Mean     773.963\n",
      "trainer/Z Policy Predictions Std      372.268\n",
      "trainer/Z Policy Predictions Max     1221.96\n",
      "trainer/Z Policy Predictions Min     -422.608\n",
      "trainer/Z Expert Targets Mean        1049.31\n",
      "trainer/Z Expert Targets Std          165.106\n",
      "trainer/Z Expert Targets Max         1271.5\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         780.708\n",
      "trainer/Z Policy Targets Std          367.731\n",
      "trainer/Z Policy Targets Max         1256.3\n",
      "trainer/Z Policy Targets Min         -409.438\n",
      "trainer/Log Pis Mean                   13.9004\n",
      "trainer/Log Pis Std                     5.05767\n",
      "trainer/Policy mu Mean                  0.436951\n",
      "trainer/Policy mu Std                   2.76647\n",
      "trainer/Policy log std Mean            -3.79151\n",
      "trainer/Policy log std Std              1.11511\n",
      "exploration/num steps total        108892\n",
      "exploration/num paths total           908\n",
      "evaluation/num steps total         669026\n",
      "evaluation/num paths total           1049\n",
      "evaluation/path length Mean           866.1\n",
      "evaluation/path length Std            188.601\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            467\n",
      "evaluation/Rewards Mean                 3.53355\n",
      "evaluation/Rewards Std                  0.616639\n",
      "evaluation/Rewards Max                  5.55409\n",
      "evaluation/Rewards Min                  0.662468\n",
      "evaluation/Returns Mean              3060.41\n",
      "evaluation/Returns Std                655.406\n",
      "evaluation/Returns Max               3543.78\n",
      "evaluation/Returns Min               1642.18\n",
      "evaluation/Estimation Bias Mean       969.004\n",
      "evaluation/Estimation Bias Std        275.592\n",
      "evaluation/EB/Q_True Mean              37.6492\n",
      "evaluation/EB/Q_True Std              107.089\n",
      "evaluation/EB/Q_Pred Mean            1006.65\n",
      "evaluation/EB/Q_Pred Std              236.989\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3060.41\n",
      "evaluation/Actions Mean                 0.0226907\n",
      "evaluation/Actions Std                  0.589877\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73826\n",
      "time/backward_zf1 (s)                   1.84286\n",
      "time/backward_zf2 (s)                   1.78899\n",
      "time/data sampling (s)                  0.233613\n",
      "time/data storing (s)                   0.0134829\n",
      "time/evaluation sampling (s)            1.35135\n",
      "time/exploration sampling (s)           0.16325\n",
      "time/logging (s)                        0.0116422\n",
      "time/preback_alpha (s)                  0.540835\n",
      "time/preback_policy (s)                 0.604356\n",
      "time/preback_start (s)                  0.119195\n",
      "time/preback_zf (s)                     4.92465\n",
      "time/saving (s)                         0.00900481\n",
      "time/training (s)                       2.45756\n",
      "time/epoch (s)                         15.799\n",
      "time/total (s)                       1595.66\n",
      "Epoch                                 103\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:28:02.372628 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 104 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 115000\n",
      "trainer/ZF1 Loss                       11.7418\n",
      "trainer/ZF2 Loss                       22.2227\n",
      "trainer/ZF Expert Reward               11.7046\n",
      "trainer/ZF Policy Reward               -0.11221\n",
      "trainer/ZF CHI2 Term                   42.4364\n",
      "trainer/Policy Loss                  -796.934\n",
      "trainer/Policy Grad Norm              447.05\n",
      "trainer/Policy Param Norm              35.4213\n",
      "trainer/Zf1 Grad Norm                6126.21\n",
      "trainer/Zf1 Param Norm                 89.7676\n",
      "trainer/Zf2 Grad Norm                6353.7\n",
      "trainer/Zf2 Param Norm                 87.7225\n",
      "trainer/Z Expert Predictions Mean    1086.46\n",
      "trainer/Z Expert Predictions Std      150.41\n",
      "trainer/Z Expert Predictions Max     1323.27\n",
      "trainer/Z Expert Predictions Min      582.086\n",
      "trainer/Z Policy Predictions Mean     779.699\n",
      "trainer/Z Policy Predictions Std      356.37\n",
      "trainer/Z Policy Predictions Max     1238.17\n",
      "trainer/Z Policy Predictions Min     -480.829\n",
      "trainer/Z Expert Targets Mean        1074.75\n",
      "trainer/Z Expert Targets Std          149.584\n",
      "trainer/Z Expert Targets Max         1291.69\n",
      "trainer/Z Expert Targets Min          549.432\n",
      "trainer/Z Policy Targets Mean         779.811\n",
      "trainer/Z Policy Targets Std          350.846\n",
      "trainer/Z Policy Targets Max         1233.94\n",
      "trainer/Z Policy Targets Min         -457.941\n",
      "trainer/Log Pis Mean                   13.775\n",
      "trainer/Log Pis Std                     5.64844\n",
      "trainer/Policy mu Mean                  0.120345\n",
      "trainer/Policy mu Std                   2.84847\n",
      "trainer/Policy log std Mean            -3.70665\n",
      "trainer/Policy log std Std              1.14324\n",
      "exploration/num steps total        111292\n",
      "exploration/num paths total           911\n",
      "evaluation/num steps total         679026\n",
      "evaluation/num paths total           1059\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51908\n",
      "evaluation/Rewards Std                  0.593701\n",
      "evaluation/Rewards Max                  4.61989\n",
      "evaluation/Rewards Min                  0.659522\n",
      "evaluation/Returns Mean              3519.08\n",
      "evaluation/Returns Std                  4.70894\n",
      "evaluation/Returns Max               3525.76\n",
      "evaluation/Returns Min               3511.99\n",
      "evaluation/Estimation Bias Mean      1029.34\n",
      "evaluation/Estimation Bias Std        152.182\n",
      "evaluation/EB/Q_True Mean              32.4857\n",
      "evaluation/EB/Q_True Std              100.04\n",
      "evaluation/EB/Q_Pred Mean            1061.83\n",
      "evaluation/EB/Q_Pred Std              114.399\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3519.08\n",
      "evaluation/Actions Mean                 0.0218227\n",
      "evaluation/Actions Std                  0.590342\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.62714\n",
      "time/backward_zf1 (s)                   1.75971\n",
      "time/backward_zf2 (s)                   1.67623\n",
      "time/data sampling (s)                  0.242465\n",
      "time/data storing (s)                   0.0136747\n",
      "time/evaluation sampling (s)            1.35365\n",
      "time/exploration sampling (s)           0.168452\n",
      "time/logging (s)                        0.0119709\n",
      "time/preback_alpha (s)                  0.542199\n",
      "time/preback_policy (s)                 0.585503\n",
      "time/preback_start (s)                  0.121126\n",
      "time/preback_zf (s)                     4.9163\n",
      "time/saving (s)                         0.00536838\n",
      "time/training (s)                       2.68937\n",
      "time/epoch (s)                         15.7132\n",
      "time/total (s)                       1611.39\n",
      "Epoch                                 104\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:28:17.608927 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 105 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 116000\n",
      "trainer/ZF1 Loss                      227.487\n",
      "trainer/ZF2 Loss                      265.865\n",
      "trainer/ZF Expert Reward               11.8243\n",
      "trainer/ZF Policy Reward               -0.813178\n",
      "trainer/ZF CHI2 Term                  272.569\n",
      "trainer/Policy Loss                  -776.88\n",
      "trainer/Policy Grad Norm              573.055\n",
      "trainer/Policy Param Norm              35.5013\n",
      "trainer/Zf1 Grad Norm               13213.5\n",
      "trainer/Zf1 Param Norm                 90.1461\n",
      "trainer/Zf2 Grad Norm               12590.4\n",
      "trainer/Zf2 Param Norm                 88.0911\n",
      "trainer/Z Expert Predictions Mean    1088.54\n",
      "trainer/Z Expert Predictions Std      145.963\n",
      "trainer/Z Expert Predictions Max     1330.32\n",
      "trainer/Z Expert Predictions Min      450.763\n",
      "trainer/Z Policy Predictions Mean     771.161\n",
      "trainer/Z Policy Predictions Std      380.155\n",
      "trainer/Z Policy Predictions Max     1237.72\n",
      "trainer/Z Policy Predictions Min     -605.388\n",
      "trainer/Z Expert Targets Mean        1076.71\n",
      "trainer/Z Expert Targets Std          155.464\n",
      "trainer/Z Expert Targets Max         1308.99\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         771.974\n",
      "trainer/Z Policy Targets Std          379.321\n",
      "trainer/Z Policy Targets Max         1238.26\n",
      "trainer/Z Policy Targets Min         -613.399\n",
      "trainer/Log Pis Mean                   13.3893\n",
      "trainer/Log Pis Std                     5.58469\n",
      "trainer/Policy mu Mean                  0.541839\n",
      "trainer/Policy mu Std                   2.84945\n",
      "trainer/Policy log std Mean            -3.52085\n",
      "trainer/Policy log std Std              1.22942\n",
      "exploration/num steps total        112689\n",
      "exploration/num paths total           913\n",
      "evaluation/num steps total         683033\n",
      "evaluation/num paths total           1069\n",
      "evaluation/path length Mean           400.7\n",
      "evaluation/path length Std              7.9\n",
      "evaluation/path length Max            423\n",
      "evaluation/path length Min            395\n",
      "evaluation/Rewards Mean                 3.47845\n",
      "evaluation/Rewards Std                  0.857009\n",
      "evaluation/Rewards Max                  5.55825\n",
      "evaluation/Rewards Min                  0.662589\n",
      "evaluation/Returns Mean              1393.82\n",
      "evaluation/Returns Std                 26.9812\n",
      "evaluation/Returns Max               1473.99\n",
      "evaluation/Returns Min               1380.61\n",
      "evaluation/Estimation Bias Mean       763.486\n",
      "evaluation/Estimation Bias Std        462.169\n",
      "evaluation/EB/Q_True Mean              30.2965\n",
      "evaluation/EB/Q_True Std               92.3261\n",
      "evaluation/EB/Q_Pred Mean             793.783\n",
      "evaluation/EB/Q_Pred Std              454.953\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1393.82\n",
      "evaluation/Actions Mean                 0.0271968\n",
      "evaluation/Actions Std                  0.606805\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71033\n",
      "time/backward_zf1 (s)                   1.81857\n",
      "time/backward_zf2 (s)                   1.76039\n",
      "time/data sampling (s)                  0.235877\n",
      "time/data storing (s)                   0.0135054\n",
      "time/evaluation sampling (s)            0.61316\n",
      "time/exploration sampling (s)           0.167695\n",
      "time/logging (s)                        0.00537651\n",
      "time/preback_alpha (s)                  0.549225\n",
      "time/preback_policy (s)                 0.605527\n",
      "time/preback_start (s)                  0.12243\n",
      "time/preback_zf (s)                     4.97074\n",
      "time/saving (s)                         0.00512229\n",
      "time/training (s)                       2.58902\n",
      "time/epoch (s)                         15.167\n",
      "time/total (s)                       1626.58\n",
      "Epoch                                 105\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:28:32.849366 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 106 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 117000\n",
      "trainer/ZF1 Loss                      220.682\n",
      "trainer/ZF2 Loss                      214.941\n",
      "trainer/ZF Expert Reward               17.9954\n",
      "trainer/ZF Policy Reward                1.91007\n",
      "trainer/ZF CHI2 Term                  248.278\n",
      "trainer/Policy Loss                  -792.479\n",
      "trainer/Policy Grad Norm              431.318\n",
      "trainer/Policy Param Norm              35.5863\n",
      "trainer/Zf1 Grad Norm               16917.9\n",
      "trainer/Zf1 Param Norm                 90.5054\n",
      "trainer/Zf2 Grad Norm               12741.5\n",
      "trainer/Zf2 Param Norm                 88.4415\n",
      "trainer/Z Expert Predictions Mean    1107.3\n",
      "trainer/Z Expert Predictions Std      142.671\n",
      "trainer/Z Expert Predictions Max     1336.16\n",
      "trainer/Z Expert Predictions Min      612.249\n",
      "trainer/Z Policy Predictions Mean     776.112\n",
      "trainer/Z Policy Predictions Std      383.797\n",
      "trainer/Z Policy Predictions Max     1282.91\n",
      "trainer/Z Policy Predictions Min     -466.973\n",
      "trainer/Z Expert Targets Mean        1089.3\n",
      "trainer/Z Expert Targets Std          158.345\n",
      "trainer/Z Expert Targets Max         1335.21\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         774.202\n",
      "trainer/Z Policy Targets Std          383.599\n",
      "trainer/Z Policy Targets Max         1263.37\n",
      "trainer/Z Policy Targets Min         -608.581\n",
      "trainer/Log Pis Mean                   14.5269\n",
      "trainer/Log Pis Std                     5.87002\n",
      "trainer/Policy mu Mean                  0.257034\n",
      "trainer/Policy mu Std                   3.02709\n",
      "trainer/Policy log std Mean            -3.73326\n",
      "trainer/Policy log std Std              1.18905\n",
      "exploration/num steps total        113689\n",
      "exploration/num paths total           914\n",
      "evaluation/num steps total         686896\n",
      "evaluation/num paths total           1079\n",
      "evaluation/path length Mean           386.3\n",
      "evaluation/path length Std             40.7996\n",
      "evaluation/path length Max            483\n",
      "evaluation/path length Min            326\n",
      "evaluation/Rewards Mean                 3.45848\n",
      "evaluation/Rewards Std                  0.853014\n",
      "evaluation/Rewards Max                  5.66764\n",
      "evaluation/Rewards Min                  0.661623\n",
      "evaluation/Returns Mean              1336.01\n",
      "evaluation/Returns Std                151.952\n",
      "evaluation/Returns Max               1665.41\n",
      "evaluation/Returns Min               1090.85\n",
      "evaluation/Estimation Bias Mean       746.995\n",
      "evaluation/Estimation Bias Std        490.295\n",
      "evaluation/EB/Q_True Mean              36.3143\n",
      "evaluation/EB/Q_True Std              100.426\n",
      "evaluation/EB/Q_Pred Mean             783.31\n",
      "evaluation/EB/Q_Pred Std              486.669\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1336.01\n",
      "evaluation/Actions Mean                 0.0437256\n",
      "evaluation/Actions Std                  0.605158\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76608\n",
      "time/backward_zf1 (s)                   1.87519\n",
      "time/backward_zf2 (s)                   1.82893\n",
      "time/data sampling (s)                  0.243917\n",
      "time/data storing (s)                   0.0140273\n",
      "time/evaluation sampling (s)            0.687044\n",
      "time/exploration sampling (s)           0.172005\n",
      "time/logging (s)                        0.00520087\n",
      "time/preback_alpha (s)                  0.541002\n",
      "time/preback_policy (s)                 0.604535\n",
      "time/preback_start (s)                  0.120846\n",
      "time/preback_zf (s)                     4.93072\n",
      "time/saving (s)                         0.0049871\n",
      "time/training (s)                       2.38309\n",
      "time/epoch (s)                         15.1776\n",
      "time/total (s)                       1641.77\n",
      "Epoch                                 106\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:28:48.470301 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 107 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 118000\n",
      "trainer/ZF1 Loss                      192.309\n",
      "trainer/ZF2 Loss                      245.295\n",
      "trainer/ZF Expert Reward               15.8624\n",
      "trainer/ZF Policy Reward                1.74743\n",
      "trainer/ZF CHI2 Term                  246.653\n",
      "trainer/Policy Loss                  -799.837\n",
      "trainer/Policy Grad Norm              225.801\n",
      "trainer/Policy Param Norm              35.6685\n",
      "trainer/Zf1 Grad Norm               14641.6\n",
      "trainer/Zf1 Param Norm                 90.8763\n",
      "trainer/Zf2 Grad Norm               11934.8\n",
      "trainer/Zf2 Param Norm                 88.8118\n",
      "trainer/Z Expert Predictions Mean    1101.63\n",
      "trainer/Z Expert Predictions Std      150.928\n",
      "trainer/Z Expert Predictions Max     1349.53\n",
      "trainer/Z Expert Predictions Min      553.514\n",
      "trainer/Z Policy Predictions Mean     792.041\n",
      "trainer/Z Policy Predictions Std      355.231\n",
      "trainer/Z Policy Predictions Max     1265.53\n",
      "trainer/Z Policy Predictions Min     -275.852\n",
      "trainer/Z Expert Targets Mean        1085.76\n",
      "trainer/Z Expert Targets Std          163.135\n",
      "trainer/Z Expert Targets Max         1335.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         790.294\n",
      "trainer/Z Policy Targets Std          360.165\n",
      "trainer/Z Policy Targets Max         1250.32\n",
      "trainer/Z Policy Targets Min         -270.13\n",
      "trainer/Log Pis Mean                   13.8755\n",
      "trainer/Log Pis Std                     5.77776\n",
      "trainer/Policy mu Mean                  0.302439\n",
      "trainer/Policy mu Std                   2.83355\n",
      "trainer/Policy log std Mean            -3.67317\n",
      "trainer/Policy log std Std              1.25597\n",
      "exploration/num steps total        113689\n",
      "exploration/num paths total           914\n",
      "evaluation/num steps total         691347\n",
      "evaluation/num paths total           1089\n",
      "evaluation/path length Mean           445.1\n",
      "evaluation/path length Std             44.2413\n",
      "evaluation/path length Max            534\n",
      "evaluation/path length Min            394\n",
      "evaluation/Rewards Mean                 3.51016\n",
      "evaluation/Rewards Std                  0.821844\n",
      "evaluation/Rewards Max                  5.78509\n",
      "evaluation/Rewards Min                  0.657166\n",
      "evaluation/Returns Mean              1562.37\n",
      "evaluation/Returns Std                175.748\n",
      "evaluation/Returns Max               1915.65\n",
      "evaluation/Returns Min               1364.43\n",
      "evaluation/Estimation Bias Mean       739.585\n",
      "evaluation/Estimation Bias Std        480.293\n",
      "evaluation/EB/Q_True Mean              31.2012\n",
      "evaluation/EB/Q_True Std               90.1381\n",
      "evaluation/EB/Q_Pred Mean             770.787\n",
      "evaluation/EB/Q_Pred Std              480.271\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1562.37\n",
      "evaluation/Actions Mean                 0.0252198\n",
      "evaluation/Actions Std                  0.592124\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81562\n",
      "time/backward_zf1 (s)                   1.91123\n",
      "time/backward_zf2 (s)                   1.86571\n",
      "time/data sampling (s)                  0.227345\n",
      "time/data storing (s)                   0.0133228\n",
      "time/evaluation sampling (s)            1.11897\n",
      "time/exploration sampling (s)           0.162715\n",
      "time/logging (s)                        0.00578251\n",
      "time/preback_alpha (s)                  0.536737\n",
      "time/preback_policy (s)                 0.608241\n",
      "time/preback_start (s)                  0.118974\n",
      "time/preback_zf (s)                     4.91725\n",
      "time/saving (s)                         0.00478605\n",
      "time/training (s)                       2.25484\n",
      "time/epoch (s)                         15.5615\n",
      "time/total (s)                       1657.35\n",
      "Epoch                                 107\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:29:04.470177 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 108 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 119000\n",
      "trainer/ZF1 Loss                      210.739\n",
      "trainer/ZF2 Loss                      203.754\n",
      "trainer/ZF Expert Reward                9.83307\n",
      "trainer/ZF Policy Reward               -1.00872\n",
      "trainer/ZF CHI2 Term                  231.47\n",
      "trainer/Policy Loss                  -814.019\n",
      "trainer/Policy Grad Norm              744.68\n",
      "trainer/Policy Param Norm              35.7405\n",
      "trainer/Zf1 Grad Norm                6832.5\n",
      "trainer/Zf1 Param Norm                 91.2665\n",
      "trainer/Zf2 Grad Norm                8602.98\n",
      "trainer/Zf2 Param Norm                 89.1949\n",
      "trainer/Z Expert Predictions Mean    1103.35\n",
      "trainer/Z Expert Predictions Std      142.419\n",
      "trainer/Z Expert Predictions Max     1346.71\n",
      "trainer/Z Expert Predictions Min      648.918\n",
      "trainer/Z Policy Predictions Mean     803.689\n",
      "trainer/Z Policy Predictions Std      353.827\n",
      "trainer/Z Policy Predictions Max     1297.88\n",
      "trainer/Z Policy Predictions Min     -322.125\n",
      "trainer/Z Expert Targets Mean        1093.52\n",
      "trainer/Z Expert Targets Std          142.353\n",
      "trainer/Z Expert Targets Max         1334.64\n",
      "trainer/Z Expert Targets Min          651.351\n",
      "trainer/Z Policy Targets Mean         804.697\n",
      "trainer/Z Policy Targets Std          356.373\n",
      "trainer/Z Policy Targets Max         1305.64\n",
      "trainer/Z Policy Targets Min         -332.065\n",
      "trainer/Log Pis Mean                   13.517\n",
      "trainer/Log Pis Std                     5.75604\n",
      "trainer/Policy mu Mean                  0.328237\n",
      "trainer/Policy mu Std                   2.74559\n",
      "trainer/Policy log std Mean            -3.7374\n",
      "trainer/Policy log std Std              1.12111\n",
      "exploration/num steps total        115788\n",
      "exploration/num paths total           918\n",
      "evaluation/num steps total         701347\n",
      "evaluation/num paths total           1099\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52566\n",
      "evaluation/Rewards Std                  0.58004\n",
      "evaluation/Rewards Max                  4.58381\n",
      "evaluation/Rewards Min                  0.700008\n",
      "evaluation/Returns Mean              3525.66\n",
      "evaluation/Returns Std                  8.84791\n",
      "evaluation/Returns Max               3540.07\n",
      "evaluation/Returns Min               3511.64\n",
      "evaluation/Estimation Bias Mean      1067.89\n",
      "evaluation/Estimation Bias Std        164.912\n",
      "evaluation/EB/Q_True Mean              32.6922\n",
      "evaluation/EB/Q_True Std              100.839\n",
      "evaluation/EB/Q_Pred Mean            1100.58\n",
      "evaluation/EB/Q_Pred Std              131.491\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3525.66\n",
      "evaluation/Actions Mean                 0.0283586\n",
      "evaluation/Actions Std                  0.567156\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.81725\n",
      "time/backward_zf1 (s)                   1.92743\n",
      "time/backward_zf2 (s)                   1.87263\n",
      "time/data sampling (s)                  0.223745\n",
      "time/data storing (s)                   0.0135637\n",
      "time/evaluation sampling (s)            1.33902\n",
      "time/exploration sampling (s)           0.170836\n",
      "time/logging (s)                        0.0126171\n",
      "time/preback_alpha (s)                  0.544894\n",
      "time/preback_policy (s)                 0.615336\n",
      "time/preback_start (s)                  0.121929\n",
      "time/preback_zf (s)                     4.95477\n",
      "time/saving (s)                         0.0052894\n",
      "time/training (s)                       2.32321\n",
      "time/epoch (s)                         15.9425\n",
      "time/total (s)                       1673.32\n",
      "Epoch                                 108\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:29:20.115592 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 109 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 120000\n",
      "trainer/ZF1 Loss                       85.9516\n",
      "trainer/ZF2 Loss                       60.4049\n",
      "trainer/ZF Expert Reward               12.0537\n",
      "trainer/ZF Policy Reward                3.08319\n",
      "trainer/ZF CHI2 Term                   95.9246\n",
      "trainer/Policy Loss                  -812.917\n",
      "trainer/Policy Grad Norm              495.896\n",
      "trainer/Policy Param Norm              35.8223\n",
      "trainer/Zf1 Grad Norm               20541.3\n",
      "trainer/Zf1 Param Norm                 91.6548\n",
      "trainer/Zf2 Grad Norm               10767.4\n",
      "trainer/Zf2 Param Norm                 89.5716\n",
      "trainer/Z Expert Predictions Mean    1109.02\n",
      "trainer/Z Expert Predictions Std      162.501\n",
      "trainer/Z Expert Predictions Max     1365.5\n",
      "trainer/Z Expert Predictions Min      649.778\n",
      "trainer/Z Policy Predictions Mean     796.007\n",
      "trainer/Z Policy Predictions Std      383.033\n",
      "trainer/Z Policy Predictions Max     1300.15\n",
      "trainer/Z Policy Predictions Min     -299.275\n",
      "trainer/Z Expert Targets Mean        1096.97\n",
      "trainer/Z Expert Targets Std          160.168\n",
      "trainer/Z Expert Targets Max         1344.47\n",
      "trainer/Z Expert Targets Min          651.056\n",
      "trainer/Z Policy Targets Mean         792.923\n",
      "trainer/Z Policy Targets Std          381.33\n",
      "trainer/Z Policy Targets Max         1287.66\n",
      "trainer/Z Policy Targets Min         -302.602\n",
      "trainer/Log Pis Mean                   13.915\n",
      "trainer/Log Pis Std                     6.34169\n",
      "trainer/Policy mu Mean                  0.549645\n",
      "trainer/Policy mu Std                   3.06167\n",
      "trainer/Policy log std Mean            -3.7044\n",
      "trainer/Policy log std Std              1.22001\n",
      "exploration/num steps total        116460\n",
      "exploration/num paths total           920\n",
      "evaluation/num steps total         705345\n",
      "evaluation/num paths total           1109\n",
      "evaluation/path length Mean           399.8\n",
      "evaluation/path length Std             25.2063\n",
      "evaluation/path length Max            474\n",
      "evaluation/path length Min            384\n",
      "evaluation/Rewards Mean                 3.48664\n",
      "evaluation/Rewards Std                  0.854347\n",
      "evaluation/Rewards Max                  5.6865\n",
      "evaluation/Rewards Min                  0.671418\n",
      "evaluation/Returns Mean              1393.96\n",
      "evaluation/Returns Std                 90.3638\n",
      "evaluation/Returns Max               1663.26\n",
      "evaluation/Returns Min               1347.18\n",
      "evaluation/Estimation Bias Mean       728.907\n",
      "evaluation/Estimation Bias Std        505.566\n",
      "evaluation/EB/Q_True Mean              30.4499\n",
      "evaluation/EB/Q_True Std               89.565\n",
      "evaluation/EB/Q_Pred Mean             759.357\n",
      "evaluation/EB/Q_Pred Std              502.06\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1393.96\n",
      "evaluation/Actions Mean                 0.0382362\n",
      "evaluation/Actions Std                  0.598398\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70996\n",
      "time/backward_zf1 (s)                   1.82845\n",
      "time/backward_zf2 (s)                   1.7663\n",
      "time/data sampling (s)                  0.238352\n",
      "time/data storing (s)                   0.0134662\n",
      "time/evaluation sampling (s)            1.06443\n",
      "time/exploration sampling (s)           0.16672\n",
      "time/logging (s)                        0.00605762\n",
      "time/preback_alpha (s)                  0.543682\n",
      "time/preback_policy (s)                 0.603112\n",
      "time/preback_start (s)                  0.121505\n",
      "time/preback_zf (s)                     4.94686\n",
      "time/saving (s)                         0.00500235\n",
      "time/training (s)                       2.56103\n",
      "time/epoch (s)                         15.5749\n",
      "time/total (s)                       1688.91\n",
      "Epoch                                 109\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:29:35.985260 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 110 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 121000\n",
      "trainer/ZF1 Loss                       32.2628\n",
      "trainer/ZF2 Loss                       26.9769\n",
      "trainer/ZF Expert Reward               17.7317\n",
      "trainer/ZF Policy Reward                1.64212\n",
      "trainer/ZF CHI2 Term                   58.9549\n",
      "trainer/Policy Loss                  -821.877\n",
      "trainer/Policy Grad Norm              399.592\n",
      "trainer/Policy Param Norm              35.8957\n",
      "trainer/Zf1 Grad Norm                6188.48\n",
      "trainer/Zf1 Param Norm                 92.0332\n",
      "trainer/Zf2 Grad Norm                7300.51\n",
      "trainer/Zf2 Param Norm                 89.9433\n",
      "trainer/Z Expert Predictions Mean    1136.9\n",
      "trainer/Z Expert Predictions Std      145.167\n",
      "trainer/Z Expert Predictions Max     1394.22\n",
      "trainer/Z Expert Predictions Min      675.408\n",
      "trainer/Z Policy Predictions Mean     813.844\n",
      "trainer/Z Policy Predictions Std      369.637\n",
      "trainer/Z Policy Predictions Max     1345.54\n",
      "trainer/Z Policy Predictions Min     -762.725\n",
      "trainer/Z Expert Targets Mean        1119.17\n",
      "trainer/Z Expert Targets Std          144.608\n",
      "trainer/Z Expert Targets Max         1362.37\n",
      "trainer/Z Expert Targets Min          670.084\n",
      "trainer/Z Policy Targets Mean         812.202\n",
      "trainer/Z Policy Targets Std          364.553\n",
      "trainer/Z Policy Targets Max         1337.26\n",
      "trainer/Z Policy Targets Min         -807.075\n",
      "trainer/Log Pis Mean                   13.3792\n",
      "trainer/Log Pis Std                     5.4799\n",
      "trainer/Policy mu Mean                  0.345369\n",
      "trainer/Policy mu Std                   2.66349\n",
      "trainer/Policy log std Mean            -3.66863\n",
      "trainer/Policy log std Std              1.17331\n",
      "exploration/num steps total        117323\n",
      "exploration/num paths total           921\n",
      "evaluation/num steps total         715218\n",
      "evaluation/num paths total           1119\n",
      "evaluation/path length Mean           987.3\n",
      "evaluation/path length Std             38.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            873\n",
      "evaluation/Rewards Mean                 3.54593\n",
      "evaluation/Rewards Std                  0.586431\n",
      "evaluation/Rewards Max                  5.06743\n",
      "evaluation/Rewards Min                  0.667822\n",
      "evaluation/Returns Mean              3500.9\n",
      "evaluation/Returns Std                125.767\n",
      "evaluation/Returns Max               3612.61\n",
      "evaluation/Returns Min               3132.43\n",
      "evaluation/Estimation Bias Mean      1075.18\n",
      "evaluation/Estimation Bias Std        245.255\n",
      "evaluation/EB/Q_True Mean              33.2132\n",
      "evaluation/EB/Q_True Std              101.822\n",
      "evaluation/EB/Q_Pred Mean            1108.4\n",
      "evaluation/EB/Q_Pred Std              208.254\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3500.9\n",
      "evaluation/Actions Mean                 0.0399182\n",
      "evaluation/Actions Std                  0.581643\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67195\n",
      "time/backward_zf1 (s)                   1.79703\n",
      "time/backward_zf2 (s)                   1.72305\n",
      "time/data sampling (s)                  0.214161\n",
      "time/data storing (s)                   0.0139538\n",
      "time/evaluation sampling (s)            1.37381\n",
      "time/exploration sampling (s)           0.167676\n",
      "time/logging (s)                        0.0120777\n",
      "time/preback_alpha (s)                  0.542705\n",
      "time/preback_policy (s)                 0.593066\n",
      "time/preback_start (s)                  0.12138\n",
      "time/preback_zf (s)                     4.93286\n",
      "time/saving (s)                         0.0054874\n",
      "time/training (s)                       2.63697\n",
      "time/epoch (s)                         15.8062\n",
      "time/total (s)                       1704.74\n",
      "Epoch                                 110\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:29:51.874672 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 111 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 122000\n",
      "trainer/ZF1 Loss                      279.687\n",
      "trainer/ZF2 Loss                      284.29\n",
      "trainer/ZF Expert Reward               22.5825\n",
      "trainer/ZF Policy Reward                4.02132\n",
      "trainer/ZF CHI2 Term                  314.047\n",
      "trainer/Policy Loss                  -852.154\n",
      "trainer/Policy Grad Norm              448.691\n",
      "trainer/Policy Param Norm              35.9648\n",
      "trainer/Zf1 Grad Norm               17139.5\n",
      "trainer/Zf1 Param Norm                 92.3893\n",
      "trainer/Zf2 Grad Norm               19679.8\n",
      "trainer/Zf2 Param Norm                 90.2745\n",
      "trainer/Z Expert Predictions Mean    1121.57\n",
      "trainer/Z Expert Predictions Std      166.596\n",
      "trainer/Z Expert Predictions Max     1396.91\n",
      "trainer/Z Expert Predictions Min      672.216\n",
      "trainer/Z Policy Predictions Mean     847.104\n",
      "trainer/Z Policy Predictions Std      395.659\n",
      "trainer/Z Policy Predictions Max     1325.99\n",
      "trainer/Z Policy Predictions Min     -715.031\n",
      "trainer/Z Expert Targets Mean        1098.98\n",
      "trainer/Z Expert Targets Std          179.523\n",
      "trainer/Z Expert Targets Max         1378.29\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         843.082\n",
      "trainer/Z Policy Targets Std          394.313\n",
      "trainer/Z Policy Targets Max         1326.85\n",
      "trainer/Z Policy Targets Min         -767.998\n",
      "trainer/Log Pis Mean                   13.6342\n",
      "trainer/Log Pis Std                     5.65497\n",
      "trainer/Policy mu Mean                  0.325158\n",
      "trainer/Policy mu Std                   2.62406\n",
      "trainer/Policy log std Mean            -3.93038\n",
      "trainer/Policy log std Std              1.12588\n",
      "exploration/num steps total        118265\n",
      "exploration/num paths total           922\n",
      "evaluation/num steps total         723042\n",
      "evaluation/num paths total           1131\n",
      "evaluation/path length Mean           652\n",
      "evaluation/path length Std            225.989\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            456\n",
      "evaluation/Rewards Mean                 3.56317\n",
      "evaluation/Rewards Std                  0.699596\n",
      "evaluation/Rewards Max                  5.44631\n",
      "evaluation/Rewards Min                  0.670778\n",
      "evaluation/Returns Mean              2323.19\n",
      "evaluation/Returns Std                816.198\n",
      "evaluation/Returns Max               3589.77\n",
      "evaluation/Returns Min               1628.06\n",
      "evaluation/Estimation Bias Mean       909.374\n",
      "evaluation/Estimation Bias Std        447.99\n",
      "evaluation/EB/Q_True Mean              42.1145\n",
      "evaluation/EB/Q_True Std              112.895\n",
      "evaluation/EB/Q_Pred Mean             951.489\n",
      "evaluation/EB/Q_Pred Std              418.094\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2323.19\n",
      "evaluation/Actions Mean                 0.0473241\n",
      "evaluation/Actions Std                  0.59956\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67178\n",
      "time/backward_zf1 (s)                   1.79154\n",
      "time/backward_zf2 (s)                   1.72347\n",
      "time/data sampling (s)                  0.237792\n",
      "time/data storing (s)                   0.0137006\n",
      "time/evaluation sampling (s)            1.41332\n",
      "time/exploration sampling (s)           0.167759\n",
      "time/logging (s)                        0.00961378\n",
      "time/preback_alpha (s)                  0.536554\n",
      "time/preback_policy (s)                 0.591049\n",
      "time/preback_start (s)                  0.120643\n",
      "time/preback_zf (s)                     4.92494\n",
      "time/saving (s)                         0.00517073\n",
      "time/training (s)                       2.61222\n",
      "time/epoch (s)                         15.8196\n",
      "time/total (s)                       1720.59\n",
      "Epoch                                 111\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:30:07.272856 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 112 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 123000\n",
      "trainer/ZF1 Loss                       26.4106\n",
      "trainer/ZF2 Loss                       29.4098\n",
      "trainer/ZF Expert Reward               13.0812\n",
      "trainer/ZF Policy Reward               -2.25668\n",
      "trainer/ZF CHI2 Term                   56.4496\n",
      "trainer/Policy Loss                  -839.807\n",
      "trainer/Policy Grad Norm              404.792\n",
      "trainer/Policy Param Norm              36.0408\n",
      "trainer/Zf1 Grad Norm                9033.05\n",
      "trainer/Zf1 Param Norm                 92.7561\n",
      "trainer/Zf2 Grad Norm               10094.9\n",
      "trainer/Zf2 Param Norm                 90.6016\n",
      "trainer/Z Expert Predictions Mean    1137.41\n",
      "trainer/Z Expert Predictions Std      149.016\n",
      "trainer/Z Expert Predictions Max     1414.44\n",
      "trainer/Z Expert Predictions Min      666.417\n",
      "trainer/Z Policy Predictions Mean     834.445\n",
      "trainer/Z Policy Predictions Std      382.254\n",
      "trainer/Z Policy Predictions Max     1348.08\n",
      "trainer/Z Policy Predictions Min     -393.646\n",
      "trainer/Z Expert Targets Mean        1124.33\n",
      "trainer/Z Expert Targets Std          148.504\n",
      "trainer/Z Expert Targets Max         1385.78\n",
      "trainer/Z Expert Targets Min          664.799\n",
      "trainer/Z Policy Targets Mean         836.701\n",
      "trainer/Z Policy Targets Std          376.133\n",
      "trainer/Z Policy Targets Max         1349.33\n",
      "trainer/Z Policy Targets Min         -362.33\n",
      "trainer/Log Pis Mean                   13.3348\n",
      "trainer/Log Pis Std                     5.30207\n",
      "trainer/Policy mu Mean                  0.244598\n",
      "trainer/Policy mu Std                   2.61969\n",
      "trainer/Policy log std Mean            -3.68921\n",
      "trainer/Policy log std Std              1.12997\n",
      "exploration/num steps total        120365\n",
      "exploration/num paths total           926\n",
      "evaluation/num steps total         726457\n",
      "evaluation/num paths total           1141\n",
      "evaluation/path length Mean           341.5\n",
      "evaluation/path length Std             29.9775\n",
      "evaluation/path length Max            395\n",
      "evaluation/path length Min            320\n",
      "evaluation/Rewards Mean                 3.39735\n",
      "evaluation/Rewards Std                  0.869285\n",
      "evaluation/Rewards Max                  5.50195\n",
      "evaluation/Rewards Min                  0.690802\n",
      "evaluation/Returns Mean              1160.2\n",
      "evaluation/Returns Std                122.63\n",
      "evaluation/Returns Max               1358.8\n",
      "evaluation/Returns Min               1074.89\n",
      "evaluation/Estimation Bias Mean       692.092\n",
      "evaluation/Estimation Bias Std        557.342\n",
      "evaluation/EB/Q_True Mean              26.8367\n",
      "evaluation/EB/Q_True Std               80.8678\n",
      "evaluation/EB/Q_Pred Mean             718.928\n",
      "evaluation/EB/Q_Pred Std              558.907\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1160.2\n",
      "evaluation/Actions Mean                 0.0448831\n",
      "evaluation/Actions Std                  0.597076\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.6634\n",
      "time/backward_zf1 (s)                   1.79421\n",
      "time/backward_zf2 (s)                   1.72097\n",
      "time/data sampling (s)                  0.238301\n",
      "time/data storing (s)                   0.0142213\n",
      "time/evaluation sampling (s)            0.890481\n",
      "time/exploration sampling (s)           0.175951\n",
      "time/logging (s)                        0.00655466\n",
      "time/preback_alpha (s)                  0.542162\n",
      "time/preback_policy (s)                 0.594833\n",
      "time/preback_start (s)                  0.124222\n",
      "time/preback_zf (s)                     4.93597\n",
      "time/saving (s)                         0.00493639\n",
      "time/training (s)                       2.62412\n",
      "time/epoch (s)                         15.3303\n",
      "time/total (s)                       1735.94\n",
      "Epoch                                 112\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:30:22.472323 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 113 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 124000\n",
      "trainer/ZF1 Loss                       45.3905\n",
      "trainer/ZF2 Loss                       51.3615\n",
      "trainer/ZF Expert Reward                8.27226\n",
      "trainer/ZF Policy Reward               -5.33566\n",
      "trainer/ZF CHI2 Term                   75.5305\n",
      "trainer/Policy Loss                  -854.253\n",
      "trainer/Policy Grad Norm              671.43\n",
      "trainer/Policy Param Norm              36.1079\n",
      "trainer/Zf1 Grad Norm               12658.2\n",
      "trainer/Zf1 Param Norm                 93.1071\n",
      "trainer/Zf2 Grad Norm               21810.3\n",
      "trainer/Zf2 Param Norm                 90.9157\n",
      "trainer/Z Expert Predictions Mean    1156.02\n",
      "trainer/Z Expert Predictions Std      151.061\n",
      "trainer/Z Expert Predictions Max     1420.6\n",
      "trainer/Z Expert Predictions Min      668.39\n",
      "trainer/Z Policy Predictions Mean     837.843\n",
      "trainer/Z Policy Predictions Std      379.726\n",
      "trainer/Z Policy Predictions Max     1327.86\n",
      "trainer/Z Policy Predictions Min     -366.169\n",
      "trainer/Z Expert Targets Mean        1147.75\n",
      "trainer/Z Expert Targets Std          148.892\n",
      "trainer/Z Expert Targets Max         1416.67\n",
      "trainer/Z Expert Targets Min          660.327\n",
      "trainer/Z Policy Targets Mean         843.179\n",
      "trainer/Z Policy Targets Std          378.862\n",
      "trainer/Z Policy Targets Max         1321.32\n",
      "trainer/Z Policy Targets Min         -378.807\n",
      "trainer/Log Pis Mean                   13.6834\n",
      "trainer/Log Pis Std                     5.52435\n",
      "trainer/Policy mu Mean                  0.433618\n",
      "trainer/Policy mu Std                   2.56784\n",
      "trainer/Policy log std Mean            -3.90522\n",
      "trainer/Policy log std Std              1.18759\n",
      "exploration/num steps total        120365\n",
      "exploration/num paths total           926\n",
      "evaluation/num steps total         730428\n",
      "evaluation/num paths total           1151\n",
      "evaluation/path length Mean           397.1\n",
      "evaluation/path length Std             23.4327\n",
      "evaluation/path length Max            466\n",
      "evaluation/path length Min            380\n",
      "evaluation/Rewards Mean                 3.47575\n",
      "evaluation/Rewards Std                  0.848252\n",
      "evaluation/Rewards Max                  5.39521\n",
      "evaluation/Rewards Min                  0.68006\n",
      "evaluation/Returns Mean              1380.22\n",
      "evaluation/Returns Std                 88.6274\n",
      "evaluation/Returns Max               1644.16\n",
      "evaluation/Returns Min               1331.28\n",
      "evaluation/Estimation Bias Mean       690.705\n",
      "evaluation/Estimation Bias Std        560.486\n",
      "evaluation/EB/Q_True Mean              34.7974\n",
      "evaluation/EB/Q_True Std               99.5445\n",
      "evaluation/EB/Q_Pred Mean             725.503\n",
      "evaluation/EB/Q_Pred Std              552.128\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1380.22\n",
      "evaluation/Actions Mean                 0.041289\n",
      "evaluation/Actions Std                  0.613548\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67151\n",
      "time/backward_zf1 (s)                   1.77705\n",
      "time/backward_zf2 (s)                   1.70843\n",
      "time/data sampling (s)                  0.20949\n",
      "time/data storing (s)                   0.0134339\n",
      "time/evaluation sampling (s)            0.698878\n",
      "time/exploration sampling (s)           0.161643\n",
      "time/logging (s)                        0.00545605\n",
      "time/preback_alpha (s)                  0.540675\n",
      "time/preback_policy (s)                 0.58779\n",
      "time/preback_start (s)                  0.119682\n",
      "time/preback_zf (s)                     4.94488\n",
      "time/saving (s)                         0.00517587\n",
      "time/training (s)                       2.69\n",
      "time/epoch (s)                         15.1341\n",
      "time/total (s)                       1751.09\n",
      "Epoch                                 113\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:30:37.685059 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 114 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 125000\n",
      "trainer/ZF1 Loss                       25.5687\n",
      "trainer/ZF2 Loss                       44.9069\n",
      "trainer/ZF Expert Reward                4.42489\n",
      "trainer/ZF Policy Reward               -5.5507\n",
      "trainer/ZF CHI2 Term                   58.774\n",
      "trainer/Policy Loss                  -815.307\n",
      "trainer/Policy Grad Norm              393.001\n",
      "trainer/Policy Param Norm              36.1722\n",
      "trainer/Zf1 Grad Norm               19744.6\n",
      "trainer/Zf1 Param Norm                 93.4661\n",
      "trainer/Zf2 Grad Norm               31526.5\n",
      "trainer/Zf2 Param Norm                 91.2296\n",
      "trainer/Z Expert Predictions Mean    1133.68\n",
      "trainer/Z Expert Predictions Std      169.285\n",
      "trainer/Z Expert Predictions Max     1434.3\n",
      "trainer/Z Expert Predictions Min      646.216\n",
      "trainer/Z Policy Predictions Mean     809.141\n",
      "trainer/Z Policy Predictions Std      408.619\n",
      "trainer/Z Policy Predictions Max     1374.64\n",
      "trainer/Z Policy Predictions Min     -509.896\n",
      "trainer/Z Expert Targets Mean        1129.25\n",
      "trainer/Z Expert Targets Std          169.078\n",
      "trainer/Z Expert Targets Max         1426.43\n",
      "trainer/Z Expert Targets Min          644.132\n",
      "trainer/Z Policy Targets Mean         814.691\n",
      "trainer/Z Policy Targets Std          408.836\n",
      "trainer/Z Policy Targets Max         1376.5\n",
      "trainer/Z Policy Targets Min         -562.836\n",
      "trainer/Log Pis Mean                   13.6977\n",
      "trainer/Log Pis Std                     5.55228\n",
      "trainer/Policy mu Mean                  0.387332\n",
      "trainer/Policy mu Std                   2.84514\n",
      "trainer/Policy log std Mean            -3.72965\n",
      "trainer/Policy log std Std              1.1695\n",
      "exploration/num steps total        122309\n",
      "exploration/num paths total           929\n",
      "evaluation/num steps total         734458\n",
      "evaluation/num paths total           1161\n",
      "evaluation/path length Mean           403\n",
      "evaluation/path length Std             31.1962\n",
      "evaluation/path length Max            467\n",
      "evaluation/path length Min            382\n",
      "evaluation/Rewards Mean                 3.50098\n",
      "evaluation/Rewards Std                  0.859876\n",
      "evaluation/Rewards Max                  5.39673\n",
      "evaluation/Rewards Min                  0.68741\n",
      "evaluation/Returns Mean              1410.89\n",
      "evaluation/Returns Std                122.81\n",
      "evaluation/Returns Max               1660.36\n",
      "evaluation/Returns Min               1331.73\n",
      "evaluation/Estimation Bias Mean       731.909\n",
      "evaluation/Estimation Bias Std        532.646\n",
      "evaluation/EB/Q_True Mean              34.6429\n",
      "evaluation/EB/Q_True Std               99.8106\n",
      "evaluation/EB/Q_Pred Mean             766.552\n",
      "evaluation/EB/Q_Pred Std              524.72\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1410.89\n",
      "evaluation/Actions Mean                 0.0570372\n",
      "evaluation/Actions Std                  0.622091\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76472\n",
      "time/backward_zf1 (s)                   1.86847\n",
      "time/backward_zf2 (s)                   1.81508\n",
      "time/data sampling (s)                  0.235616\n",
      "time/data storing (s)                   0.0143228\n",
      "time/evaluation sampling (s)            0.688991\n",
      "time/exploration sampling (s)           0.172731\n",
      "time/logging (s)                        0.00881253\n",
      "time/preback_alpha (s)                  0.540768\n",
      "time/preback_policy (s)                 0.604213\n",
      "time/preback_start (s)                  0.121345\n",
      "time/preback_zf (s)                     4.91824\n",
      "time/saving (s)                         0.00526056\n",
      "time/training (s)                       2.39406\n",
      "time/epoch (s)                         15.1526\n",
      "time/total (s)                       1766.27\n",
      "Epoch                                 114\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:30:52.783338 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 115 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 126000\n",
      "trainer/ZF1 Loss                      144.453\n",
      "trainer/ZF2 Loss                      115.756\n",
      "trainer/ZF Expert Reward               15.8471\n",
      "trainer/ZF Policy Reward               -0.925779\n",
      "trainer/ZF CHI2 Term                  160.384\n",
      "trainer/Policy Loss                  -833.215\n",
      "trainer/Policy Grad Norm              631.366\n",
      "trainer/Policy Param Norm              36.2472\n",
      "trainer/Zf1 Grad Norm               12608.8\n",
      "trainer/Zf1 Param Norm                 93.8166\n",
      "trainer/Zf2 Grad Norm               16460.2\n",
      "trainer/Zf2 Param Norm                 91.5465\n",
      "trainer/Z Expert Predictions Mean    1151.72\n",
      "trainer/Z Expert Predictions Std      168.969\n",
      "trainer/Z Expert Predictions Max     1444.45\n",
      "trainer/Z Expert Predictions Min      614.484\n",
      "trainer/Z Policy Predictions Mean     824.996\n",
      "trainer/Z Policy Predictions Std      375.927\n",
      "trainer/Z Policy Predictions Max     1384.86\n",
      "trainer/Z Policy Predictions Min     -431.144\n",
      "trainer/Z Expert Targets Mean        1135.87\n",
      "trainer/Z Expert Targets Std          179.71\n",
      "trainer/Z Expert Targets Max         1442.06\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         825.922\n",
      "trainer/Z Policy Targets Std          373.827\n",
      "trainer/Z Policy Targets Max         1359.31\n",
      "trainer/Z Policy Targets Min         -417.374\n",
      "trainer/Log Pis Mean                   13.643\n",
      "trainer/Log Pis Std                     5.54589\n",
      "trainer/Policy mu Mean                  0.538708\n",
      "trainer/Policy mu Std                   2.82434\n",
      "trainer/Policy log std Mean            -3.69318\n",
      "trainer/Policy log std Std              1.20693\n",
      "exploration/num steps total        122856\n",
      "exploration/num paths total           930\n",
      "evaluation/num steps total         738433\n",
      "evaluation/num paths total           1171\n",
      "evaluation/path length Mean           397.5\n",
      "evaluation/path length Std             22.844\n",
      "evaluation/path length Max            465\n",
      "evaluation/path length Min            384\n",
      "evaluation/Rewards Mean                 3.49779\n",
      "evaluation/Rewards Std                  0.859871\n",
      "evaluation/Rewards Max                  5.29257\n",
      "evaluation/Rewards Min                  0.658571\n",
      "evaluation/Returns Mean              1390.37\n",
      "evaluation/Returns Std                 89.474\n",
      "evaluation/Returns Max               1657.17\n",
      "evaluation/Returns Min               1346.53\n",
      "evaluation/Estimation Bias Mean       654.847\n",
      "evaluation/Estimation Bias Std        585.287\n",
      "evaluation/EB/Q_True Mean              35.0586\n",
      "evaluation/EB/Q_True Std              100.428\n",
      "evaluation/EB/Q_Pred Mean             689.906\n",
      "evaluation/EB/Q_Pred Std              579.181\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1390.37\n",
      "evaluation/Actions Mean                 0.0417877\n",
      "evaluation/Actions Std                  0.607656\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.61188\n",
      "time/backward_zf1 (s)                   1.74296\n",
      "time/backward_zf2 (s)                   1.66653\n",
      "time/data sampling (s)                  0.232978\n",
      "time/data storing (s)                   0.0139662\n",
      "time/evaluation sampling (s)            0.679176\n",
      "time/exploration sampling (s)           0.169817\n",
      "time/logging (s)                        0.00574912\n",
      "time/preback_alpha (s)                  0.539732\n",
      "time/preback_policy (s)                 0.583408\n",
      "time/preback_start (s)                  0.121694\n",
      "time/preback_zf (s)                     4.93783\n",
      "time/saving (s)                         0.0172225\n",
      "time/training (s)                       2.70943\n",
      "time/epoch (s)                         15.0324\n",
      "time/total (s)                       1781.32\n",
      "Epoch                                 115\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:31:07.865933 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 116 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 127000\n",
      "trainer/ZF1 Loss                       44.1076\n",
      "trainer/ZF2 Loss                       30.0166\n",
      "trainer/ZF Expert Reward               13.2722\n",
      "trainer/ZF Policy Reward               -0.724816\n",
      "trainer/ZF CHI2 Term                   64.4055\n",
      "trainer/Policy Loss                  -844.087\n",
      "trainer/Policy Grad Norm              573.308\n",
      "trainer/Policy Param Norm              36.3248\n",
      "trainer/Zf1 Grad Norm               10130.1\n",
      "trainer/Zf1 Param Norm                 94.1825\n",
      "trainer/Zf2 Grad Norm                6500.46\n",
      "trainer/Zf2 Param Norm                 91.8787\n",
      "trainer/Z Expert Predictions Mean    1161.65\n",
      "trainer/Z Expert Predictions Std      160.347\n",
      "trainer/Z Expert Predictions Max     1419.47\n",
      "trainer/Z Expert Predictions Min      684.473\n",
      "trainer/Z Policy Predictions Mean     836.952\n",
      "trainer/Z Policy Predictions Std      407.383\n",
      "trainer/Z Policy Predictions Max     1386.62\n",
      "trainer/Z Policy Predictions Min     -486.148\n",
      "trainer/Z Expert Targets Mean        1148.37\n",
      "trainer/Z Expert Targets Std          161.622\n",
      "trainer/Z Expert Targets Max         1406.68\n",
      "trainer/Z Expert Targets Min          689.567\n",
      "trainer/Z Policy Targets Mean         837.677\n",
      "trainer/Z Policy Targets Std          405.112\n",
      "trainer/Z Policy Targets Max         1393.2\n",
      "trainer/Z Policy Targets Min         -504.218\n",
      "trainer/Log Pis Mean                   13.4813\n",
      "trainer/Log Pis Std                     5.54181\n",
      "trainer/Policy mu Mean                  0.578679\n",
      "trainer/Policy mu Std                   2.72624\n",
      "trainer/Policy log std Mean            -3.78534\n",
      "trainer/Policy log std Std              1.18336\n",
      "exploration/num steps total        124948\n",
      "exploration/num paths total           935\n",
      "evaluation/num steps total         741566\n",
      "evaluation/num paths total           1181\n",
      "evaluation/path length Mean           313.3\n",
      "evaluation/path length Std              0.640312\n",
      "evaluation/path length Max            314\n",
      "evaluation/path length Min            312\n",
      "evaluation/Rewards Mean                 3.34592\n",
      "evaluation/Rewards Std                  0.887555\n",
      "evaluation/Rewards Max                  4.91322\n",
      "evaluation/Rewards Min                  0.70946\n",
      "evaluation/Returns Mean              1048.28\n",
      "evaluation/Returns Std                  2.10399\n",
      "evaluation/Returns Max               1052.57\n",
      "evaluation/Returns Min               1044.44\n",
      "evaluation/Estimation Bias Mean       712.918\n",
      "evaluation/Estimation Bias Std        571.471\n",
      "evaluation/EB/Q_True Mean              25.487\n",
      "evaluation/EB/Q_True Std               80.5771\n",
      "evaluation/EB/Q_Pred Mean             738.405\n",
      "evaluation/EB/Q_Pred Std              572.362\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1048.28\n",
      "evaluation/Actions Mean                 0.0502744\n",
      "evaluation/Actions Std                  0.60466\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78334\n",
      "time/backward_zf1 (s)                   1.88748\n",
      "time/backward_zf2 (s)                   1.83527\n",
      "time/data sampling (s)                  0.234123\n",
      "time/data storing (s)                   0.0135698\n",
      "time/evaluation sampling (s)            0.49931\n",
      "time/exploration sampling (s)           0.1728\n",
      "time/logging (s)                        0.00550472\n",
      "time/preback_alpha (s)                  0.540194\n",
      "time/preback_policy (s)                 0.607116\n",
      "time/preback_start (s)                  0.122158\n",
      "time/preback_zf (s)                     4.93212\n",
      "time/saving (s)                         0.00497011\n",
      "time/training (s)                       2.38398\n",
      "time/epoch (s)                         15.0219\n",
      "time/total (s)                       1796.36\n",
      "Epoch                                 116\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:31:23.976293 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 117 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 128000\n",
      "trainer/ZF1 Loss                       56.7856\n",
      "trainer/ZF2 Loss                       70.3133\n",
      "trainer/ZF Expert Reward               22.5511\n",
      "trainer/ZF Policy Reward                5.12572\n",
      "trainer/ZF CHI2 Term                   94.6945\n",
      "trainer/Policy Loss                  -815.461\n",
      "trainer/Policy Grad Norm              547.504\n",
      "trainer/Policy Param Norm              36.4202\n",
      "trainer/Zf1 Grad Norm               14179\n",
      "trainer/Zf1 Param Norm                 94.5432\n",
      "trainer/Zf2 Grad Norm               25415.5\n",
      "trainer/Zf2 Param Norm                 92.2205\n",
      "trainer/Z Expert Predictions Mean    1200.17\n",
      "trainer/Z Expert Predictions Std      147.406\n",
      "trainer/Z Expert Predictions Max     1465.72\n",
      "trainer/Z Expert Predictions Min      679.808\n",
      "trainer/Z Policy Predictions Mean     806.996\n",
      "trainer/Z Policy Predictions Std      426.059\n",
      "trainer/Z Policy Predictions Max     1415.7\n",
      "trainer/Z Policy Predictions Min     -743.227\n",
      "trainer/Z Expert Targets Mean        1177.62\n",
      "trainer/Z Expert Targets Std          147.881\n",
      "trainer/Z Expert Targets Max         1457.26\n",
      "trainer/Z Expert Targets Min          672.62\n",
      "trainer/Z Policy Targets Mean         801.87\n",
      "trainer/Z Policy Targets Std          419.237\n",
      "trainer/Z Policy Targets Max         1386.62\n",
      "trainer/Z Policy Targets Min         -737.318\n",
      "trainer/Log Pis Mean                   13.8582\n",
      "trainer/Log Pis Std                     5.68774\n",
      "trainer/Policy mu Mean                  0.474923\n",
      "trainer/Policy mu Std                   2.98285\n",
      "trainer/Policy log std Mean            -3.75412\n",
      "trainer/Policy log std Std              1.24074\n",
      "exploration/num steps total        125273\n",
      "exploration/num paths total           936\n",
      "evaluation/num steps total         751566\n",
      "evaluation/num paths total           1191\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52634\n",
      "evaluation/Rewards Std                  0.580502\n",
      "evaluation/Rewards Max                  4.5722\n",
      "evaluation/Rewards Min                  0.621221\n",
      "evaluation/Returns Mean              3526.34\n",
      "evaluation/Returns Std                  5.49156\n",
      "evaluation/Returns Max               3536.05\n",
      "evaluation/Returns Min               3518.47\n",
      "evaluation/Estimation Bias Mean      1120.24\n",
      "evaluation/Estimation Bias Std        160.264\n",
      "evaluation/EB/Q_True Mean              32.5711\n",
      "evaluation/EB/Q_True Std              100.352\n",
      "evaluation/EB/Q_Pred Mean            1152.81\n",
      "evaluation/EB/Q_Pred Std              126.436\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3526.34\n",
      "evaluation/Actions Mean                 0.0315531\n",
      "evaluation/Actions Std                  0.574048\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.84644\n",
      "time/backward_zf1 (s)                   1.93575\n",
      "time/backward_zf2 (s)                   1.89035\n",
      "time/data sampling (s)                  0.235663\n",
      "time/data storing (s)                   0.0141935\n",
      "time/evaluation sampling (s)            1.45078\n",
      "time/exploration sampling (s)           0.168723\n",
      "time/logging (s)                        0.0120161\n",
      "time/preback_alpha (s)                  0.541448\n",
      "time/preback_policy (s)                 0.6125\n",
      "time/preback_start (s)                  0.120703\n",
      "time/preback_zf (s)                     4.95315\n",
      "time/saving (s)                         0.00633069\n",
      "time/training (s)                       2.26766\n",
      "time/epoch (s)                         16.0557\n",
      "time/total (s)                       1812.43\n",
      "Epoch                                 117\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:31:40.061743 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 118 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 129000\n",
      "trainer/ZF1 Loss                       45.3782\n",
      "trainer/ZF2 Loss                       46.3737\n",
      "trainer/ZF Expert Reward               11.5877\n",
      "trainer/ZF Policy Reward               -1.62539\n",
      "trainer/ZF CHI2 Term                   73.5296\n",
      "trainer/Policy Loss                  -821.53\n",
      "trainer/Policy Grad Norm              436.209\n",
      "trainer/Policy Param Norm              36.5012\n",
      "trainer/Zf1 Grad Norm                7804.72\n",
      "trainer/Zf1 Param Norm                 94.8777\n",
      "trainer/Zf2 Grad Norm               12129.3\n",
      "trainer/Zf2 Param Norm                 92.5295\n",
      "trainer/Z Expert Predictions Mean    1154.11\n",
      "trainer/Z Expert Predictions Std      163.449\n",
      "trainer/Z Expert Predictions Max     1462.56\n",
      "trainer/Z Expert Predictions Min      683.847\n",
      "trainer/Z Policy Predictions Mean     807.365\n",
      "trainer/Z Policy Predictions Std      436.644\n",
      "trainer/Z Policy Predictions Max     1383.57\n",
      "trainer/Z Policy Predictions Min     -423.819\n",
      "trainer/Z Expert Targets Mean        1142.53\n",
      "trainer/Z Expert Targets Std          164.489\n",
      "trainer/Z Expert Targets Max         1430.63\n",
      "trainer/Z Expert Targets Min          685.719\n",
      "trainer/Z Policy Targets Mean         808.991\n",
      "trainer/Z Policy Targets Std          435.584\n",
      "trainer/Z Policy Targets Max         1373.68\n",
      "trainer/Z Policy Targets Min         -433.597\n",
      "trainer/Log Pis Mean                   14.5864\n",
      "trainer/Log Pis Std                     5.88587\n",
      "trainer/Policy mu Mean                  0.655059\n",
      "trainer/Policy mu Std                   3.24585\n",
      "trainer/Policy log std Mean            -3.79094\n",
      "trainer/Policy log std Std              1.3212\n",
      "exploration/num steps total        126057\n",
      "exploration/num paths total           938\n",
      "evaluation/num steps total         759891\n",
      "evaluation/num paths total           1201\n",
      "evaluation/path length Mean           832.5\n",
      "evaluation/path length Std            256.471\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            396\n",
      "evaluation/Rewards Mean                 3.5798\n",
      "evaluation/Rewards Std                  0.644897\n",
      "evaluation/Rewards Max                  5.10024\n",
      "evaluation/Rewards Min                  0.604546\n",
      "evaluation/Returns Mean              2980.19\n",
      "evaluation/Returns Std                938.448\n",
      "evaluation/Returns Max               3641.73\n",
      "evaluation/Returns Min               1365.22\n",
      "evaluation/Estimation Bias Mean      1044.52\n",
      "evaluation/Estimation Bias Std        322.202\n",
      "evaluation/EB/Q_True Mean              40.1558\n",
      "evaluation/EB/Q_True Std              111.559\n",
      "evaluation/EB/Q_Pred Mean            1084.68\n",
      "evaluation/EB/Q_Pred Std              271.93\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2980.19\n",
      "evaluation/Actions Mean                 0.0411649\n",
      "evaluation/Actions Std                  0.591509\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85827\n",
      "time/backward_zf1 (s)                   1.95882\n",
      "time/backward_zf2 (s)                   1.9175\n",
      "time/data sampling (s)                  0.224211\n",
      "time/data storing (s)                   0.0137773\n",
      "time/evaluation sampling (s)            1.44315\n",
      "time/exploration sampling (s)           0.1671\n",
      "time/logging (s)                        0.00982224\n",
      "time/preback_alpha (s)                  0.537624\n",
      "time/preback_policy (s)                 0.619041\n",
      "time/preback_start (s)                  0.119402\n",
      "time/preback_zf (s)                     4.94253\n",
      "time/saving (s)                         0.00504095\n",
      "time/training (s)                       2.20131\n",
      "time/epoch (s)                         16.0176\n",
      "time/total (s)                       1828.47\n",
      "Epoch                                 118\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:31:56.111680 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 119 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 130000\n",
      "trainer/ZF1 Loss                       94.6406\n",
      "trainer/ZF2 Loss                       93.9324\n",
      "trainer/ZF Expert Reward               14.1851\n",
      "trainer/ZF Policy Reward               -3.62888\n",
      "trainer/ZF CHI2 Term                  125.133\n",
      "trainer/Policy Loss                  -844.498\n",
      "trainer/Policy Grad Norm              669.962\n",
      "trainer/Policy Param Norm              36.5782\n",
      "trainer/Zf1 Grad Norm               20170.9\n",
      "trainer/Zf1 Param Norm                 95.1866\n",
      "trainer/Zf2 Grad Norm               17882.6\n",
      "trainer/Zf2 Param Norm                 92.824\n",
      "trainer/Z Expert Predictions Mean    1156.19\n",
      "trainer/Z Expert Predictions Std      158.875\n",
      "trainer/Z Expert Predictions Max     1423.27\n",
      "trainer/Z Expert Predictions Min      494.763\n",
      "trainer/Z Policy Predictions Mean     827.085\n",
      "trainer/Z Policy Predictions Std      423.814\n",
      "trainer/Z Policy Predictions Max     1384.69\n",
      "trainer/Z Policy Predictions Min     -600.784\n",
      "trainer/Z Expert Targets Mean        1142.01\n",
      "trainer/Z Expert Targets Std          170.212\n",
      "trainer/Z Expert Targets Max         1403.82\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         830.714\n",
      "trainer/Z Policy Targets Std          420.8\n",
      "trainer/Z Policy Targets Max         1368.71\n",
      "trainer/Z Policy Targets Min         -601.111\n",
      "trainer/Log Pis Mean                   13.1637\n",
      "trainer/Log Pis Std                     4.82294\n",
      "trainer/Policy mu Mean                  0.291346\n",
      "trainer/Policy mu Std                   2.51679\n",
      "trainer/Policy log std Mean            -3.87077\n",
      "trainer/Policy log std Std              1.05863\n",
      "exploration/num steps total        128492\n",
      "exploration/num paths total           943\n",
      "evaluation/num steps total         769255\n",
      "evaluation/num paths total           1211\n",
      "evaluation/path length Mean           936.4\n",
      "evaluation/path length Std            121.697\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            631\n",
      "evaluation/Rewards Mean                 3.5825\n",
      "evaluation/Rewards Std                  0.612807\n",
      "evaluation/Rewards Max                  5.07652\n",
      "evaluation/Rewards Min                  0.638428\n",
      "evaluation/Returns Mean              3354.65\n",
      "evaluation/Returns Std                437.551\n",
      "evaluation/Returns Max               3612.79\n",
      "evaluation/Returns Min               2242.67\n",
      "evaluation/Estimation Bias Mean      1085.97\n",
      "evaluation/Estimation Bias Std        285.098\n",
      "evaluation/EB/Q_True Mean              35.159\n",
      "evaluation/EB/Q_True Std              104.584\n",
      "evaluation/EB/Q_Pred Mean            1121.13\n",
      "evaluation/EB/Q_Pred Std              246.994\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3354.65\n",
      "evaluation/Actions Mean                 0.0426587\n",
      "evaluation/Actions Std                  0.589826\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.80485\n",
      "time/backward_zf1 (s)                   1.90884\n",
      "time/backward_zf2 (s)                   1.85208\n",
      "time/data sampling (s)                  0.236417\n",
      "time/data storing (s)                   0.0135344\n",
      "time/evaluation sampling (s)            1.46161\n",
      "time/exploration sampling (s)           0.173755\n",
      "time/logging (s)                        0.0125337\n",
      "time/preback_alpha (s)                  0.540277\n",
      "time/preback_policy (s)                 0.620299\n",
      "time/preback_start (s)                  0.121185\n",
      "time/preback_zf (s)                     4.9211\n",
      "time/saving (s)                         0.00520247\n",
      "time/training (s)                       2.31732\n",
      "time/epoch (s)                         15.989\n",
      "time/total (s)                       1844.48\n",
      "Epoch                                 119\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:32:11.228687 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 120 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 131000\n",
      "trainer/ZF1 Loss                       44.6317\n",
      "trainer/ZF2 Loss                       57.4081\n",
      "trainer/ZF Expert Reward               12.1443\n",
      "trainer/ZF Policy Reward               -1.26607\n",
      "trainer/ZF CHI2 Term                   78.3555\n",
      "trainer/Policy Loss                  -766.492\n",
      "trainer/Policy Grad Norm              482.462\n",
      "trainer/Policy Param Norm              36.649\n",
      "trainer/Zf1 Grad Norm                7558.97\n",
      "trainer/Zf1 Param Norm                 95.5248\n",
      "trainer/Zf2 Grad Norm               15627.6\n",
      "trainer/Zf2 Param Norm                 93.1462\n",
      "trainer/Z Expert Predictions Mean    1167.1\n",
      "trainer/Z Expert Predictions Std      163.268\n",
      "trainer/Z Expert Predictions Max     1482.1\n",
      "trainer/Z Expert Predictions Min      673.927\n",
      "trainer/Z Policy Predictions Mean     752.116\n",
      "trainer/Z Policy Predictions Std      422.858\n",
      "trainer/Z Policy Predictions Max     1371.51\n",
      "trainer/Z Policy Predictions Min     -417.985\n",
      "trainer/Z Expert Targets Mean        1154.95\n",
      "trainer/Z Expert Targets Std          161.859\n",
      "trainer/Z Expert Targets Max         1463.16\n",
      "trainer/Z Expert Targets Min          676.126\n",
      "trainer/Z Policy Targets Mean         753.382\n",
      "trainer/Z Policy Targets Std          421.331\n",
      "trainer/Z Policy Targets Max         1376.14\n",
      "trainer/Z Policy Targets Min         -393.104\n",
      "trainer/Log Pis Mean                   14.0659\n",
      "trainer/Log Pis Std                     5.89306\n",
      "trainer/Policy mu Mean                  0.493296\n",
      "trainer/Policy mu Std                   2.87996\n",
      "trainer/Policy log std Mean            -3.7825\n",
      "trainer/Policy log std Std              1.21793\n",
      "exploration/num steps total        129243\n",
      "exploration/num paths total           945\n",
      "evaluation/num steps total         772961\n",
      "evaluation/num paths total           1221\n",
      "evaluation/path length Mean           370.6\n",
      "evaluation/path length Std             23.4572\n",
      "evaluation/path length Max            386\n",
      "evaluation/path length Min            324\n",
      "evaluation/Rewards Mean                 3.43175\n",
      "evaluation/Rewards Std                  0.850779\n",
      "evaluation/Rewards Max                  5.63482\n",
      "evaluation/Rewards Min                  0.639653\n",
      "evaluation/Returns Mean              1271.81\n",
      "evaluation/Returns Std                 98.049\n",
      "evaluation/Returns Max               1332.62\n",
      "evaluation/Returns Min               1076.87\n",
      "evaluation/Estimation Bias Mean       727.011\n",
      "evaluation/Estimation Bias Std        527.048\n",
      "evaluation/EB/Q_True Mean              28.9337\n",
      "evaluation/EB/Q_True Std               89.0769\n",
      "evaluation/EB/Q_Pred Mean             755.944\n",
      "evaluation/EB/Q_Pred Std              527.087\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1271.81\n",
      "evaluation/Actions Mean                 0.0550295\n",
      "evaluation/Actions Std                  0.626055\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67711\n",
      "time/backward_zf1 (s)                   1.783\n",
      "time/backward_zf2 (s)                   1.72596\n",
      "time/data sampling (s)                  0.237204\n",
      "time/data storing (s)                   0.0139072\n",
      "time/evaluation sampling (s)            0.580181\n",
      "time/exploration sampling (s)           0.169498\n",
      "time/logging (s)                        0.00502241\n",
      "time/preback_alpha (s)                  0.539974\n",
      "time/preback_policy (s)                 0.597278\n",
      "time/preback_start (s)                  0.120492\n",
      "time/preback_zf (s)                     4.93331\n",
      "time/saving (s)                         0.00481015\n",
      "time/training (s)                       2.6599\n",
      "time/epoch (s)                         15.0477\n",
      "time/total (s)                       1859.54\n",
      "Epoch                                 120\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:32:26.547962 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 121 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 132000\n",
      "trainer/ZF1 Loss                       75.942\n",
      "trainer/ZF2 Loss                       82.2258\n",
      "trainer/ZF Expert Reward               14.8441\n",
      "trainer/ZF Policy Reward                1.16102\n",
      "trainer/ZF CHI2 Term                  106.023\n",
      "trainer/Policy Loss                  -879.663\n",
      "trainer/Policy Grad Norm              451.009\n",
      "trainer/Policy Param Norm              36.7378\n",
      "trainer/Zf1 Grad Norm               13520.3\n",
      "trainer/Zf1 Param Norm                 95.8323\n",
      "trainer/Zf2 Grad Norm               11663.2\n",
      "trainer/Zf2 Param Norm                 93.4384\n",
      "trainer/Z Expert Predictions Mean    1189.53\n",
      "trainer/Z Expert Predictions Std      161.863\n",
      "trainer/Z Expert Predictions Max     1472.87\n",
      "trainer/Z Expert Predictions Min      678.293\n",
      "trainer/Z Policy Predictions Mean     872.604\n",
      "trainer/Z Policy Predictions Std      364.453\n",
      "trainer/Z Policy Predictions Max     1398.55\n",
      "trainer/Z Policy Predictions Min     -410.699\n",
      "trainer/Z Expert Targets Mean        1174.69\n",
      "trainer/Z Expert Targets Std          160.773\n",
      "trainer/Z Expert Targets Max         1458.96\n",
      "trainer/Z Expert Targets Min          674.023\n",
      "trainer/Z Policy Targets Mean         871.443\n",
      "trainer/Z Policy Targets Std          363.913\n",
      "trainer/Z Policy Targets Max         1388.38\n",
      "trainer/Z Policy Targets Min         -386.755\n",
      "trainer/Log Pis Mean                   13.3903\n",
      "trainer/Log Pis Std                     4.86329\n",
      "trainer/Policy mu Mean                  0.529446\n",
      "trainer/Policy mu Std                   2.65888\n",
      "trainer/Policy log std Mean            -3.80904\n",
      "trainer/Policy log std Std              1.15398\n",
      "exploration/num steps total        129629\n",
      "exploration/num paths total           946\n",
      "evaluation/num steps total         777016\n",
      "evaluation/num paths total           1231\n",
      "evaluation/path length Mean           405.5\n",
      "evaluation/path length Std             29.5271\n",
      "evaluation/path length Max            460\n",
      "evaluation/path length Min            383\n",
      "evaluation/Rewards Mean                 3.4877\n",
      "evaluation/Rewards Std                  0.841214\n",
      "evaluation/Rewards Max                  6.20417\n",
      "evaluation/Rewards Min                  0.6491\n",
      "evaluation/Returns Mean              1414.26\n",
      "evaluation/Returns Std                119.154\n",
      "evaluation/Returns Max               1628.05\n",
      "evaluation/Returns Min               1326.85\n",
      "evaluation/Estimation Bias Mean       699.976\n",
      "evaluation/Estimation Bias Std        504.034\n",
      "evaluation/EB/Q_True Mean              33.61\n",
      "evaluation/EB/Q_True Std               98.2535\n",
      "evaluation/EB/Q_Pred Mean             733.586\n",
      "evaluation/EB/Q_Pred Std              497.8\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1414.26\n",
      "evaluation/Actions Mean                 0.0619103\n",
      "evaluation/Actions Std                  0.627788\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83437\n",
      "time/backward_zf1 (s)                   1.92564\n",
      "time/backward_zf2 (s)                   1.88412\n",
      "time/data sampling (s)                  0.227865\n",
      "time/data storing (s)                   0.0132751\n",
      "time/evaluation sampling (s)            0.678812\n",
      "time/exploration sampling (s)           0.162629\n",
      "time/logging (s)                        0.00551181\n",
      "time/preback_alpha (s)                  0.541066\n",
      "time/preback_policy (s)                 0.62146\n",
      "time/preback_start (s)                  0.118127\n",
      "time/preback_zf (s)                     4.95162\n",
      "time/saving (s)                         0.00481606\n",
      "time/training (s)                       2.28888\n",
      "time/epoch (s)                         15.2582\n",
      "time/total (s)                       1874.82\n",
      "Epoch                                 121\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:32:42.411112 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 122 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 133000\n",
      "trainer/ZF1 Loss                      132.183\n",
      "trainer/ZF2 Loss                      140.188\n",
      "trainer/ZF Expert Reward               14.9813\n",
      "trainer/ZF Policy Reward                4.24534\n",
      "trainer/ZF CHI2 Term                  159.903\n",
      "trainer/Policy Loss                  -914.817\n",
      "trainer/Policy Grad Norm              692.629\n",
      "trainer/Policy Param Norm              36.8182\n",
      "trainer/Zf1 Grad Norm               19847.1\n",
      "trainer/Zf1 Param Norm                 96.1451\n",
      "trainer/Zf2 Grad Norm               23577.2\n",
      "trainer/Zf2 Param Norm                 93.7548\n",
      "trainer/Z Expert Predictions Mean    1175.56\n",
      "trainer/Z Expert Predictions Std      178.838\n",
      "trainer/Z Expert Predictions Max     1475.71\n",
      "trainer/Z Expert Predictions Min      459.075\n",
      "trainer/Z Policy Predictions Mean     904.92\n",
      "trainer/Z Policy Predictions Std      376.642\n",
      "trainer/Z Policy Predictions Max     1422.12\n",
      "trainer/Z Policy Predictions Min     -431.409\n",
      "trainer/Z Expert Targets Mean        1160.58\n",
      "trainer/Z Expert Targets Std          175.626\n",
      "trainer/Z Expert Targets Max         1486.68\n",
      "trainer/Z Expert Targets Min          669.99\n",
      "trainer/Z Policy Targets Mean         900.675\n",
      "trainer/Z Policy Targets Std          370.142\n",
      "trainer/Z Policy Targets Max         1400.98\n",
      "trainer/Z Policy Targets Min         -395.5\n",
      "trainer/Log Pis Mean                   13.113\n",
      "trainer/Log Pis Std                     5.1372\n",
      "trainer/Policy mu Mean                  0.526436\n",
      "trainer/Policy mu Std                   2.56312\n",
      "trainer/Policy log std Mean            -3.78342\n",
      "trainer/Policy log std Std              1.12964\n",
      "exploration/num steps total        130385\n",
      "exploration/num paths total           948\n",
      "evaluation/num steps total         785910\n",
      "evaluation/num paths total           1242\n",
      "evaluation/path length Mean           808.545\n",
      "evaluation/path length Std            253.357\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            462\n",
      "evaluation/Rewards Mean                 3.56586\n",
      "evaluation/Rewards Std                  0.64757\n",
      "evaluation/Rewards Max                  5.05312\n",
      "evaluation/Rewards Min                  0.593325\n",
      "evaluation/Returns Mean              2883.16\n",
      "evaluation/Returns Std                912.666\n",
      "evaluation/Returns Max               3601.82\n",
      "evaluation/Returns Min               1630.81\n",
      "evaluation/Estimation Bias Mean      1006.31\n",
      "evaluation/Estimation Bias Std        382.451\n",
      "evaluation/EB/Q_True Mean              37.0991\n",
      "evaluation/EB/Q_True Std              107.11\n",
      "evaluation/EB/Q_Pred Mean            1043.41\n",
      "evaluation/EB/Q_Pred Std              335.155\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2883.16\n",
      "evaluation/Actions Mean                 0.0436265\n",
      "evaluation/Actions Std                  0.594343\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67154\n",
      "time/backward_zf1 (s)                   1.78417\n",
      "time/backward_zf2 (s)                   1.72078\n",
      "time/data sampling (s)                  0.228975\n",
      "time/data storing (s)                   0.0138676\n",
      "time/evaluation sampling (s)            1.36925\n",
      "time/exploration sampling (s)           0.168048\n",
      "time/logging (s)                        0.0107327\n",
      "time/preback_alpha (s)                  0.539251\n",
      "time/preback_policy (s)                 0.592209\n",
      "time/preback_start (s)                  0.121329\n",
      "time/preback_zf (s)                     4.94506\n",
      "time/saving (s)                         0.00518571\n",
      "time/training (s)                       2.63739\n",
      "time/epoch (s)                         15.8078\n",
      "time/total (s)                       1890.64\n",
      "Epoch                                 122\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:32:57.582165 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 123 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 134000\n",
      "trainer/ZF1 Loss                       70.2818\n",
      "trainer/ZF2 Loss                       54.0383\n",
      "trainer/ZF Expert Reward                6.40262\n",
      "trainer/ZF Policy Reward               -7.04928\n",
      "trainer/ZF CHI2 Term                   89.6566\n",
      "trainer/Policy Loss                  -791.001\n",
      "trainer/Policy Grad Norm              344.776\n",
      "trainer/Policy Param Norm              36.8951\n",
      "trainer/Zf1 Grad Norm               38430.1\n",
      "trainer/Zf1 Param Norm                 96.4696\n",
      "trainer/Zf2 Grad Norm               15233.2\n",
      "trainer/Zf2 Param Norm                 94.0853\n",
      "trainer/Z Expert Predictions Mean    1171.26\n",
      "trainer/Z Expert Predictions Std      174.652\n",
      "trainer/Z Expert Predictions Max     1504.77\n",
      "trainer/Z Expert Predictions Min      628.825\n",
      "trainer/Z Policy Predictions Mean     774.639\n",
      "trainer/Z Policy Predictions Std      453.28\n",
      "trainer/Z Policy Predictions Max     1414.34\n",
      "trainer/Z Policy Predictions Min     -357.065\n",
      "trainer/Z Expert Targets Mean        1164.86\n",
      "trainer/Z Expert Targets Std          175.115\n",
      "trainer/Z Expert Targets Max         1504.09\n",
      "trainer/Z Expert Targets Min          584.835\n",
      "trainer/Z Policy Targets Mean         781.689\n",
      "trainer/Z Policy Targets Std          449.537\n",
      "trainer/Z Policy Targets Max         1423.01\n",
      "trainer/Z Policy Targets Min         -298.457\n",
      "trainer/Log Pis Mean                   14.1865\n",
      "trainer/Log Pis Std                     5.50583\n",
      "trainer/Policy mu Mean                  0.558499\n",
      "trainer/Policy mu Std                   2.83269\n",
      "trainer/Policy log std Mean            -3.68246\n",
      "trainer/Policy log std Std              1.20503\n",
      "exploration/num steps total        130844\n",
      "exploration/num paths total           949\n",
      "evaluation/num steps total         789639\n",
      "evaluation/num paths total           1252\n",
      "evaluation/path length Mean           372.9\n",
      "evaluation/path length Std              6.34744\n",
      "evaluation/path length Max            385\n",
      "evaluation/path length Min            367\n",
      "evaluation/Rewards Mean                 3.45193\n",
      "evaluation/Rewards Std                  0.882965\n",
      "evaluation/Rewards Max                  5.76393\n",
      "evaluation/Rewards Min                  0.632129\n",
      "evaluation/Returns Mean              1287.22\n",
      "evaluation/Returns Std                 25.4473\n",
      "evaluation/Returns Max               1332.67\n",
      "evaluation/Returns Min               1263.22\n",
      "evaluation/Estimation Bias Mean       695.219\n",
      "evaluation/Estimation Bias Std        544.881\n",
      "evaluation/EB/Q_True Mean              28.6839\n",
      "evaluation/EB/Q_True Std               88.8037\n",
      "evaluation/EB/Q_Pred Mean             723.903\n",
      "evaluation/EB/Q_Pred Std              543.357\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1287.22\n",
      "evaluation/Actions Mean                 0.0684493\n",
      "evaluation/Actions Std                  0.639574\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81867\n",
      "time/backward_zf1 (s)                   1.91358\n",
      "time/backward_zf2 (s)                   1.86858\n",
      "time/data sampling (s)                  0.243916\n",
      "time/data storing (s)                   0.0135348\n",
      "time/evaluation sampling (s)            0.549251\n",
      "time/exploration sampling (s)           0.166552\n",
      "time/logging (s)                        0.00651579\n",
      "time/preback_alpha (s)                  0.545748\n",
      "time/preback_policy (s)                 0.620054\n",
      "time/preback_start (s)                  0.121264\n",
      "time/preback_zf (s)                     4.95375\n",
      "time/saving (s)                         0.0047683\n",
      "time/training (s)                       2.27953\n",
      "time/epoch (s)                         15.1057\n",
      "time/total (s)                       1905.77\n",
      "Epoch                                 123\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:33:12.778272 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 124 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 135000\n",
      "trainer/ZF1 Loss                       33.822\n",
      "trainer/ZF2 Loss                       33.3199\n",
      "trainer/ZF Expert Reward               12.2808\n",
      "trainer/ZF Policy Reward               -1.85954\n",
      "trainer/ZF CHI2 Term                   62.3848\n",
      "trainer/Policy Loss                  -831.457\n",
      "trainer/Policy Grad Norm              654.813\n",
      "trainer/Policy Param Norm              36.9728\n",
      "trainer/Zf1 Grad Norm               11254.5\n",
      "trainer/Zf1 Param Norm                 96.8114\n",
      "trainer/Zf2 Grad Norm                9511.59\n",
      "trainer/Zf2 Param Norm                 94.4259\n",
      "trainer/Z Expert Predictions Mean    1172.56\n",
      "trainer/Z Expert Predictions Std      173.179\n",
      "trainer/Z Expert Predictions Max     1497.35\n",
      "trainer/Z Expert Predictions Min      652.386\n",
      "trainer/Z Policy Predictions Mean     824.129\n",
      "trainer/Z Policy Predictions Std      430.827\n",
      "trainer/Z Policy Predictions Max     1396.99\n",
      "trainer/Z Policy Predictions Min     -421.688\n",
      "trainer/Z Expert Targets Mean        1160.28\n",
      "trainer/Z Expert Targets Std          171.938\n",
      "trainer/Z Expert Targets Max         1495.01\n",
      "trainer/Z Expert Targets Min          540.27\n",
      "trainer/Z Policy Targets Mean         825.988\n",
      "trainer/Z Policy Targets Std          429.087\n",
      "trainer/Z Policy Targets Max         1427.07\n",
      "trainer/Z Policy Targets Min         -367.478\n",
      "trainer/Log Pis Mean                   14.8217\n",
      "trainer/Log Pis Std                     6.03621\n",
      "trainer/Policy mu Mean                  0.452266\n",
      "trainer/Policy mu Std                   2.83932\n",
      "trainer/Policy log std Mean            -3.93766\n",
      "trainer/Policy log std Std              1.21585\n",
      "exploration/num steps total        131698\n",
      "exploration/num paths total           951\n",
      "evaluation/num steps total         793108\n",
      "evaluation/num paths total           1262\n",
      "evaluation/path length Mean           346.9\n",
      "evaluation/path length Std             23.7\n",
      "evaluation/path length Max            371\n",
      "evaluation/path length Min            315\n",
      "evaluation/Rewards Mean                 3.38971\n",
      "evaluation/Rewards Std                  0.862158\n",
      "evaluation/Rewards Max                  5.4361\n",
      "evaluation/Rewards Min                  0.651908\n",
      "evaluation/Returns Mean              1175.89\n",
      "evaluation/Returns Std                 97.1578\n",
      "evaluation/Returns Max               1261.43\n",
      "evaluation/Returns Min               1047.13\n",
      "evaluation/Estimation Bias Mean       728.892\n",
      "evaluation/Estimation Bias Std        528.895\n",
      "evaluation/EB/Q_True Mean              28.9592\n",
      "evaluation/EB/Q_True Std               88.1323\n",
      "evaluation/EB/Q_Pred Mean             757.852\n",
      "evaluation/EB/Q_Pred Std              528.759\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1175.89\n",
      "evaluation/Actions Mean                 0.0658727\n",
      "evaluation/Actions Std                  0.624176\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81287\n",
      "time/backward_zf1 (s)                   1.89734\n",
      "time/backward_zf2 (s)                   1.85617\n",
      "time/data sampling (s)                  0.230477\n",
      "time/data storing (s)                   0.0133214\n",
      "time/evaluation sampling (s)            0.551076\n",
      "time/exploration sampling (s)           0.165452\n",
      "time/logging (s)                        0.0047391\n",
      "time/preback_alpha (s)                  0.536173\n",
      "time/preback_policy (s)                 0.609317\n",
      "time/preback_start (s)                  0.120087\n",
      "time/preback_zf (s)                     4.93022\n",
      "time/saving (s)                         0.00484236\n",
      "time/training (s)                       2.3948\n",
      "time/epoch (s)                         15.1269\n",
      "time/total (s)                       1920.92\n",
      "Epoch                                 124\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:33:28.620959 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 125 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 136000\n",
      "trainer/ZF1 Loss                       45.4678\n",
      "trainer/ZF2 Loss                       52.155\n",
      "trainer/ZF Expert Reward               13.0165\n",
      "trainer/ZF Policy Reward                1.34758\n",
      "trainer/ZF CHI2 Term                   74.6141\n",
      "trainer/Policy Loss                  -821.008\n",
      "trainer/Policy Grad Norm              541.698\n",
      "trainer/Policy Param Norm              37.0513\n",
      "trainer/Zf1 Grad Norm               37683.6\n",
      "trainer/Zf1 Param Norm                 97.1772\n",
      "trainer/Zf2 Grad Norm               26689.7\n",
      "trainer/Zf2 Param Norm                 94.7464\n",
      "trainer/Z Expert Predictions Mean    1178.53\n",
      "trainer/Z Expert Predictions Std      170.94\n",
      "trainer/Z Expert Predictions Max     1502.34\n",
      "trainer/Z Expert Predictions Min      638.452\n",
      "trainer/Z Policy Predictions Mean     809.636\n",
      "trainer/Z Policy Predictions Std      435.59\n",
      "trainer/Z Policy Predictions Max     1394.85\n",
      "trainer/Z Policy Predictions Min     -485.743\n",
      "trainer/Z Expert Targets Mean        1165.51\n",
      "trainer/Z Expert Targets Std          170.317\n",
      "trainer/Z Expert Targets Max         1473.8\n",
      "trainer/Z Expert Targets Min          616.824\n",
      "trainer/Z Policy Targets Mean         808.289\n",
      "trainer/Z Policy Targets Std          433.857\n",
      "trainer/Z Policy Targets Max         1376.43\n",
      "trainer/Z Policy Targets Min         -526.058\n",
      "trainer/Log Pis Mean                   14.2765\n",
      "trainer/Log Pis Std                     6.05301\n",
      "trainer/Policy mu Mean                  0.517823\n",
      "trainer/Policy mu Std                   3.06539\n",
      "trainer/Policy log std Mean            -3.72173\n",
      "trainer/Policy log std Std              1.27543\n",
      "exploration/num steps total        132065\n",
      "exploration/num paths total           952\n",
      "evaluation/num steps total         803108\n",
      "evaluation/num paths total           1272\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50492\n",
      "evaluation/Rewards Std                  0.588183\n",
      "evaluation/Rewards Max                  4.72118\n",
      "evaluation/Rewards Min                  0.614325\n",
      "evaluation/Returns Mean              3504.92\n",
      "evaluation/Returns Std                  3.13348\n",
      "evaluation/Returns Max               3512.64\n",
      "evaluation/Returns Min               3499.67\n",
      "evaluation/Estimation Bias Mean      1098.48\n",
      "evaluation/Estimation Bias Std        171.161\n",
      "evaluation/EB/Q_True Mean              32.4062\n",
      "evaluation/EB/Q_True Std               99.8949\n",
      "evaluation/EB/Q_Pred Mean            1130.89\n",
      "evaluation/EB/Q_Pred Std              143.574\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3504.92\n",
      "evaluation/Actions Mean                 0.0269073\n",
      "evaluation/Actions Std                  0.576804\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.61906\n",
      "time/backward_zf1 (s)                   1.74013\n",
      "time/backward_zf2 (s)                   1.66865\n",
      "time/data sampling (s)                  0.235027\n",
      "time/data storing (s)                   0.013677\n",
      "time/evaluation sampling (s)            1.33529\n",
      "time/exploration sampling (s)           0.170065\n",
      "time/logging (s)                        0.0120394\n",
      "time/preback_alpha (s)                  0.539564\n",
      "time/preback_policy (s)                 0.584671\n",
      "time/preback_start (s)                  0.120294\n",
      "time/preback_zf (s)                     4.94719\n",
      "time/saving (s)                         0.00522532\n",
      "time/training (s)                       2.8006\n",
      "time/epoch (s)                         15.7915\n",
      "time/total (s)                       1936.72\n",
      "Epoch                                 125\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:33:44.556135 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 126 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 137000\n",
      "trainer/ZF1 Loss                       63.9758\n",
      "trainer/ZF2 Loss                       48.2401\n",
      "trainer/ZF Expert Reward               14.0557\n",
      "trainer/ZF Policy Reward               -0.10206\n",
      "trainer/ZF CHI2 Term                   83.9038\n",
      "trainer/Policy Loss                  -891.579\n",
      "trainer/Policy Grad Norm              870.547\n",
      "trainer/Policy Param Norm              37.1389\n",
      "trainer/Zf1 Grad Norm               19272.6\n",
      "trainer/Zf1 Param Norm                 97.5097\n",
      "trainer/Zf2 Grad Norm               18805.2\n",
      "trainer/Zf2 Param Norm                 95.0509\n",
      "trainer/Z Expert Predictions Mean    1193.68\n",
      "trainer/Z Expert Predictions Std      167.832\n",
      "trainer/Z Expert Predictions Max     1475.29\n",
      "trainer/Z Expert Predictions Min      597.776\n",
      "trainer/Z Policy Predictions Mean     873.458\n",
      "trainer/Z Policy Predictions Std      408.851\n",
      "trainer/Z Policy Predictions Max     1400.61\n",
      "trainer/Z Policy Predictions Min     -282.396\n",
      "trainer/Z Expert Targets Mean        1179.62\n",
      "trainer/Z Expert Targets Std          165.25\n",
      "trainer/Z Expert Targets Max         1473.72\n",
      "trainer/Z Expert Targets Min          597.965\n",
      "trainer/Z Policy Targets Mean         873.56\n",
      "trainer/Z Policy Targets Std          401.53\n",
      "trainer/Z Policy Targets Max         1382.49\n",
      "trainer/Z Policy Targets Min         -253.507\n",
      "trainer/Log Pis Mean                   13.7759\n",
      "trainer/Log Pis Std                     5.2887\n",
      "trainer/Policy mu Mean                  0.518157\n",
      "trainer/Policy mu Std                   2.64198\n",
      "trainer/Policy log std Mean            -3.95403\n",
      "trainer/Policy log std Std              1.15877\n",
      "exploration/num steps total        132065\n",
      "exploration/num paths total           952\n",
      "evaluation/num steps total         812071\n",
      "evaluation/num paths total           1282\n",
      "evaluation/path length Mean           896.3\n",
      "evaluation/path length Std            187.688\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            460\n",
      "evaluation/Rewards Mean                 3.57752\n",
      "evaluation/Rewards Std                  0.620135\n",
      "evaluation/Rewards Max                  5.58373\n",
      "evaluation/Rewards Min                  0.649293\n",
      "evaluation/Returns Mean              3206.53\n",
      "evaluation/Returns Std                683.734\n",
      "evaluation/Returns Max               3616.92\n",
      "evaluation/Returns Min               1608.29\n",
      "evaluation/Estimation Bias Mean      1023.13\n",
      "evaluation/Estimation Bias Std        368.086\n",
      "evaluation/EB/Q_True Mean              36.7696\n",
      "evaluation/EB/Q_True Std              106.648\n",
      "evaluation/EB/Q_Pred Mean            1059.9\n",
      "evaluation/EB/Q_Pred Std              333.088\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3206.53\n",
      "evaluation/Actions Mean                 0.0408571\n",
      "evaluation/Actions Std                  0.579678\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73004\n",
      "time/backward_zf1 (s)                   1.85155\n",
      "time/backward_zf2 (s)                   1.79763\n",
      "time/data sampling (s)                  0.224144\n",
      "time/data storing (s)                   0.0135013\n",
      "time/evaluation sampling (s)            1.37472\n",
      "time/exploration sampling (s)           0.163728\n",
      "time/logging (s)                        0.0109035\n",
      "time/preback_alpha (s)                  0.541667\n",
      "time/preback_policy (s)                 0.604685\n",
      "time/preback_start (s)                  0.120381\n",
      "time/preback_zf (s)                     4.94464\n",
      "time/saving (s)                         0.00829969\n",
      "time/training (s)                       2.48343\n",
      "time/epoch (s)                         15.8693\n",
      "time/total (s)                       1952.61\n",
      "Epoch                                 126\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:34:00.572935 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 127 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 138000\n",
      "trainer/ZF1 Loss                       46.1838\n",
      "trainer/ZF2 Loss                       45.3956\n",
      "trainer/ZF Expert Reward               13.7335\n",
      "trainer/ZF Policy Reward               -1.08219\n",
      "trainer/ZF CHI2 Term                   73.7412\n",
      "trainer/Policy Loss                  -868.583\n",
      "trainer/Policy Grad Norm              681.968\n",
      "trainer/Policy Param Norm              37.2231\n",
      "trainer/Zf1 Grad Norm               12570\n",
      "trainer/Zf1 Param Norm                 97.8328\n",
      "trainer/Zf2 Grad Norm               12498.6\n",
      "trainer/Zf2 Param Norm                 95.3525\n",
      "trainer/Z Expert Predictions Mean    1170.7\n",
      "trainer/Z Expert Predictions Std      188.427\n",
      "trainer/Z Expert Predictions Max     1508.89\n",
      "trainer/Z Expert Predictions Min      611.837\n",
      "trainer/Z Policy Predictions Mean     858.091\n",
      "trainer/Z Policy Predictions Std      412.962\n",
      "trainer/Z Policy Predictions Max     1364.36\n",
      "trainer/Z Policy Predictions Min     -436.86\n",
      "trainer/Z Expert Targets Mean        1156.97\n",
      "trainer/Z Expert Targets Std          187.229\n",
      "trainer/Z Expert Targets Max         1494.46\n",
      "trainer/Z Expert Targets Min          593.659\n",
      "trainer/Z Policy Targets Mean         859.173\n",
      "trainer/Z Policy Targets Std          406.853\n",
      "trainer/Z Policy Targets Max         1352.9\n",
      "trainer/Z Policy Targets Min         -377.275\n",
      "trainer/Log Pis Mean                   13.2684\n",
      "trainer/Log Pis Std                     5.09617\n",
      "trainer/Policy mu Mean                  0.350743\n",
      "trainer/Policy mu Std                   2.44333\n",
      "trainer/Policy log std Mean            -3.90543\n",
      "trainer/Policy log std Std              1.10015\n",
      "exploration/num steps total        132511\n",
      "exploration/num paths total           953\n",
      "evaluation/num steps total         822071\n",
      "evaluation/num paths total           1292\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48891\n",
      "evaluation/Rewards Std                  0.56675\n",
      "evaluation/Rewards Max                  4.6336\n",
      "evaluation/Rewards Min                  0.631492\n",
      "evaluation/Returns Mean              3488.91\n",
      "evaluation/Returns Std                  4.3982\n",
      "evaluation/Returns Max               3493.39\n",
      "evaluation/Returns Min               3479.39\n",
      "evaluation/Estimation Bias Mean      1113.16\n",
      "evaluation/Estimation Bias Std        165.675\n",
      "evaluation/EB/Q_True Mean              32.2257\n",
      "evaluation/EB/Q_True Std               99.2531\n",
      "evaluation/EB/Q_Pred Mean            1145.39\n",
      "evaluation/EB/Q_Pred Std              133.096\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3488.91\n",
      "evaluation/Actions Mean                 0.0125283\n",
      "evaluation/Actions Std                  0.557255\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999989\n",
      "time/backward_policy (s)                1.66671\n",
      "time/backward_zf1 (s)                   1.78412\n",
      "time/backward_zf2 (s)                   1.71594\n",
      "time/data sampling (s)                  0.246882\n",
      "time/data storing (s)                   0.0135831\n",
      "time/evaluation sampling (s)            1.38664\n",
      "time/exploration sampling (s)           0.165445\n",
      "time/logging (s)                        0.0116873\n",
      "time/preback_alpha (s)                  0.545748\n",
      "time/preback_policy (s)                 0.596309\n",
      "time/preback_start (s)                  0.12147\n",
      "time/preback_zf (s)                     4.96485\n",
      "time/saving (s)                         0.00551293\n",
      "time/training (s)                       2.73154\n",
      "time/epoch (s)                         15.9565\n",
      "time/total (s)                       1968.59\n",
      "Epoch                                 127\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:34:16.567799 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 128 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 139000\n",
      "trainer/ZF1 Loss                       45.404\n",
      "trainer/ZF2 Loss                       47.5272\n",
      "trainer/ZF Expert Reward                6.49392\n",
      "trainer/ZF Policy Reward               -3.97869\n",
      "trainer/ZF CHI2 Term                   71.0696\n",
      "trainer/Policy Loss                  -820.833\n",
      "trainer/Policy Grad Norm              517.861\n",
      "trainer/Policy Param Norm              37.3022\n",
      "trainer/Zf1 Grad Norm               10963.6\n",
      "trainer/Zf1 Param Norm                 98.1374\n",
      "trainer/Zf2 Grad Norm               21766.1\n",
      "trainer/Zf2 Param Norm                 95.6414\n",
      "trainer/Z Expert Predictions Mean    1176.12\n",
      "trainer/Z Expert Predictions Std      182.972\n",
      "trainer/Z Expert Predictions Max     1450.58\n",
      "trainer/Z Expert Predictions Min      596.625\n",
      "trainer/Z Policy Predictions Mean     812.442\n",
      "trainer/Z Policy Predictions Std      425.575\n",
      "trainer/Z Policy Predictions Max     1355.3\n",
      "trainer/Z Policy Predictions Min     -562.423\n",
      "trainer/Z Expert Targets Mean        1169.63\n",
      "trainer/Z Expert Targets Std          185.107\n",
      "trainer/Z Expert Targets Max         1447.31\n",
      "trainer/Z Expert Targets Min          585.466\n",
      "trainer/Z Policy Targets Mean         816.421\n",
      "trainer/Z Policy Targets Std          425.254\n",
      "trainer/Z Policy Targets Max         1370.49\n",
      "trainer/Z Policy Targets Min         -600.794\n",
      "trainer/Log Pis Mean                   14.2741\n",
      "trainer/Log Pis Std                     5.80115\n",
      "trainer/Policy mu Mean                  0.467514\n",
      "trainer/Policy mu Std                   3.04351\n",
      "trainer/Policy log std Mean            -3.8093\n",
      "trainer/Policy log std Std              1.22837\n",
      "exploration/num steps total        133030\n",
      "exploration/num paths total           954\n",
      "evaluation/num steps total         832071\n",
      "evaluation/num paths total           1302\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52171\n",
      "evaluation/Rewards Std                  0.605648\n",
      "evaluation/Rewards Max                  4.72244\n",
      "evaluation/Rewards Min                  0.640394\n",
      "evaluation/Returns Mean              3521.71\n",
      "evaluation/Returns Std                  6.48588\n",
      "evaluation/Returns Max               3531.07\n",
      "evaluation/Returns Min               3511.57\n",
      "evaluation/Estimation Bias Mean      1133.39\n",
      "evaluation/Estimation Bias Std        190.562\n",
      "evaluation/EB/Q_True Mean              32.5383\n",
      "evaluation/EB/Q_True Std              100.21\n",
      "evaluation/EB/Q_Pred Mean            1165.93\n",
      "evaluation/EB/Q_Pred Std              164.02\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3521.71\n",
      "evaluation/Actions Mean                 0.026957\n",
      "evaluation/Actions Std                  0.583421\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.82797\n",
      "time/backward_zf1 (s)                   1.91665\n",
      "time/backward_zf2 (s)                   1.87151\n",
      "time/data sampling (s)                  0.22926\n",
      "time/data storing (s)                   0.0136226\n",
      "time/evaluation sampling (s)            1.35588\n",
      "time/exploration sampling (s)           0.164707\n",
      "time/logging (s)                        0.0112729\n",
      "time/preback_alpha (s)                  0.54269\n",
      "time/preback_policy (s)                 0.616472\n",
      "time/preback_start (s)                  0.11997\n",
      "time/preback_zf (s)                     4.95731\n",
      "time/saving (s)                         0.00535024\n",
      "time/training (s)                       2.29829\n",
      "time/epoch (s)                         15.931\n",
      "time/total (s)                       1984.54\n",
      "Epoch                                 128\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:34:32.419715 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 129 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 140000\n",
      "trainer/ZF1 Loss                       25.1972\n",
      "trainer/ZF2 Loss                       38.3956\n",
      "trainer/ZF Expert Reward               15.9763\n",
      "trainer/ZF Policy Reward               -2.13588\n",
      "trainer/ZF CHI2 Term                   63.2032\n",
      "trainer/Policy Loss                  -852.916\n",
      "trainer/Policy Grad Norm              432.56\n",
      "trainer/Policy Param Norm              37.3921\n",
      "trainer/Zf1 Grad Norm               14111.4\n",
      "trainer/Zf1 Param Norm                 98.4374\n",
      "trainer/Zf2 Grad Norm               13998.8\n",
      "trainer/Zf2 Param Norm                 95.9053\n",
      "trainer/Z Expert Predictions Mean    1182.59\n",
      "trainer/Z Expert Predictions Std      175.377\n",
      "trainer/Z Expert Predictions Max     1440.21\n",
      "trainer/Z Expert Predictions Min      672.647\n",
      "trainer/Z Policy Predictions Mean     845.606\n",
      "trainer/Z Policy Predictions Std      413.384\n",
      "trainer/Z Policy Predictions Max     1373.47\n",
      "trainer/Z Policy Predictions Min     -465.908\n",
      "trainer/Z Expert Targets Mean        1166.62\n",
      "trainer/Z Expert Targets Std          171.392\n",
      "trainer/Z Expert Targets Max         1397.4\n",
      "trainer/Z Expert Targets Min          646.825\n",
      "trainer/Z Policy Targets Mean         847.742\n",
      "trainer/Z Policy Targets Std          409.776\n",
      "trainer/Z Policy Targets Max         1400.28\n",
      "trainer/Z Policy Targets Min         -387.007\n",
      "trainer/Log Pis Mean                   13.429\n",
      "trainer/Log Pis Std                     5.3271\n",
      "trainer/Policy mu Mean                  0.492635\n",
      "trainer/Policy mu Std                   2.76904\n",
      "trainer/Policy log std Mean            -3.80423\n",
      "trainer/Policy log std Std              1.25131\n",
      "exploration/num steps total        137030\n",
      "exploration/num paths total           958\n",
      "evaluation/num steps total         839988\n",
      "evaluation/num paths total           1312\n",
      "evaluation/path length Mean           791.7\n",
      "evaluation/path length Std            216.705\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            443\n",
      "evaluation/Rewards Mean                 3.5589\n",
      "evaluation/Rewards Std                  0.655531\n",
      "evaluation/Rewards Max                  5.39216\n",
      "evaluation/Rewards Min                  0.632723\n",
      "evaluation/Returns Mean              2817.58\n",
      "evaluation/Returns Std                784.78\n",
      "evaluation/Returns Max               3569.48\n",
      "evaluation/Returns Min               1545.61\n",
      "evaluation/Estimation Bias Mean       880.999\n",
      "evaluation/Estimation Bias Std        467.1\n",
      "evaluation/EB/Q_True Mean              41.7277\n",
      "evaluation/EB/Q_True Std              112.803\n",
      "evaluation/EB/Q_Pred Mean             922.727\n",
      "evaluation/EB/Q_Pred Std              430.476\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2817.58\n",
      "evaluation/Actions Mean                 0.0407807\n",
      "evaluation/Actions Std                  0.594003\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.66993\n",
      "time/backward_zf1 (s)                   1.80112\n",
      "time/backward_zf2 (s)                   1.72545\n",
      "time/data sampling (s)                  0.229664\n",
      "time/data storing (s)                   0.0135145\n",
      "time/evaluation sampling (s)            1.35177\n",
      "time/exploration sampling (s)           0.173955\n",
      "time/logging (s)                        0.00951272\n",
      "time/preback_alpha (s)                  0.540784\n",
      "time/preback_policy (s)                 0.591282\n",
      "time/preback_start (s)                  0.122153\n",
      "time/preback_zf (s)                     4.92912\n",
      "time/saving (s)                         0.00545952\n",
      "time/training (s)                       2.6226\n",
      "time/epoch (s)                         15.7863\n",
      "time/total (s)                       2000.34\n",
      "Epoch                                 129\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:34:48.418057 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 130 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 141000\n",
      "trainer/ZF1 Loss                      102.672\n",
      "trainer/ZF2 Loss                       83.9042\n",
      "trainer/ZF Expert Reward               -3.9573\n",
      "trainer/ZF Policy Reward              -10.5347\n",
      "trainer/ZF CHI2 Term                  113.115\n",
      "trainer/Policy Loss                  -797.69\n",
      "trainer/Policy Grad Norm              385.909\n",
      "trainer/Policy Param Norm              37.4818\n",
      "trainer/Zf1 Grad Norm               23507.2\n",
      "trainer/Zf1 Param Norm                 98.7278\n",
      "trainer/Zf2 Grad Norm               29096.7\n",
      "trainer/Zf2 Param Norm                 96.1587\n",
      "trainer/Z Expert Predictions Mean    1163.13\n",
      "trainer/Z Expert Predictions Std      185.093\n",
      "trainer/Z Expert Predictions Max     1466.18\n",
      "trainer/Z Expert Predictions Min      632.75\n",
      "trainer/Z Policy Predictions Mean     776.8\n",
      "trainer/Z Policy Predictions Std      453.902\n",
      "trainer/Z Policy Predictions Max     1364.84\n",
      "trainer/Z Policy Predictions Min     -564.907\n",
      "trainer/Z Expert Targets Mean        1167.09\n",
      "trainer/Z Expert Targets Std          188.259\n",
      "trainer/Z Expert Targets Max         1484.42\n",
      "trainer/Z Expert Targets Min          644.185\n",
      "trainer/Z Policy Targets Mean         787.335\n",
      "trainer/Z Policy Targets Std          455.961\n",
      "trainer/Z Policy Targets Max         1359.77\n",
      "trainer/Z Policy Targets Min         -712.021\n",
      "trainer/Log Pis Mean                   13.384\n",
      "trainer/Log Pis Std                     5.33371\n",
      "trainer/Policy mu Mean                  0.375619\n",
      "trainer/Policy mu Std                   2.56559\n",
      "trainer/Policy log std Mean            -3.92271\n",
      "trainer/Policy log std Std              1.17148\n",
      "exploration/num steps total        137030\n",
      "exploration/num paths total           958\n",
      "evaluation/num steps total         849988\n",
      "evaluation/num paths total           1322\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51378\n",
      "evaluation/Rewards Std                  0.605578\n",
      "evaluation/Rewards Max                  4.72846\n",
      "evaluation/Rewards Min                  0.581133\n",
      "evaluation/Returns Mean              3513.78\n",
      "evaluation/Returns Std                  6.0778\n",
      "evaluation/Returns Max               3525.89\n",
      "evaluation/Returns Min               3506.81\n",
      "evaluation/Estimation Bias Mean      1132.96\n",
      "evaluation/Estimation Bias Std        183.142\n",
      "evaluation/EB/Q_True Mean              32.4267\n",
      "evaluation/EB/Q_True Std              100.062\n",
      "evaluation/EB/Q_Pred Mean            1165.39\n",
      "evaluation/EB/Q_Pred Std              158.364\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3513.78\n",
      "evaluation/Actions Mean                 0.0203896\n",
      "evaluation/Actions Std                  0.578711\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999988\n",
      "time/backward_policy (s)                1.79769\n",
      "time/backward_zf1 (s)                   1.89597\n",
      "time/backward_zf2 (s)                   1.84936\n",
      "time/data sampling (s)                  0.244525\n",
      "time/data storing (s)                   0.0134432\n",
      "time/evaluation sampling (s)            1.39629\n",
      "time/exploration sampling (s)           0.163789\n",
      "time/logging (s)                        0.0120591\n",
      "time/preback_alpha (s)                  0.540689\n",
      "time/preback_policy (s)                 0.617955\n",
      "time/preback_start (s)                  0.120317\n",
      "time/preback_zf (s)                     4.93411\n",
      "time/saving (s)                         0.0190156\n",
      "time/training (s)                       2.33034\n",
      "time/epoch (s)                         15.9356\n",
      "time/total (s)                       2016.3\n",
      "Epoch                                 130\n",
      "---------------------------------  --------------\n",
      "2024-06-08 22:35:04.476437 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 131 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 142000\n",
      "trainer/ZF1 Loss                       68.3168\n",
      "trainer/ZF2 Loss                       47.8149\n",
      "trainer/ZF Expert Reward               11.147\n",
      "trainer/ZF Policy Reward               -1.13361\n",
      "trainer/ZF CHI2 Term                   84.7271\n",
      "trainer/Policy Loss                  -785.647\n",
      "trainer/Policy Grad Norm              641.948\n",
      "trainer/Policy Param Norm              37.5694\n",
      "trainer/Zf1 Grad Norm               22220\n",
      "trainer/Zf1 Param Norm                 99.0414\n",
      "trainer/Zf2 Grad Norm               19745.7\n",
      "trainer/Zf2 Param Norm                 96.4158\n",
      "trainer/Z Expert Predictions Mean    1199.99\n",
      "trainer/Z Expert Predictions Std      163.399\n",
      "trainer/Z Expert Predictions Max     1395.02\n",
      "trainer/Z Expert Predictions Min      277.599\n",
      "trainer/Z Policy Predictions Mean     776.735\n",
      "trainer/Z Policy Predictions Std      480.975\n",
      "trainer/Z Policy Predictions Max     1366.67\n",
      "trainer/Z Policy Predictions Min     -512.2\n",
      "trainer/Z Expert Targets Mean        1188.85\n",
      "trainer/Z Expert Targets Std          167.62\n",
      "trainer/Z Expert Targets Max         1391.2\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         777.869\n",
      "trainer/Z Policy Targets Std          480.596\n",
      "trainer/Z Policy Targets Max         1354.18\n",
      "trainer/Z Policy Targets Min         -526.294\n",
      "trainer/Log Pis Mean                   14.5259\n",
      "trainer/Log Pis Std                     5.8568\n",
      "trainer/Policy mu Mean                  0.670933\n",
      "trainer/Policy mu Std                   3.50206\n",
      "trainer/Policy log std Mean            -3.76126\n",
      "trainer/Policy log std Std              1.41481\n",
      "exploration/num steps total        138030\n",
      "exploration/num paths total           959\n",
      "evaluation/num steps total         859709\n",
      "evaluation/num paths total           1332\n",
      "evaluation/path length Mean           972.1\n",
      "evaluation/path length Std             83.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            721\n",
      "evaluation/Rewards Mean                 3.56105\n",
      "evaluation/Rewards Std                  0.593124\n",
      "evaluation/Rewards Max                  4.6713\n",
      "evaluation/Rewards Min                  0.611873\n",
      "evaluation/Returns Mean              3461.7\n",
      "evaluation/Returns Std                297.978\n",
      "evaluation/Returns Max               3573.77\n",
      "evaluation/Returns Min               2568.1\n",
      "evaluation/Estimation Bias Mean      1119.87\n",
      "evaluation/Estimation Bias Std        261.986\n",
      "evaluation/EB/Q_True Mean              33.8253\n",
      "evaluation/EB/Q_True Std              102.593\n",
      "evaluation/EB/Q_Pred Mean            1153.69\n",
      "evaluation/EB/Q_Pred Std              209.894\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3461.7\n",
      "evaluation/Actions Mean                 0.0402896\n",
      "evaluation/Actions Std                  0.572567\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.87431\n",
      "time/backward_zf1 (s)                   1.9476\n",
      "time/backward_zf2 (s)                   1.92664\n",
      "time/data sampling (s)                  0.243396\n",
      "time/data storing (s)                   0.013861\n",
      "time/evaluation sampling (s)            1.37997\n",
      "time/exploration sampling (s)           0.17077\n",
      "time/logging (s)                        0.0112241\n",
      "time/preback_alpha (s)                  0.545461\n",
      "time/preback_policy (s)                 0.625411\n",
      "time/preback_start (s)                  0.120956\n",
      "time/preback_zf (s)                     4.94805\n",
      "time/saving (s)                         0.00491067\n",
      "time/training (s)                       2.18142\n",
      "time/epoch (s)                         15.994\n",
      "time/total (s)                       2032.31\n",
      "Epoch                                 131\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:35:20.601513 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 132 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 143000\n",
      "trainer/ZF1 Loss                       53.9203\n",
      "trainer/ZF2 Loss                       64.7019\n",
      "trainer/ZF Expert Reward               17.5811\n",
      "trainer/ZF Policy Reward                3.95233\n",
      "trainer/ZF CHI2 Term                   86.8346\n",
      "trainer/Policy Loss                  -861.937\n",
      "trainer/Policy Grad Norm              672.297\n",
      "trainer/Policy Param Norm              37.6395\n",
      "trainer/Zf1 Grad Norm               13394\n",
      "trainer/Zf1 Param Norm                 99.3275\n",
      "trainer/Zf2 Grad Norm               24660.4\n",
      "trainer/Zf2 Param Norm                 96.6562\n",
      "trainer/Z Expert Predictions Mean    1206.91\n",
      "trainer/Z Expert Predictions Std      163.342\n",
      "trainer/Z Expert Predictions Max     1420.51\n",
      "trainer/Z Expert Predictions Min      644.09\n",
      "trainer/Z Policy Predictions Mean     855.608\n",
      "trainer/Z Policy Predictions Std      404.387\n",
      "trainer/Z Policy Predictions Max     1389.25\n",
      "trainer/Z Policy Predictions Min     -309.308\n",
      "trainer/Z Expert Targets Mean        1189.33\n",
      "trainer/Z Expert Targets Std          162.312\n",
      "trainer/Z Expert Targets Max         1383.92\n",
      "trainer/Z Expert Targets Min          645.084\n",
      "trainer/Z Policy Targets Mean         851.656\n",
      "trainer/Z Policy Targets Std          399.237\n",
      "trainer/Z Policy Targets Max         1380.65\n",
      "trainer/Z Policy Targets Min         -316.801\n",
      "trainer/Log Pis Mean                   14.035\n",
      "trainer/Log Pis Std                     5.77977\n",
      "trainer/Policy mu Mean                  0.683657\n",
      "trainer/Policy mu Std                   3.10864\n",
      "trainer/Policy log std Mean            -3.72837\n",
      "trainer/Policy log std Std              1.34223\n",
      "exploration/num steps total        138030\n",
      "exploration/num paths total           959\n",
      "evaluation/num steps total         869709\n",
      "evaluation/num paths total           1342\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.49591\n",
      "evaluation/Rewards Std                  0.595034\n",
      "evaluation/Rewards Max                  4.65106\n",
      "evaluation/Rewards Min                  0.61357\n",
      "evaluation/Returns Mean              3495.91\n",
      "evaluation/Returns Std                  7.63781\n",
      "evaluation/Returns Max               3507.17\n",
      "evaluation/Returns Min               3483.16\n",
      "evaluation/Estimation Bias Mean      1122.46\n",
      "evaluation/Estimation Bias Std        194.442\n",
      "evaluation/EB/Q_True Mean              32.3496\n",
      "evaluation/EB/Q_True Std               99.6136\n",
      "evaluation/EB/Q_Pred Mean            1154.81\n",
      "evaluation/EB/Q_Pred Std              162.482\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3495.91\n",
      "evaluation/Actions Mean                 0.0229824\n",
      "evaluation/Actions Std                  0.575876\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.86091\n",
      "time/backward_zf1 (s)                   1.96553\n",
      "time/backward_zf2 (s)                   1.9266\n",
      "time/data sampling (s)                  0.253988\n",
      "time/data storing (s)                   0.0133506\n",
      "time/evaluation sampling (s)            1.40699\n",
      "time/exploration sampling (s)           0.163436\n",
      "time/logging (s)                        0.0117372\n",
      "time/preback_alpha (s)                  0.542167\n",
      "time/preback_policy (s)                 0.624343\n",
      "time/preback_start (s)                  0.11951\n",
      "time/preback_zf (s)                     4.94962\n",
      "time/saving (s)                         0.00545239\n",
      "time/training (s)                       2.21765\n",
      "time/epoch (s)                         16.0613\n",
      "time/total (s)                       2048.39\n",
      "Epoch                                 132\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:35:36.538069 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 133 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 144000\n",
      "trainer/ZF1 Loss                       27.4074\n",
      "trainer/ZF2 Loss                       59.0007\n",
      "trainer/ZF Expert Reward               11.2974\n",
      "trainer/ZF Policy Reward               -1.98226\n",
      "trainer/ZF CHI2 Term                   70.2365\n",
      "trainer/Policy Loss                  -831.175\n",
      "trainer/Policy Grad Norm             1007.23\n",
      "trainer/Policy Param Norm              37.7221\n",
      "trainer/Zf1 Grad Norm               11056.5\n",
      "trainer/Zf1 Param Norm                 99.6192\n",
      "trainer/Zf2 Grad Norm               33360.8\n",
      "trainer/Zf2 Param Norm                 96.8762\n",
      "trainer/Z Expert Predictions Mean    1194.64\n",
      "trainer/Z Expert Predictions Std      169.38\n",
      "trainer/Z Expert Predictions Max     1477.85\n",
      "trainer/Z Expert Predictions Min      631.183\n",
      "trainer/Z Policy Predictions Mean     821.355\n",
      "trainer/Z Policy Predictions Std      438.651\n",
      "trainer/Z Policy Predictions Max     1396.49\n",
      "trainer/Z Policy Predictions Min     -406.676\n",
      "trainer/Z Expert Targets Mean        1183.34\n",
      "trainer/Z Expert Targets Std          166.493\n",
      "trainer/Z Expert Targets Max         1440.74\n",
      "trainer/Z Expert Targets Min          623.633\n",
      "trainer/Z Policy Targets Mean         823.337\n",
      "trainer/Z Policy Targets Std          437.532\n",
      "trainer/Z Policy Targets Max         1371.87\n",
      "trainer/Z Policy Targets Min         -437.858\n",
      "trainer/Log Pis Mean                   13.8917\n",
      "trainer/Log Pis Std                     5.43986\n",
      "trainer/Policy mu Mean                  0.582913\n",
      "trainer/Policy mu Std                   2.9725\n",
      "trainer/Policy log std Mean            -3.7476\n",
      "trainer/Policy log std Std              1.32883\n",
      "exploration/num steps total        138030\n",
      "exploration/num paths total           959\n",
      "evaluation/num steps total         879191\n",
      "evaluation/num paths total           1352\n",
      "evaluation/path length Mean           948.2\n",
      "evaluation/path length Std            155.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            482\n",
      "evaluation/Rewards Mean                 3.56209\n",
      "evaluation/Rewards Std                  0.595912\n",
      "evaluation/Rewards Max                  4.6424\n",
      "evaluation/Rewards Min                  0.594962\n",
      "evaluation/Returns Mean              3377.58\n",
      "evaluation/Returns Std                564.019\n",
      "evaluation/Returns Max               3586.8\n",
      "evaluation/Returns Min               1685.97\n",
      "evaluation/Estimation Bias Mean      1041.72\n",
      "evaluation/Estimation Bias Std        309.375\n",
      "evaluation/EB/Q_True Mean              35.0269\n",
      "evaluation/EB/Q_True Std              104.842\n",
      "evaluation/EB/Q_Pred Mean            1076.75\n",
      "evaluation/EB/Q_Pred Std              262.852\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3377.58\n",
      "evaluation/Actions Mean                 0.0359204\n",
      "evaluation/Actions Std                  0.574148\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.65725\n",
      "time/backward_zf1 (s)                   1.77215\n",
      "time/backward_zf2 (s)                   1.69805\n",
      "time/data sampling (s)                  0.229799\n",
      "time/data storing (s)                   0.0134606\n",
      "time/evaluation sampling (s)            1.38164\n",
      "time/exploration sampling (s)           0.163774\n",
      "time/logging (s)                        0.0109996\n",
      "time/preback_alpha (s)                  0.5438\n",
      "time/preback_policy (s)                 0.593028\n",
      "time/preback_start (s)                  0.120088\n",
      "time/preback_zf (s)                     4.956\n",
      "time/saving (s)                         0.00524867\n",
      "time/training (s)                       2.72852\n",
      "time/epoch (s)                         15.8738\n",
      "time/total (s)                       2064.29\n",
      "Epoch                                 133\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:35:52.424309 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 134 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 145000\n",
      "trainer/ZF1 Loss                       46.319\n",
      "trainer/ZF2 Loss                       71.7705\n",
      "trainer/ZF Expert Reward                7.13719\n",
      "trainer/ZF Policy Reward               -7.27828\n",
      "trainer/ZF CHI2 Term                   87.477\n",
      "trainer/Policy Loss                  -813.132\n",
      "trainer/Policy Grad Norm              488.668\n",
      "trainer/Policy Param Norm              37.8007\n",
      "trainer/Zf1 Grad Norm               17812.9\n",
      "trainer/Zf1 Param Norm                 99.8809\n",
      "trainer/Zf2 Grad Norm               19051.5\n",
      "trainer/Zf2 Param Norm                 97.0844\n",
      "trainer/Z Expert Predictions Mean    1191.36\n",
      "trainer/Z Expert Predictions Std      161.608\n",
      "trainer/Z Expert Predictions Max     1460.1\n",
      "trainer/Z Expert Predictions Min      618.747\n",
      "trainer/Z Policy Predictions Mean     801.969\n",
      "trainer/Z Policy Predictions Std      446.043\n",
      "trainer/Z Policy Predictions Max     1363.32\n",
      "trainer/Z Policy Predictions Min     -325.954\n",
      "trainer/Z Expert Targets Mean        1184.23\n",
      "trainer/Z Expert Targets Std          159.915\n",
      "trainer/Z Expert Targets Max         1448.4\n",
      "trainer/Z Expert Targets Min          623.712\n",
      "trainer/Z Policy Targets Mean         809.247\n",
      "trainer/Z Policy Targets Std          444.126\n",
      "trainer/Z Policy Targets Max         1363.19\n",
      "trainer/Z Policy Targets Min         -313.408\n",
      "trainer/Log Pis Mean                   14.1584\n",
      "trainer/Log Pis Std                     5.44843\n",
      "trainer/Policy mu Mean                  0.413023\n",
      "trainer/Policy mu Std                   2.6486\n",
      "trainer/Policy log std Mean            -4.09095\n",
      "trainer/Policy log std Std              1.17387\n",
      "exploration/num steps total        140030\n",
      "exploration/num paths total           961\n",
      "evaluation/num steps total         889191\n",
      "evaluation/num paths total           1362\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50316\n",
      "evaluation/Rewards Std                  0.57199\n",
      "evaluation/Rewards Max                  4.58399\n",
      "evaluation/Rewards Min                  0.643454\n",
      "evaluation/Returns Mean              3503.16\n",
      "evaluation/Returns Std                  7.95709\n",
      "evaluation/Returns Max               3518.72\n",
      "evaluation/Returns Min               3490.98\n",
      "evaluation/Estimation Bias Mean      1136.08\n",
      "evaluation/Estimation Bias Std        182.653\n",
      "evaluation/EB/Q_True Mean              32.3876\n",
      "evaluation/EB/Q_True Std               99.955\n",
      "evaluation/EB/Q_Pred Mean            1168.46\n",
      "evaluation/EB/Q_Pred Std              150.795\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3503.16\n",
      "evaluation/Actions Mean                 0.0231219\n",
      "evaluation/Actions Std                  0.563695\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.62884\n",
      "time/backward_zf1 (s)                   1.73984\n",
      "time/backward_zf2 (s)                   1.66811\n",
      "time/data sampling (s)                  0.240871\n",
      "time/data storing (s)                   0.0134657\n",
      "time/evaluation sampling (s)            1.4159\n",
      "time/exploration sampling (s)           0.168395\n",
      "time/logging (s)                        0.0126849\n",
      "time/preback_alpha (s)                  0.541884\n",
      "time/preback_policy (s)                 0.584276\n",
      "time/preback_start (s)                  0.121974\n",
      "time/preback_zf (s)                     4.93807\n",
      "time/saving (s)                         0.00531906\n",
      "time/training (s)                       2.74728\n",
      "time/epoch (s)                         15.8269\n",
      "time/total (s)                       2080.13\n",
      "Epoch                                 134\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:36:08.361193 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 135 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 146000\n",
      "trainer/ZF1 Loss                       22.0544\n",
      "trainer/ZF2 Loss                       53.3347\n",
      "trainer/ZF Expert Reward               12.0208\n",
      "trainer/ZF Policy Reward               -6.77751\n",
      "trainer/ZF CHI2 Term                   70.7708\n",
      "trainer/Policy Loss                  -826.2\n",
      "trainer/Policy Grad Norm              654.02\n",
      "trainer/Policy Param Norm              37.8686\n",
      "trainer/Zf1 Grad Norm                6856.97\n",
      "trainer/Zf1 Param Norm                100.182\n",
      "trainer/Zf2 Grad Norm               19225.8\n",
      "trainer/Zf2 Param Norm                 97.326\n",
      "trainer/Z Expert Predictions Mean    1191.67\n",
      "trainer/Z Expert Predictions Std      172.313\n",
      "trainer/Z Expert Predictions Max     1436.41\n",
      "trainer/Z Expert Predictions Min      611.672\n",
      "trainer/Z Policy Predictions Mean     818.773\n",
      "trainer/Z Policy Predictions Std      438.813\n",
      "trainer/Z Policy Predictions Max     1363.24\n",
      "trainer/Z Policy Predictions Min     -410.52\n",
      "trainer/Z Expert Targets Mean        1179.65\n",
      "trainer/Z Expert Targets Std          169.669\n",
      "trainer/Z Expert Targets Max         1421.86\n",
      "trainer/Z Expert Targets Min          613.497\n",
      "trainer/Z Policy Targets Mean         825.551\n",
      "trainer/Z Policy Targets Std          432.23\n",
      "trainer/Z Policy Targets Max         1351.19\n",
      "trainer/Z Policy Targets Min         -384.858\n",
      "trainer/Log Pis Mean                   14.4222\n",
      "trainer/Log Pis Std                     6.10025\n",
      "trainer/Policy mu Mean                  0.693757\n",
      "trainer/Policy mu Std                   3.28189\n",
      "trainer/Policy log std Mean            -3.73237\n",
      "trainer/Policy log std Std              1.43161\n",
      "exploration/num steps total        141030\n",
      "exploration/num paths total           962\n",
      "evaluation/num steps total         899191\n",
      "evaluation/num paths total           1372\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50038\n",
      "evaluation/Rewards Std                  0.579867\n",
      "evaluation/Rewards Max                  4.64136\n",
      "evaluation/Rewards Min                  0.60834\n",
      "evaluation/Returns Mean              3500.38\n",
      "evaluation/Returns Std                  4.84563\n",
      "evaluation/Returns Max               3506.01\n",
      "evaluation/Returns Min               3491.45\n",
      "evaluation/Estimation Bias Mean      1122.79\n",
      "evaluation/Estimation Bias Std        188.622\n",
      "evaluation/EB/Q_True Mean              32.4127\n",
      "evaluation/EB/Q_True Std               99.8484\n",
      "evaluation/EB/Q_Pred Mean            1155.2\n",
      "evaluation/EB/Q_Pred Std              157.758\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3500.38\n",
      "evaluation/Actions Mean                 0.0143892\n",
      "evaluation/Actions Std                  0.566134\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999985\n",
      "time/backward_policy (s)                1.74956\n",
      "time/backward_zf1 (s)                   1.84763\n",
      "time/backward_zf2 (s)                   1.78939\n",
      "time/data sampling (s)                  0.247354\n",
      "time/data storing (s)                   0.0140326\n",
      "time/evaluation sampling (s)            1.37015\n",
      "time/exploration sampling (s)           0.170165\n",
      "time/logging (s)                        0.0126085\n",
      "time/preback_alpha (s)                  0.542887\n",
      "time/preback_policy (s)                 0.605865\n",
      "time/preback_start (s)                  0.121983\n",
      "time/preback_zf (s)                     4.94754\n",
      "time/saving (s)                         0.00516899\n",
      "time/training (s)                       2.45157\n",
      "time/epoch (s)                         15.8759\n",
      "time/total (s)                       2096.02\n",
      "Epoch                                 135\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:36:24.289833 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 136 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 147000\n",
      "trainer/ZF1 Loss                       40.5759\n",
      "trainer/ZF2 Loss                       25.1823\n",
      "trainer/ZF Expert Reward               10.1444\n",
      "trainer/ZF Policy Reward               -6.51222\n",
      "trainer/ZF CHI2 Term                   63.0612\n",
      "trainer/Policy Loss                  -884.328\n",
      "trainer/Policy Grad Norm              881.266\n",
      "trainer/Policy Param Norm              37.9489\n",
      "trainer/Zf1 Grad Norm               24900.3\n",
      "trainer/Zf1 Param Norm                100.487\n",
      "trainer/Zf2 Grad Norm               21331.3\n",
      "trainer/Zf2 Param Norm                 97.5872\n",
      "trainer/Z Expert Predictions Mean    1202.15\n",
      "trainer/Z Expert Predictions Std      194.192\n",
      "trainer/Z Expert Predictions Max     1411.24\n",
      "trainer/Z Expert Predictions Min       29.9182\n",
      "trainer/Z Policy Predictions Mean     869.302\n",
      "trainer/Z Policy Predictions Std      418.59\n",
      "trainer/Z Policy Predictions Max     1365.43\n",
      "trainer/Z Policy Predictions Min     -567.838\n",
      "trainer/Z Expert Targets Mean        1192.01\n",
      "trainer/Z Expert Targets Std          194.594\n",
      "trainer/Z Expert Targets Max         1410.85\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         875.814\n",
      "trainer/Z Policy Targets Std          415.031\n",
      "trainer/Z Policy Targets Max         1369.29\n",
      "trainer/Z Policy Targets Min         -544.447\n",
      "trainer/Log Pis Mean                   13.662\n",
      "trainer/Log Pis Std                     4.9934\n",
      "trainer/Policy mu Mean                  0.382979\n",
      "trainer/Policy mu Std                   2.9282\n",
      "trainer/Policy log std Mean            -3.8916\n",
      "trainer/Policy log std Std              1.25149\n",
      "exploration/num steps total        141030\n",
      "exploration/num paths total           962\n",
      "evaluation/num steps total         906388\n",
      "evaluation/num paths total           1384\n",
      "evaluation/path length Mean           599.75\n",
      "evaluation/path length Std            283.05\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            392\n",
      "evaluation/Rewards Mean                 3.51299\n",
      "evaluation/Rewards Std                  0.697463\n",
      "evaluation/Rewards Max                  4.74984\n",
      "evaluation/Rewards Min                  0.59918\n",
      "evaluation/Returns Mean              2106.92\n",
      "evaluation/Returns Std               1035.01\n",
      "evaluation/Returns Max               3600.22\n",
      "evaluation/Returns Min               1351.05\n",
      "evaluation/Estimation Bias Mean       891.862\n",
      "evaluation/Estimation Bias Std        472.347\n",
      "evaluation/EB/Q_True Mean              45.6935\n",
      "evaluation/EB/Q_True Std              117.319\n",
      "evaluation/EB/Q_Pred Mean             937.555\n",
      "evaluation/EB/Q_Pred Std              440.313\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2106.92\n",
      "evaluation/Actions Mean                 0.0327151\n",
      "evaluation/Actions Std                  0.585113\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.6958\n",
      "time/backward_zf1 (s)                   1.81673\n",
      "time/backward_zf2 (s)                   1.7379\n",
      "time/data sampling (s)                  0.245331\n",
      "time/data storing (s)                   0.013894\n",
      "time/evaluation sampling (s)            1.36678\n",
      "time/exploration sampling (s)           0.166091\n",
      "time/logging (s)                        0.00973274\n",
      "time/preback_alpha (s)                  0.545546\n",
      "time/preback_policy (s)                 0.595459\n",
      "time/preback_start (s)                  0.121037\n",
      "time/preback_zf (s)                     4.95184\n",
      "time/saving (s)                         0.00511725\n",
      "time/training (s)                       2.59108\n",
      "time/epoch (s)                         15.8623\n",
      "time/total (s)                       2111.9\n",
      "Epoch                                 136\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:36:40.369759 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 137 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 148000\n",
      "trainer/ZF1 Loss                       54.8245\n",
      "trainer/ZF2 Loss                       71.4465\n",
      "trainer/ZF Expert Reward               11.6146\n",
      "trainer/ZF Policy Reward               -1.03979\n",
      "trainer/ZF CHI2 Term                   89.0651\n",
      "trainer/Policy Loss                  -881.529\n",
      "trainer/Policy Grad Norm              341.852\n",
      "trainer/Policy Param Norm              38.0297\n",
      "trainer/Zf1 Grad Norm               22270.8\n",
      "trainer/Zf1 Param Norm                100.817\n",
      "trainer/Zf2 Grad Norm               15732.3\n",
      "trainer/Zf2 Param Norm                 97.8486\n",
      "trainer/Z Expert Predictions Mean    1199.1\n",
      "trainer/Z Expert Predictions Std      173.156\n",
      "trainer/Z Expert Predictions Max     1450.36\n",
      "trainer/Z Expert Predictions Min      597.72\n",
      "trainer/Z Policy Predictions Mean     879.583\n",
      "trainer/Z Policy Predictions Std      390.345\n",
      "trainer/Z Policy Predictions Max     1392.8\n",
      "trainer/Z Policy Predictions Min     -388.404\n",
      "trainer/Z Expert Targets Mean        1187.49\n",
      "trainer/Z Expert Targets Std          174.899\n",
      "trainer/Z Expert Targets Max         1435.11\n",
      "trainer/Z Expert Targets Min          432.532\n",
      "trainer/Z Policy Targets Mean         880.623\n",
      "trainer/Z Policy Targets Std          384.037\n",
      "trainer/Z Policy Targets Max         1371.22\n",
      "trainer/Z Policy Targets Min         -423.759\n",
      "trainer/Log Pis Mean                   13.4094\n",
      "trainer/Log Pis Std                     5.2626\n",
      "trainer/Policy mu Mean                  0.511071\n",
      "trainer/Policy mu Std                   2.82297\n",
      "trainer/Policy log std Mean            -3.8328\n",
      "trainer/Policy log std Std              1.23898\n",
      "exploration/num steps total        142030\n",
      "exploration/num paths total           963\n",
      "evaluation/num steps total         915284\n",
      "evaluation/num paths total           1394\n",
      "evaluation/path length Mean           889.6\n",
      "evaluation/path length Std            133.89\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            656\n",
      "evaluation/Rewards Mean                 3.57398\n",
      "evaluation/Rewards Std                  0.615497\n",
      "evaluation/Rewards Max                  4.68139\n",
      "evaluation/Rewards Min                  0.612164\n",
      "evaluation/Returns Mean              3179.41\n",
      "evaluation/Returns Std                496.909\n",
      "evaluation/Returns Max               3601.29\n",
      "evaluation/Returns Min               2306.66\n",
      "evaluation/Estimation Bias Mean      1027.67\n",
      "evaluation/Estimation Bias Std        340.65\n",
      "evaluation/EB/Q_True Mean              37.2636\n",
      "evaluation/EB/Q_True Std              107.53\n",
      "evaluation/EB/Q_Pred Mean            1064.93\n",
      "evaluation/EB/Q_Pred Std              324.022\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3179.41\n",
      "evaluation/Actions Mean                 0.0380078\n",
      "evaluation/Actions Std                  0.581385\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.70851\n",
      "time/backward_zf1 (s)                   1.82437\n",
      "time/backward_zf2 (s)                   1.74601\n",
      "time/data sampling (s)                  0.249317\n",
      "time/data storing (s)                   0.0136618\n",
      "time/evaluation sampling (s)            1.4241\n",
      "time/exploration sampling (s)           0.169657\n",
      "time/logging (s)                        0.0110405\n",
      "time/preback_alpha (s)                  0.548518\n",
      "time/preback_policy (s)                 0.602348\n",
      "time/preback_start (s)                  0.122683\n",
      "time/preback_zf (s)                     4.9468\n",
      "time/saving (s)                         0.00595068\n",
      "time/training (s)                       2.64572\n",
      "time/epoch (s)                         16.0187\n",
      "time/total (s)                       2127.94\n",
      "Epoch                                 137\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:36:56.462558 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 138 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 149000\n",
      "trainer/ZF1 Loss                       41.4887\n",
      "trainer/ZF2 Loss                       48.8697\n",
      "trainer/ZF Expert Reward                1.1852\n",
      "trainer/ZF Policy Reward              -12.3845\n",
      "trainer/ZF CHI2 Term                   72.7057\n",
      "trainer/Policy Loss                  -856.077\n",
      "trainer/Policy Grad Norm              345.348\n",
      "trainer/Policy Param Norm              38.1065\n",
      "trainer/Zf1 Grad Norm               16779.5\n",
      "trainer/Zf1 Param Norm                101.105\n",
      "trainer/Zf2 Grad Norm               16496.2\n",
      "trainer/Zf2 Param Norm                 98.0801\n",
      "trainer/Z Expert Predictions Mean    1179.77\n",
      "trainer/Z Expert Predictions Std      189.974\n",
      "trainer/Z Expert Predictions Max     1454.98\n",
      "trainer/Z Expert Predictions Min      604.865\n",
      "trainer/Z Policy Predictions Mean     840.696\n",
      "trainer/Z Policy Predictions Std      438.803\n",
      "trainer/Z Policy Predictions Max     1390.51\n",
      "trainer/Z Policy Predictions Min     -335.298\n",
      "trainer/Z Expert Targets Mean        1178.59\n",
      "trainer/Z Expert Targets Std          192.483\n",
      "trainer/Z Expert Targets Max         1439.33\n",
      "trainer/Z Expert Targets Min          607.561\n",
      "trainer/Z Policy Targets Mean         853.081\n",
      "trainer/Z Policy Targets Std          437.589\n",
      "trainer/Z Policy Targets Max         1398.94\n",
      "trainer/Z Policy Targets Min         -345.052\n",
      "trainer/Log Pis Mean                   14.0978\n",
      "trainer/Log Pis Std                     6.34511\n",
      "trainer/Policy mu Mean                  0.891967\n",
      "trainer/Policy mu Std                   3.22137\n",
      "trainer/Policy log std Mean            -3.88728\n",
      "trainer/Policy log std Std              1.30975\n",
      "exploration/num steps total        143030\n",
      "exploration/num paths total           964\n",
      "evaluation/num steps total         925083\n",
      "evaluation/num paths total           1404\n",
      "evaluation/path length Mean           979.9\n",
      "evaluation/path length Std             60.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            799\n",
      "evaluation/Rewards Mean                 3.55177\n",
      "evaluation/Rewards Std                  0.595922\n",
      "evaluation/Rewards Max                  4.6443\n",
      "evaluation/Rewards Min                  0.600729\n",
      "evaluation/Returns Mean              3480.38\n",
      "evaluation/Returns Std                210.407\n",
      "evaluation/Returns Max               3582.64\n",
      "evaluation/Returns Min               2851.46\n",
      "evaluation/Estimation Bias Mean      1116.83\n",
      "evaluation/Estimation Bias Std        311.821\n",
      "evaluation/EB/Q_True Mean              33.3894\n",
      "evaluation/EB/Q_True Std              101.76\n",
      "evaluation/EB/Q_Pred Mean            1150.22\n",
      "evaluation/EB/Q_Pred Std              268.365\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3480.38\n",
      "evaluation/Actions Mean                 0.03524\n",
      "evaluation/Actions Std                  0.579624\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77594\n",
      "time/backward_zf1 (s)                   1.86333\n",
      "time/backward_zf2 (s)                   1.79557\n",
      "time/data sampling (s)                  0.241255\n",
      "time/data storing (s)                   0.013755\n",
      "time/evaluation sampling (s)            1.40056\n",
      "time/exploration sampling (s)           0.170371\n",
      "time/logging (s)                        0.0132663\n",
      "time/preback_alpha (s)                  0.541602\n",
      "time/preback_policy (s)                 0.59886\n",
      "time/preback_start (s)                  0.120611\n",
      "time/preback_zf (s)                     4.93057\n",
      "time/saving (s)                         0.00546011\n",
      "time/training (s)                       2.56033\n",
      "time/epoch (s)                         16.0315\n",
      "time/total (s)                       2143.99\n",
      "Epoch                                 138\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:37:12.483844 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 139 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 150000\n",
      "trainer/ZF1 Loss                       38.054\n",
      "trainer/ZF2 Loss                       73.5007\n",
      "trainer/ZF Expert Reward               16.8475\n",
      "trainer/ZF Policy Reward                2.0546\n",
      "trainer/ZF CHI2 Term                   83.7898\n",
      "trainer/Policy Loss                  -892.038\n",
      "trainer/Policy Grad Norm              621.262\n",
      "trainer/Policy Param Norm              38.1801\n",
      "trainer/Zf1 Grad Norm               39608.2\n",
      "trainer/Zf1 Param Norm                101.407\n",
      "trainer/Zf2 Grad Norm               58687\n",
      "trainer/Zf2 Param Norm                 98.3451\n",
      "trainer/Z Expert Predictions Mean    1210.75\n",
      "trainer/Z Expert Predictions Std      182.27\n",
      "trainer/Z Expert Predictions Max     1451.17\n",
      "trainer/Z Expert Predictions Min      594.919\n",
      "trainer/Z Policy Predictions Mean     896.13\n",
      "trainer/Z Policy Predictions Std      399.705\n",
      "trainer/Z Policy Predictions Max     1395.77\n",
      "trainer/Z Policy Predictions Min     -378.156\n",
      "trainer/Z Expert Targets Mean        1193.9\n",
      "trainer/Z Expert Targets Std          182.761\n",
      "trainer/Z Expert Targets Max         1442.6\n",
      "trainer/Z Expert Targets Min          560.597\n",
      "trainer/Z Policy Targets Mean         894.075\n",
      "trainer/Z Policy Targets Std          395.077\n",
      "trainer/Z Policy Targets Max         1395.4\n",
      "trainer/Z Policy Targets Min         -376.29\n",
      "trainer/Log Pis Mean                   13.3531\n",
      "trainer/Log Pis Std                     4.7378\n",
      "trainer/Policy mu Mean                  0.42968\n",
      "trainer/Policy mu Std                   2.44715\n",
      "trainer/Policy log std Mean            -4.00386\n",
      "trainer/Policy log std Std              1.16672\n",
      "exploration/num steps total        147030\n",
      "exploration/num paths total           968\n",
      "evaluation/num steps total         932374\n",
      "evaluation/num paths total           1414\n",
      "evaluation/path length Mean           729.1\n",
      "evaluation/path length Std            251.777\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            393\n",
      "evaluation/Rewards Mean                 3.5293\n",
      "evaluation/Rewards Std                  0.648439\n",
      "evaluation/Rewards Max                  4.88405\n",
      "evaluation/Rewards Min                  0.674482\n",
      "evaluation/Returns Mean              2573.21\n",
      "evaluation/Returns Std                918.864\n",
      "evaluation/Returns Max               3576\n",
      "evaluation/Returns Min               1337.75\n",
      "evaluation/Estimation Bias Mean       971.683\n",
      "evaluation/Estimation Bias Std        425.441\n",
      "evaluation/EB/Q_True Mean              44.9067\n",
      "evaluation/EB/Q_True Std              116.099\n",
      "evaluation/EB/Q_Pred Mean            1016.59\n",
      "evaluation/EB/Q_Pred Std              386.95\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2573.21\n",
      "evaluation/Actions Mean                 0.0308724\n",
      "evaluation/Actions Std                  0.585809\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83109\n",
      "time/backward_zf1 (s)                   1.92189\n",
      "time/backward_zf2 (s)                   1.87393\n",
      "time/data sampling (s)                  0.24215\n",
      "time/data storing (s)                   0.0134765\n",
      "time/evaluation sampling (s)            1.39348\n",
      "time/exploration sampling (s)           0.174558\n",
      "time/logging (s)                        0.00876266\n",
      "time/preback_alpha (s)                  0.541771\n",
      "time/preback_policy (s)                 0.619172\n",
      "time/preback_start (s)                  0.12056\n",
      "time/preback_zf (s)                     4.94596\n",
      "time/saving (s)                         0.00475063\n",
      "time/training (s)                       2.2637\n",
      "time/epoch (s)                         15.9552\n",
      "time/total (s)                       2159.97\n",
      "Epoch                                 139\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:37:28.458896 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 140 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 151000\n",
      "trainer/ZF1 Loss                       45.8634\n",
      "trainer/ZF2 Loss                       39.0508\n",
      "trainer/ZF Expert Reward                9.75749\n",
      "trainer/ZF Policy Reward               -2.61098\n",
      "trainer/ZF CHI2 Term                   68.3362\n",
      "trainer/Policy Loss                  -851.306\n",
      "trainer/Policy Grad Norm              450.499\n",
      "trainer/Policy Param Norm              38.2439\n",
      "trainer/Zf1 Grad Norm               16899.9\n",
      "trainer/Zf1 Param Norm                101.725\n",
      "trainer/Zf2 Grad Norm               16883.4\n",
      "trainer/Zf2 Param Norm                 98.6259\n",
      "trainer/Z Expert Predictions Mean    1191.03\n",
      "trainer/Z Expert Predictions Std      189.912\n",
      "trainer/Z Expert Predictions Max     1485.69\n",
      "trainer/Z Expert Predictions Min      641.073\n",
      "trainer/Z Policy Predictions Mean     841.973\n",
      "trainer/Z Policy Predictions Std      420.253\n",
      "trainer/Z Policy Predictions Max     1391.75\n",
      "trainer/Z Policy Predictions Min     -350.528\n",
      "trainer/Z Expert Targets Mean        1181.28\n",
      "trainer/Z Expert Targets Std          188.867\n",
      "trainer/Z Expert Targets Max         1464.08\n",
      "trainer/Z Expert Targets Min          632.801\n",
      "trainer/Z Policy Targets Mean         844.584\n",
      "trainer/Z Policy Targets Std          418.497\n",
      "trainer/Z Policy Targets Max         1390.73\n",
      "trainer/Z Policy Targets Min         -374.751\n",
      "trainer/Log Pis Mean                   13.6471\n",
      "trainer/Log Pis Std                     5.60546\n",
      "trainer/Policy mu Mean                  0.640892\n",
      "trainer/Policy mu Std                   2.98527\n",
      "trainer/Policy log std Mean            -3.72338\n",
      "trainer/Policy log std Std              1.25511\n",
      "exploration/num steps total        147030\n",
      "exploration/num paths total           968\n",
      "evaluation/num steps total         942374\n",
      "evaluation/num paths total           1424\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.49016\n",
      "evaluation/Rewards Std                  0.594641\n",
      "evaluation/Rewards Max                  4.63288\n",
      "evaluation/Rewards Min                  0.649207\n",
      "evaluation/Returns Mean              3490.16\n",
      "evaluation/Returns Std                  9.98641\n",
      "evaluation/Returns Max               3511.42\n",
      "evaluation/Returns Min               3470.5\n",
      "evaluation/Estimation Bias Mean      1118.6\n",
      "evaluation/Estimation Bias Std        194.433\n",
      "evaluation/EB/Q_True Mean              32.2659\n",
      "evaluation/EB/Q_True Std               99.3366\n",
      "evaluation/EB/Q_Pred Mean            1150.87\n",
      "evaluation/EB/Q_Pred Std              167.915\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3490.16\n",
      "evaluation/Actions Mean                 0.0241813\n",
      "evaluation/Actions Std                  0.577831\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.71158\n",
      "time/backward_zf1 (s)                   1.83466\n",
      "time/backward_zf2 (s)                   1.75911\n",
      "time/data sampling (s)                  0.249331\n",
      "time/data storing (s)                   0.0138851\n",
      "time/evaluation sampling (s)            1.31685\n",
      "time/exploration sampling (s)           0.168905\n",
      "time/logging (s)                        0.0119145\n",
      "time/preback_alpha (s)                  0.546468\n",
      "time/preback_policy (s)                 0.604235\n",
      "time/preback_start (s)                  0.122055\n",
      "time/preback_zf (s)                     4.95834\n",
      "time/saving (s)                         0.00544348\n",
      "time/training (s)                       2.6013\n",
      "time/epoch (s)                         15.9041\n",
      "time/total (s)                       2175.9\n",
      "Epoch                                 140\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:37:44.366512 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 141 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 152000\n",
      "trainer/ZF1 Loss                       59.3901\n",
      "trainer/ZF2 Loss                       58.576\n",
      "trainer/ZF Expert Reward                6.67805\n",
      "trainer/ZF Policy Reward               -5.7778\n",
      "trainer/ZF CHI2 Term                   85.215\n",
      "trainer/Policy Loss                  -843.777\n",
      "trainer/Policy Grad Norm              842.347\n",
      "trainer/Policy Param Norm              38.3064\n",
      "trainer/Zf1 Grad Norm               29912.1\n",
      "trainer/Zf1 Param Norm                102.05\n",
      "trainer/Zf2 Grad Norm               19898.3\n",
      "trainer/Zf2 Param Norm                 98.9038\n",
      "trainer/Z Expert Predictions Mean    1197.73\n",
      "trainer/Z Expert Predictions Std      177.978\n",
      "trainer/Z Expert Predictions Max     1496.54\n",
      "trainer/Z Expert Predictions Min      658.346\n",
      "trainer/Z Policy Predictions Mean     834.067\n",
      "trainer/Z Policy Predictions Std      417.869\n",
      "trainer/Z Policy Predictions Max     1387.88\n",
      "trainer/Z Policy Predictions Min     -408.354\n",
      "trainer/Z Expert Targets Mean        1191.05\n",
      "trainer/Z Expert Targets Std          177.2\n",
      "trainer/Z Expert Targets Max         1473.09\n",
      "trainer/Z Expert Targets Min          640.675\n",
      "trainer/Z Policy Targets Mean         839.845\n",
      "trainer/Z Policy Targets Std          417.342\n",
      "trainer/Z Policy Targets Max         1374.16\n",
      "trainer/Z Policy Targets Min         -426.125\n",
      "trainer/Log Pis Mean                   13.9153\n",
      "trainer/Log Pis Std                     5.72091\n",
      "trainer/Policy mu Mean                  0.438819\n",
      "trainer/Policy mu Std                   2.78828\n",
      "trainer/Policy log std Mean            -3.89308\n",
      "trainer/Policy log std Std              1.22457\n",
      "exploration/num steps total        148030\n",
      "exploration/num paths total           969\n",
      "evaluation/num steps total         952374\n",
      "evaluation/num paths total           1434\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.53604\n",
      "evaluation/Rewards Std                  0.585945\n",
      "evaluation/Rewards Max                  4.57087\n",
      "evaluation/Rewards Min                  0.690999\n",
      "evaluation/Returns Mean              3536.04\n",
      "evaluation/Returns Std                 14.42\n",
      "evaluation/Returns Max               3564.19\n",
      "evaluation/Returns Min               3516.74\n",
      "evaluation/Estimation Bias Mean      1162.92\n",
      "evaluation/Estimation Bias Std        205.086\n",
      "evaluation/EB/Q_True Mean              32.5857\n",
      "evaluation/EB/Q_True Std              100.468\n",
      "evaluation/EB/Q_Pred Mean            1195.5\n",
      "evaluation/EB/Q_Pred Std              179.939\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3536.04\n",
      "evaluation/Actions Mean                 0.0310939\n",
      "evaluation/Actions Std                  0.576051\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.69206\n",
      "time/backward_zf1 (s)                   1.81539\n",
      "time/backward_zf2 (s)                   1.74433\n",
      "time/data sampling (s)                  0.252515\n",
      "time/data storing (s)                   0.0137344\n",
      "time/evaluation sampling (s)            1.33809\n",
      "time/exploration sampling (s)           0.168959\n",
      "time/logging (s)                        0.0151634\n",
      "time/preback_alpha (s)                  0.545436\n",
      "time/preback_policy (s)                 0.598624\n",
      "time/preback_start (s)                  0.123012\n",
      "time/preback_zf (s)                     4.94841\n",
      "time/saving (s)                         0.00534434\n",
      "time/training (s)                       2.58447\n",
      "time/epoch (s)                         15.8455\n",
      "time/total (s)                       2191.77\n",
      "Epoch                                 141\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:38:00.526475 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 142 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 153000\n",
      "trainer/ZF1 Loss                       69.2195\n",
      "trainer/ZF2 Loss                       65.0889\n",
      "trainer/ZF Expert Reward               12.0589\n",
      "trainer/ZF Policy Reward                2.86403\n",
      "trainer/ZF CHI2 Term                   91.032\n",
      "trainer/Policy Loss                  -784.388\n",
      "trainer/Policy Grad Norm              549.605\n",
      "trainer/Policy Param Norm              38.3656\n",
      "trainer/Zf1 Grad Norm               14094.8\n",
      "trainer/Zf1 Param Norm                102.379\n",
      "trainer/Zf2 Grad Norm               18194.2\n",
      "trainer/Zf2 Param Norm                 99.2036\n",
      "trainer/Z Expert Predictions Mean    1207.21\n",
      "trainer/Z Expert Predictions Std      179.508\n",
      "trainer/Z Expert Predictions Max     1536.85\n",
      "trainer/Z Expert Predictions Min      644.412\n",
      "trainer/Z Policy Predictions Mean     772.761\n",
      "trainer/Z Policy Predictions Std      477.346\n",
      "trainer/Z Policy Predictions Max     1438.19\n",
      "trainer/Z Policy Predictions Min     -499\n",
      "trainer/Z Expert Targets Mean        1195.15\n",
      "trainer/Z Expert Targets Std          177.175\n",
      "trainer/Z Expert Targets Max         1510.26\n",
      "trainer/Z Expert Targets Min          634.19\n",
      "trainer/Z Policy Targets Mean         769.897\n",
      "trainer/Z Policy Targets Std          474.35\n",
      "trainer/Z Policy Targets Max         1432.92\n",
      "trainer/Z Policy Targets Min         -476.513\n",
      "trainer/Log Pis Mean                   14.8313\n",
      "trainer/Log Pis Std                     6.04739\n",
      "trainer/Policy mu Mean                  0.689254\n",
      "trainer/Policy mu Std                   3.23452\n",
      "trainer/Policy log std Mean            -3.79034\n",
      "trainer/Policy log std Std              1.30013\n",
      "exploration/num steps total        148030\n",
      "exploration/num paths total           969\n",
      "evaluation/num steps total         962374\n",
      "evaluation/num paths total           1444\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.5416\n",
      "evaluation/Rewards Std                  0.597599\n",
      "evaluation/Rewards Max                  4.69871\n",
      "evaluation/Rewards Min                  0.644116\n",
      "evaluation/Returns Mean              3541.6\n",
      "evaluation/Returns Std                 12.1922\n",
      "evaluation/Returns Max               3571.32\n",
      "evaluation/Returns Min               3529.98\n",
      "evaluation/Estimation Bias Mean      1169.5\n",
      "evaluation/Estimation Bias Std        220.964\n",
      "evaluation/EB/Q_True Mean              32.8383\n",
      "evaluation/EB/Q_True Std              101.17\n",
      "evaluation/EB/Q_Pred Mean            1202.34\n",
      "evaluation/EB/Q_Pred Std              199.489\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3541.6\n",
      "evaluation/Actions Mean                 0.0241777\n",
      "evaluation/Actions Std                  0.578563\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.83502\n",
      "time/backward_zf1 (s)                   1.92932\n",
      "time/backward_zf2 (s)                   1.89144\n",
      "time/data sampling (s)                  0.250625\n",
      "time/data storing (s)                   0.014049\n",
      "time/evaluation sampling (s)            1.44264\n",
      "time/exploration sampling (s)           0.167375\n",
      "time/logging (s)                        0.0117799\n",
      "time/preback_alpha (s)                  0.547974\n",
      "time/preback_policy (s)                 0.623997\n",
      "time/preback_start (s)                  0.121534\n",
      "time/preback_zf (s)                     4.96916\n",
      "time/saving (s)                         0.00535149\n",
      "time/training (s)                       2.28312\n",
      "time/epoch (s)                         16.0934\n",
      "time/total (s)                       2207.88\n",
      "Epoch                                 142\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:38:16.552134 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 143 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 154000\n",
      "trainer/ZF1 Loss                       31.9546\n",
      "trainer/ZF2 Loss                       43.6581\n",
      "trainer/ZF Expert Reward               17.3458\n",
      "trainer/ZF Policy Reward                0.942259\n",
      "trainer/ZF CHI2 Term                   67.3962\n",
      "trainer/Policy Loss                  -858.839\n",
      "trainer/Policy Grad Norm              508.759\n",
      "trainer/Policy Param Norm              38.4167\n",
      "trainer/Zf1 Grad Norm               24117.3\n",
      "trainer/Zf1 Param Norm                102.709\n",
      "trainer/Zf2 Grad Norm               33113.1\n",
      "trainer/Zf2 Param Norm                 99.5076\n",
      "trainer/Z Expert Predictions Mean    1219.71\n",
      "trainer/Z Expert Predictions Std      187.725\n",
      "trainer/Z Expert Predictions Max     1547.16\n",
      "trainer/Z Expert Predictions Min      633.647\n",
      "trainer/Z Policy Predictions Mean     851.575\n",
      "trainer/Z Policy Predictions Std      429.191\n",
      "trainer/Z Policy Predictions Max     1435.17\n",
      "trainer/Z Policy Predictions Min     -398.595\n",
      "trainer/Z Expert Targets Mean        1202.37\n",
      "trainer/Z Expert Targets Std          188.174\n",
      "trainer/Z Expert Targets Max         1538.84\n",
      "trainer/Z Expert Targets Min          596.798\n",
      "trainer/Z Policy Targets Mean         850.633\n",
      "trainer/Z Policy Targets Std          421.833\n",
      "trainer/Z Policy Targets Max         1438.04\n",
      "trainer/Z Policy Targets Min         -386.712\n",
      "trainer/Log Pis Mean                   13.3195\n",
      "trainer/Log Pis Std                     4.83069\n",
      "trainer/Policy mu Mean                  0.170359\n",
      "trainer/Policy mu Std                   2.53264\n",
      "trainer/Policy log std Mean            -4.00728\n",
      "trainer/Policy log std Std              1.04332\n",
      "exploration/num steps total        148030\n",
      "exploration/num paths total           969\n",
      "evaluation/num steps total         972374\n",
      "evaluation/num paths total           1454\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.56581\n",
      "evaluation/Rewards Std                  0.585868\n",
      "evaluation/Rewards Max                  4.64932\n",
      "evaluation/Rewards Min                  0.66374\n",
      "evaluation/Returns Mean              3565.81\n",
      "evaluation/Returns Std                 13.1501\n",
      "evaluation/Returns Max               3596.65\n",
      "evaluation/Returns Min               3551.11\n",
      "evaluation/Estimation Bias Mean      1161.63\n",
      "evaluation/Estimation Bias Std        213.077\n",
      "evaluation/EB/Q_True Mean              32.8621\n",
      "evaluation/EB/Q_True Std              101.337\n",
      "evaluation/EB/Q_Pred Mean            1194.49\n",
      "evaluation/EB/Q_Pred Std              187.663\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3565.81\n",
      "evaluation/Actions Mean                 0.0344248\n",
      "evaluation/Actions Std                  0.579487\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.8034\n",
      "time/backward_zf1 (s)                   1.89065\n",
      "time/backward_zf2 (s)                   1.83749\n",
      "time/data sampling (s)                  0.226571\n",
      "time/data storing (s)                   0.0138264\n",
      "time/evaluation sampling (s)            1.40261\n",
      "time/exploration sampling (s)           0.16703\n",
      "time/logging (s)                        0.01317\n",
      "time/preback_alpha (s)                  0.541234\n",
      "time/preback_policy (s)                 0.612866\n",
      "time/preback_start (s)                  0.120241\n",
      "time/preback_zf (s)                     4.93811\n",
      "time/saving (s)                         0.00543904\n",
      "time/training (s)                       2.38923\n",
      "time/epoch (s)                         15.9619\n",
      "time/total (s)                       2223.86\n",
      "Epoch                                 143\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:38:32.421339 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 144 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 155000\n",
      "trainer/ZF1 Loss                       94.296\n",
      "trainer/ZF2 Loss                      149.8\n",
      "trainer/ZF Expert Reward               19.567\n",
      "trainer/ZF Policy Reward                3.56593\n",
      "trainer/ZF CHI2 Term                  152.391\n",
      "trainer/Policy Loss                  -830.268\n",
      "trainer/Policy Grad Norm              318.682\n",
      "trainer/Policy Param Norm              38.4746\n",
      "trainer/Zf1 Grad Norm               44830.8\n",
      "trainer/Zf1 Param Norm                103.063\n",
      "trainer/Zf2 Grad Norm               48241.5\n",
      "trainer/Zf2 Param Norm                 99.8243\n",
      "trainer/Z Expert Predictions Mean    1202.1\n",
      "trainer/Z Expert Predictions Std      219.347\n",
      "trainer/Z Expert Predictions Max     1561.51\n",
      "trainer/Z Expert Predictions Min      468.813\n",
      "trainer/Z Policy Predictions Mean     821.513\n",
      "trainer/Z Policy Predictions Std      454.621\n",
      "trainer/Z Policy Predictions Max     1503.3\n",
      "trainer/Z Policy Predictions Min     -449.387\n",
      "trainer/Z Expert Targets Mean        1182.53\n",
      "trainer/Z Expert Targets Std          225.725\n",
      "trainer/Z Expert Targets Max         1543.5\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         817.947\n",
      "trainer/Z Policy Targets Std          448.31\n",
      "trainer/Z Policy Targets Max         1491.74\n",
      "trainer/Z Policy Targets Min         -405.211\n",
      "trainer/Log Pis Mean                   14.4873\n",
      "trainer/Log Pis Std                     6.04075\n",
      "trainer/Policy mu Mean                  0.820114\n",
      "trainer/Policy mu Std                   3.49321\n",
      "trainer/Policy log std Mean            -3.7898\n",
      "trainer/Policy log std Std              1.35805\n",
      "exploration/num steps total        150030\n",
      "exploration/num paths total           971\n",
      "evaluation/num steps total         982374\n",
      "evaluation/num paths total           1464\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50451\n",
      "evaluation/Rewards Std                  0.576845\n",
      "evaluation/Rewards Max                  4.56874\n",
      "evaluation/Rewards Min                  0.702271\n",
      "evaluation/Returns Mean              3504.51\n",
      "evaluation/Returns Std                  6.63073\n",
      "evaluation/Returns Max               3521.14\n",
      "evaluation/Returns Min               3497.67\n",
      "evaluation/Estimation Bias Mean      1146.01\n",
      "evaluation/Estimation Bias Std        194.54\n",
      "evaluation/EB/Q_True Mean              32.3867\n",
      "evaluation/EB/Q_True Std               99.757\n",
      "evaluation/EB/Q_Pred Mean            1178.4\n",
      "evaluation/EB/Q_Pred Std              173.795\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3504.51\n",
      "evaluation/Actions Mean                 0.0252266\n",
      "evaluation/Actions Std                  0.575467\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.64112\n",
      "time/backward_zf1 (s)                   1.76801\n",
      "time/backward_zf2 (s)                   1.68508\n",
      "time/data sampling (s)                  0.224991\n",
      "time/data storing (s)                   0.0134286\n",
      "time/evaluation sampling (s)            1.40738\n",
      "time/exploration sampling (s)           0.167428\n",
      "time/logging (s)                        0.0164186\n",
      "time/preback_alpha (s)                  0.540047\n",
      "time/preback_policy (s)                 0.583811\n",
      "time/preback_start (s)                  0.122242\n",
      "time/preback_zf (s)                     4.94132\n",
      "time/saving (s)                         0.00539652\n",
      "time/training (s)                       2.69186\n",
      "time/epoch (s)                         15.8085\n",
      "time/total (s)                       2239.69\n",
      "Epoch                                 144\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:38:48.404052 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 145 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 156000\n",
      "trainer/ZF1 Loss                       55.5132\n",
      "trainer/ZF2 Loss                       48.8077\n",
      "trainer/ZF Expert Reward                5.54065\n",
      "trainer/ZF Policy Reward               -9.18664\n",
      "trainer/ZF CHI2 Term                   81.5678\n",
      "trainer/Policy Loss                  -859.474\n",
      "trainer/Policy Grad Norm              377.219\n",
      "trainer/Policy Param Norm              38.5324\n",
      "trainer/Zf1 Grad Norm               35428.2\n",
      "trainer/Zf1 Param Norm                103.404\n",
      "trainer/Zf2 Grad Norm               23815.4\n",
      "trainer/Zf2 Param Norm                100.136\n",
      "trainer/Z Expert Predictions Mean    1196.11\n",
      "trainer/Z Expert Predictions Std      202.621\n",
      "trainer/Z Expert Predictions Max     1561.98\n",
      "trainer/Z Expert Predictions Min      629.646\n",
      "trainer/Z Policy Predictions Mean     844.201\n",
      "trainer/Z Policy Predictions Std      445.78\n",
      "trainer/Z Policy Predictions Max     1491.49\n",
      "trainer/Z Policy Predictions Min     -456.561\n",
      "trainer/Z Expert Targets Mean        1190.57\n",
      "trainer/Z Expert Targets Std          204.098\n",
      "trainer/Z Expert Targets Max         1554.08\n",
      "trainer/Z Expert Targets Min          639.365\n",
      "trainer/Z Policy Targets Mean         853.388\n",
      "trainer/Z Policy Targets Std          439.362\n",
      "trainer/Z Policy Targets Max         1510.47\n",
      "trainer/Z Policy Targets Min         -420.114\n",
      "trainer/Log Pis Mean                   14.8284\n",
      "trainer/Log Pis Std                     6.29501\n",
      "trainer/Policy mu Mean                  0.702467\n",
      "trainer/Policy mu Std                   3.36205\n",
      "trainer/Policy log std Mean            -3.87956\n",
      "trainer/Policy log std Std              1.32362\n",
      "exploration/num steps total        151030\n",
      "exploration/num paths total           972\n",
      "evaluation/num steps total         992374\n",
      "evaluation/num paths total           1474\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50219\n",
      "evaluation/Rewards Std                  0.586824\n",
      "evaluation/Rewards Max                  4.56245\n",
      "evaluation/Rewards Min                  0.663608\n",
      "evaluation/Returns Mean              3502.19\n",
      "evaluation/Returns Std                 18.856\n",
      "evaluation/Returns Max               3540.93\n",
      "evaluation/Returns Min               3476.64\n",
      "evaluation/Estimation Bias Mean      1114.57\n",
      "evaluation/Estimation Bias Std        205.309\n",
      "evaluation/EB/Q_True Mean              32.2929\n",
      "evaluation/EB/Q_True Std               99.5218\n",
      "evaluation/EB/Q_Pred Mean            1146.86\n",
      "evaluation/EB/Q_Pred Std              179.337\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3502.19\n",
      "evaluation/Actions Mean                 0.020707\n",
      "evaluation/Actions Std                  0.580144\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.73987\n",
      "time/backward_zf1 (s)                   1.84681\n",
      "time/backward_zf2 (s)                   1.79292\n",
      "time/data sampling (s)                  0.241734\n",
      "time/data storing (s)                   0.0139202\n",
      "time/evaluation sampling (s)            1.35693\n",
      "time/exploration sampling (s)           0.167769\n",
      "time/logging (s)                        0.011937\n",
      "time/preback_alpha (s)                  0.544163\n",
      "time/preback_policy (s)                 0.610569\n",
      "time/preback_start (s)                  0.122762\n",
      "time/preback_zf (s)                     4.94484\n",
      "time/saving (s)                         0.00484335\n",
      "time/training (s)                       2.51034\n",
      "time/epoch (s)                         15.9094\n",
      "time/total (s)                       2255.62\n",
      "Epoch                                 145\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:39:04.408760 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 146 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 157000\n",
      "trainer/ZF1 Loss                      107.029\n",
      "trainer/ZF2 Loss                       75.2207\n",
      "trainer/ZF Expert Reward               11.65\n",
      "trainer/ZF Policy Reward               -2.11892\n",
      "trainer/ZF CHI2 Term                  117.961\n",
      "trainer/Policy Loss                  -875.074\n",
      "trainer/Policy Grad Norm              698.426\n",
      "trainer/Policy Param Norm              38.5872\n",
      "trainer/Zf1 Grad Norm               23633.2\n",
      "trainer/Zf1 Param Norm                103.771\n",
      "trainer/Zf2 Grad Norm               12968.8\n",
      "trainer/Zf2 Param Norm                100.47\n",
      "trainer/Z Expert Predictions Mean    1210.86\n",
      "trainer/Z Expert Predictions Std      204.582\n",
      "trainer/Z Expert Predictions Max     1611.4\n",
      "trainer/Z Expert Predictions Min      639.382\n",
      "trainer/Z Policy Predictions Mean     864.71\n",
      "trainer/Z Policy Predictions Std      421.662\n",
      "trainer/Z Policy Predictions Max     1506.03\n",
      "trainer/Z Policy Predictions Min     -476.497\n",
      "trainer/Z Expert Targets Mean        1199.21\n",
      "trainer/Z Expert Targets Std          204.223\n",
      "trainer/Z Expert Targets Max         1602.97\n",
      "trainer/Z Expert Targets Min          614.707\n",
      "trainer/Z Policy Targets Mean         866.829\n",
      "trainer/Z Policy Targets Std          416.514\n",
      "trainer/Z Policy Targets Max         1520.91\n",
      "trainer/Z Policy Targets Min         -489.313\n",
      "trainer/Log Pis Mean                   13.1992\n",
      "trainer/Log Pis Std                     5.03134\n",
      "trainer/Policy mu Mean                  0.623996\n",
      "trainer/Policy mu Std                   2.75263\n",
      "trainer/Policy log std Mean            -3.85176\n",
      "trainer/Policy log std Std              1.22803\n",
      "exploration/num steps total        151030\n",
      "exploration/num paths total           972\n",
      "evaluation/num steps total              1.00237e+06\n",
      "evaluation/num paths total           1484\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.47818\n",
      "evaluation/Rewards Std                  0.571146\n",
      "evaluation/Rewards Max                  4.51148\n",
      "evaluation/Rewards Min                  0.703409\n",
      "evaluation/Returns Mean              3478.18\n",
      "evaluation/Returns Std                 12.4692\n",
      "evaluation/Returns Max               3491.06\n",
      "evaluation/Returns Min               3458.42\n",
      "evaluation/Estimation Bias Mean      1122.38\n",
      "evaluation/Estimation Bias Std        214.577\n",
      "evaluation/EB/Q_True Mean              32.0027\n",
      "evaluation/EB/Q_True Std               98.8231\n",
      "evaluation/EB/Q_Pred Mean            1154.39\n",
      "evaluation/EB/Q_Pred Std              192.586\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3478.18\n",
      "evaluation/Actions Mean                 0.0452769\n",
      "evaluation/Actions Std                  0.564112\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999989\n",
      "time/backward_policy (s)                1.78128\n",
      "time/backward_zf1 (s)                   1.89352\n",
      "time/backward_zf2 (s)                   1.8295\n",
      "time/data sampling (s)                  0.241031\n",
      "time/data storing (s)                   0.0135058\n",
      "time/evaluation sampling (s)            1.37972\n",
      "time/exploration sampling (s)           0.164446\n",
      "time/logging (s)                        0.0120796\n",
      "time/preback_alpha (s)                  0.544446\n",
      "time/preback_policy (s)                 0.609174\n",
      "time/preback_start (s)                  0.12078\n",
      "time/preback_zf (s)                     4.94046\n",
      "time/saving (s)                         0.00525868\n",
      "time/training (s)                       2.40445\n",
      "time/epoch (s)                         15.9397\n",
      "time/total (s)                       2271.58\n",
      "Epoch                                 146\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:39:20.545893 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 147 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 158000\n",
      "trainer/ZF1 Loss                       51.5171\n",
      "trainer/ZF2 Loss                       65.484\n",
      "trainer/ZF Expert Reward               19.1906\n",
      "trainer/ZF Policy Reward                0.18422\n",
      "trainer/ZF CHI2 Term                   90.4622\n",
      "trainer/Policy Loss                  -891.39\n",
      "trainer/Policy Grad Norm              585.088\n",
      "trainer/Policy Param Norm              38.6491\n",
      "trainer/Zf1 Grad Norm               14491.9\n",
      "trainer/Zf1 Param Norm                104.091\n",
      "trainer/Zf2 Grad Norm               12932.8\n",
      "trainer/Zf2 Param Norm                100.761\n",
      "trainer/Z Expert Predictions Mean    1221.93\n",
      "trainer/Z Expert Predictions Std      223.096\n",
      "trainer/Z Expert Predictions Max     1617.37\n",
      "trainer/Z Expert Predictions Min      633.09\n",
      "trainer/Z Policy Predictions Mean     882.722\n",
      "trainer/Z Policy Predictions Std      389.798\n",
      "trainer/Z Policy Predictions Max     1565.4\n",
      "trainer/Z Policy Predictions Min     -288.089\n",
      "trainer/Z Expert Targets Mean        1202.74\n",
      "trainer/Z Expert Targets Std          218.516\n",
      "trainer/Z Expert Targets Max         1597\n",
      "trainer/Z Expert Targets Min          580.454\n",
      "trainer/Z Policy Targets Mean         882.538\n",
      "trainer/Z Policy Targets Std          385.732\n",
      "trainer/Z Policy Targets Max         1543.42\n",
      "trainer/Z Policy Targets Min         -261.712\n",
      "trainer/Log Pis Mean                   13.0861\n",
      "trainer/Log Pis Std                     4.54753\n",
      "trainer/Policy mu Mean                  0.545517\n",
      "trainer/Policy mu Std                   2.74645\n",
      "trainer/Policy log std Mean            -3.83043\n",
      "trainer/Policy log std Std              1.22636\n",
      "exploration/num steps total        152030\n",
      "exploration/num paths total           973\n",
      "evaluation/num steps total              1.01135e+06\n",
      "evaluation/num paths total           1494\n",
      "evaluation/path length Mean           898\n",
      "evaluation/path length Std            163.754\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            555\n",
      "evaluation/Rewards Mean                 3.49546\n",
      "evaluation/Rewards Std                  0.62459\n",
      "evaluation/Rewards Max                  6.55256\n",
      "evaluation/Rewards Min                  0.640678\n",
      "evaluation/Returns Mean              3138.93\n",
      "evaluation/Returns Std                557.321\n",
      "evaluation/Returns Max               3539.65\n",
      "evaluation/Returns Min               1934.54\n",
      "evaluation/Estimation Bias Mean      1028.13\n",
      "evaluation/Estimation Bias Std        376.669\n",
      "evaluation/EB/Q_True Mean              35.3663\n",
      "evaluation/EB/Q_True Std              102.577\n",
      "evaluation/EB/Q_Pred Mean            1063.49\n",
      "evaluation/EB/Q_Pred Std              354.554\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3138.93\n",
      "evaluation/Actions Mean                 0.0579129\n",
      "evaluation/Actions Std                  0.584278\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86312\n",
      "time/backward_zf1 (s)                   1.96414\n",
      "time/backward_zf2 (s)                   1.92155\n",
      "time/data sampling (s)                  0.233339\n",
      "time/data storing (s)                   0.0141213\n",
      "time/evaluation sampling (s)            1.41495\n",
      "time/exploration sampling (s)           0.172896\n",
      "time/logging (s)                        0.0106343\n",
      "time/preback_alpha (s)                  0.54676\n",
      "time/preback_policy (s)                 0.629045\n",
      "time/preback_start (s)                  0.121876\n",
      "time/preback_zf (s)                     4.9601\n",
      "time/saving (s)                         0.00510127\n",
      "time/training (s)                       2.20276\n",
      "time/epoch (s)                         16.0604\n",
      "time/total (s)                       2287.67\n",
      "Epoch                                 147\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:39:36.666725 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 148 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 159000\n",
      "trainer/ZF1 Loss                       87.3347\n",
      "trainer/ZF2 Loss                       88.1172\n",
      "trainer/ZF Expert Reward               18.7309\n",
      "trainer/ZF Policy Reward                2.98407\n",
      "trainer/ZF CHI2 Term                  117.165\n",
      "trainer/Policy Loss                  -864.196\n",
      "trainer/Policy Grad Norm              527.41\n",
      "trainer/Policy Param Norm              38.7305\n",
      "trainer/Zf1 Grad Norm               71672\n",
      "trainer/Zf1 Param Norm                104.422\n",
      "trainer/Zf2 Grad Norm               49501.3\n",
      "trainer/Zf2 Param Norm                101.079\n",
      "trainer/Z Expert Predictions Mean    1215.18\n",
      "trainer/Z Expert Predictions Std      204.842\n",
      "trainer/Z Expert Predictions Max     1644.42\n",
      "trainer/Z Expert Predictions Min      642.935\n",
      "trainer/Z Policy Predictions Mean     854.675\n",
      "trainer/Z Policy Predictions Std      419.048\n",
      "trainer/Z Policy Predictions Max     1590.07\n",
      "trainer/Z Policy Predictions Min     -326.412\n",
      "trainer/Z Expert Targets Mean        1196.45\n",
      "trainer/Z Expert Targets Std          204.412\n",
      "trainer/Z Expert Targets Max         1611.78\n",
      "trainer/Z Expert Targets Min          639.158\n",
      "trainer/Z Policy Targets Mean         851.691\n",
      "trainer/Z Policy Targets Std          415.639\n",
      "trainer/Z Policy Targets Max         1563.97\n",
      "trainer/Z Policy Targets Min         -296.251\n",
      "trainer/Log Pis Mean                   13.8304\n",
      "trainer/Log Pis Std                     5.56544\n",
      "trainer/Policy mu Mean                  0.556937\n",
      "trainer/Policy mu Std                   3.05492\n",
      "trainer/Policy log std Mean            -3.82936\n",
      "trainer/Policy log std Std              1.27223\n",
      "exploration/num steps total        153030\n",
      "exploration/num paths total           974\n",
      "evaluation/num steps total              1.02135e+06\n",
      "evaluation/num paths total           1504\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51922\n",
      "evaluation/Rewards Std                  0.592924\n",
      "evaluation/Rewards Max                  6.48102\n",
      "evaluation/Rewards Min                  0.65205\n",
      "evaluation/Returns Mean              3519.22\n",
      "evaluation/Returns Std                 43.0478\n",
      "evaluation/Returns Max               3603.35\n",
      "evaluation/Returns Min               3438.94\n",
      "evaluation/Estimation Bias Mean      1093.99\n",
      "evaluation/Estimation Bias Std        331.059\n",
      "evaluation/EB/Q_True Mean              33.4181\n",
      "evaluation/EB/Q_True Std              102.234\n",
      "evaluation/EB/Q_Pred Mean            1127.41\n",
      "evaluation/EB/Q_Pred Std              312.514\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3519.22\n",
      "evaluation/Actions Mean                 0.0468298\n",
      "evaluation/Actions Std                  0.57869\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7769\n",
      "time/backward_zf1 (s)                   1.88008\n",
      "time/backward_zf2 (s)                   1.81629\n",
      "time/data sampling (s)                  0.24432\n",
      "time/data storing (s)                   0.0138817\n",
      "time/evaluation sampling (s)            1.39826\n",
      "time/exploration sampling (s)           0.171044\n",
      "time/logging (s)                        0.0118306\n",
      "time/preback_alpha (s)                  0.546461\n",
      "time/preback_policy (s)                 0.613545\n",
      "time/preback_start (s)                  0.122016\n",
      "time/preback_zf (s)                     4.95865\n",
      "time/saving (s)                         0.00481045\n",
      "time/training (s)                       2.50003\n",
      "time/epoch (s)                         16.0581\n",
      "time/total (s)                       2303.75\n",
      "Epoch                                 148\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:39:52.632370 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 149 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 160000\n",
      "trainer/ZF1 Loss                       64.1637\n",
      "trainer/ZF2 Loss                       62.5286\n",
      "trainer/ZF Expert Reward               18.9619\n",
      "trainer/ZF Policy Reward                4.3539\n",
      "trainer/ZF CHI2 Term                   91.6981\n",
      "trainer/Policy Loss                  -936.667\n",
      "trainer/Policy Grad Norm              474.148\n",
      "trainer/Policy Param Norm              38.8195\n",
      "trainer/Zf1 Grad Norm               25441.8\n",
      "trainer/Zf1 Param Norm                104.781\n",
      "trainer/Zf2 Grad Norm               26998.4\n",
      "trainer/Zf2 Param Norm                101.408\n",
      "trainer/Z Expert Predictions Mean    1228.52\n",
      "trainer/Z Expert Predictions Std      212.68\n",
      "trainer/Z Expert Predictions Max     1646.43\n",
      "trainer/Z Expert Predictions Min      609.96\n",
      "trainer/Z Policy Predictions Mean     929.399\n",
      "trainer/Z Policy Predictions Std      424.75\n",
      "trainer/Z Policy Predictions Max     1594.38\n",
      "trainer/Z Policy Predictions Min     -261.54\n",
      "trainer/Z Expert Targets Mean        1209.56\n",
      "trainer/Z Expert Targets Std          212.422\n",
      "trainer/Z Expert Targets Max         1633.22\n",
      "trainer/Z Expert Targets Min          593.467\n",
      "trainer/Z Policy Targets Mean         925.045\n",
      "trainer/Z Policy Targets Std          418.453\n",
      "trainer/Z Policy Targets Max         1615.42\n",
      "trainer/Z Policy Targets Min         -263.454\n",
      "trainer/Log Pis Mean                   13.8827\n",
      "trainer/Log Pis Std                     5.55203\n",
      "trainer/Policy mu Mean                  0.404958\n",
      "trainer/Policy mu Std                   2.71671\n",
      "trainer/Policy log std Mean            -3.92694\n",
      "trainer/Policy log std Std              1.13543\n",
      "exploration/num steps total        157030\n",
      "exploration/num paths total           978\n",
      "evaluation/num steps total              1.03019e+06\n",
      "evaluation/num paths total           1516\n",
      "evaluation/path length Mean           736.5\n",
      "evaluation/path length Std            277.299\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            368\n",
      "evaluation/Rewards Mean                 3.49763\n",
      "evaluation/Rewards Std                  0.659885\n",
      "evaluation/Rewards Max                  5.29045\n",
      "evaluation/Rewards Min                  0.646074\n",
      "evaluation/Returns Mean              2576.01\n",
      "evaluation/Returns Std                996.722\n",
      "evaluation/Returns Max               3586.35\n",
      "evaluation/Returns Min               1234.84\n",
      "evaluation/Estimation Bias Mean       906.079\n",
      "evaluation/Estimation Bias Std        401.543\n",
      "evaluation/EB/Q_True Mean              36.6899\n",
      "evaluation/EB/Q_True Std              105.5\n",
      "evaluation/EB/Q_Pred Mean             942.769\n",
      "evaluation/EB/Q_Pred Std              369.411\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2576.01\n",
      "evaluation/Actions Mean                 0.0439319\n",
      "evaluation/Actions Std                  0.596949\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72259\n",
      "time/backward_zf1 (s)                   1.82402\n",
      "time/backward_zf2 (s)                   1.76511\n",
      "time/data sampling (s)                  0.236097\n",
      "time/data storing (s)                   0.0134801\n",
      "time/evaluation sampling (s)            1.39894\n",
      "time/exploration sampling (s)           0.174053\n",
      "time/logging (s)                        0.0102789\n",
      "time/preback_alpha (s)                  0.54132\n",
      "time/preback_policy (s)                 0.602594\n",
      "time/preback_start (s)                  0.121411\n",
      "time/preback_zf (s)                     4.93644\n",
      "time/saving (s)                         0.00510377\n",
      "time/training (s)                       2.54718\n",
      "time/epoch (s)                         15.8986\n",
      "time/total (s)                       2319.67\n",
      "Epoch                                 149\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:40:08.566614 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 150 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 161000\n",
      "trainer/ZF1 Loss                       81.2258\n",
      "trainer/ZF2 Loss                       90.0408\n",
      "trainer/ZF Expert Reward                6.03182\n",
      "trainer/ZF Policy Reward               -2.421\n",
      "trainer/ZF CHI2 Term                  108.082\n",
      "trainer/Policy Loss                  -941.725\n",
      "trainer/Policy Grad Norm              748.54\n",
      "trainer/Policy Param Norm              38.9165\n",
      "trainer/Zf1 Grad Norm               31665.4\n",
      "trainer/Zf1 Param Norm                105.137\n",
      "trainer/Zf2 Grad Norm               48632\n",
      "trainer/Zf2 Param Norm                101.729\n",
      "trainer/Z Expert Predictions Mean    1201.14\n",
      "trainer/Z Expert Predictions Std      223.165\n",
      "trainer/Z Expert Predictions Max     1679.6\n",
      "trainer/Z Expert Predictions Min      668.64\n",
      "trainer/Z Policy Predictions Mean     930.297\n",
      "trainer/Z Policy Predictions Std      384.394\n",
      "trainer/Z Policy Predictions Max     1561.53\n",
      "trainer/Z Policy Predictions Min     -305.625\n",
      "trainer/Z Expert Targets Mean        1195.11\n",
      "trainer/Z Expert Targets Std          223.226\n",
      "trainer/Z Expert Targets Max         1666.43\n",
      "trainer/Z Expert Targets Min          669.726\n",
      "trainer/Z Policy Targets Mean         932.718\n",
      "trainer/Z Policy Targets Std          382.839\n",
      "trainer/Z Policy Targets Max         1604.17\n",
      "trainer/Z Policy Targets Min         -296.131\n",
      "trainer/Log Pis Mean                   14.1378\n",
      "trainer/Log Pis Std                     5.38004\n",
      "trainer/Policy mu Mean                  0.60263\n",
      "trainer/Policy mu Std                   3.52744\n",
      "trainer/Policy log std Mean            -4.01649\n",
      "trainer/Policy log std Std              1.31034\n",
      "exploration/num steps total        157030\n",
      "exploration/num paths total           978\n",
      "evaluation/num steps total              1.03877e+06\n",
      "evaluation/num paths total           1526\n",
      "evaluation/path length Mean           857.5\n",
      "evaluation/path length Std            217.761\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            516\n",
      "evaluation/Rewards Mean                 3.43121\n",
      "evaluation/Rewards Std                  0.594392\n",
      "evaluation/Rewards Max                  5.29038\n",
      "evaluation/Rewards Min                  0.630832\n",
      "evaluation/Returns Mean              2942.26\n",
      "evaluation/Returns Std                782.547\n",
      "evaluation/Returns Max               3493.82\n",
      "evaluation/Returns Min               1725.38\n",
      "evaluation/Estimation Bias Mean       988.222\n",
      "evaluation/Estimation Bias Std        360.565\n",
      "evaluation/EB/Q_True Mean              37.6868\n",
      "evaluation/EB/Q_True Std              106.425\n",
      "evaluation/EB/Q_Pred Mean            1025.91\n",
      "evaluation/EB/Q_Pred Std              331.525\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2942.26\n",
      "evaluation/Actions Mean                 0.0427847\n",
      "evaluation/Actions Std                  0.584531\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.69295\n",
      "time/backward_zf1 (s)                   1.8086\n",
      "time/backward_zf2 (s)                   1.73355\n",
      "time/data sampling (s)                  0.248934\n",
      "time/data storing (s)                   0.014339\n",
      "time/evaluation sampling (s)            1.38812\n",
      "time/exploration sampling (s)           0.168611\n",
      "time/logging (s)                        0.0102524\n",
      "time/preback_alpha (s)                  0.543035\n",
      "time/preback_policy (s)                 0.597052\n",
      "time/preback_start (s)                  0.122002\n",
      "time/preback_zf (s)                     4.933\n",
      "time/saving (s)                         0.00514476\n",
      "time/training (s)                       2.60725\n",
      "time/epoch (s)                         15.8728\n",
      "time/total (s)                       2335.56\n",
      "Epoch                                 150\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:40:24.736428 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 151 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 162000\n",
      "trainer/ZF1 Loss                       26.449\n",
      "trainer/ZF2 Loss                       33.2966\n",
      "trainer/ZF Expert Reward               14.9849\n",
      "trainer/ZF Policy Reward               -1.02505\n",
      "trainer/ZF CHI2 Term                   58.7572\n",
      "trainer/Policy Loss                  -884.41\n",
      "trainer/Policy Grad Norm              723.833\n",
      "trainer/Policy Param Norm              39.007\n",
      "trainer/Zf1 Grad Norm                8705.29\n",
      "trainer/Zf1 Param Norm                105.46\n",
      "trainer/Zf2 Grad Norm               14715.7\n",
      "trainer/Zf2 Param Norm                102\n",
      "trainer/Z Expert Predictions Mean    1215.33\n",
      "trainer/Z Expert Predictions Std      233.903\n",
      "trainer/Z Expert Predictions Max     1681.39\n",
      "trainer/Z Expert Predictions Min      675.689\n",
      "trainer/Z Policy Predictions Mean     880.82\n",
      "trainer/Z Policy Predictions Std      398.736\n",
      "trainer/Z Policy Predictions Max     1592.91\n",
      "trainer/Z Policy Predictions Min     -289.169\n",
      "trainer/Z Expert Targets Mean        1200.35\n",
      "trainer/Z Expert Targets Std          231.199\n",
      "trainer/Z Expert Targets Max         1656.6\n",
      "trainer/Z Expert Targets Min          668.299\n",
      "trainer/Z Policy Targets Mean         881.845\n",
      "trainer/Z Policy Targets Std          395.575\n",
      "trainer/Z Policy Targets Max         1572.92\n",
      "trainer/Z Policy Targets Min         -258.001\n",
      "trainer/Log Pis Mean                   13.0045\n",
      "trainer/Log Pis Std                     4.31219\n",
      "trainer/Policy mu Mean                  0.295073\n",
      "trainer/Policy mu Std                   2.4258\n",
      "trainer/Policy log std Mean            -3.88814\n",
      "trainer/Policy log std Std              1.13289\n",
      "exploration/num steps total        158030\n",
      "exploration/num paths total           979\n",
      "evaluation/num steps total              1.04678e+06\n",
      "evaluation/num paths total           1538\n",
      "evaluation/path length Mean           668.083\n",
      "evaluation/path length Std            281.006\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            372\n",
      "evaluation/Rewards Mean                 3.50089\n",
      "evaluation/Rewards Std                  0.689401\n",
      "evaluation/Rewards Max                  6.21705\n",
      "evaluation/Rewards Min                  0.662926\n",
      "evaluation/Returns Mean              2338.88\n",
      "evaluation/Returns Std                997.793\n",
      "evaluation/Returns Max               3543.46\n",
      "evaluation/Returns Min               1260.5\n",
      "evaluation/Estimation Bias Mean       903.497\n",
      "evaluation/Estimation Bias Std        485.129\n",
      "evaluation/EB/Q_True Mean              40.4804\n",
      "evaluation/EB/Q_True Std              110.027\n",
      "evaluation/EB/Q_Pred Mean             943.977\n",
      "evaluation/EB/Q_Pred Std              455.496\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2338.88\n",
      "evaluation/Actions Mean                 0.0422758\n",
      "evaluation/Actions Std                  0.597948\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88126\n",
      "time/backward_zf1 (s)                   1.98834\n",
      "time/backward_zf2 (s)                   1.92534\n",
      "time/data sampling (s)                  0.247618\n",
      "time/data storing (s)                   0.014308\n",
      "time/evaluation sampling (s)            1.3995\n",
      "time/exploration sampling (s)           0.175106\n",
      "time/logging (s)                        0.00969287\n",
      "time/preback_alpha (s)                  0.545908\n",
      "time/preback_policy (s)                 0.622723\n",
      "time/preback_start (s)                  0.121857\n",
      "time/preback_zf (s)                     4.9338\n",
      "time/saving (s)                         0.00493188\n",
      "time/training (s)                       2.23533\n",
      "time/epoch (s)                         16.1057\n",
      "time/total (s)                       2351.69\n",
      "Epoch                                 151\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:40:40.946072 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 152 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 163000\n",
      "trainer/ZF1 Loss                       87.774\n",
      "trainer/ZF2 Loss                       82.8696\n",
      "trainer/ZF Expert Reward               14.6711\n",
      "trainer/ZF Policy Reward               -5.91148\n",
      "trainer/ZF CHI2 Term                  119.544\n",
      "trainer/Policy Loss                  -910.997\n",
      "trainer/Policy Grad Norm              783.106\n",
      "trainer/Policy Param Norm              39.0875\n",
      "trainer/Zf1 Grad Norm               69058.1\n",
      "trainer/Zf1 Param Norm                105.79\n",
      "trainer/Zf2 Grad Norm               54473.2\n",
      "trainer/Zf2 Param Norm                102.308\n",
      "trainer/Z Expert Predictions Mean    1243.48\n",
      "trainer/Z Expert Predictions Std      259.372\n",
      "trainer/Z Expert Predictions Max     1731.2\n",
      "trainer/Z Expert Predictions Min      589.708\n",
      "trainer/Z Policy Predictions Mean     901.68\n",
      "trainer/Z Policy Predictions Std      449.665\n",
      "trainer/Z Policy Predictions Max     1629.05\n",
      "trainer/Z Policy Predictions Min     -355.088\n",
      "trainer/Z Expert Targets Mean        1228.81\n",
      "trainer/Z Expert Targets Std          258.239\n",
      "trainer/Z Expert Targets Max         1705.04\n",
      "trainer/Z Expert Targets Min          563.272\n",
      "trainer/Z Policy Targets Mean         907.592\n",
      "trainer/Z Policy Targets Std          444.666\n",
      "trainer/Z Policy Targets Max         1586.48\n",
      "trainer/Z Policy Targets Min         -314.892\n",
      "trainer/Log Pis Mean                   13.7775\n",
      "trainer/Log Pis Std                     5.07139\n",
      "trainer/Policy mu Mean                  0.331845\n",
      "trainer/Policy mu Std                   2.60223\n",
      "trainer/Policy log std Mean            -4.07496\n",
      "trainer/Policy log std Std              1.12649\n",
      "exploration/num steps total        158030\n",
      "exploration/num paths total           979\n",
      "evaluation/num steps total              1.05647e+06\n",
      "evaluation/num paths total           1548\n",
      "evaluation/path length Mean           968.3\n",
      "evaluation/path length Std             93.7743\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            687\n",
      "evaluation/Rewards Mean                 3.4515\n",
      "evaluation/Rewards Std                  0.577764\n",
      "evaluation/Rewards Max                  4.84699\n",
      "evaluation/Rewards Min                  0.606493\n",
      "evaluation/Returns Mean              3342.09\n",
      "evaluation/Returns Std                349.917\n",
      "evaluation/Returns Max               3517.05\n",
      "evaluation/Returns Min               2296.55\n",
      "evaluation/Estimation Bias Mean      1036.89\n",
      "evaluation/Estimation Bias Std        278.297\n",
      "evaluation/EB/Q_True Mean              32.6716\n",
      "evaluation/EB/Q_True Std               99.0775\n",
      "evaluation/EB/Q_Pred Mean            1069.56\n",
      "evaluation/EB/Q_Pred Std              248.89\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3342.09\n",
      "evaluation/Actions Mean                 0.0425395\n",
      "evaluation/Actions Std                  0.590508\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85144\n",
      "time/backward_zf1 (s)                   1.95011\n",
      "time/backward_zf2 (s)                   1.91742\n",
      "time/data sampling (s)                  0.247581\n",
      "time/data storing (s)                   0.0136197\n",
      "time/evaluation sampling (s)            1.49622\n",
      "time/exploration sampling (s)           0.165657\n",
      "time/logging (s)                        0.0118878\n",
      "time/preback_alpha (s)                  0.546963\n",
      "time/preback_policy (s)                 0.627902\n",
      "time/preback_start (s)                  0.12154\n",
      "time/preback_zf (s)                     4.93958\n",
      "time/saving (s)                         0.00534177\n",
      "time/training (s)                       2.25141\n",
      "time/epoch (s)                         16.1467\n",
      "time/total (s)                       2367.85\n",
      "Epoch                                 152\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:40:56.874361 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 153 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 164000\n",
      "trainer/ZF1 Loss                      466.526\n",
      "trainer/ZF2 Loss                      437.639\n",
      "trainer/ZF Expert Reward               10.2941\n",
      "trainer/ZF Policy Reward                0.455705\n",
      "trainer/ZF CHI2 Term                  475.529\n",
      "trainer/Policy Loss                  -908.777\n",
      "trainer/Policy Grad Norm             1002.27\n",
      "trainer/Policy Param Norm              39.1652\n",
      "trainer/Zf1 Grad Norm               75987.4\n",
      "trainer/Zf1 Param Norm                106.139\n",
      "trainer/Zf2 Grad Norm               30510.4\n",
      "trainer/Zf2 Param Norm                102.625\n",
      "trainer/Z Expert Predictions Mean    1220.7\n",
      "trainer/Z Expert Predictions Std      232.58\n",
      "trainer/Z Expert Predictions Max     1735.38\n",
      "trainer/Z Expert Predictions Min      602.312\n",
      "trainer/Z Policy Predictions Mean     907.529\n",
      "trainer/Z Policy Predictions Std      391.326\n",
      "trainer/Z Policy Predictions Max     1676.7\n",
      "trainer/Z Policy Predictions Min     -355.657\n",
      "trainer/Z Expert Targets Mean        1210.4\n",
      "trainer/Z Expert Targets Std          243.007\n",
      "trainer/Z Expert Targets Max         1731.61\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         907.073\n",
      "trainer/Z Policy Targets Std          395.298\n",
      "trainer/Z Policy Targets Max         1657.71\n",
      "trainer/Z Policy Targets Min         -338.243\n",
      "trainer/Log Pis Mean                   13.7458\n",
      "trainer/Log Pis Std                     5.00729\n",
      "trainer/Policy mu Mean                  0.636725\n",
      "trainer/Policy mu Std                   2.99964\n",
      "trainer/Policy log std Mean            -3.99707\n",
      "trainer/Policy log std Std              1.2993\n",
      "exploration/num steps total        158882\n",
      "exploration/num paths total           980\n",
      "evaluation/num steps total              1.06479e+06\n",
      "evaluation/num paths total           1558\n",
      "evaluation/path length Mean           832.6\n",
      "evaluation/path length Std            256.257\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            404\n",
      "evaluation/Rewards Mean                 3.52761\n",
      "evaluation/Rewards Std                  0.626491\n",
      "evaluation/Rewards Max                  5.41478\n",
      "evaluation/Rewards Min                  0.628775\n",
      "evaluation/Returns Mean              2937.09\n",
      "evaluation/Returns Std                916.493\n",
      "evaluation/Returns Max               3571.76\n",
      "evaluation/Returns Min               1389.24\n",
      "evaluation/Estimation Bias Mean      1075.51\n",
      "evaluation/Estimation Bias Std        423.198\n",
      "evaluation/EB/Q_True Mean              39.7235\n",
      "evaluation/EB/Q_True Std              110.427\n",
      "evaluation/EB/Q_Pred Mean            1115.24\n",
      "evaluation/EB/Q_Pred Std              368.205\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2937.09\n",
      "evaluation/Actions Mean                 0.033229\n",
      "evaluation/Actions Std                  0.589369\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67219\n",
      "time/backward_zf1 (s)                   1.79643\n",
      "time/backward_zf2 (s)                   1.72629\n",
      "time/data sampling (s)                  0.251447\n",
      "time/data storing (s)                   0.0135133\n",
      "time/evaluation sampling (s)            1.32116\n",
      "time/exploration sampling (s)           0.167628\n",
      "time/logging (s)                        0.0105555\n",
      "time/preback_alpha (s)                  0.546926\n",
      "time/preback_policy (s)                 0.601191\n",
      "time/preback_start (s)                  0.121818\n",
      "time/preback_zf (s)                     4.97067\n",
      "time/saving (s)                         0.00517003\n",
      "time/training (s)                       2.65557\n",
      "time/epoch (s)                         15.8605\n",
      "time/total (s)                       2383.74\n",
      "Epoch                                 153\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:41:12.889421 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 154 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 165000\n",
      "trainer/ZF1 Loss                       32.0161\n",
      "trainer/ZF2 Loss                       34.8986\n",
      "trainer/ZF Expert Reward                9.42124\n",
      "trainer/ZF Policy Reward               -2.72828\n",
      "trainer/ZF CHI2 Term                   59.6576\n",
      "trainer/Policy Loss                  -914.614\n",
      "trainer/Policy Grad Norm              410.519\n",
      "trainer/Policy Param Norm              39.2402\n",
      "trainer/Zf1 Grad Norm               19619.7\n",
      "trainer/Zf1 Param Norm                106.486\n",
      "trainer/Zf2 Grad Norm               10878.6\n",
      "trainer/Zf2 Param Norm                102.961\n",
      "trainer/Z Expert Predictions Mean    1199.33\n",
      "trainer/Z Expert Predictions Std      235.153\n",
      "trainer/Z Expert Predictions Max     1742.69\n",
      "trainer/Z Expert Predictions Min      625.426\n",
      "trainer/Z Policy Predictions Mean     908.003\n",
      "trainer/Z Policy Predictions Std      412.706\n",
      "trainer/Z Policy Predictions Max     1668.28\n",
      "trainer/Z Policy Predictions Min     -374.67\n",
      "trainer/Z Expert Targets Mean        1189.91\n",
      "trainer/Z Expert Targets Std          235.815\n",
      "trainer/Z Expert Targets Max         1721.11\n",
      "trainer/Z Expert Targets Min          587.337\n",
      "trainer/Z Policy Targets Mean         910.732\n",
      "trainer/Z Policy Targets Std          407.446\n",
      "trainer/Z Policy Targets Max         1639.05\n",
      "trainer/Z Policy Targets Min         -347.053\n",
      "trainer/Log Pis Mean                   14.1927\n",
      "trainer/Log Pis Std                     6.02674\n",
      "trainer/Policy mu Mean                  0.503868\n",
      "trainer/Policy mu Std                   2.88646\n",
      "trainer/Policy log std Mean            -3.93422\n",
      "trainer/Policy log std Std              1.3081\n",
      "exploration/num steps total        160401\n",
      "exploration/num paths total           982\n",
      "evaluation/num steps total              1.07216e+06\n",
      "evaluation/num paths total           1568\n",
      "evaluation/path length Mean           736.8\n",
      "evaluation/path length Std            269.525\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            373\n",
      "evaluation/Rewards Mean                 3.54096\n",
      "evaluation/Rewards Std                  0.666886\n",
      "evaluation/Rewards Max                  5.35524\n",
      "evaluation/Rewards Min                  0.641424\n",
      "evaluation/Returns Mean              2608.98\n",
      "evaluation/Returns Std                970.4\n",
      "evaluation/Returns Max               3561.87\n",
      "evaluation/Returns Min               1269.83\n",
      "evaluation/Estimation Bias Mean       979.558\n",
      "evaluation/Estimation Bias Std        488.084\n",
      "evaluation/EB/Q_True Mean              44.5761\n",
      "evaluation/EB/Q_True Std              115.74\n",
      "evaluation/EB/Q_Pred Mean            1024.13\n",
      "evaluation/EB/Q_Pred Std              449.88\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2608.98\n",
      "evaluation/Actions Mean                 0.0319866\n",
      "evaluation/Actions Std                  0.601906\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82855\n",
      "time/backward_zf1 (s)                   1.92606\n",
      "time/backward_zf2 (s)                   1.88033\n",
      "time/data sampling (s)                  0.243617\n",
      "time/data storing (s)                   0.0135887\n",
      "time/evaluation sampling (s)            1.39406\n",
      "time/exploration sampling (s)           0.168487\n",
      "time/logging (s)                        0.00936773\n",
      "time/preback_alpha (s)                  0.545633\n",
      "time/preback_policy (s)                 0.621647\n",
      "time/preback_start (s)                  0.122308\n",
      "time/preback_zf (s)                     4.94881\n",
      "time/saving (s)                         0.00529835\n",
      "time/training (s)                       2.24479\n",
      "time/epoch (s)                         15.9526\n",
      "time/total (s)                       2399.71\n",
      "Epoch                                 154\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:41:28.490299 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 155 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 166000\n",
      "trainer/ZF1 Loss                       52.3988\n",
      "trainer/ZF2 Loss                      115.654\n",
      "trainer/ZF Expert Reward               10.1069\n",
      "trainer/ZF Policy Reward               -0.439037\n",
      "trainer/ZF CHI2 Term                  108.44\n",
      "trainer/Policy Loss                  -886.146\n",
      "trainer/Policy Grad Norm              695.689\n",
      "trainer/Policy Param Norm              39.3102\n",
      "trainer/Zf1 Grad Norm               20275.1\n",
      "trainer/Zf1 Param Norm                106.855\n",
      "trainer/Zf2 Grad Norm               46237.1\n",
      "trainer/Zf2 Param Norm                103.309\n",
      "trainer/Z Expert Predictions Mean    1218.39\n",
      "trainer/Z Expert Predictions Std      259.41\n",
      "trainer/Z Expert Predictions Max     1729.87\n",
      "trainer/Z Expert Predictions Min      469.836\n",
      "trainer/Z Policy Predictions Mean     878.557\n",
      "trainer/Z Policy Predictions Std      403.382\n",
      "trainer/Z Policy Predictions Max     1564.42\n",
      "trainer/Z Policy Predictions Min     -352.77\n",
      "trainer/Z Expert Targets Mean        1208.29\n",
      "trainer/Z Expert Targets Std          259.951\n",
      "trainer/Z Expert Targets Max         1721.74\n",
      "trainer/Z Expert Targets Min          447.433\n",
      "trainer/Z Policy Targets Mean         878.996\n",
      "trainer/Z Policy Targets Std          398.96\n",
      "trainer/Z Policy Targets Max         1546.56\n",
      "trainer/Z Policy Targets Min         -307.404\n",
      "trainer/Log Pis Mean                   14.0081\n",
      "trainer/Log Pis Std                     5.83117\n",
      "trainer/Policy mu Mean                  0.391505\n",
      "trainer/Policy mu Std                   2.67394\n",
      "trainer/Policy log std Mean            -3.82498\n",
      "trainer/Policy log std Std              1.18531\n",
      "exploration/num steps total        162078\n",
      "exploration/num paths total           984\n",
      "evaluation/num steps total              1.07582e+06\n",
      "evaluation/num paths total           1578\n",
      "evaluation/path length Mean           366.4\n",
      "evaluation/path length Std             14.3611\n",
      "evaluation/path length Max            394\n",
      "evaluation/path length Min            345\n",
      "evaluation/Rewards Mean                 3.37725\n",
      "evaluation/Rewards Std                  0.846834\n",
      "evaluation/Rewards Max                  5.44929\n",
      "evaluation/Rewards Min                  0.60606\n",
      "evaluation/Returns Mean              1237.42\n",
      "evaluation/Returns Std                 64.4072\n",
      "evaluation/Returns Max               1354.71\n",
      "evaluation/Returns Min               1142.2\n",
      "evaluation/Estimation Bias Mean       754.18\n",
      "evaluation/Estimation Bias Std        500.71\n",
      "evaluation/EB/Q_True Mean              25.5765\n",
      "evaluation/EB/Q_True Std               80.6906\n",
      "evaluation/EB/Q_Pred Mean             779.757\n",
      "evaluation/EB/Q_Pred Std              501.595\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1237.42\n",
      "evaluation/Actions Mean                 0.0475268\n",
      "evaluation/Actions Std                  0.639689\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78868\n",
      "time/backward_zf1 (s)                   1.89984\n",
      "time/backward_zf2 (s)                   1.83924\n",
      "time/data sampling (s)                  0.249306\n",
      "time/data storing (s)                   0.0141447\n",
      "time/evaluation sampling (s)            0.973984\n",
      "time/exploration sampling (s)           0.176009\n",
      "time/logging (s)                        0.00504532\n",
      "time/preback_alpha (s)                  0.549727\n",
      "time/preback_policy (s)                 0.620076\n",
      "time/preback_start (s)                  0.123082\n",
      "time/preback_zf (s)                     4.94445\n",
      "time/saving (s)                         0.0049467\n",
      "time/training (s)                       2.34668\n",
      "time/epoch (s)                         15.5352\n",
      "time/total (s)                       2415.26\n",
      "Epoch                                 155\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:41:44.345825 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 156 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 167000\n",
      "trainer/ZF1 Loss                       37.316\n",
      "trainer/ZF2 Loss                       75.8971\n",
      "trainer/ZF Expert Reward               16.2805\n",
      "trainer/ZF Policy Reward                7.32544\n",
      "trainer/ZF CHI2 Term                   79.1079\n",
      "trainer/Policy Loss                  -900.32\n",
      "trainer/Policy Grad Norm             1271.78\n",
      "trainer/Policy Param Norm              39.3902\n",
      "trainer/Zf1 Grad Norm               35735.3\n",
      "trainer/Zf1 Param Norm                107.241\n",
      "trainer/Zf2 Grad Norm               40761.9\n",
      "trainer/Zf2 Param Norm                103.66\n",
      "trainer/Z Expert Predictions Mean    1244.62\n",
      "trainer/Z Expert Predictions Std      257.59\n",
      "trainer/Z Expert Predictions Max     1764.31\n",
      "trainer/Z Expert Predictions Min      639.226\n",
      "trainer/Z Policy Predictions Mean     897.842\n",
      "trainer/Z Policy Predictions Std      419.642\n",
      "trainer/Z Policy Predictions Max     1671.93\n",
      "trainer/Z Policy Predictions Min     -478.225\n",
      "trainer/Z Expert Targets Mean        1228.33\n",
      "trainer/Z Expert Targets Std          257.097\n",
      "trainer/Z Expert Targets Max         1748.53\n",
      "trainer/Z Expert Targets Min          638.412\n",
      "trainer/Z Policy Targets Mean         890.517\n",
      "trainer/Z Policy Targets Std          417.294\n",
      "trainer/Z Policy Targets Max         1712.9\n",
      "trainer/Z Policy Targets Min         -483.647\n",
      "trainer/Log Pis Mean                   13.6832\n",
      "trainer/Log Pis Std                     5.05844\n",
      "trainer/Policy mu Mean                  0.218309\n",
      "trainer/Policy mu Std                   2.76578\n",
      "trainer/Policy log std Mean            -3.99997\n",
      "trainer/Policy log std Std              1.11303\n",
      "exploration/num steps total        162078\n",
      "exploration/num paths total           984\n",
      "evaluation/num steps total              1.08582e+06\n",
      "evaluation/num paths total           1588\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50039\n",
      "evaluation/Rewards Std                  0.57809\n",
      "evaluation/Rewards Max                  4.55921\n",
      "evaluation/Rewards Min                  0.603732\n",
      "evaluation/Returns Mean              3500.39\n",
      "evaluation/Returns Std                 13.9197\n",
      "evaluation/Returns Max               3530.91\n",
      "evaluation/Returns Min               3479.25\n",
      "evaluation/Estimation Bias Mean      1145.19\n",
      "evaluation/Estimation Bias Std        242.969\n",
      "evaluation/EB/Q_True Mean              32.3784\n",
      "evaluation/EB/Q_True Std               99.6785\n",
      "evaluation/EB/Q_Pred Mean            1177.57\n",
      "evaluation/EB/Q_Pred Std              226.86\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3500.39\n",
      "evaluation/Actions Mean                 0.0261\n",
      "evaluation/Actions Std                  0.582923\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.63587\n",
      "time/backward_zf1 (s)                   1.7594\n",
      "time/backward_zf2 (s)                   1.6754\n",
      "time/data sampling (s)                  0.220626\n",
      "time/data storing (s)                   0.0135317\n",
      "time/evaluation sampling (s)            1.38329\n",
      "time/exploration sampling (s)           0.165307\n",
      "time/logging (s)                        0.0119212\n",
      "time/preback_alpha (s)                  0.539709\n",
      "time/preback_policy (s)                 0.588198\n",
      "time/preback_start (s)                  0.121119\n",
      "time/preback_zf (s)                     4.9508\n",
      "time/saving (s)                         0.00546908\n",
      "time/training (s)                       2.73051\n",
      "time/epoch (s)                         15.8011\n",
      "time/total (s)                       2431.08\n",
      "Epoch                                 156\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:42:00.534445 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 157 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 168000\n",
      "trainer/ZF1 Loss                      320.229\n",
      "trainer/ZF2 Loss                      285.658\n",
      "trainer/ZF Expert Reward               15.359\n",
      "trainer/ZF Policy Reward                5.68872\n",
      "trainer/ZF CHI2 Term                  326.663\n",
      "trainer/Policy Loss                  -861.888\n",
      "trainer/Policy Grad Norm              670.606\n",
      "trainer/Policy Param Norm              39.4787\n",
      "trainer/Zf1 Grad Norm               45849.3\n",
      "trainer/Zf1 Param Norm                107.588\n",
      "trainer/Zf2 Grad Norm               28801.3\n",
      "trainer/Zf2 Param Norm                104.005\n",
      "trainer/Z Expert Predictions Mean    1227.12\n",
      "trainer/Z Expert Predictions Std      274.29\n",
      "trainer/Z Expert Predictions Max     1784.83\n",
      "trainer/Z Expert Predictions Min      527.098\n",
      "trainer/Z Policy Predictions Mean     856.648\n",
      "trainer/Z Policy Predictions Std      457.498\n",
      "trainer/Z Policy Predictions Max     1639.13\n",
      "trainer/Z Policy Predictions Min     -393.869\n",
      "trainer/Z Expert Targets Mean        1211.76\n",
      "trainer/Z Expert Targets Std          271.735\n",
      "trainer/Z Expert Targets Max         1767.02\n",
      "trainer/Z Expert Targets Min          498.822\n",
      "trainer/Z Policy Targets Mean         850.96\n",
      "trainer/Z Policy Targets Std          456.517\n",
      "trainer/Z Policy Targets Max         1663.71\n",
      "trainer/Z Policy Targets Min         -399.275\n",
      "trainer/Log Pis Mean                   14.191\n",
      "trainer/Log Pis Std                     5.6966\n",
      "trainer/Policy mu Mean                  0.682536\n",
      "trainer/Policy mu Std                   3.34575\n",
      "trainer/Policy log std Mean            -3.93299\n",
      "trainer/Policy log std Std              1.20909\n",
      "exploration/num steps total        163078\n",
      "exploration/num paths total           985\n",
      "evaluation/num steps total              1.09402e+06\n",
      "evaluation/num paths total           1598\n",
      "evaluation/path length Mean           819.9\n",
      "evaluation/path length Std            234.505\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            446\n",
      "evaluation/Rewards Mean                 3.55631\n",
      "evaluation/Rewards Std                  0.647331\n",
      "evaluation/Rewards Max                  5.72879\n",
      "evaluation/Rewards Min                  0.628072\n",
      "evaluation/Returns Mean              2915.82\n",
      "evaluation/Returns Std                846.976\n",
      "evaluation/Returns Max               3597.79\n",
      "evaluation/Returns Min               1565.84\n",
      "evaluation/Estimation Bias Mean      1053.07\n",
      "evaluation/Estimation Bias Std        474.48\n",
      "evaluation/EB/Q_True Mean              40.445\n",
      "evaluation/EB/Q_True Std              111.33\n",
      "evaluation/EB/Q_Pred Mean            1093.52\n",
      "evaluation/EB/Q_Pred Std              428.994\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2915.82\n",
      "evaluation/Actions Mean                 0.0421312\n",
      "evaluation/Actions Std                  0.610922\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86633\n",
      "time/backward_zf1 (s)                   1.96322\n",
      "time/backward_zf2 (s)                   1.91642\n",
      "time/data sampling (s)                  0.250633\n",
      "time/data storing (s)                   0.0140769\n",
      "time/evaluation sampling (s)            1.35047\n",
      "time/exploration sampling (s)           0.171292\n",
      "time/logging (s)                        0.00980073\n",
      "time/preback_alpha (s)                  0.554491\n",
      "time/preback_policy (s)                 0.640475\n",
      "time/preback_start (s)                  0.12371\n",
      "time/preback_zf (s)                     4.98435\n",
      "time/saving (s)                         0.00551333\n",
      "time/training (s)                       2.27224\n",
      "time/epoch (s)                         16.123\n",
      "time/total (s)                       2447.22\n",
      "Epoch                                 157\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:42:15.767338 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 158 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 169000\n",
      "trainer/ZF1 Loss                      290.566\n",
      "trainer/ZF2 Loss                      301.085\n",
      "trainer/ZF Expert Reward                2.85485\n",
      "trainer/ZF Policy Reward                0.374512\n",
      "trainer/ZF CHI2 Term                  311.72\n",
      "trainer/Policy Loss                  -902.248\n",
      "trainer/Policy Grad Norm              613.287\n",
      "trainer/Policy Param Norm              39.5519\n",
      "trainer/Zf1 Grad Norm               63944.9\n",
      "trainer/Zf1 Param Norm                107.967\n",
      "trainer/Zf2 Grad Norm               53223.8\n",
      "trainer/Zf2 Param Norm                104.366\n",
      "trainer/Z Expert Predictions Mean    1232.36\n",
      "trainer/Z Expert Predictions Std      253.434\n",
      "trainer/Z Expert Predictions Max     1781.54\n",
      "trainer/Z Expert Predictions Min      605.524\n",
      "trainer/Z Policy Predictions Mean     887.79\n",
      "trainer/Z Policy Predictions Std      414.927\n",
      "trainer/Z Policy Predictions Max     1626.81\n",
      "trainer/Z Policy Predictions Min     -459.031\n",
      "trainer/Z Expert Targets Mean        1229.51\n",
      "trainer/Z Expert Targets Std          254.777\n",
      "trainer/Z Expert Targets Max         1782.57\n",
      "trainer/Z Expert Targets Min          612.666\n",
      "trainer/Z Policy Targets Mean         887.416\n",
      "trainer/Z Policy Targets Std          419.229\n",
      "trainer/Z Policy Targets Max         1661.57\n",
      "trainer/Z Policy Targets Min         -459.883\n",
      "trainer/Log Pis Mean                   13.5497\n",
      "trainer/Log Pis Std                     5.10156\n",
      "trainer/Policy mu Mean                  0.492025\n",
      "trainer/Policy mu Std                   2.94011\n",
      "trainer/Policy log std Mean            -3.91706\n",
      "trainer/Policy log std Std              1.20702\n",
      "exploration/num steps total        163485\n",
      "exploration/num paths total           986\n",
      "evaluation/num steps total              1.09749e+06\n",
      "evaluation/num paths total           1608\n",
      "evaluation/path length Mean           346.7\n",
      "evaluation/path length Std             18.847\n",
      "evaluation/path length Max            370\n",
      "evaluation/path length Min            330\n",
      "evaluation/Rewards Mean                 3.37585\n",
      "evaluation/Rewards Std                  0.85908\n",
      "evaluation/Rewards Max                  5.5302\n",
      "evaluation/Rewards Min                  0.63813\n",
      "evaluation/Returns Mean              1170.41\n",
      "evaluation/Returns Std                 77.0397\n",
      "evaluation/Returns Max               1268.12\n",
      "evaluation/Returns Min               1104.2\n",
      "evaluation/Estimation Bias Mean       706.38\n",
      "evaluation/Estimation Bias Std        540.458\n",
      "evaluation/EB/Q_True Mean              28.9274\n",
      "evaluation/EB/Q_True Std               88.0791\n",
      "evaluation/EB/Q_Pred Mean             735.307\n",
      "evaluation/EB/Q_Pred Std              538.755\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1170.41\n",
      "evaluation/Actions Mean                 0.0265464\n",
      "evaluation/Actions Std                  0.631475\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8337\n",
      "time/backward_zf1 (s)                   1.9473\n",
      "time/backward_zf2 (s)                   1.89611\n",
      "time/data sampling (s)                  0.248601\n",
      "time/data storing (s)                   0.0136164\n",
      "time/evaluation sampling (s)            0.561472\n",
      "time/exploration sampling (s)           0.168366\n",
      "time/logging (s)                        0.00470467\n",
      "time/preback_alpha (s)                  0.546484\n",
      "time/preback_policy (s)                 0.632342\n",
      "time/preback_start (s)                  0.12131\n",
      "time/preback_zf (s)                     4.9331\n",
      "time/saving (s)                         0.00506695\n",
      "time/training (s)                       2.24998\n",
      "time/epoch (s)                         15.1622\n",
      "time/total (s)                       2462.4\n",
      "Epoch                                 158\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:42:31.777317 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 159 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 170000\n",
      "trainer/ZF1 Loss                       78.8637\n",
      "trainer/ZF2 Loss                      167.511\n",
      "trainer/ZF Expert Reward               10.2033\n",
      "trainer/ZF Policy Reward                4.4157\n",
      "trainer/ZF CHI2 Term                  142.621\n",
      "trainer/Policy Loss                  -874.612\n",
      "trainer/Policy Grad Norm              468.234\n",
      "trainer/Policy Param Norm              39.632\n",
      "trainer/Zf1 Grad Norm               83560.7\n",
      "trainer/Zf1 Param Norm                108.339\n",
      "trainer/Zf2 Grad Norm               96149.9\n",
      "trainer/Zf2 Param Norm                104.724\n",
      "trainer/Z Expert Predictions Mean    1256.47\n",
      "trainer/Z Expert Predictions Std      249.015\n",
      "trainer/Z Expert Predictions Max     1830.94\n",
      "trainer/Z Expert Predictions Min      554.007\n",
      "trainer/Z Policy Predictions Mean     872.297\n",
      "trainer/Z Policy Predictions Std      468.867\n",
      "trainer/Z Policy Predictions Max     1701.73\n",
      "trainer/Z Policy Predictions Min     -345.63\n",
      "trainer/Z Expert Targets Mean        1246.26\n",
      "trainer/Z Expert Targets Std          253.107\n",
      "trainer/Z Expert Targets Max         1813.41\n",
      "trainer/Z Expert Targets Min          514.671\n",
      "trainer/Z Policy Targets Mean         867.881\n",
      "trainer/Z Policy Targets Std          465.49\n",
      "trainer/Z Policy Targets Max         1696.89\n",
      "trainer/Z Policy Targets Min         -390.095\n",
      "trainer/Log Pis Mean                   13.7839\n",
      "trainer/Log Pis Std                     5.2355\n",
      "trainer/Policy mu Mean                  0.377712\n",
      "trainer/Policy mu Std                   2.73663\n",
      "trainer/Policy log std Mean            -3.92575\n",
      "trainer/Policy log std Std              1.21677\n",
      "exploration/num steps total        166964\n",
      "exploration/num paths total           990\n",
      "evaluation/num steps total              1.10611e+06\n",
      "evaluation/num paths total           1620\n",
      "evaluation/path length Mean           718.083\n",
      "evaluation/path length Std            263.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            369\n",
      "evaluation/Rewards Mean                 3.54216\n",
      "evaluation/Rewards Std                  0.662854\n",
      "evaluation/Rewards Max                  5.16994\n",
      "evaluation/Rewards Min                  0.614128\n",
      "evaluation/Returns Mean              2543.57\n",
      "evaluation/Returns Std                953.75\n",
      "evaluation/Returns Max               3582.06\n",
      "evaluation/Returns Min               1260.68\n",
      "evaluation/Estimation Bias Mean       997.726\n",
      "evaluation/Estimation Bias Std        499.1\n",
      "evaluation/EB/Q_True Mean              38.3144\n",
      "evaluation/EB/Q_True Std              108.989\n",
      "evaluation/EB/Q_Pred Mean            1036.04\n",
      "evaluation/EB/Q_Pred Std              463.966\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2543.57\n",
      "evaluation/Actions Mean                 0.0331405\n",
      "evaluation/Actions Std                  0.605554\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.68608\n",
      "time/backward_zf1 (s)                   1.80206\n",
      "time/backward_zf2 (s)                   1.73147\n",
      "time/data sampling (s)                  0.248142\n",
      "time/data storing (s)                   0.0141896\n",
      "time/evaluation sampling (s)            1.37862\n",
      "time/exploration sampling (s)           0.177169\n",
      "time/logging (s)                        0.0105585\n",
      "time/preback_alpha (s)                  0.548707\n",
      "time/preback_policy (s)                 0.605681\n",
      "time/preback_start (s)                  0.123717\n",
      "time/preback_zf (s)                     4.9576\n",
      "time/saving (s)                         0.00520309\n",
      "time/training (s)                       2.66483\n",
      "time/epoch (s)                         15.954\n",
      "time/total (s)                       2478.37\n",
      "Epoch                                 159\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:42:47.775708 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 160 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 171000\n",
      "trainer/ZF1 Loss                       66.1575\n",
      "trainer/ZF2 Loss                       68.689\n",
      "trainer/ZF Expert Reward                6.07502\n",
      "trainer/ZF Policy Reward                0.72847\n",
      "trainer/ZF CHI2 Term                   87.1006\n",
      "trainer/Policy Loss                  -892.233\n",
      "trainer/Policy Grad Norm              610.548\n",
      "trainer/Policy Param Norm              39.7046\n",
      "trainer/Zf1 Grad Norm               28526.6\n",
      "trainer/Zf1 Param Norm                108.707\n",
      "trainer/Zf2 Grad Norm               30805.3\n",
      "trainer/Zf2 Param Norm                105.073\n",
      "trainer/Z Expert Predictions Mean    1270.74\n",
      "trainer/Z Expert Predictions Std      256.979\n",
      "trainer/Z Expert Predictions Max     1833.15\n",
      "trainer/Z Expert Predictions Min      645.067\n",
      "trainer/Z Policy Predictions Mean     878.215\n",
      "trainer/Z Policy Predictions Std      436.837\n",
      "trainer/Z Policy Predictions Max     1637.1\n",
      "trainer/Z Policy Predictions Min     -457.579\n",
      "trainer/Z Expert Targets Mean        1264.66\n",
      "trainer/Z Expert Targets Std          259.397\n",
      "trainer/Z Expert Targets Max         1817.57\n",
      "trainer/Z Expert Targets Min          648.92\n",
      "trainer/Z Policy Targets Mean         877.487\n",
      "trainer/Z Policy Targets Std          438.995\n",
      "trainer/Z Policy Targets Max         1602.78\n",
      "trainer/Z Policy Targets Min         -393.438\n",
      "trainer/Log Pis Mean                   14.4756\n",
      "trainer/Log Pis Std                     5.92763\n",
      "trainer/Policy mu Mean                  0.530017\n",
      "trainer/Policy mu Std                   3.22933\n",
      "trainer/Policy log std Mean            -3.89754\n",
      "trainer/Policy log std Std              1.2935\n",
      "exploration/num steps total        167410\n",
      "exploration/num paths total           991\n",
      "evaluation/num steps total              1.11478e+06\n",
      "evaluation/num paths total           1631\n",
      "evaluation/path length Mean           788\n",
      "evaluation/path length Std            261.376\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            404\n",
      "evaluation/Rewards Mean                 3.5245\n",
      "evaluation/Rewards Std                  0.64569\n",
      "evaluation/Rewards Max                  5.33087\n",
      "evaluation/Rewards Min                  0.607021\n",
      "evaluation/Returns Mean              2777.31\n",
      "evaluation/Returns Std                935.257\n",
      "evaluation/Returns Max               3550.89\n",
      "evaluation/Returns Min               1387.42\n",
      "evaluation/Estimation Bias Mean      1067.69\n",
      "evaluation/Estimation Bias Std        477.571\n",
      "evaluation/EB/Q_True Mean              37.7998\n",
      "evaluation/EB/Q_True Std              107.555\n",
      "evaluation/EB/Q_Pred Mean            1105.49\n",
      "evaluation/EB/Q_Pred Std              439.842\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2777.31\n",
      "evaluation/Actions Mean                 0.0374811\n",
      "evaluation/Actions Std                  0.595942\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.69724\n",
      "time/backward_zf1 (s)                   1.82882\n",
      "time/backward_zf2 (s)                   1.74897\n",
      "time/data sampling (s)                  0.24794\n",
      "time/data storing (s)                   0.0135079\n",
      "time/evaluation sampling (s)            1.3604\n",
      "time/exploration sampling (s)           0.167126\n",
      "time/logging (s)                        0.0104247\n",
      "time/preback_alpha (s)                  0.546575\n",
      "time/preback_policy (s)                 0.606179\n",
      "time/preback_start (s)                  0.122186\n",
      "time/preback_zf (s)                     4.95431\n",
      "time/saving (s)                         0.00524887\n",
      "time/training (s)                       2.62586\n",
      "time/epoch (s)                         15.9348\n",
      "time/total (s)                       2494.33\n",
      "Epoch                                 160\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:43:03.773923 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 161 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 172000\n",
      "trainer/ZF1 Loss                      442.192\n",
      "trainer/ZF2 Loss                      408.733\n",
      "trainer/ZF Expert Reward                9.45315\n",
      "trainer/ZF Policy Reward               -0.0817985\n",
      "trainer/ZF CHI2 Term                  448.428\n",
      "trainer/Policy Loss                  -907.423\n",
      "trainer/Policy Grad Norm              841.599\n",
      "trainer/Policy Param Norm              39.7779\n",
      "trainer/Zf1 Grad Norm               55586.2\n",
      "trainer/Zf1 Param Norm                109.094\n",
      "trainer/Zf2 Grad Norm               30804.7\n",
      "trainer/Zf2 Param Norm                105.429\n",
      "trainer/Z Expert Predictions Mean    1256.91\n",
      "trainer/Z Expert Predictions Std      269.044\n",
      "trainer/Z Expert Predictions Max     1855.55\n",
      "trainer/Z Expert Predictions Min      521.67\n",
      "trainer/Z Policy Predictions Mean     894.346\n",
      "trainer/Z Policy Predictions Std      461.835\n",
      "trainer/Z Policy Predictions Max     1666.46\n",
      "trainer/Z Policy Predictions Min     -346.138\n",
      "trainer/Z Expert Targets Mean        1247.45\n",
      "trainer/Z Expert Targets Std          266.037\n",
      "trainer/Z Expert Targets Max         1820.61\n",
      "trainer/Z Expert Targets Min          518.351\n",
      "trainer/Z Policy Targets Mean         894.428\n",
      "trainer/Z Policy Targets Std          460.651\n",
      "trainer/Z Policy Targets Max         1688.69\n",
      "trainer/Z Policy Targets Min         -378.548\n",
      "trainer/Log Pis Mean                   13.5666\n",
      "trainer/Log Pis Std                     5.01169\n",
      "trainer/Policy mu Mean                  0.240646\n",
      "trainer/Policy mu Std                   2.56551\n",
      "trainer/Policy log std Mean            -4.05674\n",
      "trainer/Policy log std Std              1.06049\n",
      "exploration/num steps total        168410\n",
      "exploration/num paths total           992\n",
      "evaluation/num steps total              1.12465e+06\n",
      "evaluation/num paths total           1641\n",
      "evaluation/path length Mean           987.8\n",
      "evaluation/path length Std             36.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            878\n",
      "evaluation/Rewards Mean                 3.52576\n",
      "evaluation/Rewards Std                  0.601787\n",
      "evaluation/Rewards Max                  4.7622\n",
      "evaluation/Rewards Min                  0.619027\n",
      "evaluation/Returns Mean              3482.74\n",
      "evaluation/Returns Std                113.43\n",
      "evaluation/Returns Max               3554.44\n",
      "evaluation/Returns Min               3149.5\n",
      "evaluation/Estimation Bias Mean      1176.58\n",
      "evaluation/Estimation Bias Std        326.19\n",
      "evaluation/EB/Q_True Mean              32.9514\n",
      "evaluation/EB/Q_True Std              100.79\n",
      "evaluation/EB/Q_Pred Mean            1209.53\n",
      "evaluation/EB/Q_Pred Std              288.862\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3482.74\n",
      "evaluation/Actions Mean                 0.0298428\n",
      "evaluation/Actions Std                  0.597966\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.70486\n",
      "time/backward_zf1 (s)                   1.83345\n",
      "time/backward_zf2 (s)                   1.75543\n",
      "time/data sampling (s)                  0.250479\n",
      "time/data storing (s)                   0.0135395\n",
      "time/evaluation sampling (s)            1.38555\n",
      "time/exploration sampling (s)           0.167206\n",
      "time/logging (s)                        0.0154344\n",
      "time/preback_alpha (s)                  0.546142\n",
      "time/preback_policy (s)                 0.605952\n",
      "time/preback_start (s)                  0.12236\n",
      "time/preback_zf (s)                     4.94618\n",
      "time/saving (s)                         0.00544528\n",
      "time/training (s)                       2.58676\n",
      "time/epoch (s)                         15.9388\n",
      "time/total (s)                       2510.29\n",
      "Epoch                                 161\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:43:19.444073 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 162 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 173000\n",
      "trainer/ZF1 Loss                       66.732\n",
      "trainer/ZF2 Loss                       62.0611\n",
      "trainer/ZF Expert Reward               11.1506\n",
      "trainer/ZF Policy Reward                0.31788\n",
      "trainer/ZF CHI2 Term                   88.9642\n",
      "trainer/Policy Loss                  -855.051\n",
      "trainer/Policy Grad Norm              583.996\n",
      "trainer/Policy Param Norm              39.8498\n",
      "trainer/Zf1 Grad Norm               40083.4\n",
      "trainer/Zf1 Param Norm                109.464\n",
      "trainer/Zf2 Grad Norm               28623.7\n",
      "trainer/Zf2 Param Norm                105.788\n",
      "trainer/Z Expert Predictions Mean    1257.02\n",
      "trainer/Z Expert Predictions Std      274.858\n",
      "trainer/Z Expert Predictions Max     1826.26\n",
      "trainer/Z Expert Predictions Min      624.85\n",
      "trainer/Z Policy Predictions Mean     844.441\n",
      "trainer/Z Policy Predictions Std      465.383\n",
      "trainer/Z Policy Predictions Max     1626.02\n",
      "trainer/Z Policy Predictions Min     -486.057\n",
      "trainer/Z Expert Targets Mean        1245.87\n",
      "trainer/Z Expert Targets Std          275.205\n",
      "trainer/Z Expert Targets Max         1810.82\n",
      "trainer/Z Expert Targets Min          629.551\n",
      "trainer/Z Policy Targets Mean         844.123\n",
      "trainer/Z Policy Targets Std          463.192\n",
      "trainer/Z Policy Targets Max         1635.46\n",
      "trainer/Z Policy Targets Min         -481.323\n",
      "trainer/Log Pis Mean                   13.8737\n",
      "trainer/Log Pis Std                     5.56379\n",
      "trainer/Policy mu Mean                  0.297963\n",
      "trainer/Policy mu Std                   2.8862\n",
      "trainer/Policy log std Mean            -3.91103\n",
      "trainer/Policy log std Std              1.19544\n",
      "exploration/num steps total        169464\n",
      "exploration/num paths total           995\n",
      "evaluation/num steps total              1.12858e+06\n",
      "evaluation/num paths total           1651\n",
      "evaluation/path length Mean           392.2\n",
      "evaluation/path length Std             42.3906\n",
      "evaluation/path length Max            458\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 3.42536\n",
      "evaluation/Rewards Std                  0.824312\n",
      "evaluation/Rewards Max                  5.47959\n",
      "evaluation/Rewards Min                  0.625337\n",
      "evaluation/Returns Mean              1343.43\n",
      "evaluation/Returns Std                169.047\n",
      "evaluation/Returns Max               1610.76\n",
      "evaluation/Returns Min               1108.1\n",
      "evaluation/Estimation Bias Mean       731.731\n",
      "evaluation/Estimation Bias Std        585.452\n",
      "evaluation/EB/Q_True Mean              30.3152\n",
      "evaluation/EB/Q_True Std               90.2585\n",
      "evaluation/EB/Q_Pred Mean             762.047\n",
      "evaluation/EB/Q_Pred Std              583.928\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1343.43\n",
      "evaluation/Actions Mean                 0.0216127\n",
      "evaluation/Actions Std                  0.619671\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.65339\n",
      "time/backward_zf1 (s)                   1.7756\n",
      "time/backward_zf2 (s)                   1.70059\n",
      "time/data sampling (s)                  0.250019\n",
      "time/data storing (s)                   0.0135738\n",
      "time/evaluation sampling (s)            1.0731\n",
      "time/exploration sampling (s)           0.167201\n",
      "time/logging (s)                        0.00521225\n",
      "time/preback_alpha (s)                  0.549935\n",
      "time/preback_policy (s)                 0.597359\n",
      "time/preback_start (s)                  0.12278\n",
      "time/preback_zf (s)                     4.95733\n",
      "time/saving (s)                         0.00487247\n",
      "time/training (s)                       2.72586\n",
      "time/epoch (s)                         15.5968\n",
      "time/total (s)                       2525.9\n",
      "Epoch                                 162\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:43:35.579923 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 163 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 174000\n",
      "trainer/ZF1 Loss                       60.6817\n",
      "trainer/ZF2 Loss                       58.0255\n",
      "trainer/ZF Expert Reward                7.14205\n",
      "trainer/ZF Policy Reward              -10.6755\n",
      "trainer/ZF CHI2 Term                   90.4515\n",
      "trainer/Policy Loss                  -907.551\n",
      "trainer/Policy Grad Norm              843.42\n",
      "trainer/Policy Param Norm              39.9216\n",
      "trainer/Zf1 Grad Norm               34539.2\n",
      "trainer/Zf1 Param Norm                109.864\n",
      "trainer/Zf2 Grad Norm               27759.8\n",
      "trainer/Zf2 Param Norm                106.176\n",
      "trainer/Z Expert Predictions Mean    1231.33\n",
      "trainer/Z Expert Predictions Std      262.997\n",
      "trainer/Z Expert Predictions Max     1782.82\n",
      "trainer/Z Expert Predictions Min      598.918\n",
      "trainer/Z Policy Predictions Mean     893.331\n",
      "trainer/Z Policy Predictions Std      458.922\n",
      "trainer/Z Policy Predictions Max     1672.39\n",
      "trainer/Z Policy Predictions Min     -379.383\n",
      "trainer/Z Expert Targets Mean        1224.19\n",
      "trainer/Z Expert Targets Std          263.69\n",
      "trainer/Z Expert Targets Max         1781.86\n",
      "trainer/Z Expert Targets Min          592.797\n",
      "trainer/Z Policy Targets Mean         904.006\n",
      "trainer/Z Policy Targets Std          458.275\n",
      "trainer/Z Policy Targets Max         1805.59\n",
      "trainer/Z Policy Targets Min         -386.633\n",
      "trainer/Log Pis Mean                   13.4145\n",
      "trainer/Log Pis Std                     5.33922\n",
      "trainer/Policy mu Mean                  0.397153\n",
      "trainer/Policy mu Std                   2.70283\n",
      "trainer/Policy log std Mean            -3.96932\n",
      "trainer/Policy log std Std              1.22943\n",
      "exploration/num steps total        170796\n",
      "exploration/num paths total           997\n",
      "evaluation/num steps total              1.13721e+06\n",
      "evaluation/num paths total           1662\n",
      "evaluation/path length Mean           784.636\n",
      "evaluation/path length Std            289.444\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            332\n",
      "evaluation/Rewards Mean                 3.53844\n",
      "evaluation/Rewards Std                  0.657473\n",
      "evaluation/Rewards Max                  4.69677\n",
      "evaluation/Rewards Min                  0.619376\n",
      "evaluation/Returns Mean              2776.39\n",
      "evaluation/Returns Std               1060.63\n",
      "evaluation/Returns Max               3595.25\n",
      "evaluation/Returns Min               1104.41\n",
      "evaluation/Estimation Bias Mean      1111.11\n",
      "evaluation/Estimation Bias Std        434.286\n",
      "evaluation/EB/Q_True Mean              37.953\n",
      "evaluation/EB/Q_True Std              107.693\n",
      "evaluation/EB/Q_Pred Mean            1149.07\n",
      "evaluation/EB/Q_Pred Std              397.412\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2776.39\n",
      "evaluation/Actions Mean                 0.0451153\n",
      "evaluation/Actions Std                  0.603847\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82642\n",
      "time/backward_zf1 (s)                   1.92251\n",
      "time/backward_zf2 (s)                   1.87823\n",
      "time/data sampling (s)                  0.23442\n",
      "time/data storing (s)                   0.0139873\n",
      "time/evaluation sampling (s)            1.3878\n",
      "time/exploration sampling (s)           0.171285\n",
      "time/logging (s)                        0.0102756\n",
      "time/preback_alpha (s)                  0.550693\n",
      "time/preback_policy (s)                 0.624879\n",
      "time/preback_start (s)                  0.123286\n",
      "time/preback_zf (s)                     4.96724\n",
      "time/saving (s)                         0.00502908\n",
      "time/training (s)                       2.36256\n",
      "time/epoch (s)                         16.0786\n",
      "time/total (s)                       2542\n",
      "Epoch                                 163\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:43:51.583317 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 164 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 175000\n",
      "trainer/ZF1 Loss                       87.9463\n",
      "trainer/ZF2 Loss                      114.759\n",
      "trainer/ZF Expert Reward               17.5008\n",
      "trainer/ZF Policy Reward                2.07924\n",
      "trainer/ZF CHI2 Term                  130.135\n",
      "trainer/Policy Loss                  -900.052\n",
      "trainer/Policy Grad Norm              810.64\n",
      "trainer/Policy Param Norm              39.9939\n",
      "trainer/Zf1 Grad Norm               50856.1\n",
      "trainer/Zf1 Param Norm                110.224\n",
      "trainer/Zf2 Grad Norm               52225\n",
      "trainer/Zf2 Param Norm                106.526\n",
      "trainer/Z Expert Predictions Mean    1276.61\n",
      "trainer/Z Expert Predictions Std      271.688\n",
      "trainer/Z Expert Predictions Max     1828.04\n",
      "trainer/Z Expert Predictions Min      613.029\n",
      "trainer/Z Policy Predictions Mean     899.486\n",
      "trainer/Z Policy Predictions Std      420.232\n",
      "trainer/Z Policy Predictions Max     1634.75\n",
      "trainer/Z Policy Predictions Min     -469.069\n",
      "trainer/Z Expert Targets Mean        1259.11\n",
      "trainer/Z Expert Targets Std          270.217\n",
      "trainer/Z Expert Targets Max         1795.05\n",
      "trainer/Z Expert Targets Min          622.388\n",
      "trainer/Z Policy Targets Mean         897.407\n",
      "trainer/Z Policy Targets Std          413.881\n",
      "trainer/Z Policy Targets Max         1740.65\n",
      "trainer/Z Policy Targets Min         -352.385\n",
      "trainer/Log Pis Mean                   13.496\n",
      "trainer/Log Pis Std                     5.17154\n",
      "trainer/Policy mu Mean                  0.433628\n",
      "trainer/Policy mu Std                   2.79978\n",
      "trainer/Policy log std Mean            -3.98768\n",
      "trainer/Policy log std Std              1.1539\n",
      "exploration/num steps total        170796\n",
      "exploration/num paths total           997\n",
      "evaluation/num steps total              1.14458e+06\n",
      "evaluation/num paths total           1674\n",
      "evaluation/path length Mean           614.833\n",
      "evaluation/path length Std            268.835\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            401\n",
      "evaluation/Rewards Mean                 3.49945\n",
      "evaluation/Rewards Std                  0.694124\n",
      "evaluation/Rewards Max                  4.82529\n",
      "evaluation/Rewards Min                  0.623943\n",
      "evaluation/Returns Mean              2151.58\n",
      "evaluation/Returns Std                971.903\n",
      "evaluation/Returns Max               3565.13\n",
      "evaluation/Returns Min               1378.23\n",
      "evaluation/Estimation Bias Mean       943.746\n",
      "evaluation/Estimation Bias Std        553.04\n",
      "evaluation/EB/Q_True Mean              44.7038\n",
      "evaluation/EB/Q_True Std              116.143\n",
      "evaluation/EB/Q_Pred Mean             988.45\n",
      "evaluation/EB/Q_Pred Std              522.186\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2151.58\n",
      "evaluation/Actions Mean                 0.0321637\n",
      "evaluation/Actions Std                  0.601928\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.6969\n",
      "time/backward_zf1 (s)                   1.81454\n",
      "time/backward_zf2 (s)                   1.7474\n",
      "time/data sampling (s)                  0.25636\n",
      "time/data storing (s)                   0.0138556\n",
      "time/evaluation sampling (s)            1.41523\n",
      "time/exploration sampling (s)           0.168315\n",
      "time/logging (s)                        0.00939349\n",
      "time/preback_alpha (s)                  0.545172\n",
      "time/preback_policy (s)                 0.607975\n",
      "time/preback_start (s)                  0.122207\n",
      "time/preback_zf (s)                     4.95408\n",
      "time/saving (s)                         0.00539666\n",
      "time/training (s)                       2.58231\n",
      "time/epoch (s)                         15.9391\n",
      "time/total (s)                       2557.96\n",
      "Epoch                                 164\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:44:07.292285 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 165 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 176000\n",
      "trainer/ZF1 Loss                       70.3728\n",
      "trainer/ZF2 Loss                       70.6932\n",
      "trainer/ZF Expert Reward               14.4399\n",
      "trainer/ZF Policy Reward                3.71591\n",
      "trainer/ZF CHI2 Term                   95.0593\n",
      "trainer/Policy Loss                  -940.099\n",
      "trainer/Policy Grad Norm              867.879\n",
      "trainer/Policy Param Norm              40.0771\n",
      "trainer/Zf1 Grad Norm               59279.4\n",
      "trainer/Zf1 Param Norm                110.574\n",
      "trainer/Zf2 Grad Norm               82690.8\n",
      "trainer/Zf2 Param Norm                106.845\n",
      "trainer/Z Expert Predictions Mean    1262.47\n",
      "trainer/Z Expert Predictions Std      271.256\n",
      "trainer/Z Expert Predictions Max     1911.32\n",
      "trainer/Z Expert Predictions Min      613.197\n",
      "trainer/Z Policy Predictions Mean     933.042\n",
      "trainer/Z Policy Predictions Std      446.972\n",
      "trainer/Z Policy Predictions Max     1816.7\n",
      "trainer/Z Policy Predictions Min     -469.81\n",
      "trainer/Z Expert Targets Mean        1248.03\n",
      "trainer/Z Expert Targets Std          269.783\n",
      "trainer/Z Expert Targets Max         1892.82\n",
      "trainer/Z Expert Targets Min          609.802\n",
      "trainer/Z Policy Targets Mean         929.326\n",
      "trainer/Z Policy Targets Std          447.116\n",
      "trainer/Z Policy Targets Max         1800.13\n",
      "trainer/Z Policy Targets Min         -483.921\n",
      "trainer/Log Pis Mean                   13.9417\n",
      "trainer/Log Pis Std                     5.84431\n",
      "trainer/Policy mu Mean                  0.359473\n",
      "trainer/Policy mu Std                   2.84817\n",
      "trainer/Policy log std Mean            -4.12212\n",
      "trainer/Policy log std Std              1.1836\n",
      "exploration/num steps total        173325\n",
      "exploration/num paths total          1001\n",
      "evaluation/num steps total              1.14821e+06\n",
      "evaluation/num paths total           1684\n",
      "evaluation/path length Mean           362.9\n",
      "evaluation/path length Std             93.4018\n",
      "evaluation/path length Max            642\n",
      "evaluation/path length Min            321\n",
      "evaluation/Rewards Mean                 3.3521\n",
      "evaluation/Rewards Std                  0.814229\n",
      "evaluation/Rewards Max                  4.73226\n",
      "evaluation/Rewards Min                  0.648759\n",
      "evaluation/Returns Mean              1216.48\n",
      "evaluation/Returns Std                345.503\n",
      "evaluation/Returns Max               2250.93\n",
      "evaluation/Returns Min               1072.76\n",
      "evaluation/Estimation Bias Mean       747.582\n",
      "evaluation/Estimation Bias Std        537.483\n",
      "evaluation/EB/Q_True Mean              45.9745\n",
      "evaluation/EB/Q_True Std              105.668\n",
      "evaluation/EB/Q_Pred Mean             793.557\n",
      "evaluation/EB/Q_Pred Std              532.303\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1216.48\n",
      "evaluation/Actions Mean                 0.0185857\n",
      "evaluation/Actions Std                  0.607618\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86252\n",
      "time/backward_zf1 (s)                   1.96222\n",
      "time/backward_zf2 (s)                   1.91355\n",
      "time/data sampling (s)                  0.24642\n",
      "time/data storing (s)                   0.0138107\n",
      "time/evaluation sampling (s)            0.966597\n",
      "time/exploration sampling (s)           0.174263\n",
      "time/logging (s)                        0.00562252\n",
      "time/preback_alpha (s)                  0.550703\n",
      "time/preback_policy (s)                 0.634808\n",
      "time/preback_start (s)                  0.124086\n",
      "time/preback_zf (s)                     4.94922\n",
      "time/saving (s)                         0.00493466\n",
      "time/training (s)                       2.23187\n",
      "time/epoch (s)                         15.6406\n",
      "time/total (s)                       2573.62\n",
      "Epoch                                 165\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:44:23.287878 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 166 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 177000\n",
      "trainer/ZF1 Loss                       83.3659\n",
      "trainer/ZF2 Loss                      100.282\n",
      "trainer/ZF Expert Reward                9.23725\n",
      "trainer/ZF Policy Reward                3.4707\n",
      "trainer/ZF CHI2 Term                  111.801\n",
      "trainer/Policy Loss                  -929.914\n",
      "trainer/Policy Grad Norm              771.11\n",
      "trainer/Policy Param Norm              40.1527\n",
      "trainer/Zf1 Grad Norm               26705.2\n",
      "trainer/Zf1 Param Norm                110.915\n",
      "trainer/Zf2 Grad Norm               38611.6\n",
      "trainer/Zf2 Param Norm                107.183\n",
      "trainer/Z Expert Predictions Mean    1282.99\n",
      "trainer/Z Expert Predictions Std      272.562\n",
      "trainer/Z Expert Predictions Max     1897.27\n",
      "trainer/Z Expert Predictions Min      606.81\n",
      "trainer/Z Policy Predictions Mean     929.02\n",
      "trainer/Z Policy Predictions Std      499.141\n",
      "trainer/Z Policy Predictions Max     1712.87\n",
      "trainer/Z Policy Predictions Min     -496.57\n",
      "trainer/Z Expert Targets Mean        1273.75\n",
      "trainer/Z Expert Targets Std          276.002\n",
      "trainer/Z Expert Targets Max         1871.23\n",
      "trainer/Z Expert Targets Min          579.619\n",
      "trainer/Z Policy Targets Mean         925.549\n",
      "trainer/Z Policy Targets Std          499.647\n",
      "trainer/Z Policy Targets Max         1743.42\n",
      "trainer/Z Policy Targets Min         -488.934\n",
      "trainer/Log Pis Mean                   14.3536\n",
      "trainer/Log Pis Std                     5.4203\n",
      "trainer/Policy mu Mean                  0.120507\n",
      "trainer/Policy mu Std                   2.52241\n",
      "trainer/Policy log std Mean            -4.12718\n",
      "trainer/Policy log std Std              1.14406\n",
      "exploration/num steps total        174041\n",
      "exploration/num paths total          1003\n",
      "evaluation/num steps total              1.15729e+06\n",
      "evaluation/num paths total           1697\n",
      "evaluation/path length Mean           698.077\n",
      "evaluation/path length Std            325.365\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 3.49333\n",
      "evaluation/Rewards Std                  0.669168\n",
      "evaluation/Rewards Max                  4.75481\n",
      "evaluation/Rewards Min                  0.631541\n",
      "evaluation/Returns Mean              2438.61\n",
      "evaluation/Returns Std               1197.86\n",
      "evaluation/Returns Max               3594.35\n",
      "evaluation/Returns Min               1115.29\n",
      "evaluation/Estimation Bias Mean      1117.12\n",
      "evaluation/Estimation Bias Std        405.428\n",
      "evaluation/EB/Q_True Mean              36.2828\n",
      "evaluation/EB/Q_True Std              105.807\n",
      "evaluation/EB/Q_Pred Mean            1153.4\n",
      "evaluation/EB/Q_Pred Std              380.699\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2438.61\n",
      "evaluation/Actions Mean                 0.0575675\n",
      "evaluation/Actions Std                  0.606474\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.72514\n",
      "time/backward_zf1 (s)                   1.83647\n",
      "time/backward_zf2 (s)                   1.7655\n",
      "time/data sampling (s)                  0.230903\n",
      "time/data storing (s)                   0.0134617\n",
      "time/evaluation sampling (s)            1.39118\n",
      "time/exploration sampling (s)           0.169074\n",
      "time/logging (s)                        0.0109643\n",
      "time/preback_alpha (s)                  0.544911\n",
      "time/preback_policy (s)                 0.609561\n",
      "time/preback_start (s)                  0.12229\n",
      "time/preback_zf (s)                     4.94925\n",
      "time/saving (s)                         0.00522476\n",
      "time/training (s)                       2.5645\n",
      "time/epoch (s)                         15.9384\n",
      "time/total (s)                       2589.57\n",
      "Epoch                                 166\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:44:39.322067 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 167 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 178000\n",
      "trainer/ZF1 Loss                       54.1039\n",
      "trainer/ZF2 Loss                       56.966\n",
      "trainer/ZF Expert Reward               17.3034\n",
      "trainer/ZF Policy Reward                0.967213\n",
      "trainer/ZF CHI2 Term                   85.6797\n",
      "trainer/Policy Loss                  -924.603\n",
      "trainer/Policy Grad Norm              548.119\n",
      "trainer/Policy Param Norm              40.2253\n",
      "trainer/Zf1 Grad Norm               50463.6\n",
      "trainer/Zf1 Param Norm                111.268\n",
      "trainer/Zf2 Grad Norm               32493.2\n",
      "trainer/Zf2 Param Norm                107.515\n",
      "trainer/Z Expert Predictions Mean    1267.79\n",
      "trainer/Z Expert Predictions Std      294.127\n",
      "trainer/Z Expert Predictions Max     1918.49\n",
      "trainer/Z Expert Predictions Min      502.322\n",
      "trainer/Z Policy Predictions Mean     911.814\n",
      "trainer/Z Policy Predictions Std      468.441\n",
      "trainer/Z Policy Predictions Max     1772.6\n",
      "trainer/Z Policy Predictions Min     -374.447\n",
      "trainer/Z Expert Targets Mean        1250.49\n",
      "trainer/Z Expert Targets Std          290.327\n",
      "trainer/Z Expert Targets Max         1869.63\n",
      "trainer/Z Expert Targets Min          492.539\n",
      "trainer/Z Policy Targets Mean         910.847\n",
      "trainer/Z Policy Targets Std          462.489\n",
      "trainer/Z Policy Targets Max         1722.93\n",
      "trainer/Z Policy Targets Min         -418.08\n",
      "trainer/Log Pis Mean                   13.948\n",
      "trainer/Log Pis Std                     4.81719\n",
      "trainer/Policy mu Mean                  0.39904\n",
      "trainer/Policy mu Std                   2.53531\n",
      "trainer/Policy log std Mean            -4.08174\n",
      "trainer/Policy log std Std              1.20934\n",
      "exploration/num steps total        174041\n",
      "exploration/num paths total          1003\n",
      "evaluation/num steps total              1.16649e+06\n",
      "evaluation/num paths total           1707\n",
      "evaluation/path length Mean           920.3\n",
      "evaluation/path length Std            114.273\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            647\n",
      "evaluation/Rewards Mean                 3.52506\n",
      "evaluation/Rewards Std                  0.604814\n",
      "evaluation/Rewards Max                  5.10104\n",
      "evaluation/Rewards Min                  0.608173\n",
      "evaluation/Returns Mean              3244.11\n",
      "evaluation/Returns Std                410.755\n",
      "evaluation/Returns Max               3578.48\n",
      "evaluation/Returns Min               2253.4\n",
      "evaluation/Estimation Bias Mean      1140.11\n",
      "evaluation/Estimation Bias Std        368.276\n",
      "evaluation/EB/Q_True Mean              35.1067\n",
      "evaluation/EB/Q_True Std              103.352\n",
      "evaluation/EB/Q_Pred Mean            1175.21\n",
      "evaluation/EB/Q_Pred Std              349.914\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3244.11\n",
      "evaluation/Actions Mean                 0.0429492\n",
      "evaluation/Actions Std                  0.595992\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75707\n",
      "time/backward_zf1 (s)                   1.86778\n",
      "time/backward_zf2 (s)                   1.80349\n",
      "time/data sampling (s)                  0.256726\n",
      "time/data storing (s)                   0.0136164\n",
      "time/evaluation sampling (s)            1.39751\n",
      "time/exploration sampling (s)           0.166611\n",
      "time/logging (s)                        0.0118745\n",
      "time/preback_alpha (s)                  0.54944\n",
      "time/preback_policy (s)                 0.613818\n",
      "time/preback_start (s)                  0.123294\n",
      "time/preback_zf (s)                     4.94822\n",
      "time/saving (s)                         0.00557575\n",
      "time/training (s)                       2.4574\n",
      "time/epoch (s)                         15.9724\n",
      "time/total (s)                       2605.56\n",
      "Epoch                                 167\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:44:54.483841 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 168 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 179000\n",
      "trainer/ZF1 Loss                       83.8298\n",
      "trainer/ZF2 Loss                       77.9498\n",
      "trainer/ZF Expert Reward                5.04764\n",
      "trainer/ZF Policy Reward               -3.37054\n",
      "trainer/ZF CHI2 Term                  102.986\n",
      "trainer/Policy Loss                  -897.765\n",
      "trainer/Policy Grad Norm              578.057\n",
      "trainer/Policy Param Norm              40.3148\n",
      "trainer/Zf1 Grad Norm               56218.4\n",
      "trainer/Zf1 Param Norm                111.605\n",
      "trainer/Zf2 Grad Norm               47810.7\n",
      "trainer/Zf2 Param Norm                107.832\n",
      "trainer/Z Expert Predictions Mean    1263.69\n",
      "trainer/Z Expert Predictions Std      271.573\n",
      "trainer/Z Expert Predictions Max     1835.15\n",
      "trainer/Z Expert Predictions Min      574.421\n",
      "trainer/Z Policy Predictions Mean     879.192\n",
      "trainer/Z Policy Predictions Std      502.504\n",
      "trainer/Z Policy Predictions Max     1808.19\n",
      "trainer/Z Policy Predictions Min     -518.14\n",
      "trainer/Z Expert Targets Mean        1258.64\n",
      "trainer/Z Expert Targets Std          272.452\n",
      "trainer/Z Expert Targets Max         1841.38\n",
      "trainer/Z Expert Targets Min          578.477\n",
      "trainer/Z Policy Targets Mean         882.562\n",
      "trainer/Z Policy Targets Std          503.402\n",
      "trainer/Z Policy Targets Max         1829.54\n",
      "trainer/Z Policy Targets Min         -509.767\n",
      "trainer/Log Pis Mean                   13.8161\n",
      "trainer/Log Pis Std                     5.13051\n",
      "trainer/Policy mu Mean                  0.480761\n",
      "trainer/Policy mu Std                   3.01056\n",
      "trainer/Policy log std Mean            -3.99595\n",
      "trainer/Policy log std Std              1.17589\n",
      "exploration/num steps total        175036\n",
      "exploration/num paths total          1006\n",
      "evaluation/num steps total              1.16976e+06\n",
      "evaluation/num paths total           1717\n",
      "evaluation/path length Mean           326.8\n",
      "evaluation/path length Std              3.05941\n",
      "evaluation/path length Max            331\n",
      "evaluation/path length Min            322\n",
      "evaluation/Rewards Mean                 3.35634\n",
      "evaluation/Rewards Std                  0.865435\n",
      "evaluation/Rewards Max                  5.00296\n",
      "evaluation/Rewards Min                  0.604654\n",
      "evaluation/Returns Mean              1096.85\n",
      "evaluation/Returns Std                  7.83258\n",
      "evaluation/Returns Max               1108.68\n",
      "evaluation/Returns Min               1083.01\n",
      "evaluation/Estimation Bias Mean       728.919\n",
      "evaluation/Estimation Bias Std        580.671\n",
      "evaluation/EB/Q_True Mean              26.1602\n",
      "evaluation/EB/Q_True Std               82.4007\n",
      "evaluation/EB/Q_Pred Mean             755.079\n",
      "evaluation/EB/Q_Pred Std              579.131\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1096.85\n",
      "evaluation/Actions Mean                 0.029313\n",
      "evaluation/Actions Std                  0.617317\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78234\n",
      "time/backward_zf1 (s)                   1.88517\n",
      "time/backward_zf2 (s)                   1.82989\n",
      "time/data sampling (s)                  0.251782\n",
      "time/data storing (s)                   0.0135973\n",
      "time/evaluation sampling (s)            0.499556\n",
      "time/exploration sampling (s)           0.169496\n",
      "time/logging (s)                        0.00531775\n",
      "time/preback_alpha (s)                  0.550585\n",
      "time/preback_policy (s)                 0.616517\n",
      "time/preback_start (s)                  0.12261\n",
      "time/preback_zf (s)                     4.95591\n",
      "time/saving (s)                         0.00492345\n",
      "time/training (s)                       2.3999\n",
      "time/epoch (s)                         15.0876\n",
      "time/total (s)                       2620.67\n",
      "Epoch                                 168\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:45:10.510154 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 169 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 180000\n",
      "trainer/ZF1 Loss                       69.4055\n",
      "trainer/ZF2 Loss                       92.0048\n",
      "trainer/ZF Expert Reward               14.3959\n",
      "trainer/ZF Policy Reward                4.41973\n",
      "trainer/ZF CHI2 Term                  104.709\n",
      "trainer/Policy Loss                  -899.575\n",
      "trainer/Policy Grad Norm              905.726\n",
      "trainer/Policy Param Norm              40.3954\n",
      "trainer/Zf1 Grad Norm               45876.9\n",
      "trainer/Zf1 Param Norm                111.928\n",
      "trainer/Zf2 Grad Norm               57495.3\n",
      "trainer/Zf2 Param Norm                108.14\n",
      "trainer/Z Expert Predictions Mean    1257.75\n",
      "trainer/Z Expert Predictions Std      267.09\n",
      "trainer/Z Expert Predictions Max     1904.25\n",
      "trainer/Z Expert Predictions Min      637.186\n",
      "trainer/Z Policy Predictions Mean     900.763\n",
      "trainer/Z Policy Predictions Std      469.717\n",
      "trainer/Z Policy Predictions Max     1831.07\n",
      "trainer/Z Policy Predictions Min     -531.694\n",
      "trainer/Z Expert Targets Mean        1243.35\n",
      "trainer/Z Expert Targets Std          266.024\n",
      "trainer/Z Expert Targets Max         1874.21\n",
      "trainer/Z Expert Targets Min          628.985\n",
      "trainer/Z Policy Targets Mean         896.343\n",
      "trainer/Z Policy Targets Std          470.822\n",
      "trainer/Z Policy Targets Max         1839\n",
      "trainer/Z Policy Targets Min         -544.685\n",
      "trainer/Log Pis Mean                   14.1698\n",
      "trainer/Log Pis Std                     5.74304\n",
      "trainer/Policy mu Mean                  0.507081\n",
      "trainer/Policy mu Std                   2.88417\n",
      "trainer/Policy log std Mean            -4.07003\n",
      "trainer/Policy log std Std              1.21734\n",
      "exploration/num steps total        177777\n",
      "exploration/num paths total          1010\n",
      "evaluation/num steps total              1.17797e+06\n",
      "evaluation/num paths total           1727\n",
      "evaluation/path length Mean           820.7\n",
      "evaluation/path length Std            138.509\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            648\n",
      "evaluation/Rewards Mean                 3.52403\n",
      "evaluation/Rewards Std                  0.625154\n",
      "evaluation/Rewards Max                  4.81474\n",
      "evaluation/Rewards Min                  0.578713\n",
      "evaluation/Returns Mean              2892.17\n",
      "evaluation/Returns Std                517.704\n",
      "evaluation/Returns Max               3585.85\n",
      "evaluation/Returns Min               2261.54\n",
      "evaluation/Estimation Bias Mean      1106.12\n",
      "evaluation/Estimation Bias Std        409.917\n",
      "evaluation/EB/Q_True Mean              40.2929\n",
      "evaluation/EB/Q_True Std              111.127\n",
      "evaluation/EB/Q_Pred Mean            1146.41\n",
      "evaluation/EB/Q_Pred Std              387.048\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2892.17\n",
      "evaluation/Actions Mean                 0.0520125\n",
      "evaluation/Actions Std                  0.598903\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.83717\n",
      "time/backward_zf1 (s)                   1.93246\n",
      "time/backward_zf2 (s)                   1.8872\n",
      "time/data sampling (s)                  0.247947\n",
      "time/data storing (s)                   0.013338\n",
      "time/evaluation sampling (s)            1.36338\n",
      "time/exploration sampling (s)           0.170002\n",
      "time/logging (s)                        0.00996852\n",
      "time/preback_alpha (s)                  0.546247\n",
      "time/preback_policy (s)                 0.623908\n",
      "time/preback_start (s)                  0.123339\n",
      "time/preback_zf (s)                     4.95709\n",
      "time/saving (s)                         0.00474784\n",
      "time/training (s)                       2.24908\n",
      "time/epoch (s)                         15.9659\n",
      "time/total (s)                       2636.66\n",
      "Epoch                                 169\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:45:25.788930 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 170 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 181000\n",
      "trainer/ZF1 Loss                       84.4651\n",
      "trainer/ZF2 Loss                      103.784\n",
      "trainer/ZF Expert Reward               12.0667\n",
      "trainer/ZF Policy Reward                4.14224\n",
      "trainer/ZF CHI2 Term                  115.442\n",
      "trainer/Policy Loss                  -885.485\n",
      "trainer/Policy Grad Norm              914.702\n",
      "trainer/Policy Param Norm              40.4681\n",
      "trainer/Zf1 Grad Norm               54987\n",
      "trainer/Zf1 Param Norm                112.201\n",
      "trainer/Zf2 Grad Norm               93900.1\n",
      "trainer/Zf2 Param Norm                108.397\n",
      "trainer/Z Expert Predictions Mean    1286.13\n",
      "trainer/Z Expert Predictions Std      269.277\n",
      "trainer/Z Expert Predictions Max     1888.37\n",
      "trainer/Z Expert Predictions Min      564.849\n",
      "trainer/Z Policy Predictions Mean     875.307\n",
      "trainer/Z Policy Predictions Std      499.235\n",
      "trainer/Z Policy Predictions Max     1792.99\n",
      "trainer/Z Policy Predictions Min     -496.2\n",
      "trainer/Z Expert Targets Mean        1274.07\n",
      "trainer/Z Expert Targets Std          270.921\n",
      "trainer/Z Expert Targets Max         1863.35\n",
      "trainer/Z Expert Targets Min          560.878\n",
      "trainer/Z Policy Targets Mean         871.164\n",
      "trainer/Z Policy Targets Std          492.002\n",
      "trainer/Z Policy Targets Max         1778.96\n",
      "trainer/Z Policy Targets Min         -447.308\n",
      "trainer/Log Pis Mean                   13.5278\n",
      "trainer/Log Pis Std                     5.00916\n",
      "trainer/Policy mu Mean                  0.490803\n",
      "trainer/Policy mu Std                   2.63397\n",
      "trainer/Policy log std Mean            -3.98312\n",
      "trainer/Policy log std Std              1.21615\n",
      "exploration/num steps total        178107\n",
      "exploration/num paths total          1011\n",
      "evaluation/num steps total              1.18122e+06\n",
      "evaluation/num paths total           1737\n",
      "evaluation/path length Mean           324.9\n",
      "evaluation/path length Std             15.0562\n",
      "evaluation/path length Max            370\n",
      "evaluation/path length Min            318\n",
      "evaluation/Rewards Mean                 3.36516\n",
      "evaluation/Rewards Std                  0.877313\n",
      "evaluation/Rewards Max                  5.27654\n",
      "evaluation/Rewards Min                  0.603631\n",
      "evaluation/Returns Mean              1093.34\n",
      "evaluation/Returns Std                 54.0915\n",
      "evaluation/Returns Max               1255.23\n",
      "evaluation/Returns Min               1066.61\n",
      "evaluation/Estimation Bias Mean       694.225\n",
      "evaluation/Estimation Bias Std        590.981\n",
      "evaluation/EB/Q_True Mean              30.6959\n",
      "evaluation/EB/Q_True Std               90.3121\n",
      "evaluation/EB/Q_Pred Mean             724.921\n",
      "evaluation/EB/Q_Pred Std              588.727\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1093.34\n",
      "evaluation/Actions Mean                 0.0362164\n",
      "evaluation/Actions Std                  0.622047\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77976\n",
      "time/backward_zf1 (s)                   1.88513\n",
      "time/backward_zf2 (s)                   1.83841\n",
      "time/data sampling (s)                  0.251214\n",
      "time/data storing (s)                   0.0140667\n",
      "time/evaluation sampling (s)            0.582494\n",
      "time/exploration sampling (s)           0.172918\n",
      "time/logging (s)                        0.00458435\n",
      "time/preback_alpha (s)                  0.547817\n",
      "time/preback_policy (s)                 0.622031\n",
      "time/preback_start (s)                  0.122977\n",
      "time/preback_zf (s)                     4.94724\n",
      "time/saving (s)                         0.00517193\n",
      "time/training (s)                       2.43531\n",
      "time/epoch (s)                         15.2091\n",
      "time/total (s)                       2651.89\n",
      "Epoch                                 170\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:45:41.881941 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 171 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 182000\n",
      "trainer/ZF1 Loss                      555.38\n",
      "trainer/ZF2 Loss                      568.238\n",
      "trainer/ZF Expert Reward               17.4248\n",
      "trainer/ZF Policy Reward                5.34846\n",
      "trainer/ZF CHI2 Term                  587.266\n",
      "trainer/Policy Loss                  -914.688\n",
      "trainer/Policy Grad Norm             1415.37\n",
      "trainer/Policy Param Norm              40.5466\n",
      "trainer/Zf1 Grad Norm               31031.4\n",
      "trainer/Zf1 Param Norm                112.483\n",
      "trainer/Zf2 Grad Norm               45481.7\n",
      "trainer/Zf2 Param Norm                108.656\n",
      "trainer/Z Expert Predictions Mean    1287.44\n",
      "trainer/Z Expert Predictions Std      298.402\n",
      "trainer/Z Expert Predictions Max     1919.75\n",
      "trainer/Z Expert Predictions Min      555.545\n",
      "trainer/Z Policy Predictions Mean     913.428\n",
      "trainer/Z Policy Predictions Std      484.964\n",
      "trainer/Z Policy Predictions Max     1716.81\n",
      "trainer/Z Policy Predictions Min     -498.681\n",
      "trainer/Z Expert Targets Mean        1270.02\n",
      "trainer/Z Expert Targets Std          306.931\n",
      "trainer/Z Expert Targets Max         1904.4\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         908.08\n",
      "trainer/Z Policy Targets Std          483.308\n",
      "trainer/Z Policy Targets Max         1701.94\n",
      "trainer/Z Policy Targets Min         -429.91\n",
      "trainer/Log Pis Mean                   13.516\n",
      "trainer/Log Pis Std                     5.05955\n",
      "trainer/Policy mu Mean                  0.194062\n",
      "trainer/Policy mu Std                   2.45716\n",
      "trainer/Policy log std Mean            -3.96253\n",
      "trainer/Policy log std Std              1.12335\n",
      "exploration/num steps total        179967\n",
      "exploration/num paths total          1015\n",
      "evaluation/num steps total              1.19122e+06\n",
      "evaluation/num paths total           1747\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52472\n",
      "evaluation/Rewards Std                  0.597951\n",
      "evaluation/Rewards Max                  4.77517\n",
      "evaluation/Rewards Min                  0.615352\n",
      "evaluation/Returns Mean              3524.72\n",
      "evaluation/Returns Std                 22.567\n",
      "evaluation/Returns Max               3557.67\n",
      "evaluation/Returns Min               3487.82\n",
      "evaluation/Estimation Bias Mean      1214.57\n",
      "evaluation/Estimation Bias Std        269.716\n",
      "evaluation/EB/Q_True Mean              32.6282\n",
      "evaluation/EB/Q_True Std              100.548\n",
      "evaluation/EB/Q_Pred Mean            1247.2\n",
      "evaluation/EB/Q_Pred Std              243.213\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3524.72\n",
      "evaluation/Actions Mean                 0.0398092\n",
      "evaluation/Actions Std                  0.60202\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80005\n",
      "time/backward_zf1 (s)                   1.89405\n",
      "time/backward_zf2 (s)                   1.85571\n",
      "time/data sampling (s)                  0.240284\n",
      "time/data storing (s)                   0.0139601\n",
      "time/evaluation sampling (s)            1.36672\n",
      "time/exploration sampling (s)           0.171918\n",
      "time/logging (s)                        0.0115953\n",
      "time/preback_alpha (s)                  0.546663\n",
      "time/preback_policy (s)                 0.618508\n",
      "time/preback_start (s)                  0.123711\n",
      "time/preback_zf (s)                     4.97128\n",
      "time/saving (s)                         0.00544293\n",
      "time/training (s)                       2.4181\n",
      "time/epoch (s)                         16.038\n",
      "time/total (s)                       2667.94\n",
      "Epoch                                 171\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:45:57.954642 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 172 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 183000\n",
      "trainer/ZF1 Loss                       44.0745\n",
      "trainer/ZF2 Loss                       31.0628\n",
      "trainer/ZF Expert Reward               11.1255\n",
      "trainer/ZF Policy Reward               -2.28146\n",
      "trainer/ZF CHI2 Term                   64.5953\n",
      "trainer/Policy Loss                  -905.017\n",
      "trainer/Policy Grad Norm              749.532\n",
      "trainer/Policy Param Norm              40.63\n",
      "trainer/Zf1 Grad Norm               10388.9\n",
      "trainer/Zf1 Param Norm                112.744\n",
      "trainer/Zf2 Grad Norm               13330.6\n",
      "trainer/Zf2 Param Norm                108.896\n",
      "trainer/Z Expert Predictions Mean    1302.51\n",
      "trainer/Z Expert Predictions Std      273.997\n",
      "trainer/Z Expert Predictions Max     1878.33\n",
      "trainer/Z Expert Predictions Min      599.4\n",
      "trainer/Z Policy Predictions Mean     896.236\n",
      "trainer/Z Policy Predictions Std      451.599\n",
      "trainer/Z Policy Predictions Max     1656.04\n",
      "trainer/Z Policy Predictions Min     -537.52\n",
      "trainer/Z Expert Targets Mean        1291.39\n",
      "trainer/Z Expert Targets Std          272.032\n",
      "trainer/Z Expert Targets Max         1849.23\n",
      "trainer/Z Expert Targets Min          583.255\n",
      "trainer/Z Policy Targets Mean         898.517\n",
      "trainer/Z Policy Targets Std          449.554\n",
      "trainer/Z Policy Targets Max         1647.69\n",
      "trainer/Z Policy Targets Min         -512.075\n",
      "trainer/Log Pis Mean                   13.7573\n",
      "trainer/Log Pis Std                     4.823\n",
      "trainer/Policy mu Mean                  0.397531\n",
      "trainer/Policy mu Std                   2.80839\n",
      "trainer/Policy log std Mean            -3.99456\n",
      "trainer/Policy log std Std              1.27341\n",
      "exploration/num steps total        180299\n",
      "exploration/num paths total          1016\n",
      "evaluation/num steps total              1.19994e+06\n",
      "evaluation/num paths total           1760\n",
      "evaluation/path length Mean           670.769\n",
      "evaluation/path length Std            280.552\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 3.50713\n",
      "evaluation/Rewards Std                  0.670345\n",
      "evaluation/Rewards Max                  4.85548\n",
      "evaluation/Rewards Min                  0.609203\n",
      "evaluation/Returns Mean              2352.48\n",
      "evaluation/Returns Std               1030.66\n",
      "evaluation/Returns Max               3604.14\n",
      "evaluation/Returns Min               1097.74\n",
      "evaluation/Estimation Bias Mean      1058.37\n",
      "evaluation/Estimation Bias Std        494.174\n",
      "evaluation/EB/Q_True Mean              37.7848\n",
      "evaluation/EB/Q_True Std              107.765\n",
      "evaluation/EB/Q_Pred Mean            1096.15\n",
      "evaluation/EB/Q_Pred Std              471.526\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2352.48\n",
      "evaluation/Actions Mean                 0.0349962\n",
      "evaluation/Actions Std                  0.600108\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7821\n",
      "time/backward_zf1 (s)                   1.88938\n",
      "time/backward_zf2 (s)                   1.83077\n",
      "time/data sampling (s)                  0.24601\n",
      "time/data storing (s)                   0.0135168\n",
      "time/evaluation sampling (s)            1.35623\n",
      "time/exploration sampling (s)           0.166819\n",
      "time/logging (s)                        0.0103897\n",
      "time/preback_alpha (s)                  0.548728\n",
      "time/preback_policy (s)                 0.618231\n",
      "time/preback_start (s)                  0.123028\n",
      "time/preback_zf (s)                     4.94967\n",
      "time/saving (s)                         0.00510946\n",
      "time/training (s)                       2.46637\n",
      "time/epoch (s)                         16.0064\n",
      "time/total (s)                       2683.97\n",
      "Epoch                                 172\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:46:14.053175 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 173 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 184000\n",
      "trainer/ZF1 Loss                      452.93\n",
      "trainer/ZF2 Loss                      481.851\n",
      "trainer/ZF Expert Reward                8.73457\n",
      "trainer/ZF Policy Reward                5.89212\n",
      "trainer/ZF CHI2 Term                  484.182\n",
      "trainer/Policy Loss                  -870.021\n",
      "trainer/Policy Grad Norm              490.107\n",
      "trainer/Policy Param Norm              40.7127\n",
      "trainer/Zf1 Grad Norm               44415.6\n",
      "trainer/Zf1 Param Norm                113.006\n",
      "trainer/Zf2 Grad Norm               41568\n",
      "trainer/Zf2 Param Norm                109.149\n",
      "trainer/Z Expert Predictions Mean    1252.1\n",
      "trainer/Z Expert Predictions Std      280.507\n",
      "trainer/Z Expert Predictions Max     1795.03\n",
      "trainer/Z Expert Predictions Min      566.006\n",
      "trainer/Z Policy Predictions Mean     865.056\n",
      "trainer/Z Policy Predictions Std      489.611\n",
      "trainer/Z Policy Predictions Max     1768.38\n",
      "trainer/Z Policy Predictions Min     -421.682\n",
      "trainer/Z Expert Targets Mean        1243.36\n",
      "trainer/Z Expert Targets Std          281.682\n",
      "trainer/Z Expert Targets Max         1767.39\n",
      "trainer/Z Expert Targets Min          549.923\n",
      "trainer/Z Policy Targets Mean         859.164\n",
      "trainer/Z Policy Targets Std          490.168\n",
      "trainer/Z Policy Targets Max         1799.65\n",
      "trainer/Z Policy Targets Min         -436.2\n",
      "trainer/Log Pis Mean                   14.0904\n",
      "trainer/Log Pis Std                     5.02145\n",
      "trainer/Policy mu Mean                  0.505037\n",
      "trainer/Policy mu Std                   2.63407\n",
      "trainer/Policy log std Mean            -4.06179\n",
      "trainer/Policy log std Std              1.13549\n",
      "exploration/num steps total        181299\n",
      "exploration/num paths total          1017\n",
      "evaluation/num steps total              1.20651e+06\n",
      "evaluation/num paths total           1770\n",
      "evaluation/path length Mean           657.6\n",
      "evaluation/path length Std            168.325\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            488\n",
      "evaluation/Rewards Mean                 3.45155\n",
      "evaluation/Rewards Std                  0.666919\n",
      "evaluation/Rewards Max                  4.74515\n",
      "evaluation/Rewards Min                  0.596116\n",
      "evaluation/Returns Mean              2269.74\n",
      "evaluation/Returns Std                613.5\n",
      "evaluation/Returns Max               3532.51\n",
      "evaluation/Returns Min               1647.25\n",
      "evaluation/Estimation Bias Mean       963.796\n",
      "evaluation/Estimation Bias Std        452.432\n",
      "evaluation/EB/Q_True Mean              49.6695\n",
      "evaluation/EB/Q_True Std              120.54\n",
      "evaluation/EB/Q_Pred Mean            1013.47\n",
      "evaluation/EB/Q_Pred Std              433.706\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2269.74\n",
      "evaluation/Actions Mean                 0.0417228\n",
      "evaluation/Actions Std                  0.609369\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80086\n",
      "time/backward_zf1 (s)                   1.90283\n",
      "time/backward_zf2 (s)                   1.86761\n",
      "time/data sampling (s)                  0.244546\n",
      "time/data storing (s)                   0.0143417\n",
      "time/evaluation sampling (s)            1.45682\n",
      "time/exploration sampling (s)           0.173069\n",
      "time/logging (s)                        0.00893581\n",
      "time/preback_alpha (s)                  0.544767\n",
      "time/preback_policy (s)                 0.62108\n",
      "time/preback_start (s)                  0.122058\n",
      "time/preback_zf (s)                     4.94251\n",
      "time/saving (s)                         0.00524029\n",
      "time/training (s)                       2.32746\n",
      "time/epoch (s)                         16.0321\n",
      "time/total (s)                       2700.02\n",
      "Epoch                                 173\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:46:30.003028 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 174 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 185000\n",
      "trainer/ZF1 Loss                      100.684\n",
      "trainer/ZF2 Loss                       85.5383\n",
      "trainer/ZF Expert Reward                9.38383\n",
      "trainer/ZF Policy Reward               -2.31897\n",
      "trainer/ZF CHI2 Term                  118.526\n",
      "trainer/Policy Loss                  -893.073\n",
      "trainer/Policy Grad Norm              535.913\n",
      "trainer/Policy Param Norm              40.7859\n",
      "trainer/Zf1 Grad Norm               32294.8\n",
      "trainer/Zf1 Param Norm                113.253\n",
      "trainer/Zf2 Grad Norm               24093.4\n",
      "trainer/Zf2 Param Norm                109.378\n",
      "trainer/Z Expert Predictions Mean    1300.05\n",
      "trainer/Z Expert Predictions Std      304.341\n",
      "trainer/Z Expert Predictions Max     1890.91\n",
      "trainer/Z Expert Predictions Min      553.651\n",
      "trainer/Z Policy Predictions Mean     880.226\n",
      "trainer/Z Policy Predictions Std      502.004\n",
      "trainer/Z Policy Predictions Max     1910.3\n",
      "trainer/Z Policy Predictions Min     -434.072\n",
      "trainer/Z Expert Targets Mean        1290.67\n",
      "trainer/Z Expert Targets Std          304.405\n",
      "trainer/Z Expert Targets Max         1883.82\n",
      "trainer/Z Expert Targets Min          531.609\n",
      "trainer/Z Policy Targets Mean         882.545\n",
      "trainer/Z Policy Targets Std          500.832\n",
      "trainer/Z Policy Targets Max         1885.62\n",
      "trainer/Z Policy Targets Min         -406.475\n",
      "trainer/Log Pis Mean                   13.8506\n",
      "trainer/Log Pis Std                     5.61725\n",
      "trainer/Policy mu Mean                  0.483488\n",
      "trainer/Policy mu Std                   2.77982\n",
      "trainer/Policy log std Mean            -4.05051\n",
      "trainer/Policy log std Std              1.212\n",
      "exploration/num steps total        181777\n",
      "exploration/num paths total          1018\n",
      "evaluation/num steps total              1.21586e+06\n",
      "evaluation/num paths total           1780\n",
      "evaluation/path length Mean           935\n",
      "evaluation/path length Std            156.292\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            481\n",
      "evaluation/Rewards Mean                 3.51384\n",
      "evaluation/Rewards Std                  0.5952\n",
      "evaluation/Rewards Max                  4.79032\n",
      "evaluation/Rewards Min                  0.619574\n",
      "evaluation/Returns Mean              3285.44\n",
      "evaluation/Returns Std                569.074\n",
      "evaluation/Returns Max               3561.45\n",
      "evaluation/Returns Min               1628.28\n",
      "evaluation/Estimation Bias Mean      1167.08\n",
      "evaluation/Estimation Bias Std        366.977\n",
      "evaluation/EB/Q_True Mean              34.7347\n",
      "evaluation/EB/Q_True Std              103.013\n",
      "evaluation/EB/Q_Pred Mean            1201.81\n",
      "evaluation/EB/Q_Pred Std              344.709\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3285.44\n",
      "evaluation/Actions Mean                 0.0445268\n",
      "evaluation/Actions Std                  0.591066\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70468\n",
      "time/backward_zf1 (s)                   1.80542\n",
      "time/backward_zf2 (s)                   1.74202\n",
      "time/data sampling (s)                  0.243355\n",
      "time/data storing (s)                   0.0137717\n",
      "time/evaluation sampling (s)            1.39\n",
      "time/exploration sampling (s)           0.167653\n",
      "time/logging (s)                        0.012595\n",
      "time/preback_alpha (s)                  0.541784\n",
      "time/preback_policy (s)                 0.601961\n",
      "time/preback_start (s)                  0.121732\n",
      "time/preback_zf (s)                     4.92517\n",
      "time/saving (s)                         0.00598773\n",
      "time/training (s)                       2.60752\n",
      "time/epoch (s)                         15.8836\n",
      "time/total (s)                       2715.93\n",
      "Epoch                                 174\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:46:46.133106 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 175 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 186000\n",
      "trainer/ZF1 Loss                      138.428\n",
      "trainer/ZF2 Loss                      129.196\n",
      "trainer/ZF Expert Reward               24.5883\n",
      "trainer/ZF Policy Reward                9.51054\n",
      "trainer/ZF CHI2 Term                  162.482\n",
      "trainer/Policy Loss                  -933.572\n",
      "trainer/Policy Grad Norm             1258.95\n",
      "trainer/Policy Param Norm              40.853\n",
      "trainer/Zf1 Grad Norm               45709.4\n",
      "trainer/Zf1 Param Norm                113.52\n",
      "trainer/Zf2 Grad Norm               72703.4\n",
      "trainer/Zf2 Param Norm                109.62\n",
      "trainer/Z Expert Predictions Mean    1281.99\n",
      "trainer/Z Expert Predictions Std      286.888\n",
      "trainer/Z Expert Predictions Max     1918.98\n",
      "trainer/Z Expert Predictions Min      569.335\n",
      "trainer/Z Policy Predictions Mean     931.493\n",
      "trainer/Z Policy Predictions Std      490.029\n",
      "trainer/Z Policy Predictions Max     1772.73\n",
      "trainer/Z Policy Predictions Min     -398.186\n",
      "trainer/Z Expert Targets Mean        1257.4\n",
      "trainer/Z Expert Targets Std          280.927\n",
      "trainer/Z Expert Targets Max         1877.58\n",
      "trainer/Z Expert Targets Min          568.834\n",
      "trainer/Z Policy Targets Mean         921.983\n",
      "trainer/Z Policy Targets Std          482.757\n",
      "trainer/Z Policy Targets Max         1721.5\n",
      "trainer/Z Policy Targets Min         -404.503\n",
      "trainer/Log Pis Mean                   13.7297\n",
      "trainer/Log Pis Std                     4.98184\n",
      "trainer/Policy mu Mean                  0.390873\n",
      "trainer/Policy mu Std                   2.75342\n",
      "trainer/Policy log std Mean            -4.04185\n",
      "trainer/Policy log std Std              1.24232\n",
      "exploration/num steps total        182585\n",
      "exploration/num paths total          1020\n",
      "evaluation/num steps total              1.22525e+06\n",
      "evaluation/num paths total           1792\n",
      "evaluation/path length Mean           782.167\n",
      "evaluation/path length Std            254.357\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            429\n",
      "evaluation/Rewards Mean                 3.45239\n",
      "evaluation/Rewards Std                  0.63716\n",
      "evaluation/Rewards Max                  5.62994\n",
      "evaluation/Rewards Min                  0.597529\n",
      "evaluation/Returns Mean              2700.35\n",
      "evaluation/Returns Std                914.474\n",
      "evaluation/Returns Max               3518.33\n",
      "evaluation/Returns Min               1420.1\n",
      "evaluation/Estimation Bias Mean      1039.88\n",
      "evaluation/Estimation Bias Std        354.98\n",
      "evaluation/EB/Q_True Mean              34.3652\n",
      "evaluation/EB/Q_True Std              102.167\n",
      "evaluation/EB/Q_Pred Mean            1074.24\n",
      "evaluation/EB/Q_Pred Std              331.752\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2700.35\n",
      "evaluation/Actions Mean                 0.0500803\n",
      "evaluation/Actions Std                  0.602592\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83802\n",
      "time/backward_zf1 (s)                   1.93809\n",
      "time/backward_zf2 (s)                   1.89168\n",
      "time/data sampling (s)                  0.247223\n",
      "time/data storing (s)                   0.0139492\n",
      "time/evaluation sampling (s)            1.3914\n",
      "time/exploration sampling (s)           0.170773\n",
      "time/logging (s)                        0.0109095\n",
      "time/preback_alpha (s)                  0.547894\n",
      "time/preback_policy (s)                 0.626384\n",
      "time/preback_start (s)                  0.121304\n",
      "time/preback_zf (s)                     4.96668\n",
      "time/saving (s)                         0.00534008\n",
      "time/training (s)                       2.29543\n",
      "time/epoch (s)                         16.0651\n",
      "time/total (s)                       2732.02\n",
      "Epoch                                 175\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:47:02.274848 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 176 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 187000\n",
      "trainer/ZF1 Loss                       67.808\n",
      "trainer/ZF2 Loss                       51.5508\n",
      "trainer/ZF Expert Reward                2.95551\n",
      "trainer/ZF Policy Reward              -10.0185\n",
      "trainer/ZF CHI2 Term                   86.7906\n",
      "trainer/Policy Loss                  -914.703\n",
      "trainer/Policy Grad Norm              796.969\n",
      "trainer/Policy Param Norm              40.9296\n",
      "trainer/Zf1 Grad Norm               34188.6\n",
      "trainer/Zf1 Param Norm                113.772\n",
      "trainer/Zf2 Grad Norm               20726.1\n",
      "trainer/Zf2 Param Norm                109.868\n",
      "trainer/Z Expert Predictions Mean    1337.53\n",
      "trainer/Z Expert Predictions Std      261.268\n",
      "trainer/Z Expert Predictions Max     1875.55\n",
      "trainer/Z Expert Predictions Min      557.618\n",
      "trainer/Z Policy Predictions Mean     900.185\n",
      "trainer/Z Policy Predictions Std      472.584\n",
      "trainer/Z Policy Predictions Max     1690.22\n",
      "trainer/Z Policy Predictions Min     -376.602\n",
      "trainer/Z Expert Targets Mean        1334.57\n",
      "trainer/Z Expert Targets Std          259.276\n",
      "trainer/Z Expert Targets Max         1856\n",
      "trainer/Z Expert Targets Min          561.23\n",
      "trainer/Z Policy Targets Mean         910.204\n",
      "trainer/Z Policy Targets Std          473.562\n",
      "trainer/Z Policy Targets Max         1690.08\n",
      "trainer/Z Policy Targets Min         -374.694\n",
      "trainer/Log Pis Mean                   14.28\n",
      "trainer/Log Pis Std                     5.3566\n",
      "trainer/Policy mu Mean                  0.4032\n",
      "trainer/Policy mu Std                   2.90284\n",
      "trainer/Policy log std Mean            -3.95218\n",
      "trainer/Policy log std Std              1.24958\n",
      "exploration/num steps total        182585\n",
      "exploration/num paths total          1020\n",
      "evaluation/num steps total              1.23364e+06\n",
      "evaluation/num paths total           1803\n",
      "evaluation/path length Mean           762.455\n",
      "evaluation/path length Std            211.57\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            467\n",
      "evaluation/Rewards Mean                 3.45575\n",
      "evaluation/Rewards Std                  0.631328\n",
      "evaluation/Rewards Max                  5.60013\n",
      "evaluation/Rewards Min                  0.604714\n",
      "evaluation/Returns Mean              2634.85\n",
      "evaluation/Returns Std                761.651\n",
      "evaluation/Returns Max               3503.7\n",
      "evaluation/Returns Min               1571.03\n",
      "evaluation/Estimation Bias Mean      1030.57\n",
      "evaluation/Estimation Bias Std        380.869\n",
      "evaluation/EB/Q_True Mean              38.074\n",
      "evaluation/EB/Q_True Std              106.361\n",
      "evaluation/EB/Q_Pred Mean            1068.65\n",
      "evaluation/EB/Q_Pred Std              359.368\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2634.85\n",
      "evaluation/Actions Mean                 0.0346412\n",
      "evaluation/Actions Std                  0.595518\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79813\n",
      "time/backward_zf1 (s)                   1.90204\n",
      "time/backward_zf2 (s)                   1.84607\n",
      "time/data sampling (s)                  0.2522\n",
      "time/data storing (s)                   0.0141821\n",
      "time/evaluation sampling (s)            1.40218\n",
      "time/exploration sampling (s)           0.168952\n",
      "time/logging (s)                        0.0100653\n",
      "time/preback_alpha (s)                  0.552781\n",
      "time/preback_policy (s)                 0.623376\n",
      "time/preback_start (s)                  0.122762\n",
      "time/preback_zf (s)                     4.95908\n",
      "time/saving (s)                         0.00471734\n",
      "time/training (s)                       2.42133\n",
      "time/epoch (s)                         16.0779\n",
      "time/total (s)                       2748.11\n",
      "Epoch                                 176\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:47:18.409141 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 177 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 188000\n",
      "trainer/ZF1 Loss                      121.292\n",
      "trainer/ZF2 Loss                      130.454\n",
      "trainer/ZF Expert Reward                3.69553\n",
      "trainer/ZF Policy Reward               -5.01489\n",
      "trainer/ZF CHI2 Term                  147.799\n",
      "trainer/Policy Loss                  -922.202\n",
      "trainer/Policy Grad Norm              752.753\n",
      "trainer/Policy Param Norm              41.0001\n",
      "trainer/Zf1 Grad Norm               50278.8\n",
      "trainer/Zf1 Param Norm                114.027\n",
      "trainer/Zf2 Grad Norm               79825.4\n",
      "trainer/Zf2 Param Norm                110.113\n",
      "trainer/Z Expert Predictions Mean    1296.84\n",
      "trainer/Z Expert Predictions Std      265.371\n",
      "trainer/Z Expert Predictions Max     1809.11\n",
      "trainer/Z Expert Predictions Min      553.358\n",
      "trainer/Z Policy Predictions Mean     914.99\n",
      "trainer/Z Policy Predictions Std      473.375\n",
      "trainer/Z Policy Predictions Max     1816.32\n",
      "trainer/Z Policy Predictions Min     -398.128\n",
      "trainer/Z Expert Targets Mean        1293.14\n",
      "trainer/Z Expert Targets Std          261.961\n",
      "trainer/Z Expert Targets Max         1814.32\n",
      "trainer/Z Expert Targets Min          551.936\n",
      "trainer/Z Policy Targets Mean         920.004\n",
      "trainer/Z Policy Targets Std          473.354\n",
      "trainer/Z Policy Targets Max         1899.19\n",
      "trainer/Z Policy Targets Min         -373.824\n",
      "trainer/Log Pis Mean                   13.3494\n",
      "trainer/Log Pis Std                     4.71634\n",
      "trainer/Policy mu Mean                  0.316906\n",
      "trainer/Policy mu Std                   2.28908\n",
      "trainer/Policy log std Mean            -4.06074\n",
      "trainer/Policy log std Std              1.14862\n",
      "exploration/num steps total        183153\n",
      "exploration/num paths total          1021\n",
      "evaluation/num steps total              1.24364e+06\n",
      "evaluation/num paths total           1813\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52404\n",
      "evaluation/Rewards Std                  0.595979\n",
      "evaluation/Rewards Max                  4.72778\n",
      "evaluation/Rewards Min                  0.621427\n",
      "evaluation/Returns Mean              3524.04\n",
      "evaluation/Returns Std                 14.0801\n",
      "evaluation/Returns Max               3552.48\n",
      "evaluation/Returns Min               3502.41\n",
      "evaluation/Estimation Bias Mean      1240.34\n",
      "evaluation/Estimation Bias Std        277.223\n",
      "evaluation/EB/Q_True Mean              32.4157\n",
      "evaluation/EB/Q_True Std               99.8918\n",
      "evaluation/EB/Q_Pred Mean            1272.76\n",
      "evaluation/EB/Q_Pred Std              260.695\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3524.04\n",
      "evaluation/Actions Mean                 0.0501903\n",
      "evaluation/Actions Std                  0.5997\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76469\n",
      "time/backward_zf1 (s)                   1.87813\n",
      "time/backward_zf2 (s)                   1.81669\n",
      "time/data sampling (s)                  0.247355\n",
      "time/data storing (s)                   0.0139018\n",
      "time/evaluation sampling (s)            1.44659\n",
      "time/exploration sampling (s)           0.169933\n",
      "time/logging (s)                        0.012724\n",
      "time/preback_alpha (s)                  0.552113\n",
      "time/preback_policy (s)                 0.621012\n",
      "time/preback_start (s)                  0.122668\n",
      "time/preback_zf (s)                     4.96106\n",
      "time/saving (s)                         0.00555341\n",
      "time/training (s)                       2.46173\n",
      "time/epoch (s)                         16.0741\n",
      "time/total (s)                       2764.2\n",
      "Epoch                                 177\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:47:34.551003 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 178 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 189000\n",
      "trainer/ZF1 Loss                      264.846\n",
      "trainer/ZF2 Loss                      240.504\n",
      "trainer/ZF Expert Reward               23.8022\n",
      "trainer/ZF Policy Reward                6.57529\n",
      "trainer/ZF CHI2 Term                  282.943\n",
      "trainer/Policy Loss                  -890.407\n",
      "trainer/Policy Grad Norm              584.726\n",
      "trainer/Policy Param Norm              41.0696\n",
      "trainer/Zf1 Grad Norm              106553\n",
      "trainer/Zf1 Param Norm                114.306\n",
      "trainer/Zf2 Grad Norm               84259.6\n",
      "trainer/Zf2 Param Norm                110.369\n",
      "trainer/Z Expert Predictions Mean    1316.11\n",
      "trainer/Z Expert Predictions Std      296.049\n",
      "trainer/Z Expert Predictions Max     1931.93\n",
      "trainer/Z Expert Predictions Min      546.855\n",
      "trainer/Z Policy Predictions Mean     894.215\n",
      "trainer/Z Policy Predictions Std      470.427\n",
      "trainer/Z Policy Predictions Max     1753.44\n",
      "trainer/Z Policy Predictions Min     -472.908\n",
      "trainer/Z Expert Targets Mean        1292.31\n",
      "trainer/Z Expert Targets Std          303.348\n",
      "trainer/Z Expert Targets Max         1937.13\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         887.639\n",
      "trainer/Z Policy Targets Std          467.21\n",
      "trainer/Z Policy Targets Max         1734.87\n",
      "trainer/Z Policy Targets Min         -464.83\n",
      "trainer/Log Pis Mean                   13.1725\n",
      "trainer/Log Pis Std                     4.70512\n",
      "trainer/Policy mu Mean                  0.465516\n",
      "trainer/Policy mu Std                   2.51942\n",
      "trainer/Policy log std Mean            -3.89612\n",
      "trainer/Policy log std Std              1.10551\n",
      "exploration/num steps total        184594\n",
      "exploration/num paths total          1023\n",
      "evaluation/num steps total              1.25174e+06\n",
      "evaluation/num paths total           1826\n",
      "evaluation/path length Mean           623.385\n",
      "evaluation/path length Std            308.198\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            331\n",
      "evaluation/Rewards Mean                 3.46218\n",
      "evaluation/Rewards Std                  0.675719\n",
      "evaluation/Rewards Max                  4.77177\n",
      "evaluation/Rewards Min                  0.62475\n",
      "evaluation/Returns Mean              2158.27\n",
      "evaluation/Returns Std               1116.38\n",
      "evaluation/Returns Max               3557\n",
      "evaluation/Returns Min               1096.4\n",
      "evaluation/Estimation Bias Mean      1131.75\n",
      "evaluation/Estimation Bias Std        408.909\n",
      "evaluation/EB/Q_True Mean              40.1434\n",
      "evaluation/EB/Q_True Std              109.909\n",
      "evaluation/EB/Q_Pred Mean            1171.9\n",
      "evaluation/EB/Q_Pred Std              382.207\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2158.27\n",
      "evaluation/Actions Mean                 0.0521245\n",
      "evaluation/Actions Std                  0.597838\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79325\n",
      "time/backward_zf1 (s)                   1.90048\n",
      "time/backward_zf2 (s)                   1.84332\n",
      "time/data sampling (s)                  0.243961\n",
      "time/data storing (s)                   0.0135717\n",
      "time/evaluation sampling (s)            1.41627\n",
      "time/exploration sampling (s)           0.168466\n",
      "time/logging (s)                        0.00961506\n",
      "time/preback_alpha (s)                  0.54852\n",
      "time/preback_policy (s)                 0.619964\n",
      "time/preback_start (s)                  0.123156\n",
      "time/preback_zf (s)                     4.96806\n",
      "time/saving (s)                         0.00509398\n",
      "time/training (s)                       2.42289\n",
      "time/epoch (s)                         16.0766\n",
      "time/total (s)                       2780.3\n",
      "Epoch                                 178\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:47:49.724098 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 179 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 190000\n",
      "trainer/ZF1 Loss                       72.2957\n",
      "trainer/ZF2 Loss                       71.1074\n",
      "trainer/ZF Expert Reward                5.92581\n",
      "trainer/ZF Policy Reward               -8.09664\n",
      "trainer/ZF CHI2 Term                   99.468\n",
      "trainer/Policy Loss                  -914.441\n",
      "trainer/Policy Grad Norm             1092.33\n",
      "trainer/Policy Param Norm              41.1511\n",
      "trainer/Zf1 Grad Norm               52872.6\n",
      "trainer/Zf1 Param Norm                114.56\n",
      "trainer/Zf2 Grad Norm               29464.5\n",
      "trainer/Zf2 Param Norm                110.618\n",
      "trainer/Z Expert Predictions Mean    1291.16\n",
      "trainer/Z Expert Predictions Std      297.821\n",
      "trainer/Z Expert Predictions Max     1886.25\n",
      "trainer/Z Expert Predictions Min      462.328\n",
      "trainer/Z Policy Predictions Mean     903.05\n",
      "trainer/Z Policy Predictions Std      513.249\n",
      "trainer/Z Policy Predictions Max     1767.23\n",
      "trainer/Z Policy Predictions Min     -399.805\n",
      "trainer/Z Expert Targets Mean        1285.23\n",
      "trainer/Z Expert Targets Std          299.34\n",
      "trainer/Z Expert Targets Max         1876.05\n",
      "trainer/Z Expert Targets Min          446.214\n",
      "trainer/Z Policy Targets Mean         911.147\n",
      "trainer/Z Policy Targets Std          513.777\n",
      "trainer/Z Policy Targets Max         1782.62\n",
      "trainer/Z Policy Targets Min         -400.488\n",
      "trainer/Log Pis Mean                   13.8829\n",
      "trainer/Log Pis Std                     4.97064\n",
      "trainer/Policy mu Mean                  0.394086\n",
      "trainer/Policy mu Std                   2.50214\n",
      "trainer/Policy log std Mean            -4.01631\n",
      "trainer/Policy log std Std              1.16595\n",
      "exploration/num steps total        185594\n",
      "exploration/num paths total          1024\n",
      "evaluation/num steps total              1.25501e+06\n",
      "evaluation/num paths total           1836\n",
      "evaluation/path length Mean           327.1\n",
      "evaluation/path length Std              4.36921\n",
      "evaluation/path length Max            331\n",
      "evaluation/path length Min            320\n",
      "evaluation/Rewards Mean                 3.33775\n",
      "evaluation/Rewards Std                  0.849575\n",
      "evaluation/Rewards Max                  4.92369\n",
      "evaluation/Rewards Min                  0.617546\n",
      "evaluation/Returns Mean              1091.78\n",
      "evaluation/Returns Std                 12.8752\n",
      "evaluation/Returns Max               1102.97\n",
      "evaluation/Returns Min               1068.94\n",
      "evaluation/Estimation Bias Mean       765.437\n",
      "evaluation/Estimation Bias Std        566.595\n",
      "evaluation/EB/Q_True Mean              25.9694\n",
      "evaluation/EB/Q_True Std               81.9131\n",
      "evaluation/EB/Q_Pred Mean             791.406\n",
      "evaluation/EB/Q_Pred Std              566.053\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1091.78\n",
      "evaluation/Actions Mean                 0.0394369\n",
      "evaluation/Actions Std                  0.615647\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8011\n",
      "time/backward_zf1 (s)                   1.90208\n",
      "time/backward_zf2 (s)                   1.8467\n",
      "time/data sampling (s)                  0.249035\n",
      "time/data storing (s)                   0.0136115\n",
      "time/evaluation sampling (s)            0.502007\n",
      "time/exploration sampling (s)           0.169746\n",
      "time/logging (s)                        0.00474349\n",
      "time/preback_alpha (s)                  0.548038\n",
      "time/preback_policy (s)                 0.622898\n",
      "time/preback_start (s)                  0.123388\n",
      "time/preback_zf (s)                     4.94778\n",
      "time/saving (s)                         0.00508778\n",
      "time/training (s)                       2.37005\n",
      "time/epoch (s)                         15.1063\n",
      "time/total (s)                       2795.42\n",
      "Epoch                                 179\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:48:05.827817 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 180 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 191000\n",
      "trainer/ZF1 Loss                      135\n",
      "trainer/ZF2 Loss                      281.352\n",
      "trainer/ZF Expert Reward                5.53004\n",
      "trainer/ZF Policy Reward                3.10562\n",
      "trainer/ZF CHI2 Term                  224.86\n",
      "trainer/Policy Loss                  -938.471\n",
      "trainer/Policy Grad Norm              684.043\n",
      "trainer/Policy Param Norm              41.2303\n",
      "trainer/Zf1 Grad Norm              150650\n",
      "trainer/Zf1 Param Norm                114.817\n",
      "trainer/Zf2 Grad Norm              146509\n",
      "trainer/Zf2 Param Norm                110.87\n",
      "trainer/Z Expert Predictions Mean    1285.82\n",
      "trainer/Z Expert Predictions Std      294.474\n",
      "trainer/Z Expert Predictions Max     1925.47\n",
      "trainer/Z Expert Predictions Min      571.834\n",
      "trainer/Z Policy Predictions Mean     931.373\n",
      "trainer/Z Policy Predictions Std      507.56\n",
      "trainer/Z Policy Predictions Max     1779.25\n",
      "trainer/Z Policy Predictions Min     -484.73\n",
      "trainer/Z Expert Targets Mean        1280.29\n",
      "trainer/Z Expert Targets Std          297.776\n",
      "trainer/Z Expert Targets Max         1914.07\n",
      "trainer/Z Expert Targets Min          554.808\n",
      "trainer/Z Policy Targets Mean         928.267\n",
      "trainer/Z Policy Targets Std          503.852\n",
      "trainer/Z Policy Targets Max         1813.48\n",
      "trainer/Z Policy Targets Min         -514.261\n",
      "trainer/Log Pis Mean                   14.4043\n",
      "trainer/Log Pis Std                     5.33841\n",
      "trainer/Policy mu Mean                  0.420883\n",
      "trainer/Policy mu Std                   2.7398\n",
      "trainer/Policy log std Mean            -4.07426\n",
      "trainer/Policy log std Std              1.20486\n",
      "exploration/num steps total        187053\n",
      "exploration/num paths total          1026\n",
      "evaluation/num steps total              1.26402e+06\n",
      "evaluation/num paths total           1846\n",
      "evaluation/path length Mean           900.6\n",
      "evaluation/path length Std            175.449\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            485\n",
      "evaluation/Rewards Mean                 3.51303\n",
      "evaluation/Rewards Std                  0.620098\n",
      "evaluation/Rewards Max                  4.87618\n",
      "evaluation/Rewards Min                  0.592462\n",
      "evaluation/Returns Mean              3163.83\n",
      "evaluation/Returns Std                624.316\n",
      "evaluation/Returns Max               3545.38\n",
      "evaluation/Returns Min               1673.07\n",
      "evaluation/Estimation Bias Mean      1159.59\n",
      "evaluation/Estimation Bias Std        354.496\n",
      "evaluation/EB/Q_True Mean              35.9697\n",
      "evaluation/EB/Q_True Std              104.696\n",
      "evaluation/EB/Q_Pred Mean            1195.56\n",
      "evaluation/EB/Q_Pred Std              329.693\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3163.83\n",
      "evaluation/Actions Mean                 0.0612897\n",
      "evaluation/Actions Std                  0.605487\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79303\n",
      "time/backward_zf1 (s)                   1.90277\n",
      "time/backward_zf2 (s)                   1.84832\n",
      "time/data sampling (s)                  0.247996\n",
      "time/data storing (s)                   0.0137357\n",
      "time/evaluation sampling (s)            1.39358\n",
      "time/exploration sampling (s)           0.171699\n",
      "time/logging (s)                        0.0110143\n",
      "time/preback_alpha (s)                  0.549188\n",
      "time/preback_policy (s)                 0.618508\n",
      "time/preback_start (s)                  0.123056\n",
      "time/preback_zf (s)                     4.95858\n",
      "time/saving (s)                         0.00536687\n",
      "time/training (s)                       2.41118\n",
      "time/epoch (s)                         16.048\n",
      "time/total (s)                       2811.49\n",
      "Epoch                                 180\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:48:21.887299 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 181 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 192000\n",
      "trainer/ZF1 Loss                       87.8672\n",
      "trainer/ZF2 Loss                       67.4714\n",
      "trainer/ZF Expert Reward               15.1301\n",
      "trainer/ZF Policy Reward                2.47744\n",
      "trainer/ZF CHI2 Term                  104.495\n",
      "trainer/Policy Loss                  -874.23\n",
      "trainer/Policy Grad Norm              674.503\n",
      "trainer/Policy Param Norm              41.2964\n",
      "trainer/Zf1 Grad Norm               51923.8\n",
      "trainer/Zf1 Param Norm                115.065\n",
      "trainer/Zf2 Grad Norm               30360.2\n",
      "trainer/Zf2 Param Norm                111.115\n",
      "trainer/Z Expert Predictions Mean    1276\n",
      "trainer/Z Expert Predictions Std      295.891\n",
      "trainer/Z Expert Predictions Max     1925.09\n",
      "trainer/Z Expert Predictions Min      523.358\n",
      "trainer/Z Policy Predictions Mean     870.594\n",
      "trainer/Z Policy Predictions Std      533.682\n",
      "trainer/Z Policy Predictions Max     1862.41\n",
      "trainer/Z Policy Predictions Min     -521.226\n",
      "trainer/Z Expert Targets Mean        1260.87\n",
      "trainer/Z Expert Targets Std          295.632\n",
      "trainer/Z Expert Targets Max         1909.5\n",
      "trainer/Z Expert Targets Min          478.413\n",
      "trainer/Z Policy Targets Mean         868.116\n",
      "trainer/Z Policy Targets Std          524.215\n",
      "trainer/Z Policy Targets Max         1822.58\n",
      "trainer/Z Policy Targets Min         -524.954\n",
      "trainer/Log Pis Mean                   14.3159\n",
      "trainer/Log Pis Std                     5.15438\n",
      "trainer/Policy mu Mean                  0.344999\n",
      "trainer/Policy mu Std                   2.69062\n",
      "trainer/Policy log std Mean            -4.07816\n",
      "trainer/Policy log std Std              1.23793\n",
      "exploration/num steps total        188384\n",
      "exploration/num paths total          1028\n",
      "evaluation/num steps total              1.27341e+06\n",
      "evaluation/num paths total           1856\n",
      "evaluation/path length Mean           939.5\n",
      "evaluation/path length Std            181.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            395\n",
      "evaluation/Rewards Mean                 3.53237\n",
      "evaluation/Rewards Std                  0.614326\n",
      "evaluation/Rewards Max                  4.84041\n",
      "evaluation/Rewards Min                  0.585632\n",
      "evaluation/Returns Mean              3318.66\n",
      "evaluation/Returns Std                653.649\n",
      "evaluation/Returns Max               3567.21\n",
      "evaluation/Returns Min               1358.75\n",
      "evaluation/Estimation Bias Mean      1190.2\n",
      "evaluation/Estimation Bias Std        358.44\n",
      "evaluation/EB/Q_True Mean              34.6457\n",
      "evaluation/EB/Q_True Std              103.316\n",
      "evaluation/EB/Q_Pred Mean            1224.85\n",
      "evaluation/EB/Q_Pred Std              327.156\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3318.66\n",
      "evaluation/Actions Mean                 0.0497847\n",
      "evaluation/Actions Std                  0.601718\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86221\n",
      "time/backward_zf1 (s)                   1.94926\n",
      "time/backward_zf2 (s)                   1.90823\n",
      "time/data sampling (s)                  0.247785\n",
      "time/data storing (s)                   0.0134068\n",
      "time/evaluation sampling (s)            1.37572\n",
      "time/exploration sampling (s)           0.166956\n",
      "time/logging (s)                        0.0112059\n",
      "time/preback_alpha (s)                  0.547551\n",
      "time/preback_policy (s)                 0.632532\n",
      "time/preback_start (s)                  0.122013\n",
      "time/preback_zf (s)                     4.93689\n",
      "time/saving (s)                         0.00501062\n",
      "time/training (s)                       2.21795\n",
      "time/epoch (s)                         15.9967\n",
      "time/total (s)                       2827.5\n",
      "Epoch                                 181\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:48:37.044842 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 182 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 193000\n",
      "trainer/ZF1 Loss                       56.7661\n",
      "trainer/ZF2 Loss                       52.0685\n",
      "trainer/ZF Expert Reward               13.6454\n",
      "trainer/ZF Policy Reward               -0.898626\n",
      "trainer/ZF CHI2 Term                   82.991\n",
      "trainer/Policy Loss                  -944.179\n",
      "trainer/Policy Grad Norm              796.308\n",
      "trainer/Policy Param Norm              41.3571\n",
      "trainer/Zf1 Grad Norm               48768.9\n",
      "trainer/Zf1 Param Norm                115.299\n",
      "trainer/Zf2 Grad Norm               36600.7\n",
      "trainer/Zf2 Param Norm                111.338\n",
      "trainer/Z Expert Predictions Mean    1293.32\n",
      "trainer/Z Expert Predictions Std      281.728\n",
      "trainer/Z Expert Predictions Max     1922.95\n",
      "trainer/Z Expert Predictions Min      530.661\n",
      "trainer/Z Policy Predictions Mean     933.2\n",
      "trainer/Z Policy Predictions Std      478.671\n",
      "trainer/Z Policy Predictions Max     1695.81\n",
      "trainer/Z Policy Predictions Min     -362.076\n",
      "trainer/Z Expert Targets Mean        1279.67\n",
      "trainer/Z Expert Targets Std          279.171\n",
      "trainer/Z Expert Targets Max         1882.72\n",
      "trainer/Z Expert Targets Min          509.441\n",
      "trainer/Z Policy Targets Mean         934.099\n",
      "trainer/Z Policy Targets Std          474.803\n",
      "trainer/Z Policy Targets Max         1748.54\n",
      "trainer/Z Policy Targets Min         -357.981\n",
      "trainer/Log Pis Mean                   14.1715\n",
      "trainer/Log Pis Std                     5.31535\n",
      "trainer/Policy mu Mean                  0.412242\n",
      "trainer/Policy mu Std                   2.86657\n",
      "trainer/Policy log std Mean            -4.09965\n",
      "trainer/Policy log std Std              1.25813\n",
      "exploration/num steps total        188790\n",
      "exploration/num paths total          1029\n",
      "evaluation/num steps total              1.27672e+06\n",
      "evaluation/num paths total           1866\n",
      "evaluation/path length Mean           330.4\n",
      "evaluation/path length Std              1.49666\n",
      "evaluation/path length Max            332\n",
      "evaluation/path length Min            327\n",
      "evaluation/Rewards Mean                 3.33619\n",
      "evaluation/Rewards Std                  0.837886\n",
      "evaluation/Rewards Max                  4.66177\n",
      "evaluation/Rewards Min                  0.571953\n",
      "evaluation/Returns Mean              1102.28\n",
      "evaluation/Returns Std                  2.29483\n",
      "evaluation/Returns Max               1105.13\n",
      "evaluation/Returns Min               1096.96\n",
      "evaluation/Estimation Bias Mean       826.337\n",
      "evaluation/Estimation Bias Std        555.339\n",
      "evaluation/EB/Q_True Mean              25.7033\n",
      "evaluation/EB/Q_True Std               81.45\n",
      "evaluation/EB/Q_Pred Mean             852.04\n",
      "evaluation/EB/Q_Pred Std              552.217\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1102.28\n",
      "evaluation/Actions Mean                 0.0444984\n",
      "evaluation/Actions Std                  0.62141\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7022\n",
      "time/backward_zf1 (s)                   1.82429\n",
      "time/backward_zf2 (s)                   1.74923\n",
      "time/data sampling (s)                  0.255708\n",
      "time/data storing (s)                   0.0137561\n",
      "time/evaluation sampling (s)            0.495611\n",
      "time/exploration sampling (s)           0.168915\n",
      "time/logging (s)                        0.00466559\n",
      "time/preback_alpha (s)                  0.549705\n",
      "time/preback_policy (s)                 0.603111\n",
      "time/preback_start (s)                  0.123364\n",
      "time/preback_zf (s)                     4.95768\n",
      "time/saving (s)                         0.00483667\n",
      "time/training (s)                       2.6355\n",
      "time/epoch (s)                         15.0886\n",
      "time/total (s)                       2842.61\n",
      "Epoch                                 182\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:48:52.961141 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 183 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 194000\n",
      "trainer/ZF1 Loss                      463.397\n",
      "trainer/ZF2 Loss                      475.021\n",
      "trainer/ZF Expert Reward               12.3569\n",
      "trainer/ZF Policy Reward                5.69262\n",
      "trainer/ZF CHI2 Term                  490.146\n",
      "trainer/Policy Loss                  -910.553\n",
      "trainer/Policy Grad Norm              697.955\n",
      "trainer/Policy Param Norm              41.4185\n",
      "trainer/Zf1 Grad Norm               35430.8\n",
      "trainer/Zf1 Param Norm                115.523\n",
      "trainer/Zf2 Grad Norm               42358.9\n",
      "trainer/Zf2 Param Norm                111.557\n",
      "trainer/Z Expert Predictions Mean    1284.33\n",
      "trainer/Z Expert Predictions Std      283.971\n",
      "trainer/Z Expert Predictions Max     1918.16\n",
      "trainer/Z Expert Predictions Min      548.528\n",
      "trainer/Z Policy Predictions Mean     905.406\n",
      "trainer/Z Policy Predictions Std      489.14\n",
      "trainer/Z Policy Predictions Max     1665.92\n",
      "trainer/Z Policy Predictions Min     -434.809\n",
      "trainer/Z Expert Targets Mean        1271.97\n",
      "trainer/Z Expert Targets Std          282.296\n",
      "trainer/Z Expert Targets Max         1905.2\n",
      "trainer/Z Expert Targets Min          551.308\n",
      "trainer/Z Policy Targets Mean         899.714\n",
      "trainer/Z Policy Targets Std          488.4\n",
      "trainer/Z Policy Targets Max         1658.78\n",
      "trainer/Z Policy Targets Min         -407.997\n",
      "trainer/Log Pis Mean                   14.4174\n",
      "trainer/Log Pis Std                     5.37608\n",
      "trainer/Policy mu Mean                  0.265492\n",
      "trainer/Policy mu Std                   2.95375\n",
      "trainer/Policy log std Mean            -4.0375\n",
      "trainer/Policy log std Std              1.19682\n",
      "exploration/num steps total        190169\n",
      "exploration/num paths total          1031\n",
      "evaluation/num steps total              1.28597e+06\n",
      "evaluation/num paths total           1877\n",
      "evaluation/path length Mean           841.636\n",
      "evaluation/path length Std            258.823\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            405\n",
      "evaluation/Rewards Mean                 3.52914\n",
      "evaluation/Rewards Std                  0.631174\n",
      "evaluation/Rewards Max                  4.79729\n",
      "evaluation/Rewards Min                  0.619465\n",
      "evaluation/Returns Mean              2970.25\n",
      "evaluation/Returns Std                932.636\n",
      "evaluation/Returns Max               3574.45\n",
      "evaluation/Returns Min               1393.61\n",
      "evaluation/Estimation Bias Mean      1155.49\n",
      "evaluation/Estimation Bias Std        431.15\n",
      "evaluation/EB/Q_True Mean              35.105\n",
      "evaluation/EB/Q_True Std              103.985\n",
      "evaluation/EB/Q_Pred Mean            1190.59\n",
      "evaluation/EB/Q_Pred Std              385.761\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2970.25\n",
      "evaluation/Actions Mean                 0.0460111\n",
      "evaluation/Actions Std                  0.602652\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.69818\n",
      "time/backward_zf1 (s)                   1.80556\n",
      "time/backward_zf2 (s)                   1.74487\n",
      "time/data sampling (s)                  0.247214\n",
      "time/data storing (s)                   0.0139764\n",
      "time/evaluation sampling (s)            1.32423\n",
      "time/exploration sampling (s)           0.170478\n",
      "time/logging (s)                        0.0109316\n",
      "time/preback_alpha (s)                  0.546027\n",
      "time/preback_policy (s)                 0.602623\n",
      "time/preback_start (s)                  0.123529\n",
      "time/preback_zf (s)                     4.94276\n",
      "time/saving (s)                         0.00560104\n",
      "time/training (s)                       2.6215\n",
      "time/epoch (s)                         15.8575\n",
      "time/total (s)                       2858.49\n",
      "Epoch                                 183\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:49:08.076479 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 184 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 195000\n",
      "trainer/ZF1 Loss                      128.552\n",
      "trainer/ZF2 Loss                      177.804\n",
      "trainer/ZF Expert Reward               19.1147\n",
      "trainer/ZF Policy Reward               -2.04766\n",
      "trainer/ZF CHI2 Term                  188.204\n",
      "trainer/Policy Loss                  -866.8\n",
      "trainer/Policy Grad Norm              453.05\n",
      "trainer/Policy Param Norm              41.4847\n",
      "trainer/Zf1 Grad Norm               29987.8\n",
      "trainer/Zf1 Param Norm                115.754\n",
      "trainer/Zf2 Grad Norm               48799.3\n",
      "trainer/Zf2 Param Norm                111.758\n",
      "trainer/Z Expert Predictions Mean    1311.27\n",
      "trainer/Z Expert Predictions Std      260.618\n",
      "trainer/Z Expert Predictions Max     1817.78\n",
      "trainer/Z Expert Predictions Min      560.444\n",
      "trainer/Z Policy Predictions Mean     857.928\n",
      "trainer/Z Policy Predictions Std      514.865\n",
      "trainer/Z Policy Predictions Max     1635.07\n",
      "trainer/Z Policy Predictions Min     -432.361\n",
      "trainer/Z Expert Targets Mean        1292.16\n",
      "trainer/Z Expert Targets Std          266.477\n",
      "trainer/Z Expert Targets Max         1748.5\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         859.976\n",
      "trainer/Z Policy Targets Std          508.175\n",
      "trainer/Z Policy Targets Max         1615.92\n",
      "trainer/Z Policy Targets Min         -458.558\n",
      "trainer/Log Pis Mean                   14.0038\n",
      "trainer/Log Pis Std                     5.34549\n",
      "trainer/Policy mu Mean                  0.57401\n",
      "trainer/Policy mu Std                   2.5476\n",
      "trainer/Policy log std Mean            -4.02657\n",
      "trainer/Policy log std Std              1.23398\n",
      "exploration/num steps total        191925\n",
      "exploration/num paths total          1034\n",
      "evaluation/num steps total              1.28912e+06\n",
      "evaluation/num paths total           1887\n",
      "evaluation/path length Mean           314.9\n",
      "evaluation/path length Std             11.9369\n",
      "evaluation/path length Max            330\n",
      "evaluation/path length Min            296\n",
      "evaluation/Rewards Mean                 3.33683\n",
      "evaluation/Rewards Std                  0.874529\n",
      "evaluation/Rewards Max                  5.3762\n",
      "evaluation/Rewards Min                  0.604967\n",
      "evaluation/Returns Mean              1050.77\n",
      "evaluation/Returns Std                 49.1604\n",
      "evaluation/Returns Max               1109.74\n",
      "evaluation/Returns Min                973.812\n",
      "evaluation/Estimation Bias Mean       731.322\n",
      "evaluation/Estimation Bias Std        623.523\n",
      "evaluation/EB/Q_True Mean              26.9053\n",
      "evaluation/EB/Q_True Std               83.0826\n",
      "evaluation/EB/Q_Pred Mean             758.227\n",
      "evaluation/EB/Q_Pred Std              622.603\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1050.77\n",
      "evaluation/Actions Mean                 0.0461367\n",
      "evaluation/Actions Std                  0.63151\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74263\n",
      "time/backward_zf1 (s)                   1.84864\n",
      "time/backward_zf2 (s)                   1.77838\n",
      "time/data sampling (s)                  0.254442\n",
      "time/data storing (s)                   0.0136476\n",
      "time/evaluation sampling (s)            0.465929\n",
      "time/exploration sampling (s)           0.171357\n",
      "time/logging (s)                        0.00450476\n",
      "time/preback_alpha (s)                  0.55126\n",
      "time/preback_policy (s)                 0.610133\n",
      "time/preback_start (s)                  0.124243\n",
      "time/preback_zf (s)                     4.93868\n",
      "time/saving (s)                         0.00502061\n",
      "time/training (s)                       2.53795\n",
      "time/epoch (s)                         15.0468\n",
      "time/total (s)                       2873.55\n",
      "Epoch                                 184\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:49:24.109043 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 185 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 196000\n",
      "trainer/ZF1 Loss                       74.8965\n",
      "trainer/ZF2 Loss                       58.5636\n",
      "trainer/ZF Expert Reward                1.45108\n",
      "trainer/ZF Policy Reward               -9.65216\n",
      "trainer/ZF CHI2 Term                   92.4137\n",
      "trainer/Policy Loss                  -893.144\n",
      "trainer/Policy Grad Norm              672.98\n",
      "trainer/Policy Param Norm              41.5482\n",
      "trainer/Zf1 Grad Norm               55964.2\n",
      "trainer/Zf1 Param Norm                115.982\n",
      "trainer/Zf2 Grad Norm               38511.3\n",
      "trainer/Zf2 Param Norm                111.978\n",
      "trainer/Z Expert Predictions Mean    1281.46\n",
      "trainer/Z Expert Predictions Std      258.477\n",
      "trainer/Z Expert Predictions Max     1882.43\n",
      "trainer/Z Expert Predictions Min      548.974\n",
      "trainer/Z Policy Predictions Mean     883.419\n",
      "trainer/Z Policy Predictions Std      489.475\n",
      "trainer/Z Policy Predictions Max     1594.97\n",
      "trainer/Z Policy Predictions Min     -385.881\n",
      "trainer/Z Expert Targets Mean        1280\n",
      "trainer/Z Expert Targets Std          259.676\n",
      "trainer/Z Expert Targets Max         1855.39\n",
      "trainer/Z Expert Targets Min          523.402\n",
      "trainer/Z Policy Targets Mean         893.072\n",
      "trainer/Z Policy Targets Std          490.274\n",
      "trainer/Z Policy Targets Max         1616.11\n",
      "trainer/Z Policy Targets Min         -402.061\n",
      "trainer/Log Pis Mean                   14.7277\n",
      "trainer/Log Pis Std                     5.12076\n",
      "trainer/Policy mu Mean                  0.54075\n",
      "trainer/Policy mu Std                   2.68223\n",
      "trainer/Policy log std Mean            -4.10261\n",
      "trainer/Policy log std Std              1.12959\n",
      "exploration/num steps total        192925\n",
      "exploration/num paths total          1035\n",
      "evaluation/num steps total              1.29912e+06\n",
      "evaluation/num paths total           1897\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50597\n",
      "evaluation/Rewards Std                  0.600323\n",
      "evaluation/Rewards Max                  4.87666\n",
      "evaluation/Rewards Min                  0.584522\n",
      "evaluation/Returns Mean              3505.97\n",
      "evaluation/Returns Std                 18.8098\n",
      "evaluation/Returns Max               3553.03\n",
      "evaluation/Returns Min               3486.88\n",
      "evaluation/Estimation Bias Mean      1185.27\n",
      "evaluation/Estimation Bias Std        245.153\n",
      "evaluation/EB/Q_True Mean              32.2616\n",
      "evaluation/EB/Q_True Std               99.5584\n",
      "evaluation/EB/Q_Pred Mean            1217.53\n",
      "evaluation/EB/Q_Pred Std              234.264\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3505.97\n",
      "evaluation/Actions Mean                 0.0431283\n",
      "evaluation/Actions Std                  0.602478\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75024\n",
      "time/backward_zf1 (s)                   1.8686\n",
      "time/backward_zf2 (s)                   1.80097\n",
      "time/data sampling (s)                  0.249297\n",
      "time/data storing (s)                   0.0135549\n",
      "time/evaluation sampling (s)            1.3305\n",
      "time/exploration sampling (s)           0.168258\n",
      "time/logging (s)                        0.0118405\n",
      "time/preback_alpha (s)                  0.550291\n",
      "time/preback_policy (s)                 0.612472\n",
      "time/preback_start (s)                  0.123444\n",
      "time/preback_zf (s)                     4.96225\n",
      "time/saving (s)                         0.00535585\n",
      "time/training (s)                       2.53161\n",
      "time/epoch (s)                         15.9787\n",
      "time/total (s)                       2889.54\n",
      "Epoch                                 185\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:49:40.158149 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 186 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 197000\n",
      "trainer/ZF1 Loss                      110.177\n",
      "trainer/ZF2 Loss                      108.827\n",
      "trainer/ZF Expert Reward               11.9006\n",
      "trainer/ZF Policy Reward                2.62774\n",
      "trainer/ZF CHI2 Term                  132.742\n",
      "trainer/Policy Loss                  -861.941\n",
      "trainer/Policy Grad Norm              621.134\n",
      "trainer/Policy Param Norm              41.6052\n",
      "trainer/Zf1 Grad Norm               26022\n",
      "trainer/Zf1 Param Norm                116.233\n",
      "trainer/Zf2 Grad Norm               43469.7\n",
      "trainer/Zf2 Param Norm                112.209\n",
      "trainer/Z Expert Predictions Mean    1327.19\n",
      "trainer/Z Expert Predictions Std      254.467\n",
      "trainer/Z Expert Predictions Max     1854.67\n",
      "trainer/Z Expert Predictions Min      592.592\n",
      "trainer/Z Policy Predictions Mean     856.532\n",
      "trainer/Z Policy Predictions Std      513.963\n",
      "trainer/Z Policy Predictions Max     1643.89\n",
      "trainer/Z Policy Predictions Min     -485.55\n",
      "trainer/Z Expert Targets Mean        1315.28\n",
      "trainer/Z Expert Targets Std          253.468\n",
      "trainer/Z Expert Targets Max         1828.71\n",
      "trainer/Z Expert Targets Min          591.195\n",
      "trainer/Z Policy Targets Mean         853.904\n",
      "trainer/Z Policy Targets Std          509.73\n",
      "trainer/Z Policy Targets Max         1627.67\n",
      "trainer/Z Policy Targets Min         -488.669\n",
      "trainer/Log Pis Mean                   14.1085\n",
      "trainer/Log Pis Std                     5.16387\n",
      "trainer/Policy mu Mean                  0.442729\n",
      "trainer/Policy mu Std                   2.8867\n",
      "trainer/Policy log std Mean            -3.93065\n",
      "trainer/Policy log std Std              1.21442\n",
      "exploration/num steps total        192925\n",
      "exploration/num paths total          1035\n",
      "evaluation/num steps total              1.30912e+06\n",
      "evaluation/num paths total           1907\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.47125\n",
      "evaluation/Rewards Std                  0.605419\n",
      "evaluation/Rewards Max                  4.84128\n",
      "evaluation/Rewards Min                  0.604124\n",
      "evaluation/Returns Mean              3471.25\n",
      "evaluation/Returns Std                 12.1166\n",
      "evaluation/Returns Max               3493.36\n",
      "evaluation/Returns Min               3455.88\n",
      "evaluation/Estimation Bias Mean      1123.06\n",
      "evaluation/Estimation Bias Std        245.528\n",
      "evaluation/EB/Q_True Mean              32.294\n",
      "evaluation/EB/Q_True Std               99.4222\n",
      "evaluation/EB/Q_Pred Mean            1155.36\n",
      "evaluation/EB/Q_Pred Std              219.607\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3471.25\n",
      "evaluation/Actions Mean                 0.0564364\n",
      "evaluation/Actions Std                  0.605093\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.66057\n",
      "time/backward_zf1 (s)                   1.79996\n",
      "time/backward_zf2 (s)                   1.71288\n",
      "time/data sampling (s)                  0.24277\n",
      "time/data storing (s)                   0.0143015\n",
      "time/evaluation sampling (s)            1.34435\n",
      "time/exploration sampling (s)           0.169199\n",
      "time/logging (s)                        0.0113951\n",
      "time/preback_alpha (s)                  0.554935\n",
      "time/preback_policy (s)                 0.610411\n",
      "time/preback_start (s)                  0.124888\n",
      "time/preback_zf (s)                     4.99646\n",
      "time/saving (s)                         0.00542761\n",
      "time/training (s)                       2.73808\n",
      "time/epoch (s)                         15.9856\n",
      "time/total (s)                       2905.55\n",
      "Epoch                                 186\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:49:56.045384 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 187 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 198000\n",
      "trainer/ZF1 Loss                       80.6484\n",
      "trainer/ZF2 Loss                       75.7604\n",
      "trainer/ZF Expert Reward               13.9339\n",
      "trainer/ZF Policy Reward                5.49843\n",
      "trainer/ZF CHI2 Term                  100.1\n",
      "trainer/Policy Loss                  -892.288\n",
      "trainer/Policy Grad Norm              904.073\n",
      "trainer/Policy Param Norm              41.6639\n",
      "trainer/Zf1 Grad Norm               31676\n",
      "trainer/Zf1 Param Norm                116.464\n",
      "trainer/Zf2 Grad Norm               39279.5\n",
      "trainer/Zf2 Param Norm                112.435\n",
      "trainer/Z Expert Predictions Mean    1305.73\n",
      "trainer/Z Expert Predictions Std      254.193\n",
      "trainer/Z Expert Predictions Max     1714.67\n",
      "trainer/Z Expert Predictions Min       82.0401\n",
      "trainer/Z Policy Predictions Mean     883.954\n",
      "trainer/Z Policy Predictions Std      493.955\n",
      "trainer/Z Policy Predictions Max     1669.37\n",
      "trainer/Z Policy Predictions Min     -367.051\n",
      "trainer/Z Expert Targets Mean        1291.8\n",
      "trainer/Z Expert Targets Std          255.704\n",
      "trainer/Z Expert Targets Max         1697.09\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         878.456\n",
      "trainer/Z Policy Targets Std          492.647\n",
      "trainer/Z Policy Targets Max         1688.02\n",
      "trainer/Z Policy Targets Min         -398.08\n",
      "trainer/Log Pis Mean                   13.5965\n",
      "trainer/Log Pis Std                     5.34201\n",
      "trainer/Policy mu Mean                  0.394324\n",
      "trainer/Policy mu Std                   2.56166\n",
      "trainer/Policy log std Mean            -3.99706\n",
      "trainer/Policy log std Std              1.09776\n",
      "exploration/num steps total        193925\n",
      "exploration/num paths total          1036\n",
      "evaluation/num steps total              1.31912e+06\n",
      "evaluation/num paths total           1917\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51191\n",
      "evaluation/Rewards Std                  0.600479\n",
      "evaluation/Rewards Max                  4.84494\n",
      "evaluation/Rewards Min                  0.618065\n",
      "evaluation/Returns Mean              3511.91\n",
      "evaluation/Returns Std                 17.6603\n",
      "evaluation/Returns Max               3560.53\n",
      "evaluation/Returns Min               3495.58\n",
      "evaluation/Estimation Bias Mean      1180.53\n",
      "evaluation/Estimation Bias Std        254.099\n",
      "evaluation/EB/Q_True Mean              32.5518\n",
      "evaluation/EB/Q_True Std              100.382\n",
      "evaluation/EB/Q_Pred Mean            1213.08\n",
      "evaluation/EB/Q_Pred Std              232.541\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3511.91\n",
      "evaluation/Actions Mean                 0.0497826\n",
      "evaluation/Actions Std                  0.601479\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72363\n",
      "time/backward_zf1 (s)                   1.83633\n",
      "time/backward_zf2 (s)                   1.77557\n",
      "time/data sampling (s)                  0.226934\n",
      "time/data storing (s)                   0.0140258\n",
      "time/evaluation sampling (s)            1.33302\n",
      "time/exploration sampling (s)           0.171183\n",
      "time/logging (s)                        0.0125793\n",
      "time/preback_alpha (s)                  0.541625\n",
      "time/preback_policy (s)                 0.597904\n",
      "time/preback_start (s)                  0.122702\n",
      "time/preback_zf (s)                     4.93204\n",
      "time/saving (s)                         0.00539601\n",
      "time/training (s)                       2.53032\n",
      "time/epoch (s)                         15.8233\n",
      "time/total (s)                       2921.39\n",
      "Epoch                                 187\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:50:12.001763 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 188 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 199000\n",
      "trainer/ZF1 Loss                      401.727\n",
      "trainer/ZF2 Loss                      399.429\n",
      "trainer/ZF Expert Reward                4.3285\n",
      "trainer/ZF Policy Reward               -2.50741\n",
      "trainer/ZF CHI2 Term                  421.535\n",
      "trainer/Policy Loss                  -921.727\n",
      "trainer/Policy Grad Norm              878.241\n",
      "trainer/Policy Param Norm              41.7199\n",
      "trainer/Zf1 Grad Norm               56482.3\n",
      "trainer/Zf1 Param Norm                116.71\n",
      "trainer/Zf2 Grad Norm               34356.5\n",
      "trainer/Zf2 Param Norm                112.626\n",
      "trainer/Z Expert Predictions Mean    1270.97\n",
      "trainer/Z Expert Predictions Std      276.749\n",
      "trainer/Z Expert Predictions Max     1842.4\n",
      "trainer/Z Expert Predictions Min      432.868\n",
      "trainer/Z Policy Predictions Mean     914.46\n",
      "trainer/Z Policy Predictions Std      481.697\n",
      "trainer/Z Policy Predictions Max     1672.48\n",
      "trainer/Z Policy Predictions Min     -468.765\n",
      "trainer/Z Expert Targets Mean        1266.64\n",
      "trainer/Z Expert Targets Std          279.699\n",
      "trainer/Z Expert Targets Max         1836.94\n",
      "trainer/Z Expert Targets Min          427.22\n",
      "trainer/Z Policy Targets Mean         916.967\n",
      "trainer/Z Policy Targets Std          483.957\n",
      "trainer/Z Policy Targets Max         1686.16\n",
      "trainer/Z Policy Targets Min         -365.816\n",
      "trainer/Log Pis Mean                   14.2638\n",
      "trainer/Log Pis Std                     4.72006\n",
      "trainer/Policy mu Mean                  0.13729\n",
      "trainer/Policy mu Std                   2.42452\n",
      "trainer/Policy log std Mean            -4.16274\n",
      "trainer/Policy log std Std              1.15271\n",
      "exploration/num steps total        194408\n",
      "exploration/num paths total          1037\n",
      "evaluation/num steps total              1.32691e+06\n",
      "evaluation/num paths total           1927\n",
      "evaluation/path length Mean           778.8\n",
      "evaluation/path length Std            298.006\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 3.51902\n",
      "evaluation/Rewards Std                  0.637332\n",
      "evaluation/Rewards Max                  4.74416\n",
      "evaluation/Rewards Min                  0.625287\n",
      "evaluation/Returns Mean              2740.61\n",
      "evaluation/Returns Std               1088.88\n",
      "evaluation/Returns Max               3598.18\n",
      "evaluation/Returns Min               1108.12\n",
      "evaluation/Estimation Bias Mean      1093.19\n",
      "evaluation/Estimation Bias Std        435.599\n",
      "evaluation/EB/Q_True Mean              41.7976\n",
      "evaluation/EB/Q_True Std              112.297\n",
      "evaluation/EB/Q_Pred Mean            1134.99\n",
      "evaluation/EB/Q_Pred Std              405.83\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2740.61\n",
      "evaluation/Actions Mean                 0.047367\n",
      "evaluation/Actions Std                  0.597601\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67803\n",
      "time/backward_zf1 (s)                   1.80597\n",
      "time/backward_zf2 (s)                   1.72354\n",
      "time/data sampling (s)                  0.238057\n",
      "time/data storing (s)                   0.0136832\n",
      "time/evaluation sampling (s)            1.34794\n",
      "time/exploration sampling (s)           0.168189\n",
      "time/logging (s)                        0.00920035\n",
      "time/preback_alpha (s)                  0.546022\n",
      "time/preback_policy (s)                 0.594047\n",
      "time/preback_start (s)                  0.123466\n",
      "time/preback_zf (s)                     4.96095\n",
      "time/saving (s)                         0.00542143\n",
      "time/training (s)                       2.67585\n",
      "time/epoch (s)                         15.8904\n",
      "time/total (s)                       2937.3\n",
      "Epoch                                 188\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:50:28.043211 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 189 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 200000\n",
      "trainer/ZF1 Loss                       72.239\n",
      "trainer/ZF2 Loss                       63.2841\n",
      "trainer/ZF Expert Reward               11.402\n",
      "trainer/ZF Policy Reward                4.48352\n",
      "trainer/ZF CHI2 Term                   88.7701\n",
      "trainer/Policy Loss                  -904.984\n",
      "trainer/Policy Grad Norm              846.138\n",
      "trainer/Policy Param Norm              41.7716\n",
      "trainer/Zf1 Grad Norm               25546.9\n",
      "trainer/Zf1 Param Norm                116.955\n",
      "trainer/Zf2 Grad Norm               29533.1\n",
      "trainer/Zf2 Param Norm                112.845\n",
      "trainer/Z Expert Predictions Mean    1259.72\n",
      "trainer/Z Expert Predictions Std      281.962\n",
      "trainer/Z Expert Predictions Max     1825.75\n",
      "trainer/Z Expert Predictions Min      454.757\n",
      "trainer/Z Policy Predictions Mean     895.194\n",
      "trainer/Z Policy Predictions Std      484.627\n",
      "trainer/Z Policy Predictions Max     1670.59\n",
      "trainer/Z Policy Predictions Min     -451.639\n",
      "trainer/Z Expert Targets Mean        1248.31\n",
      "trainer/Z Expert Targets Std          287.029\n",
      "trainer/Z Expert Targets Max         1829.34\n",
      "trainer/Z Expert Targets Min          435.528\n",
      "trainer/Z Policy Targets Mean         890.711\n",
      "trainer/Z Policy Targets Std          483.527\n",
      "trainer/Z Policy Targets Max         1658.55\n",
      "trainer/Z Policy Targets Min         -470.342\n",
      "trainer/Log Pis Mean                   14.2324\n",
      "trainer/Log Pis Std                     5.23686\n",
      "trainer/Policy mu Mean                  0.372355\n",
      "trainer/Policy mu Std                   2.65011\n",
      "trainer/Policy log std Mean            -4.07681\n",
      "trainer/Policy log std Std              1.16947\n",
      "exploration/num steps total        195141\n",
      "exploration/num paths total          1038\n",
      "evaluation/num steps total              1.33569e+06\n",
      "evaluation/num paths total           1937\n",
      "evaluation/path length Mean           878.3\n",
      "evaluation/path length Std            244.802\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 3.54131\n",
      "evaluation/Rewards Std                  0.61284\n",
      "evaluation/Rewards Max                  4.78084\n",
      "evaluation/Rewards Min                  0.620103\n",
      "evaluation/Returns Mean              3110.33\n",
      "evaluation/Returns Std                895.437\n",
      "evaluation/Returns Max               3617.19\n",
      "evaluation/Returns Min               1102.73\n",
      "evaluation/Estimation Bias Mean      1169.48\n",
      "evaluation/Estimation Bias Std        423.604\n",
      "evaluation/EB/Q_True Mean              38.1492\n",
      "evaluation/EB/Q_True Std              109.229\n",
      "evaluation/EB/Q_Pred Mean            1207.63\n",
      "evaluation/EB/Q_Pred Std              383.334\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3110.33\n",
      "evaluation/Actions Mean                 0.0436937\n",
      "evaluation/Actions Std                  0.590727\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70555\n",
      "time/backward_zf1 (s)                   1.83117\n",
      "time/backward_zf2 (s)                   1.76077\n",
      "time/data sampling (s)                  0.247546\n",
      "time/data storing (s)                   0.0136346\n",
      "time/evaluation sampling (s)            1.33673\n",
      "time/exploration sampling (s)           0.167448\n",
      "time/logging (s)                        0.010416\n",
      "time/preback_alpha (s)                  0.550972\n",
      "time/preback_policy (s)                 0.609565\n",
      "time/preback_start (s)                  0.123836\n",
      "time/preback_zf (s)                     4.98013\n",
      "time/saving (s)                         0.00504058\n",
      "time/training (s)                       2.63847\n",
      "time/epoch (s)                         15.9813\n",
      "time/total (s)                       2953.3\n",
      "Epoch                                 189\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:50:44.093647 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 190 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 201000\n",
      "trainer/ZF1 Loss                       92.931\n",
      "trainer/ZF2 Loss                       98.6449\n",
      "trainer/ZF Expert Reward               22.6111\n",
      "trainer/ZF Policy Reward                9.63096\n",
      "trainer/ZF CHI2 Term                  123.141\n",
      "trainer/Policy Loss                  -927.732\n",
      "trainer/Policy Grad Norm              896.201\n",
      "trainer/Policy Param Norm              41.8387\n",
      "trainer/Zf1 Grad Norm               62342.1\n",
      "trainer/Zf1 Param Norm                117.179\n",
      "trainer/Zf2 Grad Norm               39345.7\n",
      "trainer/Zf2 Param Norm                113.049\n",
      "trainer/Z Expert Predictions Mean    1270.99\n",
      "trainer/Z Expert Predictions Std      277.399\n",
      "trainer/Z Expert Predictions Max     1767.63\n",
      "trainer/Z Expert Predictions Min      443.52\n",
      "trainer/Z Policy Predictions Mean     930.044\n",
      "trainer/Z Policy Predictions Std      498.657\n",
      "trainer/Z Policy Predictions Max     1695.97\n",
      "trainer/Z Policy Predictions Min     -489.424\n",
      "trainer/Z Expert Targets Mean        1248.38\n",
      "trainer/Z Expert Targets Std          274.857\n",
      "trainer/Z Expert Targets Max         1734\n",
      "trainer/Z Expert Targets Min          364.283\n",
      "trainer/Z Policy Targets Mean         920.413\n",
      "trainer/Z Policy Targets Std          494.705\n",
      "trainer/Z Policy Targets Max         1644.46\n",
      "trainer/Z Policy Targets Min         -474.084\n",
      "trainer/Log Pis Mean                   14.5186\n",
      "trainer/Log Pis Std                     5.78638\n",
      "trainer/Policy mu Mean                  0.44999\n",
      "trainer/Policy mu Std                   2.96797\n",
      "trainer/Policy log std Mean            -4.25251\n",
      "trainer/Policy log std Std              1.15854\n",
      "exploration/num steps total        195141\n",
      "exploration/num paths total          1038\n",
      "evaluation/num steps total              1.34569e+06\n",
      "evaluation/num paths total           1947\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48501\n",
      "evaluation/Rewards Std                  0.601895\n",
      "evaluation/Rewards Max                  4.85185\n",
      "evaluation/Rewards Min                  0.636379\n",
      "evaluation/Returns Mean              3485.01\n",
      "evaluation/Returns Std                 15.903\n",
      "evaluation/Returns Max               3524.55\n",
      "evaluation/Returns Min               3460.83\n",
      "evaluation/Estimation Bias Mean      1146.3\n",
      "evaluation/Estimation Bias Std        242.352\n",
      "evaluation/EB/Q_True Mean              32.1747\n",
      "evaluation/EB/Q_True Std               98.9437\n",
      "evaluation/EB/Q_Pred Mean            1178.47\n",
      "evaluation/EB/Q_Pred Std              224.718\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3485.01\n",
      "evaluation/Actions Mean                 0.0423299\n",
      "evaluation/Actions Std                  0.596687\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79139\n",
      "time/backward_zf1 (s)                   1.90583\n",
      "time/backward_zf2 (s)                   1.84367\n",
      "time/data sampling (s)                  0.257681\n",
      "time/data storing (s)                   0.0138763\n",
      "time/evaluation sampling (s)            1.33973\n",
      "time/exploration sampling (s)           0.170051\n",
      "time/logging (s)                        0.0118943\n",
      "time/preback_alpha (s)                  0.548709\n",
      "time/preback_policy (s)                 0.626192\n",
      "time/preback_start (s)                  0.123003\n",
      "time/preback_zf (s)                     4.96468\n",
      "time/saving (s)                         0.00603701\n",
      "time/training (s)                       2.38552\n",
      "time/epoch (s)                         15.9883\n",
      "time/total (s)                       2969.3\n",
      "Epoch                                 190\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:51:00.328192 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 191 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 202000\n",
      "trainer/ZF1 Loss                      155.751\n",
      "trainer/ZF2 Loss                      125.195\n",
      "trainer/ZF Expert Reward               22.052\n",
      "trainer/ZF Policy Reward                3.19714\n",
      "trainer/ZF CHI2 Term                  173.143\n",
      "trainer/Policy Loss                  -894.696\n",
      "trainer/Policy Grad Norm             1227.14\n",
      "trainer/Policy Param Norm              41.8955\n",
      "trainer/Zf1 Grad Norm               69293.8\n",
      "trainer/Zf1 Param Norm                117.405\n",
      "trainer/Zf2 Grad Norm               33693.8\n",
      "trainer/Zf2 Param Norm                113.261\n",
      "trainer/Z Expert Predictions Mean    1276.94\n",
      "trainer/Z Expert Predictions Std      253.671\n",
      "trainer/Z Expert Predictions Max     1790.67\n",
      "trainer/Z Expert Predictions Min      537.584\n",
      "trainer/Z Policy Predictions Mean     892.757\n",
      "trainer/Z Policy Predictions Std      526.017\n",
      "trainer/Z Policy Predictions Max     1730.52\n",
      "trainer/Z Policy Predictions Min     -397.855\n",
      "trainer/Z Expert Targets Mean        1254.89\n",
      "trainer/Z Expert Targets Std          261.747\n",
      "trainer/Z Expert Targets Max         1773.32\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         889.559\n",
      "trainer/Z Policy Targets Std          517.874\n",
      "trainer/Z Policy Targets Max         1699.08\n",
      "trainer/Z Policy Targets Min         -328.672\n",
      "trainer/Log Pis Mean                   13.9545\n",
      "trainer/Log Pis Std                     5.26777\n",
      "trainer/Policy mu Mean                  0.400537\n",
      "trainer/Policy mu Std                   3.06132\n",
      "trainer/Policy log std Mean            -4.1462\n",
      "trainer/Policy log std Std              1.24592\n",
      "exploration/num steps total        197141\n",
      "exploration/num paths total          1040\n",
      "evaluation/num steps total              1.35569e+06\n",
      "evaluation/num paths total           1957\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.49279\n",
      "evaluation/Rewards Std                  0.590739\n",
      "evaluation/Rewards Max                  4.77407\n",
      "evaluation/Rewards Min                  0.664895\n",
      "evaluation/Returns Mean              3492.79\n",
      "evaluation/Returns Std                 17.5944\n",
      "evaluation/Returns Max               3510.49\n",
      "evaluation/Returns Min               3459.72\n",
      "evaluation/Estimation Bias Mean      1153.58\n",
      "evaluation/Estimation Bias Std        238.705\n",
      "evaluation/EB/Q_True Mean              32.249\n",
      "evaluation/EB/Q_True Std               99.4588\n",
      "evaluation/EB/Q_Pred Mean            1185.83\n",
      "evaluation/EB/Q_Pred Std              223.152\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3492.79\n",
      "evaluation/Actions Mean                 0.0407808\n",
      "evaluation/Actions Std                  0.584726\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81964\n",
      "time/backward_zf1 (s)                   1.92195\n",
      "time/backward_zf2 (s)                   1.87669\n",
      "time/data sampling (s)                  0.24612\n",
      "time/data storing (s)                   0.0140941\n",
      "time/evaluation sampling (s)            1.41714\n",
      "time/exploration sampling (s)           0.172055\n",
      "time/logging (s)                        0.0119701\n",
      "time/preback_alpha (s)                  0.554888\n",
      "time/preback_policy (s)                 0.624712\n",
      "time/preback_start (s)                  0.125257\n",
      "time/preback_zf (s)                     4.98058\n",
      "time/saving (s)                         0.00487635\n",
      "time/training (s)                       2.40101\n",
      "time/epoch (s)                         16.171\n",
      "time/total (s)                       2985.49\n",
      "Epoch                                 191\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:51:16.964718 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 192 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 203000\n",
      "trainer/ZF1 Loss                      904.848\n",
      "trainer/ZF2 Loss                     1013.2\n",
      "trainer/ZF Expert Reward               11.0029\n",
      "trainer/ZF Policy Reward                3.76342\n",
      "trainer/ZF CHI2 Term                  980.373\n",
      "trainer/Policy Loss                  -841.738\n",
      "trainer/Policy Grad Norm              648.199\n",
      "trainer/Policy Param Norm              41.9624\n",
      "trainer/Zf1 Grad Norm               64818.8\n",
      "trainer/Zf1 Param Norm                117.644\n",
      "trainer/Zf2 Grad Norm               62348.6\n",
      "trainer/Zf2 Param Norm                113.458\n",
      "trainer/Z Expert Predictions Mean    1259.16\n",
      "trainer/Z Expert Predictions Std      268.082\n",
      "trainer/Z Expert Predictions Max     1759.52\n",
      "trainer/Z Expert Predictions Min      207.671\n",
      "trainer/Z Policy Predictions Mean     837.463\n",
      "trainer/Z Policy Predictions Std      508.106\n",
      "trainer/Z Policy Predictions Max     1628.16\n",
      "trainer/Z Policy Predictions Min     -434.649\n",
      "trainer/Z Expert Targets Mean        1248.15\n",
      "trainer/Z Expert Targets Std          284.132\n",
      "trainer/Z Expert Targets Max         1753.1\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         833.7\n",
      "trainer/Z Policy Targets Std          509.721\n",
      "trainer/Z Policy Targets Max         1629.49\n",
      "trainer/Z Policy Targets Min         -435.388\n",
      "trainer/Log Pis Mean                   14.2516\n",
      "trainer/Log Pis Std                     4.71577\n",
      "trainer/Policy mu Mean                  0.442826\n",
      "trainer/Policy mu Std                   3.40268\n",
      "trainer/Policy log std Mean            -3.97236\n",
      "trainer/Policy log std Std              1.31436\n",
      "exploration/num steps total        197947\n",
      "exploration/num paths total          1041\n",
      "evaluation/num steps total              1.36569e+06\n",
      "evaluation/num paths total           1967\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.5218\n",
      "evaluation/Rewards Std                  0.596166\n",
      "evaluation/Rewards Max                  4.85664\n",
      "evaluation/Rewards Min                  0.643172\n",
      "evaluation/Returns Mean              3521.8\n",
      "evaluation/Returns Std                 21.9755\n",
      "evaluation/Returns Max               3549.46\n",
      "evaluation/Returns Min               3485.77\n",
      "evaluation/Estimation Bias Mean      1172.1\n",
      "evaluation/Estimation Bias Std        250.168\n",
      "evaluation/EB/Q_True Mean              32.3105\n",
      "evaluation/EB/Q_True Std               99.705\n",
      "evaluation/EB/Q_Pred Mean            1204.41\n",
      "evaluation/EB/Q_Pred Std              233.83\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3521.8\n",
      "evaluation/Actions Mean                 0.0474754\n",
      "evaluation/Actions Std                  0.589537\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79947\n",
      "time/backward_zf1 (s)                   1.93374\n",
      "time/backward_zf2 (s)                   1.84502\n",
      "time/data sampling (s)                  0.283509\n",
      "time/data storing (s)                   0.0149485\n",
      "time/evaluation sampling (s)            1.54369\n",
      "time/exploration sampling (s)           0.178502\n",
      "time/logging (s)                        0.012082\n",
      "time/preback_alpha (s)                  0.581903\n",
      "time/preback_policy (s)                 0.646622\n",
      "time/preback_start (s)                  0.13106\n",
      "time/preback_zf (s)                     5.05634\n",
      "time/saving (s)                         0.00625911\n",
      "time/training (s)                       2.53497\n",
      "time/epoch (s)                         16.5681\n",
      "time/total (s)                       3002.08\n",
      "Epoch                                 192\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:51:33.157704 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 193 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 204000\n",
      "trainer/ZF1 Loss                      118.111\n",
      "trainer/ZF2 Loss                      129.506\n",
      "trainer/ZF Expert Reward                6.57246\n",
      "trainer/ZF Policy Reward               -9.71277\n",
      "trainer/ZF CHI2 Term                  153.908\n",
      "trainer/Policy Loss                  -911.425\n",
      "trainer/Policy Grad Norm              826.006\n",
      "trainer/Policy Param Norm              42.0268\n",
      "trainer/Zf1 Grad Norm               45773.5\n",
      "trainer/Zf1 Param Norm                117.861\n",
      "trainer/Zf2 Grad Norm               37616.6\n",
      "trainer/Zf2 Param Norm                113.654\n",
      "trainer/Z Expert Predictions Mean    1245.59\n",
      "trainer/Z Expert Predictions Std      252.408\n",
      "trainer/Z Expert Predictions Max     1786.29\n",
      "trainer/Z Expert Predictions Min      528.803\n",
      "trainer/Z Policy Predictions Mean     901.674\n",
      "trainer/Z Policy Predictions Std      452.377\n",
      "trainer/Z Policy Predictions Max     1639.38\n",
      "trainer/Z Policy Predictions Min     -380.608\n",
      "trainer/Z Expert Targets Mean        1239.02\n",
      "trainer/Z Expert Targets Std          260.877\n",
      "trainer/Z Expert Targets Max         1774.61\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         911.387\n",
      "trainer/Z Policy Targets Std          450.395\n",
      "trainer/Z Policy Targets Max         1640.41\n",
      "trainer/Z Policy Targets Min         -366.49\n",
      "trainer/Log Pis Mean                   13.9536\n",
      "trainer/Log Pis Std                     4.80124\n",
      "trainer/Policy mu Mean                  0.443896\n",
      "trainer/Policy mu Std                   3.01128\n",
      "trainer/Policy log std Mean            -4.10052\n",
      "trainer/Policy log std Std              1.18593\n",
      "exploration/num steps total        199828\n",
      "exploration/num paths total          1043\n",
      "evaluation/num steps total              1.37084e+06\n",
      "evaluation/num paths total           1977\n",
      "evaluation/path length Mean           515.1\n",
      "evaluation/path length Std            149.793\n",
      "evaluation/path length Max            658\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 3.48009\n",
      "evaluation/Rewards Std                  0.734977\n",
      "evaluation/Rewards Max                  5.26408\n",
      "evaluation/Rewards Min                  0.675255\n",
      "evaluation/Returns Mean              1792.6\n",
      "evaluation/Returns Std                561.006\n",
      "evaluation/Returns Max               2315.96\n",
      "evaluation/Returns Min               1111.42\n",
      "evaluation/Estimation Bias Mean       954.134\n",
      "evaluation/Estimation Bias Std        569.016\n",
      "evaluation/EB/Q_True Mean              39.4588\n",
      "evaluation/EB/Q_True Std              107.477\n",
      "evaluation/EB/Q_Pred Mean             993.593\n",
      "evaluation/EB/Q_Pred Std              548.948\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1792.6\n",
      "evaluation/Actions Mean                 0.0466124\n",
      "evaluation/Actions Std                  0.608109\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.68431\n",
      "time/backward_zf1 (s)                   1.8274\n",
      "time/backward_zf2 (s)                   1.71453\n",
      "time/data sampling (s)                  0.281108\n",
      "time/data storing (s)                   0.0137032\n",
      "time/evaluation sampling (s)            1.42165\n",
      "time/exploration sampling (s)           0.174022\n",
      "time/logging (s)                        0.00754227\n",
      "time/preback_alpha (s)                  0.576583\n",
      "time/preback_policy (s)                 0.626513\n",
      "time/preback_start (s)                  0.12883\n",
      "time/preback_zf (s)                     5.00912\n",
      "time/saving (s)                         0.00543178\n",
      "time/training (s)                       2.64805\n",
      "time/epoch (s)                         16.1188\n",
      "time/total (s)                       3018.22\n",
      "Epoch                                 193\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:51:49.022093 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 194 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 205000\n",
      "trainer/ZF1 Loss                       77.5734\n",
      "trainer/ZF2 Loss                       98.6858\n",
      "trainer/ZF Expert Reward                8.84339\n",
      "trainer/ZF Policy Reward               -9.51153\n",
      "trainer/ZF CHI2 Term                  120.507\n",
      "trainer/Policy Loss                  -832.067\n",
      "trainer/Policy Grad Norm              464.301\n",
      "trainer/Policy Param Norm              42.0927\n",
      "trainer/Zf1 Grad Norm               18040.2\n",
      "trainer/Zf1 Param Norm                118.083\n",
      "trainer/Zf2 Grad Norm               60770.4\n",
      "trainer/Zf2 Param Norm                113.848\n",
      "trainer/Z Expert Predictions Mean    1269.21\n",
      "trainer/Z Expert Predictions Std      260.477\n",
      "trainer/Z Expert Predictions Max     1736.76\n",
      "trainer/Z Expert Predictions Min      424.269\n",
      "trainer/Z Policy Predictions Mean     819.546\n",
      "trainer/Z Policy Predictions Std      519.851\n",
      "trainer/Z Policy Predictions Max     1712.33\n",
      "trainer/Z Policy Predictions Min     -477.471\n",
      "trainer/Z Expert Targets Mean        1260.37\n",
      "trainer/Z Expert Targets Std          263.108\n",
      "trainer/Z Expert Targets Max         1731.82\n",
      "trainer/Z Expert Targets Min          419.984\n",
      "trainer/Z Policy Targets Mean         829.057\n",
      "trainer/Z Policy Targets Std          520.188\n",
      "trainer/Z Policy Targets Max         1717.48\n",
      "trainer/Z Policy Targets Min         -502.916\n",
      "trainer/Log Pis Mean                   14.1639\n",
      "trainer/Log Pis Std                     5.443\n",
      "trainer/Policy mu Mean                  0.442329\n",
      "trainer/Policy mu Std                   3.1061\n",
      "trainer/Policy log std Mean            -4.06984\n",
      "trainer/Policy log std Std              1.24213\n",
      "exploration/num steps total        200828\n",
      "exploration/num paths total          1044\n",
      "evaluation/num steps total              1.37454e+06\n",
      "evaluation/num paths total           1987\n",
      "evaluation/path length Mean           370.1\n",
      "evaluation/path length Std             69.3317\n",
      "evaluation/path length Max            559\n",
      "evaluation/path length Min            324\n",
      "evaluation/Rewards Mean                 3.36676\n",
      "evaluation/Rewards Std                  0.802032\n",
      "evaluation/Rewards Max                  4.84577\n",
      "evaluation/Rewards Min                  0.670702\n",
      "evaluation/Returns Mean              1246.04\n",
      "evaluation/Returns Std                263.742\n",
      "evaluation/Returns Max               1962.62\n",
      "evaluation/Returns Min               1077.92\n",
      "evaluation/Estimation Bias Mean       936.174\n",
      "evaluation/Estimation Bias Std        553.062\n",
      "evaluation/EB/Q_True Mean              37.2764\n",
      "evaluation/EB/Q_True Std               94.6673\n",
      "evaluation/EB/Q_Pred Mean             973.45\n",
      "evaluation/EB/Q_Pred Std              547.285\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1246.04\n",
      "evaluation/Actions Mean                 0.0478016\n",
      "evaluation/Actions Std                  0.61257\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74692\n",
      "time/backward_zf1 (s)                   1.84194\n",
      "time/backward_zf2 (s)                   1.74115\n",
      "time/data sampling (s)                  0.247507\n",
      "time/data storing (s)                   0.0141536\n",
      "time/evaluation sampling (s)            1.01587\n",
      "time/exploration sampling (s)           0.175189\n",
      "time/logging (s)                        0.0051196\n",
      "time/preback_alpha (s)                  0.567247\n",
      "time/preback_policy (s)                 0.616277\n",
      "time/preback_start (s)                  0.12856\n",
      "time/preback_zf (s)                     4.99788\n",
      "time/saving (s)                         0.00493874\n",
      "time/training (s)                       2.69523\n",
      "time/epoch (s)                         15.798\n",
      "time/total (s)                       3034.04\n",
      "Epoch                                 194\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:52:05.020735 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 195 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 206000\n",
      "trainer/ZF1 Loss                      471.619\n",
      "trainer/ZF2 Loss                      503.509\n",
      "trainer/ZF Expert Reward               14.2879\n",
      "trainer/ZF Policy Reward                8.17829\n",
      "trainer/ZF CHI2 Term                  507.238\n",
      "trainer/Policy Loss                  -922.386\n",
      "trainer/Policy Grad Norm              567.309\n",
      "trainer/Policy Param Norm              42.1574\n",
      "trainer/Zf1 Grad Norm               33333.2\n",
      "trainer/Zf1 Param Norm                118.308\n",
      "trainer/Zf2 Grad Norm               34507\n",
      "trainer/Zf2 Param Norm                114.062\n",
      "trainer/Z Expert Predictions Mean    1257.14\n",
      "trainer/Z Expert Predictions Std      269.366\n",
      "trainer/Z Expert Predictions Max     1757.51\n",
      "trainer/Z Expert Predictions Min      296.795\n",
      "trainer/Z Policy Predictions Mean     920.115\n",
      "trainer/Z Policy Predictions Std      458.915\n",
      "trainer/Z Policy Predictions Max     1610.81\n",
      "trainer/Z Policy Predictions Min     -490.414\n",
      "trainer/Z Expert Targets Mean        1242.85\n",
      "trainer/Z Expert Targets Std          274.112\n",
      "trainer/Z Expert Targets Max         1775.32\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         911.937\n",
      "trainer/Z Policy Targets Std          467.272\n",
      "trainer/Z Policy Targets Max         1627.9\n",
      "trainer/Z Policy Targets Min         -473.047\n",
      "trainer/Log Pis Mean                   13.7011\n",
      "trainer/Log Pis Std                     4.42326\n",
      "trainer/Policy mu Mean                  0.180691\n",
      "trainer/Policy mu Std                   2.65405\n",
      "trainer/Policy log std Mean            -4.21775\n",
      "trainer/Policy log std Std              1.09735\n",
      "exploration/num steps total        202453\n",
      "exploration/num paths total          1047\n",
      "evaluation/num steps total              1.38282e+06\n",
      "evaluation/num paths total           1998\n",
      "evaluation/path length Mean           752.636\n",
      "evaluation/path length Std            286.395\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            334\n",
      "evaluation/Rewards Mean                 3.51308\n",
      "evaluation/Rewards Std                  0.646185\n",
      "evaluation/Rewards Max                  4.76229\n",
      "evaluation/Rewards Min                  0.671745\n",
      "evaluation/Returns Mean              2644.07\n",
      "evaluation/Returns Std               1038.08\n",
      "evaluation/Returns Max               3570.36\n",
      "evaluation/Returns Min               1108.71\n",
      "evaluation/Estimation Bias Mean      1093.63\n",
      "evaluation/Estimation Bias Std        424.071\n",
      "evaluation/EB/Q_True Mean              39.9256\n",
      "evaluation/EB/Q_True Std              110.696\n",
      "evaluation/EB/Q_Pred Mean            1133.55\n",
      "evaluation/EB/Q_Pred Std              388.326\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2644.07\n",
      "evaluation/Actions Mean                 0.0463359\n",
      "evaluation/Actions Std                  0.592107\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.756\n",
      "time/backward_zf1 (s)                   1.86656\n",
      "time/backward_zf2 (s)                   1.79837\n",
      "time/data sampling (s)                  0.231407\n",
      "time/data storing (s)                   0.0143877\n",
      "time/evaluation sampling (s)            1.36851\n",
      "time/exploration sampling (s)           0.178354\n",
      "time/logging (s)                        0.0105458\n",
      "time/preback_alpha (s)                  0.545948\n",
      "time/preback_policy (s)                 0.607457\n",
      "time/preback_start (s)                  0.12396\n",
      "time/preback_zf (s)                     4.94326\n",
      "time/saving (s)                         0.00516217\n",
      "time/training (s)                       2.49277\n",
      "time/epoch (s)                         15.9427\n",
      "time/total (s)                       3050\n",
      "Epoch                                 195\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:52:20.167472 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 196 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 207000\n",
      "trainer/ZF1 Loss                      262.511\n",
      "trainer/ZF2 Loss                      245.954\n",
      "trainer/ZF Expert Reward               11.1147\n",
      "trainer/ZF Policy Reward                1.01245\n",
      "trainer/ZF CHI2 Term                  278.843\n",
      "trainer/Policy Loss                  -867.903\n",
      "trainer/Policy Grad Norm              555.75\n",
      "trainer/Policy Param Norm              42.2177\n",
      "trainer/Zf1 Grad Norm               36854.7\n",
      "trainer/Zf1 Param Norm                118.55\n",
      "trainer/Zf2 Grad Norm               45970.2\n",
      "trainer/Zf2 Param Norm                114.288\n",
      "trainer/Z Expert Predictions Mean    1226.59\n",
      "trainer/Z Expert Predictions Std      273.628\n",
      "trainer/Z Expert Predictions Max     1744.43\n",
      "trainer/Z Expert Predictions Min      560.903\n",
      "trainer/Z Policy Predictions Mean     859.87\n",
      "trainer/Z Policy Predictions Std      497.882\n",
      "trainer/Z Policy Predictions Max     1586.53\n",
      "trainer/Z Policy Predictions Min     -473.967\n",
      "trainer/Z Expert Targets Mean        1215.47\n",
      "trainer/Z Expert Targets Std          270.343\n",
      "trainer/Z Expert Targets Max         1700.49\n",
      "trainer/Z Expert Targets Min          509.628\n",
      "trainer/Z Policy Targets Mean         858.858\n",
      "trainer/Z Policy Targets Std          495.1\n",
      "trainer/Z Policy Targets Max         1591.03\n",
      "trainer/Z Policy Targets Min         -439.061\n",
      "trainer/Log Pis Mean                   14.6547\n",
      "trainer/Log Pis Std                     5.25263\n",
      "trainer/Policy mu Mean                  0.426112\n",
      "trainer/Policy mu Std                   2.93976\n",
      "trainer/Policy log std Mean            -4.10588\n",
      "trainer/Policy log std Std              1.34816\n",
      "exploration/num steps total        202453\n",
      "exploration/num paths total          1047\n",
      "evaluation/num steps total              1.38598e+06\n",
      "evaluation/num paths total           2008\n",
      "evaluation/path length Mean           315.7\n",
      "evaluation/path length Std             28.6358\n",
      "evaluation/path length Max            332\n",
      "evaluation/path length Min            258\n",
      "evaluation/Rewards Mean                 3.33256\n",
      "evaluation/Rewards Std                  0.860355\n",
      "evaluation/Rewards Max                  4.84833\n",
      "evaluation/Rewards Min                  0.654922\n",
      "evaluation/Returns Mean              1052.09\n",
      "evaluation/Returns Std                117.135\n",
      "evaluation/Returns Max               1116.01\n",
      "evaluation/Returns Min                815.852\n",
      "evaluation/Estimation Bias Mean       712.309\n",
      "evaluation/Estimation Bias Std        626.335\n",
      "evaluation/EB/Q_True Mean              27.325\n",
      "evaluation/EB/Q_True Std               84.1479\n",
      "evaluation/EB/Q_Pred Mean             739.634\n",
      "evaluation/EB/Q_Pred Std              630.262\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1052.09\n",
      "evaluation/Actions Mean                 0.0438533\n",
      "evaluation/Actions Std                  0.628505\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79461\n",
      "time/backward_zf1 (s)                   1.90278\n",
      "time/backward_zf2 (s)                   1.84605\n",
      "time/data sampling (s)                  0.252966\n",
      "time/data storing (s)                   0.0135795\n",
      "time/evaluation sampling (s)            0.479054\n",
      "time/exploration sampling (s)           0.167337\n",
      "time/logging (s)                        0.00465368\n",
      "time/preback_alpha (s)                  0.547247\n",
      "time/preback_policy (s)                 0.622614\n",
      "time/preback_start (s)                  0.122903\n",
      "time/preback_zf (s)                     4.95042\n",
      "time/saving (s)                         0.00514739\n",
      "time/training (s)                       2.36516\n",
      "time/epoch (s)                         15.0745\n",
      "time/total (s)                       3065.09\n",
      "Epoch                                 196\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:52:36.248437 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 197 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 208000\n",
      "trainer/ZF1 Loss                      328.521\n",
      "trainer/ZF2 Loss                      311.232\n",
      "trainer/ZF Expert Reward               20.0054\n",
      "trainer/ZF Policy Reward                4.8613\n",
      "trainer/ZF CHI2 Term                  348.415\n",
      "trainer/Policy Loss                  -915.221\n",
      "trainer/Policy Grad Norm              768.969\n",
      "trainer/Policy Param Norm              42.2783\n",
      "trainer/Zf1 Grad Norm               99968\n",
      "trainer/Zf1 Param Norm                118.778\n",
      "trainer/Zf2 Grad Norm               74666.6\n",
      "trainer/Zf2 Param Norm                114.474\n",
      "trainer/Z Expert Predictions Mean    1253.6\n",
      "trainer/Z Expert Predictions Std      257.963\n",
      "trainer/Z Expert Predictions Max     1727.16\n",
      "trainer/Z Expert Predictions Min      456.498\n",
      "trainer/Z Policy Predictions Mean     916.901\n",
      "trainer/Z Policy Predictions Std      416.698\n",
      "trainer/Z Policy Predictions Max     1610.94\n",
      "trainer/Z Policy Predictions Min     -394.297\n",
      "trainer/Z Expert Targets Mean        1233.59\n",
      "trainer/Z Expert Targets Std          257.842\n",
      "trainer/Z Expert Targets Max         1673.57\n",
      "trainer/Z Expert Targets Min          412.339\n",
      "trainer/Z Policy Targets Mean         912.04\n",
      "trainer/Z Policy Targets Std          412.277\n",
      "trainer/Z Policy Targets Max         1640.02\n",
      "trainer/Z Policy Targets Min         -396.778\n",
      "trainer/Log Pis Mean                   13.5303\n",
      "trainer/Log Pis Std                     4.88273\n",
      "trainer/Policy mu Mean                  0.538328\n",
      "trainer/Policy mu Std                   3.41944\n",
      "trainer/Policy log std Mean            -4.12173\n",
      "trainer/Policy log std Std              1.23427\n",
      "exploration/num steps total        203453\n",
      "exploration/num paths total          1048\n",
      "evaluation/num steps total              1.39598e+06\n",
      "evaluation/num paths total           2018\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.5211\n",
      "evaluation/Rewards Std                  0.600721\n",
      "evaluation/Rewards Max                  4.81835\n",
      "evaluation/Rewards Min                  0.669299\n",
      "evaluation/Returns Mean              3521.1\n",
      "evaluation/Returns Std                 17.662\n",
      "evaluation/Returns Max               3559.09\n",
      "evaluation/Returns Min               3504.27\n",
      "evaluation/Estimation Bias Mean      1167.94\n",
      "evaluation/Estimation Bias Std        248.808\n",
      "evaluation/EB/Q_True Mean              32.4001\n",
      "evaluation/EB/Q_True Std              100.011\n",
      "evaluation/EB/Q_Pred Mean            1200.34\n",
      "evaluation/EB/Q_Pred Std              229.655\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3521.1\n",
      "evaluation/Actions Mean                 0.0522389\n",
      "evaluation/Actions Std                  0.590612\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71542\n",
      "time/backward_zf1 (s)                   1.8422\n",
      "time/backward_zf2 (s)                   1.76314\n",
      "time/data sampling (s)                  0.256745\n",
      "time/data storing (s)                   0.0137202\n",
      "time/evaluation sampling (s)            1.38278\n",
      "time/exploration sampling (s)           0.170658\n",
      "time/logging (s)                        0.0128446\n",
      "time/preback_alpha (s)                  0.551674\n",
      "time/preback_policy (s)                 0.609315\n",
      "time/preback_start (s)                  0.124132\n",
      "time/preback_zf (s)                     4.9808\n",
      "time/saving (s)                         0.00506857\n",
      "time/training (s)                       2.59851\n",
      "time/epoch (s)                         16.027\n",
      "time/total (s)                       3081.14\n",
      "Epoch                                 197\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:52:52.428716 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 198 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 209000\n",
      "trainer/ZF1 Loss                      103.457\n",
      "trainer/ZF2 Loss                      114.799\n",
      "trainer/ZF Expert Reward               18.8241\n",
      "trainer/ZF Policy Reward               -2.35019\n",
      "trainer/ZF CHI2 Term                  143.997\n",
      "trainer/Policy Loss                  -879.048\n",
      "trainer/Policy Grad Norm              626.244\n",
      "trainer/Policy Param Norm              42.3335\n",
      "trainer/Zf1 Grad Norm              111958\n",
      "trainer/Zf1 Param Norm                118.997\n",
      "trainer/Zf2 Grad Norm              123253\n",
      "trainer/Zf2 Param Norm                114.684\n",
      "trainer/Z Expert Predictions Mean    1235.95\n",
      "trainer/Z Expert Predictions Std      271.58\n",
      "trainer/Z Expert Predictions Max     1735.68\n",
      "trainer/Z Expert Predictions Min      322.647\n",
      "trainer/Z Policy Predictions Mean     870.035\n",
      "trainer/Z Policy Predictions Std      439.638\n",
      "trainer/Z Policy Predictions Max     1609.99\n",
      "trainer/Z Policy Predictions Min     -401.649\n",
      "trainer/Z Expert Targets Mean        1217.13\n",
      "trainer/Z Expert Targets Std          274.126\n",
      "trainer/Z Expert Targets Max         1688.61\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         872.385\n",
      "trainer/Z Policy Targets Std          435.538\n",
      "trainer/Z Policy Targets Max         1586.85\n",
      "trainer/Z Policy Targets Min         -366.103\n",
      "trainer/Log Pis Mean                   13.8326\n",
      "trainer/Log Pis Std                     4.85829\n",
      "trainer/Policy mu Mean                  0.467782\n",
      "trainer/Policy mu Std                   2.9424\n",
      "trainer/Policy log std Mean            -4.14503\n",
      "trainer/Policy log std Std              1.20199\n",
      "exploration/num steps total        205342\n",
      "exploration/num paths total          1051\n",
      "evaluation/num steps total              1.40367e+06\n",
      "evaluation/num paths total           2030\n",
      "evaluation/path length Mean           640.917\n",
      "evaluation/path length Std            281.539\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            323\n",
      "evaluation/Rewards Mean                 3.51893\n",
      "evaluation/Rewards Std                  0.687419\n",
      "evaluation/Rewards Max                  5.15834\n",
      "evaluation/Rewards Min                  0.651837\n",
      "evaluation/Returns Mean              2255.34\n",
      "evaluation/Returns Std               1043.42\n",
      "evaluation/Returns Max               3629.25\n",
      "evaluation/Returns Min               1077.43\n",
      "evaluation/Estimation Bias Mean      1029.52\n",
      "evaluation/Estimation Bias Std        457.913\n",
      "evaluation/EB/Q_True Mean              43.0186\n",
      "evaluation/EB/Q_True Std              114.295\n",
      "evaluation/EB/Q_Pred Mean            1072.54\n",
      "evaluation/EB/Q_Pred Std              420.224\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2255.34\n",
      "evaluation/Actions Mean                 0.0592788\n",
      "evaluation/Actions Std                  0.605325\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75284\n",
      "time/backward_zf1 (s)                   1.86707\n",
      "time/backward_zf2 (s)                   1.80449\n",
      "time/data sampling (s)                  0.256193\n",
      "time/data storing (s)                   0.0138858\n",
      "time/evaluation sampling (s)            1.47977\n",
      "time/exploration sampling (s)           0.173152\n",
      "time/logging (s)                        0.0109385\n",
      "time/preback_alpha (s)                  0.551091\n",
      "time/preback_policy (s)                 0.617603\n",
      "time/preback_start (s)                  0.125203\n",
      "time/preback_zf (s)                     4.95741\n",
      "time/saving (s)                         0.00513893\n",
      "time/training (s)                       2.50138\n",
      "time/epoch (s)                         16.1162\n",
      "time/total (s)                       3097.27\n",
      "Epoch                                 198\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:53:07.972090 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 199 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 210000\n",
      "trainer/ZF1 Loss                       93.3848\n",
      "trainer/ZF2 Loss                       98.2276\n",
      "trainer/ZF Expert Reward               16.2622\n",
      "trainer/ZF Policy Reward               -0.132147\n",
      "trainer/ZF CHI2 Term                  126.96\n",
      "trainer/Policy Loss                  -829.433\n",
      "trainer/Policy Grad Norm              486.948\n",
      "trainer/Policy Param Norm              42.3942\n",
      "trainer/Zf1 Grad Norm              131577\n",
      "trainer/Zf1 Param Norm                119.201\n",
      "trainer/Zf2 Grad Norm               99905.7\n",
      "trainer/Zf2 Param Norm                114.871\n",
      "trainer/Z Expert Predictions Mean    1225.66\n",
      "trainer/Z Expert Predictions Std      271.23\n",
      "trainer/Z Expert Predictions Max     1715.52\n",
      "trainer/Z Expert Predictions Min      319.328\n",
      "trainer/Z Policy Predictions Mean     821.126\n",
      "trainer/Z Policy Predictions Std      496.771\n",
      "trainer/Z Policy Predictions Max     1602.05\n",
      "trainer/Z Policy Predictions Min     -484.031\n",
      "trainer/Z Expert Targets Mean        1209.4\n",
      "trainer/Z Expert Targets Std          270.035\n",
      "trainer/Z Expert Targets Max         1693.75\n",
      "trainer/Z Expert Targets Min          306.661\n",
      "trainer/Z Policy Targets Mean         821.258\n",
      "trainer/Z Policy Targets Std          485.996\n",
      "trainer/Z Policy Targets Max         1610.41\n",
      "trainer/Z Policy Targets Min         -462.246\n",
      "trainer/Log Pis Mean                   14.9085\n",
      "trainer/Log Pis Std                     6.08236\n",
      "trainer/Policy mu Mean                  0.704834\n",
      "trainer/Policy mu Std                   3.54115\n",
      "trainer/Policy log std Mean            -3.94146\n",
      "trainer/Policy log std Std              1.36921\n",
      "exploration/num steps total        206748\n",
      "exploration/num paths total          1053\n",
      "evaluation/num steps total              1.40702e+06\n",
      "evaluation/num paths total           2040\n",
      "evaluation/path length Mean           334.6\n",
      "evaluation/path length Std              2.45764\n",
      "evaluation/path length Max            339\n",
      "evaluation/path length Min            331\n",
      "evaluation/Rewards Mean                 3.32349\n",
      "evaluation/Rewards Std                  0.817543\n",
      "evaluation/Rewards Max                  4.60081\n",
      "evaluation/Rewards Min                  0.69045\n",
      "evaluation/Returns Mean              1112.04\n",
      "evaluation/Returns Std                  4.74836\n",
      "evaluation/Returns Max               1122.56\n",
      "evaluation/Returns Min               1104.91\n",
      "evaluation/Estimation Bias Mean       893.122\n",
      "evaluation/Estimation Bias Std        495.467\n",
      "evaluation/EB/Q_True Mean              25.6897\n",
      "evaluation/EB/Q_True Std               81.3915\n",
      "evaluation/EB/Q_Pred Mean             918.812\n",
      "evaluation/EB/Q_Pred Std              493.054\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1112.04\n",
      "evaluation/Actions Mean                 0.0368544\n",
      "evaluation/Actions Std                  0.601796\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.64784\n",
      "time/backward_zf1 (s)                   1.78187\n",
      "time/backward_zf2 (s)                   1.69379\n",
      "time/data sampling (s)                  0.250116\n",
      "time/data storing (s)                   0.0136801\n",
      "time/evaluation sampling (s)            0.980657\n",
      "time/exploration sampling (s)           0.171004\n",
      "time/logging (s)                        0.00463461\n",
      "time/preback_alpha (s)                  0.549869\n",
      "time/preback_policy (s)                 0.601872\n",
      "time/preback_start (s)                  0.124269\n",
      "time/preback_zf (s)                     4.95486\n",
      "time/saving (s)                         0.00481941\n",
      "time/training (s)                       2.69216\n",
      "time/epoch (s)                         15.4715\n",
      "time/total (s)                       3112.76\n",
      "Epoch                                 199\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:53:24.050906 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 200 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 211000\n",
      "trainer/ZF1 Loss                      116.481\n",
      "trainer/ZF2 Loss                       85.6709\n",
      "trainer/ZF Expert Reward               20.4246\n",
      "trainer/ZF Policy Reward                2.78754\n",
      "trainer/ZF CHI2 Term                  132.7\n",
      "trainer/Policy Loss                  -871.966\n",
      "trainer/Policy Grad Norm             1192.98\n",
      "trainer/Policy Param Norm              42.4622\n",
      "trainer/Zf1 Grad Norm               65559.6\n",
      "trainer/Zf1 Param Norm                119.39\n",
      "trainer/Zf2 Grad Norm               53047.2\n",
      "trainer/Zf2 Param Norm                115.043\n",
      "trainer/Z Expert Predictions Mean    1242.06\n",
      "trainer/Z Expert Predictions Std      262.72\n",
      "trainer/Z Expert Predictions Max     1754.74\n",
      "trainer/Z Expert Predictions Min      309.224\n",
      "trainer/Z Policy Predictions Mean     869.895\n",
      "trainer/Z Policy Predictions Std      498.73\n",
      "trainer/Z Policy Predictions Max     1651.26\n",
      "trainer/Z Policy Predictions Min     -437.216\n",
      "trainer/Z Expert Targets Mean        1221.63\n",
      "trainer/Z Expert Targets Std          258.561\n",
      "trainer/Z Expert Targets Max         1731.7\n",
      "trainer/Z Expert Targets Min          286.741\n",
      "trainer/Z Policy Targets Mean         867.107\n",
      "trainer/Z Policy Targets Std          491.745\n",
      "trainer/Z Policy Targets Max         1672.15\n",
      "trainer/Z Policy Targets Min         -468.855\n",
      "trainer/Log Pis Mean                   14.1284\n",
      "trainer/Log Pis Std                     5.15908\n",
      "trainer/Policy mu Mean                  0.293585\n",
      "trainer/Policy mu Std                   2.5826\n",
      "trainer/Policy log std Mean            -4.2153\n",
      "trainer/Policy log std Std              1.1889\n",
      "exploration/num steps total        206748\n",
      "exploration/num paths total          1053\n",
      "evaluation/num steps total              1.41702e+06\n",
      "evaluation/num paths total           2050\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.49458\n",
      "evaluation/Rewards Std                  0.599404\n",
      "evaluation/Rewards Max                  4.80071\n",
      "evaluation/Rewards Min                  0.660266\n",
      "evaluation/Returns Mean              3494.58\n",
      "evaluation/Returns Std                 18.1505\n",
      "evaluation/Returns Max               3517.82\n",
      "evaluation/Returns Min               3449.38\n",
      "evaluation/Estimation Bias Mean      1102.51\n",
      "evaluation/Estimation Bias Std        230.088\n",
      "evaluation/EB/Q_True Mean              32.2848\n",
      "evaluation/EB/Q_True Std               99.8233\n",
      "evaluation/EB/Q_Pred Mean            1134.8\n",
      "evaluation/EB/Q_Pred Std              209.019\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3494.58\n",
      "evaluation/Actions Mean                 0.0509899\n",
      "evaluation/Actions Std                  0.587836\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75807\n",
      "time/backward_zf1 (s)                   1.85201\n",
      "time/backward_zf2 (s)                   1.80865\n",
      "time/data sampling (s)                  0.223598\n",
      "time/data storing (s)                   0.0134187\n",
      "time/evaluation sampling (s)            1.4852\n",
      "time/exploration sampling (s)           0.167071\n",
      "time/logging (s)                        0.0116259\n",
      "time/preback_alpha (s)                  0.543226\n",
      "time/preback_policy (s)                 0.609939\n",
      "time/preback_start (s)                  0.122386\n",
      "time/preback_zf (s)                     4.93519\n",
      "time/saving (s)                         0.00535598\n",
      "time/training (s)                       2.48734\n",
      "time/epoch (s)                         16.0231\n",
      "time/total (s)                       3128.8\n",
      "Epoch                                 200\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:53:40.052029 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 201 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 212000\n",
      "trainer/ZF1 Loss                      104.192\n",
      "trainer/ZF2 Loss                       93.9669\n",
      "trainer/ZF Expert Reward                2.28758\n",
      "trainer/ZF Policy Reward              -11.3647\n",
      "trainer/ZF CHI2 Term                  126.456\n",
      "trainer/Policy Loss                  -875.319\n",
      "trainer/Policy Grad Norm              607.591\n",
      "trainer/Policy Param Norm              42.5252\n",
      "trainer/Zf1 Grad Norm               90982.4\n",
      "trainer/Zf1 Param Norm                119.581\n",
      "trainer/Zf2 Grad Norm               57192\n",
      "trainer/Zf2 Param Norm                115.236\n",
      "trainer/Z Expert Predictions Mean    1193.17\n",
      "trainer/Z Expert Predictions Std      279.955\n",
      "trainer/Z Expert Predictions Max     1665.39\n",
      "trainer/Z Expert Predictions Min      165.612\n",
      "trainer/Z Policy Predictions Mean     862.846\n",
      "trainer/Z Policy Predictions Std      473.161\n",
      "trainer/Z Policy Predictions Max     1598.26\n",
      "trainer/Z Policy Predictions Min     -444.887\n",
      "trainer/Z Expert Targets Mean        1190.88\n",
      "trainer/Z Expert Targets Std          279.413\n",
      "trainer/Z Expert Targets Max         1666.77\n",
      "trainer/Z Expert Targets Min          242.302\n",
      "trainer/Z Policy Targets Mean         874.211\n",
      "trainer/Z Policy Targets Std          475.122\n",
      "trainer/Z Policy Targets Max         1573.7\n",
      "trainer/Z Policy Targets Min         -442.088\n",
      "trainer/Log Pis Mean                   13.8622\n",
      "trainer/Log Pis Std                     4.44993\n",
      "trainer/Policy mu Mean                  0.215583\n",
      "trainer/Policy mu Std                   3.03897\n",
      "trainer/Policy log std Mean            -4.10571\n",
      "trainer/Policy log std Std              1.18158\n",
      "exploration/num steps total        207748\n",
      "exploration/num paths total          1054\n",
      "evaluation/num steps total              1.42702e+06\n",
      "evaluation/num paths total           2060\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.48876\n",
      "evaluation/Rewards Std                  0.587805\n",
      "evaluation/Rewards Max                  4.69258\n",
      "evaluation/Rewards Min                  0.662432\n",
      "evaluation/Returns Mean              3488.76\n",
      "evaluation/Returns Std                  7.15517\n",
      "evaluation/Returns Max               3500.3\n",
      "evaluation/Returns Min               3478.01\n",
      "evaluation/Estimation Bias Mean      1120.14\n",
      "evaluation/Estimation Bias Std        220.418\n",
      "evaluation/EB/Q_True Mean              32.2987\n",
      "evaluation/EB/Q_True Std               99.4771\n",
      "evaluation/EB/Q_Pred Mean            1152.44\n",
      "evaluation/EB/Q_Pred Std              201.439\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3488.76\n",
      "evaluation/Actions Mean                 0.0423433\n",
      "evaluation/Actions Std                  0.578517\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.68723\n",
      "time/backward_zf1 (s)                   1.81054\n",
      "time/backward_zf2 (s)                   1.73462\n",
      "time/data sampling (s)                  0.251068\n",
      "time/data storing (s)                   0.013644\n",
      "time/evaluation sampling (s)            1.39394\n",
      "time/exploration sampling (s)           0.168856\n",
      "time/logging (s)                        0.0115004\n",
      "time/preback_alpha (s)                  0.547166\n",
      "time/preback_policy (s)                 0.604867\n",
      "time/preback_start (s)                  0.124705\n",
      "time/preback_zf (s)                     4.94796\n",
      "time/saving (s)                         0.00501484\n",
      "time/training (s)                       2.6355\n",
      "time/epoch (s)                         15.9366\n",
      "time/total (s)                       3144.76\n",
      "Epoch                                 201\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:53:55.684369 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 202 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 213000\n",
      "trainer/ZF1 Loss                      285.289\n",
      "trainer/ZF2 Loss                      308.693\n",
      "trainer/ZF Expert Reward               17.6757\n",
      "trainer/ZF Policy Reward                5.79651\n",
      "trainer/ZF CHI2 Term                  322.921\n",
      "trainer/Policy Loss                  -880.725\n",
      "trainer/Policy Grad Norm             1060.64\n",
      "trainer/Policy Param Norm              42.5932\n",
      "trainer/Zf1 Grad Norm               24388.5\n",
      "trainer/Zf1 Param Norm                119.782\n",
      "trainer/Zf2 Grad Norm               31420.2\n",
      "trainer/Zf2 Param Norm                115.423\n",
      "trainer/Z Expert Predictions Mean    1233.32\n",
      "trainer/Z Expert Predictions Std      246.785\n",
      "trainer/Z Expert Predictions Max     1700.64\n",
      "trainer/Z Expert Predictions Min      508.092\n",
      "trainer/Z Policy Predictions Mean     879.262\n",
      "trainer/Z Policy Predictions Std      452.75\n",
      "trainer/Z Policy Predictions Max     1642.56\n",
      "trainer/Z Policy Predictions Min     -412.436\n",
      "trainer/Z Expert Targets Mean        1215.65\n",
      "trainer/Z Expert Targets Std          253.281\n",
      "trainer/Z Expert Targets Max         1696.27\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         873.466\n",
      "trainer/Z Policy Targets Std          453.901\n",
      "trainer/Z Policy Targets Max         1606.37\n",
      "trainer/Z Policy Targets Min         -409.862\n",
      "trainer/Log Pis Mean                   14.1932\n",
      "trainer/Log Pis Std                     5.07085\n",
      "trainer/Policy mu Mean                  0.517129\n",
      "trainer/Policy mu Std                   3.11723\n",
      "trainer/Policy log std Mean            -4.1168\n",
      "trainer/Policy log std Std              1.27711\n",
      "exploration/num steps total        208479\n",
      "exploration/num paths total          1055\n",
      "evaluation/num steps total              1.43011e+06\n",
      "evaluation/num paths total           2070\n",
      "evaluation/path length Mean           308.8\n",
      "evaluation/path length Std             33.9258\n",
      "evaluation/path length Max            332\n",
      "evaluation/path length Min            256\n",
      "evaluation/Rewards Mean                 3.2857\n",
      "evaluation/Rewards Std                  0.829461\n",
      "evaluation/Rewards Max                  4.5826\n",
      "evaluation/Rewards Min                  0.635285\n",
      "evaluation/Returns Mean              1014.62\n",
      "evaluation/Returns Std                130.086\n",
      "evaluation/Returns Max               1103.36\n",
      "evaluation/Returns Min                814.628\n",
      "evaluation/Estimation Bias Mean       932.417\n",
      "evaluation/Estimation Bias Std        371.063\n",
      "evaluation/EB/Q_True Mean              27.2283\n",
      "evaluation/EB/Q_True Std               83.5697\n",
      "evaluation/EB/Q_Pred Mean             959.645\n",
      "evaluation/EB/Q_Pred Std              364.897\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1014.62\n",
      "evaluation/Actions Mean                 0.0392899\n",
      "evaluation/Actions Std                  0.607746\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81512\n",
      "time/backward_zf1 (s)                   1.91809\n",
      "time/backward_zf2 (s)                   1.86502\n",
      "time/data sampling (s)                  0.251548\n",
      "time/data storing (s)                   0.013993\n",
      "time/evaluation sampling (s)            0.831111\n",
      "time/exploration sampling (s)           0.171614\n",
      "time/logging (s)                        0.00432973\n",
      "time/preback_alpha (s)                  0.553977\n",
      "time/preback_policy (s)                 0.623194\n",
      "time/preback_start (s)                  0.124133\n",
      "time/preback_zf (s)                     4.97938\n",
      "time/saving (s)                         0.0048065\n",
      "time/training (s)                       2.39828\n",
      "time/epoch (s)                         15.5546\n",
      "time/total (s)                       3160.34\n",
      "Epoch                                 202\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:54:11.872279 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 203 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 214000\n",
      "trainer/ZF1 Loss                      101.877\n",
      "trainer/ZF2 Loss                      133.621\n",
      "trainer/ZF Expert Reward                7.58339\n",
      "trainer/ZF Policy Reward               -4.48436\n",
      "trainer/ZF CHI2 Term                  143.073\n",
      "trainer/Policy Loss                  -864.777\n",
      "trainer/Policy Grad Norm              694.793\n",
      "trainer/Policy Param Norm              42.6677\n",
      "trainer/Zf1 Grad Norm               58663.5\n",
      "trainer/Zf1 Param Norm                119.98\n",
      "trainer/Zf2 Grad Norm               38394.9\n",
      "trainer/Zf2 Param Norm                115.611\n",
      "trainer/Z Expert Predictions Mean    1205.71\n",
      "trainer/Z Expert Predictions Std      256.002\n",
      "trainer/Z Expert Predictions Max     1721.45\n",
      "trainer/Z Expert Predictions Min      300.016\n",
      "trainer/Z Policy Predictions Mean     862.624\n",
      "trainer/Z Policy Predictions Std      457.91\n",
      "trainer/Z Policy Predictions Max     1614.12\n",
      "trainer/Z Policy Predictions Min     -419.393\n",
      "trainer/Z Expert Targets Mean        1198.12\n",
      "trainer/Z Expert Targets Std          256.683\n",
      "trainer/Z Expert Targets Max         1699.33\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         867.108\n",
      "trainer/Z Policy Targets Std          456.702\n",
      "trainer/Z Policy Targets Max         1592.06\n",
      "trainer/Z Policy Targets Min         -413.774\n",
      "trainer/Log Pis Mean                   13.3899\n",
      "trainer/Log Pis Std                     4.54213\n",
      "trainer/Policy mu Mean                  0.363804\n",
      "trainer/Policy mu Std                   2.23618\n",
      "trainer/Policy log std Mean            -4.3566\n",
      "trainer/Policy log std Std              1.00892\n",
      "exploration/num steps total        209479\n",
      "exploration/num paths total          1056\n",
      "evaluation/num steps total              1.44011e+06\n",
      "evaluation/num paths total           2080\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.5371\n",
      "evaluation/Rewards Std                  0.601296\n",
      "evaluation/Rewards Max                  4.71034\n",
      "evaluation/Rewards Min                  0.706104\n",
      "evaluation/Returns Mean              3537.1\n",
      "evaluation/Returns Std                 14.2616\n",
      "evaluation/Returns Max               3560.7\n",
      "evaluation/Returns Min               3509.34\n",
      "evaluation/Estimation Bias Mean      1167.05\n",
      "evaluation/Estimation Bias Std        253.232\n",
      "evaluation/EB/Q_True Mean              32.7682\n",
      "evaluation/EB/Q_True Std              100.982\n",
      "evaluation/EB/Q_Pred Mean            1199.81\n",
      "evaluation/EB/Q_Pred Std              233.748\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3537.1\n",
      "evaluation/Actions Mean                 0.0398787\n",
      "evaluation/Actions Std                  0.591958\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8441\n",
      "time/backward_zf1 (s)                   1.94225\n",
      "time/backward_zf2 (s)                   1.89484\n",
      "time/data sampling (s)                  0.237292\n",
      "time/data storing (s)                   0.0135098\n",
      "time/evaluation sampling (s)            1.39789\n",
      "time/exploration sampling (s)           0.167374\n",
      "time/logging (s)                        0.0199147\n",
      "time/preback_alpha (s)                  0.552346\n",
      "time/preback_policy (s)                 0.629569\n",
      "time/preback_start (s)                  0.124261\n",
      "time/preback_zf (s)                     4.98584\n",
      "time/saving (s)                         0.0167429\n",
      "time/training (s)                       2.31461\n",
      "time/epoch (s)                         16.1406\n",
      "time/total (s)                       3176.5\n",
      "Epoch                                 203\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:54:27.945909 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 204 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 215000\n",
      "trainer/ZF1 Loss                      234.454\n",
      "trainer/ZF2 Loss                      232.645\n",
      "trainer/ZF Expert Reward               23.827\n",
      "trainer/ZF Policy Reward                0.951048\n",
      "trainer/ZF CHI2 Term                  270.115\n",
      "trainer/Policy Loss                  -923.001\n",
      "trainer/Policy Grad Norm              757.784\n",
      "trainer/Policy Param Norm              42.7475\n",
      "trainer/Zf1 Grad Norm              105706\n",
      "trainer/Zf1 Param Norm                120.169\n",
      "trainer/Zf2 Grad Norm               55315.3\n",
      "trainer/Zf2 Param Norm                115.795\n",
      "trainer/Z Expert Predictions Mean    1205.71\n",
      "trainer/Z Expert Predictions Std      282.666\n",
      "trainer/Z Expert Predictions Max     1766.4\n",
      "trainer/Z Expert Predictions Min      147.803\n",
      "trainer/Z Policy Predictions Mean     919.974\n",
      "trainer/Z Policy Predictions Std      464.433\n",
      "trainer/Z Policy Predictions Max     1716.35\n",
      "trainer/Z Policy Predictions Min     -383.24\n",
      "trainer/Z Expert Targets Mean        1181.88\n",
      "trainer/Z Expert Targets Std          289.993\n",
      "trainer/Z Expert Targets Max         1733.87\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         919.023\n",
      "trainer/Z Policy Targets Std          454.245\n",
      "trainer/Z Policy Targets Max         1691.95\n",
      "trainer/Z Policy Targets Min         -375.825\n",
      "trainer/Log Pis Mean                   13.8281\n",
      "trainer/Log Pis Std                     4.7729\n",
      "trainer/Policy mu Mean                  0.435425\n",
      "trainer/Policy mu Std                   3.13206\n",
      "trainer/Policy log std Mean            -4.25624\n",
      "trainer/Policy log std Std              1.15919\n",
      "exploration/num steps total        209479\n",
      "exploration/num paths total          1056\n",
      "evaluation/num steps total              1.44845e+06\n",
      "evaluation/num paths total           2091\n",
      "evaluation/path length Mean           758.273\n",
      "evaluation/path length Std            319.776\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            334\n",
      "evaluation/Rewards Mean                 3.51243\n",
      "evaluation/Rewards Std                  0.639902\n",
      "evaluation/Rewards Max                  4.65719\n",
      "evaluation/Rewards Min                  0.660695\n",
      "evaluation/Returns Mean              2663.38\n",
      "evaluation/Returns Std               1172.45\n",
      "evaluation/Returns Max               3608.27\n",
      "evaluation/Returns Min               1107.56\n",
      "evaluation/Estimation Bias Mean      1106.24\n",
      "evaluation/Estimation Bias Std        331.969\n",
      "evaluation/EB/Q_True Mean              40.0688\n",
      "evaluation/EB/Q_True Std              111.499\n",
      "evaluation/EB/Q_Pred Mean            1146.31\n",
      "evaluation/EB/Q_Pred Std              291.362\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2663.38\n",
      "evaluation/Actions Mean                 0.0421752\n",
      "evaluation/Actions Std                  0.58922\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76061\n",
      "time/backward_zf1 (s)                   1.8652\n",
      "time/backward_zf2 (s)                   1.80423\n",
      "time/data sampling (s)                  0.258768\n",
      "time/data storing (s)                   0.0142255\n",
      "time/evaluation sampling (s)            1.33936\n",
      "time/exploration sampling (s)           0.170412\n",
      "time/logging (s)                        0.0098004\n",
      "time/preback_alpha (s)                  0.557757\n",
      "time/preback_policy (s)                 0.623377\n",
      "time/preback_start (s)                  0.124355\n",
      "time/preback_zf (s)                     5.00168\n",
      "time/saving (s)                         0.00535216\n",
      "time/training (s)                       2.46481\n",
      "time/epoch (s)                         15.9999\n",
      "time/total (s)                       3192.52\n",
      "Epoch                                 204\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:54:44.073539 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 205 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 216000\n",
      "trainer/ZF1 Loss                      102.89\n",
      "trainer/ZF2 Loss                      123.56\n",
      "trainer/ZF Expert Reward               10.7699\n",
      "trainer/ZF Policy Reward               -5.13027\n",
      "trainer/ZF CHI2 Term                  143.398\n",
      "trainer/Policy Loss                  -828.23\n",
      "trainer/Policy Grad Norm              515.125\n",
      "trainer/Policy Param Norm              42.8245\n",
      "trainer/Zf1 Grad Norm              120814\n",
      "trainer/Zf1 Param Norm                120.35\n",
      "trainer/Zf2 Grad Norm              159296\n",
      "trainer/Zf2 Param Norm                115.962\n",
      "trainer/Z Expert Predictions Mean    1220.03\n",
      "trainer/Z Expert Predictions Std      256.576\n",
      "trainer/Z Expert Predictions Max     1765.26\n",
      "trainer/Z Expert Predictions Min      557.575\n",
      "trainer/Z Policy Predictions Mean     809.423\n",
      "trainer/Z Policy Predictions Std      465.121\n",
      "trainer/Z Policy Predictions Max     1581.72\n",
      "trainer/Z Policy Predictions Min     -440.602\n",
      "trainer/Z Expert Targets Mean        1209.26\n",
      "trainer/Z Expert Targets Std          255.198\n",
      "trainer/Z Expert Targets Max         1729.55\n",
      "trainer/Z Expert Targets Min          541.896\n",
      "trainer/Z Policy Targets Mean         814.553\n",
      "trainer/Z Policy Targets Std          458.644\n",
      "trainer/Z Policy Targets Max         1478.04\n",
      "trainer/Z Policy Targets Min         -437.593\n",
      "trainer/Log Pis Mean                   14.4172\n",
      "trainer/Log Pis Std                     4.79997\n",
      "trainer/Policy mu Mean                  0.232184\n",
      "trainer/Policy mu Std                   2.59078\n",
      "trainer/Policy log std Mean            -4.24593\n",
      "trainer/Policy log std Std              1.03998\n",
      "exploration/num steps total        210479\n",
      "exploration/num paths total          1057\n",
      "evaluation/num steps total              1.45845e+06\n",
      "evaluation/num paths total           2101\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52941\n",
      "evaluation/Rewards Std                  0.605663\n",
      "evaluation/Rewards Max                  4.71622\n",
      "evaluation/Rewards Min                  0.673495\n",
      "evaluation/Returns Mean              3529.41\n",
      "evaluation/Returns Std                 20.5863\n",
      "evaluation/Returns Max               3570.73\n",
      "evaluation/Returns Min               3506.4\n",
      "evaluation/Estimation Bias Mean      1136.48\n",
      "evaluation/Estimation Bias Std        254.898\n",
      "evaluation/EB/Q_True Mean              32.4681\n",
      "evaluation/EB/Q_True Std               99.9847\n",
      "evaluation/EB/Q_Pred Mean            1168.95\n",
      "evaluation/EB/Q_Pred Std              230.396\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3529.41\n",
      "evaluation/Actions Mean                 0.0494194\n",
      "evaluation/Actions Std                  0.589176\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80792\n",
      "time/backward_zf1 (s)                   1.9369\n",
      "time/backward_zf2 (s)                   1.86496\n",
      "time/data sampling (s)                  0.252879\n",
      "time/data storing (s)                   0.0139368\n",
      "time/evaluation sampling (s)            1.3557\n",
      "time/exploration sampling (s)           0.169443\n",
      "time/logging (s)                        0.0115192\n",
      "time/preback_alpha (s)                  0.552836\n",
      "time/preback_policy (s)                 0.624649\n",
      "time/preback_start (s)                  0.123307\n",
      "time/preback_zf (s)                     4.98062\n",
      "time/saving (s)                         0.00550426\n",
      "time/training (s)                       2.36419\n",
      "time/epoch (s)                         16.0644\n",
      "time/total (s)                       3208.6\n",
      "Epoch                                 205\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:55:00.129429 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 206 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 217000\n",
      "trainer/ZF1 Loss                       80.4357\n",
      "trainer/ZF2 Loss                       64.8785\n",
      "trainer/ZF Expert Reward               14.3739\n",
      "trainer/ZF Policy Reward                2.39704\n",
      "trainer/ZF CHI2 Term                   98.8389\n",
      "trainer/Policy Loss                  -836.557\n",
      "trainer/Policy Grad Norm              592.215\n",
      "trainer/Policy Param Norm              42.8994\n",
      "trainer/Zf1 Grad Norm               82656.9\n",
      "trainer/Zf1 Param Norm                120.514\n",
      "trainer/Zf2 Grad Norm               57947.8\n",
      "trainer/Zf2 Param Norm                116.114\n",
      "trainer/Z Expert Predictions Mean    1207.19\n",
      "trainer/Z Expert Predictions Std      264.495\n",
      "trainer/Z Expert Predictions Max     1720.09\n",
      "trainer/Z Expert Predictions Min      353.971\n",
      "trainer/Z Policy Predictions Mean     831.98\n",
      "trainer/Z Policy Predictions Std      448.946\n",
      "trainer/Z Policy Predictions Max     1573.93\n",
      "trainer/Z Policy Predictions Min     -490.735\n",
      "trainer/Z Expert Targets Mean        1192.82\n",
      "trainer/Z Expert Targets Std          265.92\n",
      "trainer/Z Expert Targets Max         1724.59\n",
      "trainer/Z Expert Targets Min          332.558\n",
      "trainer/Z Policy Targets Mean         829.583\n",
      "trainer/Z Policy Targets Std          444.082\n",
      "trainer/Z Policy Targets Max         1537.43\n",
      "trainer/Z Policy Targets Min         -501.98\n",
      "trainer/Log Pis Mean                   14.3483\n",
      "trainer/Log Pis Std                     5.49025\n",
      "trainer/Policy mu Mean                  0.39562\n",
      "trainer/Policy mu Std                   2.8714\n",
      "trainer/Policy log std Mean            -4.00074\n",
      "trainer/Policy log std Std              1.32919\n",
      "exploration/num steps total        210479\n",
      "exploration/num paths total          1057\n",
      "evaluation/num steps total              1.46845e+06\n",
      "evaluation/num paths total           2111\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51616\n",
      "evaluation/Rewards Std                  0.600866\n",
      "evaluation/Rewards Max                  4.7528\n",
      "evaluation/Rewards Min                  0.654143\n",
      "evaluation/Returns Mean              3516.16\n",
      "evaluation/Returns Std                 19.4041\n",
      "evaluation/Returns Max               3550.61\n",
      "evaluation/Returns Min               3490.64\n",
      "evaluation/Estimation Bias Mean      1095.01\n",
      "evaluation/Estimation Bias Std        237.044\n",
      "evaluation/EB/Q_True Mean              32.4853\n",
      "evaluation/EB/Q_True Std              100.119\n",
      "evaluation/EB/Q_Pred Mean            1127.49\n",
      "evaluation/EB/Q_Pred Std              208.918\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3516.16\n",
      "evaluation/Actions Mean                 0.0433607\n",
      "evaluation/Actions Std                  0.589431\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.6891\n",
      "time/backward_zf1 (s)                   1.80277\n",
      "time/backward_zf2 (s)                   1.72776\n",
      "time/data sampling (s)                  0.251265\n",
      "time/data storing (s)                   0.0138984\n",
      "time/evaluation sampling (s)            1.40339\n",
      "time/exploration sampling (s)           0.1677\n",
      "time/logging (s)                        0.0133784\n",
      "time/preback_alpha (s)                  0.551948\n",
      "time/preback_policy (s)                 0.599068\n",
      "time/preback_start (s)                  0.123101\n",
      "time/preback_zf (s)                     4.96822\n",
      "time/saving (s)                         0.00614896\n",
      "time/training (s)                       2.67269\n",
      "time/epoch (s)                         15.9904\n",
      "time/total (s)                       3224.61\n",
      "Epoch                                 206\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:55:15.284973 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 207 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 218000\n",
      "trainer/ZF1 Loss                       67.9774\n",
      "trainer/ZF2 Loss                       65.7202\n",
      "trainer/ZF Expert Reward                7.97521\n",
      "trainer/ZF Policy Reward               -6.28002\n",
      "trainer/ZF CHI2 Term                   94.7725\n",
      "trainer/Policy Loss                  -833.969\n",
      "trainer/Policy Grad Norm              849.025\n",
      "trainer/Policy Param Norm              42.9733\n",
      "trainer/Zf1 Grad Norm               32933.2\n",
      "trainer/Zf1 Param Norm                120.67\n",
      "trainer/Zf2 Grad Norm               62518.6\n",
      "trainer/Zf2 Param Norm                116.267\n",
      "trainer/Z Expert Predictions Mean    1187.23\n",
      "trainer/Z Expert Predictions Std      263.801\n",
      "trainer/Z Expert Predictions Max     1749.47\n",
      "trainer/Z Expert Predictions Min      287.786\n",
      "trainer/Z Policy Predictions Mean     823.112\n",
      "trainer/Z Policy Predictions Std      441.657\n",
      "trainer/Z Policy Predictions Max     1621.16\n",
      "trainer/Z Policy Predictions Min     -454.873\n",
      "trainer/Z Expert Targets Mean        1179.26\n",
      "trainer/Z Expert Targets Std          264.493\n",
      "trainer/Z Expert Targets Max         1713.06\n",
      "trainer/Z Expert Targets Min          308.042\n",
      "trainer/Z Policy Targets Mean         829.392\n",
      "trainer/Z Policy Targets Std          440.329\n",
      "trainer/Z Policy Targets Max         1607.78\n",
      "trainer/Z Policy Targets Min         -384.622\n",
      "trainer/Log Pis Mean                   13.8066\n",
      "trainer/Log Pis Std                     4.87091\n",
      "trainer/Policy mu Mean                  0.507531\n",
      "trainer/Policy mu Std                   2.84745\n",
      "trainer/Policy log std Mean            -4.10138\n",
      "trainer/Policy log std Std              1.21813\n",
      "exploration/num steps total        211479\n",
      "exploration/num paths total          1058\n",
      "evaluation/num steps total              1.47139e+06\n",
      "evaluation/num paths total           2121\n",
      "evaluation/path length Mean           294.4\n",
      "evaluation/path length Std             35.2114\n",
      "evaluation/path length Max            331\n",
      "evaluation/path length Min            258\n",
      "evaluation/Rewards Mean                 3.26687\n",
      "evaluation/Rewards Std                  0.84993\n",
      "evaluation/Rewards Max                  4.69605\n",
      "evaluation/Rewards Min                  0.688396\n",
      "evaluation/Returns Mean               961.765\n",
      "evaluation/Returns Std                139.535\n",
      "evaluation/Returns Max               1104.31\n",
      "evaluation/Returns Min                817.261\n",
      "evaluation/Estimation Bias Mean       785.976\n",
      "evaluation/Estimation Bias Std        493.927\n",
      "evaluation/EB/Q_True Mean              28.9112\n",
      "evaluation/EB/Q_True Std               85.9417\n",
      "evaluation/EB/Q_Pred Mean             814.887\n",
      "evaluation/EB/Q_Pred Std              491.78\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            961.765\n",
      "evaluation/Actions Mean                 0.0402796\n",
      "evaluation/Actions Std                  0.613333\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81203\n",
      "time/backward_zf1 (s)                   1.89336\n",
      "time/backward_zf2 (s)                   1.84988\n",
      "time/data sampling (s)                  0.23592\n",
      "time/data storing (s)                   0.0142931\n",
      "time/evaluation sampling (s)            0.499761\n",
      "time/exploration sampling (s)           0.173686\n",
      "time/logging (s)                        0.00478905\n",
      "time/preback_alpha (s)                  0.548891\n",
      "time/preback_policy (s)                 0.625695\n",
      "time/preback_start (s)                  0.123494\n",
      "time/preback_zf (s)                     4.93544\n",
      "time/saving (s)                         0.00503041\n",
      "time/training (s)                       2.36099\n",
      "time/epoch (s)                         15.0833\n",
      "time/total (s)                       3239.71\n",
      "Epoch                                 207\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:55:31.360463 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 208 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 219000\n",
      "trainer/ZF1 Loss                       64.3044\n",
      "trainer/ZF2 Loss                       92.2254\n",
      "trainer/ZF Expert Reward               13.1521\n",
      "trainer/ZF Policy Reward               -0.118586\n",
      "trainer/ZF CHI2 Term                  105.51\n",
      "trainer/Policy Loss                  -833.863\n",
      "trainer/Policy Grad Norm             1052.74\n",
      "trainer/Policy Param Norm              43.043\n",
      "trainer/Zf1 Grad Norm               42359.4\n",
      "trainer/Zf1 Param Norm                120.84\n",
      "trainer/Zf2 Grad Norm               55718.5\n",
      "trainer/Zf2 Param Norm                116.441\n",
      "trainer/Z Expert Predictions Mean    1187.13\n",
      "trainer/Z Expert Predictions Std      269.506\n",
      "trainer/Z Expert Predictions Max     1706.43\n",
      "trainer/Z Expert Predictions Min       48.4709\n",
      "trainer/Z Policy Predictions Mean     822.423\n",
      "trainer/Z Policy Predictions Std      471.663\n",
      "trainer/Z Policy Predictions Max     1603.92\n",
      "trainer/Z Policy Predictions Min     -427.082\n",
      "trainer/Z Expert Targets Mean        1173.98\n",
      "trainer/Z Expert Targets Std          269.582\n",
      "trainer/Z Expert Targets Max         1695.77\n",
      "trainer/Z Expert Targets Min          -16.7117\n",
      "trainer/Z Policy Targets Mean         822.541\n",
      "trainer/Z Policy Targets Std          466.683\n",
      "trainer/Z Policy Targets Max         1651.31\n",
      "trainer/Z Policy Targets Min         -413.805\n",
      "trainer/Log Pis Mean                   14.1153\n",
      "trainer/Log Pis Std                     5.73747\n",
      "trainer/Policy mu Mean                  0.472558\n",
      "trainer/Policy mu Std                   2.87206\n",
      "trainer/Policy log std Mean            -4.12046\n",
      "trainer/Policy log std Std              1.1922\n",
      "exploration/num steps total        215132\n",
      "exploration/num paths total          1062\n",
      "evaluation/num steps total              1.47556e+06\n",
      "evaluation/num paths total           2131\n",
      "evaluation/path length Mean           416.7\n",
      "evaluation/path length Std            189.572\n",
      "evaluation/path length Max            976\n",
      "evaluation/path length Min            324\n",
      "evaluation/Rewards Mean                 3.42903\n",
      "evaluation/Rewards Std                  0.792911\n",
      "evaluation/Rewards Max                  5.18888\n",
      "evaluation/Rewards Min                  0.695312\n",
      "evaluation/Returns Mean              1428.88\n",
      "evaluation/Returns Std                701.884\n",
      "evaluation/Returns Max               3494.65\n",
      "evaluation/Returns Min               1086.96\n",
      "evaluation/Estimation Bias Mean       753.786\n",
      "evaluation/Estimation Bias Std        488.416\n",
      "evaluation/EB/Q_True Mean              77.479\n",
      "evaluation/EB/Q_True Std              144.316\n",
      "evaluation/EB/Q_Pred Mean             831.265\n",
      "evaluation/EB/Q_Pred Std              473.733\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1428.88\n",
      "evaluation/Actions Mean                 0.0407783\n",
      "evaluation/Actions Std                  0.604878\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74763\n",
      "time/backward_zf1 (s)                   1.85323\n",
      "time/backward_zf2 (s)                   1.78762\n",
      "time/data sampling (s)                  0.247118\n",
      "time/data storing (s)                   0.0140736\n",
      "time/evaluation sampling (s)            1.31917\n",
      "time/exploration sampling (s)           0.176974\n",
      "time/logging (s)                        0.00637494\n",
      "time/preback_alpha (s)                  0.553015\n",
      "time/preback_policy (s)                 0.614229\n",
      "time/preback_start (s)                  0.125801\n",
      "time/preback_zf (s)                     4.97932\n",
      "time/saving (s)                         0.00552154\n",
      "time/training (s)                       2.58198\n",
      "time/epoch (s)                         16.0121\n",
      "time/total (s)                       3255.74\n",
      "Epoch                                 208\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:55:47.452918 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 209 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 220000\n",
      "trainer/ZF1 Loss                      183.389\n",
      "trainer/ZF2 Loss                      130.244\n",
      "trainer/ZF Expert Reward                8.03828\n",
      "trainer/ZF Policy Reward               -5.31826\n",
      "trainer/ZF CHI2 Term                  184.409\n",
      "trainer/Policy Loss                  -838.845\n",
      "trainer/Policy Grad Norm              595.058\n",
      "trainer/Policy Param Norm              43.1196\n",
      "trainer/Zf1 Grad Norm               52402.9\n",
      "trainer/Zf1 Param Norm                120.998\n",
      "trainer/Zf2 Grad Norm               70361\n",
      "trainer/Zf2 Param Norm                116.597\n",
      "trainer/Z Expert Predictions Mean    1188.8\n",
      "trainer/Z Expert Predictions Std      259.421\n",
      "trainer/Z Expert Predictions Max     1698.66\n",
      "trainer/Z Expert Predictions Min      140.883\n",
      "trainer/Z Policy Predictions Mean     822.702\n",
      "trainer/Z Policy Predictions Std      449.061\n",
      "trainer/Z Policy Predictions Max     1646.56\n",
      "trainer/Z Policy Predictions Min     -354.037\n",
      "trainer/Z Expert Targets Mean        1180.77\n",
      "trainer/Z Expert Targets Std          257.462\n",
      "trainer/Z Expert Targets Max         1705.53\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         828.02\n",
      "trainer/Z Policy Targets Std          445.196\n",
      "trainer/Z Policy Targets Max         1659.34\n",
      "trainer/Z Policy Targets Min         -296.631\n",
      "trainer/Log Pis Mean                   14.3799\n",
      "trainer/Log Pis Std                     5.94172\n",
      "trainer/Policy mu Mean                  0.295248\n",
      "trainer/Policy mu Std                   2.70053\n",
      "trainer/Policy log std Mean            -4.13549\n",
      "trainer/Policy log std Std              1.14431\n",
      "exploration/num steps total        217132\n",
      "exploration/num paths total          1064\n",
      "evaluation/num steps total              1.48489e+06\n",
      "evaluation/num paths total           2141\n",
      "evaluation/path length Mean           933.4\n",
      "evaluation/path length Std            199.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            334\n",
      "evaluation/Rewards Mean                 3.52317\n",
      "evaluation/Rewards Std                  0.611161\n",
      "evaluation/Rewards Max                  4.66188\n",
      "evaluation/Rewards Min                  0.674983\n",
      "evaluation/Returns Mean              3288.53\n",
      "evaluation/Returns Std                727.609\n",
      "evaluation/Returns Max               3557\n",
      "evaluation/Returns Min               1106.22\n",
      "evaluation/Estimation Bias Mean      1098.33\n",
      "evaluation/Estimation Bias Std        262.915\n",
      "evaluation/EB/Q_True Mean              35.0912\n",
      "evaluation/EB/Q_True Std              104.128\n",
      "evaluation/EB/Q_Pred Mean            1133.42\n",
      "evaluation/EB/Q_Pred Std              244.005\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3288.53\n",
      "evaluation/Actions Mean                 0.0368821\n",
      "evaluation/Actions Std                  0.582909\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74161\n",
      "time/backward_zf1 (s)                   1.87367\n",
      "time/backward_zf2 (s)                   1.77902\n",
      "time/data sampling (s)                  0.234732\n",
      "time/data storing (s)                   0.0138122\n",
      "time/evaluation sampling (s)            1.39382\n",
      "time/exploration sampling (s)           0.175677\n",
      "time/logging (s)                        0.0112506\n",
      "time/preback_alpha (s)                  0.550765\n",
      "time/preback_policy (s)                 0.606648\n",
      "time/preback_start (s)                  0.125589\n",
      "time/preback_zf (s)                     4.97244\n",
      "time/saving (s)                         0.00501764\n",
      "time/training (s)                       2.54826\n",
      "time/epoch (s)                         16.0323\n",
      "time/total (s)                       3271.8\n",
      "Epoch                                 209\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:56:02.688044 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 210 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 221000\n",
      "trainer/ZF1 Loss                       87.5988\n",
      "trainer/ZF2 Loss                      110.612\n",
      "trainer/ZF Expert Reward                7.21801\n",
      "trainer/ZF Policy Reward               -9.15465\n",
      "trainer/ZF CHI2 Term                  129.574\n",
      "trainer/Policy Loss                  -865.681\n",
      "trainer/Policy Grad Norm              656.482\n",
      "trainer/Policy Param Norm              43.194\n",
      "trainer/Zf1 Grad Norm              163460\n",
      "trainer/Zf1 Param Norm                121.174\n",
      "trainer/Zf2 Grad Norm              160207\n",
      "trainer/Zf2 Param Norm                116.76\n",
      "trainer/Z Expert Predictions Mean    1169.95\n",
      "trainer/Z Expert Predictions Std      228.348\n",
      "trainer/Z Expert Predictions Max     1695.82\n",
      "trainer/Z Expert Predictions Min      524.799\n",
      "trainer/Z Policy Predictions Mean     849.838\n",
      "trainer/Z Policy Predictions Std      433.631\n",
      "trainer/Z Policy Predictions Max     1574.4\n",
      "trainer/Z Policy Predictions Min     -406.181\n",
      "trainer/Z Expert Targets Mean        1162.73\n",
      "trainer/Z Expert Targets Std          229.002\n",
      "trainer/Z Expert Targets Max         1692.8\n",
      "trainer/Z Expert Targets Min          521.421\n",
      "trainer/Z Policy Targets Mean         858.993\n",
      "trainer/Z Policy Targets Std          434.482\n",
      "trainer/Z Policy Targets Max         1564.34\n",
      "trainer/Z Policy Targets Min         -351.814\n",
      "trainer/Log Pis Mean                   14.2387\n",
      "trainer/Log Pis Std                     5.35555\n",
      "trainer/Policy mu Mean                  0.271454\n",
      "trainer/Policy mu Std                   2.57575\n",
      "trainer/Policy log std Mean            -4.17521\n",
      "trainer/Policy log std Std              1.19916\n",
      "exploration/num steps total        217132\n",
      "exploration/num paths total          1064\n",
      "evaluation/num steps total              1.4878e+06\n",
      "evaluation/num paths total           2151\n",
      "evaluation/path length Mean           290.9\n",
      "evaluation/path length Std             34.3874\n",
      "evaluation/path length Max            333\n",
      "evaluation/path length Min            258\n",
      "evaluation/Rewards Mean                 3.25462\n",
      "evaluation/Rewards Std                  0.846107\n",
      "evaluation/Rewards Max                  4.64336\n",
      "evaluation/Rewards Min                  0.674088\n",
      "evaluation/Returns Mean               946.77\n",
      "evaluation/Returns Std                134.179\n",
      "evaluation/Returns Max               1111.13\n",
      "evaluation/Returns Min                820.467\n",
      "evaluation/Estimation Bias Mean       875.669\n",
      "evaluation/Estimation Bias Std        421.344\n",
      "evaluation/EB/Q_True Mean              29.4446\n",
      "evaluation/EB/Q_True Std               86.7408\n",
      "evaluation/EB/Q_Pred Mean             905.114\n",
      "evaluation/EB/Q_Pred Std              417.148\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            946.77\n",
      "evaluation/Actions Mean                 0.0248678\n",
      "evaluation/Actions Std                  0.607057\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.68389\n",
      "time/backward_zf1 (s)                   1.8155\n",
      "time/backward_zf2 (s)                   1.72731\n",
      "time/data sampling (s)                  0.260003\n",
      "time/data storing (s)                   0.0144739\n",
      "time/evaluation sampling (s)            0.566893\n",
      "time/exploration sampling (s)           0.170981\n",
      "time/logging (s)                        0.00418033\n",
      "time/preback_alpha (s)                  0.5532\n",
      "time/preback_policy (s)                 0.60951\n",
      "time/preback_start (s)                  0.124469\n",
      "time/preback_zf (s)                     4.9583\n",
      "time/saving (s)                         0.00483129\n",
      "time/training (s)                       2.67212\n",
      "time/epoch (s)                         15.1656\n",
      "time/total (s)                       3286.98\n",
      "Epoch                                 210\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:56:18.817241 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 211 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 222000\n",
      "trainer/ZF1 Loss                       95.0396\n",
      "trainer/ZF2 Loss                       68.2214\n",
      "trainer/ZF Expert Reward               14.2842\n",
      "trainer/ZF Policy Reward                4.80081\n",
      "trainer/ZF CHI2 Term                  105.063\n",
      "trainer/Policy Loss                  -853.605\n",
      "trainer/Policy Grad Norm              577.977\n",
      "trainer/Policy Param Norm              43.2557\n",
      "trainer/Zf1 Grad Norm               30736.5\n",
      "trainer/Zf1 Param Norm                121.357\n",
      "trainer/Zf2 Grad Norm               26280.7\n",
      "trainer/Zf2 Param Norm                116.935\n",
      "trainer/Z Expert Predictions Mean    1177.77\n",
      "trainer/Z Expert Predictions Std      236.828\n",
      "trainer/Z Expert Predictions Max     1689.64\n",
      "trainer/Z Expert Predictions Min      276.022\n",
      "trainer/Z Policy Predictions Mean     848.101\n",
      "trainer/Z Policy Predictions Std      438.903\n",
      "trainer/Z Policy Predictions Max     1644.61\n",
      "trainer/Z Policy Predictions Min     -458.812\n",
      "trainer/Z Expert Targets Mean        1163.49\n",
      "trainer/Z Expert Targets Std          237.096\n",
      "trainer/Z Expert Targets Max         1683.75\n",
      "trainer/Z Expert Targets Min          278.996\n",
      "trainer/Z Policy Targets Mean         843.3\n",
      "trainer/Z Policy Targets Std          440.01\n",
      "trainer/Z Policy Targets Max         1631.37\n",
      "trainer/Z Policy Targets Min         -481.166\n",
      "trainer/Log Pis Mean                   14.0896\n",
      "trainer/Log Pis Std                     5.55839\n",
      "trainer/Policy mu Mean                  0.409278\n",
      "trainer/Policy mu Std                   3.07829\n",
      "trainer/Policy log std Mean            -4.1163\n",
      "trainer/Policy log std Std              1.29502\n",
      "exploration/num steps total        218461\n",
      "exploration/num paths total          1066\n",
      "evaluation/num steps total              1.4978e+06\n",
      "evaluation/num paths total           2161\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.56206\n",
      "evaluation/Rewards Std                  0.603842\n",
      "evaluation/Rewards Max                  4.72598\n",
      "evaluation/Rewards Min                  0.690027\n",
      "evaluation/Returns Mean              3562.06\n",
      "evaluation/Returns Std                 27.9523\n",
      "evaluation/Returns Max               3602.32\n",
      "evaluation/Returns Min               3530.8\n",
      "evaluation/Estimation Bias Mean      1101.04\n",
      "evaluation/Estimation Bias Std        271.052\n",
      "evaluation/EB/Q_True Mean              32.7211\n",
      "evaluation/EB/Q_True Std              100.798\n",
      "evaluation/EB/Q_Pred Mean            1133.76\n",
      "evaluation/EB/Q_Pred Std              256.392\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3562.06\n",
      "evaluation/Actions Mean                 0.0376019\n",
      "evaluation/Actions Std                  0.586943\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75986\n",
      "time/backward_zf1 (s)                   1.87727\n",
      "time/backward_zf2 (s)                   1.81233\n",
      "time/data sampling (s)                  0.250309\n",
      "time/data storing (s)                   0.0150263\n",
      "time/evaluation sampling (s)            1.38789\n",
      "time/exploration sampling (s)           0.179598\n",
      "time/logging (s)                        0.0117511\n",
      "time/preback_alpha (s)                  0.552289\n",
      "time/preback_policy (s)                 0.613266\n",
      "time/preback_start (s)                  0.126192\n",
      "time/preback_zf (s)                     4.96865\n",
      "time/saving (s)                         0.00481141\n",
      "time/training (s)                       2.51519\n",
      "time/epoch (s)                         16.0744\n",
      "time/total (s)                       3303.07\n",
      "Epoch                                 211\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:56:34.797394 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 212 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 223000\n",
      "trainer/ZF1 Loss                       84.7075\n",
      "trainer/ZF2 Loss                       81.6476\n",
      "trainer/ZF Expert Reward               18.4441\n",
      "trainer/ZF Policy Reward                0.395378\n",
      "trainer/ZF CHI2 Term                  115.07\n",
      "trainer/Policy Loss                  -794.679\n",
      "trainer/Policy Grad Norm              828.999\n",
      "trainer/Policy Param Norm              43.3257\n",
      "trainer/Zf1 Grad Norm               92866.8\n",
      "trainer/Zf1 Param Norm                121.528\n",
      "trainer/Zf2 Grad Norm               72457.7\n",
      "trainer/Zf2 Param Norm                117.098\n",
      "trainer/Z Expert Predictions Mean    1138.1\n",
      "trainer/Z Expert Predictions Std      252.976\n",
      "trainer/Z Expert Predictions Max     1724.07\n",
      "trainer/Z Expert Predictions Min      175.801\n",
      "trainer/Z Policy Predictions Mean     786.181\n",
      "trainer/Z Policy Predictions Std      471.144\n",
      "trainer/Z Policy Predictions Max     1704.36\n",
      "trainer/Z Policy Predictions Min     -419.877\n",
      "trainer/Z Expert Targets Mean        1119.66\n",
      "trainer/Z Expert Targets Std          254.539\n",
      "trainer/Z Expert Targets Max         1711.98\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         785.785\n",
      "trainer/Z Policy Targets Std          468.685\n",
      "trainer/Z Policy Targets Max         1707.27\n",
      "trainer/Z Policy Targets Min         -458.026\n",
      "trainer/Log Pis Mean                   13.9835\n",
      "trainer/Log Pis Std                     5.27058\n",
      "trainer/Policy mu Mean                  0.554538\n",
      "trainer/Policy mu Std                   2.87225\n",
      "trainer/Policy log std Mean            -4.04258\n",
      "trainer/Policy log std Std              1.28739\n",
      "exploration/num steps total        218461\n",
      "exploration/num paths total          1066\n",
      "evaluation/num steps total              1.5078e+06\n",
      "evaluation/num paths total           2171\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51572\n",
      "evaluation/Rewards Std                  0.582025\n",
      "evaluation/Rewards Max                  4.69845\n",
      "evaluation/Rewards Min                  0.707013\n",
      "evaluation/Returns Mean              3515.72\n",
      "evaluation/Returns Std                 11.2133\n",
      "evaluation/Returns Max               3534.38\n",
      "evaluation/Returns Min               3495.72\n",
      "evaluation/Estimation Bias Mean      1066.24\n",
      "evaluation/Estimation Bias Std        207.967\n",
      "evaluation/EB/Q_True Mean              32.4777\n",
      "evaluation/EB/Q_True Std              100.234\n",
      "evaluation/EB/Q_Pred Mean            1098.71\n",
      "evaluation/EB/Q_Pred Std              189.906\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3515.72\n",
      "evaluation/Actions Mean                 0.0306752\n",
      "evaluation/Actions Std                  0.577145\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.68928\n",
      "time/backward_zf1 (s)                   1.79409\n",
      "time/backward_zf2 (s)                   1.74122\n",
      "time/data sampling (s)                  0.253501\n",
      "time/data storing (s)                   0.013389\n",
      "time/evaluation sampling (s)            1.38623\n",
      "time/exploration sampling (s)           0.165127\n",
      "time/logging (s)                        0.0114375\n",
      "time/preback_alpha (s)                  0.548099\n",
      "time/preback_policy (s)                 0.601752\n",
      "time/preback_start (s)                  0.123303\n",
      "time/preback_zf (s)                     4.95628\n",
      "time/saving (s)                         0.00526075\n",
      "time/training (s)                       2.62867\n",
      "time/epoch (s)                         15.9176\n",
      "time/total (s)                       3319.01\n",
      "Epoch                                 212\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 22:56:50.005459 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 213 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 224000\n",
      "trainer/ZF1 Loss                       81.999\n",
      "trainer/ZF2 Loss                      128.036\n",
      "trainer/ZF Expert Reward                3.07511\n",
      "trainer/ZF Policy Reward               -7.23351\n",
      "trainer/ZF CHI2 Term                  129.816\n",
      "trainer/Policy Loss                  -771.457\n",
      "trainer/Policy Grad Norm              654.43\n",
      "trainer/Policy Param Norm              43.4036\n",
      "trainer/Zf1 Grad Norm               38885\n",
      "trainer/Zf1 Param Norm                121.706\n",
      "trainer/Zf2 Grad Norm              103180\n",
      "trainer/Zf2 Param Norm                117.267\n",
      "trainer/Z Expert Predictions Mean    1159.88\n",
      "trainer/Z Expert Predictions Std      252.191\n",
      "trainer/Z Expert Predictions Max     1699\n",
      "trainer/Z Expert Predictions Min      434.322\n",
      "trainer/Z Policy Predictions Mean     757.784\n",
      "trainer/Z Policy Predictions Std      451.451\n",
      "trainer/Z Policy Predictions Max     1684.65\n",
      "trainer/Z Policy Predictions Min     -456.481\n",
      "trainer/Z Expert Targets Mean        1156.8\n",
      "trainer/Z Expert Targets Std          259.445\n",
      "trainer/Z Expert Targets Max         1719.84\n",
      "trainer/Z Expert Targets Min          330.94\n",
      "trainer/Z Policy Targets Mean         765.018\n",
      "trainer/Z Policy Targets Std          451.589\n",
      "trainer/Z Policy Targets Max         1690.16\n",
      "trainer/Z Policy Targets Min         -377.237\n",
      "trainer/Log Pis Mean                   14.6361\n",
      "trainer/Log Pis Std                     5.89545\n",
      "trainer/Policy mu Mean                  0.582801\n",
      "trainer/Policy mu Std                   3.16179\n",
      "trainer/Policy log std Mean            -4.07868\n",
      "trainer/Policy log std Std              1.29444\n",
      "exploration/num steps total        219461\n",
      "exploration/num paths total          1067\n",
      "evaluation/num steps total              1.51101e+06\n",
      "evaluation/num paths total           2181\n",
      "evaluation/path length Mean           320.6\n",
      "evaluation/path length Std             13.3432\n",
      "evaluation/path length Max            329\n",
      "evaluation/path length Min            293\n",
      "evaluation/Rewards Mean                 3.32424\n",
      "evaluation/Rewards Std                  0.851496\n",
      "evaluation/Rewards Max                  5.12477\n",
      "evaluation/Rewards Min                  0.672342\n",
      "evaluation/Returns Mean              1065.75\n",
      "evaluation/Returns Std                 52.5551\n",
      "evaluation/Returns Max               1096.23\n",
      "evaluation/Returns Min                956.284\n",
      "evaluation/Estimation Bias Mean       862.747\n",
      "evaluation/Estimation Bias Std        442.151\n",
      "evaluation/EB/Q_True Mean              26.2975\n",
      "evaluation/EB/Q_True Std               82.2186\n",
      "evaluation/EB/Q_Pred Mean             889.044\n",
      "evaluation/EB/Q_Pred Std              438.94\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1065.75\n",
      "evaluation/Actions Mean                 0.0437614\n",
      "evaluation/Actions Std                  0.613229\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75518\n",
      "time/backward_zf1 (s)                   1.86786\n",
      "time/backward_zf2 (s)                   1.80457\n",
      "time/data sampling (s)                  0.247628\n",
      "time/data storing (s)                   0.0138591\n",
      "time/evaluation sampling (s)            0.490575\n",
      "time/exploration sampling (s)           0.171607\n",
      "time/logging (s)                        0.0045176\n",
      "time/preback_alpha (s)                  0.552029\n",
      "time/preback_policy (s)                 0.610795\n",
      "time/preback_start (s)                  0.12436\n",
      "time/preback_zf (s)                     4.97654\n",
      "time/saving (s)                         0.00494982\n",
      "time/training (s)                       2.51312\n",
      "time/epoch (s)                         15.1376\n",
      "time/total (s)                       3334.16\n",
      "Epoch                                 213\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:57:06.073375 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 214 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 225000\n",
      "trainer/ZF1 Loss                       75.7739\n",
      "trainer/ZF2 Loss                       73.869\n",
      "trainer/ZF Expert Reward               11.4411\n",
      "trainer/ZF Policy Reward               -0.824547\n",
      "trainer/ZF CHI2 Term                  101.633\n",
      "trainer/Policy Loss                  -810.739\n",
      "trainer/Policy Grad Norm              461.524\n",
      "trainer/Policy Param Norm              43.4885\n",
      "trainer/Zf1 Grad Norm               34889.1\n",
      "trainer/Zf1 Param Norm                121.897\n",
      "trainer/Zf2 Grad Norm               46976.4\n",
      "trainer/Zf2 Param Norm                117.44\n",
      "trainer/Z Expert Predictions Mean    1122.36\n",
      "trainer/Z Expert Predictions Std      258.848\n",
      "trainer/Z Expert Predictions Max     1771.13\n",
      "trainer/Z Expert Predictions Min      344.289\n",
      "trainer/Z Policy Predictions Mean     795.998\n",
      "trainer/Z Policy Predictions Std      448.531\n",
      "trainer/Z Policy Predictions Max     1528.54\n",
      "trainer/Z Policy Predictions Min     -321.68\n",
      "trainer/Z Expert Targets Mean        1110.92\n",
      "trainer/Z Expert Targets Std          259.189\n",
      "trainer/Z Expert Targets Max         1730.72\n",
      "trainer/Z Expert Targets Min          317.985\n",
      "trainer/Z Policy Targets Mean         796.822\n",
      "trainer/Z Policy Targets Std          447.358\n",
      "trainer/Z Policy Targets Max         1525.68\n",
      "trainer/Z Policy Targets Min         -349.061\n",
      "trainer/Log Pis Mean                   14.6927\n",
      "trainer/Log Pis Std                     5.84901\n",
      "trainer/Policy mu Mean                  0.555064\n",
      "trainer/Policy mu Std                   3.5138\n",
      "trainer/Policy log std Mean            -4.03279\n",
      "trainer/Policy log std Std              1.29752\n",
      "exploration/num steps total        219461\n",
      "exploration/num paths total          1067\n",
      "evaluation/num steps total              1.52101e+06\n",
      "evaluation/num paths total           2191\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.53704\n",
      "evaluation/Rewards Std                  0.589824\n",
      "evaluation/Rewards Max                  4.6855\n",
      "evaluation/Rewards Min                  0.691172\n",
      "evaluation/Returns Mean              3537.04\n",
      "evaluation/Returns Std                 13.534\n",
      "evaluation/Returns Max               3552.58\n",
      "evaluation/Returns Min               3515.74\n",
      "evaluation/Estimation Bias Mean      1107.97\n",
      "evaluation/Estimation Bias Std        234.059\n",
      "evaluation/EB/Q_True Mean              32.8342\n",
      "evaluation/EB/Q_True Std              101.156\n",
      "evaluation/EB/Q_Pred Mean            1140.81\n",
      "evaluation/EB/Q_Pred Std              216.433\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3537.04\n",
      "evaluation/Actions Mean                 0.0372505\n",
      "evaluation/Actions Std                  0.582435\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7468\n",
      "time/backward_zf1 (s)                   1.84097\n",
      "time/backward_zf2 (s)                   1.78531\n",
      "time/data sampling (s)                  0.228492\n",
      "time/data storing (s)                   0.0135993\n",
      "time/evaluation sampling (s)            1.37894\n",
      "time/exploration sampling (s)           0.165836\n",
      "time/logging (s)                        0.01252\n",
      "time/preback_alpha (s)                  0.547945\n",
      "time/preback_policy (s)                 0.606538\n",
      "time/preback_start (s)                  0.12306\n",
      "time/preback_zf (s)                     4.95976\n",
      "time/saving (s)                         0.00537902\n",
      "time/training (s)                       2.59957\n",
      "time/epoch (s)                         16.0147\n",
      "time/total (s)                       3350.19\n",
      "Epoch                                 214\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:57:22.101824 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 215 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 226000\n",
      "trainer/ZF1 Loss                       65.2089\n",
      "trainer/ZF2 Loss                       40.8525\n",
      "trainer/ZF Expert Reward               13.2354\n",
      "trainer/ZF Policy Reward                3.23675\n",
      "trainer/ZF CHI2 Term                   76.6091\n",
      "trainer/Policy Loss                  -876.541\n",
      "trainer/Policy Grad Norm              768.875\n",
      "trainer/Policy Param Norm              43.5553\n",
      "trainer/Zf1 Grad Norm               21889\n",
      "trainer/Zf1 Param Norm                122.08\n",
      "trainer/Zf2 Grad Norm               21957.5\n",
      "trainer/Zf2 Param Norm                117.616\n",
      "trainer/Z Expert Predictions Mean    1159.99\n",
      "trainer/Z Expert Predictions Std      240.245\n",
      "trainer/Z Expert Predictions Max     1803.69\n",
      "trainer/Z Expert Predictions Min      413.16\n",
      "trainer/Z Policy Predictions Mean     879.907\n",
      "trainer/Z Policy Predictions Std      424.611\n",
      "trainer/Z Policy Predictions Max     1688.86\n",
      "trainer/Z Policy Predictions Min     -318.833\n",
      "trainer/Z Expert Targets Mean        1146.75\n",
      "trainer/Z Expert Targets Std          236.954\n",
      "trainer/Z Expert Targets Max         1758.85\n",
      "trainer/Z Expert Targets Min          362.826\n",
      "trainer/Z Policy Targets Mean         876.67\n",
      "trainer/Z Policy Targets Std          418.194\n",
      "trainer/Z Policy Targets Max         1655.48\n",
      "trainer/Z Policy Targets Min         -326.989\n",
      "trainer/Log Pis Mean                   13.7169\n",
      "trainer/Log Pis Std                     5.10078\n",
      "trainer/Policy mu Mean                  0.610698\n",
      "trainer/Policy mu Std                   3.18622\n",
      "trainer/Policy log std Mean            -4.13414\n",
      "trainer/Policy log std Std              1.27965\n",
      "exploration/num steps total        220461\n",
      "exploration/num paths total          1068\n",
      "evaluation/num steps total              1.53013e+06\n",
      "evaluation/num paths total           2202\n",
      "evaluation/path length Mean           829.091\n",
      "evaluation/path length Std            280.758\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            331\n",
      "evaluation/Rewards Mean                 3.52629\n",
      "evaluation/Rewards Std                  0.624615\n",
      "evaluation/Rewards Max                  4.74166\n",
      "evaluation/Rewards Min                  0.711289\n",
      "evaluation/Returns Mean              2923.62\n",
      "evaluation/Returns Std               1025.13\n",
      "evaluation/Returns Max               3563.15\n",
      "evaluation/Returns Min               1098.13\n",
      "evaluation/Estimation Bias Mean      1084.96\n",
      "evaluation/Estimation Bias Std        315.846\n",
      "evaluation/EB/Q_True Mean              35.8679\n",
      "evaluation/EB/Q_True Std              105.263\n",
      "evaluation/EB/Q_Pred Mean            1120.83\n",
      "evaluation/EB/Q_Pred Std              278.822\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2923.62\n",
      "evaluation/Actions Mean                 0.0341239\n",
      "evaluation/Actions Std                  0.591881\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67872\n",
      "time/backward_zf1 (s)                   1.79734\n",
      "time/backward_zf2 (s)                   1.71117\n",
      "time/data sampling (s)                  0.231137\n",
      "time/data storing (s)                   0.0136561\n",
      "time/evaluation sampling (s)            1.39451\n",
      "time/exploration sampling (s)           0.169998\n",
      "time/logging (s)                        0.0106598\n",
      "time/preback_alpha (s)                  0.546168\n",
      "time/preback_policy (s)                 0.593074\n",
      "time/preback_start (s)                  0.123902\n",
      "time/preback_zf (s)                     4.95543\n",
      "time/saving (s)                         0.00519033\n",
      "time/training (s)                       2.73058\n",
      "time/epoch (s)                         15.9615\n",
      "time/total (s)                       3366.17\n",
      "Epoch                                 215\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:57:37.259646 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 216 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 227000\n",
      "trainer/ZF1 Loss                       67.5949\n",
      "trainer/ZF2 Loss                       64.2058\n",
      "trainer/ZF Expert Reward               15.454\n",
      "trainer/ZF Policy Reward                5.43076\n",
      "trainer/ZF CHI2 Term                   89.6466\n",
      "trainer/Policy Loss                  -853.426\n",
      "trainer/Policy Grad Norm              710.287\n",
      "trainer/Policy Param Norm              43.6301\n",
      "trainer/Zf1 Grad Norm               60270.4\n",
      "trainer/Zf1 Param Norm                122.266\n",
      "trainer/Zf2 Grad Norm               62174.2\n",
      "trainer/Zf2 Param Norm                117.775\n",
      "trainer/Z Expert Predictions Mean    1159.93\n",
      "trainer/Z Expert Predictions Std      235.869\n",
      "trainer/Z Expert Predictions Max     1747.88\n",
      "trainer/Z Expert Predictions Min      573.893\n",
      "trainer/Z Policy Predictions Mean     854.01\n",
      "trainer/Z Policy Predictions Std      403.286\n",
      "trainer/Z Policy Predictions Max     1525.82\n",
      "trainer/Z Policy Predictions Min     -379.463\n",
      "trainer/Z Expert Targets Mean        1144.48\n",
      "trainer/Z Expert Targets Std          237.855\n",
      "trainer/Z Expert Targets Max         1732.61\n",
      "trainer/Z Expert Targets Min          522.779\n",
      "trainer/Z Policy Targets Mean         848.579\n",
      "trainer/Z Policy Targets Std          401.287\n",
      "trainer/Z Policy Targets Max         1442.65\n",
      "trainer/Z Policy Targets Min         -412.135\n",
      "trainer/Log Pis Mean                   13.8617\n",
      "trainer/Log Pis Std                     4.73872\n",
      "trainer/Policy mu Mean                  0.420916\n",
      "trainer/Policy mu Std                   2.73228\n",
      "trainer/Policy log std Mean            -4.22055\n",
      "trainer/Policy log std Std              1.15922\n",
      "exploration/num steps total        221269\n",
      "exploration/num paths total          1069\n",
      "evaluation/num steps total              1.53326e+06\n",
      "evaluation/num paths total           2212\n",
      "evaluation/path length Mean           313.4\n",
      "evaluation/path length Std             18.1945\n",
      "evaluation/path length Max            329\n",
      "evaluation/path length Min            278\n",
      "evaluation/Rewards Mean                 3.3092\n",
      "evaluation/Rewards Std                  0.845467\n",
      "evaluation/Rewards Max                  4.71878\n",
      "evaluation/Rewards Min                  0.691032\n",
      "evaluation/Returns Mean              1037.1\n",
      "evaluation/Returns Std                 71.9486\n",
      "evaluation/Returns Max               1095.83\n",
      "evaluation/Returns Min                894.885\n",
      "evaluation/Estimation Bias Mean       812.138\n",
      "evaluation/Estimation Bias Std        433.184\n",
      "evaluation/EB/Q_True Mean              26.8866\n",
      "evaluation/EB/Q_True Std               83.0418\n",
      "evaluation/EB/Q_Pred Mean             839.024\n",
      "evaluation/EB/Q_Pred Std              433.987\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1037.1\n",
      "evaluation/Actions Mean                 0.0400853\n",
      "evaluation/Actions Std                  0.60875\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.69138\n",
      "time/backward_zf1 (s)                   1.79033\n",
      "time/backward_zf2 (s)                   1.72798\n",
      "time/data sampling (s)                  0.261956\n",
      "time/data storing (s)                   0.0140042\n",
      "time/evaluation sampling (s)            0.502871\n",
      "time/exploration sampling (s)           0.170199\n",
      "time/logging (s)                        0.00467319\n",
      "time/preback_alpha (s)                  0.552544\n",
      "time/preback_policy (s)                 0.601876\n",
      "time/preback_start (s)                  0.124236\n",
      "time/preback_zf (s)                     4.96165\n",
      "time/saving (s)                         0.00544107\n",
      "time/training (s)                       2.68\n",
      "time/epoch (s)                         15.0891\n",
      "time/total (s)                       3381.28\n",
      "Epoch                                 216\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:57:53.110716 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 217 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 228000\n",
      "trainer/ZF1 Loss                       85.1567\n",
      "trainer/ZF2 Loss                       61.6849\n",
      "trainer/ZF Expert Reward               10.7422\n",
      "trainer/ZF Policy Reward                0.52341\n",
      "trainer/ZF CHI2 Term                   97.5674\n",
      "trainer/Policy Loss                  -848.907\n",
      "trainer/Policy Grad Norm              482.483\n",
      "trainer/Policy Param Norm              43.6974\n",
      "trainer/Zf1 Grad Norm               32628.6\n",
      "trainer/Zf1 Param Norm                122.434\n",
      "trainer/Zf2 Grad Norm               22869\n",
      "trainer/Zf2 Param Norm                117.917\n",
      "trainer/Z Expert Predictions Mean    1157.2\n",
      "trainer/Z Expert Predictions Std      255.43\n",
      "trainer/Z Expert Predictions Max     1789.89\n",
      "trainer/Z Expert Predictions Min      313.676\n",
      "trainer/Z Policy Predictions Mean     842.882\n",
      "trainer/Z Policy Predictions Std      372.872\n",
      "trainer/Z Policy Predictions Max     1480.34\n",
      "trainer/Z Policy Predictions Min     -310.018\n",
      "trainer/Z Expert Targets Mean        1146.46\n",
      "trainer/Z Expert Targets Std          253.198\n",
      "trainer/Z Expert Targets Max         1790.89\n",
      "trainer/Z Expert Targets Min          294.616\n",
      "trainer/Z Policy Targets Mean         842.358\n",
      "trainer/Z Policy Targets Std          369.5\n",
      "trainer/Z Policy Targets Max         1475.7\n",
      "trainer/Z Policy Targets Min         -303.763\n",
      "trainer/Log Pis Mean                   14.0685\n",
      "trainer/Log Pis Std                     5.29962\n",
      "trainer/Policy mu Mean                  0.359302\n",
      "trainer/Policy mu Std                   2.76879\n",
      "trainer/Policy log std Mean            -4.07529\n",
      "trainer/Policy log std Std              1.2174\n",
      "exploration/num steps total        223555\n",
      "exploration/num paths total          1072\n",
      "evaluation/num steps total              1.53686e+06\n",
      "evaluation/num paths total           2222\n",
      "evaluation/path length Mean           359.4\n",
      "evaluation/path length Std             81.5588\n",
      "evaluation/path length Max            604\n",
      "evaluation/path length Min            329\n",
      "evaluation/Rewards Mean                 3.35302\n",
      "evaluation/Rewards Std                  0.815466\n",
      "evaluation/Rewards Max                  4.70971\n",
      "evaluation/Rewards Min                  0.670687\n",
      "evaluation/Returns Mean              1205.08\n",
      "evaluation/Returns Std                302.718\n",
      "evaluation/Returns Max               2112.95\n",
      "evaluation/Returns Min               1093.41\n",
      "evaluation/Estimation Bias Mean       961.92\n",
      "evaluation/Estimation Bias Std        327.01\n",
      "evaluation/EB/Q_True Mean              42.4805\n",
      "evaluation/EB/Q_True Std              100.96\n",
      "evaluation/EB/Q_Pred Mean            1004.4\n",
      "evaluation/EB/Q_Pred Std              316.079\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1205.08\n",
      "evaluation/Actions Mean                 0.0361593\n",
      "evaluation/Actions Std                  0.604804\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81832\n",
      "time/backward_zf1 (s)                   1.92882\n",
      "time/backward_zf2 (s)                   1.86888\n",
      "time/data sampling (s)                  0.242249\n",
      "time/data storing (s)                   0.0151688\n",
      "time/evaluation sampling (s)            0.958078\n",
      "time/exploration sampling (s)           0.181436\n",
      "time/logging (s)                        0.00582782\n",
      "time/preback_alpha (s)                  0.555332\n",
      "time/preback_policy (s)                 0.628684\n",
      "time/preback_start (s)                  0.125691\n",
      "time/preback_zf (s)                     4.99342\n",
      "time/saving (s)                         0.00488855\n",
      "time/training (s)                       2.46228\n",
      "time/epoch (s)                         15.7891\n",
      "time/total (s)                       3397.09\n",
      "Epoch                                 217\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:58:09.216341 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 218 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 229000\n",
      "trainer/ZF1 Loss                       55.9338\n",
      "trainer/ZF2 Loss                       45.3316\n",
      "trainer/ZF Expert Reward               20.1712\n",
      "trainer/ZF Policy Reward                4.18798\n",
      "trainer/ZF CHI2 Term                   80.9017\n",
      "trainer/Policy Loss                  -805.749\n",
      "trainer/Policy Grad Norm              581.169\n",
      "trainer/Policy Param Norm              43.7609\n",
      "trainer/Zf1 Grad Norm               32905.1\n",
      "trainer/Zf1 Param Norm                122.609\n",
      "trainer/Zf2 Grad Norm               19158.2\n",
      "trainer/Zf2 Param Norm                118.091\n",
      "trainer/Z Expert Predictions Mean    1172.53\n",
      "trainer/Z Expert Predictions Std      230.701\n",
      "trainer/Z Expert Predictions Max     1807.83\n",
      "trainer/Z Expert Predictions Min      515.497\n",
      "trainer/Z Policy Predictions Mean     798.017\n",
      "trainer/Z Policy Predictions Std      420.673\n",
      "trainer/Z Policy Predictions Max     1562.65\n",
      "trainer/Z Policy Predictions Min     -380.433\n",
      "trainer/Z Expert Targets Mean        1152.35\n",
      "trainer/Z Expert Targets Std          231.121\n",
      "trainer/Z Expert Targets Max         1807.18\n",
      "trainer/Z Expert Targets Min          477.345\n",
      "trainer/Z Policy Targets Mean         793.829\n",
      "trainer/Z Policy Targets Std          415.675\n",
      "trainer/Z Policy Targets Max         1631.37\n",
      "trainer/Z Policy Targets Min         -341.188\n",
      "trainer/Log Pis Mean                   14.4301\n",
      "trainer/Log Pis Std                     4.93613\n",
      "trainer/Policy mu Mean                  0.360585\n",
      "trainer/Policy mu Std                   2.6731\n",
      "trainer/Policy log std Mean            -4.10079\n",
      "trainer/Policy log std Std              1.25196\n",
      "exploration/num steps total        225555\n",
      "exploration/num paths total          1074\n",
      "evaluation/num steps total              1.54686e+06\n",
      "evaluation/num paths total           2232\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.49719\n",
      "evaluation/Rewards Std                  0.599597\n",
      "evaluation/Rewards Max                  4.77855\n",
      "evaluation/Rewards Min                  0.694339\n",
      "evaluation/Returns Mean              3497.19\n",
      "evaluation/Returns Std                  8.3205\n",
      "evaluation/Returns Max               3511.53\n",
      "evaluation/Returns Min               3483.93\n",
      "evaluation/Estimation Bias Mean      1004.59\n",
      "evaluation/Estimation Bias Std        203.076\n",
      "evaluation/EB/Q_True Mean              32.2028\n",
      "evaluation/EB/Q_True Std               99.3976\n",
      "evaluation/EB/Q_Pred Mean            1036.79\n",
      "evaluation/EB/Q_Pred Std              177.769\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3497.19\n",
      "evaluation/Actions Mean                 0.0252774\n",
      "evaluation/Actions Std                  0.589645\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82526\n",
      "time/backward_zf1 (s)                   1.94641\n",
      "time/backward_zf2 (s)                   1.88657\n",
      "time/data sampling (s)                  0.234286\n",
      "time/data storing (s)                   0.0134802\n",
      "time/evaluation sampling (s)            1.37764\n",
      "time/exploration sampling (s)           0.170635\n",
      "time/logging (s)                        0.0116118\n",
      "time/preback_alpha (s)                  0.549922\n",
      "time/preback_policy (s)                 0.621714\n",
      "time/preback_start (s)                  0.123776\n",
      "time/preback_zf (s)                     4.95359\n",
      "time/saving (s)                         0.0056595\n",
      "time/training (s)                       2.32368\n",
      "time/epoch (s)                         16.0442\n",
      "time/total (s)                       3413.15\n",
      "Epoch                                 218\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:58:25.228687 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 219 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 230000\n",
      "trainer/ZF1 Loss                       81.0353\n",
      "trainer/ZF2 Loss                       97.8062\n",
      "trainer/ZF Expert Reward               10.0041\n",
      "trainer/ZF Policy Reward               -1.5456\n",
      "trainer/ZF CHI2 Term                  114.967\n",
      "trainer/Policy Loss                  -829.691\n",
      "trainer/Policy Grad Norm              865.909\n",
      "trainer/Policy Param Norm              43.831\n",
      "trainer/Zf1 Grad Norm               85680.7\n",
      "trainer/Zf1 Param Norm                122.783\n",
      "trainer/Zf2 Grad Norm              101965\n",
      "trainer/Zf2 Param Norm                118.253\n",
      "trainer/Z Expert Predictions Mean    1138.9\n",
      "trainer/Z Expert Predictions Std      258.055\n",
      "trainer/Z Expert Predictions Max     1832.79\n",
      "trainer/Z Expert Predictions Min      170.552\n",
      "trainer/Z Policy Predictions Mean     826.865\n",
      "trainer/Z Policy Predictions Std      402.905\n",
      "trainer/Z Policy Predictions Max     1479.38\n",
      "trainer/Z Policy Predictions Min     -340.044\n",
      "trainer/Z Expert Targets Mean        1128.89\n",
      "trainer/Z Expert Targets Std          263.094\n",
      "trainer/Z Expert Targets Max         1815.11\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         828.411\n",
      "trainer/Z Policy Targets Std          397.881\n",
      "trainer/Z Policy Targets Max         1472.7\n",
      "trainer/Z Policy Targets Min         -370.324\n",
      "trainer/Log Pis Mean                   14.1376\n",
      "trainer/Log Pis Std                     4.72695\n",
      "trainer/Policy mu Mean                  0.311783\n",
      "trainer/Policy mu Std                   2.40941\n",
      "trainer/Policy log std Mean            -4.2262\n",
      "trainer/Policy log std Std              1.15344\n",
      "exploration/num steps total        226555\n",
      "exploration/num paths total          1075\n",
      "evaluation/num steps total              1.55686e+06\n",
      "evaluation/num paths total           2242\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51988\n",
      "evaluation/Rewards Std                  0.602492\n",
      "evaluation/Rewards Max                  4.74485\n",
      "evaluation/Rewards Min                  0.704816\n",
      "evaluation/Returns Mean              3519.88\n",
      "evaluation/Returns Std                  5.03649\n",
      "evaluation/Returns Max               3529.71\n",
      "evaluation/Returns Min               3515.5\n",
      "evaluation/Estimation Bias Mean      1040.73\n",
      "evaluation/Estimation Bias Std        222.469\n",
      "evaluation/EB/Q_True Mean              32.5017\n",
      "evaluation/EB/Q_True Std              100.396\n",
      "evaluation/EB/Q_Pred Mean            1073.24\n",
      "evaluation/EB/Q_Pred Std              197.666\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3519.88\n",
      "evaluation/Actions Mean                 0.0469987\n",
      "evaluation/Actions Std                  0.59253\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.68217\n",
      "time/backward_zf1 (s)                   1.81318\n",
      "time/backward_zf2 (s)                   1.72185\n",
      "time/data sampling (s)                  0.251423\n",
      "time/data storing (s)                   0.014845\n",
      "time/evaluation sampling (s)            1.39091\n",
      "time/exploration sampling (s)           0.172429\n",
      "time/logging (s)                        0.0117601\n",
      "time/preback_alpha (s)                  0.550215\n",
      "time/preback_policy (s)                 0.602875\n",
      "time/preback_start (s)                  0.124622\n",
      "time/preback_zf (s)                     4.96004\n",
      "time/saving (s)                         0.00614874\n",
      "time/training (s)                       2.64357\n",
      "time/epoch (s)                         15.946\n",
      "time/total (s)                       3429.12\n",
      "Epoch                                 219\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:58:40.373351 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 220 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 231000\n",
      "trainer/ZF1 Loss                      175.748\n",
      "trainer/ZF2 Loss                      189.235\n",
      "trainer/ZF Expert Reward               12.2998\n",
      "trainer/ZF Policy Reward                2.08754\n",
      "trainer/ZF CHI2 Term                  206.164\n",
      "trainer/Policy Loss                  -823.83\n",
      "trainer/Policy Grad Norm              919.819\n",
      "trainer/Policy Param Norm              43.9044\n",
      "trainer/Zf1 Grad Norm               27113.4\n",
      "trainer/Zf1 Param Norm                122.951\n",
      "trainer/Zf2 Grad Norm               27642.8\n",
      "trainer/Zf2 Param Norm                118.392\n",
      "trainer/Z Expert Predictions Mean    1112.62\n",
      "trainer/Z Expert Predictions Std      246.187\n",
      "trainer/Z Expert Predictions Max     1797.63\n",
      "trainer/Z Expert Predictions Min      321.539\n",
      "trainer/Z Policy Predictions Mean     818.887\n",
      "trainer/Z Policy Predictions Std      380.694\n",
      "trainer/Z Policy Predictions Max     1620.35\n",
      "trainer/Z Policy Predictions Min     -314.637\n",
      "trainer/Z Expert Targets Mean        1100.32\n",
      "trainer/Z Expert Targets Std          251.766\n",
      "trainer/Z Expert Targets Max         1770.94\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         816.8\n",
      "trainer/Z Policy Targets Std          382.768\n",
      "trainer/Z Policy Targets Max         1550.52\n",
      "trainer/Z Policy Targets Min         -321.073\n",
      "trainer/Log Pis Mean                   13.5963\n",
      "trainer/Log Pis Std                     4.9596\n",
      "trainer/Policy mu Mean                  0.408789\n",
      "trainer/Policy mu Std                   2.77022\n",
      "trainer/Policy log std Mean            -4.10158\n",
      "trainer/Policy log std Std              1.24893\n",
      "exploration/num steps total        227546\n",
      "exploration/num paths total          1078\n",
      "evaluation/num steps total              1.55972e+06\n",
      "evaluation/num paths total           2252\n",
      "evaluation/path length Mean           286.8\n",
      "evaluation/path length Std             14.0769\n",
      "evaluation/path length Max            329\n",
      "evaluation/path length Min            281\n",
      "evaluation/Rewards Mean                 3.25717\n",
      "evaluation/Rewards Std                  0.865241\n",
      "evaluation/Rewards Max                  4.66594\n",
      "evaluation/Rewards Min                  0.68811\n",
      "evaluation/Returns Mean               934.156\n",
      "evaluation/Returns Std                 55.3261\n",
      "evaluation/Returns Max               1100.05\n",
      "evaluation/Returns Min                911.717\n",
      "evaluation/Estimation Bias Mean       828.557\n",
      "evaluation/Estimation Bias Std        397.237\n",
      "evaluation/EB/Q_True Mean              29.5308\n",
      "evaluation/EB/Q_True Std               86.7661\n",
      "evaluation/EB/Q_Pred Mean             858.087\n",
      "evaluation/EB/Q_Pred Std              391.675\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            934.156\n",
      "evaluation/Actions Mean                 0.0207906\n",
      "evaluation/Actions Std                  0.595405\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70687\n",
      "time/backward_zf1 (s)                   1.81447\n",
      "time/backward_zf2 (s)                   1.74816\n",
      "time/data sampling (s)                  0.257668\n",
      "time/data storing (s)                   0.0136649\n",
      "time/evaluation sampling (s)            0.52395\n",
      "time/exploration sampling (s)           0.169729\n",
      "time/logging (s)                        0.00422778\n",
      "time/preback_alpha (s)                  0.549264\n",
      "time/preback_policy (s)                 0.610611\n",
      "time/preback_start (s)                  0.123451\n",
      "time/preback_zf (s)                     4.94998\n",
      "time/saving (s)                         0.00488821\n",
      "time/training (s)                       2.59385\n",
      "time/epoch (s)                         15.0708\n",
      "time/total (s)                       3444.21\n",
      "Epoch                                 220\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:58:55.683569 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 221 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 232000\n",
      "trainer/ZF1 Loss                       78.1844\n",
      "trainer/ZF2 Loss                       73.413\n",
      "trainer/ZF Expert Reward                8.99917\n",
      "trainer/ZF Policy Reward                0.693196\n",
      "trainer/ZF CHI2 Term                   98.25\n",
      "trainer/Policy Loss                  -824.362\n",
      "trainer/Policy Grad Norm              678.974\n",
      "trainer/Policy Param Norm              43.9678\n",
      "trainer/Zf1 Grad Norm               77136\n",
      "trainer/Zf1 Param Norm                123.129\n",
      "trainer/Zf2 Grad Norm               76154.8\n",
      "trainer/Zf2 Param Norm                118.556\n",
      "trainer/Z Expert Predictions Mean    1123.82\n",
      "trainer/Z Expert Predictions Std      233.178\n",
      "trainer/Z Expert Predictions Max     1777.7\n",
      "trainer/Z Expert Predictions Min      300.947\n",
      "trainer/Z Policy Predictions Mean     823.837\n",
      "trainer/Z Policy Predictions Std      374.944\n",
      "trainer/Z Policy Predictions Max     1521.33\n",
      "trainer/Z Policy Predictions Min     -287.602\n",
      "trainer/Z Expert Targets Mean        1114.82\n",
      "trainer/Z Expert Targets Std          233.69\n",
      "trainer/Z Expert Targets Max         1752.83\n",
      "trainer/Z Expert Targets Min          271.87\n",
      "trainer/Z Policy Targets Mean         823.144\n",
      "trainer/Z Policy Targets Std          375.73\n",
      "trainer/Z Policy Targets Max         1513.61\n",
      "trainer/Z Policy Targets Min         -286.559\n",
      "trainer/Log Pis Mean                   14.2882\n",
      "trainer/Log Pis Std                     5.13655\n",
      "trainer/Policy mu Mean                  0.571195\n",
      "trainer/Policy mu Std                   3.08743\n",
      "trainer/Policy log std Mean            -4.20809\n",
      "trainer/Policy log std Std              1.32548\n",
      "exploration/num steps total        230161\n",
      "exploration/num paths total          1082\n",
      "evaluation/num steps total              1.56232e+06\n",
      "evaluation/num paths total           2262\n",
      "evaluation/path length Mean           259.4\n",
      "evaluation/path length Std              5.62494\n",
      "evaluation/path length Max            276\n",
      "evaluation/path length Min            256\n",
      "evaluation/Rewards Mean                 3.1927\n",
      "evaluation/Rewards Std                  0.865808\n",
      "evaluation/Rewards Max                  4.55525\n",
      "evaluation/Rewards Min                  0.692595\n",
      "evaluation/Returns Mean               828.185\n",
      "evaluation/Returns Std                 22.4138\n",
      "evaluation/Returns Max                894.516\n",
      "evaluation/Returns Min                814.9\n",
      "evaluation/Estimation Bias Mean       834.014\n",
      "evaluation/Estimation Bias Std        374.03\n",
      "evaluation/EB/Q_True Mean              25.0337\n",
      "evaluation/EB/Q_True Std               77.1501\n",
      "evaluation/EB/Q_Pred Mean             859.047\n",
      "evaluation/EB/Q_Pred Std              369.695\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            828.185\n",
      "evaluation/Actions Mean                 0.0214879\n",
      "evaluation/Actions Std                  0.608111\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86472\n",
      "time/backward_zf1 (s)                   1.95235\n",
      "time/backward_zf2 (s)                   1.90898\n",
      "time/data sampling (s)                  0.241836\n",
      "time/data storing (s)                   0.0143191\n",
      "time/evaluation sampling (s)            0.404551\n",
      "time/exploration sampling (s)           0.178115\n",
      "time/logging (s)                        0.00395561\n",
      "time/preback_alpha (s)                  0.558773\n",
      "time/preback_policy (s)                 0.636551\n",
      "time/preback_start (s)                  0.127407\n",
      "time/preback_zf (s)                     4.99651\n",
      "time/saving (s)                         0.00477749\n",
      "time/training (s)                       2.35181\n",
      "time/epoch (s)                         15.2447\n",
      "time/total (s)                       3459.48\n",
      "Epoch                                 221\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:59:11.685910 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 222 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 233000\n",
      "trainer/ZF1 Loss                       61.9053\n",
      "trainer/ZF2 Loss                       68.9388\n",
      "trainer/ZF Expert Reward                9.85115\n",
      "trainer/ZF Policy Reward               -6.01373\n",
      "trainer/ZF CHI2 Term                   95.5787\n",
      "trainer/Policy Loss                  -826.411\n",
      "trainer/Policy Grad Norm              782.727\n",
      "trainer/Policy Param Norm              44.038\n",
      "trainer/Zf1 Grad Norm               32067.4\n",
      "trainer/Zf1 Param Norm                123.319\n",
      "trainer/Zf2 Grad Norm               35483.1\n",
      "trainer/Zf2 Param Norm                118.733\n",
      "trainer/Z Expert Predictions Mean    1126.19\n",
      "trainer/Z Expert Predictions Std      246.609\n",
      "trainer/Z Expert Predictions Max     1775.03\n",
      "trainer/Z Expert Predictions Min      452.018\n",
      "trainer/Z Policy Predictions Mean     815.946\n",
      "trainer/Z Policy Predictions Std      408.665\n",
      "trainer/Z Policy Predictions Max     1595.27\n",
      "trainer/Z Policy Predictions Min     -316.812\n",
      "trainer/Z Expert Targets Mean        1116.34\n",
      "trainer/Z Expert Targets Std          244.87\n",
      "trainer/Z Expert Targets Max         1753.25\n",
      "trainer/Z Expert Targets Min          420.637\n",
      "trainer/Z Policy Targets Mean         821.96\n",
      "trainer/Z Policy Targets Std          405.255\n",
      "trainer/Z Policy Targets Max         1570.4\n",
      "trainer/Z Policy Targets Min         -335.902\n",
      "trainer/Log Pis Mean                   14.4361\n",
      "trainer/Log Pis Std                     5.18297\n",
      "trainer/Policy mu Mean                  0.370053\n",
      "trainer/Policy mu Std                   3.04084\n",
      "trainer/Policy log std Mean            -4.14112\n",
      "trainer/Policy log std Std              1.27166\n",
      "exploration/num steps total        230161\n",
      "exploration/num paths total          1082\n",
      "evaluation/num steps total              1.57232e+06\n",
      "evaluation/num paths total           2272\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.53533\n",
      "evaluation/Rewards Std                  0.597127\n",
      "evaluation/Rewards Max                  4.71057\n",
      "evaluation/Rewards Min                  0.663782\n",
      "evaluation/Returns Mean              3535.33\n",
      "evaluation/Returns Std                 18.0393\n",
      "evaluation/Returns Max               3568.96\n",
      "evaluation/Returns Min               3504.42\n",
      "evaluation/Estimation Bias Mean      1059.01\n",
      "evaluation/Estimation Bias Std        244.912\n",
      "evaluation/EB/Q_True Mean              32.5939\n",
      "evaluation/EB/Q_True Std              100.47\n",
      "evaluation/EB/Q_Pred Mean            1091.61\n",
      "evaluation/EB/Q_Pred Std              224.418\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3535.33\n",
      "evaluation/Actions Mean                 0.0439075\n",
      "evaluation/Actions Std                  0.586205\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74704\n",
      "time/backward_zf1 (s)                   1.84659\n",
      "time/backward_zf2 (s)                   1.77331\n",
      "time/data sampling (s)                  0.244847\n",
      "time/data storing (s)                   0.01385\n",
      "time/evaluation sampling (s)            1.33927\n",
      "time/exploration sampling (s)           0.166567\n",
      "time/logging (s)                        0.0118203\n",
      "time/preback_alpha (s)                  0.547595\n",
      "time/preback_policy (s)                 0.608196\n",
      "time/preback_start (s)                  0.123295\n",
      "time/preback_zf (s)                     4.97316\n",
      "time/saving (s)                         0.00489217\n",
      "time/training (s)                       2.54725\n",
      "time/epoch (s)                         15.9477\n",
      "time/total (s)                       3475.44\n",
      "Epoch                                 222\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:59:26.883391 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 223 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 234000\n",
      "trainer/ZF1 Loss                       53.4606\n",
      "trainer/ZF2 Loss                       57.0134\n",
      "trainer/ZF Expert Reward               12.5106\n",
      "trainer/ZF Policy Reward               -4.65873\n",
      "trainer/ZF CHI2 Term                   86.7791\n",
      "trainer/Policy Loss                  -820.571\n",
      "trainer/Policy Grad Norm              521.406\n",
      "trainer/Policy Param Norm              44.1176\n",
      "trainer/Zf1 Grad Norm               23704.8\n",
      "trainer/Zf1 Param Norm                123.511\n",
      "trainer/Zf2 Grad Norm               27201.7\n",
      "trainer/Zf2 Param Norm                118.907\n",
      "trainer/Z Expert Predictions Mean    1148.01\n",
      "trainer/Z Expert Predictions Std      225.686\n",
      "trainer/Z Expert Predictions Max     1702.12\n",
      "trainer/Z Expert Predictions Min      313.107\n",
      "trainer/Z Policy Predictions Mean     813.964\n",
      "trainer/Z Policy Predictions Std      368.164\n",
      "trainer/Z Policy Predictions Max     1629.74\n",
      "trainer/Z Policy Predictions Min     -427.305\n",
      "trainer/Z Expert Targets Mean        1135.5\n",
      "trainer/Z Expert Targets Std          225.804\n",
      "trainer/Z Expert Targets Max         1713.01\n",
      "trainer/Z Expert Targets Min          267.65\n",
      "trainer/Z Policy Targets Mean         818.622\n",
      "trainer/Z Policy Targets Std          367.876\n",
      "trainer/Z Policy Targets Max         1593.28\n",
      "trainer/Z Policy Targets Min         -421.729\n",
      "trainer/Log Pis Mean                   14.518\n",
      "trainer/Log Pis Std                     5.53821\n",
      "trainer/Policy mu Mean                  0.483311\n",
      "trainer/Policy mu Std                   2.9729\n",
      "trainer/Policy log std Mean            -4.07093\n",
      "trainer/Policy log std Std              1.31173\n",
      "exploration/num steps total        230767\n",
      "exploration/num paths total          1084\n",
      "evaluation/num steps total              1.57502e+06\n",
      "evaluation/num paths total           2282\n",
      "evaluation/path length Mean           270.7\n",
      "evaluation/path length Std              6.9\n",
      "evaluation/path length Max            278\n",
      "evaluation/path length Min            259\n",
      "evaluation/Rewards Mean                 3.21216\n",
      "evaluation/Rewards Std                  0.859915\n",
      "evaluation/Rewards Max                  4.69989\n",
      "evaluation/Rewards Min                  0.682637\n",
      "evaluation/Returns Mean               869.532\n",
      "evaluation/Returns Std                 27.8268\n",
      "evaluation/Returns Max                898.269\n",
      "evaluation/Returns Min                822.903\n",
      "evaluation/Estimation Bias Mean       845.39\n",
      "evaluation/Estimation Bias Std        386.278\n",
      "evaluation/EB/Q_True Mean              24.1774\n",
      "evaluation/EB/Q_True Std               75.9088\n",
      "evaluation/EB/Q_Pred Mean             869.567\n",
      "evaluation/EB/Q_Pred Std              382.914\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            869.532\n",
      "evaluation/Actions Mean                 0.0272947\n",
      "evaluation/Actions Std                  0.606017\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74669\n",
      "time/backward_zf1 (s)                   1.85998\n",
      "time/backward_zf2 (s)                   1.78755\n",
      "time/data sampling (s)                  0.233595\n",
      "time/data storing (s)                   0.0136219\n",
      "time/evaluation sampling (s)            0.409844\n",
      "time/exploration sampling (s)           0.168599\n",
      "time/logging (s)                        0.00426878\n",
      "time/preback_alpha (s)                  0.551969\n",
      "time/preback_policy (s)                 0.614044\n",
      "time/preback_start (s)                  0.124909\n",
      "time/preback_zf (s)                     4.97567\n",
      "time/saving (s)                         0.00481956\n",
      "time/training (s)                       2.63039\n",
      "time/epoch (s)                         15.126\n",
      "time/total (s)                       3490.59\n",
      "Epoch                                 223\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:59:42.580038 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 224 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 235000\n",
      "trainer/ZF1 Loss                      129.601\n",
      "trainer/ZF2 Loss                       79.5264\n",
      "trainer/ZF Expert Reward               17.6115\n",
      "trainer/ZF Policy Reward                6.31115\n",
      "trainer/ZF CHI2 Term                  130.146\n",
      "trainer/Policy Loss                  -829.789\n",
      "trainer/Policy Grad Norm              695.805\n",
      "trainer/Policy Param Norm              44.186\n",
      "trainer/Zf1 Grad Norm               36249.1\n",
      "trainer/Zf1 Param Norm                123.714\n",
      "trainer/Zf2 Grad Norm               59615.7\n",
      "trainer/Zf2 Param Norm                119.101\n",
      "trainer/Z Expert Predictions Mean    1153.97\n",
      "trainer/Z Expert Predictions Std      257.438\n",
      "trainer/Z Expert Predictions Max     1715.23\n",
      "trainer/Z Expert Predictions Min      172.78\n",
      "trainer/Z Policy Predictions Mean     828.526\n",
      "trainer/Z Policy Predictions Std      411.488\n",
      "trainer/Z Policy Predictions Max     1544.02\n",
      "trainer/Z Policy Predictions Min     -378.891\n",
      "trainer/Z Expert Targets Mean        1136.36\n",
      "trainer/Z Expert Targets Std          256.33\n",
      "trainer/Z Expert Targets Max         1715.65\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         822.214\n",
      "trainer/Z Policy Targets Std          412.557\n",
      "trainer/Z Policy Targets Max         1537.51\n",
      "trainer/Z Policy Targets Min         -437.776\n",
      "trainer/Log Pis Mean                   14.4263\n",
      "trainer/Log Pis Std                     5.41412\n",
      "trainer/Policy mu Mean                  0.313756\n",
      "trainer/Policy mu Std                   2.90372\n",
      "trainer/Policy log std Mean            -4.32486\n",
      "trainer/Policy log std Std              1.19003\n",
      "exploration/num steps total        232593\n",
      "exploration/num paths total          1089\n",
      "evaluation/num steps total              1.57838e+06\n",
      "evaluation/num paths total           2292\n",
      "evaluation/path length Mean           335.5\n",
      "evaluation/path length Std             20.363\n",
      "evaluation/path length Max            352\n",
      "evaluation/path length Min            280\n",
      "evaluation/Rewards Mean                 3.32426\n",
      "evaluation/Rewards Std                  0.823463\n",
      "evaluation/Rewards Max                  4.67792\n",
      "evaluation/Rewards Min                  0.669443\n",
      "evaluation/Returns Mean              1115.29\n",
      "evaluation/Returns Std                 78.7359\n",
      "evaluation/Returns Max               1177.67\n",
      "evaluation/Returns Min                899.762\n",
      "evaluation/Estimation Bias Mean       958.6\n",
      "evaluation/Estimation Bias Std        358.079\n",
      "evaluation/EB/Q_True Mean              22.033\n",
      "evaluation/EB/Q_True Std               70.5905\n",
      "evaluation/EB/Q_Pred Mean             980.633\n",
      "evaluation/EB/Q_Pred Std              348.497\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1115.29\n",
      "evaluation/Actions Mean                 0.038542\n",
      "evaluation/Actions Std                  0.603218\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.87686\n",
      "time/backward_zf1 (s)                   1.9704\n",
      "time/backward_zf2 (s)                   1.92043\n",
      "time/data sampling (s)                  0.238736\n",
      "time/data storing (s)                   0.0137542\n",
      "time/evaluation sampling (s)            0.849785\n",
      "time/exploration sampling (s)           0.172383\n",
      "time/logging (s)                        0.00483026\n",
      "time/preback_alpha (s)                  0.549709\n",
      "time/preback_policy (s)                 0.6322\n",
      "time/preback_start (s)                  0.124771\n",
      "time/preback_zf (s)                     4.9579\n",
      "time/saving (s)                         0.0163979\n",
      "time/training (s)                       2.3073\n",
      "time/epoch (s)                         15.6355\n",
      "time/total (s)                       3506.24\n",
      "Epoch                                 224\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 22:59:57.720228 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 225 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 236000\n",
      "trainer/ZF1 Loss                       76.6418\n",
      "trainer/ZF2 Loss                       91.1375\n",
      "trainer/ZF Expert Reward               13.994\n",
      "trainer/ZF Policy Reward                1.44172\n",
      "trainer/ZF CHI2 Term                  110.676\n",
      "trainer/Policy Loss                  -859.929\n",
      "trainer/Policy Grad Norm              582.242\n",
      "trainer/Policy Param Norm              44.2754\n",
      "trainer/Zf1 Grad Norm               49917.1\n",
      "trainer/Zf1 Param Norm                123.906\n",
      "trainer/Zf2 Grad Norm               42011.5\n",
      "trainer/Zf2 Param Norm                119.3\n",
      "trainer/Z Expert Predictions Mean    1074.88\n",
      "trainer/Z Expert Predictions Std      231.246\n",
      "trainer/Z Expert Predictions Max     1657.4\n",
      "trainer/Z Expert Predictions Min      362.161\n",
      "trainer/Z Policy Predictions Mean     861.511\n",
      "trainer/Z Policy Predictions Std      382.65\n",
      "trainer/Z Policy Predictions Max     1550.79\n",
      "trainer/Z Policy Predictions Min     -261.417\n",
      "trainer/Z Expert Targets Mean        1060.89\n",
      "trainer/Z Expert Targets Std          226.333\n",
      "trainer/Z Expert Targets Max         1645.42\n",
      "trainer/Z Expert Targets Min          359.838\n",
      "trainer/Z Policy Targets Mean         860.069\n",
      "trainer/Z Policy Targets Std          376.137\n",
      "trainer/Z Policy Targets Max         1558.07\n",
      "trainer/Z Policy Targets Min         -236.063\n",
      "trainer/Log Pis Mean                   14.3776\n",
      "trainer/Log Pis Std                     4.84415\n",
      "trainer/Policy mu Mean                  0.399028\n",
      "trainer/Policy mu Std                   3.06633\n",
      "trainer/Policy log std Mean            -4.2589\n",
      "trainer/Policy log std Std              1.28735\n",
      "exploration/num steps total        233593\n",
      "exploration/num paths total          1090\n",
      "evaluation/num steps total              1.58135e+06\n",
      "evaluation/num paths total           2302\n",
      "evaluation/path length Mean           297.1\n",
      "evaluation/path length Std             22.7088\n",
      "evaluation/path length Max            326\n",
      "evaluation/path length Min            275\n",
      "evaluation/Rewards Mean                 3.28415\n",
      "evaluation/Rewards Std                  0.868001\n",
      "evaluation/Rewards Max                  5.30451\n",
      "evaluation/Rewards Min                  0.682657\n",
      "evaluation/Returns Mean               975.722\n",
      "evaluation/Returns Std                 92.8563\n",
      "evaluation/Returns Max               1092.52\n",
      "evaluation/Returns Min                885.688\n",
      "evaluation/Estimation Bias Mean       780.957\n",
      "evaluation/Estimation Bias Std        484.058\n",
      "evaluation/EB/Q_True Mean              28.257\n",
      "evaluation/EB/Q_True Std               85.0169\n",
      "evaluation/EB/Q_Pred Mean             809.214\n",
      "evaluation/EB/Q_Pred Std              482.753\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            975.722\n",
      "evaluation/Actions Mean                 0.0297734\n",
      "evaluation/Actions Std                  0.607443\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70984\n",
      "time/backward_zf1 (s)                   1.82237\n",
      "time/backward_zf2 (s)                   1.75136\n",
      "time/data sampling (s)                  0.227018\n",
      "time/data storing (s)                   0.0137008\n",
      "time/evaluation sampling (s)            0.492238\n",
      "time/exploration sampling (s)           0.168745\n",
      "time/logging (s)                        0.00426837\n",
      "time/preback_alpha (s)                  0.546874\n",
      "time/preback_policy (s)                 0.598142\n",
      "time/preback_start (s)                  0.125503\n",
      "time/preback_zf (s)                     4.9686\n",
      "time/saving (s)                         0.00484542\n",
      "time/training (s)                       2.64411\n",
      "time/epoch (s)                         15.0776\n",
      "time/total (s)                       3521.33\n",
      "Epoch                                 225\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:00:12.925452 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 226 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 237000\n",
      "trainer/ZF1 Loss                      161.665\n",
      "trainer/ZF2 Loss                      177.971\n",
      "trainer/ZF Expert Reward               28.0789\n",
      "trainer/ZF Policy Reward                8.72269\n",
      "trainer/ZF CHI2 Term                  203.668\n",
      "trainer/Policy Loss                  -780.2\n",
      "trainer/Policy Grad Norm              838.278\n",
      "trainer/Policy Param Norm              44.3475\n",
      "trainer/Zf1 Grad Norm              128516\n",
      "trainer/Zf1 Param Norm                124.091\n",
      "trainer/Zf2 Grad Norm               93525.4\n",
      "trainer/Zf2 Param Norm                119.478\n",
      "trainer/Z Expert Predictions Mean    1133.68\n",
      "trainer/Z Expert Predictions Std      247.184\n",
      "trainer/Z Expert Predictions Max     1773.97\n",
      "trainer/Z Expert Predictions Min      327.073\n",
      "trainer/Z Policy Predictions Mean     778.3\n",
      "trainer/Z Policy Predictions Std      442.314\n",
      "trainer/Z Policy Predictions Max     1537.57\n",
      "trainer/Z Policy Predictions Min     -302.869\n",
      "trainer/Z Expert Targets Mean        1105.6\n",
      "trainer/Z Expert Targets Std          237.293\n",
      "trainer/Z Expert Targets Max         1670.51\n",
      "trainer/Z Expert Targets Min          343.843\n",
      "trainer/Z Policy Targets Mean         769.577\n",
      "trainer/Z Policy Targets Std          436.614\n",
      "trainer/Z Policy Targets Max         1501.49\n",
      "trainer/Z Policy Targets Min         -308.934\n",
      "trainer/Log Pis Mean                   14.6396\n",
      "trainer/Log Pis Std                     5.78894\n",
      "trainer/Policy mu Mean                  0.537504\n",
      "trainer/Policy mu Std                   3.33617\n",
      "trainer/Policy log std Mean            -4.16416\n",
      "trainer/Policy log std Std              1.36398\n",
      "exploration/num steps total        233870\n",
      "exploration/num paths total          1091\n",
      "evaluation/num steps total              1.58472e+06\n",
      "evaluation/num paths total           2312\n",
      "evaluation/path length Mean           337.2\n",
      "evaluation/path length Std             48.969\n",
      "evaluation/path length Max            409\n",
      "evaluation/path length Min            279\n",
      "evaluation/Rewards Mean                 3.3499\n",
      "evaluation/Rewards Std                  0.838182\n",
      "evaluation/Rewards Max                  5.76621\n",
      "evaluation/Rewards Min                  0.683523\n",
      "evaluation/Returns Mean              1129.59\n",
      "evaluation/Returns Std                192.522\n",
      "evaluation/Returns Max               1410.79\n",
      "evaluation/Returns Min                899.89\n",
      "evaluation/Estimation Bias Mean       818.501\n",
      "evaluation/Estimation Bias Std        427.366\n",
      "evaluation/EB/Q_True Mean              34.1162\n",
      "evaluation/EB/Q_True Std               96.6095\n",
      "evaluation/EB/Q_Pred Mean             852.618\n",
      "evaluation/EB/Q_Pred Std              419.573\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1129.59\n",
      "evaluation/Actions Mean                 0.0342569\n",
      "evaluation/Actions Std                  0.603255\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67572\n",
      "time/backward_zf1 (s)                   1.79399\n",
      "time/backward_zf2 (s)                   1.71499\n",
      "time/data sampling (s)                  0.246231\n",
      "time/data storing (s)                   0.0141081\n",
      "time/evaluation sampling (s)            0.597385\n",
      "time/exploration sampling (s)           0.17075\n",
      "time/logging (s)                        0.00462122\n",
      "time/preback_alpha (s)                  0.548109\n",
      "time/preback_policy (s)                 0.599023\n",
      "time/preback_start (s)                  0.123341\n",
      "time/preback_zf (s)                     4.95252\n",
      "time/saving (s)                         0.00481768\n",
      "time/training (s)                       2.69805\n",
      "time/epoch (s)                         15.1437\n",
      "time/total (s)                       3536.49\n",
      "Epoch                                 226\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:00:28.038129 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 227 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 238000\n",
      "trainer/ZF1 Loss                      165.143\n",
      "trainer/ZF2 Loss                      163.79\n",
      "trainer/ZF Expert Reward               14.7301\n",
      "trainer/ZF Policy Reward                0.0549388\n",
      "trainer/ZF CHI2 Term                  193.047\n",
      "trainer/Policy Loss                  -812.145\n",
      "trainer/Policy Grad Norm              691.114\n",
      "trainer/Policy Param Norm              44.4338\n",
      "trainer/Zf1 Grad Norm               39193.7\n",
      "trainer/Zf1 Param Norm                124.271\n",
      "trainer/Zf2 Grad Norm               38531.6\n",
      "trainer/Zf2 Param Norm                119.652\n",
      "trainer/Z Expert Predictions Mean    1121.8\n",
      "trainer/Z Expert Predictions Std      237.473\n",
      "trainer/Z Expert Predictions Max     1697.82\n",
      "trainer/Z Expert Predictions Min      227.372\n",
      "trainer/Z Policy Predictions Mean     800.767\n",
      "trainer/Z Policy Predictions Std      393.174\n",
      "trainer/Z Policy Predictions Max     1503.08\n",
      "trainer/Z Policy Predictions Min     -249.218\n",
      "trainer/Z Expert Targets Mean        1107.07\n",
      "trainer/Z Expert Targets Std          249.497\n",
      "trainer/Z Expert Targets Max         1655.24\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         800.712\n",
      "trainer/Z Policy Targets Std          388.651\n",
      "trainer/Z Policy Targets Max         1506.19\n",
      "trainer/Z Policy Targets Min         -211.718\n",
      "trainer/Log Pis Mean                   14.0459\n",
      "trainer/Log Pis Std                     4.57634\n",
      "trainer/Policy mu Mean                  0.206816\n",
      "trainer/Policy mu Std                   2.37714\n",
      "trainer/Policy log std Mean            -4.1567\n",
      "trainer/Policy log std Std              1.22343\n",
      "exploration/num steps total        235156\n",
      "exploration/num paths total          1095\n",
      "evaluation/num steps total              1.58729e+06\n",
      "evaluation/num paths total           2322\n",
      "evaluation/path length Mean           256.7\n",
      "evaluation/path length Std              0.781025\n",
      "evaluation/path length Max            258\n",
      "evaluation/path length Min            256\n",
      "evaluation/Rewards Mean                 3.18093\n",
      "evaluation/Rewards Std                  0.868486\n",
      "evaluation/Rewards Max                  4.58837\n",
      "evaluation/Rewards Min                  0.687432\n",
      "evaluation/Returns Mean               816.545\n",
      "evaluation/Returns Std                  3.24538\n",
      "evaluation/Returns Max                823.218\n",
      "evaluation/Returns Min                812.972\n",
      "evaluation/Estimation Bias Mean       839.533\n",
      "evaluation/Estimation Bias Std        342.715\n",
      "evaluation/EB/Q_True Mean              22.6574\n",
      "evaluation/EB/Q_True Std               72.1965\n",
      "evaluation/EB/Q_Pred Mean             862.191\n",
      "evaluation/EB/Q_Pred Std              339.902\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            816.545\n",
      "evaluation/Actions Mean                 0.0185542\n",
      "evaluation/Actions Std                  0.608324\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79136\n",
      "time/backward_zf1 (s)                   1.90632\n",
      "time/backward_zf2 (s)                   1.83328\n",
      "time/data sampling (s)                  0.240493\n",
      "time/data storing (s)                   0.0135636\n",
      "time/evaluation sampling (s)            0.395129\n",
      "time/exploration sampling (s)           0.170835\n",
      "time/logging (s)                        0.00396522\n",
      "time/preback_alpha (s)                  0.547917\n",
      "time/preback_policy (s)                 0.625727\n",
      "time/preback_start (s)                  0.124093\n",
      "time/preback_zf (s)                     4.96984\n",
      "time/saving (s)                         0.00485293\n",
      "time/training (s)                       2.42197\n",
      "time/epoch (s)                         15.0493\n",
      "time/total (s)                       3551.56\n",
      "Epoch                                 227\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:00:43.400526 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 228 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 239000\n",
      "trainer/ZF1 Loss                       72.2584\n",
      "trainer/ZF2 Loss                       56.5302\n",
      "trainer/ZF Expert Reward               13.9776\n",
      "trainer/ZF Policy Reward                2.29339\n",
      "trainer/ZF CHI2 Term                   89.8305\n",
      "trainer/Policy Loss                  -798.17\n",
      "trainer/Policy Grad Norm              891.443\n",
      "trainer/Policy Param Norm              44.5073\n",
      "trainer/Zf1 Grad Norm               49714.5\n",
      "trainer/Zf1 Param Norm                124.444\n",
      "trainer/Zf2 Grad Norm               34003.7\n",
      "trainer/Zf2 Param Norm                119.825\n",
      "trainer/Z Expert Predictions Mean    1075.7\n",
      "trainer/Z Expert Predictions Std      244.2\n",
      "trainer/Z Expert Predictions Max     1659.34\n",
      "trainer/Z Expert Predictions Min      385.294\n",
      "trainer/Z Policy Predictions Mean     796.173\n",
      "trainer/Z Policy Predictions Std      401.645\n",
      "trainer/Z Policy Predictions Max     1531.08\n",
      "trainer/Z Policy Predictions Min     -348.607\n",
      "trainer/Z Expert Targets Mean        1061.72\n",
      "trainer/Z Expert Targets Std          243.153\n",
      "trainer/Z Expert Targets Max         1654.73\n",
      "trainer/Z Expert Targets Min          377.137\n",
      "trainer/Z Policy Targets Mean         793.879\n",
      "trainer/Z Policy Targets Std          401.918\n",
      "trainer/Z Policy Targets Max         1493.25\n",
      "trainer/Z Policy Targets Min         -356.448\n",
      "trainer/Log Pis Mean                   13.8909\n",
      "trainer/Log Pis Std                     4.74857\n",
      "trainer/Policy mu Mean                  0.299837\n",
      "trainer/Policy mu Std                   2.81968\n",
      "trainer/Policy log std Mean            -4.1233\n",
      "trainer/Policy log std Std              1.14848\n",
      "exploration/num steps total        236309\n",
      "exploration/num paths total          1097\n",
      "evaluation/num steps total              1.59034e+06\n",
      "evaluation/num paths total           2332\n",
      "evaluation/path length Mean           305.3\n",
      "evaluation/path length Std             29.0725\n",
      "evaluation/path length Max            333\n",
      "evaluation/path length Min            261\n",
      "evaluation/Rewards Mean                 3.29112\n",
      "evaluation/Rewards Std                  0.849329\n",
      "evaluation/Rewards Max                  4.89668\n",
      "evaluation/Rewards Min                  0.690413\n",
      "evaluation/Returns Mean              1004.78\n",
      "evaluation/Returns Std                115\n",
      "evaluation/Returns Max               1112.46\n",
      "evaluation/Returns Min                830.255\n",
      "evaluation/Estimation Bias Mean       802.592\n",
      "evaluation/Estimation Bias Std        416.362\n",
      "evaluation/EB/Q_True Mean              28.1103\n",
      "evaluation/EB/Q_True Std               85.022\n",
      "evaluation/EB/Q_Pred Mean             830.702\n",
      "evaluation/EB/Q_Pred Std              414.479\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1004.78\n",
      "evaluation/Actions Mean                 0.0335135\n",
      "evaluation/Actions Std                  0.607318\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83614\n",
      "time/backward_zf1 (s)                   1.93055\n",
      "time/backward_zf2 (s)                   1.87387\n",
      "time/data sampling (s)                  0.245228\n",
      "time/data storing (s)                   0.0139941\n",
      "time/evaluation sampling (s)            0.511975\n",
      "time/exploration sampling (s)           0.173598\n",
      "time/logging (s)                        0.00472055\n",
      "time/preback_alpha (s)                  0.556331\n",
      "time/preback_policy (s)                 0.629563\n",
      "time/preback_start (s)                  0.125628\n",
      "time/preback_zf (s)                     4.97689\n",
      "time/saving (s)                         0.0161726\n",
      "time/training (s)                       2.40058\n",
      "time/epoch (s)                         15.2952\n",
      "time/total (s)                       3566.88\n",
      "Epoch                                 228\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:00:59.269350 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 229 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 240000\n",
      "trainer/ZF1 Loss                       95.9053\n",
      "trainer/ZF2 Loss                       90.2979\n",
      "trainer/ZF Expert Reward                5.40779\n",
      "trainer/ZF Policy Reward              -10.1252\n",
      "trainer/ZF CHI2 Term                  122.246\n",
      "trainer/Policy Loss                  -830.479\n",
      "trainer/Policy Grad Norm              691.412\n",
      "trainer/Policy Param Norm              44.5893\n",
      "trainer/Zf1 Grad Norm               41778.6\n",
      "trainer/Zf1 Param Norm                124.622\n",
      "trainer/Zf2 Grad Norm               38696.4\n",
      "trainer/Zf2 Param Norm                119.999\n",
      "trainer/Z Expert Predictions Mean    1109.82\n",
      "trainer/Z Expert Predictions Std      239.592\n",
      "trainer/Z Expert Predictions Max     1628.4\n",
      "trainer/Z Expert Predictions Min      381.082\n",
      "trainer/Z Policy Predictions Mean     814.544\n",
      "trainer/Z Policy Predictions Std      373.244\n",
      "trainer/Z Policy Predictions Max     1478\n",
      "trainer/Z Policy Predictions Min     -247.442\n",
      "trainer/Z Expert Targets Mean        1104.41\n",
      "trainer/Z Expert Targets Std          240.354\n",
      "trainer/Z Expert Targets Max         1633.77\n",
      "trainer/Z Expert Targets Min          362.92\n",
      "trainer/Z Policy Targets Mean         824.669\n",
      "trainer/Z Policy Targets Std          372.493\n",
      "trainer/Z Policy Targets Max         1466.46\n",
      "trainer/Z Policy Targets Min         -186.865\n",
      "trainer/Log Pis Mean                   13.7492\n",
      "trainer/Log Pis Std                     5.27825\n",
      "trainer/Policy mu Mean                  0.343477\n",
      "trainer/Policy mu Std                   2.76219\n",
      "trainer/Policy log std Mean            -4.16535\n",
      "trainer/Policy log std Std              1.23348\n",
      "exploration/num steps total        236794\n",
      "exploration/num paths total          1098\n",
      "evaluation/num steps total              1.59464e+06\n",
      "evaluation/num paths total           2342\n",
      "evaluation/path length Mean           429.8\n",
      "evaluation/path length Std            163.758\n",
      "evaluation/path length Max            869\n",
      "evaluation/path length Min            334\n",
      "evaluation/Rewards Mean                 3.44067\n",
      "evaluation/Rewards Std                  0.775546\n",
      "evaluation/Rewards Max                  4.70065\n",
      "evaluation/Rewards Min                  0.700866\n",
      "evaluation/Returns Mean              1478.8\n",
      "evaluation/Returns Std                628.456\n",
      "evaluation/Returns Max               3159.38\n",
      "evaluation/Returns Min               1108.26\n",
      "evaluation/Estimation Bias Mean       824.461\n",
      "evaluation/Estimation Bias Std        414.591\n",
      "evaluation/EB/Q_True Mean              59.232\n",
      "evaluation/EB/Q_True Std              124.837\n",
      "evaluation/EB/Q_Pred Mean             883.693\n",
      "evaluation/EB/Q_Pred Std              411.1\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1478.8\n",
      "evaluation/Actions Mean                 0.0297175\n",
      "evaluation/Actions Std                  0.60184\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72053\n",
      "time/backward_zf1 (s)                   1.84187\n",
      "time/backward_zf2 (s)                   1.77278\n",
      "time/data sampling (s)                  0.250946\n",
      "time/data storing (s)                   0.013541\n",
      "time/evaluation sampling (s)            1.20888\n",
      "time/exploration sampling (s)           0.16862\n",
      "time/logging (s)                        0.00894454\n",
      "time/preback_alpha (s)                  0.548078\n",
      "time/preback_policy (s)                 0.614469\n",
      "time/preback_start (s)                  0.124812\n",
      "time/preback_zf (s)                     4.95378\n",
      "time/saving (s)                         0.0236573\n",
      "time/training (s)                       2.55855\n",
      "time/epoch (s)                         15.8094\n",
      "time/total (s)                       3582.71\n",
      "Epoch                                 229\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:01:15.447167 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 230 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 241000\n",
      "trainer/ZF1 Loss                       61.7186\n",
      "trainer/ZF2 Loss                       61.5597\n",
      "trainer/ZF Expert Reward               14.2456\n",
      "trainer/ZF Policy Reward                3.38727\n",
      "trainer/ZF CHI2 Term                   86.3255\n",
      "trainer/Policy Loss                  -787.903\n",
      "trainer/Policy Grad Norm              832.326\n",
      "trainer/Policy Param Norm              44.6537\n",
      "trainer/Zf1 Grad Norm               54364.3\n",
      "trainer/Zf1 Param Norm                124.811\n",
      "trainer/Zf2 Grad Norm               59168.9\n",
      "trainer/Zf2 Param Norm                120.178\n",
      "trainer/Z Expert Predictions Mean    1111.57\n",
      "trainer/Z Expert Predictions Std      232.155\n",
      "trainer/Z Expert Predictions Max     1640.26\n",
      "trainer/Z Expert Predictions Min      600.97\n",
      "trainer/Z Policy Predictions Mean     786.413\n",
      "trainer/Z Policy Predictions Std      379.656\n",
      "trainer/Z Policy Predictions Max     1520.32\n",
      "trainer/Z Policy Predictions Min     -268.035\n",
      "trainer/Z Expert Targets Mean        1097.32\n",
      "trainer/Z Expert Targets Std          232.611\n",
      "trainer/Z Expert Targets Max         1640.78\n",
      "trainer/Z Expert Targets Min          568.979\n",
      "trainer/Z Policy Targets Mean         783.026\n",
      "trainer/Z Policy Targets Std          376.676\n",
      "trainer/Z Policy Targets Max         1513.43\n",
      "trainer/Z Policy Targets Min         -242.447\n",
      "trainer/Log Pis Mean                   13.9677\n",
      "trainer/Log Pis Std                     5.39386\n",
      "trainer/Policy mu Mean                  0.339757\n",
      "trainer/Policy mu Std                   2.64895\n",
      "trainer/Policy log std Mean            -4.10936\n",
      "trainer/Policy log std Std              1.17569\n",
      "exploration/num steps total        238124\n",
      "exploration/num paths total          1100\n",
      "evaluation/num steps total              1.60316e+06\n",
      "evaluation/num paths total           2353\n",
      "evaluation/path length Mean           774.545\n",
      "evaluation/path length Std            235.957\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            350\n",
      "evaluation/Rewards Mean                 3.52865\n",
      "evaluation/Rewards Std                  0.648303\n",
      "evaluation/Rewards Max                  4.7296\n",
      "evaluation/Rewards Min                  0.693657\n",
      "evaluation/Returns Mean              2733.1\n",
      "evaluation/Returns Std                864.213\n",
      "evaluation/Returns Max               3569.05\n",
      "evaluation/Returns Min               1176.71\n",
      "evaluation/Estimation Bias Mean       997.038\n",
      "evaluation/Estimation Bias Std        291.704\n",
      "evaluation/EB/Q_True Mean              38.7741\n",
      "evaluation/EB/Q_True Std              109.382\n",
      "evaluation/EB/Q_Pred Mean            1035.81\n",
      "evaluation/EB/Q_Pred Std              258.592\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2733.1\n",
      "evaluation/Actions Mean                 0.0478994\n",
      "evaluation/Actions Std                  0.597229\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84822\n",
      "time/backward_zf1 (s)                   1.95747\n",
      "time/backward_zf2 (s)                   1.89261\n",
      "time/data sampling (s)                  0.235604\n",
      "time/data storing (s)                   0.0136302\n",
      "time/evaluation sampling (s)            1.36962\n",
      "time/exploration sampling (s)           0.170969\n",
      "time/logging (s)                        0.0101527\n",
      "time/preback_alpha (s)                  0.553931\n",
      "time/preback_policy (s)                 0.624396\n",
      "time/preback_start (s)                  0.12473\n",
      "time/preback_zf (s)                     4.97464\n",
      "time/saving (s)                         0.00532641\n",
      "time/training (s)                       2.3354\n",
      "time/epoch (s)                         16.1167\n",
      "time/total (s)                       3598.84\n",
      "Epoch                                 230\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:01:31.491463 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 231 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 242000\n",
      "trainer/ZF1 Loss                       68.9222\n",
      "trainer/ZF2 Loss                       47.4126\n",
      "trainer/ZF Expert Reward                5.78684\n",
      "trainer/ZF Policy Reward               -6.41911\n",
      "trainer/ZF CHI2 Term                   84.7365\n",
      "trainer/Policy Loss                  -788.256\n",
      "trainer/Policy Grad Norm              864.86\n",
      "trainer/Policy Param Norm              44.7182\n",
      "trainer/Zf1 Grad Norm               82885.9\n",
      "trainer/Zf1 Param Norm                124.993\n",
      "trainer/Zf2 Grad Norm               23107\n",
      "trainer/Zf2 Param Norm                120.353\n",
      "trainer/Z Expert Predictions Mean    1115.26\n",
      "trainer/Z Expert Predictions Std      226.712\n",
      "trainer/Z Expert Predictions Max     1676.14\n",
      "trainer/Z Expert Predictions Min      506.21\n",
      "trainer/Z Policy Predictions Mean     777.156\n",
      "trainer/Z Policy Predictions Std      397.683\n",
      "trainer/Z Policy Predictions Max     1468.47\n",
      "trainer/Z Policy Predictions Min     -355.65\n",
      "trainer/Z Expert Targets Mean        1109.48\n",
      "trainer/Z Expert Targets Std          227.428\n",
      "trainer/Z Expert Targets Max         1663.79\n",
      "trainer/Z Expert Targets Min          484.397\n",
      "trainer/Z Policy Targets Mean         783.575\n",
      "trainer/Z Policy Targets Std          391.742\n",
      "trainer/Z Policy Targets Max         1490.82\n",
      "trainer/Z Policy Targets Min         -304.714\n",
      "trainer/Log Pis Mean                   14.5082\n",
      "trainer/Log Pis Std                     4.91029\n",
      "trainer/Policy mu Mean                  0.414468\n",
      "trainer/Policy mu Std                   2.99987\n",
      "trainer/Policy log std Mean            -4.14776\n",
      "trainer/Policy log std Std              1.28397\n",
      "exploration/num steps total        238737\n",
      "exploration/num paths total          1102\n",
      "evaluation/num steps total              1.61225e+06\n",
      "evaluation/num paths total           2365\n",
      "evaluation/path length Mean           757.167\n",
      "evaluation/path length Std            254.581\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            334\n",
      "evaluation/Rewards Mean                 3.54152\n",
      "evaluation/Rewards Std                  0.644846\n",
      "evaluation/Rewards Max                  4.74521\n",
      "evaluation/Rewards Min                  0.707359\n",
      "evaluation/Returns Mean              2681.52\n",
      "evaluation/Returns Std                933.325\n",
      "evaluation/Returns Max               3606.62\n",
      "evaluation/Returns Min               1112\n",
      "evaluation/Estimation Bias Mean       967.938\n",
      "evaluation/Estimation Bias Std        377.07\n",
      "evaluation/EB/Q_True Mean              35.9103\n",
      "evaluation/EB/Q_True Std              105.125\n",
      "evaluation/EB/Q_Pred Mean            1003.85\n",
      "evaluation/EB/Q_Pred Std              351.37\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2681.52\n",
      "evaluation/Actions Mean                 0.0440524\n",
      "evaluation/Actions Std                  0.597281\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67037\n",
      "time/backward_zf1 (s)                   1.79658\n",
      "time/backward_zf2 (s)                   1.71504\n",
      "time/data sampling (s)                  0.252023\n",
      "time/data storing (s)                   0.013714\n",
      "time/evaluation sampling (s)            1.44338\n",
      "time/exploration sampling (s)           0.169292\n",
      "time/logging (s)                        0.0108651\n",
      "time/preback_alpha (s)                  0.549193\n",
      "time/preback_policy (s)                 0.600161\n",
      "time/preback_start (s)                  0.123714\n",
      "time/preback_zf (s)                     4.9526\n",
      "time/saving (s)                         0.00522746\n",
      "time/training (s)                       2.67343\n",
      "time/epoch (s)                         15.9756\n",
      "time/total (s)                       3614.84\n",
      "Epoch                                 231\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:01:46.715906 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 232 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 243000\n",
      "trainer/ZF1 Loss                      366.175\n",
      "trainer/ZF2 Loss                      412.746\n",
      "trainer/ZF Expert Reward               10.3071\n",
      "trainer/ZF Policy Reward                4.23549\n",
      "trainer/ZF CHI2 Term                  409.698\n",
      "trainer/Policy Loss                  -818.501\n",
      "trainer/Policy Grad Norm              831.593\n",
      "trainer/Policy Param Norm              44.7779\n",
      "trainer/Zf1 Grad Norm              101530\n",
      "trainer/Zf1 Param Norm                125.168\n",
      "trainer/Zf2 Grad Norm               97719.8\n",
      "trainer/Zf2 Param Norm                120.539\n",
      "trainer/Z Expert Predictions Mean    1108.4\n",
      "trainer/Z Expert Predictions Std      234.826\n",
      "trainer/Z Expert Predictions Max     1643.63\n",
      "trainer/Z Expert Predictions Min      521.842\n",
      "trainer/Z Policy Predictions Mean     820.765\n",
      "trainer/Z Policy Predictions Std      378.713\n",
      "trainer/Z Policy Predictions Max     1471.89\n",
      "trainer/Z Policy Predictions Min     -291.372\n",
      "trainer/Z Expert Targets Mean        1098.1\n",
      "trainer/Z Expert Targets Std          238.205\n",
      "trainer/Z Expert Targets Max         1631.31\n",
      "trainer/Z Expert Targets Min          462.679\n",
      "trainer/Z Policy Targets Mean         816.53\n",
      "trainer/Z Policy Targets Std          379.967\n",
      "trainer/Z Policy Targets Max         1453.21\n",
      "trainer/Z Policy Targets Min         -260.531\n",
      "trainer/Log Pis Mean                   14.3087\n",
      "trainer/Log Pis Std                     5.55504\n",
      "trainer/Policy mu Mean                  0.328704\n",
      "trainer/Policy mu Std                   2.47786\n",
      "trainer/Policy log std Mean            -4.26823\n",
      "trainer/Policy log std Std              1.23446\n",
      "exploration/num steps total        239070\n",
      "exploration/num paths total          1103\n",
      "evaluation/num steps total              1.61485e+06\n",
      "evaluation/num paths total           2375\n",
      "evaluation/path length Mean           260\n",
      "evaluation/path length Std              1.41421\n",
      "evaluation/path length Max            263\n",
      "evaluation/path length Min            258\n",
      "evaluation/Rewards Mean                 3.18135\n",
      "evaluation/Rewards Std                  0.867807\n",
      "evaluation/Rewards Max                  4.57664\n",
      "evaluation/Rewards Min                  0.70411\n",
      "evaluation/Returns Mean               827.152\n",
      "evaluation/Returns Std                  4.64226\n",
      "evaluation/Returns Max                837.187\n",
      "evaluation/Returns Min                821.688\n",
      "evaluation/Estimation Bias Mean       861.752\n",
      "evaluation/Estimation Bias Std        379.578\n",
      "evaluation/EB/Q_True Mean              22.9879\n",
      "evaluation/EB/Q_True Std               72.9316\n",
      "evaluation/EB/Q_Pred Mean             884.74\n",
      "evaluation/EB/Q_Pred Std              376.34\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            827.152\n",
      "evaluation/Actions Mean                 0.0342764\n",
      "evaluation/Actions Std                  0.613314\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80948\n",
      "time/backward_zf1 (s)                   1.91425\n",
      "time/backward_zf2 (s)                   1.8647\n",
      "time/data sampling (s)                  0.25512\n",
      "time/data storing (s)                   0.0144552\n",
      "time/evaluation sampling (s)            0.397795\n",
      "time/exploration sampling (s)           0.172198\n",
      "time/logging (s)                        0.00389962\n",
      "time/preback_alpha (s)                  0.557382\n",
      "time/preback_policy (s)                 0.630348\n",
      "time/preback_start (s)                  0.12371\n",
      "time/preback_zf (s)                     4.99785\n",
      "time/saving (s)                         0.00473833\n",
      "time/training (s)                       2.40453\n",
      "time/epoch (s)                         15.1505\n",
      "time/total (s)                       3630.01\n",
      "Epoch                                 232\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:02:02.694915 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 233 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 244000\n",
      "trainer/ZF1 Loss                       72.333\n",
      "trainer/ZF2 Loss                      108.008\n",
      "trainer/ZF Expert Reward               12.1807\n",
      "trainer/ZF Policy Reward               -0.877989\n",
      "trainer/ZF CHI2 Term                  117.128\n",
      "trainer/Policy Loss                  -838.151\n",
      "trainer/Policy Grad Norm              923.229\n",
      "trainer/Policy Param Norm              44.8359\n",
      "trainer/Zf1 Grad Norm               28045.9\n",
      "trainer/Zf1 Param Norm                125.352\n",
      "trainer/Zf2 Grad Norm               71382.4\n",
      "trainer/Zf2 Param Norm                120.719\n",
      "trainer/Z Expert Predictions Mean    1096.25\n",
      "trainer/Z Expert Predictions Std      236.19\n",
      "trainer/Z Expert Predictions Max     1692.11\n",
      "trainer/Z Expert Predictions Min      331.622\n",
      "trainer/Z Policy Predictions Mean     834.829\n",
      "trainer/Z Policy Predictions Std      370.357\n",
      "trainer/Z Policy Predictions Max     1590.71\n",
      "trainer/Z Policy Predictions Min     -281.101\n",
      "trainer/Z Expert Targets Mean        1084.07\n",
      "trainer/Z Expert Targets Std          236.953\n",
      "trainer/Z Expert Targets Max         1663.93\n",
      "trainer/Z Expert Targets Min          305.893\n",
      "trainer/Z Policy Targets Mean         835.707\n",
      "trainer/Z Policy Targets Std          368.777\n",
      "trainer/Z Policy Targets Max         1624.49\n",
      "trainer/Z Policy Targets Min         -250.274\n",
      "trainer/Log Pis Mean                   14.039\n",
      "trainer/Log Pis Std                     4.92111\n",
      "trainer/Policy mu Mean                  0.415986\n",
      "trainer/Policy mu Std                   2.82757\n",
      "trainer/Policy log std Mean            -4.25382\n",
      "trainer/Policy log std Std              1.21371\n",
      "exploration/num steps total        240070\n",
      "exploration/num paths total          1104\n",
      "evaluation/num steps total              1.62485e+06\n",
      "evaluation/num paths total           2385\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52036\n",
      "evaluation/Rewards Std                  0.584205\n",
      "evaluation/Rewards Max                  4.77473\n",
      "evaluation/Rewards Min                  0.706636\n",
      "evaluation/Returns Mean              3520.36\n",
      "evaluation/Returns Std                  8.36929\n",
      "evaluation/Returns Max               3536.73\n",
      "evaluation/Returns Min               3506.78\n",
      "evaluation/Estimation Bias Mean      1003.52\n",
      "evaluation/Estimation Bias Std        206.94\n",
      "evaluation/EB/Q_True Mean              32.4797\n",
      "evaluation/EB/Q_True Std              100.137\n",
      "evaluation/EB/Q_Pred Mean            1036\n",
      "evaluation/EB/Q_Pred Std              186.811\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3520.36\n",
      "evaluation/Actions Mean                 0.0433617\n",
      "evaluation/Actions Std                  0.587271\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.69163\n",
      "time/backward_zf1 (s)                   1.80661\n",
      "time/backward_zf2 (s)                   1.73708\n",
      "time/data sampling (s)                  0.254376\n",
      "time/data storing (s)                   0.0134804\n",
      "time/evaluation sampling (s)            1.33671\n",
      "time/exploration sampling (s)           0.16903\n",
      "time/logging (s)                        0.0118069\n",
      "time/preback_alpha (s)                  0.551287\n",
      "time/preback_policy (s)                 0.604732\n",
      "time/preback_start (s)                  0.124744\n",
      "time/preback_zf (s)                     4.96495\n",
      "time/saving (s)                         0.00680823\n",
      "time/training (s)                       2.64823\n",
      "time/epoch (s)                         15.9215\n",
      "time/total (s)                       3645.95\n",
      "Epoch                                 233\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:02:18.817011 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 234 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 245000\n",
      "trainer/ZF1 Loss                       59.9117\n",
      "trainer/ZF2 Loss                       69.0779\n",
      "trainer/ZF Expert Reward               10.1672\n",
      "trainer/ZF Policy Reward               -3.01173\n",
      "trainer/ZF CHI2 Term                   92.4508\n",
      "trainer/Policy Loss                  -810.876\n",
      "trainer/Policy Grad Norm              697.843\n",
      "trainer/Policy Param Norm              44.8882\n",
      "trainer/Zf1 Grad Norm               42677\n",
      "trainer/Zf1 Param Norm                125.534\n",
      "trainer/Zf2 Grad Norm               61692.9\n",
      "trainer/Zf2 Param Norm                120.892\n",
      "trainer/Z Expert Predictions Mean    1116.86\n",
      "trainer/Z Expert Predictions Std      228.277\n",
      "trainer/Z Expert Predictions Max     1654.2\n",
      "trainer/Z Expert Predictions Min      523.732\n",
      "trainer/Z Policy Predictions Mean     801.739\n",
      "trainer/Z Policy Predictions Std      389.823\n",
      "trainer/Z Policy Predictions Max     1473.76\n",
      "trainer/Z Policy Predictions Min     -341.456\n",
      "trainer/Z Expert Targets Mean        1106.69\n",
      "trainer/Z Expert Targets Std          228.041\n",
      "trainer/Z Expert Targets Max         1627.88\n",
      "trainer/Z Expert Targets Min          496.179\n",
      "trainer/Z Policy Targets Mean         804.751\n",
      "trainer/Z Policy Targets Std          386.257\n",
      "trainer/Z Policy Targets Max         1490.74\n",
      "trainer/Z Policy Targets Min         -341.734\n",
      "trainer/Log Pis Mean                   14.9264\n",
      "trainer/Log Pis Std                     5.8251\n",
      "trainer/Policy mu Mean                  0.303946\n",
      "trainer/Policy mu Std                   2.87808\n",
      "trainer/Policy log std Mean            -4.22212\n",
      "trainer/Policy log std Std              1.22999\n",
      "exploration/num steps total        241413\n",
      "exploration/num paths total          1107\n",
      "evaluation/num steps total              1.63485e+06\n",
      "evaluation/num paths total           2395\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.54205\n",
      "evaluation/Rewards Std                  0.597564\n",
      "evaluation/Rewards Max                  4.79714\n",
      "evaluation/Rewards Min                  0.700577\n",
      "evaluation/Returns Mean              3542.05\n",
      "evaluation/Returns Std                 14.4251\n",
      "evaluation/Returns Max               3562.62\n",
      "evaluation/Returns Min               3509.42\n",
      "evaluation/Estimation Bias Mean      1009.74\n",
      "evaluation/Estimation Bias Std        225.986\n",
      "evaluation/EB/Q_True Mean              32.8843\n",
      "evaluation/EB/Q_True Std              101.204\n",
      "evaluation/EB/Q_Pred Mean            1042.63\n",
      "evaluation/EB/Q_Pred Std              200.029\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3542.05\n",
      "evaluation/Actions Mean                 0.0405713\n",
      "evaluation/Actions Std                  0.590456\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8301\n",
      "time/backward_zf1 (s)                   1.9327\n",
      "time/backward_zf2 (s)                   1.88628\n",
      "time/data sampling (s)                  0.24686\n",
      "time/data storing (s)                   0.0140051\n",
      "time/evaluation sampling (s)            1.34617\n",
      "time/exploration sampling (s)           0.170484\n",
      "time/logging (s)                        0.0114816\n",
      "time/preback_alpha (s)                  0.553626\n",
      "time/preback_policy (s)                 0.625704\n",
      "time/preback_start (s)                  0.124688\n",
      "time/preback_zf (s)                     4.97077\n",
      "time/saving (s)                         0.00525236\n",
      "time/training (s)                       2.3386\n",
      "time/epoch (s)                         16.0567\n",
      "time/total (s)                       3662.03\n",
      "Epoch                                 234\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:02:34.092057 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 235 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 246000\n",
      "trainer/ZF1 Loss                       79.3987\n",
      "trainer/ZF2 Loss                      114.625\n",
      "trainer/ZF Expert Reward               15.5276\n",
      "trainer/ZF Policy Reward               -0.0437833\n",
      "trainer/ZF CHI2 Term                  126.794\n",
      "trainer/Policy Loss                  -829.886\n",
      "trainer/Policy Grad Norm              829.107\n",
      "trainer/Policy Param Norm              44.9383\n",
      "trainer/Zf1 Grad Norm               37829.3\n",
      "trainer/Zf1 Param Norm                125.722\n",
      "trainer/Zf2 Grad Norm               49364.9\n",
      "trainer/Zf2 Param Norm                121.072\n",
      "trainer/Z Expert Predictions Mean    1105.17\n",
      "trainer/Z Expert Predictions Std      247.019\n",
      "trainer/Z Expert Predictions Max     1628.7\n",
      "trainer/Z Expert Predictions Min      425.556\n",
      "trainer/Z Policy Predictions Mean     822.82\n",
      "trainer/Z Policy Predictions Std      361.8\n",
      "trainer/Z Policy Predictions Max     1433.79\n",
      "trainer/Z Policy Predictions Min     -389.088\n",
      "trainer/Z Expert Targets Mean        1089.64\n",
      "trainer/Z Expert Targets Std          245.804\n",
      "trainer/Z Expert Targets Max         1644.05\n",
      "trainer/Z Expert Targets Min          402.657\n",
      "trainer/Z Policy Targets Mean         822.863\n",
      "trainer/Z Policy Targets Std          352.665\n",
      "trainer/Z Policy Targets Max         1447.32\n",
      "trainer/Z Policy Targets Min         -329.899\n",
      "trainer/Log Pis Mean                   14.3544\n",
      "trainer/Log Pis Std                     6.02466\n",
      "trainer/Policy mu Mean                  0.438056\n",
      "trainer/Policy mu Std                   2.83463\n",
      "trainer/Policy log std Mean            -4.07925\n",
      "trainer/Policy log std Std              1.359\n",
      "exploration/num steps total        242543\n",
      "exploration/num paths total          1109\n",
      "evaluation/num steps total              1.63768e+06\n",
      "evaluation/num paths total           2405\n",
      "evaluation/path length Mean           283.6\n",
      "evaluation/path length Std             18.211\n",
      "evaluation/path length Max            336\n",
      "evaluation/path length Min            267\n",
      "evaluation/Rewards Mean                 3.23774\n",
      "evaluation/Rewards Std                  0.854886\n",
      "evaluation/Rewards Max                  4.67604\n",
      "evaluation/Rewards Min                  0.721715\n",
      "evaluation/Returns Mean               918.224\n",
      "evaluation/Returns Std                 71.7349\n",
      "evaluation/Returns Max               1124.68\n",
      "evaluation/Returns Min                852.532\n",
      "evaluation/Estimation Bias Mean       814.841\n",
      "evaluation/Estimation Bias Std        391.083\n",
      "evaluation/EB/Q_True Mean              30.6706\n",
      "evaluation/EB/Q_True Std               88.582\n",
      "evaluation/EB/Q_Pred Mean             845.512\n",
      "evaluation/EB/Q_Pred Std              384.922\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            918.224\n",
      "evaluation/Actions Mean                 0.0391424\n",
      "evaluation/Actions Std                  0.589638\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81572\n",
      "time/backward_zf1 (s)                   1.92513\n",
      "time/backward_zf2 (s)                   1.86181\n",
      "time/data sampling (s)                  0.24181\n",
      "time/data storing (s)                   0.0134614\n",
      "time/evaluation sampling (s)            0.514766\n",
      "time/exploration sampling (s)           0.168016\n",
      "time/logging (s)                        0.00479605\n",
      "time/preback_alpha (s)                  0.549111\n",
      "time/preback_policy (s)                 0.619946\n",
      "time/preback_start (s)                  0.123739\n",
      "time/preback_zf (s)                     4.96307\n",
      "time/saving (s)                         0.00555044\n",
      "time/training (s)                       2.39486\n",
      "time/epoch (s)                         15.2018\n",
      "time/total (s)                       3677.25\n",
      "Epoch                                 235\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:02:49.704125 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 236 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 247000\n",
      "trainer/ZF1 Loss                       65.1133\n",
      "trainer/ZF2 Loss                       56.4043\n",
      "trainer/ZF Expert Reward                9.11343\n",
      "trainer/ZF Policy Reward               -0.734457\n",
      "trainer/ZF CHI2 Term                   85.314\n",
      "trainer/Policy Loss                  -812.102\n",
      "trainer/Policy Grad Norm              670.746\n",
      "trainer/Policy Param Norm              44.997\n",
      "trainer/Zf1 Grad Norm               32618.8\n",
      "trainer/Zf1 Param Norm                125.908\n",
      "trainer/Zf2 Grad Norm               33582.4\n",
      "trainer/Zf2 Param Norm                121.264\n",
      "trainer/Z Expert Predictions Mean    1090.73\n",
      "trainer/Z Expert Predictions Std      251.455\n",
      "trainer/Z Expert Predictions Max     1623.97\n",
      "trainer/Z Expert Predictions Min      235.784\n",
      "trainer/Z Policy Predictions Mean     808.616\n",
      "trainer/Z Policy Predictions Std      404.55\n",
      "trainer/Z Policy Predictions Max     1466.69\n",
      "trainer/Z Policy Predictions Min     -296.167\n",
      "trainer/Z Expert Targets Mean        1081.62\n",
      "trainer/Z Expert Targets Std          255.355\n",
      "trainer/Z Expert Targets Max         1649.53\n",
      "trainer/Z Expert Targets Min          143.151\n",
      "trainer/Z Policy Targets Mean         809.35\n",
      "trainer/Z Policy Targets Std          403.025\n",
      "trainer/Z Policy Targets Max         1532.07\n",
      "trainer/Z Policy Targets Min         -296.61\n",
      "trainer/Log Pis Mean                   14.8559\n",
      "trainer/Log Pis Std                     5.45513\n",
      "trainer/Policy mu Mean                  0.381172\n",
      "trainer/Policy mu Std                   3.08158\n",
      "trainer/Policy log std Mean            -4.119\n",
      "trainer/Policy log std Std              1.29308\n",
      "exploration/num steps total        242884\n",
      "exploration/num paths total          1110\n",
      "evaluation/num steps total              1.64096e+06\n",
      "evaluation/num paths total           2415\n",
      "evaluation/path length Mean           328.2\n",
      "evaluation/path length Std             15.8164\n",
      "evaluation/path length Max            335\n",
      "evaluation/path length Min            281\n",
      "evaluation/Rewards Mean                 3.31439\n",
      "evaluation/Rewards Std                  0.825229\n",
      "evaluation/Rewards Max                  4.62925\n",
      "evaluation/Rewards Min                  0.698179\n",
      "evaluation/Returns Mean              1087.78\n",
      "evaluation/Returns Std                 60.5365\n",
      "evaluation/Returns Max               1113.06\n",
      "evaluation/Returns Min                906.697\n",
      "evaluation/Estimation Bias Mean       875.466\n",
      "evaluation/Estimation Bias Std        369.175\n",
      "evaluation/EB/Q_True Mean              25.9185\n",
      "evaluation/EB/Q_True Std               81.7404\n",
      "evaluation/EB/Q_Pred Mean             901.384\n",
      "evaluation/EB/Q_Pred Std              363.678\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1087.78\n",
      "evaluation/Actions Mean                 0.0317369\n",
      "evaluation/Actions Std                  0.602464\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78147\n",
      "time/backward_zf1 (s)                   1.89399\n",
      "time/backward_zf2 (s)                   1.82539\n",
      "time/data sampling (s)                  0.232401\n",
      "time/data storing (s)                   0.0135109\n",
      "time/evaluation sampling (s)            0.947213\n",
      "time/exploration sampling (s)           0.166503\n",
      "time/logging (s)                        0.00457645\n",
      "time/preback_alpha (s)                  0.544211\n",
      "time/preback_policy (s)                 0.609853\n",
      "time/preback_start (s)                  0.123125\n",
      "time/preback_zf (s)                     4.94732\n",
      "time/saving (s)                         0.00504323\n",
      "time/training (s)                       2.44972\n",
      "time/epoch (s)                         15.5443\n",
      "time/total (s)                       3692.82\n",
      "Epoch                                 236\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:03:05.854438 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 237 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 248000\n",
      "trainer/ZF1 Loss                      289.663\n",
      "trainer/ZF2 Loss                      257.441\n",
      "trainer/ZF Expert Reward                5.2554\n",
      "trainer/ZF Policy Reward               -1.43456\n",
      "trainer/ZF CHI2 Term                  294.406\n",
      "trainer/Policy Loss                  -773.955\n",
      "trainer/Policy Grad Norm              709.435\n",
      "trainer/Policy Param Norm              45.0553\n",
      "trainer/Zf1 Grad Norm               59417.6\n",
      "trainer/Zf1 Param Norm                126.104\n",
      "trainer/Zf2 Grad Norm               37201.4\n",
      "trainer/Zf2 Param Norm                121.477\n",
      "trainer/Z Expert Predictions Mean    1079.74\n",
      "trainer/Z Expert Predictions Std      229.572\n",
      "trainer/Z Expert Predictions Max     1605.45\n",
      "trainer/Z Expert Predictions Min      294.638\n",
      "trainer/Z Policy Predictions Mean     771.396\n",
      "trainer/Z Policy Predictions Std      391.43\n",
      "trainer/Z Policy Predictions Max     1576.38\n",
      "trainer/Z Policy Predictions Min     -331.425\n",
      "trainer/Z Expert Targets Mean        1074.48\n",
      "trainer/Z Expert Targets Std          234.366\n",
      "trainer/Z Expert Targets Max         1607.31\n",
      "trainer/Z Expert Targets Min          285.74\n",
      "trainer/Z Policy Targets Mean         772.831\n",
      "trainer/Z Policy Targets Std          390.409\n",
      "trainer/Z Policy Targets Max         1557.77\n",
      "trainer/Z Policy Targets Min         -298.284\n",
      "trainer/Log Pis Mean                   14.3073\n",
      "trainer/Log Pis Std                     5.39327\n",
      "trainer/Policy mu Mean                  0.300679\n",
      "trainer/Policy mu Std                   2.67687\n",
      "trainer/Policy log std Mean            -4.17127\n",
      "trainer/Policy log std Std              1.2678\n",
      "exploration/num steps total        245278\n",
      "exploration/num paths total          1114\n",
      "evaluation/num steps total              1.65096e+06\n",
      "evaluation/num paths total           2425\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52747\n",
      "evaluation/Rewards Std                  0.601633\n",
      "evaluation/Rewards Max                  4.87948\n",
      "evaluation/Rewards Min                  0.735193\n",
      "evaluation/Returns Mean              3527.47\n",
      "evaluation/Returns Std                 15.2941\n",
      "evaluation/Returns Max               3553.9\n",
      "evaluation/Returns Min               3505.59\n",
      "evaluation/Estimation Bias Mean       984.962\n",
      "evaluation/Estimation Bias Std        212.892\n",
      "evaluation/EB/Q_True Mean              32.5277\n",
      "evaluation/EB/Q_True Std              100.241\n",
      "evaluation/EB/Q_Pred Mean            1017.49\n",
      "evaluation/EB/Q_Pred Std              189.933\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3527.47\n",
      "evaluation/Actions Mean                 0.0437236\n",
      "evaluation/Actions Std                  0.588332\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80401\n",
      "time/backward_zf1 (s)                   1.91008\n",
      "time/backward_zf2 (s)                   1.84852\n",
      "time/data sampling (s)                  0.228801\n",
      "time/data storing (s)                   0.0149082\n",
      "time/evaluation sampling (s)            1.44879\n",
      "time/exploration sampling (s)           0.178693\n",
      "time/logging (s)                        0.0116306\n",
      "time/preback_alpha (s)                  0.550299\n",
      "time/preback_policy (s)                 0.618357\n",
      "time/preback_start (s)                  0.126261\n",
      "time/preback_zf (s)                     4.95624\n",
      "time/saving (s)                         0.0053909\n",
      "time/training (s)                       2.39345\n",
      "time/epoch (s)                         16.0954\n",
      "time/total (s)                       3708.93\n",
      "Epoch                                 237\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:03:21.186126 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 238 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 249000\n",
      "trainer/ZF1 Loss                       60.4495\n",
      "trainer/ZF2 Loss                       88.7938\n",
      "trainer/ZF Expert Reward                8.41422\n",
      "trainer/ZF Policy Reward               -3.29179\n",
      "trainer/ZF CHI2 Term                  100.768\n",
      "trainer/Policy Loss                  -777.501\n",
      "trainer/Policy Grad Norm              857.98\n",
      "trainer/Policy Param Norm              45.1117\n",
      "trainer/Zf1 Grad Norm               62533.9\n",
      "trainer/Zf1 Param Norm                126.294\n",
      "trainer/Zf2 Grad Norm               83429.8\n",
      "trainer/Zf2 Param Norm                121.669\n",
      "trainer/Z Expert Predictions Mean    1079.73\n",
      "trainer/Z Expert Predictions Std      233.582\n",
      "trainer/Z Expert Predictions Max     1664.53\n",
      "trainer/Z Expert Predictions Min      351.46\n",
      "trainer/Z Policy Predictions Mean     769.501\n",
      "trainer/Z Policy Predictions Std      394.038\n",
      "trainer/Z Policy Predictions Max     1521.76\n",
      "trainer/Z Policy Predictions Min     -265.989\n",
      "trainer/Z Expert Targets Mean        1071.32\n",
      "trainer/Z Expert Targets Std          236.039\n",
      "trainer/Z Expert Targets Max         1599.57\n",
      "trainer/Z Expert Targets Min          321.203\n",
      "trainer/Z Policy Targets Mean         772.793\n",
      "trainer/Z Policy Targets Std          393.427\n",
      "trainer/Z Policy Targets Max         1551.1\n",
      "trainer/Z Policy Targets Min         -278.505\n",
      "trainer/Log Pis Mean                   14.5861\n",
      "trainer/Log Pis Std                     5.62674\n",
      "trainer/Policy mu Mean                  0.610701\n",
      "trainer/Policy mu Std                   3.54721\n",
      "trainer/Policy log std Mean            -4.01052\n",
      "trainer/Policy log std Std              1.39522\n",
      "exploration/num steps total        245613\n",
      "exploration/num paths total          1115\n",
      "evaluation/num steps total              1.65433e+06\n",
      "evaluation/num paths total           2435\n",
      "evaluation/path length Mean           336.7\n",
      "evaluation/path length Std              9.92018\n",
      "evaluation/path length Max            360\n",
      "evaluation/path length Min            322\n",
      "evaluation/Rewards Mean                 3.34157\n",
      "evaluation/Rewards Std                  0.828346\n",
      "evaluation/Rewards Max                  5.07985\n",
      "evaluation/Rewards Min                  0.696388\n",
      "evaluation/Returns Mean              1125.11\n",
      "evaluation/Returns Std                 35.1364\n",
      "evaluation/Returns Max               1207.27\n",
      "evaluation/Returns Min               1073.38\n",
      "evaluation/Estimation Bias Mean       731.979\n",
      "evaluation/Estimation Bias Std        423.988\n",
      "evaluation/EB/Q_True Mean              28.279\n",
      "evaluation/EB/Q_True Std               86.3594\n",
      "evaluation/EB/Q_Pred Mean             760.258\n",
      "evaluation/EB/Q_Pred Std              422.192\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1125.11\n",
      "evaluation/Actions Mean                 0.0345141\n",
      "evaluation/Actions Std                  0.598437\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72907\n",
      "time/backward_zf1 (s)                   1.84258\n",
      "time/backward_zf2 (s)                   1.77474\n",
      "time/data sampling (s)                  0.258405\n",
      "time/data storing (s)                   0.0144399\n",
      "time/evaluation sampling (s)            0.532353\n",
      "time/exploration sampling (s)           0.172004\n",
      "time/logging (s)                        0.00489172\n",
      "time/preback_alpha (s)                  0.560004\n",
      "time/preback_policy (s)                 0.621028\n",
      "time/preback_start (s)                  0.126703\n",
      "time/preback_zf (s)                     4.99175\n",
      "time/saving (s)                         0.00483835\n",
      "time/training (s)                       2.6282\n",
      "time/epoch (s)                         15.261\n",
      "time/total (s)                       3724.21\n",
      "Epoch                                 238\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:03:36.883617 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 239 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 250000\n",
      "trainer/ZF1 Loss                       73.4871\n",
      "trainer/ZF2 Loss                       60.5622\n",
      "trainer/ZF Expert Reward                8.30965\n",
      "trainer/ZF Policy Reward               -1.09504\n",
      "trainer/ZF CHI2 Term                   90.2387\n",
      "trainer/Policy Loss                  -808.071\n",
      "trainer/Policy Grad Norm             1158.09\n",
      "trainer/Policy Param Norm              45.1726\n",
      "trainer/Zf1 Grad Norm               50506.3\n",
      "trainer/Zf1 Param Norm                126.475\n",
      "trainer/Zf2 Grad Norm               55395.7\n",
      "trainer/Zf2 Param Norm                121.843\n",
      "trainer/Z Expert Predictions Mean    1081.86\n",
      "trainer/Z Expert Predictions Std      229.927\n",
      "trainer/Z Expert Predictions Max     1596.64\n",
      "trainer/Z Expert Predictions Min       77.8068\n",
      "trainer/Z Policy Predictions Mean     804.802\n",
      "trainer/Z Policy Predictions Std      395.84\n",
      "trainer/Z Policy Predictions Max     1463.4\n",
      "trainer/Z Policy Predictions Min     -361.284\n",
      "trainer/Z Expert Targets Mean        1073.55\n",
      "trainer/Z Expert Targets Std          233.172\n",
      "trainer/Z Expert Targets Max         1601.14\n",
      "trainer/Z Expert Targets Min          -11.0744\n",
      "trainer/Z Policy Targets Mean         805.897\n",
      "trainer/Z Policy Targets Std          397.037\n",
      "trainer/Z Policy Targets Max         1459.73\n",
      "trainer/Z Policy Targets Min         -426.249\n",
      "trainer/Log Pis Mean                   13.9489\n",
      "trainer/Log Pis Std                     5.03871\n",
      "trainer/Policy mu Mean                  0.390281\n",
      "trainer/Policy mu Std                   2.96812\n",
      "trainer/Policy log std Mean            -4.10052\n",
      "trainer/Policy log std Std              1.27093\n",
      "exploration/num steps total        247038\n",
      "exploration/num paths total          1117\n",
      "evaluation/num steps total              1.65776e+06\n",
      "evaluation/num paths total           2445\n",
      "evaluation/path length Mean           342.4\n",
      "evaluation/path length Std             43.2231\n",
      "evaluation/path length Max            420\n",
      "evaluation/path length Min            284\n",
      "evaluation/Rewards Mean                 3.33536\n",
      "evaluation/Rewards Std                  0.815933\n",
      "evaluation/Rewards Max                  4.59223\n",
      "evaluation/Rewards Min                  0.656876\n",
      "evaluation/Returns Mean              1142.03\n",
      "evaluation/Returns Std                166.458\n",
      "evaluation/Returns Max               1441.01\n",
      "evaluation/Returns Min                917.027\n",
      "evaluation/Estimation Bias Mean       887.329\n",
      "evaluation/Estimation Bias Std        391.373\n",
      "evaluation/EB/Q_True Mean              28.3736\n",
      "evaluation/EB/Q_True Std               83.0312\n",
      "evaluation/EB/Q_Pred Mean             915.703\n",
      "evaluation/EB/Q_Pred Std              384.826\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1142.03\n",
      "evaluation/Actions Mean                 0.0330307\n",
      "evaluation/Actions Std                  0.596891\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81683\n",
      "time/backward_zf1 (s)                   1.90582\n",
      "time/backward_zf2 (s)                   1.84973\n",
      "time/data sampling (s)                  0.248382\n",
      "time/data storing (s)                   0.0133742\n",
      "time/evaluation sampling (s)            0.92745\n",
      "time/exploration sampling (s)           0.168691\n",
      "time/logging (s)                        0.00492959\n",
      "time/preback_alpha (s)                  0.55012\n",
      "time/preback_policy (s)                 0.627844\n",
      "time/preback_start (s)                  0.12442\n",
      "time/preback_zf (s)                     4.95832\n",
      "time/saving (s)                         0.0067753\n",
      "time/training (s)                       2.41876\n",
      "time/epoch (s)                         15.6214\n",
      "time/total (s)                       3739.86\n",
      "Epoch                                 239\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:03:52.918696 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 240 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 251000\n",
      "trainer/ZF1 Loss                       54.7199\n",
      "trainer/ZF2 Loss                       62.4125\n",
      "trainer/ZF Expert Reward               15.7004\n",
      "trainer/ZF Policy Reward                3.94827\n",
      "trainer/ZF CHI2 Term                   84.421\n",
      "trainer/Policy Loss                  -780.165\n",
      "trainer/Policy Grad Norm              395.863\n",
      "trainer/Policy Param Norm              45.2377\n",
      "trainer/Zf1 Grad Norm               48852.5\n",
      "trainer/Zf1 Param Norm                126.65\n",
      "trainer/Zf2 Grad Norm               48030.7\n",
      "trainer/Zf2 Param Norm                122.016\n",
      "trainer/Z Expert Predictions Mean    1104.77\n",
      "trainer/Z Expert Predictions Std      238.254\n",
      "trainer/Z Expert Predictions Max     1646.9\n",
      "trainer/Z Expert Predictions Min      516.841\n",
      "trainer/Z Policy Predictions Mean     780.259\n",
      "trainer/Z Policy Predictions Std      396.525\n",
      "trainer/Z Policy Predictions Max     1391.81\n",
      "trainer/Z Policy Predictions Min     -385.393\n",
      "trainer/Z Expert Targets Mean        1089.07\n",
      "trainer/Z Expert Targets Std          237.937\n",
      "trainer/Z Expert Targets Max         1626.72\n",
      "trainer/Z Expert Targets Min          487.699\n",
      "trainer/Z Policy Targets Mean         776.31\n",
      "trainer/Z Policy Targets Std          393.553\n",
      "trainer/Z Policy Targets Max         1385.79\n",
      "trainer/Z Policy Targets Min         -351.927\n",
      "trainer/Log Pis Mean                   14.245\n",
      "trainer/Log Pis Std                     5.11799\n",
      "trainer/Policy mu Mean                  0.248207\n",
      "trainer/Policy mu Std                   2.89774\n",
      "trainer/Policy log std Mean            -4.32026\n",
      "trainer/Policy log std Std              1.23065\n",
      "exploration/num steps total        247038\n",
      "exploration/num paths total          1117\n",
      "evaluation/num steps total              1.6671e+06\n",
      "evaluation/num paths total           2455\n",
      "evaluation/path length Mean           934.2\n",
      "evaluation/path length Std            197.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            342\n",
      "evaluation/Rewards Mean                 3.53741\n",
      "evaluation/Rewards Std                  0.614056\n",
      "evaluation/Rewards Max                  4.84042\n",
      "evaluation/Rewards Min                  0.695244\n",
      "evaluation/Returns Mean              3304.65\n",
      "evaluation/Returns Std                722.315\n",
      "evaluation/Returns Max               3567.48\n",
      "evaluation/Returns Min               1138.14\n",
      "evaluation/Estimation Bias Mean      1011.07\n",
      "evaluation/Estimation Bias Std        252.618\n",
      "evaluation/EB/Q_True Mean              35.3503\n",
      "evaluation/EB/Q_True Std              104.987\n",
      "evaluation/EB/Q_Pred Mean            1046.42\n",
      "evaluation/EB/Q_Pred Std              235.693\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3304.65\n",
      "evaluation/Actions Mean                 0.0528362\n",
      "evaluation/Actions Std                  0.585866\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72507\n",
      "time/backward_zf1 (s)                   1.83849\n",
      "time/backward_zf2 (s)                   1.79481\n",
      "time/data sampling (s)                  0.225313\n",
      "time/data storing (s)                   0.0152899\n",
      "time/evaluation sampling (s)            1.37575\n",
      "time/exploration sampling (s)           0.17266\n",
      "time/logging (s)                        0.0107951\n",
      "time/preback_alpha (s)                  0.551139\n",
      "time/preback_policy (s)                 0.613941\n",
      "time/preback_start (s)                  0.125306\n",
      "time/preback_zf (s)                     4.95053\n",
      "time/saving (s)                         0.00520685\n",
      "time/training (s)                       2.57035\n",
      "time/epoch (s)                         15.9746\n",
      "time/total (s)                       3755.86\n",
      "Epoch                                 240\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:04:09.040282 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 241 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 252000\n",
      "trainer/ZF1 Loss                       68.0522\n",
      "trainer/ZF2 Loss                       58.5058\n",
      "trainer/ZF Expert Reward               15.8905\n",
      "trainer/ZF Policy Reward                2.40577\n",
      "trainer/ZF CHI2 Term                   91.426\n",
      "trainer/Policy Loss                  -767.799\n",
      "trainer/Policy Grad Norm              960.267\n",
      "trainer/Policy Param Norm              45.3052\n",
      "trainer/Zf1 Grad Norm              125098\n",
      "trainer/Zf1 Param Norm                126.833\n",
      "trainer/Zf2 Grad Norm               32330.9\n",
      "trainer/Zf2 Param Norm                122.191\n",
      "trainer/Z Expert Predictions Mean    1106.56\n",
      "trainer/Z Expert Predictions Std      247.091\n",
      "trainer/Z Expert Predictions Max     1645.75\n",
      "trainer/Z Expert Predictions Min      364.671\n",
      "trainer/Z Policy Predictions Mean     765.868\n",
      "trainer/Z Policy Predictions Std      432.004\n",
      "trainer/Z Policy Predictions Max     1542.11\n",
      "trainer/Z Policy Predictions Min     -362.178\n",
      "trainer/Z Expert Targets Mean        1090.67\n",
      "trainer/Z Expert Targets Std          249.484\n",
      "trainer/Z Expert Targets Max         1617.79\n",
      "trainer/Z Expert Targets Min          348.957\n",
      "trainer/Z Policy Targets Mean         763.462\n",
      "trainer/Z Policy Targets Std          425.608\n",
      "trainer/Z Policy Targets Max         1511.32\n",
      "trainer/Z Policy Targets Min         -371.672\n",
      "trainer/Log Pis Mean                   14.8104\n",
      "trainer/Log Pis Std                     5.90028\n",
      "trainer/Policy mu Mean                  0.414087\n",
      "trainer/Policy mu Std                   3.40362\n",
      "trainer/Policy log std Mean            -4.15041\n",
      "trainer/Policy log std Std              1.41845\n",
      "exploration/num steps total        248446\n",
      "exploration/num paths total          1119\n",
      "evaluation/num steps total              1.67577e+06\n",
      "evaluation/num paths total           2465\n",
      "evaluation/path length Mean           867\n",
      "evaluation/path length Std            266\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 3.53651\n",
      "evaluation/Rewards Std                  0.621915\n",
      "evaluation/Rewards Max                  4.85022\n",
      "evaluation/Rewards Min                  0.719945\n",
      "evaluation/Returns Mean              3066.16\n",
      "evaluation/Returns Std                975.167\n",
      "evaluation/Returns Max               3571.22\n",
      "evaluation/Returns Min               1115.78\n",
      "evaluation/Estimation Bias Mean       997.948\n",
      "evaluation/Estimation Bias Std        287.833\n",
      "evaluation/EB/Q_True Mean              37.876\n",
      "evaluation/EB/Q_True Std              107.793\n",
      "evaluation/EB/Q_Pred Mean            1035.82\n",
      "evaluation/EB/Q_Pred Std              251.214\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3066.16\n",
      "evaluation/Actions Mean                 0.0531839\n",
      "evaluation/Actions Std                  0.58604\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71321\n",
      "time/backward_zf1 (s)                   1.85393\n",
      "time/backward_zf2 (s)                   1.7755\n",
      "time/data sampling (s)                  0.256379\n",
      "time/data storing (s)                   0.0142838\n",
      "time/evaluation sampling (s)            1.39418\n",
      "time/exploration sampling (s)           0.178532\n",
      "time/logging (s)                        0.0105843\n",
      "time/preback_alpha (s)                  0.55489\n",
      "time/preback_policy (s)                 0.615998\n",
      "time/preback_start (s)                  0.125618\n",
      "time/preback_zf (s)                     4.95552\n",
      "time/saving (s)                         0.01724\n",
      "time/training (s)                       2.59185\n",
      "time/epoch (s)                         16.0577\n",
      "time/total (s)                       3771.93\n",
      "Epoch                                 241\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:04:25.256635 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 242 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 253000\n",
      "trainer/ZF1 Loss                       49.2766\n",
      "trainer/ZF2 Loss                       50.6144\n",
      "trainer/ZF Expert Reward               10.4047\n",
      "trainer/ZF Policy Reward               -3.20618\n",
      "trainer/ZF CHI2 Term                   77.6245\n",
      "trainer/Policy Loss                  -794.765\n",
      "trainer/Policy Grad Norm              526.031\n",
      "trainer/Policy Param Norm              45.3663\n",
      "trainer/Zf1 Grad Norm               34823.8\n",
      "trainer/Zf1 Param Norm                127.015\n",
      "trainer/Zf2 Grad Norm               39631.8\n",
      "trainer/Zf2 Param Norm                122.377\n",
      "trainer/Z Expert Predictions Mean    1072.13\n",
      "trainer/Z Expert Predictions Std      248.724\n",
      "trainer/Z Expert Predictions Max     1639.67\n",
      "trainer/Z Expert Predictions Min      416.706\n",
      "trainer/Z Policy Predictions Mean     786.177\n",
      "trainer/Z Policy Predictions Std      369.098\n",
      "trainer/Z Policy Predictions Max     1426.74\n",
      "trainer/Z Policy Predictions Min     -349.658\n",
      "trainer/Z Expert Targets Mean        1061.72\n",
      "trainer/Z Expert Targets Std          251.214\n",
      "trainer/Z Expert Targets Max         1624.92\n",
      "trainer/Z Expert Targets Min          395.307\n",
      "trainer/Z Policy Targets Mean         789.383\n",
      "trainer/Z Policy Targets Std          366.182\n",
      "trainer/Z Policy Targets Max         1427.06\n",
      "trainer/Z Policy Targets Min         -350.546\n",
      "trainer/Log Pis Mean                   14.2101\n",
      "trainer/Log Pis Std                     4.82975\n",
      "trainer/Policy mu Mean                  0.31915\n",
      "trainer/Policy mu Std                   2.50372\n",
      "trainer/Policy log std Mean            -4.24926\n",
      "trainer/Policy log std Std              1.23266\n",
      "exploration/num steps total        248777\n",
      "exploration/num paths total          1120\n",
      "evaluation/num steps total              1.68329e+06\n",
      "evaluation/num paths total           2477\n",
      "evaluation/path length Mean           626.667\n",
      "evaluation/path length Std            316.504\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 3.48557\n",
      "evaluation/Rewards Std                  0.681152\n",
      "evaluation/Rewards Max                  4.6964\n",
      "evaluation/Rewards Min                  0.701144\n",
      "evaluation/Returns Mean              2184.29\n",
      "evaluation/Returns Std               1160.81\n",
      "evaluation/Returns Max               3586.29\n",
      "evaluation/Returns Min               1106.15\n",
      "evaluation/Estimation Bias Mean       985.095\n",
      "evaluation/Estimation Bias Std        330.833\n",
      "evaluation/EB/Q_True Mean              43.4619\n",
      "evaluation/EB/Q_True Std              114.055\n",
      "evaluation/EB/Q_Pred Mean            1028.56\n",
      "evaluation/EB/Q_Pred Std              304.322\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2184.29\n",
      "evaluation/Actions Mean                 0.0478101\n",
      "evaluation/Actions Std                  0.588213\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80433\n",
      "time/backward_zf1 (s)                   1.90669\n",
      "time/backward_zf2 (s)                   1.84896\n",
      "time/data sampling (s)                  0.25717\n",
      "time/data storing (s)                   0.0136203\n",
      "time/evaluation sampling (s)            1.44147\n",
      "time/exploration sampling (s)           0.168346\n",
      "time/logging (s)                        0.00922917\n",
      "time/preback_alpha (s)                  0.556231\n",
      "time/preback_policy (s)                 0.630846\n",
      "time/preback_start (s)                  0.12424\n",
      "time/preback_zf (s)                     4.97671\n",
      "time/saving (s)                         0.00546654\n",
      "time/training (s)                       2.40756\n",
      "time/epoch (s)                         16.1509\n",
      "time/total (s)                       3788.1\n",
      "Epoch                                 242\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:04:41.302184 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 243 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 254000\n",
      "trainer/ZF1 Loss                       84.1429\n",
      "trainer/ZF2 Loss                       56.8\n",
      "trainer/ZF Expert Reward               15.8919\n",
      "trainer/ZF Policy Reward                7.28878\n",
      "trainer/ZF CHI2 Term                   93.4724\n",
      "trainer/Policy Loss                  -744.504\n",
      "trainer/Policy Grad Norm              779.559\n",
      "trainer/Policy Param Norm              45.4239\n",
      "trainer/Zf1 Grad Norm              130685\n",
      "trainer/Zf1 Param Norm                127.208\n",
      "trainer/Zf2 Grad Norm               35357.1\n",
      "trainer/Zf2 Param Norm                122.567\n",
      "trainer/Z Expert Predictions Mean    1088\n",
      "trainer/Z Expert Predictions Std      251.036\n",
      "trainer/Z Expert Predictions Max     1658\n",
      "trainer/Z Expert Predictions Min      468.384\n",
      "trainer/Z Policy Predictions Mean     743.186\n",
      "trainer/Z Policy Predictions Std      443.464\n",
      "trainer/Z Policy Predictions Max     1554.06\n",
      "trainer/Z Policy Predictions Min     -323.07\n",
      "trainer/Z Expert Targets Mean        1072.1\n",
      "trainer/Z Expert Targets Std          248.699\n",
      "trainer/Z Expert Targets Max         1625.73\n",
      "trainer/Z Expert Targets Min          447.666\n",
      "trainer/Z Policy Targets Mean         735.897\n",
      "trainer/Z Policy Targets Std          438.996\n",
      "trainer/Z Policy Targets Max         1522.22\n",
      "trainer/Z Policy Targets Min         -330.899\n",
      "trainer/Log Pis Mean                   14.5433\n",
      "trainer/Log Pis Std                     5.55115\n",
      "trainer/Policy mu Mean                  0.470759\n",
      "trainer/Policy mu Std                   3.2386\n",
      "trainer/Policy log std Mean            -4.15758\n",
      "trainer/Policy log std Std              1.38628\n",
      "exploration/num steps total        248777\n",
      "exploration/num paths total          1120\n",
      "evaluation/num steps total              1.69329e+06\n",
      "evaluation/num paths total           2487\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52249\n",
      "evaluation/Rewards Std                  0.597125\n",
      "evaluation/Rewards Max                  4.85088\n",
      "evaluation/Rewards Min                  0.698784\n",
      "evaluation/Returns Mean              3522.49\n",
      "evaluation/Returns Std                 10.9246\n",
      "evaluation/Returns Max               3537.14\n",
      "evaluation/Returns Min               3506.67\n",
      "evaluation/Estimation Bias Mean       983.469\n",
      "evaluation/Estimation Bias Std        238.019\n",
      "evaluation/EB/Q_True Mean              32.7148\n",
      "evaluation/EB/Q_True Std              100.896\n",
      "evaluation/EB/Q_Pred Mean            1016.18\n",
      "evaluation/EB/Q_Pred Std              212.673\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3522.49\n",
      "evaluation/Actions Mean                 0.0517662\n",
      "evaluation/Actions Std                  0.585797\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70313\n",
      "time/backward_zf1 (s)                   1.81828\n",
      "time/backward_zf2 (s)                   1.74638\n",
      "time/data sampling (s)                  0.257189\n",
      "time/data storing (s)                   0.014046\n",
      "time/evaluation sampling (s)            1.37612\n",
      "time/exploration sampling (s)           0.170771\n",
      "time/logging (s)                        0.0119558\n",
      "time/preback_alpha (s)                  0.55365\n",
      "time/preback_policy (s)                 0.612067\n",
      "time/preback_start (s)                  0.12343\n",
      "time/preback_zf (s)                     4.96312\n",
      "time/saving (s)                         0.00533261\n",
      "time/training (s)                       2.62936\n",
      "time/epoch (s)                         15.9849\n",
      "time/total (s)                       3804.1\n",
      "Epoch                                 243\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:04:57.553976 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 244 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 255000\n",
      "trainer/ZF1 Loss                      148.879\n",
      "trainer/ZF2 Loss                      153.813\n",
      "trainer/ZF Expert Reward               17.7235\n",
      "trainer/ZF Policy Reward                4.16624\n",
      "trainer/ZF CHI2 Term                  179.251\n",
      "trainer/Policy Loss                  -778.269\n",
      "trainer/Policy Grad Norm              457.312\n",
      "trainer/Policy Param Norm              45.4972\n",
      "trainer/Zf1 Grad Norm               24781.2\n",
      "trainer/Zf1 Param Norm                127.387\n",
      "trainer/Zf2 Grad Norm               64006.9\n",
      "trainer/Zf2 Param Norm                122.733\n",
      "trainer/Z Expert Predictions Mean    1081.75\n",
      "trainer/Z Expert Predictions Std      218.033\n",
      "trainer/Z Expert Predictions Max     1647.17\n",
      "trainer/Z Expert Predictions Min      567.988\n",
      "trainer/Z Policy Predictions Mean     771.032\n",
      "trainer/Z Policy Predictions Std      414.832\n",
      "trainer/Z Policy Predictions Max     1494.29\n",
      "trainer/Z Policy Predictions Min     -397.967\n",
      "trainer/Z Expert Targets Mean        1064.03\n",
      "trainer/Z Expert Targets Std          219.58\n",
      "trainer/Z Expert Targets Max         1631.75\n",
      "trainer/Z Expert Targets Min          523.147\n",
      "trainer/Z Policy Targets Mean         766.866\n",
      "trainer/Z Policy Targets Std          412.382\n",
      "trainer/Z Policy Targets Max         1481.04\n",
      "trainer/Z Policy Targets Min         -378.25\n",
      "trainer/Log Pis Mean                   14.4929\n",
      "trainer/Log Pis Std                     5.28787\n",
      "trainer/Policy mu Mean                  0.16569\n",
      "trainer/Policy mu Std                   2.99792\n",
      "trainer/Policy log std Mean            -4.16801\n",
      "trainer/Policy log std Std              1.29724\n",
      "exploration/num steps total        248777\n",
      "exploration/num paths total          1120\n",
      "evaluation/num steps total              1.70329e+06\n",
      "evaluation/num paths total           2497\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51851\n",
      "evaluation/Rewards Std                  0.592588\n",
      "evaluation/Rewards Max                  4.78907\n",
      "evaluation/Rewards Min                  0.681206\n",
      "evaluation/Returns Mean              3518.51\n",
      "evaluation/Returns Std                  8.40801\n",
      "evaluation/Returns Max               3531.78\n",
      "evaluation/Returns Min               3505.67\n",
      "evaluation/Estimation Bias Mean       955.692\n",
      "evaluation/Estimation Bias Std        211.587\n",
      "evaluation/EB/Q_True Mean              32.5879\n",
      "evaluation/EB/Q_True Std              100.377\n",
      "evaluation/EB/Q_Pred Mean             988.28\n",
      "evaluation/EB/Q_Pred Std              190.928\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3518.51\n",
      "evaluation/Actions Mean                 0.0388849\n",
      "evaluation/Actions Std                  0.574065\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81562\n",
      "time/backward_zf1 (s)                   1.93873\n",
      "time/backward_zf2 (s)                   1.87033\n",
      "time/data sampling (s)                  0.259965\n",
      "time/data storing (s)                   0.0139475\n",
      "time/evaluation sampling (s)            1.33532\n",
      "time/exploration sampling (s)           0.169904\n",
      "time/logging (s)                        0.011543\n",
      "time/preback_alpha (s)                  0.558156\n",
      "time/preback_policy (s)                 0.636791\n",
      "time/preback_start (s)                  0.125554\n",
      "time/preback_zf (s)                     4.99972\n",
      "time/saving (s)                         0.00496522\n",
      "time/training (s)                       2.44676\n",
      "time/epoch (s)                         16.1873\n",
      "time/total (s)                       3820.31\n",
      "Epoch                                 244\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:05:13.577488 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 245 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 256000\n",
      "trainer/ZF1 Loss                      269.285\n",
      "trainer/ZF2 Loss                      285.734\n",
      "trainer/ZF Expert Reward               12.5651\n",
      "trainer/ZF Policy Reward                1.90912\n",
      "trainer/ZF CHI2 Term                  302.619\n",
      "trainer/Policy Loss                  -771.632\n",
      "trainer/Policy Grad Norm              781.142\n",
      "trainer/Policy Param Norm              45.5659\n",
      "trainer/Zf1 Grad Norm               39965.2\n",
      "trainer/Zf1 Param Norm                127.562\n",
      "trainer/Zf2 Grad Norm               50472\n",
      "trainer/Zf2 Param Norm                122.908\n",
      "trainer/Z Expert Predictions Mean    1085.36\n",
      "trainer/Z Expert Predictions Std      221.431\n",
      "trainer/Z Expert Predictions Max     1647.04\n",
      "trainer/Z Expert Predictions Min      371.123\n",
      "trainer/Z Policy Predictions Mean     765.117\n",
      "trainer/Z Policy Predictions Std      395.065\n",
      "trainer/Z Policy Predictions Max     1588.35\n",
      "trainer/Z Policy Predictions Min     -269.124\n",
      "trainer/Z Expert Targets Mean        1072.79\n",
      "trainer/Z Expert Targets Std          220.312\n",
      "trainer/Z Expert Targets Max         1631.51\n",
      "trainer/Z Expert Targets Min          362.558\n",
      "trainer/Z Policy Targets Mean         763.208\n",
      "trainer/Z Policy Targets Std          394.609\n",
      "trainer/Z Policy Targets Max         1594.47\n",
      "trainer/Z Policy Targets Min         -240.139\n",
      "trainer/Log Pis Mean                   14.5993\n",
      "trainer/Log Pis Std                     5.76637\n",
      "trainer/Policy mu Mean                  0.645288\n",
      "trainer/Policy mu Std                   3.13314\n",
      "trainer/Policy log std Mean            -4.03713\n",
      "trainer/Policy log std Std              1.46796\n",
      "exploration/num steps total        250186\n",
      "exploration/num paths total          1122\n",
      "evaluation/num steps total              1.71329e+06\n",
      "evaluation/num paths total           2507\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52398\n",
      "evaluation/Rewards Std                  0.589326\n",
      "evaluation/Rewards Max                  4.79979\n",
      "evaluation/Rewards Min                  0.720838\n",
      "evaluation/Returns Mean              3523.98\n",
      "evaluation/Returns Std                 17.6245\n",
      "evaluation/Returns Max               3557.41\n",
      "evaluation/Returns Min               3493.12\n",
      "evaluation/Estimation Bias Mean      1011.07\n",
      "evaluation/Estimation Bias Std        228.974\n",
      "evaluation/EB/Q_True Mean              32.6667\n",
      "evaluation/EB/Q_True Std              100.8\n",
      "evaluation/EB/Q_Pred Mean            1043.74\n",
      "evaluation/EB/Q_Pred Std              216.645\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3523.98\n",
      "evaluation/Actions Mean                 0.0451792\n",
      "evaluation/Actions Std                  0.579616\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73958\n",
      "time/backward_zf1 (s)                   1.8562\n",
      "time/backward_zf2 (s)                   1.78486\n",
      "time/data sampling (s)                  0.24478\n",
      "time/data storing (s)                   0.0137787\n",
      "time/evaluation sampling (s)            1.34088\n",
      "time/exploration sampling (s)           0.171024\n",
      "time/logging (s)                        0.0118286\n",
      "time/preback_alpha (s)                  0.54972\n",
      "time/preback_policy (s)                 0.605872\n",
      "time/preback_start (s)                  0.124838\n",
      "time/preback_zf (s)                     4.9476\n",
      "time/saving (s)                         0.00548538\n",
      "time/training (s)                       2.56415\n",
      "time/epoch (s)                         15.9606\n",
      "time/total (s)                       3836.29\n",
      "Epoch                                 245\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:05:29.747130 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 246 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 257000\n",
      "trainer/ZF1 Loss                       71.2884\n",
      "trainer/ZF2 Loss                       82.8818\n",
      "trainer/ZF Expert Reward               11.5506\n",
      "trainer/ZF Policy Reward               -7.27692\n",
      "trainer/ZF CHI2 Term                  110.628\n",
      "trainer/Policy Loss                  -767.567\n",
      "trainer/Policy Grad Norm              717.703\n",
      "trainer/Policy Param Norm              45.637\n",
      "trainer/Zf1 Grad Norm               70109.8\n",
      "trainer/Zf1 Param Norm                127.752\n",
      "trainer/Zf2 Grad Norm               64456.6\n",
      "trainer/Zf2 Param Norm                123.092\n",
      "trainer/Z Expert Predictions Mean    1095.35\n",
      "trainer/Z Expert Predictions Std      233.696\n",
      "trainer/Z Expert Predictions Max     1617.43\n",
      "trainer/Z Expert Predictions Min      475.497\n",
      "trainer/Z Policy Predictions Mean     754.289\n",
      "trainer/Z Policy Predictions Std      429.414\n",
      "trainer/Z Policy Predictions Max     1419.84\n",
      "trainer/Z Policy Predictions Min     -451.111\n",
      "trainer/Z Expert Targets Mean        1083.8\n",
      "trainer/Z Expert Targets Std          235.171\n",
      "trainer/Z Expert Targets Max         1606.14\n",
      "trainer/Z Expert Targets Min          473.439\n",
      "trainer/Z Policy Targets Mean         761.566\n",
      "trainer/Z Policy Targets Std          425.024\n",
      "trainer/Z Policy Targets Max         1441.87\n",
      "trainer/Z Policy Targets Min         -451.158\n",
      "trainer/Log Pis Mean                   14.8638\n",
      "trainer/Log Pis Std                     5.59346\n",
      "trainer/Policy mu Mean                  0.337974\n",
      "trainer/Policy mu Std                   3.2189\n",
      "trainer/Policy log std Mean            -4.23112\n",
      "trainer/Policy log std Std              1.32135\n",
      "exploration/num steps total        251186\n",
      "exploration/num paths total          1123\n",
      "evaluation/num steps total              1.72329e+06\n",
      "evaluation/num paths total           2517\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51123\n",
      "evaluation/Rewards Std                  0.608324\n",
      "evaluation/Rewards Max                  4.89005\n",
      "evaluation/Rewards Min                  0.677124\n",
      "evaluation/Returns Mean              3511.23\n",
      "evaluation/Returns Std                 13.6488\n",
      "evaluation/Returns Max               3527.03\n",
      "evaluation/Returns Min               3488.39\n",
      "evaluation/Estimation Bias Mean       943.595\n",
      "evaluation/Estimation Bias Std        229.44\n",
      "evaluation/EB/Q_True Mean              32.5691\n",
      "evaluation/EB/Q_True Std              100.277\n",
      "evaluation/EB/Q_Pred Mean             976.164\n",
      "evaluation/EB/Q_Pred Std              202.328\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3511.23\n",
      "evaluation/Actions Mean                 0.052617\n",
      "evaluation/Actions Std                  0.590097\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8513\n",
      "time/backward_zf1 (s)                   1.94464\n",
      "time/backward_zf2 (s)                   1.88246\n",
      "time/data sampling (s)                  0.25176\n",
      "time/data storing (s)                   0.0140876\n",
      "time/evaluation sampling (s)            1.36727\n",
      "time/exploration sampling (s)           0.176456\n",
      "time/logging (s)                        0.0116302\n",
      "time/preback_alpha (s)                  0.553819\n",
      "time/preback_policy (s)                 0.634693\n",
      "time/preback_start (s)                  0.125207\n",
      "time/preback_zf (s)                     4.97332\n",
      "time/saving (s)                         0.00537219\n",
      "time/training (s)                       2.31368\n",
      "time/epoch (s)                         16.1057\n",
      "time/total (s)                       3852.41\n",
      "Epoch                                 246\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:05:45.056652 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 247 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 258000\n",
      "trainer/ZF1 Loss                      260.486\n",
      "trainer/ZF2 Loss                      306.026\n",
      "trainer/ZF Expert Reward               22.7542\n",
      "trainer/ZF Policy Reward               14.8225\n",
      "trainer/ZF CHI2 Term                  305.869\n",
      "trainer/Policy Loss                  -775.096\n",
      "trainer/Policy Grad Norm              719.942\n",
      "trainer/Policy Param Norm              45.7114\n",
      "trainer/Zf1 Grad Norm              102734\n",
      "trainer/Zf1 Param Norm                127.95\n",
      "trainer/Zf2 Grad Norm              172642\n",
      "trainer/Zf2 Param Norm                123.273\n",
      "trainer/Z Expert Predictions Mean    1091.39\n",
      "trainer/Z Expert Predictions Std      227.507\n",
      "trainer/Z Expert Predictions Max     1673.93\n",
      "trainer/Z Expert Predictions Min      567.015\n",
      "trainer/Z Policy Predictions Mean     776.018\n",
      "trainer/Z Policy Predictions Std      416.542\n",
      "trainer/Z Policy Predictions Max     1561.68\n",
      "trainer/Z Policy Predictions Min     -443.216\n",
      "trainer/Z Expert Targets Mean        1068.64\n",
      "trainer/Z Expert Targets Std          231.633\n",
      "trainer/Z Expert Targets Max         1613.72\n",
      "trainer/Z Expert Targets Min          394.299\n",
      "trainer/Z Policy Targets Mean         761.196\n",
      "trainer/Z Policy Targets Std          422.042\n",
      "trainer/Z Policy Targets Max         1538.89\n",
      "trainer/Z Policy Targets Min         -461.32\n",
      "trainer/Log Pis Mean                   14.8299\n",
      "trainer/Log Pis Std                     5.95533\n",
      "trainer/Policy mu Mean                  0.296291\n",
      "trainer/Policy mu Std                   2.72178\n",
      "trainer/Policy log std Mean            -4.27461\n",
      "trainer/Policy log std Std              1.22756\n",
      "exploration/num steps total        254186\n",
      "exploration/num paths total          1126\n",
      "evaluation/num steps total              1.7265e+06\n",
      "evaluation/num paths total           2527\n",
      "evaluation/path length Mean           321\n",
      "evaluation/path length Std             24.7831\n",
      "evaluation/path length Max            336\n",
      "evaluation/path length Min            271\n",
      "evaluation/Rewards Mean                 3.3102\n",
      "evaluation/Rewards Std                  0.832496\n",
      "evaluation/Rewards Max                  4.6143\n",
      "evaluation/Rewards Min                  0.718063\n",
      "evaluation/Returns Mean              1062.57\n",
      "evaluation/Returns Std                 95.8305\n",
      "evaluation/Returns Max               1117.8\n",
      "evaluation/Returns Min                868.046\n",
      "evaluation/Estimation Bias Mean       770.935\n",
      "evaluation/Estimation Bias Std        381.126\n",
      "evaluation/EB/Q_True Mean              26.9142\n",
      "evaluation/EB/Q_True Std               83.3978\n",
      "evaluation/EB/Q_Pred Mean             797.849\n",
      "evaluation/EB/Q_Pred Std              376.064\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1062.57\n",
      "evaluation/Actions Mean                 0.0325643\n",
      "evaluation/Actions Std                  0.602927\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81657\n",
      "time/backward_zf1 (s)                   1.9213\n",
      "time/backward_zf2 (s)                   1.86427\n",
      "time/data sampling (s)                  0.241209\n",
      "time/data storing (s)                   0.0136116\n",
      "time/evaluation sampling (s)            0.527677\n",
      "time/exploration sampling (s)           0.172256\n",
      "time/logging (s)                        0.00455293\n",
      "time/preback_alpha (s)                  0.551594\n",
      "time/preback_policy (s)                 0.627419\n",
      "time/preback_start (s)                  0.12484\n",
      "time/preback_zf (s)                     4.9537\n",
      "time/saving (s)                         0.00499211\n",
      "time/training (s)                       2.40815\n",
      "time/epoch (s)                         15.2321\n",
      "time/total (s)                       3867.67\n",
      "Epoch                                 247\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:06:01.249893 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 248 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 259000\n",
      "trainer/ZF1 Loss                       69.1618\n",
      "trainer/ZF2 Loss                       76.527\n",
      "trainer/ZF Expert Reward               10.6392\n",
      "trainer/ZF Policy Reward               -1.67345\n",
      "trainer/ZF CHI2 Term                   99.2373\n",
      "trainer/Policy Loss                  -777.593\n",
      "trainer/Policy Grad Norm              999.128\n",
      "trainer/Policy Param Norm              45.7777\n",
      "trainer/Zf1 Grad Norm               84932\n",
      "trainer/Zf1 Param Norm                128.141\n",
      "trainer/Zf2 Grad Norm               94320\n",
      "trainer/Zf2 Param Norm                123.468\n",
      "trainer/Z Expert Predictions Mean    1072.32\n",
      "trainer/Z Expert Predictions Std      231.904\n",
      "trainer/Z Expert Predictions Max     1624.95\n",
      "trainer/Z Expert Predictions Min      469.333\n",
      "trainer/Z Policy Predictions Mean     774.805\n",
      "trainer/Z Policy Predictions Std      414.373\n",
      "trainer/Z Policy Predictions Max     1588.64\n",
      "trainer/Z Policy Predictions Min     -406.281\n",
      "trainer/Z Expert Targets Mean        1061.68\n",
      "trainer/Z Expert Targets Std          230.044\n",
      "trainer/Z Expert Targets Max         1588.38\n",
      "trainer/Z Expert Targets Min          448.379\n",
      "trainer/Z Policy Targets Mean         776.478\n",
      "trainer/Z Policy Targets Std          411.705\n",
      "trainer/Z Policy Targets Max         1579.1\n",
      "trainer/Z Policy Targets Min         -373.862\n",
      "trainer/Log Pis Mean                   14.2224\n",
      "trainer/Log Pis Std                     4.68756\n",
      "trainer/Policy mu Mean                  0.202371\n",
      "trainer/Policy mu Std                   2.56029\n",
      "trainer/Policy log std Mean            -4.20349\n",
      "trainer/Policy log std Std              1.27503\n",
      "exploration/num steps total        255186\n",
      "exploration/num paths total          1127\n",
      "evaluation/num steps total              1.7365e+06\n",
      "evaluation/num paths total           2537\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51284\n",
      "evaluation/Rewards Std                  0.594846\n",
      "evaluation/Rewards Max                  4.87685\n",
      "evaluation/Rewards Min                  0.696968\n",
      "evaluation/Returns Mean              3512.84\n",
      "evaluation/Returns Std                  8.0938\n",
      "evaluation/Returns Max               3524.97\n",
      "evaluation/Returns Min               3494.08\n",
      "evaluation/Estimation Bias Mean       954.192\n",
      "evaluation/Estimation Bias Std        219.426\n",
      "evaluation/EB/Q_True Mean              32.607\n",
      "evaluation/EB/Q_True Std              100.513\n",
      "evaluation/EB/Q_Pred Mean             986.799\n",
      "evaluation/EB/Q_Pred Std              194.056\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3512.84\n",
      "evaluation/Actions Mean                 0.0456013\n",
      "evaluation/Actions Std                  0.584618\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82111\n",
      "time/backward_zf1 (s)                   1.93608\n",
      "time/backward_zf2 (s)                   1.87918\n",
      "time/data sampling (s)                  0.2547\n",
      "time/data storing (s)                   0.0135426\n",
      "time/evaluation sampling (s)            1.40561\n",
      "time/exploration sampling (s)           0.169429\n",
      "time/logging (s)                        0.0134466\n",
      "time/preback_alpha (s)                  0.553035\n",
      "time/preback_policy (s)                 0.632405\n",
      "time/preback_start (s)                  0.123998\n",
      "time/preback_zf (s)                     4.97862\n",
      "time/saving (s)                         0.00532407\n",
      "time/training (s)                       2.35276\n",
      "time/epoch (s)                         16.1392\n",
      "time/total (s)                       3883.82\n",
      "Epoch                                 248\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:06:16.881813 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 249 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 260000\n",
      "trainer/ZF1 Loss                      121.254\n",
      "trainer/ZF2 Loss                       93.8607\n",
      "trainer/ZF Expert Reward                5.13946\n",
      "trainer/ZF Policy Reward              -12.9141\n",
      "trainer/ZF CHI2 Term                  139.523\n",
      "trainer/Policy Loss                  -841.468\n",
      "trainer/Policy Grad Norm              833.581\n",
      "trainer/Policy Param Norm              45.8511\n",
      "trainer/Zf1 Grad Norm              203312\n",
      "trainer/Zf1 Param Norm                128.329\n",
      "trainer/Zf2 Grad Norm              132561\n",
      "trainer/Zf2 Param Norm                123.649\n",
      "trainer/Z Expert Predictions Mean    1080.87\n",
      "trainer/Z Expert Predictions Std      244.473\n",
      "trainer/Z Expert Predictions Max     1634.55\n",
      "trainer/Z Expert Predictions Min      494.904\n",
      "trainer/Z Policy Predictions Mean     824.443\n",
      "trainer/Z Policy Predictions Std      349.39\n",
      "trainer/Z Policy Predictions Max     1520.75\n",
      "trainer/Z Policy Predictions Min     -422.978\n",
      "trainer/Z Expert Targets Mean        1075.73\n",
      "trainer/Z Expert Targets Std          247.676\n",
      "trainer/Z Expert Targets Max         1624.87\n",
      "trainer/Z Expert Targets Min          487.69\n",
      "trainer/Z Policy Targets Mean         837.357\n",
      "trainer/Z Policy Targets Std          348.384\n",
      "trainer/Z Policy Targets Max         1506.28\n",
      "trainer/Z Policy Targets Min         -433.08\n",
      "trainer/Log Pis Mean                   14.0528\n",
      "trainer/Log Pis Std                     5.06772\n",
      "trainer/Policy mu Mean                  0.152606\n",
      "trainer/Policy mu Std                   2.77599\n",
      "trainer/Policy log std Mean            -4.20637\n",
      "trainer/Policy log std Std              1.24197\n",
      "exploration/num steps total        256186\n",
      "exploration/num paths total          1128\n",
      "evaluation/num steps total              1.7399e+06\n",
      "evaluation/num paths total           2547\n",
      "evaluation/path length Mean           340.7\n",
      "evaluation/path length Std             23.4779\n",
      "evaluation/path length Max            411\n",
      "evaluation/path length Min            331\n",
      "evaluation/Rewards Mean                 3.33379\n",
      "evaluation/Rewards Std                  0.817195\n",
      "evaluation/Rewards Max                  4.59744\n",
      "evaluation/Rewards Min                  0.737452\n",
      "evaluation/Returns Mean              1135.82\n",
      "evaluation/Returns Std                 89.781\n",
      "evaluation/Returns Max               1404.79\n",
      "evaluation/Returns Min               1098.98\n",
      "evaluation/Estimation Bias Mean       834.406\n",
      "evaluation/Estimation Bias Std        395.76\n",
      "evaluation/EB/Q_True Mean              27.6828\n",
      "evaluation/EB/Q_True Std               81.9356\n",
      "evaluation/EB/Q_Pred Mean             862.089\n",
      "evaluation/EB/Q_Pred Std              387.477\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1135.82\n",
      "evaluation/Actions Mean                 0.0317352\n",
      "evaluation/Actions Std                  0.601097\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71255\n",
      "time/backward_zf1 (s)                   1.82141\n",
      "time/backward_zf2 (s)                   1.75853\n",
      "time/data sampling (s)                  0.252083\n",
      "time/data storing (s)                   0.0141593\n",
      "time/evaluation sampling (s)            0.935717\n",
      "time/exploration sampling (s)           0.174374\n",
      "time/logging (s)                        0.0054957\n",
      "time/preback_alpha (s)                  0.551572\n",
      "time/preback_policy (s)                 0.603735\n",
      "time/preback_start (s)                  0.125361\n",
      "time/preback_zf (s)                     4.95286\n",
      "time/saving (s)                         0.00472005\n",
      "time/training (s)                       2.6458\n",
      "time/epoch (s)                         15.5584\n",
      "time/total (s)                       3899.4\n",
      "Epoch                                 249\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:06:33.007286 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 250 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 261000\n",
      "trainer/ZF1 Loss                       96.1336\n",
      "trainer/ZF2 Loss                       86.6785\n",
      "trainer/ZF Expert Reward               11.0837\n",
      "trainer/ZF Policy Reward                5.33804\n",
      "trainer/ZF CHI2 Term                  111.659\n",
      "trainer/Policy Loss                  -795.075\n",
      "trainer/Policy Grad Norm              841.473\n",
      "trainer/Policy Param Norm              45.9291\n",
      "trainer/Zf1 Grad Norm               81790.1\n",
      "trainer/Zf1 Param Norm                128.528\n",
      "trainer/Zf2 Grad Norm               87880.8\n",
      "trainer/Zf2 Param Norm                123.851\n",
      "trainer/Z Expert Predictions Mean    1069.91\n",
      "trainer/Z Expert Predictions Std      225.852\n",
      "trainer/Z Expert Predictions Max     1630.29\n",
      "trainer/Z Expert Predictions Min      467.929\n",
      "trainer/Z Policy Predictions Mean     799.101\n",
      "trainer/Z Policy Predictions Std      360.883\n",
      "trainer/Z Policy Predictions Max     1443.19\n",
      "trainer/Z Policy Predictions Min     -357.198\n",
      "trainer/Z Expert Targets Mean        1058.83\n",
      "trainer/Z Expert Targets Std          226.865\n",
      "trainer/Z Expert Targets Max         1600.97\n",
      "trainer/Z Expert Targets Min          430.173\n",
      "trainer/Z Policy Targets Mean         793.763\n",
      "trainer/Z Policy Targets Std          367.742\n",
      "trainer/Z Policy Targets Max         1443.78\n",
      "trainer/Z Policy Targets Min         -462.273\n",
      "trainer/Log Pis Mean                   14.6538\n",
      "trainer/Log Pis Std                     5.62941\n",
      "trainer/Policy mu Mean                  0.126041\n",
      "trainer/Policy mu Std                   2.52632\n",
      "trainer/Policy log std Mean            -4.23496\n",
      "trainer/Policy log std Std              1.16151\n",
      "exploration/num steps total        256186\n",
      "exploration/num paths total          1128\n",
      "evaluation/num steps total              1.7499e+06\n",
      "evaluation/num paths total           2557\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51505\n",
      "evaluation/Rewards Std                  0.600716\n",
      "evaluation/Rewards Max                  4.93848\n",
      "evaluation/Rewards Min                  0.724343\n",
      "evaluation/Returns Mean              3515.05\n",
      "evaluation/Returns Std                  8.19431\n",
      "evaluation/Returns Max               3527.08\n",
      "evaluation/Returns Min               3502.94\n",
      "evaluation/Estimation Bias Mean       942.863\n",
      "evaluation/Estimation Bias Std        220.129\n",
      "evaluation/EB/Q_True Mean              32.387\n",
      "evaluation/EB/Q_True Std               99.6773\n",
      "evaluation/EB/Q_Pred Mean             975.25\n",
      "evaluation/EB/Q_Pred Std              197.742\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3515.05\n",
      "evaluation/Actions Mean                 0.05182\n",
      "evaluation/Actions Std                  0.588548\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76563\n",
      "time/backward_zf1 (s)                   1.87621\n",
      "time/backward_zf2 (s)                   1.80456\n",
      "time/data sampling (s)                  0.222692\n",
      "time/data storing (s)                   0.0139772\n",
      "time/evaluation sampling (s)            1.43171\n",
      "time/exploration sampling (s)           0.169685\n",
      "time/logging (s)                        0.011475\n",
      "time/preback_alpha (s)                  0.55058\n",
      "time/preback_policy (s)                 0.608231\n",
      "time/preback_start (s)                  0.124779\n",
      "time/preback_zf (s)                     4.95678\n",
      "time/saving (s)                         0.00528237\n",
      "time/training (s)                       2.52651\n",
      "time/epoch (s)                         16.0681\n",
      "time/total (s)                       3915.49\n",
      "Epoch                                 250\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:06:48.287895 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 251 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 262000\n",
      "trainer/ZF1 Loss                      130.915\n",
      "trainer/ZF2 Loss                      114.043\n",
      "trainer/ZF Expert Reward               23.9393\n",
      "trainer/ZF Policy Reward                8.19766\n",
      "trainer/ZF CHI2 Term                  152.344\n",
      "trainer/Policy Loss                  -801.031\n",
      "trainer/Policy Grad Norm              946.971\n",
      "trainer/Policy Param Norm              45.9982\n",
      "trainer/Zf1 Grad Norm              142753\n",
      "trainer/Zf1 Param Norm                128.716\n",
      "trainer/Zf2 Grad Norm              114754\n",
      "trainer/Zf2 Param Norm                124.046\n",
      "trainer/Z Expert Predictions Mean    1105.77\n",
      "trainer/Z Expert Predictions Std      258.961\n",
      "trainer/Z Expert Predictions Max     1649.72\n",
      "trainer/Z Expert Predictions Min      152.222\n",
      "trainer/Z Policy Predictions Mean     800.202\n",
      "trainer/Z Policy Predictions Std      397.812\n",
      "trainer/Z Policy Predictions Max     1558.87\n",
      "trainer/Z Policy Predictions Min     -334.261\n",
      "trainer/Z Expert Targets Mean        1081.84\n",
      "trainer/Z Expert Targets Std          256.96\n",
      "trainer/Z Expert Targets Max         1610.68\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         792.004\n",
      "trainer/Z Policy Targets Std          392.418\n",
      "trainer/Z Policy Targets Max         1460.51\n",
      "trainer/Z Policy Targets Min         -468.461\n",
      "trainer/Log Pis Mean                   14.2659\n",
      "trainer/Log Pis Std                     5.14362\n",
      "trainer/Policy mu Mean                  0.44328\n",
      "trainer/Policy mu Std                   2.60364\n",
      "trainer/Policy log std Mean            -4.04582\n",
      "trainer/Policy log std Std              1.25514\n",
      "exploration/num steps total        257186\n",
      "exploration/num paths total          1129\n",
      "evaluation/num steps total              1.75314e+06\n",
      "evaluation/num paths total           2567\n",
      "evaluation/path length Mean           323.3\n",
      "evaluation/path length Std             17.1642\n",
      "evaluation/path length Max            333\n",
      "evaluation/path length Min            272\n",
      "evaluation/Rewards Mean                 3.32996\n",
      "evaluation/Rewards Std                  0.844942\n",
      "evaluation/Rewards Max                  4.94024\n",
      "evaluation/Rewards Min                  0.753759\n",
      "evaluation/Returns Mean              1076.58\n",
      "evaluation/Returns Std                 67.0313\n",
      "evaluation/Returns Max               1108.07\n",
      "evaluation/Returns Min                875.746\n",
      "evaluation/Estimation Bias Mean       665.531\n",
      "evaluation/Estimation Bias Std        511.323\n",
      "evaluation/EB/Q_True Mean              26.4725\n",
      "evaluation/EB/Q_True Std               82.6534\n",
      "evaluation/EB/Q_Pred Mean             692.003\n",
      "evaluation/EB/Q_Pred Std              514.041\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1076.58\n",
      "evaluation/Actions Mean                 0.0372187\n",
      "evaluation/Actions Std                  0.601192\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73611\n",
      "time/backward_zf1 (s)                   1.85734\n",
      "time/backward_zf2 (s)                   1.78757\n",
      "time/data sampling (s)                  0.251633\n",
      "time/data storing (s)                   0.0140412\n",
      "time/evaluation sampling (s)            0.521151\n",
      "time/exploration sampling (s)           0.169223\n",
      "time/logging (s)                        0.00450317\n",
      "time/preback_alpha (s)                  0.556117\n",
      "time/preback_policy (s)                 0.615187\n",
      "time/preback_start (s)                  0.126452\n",
      "time/preback_zf (s)                     4.97212\n",
      "time/saving (s)                         0.00490444\n",
      "time/training (s)                       2.59349\n",
      "time/epoch (s)                         15.2098\n",
      "time/total (s)                       3930.71\n",
      "Epoch                                 251\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:07:04.351176 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 252 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 263000\n",
      "trainer/ZF1 Loss                       89.7765\n",
      "trainer/ZF2 Loss                       95.1618\n",
      "trainer/ZF Expert Reward               18.3868\n",
      "trainer/ZF Policy Reward                4.7692\n",
      "trainer/ZF CHI2 Term                  121.077\n",
      "trainer/Policy Loss                  -769.063\n",
      "trainer/Policy Grad Norm              963.288\n",
      "trainer/Policy Param Norm              46.0724\n",
      "trainer/Zf1 Grad Norm              156015\n",
      "trainer/Zf1 Param Norm                128.907\n",
      "trainer/Zf2 Grad Norm              147622\n",
      "trainer/Zf2 Param Norm                124.236\n",
      "trainer/Z Expert Predictions Mean    1092.57\n",
      "trainer/Z Expert Predictions Std      244.986\n",
      "trainer/Z Expert Predictions Max     1647.43\n",
      "trainer/Z Expert Predictions Min      553.033\n",
      "trainer/Z Policy Predictions Mean     764.867\n",
      "trainer/Z Policy Predictions Std      435.579\n",
      "trainer/Z Policy Predictions Max     1594.06\n",
      "trainer/Z Policy Predictions Min     -457.441\n",
      "trainer/Z Expert Targets Mean        1074.18\n",
      "trainer/Z Expert Targets Std          245.948\n",
      "trainer/Z Expert Targets Max         1631.82\n",
      "trainer/Z Expert Targets Min          514.707\n",
      "trainer/Z Policy Targets Mean         760.097\n",
      "trainer/Z Policy Targets Std          432.431\n",
      "trainer/Z Policy Targets Max         1581.63\n",
      "trainer/Z Policy Targets Min         -561.93\n",
      "trainer/Log Pis Mean                   15.1422\n",
      "trainer/Log Pis Std                     6.11881\n",
      "trainer/Policy mu Mean                  0.189324\n",
      "trainer/Policy mu Std                   2.999\n",
      "trainer/Policy log std Mean            -4.27804\n",
      "trainer/Policy log std Std              1.20928\n",
      "exploration/num steps total        258186\n",
      "exploration/num paths total          1130\n",
      "evaluation/num steps total              1.76314e+06\n",
      "evaluation/num paths total           2577\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.53681\n",
      "evaluation/Rewards Std                  0.594122\n",
      "evaluation/Rewards Max                  4.85811\n",
      "evaluation/Rewards Min                  0.702497\n",
      "evaluation/Returns Mean              3536.81\n",
      "evaluation/Returns Std                  7.61392\n",
      "evaluation/Returns Max               3547.75\n",
      "evaluation/Returns Min               3523.99\n",
      "evaluation/Estimation Bias Mean       969.945\n",
      "evaluation/Estimation Bias Std        219.775\n",
      "evaluation/EB/Q_True Mean              32.7169\n",
      "evaluation/EB/Q_True Std              100.786\n",
      "evaluation/EB/Q_Pred Mean            1002.66\n",
      "evaluation/EB/Q_Pred Std              201.359\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3536.81\n",
      "evaluation/Actions Mean                 0.0485111\n",
      "evaluation/Actions Std                  0.585619\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70503\n",
      "time/backward_zf1 (s)                   1.81845\n",
      "time/backward_zf2 (s)                   1.73368\n",
      "time/data sampling (s)                  0.246164\n",
      "time/data storing (s)                   0.013743\n",
      "time/evaluation sampling (s)            1.36465\n",
      "time/exploration sampling (s)           0.169511\n",
      "time/logging (s)                        0.0119565\n",
      "time/preback_alpha (s)                  0.553251\n",
      "time/preback_policy (s)                 0.603564\n",
      "time/preback_start (s)                  0.126309\n",
      "time/preback_zf (s)                     4.97106\n",
      "time/saving (s)                         0.00540413\n",
      "time/training (s)                       2.68481\n",
      "time/epoch (s)                         16.0076\n",
      "time/total (s)                       3946.74\n",
      "Epoch                                 252\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:07:20.597106 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 253 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 264000\n",
      "trainer/ZF1 Loss                       93.2503\n",
      "trainer/ZF2 Loss                       86.2832\n",
      "trainer/ZF Expert Reward                8.90806\n",
      "trainer/ZF Policy Reward               -0.651238\n",
      "trainer/ZF CHI2 Term                  113.341\n",
      "trainer/Policy Loss                  -798.243\n",
      "trainer/Policy Grad Norm              577.126\n",
      "trainer/Policy Param Norm              46.1429\n",
      "trainer/Zf1 Grad Norm              132349\n",
      "trainer/Zf1 Param Norm                129.098\n",
      "trainer/Zf2 Grad Norm              104472\n",
      "trainer/Zf2 Param Norm                124.429\n",
      "trainer/Z Expert Predictions Mean    1095.97\n",
      "trainer/Z Expert Predictions Std      240.89\n",
      "trainer/Z Expert Predictions Max     1640.21\n",
      "trainer/Z Expert Predictions Min      412.994\n",
      "trainer/Z Policy Predictions Mean     793.737\n",
      "trainer/Z Policy Predictions Std      374.6\n",
      "trainer/Z Policy Predictions Max     1510.9\n",
      "trainer/Z Policy Predictions Min     -261.373\n",
      "trainer/Z Expert Targets Mean        1087.06\n",
      "trainer/Z Expert Targets Std          242.16\n",
      "trainer/Z Expert Targets Max         1622.32\n",
      "trainer/Z Expert Targets Min          415.347\n",
      "trainer/Z Policy Targets Mean         794.388\n",
      "trainer/Z Policy Targets Std          372.097\n",
      "trainer/Z Policy Targets Max         1605.23\n",
      "trainer/Z Policy Targets Min         -265.715\n",
      "trainer/Log Pis Mean                   14.1567\n",
      "trainer/Log Pis Std                     5.11198\n",
      "trainer/Policy mu Mean                  0.378798\n",
      "trainer/Policy mu Std                   3.07331\n",
      "trainer/Policy log std Mean            -4.22075\n",
      "trainer/Policy log std Std              1.25562\n",
      "exploration/num steps total        258186\n",
      "exploration/num paths total          1130\n",
      "evaluation/num steps total              1.77314e+06\n",
      "evaluation/num paths total           2587\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52043\n",
      "evaluation/Rewards Std                  0.600318\n",
      "evaluation/Rewards Max                  4.77261\n",
      "evaluation/Rewards Min                  0.820466\n",
      "evaluation/Returns Mean              3520.43\n",
      "evaluation/Returns Std                 18.108\n",
      "evaluation/Returns Max               3543.51\n",
      "evaluation/Returns Min               3481.81\n",
      "evaluation/Estimation Bias Mean       966.369\n",
      "evaluation/Estimation Bias Std        229.958\n",
      "evaluation/EB/Q_True Mean              32.5552\n",
      "evaluation/EB/Q_True Std              100.543\n",
      "evaluation/EB/Q_Pred Mean             998.924\n",
      "evaluation/EB/Q_Pred Std              215.32\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3520.43\n",
      "evaluation/Actions Mean                 0.0435061\n",
      "evaluation/Actions Std                  0.581176\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77543\n",
      "time/backward_zf1 (s)                   1.88558\n",
      "time/backward_zf2 (s)                   1.81944\n",
      "time/data sampling (s)                  0.255256\n",
      "time/data storing (s)                   0.0138424\n",
      "time/evaluation sampling (s)            1.37518\n",
      "time/exploration sampling (s)           0.169076\n",
      "time/logging (s)                        0.0115846\n",
      "time/preback_alpha (s)                  0.554863\n",
      "time/preback_policy (s)                 0.622045\n",
      "time/preback_start (s)                  0.125516\n",
      "time/preback_zf (s)                     4.99282\n",
      "time/saving (s)                         0.0167416\n",
      "time/training (s)                       2.56159\n",
      "time/epoch (s)                         16.179\n",
      "time/total (s)                       3962.94\n",
      "Epoch                                 253\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:07:36.661653 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 254 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 265000\n",
      "trainer/ZF1 Loss                       93.7454\n",
      "trainer/ZF2 Loss                       83.1481\n",
      "trainer/ZF Expert Reward                9.70614\n",
      "trainer/ZF Policy Reward                1.62257\n",
      "trainer/ZF CHI2 Term                  110.925\n",
      "trainer/Policy Loss                  -807.748\n",
      "trainer/Policy Grad Norm              453.871\n",
      "trainer/Policy Param Norm              46.2109\n",
      "trainer/Zf1 Grad Norm               87122.3\n",
      "trainer/Zf1 Param Norm                129.301\n",
      "trainer/Zf2 Grad Norm               42538.2\n",
      "trainer/Zf2 Param Norm                124.626\n",
      "trainer/Z Expert Predictions Mean    1036.9\n",
      "trainer/Z Expert Predictions Std      223.994\n",
      "trainer/Z Expert Predictions Max     1609.59\n",
      "trainer/Z Expert Predictions Min      446.383\n",
      "trainer/Z Policy Predictions Mean     804.763\n",
      "trainer/Z Policy Predictions Std      393.215\n",
      "trainer/Z Policy Predictions Max     1520.4\n",
      "trainer/Z Policy Predictions Min     -398.986\n",
      "trainer/Z Expert Targets Mean        1027.19\n",
      "trainer/Z Expert Targets Std          226.002\n",
      "trainer/Z Expert Targets Max         1583.82\n",
      "trainer/Z Expert Targets Min          385.99\n",
      "trainer/Z Policy Targets Mean         803.14\n",
      "trainer/Z Policy Targets Std          388.455\n",
      "trainer/Z Policy Targets Max         1483.97\n",
      "trainer/Z Policy Targets Min         -384.917\n",
      "trainer/Log Pis Mean                   14.5396\n",
      "trainer/Log Pis Std                     5.16588\n",
      "trainer/Policy mu Mean                  0.107363\n",
      "trainer/Policy mu Std                   2.65397\n",
      "trainer/Policy log std Mean            -4.38413\n",
      "trainer/Policy log std Std              1.05502\n",
      "exploration/num steps total        258186\n",
      "exploration/num paths total          1130\n",
      "evaluation/num steps total              1.78181e+06\n",
      "evaluation/num paths total           2597\n",
      "evaluation/path length Mean           867.2\n",
      "evaluation/path length Std            265.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 3.52178\n",
      "evaluation/Rewards Std                  0.623533\n",
      "evaluation/Rewards Max                  4.73588\n",
      "evaluation/Rewards Min                  0.734556\n",
      "evaluation/Returns Mean              3054.09\n",
      "evaluation/Returns Std                968.751\n",
      "evaluation/Returns Max               3545.55\n",
      "evaluation/Returns Min               1111.99\n",
      "evaluation/Estimation Bias Mean       989.356\n",
      "evaluation/Estimation Bias Std        268.926\n",
      "evaluation/EB/Q_True Mean              37.7995\n",
      "evaluation/EB/Q_True Std              107.546\n",
      "evaluation/EB/Q_Pred Mean            1027.16\n",
      "evaluation/EB/Q_Pred Std              237.753\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3054.09\n",
      "evaluation/Actions Mean                 0.0499482\n",
      "evaluation/Actions Std                  0.588068\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76938\n",
      "time/backward_zf1 (s)                   1.87767\n",
      "time/backward_zf2 (s)                   1.80586\n",
      "time/data sampling (s)                  0.229749\n",
      "time/data storing (s)                   0.0135134\n",
      "time/evaluation sampling (s)            1.38223\n",
      "time/exploration sampling (s)           0.165085\n",
      "time/logging (s)                        0.0100164\n",
      "time/preback_alpha (s)                  0.549116\n",
      "time/preback_policy (s)                 0.610615\n",
      "time/preback_start (s)                  0.125243\n",
      "time/preback_zf (s)                     4.95904\n",
      "time/saving (s)                         0.00499039\n",
      "time/training (s)                       2.49736\n",
      "time/epoch (s)                         15.9999\n",
      "time/total (s)                       3978.96\n",
      "Epoch                                 254\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:07:52.913612 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 255 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 266000\n",
      "trainer/ZF1 Loss                      103.34\n",
      "trainer/ZF2 Loss                      102.712\n",
      "trainer/ZF Expert Reward               15.7554\n",
      "trainer/ZF Policy Reward                2.51536\n",
      "trainer/ZF CHI2 Term                  130.689\n",
      "trainer/Policy Loss                  -794.894\n",
      "trainer/Policy Grad Norm              763.118\n",
      "trainer/Policy Param Norm              46.272\n",
      "trainer/Zf1 Grad Norm              128712\n",
      "trainer/Zf1 Param Norm                129.497\n",
      "trainer/Zf2 Grad Norm               96373.2\n",
      "trainer/Zf2 Param Norm                124.839\n",
      "trainer/Z Expert Predictions Mean    1076.34\n",
      "trainer/Z Expert Predictions Std      239.645\n",
      "trainer/Z Expert Predictions Max     1627.87\n",
      "trainer/Z Expert Predictions Min      151.133\n",
      "trainer/Z Policy Predictions Mean     789.937\n",
      "trainer/Z Policy Predictions Std      378.45\n",
      "trainer/Z Policy Predictions Max     1521.18\n",
      "trainer/Z Policy Predictions Min     -375.782\n",
      "trainer/Z Expert Targets Mean        1060.59\n",
      "trainer/Z Expert Targets Std          241.841\n",
      "trainer/Z Expert Targets Max         1628.22\n",
      "trainer/Z Expert Targets Min           59.2691\n",
      "trainer/Z Policy Targets Mean         787.421\n",
      "trainer/Z Policy Targets Std          376.38\n",
      "trainer/Z Policy Targets Max         1541.62\n",
      "trainer/Z Policy Targets Min         -438.685\n",
      "trainer/Log Pis Mean                   14.5685\n",
      "trainer/Log Pis Std                     5.06087\n",
      "trainer/Policy mu Mean                  0.102595\n",
      "trainer/Policy mu Std                   2.80144\n",
      "trainer/Policy log std Mean            -4.35307\n",
      "trainer/Policy log std Std              1.17834\n",
      "exploration/num steps total        260186\n",
      "exploration/num paths total          1132\n",
      "evaluation/num steps total              1.79181e+06\n",
      "evaluation/num paths total           2607\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50408\n",
      "evaluation/Rewards Std                  0.590381\n",
      "evaluation/Rewards Max                  4.6867\n",
      "evaluation/Rewards Min                  0.752567\n",
      "evaluation/Returns Mean              3504.08\n",
      "evaluation/Returns Std                 13.0409\n",
      "evaluation/Returns Max               3523.34\n",
      "evaluation/Returns Min               3479.08\n",
      "evaluation/Estimation Bias Mean       973.227\n",
      "evaluation/Estimation Bias Std        226.496\n",
      "evaluation/EB/Q_True Mean              32.4117\n",
      "evaluation/EB/Q_True Std              100.03\n",
      "evaluation/EB/Q_Pred Mean            1005.64\n",
      "evaluation/EB/Q_Pred Std              203.166\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3504.08\n",
      "evaluation/Actions Mean                 0.0400675\n",
      "evaluation/Actions Std                  0.581355\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79767\n",
      "time/backward_zf1 (s)                   1.90445\n",
      "time/backward_zf2 (s)                   1.83157\n",
      "time/data sampling (s)                  0.254599\n",
      "time/data storing (s)                   0.0143145\n",
      "time/evaluation sampling (s)            1.44395\n",
      "time/exploration sampling (s)           0.17581\n",
      "time/logging (s)                        0.0129943\n",
      "time/preback_alpha (s)                  0.557324\n",
      "time/preback_policy (s)                 0.627372\n",
      "time/preback_start (s)                  0.125785\n",
      "time/preback_zf (s)                     4.9642\n",
      "time/saving (s)                         0.00628393\n",
      "time/training (s)                       2.47504\n",
      "time/epoch (s)                         16.1914\n",
      "time/total (s)                       3995.16\n",
      "Epoch                                 255\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:08:09.136594 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 256 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 267000\n",
      "trainer/ZF1 Loss                      100.511\n",
      "trainer/ZF2 Loss                       90.2096\n",
      "trainer/ZF Expert Reward               14.8407\n",
      "trainer/ZF Policy Reward                0.224994\n",
      "trainer/ZF CHI2 Term                  123.462\n",
      "trainer/Policy Loss                  -742.843\n",
      "trainer/Policy Grad Norm              701.385\n",
      "trainer/Policy Param Norm              46.348\n",
      "trainer/Zf1 Grad Norm               62555.9\n",
      "trainer/Zf1 Param Norm                129.711\n",
      "trainer/Zf2 Grad Norm               57223\n",
      "trainer/Zf2 Param Norm                125.042\n",
      "trainer/Z Expert Predictions Mean    1049.27\n",
      "trainer/Z Expert Predictions Std      250.952\n",
      "trainer/Z Expert Predictions Max     1620.37\n",
      "trainer/Z Expert Predictions Min      488.675\n",
      "trainer/Z Policy Predictions Mean     735.562\n",
      "trainer/Z Policy Predictions Std      409.501\n",
      "trainer/Z Policy Predictions Max     1405.46\n",
      "trainer/Z Policy Predictions Min     -547.26\n",
      "trainer/Z Expert Targets Mean        1034.43\n",
      "trainer/Z Expert Targets Std          254.679\n",
      "trainer/Z Expert Targets Max         1640.58\n",
      "trainer/Z Expert Targets Min          433.618\n",
      "trainer/Z Policy Targets Mean         735.337\n",
      "trainer/Z Policy Targets Std          400.299\n",
      "trainer/Z Policy Targets Max         1362.61\n",
      "trainer/Z Policy Targets Min         -553.017\n",
      "trainer/Log Pis Mean                   13.6225\n",
      "trainer/Log Pis Std                     5.2156\n",
      "trainer/Policy mu Mean                  0.210877\n",
      "trainer/Policy mu Std                   2.96776\n",
      "trainer/Policy log std Mean            -4.16963\n",
      "trainer/Policy log std Std              1.26872\n",
      "exploration/num steps total        261186\n",
      "exploration/num paths total          1133\n",
      "evaluation/num steps total              1.80181e+06\n",
      "evaluation/num paths total           2617\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52518\n",
      "evaluation/Rewards Std                  0.595516\n",
      "evaluation/Rewards Max                  4.7319\n",
      "evaluation/Rewards Min                  0.771238\n",
      "evaluation/Returns Mean              3525.18\n",
      "evaluation/Returns Std                 27.064\n",
      "evaluation/Returns Max               3560.61\n",
      "evaluation/Returns Min               3474.07\n",
      "evaluation/Estimation Bias Mean       980.086\n",
      "evaluation/Estimation Bias Std        244.433\n",
      "evaluation/EB/Q_True Mean              32.9018\n",
      "evaluation/EB/Q_True Std              101.448\n",
      "evaluation/EB/Q_Pred Mean            1012.99\n",
      "evaluation/EB/Q_Pred Std              226.096\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3525.18\n",
      "evaluation/Actions Mean                 0.0475414\n",
      "evaluation/Actions Std                  0.588836\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74223\n",
      "time/backward_zf1 (s)                   1.84672\n",
      "time/backward_zf2 (s)                   1.77641\n",
      "time/data sampling (s)                  0.256038\n",
      "time/data storing (s)                   0.0135793\n",
      "time/evaluation sampling (s)            1.41782\n",
      "time/exploration sampling (s)           0.167098\n",
      "time/logging (s)                        0.0115821\n",
      "time/preback_alpha (s)                  0.555213\n",
      "time/preback_policy (s)                 0.608235\n",
      "time/preback_start (s)                  0.125955\n",
      "time/preback_zf (s)                     4.95423\n",
      "time/saving (s)                         0.00533413\n",
      "time/training (s)                       2.67414\n",
      "time/epoch (s)                         16.1546\n",
      "time/total (s)                       4011.34\n",
      "Epoch                                 256\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:08:24.455198 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 257 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 268000\n",
      "trainer/ZF1 Loss                      150.099\n",
      "trainer/ZF2 Loss                      103.666\n",
      "trainer/ZF Expert Reward               12.167\n",
      "trainer/ZF Policy Reward               -5.68398\n",
      "trainer/ZF CHI2 Term                  158.461\n",
      "trainer/Policy Loss                  -792.456\n",
      "trainer/Policy Grad Norm              601.707\n",
      "trainer/Policy Param Norm              46.431\n",
      "trainer/Zf1 Grad Norm              177646\n",
      "trainer/Zf1 Param Norm                129.919\n",
      "trainer/Zf2 Grad Norm               60687\n",
      "trainer/Zf2 Param Norm                125.241\n",
      "trainer/Z Expert Predictions Mean    1063.31\n",
      "trainer/Z Expert Predictions Std      237.866\n",
      "trainer/Z Expert Predictions Max     1675.85\n",
      "trainer/Z Expert Predictions Min      568.611\n",
      "trainer/Z Policy Predictions Mean     781.49\n",
      "trainer/Z Policy Predictions Std      387.455\n",
      "trainer/Z Policy Predictions Max     1482.44\n",
      "trainer/Z Policy Predictions Min     -373.09\n",
      "trainer/Z Expert Targets Mean        1051.14\n",
      "trainer/Z Expert Targets Std          237.404\n",
      "trainer/Z Expert Targets Max         1641.81\n",
      "trainer/Z Expert Targets Min          532.549\n",
      "trainer/Z Policy Targets Mean         787.174\n",
      "trainer/Z Policy Targets Std          386.124\n",
      "trainer/Z Policy Targets Max         1482.38\n",
      "trainer/Z Policy Targets Min         -376.512\n",
      "trainer/Log Pis Mean                   13.8657\n",
      "trainer/Log Pis Std                     4.52277\n",
      "trainer/Policy mu Mean                  0.342705\n",
      "trainer/Policy mu Std                   2.80355\n",
      "trainer/Policy log std Mean            -4.22317\n",
      "trainer/Policy log std Std              1.25062\n",
      "exploration/num steps total        264186\n",
      "exploration/num paths total          1136\n",
      "evaluation/num steps total              1.80491e+06\n",
      "evaluation/num paths total           2627\n",
      "evaluation/path length Mean           310.5\n",
      "evaluation/path length Std             33.1217\n",
      "evaluation/path length Max            337\n",
      "evaluation/path length Min            259\n",
      "evaluation/Rewards Mean                 3.28277\n",
      "evaluation/Rewards Std                  0.832907\n",
      "evaluation/Rewards Max                  4.61425\n",
      "evaluation/Rewards Min                  0.73575\n",
      "evaluation/Returns Mean              1019.3\n",
      "evaluation/Returns Std                127.715\n",
      "evaluation/Returns Max               1117.55\n",
      "evaluation/Returns Min                822.448\n",
      "evaluation/Estimation Bias Mean       762.375\n",
      "evaluation/Estimation Bias Std        353.146\n",
      "evaluation/EB/Q_True Mean              27.8499\n",
      "evaluation/EB/Q_True Std               84.6053\n",
      "evaluation/EB/Q_Pred Mean             790.225\n",
      "evaluation/EB/Q_Pred Std              349.36\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1019.3\n",
      "evaluation/Actions Mean                 0.0300751\n",
      "evaluation/Actions Std                  0.608753\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83006\n",
      "time/backward_zf1 (s)                   1.93294\n",
      "time/backward_zf2 (s)                   1.87516\n",
      "time/data sampling (s)                  0.258089\n",
      "time/data storing (s)                   0.0140585\n",
      "time/evaluation sampling (s)            0.52273\n",
      "time/exploration sampling (s)           0.176797\n",
      "time/logging (s)                        0.00440431\n",
      "time/preback_alpha (s)                  0.553096\n",
      "time/preback_policy (s)                 0.62484\n",
      "time/preback_start (s)                  0.127071\n",
      "time/preback_zf (s)                     4.97334\n",
      "time/saving (s)                         0.00505092\n",
      "time/training (s)                       2.34681\n",
      "time/epoch (s)                         15.2445\n",
      "time/total (s)                       4026.6\n",
      "Epoch                                 257\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:08:40.578728 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 258 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 269000\n",
      "trainer/ZF1 Loss                      233.201\n",
      "trainer/ZF2 Loss                      259.372\n",
      "trainer/ZF Expert Reward               15.1478\n",
      "trainer/ZF Policy Reward               11.229\n",
      "trainer/ZF CHI2 Term                  264.434\n",
      "trainer/Policy Loss                  -782.569\n",
      "trainer/Policy Grad Norm             1178.52\n",
      "trainer/Policy Param Norm              46.5073\n",
      "trainer/Zf1 Grad Norm               79308.9\n",
      "trainer/Zf1 Param Norm                130.117\n",
      "trainer/Zf2 Grad Norm              114460\n",
      "trainer/Zf2 Param Norm                125.441\n",
      "trainer/Z Expert Predictions Mean    1057.22\n",
      "trainer/Z Expert Predictions Std      234.441\n",
      "trainer/Z Expert Predictions Max     1665.71\n",
      "trainer/Z Expert Predictions Min      511.784\n",
      "trainer/Z Policy Predictions Mean     780.141\n",
      "trainer/Z Policy Predictions Std      408.552\n",
      "trainer/Z Policy Predictions Max     1576.55\n",
      "trainer/Z Policy Predictions Min     -397.157\n",
      "trainer/Z Expert Targets Mean        1042.08\n",
      "trainer/Z Expert Targets Std          236.891\n",
      "trainer/Z Expert Targets Max         1653.49\n",
      "trainer/Z Expert Targets Min          479.951\n",
      "trainer/Z Policy Targets Mean         768.912\n",
      "trainer/Z Policy Targets Std          411.82\n",
      "trainer/Z Policy Targets Max         1529.09\n",
      "trainer/Z Policy Targets Min         -405.749\n",
      "trainer/Log Pis Mean                   14.3721\n",
      "trainer/Log Pis Std                     5.25295\n",
      "trainer/Policy mu Mean                  0.221813\n",
      "trainer/Policy mu Std                   2.58094\n",
      "trainer/Policy log std Mean            -4.32806\n",
      "trainer/Policy log std Std              1.14548\n",
      "exploration/num steps total        265186\n",
      "exploration/num paths total          1137\n",
      "evaluation/num steps total              1.81259e+06\n",
      "evaluation/num paths total           2638\n",
      "evaluation/path length Mean           697.636\n",
      "evaluation/path length Std            331.224\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 3.49333\n",
      "evaluation/Rewards Std                  0.656817\n",
      "evaluation/Rewards Max                  4.74526\n",
      "evaluation/Rewards Min                  0.746655\n",
      "evaluation/Returns Mean              2437.07\n",
      "evaluation/Returns Std               1210.29\n",
      "evaluation/Returns Max               3558.99\n",
      "evaluation/Returns Min               1104.32\n",
      "evaluation/Estimation Bias Mean       924.366\n",
      "evaluation/Estimation Bias Std        309.645\n",
      "evaluation/EB/Q_True Mean              42.4816\n",
      "evaluation/EB/Q_True Std              113.17\n",
      "evaluation/EB/Q_Pred Mean             966.847\n",
      "evaluation/EB/Q_Pred Std              266.083\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2437.07\n",
      "evaluation/Actions Mean                 0.0393215\n",
      "evaluation/Actions Std                  0.598186\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79346\n",
      "time/backward_zf1 (s)                   1.90882\n",
      "time/backward_zf2 (s)                   1.84239\n",
      "time/data sampling (s)                  0.261527\n",
      "time/data storing (s)                   0.0135087\n",
      "time/evaluation sampling (s)            1.36655\n",
      "time/exploration sampling (s)           0.168725\n",
      "time/logging (s)                        0.00990474\n",
      "time/preback_alpha (s)                  0.553321\n",
      "time/preback_policy (s)                 0.615833\n",
      "time/preback_start (s)                  0.124573\n",
      "time/preback_zf (s)                     4.96075\n",
      "time/saving (s)                         0.0053447\n",
      "time/training (s)                       2.43801\n",
      "time/epoch (s)                         16.0627\n",
      "time/total (s)                       4042.69\n",
      "Epoch                                 258\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:08:56.819287 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 259 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 270000\n",
      "trainer/ZF1 Loss                      291.695\n",
      "trainer/ZF2 Loss                      319.109\n",
      "trainer/ZF Expert Reward               15.5295\n",
      "trainer/ZF Policy Reward                0.698901\n",
      "trainer/ZF CHI2 Term                  334.178\n",
      "trainer/Policy Loss                  -778.743\n",
      "trainer/Policy Grad Norm             1152.3\n",
      "trainer/Policy Param Norm              46.5808\n",
      "trainer/Zf1 Grad Norm              121079\n",
      "trainer/Zf1 Param Norm                130.331\n",
      "trainer/Zf2 Grad Norm              189753\n",
      "trainer/Zf2 Param Norm                125.645\n",
      "trainer/Z Expert Predictions Mean    1055.71\n",
      "trainer/Z Expert Predictions Std      245.457\n",
      "trainer/Z Expert Predictions Max     1661.71\n",
      "trainer/Z Expert Predictions Min      352.609\n",
      "trainer/Z Policy Predictions Mean     774.23\n",
      "trainer/Z Policy Predictions Std      383.173\n",
      "trainer/Z Policy Predictions Max     1565.43\n",
      "trainer/Z Policy Predictions Min     -360.672\n",
      "trainer/Z Expert Targets Mean        1040.18\n",
      "trainer/Z Expert Targets Std          254.356\n",
      "trainer/Z Expert Targets Max         1655.58\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         773.531\n",
      "trainer/Z Policy Targets Std          378.601\n",
      "trainer/Z Policy Targets Max         1566.56\n",
      "trainer/Z Policy Targets Min         -356.99\n",
      "trainer/Log Pis Mean                   14.0862\n",
      "trainer/Log Pis Std                     5.26476\n",
      "trainer/Policy mu Mean                  0.159747\n",
      "trainer/Policy mu Std                   2.3229\n",
      "trainer/Policy log std Mean            -4.36927\n",
      "trainer/Policy log std Std              1.0438\n",
      "exploration/num steps total        266186\n",
      "exploration/num paths total          1138\n",
      "evaluation/num steps total              1.82259e+06\n",
      "evaluation/num paths total           2648\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51228\n",
      "evaluation/Rewards Std                  0.590341\n",
      "evaluation/Rewards Max                  4.69662\n",
      "evaluation/Rewards Min                  0.78825\n",
      "evaluation/Returns Mean              3512.28\n",
      "evaluation/Returns Std                 15.3636\n",
      "evaluation/Returns Max               3535.17\n",
      "evaluation/Returns Min               3483.98\n",
      "evaluation/Estimation Bias Mean       949.726\n",
      "evaluation/Estimation Bias Std        239.714\n",
      "evaluation/EB/Q_True Mean              32.5513\n",
      "evaluation/EB/Q_True Std              100.432\n",
      "evaluation/EB/Q_Pred Mean             982.277\n",
      "evaluation/EB/Q_Pred Std              221.046\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3512.28\n",
      "evaluation/Actions Mean                 0.0457069\n",
      "evaluation/Actions Std                  0.588065\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81305\n",
      "time/backward_zf1 (s)                   1.91462\n",
      "time/backward_zf2 (s)                   1.85296\n",
      "time/data sampling (s)                  0.262307\n",
      "time/data storing (s)                   0.014303\n",
      "time/evaluation sampling (s)            1.4448\n",
      "time/exploration sampling (s)           0.174162\n",
      "time/logging (s)                        0.0118879\n",
      "time/preback_alpha (s)                  0.556986\n",
      "time/preback_policy (s)                 0.627965\n",
      "time/preback_start (s)                  0.124511\n",
      "time/preback_zf (s)                     4.95759\n",
      "time/saving (s)                         0.00544839\n",
      "time/training (s)                       2.4137\n",
      "time/epoch (s)                         16.1743\n",
      "time/total (s)                       4058.88\n",
      "Epoch                                 259\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:09:12.941986 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 260 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 271000\n",
      "trainer/ZF1 Loss                      147.692\n",
      "trainer/ZF2 Loss                      224.957\n",
      "trainer/ZF Expert Reward                8.76812\n",
      "trainer/ZF Policy Reward                1.56959\n",
      "trainer/ZF CHI2 Term                  207.467\n",
      "trainer/Policy Loss                  -744.556\n",
      "trainer/Policy Grad Norm              690.528\n",
      "trainer/Policy Param Norm              46.6545\n",
      "trainer/Zf1 Grad Norm              151656\n",
      "trainer/Zf1 Param Norm                130.539\n",
      "trainer/Zf2 Grad Norm              156966\n",
      "trainer/Zf2 Param Norm                125.846\n",
      "trainer/Z Expert Predictions Mean    1028.24\n",
      "trainer/Z Expert Predictions Std      243.307\n",
      "trainer/Z Expert Predictions Max     1663.04\n",
      "trainer/Z Expert Predictions Min      307.488\n",
      "trainer/Z Policy Predictions Mean     745.785\n",
      "trainer/Z Policy Predictions Std      383.256\n",
      "trainer/Z Policy Predictions Max     1508.55\n",
      "trainer/Z Policy Predictions Min     -485.715\n",
      "trainer/Z Expert Targets Mean        1019.48\n",
      "trainer/Z Expert Targets Std          254.618\n",
      "trainer/Z Expert Targets Max         1631.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         744.215\n",
      "trainer/Z Policy Targets Std          382.778\n",
      "trainer/Z Policy Targets Max         1519.05\n",
      "trainer/Z Policy Targets Min         -372.139\n",
      "trainer/Log Pis Mean                   14.085\n",
      "trainer/Log Pis Std                     4.971\n",
      "trainer/Policy mu Mean                  0.262237\n",
      "trainer/Policy mu Std                   2.48805\n",
      "trainer/Policy log std Mean            -4.25669\n",
      "trainer/Policy log std Std              1.20213\n",
      "exploration/num steps total        266518\n",
      "exploration/num paths total          1139\n",
      "evaluation/num steps total              1.83259e+06\n",
      "evaluation/num paths total           2658\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.49101\n",
      "evaluation/Rewards Std                  0.594296\n",
      "evaluation/Rewards Max                  4.72751\n",
      "evaluation/Rewards Min                  0.822228\n",
      "evaluation/Returns Mean              3491.01\n",
      "evaluation/Returns Std                 32.9712\n",
      "evaluation/Returns Max               3531.23\n",
      "evaluation/Returns Min               3422.43\n",
      "evaluation/Estimation Bias Mean       946.607\n",
      "evaluation/Estimation Bias Std        237.596\n",
      "evaluation/EB/Q_True Mean              32.2324\n",
      "evaluation/EB/Q_True Std               99.3969\n",
      "evaluation/EB/Q_Pred Mean             978.839\n",
      "evaluation/EB/Q_Pred Std              220.384\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3491.01\n",
      "evaluation/Actions Mean                 0.0391422\n",
      "evaluation/Actions Std                  0.589165\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.82158\n",
      "time/backward_zf1 (s)                   1.93871\n",
      "time/backward_zf2 (s)                   1.88625\n",
      "time/data sampling (s)                  0.26377\n",
      "time/data storing (s)                   0.0134565\n",
      "time/evaluation sampling (s)            1.36624\n",
      "time/exploration sampling (s)           0.167518\n",
      "time/logging (s)                        0.0117667\n",
      "time/preback_alpha (s)                  0.553272\n",
      "time/preback_policy (s)                 0.62537\n",
      "time/preback_start (s)                  0.12364\n",
      "time/preback_zf (s)                     4.95992\n",
      "time/saving (s)                         0.00483421\n",
      "time/training (s)                       2.32246\n",
      "time/epoch (s)                         16.0588\n",
      "time/total (s)                       4074.96\n",
      "Epoch                                 260\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:09:29.101370 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 261 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 272000\n",
      "trainer/ZF1 Loss                       59.4569\n",
      "trainer/ZF2 Loss                       92.4403\n",
      "trainer/ZF Expert Reward                5.75898\n",
      "trainer/ZF Policy Reward               -3.25367\n",
      "trainer/ZF CHI2 Term                   99.943\n",
      "trainer/Policy Loss                  -731.25\n",
      "trainer/Policy Grad Norm              906.342\n",
      "trainer/Policy Param Norm              46.729\n",
      "trainer/Zf1 Grad Norm               42607\n",
      "trainer/Zf1 Param Norm                130.732\n",
      "trainer/Zf2 Grad Norm               54580.9\n",
      "trainer/Zf2 Param Norm                126.031\n",
      "trainer/Z Expert Predictions Mean    1044.52\n",
      "trainer/Z Expert Predictions Std      227.954\n",
      "trainer/Z Expert Predictions Max     1651.46\n",
      "trainer/Z Expert Predictions Min      386.014\n",
      "trainer/Z Policy Predictions Mean     727.039\n",
      "trainer/Z Policy Predictions Std      412.791\n",
      "trainer/Z Policy Predictions Max     1377.49\n",
      "trainer/Z Policy Predictions Min     -430.52\n",
      "trainer/Z Expert Targets Mean        1038.77\n",
      "trainer/Z Expert Targets Std          229.581\n",
      "trainer/Z Expert Targets Max         1650.78\n",
      "trainer/Z Expert Targets Min          375.781\n",
      "trainer/Z Policy Targets Mean         730.292\n",
      "trainer/Z Policy Targets Std          411.556\n",
      "trainer/Z Policy Targets Max         1421.78\n",
      "trainer/Z Policy Targets Min         -407.51\n",
      "trainer/Log Pis Mean                   15.1331\n",
      "trainer/Log Pis Std                     6.00239\n",
      "trainer/Policy mu Mean                  0.472927\n",
      "trainer/Policy mu Std                   3.50686\n",
      "trainer/Policy log std Mean            -4.20759\n",
      "trainer/Policy log std Std              1.37915\n",
      "exploration/num steps total        267518\n",
      "exploration/num paths total          1140\n",
      "evaluation/num steps total              1.84259e+06\n",
      "evaluation/num paths total           2668\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.51376\n",
      "evaluation/Rewards Std                  0.591876\n",
      "evaluation/Rewards Max                  4.67533\n",
      "evaluation/Rewards Min                  0.787617\n",
      "evaluation/Returns Mean              3513.76\n",
      "evaluation/Returns Std                 17.3712\n",
      "evaluation/Returns Max               3533.55\n",
      "evaluation/Returns Min               3478.41\n",
      "evaluation/Estimation Bias Mean       974.185\n",
      "evaluation/Estimation Bias Std        234.77\n",
      "evaluation/EB/Q_True Mean              32.5947\n",
      "evaluation/EB/Q_True Std              100.72\n",
      "evaluation/EB/Q_Pred Mean            1006.78\n",
      "evaluation/EB/Q_Pred Std              215.418\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3513.76\n",
      "evaluation/Actions Mean                 0.0392178\n",
      "evaluation/Actions Std                  0.589914\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74491\n",
      "time/backward_zf1 (s)                   1.86368\n",
      "time/backward_zf2 (s)                   1.78992\n",
      "time/data sampling (s)                  0.257211\n",
      "time/data storing (s)                   0.0135873\n",
      "time/evaluation sampling (s)            1.42287\n",
      "time/exploration sampling (s)           0.170096\n",
      "time/logging (s)                        0.0118089\n",
      "time/preback_alpha (s)                  0.553766\n",
      "time/preback_policy (s)                 0.616497\n",
      "time/preback_start (s)                  0.12566\n",
      "time/preback_zf (s)                     4.96877\n",
      "time/saving (s)                         0.00549154\n",
      "time/training (s)                       2.55043\n",
      "time/epoch (s)                         16.0947\n",
      "time/total (s)                       4091.07\n",
      "Epoch                                 261\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:09:44.834241 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 262 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 273000\n",
      "trainer/ZF1 Loss                       75.1922\n",
      "trainer/ZF2 Loss                       85.9272\n",
      "trainer/ZF Expert Reward               15.204\n",
      "trainer/ZF Policy Reward                3.00768\n",
      "trainer/ZF CHI2 Term                  106.585\n",
      "trainer/Policy Loss                  -834.333\n",
      "trainer/Policy Grad Norm             1241.12\n",
      "trainer/Policy Param Norm              46.7921\n",
      "trainer/Zf1 Grad Norm              112594\n",
      "trainer/Zf1 Param Norm                130.931\n",
      "trainer/Zf2 Grad Norm               59898.3\n",
      "trainer/Zf2 Param Norm                126.241\n",
      "trainer/Z Expert Predictions Mean    1085.47\n",
      "trainer/Z Expert Predictions Std      249.233\n",
      "trainer/Z Expert Predictions Max     1627.81\n",
      "trainer/Z Expert Predictions Min      -57.5732\n",
      "trainer/Z Policy Predictions Mean     830.759\n",
      "trainer/Z Policy Predictions Std      356.162\n",
      "trainer/Z Policy Predictions Max     1634.13\n",
      "trainer/Z Policy Predictions Min     -401.63\n",
      "trainer/Z Expert Targets Mean        1070.26\n",
      "trainer/Z Expert Targets Std          252.815\n",
      "trainer/Z Expert Targets Max         1620.15\n",
      "trainer/Z Expert Targets Min         -114.588\n",
      "trainer/Z Policy Targets Mean         827.751\n",
      "trainer/Z Policy Targets Std          348.769\n",
      "trainer/Z Policy Targets Max         1613.17\n",
      "trainer/Z Policy Targets Min         -370.339\n",
      "trainer/Log Pis Mean                   13.9688\n",
      "trainer/Log Pis Std                     4.54155\n",
      "trainer/Policy mu Mean                  0.469346\n",
      "trainer/Policy mu Std                   2.84166\n",
      "trainer/Policy log std Mean            -4.41349\n",
      "trainer/Policy log std Std              1.22028\n",
      "exploration/num steps total        268518\n",
      "exploration/num paths total          1141\n",
      "evaluation/num steps total              1.84591e+06\n",
      "evaluation/num paths total           2678\n",
      "evaluation/path length Mean           332.6\n",
      "evaluation/path length Std              3.03974\n",
      "evaluation/path length Max            337\n",
      "evaluation/path length Min            327\n",
      "evaluation/Rewards Mean                 3.31695\n",
      "evaluation/Rewards Std                  0.823379\n",
      "evaluation/Rewards Max                  4.66931\n",
      "evaluation/Rewards Min                  0.861391\n",
      "evaluation/Returns Mean              1103.22\n",
      "evaluation/Returns Std                  8.50496\n",
      "evaluation/Returns Max               1115.28\n",
      "evaluation/Returns Min               1089\n",
      "evaluation/Estimation Bias Mean       733.237\n",
      "evaluation/Estimation Bias Std        398.92\n",
      "evaluation/EB/Q_True Mean              25.4735\n",
      "evaluation/EB/Q_True Std               80.9979\n",
      "evaluation/EB/Q_Pred Mean             758.711\n",
      "evaluation/EB/Q_Pred Std              392.51\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1103.22\n",
      "evaluation/Actions Mean                 0.0309501\n",
      "evaluation/Actions Std                  0.606058\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77962\n",
      "time/backward_zf1 (s)                   1.87617\n",
      "time/backward_zf2 (s)                   1.81318\n",
      "time/data sampling (s)                  0.241376\n",
      "time/data storing (s)                   0.0138764\n",
      "time/evaluation sampling (s)            0.963465\n",
      "time/exploration sampling (s)           0.169453\n",
      "time/logging (s)                        0.00502032\n",
      "time/preback_alpha (s)                  0.552298\n",
      "time/preback_policy (s)                 0.615201\n",
      "time/preback_start (s)                  0.125962\n",
      "time/preback_zf (s)                     4.96488\n",
      "time/saving (s)                         0.00525124\n",
      "time/training (s)                       2.53681\n",
      "time/epoch (s)                         15.6626\n",
      "time/total (s)                       4106.75\n",
      "Epoch                                 262\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:10:01.099216 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 263 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 274000\n",
      "trainer/ZF1 Loss                      107.847\n",
      "trainer/ZF2 Loss                      130.782\n",
      "trainer/ZF Expert Reward               20.678\n",
      "trainer/ZF Policy Reward               10.5846\n",
      "trainer/ZF CHI2 Term                  143.831\n",
      "trainer/Policy Loss                  -810.687\n",
      "trainer/Policy Grad Norm              771.553\n",
      "trainer/Policy Param Norm              46.8518\n",
      "trainer/Zf1 Grad Norm               43188.1\n",
      "trainer/Zf1 Param Norm                131.117\n",
      "trainer/Zf2 Grad Norm               32625.8\n",
      "trainer/Zf2 Param Norm                126.444\n",
      "trainer/Z Expert Predictions Mean    1070.07\n",
      "trainer/Z Expert Predictions Std      235.935\n",
      "trainer/Z Expert Predictions Max     1655.49\n",
      "trainer/Z Expert Predictions Min      230.491\n",
      "trainer/Z Policy Predictions Mean     805.122\n",
      "trainer/Z Policy Predictions Std      392.396\n",
      "trainer/Z Policy Predictions Max     1584.27\n",
      "trainer/Z Policy Predictions Min     -370.997\n",
      "trainer/Z Expert Targets Mean        1049.39\n",
      "trainer/Z Expert Targets Std          232.106\n",
      "trainer/Z Expert Targets Max         1599.49\n",
      "trainer/Z Expert Targets Min          376.29\n",
      "trainer/Z Policy Targets Mean         794.538\n",
      "trainer/Z Policy Targets Std          383.314\n",
      "trainer/Z Policy Targets Max         1580.87\n",
      "trainer/Z Policy Targets Min         -346.231\n",
      "trainer/Log Pis Mean                   14.5696\n",
      "trainer/Log Pis Std                     5.55951\n",
      "trainer/Policy mu Mean                  0.366286\n",
      "trainer/Policy mu Std                   3.12609\n",
      "trainer/Policy log std Mean            -4.30089\n",
      "trainer/Policy log std Std              1.28858\n",
      "exploration/num steps total        268518\n",
      "exploration/num paths total          1141\n",
      "evaluation/num steps total              1.85492e+06\n",
      "evaluation/num paths total           2689\n",
      "evaluation/path length Mean           818.273\n",
      "evaluation/path length Std            296.763\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            330\n",
      "evaluation/Rewards Mean                 3.52066\n",
      "evaluation/Rewards Std                  0.629307\n",
      "evaluation/Rewards Max                  4.66739\n",
      "evaluation/Rewards Min                  0.807509\n",
      "evaluation/Returns Mean              2880.86\n",
      "evaluation/Returns Std               1085.58\n",
      "evaluation/Returns Max               3576.7\n",
      "evaluation/Returns Min               1098.79\n",
      "evaluation/Estimation Bias Mean      1019.84\n",
      "evaluation/Estimation Bias Std        288.192\n",
      "evaluation/EB/Q_True Mean              36.5206\n",
      "evaluation/EB/Q_True Std              106.442\n",
      "evaluation/EB/Q_Pred Mean            1056.36\n",
      "evaluation/EB/Q_Pred Std              258.779\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2880.86\n",
      "evaluation/Actions Mean                 0.0453821\n",
      "evaluation/Actions Std                  0.594689\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83395\n",
      "time/backward_zf1 (s)                   1.93335\n",
      "time/backward_zf2 (s)                   1.878\n",
      "time/data sampling (s)                  0.21935\n",
      "time/data storing (s)                   0.0134143\n",
      "time/evaluation sampling (s)            1.38323\n",
      "time/exploration sampling (s)           0.165956\n",
      "time/logging (s)                        0.0108391\n",
      "time/preback_alpha (s)                  0.557052\n",
      "time/preback_policy (s)                 0.634752\n",
      "time/preback_start (s)                  0.125384\n",
      "time/preback_zf (s)                     4.98962\n",
      "time/saving (s)                         0.0048652\n",
      "time/training (s)                       2.45568\n",
      "time/epoch (s)                         16.2054\n",
      "time/total (s)                       4122.98\n",
      "Epoch                                 263\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:10:16.803785 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 264 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 275000\n",
      "trainer/ZF1 Loss                      208.722\n",
      "trainer/ZF2 Loss                       94.3705\n",
      "trainer/ZF Expert Reward               24.0758\n",
      "trainer/ZF Policy Reward               13.1554\n",
      "trainer/ZF CHI2 Term                  177.082\n",
      "trainer/Policy Loss                  -764.275\n",
      "trainer/Policy Grad Norm              417.849\n",
      "trainer/Policy Param Norm              46.9166\n",
      "trainer/Zf1 Grad Norm              248546\n",
      "trainer/Zf1 Param Norm                131.31\n",
      "trainer/Zf2 Grad Norm               65012.8\n",
      "trainer/Zf2 Param Norm                126.654\n",
      "trainer/Z Expert Predictions Mean    1087.3\n",
      "trainer/Z Expert Predictions Std      255.377\n",
      "trainer/Z Expert Predictions Max     1645.32\n",
      "trainer/Z Expert Predictions Min      128.169\n",
      "trainer/Z Policy Predictions Mean     766.983\n",
      "trainer/Z Policy Predictions Std      380.281\n",
      "trainer/Z Policy Predictions Max     1524.01\n",
      "trainer/Z Policy Predictions Min     -390.688\n",
      "trainer/Z Expert Targets Mean        1063.23\n",
      "trainer/Z Expert Targets Std          254.849\n",
      "trainer/Z Expert Targets Max         1596.87\n",
      "trainer/Z Expert Targets Min           95.61\n",
      "trainer/Z Policy Targets Mean         753.827\n",
      "trainer/Z Policy Targets Std          376.487\n",
      "trainer/Z Policy Targets Max         1393.85\n",
      "trainer/Z Policy Targets Min         -400.679\n",
      "trainer/Log Pis Mean                   14.7636\n",
      "trainer/Log Pis Std                     5.27843\n",
      "trainer/Policy mu Mean                  0.308895\n",
      "trainer/Policy mu Std                   2.74208\n",
      "trainer/Policy log std Mean            -4.35276\n",
      "trainer/Policy log std Std              1.20396\n",
      "exploration/num steps total        268849\n",
      "exploration/num paths total          1142\n",
      "evaluation/num steps total              1.85826e+06\n",
      "evaluation/num paths total           2699\n",
      "evaluation/path length Mean           334.4\n",
      "evaluation/path length Std              2.87054\n",
      "evaluation/path length Max            338\n",
      "evaluation/path length Min            329\n",
      "evaluation/Rewards Mean                 3.32016\n",
      "evaluation/Rewards Std                  0.824395\n",
      "evaluation/Rewards Max                  4.60494\n",
      "evaluation/Rewards Min                  0.822098\n",
      "evaluation/Returns Mean              1110.26\n",
      "evaluation/Returns Std                  8.54596\n",
      "evaluation/Returns Max               1121.16\n",
      "evaluation/Returns Min               1095\n",
      "evaluation/Estimation Bias Mean       895.003\n",
      "evaluation/Estimation Bias Std        357.426\n",
      "evaluation/EB/Q_True Mean              25.3432\n",
      "evaluation/EB/Q_True Std               80.8666\n",
      "evaluation/EB/Q_Pred Mean             920.346\n",
      "evaluation/EB/Q_Pred Std              346.093\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1110.26\n",
      "evaluation/Actions Mean                 0.047033\n",
      "evaluation/Actions Std                  0.605016\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77751\n",
      "time/backward_zf1 (s)                   1.87533\n",
      "time/backward_zf2 (s)                   1.82846\n",
      "time/data sampling (s)                  0.263413\n",
      "time/data storing (s)                   0.0139529\n",
      "time/evaluation sampling (s)            0.927794\n",
      "time/exploration sampling (s)           0.169071\n",
      "time/logging (s)                        0.0046325\n",
      "time/preback_alpha (s)                  0.557047\n",
      "time/preback_policy (s)                 0.628311\n",
      "time/preback_start (s)                  0.124566\n",
      "time/preback_zf (s)                     4.97458\n",
      "time/saving (s)                         0.00482928\n",
      "time/training (s)                       2.48571\n",
      "time/epoch (s)                         15.6352\n",
      "time/total (s)                       4138.63\n",
      "Epoch                                 264\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:10:32.410791 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 265 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 276000\n",
      "trainer/ZF1 Loss                      102.825\n",
      "trainer/ZF2 Loss                      108.435\n",
      "trainer/ZF Expert Reward               13.306\n",
      "trainer/ZF Policy Reward               -1.18032\n",
      "trainer/ZF CHI2 Term                  134.396\n",
      "trainer/Policy Loss                  -777.49\n",
      "trainer/Policy Grad Norm              774.104\n",
      "trainer/Policy Param Norm              46.9836\n",
      "trainer/Zf1 Grad Norm              145859\n",
      "trainer/Zf1 Param Norm                131.493\n",
      "trainer/Zf2 Grad Norm              153526\n",
      "trainer/Zf2 Param Norm                126.84\n",
      "trainer/Z Expert Predictions Mean    1060.99\n",
      "trainer/Z Expert Predictions Std      241.667\n",
      "trainer/Z Expert Predictions Max     1657.95\n",
      "trainer/Z Expert Predictions Min      224.748\n",
      "trainer/Z Policy Predictions Mean     761.766\n",
      "trainer/Z Policy Predictions Std      395.997\n",
      "trainer/Z Policy Predictions Max     1584.68\n",
      "trainer/Z Policy Predictions Min     -424.357\n",
      "trainer/Z Expert Targets Mean        1047.69\n",
      "trainer/Z Expert Targets Std          244.066\n",
      "trainer/Z Expert Targets Max         1647.25\n",
      "trainer/Z Expert Targets Min          173.17\n",
      "trainer/Z Policy Targets Mean         762.946\n",
      "trainer/Z Policy Targets Std          388.168\n",
      "trainer/Z Policy Targets Max         1546.04\n",
      "trainer/Z Policy Targets Min         -411.332\n",
      "trainer/Log Pis Mean                   14.4237\n",
      "trainer/Log Pis Std                     5.80747\n",
      "trainer/Policy mu Mean                  0.471821\n",
      "trainer/Policy mu Std                   3.47146\n",
      "trainer/Policy log std Mean            -4.17395\n",
      "trainer/Policy log std Std              1.34312\n",
      "exploration/num steps total        270849\n",
      "exploration/num paths total          1144\n",
      "evaluation/num steps total              1.86115e+06\n",
      "evaluation/num paths total           2709\n",
      "evaluation/path length Mean           288.8\n",
      "evaluation/path length Std             34.0846\n",
      "evaluation/path length Max            331\n",
      "evaluation/path length Min            259\n",
      "evaluation/Rewards Mean                 3.24287\n",
      "evaluation/Rewards Std                  0.848361\n",
      "evaluation/Rewards Max                  4.60531\n",
      "evaluation/Rewards Min                  0.823579\n",
      "evaluation/Returns Mean               936.539\n",
      "evaluation/Returns Std                131.685\n",
      "evaluation/Returns Max               1099.69\n",
      "evaluation/Returns Min                820.76\n",
      "evaluation/Estimation Bias Mean       764.863\n",
      "evaluation/Estimation Bias Std        351.937\n",
      "evaluation/EB/Q_True Mean              23.1795\n",
      "evaluation/EB/Q_True Std               70.9606\n",
      "evaluation/EB/Q_Pred Mean             788.042\n",
      "evaluation/EB/Q_Pred Std              350.806\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            936.539\n",
      "evaluation/Actions Mean                 0.0322273\n",
      "evaluation/Actions Std                  0.601952\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79821\n",
      "time/backward_zf1 (s)                   1.89752\n",
      "time/backward_zf2 (s)                   1.82686\n",
      "time/data sampling (s)                  0.239446\n",
      "time/data storing (s)                   0.0136188\n",
      "time/evaluation sampling (s)            0.844325\n",
      "time/exploration sampling (s)           0.171724\n",
      "time/logging (s)                        0.00470792\n",
      "time/preback_alpha (s)                  0.552552\n",
      "time/preback_policy (s)                 0.621726\n",
      "time/preback_start (s)                  0.124595\n",
      "time/preback_zf (s)                     4.98287\n",
      "time/saving (s)                         0.00491792\n",
      "time/training (s)                       2.45975\n",
      "time/epoch (s)                         15.5428\n",
      "time/total (s)                       4154.19\n",
      "Epoch                                 265\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:10:48.386468 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 266 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 277000\n",
      "trainer/ZF1 Loss                      142.9\n",
      "trainer/ZF2 Loss                      123.303\n",
      "trainer/ZF Expert Reward               12.466\n",
      "trainer/ZF Policy Reward                5.56731\n",
      "trainer/ZF CHI2 Term                  154.603\n",
      "trainer/Policy Loss                  -813.055\n",
      "trainer/Policy Grad Norm              801.234\n",
      "trainer/Policy Param Norm              47.0471\n",
      "trainer/Zf1 Grad Norm               89069.9\n",
      "trainer/Zf1 Param Norm                131.663\n",
      "trainer/Zf2 Grad Norm               70396.7\n",
      "trainer/Zf2 Param Norm                127.019\n",
      "trainer/Z Expert Predictions Mean    1040.69\n",
      "trainer/Z Expert Predictions Std      256.291\n",
      "trainer/Z Expert Predictions Max     1617.29\n",
      "trainer/Z Expert Predictions Min      200.843\n",
      "trainer/Z Policy Predictions Mean     809.313\n",
      "trainer/Z Policy Predictions Std      399.643\n",
      "trainer/Z Policy Predictions Max     1556.68\n",
      "trainer/Z Policy Predictions Min     -393.019\n",
      "trainer/Z Expert Targets Mean        1028.23\n",
      "trainer/Z Expert Targets Std          258.988\n",
      "trainer/Z Expert Targets Max         1647.02\n",
      "trainer/Z Expert Targets Min          137.953\n",
      "trainer/Z Policy Targets Mean         803.745\n",
      "trainer/Z Policy Targets Std          395.809\n",
      "trainer/Z Policy Targets Max         1542.14\n",
      "trainer/Z Policy Targets Min         -418.875\n",
      "trainer/Log Pis Mean                   14.7506\n",
      "trainer/Log Pis Std                     5.26404\n",
      "trainer/Policy mu Mean                  0.330281\n",
      "trainer/Policy mu Std                   2.96985\n",
      "trainer/Policy log std Mean            -4.2965\n",
      "trainer/Policy log std Std              1.238\n",
      "exploration/num steps total        271849\n",
      "exploration/num paths total          1145\n",
      "evaluation/num steps total              1.87115e+06\n",
      "evaluation/num paths total           2719\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50052\n",
      "evaluation/Rewards Std                  0.596708\n",
      "evaluation/Rewards Max                  4.71427\n",
      "evaluation/Rewards Min                  0.800386\n",
      "evaluation/Returns Mean              3500.52\n",
      "evaluation/Returns Std                 23.1894\n",
      "evaluation/Returns Max               3534.28\n",
      "evaluation/Returns Min               3463.25\n",
      "evaluation/Estimation Bias Mean       947.91\n",
      "evaluation/Estimation Bias Std        252.548\n",
      "evaluation/EB/Q_True Mean              32.5723\n",
      "evaluation/EB/Q_True Std              100.516\n",
      "evaluation/EB/Q_Pred Mean             980.482\n",
      "evaluation/EB/Q_Pred Std              237.939\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3500.52\n",
      "evaluation/Actions Mean                 0.043179\n",
      "evaluation/Actions Std                  0.589319\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.6797\n",
      "time/backward_zf1 (s)                   1.8019\n",
      "time/backward_zf2 (s)                   1.71435\n",
      "time/data sampling (s)                  0.235595\n",
      "time/data storing (s)                   0.0134762\n",
      "time/evaluation sampling (s)            1.37041\n",
      "time/exploration sampling (s)           0.167571\n",
      "time/logging (s)                        0.0121906\n",
      "time/preback_alpha (s)                  0.549078\n",
      "time/preback_policy (s)                 0.593977\n",
      "time/preback_start (s)                  0.125619\n",
      "time/preback_zf (s)                     4.95401\n",
      "time/saving (s)                         0.00491816\n",
      "time/training (s)                       2.6979\n",
      "time/epoch (s)                         15.9207\n",
      "time/total (s)                       4170.13\n",
      "Epoch                                 266\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:11:04.648398 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 267 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 278000\n",
      "trainer/ZF1 Loss                      147.176\n",
      "trainer/ZF2 Loss                      111.7\n",
      "trainer/ZF Expert Reward               -3.02426\n",
      "trainer/ZF Policy Reward               -8.23081\n",
      "trainer/ZF CHI2 Term                  149.527\n",
      "trainer/Policy Loss                  -766.126\n",
      "trainer/Policy Grad Norm              844.644\n",
      "trainer/Policy Param Norm              47.0999\n",
      "trainer/Zf1 Grad Norm              126114\n",
      "trainer/Zf1 Param Norm                131.826\n",
      "trainer/Zf2 Grad Norm               42893.4\n",
      "trainer/Zf2 Param Norm                127.189\n",
      "trainer/Z Expert Predictions Mean    1060.6\n",
      "trainer/Z Expert Predictions Std      235.325\n",
      "trainer/Z Expert Predictions Max     1640.17\n",
      "trainer/Z Expert Predictions Min      475.327\n",
      "trainer/Z Policy Predictions Mean     754.563\n",
      "trainer/Z Policy Predictions Std      431.186\n",
      "trainer/Z Policy Predictions Max     1508.95\n",
      "trainer/Z Policy Predictions Min     -404.283\n",
      "trainer/Z Expert Targets Mean        1063.62\n",
      "trainer/Z Expert Targets Std          233.632\n",
      "trainer/Z Expert Targets Max         1630.91\n",
      "trainer/Z Expert Targets Min          591.215\n",
      "trainer/Z Policy Targets Mean         762.794\n",
      "trainer/Z Policy Targets Std          425.844\n",
      "trainer/Z Policy Targets Max         1527.6\n",
      "trainer/Z Policy Targets Min         -361.888\n",
      "trainer/Log Pis Mean                   15.0325\n",
      "trainer/Log Pis Std                     6.32743\n",
      "trainer/Policy mu Mean                  0.388408\n",
      "trainer/Policy mu Std                   3.21658\n",
      "trainer/Policy log std Mean            -4.18751\n",
      "trainer/Policy log std Std              1.26915\n",
      "exploration/num steps total        273849\n",
      "exploration/num paths total          1147\n",
      "evaluation/num steps total              1.88115e+06\n",
      "evaluation/num paths total           2729\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.47762\n",
      "evaluation/Rewards Std                  0.588774\n",
      "evaluation/Rewards Max                  4.68414\n",
      "evaluation/Rewards Min                  0.814657\n",
      "evaluation/Returns Mean              3477.62\n",
      "evaluation/Returns Std                 28.7335\n",
      "evaluation/Returns Max               3521.83\n",
      "evaluation/Returns Min               3435.53\n",
      "evaluation/Estimation Bias Mean       932.36\n",
      "evaluation/Estimation Bias Std        264.262\n",
      "evaluation/EB/Q_True Mean              32.0801\n",
      "evaluation/EB/Q_True Std               98.8654\n",
      "evaluation/EB/Q_Pred Mean             964.44\n",
      "evaluation/EB/Q_Pred Std              252.314\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3477.62\n",
      "evaluation/Actions Mean                 0.0356383\n",
      "evaluation/Actions Std                  0.583236\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.87569\n",
      "time/backward_zf1 (s)                   1.97234\n",
      "time/backward_zf2 (s)                   1.91711\n",
      "time/data sampling (s)                  0.256952\n",
      "time/data storing (s)                   0.0147347\n",
      "time/evaluation sampling (s)            1.4152\n",
      "time/exploration sampling (s)           0.174839\n",
      "time/logging (s)                        0.0116722\n",
      "time/preback_alpha (s)                  0.55102\n",
      "time/preback_policy (s)                 0.634023\n",
      "time/preback_start (s)                  0.125309\n",
      "time/preback_zf (s)                     4.94705\n",
      "time/saving (s)                         0.00505414\n",
      "time/training (s)                       2.2953\n",
      "time/epoch (s)                         16.1963\n",
      "time/total (s)                       4186.34\n",
      "Epoch                                 267\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:11:20.661724 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 268 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 279000\n",
      "trainer/ZF1 Loss                       95.0774\n",
      "trainer/ZF2 Loss                      122.021\n",
      "trainer/ZF Expert Reward               19.9586\n",
      "trainer/ZF Policy Reward                7.64037\n",
      "trainer/ZF CHI2 Term                  135.292\n",
      "trainer/Policy Loss                  -780.542\n",
      "trainer/Policy Grad Norm              852.462\n",
      "trainer/Policy Param Norm              47.1501\n",
      "trainer/Zf1 Grad Norm               24362.6\n",
      "trainer/Zf1 Param Norm                132.005\n",
      "trainer/Zf2 Grad Norm               50381.6\n",
      "trainer/Zf2 Param Norm                127.37\n",
      "trainer/Z Expert Predictions Mean    1066.71\n",
      "trainer/Z Expert Predictions Std      246.79\n",
      "trainer/Z Expert Predictions Max     1668.39\n",
      "trainer/Z Expert Predictions Min      163.396\n",
      "trainer/Z Policy Predictions Mean     780.332\n",
      "trainer/Z Policy Predictions Std      372.925\n",
      "trainer/Z Policy Predictions Max     1581.82\n",
      "trainer/Z Policy Predictions Min     -492.913\n",
      "trainer/Z Expert Targets Mean        1046.75\n",
      "trainer/Z Expert Targets Std          246.518\n",
      "trainer/Z Expert Targets Max         1644.25\n",
      "trainer/Z Expert Targets Min          123.861\n",
      "trainer/Z Policy Targets Mean         772.692\n",
      "trainer/Z Policy Targets Std          371.34\n",
      "trainer/Z Policy Targets Max         1548.51\n",
      "trainer/Z Policy Targets Min         -530.604\n",
      "trainer/Log Pis Mean                   14.5698\n",
      "trainer/Log Pis Std                     5.19222\n",
      "trainer/Policy mu Mean                  0.308357\n",
      "trainer/Policy mu Std                   2.81074\n",
      "trainer/Policy log std Mean            -4.21142\n",
      "trainer/Policy log std Std              1.23329\n",
      "exploration/num steps total        274849\n",
      "exploration/num paths total          1148\n",
      "evaluation/num steps total              1.88916e+06\n",
      "evaluation/num paths total           2741\n",
      "evaluation/path length Mean           667.917\n",
      "evaluation/path length Std            332.084\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 3.4725\n",
      "evaluation/Rewards Std                  0.662597\n",
      "evaluation/Rewards Max                  4.62322\n",
      "evaluation/Rewards Min                  0.802342\n",
      "evaluation/Returns Mean              2319.34\n",
      "evaluation/Returns Std               1204.97\n",
      "evaluation/Returns Max               3559.08\n",
      "evaluation/Returns Min               1108.82\n",
      "evaluation/Estimation Bias Mean       938.698\n",
      "evaluation/Estimation Bias Std        300.894\n",
      "evaluation/EB/Q_True Mean              40.3098\n",
      "evaluation/EB/Q_True Std              109.911\n",
      "evaluation/EB/Q_Pred Mean             979.008\n",
      "evaluation/EB/Q_Pred Std              273.006\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2319.34\n",
      "evaluation/Actions Mean                 0.0453981\n",
      "evaluation/Actions Std                  0.590903\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80586\n",
      "time/backward_zf1 (s)                   1.89801\n",
      "time/backward_zf2 (s)                   1.8485\n",
      "time/data sampling (s)                  0.260366\n",
      "time/data storing (s)                   0.0139623\n",
      "time/evaluation sampling (s)            1.36579\n",
      "time/exploration sampling (s)           0.172612\n",
      "time/logging (s)                        0.00961194\n",
      "time/preback_alpha (s)                  0.547277\n",
      "time/preback_policy (s)                 0.617757\n",
      "time/preback_start (s)                  0.123369\n",
      "time/preback_zf (s)                     4.94276\n",
      "time/saving (s)                         0.00511672\n",
      "time/training (s)                       2.3343\n",
      "time/epoch (s)                         15.9453\n",
      "time/total (s)                       4202.31\n",
      "Epoch                                 268\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:11:36.856920 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 269 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 280000\n",
      "trainer/ZF1 Loss                       67.3746\n",
      "trainer/ZF2 Loss                       79.9138\n",
      "trainer/ZF Expert Reward                8.29809\n",
      "trainer/ZF Policy Reward               -5.50835\n",
      "trainer/ZF CHI2 Term                  101.384\n",
      "trainer/Policy Loss                  -818.248\n",
      "trainer/Policy Grad Norm              775.314\n",
      "trainer/Policy Param Norm              47.2106\n",
      "trainer/Zf1 Grad Norm               68007.8\n",
      "trainer/Zf1 Param Norm                132.172\n",
      "trainer/Zf2 Grad Norm              109415\n",
      "trainer/Zf2 Param Norm                127.547\n",
      "trainer/Z Expert Predictions Mean    1060.47\n",
      "trainer/Z Expert Predictions Std      209.38\n",
      "trainer/Z Expert Predictions Max     1628.9\n",
      "trainer/Z Expert Predictions Min      540.153\n",
      "trainer/Z Policy Predictions Mean     809.175\n",
      "trainer/Z Policy Predictions Std      386.903\n",
      "trainer/Z Policy Predictions Max     1554.37\n",
      "trainer/Z Policy Predictions Min     -397.26\n",
      "trainer/Z Expert Targets Mean        1052.17\n",
      "trainer/Z Expert Targets Std          212.175\n",
      "trainer/Z Expert Targets Max         1641.49\n",
      "trainer/Z Expert Targets Min          540.654\n",
      "trainer/Z Policy Targets Mean         814.683\n",
      "trainer/Z Policy Targets Std          387.527\n",
      "trainer/Z Policy Targets Max         1590.28\n",
      "trainer/Z Policy Targets Min         -383.121\n",
      "trainer/Log Pis Mean                   14.0737\n",
      "trainer/Log Pis Std                     5.24193\n",
      "trainer/Policy mu Mean                  0.241844\n",
      "trainer/Policy mu Std                   2.89433\n",
      "trainer/Policy log std Mean            -4.28794\n",
      "trainer/Policy log std Std              1.12105\n",
      "exploration/num steps total        275849\n",
      "exploration/num paths total          1149\n",
      "evaluation/num steps total              1.89599e+06\n",
      "evaluation/num paths total           2752\n",
      "evaluation/path length Mean           620.727\n",
      "evaluation/path length Std            316.276\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            332\n",
      "evaluation/Rewards Mean                 3.46636\n",
      "evaluation/Rewards Std                  0.675549\n",
      "evaluation/Rewards Max                  4.62781\n",
      "evaluation/Rewards Min                  0.800307\n",
      "evaluation/Returns Mean              2151.66\n",
      "evaluation/Returns Std               1152.54\n",
      "evaluation/Returns Max               3557.99\n",
      "evaluation/Returns Min               1101.85\n",
      "evaluation/Estimation Bias Mean       934.289\n",
      "evaluation/Estimation Bias Std        333.012\n",
      "evaluation/EB/Q_True Mean              47.7692\n",
      "evaluation/EB/Q_True Std              118.976\n",
      "evaluation/EB/Q_Pred Mean             982.059\n",
      "evaluation/EB/Q_Pred Std              302.603\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2151.66\n",
      "evaluation/Actions Mean                 0.0406829\n",
      "evaluation/Actions Std                  0.583669\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72724\n",
      "time/backward_zf1 (s)                   1.85941\n",
      "time/backward_zf2 (s)                   1.7715\n",
      "time/data sampling (s)                  0.262012\n",
      "time/data storing (s)                   0.013687\n",
      "time/evaluation sampling (s)            1.41602\n",
      "time/exploration sampling (s)           0.16807\n",
      "time/logging (s)                        0.00850195\n",
      "time/preback_alpha (s)                  0.560748\n",
      "time/preback_policy (s)                 0.623898\n",
      "time/preback_start (s)                  0.126676\n",
      "time/preback_zf (s)                     4.98631\n",
      "time/saving (s)                         0.0054504\n",
      "time/training (s)                       2.6\n",
      "time/epoch (s)                         16.1295\n",
      "time/total (s)                       4218.46\n",
      "Epoch                                 269\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:11:53.128891 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 270 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 281000\n",
      "trainer/ZF1 Loss                       92.502\n",
      "trainer/ZF2 Loss                       72.1477\n",
      "trainer/ZF Expert Reward               19.4526\n",
      "trainer/ZF Policy Reward                5.20858\n",
      "trainer/ZF CHI2 Term                  110.58\n",
      "trainer/Policy Loss                  -836.978\n",
      "trainer/Policy Grad Norm              971.599\n",
      "trainer/Policy Param Norm              47.2729\n",
      "trainer/Zf1 Grad Norm              106346\n",
      "trainer/Zf1 Param Norm                132.331\n",
      "trainer/Zf2 Grad Norm               84514.3\n",
      "trainer/Zf2 Param Norm                127.723\n",
      "trainer/Z Expert Predictions Mean    1094.18\n",
      "trainer/Z Expert Predictions Std      251.328\n",
      "trainer/Z Expert Predictions Max     1680.46\n",
      "trainer/Z Expert Predictions Min      132.284\n",
      "trainer/Z Policy Predictions Mean     836.659\n",
      "trainer/Z Policy Predictions Std      367.914\n",
      "trainer/Z Policy Predictions Max     1634.44\n",
      "trainer/Z Policy Predictions Min     -441.27\n",
      "trainer/Z Expert Targets Mean        1074.72\n",
      "trainer/Z Expert Targets Std          250.43\n",
      "trainer/Z Expert Targets Max         1626.7\n",
      "trainer/Z Expert Targets Min          102.336\n",
      "trainer/Z Policy Targets Mean         831.451\n",
      "trainer/Z Policy Targets Std          361.933\n",
      "trainer/Z Policy Targets Max         1593.96\n",
      "trainer/Z Policy Targets Min         -417.524\n",
      "trainer/Log Pis Mean                   14.153\n",
      "trainer/Log Pis Std                     5.43922\n",
      "trainer/Policy mu Mean                  0.29547\n",
      "trainer/Policy mu Std                   2.35017\n",
      "trainer/Policy log std Mean            -4.3799\n",
      "trainer/Policy log std Std              1.09192\n",
      "exploration/num steps total        277134\n",
      "exploration/num paths total          1151\n",
      "evaluation/num steps total              1.90532e+06\n",
      "evaluation/num paths total           2762\n",
      "evaluation/path length Mean           933.5\n",
      "evaluation/path length Std            199.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 3.49006\n",
      "evaluation/Rewards Std                  0.594996\n",
      "evaluation/Rewards Max                  4.58875\n",
      "evaluation/Rewards Min                  0.785076\n",
      "evaluation/Returns Mean              3257.97\n",
      "evaluation/Returns Std                717.594\n",
      "evaluation/Returns Max               3534.31\n",
      "evaluation/Returns Min               1107.33\n",
      "evaluation/Estimation Bias Mean       955.512\n",
      "evaluation/Estimation Bias Std        269.174\n",
      "evaluation/EB/Q_True Mean              34.1049\n",
      "evaluation/EB/Q_True Std              101.662\n",
      "evaluation/EB/Q_Pred Mean             989.616\n",
      "evaluation/EB/Q_Pred Std              256.294\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3257.97\n",
      "evaluation/Actions Mean                 0.0454378\n",
      "evaluation/Actions Std                  0.579085\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80279\n",
      "time/backward_zf1 (s)                   1.93297\n",
      "time/backward_zf2 (s)                   1.86626\n",
      "time/data sampling (s)                  0.256343\n",
      "time/data storing (s)                   0.0135343\n",
      "time/evaluation sampling (s)            1.43853\n",
      "time/exploration sampling (s)           0.168545\n",
      "time/logging (s)                        0.0109834\n",
      "time/preback_alpha (s)                  0.560032\n",
      "time/preback_policy (s)                 0.638043\n",
      "time/preback_start (s)                  0.125825\n",
      "time/preback_zf (s)                     4.99018\n",
      "time/saving (s)                         0.00551098\n",
      "time/training (s)                       2.39799\n",
      "time/epoch (s)                         16.2075\n",
      "time/total (s)                       4234.69\n",
      "Epoch                                 270\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:12:08.715217 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 271 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 282000\n",
      "trainer/ZF1 Loss                       81.4435\n",
      "trainer/ZF2 Loss                       94.0595\n",
      "trainer/ZF Expert Reward                8.83102\n",
      "trainer/ZF Policy Reward               -6.51834\n",
      "trainer/ZF CHI2 Term                  117.015\n",
      "trainer/Policy Loss                  -763.148\n",
      "trainer/Policy Grad Norm              953.845\n",
      "trainer/Policy Param Norm              47.3401\n",
      "trainer/Zf1 Grad Norm              103310\n",
      "trainer/Zf1 Param Norm                132.475\n",
      "trainer/Zf2 Grad Norm               89643.9\n",
      "trainer/Zf2 Param Norm                127.885\n",
      "trainer/Z Expert Predictions Mean    1039.94\n",
      "trainer/Z Expert Predictions Std      246.027\n",
      "trainer/Z Expert Predictions Max     1681.49\n",
      "trainer/Z Expert Predictions Min      247.604\n",
      "trainer/Z Policy Predictions Mean     762.663\n",
      "trainer/Z Policy Predictions Std      397.04\n",
      "trainer/Z Policy Predictions Max     1474.03\n",
      "trainer/Z Policy Predictions Min     -385.59\n",
      "trainer/Z Expert Targets Mean        1031.11\n",
      "trainer/Z Expert Targets Std          246.176\n",
      "trainer/Z Expert Targets Max         1669.44\n",
      "trainer/Z Expert Targets Min          182.385\n",
      "trainer/Z Policy Targets Mean         769.182\n",
      "trainer/Z Policy Targets Std          387.107\n",
      "trainer/Z Policy Targets Max         1495.71\n",
      "trainer/Z Policy Targets Min         -321.582\n",
      "trainer/Log Pis Mean                   14.055\n",
      "trainer/Log Pis Std                     5.12717\n",
      "trainer/Policy mu Mean                  0.211582\n",
      "trainer/Policy mu Std                   2.54629\n",
      "trainer/Policy log std Mean            -4.44085\n",
      "trainer/Policy log std Std              1.08567\n",
      "exploration/num steps total        277134\n",
      "exploration/num paths total          1151\n",
      "evaluation/num steps total              1.90847e+06\n",
      "evaluation/num paths total           2773\n",
      "evaluation/path length Mean           285.636\n",
      "evaluation/path length Std             33.3828\n",
      "evaluation/path length Max            331\n",
      "evaluation/path length Min            257\n",
      "evaluation/Rewards Mean                 3.24594\n",
      "evaluation/Rewards Std                  0.849478\n",
      "evaluation/Rewards Max                  4.61652\n",
      "evaluation/Rewards Min                  0.744874\n",
      "evaluation/Returns Mean               927.159\n",
      "evaluation/Returns Std                128.218\n",
      "evaluation/Returns Max               1099.31\n",
      "evaluation/Returns Min                818.081\n",
      "evaluation/Estimation Bias Mean       765.085\n",
      "evaluation/Estimation Bias Std        305.503\n",
      "evaluation/EB/Q_True Mean              26.9156\n",
      "evaluation/EB/Q_True Std               83.1635\n",
      "evaluation/EB/Q_Pred Mean             792\n",
      "evaluation/EB/Q_Pred Std              300.611\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns            927.159\n",
      "evaluation/Actions Mean                 0.0269951\n",
      "evaluation/Actions Std                  0.597267\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72772\n",
      "time/backward_zf1 (s)                   1.85469\n",
      "time/backward_zf2 (s)                   1.788\n",
      "time/data sampling (s)                  0.270007\n",
      "time/data storing (s)                   0.0135204\n",
      "time/evaluation sampling (s)            0.841371\n",
      "time/exploration sampling (s)           0.166153\n",
      "time/logging (s)                        0.00447436\n",
      "time/preback_alpha (s)                  0.554339\n",
      "time/preback_policy (s)                 0.621611\n",
      "time/preback_start (s)                  0.124408\n",
      "time/preback_zf (s)                     4.95393\n",
      "time/saving (s)                         0.00477169\n",
      "time/training (s)                       2.58793\n",
      "time/epoch (s)                         15.5129\n",
      "time/total (s)                       4250.22\n",
      "Epoch                                 271\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:12:24.889467 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 272 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 283000\n",
      "trainer/ZF1 Loss                       97.3947\n",
      "trainer/ZF2 Loss                       80.607\n",
      "trainer/ZF Expert Reward                2.39346\n",
      "trainer/ZF Policy Reward               -5.98134\n",
      "trainer/ZF CHI2 Term                  111.426\n",
      "trainer/Policy Loss                  -808.341\n",
      "trainer/Policy Grad Norm              884.796\n",
      "trainer/Policy Param Norm              47.405\n",
      "trainer/Zf1 Grad Norm               20066.6\n",
      "trainer/Zf1 Param Norm                132.626\n",
      "trainer/Zf2 Grad Norm               16395.1\n",
      "trainer/Zf2 Param Norm                128.048\n",
      "trainer/Z Expert Predictions Mean    1070.03\n",
      "trainer/Z Expert Predictions Std      254.946\n",
      "trainer/Z Expert Predictions Max     1643.34\n",
      "trainer/Z Expert Predictions Min      -23.1864\n",
      "trainer/Z Policy Predictions Mean     805.468\n",
      "trainer/Z Policy Predictions Std      365.071\n",
      "trainer/Z Policy Predictions Max     1500.46\n",
      "trainer/Z Policy Predictions Min     -399.867\n",
      "trainer/Z Expert Targets Mean        1067.64\n",
      "trainer/Z Expert Targets Std          257.325\n",
      "trainer/Z Expert Targets Max         1666.52\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         811.449\n",
      "trainer/Z Policy Targets Std          365.579\n",
      "trainer/Z Policy Targets Max         1461.49\n",
      "trainer/Z Policy Targets Min         -414.884\n",
      "trainer/Log Pis Mean                   14.1921\n",
      "trainer/Log Pis Std                     4.79302\n",
      "trainer/Policy mu Mean                  0.345298\n",
      "trainer/Policy mu Std                   2.89593\n",
      "trainer/Policy log std Mean            -4.24014\n",
      "trainer/Policy log std Std              1.28325\n",
      "exploration/num steps total        278868\n",
      "exploration/num paths total          1153\n",
      "evaluation/num steps total              1.91778e+06\n",
      "evaluation/num paths total           2786\n",
      "evaluation/path length Mean           716.154\n",
      "evaluation/path length Std            326.455\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            286\n",
      "evaluation/Rewards Mean                 3.49713\n",
      "evaluation/Rewards Std                  0.649244\n",
      "evaluation/Rewards Max                  4.72031\n",
      "evaluation/Rewards Min                  0.740114\n",
      "evaluation/Returns Mean              2504.48\n",
      "evaluation/Returns Std               1197.22\n",
      "evaluation/Returns Max               3561.22\n",
      "evaluation/Returns Min                922.841\n",
      "evaluation/Estimation Bias Mean      1001.76\n",
      "evaluation/Estimation Bias Std        297.47\n",
      "evaluation/EB/Q_True Mean              35.2139\n",
      "evaluation/EB/Q_True Std              104.296\n",
      "evaluation/EB/Q_Pred Mean            1036.98\n",
      "evaluation/EB/Q_Pred Std              271.772\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2504.48\n",
      "evaluation/Actions Mean                 0.0405131\n",
      "evaluation/Actions Std                  0.581162\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7447\n",
      "time/backward_zf1 (s)                   1.85523\n",
      "time/backward_zf2 (s)                   1.78464\n",
      "time/data sampling (s)                  0.244479\n",
      "time/data storing (s)                   0.0135986\n",
      "time/evaluation sampling (s)            1.41761\n",
      "time/exploration sampling (s)           0.170134\n",
      "time/logging (s)                        0.0110177\n",
      "time/preback_alpha (s)                  0.554453\n",
      "time/preback_policy (s)                 0.618141\n",
      "time/preback_start (s)                  0.126231\n",
      "time/preback_zf (s)                     4.95223\n",
      "time/saving (s)                         0.00522198\n",
      "time/training (s)                       2.61531\n",
      "time/epoch (s)                         16.113\n",
      "time/total (s)                       4266.35\n",
      "Epoch                                 272\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:12:40.971557 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 273 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 284000\n",
      "trainer/ZF1 Loss                       98.491\n",
      "trainer/ZF2 Loss                       68.5505\n",
      "trainer/ZF Expert Reward                7.90739\n",
      "trainer/ZF Policy Reward               -0.841769\n",
      "trainer/ZF CHI2 Term                  106.279\n",
      "trainer/Policy Loss                  -793.384\n",
      "trainer/Policy Grad Norm              981.239\n",
      "trainer/Policy Param Norm              47.4778\n",
      "trainer/Zf1 Grad Norm               85863.4\n",
      "trainer/Zf1 Param Norm                132.778\n",
      "trainer/Zf2 Grad Norm               40072.6\n",
      "trainer/Zf2 Param Norm                128.213\n",
      "trainer/Z Expert Predictions Mean    1049.08\n",
      "trainer/Z Expert Predictions Std      260.814\n",
      "trainer/Z Expert Predictions Max     1665.11\n",
      "trainer/Z Expert Predictions Min       94.5515\n",
      "trainer/Z Policy Predictions Mean     793.017\n",
      "trainer/Z Policy Predictions Std      392.156\n",
      "trainer/Z Policy Predictions Max     1550.76\n",
      "trainer/Z Policy Predictions Min     -472.875\n",
      "trainer/Z Expert Targets Mean        1041.17\n",
      "trainer/Z Expert Targets Std          264.435\n",
      "trainer/Z Expert Targets Max         1651.23\n",
      "trainer/Z Expert Targets Min           36.0515\n",
      "trainer/Z Policy Targets Mean         793.859\n",
      "trainer/Z Policy Targets Std          393.41\n",
      "trainer/Z Policy Targets Max         1563.02\n",
      "trainer/Z Policy Targets Min         -479.389\n",
      "trainer/Log Pis Mean                   14.1504\n",
      "trainer/Log Pis Std                     4.96102\n",
      "trainer/Policy mu Mean                  0.29457\n",
      "trainer/Policy mu Std                   2.47442\n",
      "trainer/Policy log std Mean            -4.29774\n",
      "trainer/Policy log std Std              1.14904\n",
      "exploration/num steps total        278868\n",
      "exploration/num paths total          1153\n",
      "evaluation/num steps total              1.92778e+06\n",
      "evaluation/num paths total           2796\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.49866\n",
      "evaluation/Rewards Std                  0.595107\n",
      "evaluation/Rewards Max                  4.65912\n",
      "evaluation/Rewards Min                  0.716416\n",
      "evaluation/Returns Mean              3498.66\n",
      "evaluation/Returns Std                 23.9493\n",
      "evaluation/Returns Max               3531.14\n",
      "evaluation/Returns Min               3450.69\n",
      "evaluation/Estimation Bias Mean       960.694\n",
      "evaluation/Estimation Bias Std        228.258\n",
      "evaluation/EB/Q_True Mean              32.1437\n",
      "evaluation/EB/Q_True Std               99.1363\n",
      "evaluation/EB/Q_Pred Mean             992.838\n",
      "evaluation/EB/Q_Pred Std              208.663\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3498.66\n",
      "evaluation/Actions Mean                 0.0380387\n",
      "evaluation/Actions Std                  0.585312\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.74826\n",
      "time/backward_zf1 (s)                   1.87028\n",
      "time/backward_zf2 (s)                   1.79064\n",
      "time/data sampling (s)                  0.265718\n",
      "time/data storing (s)                   0.0136279\n",
      "time/evaluation sampling (s)            1.39819\n",
      "time/exploration sampling (s)           0.166567\n",
      "time/logging (s)                        0.0117238\n",
      "time/preback_alpha (s)                  0.555688\n",
      "time/preback_policy (s)                 0.618939\n",
      "time/preback_start (s)                  0.123948\n",
      "time/preback_zf (s)                     4.95492\n",
      "time/saving (s)                         0.00536382\n",
      "time/training (s)                       2.49159\n",
      "time/epoch (s)                         16.0154\n",
      "time/total (s)                       4282.39\n",
      "Epoch                                 273\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:12:57.114961 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 274 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 285000\n",
      "trainer/ZF1 Loss                      136.641\n",
      "trainer/ZF2 Loss                       82.3885\n",
      "trainer/ZF Expert Reward                9.18572\n",
      "trainer/ZF Policy Reward               -7.01816\n",
      "trainer/ZF CHI2 Term                  139.616\n",
      "trainer/Policy Loss                  -782.174\n",
      "trainer/Policy Grad Norm              887.19\n",
      "trainer/Policy Param Norm              47.5419\n",
      "trainer/Zf1 Grad Norm              158431\n",
      "trainer/Zf1 Param Norm                132.912\n",
      "trainer/Zf2 Grad Norm               65454.3\n",
      "trainer/Zf2 Param Norm                128.365\n",
      "trainer/Z Expert Predictions Mean    1055.18\n",
      "trainer/Z Expert Predictions Std      236.654\n",
      "trainer/Z Expert Predictions Max     1595.66\n",
      "trainer/Z Expert Predictions Min      106.775\n",
      "trainer/Z Policy Predictions Mean     772.62\n",
      "trainer/Z Policy Predictions Std      405.757\n",
      "trainer/Z Policy Predictions Max     1500.02\n",
      "trainer/Z Policy Predictions Min     -370.727\n",
      "trainer/Z Expert Targets Mean        1045.99\n",
      "trainer/Z Expert Targets Std          240.164\n",
      "trainer/Z Expert Targets Max         1603.34\n",
      "trainer/Z Expert Targets Min           81.605\n",
      "trainer/Z Policy Targets Mean         779.638\n",
      "trainer/Z Policy Targets Std          400.607\n",
      "trainer/Z Policy Targets Max         1572.38\n",
      "trainer/Z Policy Targets Min         -342.747\n",
      "trainer/Log Pis Mean                   14.0374\n",
      "trainer/Log Pis Std                     4.68624\n",
      "trainer/Policy mu Mean                  0.0827041\n",
      "trainer/Policy mu Std                   2.61326\n",
      "trainer/Policy log std Mean            -4.35918\n",
      "trainer/Policy log std Std              1.15991\n",
      "exploration/num steps total        280199\n",
      "exploration/num paths total          1155\n",
      "evaluation/num steps total              1.93678e+06\n",
      "evaluation/num paths total           2807\n",
      "evaluation/path length Mean           818.636\n",
      "evaluation/path length Std            296.168\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            332\n",
      "evaluation/Rewards Mean                 3.53263\n",
      "evaluation/Rewards Std                  0.639265\n",
      "evaluation/Rewards Max                  4.72672\n",
      "evaluation/Rewards Min                  0.749269\n",
      "evaluation/Returns Mean              2891.94\n",
      "evaluation/Returns Std               1089.48\n",
      "evaluation/Returns Max               3568.61\n",
      "evaluation/Returns Min               1104.14\n",
      "evaluation/Estimation Bias Mean       998.606\n",
      "evaluation/Estimation Bias Std        283.847\n",
      "evaluation/EB/Q_True Mean              36.5619\n",
      "evaluation/EB/Q_True Std              106.281\n",
      "evaluation/EB/Q_Pred Mean            1035.17\n",
      "evaluation/EB/Q_Pred Std              256.579\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2891.94\n",
      "evaluation/Actions Mean                 0.0465032\n",
      "evaluation/Actions Std                  0.58924\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77415\n",
      "time/backward_zf1 (s)                   1.89237\n",
      "time/backward_zf2 (s)                   1.82862\n",
      "time/data sampling (s)                  0.262135\n",
      "time/data storing (s)                   0.0140036\n",
      "time/evaluation sampling (s)            1.38888\n",
      "time/exploration sampling (s)           0.174118\n",
      "time/logging (s)                        0.0108959\n",
      "time/preback_alpha (s)                  0.552351\n",
      "time/preback_policy (s)                 0.620025\n",
      "time/preback_start (s)                  0.124722\n",
      "time/preback_zf (s)                     4.96729\n",
      "time/saving (s)                         0.00562923\n",
      "time/training (s)                       2.46054\n",
      "time/epoch (s)                         16.0757\n",
      "time/total (s)                       4298.49\n",
      "Epoch                                 274\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:13:13.314373 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 275 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 286000\n",
      "trainer/ZF1 Loss                       91.7766\n",
      "trainer/ZF2 Loss                      100.358\n",
      "trainer/ZF Expert Reward               14.0926\n",
      "trainer/ZF Policy Reward                4.95904\n",
      "trainer/ZF CHI2 Term                  119.367\n",
      "trainer/Policy Loss                  -826.481\n",
      "trainer/Policy Grad Norm              716.042\n",
      "trainer/Policy Param Norm              47.6003\n",
      "trainer/Zf1 Grad Norm               73082\n",
      "trainer/Zf1 Param Norm                133.079\n",
      "trainer/Zf2 Grad Norm               28884.1\n",
      "trainer/Zf2 Param Norm                128.539\n",
      "trainer/Z Expert Predictions Mean    1089.57\n",
      "trainer/Z Expert Predictions Std      233.497\n",
      "trainer/Z Expert Predictions Max     1639.31\n",
      "trainer/Z Expert Predictions Min      572.562\n",
      "trainer/Z Policy Predictions Mean     830.727\n",
      "trainer/Z Policy Predictions Std      358.149\n",
      "trainer/Z Policy Predictions Max     1568.12\n",
      "trainer/Z Policy Predictions Min     -366.652\n",
      "trainer/Z Expert Targets Mean        1075.48\n",
      "trainer/Z Expert Targets Std          231.713\n",
      "trainer/Z Expert Targets Max         1637.74\n",
      "trainer/Z Expert Targets Min          558.848\n",
      "trainer/Z Policy Targets Mean         825.768\n",
      "trainer/Z Policy Targets Std          356.889\n",
      "trainer/Z Policy Targets Max         1566.8\n",
      "trainer/Z Policy Targets Min         -373.436\n",
      "trainer/Log Pis Mean                   14.3086\n",
      "trainer/Log Pis Std                     5.13033\n",
      "trainer/Policy mu Mean                  0.13917\n",
      "trainer/Policy mu Std                   2.67804\n",
      "trainer/Policy log std Mean            -4.38527\n",
      "trainer/Policy log std Std              1.13892\n",
      "exploration/num steps total        281199\n",
      "exploration/num paths total          1156\n",
      "evaluation/num steps total              1.94678e+06\n",
      "evaluation/num paths total           2817\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52551\n",
      "evaluation/Rewards Std                  0.595286\n",
      "evaluation/Rewards Max                  4.70292\n",
      "evaluation/Rewards Min                  0.709094\n",
      "evaluation/Returns Mean              3525.51\n",
      "evaluation/Returns Std                 14.7044\n",
      "evaluation/Returns Max               3535.54\n",
      "evaluation/Returns Min               3485.39\n",
      "evaluation/Estimation Bias Mean       989.8\n",
      "evaluation/Estimation Bias Std        222.12\n",
      "evaluation/EB/Q_True Mean              32.695\n",
      "evaluation/EB/Q_True Std              100.751\n",
      "evaluation/EB/Q_Pred Mean            1022.5\n",
      "evaluation/EB/Q_Pred Std              196.229\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3525.51\n",
      "evaluation/Actions Mean                 0.0391391\n",
      "evaluation/Actions Std                  0.58624\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8104\n",
      "time/backward_zf1 (s)                   1.91659\n",
      "time/backward_zf2 (s)                   1.84354\n",
      "time/data sampling (s)                  0.263226\n",
      "time/data storing (s)                   0.0136008\n",
      "time/evaluation sampling (s)            1.38115\n",
      "time/exploration sampling (s)           0.170163\n",
      "time/logging (s)                        0.0114552\n",
      "time/preback_alpha (s)                  0.556129\n",
      "time/preback_policy (s)                 0.63221\n",
      "time/preback_start (s)                  0.126111\n",
      "time/preback_zf (s)                     4.98689\n",
      "time/saving (s)                         0.00525489\n",
      "time/training (s)                       2.41971\n",
      "time/epoch (s)                         16.1364\n",
      "time/total (s)                       4314.64\n",
      "Epoch                                 275\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:13:29.580341 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 276 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 287000\n",
      "trainer/ZF1 Loss                       60.4338\n",
      "trainer/ZF2 Loss                       68.1127\n",
      "trainer/ZF Expert Reward               11.338\n",
      "trainer/ZF Policy Reward               -1.36656\n",
      "trainer/ZF CHI2 Term                   91.2664\n",
      "trainer/Policy Loss                  -759.042\n",
      "trainer/Policy Grad Norm              528.689\n",
      "trainer/Policy Param Norm              47.6595\n",
      "trainer/Zf1 Grad Norm               34011.4\n",
      "trainer/Zf1 Param Norm                133.24\n",
      "trainer/Zf2 Grad Norm               39498.5\n",
      "trainer/Zf2 Param Norm                128.71\n",
      "trainer/Z Expert Predictions Mean    1066.13\n",
      "trainer/Z Expert Predictions Std      242.625\n",
      "trainer/Z Expert Predictions Max     1634.31\n",
      "trainer/Z Expert Predictions Min      116.821\n",
      "trainer/Z Policy Predictions Mean     758.759\n",
      "trainer/Z Policy Predictions Std      419.314\n",
      "trainer/Z Policy Predictions Max     1502.79\n",
      "trainer/Z Policy Predictions Min     -294.791\n",
      "trainer/Z Expert Targets Mean        1054.8\n",
      "trainer/Z Expert Targets Std          245.626\n",
      "trainer/Z Expert Targets Max         1656.81\n",
      "trainer/Z Expert Targets Min           84.3637\n",
      "trainer/Z Policy Targets Mean         760.126\n",
      "trainer/Z Policy Targets Std          418.587\n",
      "trainer/Z Policy Targets Max         1484.34\n",
      "trainer/Z Policy Targets Min         -304.631\n",
      "trainer/Log Pis Mean                   14.433\n",
      "trainer/Log Pis Std                     5.95929\n",
      "trainer/Policy mu Mean                  0.575916\n",
      "trainer/Policy mu Std                   3.68855\n",
      "trainer/Policy log std Mean            -4.22275\n",
      "trainer/Policy log std Std              1.36652\n",
      "exploration/num steps total        282199\n",
      "exploration/num paths total          1157\n",
      "evaluation/num steps total              1.95414e+06\n",
      "evaluation/num paths total           2827\n",
      "evaluation/path length Mean           735.7\n",
      "evaluation/path length Std            323.712\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 3.48543\n",
      "evaluation/Rewards Std                  0.649215\n",
      "evaluation/Rewards Max                  4.7219\n",
      "evaluation/Rewards Min                  0.766361\n",
      "evaluation/Returns Mean              2564.23\n",
      "evaluation/Returns Std               1171.51\n",
      "evaluation/Returns Max               3566.93\n",
      "evaluation/Returns Min               1115.36\n",
      "evaluation/Estimation Bias Mean       977.63\n",
      "evaluation/Estimation Bias Std        316.194\n",
      "evaluation/EB/Q_True Mean              43.6019\n",
      "evaluation/EB/Q_True Std              112.937\n",
      "evaluation/EB/Q_Pred Mean            1021.23\n",
      "evaluation/EB/Q_Pred Std              289.217\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2564.23\n",
      "evaluation/Actions Mean                 0.0465283\n",
      "evaluation/Actions Std                  0.587964\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77963\n",
      "time/backward_zf1 (s)                   1.88728\n",
      "time/backward_zf2 (s)                   1.83016\n",
      "time/data sampling (s)                  0.262896\n",
      "time/data storing (s)                   0.014187\n",
      "time/evaluation sampling (s)            1.41587\n",
      "time/exploration sampling (s)           0.172494\n",
      "time/logging (s)                        0.00904623\n",
      "time/preback_alpha (s)                  0.557846\n",
      "time/preback_policy (s)                 0.62666\n",
      "time/preback_start (s)                  0.125653\n",
      "time/preback_zf (s)                     4.99362\n",
      "time/saving (s)                         0.00550096\n",
      "time/training (s)                       2.51564\n",
      "time/epoch (s)                         16.1965\n",
      "time/total (s)                       4330.86\n",
      "Epoch                                 276\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:13:45.958688 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 277 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 288000\n",
      "trainer/ZF1 Loss                       73.8232\n",
      "trainer/ZF2 Loss                       95.8895\n",
      "trainer/ZF Expert Reward               16.8187\n",
      "trainer/ZF Policy Reward                8.16593\n",
      "trainer/ZF CHI2 Term                  107.396\n",
      "trainer/Policy Loss                  -803.674\n",
      "trainer/Policy Grad Norm              856.12\n",
      "trainer/Policy Param Norm              47.7175\n",
      "trainer/Zf1 Grad Norm               27334.9\n",
      "trainer/Zf1 Param Norm                133.395\n",
      "trainer/Zf2 Grad Norm               48247.2\n",
      "trainer/Zf2 Param Norm                128.869\n",
      "trainer/Z Expert Predictions Mean    1094.91\n",
      "trainer/Z Expert Predictions Std      238.257\n",
      "trainer/Z Expert Predictions Max     1689.13\n",
      "trainer/Z Expert Predictions Min      447.858\n",
      "trainer/Z Policy Predictions Mean     799.74\n",
      "trainer/Z Policy Predictions Std      391.443\n",
      "trainer/Z Policy Predictions Max     1464.13\n",
      "trainer/Z Policy Predictions Min     -362.029\n",
      "trainer/Z Expert Targets Mean        1078.09\n",
      "trainer/Z Expert Targets Std          234.644\n",
      "trainer/Z Expert Targets Max         1635.95\n",
      "trainer/Z Expert Targets Min          446.483\n",
      "trainer/Z Policy Targets Mean         791.574\n",
      "trainer/Z Policy Targets Std          386.5\n",
      "trainer/Z Policy Targets Max         1497.56\n",
      "trainer/Z Policy Targets Min         -433.256\n",
      "trainer/Log Pis Mean                   14.0273\n",
      "trainer/Log Pis Std                     4.91187\n",
      "trainer/Policy mu Mean                  0.393992\n",
      "trainer/Policy mu Std                   2.7023\n",
      "trainer/Policy log std Mean            -4.3671\n",
      "trainer/Policy log std Std              1.30266\n",
      "exploration/num steps total        283199\n",
      "exploration/num paths total          1158\n",
      "evaluation/num steps total              1.96414e+06\n",
      "evaluation/num paths total           2837\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.52735\n",
      "evaluation/Rewards Std                  0.599885\n",
      "evaluation/Rewards Max                  4.751\n",
      "evaluation/Rewards Min                  0.741251\n",
      "evaluation/Returns Mean              3527.35\n",
      "evaluation/Returns Std                 16.7127\n",
      "evaluation/Returns Max               3541.73\n",
      "evaluation/Returns Min               3481.26\n",
      "evaluation/Estimation Bias Mean      1003.51\n",
      "evaluation/Estimation Bias Std        212.848\n",
      "evaluation/EB/Q_True Mean              32.5956\n",
      "evaluation/EB/Q_True Std              100.459\n",
      "evaluation/EB/Q_Pred Mean            1036.11\n",
      "evaluation/EB/Q_Pred Std              190.862\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3527.35\n",
      "evaluation/Actions Mean                 0.0388828\n",
      "evaluation/Actions Std                  0.585506\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.82278\n",
      "time/backward_zf1 (s)                   1.94384\n",
      "time/backward_zf2 (s)                   1.88651\n",
      "time/data sampling (s)                  0.262777\n",
      "time/data storing (s)                   0.0137676\n",
      "time/evaluation sampling (s)            1.43222\n",
      "time/exploration sampling (s)           0.170751\n",
      "time/logging (s)                        0.0120517\n",
      "time/preback_alpha (s)                  0.564333\n",
      "time/preback_policy (s)                 0.643173\n",
      "time/preback_start (s)                  0.127418\n",
      "time/preback_zf (s)                     4.99004\n",
      "time/saving (s)                         0.00507146\n",
      "time/training (s)                       2.43995\n",
      "time/epoch (s)                         16.3147\n",
      "time/total (s)                       4347.19\n",
      "Epoch                                 277\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:14:02.224172 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 278 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 289000\n",
      "trainer/ZF1 Loss                       73.859\n",
      "trainer/ZF2 Loss                       72.0542\n",
      "trainer/ZF Expert Reward               13.7611\n",
      "trainer/ZF Policy Reward                1.80842\n",
      "trainer/ZF CHI2 Term                   98.8555\n",
      "trainer/Policy Loss                  -808.255\n",
      "trainer/Policy Grad Norm              903.745\n",
      "trainer/Policy Param Norm              47.7771\n",
      "trainer/Zf1 Grad Norm               68667.7\n",
      "trainer/Zf1 Param Norm                133.559\n",
      "trainer/Zf2 Grad Norm               79893.6\n",
      "trainer/Zf2 Param Norm                129.033\n",
      "trainer/Z Expert Predictions Mean    1070.39\n",
      "trainer/Z Expert Predictions Std      256.35\n",
      "trainer/Z Expert Predictions Max     1631.34\n",
      "trainer/Z Expert Predictions Min       22.4609\n",
      "trainer/Z Policy Predictions Mean     802.971\n",
      "trainer/Z Policy Predictions Std      385.297\n",
      "trainer/Z Policy Predictions Max     1583.95\n",
      "trainer/Z Policy Predictions Min     -337.749\n",
      "trainer/Z Expert Targets Mean        1056.63\n",
      "trainer/Z Expert Targets Std          256.003\n",
      "trainer/Z Expert Targets Max         1603.22\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         801.162\n",
      "trainer/Z Policy Targets Std          381.81\n",
      "trainer/Z Policy Targets Max         1525.41\n",
      "trainer/Z Policy Targets Min         -287.56\n",
      "trainer/Log Pis Mean                   14.0871\n",
      "trainer/Log Pis Std                     4.60056\n",
      "trainer/Policy mu Mean                  0.110872\n",
      "trainer/Policy mu Std                   2.47521\n",
      "trainer/Policy log std Mean            -4.21281\n",
      "trainer/Policy log std Std              1.23155\n",
      "exploration/num steps total        284199\n",
      "exploration/num paths total          1159\n",
      "evaluation/num steps total              1.97414e+06\n",
      "evaluation/num paths total           2847\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.50475\n",
      "evaluation/Rewards Std                  0.601533\n",
      "evaluation/Rewards Max                  4.72795\n",
      "evaluation/Rewards Min                  0.744983\n",
      "evaluation/Returns Mean              3504.75\n",
      "evaluation/Returns Std                 28.0091\n",
      "evaluation/Returns Max               3529.83\n",
      "evaluation/Returns Min               3430.56\n",
      "evaluation/Estimation Bias Mean       977.625\n",
      "evaluation/Estimation Bias Std        234.441\n",
      "evaluation/EB/Q_True Mean              32.3623\n",
      "evaluation/EB/Q_True Std               99.7367\n",
      "evaluation/EB/Q_Pred Mean            1009.99\n",
      "evaluation/EB/Q_Pred Std              211.796\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3504.75\n",
      "evaluation/Actions Mean                 0.042034\n",
      "evaluation/Actions Std                  0.588347\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.8463\n",
      "time/backward_zf1 (s)                   1.94642\n",
      "time/backward_zf2 (s)                   1.88246\n",
      "time/data sampling (s)                  0.262891\n",
      "time/data storing (s)                   0.0141363\n",
      "time/evaluation sampling (s)            1.38742\n",
      "time/exploration sampling (s)           0.176225\n",
      "time/logging (s)                        0.011445\n",
      "time/preback_alpha (s)                  0.555488\n",
      "time/preback_policy (s)                 0.638016\n",
      "time/preback_start (s)                  0.124868\n",
      "time/preback_zf (s)                     4.97599\n",
      "time/saving (s)                         0.00565035\n",
      "time/training (s)                       2.3731\n",
      "time/epoch (s)                         16.2004\n",
      "time/total (s)                       4363.41\n",
      "Epoch                                 278\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:14:17.890338 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 279 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 290000\n",
      "trainer/ZF1 Loss                      103.737\n",
      "trainer/ZF2 Loss                      126.163\n",
      "trainer/ZF Expert Reward               13.8936\n",
      "trainer/ZF Policy Reward                6.62497\n",
      "trainer/ZF CHI2 Term                  136.417\n",
      "trainer/Policy Loss                  -772.499\n",
      "trainer/Policy Grad Norm              588.891\n",
      "trainer/Policy Param Norm              47.8438\n",
      "trainer/Zf1 Grad Norm              123007\n",
      "trainer/Zf1 Param Norm                133.717\n",
      "trainer/Zf2 Grad Norm              125702\n",
      "trainer/Zf2 Param Norm                129.194\n",
      "trainer/Z Expert Predictions Mean    1076.3\n",
      "trainer/Z Expert Predictions Std      242.37\n",
      "trainer/Z Expert Predictions Max     1609.68\n",
      "trainer/Z Expert Predictions Min      429.23\n",
      "trainer/Z Policy Predictions Mean     770.465\n",
      "trainer/Z Policy Predictions Std      378.442\n",
      "trainer/Z Policy Predictions Max     1542.95\n",
      "trainer/Z Policy Predictions Min     -305.358\n",
      "trainer/Z Expert Targets Mean        1062.41\n",
      "trainer/Z Expert Targets Std          246.193\n",
      "trainer/Z Expert Targets Max         1575.32\n",
      "trainer/Z Expert Targets Min          399.131\n",
      "trainer/Z Policy Targets Mean         763.84\n",
      "trainer/Z Policy Targets Std          374.061\n",
      "trainer/Z Policy Targets Max         1521.04\n",
      "trainer/Z Policy Targets Min         -304.306\n",
      "trainer/Log Pis Mean                   14.3418\n",
      "trainer/Log Pis Std                     5.39254\n",
      "trainer/Policy mu Mean                  0.426532\n",
      "trainer/Policy mu Std                   3.5693\n",
      "trainer/Policy log std Mean            -4.2334\n",
      "trainer/Policy log std Std              1.33507\n",
      "exploration/num steps total        285163\n",
      "exploration/num paths total          1160\n",
      "evaluation/num steps total              1.97735e+06\n",
      "evaluation/num paths total           2857\n",
      "evaluation/path length Mean           321.3\n",
      "evaluation/path length Std             36.8132\n",
      "evaluation/path length Max            407\n",
      "evaluation/path length Min            282\n",
      "evaluation/Rewards Mean                 3.30647\n",
      "evaluation/Rewards Std                  0.831323\n",
      "evaluation/Rewards Max                  4.79662\n",
      "evaluation/Rewards Min                  0.749129\n",
      "evaluation/Returns Mean              1062.37\n",
      "evaluation/Returns Std                140.523\n",
      "evaluation/Returns Max               1388.69\n",
      "evaluation/Returns Min                913.245\n",
      "evaluation/Estimation Bias Mean       742.283\n",
      "evaluation/Estimation Bias Std        384.413\n",
      "evaluation/EB/Q_True Mean              27.2746\n",
      "evaluation/EB/Q_True Std               77.8618\n",
      "evaluation/EB/Q_Pred Mean             769.557\n",
      "evaluation/EB/Q_Pred Std              384.193\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1062.37\n",
      "evaluation/Actions Mean                 0.0245082\n",
      "evaluation/Actions Std                  0.596764\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74183\n",
      "time/backward_zf1 (s)                   1.85151\n",
      "time/backward_zf2 (s)                   1.77568\n",
      "time/data sampling (s)                  0.260407\n",
      "time/data storing (s)                   0.014254\n",
      "time/evaluation sampling (s)            0.826078\n",
      "time/exploration sampling (s)           0.174424\n",
      "time/logging (s)                        0.00538193\n",
      "time/preback_alpha (s)                  0.562506\n",
      "time/preback_policy (s)                 0.620139\n",
      "time/preback_start (s)                  0.125519\n",
      "time/preback_zf (s)                     5.01322\n",
      "time/saving (s)                         0.00539518\n",
      "time/training (s)                       2.61921\n",
      "time/epoch (s)                         15.5956\n",
      "time/total (s)                       4379.03\n",
      "Epoch                                 279\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:14:34.131039 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 280 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 291000\n",
      "trainer/ZF1 Loss                      163.806\n",
      "trainer/ZF2 Loss                      117.92\n",
      "trainer/ZF Expert Reward               11.4664\n",
      "trainer/ZF Policy Reward               -2.11212\n",
      "trainer/ZF CHI2 Term                  168.558\n",
      "trainer/Policy Loss                  -773.479\n",
      "trainer/Policy Grad Norm              824.138\n",
      "trainer/Policy Param Norm              47.9\n",
      "trainer/Zf1 Grad Norm              122309\n",
      "trainer/Zf1 Param Norm                133.872\n",
      "trainer/Zf2 Grad Norm               79152.1\n",
      "trainer/Zf2 Param Norm                129.348\n",
      "trainer/Z Expert Predictions Mean    1078.22\n",
      "trainer/Z Expert Predictions Std      247.188\n",
      "trainer/Z Expert Predictions Max     1607.3\n",
      "trainer/Z Expert Predictions Min      276.332\n",
      "trainer/Z Policy Predictions Mean     763.575\n",
      "trainer/Z Policy Predictions Std      400.499\n",
      "trainer/Z Policy Predictions Max     1457.95\n",
      "trainer/Z Policy Predictions Min     -535.968\n",
      "trainer/Z Expert Targets Mean        1066.76\n",
      "trainer/Z Expert Targets Std          255.474\n",
      "trainer/Z Expert Targets Max         1619.69\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         765.687\n",
      "trainer/Z Policy Targets Std          400.989\n",
      "trainer/Z Policy Targets Max         1484.84\n",
      "trainer/Z Policy Targets Min         -521.769\n",
      "trainer/Log Pis Mean                   14.2587\n",
      "trainer/Log Pis Std                     4.94397\n",
      "trainer/Policy mu Mean                  0.320954\n",
      "trainer/Policy mu Std                   2.81974\n",
      "trainer/Policy log std Mean            -4.33176\n",
      "trainer/Policy log std Std              1.27046\n",
      "exploration/num steps total        286446\n",
      "exploration/num paths total          1162\n",
      "evaluation/num steps total              1.98735e+06\n",
      "evaluation/num paths total           2867\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.54112\n",
      "evaluation/Rewards Std                  0.595195\n",
      "evaluation/Rewards Max                  4.74513\n",
      "evaluation/Rewards Min                  0.751891\n",
      "evaluation/Returns Mean              3541.12\n",
      "evaluation/Returns Std                 10.2997\n",
      "evaluation/Returns Max               3550.17\n",
      "evaluation/Returns Min               3520.59\n",
      "evaluation/Estimation Bias Mean      1009.1\n",
      "evaluation/Estimation Bias Std        235.193\n",
      "evaluation/EB/Q_True Mean              32.8191\n",
      "evaluation/EB/Q_True Std              101.165\n",
      "evaluation/EB/Q_Pred Mean            1041.92\n",
      "evaluation/EB/Q_Pred Std              212.153\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3541.12\n",
      "evaluation/Actions Mean                 0.0443117\n",
      "evaluation/Actions Std                  0.587794\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83641\n",
      "time/backward_zf1 (s)                   1.95489\n",
      "time/backward_zf2 (s)                   1.89078\n",
      "time/data sampling (s)                  0.241091\n",
      "time/data storing (s)                   0.0142475\n",
      "time/evaluation sampling (s)            1.38605\n",
      "time/exploration sampling (s)           0.177621\n",
      "time/logging (s)                        0.0120632\n",
      "time/preback_alpha (s)                  0.557037\n",
      "time/preback_policy (s)                 0.628725\n",
      "time/preback_start (s)                  0.126464\n",
      "time/preback_zf (s)                     4.96536\n",
      "time/saving (s)                         0.0050817\n",
      "time/training (s)                       2.38601\n",
      "time/epoch (s)                         16.1818\n",
      "time/total (s)                       4395.22\n",
      "Epoch                                 280\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:14:50.294084 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 281 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 292000\n",
      "trainer/ZF1 Loss                      484.246\n",
      "trainer/ZF2 Loss                      456.727\n",
      "trainer/ZF Expert Reward               10.1153\n",
      "trainer/ZF Policy Reward                3.12836\n",
      "trainer/ZF CHI2 Term                  492.27\n",
      "trainer/Policy Loss                  -784.2\n",
      "trainer/Policy Grad Norm              672.108\n",
      "trainer/Policy Param Norm              47.9682\n",
      "trainer/Zf1 Grad Norm               62931.8\n",
      "trainer/Zf1 Param Norm                134.034\n",
      "trainer/Zf2 Grad Norm               53419.2\n",
      "trainer/Zf2 Param Norm                129.517\n",
      "trainer/Z Expert Predictions Mean    1090.61\n",
      "trainer/Z Expert Predictions Std      251.409\n",
      "trainer/Z Expert Predictions Max     1658.66\n",
      "trainer/Z Expert Predictions Min      629.933\n",
      "trainer/Z Policy Predictions Mean     787.293\n",
      "trainer/Z Policy Predictions Std      414.412\n",
      "trainer/Z Policy Predictions Max     1564.4\n",
      "trainer/Z Policy Predictions Min     -426.903\n",
      "trainer/Z Expert Targets Mean        1080.5\n",
      "trainer/Z Expert Targets Std          250.533\n",
      "trainer/Z Expert Targets Max         1657.62\n",
      "trainer/Z Expert Targets Min          624.784\n",
      "trainer/Z Policy Targets Mean         784.165\n",
      "trainer/Z Policy Targets Std          409.138\n",
      "trainer/Z Policy Targets Max         1598.9\n",
      "trainer/Z Policy Targets Min         -394.841\n",
      "trainer/Log Pis Mean                   14.9466\n",
      "trainer/Log Pis Std                     5.3632\n",
      "trainer/Policy mu Mean                  0.345953\n",
      "trainer/Policy mu Std                   3.12401\n",
      "trainer/Policy log std Mean            -4.31658\n",
      "trainer/Policy log std Std              1.21569\n",
      "exploration/num steps total        286446\n",
      "exploration/num paths total          1162\n",
      "evaluation/num steps total              1.99447e+06\n",
      "evaluation/num paths total           2879\n",
      "evaluation/path length Mean           593.25\n",
      "evaluation/path length Std            279.832\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            332\n",
      "evaluation/Rewards Mean                 3.47638\n",
      "evaluation/Rewards Std                  0.694768\n",
      "evaluation/Rewards Max                  4.72942\n",
      "evaluation/Rewards Min                  0.760034\n",
      "evaluation/Returns Mean              2062.36\n",
      "evaluation/Returns Std               1024.43\n",
      "evaluation/Returns Max               3561.1\n",
      "evaluation/Returns Min               1104.25\n",
      "evaluation/Estimation Bias Mean       892.529\n",
      "evaluation/Estimation Bias Std        390.027\n",
      "evaluation/EB/Q_True Mean              46.0885\n",
      "evaluation/EB/Q_True Std              117.224\n",
      "evaluation/EB/Q_Pred Mean             938.618\n",
      "evaluation/EB/Q_Pred Std              366.483\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2062.36\n",
      "evaluation/Actions Mean                 0.0385641\n",
      "evaluation/Actions Std                  0.594098\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71942\n",
      "time/backward_zf1 (s)                   1.83131\n",
      "time/backward_zf2 (s)                   1.75849\n",
      "time/data sampling (s)                  0.260801\n",
      "time/data storing (s)                   0.0135277\n",
      "time/evaluation sampling (s)            1.39812\n",
      "time/exploration sampling (s)           0.170987\n",
      "time/logging (s)                        0.00875541\n",
      "time/preback_alpha (s)                  0.555755\n",
      "time/preback_policy (s)                 0.611314\n",
      "time/preback_start (s)                  0.12448\n",
      "time/preback_zf (s)                     4.97699\n",
      "time/saving (s)                         0.00511306\n",
      "time/training (s)                       2.64966\n",
      "time/epoch (s)                         16.0847\n",
      "time/total (s)                       4411.34\n",
      "Epoch                                 281\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:15:06.649762 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 282 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 293000\n",
      "trainer/ZF1 Loss                       78.1828\n",
      "trainer/ZF2 Loss                       59.4253\n",
      "trainer/ZF Expert Reward                7.77739\n",
      "trainer/ZF Policy Reward               -6.92755\n",
      "trainer/ZF CHI2 Term                   97.9364\n",
      "trainer/Policy Loss                  -802.534\n",
      "trainer/Policy Grad Norm              609.143\n",
      "trainer/Policy Param Norm              48.0388\n",
      "trainer/Zf1 Grad Norm              106149\n",
      "trainer/Zf1 Param Norm                134.194\n",
      "trainer/Zf2 Grad Norm               49424.5\n",
      "trainer/Zf2 Param Norm                129.684\n",
      "trainer/Z Expert Predictions Mean    1068.15\n",
      "trainer/Z Expert Predictions Std      247.047\n",
      "trainer/Z Expert Predictions Max     1585.78\n",
      "trainer/Z Expert Predictions Min      368.269\n",
      "trainer/Z Policy Predictions Mean     790.859\n",
      "trainer/Z Policy Predictions Std      408.752\n",
      "trainer/Z Policy Predictions Max     1592.69\n",
      "trainer/Z Policy Predictions Min     -364.427\n",
      "trainer/Z Expert Targets Mean        1060.37\n",
      "trainer/Z Expert Targets Std          248.03\n",
      "trainer/Z Expert Targets Max         1578.95\n",
      "trainer/Z Expert Targets Min          321.784\n",
      "trainer/Z Policy Targets Mean         797.787\n",
      "trainer/Z Policy Targets Std          407.169\n",
      "trainer/Z Policy Targets Max         1612.84\n",
      "trainer/Z Policy Targets Min         -341.56\n",
      "trainer/Log Pis Mean                   14.5731\n",
      "trainer/Log Pis Std                     5.38454\n",
      "trainer/Policy mu Mean                  0.230782\n",
      "trainer/Policy mu Std                   2.87737\n",
      "trainer/Policy log std Mean            -4.37198\n",
      "trainer/Policy log std Std              1.26091\n",
      "exploration/num steps total        288446\n",
      "exploration/num paths total          1164\n",
      "evaluation/num steps total              2.00156e+06\n",
      "evaluation/num paths total           2890\n",
      "evaluation/path length Mean           644.545\n",
      "evaluation/path length Std            325.169\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            331\n",
      "evaluation/Rewards Mean                 3.48336\n",
      "evaluation/Rewards Std                  0.668684\n",
      "evaluation/Rewards Max                  4.63293\n",
      "evaluation/Rewards Min                  0.760254\n",
      "evaluation/Returns Mean              2245.19\n",
      "evaluation/Returns Std               1190.26\n",
      "evaluation/Returns Max               3560.3\n",
      "evaluation/Returns Min               1097.73\n",
      "evaluation/Estimation Bias Mean      1018.09\n",
      "evaluation/Estimation Bias Std        326.475\n",
      "evaluation/EB/Q_True Mean              46.3078\n",
      "evaluation/EB/Q_True Std              117.491\n",
      "evaluation/EB/Q_Pred Mean            1064.4\n",
      "evaluation/EB/Q_Pred Std              291.216\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2245.19\n",
      "evaluation/Actions Mean                 0.0394099\n",
      "evaluation/Actions Std                  0.591133\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81918\n",
      "time/backward_zf1 (s)                   1.93393\n",
      "time/backward_zf2 (s)                   1.86338\n",
      "time/data sampling (s)                  0.256552\n",
      "time/data storing (s)                   0.0138194\n",
      "time/evaluation sampling (s)            1.42881\n",
      "time/exploration sampling (s)           0.171447\n",
      "time/logging (s)                        0.0107061\n",
      "time/preback_alpha (s)                  0.5595\n",
      "time/preback_policy (s)                 0.633146\n",
      "time/preback_start (s)                  0.127113\n",
      "time/preback_zf (s)                     4.98504\n",
      "time/saving (s)                         0.00632993\n",
      "time/training (s)                       2.48522\n",
      "time/epoch (s)                         16.2942\n",
      "time/total (s)                       4427.65\n",
      "Epoch                                 282\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:15:22.832476 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 283 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 294000\n",
      "trainer/ZF1 Loss                       57.6666\n",
      "trainer/ZF2 Loss                       70.8745\n",
      "trainer/ZF Expert Reward               13.1126\n",
      "trainer/ZF Policy Reward               -1.18092\n",
      "trainer/ZF CHI2 Term                   92.3768\n",
      "trainer/Policy Loss                  -818.763\n",
      "trainer/Policy Grad Norm              573.221\n",
      "trainer/Policy Param Norm              48.0997\n",
      "trainer/Zf1 Grad Norm               66988\n",
      "trainer/Zf1 Param Norm                134.351\n",
      "trainer/Zf2 Grad Norm               65194.4\n",
      "trainer/Zf2 Param Norm                129.841\n",
      "trainer/Z Expert Predictions Mean    1064.67\n",
      "trainer/Z Expert Predictions Std      230.323\n",
      "trainer/Z Expert Predictions Max     1636.07\n",
      "trainer/Z Expert Predictions Min      350.997\n",
      "trainer/Z Policy Predictions Mean     804.974\n",
      "trainer/Z Policy Predictions Std      400.007\n",
      "trainer/Z Policy Predictions Max     1505.12\n",
      "trainer/Z Policy Predictions Min     -366.118\n",
      "trainer/Z Expert Targets Mean        1051.56\n",
      "trainer/Z Expert Targets Std          232.849\n",
      "trainer/Z Expert Targets Max         1660.21\n",
      "trainer/Z Expert Targets Min          349.858\n",
      "trainer/Z Policy Targets Mean         806.155\n",
      "trainer/Z Policy Targets Std          397.236\n",
      "trainer/Z Policy Targets Max         1487.07\n",
      "trainer/Z Policy Targets Min         -389.125\n",
      "trainer/Log Pis Mean                   13.9522\n",
      "trainer/Log Pis Std                     5.0098\n",
      "trainer/Policy mu Mean                  0.352351\n",
      "trainer/Policy mu Std                   2.84148\n",
      "trainer/Policy log std Mean            -4.30207\n",
      "trainer/Policy log std Std              1.31273\n",
      "exploration/num steps total        288778\n",
      "exploration/num paths total          1165\n",
      "evaluation/num steps total              2.00772e+06\n",
      "evaluation/num paths total           2900\n",
      "evaluation/path length Mean           616.1\n",
      "evaluation/path length Std            314.622\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 3.49128\n",
      "evaluation/Rewards Std                  0.681621\n",
      "evaluation/Rewards Max                  4.72551\n",
      "evaluation/Rewards Min                  0.732106\n",
      "evaluation/Returns Mean              2150.98\n",
      "evaluation/Returns Std               1155.42\n",
      "evaluation/Returns Max               3569.52\n",
      "evaluation/Returns Min               1115.03\n",
      "evaluation/Estimation Bias Mean       960.773\n",
      "evaluation/Estimation Bias Std        392.806\n",
      "evaluation/EB/Q_True Mean              53.5582\n",
      "evaluation/EB/Q_True Std              125.292\n",
      "evaluation/EB/Q_Pred Mean            1014.33\n",
      "evaluation/EB/Q_Pred Std              358.151\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2150.98\n",
      "evaluation/Actions Mean                 0.0303526\n",
      "evaluation/Actions Std                  0.586066\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77005\n",
      "time/backward_zf1 (s)                   1.90646\n",
      "time/backward_zf2 (s)                   1.82761\n",
      "time/data sampling (s)                  0.260838\n",
      "time/data storing (s)                   0.0134099\n",
      "time/evaluation sampling (s)            1.35207\n",
      "time/exploration sampling (s)           0.166651\n",
      "time/logging (s)                        0.00844907\n",
      "time/preback_alpha (s)                  0.56265\n",
      "time/preback_policy (s)                 0.632308\n",
      "time/preback_start (s)                  0.126179\n",
      "time/preback_zf (s)                     4.99937\n",
      "time/saving (s)                         0.00534113\n",
      "time/training (s)                       2.47731\n",
      "time/epoch (s)                         16.1087\n",
      "time/total (s)                       4443.78\n",
      "Epoch                                 283\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:15:38.038486 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 284 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 295000\n",
      "trainer/ZF1 Loss                      295.322\n",
      "trainer/ZF2 Loss                      199.723\n",
      "trainer/ZF Expert Reward               22.7864\n",
      "trainer/ZF Policy Reward               12.2806\n",
      "trainer/ZF CHI2 Term                  272.418\n",
      "trainer/Policy Loss                  -823.912\n",
      "trainer/Policy Grad Norm              828.105\n",
      "trainer/Policy Param Norm              48.1531\n",
      "trainer/Zf1 Grad Norm              134276\n",
      "trainer/Zf1 Param Norm                134.522\n",
      "trainer/Zf2 Grad Norm               53363.3\n",
      "trainer/Zf2 Param Norm                130.015\n",
      "trainer/Z Expert Predictions Mean    1101.43\n",
      "trainer/Z Expert Predictions Std      238.279\n",
      "trainer/Z Expert Predictions Max     1659.11\n",
      "trainer/Z Expert Predictions Min      385.611\n",
      "trainer/Z Policy Predictions Mean     818.989\n",
      "trainer/Z Policy Predictions Std      407.048\n",
      "trainer/Z Policy Predictions Max     1588.48\n",
      "trainer/Z Policy Predictions Min     -353.457\n",
      "trainer/Z Expert Targets Mean        1078.64\n",
      "trainer/Z Expert Targets Std          238.767\n",
      "trainer/Z Expert Targets Max         1616.78\n",
      "trainer/Z Expert Targets Min          314.259\n",
      "trainer/Z Policy Targets Mean         806.709\n",
      "trainer/Z Policy Targets Std          402.35\n",
      "trainer/Z Policy Targets Max         1549.58\n",
      "trainer/Z Policy Targets Min         -338.411\n",
      "trainer/Log Pis Mean                   14.5349\n",
      "trainer/Log Pis Std                     4.8767\n",
      "trainer/Policy mu Mean                  0.204846\n",
      "trainer/Policy mu Std                   2.78981\n",
      "trainer/Policy log std Mean            -4.25903\n",
      "trainer/Policy log std Std              1.31827\n",
      "exploration/num steps total        290778\n",
      "exploration/num paths total          1167\n",
      "evaluation/num steps total              2.01089e+06\n",
      "evaluation/num paths total           2910\n",
      "evaluation/path length Mean           317.2\n",
      "evaluation/path length Std             24.219\n",
      "evaluation/path length Max            336\n",
      "evaluation/path length Min            278\n",
      "evaluation/Rewards Mean                 3.30873\n",
      "evaluation/Rewards Std                  0.837161\n",
      "evaluation/Rewards Max                  4.84623\n",
      "evaluation/Rewards Min                  0.752365\n",
      "evaluation/Returns Mean              1049.53\n",
      "evaluation/Returns Std                 93.278\n",
      "evaluation/Returns Max               1120.33\n",
      "evaluation/Returns Min                898.78\n",
      "evaluation/Estimation Bias Mean       824.645\n",
      "evaluation/Estimation Bias Std        420.053\n",
      "evaluation/EB/Q_True Mean              27.2893\n",
      "evaluation/EB/Q_True Std               83.971\n",
      "evaluation/EB/Q_Pred Mean             851.935\n",
      "evaluation/EB/Q_Pred Std              414.967\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1049.53\n",
      "evaluation/Actions Mean                 0.0276989\n",
      "evaluation/Actions Std                  0.594384\n",
      "evaluation/Actions Max                  0.999988\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73417\n",
      "time/backward_zf1 (s)                   1.85715\n",
      "time/backward_zf2 (s)                   1.78163\n",
      "time/data sampling (s)                  0.258954\n",
      "time/data storing (s)                   0.0137671\n",
      "time/evaluation sampling (s)            0.508916\n",
      "time/exploration sampling (s)           0.173164\n",
      "time/logging (s)                        0.00450618\n",
      "time/preback_alpha (s)                  0.552592\n",
      "time/preback_policy (s)                 0.62333\n",
      "time/preback_start (s)                  0.124817\n",
      "time/preback_zf (s)                     4.95309\n",
      "time/saving (s)                         0.00558301\n",
      "time/training (s)                       2.54459\n",
      "time/epoch (s)                         15.1363\n",
      "time/total (s)                       4458.94\n",
      "Epoch                                 284\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:15:53.299501 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 285 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 296000\n",
      "trainer/ZF1 Loss                      164.823\n",
      "trainer/ZF2 Loss                      191.961\n",
      "trainer/ZF Expert Reward               17.6194\n",
      "trainer/ZF Policy Reward               10.0164\n",
      "trainer/ZF CHI2 Term                  199.999\n",
      "trainer/Policy Loss                  -802.858\n",
      "trainer/Policy Grad Norm              675.508\n",
      "trainer/Policy Param Norm              48.2081\n",
      "trainer/Zf1 Grad Norm               85197.3\n",
      "trainer/Zf1 Param Norm                134.694\n",
      "trainer/Zf2 Grad Norm              128463\n",
      "trainer/Zf2 Param Norm                130.187\n",
      "trainer/Z Expert Predictions Mean    1094.94\n",
      "trainer/Z Expert Predictions Std      253.056\n",
      "trainer/Z Expert Predictions Max     1619.37\n",
      "trainer/Z Expert Predictions Min      289.917\n",
      "trainer/Z Policy Predictions Mean     806.85\n",
      "trainer/Z Policy Predictions Std      382.677\n",
      "trainer/Z Policy Predictions Max     1610.01\n",
      "trainer/Z Policy Predictions Min     -373.776\n",
      "trainer/Z Expert Targets Mean        1077.32\n",
      "trainer/Z Expert Targets Std          266.74\n",
      "trainer/Z Expert Targets Max         1632.81\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         796.833\n",
      "trainer/Z Policy Targets Std          384.68\n",
      "trainer/Z Policy Targets Max         1595.46\n",
      "trainer/Z Policy Targets Min         -337.872\n",
      "trainer/Log Pis Mean                   14.1455\n",
      "trainer/Log Pis Std                     4.27812\n",
      "trainer/Policy mu Mean                  0.29161\n",
      "trainer/Policy mu Std                   2.91482\n",
      "trainer/Policy log std Mean            -4.38458\n",
      "trainer/Policy log std Std              1.24685\n",
      "exploration/num steps total        291778\n",
      "exploration/num paths total          1168\n",
      "evaluation/num steps total              2.01403e+06\n",
      "evaluation/num paths total           2920\n",
      "evaluation/path length Mean           313.3\n",
      "evaluation/path length Std             26.8516\n",
      "evaluation/path length Max            336\n",
      "evaluation/path length Min            277\n",
      "evaluation/Rewards Mean                 3.29444\n",
      "evaluation/Rewards Std                  0.835747\n",
      "evaluation/Rewards Max                  4.7964\n",
      "evaluation/Rewards Min                  0.740175\n",
      "evaluation/Returns Mean              1032.15\n",
      "evaluation/Returns Std                103.337\n",
      "evaluation/Returns Max               1119.77\n",
      "evaluation/Returns Min                892.699\n",
      "evaluation/Estimation Bias Mean       904.357\n",
      "evaluation/Estimation Bias Std        387.133\n",
      "evaluation/EB/Q_True Mean              27.6376\n",
      "evaluation/EB/Q_True Std               84.3747\n",
      "evaluation/EB/Q_Pred Mean             931.995\n",
      "evaluation/EB/Q_Pred Std              380.254\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1032.15\n",
      "evaluation/Actions Mean                 0.0288047\n",
      "evaluation/Actions Std                  0.593779\n",
      "evaluation/Actions Max                  0.999991\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75521\n",
      "time/backward_zf1 (s)                   1.87513\n",
      "time/backward_zf2 (s)                   1.79285\n",
      "time/data sampling (s)                  0.261642\n",
      "time/data storing (s)                   0.0141714\n",
      "time/evaluation sampling (s)            0.480109\n",
      "time/exploration sampling (s)           0.172879\n",
      "time/logging (s)                        0.00509986\n",
      "time/preback_alpha (s)                  0.560016\n",
      "time/preback_policy (s)                 0.626546\n",
      "time/preback_start (s)                  0.126085\n",
      "time/preback_zf (s)                     4.98658\n",
      "time/saving (s)                         0.00505593\n",
      "time/training (s)                       2.53613\n",
      "time/epoch (s)                         15.1975\n",
      "time/total (s)                       4474.15\n",
      "Epoch                                 285\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:16:08.526644 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 286 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 297000\n",
      "trainer/ZF1 Loss                      179.456\n",
      "trainer/ZF2 Loss                      171.931\n",
      "trainer/ZF Expert Reward               12.6896\n",
      "trainer/ZF Policy Reward               10.0973\n",
      "trainer/ZF CHI2 Term                  192.933\n",
      "trainer/Policy Loss                  -824.302\n",
      "trainer/Policy Grad Norm              797.599\n",
      "trainer/Policy Param Norm              48.2691\n",
      "trainer/Zf1 Grad Norm              102481\n",
      "trainer/Zf1 Param Norm                134.848\n",
      "trainer/Zf2 Grad Norm               80559\n",
      "trainer/Zf2 Param Norm                130.356\n",
      "trainer/Z Expert Predictions Mean    1076.59\n",
      "trainer/Z Expert Predictions Std      239.27\n",
      "trainer/Z Expert Predictions Max     1537.19\n",
      "trainer/Z Expert Predictions Min      298.437\n",
      "trainer/Z Policy Predictions Mean     823.29\n",
      "trainer/Z Policy Predictions Std      385.853\n",
      "trainer/Z Policy Predictions Max     1576.84\n",
      "trainer/Z Policy Predictions Min     -451.315\n",
      "trainer/Z Expert Targets Mean        1063.9\n",
      "trainer/Z Expert Targets Std          240.114\n",
      "trainer/Z Expert Targets Max         1542.46\n",
      "trainer/Z Expert Targets Min          262.313\n",
      "trainer/Z Policy Targets Mean         813.193\n",
      "trainer/Z Policy Targets Std          389.13\n",
      "trainer/Z Policy Targets Max         1610.38\n",
      "trainer/Z Policy Targets Min         -536.052\n",
      "trainer/Log Pis Mean                   14.7959\n",
      "trainer/Log Pis Std                     4.99509\n",
      "trainer/Policy mu Mean                  0.282352\n",
      "trainer/Policy mu Std                   2.64064\n",
      "trainer/Policy log std Mean            -4.3754\n",
      "trainer/Policy log std Std              1.26103\n",
      "exploration/num steps total        293114\n",
      "exploration/num paths total          1170\n",
      "evaluation/num steps total              2.0171e+06\n",
      "evaluation/num paths total           2930\n",
      "evaluation/path length Mean           307.5\n",
      "evaluation/path length Std             30.6145\n",
      "evaluation/path length Max            350\n",
      "evaluation/path length Min            264\n",
      "evaluation/Rewards Mean                 3.28248\n",
      "evaluation/Rewards Std                  0.83911\n",
      "evaluation/Rewards Max                  4.7892\n",
      "evaluation/Rewards Min                  0.755888\n",
      "evaluation/Returns Mean              1009.36\n",
      "evaluation/Returns Std                116.673\n",
      "evaluation/Returns Max               1168.14\n",
      "evaluation/Returns Min                844.009\n",
      "evaluation/Estimation Bias Mean       859.683\n",
      "evaluation/Estimation Bias Std        366.097\n",
      "evaluation/EB/Q_True Mean              29.7177\n",
      "evaluation/EB/Q_True Std               87.7907\n",
      "evaluation/EB/Q_Pred Mean             889.401\n",
      "evaluation/EB/Q_Pred Std              355.473\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1009.36\n",
      "evaluation/Actions Mean                 0.0327474\n",
      "evaluation/Actions Std                  0.587803\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75117\n",
      "time/backward_zf1 (s)                   1.87129\n",
      "time/backward_zf2 (s)                   1.80462\n",
      "time/data sampling (s)                  0.254855\n",
      "time/data storing (s)                   0.0138191\n",
      "time/evaluation sampling (s)            0.522875\n",
      "time/exploration sampling (s)           0.173778\n",
      "time/logging (s)                        0.00455598\n",
      "time/preback_alpha (s)                  0.547365\n",
      "time/preback_policy (s)                 0.613081\n",
      "time/preback_start (s)                  0.124292\n",
      "time/preback_zf (s)                     4.96215\n",
      "time/saving (s)                         0.00514659\n",
      "time/training (s)                       2.51012\n",
      "time/epoch (s)                         15.1591\n",
      "time/total (s)                       4489.33\n",
      "Epoch                                 286\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:16:24.535254 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 287 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 298000\n",
      "trainer/ZF1 Loss                       62.9079\n",
      "trainer/ZF2 Loss                       50.095\n",
      "trainer/ZF Expert Reward                7.80958\n",
      "trainer/ZF Policy Reward               -2.91832\n",
      "trainer/ZF CHI2 Term                   82.5719\n",
      "trainer/Policy Loss                  -797.005\n",
      "trainer/Policy Grad Norm              906.187\n",
      "trainer/Policy Param Norm              48.3262\n",
      "trainer/Zf1 Grad Norm               43665.1\n",
      "trainer/Zf1 Param Norm                135.025\n",
      "trainer/Zf2 Grad Norm               33606.7\n",
      "trainer/Zf2 Param Norm                130.524\n",
      "trainer/Z Expert Predictions Mean    1095.42\n",
      "trainer/Z Expert Predictions Std      242.896\n",
      "trainer/Z Expert Predictions Max     1601.99\n",
      "trainer/Z Expert Predictions Min      380.122\n",
      "trainer/Z Policy Predictions Mean     790.283\n",
      "trainer/Z Policy Predictions Std      426.293\n",
      "trainer/Z Policy Predictions Max     1519.01\n",
      "trainer/Z Policy Predictions Min     -393.787\n",
      "trainer/Z Expert Targets Mean        1087.62\n",
      "trainer/Z Expert Targets Std          242.352\n",
      "trainer/Z Expert Targets Max         1588.62\n",
      "trainer/Z Expert Targets Min          365.148\n",
      "trainer/Z Policy Targets Mean         793.201\n",
      "trainer/Z Policy Targets Std          425.831\n",
      "trainer/Z Policy Targets Max         1513.07\n",
      "trainer/Z Policy Targets Min         -420.243\n",
      "trainer/Log Pis Mean                   15.4975\n",
      "trainer/Log Pis Std                     6.00902\n",
      "trainer/Policy mu Mean                  0.629753\n",
      "trainer/Policy mu Std                   3.49998\n",
      "trainer/Policy log std Mean            -4.16245\n",
      "trainer/Policy log std Std              1.45987\n",
      "exploration/num steps total        293788\n",
      "exploration/num paths total          1172\n",
      "evaluation/num steps total              2.0271e+06\n",
      "evaluation/num paths total           2940\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.53196\n",
      "evaluation/Rewards Std                  0.596815\n",
      "evaluation/Rewards Max                  4.70714\n",
      "evaluation/Rewards Min                  0.705935\n",
      "evaluation/Returns Mean              3531.96\n",
      "evaluation/Returns Std                 10.5173\n",
      "evaluation/Returns Max               3544.17\n",
      "evaluation/Returns Min               3511.55\n",
      "evaluation/Estimation Bias Mean      1042.55\n",
      "evaluation/Estimation Bias Std        240.19\n",
      "evaluation/EB/Q_True Mean              32.6761\n",
      "evaluation/EB/Q_True Std              100.818\n",
      "evaluation/EB/Q_Pred Mean            1075.23\n",
      "evaluation/EB/Q_Pred Std              214.151\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3531.96\n",
      "evaluation/Actions Mean                 0.0391995\n",
      "evaluation/Actions Std                  0.588295\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.69641\n",
      "time/backward_zf1 (s)                   1.78835\n",
      "time/backward_zf2 (s)                   1.72695\n",
      "time/data sampling (s)                  0.258288\n",
      "time/data storing (s)                   0.0135689\n",
      "time/evaluation sampling (s)            1.38865\n",
      "time/exploration sampling (s)           0.169281\n",
      "time/logging (s)                        0.0117704\n",
      "time/preback_alpha (s)                  0.550625\n",
      "time/preback_policy (s)                 0.600306\n",
      "time/preback_start (s)                  0.12542\n",
      "time/preback_zf (s)                     4.95695\n",
      "time/saving (s)                         0.00544583\n",
      "time/training (s)                       2.66151\n",
      "time/epoch (s)                         15.9535\n",
      "time/total (s)                       4505.3\n",
      "Epoch                                 287\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:16:40.247809 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 288 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 299000\n",
      "trainer/ZF1 Loss                       67.1598\n",
      "trainer/ZF2 Loss                       63.3805\n",
      "trainer/ZF Expert Reward               17.3577\n",
      "trainer/ZF Policy Reward                4.35645\n",
      "trainer/ZF CHI2 Term                   92.1879\n",
      "trainer/Policy Loss                  -815.305\n",
      "trainer/Policy Grad Norm              563.789\n",
      "trainer/Policy Param Norm              48.3888\n",
      "trainer/Zf1 Grad Norm               29267.9\n",
      "trainer/Zf1 Param Norm                135.184\n",
      "trainer/Zf2 Grad Norm               65317.4\n",
      "trainer/Zf2 Param Norm                130.701\n",
      "trainer/Z Expert Predictions Mean    1096.51\n",
      "trainer/Z Expert Predictions Std      242.651\n",
      "trainer/Z Expert Predictions Max     1655.67\n",
      "trainer/Z Expert Predictions Min      405.906\n",
      "trainer/Z Policy Predictions Mean     814.645\n",
      "trainer/Z Policy Predictions Std      425.972\n",
      "trainer/Z Policy Predictions Max     1574.9\n",
      "trainer/Z Policy Predictions Min     -432.903\n",
      "trainer/Z Expert Targets Mean        1079.15\n",
      "trainer/Z Expert Targets Std          239.689\n",
      "trainer/Z Expert Targets Max         1636.8\n",
      "trainer/Z Expert Targets Min          429.854\n",
      "trainer/Z Policy Targets Mean         810.289\n",
      "trainer/Z Policy Targets Std          424.898\n",
      "trainer/Z Policy Targets Max         1572.49\n",
      "trainer/Z Policy Targets Min         -479.961\n",
      "trainer/Log Pis Mean                   14.0571\n",
      "trainer/Log Pis Std                     4.76179\n",
      "trainer/Policy mu Mean                  0.269372\n",
      "trainer/Policy mu Std                   2.80507\n",
      "trainer/Policy log std Mean            -4.41965\n",
      "trainer/Policy log std Std              1.22285\n",
      "exploration/num steps total        294788\n",
      "exploration/num paths total          1173\n",
      "evaluation/num steps total              2.03039e+06\n",
      "evaluation/num paths total           2950\n",
      "evaluation/path length Mean           328.8\n",
      "evaluation/path length Std             16.0798\n",
      "evaluation/path length Max            338\n",
      "evaluation/path length Min            281\n",
      "evaluation/Rewards Mean                 3.32425\n",
      "evaluation/Rewards Std                  0.828141\n",
      "evaluation/Rewards Max                  4.74835\n",
      "evaluation/Rewards Min                  0.670267\n",
      "evaluation/Returns Mean              1093.01\n",
      "evaluation/Returns Std                 62.1123\n",
      "evaluation/Returns Max               1123.88\n",
      "evaluation/Returns Min                907.574\n",
      "evaluation/Estimation Bias Mean       842.945\n",
      "evaluation/Estimation Bias Std        431.979\n",
      "evaluation/EB/Q_True Mean              26.3635\n",
      "evaluation/EB/Q_True Std               82.6966\n",
      "evaluation/EB/Q_Pred Mean             869.308\n",
      "evaluation/EB/Q_Pred Std              428.313\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1093.01\n",
      "evaluation/Actions Mean                 0.0222876\n",
      "evaluation/Actions Std                  0.596697\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79446\n",
      "time/backward_zf1 (s)                   1.88915\n",
      "time/backward_zf2 (s)                   1.84416\n",
      "time/data sampling (s)                  0.260831\n",
      "time/data storing (s)                   0.0136256\n",
      "time/evaluation sampling (s)            0.956745\n",
      "time/exploration sampling (s)           0.171533\n",
      "time/logging (s)                        0.00460894\n",
      "time/preback_alpha (s)                  0.553518\n",
      "time/preback_policy (s)                 0.629071\n",
      "time/preback_start (s)                  0.125841\n",
      "time/preback_zf (s)                     4.9641\n",
      "time/saving (s)                         0.0046722\n",
      "time/training (s)                       2.42874\n",
      "time/epoch (s)                         15.6411\n",
      "time/total (s)                       4520.96\n",
      "Epoch                                 288\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:16:56.484254 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 289 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 300000\n",
      "trainer/ZF1 Loss                      216.637\n",
      "trainer/ZF2 Loss                      231.338\n",
      "trainer/ZF Expert Reward                7.07453\n",
      "trainer/ZF Policy Reward               -4.9696\n",
      "trainer/ZF CHI2 Term                  250.35\n",
      "trainer/Policy Loss                  -837.666\n",
      "trainer/Policy Grad Norm              499.844\n",
      "trainer/Policy Param Norm              48.4401\n",
      "trainer/Zf1 Grad Norm              168611\n",
      "trainer/Zf1 Param Norm                135.345\n",
      "trainer/Zf2 Grad Norm               75374.8\n",
      "trainer/Zf2 Param Norm                130.872\n",
      "trainer/Z Expert Predictions Mean    1075.58\n",
      "trainer/Z Expert Predictions Std      225.861\n",
      "trainer/Z Expert Predictions Max     1561.53\n",
      "trainer/Z Expert Predictions Min      326.424\n",
      "trainer/Z Policy Predictions Mean     828.511\n",
      "trainer/Z Policy Predictions Std      372.714\n",
      "trainer/Z Policy Predictions Max     1596.68\n",
      "trainer/Z Policy Predictions Min     -365.003\n",
      "trainer/Z Expert Targets Mean        1068.51\n",
      "trainer/Z Expert Targets Std          237.396\n",
      "trainer/Z Expert Targets Max         1575.31\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         833.481\n",
      "trainer/Z Policy Targets Std          375.107\n",
      "trainer/Z Policy Targets Max         1584.55\n",
      "trainer/Z Policy Targets Min         -361.662\n",
      "trainer/Log Pis Mean                   14.4628\n",
      "trainer/Log Pis Std                     4.82657\n",
      "trainer/Policy mu Mean                  0.138501\n",
      "trainer/Policy mu Std                   2.4039\n",
      "trainer/Policy log std Mean            -4.46972\n",
      "trainer/Policy log std Std              1.12501\n",
      "exploration/num steps total        296535\n",
      "exploration/num paths total          1176\n",
      "evaluation/num steps total              2.04039e+06\n",
      "evaluation/num paths total           2960\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.54166\n",
      "evaluation/Rewards Std                  0.597282\n",
      "evaluation/Rewards Max                  4.73105\n",
      "evaluation/Rewards Min                  0.701438\n",
      "evaluation/Returns Mean              3541.66\n",
      "evaluation/Returns Std                  8.94006\n",
      "evaluation/Returns Max               3553.44\n",
      "evaluation/Returns Min               3522.63\n",
      "evaluation/Estimation Bias Mean      1036.41\n",
      "evaluation/Estimation Bias Std        246.278\n",
      "evaluation/EB/Q_True Mean              32.7367\n",
      "evaluation/EB/Q_True Std              100.855\n",
      "evaluation/EB/Q_Pred Mean            1069.15\n",
      "evaluation/EB/Q_Pred Std              221.948\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3541.66\n",
      "evaluation/Actions Mean                 0.0397425\n",
      "evaluation/Actions Std                  0.587354\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85747\n",
      "time/backward_zf1 (s)                   1.98815\n",
      "time/backward_zf2 (s)                   1.92096\n",
      "time/data sampling (s)                  0.242626\n",
      "time/data storing (s)                   0.0134891\n",
      "time/evaluation sampling (s)            1.335\n",
      "time/exploration sampling (s)           0.171332\n",
      "time/logging (s)                        0.0118197\n",
      "time/preback_alpha (s)                  0.55266\n",
      "time/preback_policy (s)                 0.629906\n",
      "time/preback_start (s)                  0.124775\n",
      "time/preback_zf (s)                     4.96992\n",
      "time/saving (s)                         0.0169193\n",
      "time/training (s)                       2.34653\n",
      "time/epoch (s)                         16.1815\n",
      "time/total (s)                       4537.16\n",
      "Epoch                                 289\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:17:12.724238 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 290 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 301000\n",
      "trainer/ZF1 Loss                      134.452\n",
      "trainer/ZF2 Loss                       87.5076\n",
      "trainer/ZF Expert Reward               15.762\n",
      "trainer/ZF Policy Reward                7.69311\n",
      "trainer/ZF CHI2 Term                  132.721\n",
      "trainer/Policy Loss                  -826.228\n",
      "trainer/Policy Grad Norm              823.024\n",
      "trainer/Policy Param Norm              48.4995\n",
      "trainer/Zf1 Grad Norm               95237.2\n",
      "trainer/Zf1 Param Norm                135.508\n",
      "trainer/Zf2 Grad Norm               30364.7\n",
      "trainer/Zf2 Param Norm                131.035\n",
      "trainer/Z Expert Predictions Mean    1102.78\n",
      "trainer/Z Expert Predictions Std      223.508\n",
      "trainer/Z Expert Predictions Max     1640.73\n",
      "trainer/Z Expert Predictions Min      450.679\n",
      "trainer/Z Policy Predictions Mean     818.973\n",
      "trainer/Z Policy Predictions Std      391.832\n",
      "trainer/Z Policy Predictions Max     1512.74\n",
      "trainer/Z Policy Predictions Min     -520.77\n",
      "trainer/Z Expert Targets Mean        1087.01\n",
      "trainer/Z Expert Targets Std          222.252\n",
      "trainer/Z Expert Targets Max         1588.61\n",
      "trainer/Z Expert Targets Min          434.669\n",
      "trainer/Z Policy Targets Mean         811.28\n",
      "trainer/Z Policy Targets Std          392.042\n",
      "trainer/Z Policy Targets Max         1585.11\n",
      "trainer/Z Policy Targets Min         -484.7\n",
      "trainer/Log Pis Mean                   13.8102\n",
      "trainer/Log Pis Std                     4.62514\n",
      "trainer/Policy mu Mean                  0.3179\n",
      "trainer/Policy mu Std                   2.63061\n",
      "trainer/Policy log std Mean            -4.29941\n",
      "trainer/Policy log std Std              1.26129\n",
      "exploration/num steps total        297535\n",
      "exploration/num paths total          1177\n",
      "evaluation/num steps total              2.04814e+06\n",
      "evaluation/num paths total           2971\n",
      "evaluation/path length Mean           704.455\n",
      "evaluation/path length Std            324.33\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 3.50057\n",
      "evaluation/Rewards Std                  0.65151\n",
      "evaluation/Rewards Max                  4.67443\n",
      "evaluation/Rewards Min                  0.762013\n",
      "evaluation/Returns Mean              2465.99\n",
      "evaluation/Returns Std               1184.14\n",
      "evaluation/Returns Max               3589.78\n",
      "evaluation/Returns Min               1106.09\n",
      "evaluation/Estimation Bias Mean       998.303\n",
      "evaluation/Estimation Bias Std        322.651\n",
      "evaluation/EB/Q_True Mean              42.891\n",
      "evaluation/EB/Q_True Std              114.556\n",
      "evaluation/EB/Q_Pred Mean            1041.19\n",
      "evaluation/EB/Q_Pred Std              286.822\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2465.99\n",
      "evaluation/Actions Mean                 0.0386666\n",
      "evaluation/Actions Std                  0.593646\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77682\n",
      "time/backward_zf1 (s)                   1.88118\n",
      "time/backward_zf2 (s)                   1.79906\n",
      "time/data sampling (s)                  0.260271\n",
      "time/data storing (s)                   0.0139707\n",
      "time/evaluation sampling (s)            1.34108\n",
      "time/exploration sampling (s)           0.171166\n",
      "time/logging (s)                        0.00935219\n",
      "time/preback_alpha (s)                  0.561043\n",
      "time/preback_policy (s)                 0.617825\n",
      "time/preback_start (s)                  0.125798\n",
      "time/preback_zf (s)                     5.00921\n",
      "time/saving (s)                         0.00513647\n",
      "time/training (s)                       2.6021\n",
      "time/epoch (s)                         16.174\n",
      "time/total (s)                       4553.35\n",
      "Epoch                                 290\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:17:29.078035 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 291 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 302000\n",
      "trainer/ZF1 Loss                      204.792\n",
      "trainer/ZF2 Loss                      193.54\n",
      "trainer/ZF Expert Reward                6.39913\n",
      "trainer/ZF Policy Reward                4.04453\n",
      "trainer/ZF CHI2 Term                  215.93\n",
      "trainer/Policy Loss                  -825.691\n",
      "trainer/Policy Grad Norm              604.818\n",
      "trainer/Policy Param Norm              48.5601\n",
      "trainer/Zf1 Grad Norm               60835.7\n",
      "trainer/Zf1 Param Norm                135.661\n",
      "trainer/Zf2 Grad Norm               71168\n",
      "trainer/Zf2 Param Norm                131.201\n",
      "trainer/Z Expert Predictions Mean    1108.85\n",
      "trainer/Z Expert Predictions Std      242.43\n",
      "trainer/Z Expert Predictions Max     1569.49\n",
      "trainer/Z Expert Predictions Min      486.231\n",
      "trainer/Z Policy Predictions Mean     820.489\n",
      "trainer/Z Policy Predictions Std      391.535\n",
      "trainer/Z Policy Predictions Max     1587.76\n",
      "trainer/Z Policy Predictions Min     -402.916\n",
      "trainer/Z Expert Targets Mean        1102.45\n",
      "trainer/Z Expert Targets Std          247.089\n",
      "trainer/Z Expert Targets Max         1575.95\n",
      "trainer/Z Expert Targets Min          458.969\n",
      "trainer/Z Policy Targets Mean         816.444\n",
      "trainer/Z Policy Targets Std          394.762\n",
      "trainer/Z Policy Targets Max         1562.08\n",
      "trainer/Z Policy Targets Min         -415.521\n",
      "trainer/Log Pis Mean                   14.5553\n",
      "trainer/Log Pis Std                     5.01118\n",
      "trainer/Policy mu Mean                  0.170101\n",
      "trainer/Policy mu Std                   2.65721\n",
      "trainer/Policy log std Mean            -4.39875\n",
      "trainer/Policy log std Std              1.1142\n",
      "exploration/num steps total        297535\n",
      "exploration/num paths total          1177\n",
      "evaluation/num steps total              2.0578e+06\n",
      "evaluation/num paths total           2983\n",
      "evaluation/path length Mean           805\n",
      "evaluation/path length Std            281.027\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            338\n",
      "evaluation/Rewards Mean                 3.53601\n",
      "evaluation/Rewards Std                  0.633165\n",
      "evaluation/Rewards Max                  4.68013\n",
      "evaluation/Rewards Min                  0.736862\n",
      "evaluation/Returns Mean              2846.49\n",
      "evaluation/Returns Std               1030.66\n",
      "evaluation/Returns Max               3584.78\n",
      "evaluation/Returns Min               1126.2\n",
      "evaluation/Estimation Bias Mean       994.619\n",
      "evaluation/Estimation Bias Std        313.856\n",
      "evaluation/EB/Q_True Mean              34.1349\n",
      "evaluation/EB/Q_True Std              103.202\n",
      "evaluation/EB/Q_Pred Mean            1028.75\n",
      "evaluation/EB/Q_Pred Std              282.216\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2846.49\n",
      "evaluation/Actions Mean                 0.0419978\n",
      "evaluation/Actions Std                  0.593305\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79081\n",
      "time/backward_zf1 (s)                   1.89975\n",
      "time/backward_zf2 (s)                   1.84738\n",
      "time/data sampling (s)                  0.266314\n",
      "time/data storing (s)                   0.0146511\n",
      "time/evaluation sampling (s)            1.44377\n",
      "time/exploration sampling (s)           0.176117\n",
      "time/logging (s)                        0.0115868\n",
      "time/preback_alpha (s)                  0.564961\n",
      "time/preback_policy (s)                 0.635044\n",
      "time/preback_start (s)                  0.126661\n",
      "time/preback_zf (s)                     5.00557\n",
      "time/saving (s)                         0.00536655\n",
      "time/training (s)                       2.50432\n",
      "time/epoch (s)                         16.2923\n",
      "time/total (s)                       4569.66\n",
      "Epoch                                 291\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:17:45.308484 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 292 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 303000\n",
      "trainer/ZF1 Loss                      149.253\n",
      "trainer/ZF2 Loss                      185.477\n",
      "trainer/ZF Expert Reward                8.74323\n",
      "trainer/ZF Policy Reward               -1.74108\n",
      "trainer/ZF CHI2 Term                  191.869\n",
      "trainer/Policy Loss                  -845.11\n",
      "trainer/Policy Grad Norm              610.136\n",
      "trainer/Policy Param Norm              48.618\n",
      "trainer/Zf1 Grad Norm               72825.8\n",
      "trainer/Zf1 Param Norm                135.837\n",
      "trainer/Zf2 Grad Norm               57774.3\n",
      "trainer/Zf2 Param Norm                131.384\n",
      "trainer/Z Expert Predictions Mean    1090.46\n",
      "trainer/Z Expert Predictions Std      237.018\n",
      "trainer/Z Expert Predictions Max     1657.38\n",
      "trainer/Z Expert Predictions Min      382.295\n",
      "trainer/Z Policy Predictions Mean     838.28\n",
      "trainer/Z Policy Predictions Std      409.748\n",
      "trainer/Z Policy Predictions Max     1521.25\n",
      "trainer/Z Policy Predictions Min     -552.394\n",
      "trainer/Z Expert Targets Mean        1081.71\n",
      "trainer/Z Expert Targets Std          243.31\n",
      "trainer/Z Expert Targets Max         1634.96\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         840.021\n",
      "trainer/Z Policy Targets Std          409.66\n",
      "trainer/Z Policy Targets Max         1570.25\n",
      "trainer/Z Policy Targets Min         -567.782\n",
      "trainer/Log Pis Mean                   14.1608\n",
      "trainer/Log Pis Std                     4.57571\n",
      "trainer/Policy mu Mean                  0.0672401\n",
      "trainer/Policy mu Std                   2.6412\n",
      "trainer/Policy log std Mean            -4.42963\n",
      "trainer/Policy log std Std              1.23075\n",
      "exploration/num steps total        298535\n",
      "exploration/num paths total          1178\n",
      "evaluation/num steps total              2.0678e+06\n",
      "evaluation/num paths total           2993\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.5004\n",
      "evaluation/Rewards Std                  0.601275\n",
      "evaluation/Rewards Max                  4.72079\n",
      "evaluation/Rewards Min                  0.761636\n",
      "evaluation/Returns Mean              3500.4\n",
      "evaluation/Returns Std                 21.882\n",
      "evaluation/Returns Max               3526.64\n",
      "evaluation/Returns Min               3450.25\n",
      "evaluation/Estimation Bias Mean      1000.26\n",
      "evaluation/Estimation Bias Std        224.205\n",
      "evaluation/EB/Q_True Mean              32.4161\n",
      "evaluation/EB/Q_True Std               99.8535\n",
      "evaluation/EB/Q_Pred Mean            1032.68\n",
      "evaluation/EB/Q_Pred Std              201.637\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3500.4\n",
      "evaluation/Actions Mean                 0.0408104\n",
      "evaluation/Actions Std                  0.591464\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.81226\n",
      "time/backward_zf1 (s)                   1.93368\n",
      "time/backward_zf2 (s)                   1.86709\n",
      "time/data sampling (s)                  0.257662\n",
      "time/data storing (s)                   0.0134376\n",
      "time/evaluation sampling (s)            1.34101\n",
      "time/exploration sampling (s)           0.16765\n",
      "time/logging (s)                        0.0127158\n",
      "time/preback_alpha (s)                  0.551038\n",
      "time/preback_policy (s)                 0.622635\n",
      "time/preback_start (s)                  0.123851\n",
      "time/preback_zf (s)                     4.95975\n",
      "time/saving (s)                         0.00516952\n",
      "time/training (s)                       2.49955\n",
      "time/epoch (s)                         16.1675\n",
      "time/total (s)                       4585.84\n",
      "Epoch                                 292\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:18:01.412025 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 293 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 304000\n",
      "trainer/ZF1 Loss                       78.5652\n",
      "trainer/ZF2 Loss                       94.7489\n",
      "trainer/ZF Expert Reward               12.0579\n",
      "trainer/ZF Policy Reward               -0.864495\n",
      "trainer/ZF CHI2 Term                  114.616\n",
      "trainer/Policy Loss                  -821.983\n",
      "trainer/Policy Grad Norm              923.911\n",
      "trainer/Policy Param Norm              48.6895\n",
      "trainer/Zf1 Grad Norm              111410\n",
      "trainer/Zf1 Param Norm                135.997\n",
      "trainer/Zf2 Grad Norm              110110\n",
      "trainer/Zf2 Param Norm                131.544\n",
      "trainer/Z Expert Predictions Mean    1117.12\n",
      "trainer/Z Expert Predictions Std      238.385\n",
      "trainer/Z Expert Predictions Max     1622.8\n",
      "trainer/Z Expert Predictions Min      447.306\n",
      "trainer/Z Policy Predictions Mean     814.871\n",
      "trainer/Z Policy Predictions Std      414.145\n",
      "trainer/Z Policy Predictions Max     1589.14\n",
      "trainer/Z Policy Predictions Min     -383.557\n",
      "trainer/Z Expert Targets Mean        1105.06\n",
      "trainer/Z Expert Targets Std          239.405\n",
      "trainer/Z Expert Targets Max         1613.46\n",
      "trainer/Z Expert Targets Min          444.672\n",
      "trainer/Z Policy Targets Mean         815.736\n",
      "trainer/Z Policy Targets Std          411.305\n",
      "trainer/Z Policy Targets Max         1603.84\n",
      "trainer/Z Policy Targets Min         -405.567\n",
      "trainer/Log Pis Mean                   15.1882\n",
      "trainer/Log Pis Std                     5.71893\n",
      "trainer/Policy mu Mean                  0.241303\n",
      "trainer/Policy mu Std                   3.40045\n",
      "trainer/Policy log std Mean            -4.38551\n",
      "trainer/Policy log std Std              1.25587\n",
      "exploration/num steps total        299446\n",
      "exploration/num paths total          1179\n",
      "evaluation/num steps total              2.0778e+06\n",
      "evaluation/num paths total           3003\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.55834\n",
      "evaluation/Rewards Std                  0.596582\n",
      "evaluation/Rewards Max                  4.70366\n",
      "evaluation/Rewards Min                  0.727676\n",
      "evaluation/Returns Mean              3558.34\n",
      "evaluation/Returns Std                 18.5706\n",
      "evaluation/Returns Max               3588.83\n",
      "evaluation/Returns Min               3535.98\n",
      "evaluation/Estimation Bias Mean      1058.37\n",
      "evaluation/Estimation Bias Std        255.546\n",
      "evaluation/EB/Q_True Mean              32.7486\n",
      "evaluation/EB/Q_True Std              101.277\n",
      "evaluation/EB/Q_Pred Mean            1091.12\n",
      "evaluation/EB/Q_Pred Std              235.67\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3558.34\n",
      "evaluation/Actions Mean                 0.0494209\n",
      "evaluation/Actions Std                  0.59061\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74721\n",
      "time/backward_zf1 (s)                   1.84551\n",
      "time/backward_zf2 (s)                   1.78407\n",
      "time/data sampling (s)                  0.255861\n",
      "time/data storing (s)                   0.0134658\n",
      "time/evaluation sampling (s)            1.34551\n",
      "time/exploration sampling (s)           0.167884\n",
      "time/logging (s)                        0.0119511\n",
      "time/preback_alpha (s)                  0.554623\n",
      "time/preback_policy (s)                 0.614659\n",
      "time/preback_start (s)                  0.125519\n",
      "time/preback_zf (s)                     4.98044\n",
      "time/saving (s)                         0.00488304\n",
      "time/training (s)                       2.58471\n",
      "time/epoch (s)                         16.0363\n",
      "time/total (s)                       4601.9\n",
      "Epoch                                 293\n",
      "---------------------------------  ---------------\n",
      "2024-06-08 23:18:17.521980 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 294 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 305000\n",
      "trainer/ZF1 Loss                       81.8082\n",
      "trainer/ZF2 Loss                       81.114\n",
      "trainer/ZF Expert Reward               10.4268\n",
      "trainer/ZF Policy Reward                2.57305\n",
      "trainer/ZF CHI2 Term                  103.59\n",
      "trainer/Policy Loss                  -815.2\n",
      "trainer/Policy Grad Norm              681.612\n",
      "trainer/Policy Param Norm              48.7489\n",
      "trainer/Zf1 Grad Norm               74613.1\n",
      "trainer/Zf1 Param Norm                136.154\n",
      "trainer/Zf2 Grad Norm               80836.9\n",
      "trainer/Zf2 Param Norm                131.702\n",
      "trainer/Z Expert Predictions Mean    1097.9\n",
      "trainer/Z Expert Predictions Std      236.228\n",
      "trainer/Z Expert Predictions Max     1565.82\n",
      "trainer/Z Expert Predictions Min      172.352\n",
      "trainer/Z Policy Predictions Mean     812.693\n",
      "trainer/Z Policy Predictions Std      410.311\n",
      "trainer/Z Policy Predictions Max     1529.77\n",
      "trainer/Z Policy Predictions Min     -541.571\n",
      "trainer/Z Expert Targets Mean        1087.47\n",
      "trainer/Z Expert Targets Std          239.95\n",
      "trainer/Z Expert Targets Max         1616.75\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         810.119\n",
      "trainer/Z Policy Targets Std          410.275\n",
      "trainer/Z Policy Targets Max         1554.37\n",
      "trainer/Z Policy Targets Min         -583.499\n",
      "trainer/Log Pis Mean                   14.4192\n",
      "trainer/Log Pis Std                     5.14159\n",
      "trainer/Policy mu Mean                  0.494027\n",
      "trainer/Policy mu Std                   3.62141\n",
      "trainer/Policy log std Mean            -4.36834\n",
      "trainer/Policy log std Std              1.2617\n",
      "exploration/num steps total        299446\n",
      "exploration/num paths total          1179\n",
      "evaluation/num steps total              2.08678e+06\n",
      "evaluation/num paths total           3014\n",
      "evaluation/path length Mean           816.273\n",
      "evaluation/path length Std            300.476\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            283\n",
      "evaluation/Rewards Mean                 3.52291\n",
      "evaluation/Rewards Std                  0.62139\n",
      "evaluation/Rewards Max                  4.7063\n",
      "evaluation/Rewards Min                  0.749747\n",
      "evaluation/Returns Mean              2875.65\n",
      "evaluation/Returns Std               1101.61\n",
      "evaluation/Returns Max               3578.12\n",
      "evaluation/Returns Min                913.483\n",
      "evaluation/Estimation Bias Mean      1057.92\n",
      "evaluation/Estimation Bias Std        265.41\n",
      "evaluation/EB/Q_True Mean              36.5341\n",
      "evaluation/EB/Q_True Std              106.222\n",
      "evaluation/EB/Q_Pred Mean            1094.46\n",
      "evaluation/EB/Q_Pred Std              232.888\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2875.65\n",
      "evaluation/Actions Mean                 0.0394595\n",
      "evaluation/Actions Std                  0.587538\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8111\n",
      "time/backward_zf1 (s)                   1.92026\n",
      "time/backward_zf2 (s)                   1.85508\n",
      "time/data sampling (s)                  0.244754\n",
      "time/data storing (s)                   0.0134823\n",
      "time/evaluation sampling (s)            1.33685\n",
      "time/exploration sampling (s)           0.166225\n",
      "time/logging (s)                        0.010417\n",
      "time/preback_alpha (s)                  0.550664\n",
      "time/preback_policy (s)                 0.624907\n",
      "time/preback_start (s)                  0.124075\n",
      "time/preback_zf (s)                     4.96164\n",
      "time/saving (s)                         0.00513198\n",
      "time/training (s)                       2.41983\n",
      "time/epoch (s)                         16.0444\n",
      "time/total (s)                       4617.96\n",
      "Epoch                                 294\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:18:33.664439 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 295 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 306000\n",
      "trainer/ZF1 Loss                       67.4164\n",
      "trainer/ZF2 Loss                      113.291\n",
      "trainer/ZF Expert Reward               11.3009\n",
      "trainer/ZF Policy Reward                3.47016\n",
      "trainer/ZF CHI2 Term                  112.682\n",
      "trainer/Policy Loss                  -822.939\n",
      "trainer/Policy Grad Norm              770.564\n",
      "trainer/Policy Param Norm              48.8143\n",
      "trainer/Zf1 Grad Norm              113764\n",
      "trainer/Zf1 Param Norm                136.299\n",
      "trainer/Zf2 Grad Norm              117310\n",
      "trainer/Zf2 Param Norm                131.853\n",
      "trainer/Z Expert Predictions Mean    1133.77\n",
      "trainer/Z Expert Predictions Std      240.111\n",
      "trainer/Z Expert Predictions Max     1591.15\n",
      "trainer/Z Expert Predictions Min      339.912\n",
      "trainer/Z Policy Predictions Mean     825.853\n",
      "trainer/Z Policy Predictions Std      395.612\n",
      "trainer/Z Policy Predictions Max     1506.87\n",
      "trainer/Z Policy Predictions Min     -432.825\n",
      "trainer/Z Expert Targets Mean        1122.47\n",
      "trainer/Z Expert Targets Std          241.353\n",
      "trainer/Z Expert Targets Max         1590.73\n",
      "trainer/Z Expert Targets Min          278.85\n",
      "trainer/Z Policy Targets Mean         822.383\n",
      "trainer/Z Policy Targets Std          393.818\n",
      "trainer/Z Policy Targets Max         1491.05\n",
      "trainer/Z Policy Targets Min         -418.316\n",
      "trainer/Log Pis Mean                   14.6435\n",
      "trainer/Log Pis Std                     5.25531\n",
      "trainer/Policy mu Mean                  0.453382\n",
      "trainer/Policy mu Std                   3.60691\n",
      "trainer/Policy log std Mean            -4.3754\n",
      "trainer/Policy log std Std              1.27609\n",
      "exploration/num steps total        299446\n",
      "exploration/num paths total          1179\n",
      "evaluation/num steps total              2.09678e+06\n",
      "evaluation/num paths total           3024\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.5178\n",
      "evaluation/Rewards Std                  0.60018\n",
      "evaluation/Rewards Max                  4.72285\n",
      "evaluation/Rewards Min                  0.676579\n",
      "evaluation/Returns Mean              3517.8\n",
      "evaluation/Returns Std                 15.2831\n",
      "evaluation/Returns Max               3538.27\n",
      "evaluation/Returns Min               3492.96\n",
      "evaluation/Estimation Bias Mean      1010.13\n",
      "evaluation/Estimation Bias Std        203.621\n",
      "evaluation/EB/Q_True Mean              32.3852\n",
      "evaluation/EB/Q_True Std               99.9292\n",
      "evaluation/EB/Q_Pred Mean            1042.51\n",
      "evaluation/EB/Q_Pred Std              182.455\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3517.8\n",
      "evaluation/Actions Mean                 0.0432778\n",
      "evaluation/Actions Std                  0.586716\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.74109\n",
      "time/backward_zf1 (s)                   1.86468\n",
      "time/backward_zf2 (s)                   1.79163\n",
      "time/data sampling (s)                  0.261468\n",
      "time/data storing (s)                   0.0145861\n",
      "time/evaluation sampling (s)            1.39724\n",
      "time/exploration sampling (s)           0.174842\n",
      "time/logging (s)                        0.0118502\n",
      "time/preback_alpha (s)                  0.554371\n",
      "time/preback_policy (s)                 0.621189\n",
      "time/preback_start (s)                  0.126283\n",
      "time/preback_zf (s)                     4.95848\n",
      "time/saving (s)                         0.00616607\n",
      "time/training (s)                       2.55634\n",
      "time/epoch (s)                         16.0802\n",
      "time/total (s)                       4634.06\n",
      "Epoch                                 295\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:18:49.791774 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 296 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 307000\n",
      "trainer/ZF1 Loss                      114.671\n",
      "trainer/ZF2 Loss                       60.36\n",
      "trainer/ZF Expert Reward               16.8162\n",
      "trainer/ZF Policy Reward                0.0421278\n",
      "trainer/ZF CHI2 Term                  118.647\n",
      "trainer/Policy Loss                  -821.525\n",
      "trainer/Policy Grad Norm              752.397\n",
      "trainer/Policy Param Norm              48.8854\n",
      "trainer/Zf1 Grad Norm              127300\n",
      "trainer/Zf1 Param Norm                136.459\n",
      "trainer/Zf2 Grad Norm               33828.4\n",
      "trainer/Zf2 Param Norm                132.017\n",
      "trainer/Z Expert Predictions Mean    1135.63\n",
      "trainer/Z Expert Predictions Std      235.604\n",
      "trainer/Z Expert Predictions Max     1660.78\n",
      "trainer/Z Expert Predictions Min      400.289\n",
      "trainer/Z Policy Predictions Mean     820.42\n",
      "trainer/Z Policy Predictions Std      409.161\n",
      "trainer/Z Policy Predictions Max     1555.06\n",
      "trainer/Z Policy Predictions Min     -358.004\n",
      "trainer/Z Expert Targets Mean        1118.81\n",
      "trainer/Z Expert Targets Std          234.166\n",
      "trainer/Z Expert Targets Max         1627.9\n",
      "trainer/Z Expert Targets Min          409.439\n",
      "trainer/Z Policy Targets Mean         820.378\n",
      "trainer/Z Policy Targets Std          403.359\n",
      "trainer/Z Policy Targets Max         1533.02\n",
      "trainer/Z Policy Targets Min         -373.571\n",
      "trainer/Log Pis Mean                   14.5023\n",
      "trainer/Log Pis Std                     5.0743\n",
      "trainer/Policy mu Mean                  0.0606365\n",
      "trainer/Policy mu Std                   2.456\n",
      "trainer/Policy log std Mean            -4.40589\n",
      "trainer/Policy log std Std              1.1933\n",
      "exploration/num steps total        301347\n",
      "exploration/num paths total          1181\n",
      "evaluation/num steps total              2.10538e+06\n",
      "evaluation/num paths total           3036\n",
      "evaluation/path length Mean           716.417\n",
      "evaluation/path length Std            336.184\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            281\n",
      "evaluation/Rewards Mean                 3.49285\n",
      "evaluation/Rewards Std                  0.648107\n",
      "evaluation/Rewards Max                  4.87512\n",
      "evaluation/Rewards Min                  0.73761\n",
      "evaluation/Returns Mean              2502.34\n",
      "evaluation/Returns Std               1228.08\n",
      "evaluation/Returns Max               3553.72\n",
      "evaluation/Returns Min                906.056\n",
      "evaluation/Estimation Bias Mean       990.096\n",
      "evaluation/Estimation Bias Std        288.401\n",
      "evaluation/EB/Q_True Mean              37.9647\n",
      "evaluation/EB/Q_True Std              107.456\n",
      "evaluation/EB/Q_Pred Mean            1028.06\n",
      "evaluation/EB/Q_Pred Std              250.764\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2502.34\n",
      "evaluation/Actions Mean                 0.0365187\n",
      "evaluation/Actions Std                  0.583457\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80111\n",
      "time/backward_zf1 (s)                   1.92524\n",
      "time/backward_zf2 (s)                   1.86161\n",
      "time/data sampling (s)                  0.248445\n",
      "time/data storing (s)                   0.0138885\n",
      "time/evaluation sampling (s)            1.36375\n",
      "time/exploration sampling (s)           0.175285\n",
      "time/logging (s)                        0.0104182\n",
      "time/preback_alpha (s)                  0.553337\n",
      "time/preback_policy (s)                 0.630963\n",
      "time/preback_start (s)                  0.126506\n",
      "time/preback_zf (s)                     4.96141\n",
      "time/saving (s)                         0.0051146\n",
      "time/training (s)                       2.38276\n",
      "time/epoch (s)                         16.0598\n",
      "time/total (s)                       4650.14\n",
      "Epoch                                 296\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:19:05.928167 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 297 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 308000\n",
      "trainer/ZF1 Loss                       69.0097\n",
      "trainer/ZF2 Loss                       56.7011\n",
      "trainer/ZF Expert Reward                8.51533\n",
      "trainer/ZF Policy Reward               -8.34449\n",
      "trainer/ZF CHI2 Term                   93.6023\n",
      "trainer/Policy Loss                  -825.328\n",
      "trainer/Policy Grad Norm              769.851\n",
      "trainer/Policy Param Norm              48.9459\n",
      "trainer/Zf1 Grad Norm               99280.2\n",
      "trainer/Zf1 Param Norm                136.601\n",
      "trainer/Zf2 Grad Norm               86605.7\n",
      "trainer/Zf2 Param Norm                132.174\n",
      "trainer/Z Expert Predictions Mean    1075.31\n",
      "trainer/Z Expert Predictions Std      224.371\n",
      "trainer/Z Expert Predictions Max     1609.6\n",
      "trainer/Z Expert Predictions Min      181.556\n",
      "trainer/Z Policy Predictions Mean     817.255\n",
      "trainer/Z Policy Predictions Std      383.29\n",
      "trainer/Z Policy Predictions Max     1483.68\n",
      "trainer/Z Policy Predictions Min     -385.138\n",
      "trainer/Z Expert Targets Mean        1066.8\n",
      "trainer/Z Expert Targets Std          229.467\n",
      "trainer/Z Expert Targets Max         1585.98\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         825.599\n",
      "trainer/Z Policy Targets Std          380.864\n",
      "trainer/Z Policy Targets Max         1493.31\n",
      "trainer/Z Policy Targets Min         -366.087\n",
      "trainer/Log Pis Mean                   14.0273\n",
      "trainer/Log Pis Std                     4.82405\n",
      "trainer/Policy mu Mean                  0.305327\n",
      "trainer/Policy mu Std                   2.51058\n",
      "trainer/Policy log std Mean            -4.44173\n",
      "trainer/Policy log std Std              1.10933\n",
      "exploration/num steps total        302347\n",
      "exploration/num paths total          1182\n",
      "evaluation/num steps total              2.11406e+06\n",
      "evaluation/num paths total           3046\n",
      "evaluation/path length Mean           868.4\n",
      "evaluation/path length Std            263.224\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            334\n",
      "evaluation/Rewards Mean                 3.53473\n",
      "evaluation/Rewards Std                  0.623599\n",
      "evaluation/Rewards Max                  4.66374\n",
      "evaluation/Rewards Min                  0.697002\n",
      "evaluation/Returns Mean              3069.56\n",
      "evaluation/Returns Std                964.989\n",
      "evaluation/Returns Max               3581.64\n",
      "evaluation/Returns Min               1111.75\n",
      "evaluation/Estimation Bias Mean      1030.82\n",
      "evaluation/Estimation Bias Std        292.441\n",
      "evaluation/EB/Q_True Mean              37.4472\n",
      "evaluation/EB/Q_True Std              106.606\n",
      "evaluation/EB/Q_Pred Mean            1068.27\n",
      "evaluation/EB/Q_Pred Std              252.774\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3069.56\n",
      "evaluation/Actions Mean                 0.0504264\n",
      "evaluation/Actions Std                  0.593156\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73841\n",
      "time/backward_zf1 (s)                   1.85196\n",
      "time/backward_zf2 (s)                   1.77719\n",
      "time/data sampling (s)                  0.266588\n",
      "time/data storing (s)                   0.0135623\n",
      "time/evaluation sampling (s)            1.3625\n",
      "time/exploration sampling (s)           0.168351\n",
      "time/logging (s)                        0.0222827\n",
      "time/preback_alpha (s)                  0.558637\n",
      "time/preback_policy (s)                 0.61848\n",
      "time/preback_start (s)                  0.125257\n",
      "time/preback_zf (s)                     4.97174\n",
      "time/saving (s)                         0.0238339\n",
      "time/training (s)                       2.58537\n",
      "time/epoch (s)                         16.0842\n",
      "time/total (s)                       4666.24\n",
      "Epoch                                 297\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:19:22.071115 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 298 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 309000\n",
      "trainer/ZF1 Loss                      216.312\n",
      "trainer/ZF2 Loss                      239.489\n",
      "trainer/ZF Expert Reward               12.793\n",
      "trainer/ZF Policy Reward                7.06942\n",
      "trainer/ZF CHI2 Term                  247.369\n",
      "trainer/Policy Loss                  -875.328\n",
      "trainer/Policy Grad Norm              796.93\n",
      "trainer/Policy Param Norm              49.0128\n",
      "trainer/Zf1 Grad Norm               82837.1\n",
      "trainer/Zf1 Param Norm                136.749\n",
      "trainer/Zf2 Grad Norm               75828.2\n",
      "trainer/Zf2 Param Norm                132.328\n",
      "trainer/Z Expert Predictions Mean    1115.29\n",
      "trainer/Z Expert Predictions Std      229.989\n",
      "trainer/Z Expert Predictions Max     1590.07\n",
      "trainer/Z Expert Predictions Min      198.895\n",
      "trainer/Z Policy Predictions Mean     872.597\n",
      "trainer/Z Policy Predictions Std      384.409\n",
      "trainer/Z Policy Predictions Max     1619.87\n",
      "trainer/Z Policy Predictions Min     -451.375\n",
      "trainer/Z Expert Targets Mean        1102.5\n",
      "trainer/Z Expert Targets Std          236.349\n",
      "trainer/Z Expert Targets Max         1601.77\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         865.528\n",
      "trainer/Z Policy Targets Std          386.71\n",
      "trainer/Z Policy Targets Max         1610.83\n",
      "trainer/Z Policy Targets Min         -458.88\n",
      "trainer/Log Pis Mean                   13.8842\n",
      "trainer/Log Pis Std                     4.46818\n",
      "trainer/Policy mu Mean                  0.129869\n",
      "trainer/Policy mu Std                   2.37522\n",
      "trainer/Policy log std Mean            -4.39012\n",
      "trainer/Policy log std Std              1.17759\n",
      "exploration/num steps total        303347\n",
      "exploration/num paths total          1183\n",
      "evaluation/num steps total              2.12406e+06\n",
      "evaluation/num paths total           3056\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.53981\n",
      "evaluation/Rewards Std                  0.584454\n",
      "evaluation/Rewards Max                  4.71567\n",
      "evaluation/Rewards Min                  0.683509\n",
      "evaluation/Returns Mean              3539.81\n",
      "evaluation/Returns Std                 15.1387\n",
      "evaluation/Returns Max               3568.27\n",
      "evaluation/Returns Min               3522.28\n",
      "evaluation/Estimation Bias Mean      1074.86\n",
      "evaluation/Estimation Bias Std        229.045\n",
      "evaluation/EB/Q_True Mean              33.0326\n",
      "evaluation/EB/Q_True Std              101.866\n",
      "evaluation/EB/Q_Pred Mean            1107.89\n",
      "evaluation/EB/Q_Pred Std              207.462\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3539.81\n",
      "evaluation/Actions Mean                 0.030312\n",
      "evaluation/Actions Std                  0.579307\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79696\n",
      "time/backward_zf1 (s)                   1.91839\n",
      "time/backward_zf2 (s)                   1.84619\n",
      "time/data sampling (s)                  0.265564\n",
      "time/data storing (s)                   0.0137013\n",
      "time/evaluation sampling (s)            1.39476\n",
      "time/exploration sampling (s)           0.169837\n",
      "time/logging (s)                        0.0118943\n",
      "time/preback_alpha (s)                  0.553274\n",
      "time/preback_policy (s)                 0.626477\n",
      "time/preback_start (s)                  0.124387\n",
      "time/preback_zf (s)                     4.94656\n",
      "time/saving (s)                         0.00544606\n",
      "time/training (s)                       2.39237\n",
      "time/epoch (s)                         16.0658\n",
      "time/total (s)                       4682.33\n",
      "Epoch                                 298\n",
      "---------------------------------  ----------------\n",
      "2024-06-08 23:19:38.416799 +0330 | [idsac_hopper_normal-iqn-neutral_2024_06_08_22_01_08_0000--s-1] Epoch 299 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 310000\n",
      "trainer/ZF1 Loss                      128.821\n",
      "trainer/ZF2 Loss                      142.334\n",
      "trainer/ZF Expert Reward                7.52597\n",
      "trainer/ZF Policy Reward               -0.382779\n",
      "trainer/ZF CHI2 Term                  157.782\n",
      "trainer/Policy Loss                  -843.381\n",
      "trainer/Policy Grad Norm              989.897\n",
      "trainer/Policy Param Norm              49.0742\n",
      "trainer/Zf1 Grad Norm               83667.5\n",
      "trainer/Zf1 Param Norm                136.887\n",
      "trainer/Zf2 Grad Norm              154845\n",
      "trainer/Zf2 Param Norm                132.484\n",
      "trainer/Z Expert Predictions Mean    1103.87\n",
      "trainer/Z Expert Predictions Std      229.034\n",
      "trainer/Z Expert Predictions Max     1694.47\n",
      "trainer/Z Expert Predictions Min      108.679\n",
      "trainer/Z Policy Predictions Mean     842.132\n",
      "trainer/Z Policy Predictions Std      359.291\n",
      "trainer/Z Policy Predictions Max     1499.8\n",
      "trainer/Z Policy Predictions Min     -312.05\n",
      "trainer/Z Expert Targets Mean        1096.34\n",
      "trainer/Z Expert Targets Std          231.068\n",
      "trainer/Z Expert Targets Max         1671.78\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         842.514\n",
      "trainer/Z Policy Targets Std          361.127\n",
      "trainer/Z Policy Targets Max         1492.4\n",
      "trainer/Z Policy Targets Min         -304.541\n",
      "trainer/Log Pis Mean                   14.4399\n",
      "trainer/Log Pis Std                     4.88083\n",
      "trainer/Policy mu Mean                  0.28109\n",
      "trainer/Policy mu Std                   2.71287\n",
      "trainer/Policy log std Mean            -4.41661\n",
      "trainer/Policy log std Std              1.20782\n",
      "exploration/num steps total        306347\n",
      "exploration/num paths total          1186\n",
      "evaluation/num steps total              2.13114e+06\n",
      "evaluation/num paths total           3068\n",
      "evaluation/path length Mean           589.917\n",
      "evaluation/path length Std            303.044\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            281\n",
      "evaluation/Rewards Mean                 3.46659\n",
      "evaluation/Rewards Std                  0.693776\n",
      "evaluation/Rewards Max                  4.92936\n",
      "evaluation/Rewards Min                  0.697485\n",
      "evaluation/Returns Mean              2045\n",
      "evaluation/Returns Std               1106.37\n",
      "evaluation/Returns Max               3561.83\n",
      "evaluation/Returns Min                905.979\n",
      "evaluation/Estimation Bias Mean       986.952\n",
      "evaluation/Estimation Bias Std        368.625\n",
      "evaluation/EB/Q_True Mean              46.3153\n",
      "evaluation/EB/Q_True Std              117.581\n",
      "evaluation/EB/Q_Pred Mean            1033.27\n",
      "evaluation/EB/Q_Pred Std              334.236\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2045\n",
      "evaluation/Actions Mean                 0.0450818\n",
      "evaluation/Actions Std                  0.593274\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82685\n",
      "time/backward_zf1 (s)                   1.94521\n",
      "time/backward_zf2 (s)                   1.86734\n",
      "time/data sampling (s)                  0.264955\n",
      "time/data storing (s)                   0.0139262\n",
      "time/evaluation sampling (s)            1.38721\n",
      "time/exploration sampling (s)           0.178202\n",
      "time/logging (s)                        0.00859869\n",
      "time/preback_alpha (s)                  0.567331\n",
      "time/preback_policy (s)                 0.647154\n",
      "time/preback_start (s)                  0.128841\n",
      "time/preback_zf (s)                     4.98812\n",
      "time/saving (s)                         0.0048633\n",
      "time/training (s)                       2.44887\n",
      "time/epoch (s)                         16.2775\n",
      "time/total (s)                       4698.62\n",
      "Epoch                                 299\n",
      "---------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    experiment(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6679a-5037-44ff-a459-897c0ee8c8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

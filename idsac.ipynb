{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd095125-6be1-4c22-8760-d1fba60ab86d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## experiment (tqc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603bc9d-5ced-4410-9d8b-bc74345fd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_tqc(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant['layer_size']\n",
    "    num_quantiles = variant['num_quantiles']\n",
    "    n_nets = variant['n_nets']\n",
    "    \n",
    "    zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    target_zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = TruncIDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        zf=zf,\n",
    "        target_zf=target_zf,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b40f96-5af4-4fc9-8f5d-34bacdc440d8",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df783e4e-ddf6-45d9-8b26-6863e89107f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.data_management.torch_replay_buffer import TorchReplayBuffer\n",
    "from rlkit.envs import make_env\n",
    "from rlkit.envs.vecenv import SubprocVectorEnv, VectorEnv\n",
    "from rlkit.launchers.launcher_util import set_seed, setup_logger\n",
    "from rlkit.samplers.data_collector import (VecMdpPathCollector, VecMdpStepCollector)\n",
    "from rlkit.torch.idsac.idsac import IDSACTrainer\n",
    "from rlkit.torch.idsac.networks import QuantileMlp, Critic, softmax\n",
    "from rlkit.torch.networks import FlattenMlp\n",
    "from rlkit.torch.sac.policies import MakeDeterministic, TanhGaussianPolicy\n",
    "from rlkit.torch.torch_iq_algorithm import TorchVecOnlineIQAlgorithm\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba84c8-f8f8-4272-8885-83a6c028ee37",
   "metadata": {},
   "source": [
    "# experiment (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c847e24-53fa-4f9b-850b-c7b648d30304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant[\"layer_size\"]\n",
    "    num_quantiles = variant[\"num_quantiles\"]\n",
    "    tau_type = variant[\"trainer_kwargs\"][\"tau_type\"]\n",
    "    \n",
    "    zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M // 2],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    target_policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M // 2],\n",
    "    )\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "        zf1,\n",
    "        tau_type,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = IDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        target_policy=target_policy,\n",
    "        zf1=zf1,\n",
    "        zf2=zf2,\n",
    "        target_zf1=target_zf1,\n",
    "        target_zf2=target_zf2,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e380543-9ff2-4947-8cda-2f5b05957627",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fa2c3c-ae22-4830-bad1-8b99032cb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(dsac_cfg_path,\n",
    "               expert_path,\n",
    "               iq_cfg_path='configs/dsac-normal-iqn-neutral/iq.yaml',\n",
    "               cql_cfg_path='configs/dsac-normal-iqn-neutral/cql.yaml'\n",
    "              ):\n",
    "    \n",
    "    with open(dsac_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        variant = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    with open(iq_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        iq_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    with open(cql_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        cql_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    iq_cfg['expert_path'] = expert_path\n",
    "    variant['iq_kwargs'] = iq_cfg\n",
    "    variant['cql_kwargs'] = cql_cfg\n",
    "    return variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40faac3-2a8c-49fc-bece-f891df61d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = get_config(dsac_cfg_path='configs/dsac-normal-iqn-neutral/ant.yaml',\n",
    "                     expert_path='experts/Ant-v2_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00203431-e8bc-4e42-977f-298ec40d51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15 10:52:07.220931 +0330 | Variant:\n",
      "2024-06-15 10:52:07.222854 +0330 | {\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"min_num_steps_before_training\": 10000,\n",
      "    \"num_epochs\": 300,\n",
      "    \"num_eval_paths_per_epoch\": 10,\n",
      "    \"num_expl_steps_per_train_loop\": 1000,\n",
      "    \"num_trains_per_train_loop\": 1000\n",
      "  },\n",
      "  \"env\": \"Ant-v2\",\n",
      "  \"seed\": 2,\n",
      "  \"expectation_z\": false,\n",
      "  \"eval_env_num\": 10,\n",
      "  \"expl_env_num\": 10,\n",
      "  \"layer_size\": 256,\n",
      "  \"num_quantiles\": 24,\n",
      "  \"replay_buffer_size\": 1000000,\n",
      "  \"trainer_kwargs\": {\n",
      "    \"alpha\": 0.01,\n",
      "    \"discount\": 0.99,\n",
      "    \"policy_lr\": 7.5e-05,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"tau_type\": \"iqn\",\n",
      "    \"target_entropy\": -20.0,\n",
      "    \"use_automatic_entropy_tuning\": true,\n",
      "    \"zf_lr\": 0.0003,\n",
      "    \"bias\": 10,\n",
      "    \"bias_lr\": 0.0001,\n",
      "    \"use_automatic_bias_tuning\": true\n",
      "  },\n",
      "  \"version\": \"normal-iqn-neutral\",\n",
      "  \"iq_kwargs\": {\n",
      "    \"expert_path\": \"experts/Ant-v2_25.pkl\",\n",
      "    \"subsample_freq\": 1,\n",
      "    \"demos\": 10,\n",
      "    \"regularize\": true,\n",
      "    \"div\": null,\n",
      "    \"loss\": \"value_policy\",\n",
      "    \"alpha\": 2.5\n",
      "  },\n",
      "  \"cql_kwargs\": {\n",
      "    \"use_cql\": false,\n",
      "    \"cql_weight\": 0.05,\n",
      "    \"num_random\": 10,\n",
      "    \"with_lagrange\": false,\n",
      "    \"lagrange_thresh\": 10.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    ptu.set_gpu_mode(True, 0)\n",
    "    # device = torch.device('cuda:0')\n",
    "seed = variant[\"seed\"]\n",
    "set_seed(seed)\n",
    "log_prefix = \"_\".join([\"idsac\", variant[\"env\"][:-3].lower(), str(variant[\"version\"])])\n",
    "setup_logger(log_prefix, variant=variant, seed=seed)\n",
    "variant[\"device\"] = ptu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9e0ac-93fd-4003-bfd1-29f851badba5",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa21b2b4-9bf0-4965-91a7-ff8ca706fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddie/venvs/IQ/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15 10:52:28.567194 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 0 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 11000\n",
      "trainer/ZF1 Loss                      10.3674\n",
      "trainer/ZF2 Loss                       9.48463\n",
      "trainer/ZF Expert Reward               0.274076\n",
      "trainer/ZF Policy Reward               0.102778\n",
      "trainer/ZF CHI2 Term                   4.80357\n",
      "trainer/Policy Loss                    0.214976\n",
      "trainer/Bias Loss                     47.3247\n",
      "trainer/Bias Value                     9.9999\n",
      "trainer/Policy Grad Norm               0.0487117\n",
      "trainer/Policy Param Norm             14.6356\n",
      "trainer/Zf1 Grad Norm                 23.5424\n",
      "trainer/Zf1 Param Norm                32.0261\n",
      "trainer/Zf2 Grad Norm                 14.4092\n",
      "trainer/Zf2 Param Norm                32.0359\n",
      "trainer/Z Expert Predictions Mean      0.201803\n",
      "trainer/Z Expert Predictions Std       0.156653\n",
      "trainer/Z Expert Predictions Max       0.626574\n",
      "trainer/Z Expert Predictions Min      -0.413808\n",
      "trainer/Z Policy Predictions Mean      0.0504234\n",
      "trainer/Z Policy Predictions Std       0.20858\n",
      "trainer/Z Policy Predictions Max       0.779348\n",
      "trainer/Z Policy Predictions Min      -0.669486\n",
      "trainer/Z Expert Targets Mean         -0.072273\n",
      "trainer/Z Expert Targets Std           0.180103\n",
      "trainer/Z Expert Targets Max           0.469873\n",
      "trainer/Z Expert Targets Min          -0.853705\n",
      "trainer/Z Policy Targets Mean         -0.0523545\n",
      "trainer/Z Policy Targets Std           0.22645\n",
      "trainer/Z Policy Targets Max           0.644936\n",
      "trainer/Z Policy Targets Min          -0.901204\n",
      "trainer/Log Pis Mean                  -5.34723\n",
      "trainer/Log Pis Std                    0.626019\n",
      "trainer/Policy mu Mean                -0.000912891\n",
      "trainer/Policy mu Std                  0.00094547\n",
      "trainer/Policy log std Mean           -6.2155e-05\n",
      "trainer/Policy log std Std             0.000844134\n",
      "trainer/Alpha                          0.00999925\n",
      "trainer/Alpha Loss                     0.253472\n",
      "exploration/num steps total         5776\n",
      "exploration/num paths total           63\n",
      "evaluation/num steps total           625\n",
      "evaluation/num paths total            10\n",
      "evaluation/path length Mean           62.5\n",
      "evaluation/path length Std            50.0045\n",
      "evaluation/path length Max           155\n",
      "evaluation/path length Min            13\n",
      "evaluation/Rewards Mean               -0.72163\n",
      "evaluation/Rewards Std                 0.897838\n",
      "evaluation/Rewards Max                 1.80722\n",
      "evaluation/Rewards Min                -3.92185\n",
      "evaluation/Returns Mean              -45.1019\n",
      "evaluation/Returns Std                39.1418\n",
      "evaluation/Returns Max                -7.88887\n",
      "evaluation/Returns Min              -137.528\n",
      "evaluation/Estimation Bias Mean       12.6974\n",
      "evaluation/Estimation Bias Std        42.1523\n",
      "evaluation/EB/Q_True Mean             -8.5183\n",
      "evaluation/EB/Q_True Std              17.2181\n",
      "evaluation/EB/Q_Pred Mean              4.17914\n",
      "evaluation/EB/Q_Pred Std              38.9111\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           -45.1019\n",
      "evaluation/Actions Mean                0.0826209\n",
      "evaluation/Actions Std                 0.740805\n",
      "evaluation/Actions Max                 0.999794\n",
      "evaluation/Actions Min                -0.9999\n",
      "time/backward_policy (s)               1.67637\n",
      "time/backward_zf1 (s)                  1.78134\n",
      "time/backward_zf2 (s)                  1.71921\n",
      "time/data sampling (s)                 0.205053\n",
      "time/data storing (s)                  0.0136541\n",
      "time/evaluation sampling (s)           0.776319\n",
      "time/exploration sampling (s)          0.656744\n",
      "time/logging (s)                       0.00208258\n",
      "time/preback_alpha (s)                 0.865434\n",
      "time/preback_policy (s)                0.933696\n",
      "time/preback_start (s)                 0.136012\n",
      "time/preback_zf (s)                    5.05359\n",
      "time/saving (s)                        0.0051348\n",
      "time/training (s)                      2.42098\n",
      "time/epoch (s)                        16.2456\n",
      "time/total (s)                        21.9221\n",
      "Epoch                                  0\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 10:52:46.262668 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 1 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 12000\n",
      "trainer/ZF1 Loss                     -34.8616\n",
      "trainer/ZF2 Loss                     -35.1851\n",
      "trainer/ZF Expert Reward              15.2734\n",
      "trainer/ZF Policy Reward              -9.82686\n",
      "trainer/ZF CHI2 Term                   7.12799\n",
      "trainer/Policy Loss                   41.3724\n",
      "trainer/Bias Loss                     18.7832\n",
      "trainer/Bias Value                    10.0693\n",
      "trainer/Policy Grad Norm               2.38321\n",
      "trainer/Policy Param Norm             16.0627\n",
      "trainer/Zf1 Grad Norm                 28.3572\n",
      "trainer/Zf1 Param Norm                34.3846\n",
      "trainer/Zf2 Grad Norm                 32.7085\n",
      "trainer/Zf2 Param Norm                34.574\n",
      "trainer/Z Expert Predictions Mean     63.9499\n",
      "trainer/Z Expert Predictions Std       1.29566\n",
      "trainer/Z Expert Predictions Max      64.1043\n",
      "trainer/Z Expert Predictions Min      37.9775\n",
      "trainer/Z Policy Predictions Mean    -44.1122\n",
      "trainer/Z Policy Predictions Std       6.55373\n",
      "trainer/Z Policy Predictions Max      21.656\n",
      "trainer/Z Policy Predictions Min     -46.1691\n",
      "trainer/Z Expert Targets Mean         48.6764\n",
      "trainer/Z Expert Targets Std           3.2988\n",
      "trainer/Z Expert Targets Max          49.1777\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        -34.2854\n",
      "trainer/Z Policy Targets Std           8.71879\n",
      "trainer/Z Policy Targets Max          40.1159\n",
      "trainer/Z Policy Targets Min         -37.0781\n",
      "trainer/Log Pis Mean                  17.2233\n",
      "trainer/Log Pis Std                   10.0556\n",
      "trainer/Policy mu Mean                 0.0910266\n",
      "trainer/Policy mu Std                  1.67605\n",
      "trainer/Policy log std Mean           -1.83658\n",
      "trainer/Policy log std Std             0.775184\n",
      "trainer/Alpha                          0.00949165\n",
      "trainer/Alpha Loss                     0.0263563\n",
      "exploration/num steps total         8161\n",
      "exploration/num paths total           68\n",
      "evaluation/num steps total         10625\n",
      "evaluation/num paths total            20\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                0.713721\n",
      "evaluation/Rewards Std                 0.316858\n",
      "evaluation/Rewards Max                 3.8753\n",
      "evaluation/Rewards Min                -3.29473\n",
      "evaluation/Returns Mean              713.721\n",
      "evaluation/Returns Std                24.4995\n",
      "evaluation/Returns Max               780.527\n",
      "evaluation/Returns Min               684.799\n",
      "evaluation/Estimation Bias Mean      -41.9613\n",
      "evaluation/Estimation Bias Std        36.2238\n",
      "evaluation/EB/Q_True Mean              6.38301\n",
      "evaluation/EB/Q_True Std              19.6584\n",
      "evaluation/EB/Q_Pred Mean            -35.5783\n",
      "evaluation/EB/Q_Pred Std              29.0665\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           713.721\n",
      "evaluation/Actions Mean                0.100588\n",
      "evaluation/Actions Std                 0.26919\n",
      "evaluation/Actions Max                 0.999649\n",
      "evaluation/Actions Min                -0.997764\n",
      "time/backward_policy (s)               1.85708\n",
      "time/backward_zf1 (s)                  1.95865\n",
      "time/backward_zf2 (s)                  1.90759\n",
      "time/data sampling (s)                 0.235596\n",
      "time/data storing (s)                  0.0138503\n",
      "time/evaluation sampling (s)           1.83435\n",
      "time/exploration sampling (s)          0.342243\n",
      "time/logging (s)                       0.0117935\n",
      "time/preback_alpha (s)                 0.979177\n",
      "time/preback_policy (s)                1.11315\n",
      "time/preback_start (s)                 0.139582\n",
      "time/preback_zf (s)                    5.10295\n",
      "time/saving (s)                        0.00577266\n",
      "time/training (s)                      2.1383\n",
      "time/epoch (s)                        17.6401\n",
      "time/total (s)                        39.5827\n",
      "Epoch                                  1\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:53:04.455591 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 2 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 13000\n",
      "trainer/ZF1 Loss                     -33.9972\n",
      "trainer/ZF2 Loss                     -34.4698\n",
      "trainer/ZF Expert Reward              17.5148\n",
      "trainer/ZF Policy Reward              -9.54993\n",
      "trainer/ZF CHI2 Term                  13.9857\n",
      "trainer/Policy Loss                   54.0889\n",
      "trainer/Bias Loss                     29.7744\n",
      "trainer/Bias Value                    10.2049\n",
      "trainer/Policy Grad Norm              11.946\n",
      "trainer/Policy Param Norm             16.9298\n",
      "trainer/Zf1 Grad Norm                151.749\n",
      "trainer/Zf1 Param Norm                37.2171\n",
      "trainer/Zf2 Grad Norm                139.011\n",
      "trainer/Zf2 Param Norm                37.4091\n",
      "trainer/Z Expert Predictions Mean    138.714\n",
      "trainer/Z Expert Predictions Std       4.79861\n",
      "trainer/Z Expert Predictions Max     139.731\n",
      "trainer/Z Expert Predictions Min      93.989\n",
      "trainer/Z Policy Predictions Mean    -62.289\n",
      "trainer/Z Policy Predictions Std      33.7446\n",
      "trainer/Z Policy Predictions Max     130.264\n",
      "trainer/Z Policy Predictions Min     -88.1546\n",
      "trainer/Z Expert Targets Mean        121.199\n",
      "trainer/Z Expert Targets Std           3.41643\n",
      "trainer/Z Expert Targets Max         121.998\n",
      "trainer/Z Expert Targets Min          76.6972\n",
      "trainer/Z Policy Targets Mean        -52.7391\n",
      "trainer/Z Policy Targets Std          34.7861\n",
      "trainer/Z Policy Targets Max         118.374\n",
      "trainer/Z Policy Targets Min         -79.0858\n",
      "trainer/Log Pis Mean                  21.3682\n",
      "trainer/Log Pis Std                   11.7989\n",
      "trainer/Policy mu Mean                 0.145744\n",
      "trainer/Policy mu Std                  1.40136\n",
      "trainer/Policy log std Mean           -2.86745\n",
      "trainer/Policy log std Std             0.7913\n",
      "trainer/Alpha                          0.00967257\n",
      "trainer/Alpha Loss                    -0.0132339\n",
      "exploration/num steps total         9188\n",
      "exploration/num paths total           70\n",
      "evaluation/num steps total         20625\n",
      "evaluation/num paths total            30\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                0.00546099\n",
      "evaluation/Rewards Std                 0.180497\n",
      "evaluation/Rewards Max                 2.03102\n",
      "evaluation/Rewards Min                -2.92086\n",
      "evaluation/Returns Mean                5.46099\n",
      "evaluation/Returns Std                75.6397\n",
      "evaluation/Returns Max                91.0662\n",
      "evaluation/Returns Min              -178.568\n",
      "evaluation/Estimation Bias Mean      113.038\n",
      "evaluation/Estimation Bias Std         8.57344\n",
      "evaluation/EB/Q_True Mean              0.0512266\n",
      "evaluation/EB/Q_True Std               0.802877\n",
      "evaluation/EB/Q_Pred Mean            113.09\n",
      "evaluation/EB/Q_Pred Std               8.55653\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns             5.46099\n",
      "evaluation/Actions Mean                0.130114\n",
      "evaluation/Actions Std                 0.483808\n",
      "evaluation/Actions Max                 0.99924\n",
      "evaluation/Actions Min                -0.999199\n",
      "time/backward_policy (s)               1.90114\n",
      "time/backward_zf1 (s)                  2.04039\n",
      "time/backward_zf2 (s)                  1.99077\n",
      "time/data sampling (s)                 0.261015\n",
      "time/data storing (s)                  0.0157036\n",
      "time/evaluation sampling (s)           1.75493\n",
      "time/exploration sampling (s)          0.374384\n",
      "time/logging (s)                       0.0114843\n",
      "time/preback_alpha (s)                 0.971512\n",
      "time/preback_policy (s)                1.12182\n",
      "time/preback_start (s)                 0.145371\n",
      "time/preback_zf (s)                    5.18726\n",
      "time/saving (s)                        0.0057682\n",
      "time/training (s)                      2.34471\n",
      "time/epoch (s)                        18.1263\n",
      "time/total (s)                        57.728\n",
      "Epoch                                  2\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:53:20.156364 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 3 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 14000\n",
      "trainer/ZF1 Loss                     -24.9676\n",
      "trainer/ZF2 Loss                     -26.4204\n",
      "trainer/ZF Expert Reward              18.7557\n",
      "trainer/ZF Policy Reward              -8.81573\n",
      "trainer/ZF CHI2 Term                  19.9794\n",
      "trainer/Policy Loss                   44.1717\n",
      "trainer/Bias Loss                     37.7499\n",
      "trainer/Bias Value                    10.3237\n",
      "trainer/Policy Grad Norm              21.6154\n",
      "trainer/Policy Param Norm             17.5771\n",
      "trainer/Zf1 Grad Norm                197.499\n",
      "trainer/Zf1 Param Norm                40.0288\n",
      "trainer/Zf2 Grad Norm                208.906\n",
      "trainer/Zf2 Param Norm                40.1702\n",
      "trainer/Z Expert Predictions Mean    218.451\n",
      "trainer/Z Expert Predictions Std       5.88909\n",
      "trainer/Z Expert Predictions Max     220.213\n",
      "trainer/Z Expert Predictions Min     155.011\n",
      "trainer/Z Policy Predictions Mean    -57.9918\n",
      "trainer/Z Policy Predictions Std      70.5957\n",
      "trainer/Z Policy Predictions Max     173.238\n",
      "trainer/Z Policy Predictions Min    -128.166\n",
      "trainer/Z Expert Targets Mean        199.696\n",
      "trainer/Z Expert Targets Std           5.51918\n",
      "trainer/Z Expert Targets Max         201.54\n",
      "trainer/Z Expert Targets Min         136.273\n",
      "trainer/Z Policy Targets Mean        -49.1761\n",
      "trainer/Z Policy Targets Std          71.0042\n",
      "trainer/Z Policy Targets Max         186.019\n",
      "trainer/Z Policy Targets Min        -119.874\n",
      "trainer/Log Pis Mean                  18.2849\n",
      "trainer/Log Pis Std                    7.12201\n",
      "trainer/Policy mu Mean                 0.209328\n",
      "trainer/Policy mu Std                  1.40956\n",
      "trainer/Policy log std Mean           -2.52389\n",
      "trainer/Policy log std Std             0.750766\n",
      "trainer/Alpha                          0.00961847\n",
      "trainer/Alpha Loss                     0.0164976\n",
      "exploration/num steps total        11715\n",
      "exploration/num paths total           75\n",
      "evaluation/num steps total         21176\n",
      "evaluation/num paths total            40\n",
      "evaluation/path length Mean           55.1\n",
      "evaluation/path length Std            36.4731\n",
      "evaluation/path length Max           117\n",
      "evaluation/path length Min             9\n",
      "evaluation/Rewards Mean                0.895713\n",
      "evaluation/Rewards Std                 1.00907\n",
      "evaluation/Rewards Max                 3.33762\n",
      "evaluation/Rewards Min                -2.08169\n",
      "evaluation/Returns Mean               49.3538\n",
      "evaluation/Returns Std                42.4935\n",
      "evaluation/Returns Max               134.086\n",
      "evaluation/Returns Min                 2.77537\n",
      "evaluation/Estimation Bias Mean      170.571\n",
      "evaluation/Estimation Bias Std        61.8077\n",
      "evaluation/EB/Q_True Mean             10.7123\n",
      "evaluation/EB/Q_True Std              23.3414\n",
      "evaluation/EB/Q_Pred Mean            181.283\n",
      "evaluation/EB/Q_Pred Std              53.7878\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            49.3538\n",
      "evaluation/Actions Mean                0.0581335\n",
      "evaluation/Actions Std                 0.542768\n",
      "evaluation/Actions Max                 0.97354\n",
      "evaluation/Actions Min                -0.999544\n",
      "time/backward_policy (s)               1.67402\n",
      "time/backward_zf1 (s)                  1.79029\n",
      "time/backward_zf2 (s)                  1.72074\n",
      "time/data sampling (s)                 0.252846\n",
      "time/data storing (s)                  0.0140919\n",
      "time/evaluation sampling (s)           0.339502\n",
      "time/exploration sampling (s)          0.34568\n",
      "time/logging (s)                       0.00174181\n",
      "time/preback_alpha (s)                 0.866511\n",
      "time/preback_policy (s)                0.931754\n",
      "time/preback_start (s)                 0.142486\n",
      "time/preback_zf (s)                    5.09969\n",
      "time/saving (s)                        0.00510589\n",
      "time/training (s)                      2.4412\n",
      "time/epoch (s)                        15.6257\n",
      "time/total (s)                        73.3743\n",
      "Epoch                                  3\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:53:39.197406 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 4 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 15000\n",
      "trainer/ZF1 Loss                     -30.5874\n",
      "trainer/ZF2 Loss                     -30.5786\n",
      "trainer/ZF Expert Reward              18.4985\n",
      "trainer/ZF Policy Reward             -10.2083\n",
      "trainer/ZF CHI2 Term                  18.7258\n",
      "trainer/Policy Loss                   13.817\n",
      "trainer/Bias Loss                     43.4756\n",
      "trainer/Bias Value                    10.4339\n",
      "trainer/Policy Grad Norm              33.1424\n",
      "trainer/Policy Param Norm             18.2741\n",
      "trainer/Zf1 Grad Norm                378.683\n",
      "trainer/Zf1 Param Norm                42.5566\n",
      "trainer/Zf2 Grad Norm                294.314\n",
      "trainer/Zf2 Param Norm                42.7014\n",
      "trainer/Z Expert Predictions Mean    289.604\n",
      "trainer/Z Expert Predictions Std      19.0706\n",
      "trainer/Z Expert Predictions Max     297.434\n",
      "trainer/Z Expert Predictions Min     177.304\n",
      "trainer/Z Policy Predictions Mean    -27.1172\n",
      "trainer/Z Policy Predictions Std     103.177\n",
      "trainer/Z Policy Predictions Max     278.006\n",
      "trainer/Z Policy Predictions Min    -162.441\n",
      "trainer/Z Expert Targets Mean        271.106\n",
      "trainer/Z Expert Targets Std          17.4015\n",
      "trainer/Z Expert Targets Max         278.884\n",
      "trainer/Z Expert Targets Min         161\n",
      "trainer/Z Policy Targets Mean        -16.9088\n",
      "trainer/Z Policy Targets Std         104.46\n",
      "trainer/Z Policy Targets Max         264.608\n",
      "trainer/Z Policy Targets Min        -154.974\n",
      "trainer/Log Pis Mean                  20.8101\n",
      "trainer/Log Pis Std                    5.14652\n",
      "trainer/Policy mu Mean                 0.117798\n",
      "trainer/Policy mu Std                  1.39573\n",
      "trainer/Policy log std Mean           -2.80096\n",
      "trainer/Policy log std Std             0.744105\n",
      "trainer/Alpha                          0.00932439\n",
      "trainer/Alpha Loss                    -0.00755321\n",
      "exploration/num steps total        11837\n",
      "exploration/num paths total           78\n",
      "evaluation/num steps total         31176\n",
      "evaluation/num paths total            50\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                0.200107\n",
      "evaluation/Rewards Std                 0.130496\n",
      "evaluation/Rewards Max                 1.77408\n",
      "evaluation/Rewards Min                -1.96367\n",
      "evaluation/Returns Mean              200.107\n",
      "evaluation/Returns Std                68.5968\n",
      "evaluation/Returns Max               245.622\n",
      "evaluation/Returns Min                -1.08826\n",
      "evaluation/Estimation Bias Mean      149.757\n",
      "evaluation/Estimation Bias Std        32.9639\n",
      "evaluation/EB/Q_True Mean              2.24473\n",
      "evaluation/EB/Q_True Std               6.91438\n",
      "evaluation/EB/Q_Pred Mean            152.002\n",
      "evaluation/EB/Q_Pred Std              27.588\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           200.107\n",
      "evaluation/Actions Mean               -0.031789\n",
      "evaluation/Actions Std                 0.448422\n",
      "evaluation/Actions Max                 0.996779\n",
      "evaluation/Actions Min                -0.999269\n",
      "time/backward_policy (s)               2.06625\n",
      "time/backward_zf1 (s)                  2.22421\n",
      "time/backward_zf2 (s)                  2.11715\n",
      "time/data sampling (s)                 0.280331\n",
      "time/data storing (s)                  0.0154725\n",
      "time/evaluation sampling (s)           1.8721\n",
      "time/exploration sampling (s)          0.360028\n",
      "time/logging (s)                       0.0119038\n",
      "time/preback_alpha (s)                 1.0425\n",
      "time/preback_policy (s)                1.2058\n",
      "time/preback_start (s)                 0.152356\n",
      "time/preback_zf (s)                    5.32589\n",
      "time/saving (s)                        0.00602824\n",
      "time/training (s)                      2.30169\n",
      "time/epoch (s)                        18.9817\n",
      "time/total (s)                        92.3756\n",
      "Epoch                                  4\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:53:56.139718 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 5 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 16000\n",
      "trainer/ZF1 Loss                     -28.6027\n",
      "trainer/ZF2 Loss                     -29.5414\n",
      "trainer/ZF Expert Reward              18.88\n",
      "trainer/ZF Policy Reward              -9.78339\n",
      "trainer/ZF CHI2 Term                  23.3302\n",
      "trainer/Policy Loss                   -7.92538\n",
      "trainer/Bias Loss                     67.9108\n",
      "trainer/Bias Value                    10.5382\n",
      "trainer/Policy Grad Norm              49.1718\n",
      "trainer/Policy Param Norm             18.9033\n",
      "trainer/Zf1 Grad Norm                447.392\n",
      "trainer/Zf1 Param Norm                44.4803\n",
      "trainer/Zf2 Grad Norm                411.503\n",
      "trainer/Zf2 Param Norm                44.6624\n",
      "trainer/Z Expert Predictions Mean    359.226\n",
      "trainer/Z Expert Predictions Std      27.2608\n",
      "trainer/Z Expert Predictions Max     370.746\n",
      "trainer/Z Expert Predictions Min     110.15\n",
      "trainer/Z Policy Predictions Mean     -3.63154\n",
      "trainer/Z Policy Predictions Std     116.435\n",
      "trainer/Z Policy Predictions Max     265.092\n",
      "trainer/Z Policy Predictions Min    -165.338\n",
      "trainer/Z Expert Targets Mean        340.346\n",
      "trainer/Z Expert Targets Std          24.7227\n",
      "trainer/Z Expert Targets Max         351.793\n",
      "trainer/Z Expert Targets Min          89.8497\n",
      "trainer/Z Policy Targets Mean          6.15185\n",
      "trainer/Z Policy Targets Std         115.545\n",
      "trainer/Z Policy Targets Max         270.468\n",
      "trainer/Z Policy Targets Min        -161.967\n",
      "trainer/Log Pis Mean                  23.9786\n",
      "trainer/Log Pis Std                    9.07896\n",
      "trainer/Policy mu Mean                -0.137939\n",
      "trainer/Policy mu Std                  1.98795\n",
      "trainer/Policy log std Mean           -2.4269\n",
      "trainer/Policy log std Std             1.07977\n",
      "trainer/Alpha                          0.0100783\n",
      "trainer/Alpha Loss                    -0.0400935\n",
      "exploration/num steps total        14277\n",
      "exploration/num paths total           83\n",
      "evaluation/num steps total         33774\n",
      "evaluation/num paths total            60\n",
      "evaluation/path length Mean          259.8\n",
      "evaluation/path length Std           202.997\n",
      "evaluation/path length Max           735\n",
      "evaluation/path length Min            18\n",
      "evaluation/Rewards Mean                1.40934\n",
      "evaluation/Rewards Std                 1.06686\n",
      "evaluation/Rewards Max                 4.21888\n",
      "evaluation/Rewards Min                -1.96546\n",
      "evaluation/Returns Mean              366.145\n",
      "evaluation/Returns Std               318.596\n",
      "evaluation/Returns Max              1119.36\n",
      "evaluation/Returns Min                13.9968\n",
      "evaluation/Estimation Bias Mean      165.132\n",
      "evaluation/Estimation Bias Std       132.973\n",
      "evaluation/EB/Q_True Mean             38.6301\n",
      "evaluation/EB/Q_True Std              66.3963\n",
      "evaluation/EB/Q_Pred Mean            203.762\n",
      "evaluation/EB/Q_Pred Std             118.547\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           366.145\n",
      "evaluation/Actions Mean                0.0299748\n",
      "evaluation/Actions Std                 0.544712\n",
      "evaluation/Actions Max                 0.997495\n",
      "evaluation/Actions Min                -0.998824\n",
      "time/backward_policy (s)               1.75313\n",
      "time/backward_zf1 (s)                  1.86086\n",
      "time/backward_zf2 (s)                  1.79861\n",
      "time/data sampling (s)                 0.24657\n",
      "time/data storing (s)                  0.0140814\n",
      "time/evaluation sampling (s)           1.34911\n",
      "time/exploration sampling (s)          0.336951\n",
      "time/logging (s)                       0.00402934\n",
      "time/preback_alpha (s)                 0.922361\n",
      "time/preback_policy (s)                1.0202\n",
      "time/preback_start (s)                 0.140711\n",
      "time/preback_zf (s)                    5.12119\n",
      "time/saving (s)                        0.00574105\n",
      "time/training (s)                      2.29717\n",
      "time/epoch (s)                        16.8707\n",
      "time/total (s)                       109.265\n",
      "Epoch                                  5\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:54:14.003610 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 6 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 17000\n",
      "trainer/ZF1 Loss                     -28.0667\n",
      "trainer/ZF2 Loss                     -26.4417\n",
      "trainer/ZF Expert Reward              20.7089\n",
      "trainer/ZF Policy Reward             -10.934\n",
      "trainer/ZF CHI2 Term                  27.1153\n",
      "trainer/Policy Loss                   12.5961\n",
      "trainer/Bias Loss                    104.477\n",
      "trainer/Bias Value                    10.6397\n",
      "trainer/Policy Grad Norm              24.4602\n",
      "trainer/Policy Param Norm             19.337\n",
      "trainer/Zf1 Grad Norm                456.604\n",
      "trainer/Zf1 Param Norm                46.1844\n",
      "trainer/Zf2 Grad Norm                434.987\n",
      "trainer/Zf2 Param Norm                46.4029\n",
      "trainer/Z Expert Predictions Mean    410.513\n",
      "trainer/Z Expert Predictions Std      26.3905\n",
      "trainer/Z Expert Predictions Max     432.739\n",
      "trainer/Z Expert Predictions Min     203.353\n",
      "trainer/Z Policy Predictions Mean    -20.8862\n",
      "trainer/Z Policy Predictions Std     121.968\n",
      "trainer/Z Policy Predictions Max     274.937\n",
      "trainer/Z Policy Predictions Min    -174.736\n",
      "trainer/Z Expert Targets Mean        389.805\n",
      "trainer/Z Expert Targets Std          29.2816\n",
      "trainer/Z Expert Targets Max         415.67\n",
      "trainer/Z Expert Targets Min         140.733\n",
      "trainer/Z Policy Targets Mean         -9.95215\n",
      "trainer/Z Policy Targets Std         124.427\n",
      "trainer/Z Policy Targets Max         279.099\n",
      "trainer/Z Policy Targets Min        -165.839\n",
      "trainer/Log Pis Mean                  22.9561\n",
      "trainer/Log Pis Std                    9.90731\n",
      "trainer/Policy mu Mean                -0.00109838\n",
      "trainer/Policy mu Std                  2.16095\n",
      "trainer/Policy log std Mean           -1.97701\n",
      "trainer/Policy log std Std             1.56584\n",
      "trainer/Alpha                          0.0108738\n",
      "trainer/Alpha Loss                    -0.0321423\n",
      "exploration/num steps total        14913\n",
      "exploration/num paths total           86\n",
      "evaluation/num steps total         42099\n",
      "evaluation/num paths total            74\n",
      "evaluation/path length Mean          594.643\n",
      "evaluation/path length Std           420.085\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            90\n",
      "evaluation/Rewards Mean               -0.377401\n",
      "evaluation/Rewards Std                 1.75474\n",
      "evaluation/Rewards Max                 3.96186\n",
      "evaluation/Rewards Min                -3.96826\n",
      "evaluation/Returns Mean             -224.419\n",
      "evaluation/Returns Std               947.042\n",
      "evaluation/Returns Max              1288.66\n",
      "evaluation/Returns Min             -2019.79\n",
      "evaluation/Estimation Bias Mean      -12.7234\n",
      "evaluation/Estimation Bias Std       202.621\n",
      "evaluation/EB/Q_True Mean             14.1296\n",
      "evaluation/EB/Q_True Std              46.7859\n",
      "evaluation/EB/Q_Pred Mean              1.40627\n",
      "evaluation/EB/Q_Pred Std             214.797\n",
      "evaluation/Num Paths                  14\n",
      "evaluation/Average Returns          -224.419\n",
      "evaluation/Actions Mean               -0.0426964\n",
      "evaluation/Actions Std                 0.719652\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999973\n",
      "time/backward_policy (s)               1.90859\n",
      "time/backward_zf1 (s)                  2.01065\n",
      "time/backward_zf2 (s)                  1.9681\n",
      "time/data sampling (s)                 0.235464\n",
      "time/data storing (s)                  0.0142201\n",
      "time/evaluation sampling (s)           1.83074\n",
      "time/exploration sampling (s)          0.335408\n",
      "time/logging (s)                       0.0104533\n",
      "time/preback_alpha (s)                 1.01975\n",
      "time/preback_policy (s)                1.1681\n",
      "time/preback_start (s)                 0.139582\n",
      "time/preback_zf (s)                    5.13352\n",
      "time/saving (s)                        0.00573044\n",
      "time/training (s)                      2.02406\n",
      "time/epoch (s)                        17.8044\n",
      "time/total (s)                       127.09\n",
      "Epoch                                  6\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:54:31.574103 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 7 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 18000\n",
      "trainer/ZF1 Loss                     -21.8825\n",
      "trainer/ZF2 Loss                     -17.8891\n",
      "trainer/ZF Expert Reward              16.9941\n",
      "trainer/ZF Policy Reward             -12.4477\n",
      "trainer/ZF CHI2 Term                  34.6441\n",
      "trainer/Policy Loss                   18.6922\n",
      "trainer/Bias Loss                     95.0696\n",
      "trainer/Bias Value                    10.7398\n",
      "trainer/Policy Grad Norm              35.7575\n",
      "trainer/Policy Param Norm             19.7479\n",
      "trainer/Zf1 Grad Norm               1310.69\n",
      "trainer/Zf1 Param Norm                47.6309\n",
      "trainer/Zf2 Grad Norm               1286.33\n",
      "trainer/Zf2 Param Norm                47.8731\n",
      "trainer/Z Expert Predictions Mean    427.58\n",
      "trainer/Z Expert Predictions Std      36.9085\n",
      "trainer/Z Expert Predictions Max     470.018\n",
      "trainer/Z Expert Predictions Min     253.645\n",
      "trainer/Z Policy Predictions Mean    -29.3611\n",
      "trainer/Z Policy Predictions Std     138.419\n",
      "trainer/Z Policy Predictions Max     315.81\n",
      "trainer/Z Policy Predictions Min    -198.64\n",
      "trainer/Z Expert Targets Mean        410.586\n",
      "trainer/Z Expert Targets Std          34.461\n",
      "trainer/Z Expert Targets Max         460.192\n",
      "trainer/Z Expert Targets Min         244.236\n",
      "trainer/Z Policy Targets Mean        -16.9134\n",
      "trainer/Z Policy Targets Std         140.906\n",
      "trainer/Z Policy Targets Max         377.353\n",
      "trainer/Z Policy Targets Min        -191.159\n",
      "trainer/Log Pis Mean                  25.3414\n",
      "trainer/Log Pis Std                   11.7483\n",
      "trainer/Policy mu Mean                 0.0539867\n",
      "trainer/Policy mu Std                  2.38429\n",
      "trainer/Policy log std Mean           -2.11749\n",
      "trainer/Policy log std Std             1.54563\n",
      "trainer/Alpha                          0.0118853\n",
      "trainer/Alpha Loss                    -0.0634789\n",
      "exploration/num steps total        15682\n",
      "exploration/num paths total           89\n",
      "evaluation/num steps total         51214\n",
      "evaluation/num paths total            84\n",
      "evaluation/path length Mean          911.5\n",
      "evaluation/path length Std           265.5\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           115\n",
      "evaluation/Rewards Mean                0.511023\n",
      "evaluation/Rewards Std                 1.29822\n",
      "evaluation/Rewards Max                 4.986\n",
      "evaluation/Rewards Min                -3.69487\n",
      "evaluation/Returns Mean              465.797\n",
      "evaluation/Returns Std               991.845\n",
      "evaluation/Returns Max              1660.75\n",
      "evaluation/Returns Min             -2261.39\n",
      "evaluation/Estimation Bias Mean      143.693\n",
      "evaluation/Estimation Bias Std       139.137\n",
      "evaluation/EB/Q_True Mean              6.12284\n",
      "evaluation/EB/Q_True Std              18.0504\n",
      "evaluation/EB/Q_Pred Mean            149.816\n",
      "evaluation/EB/Q_Pred Std             139.097\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           465.797\n",
      "evaluation/Actions Mean                0.0482641\n",
      "evaluation/Actions Std                 0.495958\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999599\n",
      "time/backward_policy (s)               1.77658\n",
      "time/backward_zf1 (s)                  1.90864\n",
      "time/backward_zf2 (s)                  1.86839\n",
      "time/data sampling (s)                 0.258317\n",
      "time/data storing (s)                  0.0138355\n",
      "time/evaluation sampling (s)           1.79263\n",
      "time/exploration sampling (s)          0.327303\n",
      "time/logging (s)                       0.0114272\n",
      "time/preback_alpha (s)                 0.957392\n",
      "time/preback_policy (s)                1.06446\n",
      "time/preback_start (s)                 0.14119\n",
      "time/preback_zf (s)                    5.16029\n",
      "time/saving (s)                        0.00616666\n",
      "time/training (s)                      2.21899\n",
      "time/epoch (s)                        17.5056\n",
      "time/total (s)                       144.616\n",
      "Epoch                                  7\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:54:49.691296 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 8 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 19000\n",
      "trainer/ZF1 Loss                     -17.9283\n",
      "trainer/ZF2 Loss                     -21.098\n",
      "trainer/ZF Expert Reward              15.2132\n",
      "trainer/ZF Policy Reward             -12.739\n",
      "trainer/ZF CHI2 Term                  31.1813\n",
      "trainer/Policy Loss                   50.7456\n",
      "trainer/Bias Loss                     82.5991\n",
      "trainer/Bias Value                    10.8382\n",
      "trainer/Policy Grad Norm              43.6223\n",
      "trainer/Policy Param Norm             20.0913\n",
      "trainer/Zf1 Grad Norm               1732.47\n",
      "trainer/Zf1 Param Norm                48.7501\n",
      "trainer/Zf2 Grad Norm               1728.96\n",
      "trainer/Zf2 Param Norm                49.0423\n",
      "trainer/Z Expert Predictions Mean    456.031\n",
      "trainer/Z Expert Predictions Std      42.7634\n",
      "trainer/Z Expert Predictions Max     491.056\n",
      "trainer/Z Expert Predictions Min     214.393\n",
      "trainer/Z Policy Predictions Mean    -58.4413\n",
      "trainer/Z Policy Predictions Std     158.817\n",
      "trainer/Z Policy Predictions Max     442.569\n",
      "trainer/Z Policy Predictions Min    -227.645\n",
      "trainer/Z Expert Targets Mean        440.817\n",
      "trainer/Z Expert Targets Std          38.8228\n",
      "trainer/Z Expert Targets Max         478.745\n",
      "trainer/Z Expert Targets Min         218.106\n",
      "trainer/Z Policy Targets Mean        -45.7023\n",
      "trainer/Z Policy Targets Std         161.911\n",
      "trainer/Z Policy Targets Max         443.98\n",
      "trainer/Z Policy Targets Min        -218.383\n",
      "trainer/Log Pis Mean                  22.972\n",
      "trainer/Log Pis Std                   10.8497\n",
      "trainer/Policy mu Mean                 0.159363\n",
      "trainer/Policy mu Std                  2.3076\n",
      "trainer/Policy log std Mean           -1.7465\n",
      "trainer/Policy log std Std             1.83327\n",
      "trainer/Alpha                          0.0128086\n",
      "trainer/Alpha Loss                    -0.0380642\n",
      "exploration/num steps total        15910\n",
      "exploration/num paths total           90\n",
      "evaluation/num steps total         60326\n",
      "evaluation/num paths total            94\n",
      "evaluation/path length Mean          911.2\n",
      "evaluation/path length Std           266.4\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           112\n",
      "evaluation/Rewards Mean                0.364205\n",
      "evaluation/Rewards Std                 0.816448\n",
      "evaluation/Rewards Max                 5.04596\n",
      "evaluation/Rewards Min                -1.60687\n",
      "evaluation/Returns Mean              331.864\n",
      "evaluation/Returns Std               458.501\n",
      "evaluation/Returns Max               961.869\n",
      "evaluation/Returns Min              -522.178\n",
      "evaluation/Estimation Bias Mean      141.58\n",
      "evaluation/Estimation Bias Std        65.3037\n",
      "evaluation/EB/Q_True Mean              9.01271\n",
      "evaluation/EB/Q_True Std              28.7737\n",
      "evaluation/EB/Q_Pred Mean            150.592\n",
      "evaluation/EB/Q_Pred Std              65.6608\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           331.864\n",
      "evaluation/Actions Mean                0.0185049\n",
      "evaluation/Actions Std                 0.456882\n",
      "evaluation/Actions Max                 0.995397\n",
      "evaluation/Actions Min                -0.999557\n",
      "time/backward_policy (s)               1.88157\n",
      "time/backward_zf1 (s)                  2.00227\n",
      "time/backward_zf2 (s)                  1.93945\n",
      "time/data sampling (s)                 0.321083\n",
      "time/data storing (s)                  0.0142854\n",
      "time/evaluation sampling (s)           1.80159\n",
      "time/exploration sampling (s)          0.342991\n",
      "time/logging (s)                       0.0117751\n",
      "time/preback_alpha (s)                 0.996415\n",
      "time/preback_policy (s)                1.10924\n",
      "time/preback_start (s)                 0.145796\n",
      "time/preback_zf (s)                    5.18401\n",
      "time/saving (s)                        0.00585992\n",
      "time/training (s)                      2.29361\n",
      "time/epoch (s)                        18.0499\n",
      "time/total (s)                       162.687\n",
      "Epoch                                  8\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:55:07.047440 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 9 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 20000\n",
      "trainer/ZF1 Loss                     -21.0548\n",
      "trainer/ZF2 Loss                     -12.3209\n",
      "trainer/ZF Expert Reward              20.5343\n",
      "trainer/ZF Policy Reward              -9.94075\n",
      "trainer/ZF CHI2 Term                  35.1782\n",
      "trainer/Policy Loss                   51.6219\n",
      "trainer/Bias Loss                     85.0048\n",
      "trainer/Bias Value                    10.934\n",
      "trainer/Policy Grad Norm              56.34\n",
      "trainer/Policy Param Norm             20.4663\n",
      "trainer/Zf1 Grad Norm                850.282\n",
      "trainer/Zf1 Param Norm                50.173\n",
      "trainer/Zf2 Grad Norm               1141.23\n",
      "trainer/Zf2 Param Norm                50.4705\n",
      "trainer/Z Expert Predictions Mean    510.366\n",
      "trainer/Z Expert Predictions Std      38.7545\n",
      "trainer/Z Expert Predictions Max     538.268\n",
      "trainer/Z Expert Predictions Min     227.704\n",
      "trainer/Z Policy Predictions Mean    -58.5423\n",
      "trainer/Z Policy Predictions Std     177.453\n",
      "trainer/Z Policy Predictions Max     493.469\n",
      "trainer/Z Policy Predictions Min    -263.806\n",
      "trainer/Z Expert Targets Mean        489.831\n",
      "trainer/Z Expert Targets Std          41.0911\n",
      "trainer/Z Expert Targets Max         519.648\n",
      "trainer/Z Expert Targets Min         179.846\n",
      "trainer/Z Policy Targets Mean        -48.6015\n",
      "trainer/Z Policy Targets Std         176.41\n",
      "trainer/Z Policy Targets Max         480.613\n",
      "trainer/Z Policy Targets Min        -254.507\n",
      "trainer/Log Pis Mean                  21.607\n",
      "trainer/Log Pis Std                   10.3105\n",
      "trainer/Policy mu Mean                -0.0581026\n",
      "trainer/Policy mu Std                  1.99403\n",
      "trainer/Policy log std Mean           -1.75722\n",
      "trainer/Policy log std Std             1.94618\n",
      "trainer/Alpha                          0.0135463\n",
      "trainer/Alpha Loss                    -0.0217686\n",
      "exploration/num steps total        15910\n",
      "exploration/num paths total           90\n",
      "evaluation/num steps total         68641\n",
      "evaluation/num paths total           106\n",
      "evaluation/path length Mean          692.917\n",
      "evaluation/path length Std           357.376\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            99\n",
      "evaluation/Rewards Mean                1.60489\n",
      "evaluation/Rewards Std                 2.29179\n",
      "evaluation/Rewards Max                 5.30462\n",
      "evaluation/Rewards Min                -3.5672\n",
      "evaluation/Returns Mean             1112.06\n",
      "evaluation/Returns Std              1512.44\n",
      "evaluation/Returns Max              2878.18\n",
      "evaluation/Returns Min             -2665.91\n",
      "evaluation/Estimation Bias Mean      302.717\n",
      "evaluation/Estimation Bias Std       303.406\n",
      "evaluation/EB/Q_True Mean             23.6659\n",
      "evaluation/EB/Q_True Std              65.4683\n",
      "evaluation/EB/Q_Pred Mean            326.383\n",
      "evaluation/EB/Q_Pred Std             308.118\n",
      "evaluation/Num Paths                  12\n",
      "evaluation/Average Returns          1112.06\n",
      "evaluation/Actions Mean                0.0214857\n",
      "evaluation/Actions Std                 0.642181\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.75173\n",
      "time/backward_zf1 (s)                  1.83512\n",
      "time/backward_zf2 (s)                  1.80085\n",
      "time/data sampling (s)                 0.256764\n",
      "time/data storing (s)                  0.0140807\n",
      "time/evaluation sampling (s)           1.86045\n",
      "time/exploration sampling (s)          0.330071\n",
      "time/logging (s)                       0.010508\n",
      "time/preback_alpha (s)                 0.939542\n",
      "time/preback_policy (s)                1.05072\n",
      "time/preback_start (s)                 0.137217\n",
      "time/preback_zf (s)                    5.09623\n",
      "time/saving (s)                        0.00636312\n",
      "time/training (s)                      2.20143\n",
      "time/epoch (s)                        17.2911\n",
      "time/total (s)                       179.998\n",
      "Epoch                                  9\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:55:23.942563 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 10 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 21000\n",
      "trainer/ZF1 Loss                      -7.30931\n",
      "trainer/ZF2 Loss                      16.1527\n",
      "trainer/ZF Expert Reward              20.4361\n",
      "trainer/ZF Policy Reward              -9.20518\n",
      "trainer/ZF CHI2 Term                  58.3229\n",
      "trainer/Policy Loss                   34.6061\n",
      "trainer/Bias Loss                    287.901\n",
      "trainer/Bias Value                    11.031\n",
      "trainer/Policy Grad Norm              78.2076\n",
      "trainer/Policy Param Norm             20.8608\n",
      "trainer/Zf1 Grad Norm               1397.37\n",
      "trainer/Zf1 Param Norm                51.554\n",
      "trainer/Zf2 Grad Norm               1265.06\n",
      "trainer/Zf2 Param Norm                51.8753\n",
      "trainer/Z Expert Predictions Mean    553.342\n",
      "trainer/Z Expert Predictions Std      40.3857\n",
      "trainer/Z Expert Predictions Max     583.551\n",
      "trainer/Z Expert Predictions Min     269.054\n",
      "trainer/Z Policy Predictions Mean    -39.7247\n",
      "trainer/Z Policy Predictions Std     215.954\n",
      "trainer/Z Policy Predictions Max     564.475\n",
      "trainer/Z Policy Predictions Min    -299.399\n",
      "trainer/Z Expert Targets Mean        532.906\n",
      "trainer/Z Expert Targets Std          51.0712\n",
      "trainer/Z Expert Targets Max         569.363\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        -30.5195\n",
      "trainer/Z Policy Targets Std         212.496\n",
      "trainer/Z Policy Targets Max         544.021\n",
      "trainer/Z Policy Targets Min        -289.268\n",
      "trainer/Log Pis Mean                  24.505\n",
      "trainer/Log Pis Std                   10.4567\n",
      "trainer/Policy mu Mean                -0.0389435\n",
      "trainer/Policy mu Std                  2.15944\n",
      "trainer/Policy log std Mean           -2.33384\n",
      "trainer/Policy log std Std             1.90471\n",
      "trainer/Alpha                          0.0145807\n",
      "trainer/Alpha Loss                    -0.0656796\n",
      "exploration/num steps total        15910\n",
      "exploration/num paths total           90\n",
      "evaluation/num steps total         70068\n",
      "evaluation/num paths total           116\n",
      "evaluation/path length Mean          142.7\n",
      "evaluation/path length Std            92.3212\n",
      "evaluation/path length Max           270\n",
      "evaluation/path length Min            16\n",
      "evaluation/Rewards Mean                2.12942\n",
      "evaluation/Rewards Std                 1.45467\n",
      "evaluation/Rewards Max                 5.24207\n",
      "evaluation/Rewards Min                -2.22463\n",
      "evaluation/Returns Mean              303.869\n",
      "evaluation/Returns Std               245.878\n",
      "evaluation/Returns Max               736.948\n",
      "evaluation/Returns Min                 3.2127\n",
      "evaluation/Estimation Bias Mean      350.41\n",
      "evaluation/Estimation Bias Std       201.69\n",
      "evaluation/EB/Q_True Mean             32.5742\n",
      "evaluation/EB/Q_True Std              76.0237\n",
      "evaluation/EB/Q_Pred Mean            382.984\n",
      "evaluation/EB/Q_Pred Std             187.719\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           303.869\n",
      "evaluation/Actions Mean                0.00549016\n",
      "evaluation/Actions Std                 0.521355\n",
      "evaluation/Actions Max                 0.999707\n",
      "evaluation/Actions Min                -0.999983\n",
      "time/backward_policy (s)               1.85459\n",
      "time/backward_zf1 (s)                  1.97393\n",
      "time/backward_zf2 (s)                  1.91403\n",
      "time/data sampling (s)                 0.288301\n",
      "time/data storing (s)                  0.0142099\n",
      "time/evaluation sampling (s)           0.546844\n",
      "time/exploration sampling (s)          0.341727\n",
      "time/logging (s)                       0.00266921\n",
      "time/preback_alpha (s)                 0.983615\n",
      "time/preback_policy (s)                1.10044\n",
      "time/preback_start (s)                 0.145729\n",
      "time/preback_zf (s)                    5.27738\n",
      "time/saving (s)                        0.00527338\n",
      "time/training (s)                      2.37135\n",
      "time/epoch (s)                        16.8201\n",
      "time/total (s)                       196.837\n",
      "Epoch                                 10\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:55:40.179177 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 11 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 22000\n",
      "trainer/ZF1 Loss                      -2.5651\n",
      "trainer/ZF2 Loss                     -13.3669\n",
      "trainer/ZF Expert Reward              16.5177\n",
      "trainer/ZF Policy Reward             -13.298\n",
      "trainer/ZF CHI2 Term                  46.7436\n",
      "trainer/Policy Loss                   26.8645\n",
      "trainer/Bias Loss                     86.368\n",
      "trainer/Bias Value                    11.1284\n",
      "trainer/Policy Grad Norm              72.2632\n",
      "trainer/Policy Param Norm             21.2633\n",
      "trainer/Zf1 Grad Norm               1703.34\n",
      "trainer/Zf1 Param Norm                52.7007\n",
      "trainer/Zf2 Grad Norm               1398.57\n",
      "trainer/Zf2 Param Norm                53.0197\n",
      "trainer/Z Expert Predictions Mean    585.171\n",
      "trainer/Z Expert Predictions Std      52.7694\n",
      "trainer/Z Expert Predictions Max     621.843\n",
      "trainer/Z Expert Predictions Min     234.828\n",
      "trainer/Z Policy Predictions Mean    -42.4725\n",
      "trainer/Z Policy Predictions Std     249.426\n",
      "trainer/Z Policy Predictions Max     598.846\n",
      "trainer/Z Policy Predictions Min    -333.585\n",
      "trainer/Z Expert Targets Mean        568.653\n",
      "trainer/Z Expert Targets Std          48.0488\n",
      "trainer/Z Expert Targets Max         606.58\n",
      "trainer/Z Expert Targets Min         254.915\n",
      "trainer/Z Policy Targets Mean        -29.1745\n",
      "trainer/Z Policy Targets Std         249.394\n",
      "trainer/Z Policy Targets Max         581.619\n",
      "trainer/Z Policy Targets Min        -324.564\n",
      "trainer/Log Pis Mean                  25.1454\n",
      "trainer/Log Pis Std                   11.7445\n",
      "trainer/Policy mu Mean                -0.28586\n",
      "trainer/Policy mu Std                  2.24191\n",
      "trainer/Policy log std Mean           -2.10143\n",
      "trainer/Policy log std Std             1.81435\n",
      "trainer/Alpha                          0.0161484\n",
      "trainer/Alpha Loss                    -0.0830824\n",
      "exploration/num steps total        17202\n",
      "exploration/num paths total           92\n",
      "evaluation/num steps total         71337\n",
      "evaluation/num paths total           126\n",
      "evaluation/path length Mean          126.9\n",
      "evaluation/path length Std            74.3525\n",
      "evaluation/path length Max           247\n",
      "evaluation/path length Min            14\n",
      "evaluation/Rewards Mean                2.6014\n",
      "evaluation/Rewards Std                 1.47345\n",
      "evaluation/Rewards Max                 5.47612\n",
      "evaluation/Rewards Min                -2.08529\n",
      "evaluation/Returns Mean              330.117\n",
      "evaluation/Returns Std               245.001\n",
      "evaluation/Returns Max               750.946\n",
      "evaluation/Returns Min                -7.25991\n",
      "evaluation/Estimation Bias Mean      460.457\n",
      "evaluation/Estimation Bias Std       155.609\n",
      "evaluation/EB/Q_True Mean             26.8155\n",
      "evaluation/EB/Q_True Std              65.3188\n",
      "evaluation/EB/Q_Pred Mean            487.272\n",
      "evaluation/EB/Q_Pred Std             150.833\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           330.117\n",
      "evaluation/Actions Mean                0.00496787\n",
      "evaluation/Actions Std                 0.523476\n",
      "evaluation/Actions Max                 0.999673\n",
      "evaluation/Actions Min                -0.999751\n",
      "time/backward_policy (s)               1.78345\n",
      "time/backward_zf1 (s)                  1.92916\n",
      "time/backward_zf2 (s)                  1.85572\n",
      "time/data sampling (s)                 0.253561\n",
      "time/data storing (s)                  0.0139584\n",
      "time/evaluation sampling (s)           0.5103\n",
      "time/exploration sampling (s)          0.32157\n",
      "time/logging (s)                       0.00271919\n",
      "time/preback_alpha (s)                 0.940894\n",
      "time/preback_policy (s)                1.05026\n",
      "time/preback_start (s)                 0.139835\n",
      "time/preback_zf (s)                    5.14679\n",
      "time/saving (s)                        0.0051443\n",
      "time/training (s)                      2.21798\n",
      "time/epoch (s)                        16.1713\n",
      "time/total (s)                       213.029\n",
      "Epoch                                 11\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:55:56.295789 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 12 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 23000\n",
      "trainer/ZF1 Loss                      -3.79961\n",
      "trainer/ZF2 Loss                      -8.53842\n",
      "trainer/ZF Expert Reward              20.0517\n",
      "trainer/ZF Policy Reward             -12.8339\n",
      "trainer/ZF CHI2 Term                  55.054\n",
      "trainer/Policy Loss                   47.997\n",
      "trainer/Bias Loss                     94.6257\n",
      "trainer/Bias Value                    11.2243\n",
      "trainer/Policy Grad Norm              60.7974\n",
      "trainer/Policy Param Norm             21.6637\n",
      "trainer/Zf1 Grad Norm               1550.85\n",
      "trainer/Zf1 Param Norm                53.7888\n",
      "trainer/Zf2 Grad Norm               1064.19\n",
      "trainer/Zf2 Param Norm                54.1188\n",
      "trainer/Z Expert Predictions Mean    632.401\n",
      "trainer/Z Expert Predictions Std      35.6243\n",
      "trainer/Z Expert Predictions Max     658.801\n",
      "trainer/Z Expert Predictions Min     377.116\n",
      "trainer/Z Policy Predictions Mean    -63.3332\n",
      "trainer/Z Policy Predictions Std     269.438\n",
      "trainer/Z Policy Predictions Max     624.751\n",
      "trainer/Z Policy Predictions Min    -368.546\n",
      "trainer/Z Expert Targets Mean        612.349\n",
      "trainer/Z Expert Targets Std          37.2964\n",
      "trainer/Z Expert Targets Max         642.378\n",
      "trainer/Z Expert Targets Min         329.618\n",
      "trainer/Z Policy Targets Mean        -50.4993\n",
      "trainer/Z Policy Targets Std         270.157\n",
      "trainer/Z Policy Targets Max         621.899\n",
      "trainer/Z Policy Targets Min        -358.479\n",
      "trainer/Log Pis Mean                  28.6237\n",
      "trainer/Log Pis Std                   15.4237\n",
      "trainer/Policy mu Mean                -0.343718\n",
      "trainer/Policy mu Std                  2.6663\n",
      "trainer/Policy log std Mean           -2.06135\n",
      "trainer/Policy log std Std             1.82731\n",
      "trainer/Alpha                          0.0178098\n",
      "trainer/Alpha Loss                    -0.153572\n",
      "exploration/num steps total        19535\n",
      "exploration/num paths total           98\n",
      "evaluation/num steps total         72363\n",
      "evaluation/num paths total           136\n",
      "evaluation/path length Mean          102.6\n",
      "evaluation/path length Std            44.7017\n",
      "evaluation/path length Max           168\n",
      "evaluation/path length Min            42\n",
      "evaluation/Rewards Mean                2.79613\n",
      "evaluation/Rewards Std                 1.40448\n",
      "evaluation/Rewards Max                 6.24955\n",
      "evaluation/Rewards Min                -1.96062\n",
      "evaluation/Returns Mean              286.883\n",
      "evaluation/Returns Std               155.823\n",
      "evaluation/Returns Max               526.42\n",
      "evaluation/Returns Min                75.4019\n",
      "evaluation/Estimation Bias Mean      485.598\n",
      "evaluation/Estimation Bias Std       154.282\n",
      "evaluation/EB/Q_True Mean             29.1952\n",
      "evaluation/EB/Q_True Std              72.4571\n",
      "evaluation/EB/Q_Pred Mean            514.793\n",
      "evaluation/EB/Q_Pred Std             119.029\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           286.883\n",
      "evaluation/Actions Mean               -0.00484954\n",
      "evaluation/Actions Std                 0.511859\n",
      "evaluation/Actions Max                 0.999574\n",
      "evaluation/Actions Min                -0.999854\n",
      "time/backward_policy (s)               1.78563\n",
      "time/backward_zf1 (s)                  1.91919\n",
      "time/backward_zf2 (s)                  1.84225\n",
      "time/data sampling (s)                 0.256783\n",
      "time/data storing (s)                  0.0143292\n",
      "time/evaluation sampling (s)           0.329448\n",
      "time/exploration sampling (s)          0.324122\n",
      "time/logging (s)                       0.00223445\n",
      "time/preback_alpha (s)                 0.922838\n",
      "time/preback_policy (s)                1.0147\n",
      "time/preback_start (s)                 0.142472\n",
      "time/preback_zf (s)                    5.15469\n",
      "time/saving (s)                        0.00529785\n",
      "time/training (s)                      2.33945\n",
      "time/epoch (s)                        16.0534\n",
      "time/total (s)                       229.1\n",
      "Epoch                                 12\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:56:13.676238 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 13 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 24000\n",
      "trainer/ZF1 Loss                      -1.77713\n",
      "trainer/ZF2 Loss                       0.42926\n",
      "trainer/ZF Expert Reward              15.6204\n",
      "trainer/ZF Policy Reward             -14.1009\n",
      "trainer/ZF CHI2 Term                  55.3614\n",
      "trainer/Policy Loss                  -42.4639\n",
      "trainer/Bias Loss                     64.1093\n",
      "trainer/Bias Value                    11.3187\n",
      "trainer/Policy Grad Norm              60.6322\n",
      "trainer/Policy Param Norm             22.0333\n",
      "trainer/Zf1 Grad Norm               1709.61\n",
      "trainer/Zf1 Param Norm                54.8774\n",
      "trainer/Zf2 Grad Norm               1373.92\n",
      "trainer/Zf2 Param Norm                55.2216\n",
      "trainer/Z Expert Predictions Mean    670.685\n",
      "trainer/Z Expert Predictions Std      45.9089\n",
      "trainer/Z Expert Predictions Max     703.008\n",
      "trainer/Z Expert Predictions Min     362.473\n",
      "trainer/Z Policy Predictions Mean     28.0517\n",
      "trainer/Z Policy Predictions Std     319.99\n",
      "trainer/Z Policy Predictions Max     683.06\n",
      "trainer/Z Policy Predictions Min    -401.525\n",
      "trainer/Z Expert Targets Mean        655.065\n",
      "trainer/Z Expert Targets Std          42.7221\n",
      "trainer/Z Expert Targets Max         685.579\n",
      "trainer/Z Expert Targets Min         373.658\n",
      "trainer/Z Policy Targets Mean         42.1526\n",
      "trainer/Z Policy Targets Std         322.867\n",
      "trainer/Z Policy Targets Max         667.887\n",
      "trainer/Z Policy Targets Min        -391.431\n",
      "trainer/Log Pis Mean                  26.5799\n",
      "trainer/Log Pis Std                   14.9669\n",
      "trainer/Policy mu Mean                -0.207627\n",
      "trainer/Policy mu Std                  2.51437\n",
      "trainer/Policy log std Mean           -2.24509\n",
      "trainer/Policy log std Std             1.68657\n",
      "trainer/Alpha                          0.0193971\n",
      "trainer/Alpha Loss                    -0.12762\n",
      "exploration/num steps total        21102\n",
      "exploration/num paths total          101\n",
      "evaluation/num steps total         82116\n",
      "evaluation/num paths total           148\n",
      "evaluation/path length Mean          812.75\n",
      "evaluation/path length Std           330.754\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            83\n",
      "evaluation/Rewards Mean                3.05025\n",
      "evaluation/Rewards Std                 2.21709\n",
      "evaluation/Rewards Max                 6.37474\n",
      "evaluation/Rewards Min                -3.66204\n",
      "evaluation/Returns Mean             2479.09\n",
      "evaluation/Returns Std              1528.45\n",
      "evaluation/Returns Max              3832.72\n",
      "evaluation/Returns Min               209.888\n",
      "evaluation/Estimation Bias Mean      526.585\n",
      "evaluation/Estimation Bias Std       320.009\n",
      "evaluation/EB/Q_True Mean             35.9122\n",
      "evaluation/EB/Q_True Std             109.383\n",
      "evaluation/EB/Q_Pred Mean            562.497\n",
      "evaluation/EB/Q_Pred Std             309.933\n",
      "evaluation/Num Paths                  12\n",
      "evaluation/Average Returns          2479.09\n",
      "evaluation/Actions Mean                0.0144132\n",
      "evaluation/Actions Std                 0.5685\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.80545\n",
      "time/backward_zf1 (s)                  1.9033\n",
      "time/backward_zf2 (s)                  1.86265\n",
      "time/data sampling (s)                 0.251535\n",
      "time/data storing (s)                  0.0138343\n",
      "time/evaluation sampling (s)           1.69422\n",
      "time/exploration sampling (s)          0.31895\n",
      "time/logging (s)                       0.0135589\n",
      "time/preback_alpha (s)                 0.951952\n",
      "time/preback_policy (s)                1.05778\n",
      "time/preback_start (s)                 0.140161\n",
      "time/preback_zf (s)                    5.10304\n",
      "time/saving (s)                        0.0060963\n",
      "time/training (s)                      2.20589\n",
      "time/epoch (s)                        17.3284\n",
      "time/total (s)                       246.448\n",
      "Epoch                                 13\n",
      "---------------------------------  -------------\n",
      "2024-06-15 10:56:30.499419 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 14 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 25000\n",
      "trainer/ZF1 Loss                      -0.750717\n",
      "trainer/ZF2 Loss                      -5.36515\n",
      "trainer/ZF Expert Reward              20.5929\n",
      "trainer/ZF Policy Reward              -2.7608\n",
      "trainer/ZF CHI2 Term                  45.8955\n",
      "trainer/Policy Loss                  -31.3906\n",
      "trainer/Bias Loss                    105.299\n",
      "trainer/Bias Value                    11.4127\n",
      "trainer/Policy Grad Norm              82.9713\n",
      "trainer/Policy Param Norm             22.3534\n",
      "trainer/Zf1 Grad Norm               1830.32\n",
      "trainer/Zf1 Param Norm                55.8983\n",
      "trainer/Zf2 Grad Norm               1657.63\n",
      "trainer/Zf2 Param Norm                56.2602\n",
      "trainer/Z Expert Predictions Mean    718.341\n",
      "trainer/Z Expert Predictions Std      46.3061\n",
      "trainer/Z Expert Predictions Max     747.856\n",
      "trainer/Z Expert Predictions Min     440.243\n",
      "trainer/Z Policy Predictions Mean     20.8827\n",
      "trainer/Z Policy Predictions Std     340.448\n",
      "trainer/Z Policy Predictions Max     732.146\n",
      "trainer/Z Policy Predictions Min    -432.455\n",
      "trainer/Z Expert Targets Mean        697.748\n",
      "trainer/Z Expert Targets Std          48.0627\n",
      "trainer/Z Expert Targets Max         727.926\n",
      "trainer/Z Expert Targets Min         421.525\n",
      "trainer/Z Policy Targets Mean         23.6435\n",
      "trainer/Z Policy Targets Std         334.97\n",
      "trainer/Z Policy Targets Max         714.175\n",
      "trainer/Z Policy Targets Min        -421.696\n",
      "trainer/Log Pis Mean                  25.8583\n",
      "trainer/Log Pis Std                   12.0153\n",
      "trainer/Policy mu Mean                -0.206344\n",
      "trainer/Policy mu Std                  2.3349\n",
      "trainer/Policy log std Mean           -2.11459\n",
      "trainer/Policy log std Std             1.88173\n",
      "trainer/Alpha                          0.0209005\n",
      "trainer/Alpha Loss                    -0.122432\n",
      "exploration/num steps total        22566\n",
      "exploration/num paths total          104\n",
      "evaluation/num steps total         87712\n",
      "evaluation/num paths total           159\n",
      "evaluation/path length Mean          508.727\n",
      "evaluation/path length Std           385.806\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            38\n",
      "evaluation/Rewards Mean                3.69797\n",
      "evaluation/Rewards Std                 1.26296\n",
      "evaluation/Rewards Max                 5.89851\n",
      "evaluation/Rewards Min                -1.51787\n",
      "evaluation/Returns Mean             1881.26\n",
      "evaluation/Returns Std              1481.98\n",
      "evaluation/Returns Max              3982.77\n",
      "evaluation/Returns Min                30.287\n",
      "evaluation/Estimation Bias Mean      637.713\n",
      "evaluation/Estimation Bias Std       190.063\n",
      "evaluation/EB/Q_True Mean             65.3018\n",
      "evaluation/EB/Q_True Std             144.627\n",
      "evaluation/EB/Q_Pred Mean            703.014\n",
      "evaluation/EB/Q_Pred Std             107.052\n",
      "evaluation/Num Paths                  11\n",
      "evaluation/Average Returns          1881.26\n",
      "evaluation/Actions Mean                0.0140743\n",
      "evaluation/Actions Std                 0.509127\n",
      "evaluation/Actions Max                 0.999224\n",
      "evaluation/Actions Min                -0.999898\n",
      "time/backward_policy (s)               1.64834\n",
      "time/backward_zf1 (s)                  1.74069\n",
      "time/backward_zf2 (s)                  1.68772\n",
      "time/data sampling (s)                 0.235145\n",
      "time/data storing (s)                  0.0136329\n",
      "time/evaluation sampling (s)           1.68898\n",
      "time/exploration sampling (s)          0.314038\n",
      "time/logging (s)                       0.00746682\n",
      "time/preback_alpha (s)                 0.855033\n",
      "time/preback_policy (s)                0.926604\n",
      "time/preback_start (s)                 0.13449\n",
      "time/preback_zf (s)                    5.06277\n",
      "time/saving (s)                        0.00594967\n",
      "time/training (s)                      2.42881\n",
      "time/epoch (s)                        16.7497\n",
      "time/total (s)                       263.221\n",
      "Epoch                                 14\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:56:46.281289 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 15 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 26000\n",
      "trainer/ZF1 Loss                      -0.871555\n",
      "trainer/ZF2 Loss                      -0.156395\n",
      "trainer/ZF Expert Reward              17.9229\n",
      "trainer/ZF Policy Reward              -3.95651\n",
      "trainer/ZF CHI2 Term                  46.6572\n",
      "trainer/Policy Loss                  -75.1728\n",
      "trainer/Bias Loss                     92.4678\n",
      "trainer/Bias Value                    11.5064\n",
      "trainer/Policy Grad Norm              75.35\n",
      "trainer/Policy Param Norm             22.6758\n",
      "trainer/Zf1 Grad Norm               1860.37\n",
      "trainer/Zf1 Param Norm                56.8665\n",
      "trainer/Zf2 Grad Norm               2136.44\n",
      "trainer/Zf2 Param Norm                57.2584\n",
      "trainer/Z Expert Predictions Mean    758.196\n",
      "trainer/Z Expert Predictions Std      39.4249\n",
      "trainer/Z Expert Predictions Max     791.922\n",
      "trainer/Z Expert Predictions Min     465.022\n",
      "trainer/Z Policy Predictions Mean     61.6048\n",
      "trainer/Z Policy Predictions Std     392.781\n",
      "trainer/Z Policy Predictions Max     763.742\n",
      "trainer/Z Policy Predictions Min    -457.689\n",
      "trainer/Z Expert Targets Mean        740.273\n",
      "trainer/Z Expert Targets Std          37.885\n",
      "trainer/Z Expert Targets Max         772.04\n",
      "trainer/Z Expert Targets Min         499.41\n",
      "trainer/Z Policy Targets Mean         65.5614\n",
      "trainer/Z Policy Targets Std         388.135\n",
      "trainer/Z Policy Targets Max         756.788\n",
      "trainer/Z Policy Targets Min        -448.585\n",
      "trainer/Log Pis Mean                  25.5472\n",
      "trainer/Log Pis Std                   11.5977\n",
      "trainer/Policy mu Mean                -0.270789\n",
      "trainer/Policy mu Std                  2.27394\n",
      "trainer/Policy log std Mean           -2.14695\n",
      "trainer/Policy log std Std             1.85236\n",
      "trainer/Alpha                          0.0225616\n",
      "trainer/Alpha Loss                    -0.125144\n",
      "exploration/num steps total        23566\n",
      "exploration/num paths total          105\n",
      "evaluation/num steps total         89473\n",
      "evaluation/num paths total           169\n",
      "evaluation/path length Mean          176.1\n",
      "evaluation/path length Std            88.1254\n",
      "evaluation/path length Max           328\n",
      "evaluation/path length Min            32\n",
      "evaluation/Rewards Mean                2.76845\n",
      "evaluation/Rewards Std                 1.52383\n",
      "evaluation/Rewards Max                 5.97014\n",
      "evaluation/Rewards Min                -1.5592\n",
      "evaluation/Returns Mean              487.525\n",
      "evaluation/Returns Std               283.926\n",
      "evaluation/Returns Max               919.011\n",
      "evaluation/Returns Min                17.6523\n",
      "evaluation/Estimation Bias Mean      576.115\n",
      "evaluation/Estimation Bias Std       170.912\n",
      "evaluation/EB/Q_True Mean             33.6914\n",
      "evaluation/EB/Q_True Std              78.8625\n",
      "evaluation/EB/Q_Pred Mean            609.807\n",
      "evaluation/EB/Q_Pred Std             151.143\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           487.525\n",
      "evaluation/Actions Mean               -0.0013232\n",
      "evaluation/Actions Std                 0.50952\n",
      "evaluation/Actions Max                 0.999628\n",
      "evaluation/Actions Min                -0.999918\n",
      "time/backward_policy (s)               1.65409\n",
      "time/backward_zf1 (s)                  1.74279\n",
      "time/backward_zf2 (s)                  1.68909\n",
      "time/data sampling (s)                 0.238297\n",
      "time/data storing (s)                  0.0136815\n",
      "time/evaluation sampling (s)           0.64749\n",
      "time/exploration sampling (s)          0.313492\n",
      "time/logging (s)                       0.00393836\n",
      "time/preback_alpha (s)                 0.857186\n",
      "time/preback_policy (s)                0.934203\n",
      "time/preback_start (s)                 0.135851\n",
      "time/preback_zf (s)                    5.05985\n",
      "time/saving (s)                        0.00840254\n",
      "time/training (s)                      2.41655\n",
      "time/epoch (s)                        15.7149\n",
      "time/total (s)                       278.956\n",
      "Epoch                                 15\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:57:03.188913 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 16 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 27000\n",
      "trainer/ZF1 Loss                      21.4214\n",
      "trainer/ZF2 Loss                      29.1109\n",
      "trainer/ZF Expert Reward              19.9713\n",
      "trainer/ZF Policy Reward              -7.18502\n",
      "trainer/ZF CHI2 Term                  78.6276\n",
      "trainer/Policy Loss                 -134.359\n",
      "trainer/Bias Loss                     96.9386\n",
      "trainer/Bias Value                    11.5972\n",
      "trainer/Policy Grad Norm              99.7821\n",
      "trainer/Policy Param Norm             22.9652\n",
      "trainer/Zf1 Grad Norm               2330.47\n",
      "trainer/Zf1 Param Norm                57.8427\n",
      "trainer/Zf2 Grad Norm               2099.22\n",
      "trainer/Zf2 Param Norm                58.2572\n",
      "trainer/Z Expert Predictions Mean    804.808\n",
      "trainer/Z Expert Predictions Std      49.3642\n",
      "trainer/Z Expert Predictions Max     837.809\n",
      "trainer/Z Expert Predictions Min     467.864\n",
      "trainer/Z Policy Predictions Mean    123.538\n",
      "trainer/Z Policy Predictions Std     416.957\n",
      "trainer/Z Policy Predictions Max     830.493\n",
      "trainer/Z Policy Predictions Min    -481.924\n",
      "trainer/Z Expert Targets Mean        784.837\n",
      "trainer/Z Expert Targets Std          49.3906\n",
      "trainer/Z Expert Targets Max         817.447\n",
      "trainer/Z Expert Targets Min         440.568\n",
      "trainer/Z Policy Targets Mean        130.723\n",
      "trainer/Z Policy Targets Std         409.773\n",
      "trainer/Z Policy Targets Max         809.891\n",
      "trainer/Z Policy Targets Min        -474.13\n",
      "trainer/Log Pis Mean                  26.4699\n",
      "trainer/Log Pis Std                   12.4017\n",
      "trainer/Policy mu Mean                -0.260933\n",
      "trainer/Policy mu Std                  2.26018\n",
      "trainer/Policy log std Mean           -2.24732\n",
      "trainer/Policy log std Std             1.78168\n",
      "trainer/Alpha                          0.024576\n",
      "trainer/Alpha Loss                    -0.15899\n",
      "exploration/num steps total        24075\n",
      "exploration/num paths total          107\n",
      "evaluation/num steps total         90923\n",
      "evaluation/num paths total           179\n",
      "evaluation/path length Mean          145\n",
      "evaluation/path length Std           137.188\n",
      "evaluation/path length Max           477\n",
      "evaluation/path length Min            19\n",
      "evaluation/Rewards Mean                3.25083\n",
      "evaluation/Rewards Std                 1.63889\n",
      "evaluation/Rewards Max                 6.77541\n",
      "evaluation/Rewards Min                -1.95729\n",
      "evaluation/Returns Mean              471.371\n",
      "evaluation/Returns Std               518.567\n",
      "evaluation/Returns Max              1719.46\n",
      "evaluation/Returns Min                 6.62906\n",
      "evaluation/Estimation Bias Mean      637.411\n",
      "evaluation/Estimation Bias Std       196.922\n",
      "evaluation/EB/Q_True Mean             76.7819\n",
      "evaluation/EB/Q_True Std             121.879\n",
      "evaluation/EB/Q_Pred Mean            714.193\n",
      "evaluation/EB/Q_Pred Std             149.849\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           471.371\n",
      "evaluation/Actions Mean                0.0366414\n",
      "evaluation/Actions Std                 0.520146\n",
      "evaluation/Actions Max                 0.999532\n",
      "evaluation/Actions Min                -0.999933\n",
      "time/backward_policy (s)               1.87534\n",
      "time/backward_zf1 (s)                  1.95483\n",
      "time/backward_zf2 (s)                  1.90587\n",
      "time/data sampling (s)                 0.25587\n",
      "time/data storing (s)                  0.0138377\n",
      "time/evaluation sampling (s)           0.952095\n",
      "time/exploration sampling (s)          0.312545\n",
      "time/logging (s)                       0.00272163\n",
      "time/preback_alpha (s)                 0.969089\n",
      "time/preback_policy (s)                1.07738\n",
      "time/preback_start (s)                 0.141002\n",
      "time/preback_zf (s)                    5.12341\n",
      "time/saving (s)                        0.00543218\n",
      "time/training (s)                      2.24914\n",
      "time/epoch (s)                        16.8386\n",
      "time/total (s)                       295.818\n",
      "Epoch                                 16\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:57:20.573825 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 17 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  28000\n",
      "trainer/ZF1 Loss                        0.635265\n",
      "trainer/ZF2 Loss                        5.18827\n",
      "trainer/ZF Expert Reward               17.026\n",
      "trainer/ZF Policy Reward              -11.6506\n",
      "trainer/ZF CHI2 Term                   56.6527\n",
      "trainer/Policy Loss                  -169.383\n",
      "trainer/Bias Loss                      95.2969\n",
      "trainer/Bias Value                     11.6867\n",
      "trainer/Policy Grad Norm               69.3283\n",
      "trainer/Policy Param Norm              23.236\n",
      "trainer/Zf1 Grad Norm                1575.9\n",
      "trainer/Zf1 Param Norm                 58.7554\n",
      "trainer/Zf2 Grad Norm                2998.89\n",
      "trainer/Zf2 Param Norm                 59.1946\n",
      "trainer/Z Expert Predictions Mean     840.244\n",
      "trainer/Z Expert Predictions Std       56.8346\n",
      "trainer/Z Expert Predictions Max      884.806\n",
      "trainer/Z Expert Predictions Min      504.672\n",
      "trainer/Z Policy Predictions Mean     157.711\n",
      "trainer/Z Policy Predictions Std      431.276\n",
      "trainer/Z Policy Predictions Max      865.91\n",
      "trainer/Z Policy Predictions Min     -502.567\n",
      "trainer/Z Expert Targets Mean         823.218\n",
      "trainer/Z Expert Targets Std           53.705\n",
      "trainer/Z Expert Targets Max          864.781\n",
      "trainer/Z Expert Targets Min          506.921\n",
      "trainer/Z Policy Targets Mean         169.362\n",
      "trainer/Z Policy Targets Std          430.05\n",
      "trainer/Z Policy Targets Max          853.705\n",
      "trainer/Z Policy Targets Min         -497.175\n",
      "trainer/Log Pis Mean                   25.3174\n",
      "trainer/Log Pis Std                     9.21129\n",
      "trainer/Policy mu Mean                 -0.127126\n",
      "trainer/Policy mu Std                   2.14588\n",
      "trainer/Policy log std Mean            -2.30745\n",
      "trainer/Policy log std Std              1.80376\n",
      "trainer/Alpha                           0.0265511\n",
      "trainer/Alpha Loss                     -0.141172\n",
      "exploration/num steps total         24075\n",
      "exploration/num paths total           107\n",
      "evaluation/num steps total         100429\n",
      "evaluation/num paths total            189\n",
      "evaluation/path length Mean           950.6\n",
      "evaluation/path length Std            148.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            506\n",
      "evaluation/Rewards Mean                 3.19411\n",
      "evaluation/Rewards Std                  2.44018\n",
      "evaluation/Rewards Max                  6.15829\n",
      "evaluation/Rewards Min                 -3.41793\n",
      "evaluation/Returns Mean              3036.32\n",
      "evaluation/Returns Std               2061.36\n",
      "evaluation/Returns Max               4176.25\n",
      "evaluation/Returns Min              -2775.67\n",
      "evaluation/Estimation Bias Mean       642.778\n",
      "evaluation/Estimation Bias Std        446.073\n",
      "evaluation/EB/Q_True Mean              39.8571\n",
      "evaluation/EB/Q_True Std              119.702\n",
      "evaluation/EB/Q_Pred Mean             682.635\n",
      "evaluation/EB/Q_Pred Std              442.652\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3036.32\n",
      "evaluation/Actions Mean                 0.00627997\n",
      "evaluation/Actions Std                  0.575223\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70885\n",
      "time/backward_zf1 (s)                   1.80855\n",
      "time/backward_zf2 (s)                   1.75206\n",
      "time/data sampling (s)                  0.232251\n",
      "time/data storing (s)                   0.0138805\n",
      "time/evaluation sampling (s)            1.78404\n",
      "time/exploration sampling (s)           0.318331\n",
      "time/logging (s)                        0.012291\n",
      "time/preback_alpha (s)                  0.871704\n",
      "time/preback_policy (s)                 0.949605\n",
      "time/preback_start (s)                  0.142405\n",
      "time/preback_zf (s)                     5.12959\n",
      "time/saving (s)                         0.0200147\n",
      "time/training (s)                       2.58868\n",
      "time/epoch (s)                         17.3323\n",
      "time/total (s)                        313.167\n",
      "Epoch                                  17\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 10:57:37.997286 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 18 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  29000\n",
      "trainer/ZF1 Loss                        6.75017\n",
      "trainer/ZF2 Loss                        5.16744\n",
      "trainer/ZF Expert Reward               20.4989\n",
      "trainer/ZF Policy Reward               -6.06975\n",
      "trainer/ZF CHI2 Term                   58.4016\n",
      "trainer/Policy Loss                  -201.171\n",
      "trainer/Bias Loss                     123.088\n",
      "trainer/Bias Value                     11.7766\n",
      "trainer/Policy Grad Norm               66.0568\n",
      "trainer/Policy Param Norm              23.4884\n",
      "trainer/Zf1 Grad Norm                1337.17\n",
      "trainer/Zf1 Param Norm                 59.5703\n",
      "trainer/Zf2 Grad Norm                1401.99\n",
      "trainer/Zf2 Param Norm                 60.0107\n",
      "trainer/Z Expert Predictions Mean     876.448\n",
      "trainer/Z Expert Predictions Std       68.2486\n",
      "trainer/Z Expert Predictions Max      929.167\n",
      "trainer/Z Expert Predictions Min      539.248\n",
      "trainer/Z Policy Predictions Mean     187.019\n",
      "trainer/Z Policy Predictions Std      466.582\n",
      "trainer/Z Policy Predictions Max      904.964\n",
      "trainer/Z Policy Predictions Min     -520.178\n",
      "trainer/Z Expert Targets Mean         855.949\n",
      "trainer/Z Expert Targets Std           68.6337\n",
      "trainer/Z Expert Targets Max          907.82\n",
      "trainer/Z Expert Targets Min          515.831\n",
      "trainer/Z Policy Targets Mean         193.089\n",
      "trainer/Z Policy Targets Std          462.265\n",
      "trainer/Z Policy Targets Max          891.36\n",
      "trainer/Z Policy Targets Min         -512.12\n",
      "trainer/Log Pis Mean                   26.1355\n",
      "trainer/Log Pis Std                     9.5148\n",
      "trainer/Policy mu Mean                 -0.112086\n",
      "trainer/Policy mu Std                   2.18013\n",
      "trainer/Policy log std Mean            -2.36145\n",
      "trainer/Policy log std Std              1.74542\n",
      "trainer/Alpha                           0.0287658\n",
      "trainer/Alpha Loss                     -0.176479\n",
      "exploration/num steps total         24075\n",
      "exploration/num paths total           107\n",
      "evaluation/num steps total         108923\n",
      "evaluation/num paths total            200\n",
      "evaluation/path length Mean           772.182\n",
      "evaluation/path length Std            379.934\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             48\n",
      "evaluation/Rewards Mean                 3.69385\n",
      "evaluation/Rewards Std                  1.08422\n",
      "evaluation/Rewards Max                  5.91629\n",
      "evaluation/Rewards Min                 -1.95356\n",
      "evaluation/Returns Mean              2852.32\n",
      "evaluation/Returns Std               1482.04\n",
      "evaluation/Returns Max               3882.23\n",
      "evaluation/Returns Min                 53.5815\n",
      "evaluation/Estimation Bias Mean       826.289\n",
      "evaluation/Estimation Bias Std        169.059\n",
      "evaluation/EB/Q_True Mean              40.4374\n",
      "evaluation/EB/Q_True Std              113.839\n",
      "evaluation/EB/Q_Pred Mean             866.727\n",
      "evaluation/EB/Q_Pred Std              111.269\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2852.32\n",
      "evaluation/Actions Mean                 0.00993193\n",
      "evaluation/Actions Std                  0.532357\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999976\n",
      "time/backward_policy (s)                1.71057\n",
      "time/backward_zf1 (s)                   1.84144\n",
      "time/backward_zf2 (s)                   1.74643\n",
      "time/data sampling (s)                  0.285688\n",
      "time/data storing (s)                   0.0141069\n",
      "time/evaluation sampling (s)            1.81699\n",
      "time/exploration sampling (s)           0.312553\n",
      "time/logging (s)                        0.0107479\n",
      "time/preback_alpha (s)                  0.880433\n",
      "time/preback_policy (s)                 0.955866\n",
      "time/preback_start (s)                  0.141675\n",
      "time/preback_zf (s)                     5.14215\n",
      "time/saving (s)                         0.0057207\n",
      "time/training (s)                       2.49346\n",
      "time/epoch (s)                         17.3578\n",
      "time/total (s)                        330.544\n",
      "Epoch                                  18\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 10:57:56.454032 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 19 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  30000\n",
      "trainer/ZF1 Loss                        5.9245\n",
      "trainer/ZF2 Loss                        3.75778\n",
      "trainer/ZF Expert Reward               16.7949\n",
      "trainer/ZF Policy Reward               -8.96852\n",
      "trainer/ZF CHI2 Term                   55.406\n",
      "trainer/Policy Loss                  -250.96\n",
      "trainer/Bias Loss                     147.185\n",
      "trainer/Bias Value                     11.8645\n",
      "trainer/Policy Grad Norm               79.0181\n",
      "trainer/Policy Param Norm              23.7666\n",
      "trainer/Zf1 Grad Norm                2578.79\n",
      "trainer/Zf1 Param Norm                 60.2847\n",
      "trainer/Zf2 Grad Norm                2435.26\n",
      "trainer/Zf2 Param Norm                 60.7454\n",
      "trainer/Z Expert Predictions Mean     915.245\n",
      "trainer/Z Expert Predictions Std       56.3638\n",
      "trainer/Z Expert Predictions Max      962.917\n",
      "trainer/Z Expert Predictions Min      654.09\n",
      "trainer/Z Policy Predictions Mean     235.743\n",
      "trainer/Z Policy Predictions Std      457.963\n",
      "trainer/Z Policy Predictions Max      946.646\n",
      "trainer/Z Policy Predictions Min     -523.602\n",
      "trainer/Z Expert Targets Mean         898.45\n",
      "trainer/Z Expert Targets Std           57.3783\n",
      "trainer/Z Expert Targets Max          948.23\n",
      "trainer/Z Expert Targets Min          606.809\n",
      "trainer/Z Policy Targets Mean         244.711\n",
      "trainer/Z Policy Targets Std          453.905\n",
      "trainer/Z Policy Targets Max          937.253\n",
      "trainer/Z Policy Targets Min         -515.08\n",
      "trainer/Log Pis Mean                   25.052\n",
      "trainer/Log Pis Std                     8.48721\n",
      "trainer/Policy mu Mean                  0.0829396\n",
      "trainer/Policy mu Std                   2.187\n",
      "trainer/Policy log std Mean            -2.50541\n",
      "trainer/Policy log std Std              1.47351\n",
      "trainer/Alpha                           0.0311715\n",
      "trainer/Alpha Loss                     -0.157467\n",
      "exploration/num steps total         24075\n",
      "exploration/num paths total           107\n",
      "evaluation/num steps total         117919\n",
      "evaluation/num paths total            210\n",
      "evaluation/path length Mean           899.6\n",
      "evaluation/path length Std            218.038\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            308\n",
      "evaluation/Rewards Mean                 3.89622\n",
      "evaluation/Rewards Std                  0.993385\n",
      "evaluation/Rewards Max                  6.10596\n",
      "evaluation/Rewards Min                 -2.70701\n",
      "evaluation/Returns Mean              3505.04\n",
      "evaluation/Returns Std                863.447\n",
      "evaluation/Returns Max               4065.44\n",
      "evaluation/Returns Min               1137.82\n",
      "evaluation/Estimation Bias Mean       891.576\n",
      "evaluation/Estimation Bias Std        140.262\n",
      "evaluation/EB/Q_True Mean              39.6658\n",
      "evaluation/EB/Q_True Std              115.198\n",
      "evaluation/EB/Q_Pred Mean             931.242\n",
      "evaluation/EB/Q_Pred Std               79.3733\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3505.04\n",
      "evaluation/Actions Mean                 0.0327507\n",
      "evaluation/Actions Std                  0.521749\n",
      "evaluation/Actions Max                  0.999564\n",
      "evaluation/Actions Min                 -0.999985\n",
      "time/backward_policy (s)                1.9221\n",
      "time/backward_zf1 (s)                   2.09279\n",
      "time/backward_zf2 (s)                   2.03028\n",
      "time/data sampling (s)                  0.316257\n",
      "time/data storing (s)                   0.0142972\n",
      "time/evaluation sampling (s)            1.8035\n",
      "time/exploration sampling (s)           0.324594\n",
      "time/logging (s)                        0.0113118\n",
      "time/preback_alpha (s)                  1.00085\n",
      "time/preback_policy (s)                 1.14966\n",
      "time/preback_start (s)                  0.146858\n",
      "time/preback_zf (s)                     5.28654\n",
      "time/saving (s)                         0.00615888\n",
      "time/training (s)                       2.28324\n",
      "time/epoch (s)                         18.3884\n",
      "time/total (s)                        348.952\n",
      "Epoch                                  19\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 10:58:13.696453 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 20 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  31000\n",
      "trainer/ZF1 Loss                       27.8557\n",
      "trainer/ZF2 Loss                       17.4734\n",
      "trainer/ZF Expert Reward               16.38\n",
      "trainer/ZF Policy Reward              -14.1543\n",
      "trainer/ZF CHI2 Term                   77.9625\n",
      "trainer/Policy Loss                  -277.464\n",
      "trainer/Bias Loss                     135.783\n",
      "trainer/Bias Value                     11.9489\n",
      "trainer/Policy Grad Norm               94.4278\n",
      "trainer/Policy Param Norm              24.0404\n",
      "trainer/Zf1 Grad Norm                2601.76\n",
      "trainer/Zf1 Param Norm                 60.9627\n",
      "trainer/Zf2 Grad Norm                1799.74\n",
      "trainer/Zf2 Param Norm                 61.4463\n",
      "trainer/Z Expert Predictions Mean     953.75\n",
      "trainer/Z Expert Predictions Std       84.1269\n",
      "trainer/Z Expert Predictions Max     1009.39\n",
      "trainer/Z Expert Predictions Min      129.173\n",
      "trainer/Z Policy Predictions Mean     263.792\n",
      "trainer/Z Policy Predictions Std      501.196\n",
      "trainer/Z Policy Predictions Max      985.712\n",
      "trainer/Z Policy Predictions Min     -524.948\n",
      "trainer/Z Expert Targets Mean         937.37\n",
      "trainer/Z Expert Targets Std           87.1397\n",
      "trainer/Z Expert Targets Max          989.737\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         277.946\n",
      "trainer/Z Policy Targets Std          497.683\n",
      "trainer/Z Policy Targets Max          974.179\n",
      "trainer/Z Policy Targets Min         -514.545\n",
      "trainer/Log Pis Mean                   25.0138\n",
      "trainer/Log Pis Std                     9.14887\n",
      "trainer/Policy mu Mean                  0.194643\n",
      "trainer/Policy mu Std                   2.32493\n",
      "trainer/Policy log std Mean            -2.26677\n",
      "trainer/Policy log std Std              1.58419\n",
      "trainer/Alpha                           0.0334167\n",
      "trainer/Alpha Loss                     -0.167533\n",
      "exploration/num steps total         24075\n",
      "exploration/num paths total           107\n",
      "evaluation/num steps total         125698\n",
      "evaluation/num paths total            220\n",
      "evaluation/path length Mean           777.9\n",
      "evaluation/path length Std            278.295\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            277\n",
      "evaluation/Rewards Mean                 3.87487\n",
      "evaluation/Rewards Std                  1.24028\n",
      "evaluation/Rewards Max                  6.44683\n",
      "evaluation/Rewards Min                 -3.82733\n",
      "evaluation/Returns Mean              3014.26\n",
      "evaluation/Returns Std               1097.52\n",
      "evaluation/Returns Max               3953.56\n",
      "evaluation/Returns Min                947.52\n",
      "evaluation/Estimation Bias Mean       875.944\n",
      "evaluation/Estimation Bias Std        172.088\n",
      "evaluation/EB/Q_True Mean              43.9538\n",
      "evaluation/EB/Q_True Std              118.223\n",
      "evaluation/EB/Q_Pred Mean             919.898\n",
      "evaluation/EB/Q_Pred Std              122.469\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3014.26\n",
      "evaluation/Actions Mean                 0.0303253\n",
      "evaluation/Actions Std                  0.524851\n",
      "evaluation/Actions Max                  0.999413\n",
      "evaluation/Actions Min                 -0.999962\n",
      "time/backward_policy (s)                1.70825\n",
      "time/backward_zf1 (s)                   1.82402\n",
      "time/backward_zf2 (s)                   1.765\n",
      "time/data sampling (s)                  0.277706\n",
      "time/data storing (s)                   0.0137529\n",
      "time/evaluation sampling (s)            1.74391\n",
      "time/exploration sampling (s)           0.308938\n",
      "time/logging (s)                        0.00956063\n",
      "time/preback_alpha (s)                  0.896814\n",
      "time/preback_policy (s)                 0.975837\n",
      "time/preback_start (s)                  0.138635\n",
      "time/preback_zf (s)                     5.11251\n",
      "time/saving (s)                         0.00603566\n",
      "time/training (s)                       2.39451\n",
      "time/epoch (s)                         17.1755\n",
      "time/total (s)                        366.148\n",
      "Epoch                                  20\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 10:58:31.173784 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 21 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  32000\n",
      "trainer/ZF1 Loss                       53.8438\n",
      "trainer/ZF2 Loss                       46.306\n",
      "trainer/ZF Expert Reward               15.2976\n",
      "trainer/ZF Policy Reward              -12.5539\n",
      "trainer/ZF CHI2 Term                  103.598\n",
      "trainer/Policy Loss                  -301.253\n",
      "trainer/Bias Loss                     124.867\n",
      "trainer/Bias Value                     12.0335\n",
      "trainer/Policy Grad Norm               64.6663\n",
      "trainer/Policy Param Norm              24.2679\n",
      "trainer/Zf1 Grad Norm                1717.92\n",
      "trainer/Zf1 Param Norm                 61.5781\n",
      "trainer/Zf2 Grad Norm                1362.58\n",
      "trainer/Zf2 Param Norm                 62.0987\n",
      "trainer/Z Expert Predictions Mean     989.925\n",
      "trainer/Z Expert Predictions Std       65.5073\n",
      "trainer/Z Expert Predictions Max     1048.23\n",
      "trainer/Z Expert Predictions Min      619.224\n",
      "trainer/Z Policy Predictions Mean     283.385\n",
      "trainer/Z Policy Predictions Std      519.268\n",
      "trainer/Z Policy Predictions Max     1026.69\n",
      "trainer/Z Policy Predictions Min     -517.695\n",
      "trainer/Z Expert Targets Mean         974.627\n",
      "trainer/Z Expert Targets Std           64.2616\n",
      "trainer/Z Expert Targets Max         1028.81\n",
      "trainer/Z Expert Targets Min          617.968\n",
      "trainer/Z Policy Targets Mean         295.939\n",
      "trainer/Z Policy Targets Std          513.661\n",
      "trainer/Z Policy Targets Max         1017.84\n",
      "trainer/Z Policy Targets Min         -515.928\n",
      "trainer/Log Pis Mean                   25.9309\n",
      "trainer/Log Pis Std                     9.37206\n",
      "trainer/Policy mu Mean                  0.366157\n",
      "trainer/Policy mu Std                   2.27728\n",
      "trainer/Policy log std Mean            -2.22994\n",
      "trainer/Policy log std Std              1.70001\n",
      "trainer/Alpha                           0.036038\n",
      "trainer/Alpha Loss                     -0.213723\n",
      "exploration/num steps total         25075\n",
      "exploration/num paths total           108\n",
      "evaluation/num steps total         129025\n",
      "evaluation/num paths total            230\n",
      "evaluation/path length Mean           332.7\n",
      "evaluation/path length Std            201.389\n",
      "evaluation/path length Max            725\n",
      "evaluation/path length Min             69\n",
      "evaluation/Rewards Mean                 3.64794\n",
      "evaluation/Rewards Std                  1.2696\n",
      "evaluation/Rewards Max                  6.24116\n",
      "evaluation/Rewards Min                 -2.17448\n",
      "evaluation/Returns Mean              1213.67\n",
      "evaluation/Returns Std                805.303\n",
      "evaluation/Returns Max               2785.14\n",
      "evaluation/Returns Min                142.964\n",
      "evaluation/Estimation Bias Mean       890.845\n",
      "evaluation/Estimation Bias Std        193.081\n",
      "evaluation/EB/Q_True Mean              63.9491\n",
      "evaluation/EB/Q_True Std              129.959\n",
      "evaluation/EB/Q_Pred Mean             954.794\n",
      "evaluation/EB/Q_Pred Std              133.044\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1213.67\n",
      "evaluation/Actions Mean                 0.0159398\n",
      "evaluation/Actions Std                  0.522329\n",
      "evaluation/Actions Max                  0.999517\n",
      "evaluation/Actions Min                 -0.99998\n",
      "time/backward_policy (s)                1.89062\n",
      "time/backward_zf1 (s)                   2.00541\n",
      "time/backward_zf2 (s)                   1.95516\n",
      "time/data sampling (s)                  0.26193\n",
      "time/data storing (s)                   0.0138239\n",
      "time/evaluation sampling (s)            1.48145\n",
      "time/exploration sampling (s)           0.312966\n",
      "time/logging (s)                        0.0048667\n",
      "time/preback_alpha (s)                  1.02058\n",
      "time/preback_policy (s)                 1.15813\n",
      "time/preback_start (s)                  0.13955\n",
      "time/preback_zf (s)                     5.13514\n",
      "time/saving (s)                         0.0168192\n",
      "time/training (s)                       2.00998\n",
      "time/epoch (s)                         17.4064\n",
      "time/total (s)                        383.576\n",
      "Epoch                                  21\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:58:48.788731 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 22 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  33000\n",
      "trainer/ZF1 Loss                       59.7131\n",
      "trainer/ZF2 Loss                       61.5078\n",
      "trainer/ZF Expert Reward               18.1171\n",
      "trainer/ZF Policy Reward              -11.1475\n",
      "trainer/ZF CHI2 Term                  113.895\n",
      "trainer/Policy Loss                  -443.743\n",
      "trainer/Bias Loss                     134.327\n",
      "trainer/Bias Value                     12.1159\n",
      "trainer/Policy Grad Norm               84.4751\n",
      "trainer/Policy Param Norm              24.4718\n",
      "trainer/Zf1 Grad Norm                2826.97\n",
      "trainer/Zf1 Param Norm                 62.1317\n",
      "trainer/Zf2 Grad Norm                3171.46\n",
      "trainer/Zf2 Param Norm                 62.6993\n",
      "trainer/Z Expert Predictions Mean    1038.44\n",
      "trainer/Z Expert Predictions Std       55.7574\n",
      "trainer/Z Expert Predictions Max     1089.3\n",
      "trainer/Z Expert Predictions Min      680.28\n",
      "trainer/Z Policy Predictions Mean     426.646\n",
      "trainer/Z Policy Predictions Std      488.938\n",
      "trainer/Z Policy Predictions Max     1074.28\n",
      "trainer/Z Policy Predictions Min     -491.188\n",
      "trainer/Z Expert Targets Mean        1020.33\n",
      "trainer/Z Expert Targets Std           54.1431\n",
      "trainer/Z Expert Targets Max         1070.47\n",
      "trainer/Z Expert Targets Min          680.023\n",
      "trainer/Z Policy Targets Mean         437.793\n",
      "trainer/Z Policy Targets Std          479.235\n",
      "trainer/Z Policy Targets Max         1051.32\n",
      "trainer/Z Policy Targets Min         -485.102\n",
      "trainer/Log Pis Mean                   24.2628\n",
      "trainer/Log Pis Std                     9.75956\n",
      "trainer/Policy mu Mean                  0.20794\n",
      "trainer/Policy mu Std                   2.15122\n",
      "trainer/Policy log std Mean            -2.48088\n",
      "trainer/Policy log std Std              1.36522\n",
      "trainer/Alpha                           0.0391472\n",
      "trainer/Alpha Loss                     -0.166865\n",
      "exploration/num steps total         27062\n",
      "exploration/num paths total           110\n",
      "evaluation/num steps total         137392\n",
      "evaluation/num paths total            244\n",
      "evaluation/path length Mean           597.643\n",
      "evaluation/path length Std            376.489\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             37\n",
      "evaluation/Rewards Mean                 3.91222\n",
      "evaluation/Rewards Std                  1.29543\n",
      "evaluation/Rewards Max                  6.55097\n",
      "evaluation/Rewards Min                 -2.41128\n",
      "evaluation/Returns Mean              2338.11\n",
      "evaluation/Returns Std               1500.02\n",
      "evaluation/Returns Max               4089.74\n",
      "evaluation/Returns Min                -37.0829\n",
      "evaluation/Estimation Bias Mean       955.804\n",
      "evaluation/Estimation Bias Std        178.748\n",
      "evaluation/EB/Q_True Mean              44.2255\n",
      "evaluation/EB/Q_True Std              123.349\n",
      "evaluation/EB/Q_Pred Mean            1000.03\n",
      "evaluation/EB/Q_Pred Std              131.956\n",
      "evaluation/Num Paths                   14\n",
      "evaluation/Average Returns           2338.11\n",
      "evaluation/Actions Mean                 0.0201836\n",
      "evaluation/Actions Std                  0.531264\n",
      "evaluation/Actions Max                  0.999876\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.8806\n",
      "time/backward_zf1 (s)                   1.98661\n",
      "time/backward_zf2 (s)                   1.95137\n",
      "time/data sampling (s)                  0.238298\n",
      "time/data storing (s)                   0.0136381\n",
      "time/evaluation sampling (s)            1.81666\n",
      "time/exploration sampling (s)           0.313925\n",
      "time/logging (s)                        0.0106392\n",
      "time/preback_alpha (s)                  1.01903\n",
      "time/preback_policy (s)                 1.16697\n",
      "time/preback_start (s)                  0.138373\n",
      "time/preback_zf (s)                     5.09112\n",
      "time/saving (s)                         0.00644946\n",
      "time/training (s)                       1.92402\n",
      "time/epoch (s)                         17.5577\n",
      "time/total (s)                        401.152\n",
      "Epoch                                  22\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 10:59:06.281440 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 23 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  34000\n",
      "trainer/ZF1 Loss                       20.9858\n",
      "trainer/ZF2 Loss                       17.2896\n",
      "trainer/ZF Expert Reward               15.516\n",
      "trainer/ZF Policy Reward               -2.49434\n",
      "trainer/ZF CHI2 Term                   62.0085\n",
      "trainer/Policy Loss                  -464.211\n",
      "trainer/Bias Loss                     110.848\n",
      "trainer/Bias Value                     12.1961\n",
      "trainer/Policy Grad Norm               79.8276\n",
      "trainer/Policy Param Norm              24.6674\n",
      "trainer/Zf1 Grad Norm                1673.75\n",
      "trainer/Zf1 Param Norm                 62.6462\n",
      "trainer/Zf2 Grad Norm                1821.22\n",
      "trainer/Zf2 Param Norm                 63.2717\n",
      "trainer/Z Expert Predictions Mean    1068.44\n",
      "trainer/Z Expert Predictions Std       56.7238\n",
      "trainer/Z Expert Predictions Max     1126.89\n",
      "trainer/Z Expert Predictions Min      721.812\n",
      "trainer/Z Policy Predictions Mean     453.517\n",
      "trainer/Z Policy Predictions Std      527.178\n",
      "trainer/Z Policy Predictions Max     1110.28\n",
      "trainer/Z Policy Predictions Min     -462.819\n",
      "trainer/Z Expert Targets Mean        1052.92\n",
      "trainer/Z Expert Targets Std           56.6494\n",
      "trainer/Z Expert Targets Max         1111.64\n",
      "trainer/Z Expert Targets Min          715.512\n",
      "trainer/Z Policy Targets Mean         456.011\n",
      "trainer/Z Policy Targets Std          520.449\n",
      "trainer/Z Policy Targets Max         1089.07\n",
      "trainer/Z Policy Targets Min         -458.821\n",
      "trainer/Log Pis Mean                   25.1115\n",
      "trainer/Log Pis Std                    10.379\n",
      "trainer/Policy mu Mean                  0.270789\n",
      "trainer/Policy mu Std                   2.31631\n",
      "trainer/Policy log std Mean            -2.49024\n",
      "trainer/Policy log std Std              1.36361\n",
      "trainer/Alpha                           0.0423813\n",
      "trainer/Alpha Loss                     -0.216615\n",
      "exploration/num steps total         29062\n",
      "exploration/num paths total           112\n",
      "evaluation/num steps total         140677\n",
      "evaluation/num paths total            254\n",
      "evaluation/path length Mean           328.5\n",
      "evaluation/path length Std            205.937\n",
      "evaluation/path length Max            655\n",
      "evaluation/path length Min             48\n",
      "evaluation/Rewards Mean                 3.66287\n",
      "evaluation/Rewards Std                  1.54269\n",
      "evaluation/Rewards Max                  6.62125\n",
      "evaluation/Rewards Min                 -2.26769\n",
      "evaluation/Returns Mean              1203.25\n",
      "evaluation/Returns Std                809.322\n",
      "evaluation/Returns Max               2550.23\n",
      "evaluation/Returns Min                 87.0443\n",
      "evaluation/Estimation Bias Mean       922.996\n",
      "evaluation/Estimation Bias Std        215.912\n",
      "evaluation/EB/Q_True Mean              65.0569\n",
      "evaluation/EB/Q_True Std              143.053\n",
      "evaluation/EB/Q_Pred Mean             988.053\n",
      "evaluation/EB/Q_Pred Std              154.249\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1203.25\n",
      "evaluation/Actions Mean                 0.0199471\n",
      "evaluation/Actions Std                  0.525256\n",
      "evaluation/Actions Max                  0.99994\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91804\n",
      "time/backward_zf1 (s)                   2.0559\n",
      "time/backward_zf2 (s)                   2.0279\n",
      "time/data sampling (s)                  0.274849\n",
      "time/data storing (s)                   0.014426\n",
      "time/evaluation sampling (s)            1.18263\n",
      "time/exploration sampling (s)           0.32376\n",
      "time/logging (s)                        0.00561429\n",
      "time/preback_alpha (s)                  1.00505\n",
      "time/preback_policy (s)                 1.16739\n",
      "time/preback_start (s)                  0.143131\n",
      "time/preback_zf (s)                     5.19789\n",
      "time/saving (s)                         0.00799043\n",
      "time/training (s)                       2.0962\n",
      "time/epoch (s)                         17.4208\n",
      "time/total (s)                        418.594\n",
      "Epoch                                  23\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 10:59:24.669904 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 24 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  35000\n",
      "trainer/ZF1 Loss                       16.1254\n",
      "trainer/ZF2 Loss                        4.81801\n",
      "trainer/ZF Expert Reward               20.0184\n",
      "trainer/ZF Policy Reward               -5.61961\n",
      "trainer/ZF CHI2 Term                   59.6418\n",
      "trainer/Policy Loss                  -517.496\n",
      "trainer/Bias Loss                     164.292\n",
      "trainer/Bias Value                     12.2749\n",
      "trainer/Policy Grad Norm              123.98\n",
      "trainer/Policy Param Norm              24.8583\n",
      "trainer/Zf1 Grad Norm                2109.42\n",
      "trainer/Zf1 Param Norm                 63.15\n",
      "trainer/Zf2 Grad Norm                1941.61\n",
      "trainer/Zf2 Param Norm                 63.844\n",
      "trainer/Z Expert Predictions Mean    1105.65\n",
      "trainer/Z Expert Predictions Std       49.001\n",
      "trainer/Z Expert Predictions Max     1159.3\n",
      "trainer/Z Expert Predictions Min      892.187\n",
      "trainer/Z Policy Predictions Mean     500.727\n",
      "trainer/Z Policy Predictions Std      511.327\n",
      "trainer/Z Policy Predictions Max     1145.81\n",
      "trainer/Z Policy Predictions Min     -437.802\n",
      "trainer/Z Expert Targets Mean        1085.63\n",
      "trainer/Z Expert Targets Std           50.0243\n",
      "trainer/Z Expert Targets Max         1142.58\n",
      "trainer/Z Expert Targets Min          880.11\n",
      "trainer/Z Policy Targets Mean         506.347\n",
      "trainer/Z Policy Targets Std          505.175\n",
      "trainer/Z Policy Targets Max         1125.25\n",
      "trainer/Z Policy Targets Min         -426.86\n",
      "trainer/Log Pis Mean                   23.7697\n",
      "trainer/Log Pis Std                     9.34687\n",
      "trainer/Policy mu Mean                  0.202669\n",
      "trainer/Policy mu Std                   2.19719\n",
      "trainer/Policy log std Mean            -2.50201\n",
      "trainer/Policy log std Std              1.33223\n",
      "trainer/Alpha                           0.0454933\n",
      "trainer/Alpha Loss                     -0.171487\n",
      "exploration/num steps total         31062\n",
      "exploration/num paths total           114\n",
      "evaluation/num steps total         149695\n",
      "evaluation/num paths total            264\n",
      "evaluation/path length Mean           901.8\n",
      "evaluation/path length Std            294.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             18\n",
      "evaluation/Rewards Mean                 3.72802\n",
      "evaluation/Rewards Std                  2.27263\n",
      "evaluation/Rewards Max                  6.57137\n",
      "evaluation/Rewards Min                 -3.41569\n",
      "evaluation/Returns Mean              3361.93\n",
      "evaluation/Returns Std               2024.09\n",
      "evaluation/Returns Max               4488.98\n",
      "evaluation/Returns Min              -1284.37\n",
      "evaluation/Estimation Bias Mean       946.568\n",
      "evaluation/Estimation Bias Std        466.218\n",
      "evaluation/EB/Q_True Mean              43.6379\n",
      "evaluation/EB/Q_True Std              127.303\n",
      "evaluation/EB/Q_Pred Mean             990.206\n",
      "evaluation/EB/Q_Pred Std              359.89\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3361.93\n",
      "evaluation/Actions Mean                 0.107361\n",
      "evaluation/Actions Std                  0.568187\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999977\n",
      "time/backward_policy (s)                1.90491\n",
      "time/backward_zf1 (s)                   2.10701\n",
      "time/backward_zf2 (s)                   1.97248\n",
      "time/data sampling (s)                  0.314286\n",
      "time/data storing (s)                   0.0152262\n",
      "time/evaluation sampling (s)            1.79116\n",
      "time/exploration sampling (s)           0.334063\n",
      "time/logging (s)                        0.0116557\n",
      "time/preback_alpha (s)                  0.98243\n",
      "time/preback_policy (s)                 1.11073\n",
      "time/preback_start (s)                  0.152318\n",
      "time/preback_zf (s)                     5.2864\n",
      "time/saving (s)                         0.0062211\n",
      "time/training (s)                       2.33232\n",
      "time/epoch (s)                         18.3212\n",
      "time/total (s)                        436.938\n",
      "Epoch                                  24\n",
      "---------------------------------  --------------\n",
      "2024-06-15 10:59:44.569990 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 25 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  36000\n",
      "trainer/ZF1 Loss                       22.6102\n",
      "trainer/ZF2 Loss                       22.0066\n",
      "trainer/ZF Expert Reward               13.4155\n",
      "trainer/ZF Policy Reward               -9.70038\n",
      "trainer/ZF CHI2 Term                   68.1824\n",
      "trainer/Policy Loss                  -495.905\n",
      "trainer/Bias Loss                     141.161\n",
      "trainer/Bias Value                     12.3505\n",
      "trainer/Policy Grad Norm               80.7826\n",
      "trainer/Policy Param Norm              25.0396\n",
      "trainer/Zf1 Grad Norm                2152.12\n",
      "trainer/Zf1 Param Norm                 63.6506\n",
      "trainer/Zf2 Grad Norm                2537.75\n",
      "trainer/Zf2 Param Norm                 64.3881\n",
      "trainer/Z Expert Predictions Mean    1124.81\n",
      "trainer/Z Expert Predictions Std       64.3013\n",
      "trainer/Z Expert Predictions Max     1189.07\n",
      "trainer/Z Expert Predictions Min      787.251\n",
      "trainer/Z Policy Predictions Mean     486.745\n",
      "trainer/Z Policy Predictions Std      528.03\n",
      "trainer/Z Policy Predictions Max     1180.62\n",
      "trainer/Z Policy Predictions Min     -407.923\n",
      "trainer/Z Expert Targets Mean        1111.4\n",
      "trainer/Z Expert Targets Std           63.971\n",
      "trainer/Z Expert Targets Max         1178.1\n",
      "trainer/Z Expert Targets Min          771.102\n",
      "trainer/Z Policy Targets Mean         496.446\n",
      "trainer/Z Policy Targets Std          525.715\n",
      "trainer/Z Policy Targets Max         1177.3\n",
      "trainer/Z Policy Targets Min         -396.988\n",
      "trainer/Log Pis Mean                   22.988\n",
      "trainer/Log Pis Std                     8.05922\n",
      "trainer/Policy mu Mean                  0.352315\n",
      "trainer/Policy mu Std                   2.07799\n",
      "trainer/Policy log std Mean            -2.48136\n",
      "trainer/Policy log std Std              1.26928\n",
      "trainer/Alpha                           0.0485389\n",
      "trainer/Alpha Loss                     -0.145023\n",
      "exploration/num steps total         32062\n",
      "exploration/num paths total           115\n",
      "evaluation/num steps total         158659\n",
      "evaluation/num paths total            274\n",
      "evaluation/path length Mean           896.4\n",
      "evaluation/path length Std            207.212\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            477\n",
      "evaluation/Rewards Mean                 3.99753\n",
      "evaluation/Rewards Std                  1.19129\n",
      "evaluation/Rewards Max                  6.66202\n",
      "evaluation/Rewards Min                 -3.45699\n",
      "evaluation/Returns Mean              3583.38\n",
      "evaluation/Returns Std                864.311\n",
      "evaluation/Returns Max               4250.89\n",
      "evaluation/Returns Min               1845.68\n",
      "evaluation/Estimation Bias Mean      1036.3\n",
      "evaluation/Estimation Bias Std        204.862\n",
      "evaluation/EB/Q_True Mean              43.7285\n",
      "evaluation/EB/Q_True Std              127.065\n",
      "evaluation/EB/Q_Pred Mean            1080.03\n",
      "evaluation/EB/Q_Pred Std              161.832\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3583.38\n",
      "evaluation/Actions Mean                 0.0298699\n",
      "evaluation/Actions Std                  0.515247\n",
      "evaluation/Actions Max                  0.999965\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.09102\n",
      "time/backward_zf1 (s)                   2.34194\n",
      "time/backward_zf2 (s)                   2.18151\n",
      "time/data sampling (s)                  0.374002\n",
      "time/data storing (s)                   0.0167873\n",
      "time/evaluation sampling (s)            2.11389\n",
      "time/exploration sampling (s)           0.353526\n",
      "time/logging (s)                        0.0119206\n",
      "time/preback_alpha (s)                  1.09236\n",
      "time/preback_policy (s)                 1.20267\n",
      "time/preback_start (s)                  0.162994\n",
      "time/preback_zf (s)                     5.52013\n",
      "time/saving (s)                         0.00660792\n",
      "time/training (s)                       2.35656\n",
      "time/epoch (s)                         19.8259\n",
      "time/total (s)                        456.783\n",
      "Epoch                                  25\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:00:02.209162 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 26 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  37000\n",
      "trainer/ZF1 Loss                        5.02304\n",
      "trainer/ZF2 Loss                       10.5689\n",
      "trainer/ZF Expert Reward               12.7593\n",
      "trainer/ZF Policy Reward               -0.187983\n",
      "trainer/ZF CHI2 Term                   43.778\n",
      "trainer/Policy Loss                  -575.422\n",
      "trainer/Bias Loss                     124.556\n",
      "trainer/Bias Value                     12.4222\n",
      "trainer/Policy Grad Norm              107.318\n",
      "trainer/Policy Param Norm              25.2211\n",
      "trainer/Zf1 Grad Norm                1236.65\n",
      "trainer/Zf1 Param Norm                 64.1797\n",
      "trainer/Zf2 Grad Norm                1930.82\n",
      "trainer/Zf2 Param Norm                 64.9508\n",
      "trainer/Z Expert Predictions Mean    1155.66\n",
      "trainer/Z Expert Predictions Std       63.8331\n",
      "trainer/Z Expert Predictions Max     1226.34\n",
      "trainer/Z Expert Predictions Min      816.031\n",
      "trainer/Z Policy Predictions Mean     568.092\n",
      "trainer/Z Policy Predictions Std      555.832\n",
      "trainer/Z Policy Predictions Max     1212.52\n",
      "trainer/Z Policy Predictions Min     -375.743\n",
      "trainer/Z Expert Targets Mean        1142.9\n",
      "trainer/Z Expert Targets Std           62.3267\n",
      "trainer/Z Expert Targets Max         1208.06\n",
      "trainer/Z Expert Targets Min          811.916\n",
      "trainer/Z Policy Targets Mean         568.28\n",
      "trainer/Z Policy Targets Std          549.494\n",
      "trainer/Z Policy Targets Max         1195.79\n",
      "trainer/Z Policy Targets Min         -363.988\n",
      "trainer/Log Pis Mean                   23.2673\n",
      "trainer/Log Pis Std                     8.13802\n",
      "trainer/Policy mu Mean                  0.331865\n",
      "trainer/Policy mu Std                   2.03964\n",
      "trainer/Policy log std Mean            -2.51523\n",
      "trainer/Policy log std Std              1.31062\n",
      "trainer/Alpha                           0.0517173\n",
      "trainer/Alpha Loss                     -0.168965\n",
      "exploration/num steps total         34062\n",
      "exploration/num paths total           117\n",
      "evaluation/num steps total         159759\n",
      "evaluation/num paths total            284\n",
      "evaluation/path length Mean           110\n",
      "evaluation/path length Std             94.7439\n",
      "evaluation/path length Max            296\n",
      "evaluation/path length Min             19\n",
      "evaluation/Rewards Mean                 2.70571\n",
      "evaluation/Rewards Std                  1.71355\n",
      "evaluation/Rewards Max                  5.967\n",
      "evaluation/Rewards Min                 -2.3862\n",
      "evaluation/Returns Mean               297.628\n",
      "evaluation/Returns Std                317.219\n",
      "evaluation/Returns Max                850.419\n",
      "evaluation/Returns Min                -12.3903\n",
      "evaluation/Estimation Bias Mean       899.312\n",
      "evaluation/Estimation Bias Std        229.482\n",
      "evaluation/EB/Q_True Mean              53.9291\n",
      "evaluation/EB/Q_True Std              101.773\n",
      "evaluation/EB/Q_Pred Mean             953.241\n",
      "evaluation/EB/Q_Pred Std              184.987\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            297.628\n",
      "evaluation/Actions Mean                 0.0335944\n",
      "evaluation/Actions Std                  0.552139\n",
      "evaluation/Actions Max                  0.999975\n",
      "evaluation/Actions Min                 -0.999989\n",
      "time/backward_policy (s)                1.97213\n",
      "time/backward_zf1 (s)                   2.18693\n",
      "time/backward_zf2 (s)                   2.05463\n",
      "time/data sampling (s)                  0.330564\n",
      "time/data storing (s)                   0.014998\n",
      "time/evaluation sampling (s)            0.568167\n",
      "time/exploration sampling (s)           0.336672\n",
      "time/logging (s)                        0.00300824\n",
      "time/preback_alpha (s)                  1.01313\n",
      "time/preback_policy (s)                 1.12098\n",
      "time/preback_start (s)                  0.153719\n",
      "time/preback_zf (s)                     5.36915\n",
      "time/saving (s)                         0.00572913\n",
      "time/training (s)                       2.43204\n",
      "time/epoch (s)                         17.5619\n",
      "time/total (s)                        474.364\n",
      "Epoch                                  26\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:00:20.310872 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 27 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  38000\n",
      "trainer/ZF1 Loss                       33.8413\n",
      "trainer/ZF2 Loss                       22.0995\n",
      "trainer/ZF Expert Reward               22.3595\n",
      "trainer/ZF Policy Reward               -2.63884\n",
      "trainer/ZF CHI2 Term                   75.4424\n",
      "trainer/Policy Loss                  -597.513\n",
      "trainer/Bias Loss                     289.207\n",
      "trainer/Bias Value                     12.4926\n",
      "trainer/Policy Grad Norm              193.471\n",
      "trainer/Policy Param Norm              25.3929\n",
      "trainer/Zf1 Grad Norm                6622.38\n",
      "trainer/Zf1 Param Norm                 64.7076\n",
      "trainer/Zf2 Grad Norm                4649.35\n",
      "trainer/Zf2 Param Norm                 65.5043\n",
      "trainer/Z Expert Predictions Mean    1195.57\n",
      "trainer/Z Expert Predictions Std       61.419\n",
      "trainer/Z Expert Predictions Max     1260.23\n",
      "trainer/Z Expert Predictions Min      798.522\n",
      "trainer/Z Policy Predictions Mean     581.193\n",
      "trainer/Z Policy Predictions Std      538.145\n",
      "trainer/Z Policy Predictions Max     1246.06\n",
      "trainer/Z Policy Predictions Min     -361.392\n",
      "trainer/Z Expert Targets Mean        1173.21\n",
      "trainer/Z Expert Targets Std           62.6453\n",
      "trainer/Z Expert Targets Max         1240.49\n",
      "trainer/Z Expert Targets Min          795.563\n",
      "trainer/Z Policy Targets Mean         583.832\n",
      "trainer/Z Policy Targets Std          527.355\n",
      "trainer/Z Policy Targets Max         1238.63\n",
      "trainer/Z Policy Targets Min         -343.765\n",
      "trainer/Log Pis Mean                   22.7006\n",
      "trainer/Log Pis Std                     8.143\n",
      "trainer/Policy mu Mean                  0.17123\n",
      "trainer/Policy mu Std                   1.9734\n",
      "trainer/Policy log std Mean            -2.5303\n",
      "trainer/Policy log std Std              1.20909\n",
      "trainer/Alpha                           0.0553499\n",
      "trainer/Alpha Loss                     -0.149469\n",
      "exploration/num steps total         34062\n",
      "exploration/num paths total           117\n",
      "evaluation/num steps total         169134\n",
      "evaluation/num paths total            295\n",
      "evaluation/path length Mean           852.273\n",
      "evaluation/path length Std            274.695\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             44\n",
      "evaluation/Rewards Mean                 3.82118\n",
      "evaluation/Rewards Std                  1.19823\n",
      "evaluation/Rewards Max                  6.42353\n",
      "evaluation/Rewards Min                 -2.73624\n",
      "evaluation/Returns Mean              3256.69\n",
      "evaluation/Returns Std               1064.49\n",
      "evaluation/Returns Max               4039\n",
      "evaluation/Returns Min                 95.921\n",
      "evaluation/Estimation Bias Mean      1075.24\n",
      "evaluation/Estimation Bias Std        172.138\n",
      "evaluation/EB/Q_True Mean              37.0876\n",
      "evaluation/EB/Q_True Std              110.881\n",
      "evaluation/EB/Q_Pred Mean            1112.33\n",
      "evaluation/EB/Q_Pred Std              131.372\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3256.69\n",
      "evaluation/Actions Mean                -0.00358374\n",
      "evaluation/Actions Std                  0.51031\n",
      "evaluation/Actions Max                  0.999966\n",
      "evaluation/Actions Min                 -0.99998\n",
      "time/backward_policy (s)                1.83931\n",
      "time/backward_zf1 (s)                   1.9768\n",
      "time/backward_zf2 (s)                   1.89827\n",
      "time/data sampling (s)                  0.279936\n",
      "time/data storing (s)                   0.0162821\n",
      "time/evaluation sampling (s)            1.85284\n",
      "time/exploration sampling (s)           0.336148\n",
      "time/logging (s)                        0.0126476\n",
      "time/preback_alpha (s)                  0.990073\n",
      "time/preback_policy (s)                 1.10032\n",
      "time/preback_start (s)                  0.151716\n",
      "time/preback_zf (s)                     5.26984\n",
      "time/saving (s)                         0.006142\n",
      "time/training (s)                       2.311\n",
      "time/epoch (s)                         18.0413\n",
      "time/total (s)                        492.427\n",
      "Epoch                                  27\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:00:38.435332 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 28 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  39000\n",
      "trainer/ZF1 Loss                       27.3978\n",
      "trainer/ZF2 Loss                       21.6481\n",
      "trainer/ZF Expert Reward               17.5717\n",
      "trainer/ZF Policy Reward                1.28909\n",
      "trainer/ZF CHI2 Term                   61.12\n",
      "trainer/Policy Loss                  -733.742\n",
      "trainer/Bias Loss                     144.718\n",
      "trainer/Bias Value                     12.5605\n",
      "trainer/Policy Grad Norm              167.78\n",
      "trainer/Policy Param Norm              25.5627\n",
      "trainer/Zf1 Grad Norm                1956.93\n",
      "trainer/Zf1 Param Norm                 65.2397\n",
      "trainer/Zf2 Grad Norm                2084.78\n",
      "trainer/Zf2 Param Norm                 66.061\n",
      "trainer/Z Expert Predictions Mean    1216.42\n",
      "trainer/Z Expert Predictions Std       69.7574\n",
      "trainer/Z Expert Predictions Max     1294.06\n",
      "trainer/Z Expert Predictions Min      844.369\n",
      "trainer/Z Policy Predictions Mean     723.613\n",
      "trainer/Z Policy Predictions Std      497.958\n",
      "trainer/Z Policy Predictions Max     1273.17\n",
      "trainer/Z Policy Predictions Min     -323.433\n",
      "trainer/Z Expert Targets Mean        1198.85\n",
      "trainer/Z Expert Targets Std           71.1609\n",
      "trainer/Z Expert Targets Max         1275.51\n",
      "trainer/Z Expert Targets Min          825.145\n",
      "trainer/Z Policy Targets Mean         722.324\n",
      "trainer/Z Policy Targets Std          492.668\n",
      "trainer/Z Policy Targets Max         1264.14\n",
      "trainer/Z Policy Targets Min         -314.593\n",
      "trainer/Log Pis Mean                   20.5196\n",
      "trainer/Log Pis Std                     6.42525\n",
      "trainer/Policy mu Mean                  0.0215048\n",
      "trainer/Policy mu Std                   1.68735\n",
      "trainer/Policy log std Mean            -2.70001\n",
      "trainer/Policy log std Std              1.06397\n",
      "trainer/Alpha                           0.058811\n",
      "trainer/Alpha Loss                     -0.0305543\n",
      "exploration/num steps total         34661\n",
      "exploration/num paths total           118\n",
      "evaluation/num steps total         172929\n",
      "evaluation/num paths total            305\n",
      "evaluation/path length Mean           379.5\n",
      "evaluation/path length Std            206.102\n",
      "evaluation/path length Max            714\n",
      "evaluation/path length Min             43\n",
      "evaluation/Rewards Mean                 3.91037\n",
      "evaluation/Rewards Std                  1.57977\n",
      "evaluation/Rewards Max                  7.08918\n",
      "evaluation/Rewards Min                 -2.20796\n",
      "evaluation/Returns Mean              1483.98\n",
      "evaluation/Returns Std                853.248\n",
      "evaluation/Returns Max               3012.08\n",
      "evaluation/Returns Min                 94.1684\n",
      "evaluation/Estimation Bias Mean      1059.75\n",
      "evaluation/Estimation Bias Std        211.053\n",
      "evaluation/EB/Q_True Mean              59.547\n",
      "evaluation/EB/Q_True Std              132.156\n",
      "evaluation/EB/Q_Pred Mean            1119.3\n",
      "evaluation/EB/Q_Pred Std              174.789\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1483.98\n",
      "evaluation/Actions Mean                 0.00548962\n",
      "evaluation/Actions Std                  0.537501\n",
      "evaluation/Actions Max                  0.999983\n",
      "evaluation/Actions Min                 -0.999948\n",
      "time/backward_policy (s)                1.91191\n",
      "time/backward_zf1 (s)                   2.00998\n",
      "time/backward_zf2 (s)                   1.96061\n",
      "time/data sampling (s)                  0.296412\n",
      "time/data storing (s)                   0.0144134\n",
      "time/evaluation sampling (s)            1.7468\n",
      "time/exploration sampling (s)           0.327361\n",
      "time/logging (s)                        0.0056266\n",
      "time/preback_alpha (s)                  0.981998\n",
      "time/preback_policy (s)                 1.11492\n",
      "time/preback_start (s)                  0.146333\n",
      "time/preback_zf (s)                     5.23261\n",
      "time/saving (s)                         0.00584237\n",
      "time/training (s)                       2.29547\n",
      "time/epoch (s)                         18.0503\n",
      "time/total (s)                        510.497\n",
      "Epoch                                  28\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:00:56.867015 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 29 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  40000\n",
      "trainer/ZF1 Loss                      210.451\n",
      "trainer/ZF2 Loss                      219.972\n",
      "trainer/ZF Expert Reward               13.3249\n",
      "trainer/ZF Policy Reward               -5.5858\n",
      "trainer/ZF CHI2 Term                  255.799\n",
      "trainer/Policy Loss                  -690.791\n",
      "trainer/Bias Loss                    1918.82\n",
      "trainer/Bias Value                     12.6246\n",
      "trainer/Policy Grad Norm              100.674\n",
      "trainer/Policy Param Norm              25.7336\n",
      "trainer/Zf1 Grad Norm               14563.4\n",
      "trainer/Zf1 Param Norm                 65.7536\n",
      "trainer/Zf2 Grad Norm               10749.6\n",
      "trainer/Zf2 Param Norm                 66.5801\n",
      "trainer/Z Expert Predictions Mean    1235.83\n",
      "trainer/Z Expert Predictions Std       79.3085\n",
      "trainer/Z Expert Predictions Max     1315.23\n",
      "trainer/Z Expert Predictions Min      849.106\n",
      "trainer/Z Policy Predictions Mean     680.66\n",
      "trainer/Z Policy Predictions Std      533.144\n",
      "trainer/Z Policy Predictions Max     1288.14\n",
      "trainer/Z Policy Predictions Min     -298.082\n",
      "trainer/Z Expert Targets Mean        1222.5\n",
      "trainer/Z Expert Targets Std          107.144\n",
      "trainer/Z Expert Targets Max         1300.04\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         686.245\n",
      "trainer/Z Policy Targets Std          531.373\n",
      "trainer/Z Policy Targets Max         1276.12\n",
      "trainer/Z Policy Targets Min         -301.187\n",
      "trainer/Log Pis Mean                   21.8955\n",
      "trainer/Log Pis Std                     7.97968\n",
      "trainer/Policy mu Mean                  0.0723143\n",
      "trainer/Policy mu Std                   1.93132\n",
      "trainer/Policy log std Mean            -2.56693\n",
      "trainer/Policy log std Std              1.17869\n",
      "trainer/Alpha                           0.0632844\n",
      "trainer/Alpha Loss                     -0.119946\n",
      "exploration/num steps total         35444\n",
      "exploration/num paths total           120\n",
      "evaluation/num steps total         182028\n",
      "evaluation/num paths total            316\n",
      "evaluation/path length Mean           827.182\n",
      "evaluation/path length Std            291.547\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            170\n",
      "evaluation/Rewards Mean                 4.25381\n",
      "evaluation/Rewards Std                  1.21407\n",
      "evaluation/Rewards Max                  6.73035\n",
      "evaluation/Rewards Min                 -1.83854\n",
      "evaluation/Returns Mean              3518.67\n",
      "evaluation/Returns Std               1300.07\n",
      "evaluation/Returns Max               4455.73\n",
      "evaluation/Returns Min                685.165\n",
      "evaluation/Estimation Bias Mean      1170.63\n",
      "evaluation/Estimation Bias Std        185.833\n",
      "evaluation/EB/Q_True Mean              43.3325\n",
      "evaluation/EB/Q_True Std              126.47\n",
      "evaluation/EB/Q_Pred Mean            1213.96\n",
      "evaluation/EB/Q_Pred Std              126.581\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3518.67\n",
      "evaluation/Actions Mean                 0.00471022\n",
      "evaluation/Actions Std                  0.532942\n",
      "evaluation/Actions Max                  0.999977\n",
      "evaluation/Actions Min                 -0.999953\n",
      "time/backward_policy (s)                1.90563\n",
      "time/backward_zf1 (s)                   2.05439\n",
      "time/backward_zf2 (s)                   1.98421\n",
      "time/data sampling (s)                  0.278507\n",
      "time/data storing (s)                   0.0144582\n",
      "time/evaluation sampling (s)            1.91285\n",
      "time/exploration sampling (s)           0.327772\n",
      "time/logging (s)                        0.0121093\n",
      "time/preback_alpha (s)                  0.984131\n",
      "time/preback_policy (s)                 1.12784\n",
      "time/preback_start (s)                  0.149585\n",
      "time/preback_zf (s)                     5.28258\n",
      "time/saving (s)                         0.007098\n",
      "time/training (s)                       2.32528\n",
      "time/epoch (s)                         18.3664\n",
      "time/total (s)                        528.887\n",
      "Epoch                                  29\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:01:15.563011 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 30 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  41000\n",
      "trainer/ZF1 Loss                       29.6386\n",
      "trainer/ZF2 Loss                       34.852\n",
      "trainer/ZF Expert Reward               20.8941\n",
      "trainer/ZF Policy Reward                1.2671\n",
      "trainer/ZF CHI2 Term                   72.8944\n",
      "trainer/Policy Loss                  -747.393\n",
      "trainer/Bias Loss                     216.886\n",
      "trainer/Bias Value                     12.685\n",
      "trainer/Policy Grad Norm               71.7456\n",
      "trainer/Policy Param Norm              25.8851\n",
      "trainer/Zf1 Grad Norm                2061.59\n",
      "trainer/Zf1 Param Norm                 66.2428\n",
      "trainer/Zf2 Grad Norm                2774.4\n",
      "trainer/Zf2 Param Norm                 67.1122\n",
      "trainer/Z Expert Predictions Mean    1267.53\n",
      "trainer/Z Expert Predictions Std       79.3787\n",
      "trainer/Z Expert Predictions Max     1349.94\n",
      "trainer/Z Expert Predictions Min      883.981\n",
      "trainer/Z Policy Predictions Mean     733.887\n",
      "trainer/Z Policy Predictions Std      535.716\n",
      "trainer/Z Policy Predictions Max     1327.07\n",
      "trainer/Z Policy Predictions Min     -292.849\n",
      "trainer/Z Expert Targets Mean        1246.63\n",
      "trainer/Z Expert Targets Std           77.3775\n",
      "trainer/Z Expert Targets Max         1327.8\n",
      "trainer/Z Expert Targets Min          861.046\n",
      "trainer/Z Policy Targets Mean         732.62\n",
      "trainer/Z Policy Targets Std          532.015\n",
      "trainer/Z Policy Targets Max         1321.15\n",
      "trainer/Z Policy Targets Min         -279.25\n",
      "trainer/Log Pis Mean                   21.2344\n",
      "trainer/Log Pis Std                     6.9249\n",
      "trainer/Policy mu Mean                  0.0584461\n",
      "trainer/Policy mu Std                   1.91127\n",
      "trainer/Policy log std Mean            -2.51698\n",
      "trainer/Policy log std Std              1.17466\n",
      "trainer/Alpha                           0.0682602\n",
      "trainer/Alpha Loss                     -0.0842569\n",
      "exploration/num steps total         36034\n",
      "exploration/num paths total           122\n",
      "evaluation/num steps total         192028\n",
      "evaluation/num paths total            326\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.33655\n",
      "evaluation/Rewards Std                  1.18374\n",
      "evaluation/Rewards Max                  6.5034\n",
      "evaluation/Rewards Min                 -2.62967\n",
      "evaluation/Returns Mean              4336.55\n",
      "evaluation/Returns Std                153.71\n",
      "evaluation/Returns Max               4596.31\n",
      "evaluation/Returns Min               3978.87\n",
      "evaluation/Estimation Bias Mean      1225.74\n",
      "evaluation/Estimation Bias Std        169.645\n",
      "evaluation/EB/Q_True Mean              36.4971\n",
      "evaluation/EB/Q_True Std              115.714\n",
      "evaluation/EB/Q_Pred Mean            1262.24\n",
      "evaluation/EB/Q_Pred Std              122.226\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4336.55\n",
      "evaluation/Actions Mean                 0.0156301\n",
      "evaluation/Actions Std                  0.527434\n",
      "evaluation/Actions Max                  0.999941\n",
      "evaluation/Actions Min                 -0.999967\n",
      "time/backward_policy (s)                1.92344\n",
      "time/backward_zf1 (s)                   2.08359\n",
      "time/backward_zf2 (s)                   2.0399\n",
      "time/data sampling (s)                  0.31413\n",
      "time/data storing (s)                   0.0143902\n",
      "time/evaluation sampling (s)            1.9406\n",
      "time/exploration sampling (s)           0.321326\n",
      "time/logging (s)                        0.0127291\n",
      "time/preback_alpha (s)                  1.00201\n",
      "time/preback_policy (s)                 1.1296\n",
      "time/preback_start (s)                  0.149668\n",
      "time/preback_zf (s)                     5.33488\n",
      "time/saving (s)                         0.00623938\n",
      "time/training (s)                       2.35311\n",
      "time/epoch (s)                         18.6256\n",
      "time/total (s)                        547.535\n",
      "Epoch                                  30\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:01:33.184189 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 31 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  42000\n",
      "trainer/ZF1 Loss                      100.543\n",
      "trainer/ZF2 Loss                       76.4318\n",
      "trainer/ZF Expert Reward               23.5319\n",
      "trainer/ZF Policy Reward                1.23131\n",
      "trainer/ZF CHI2 Term                  132.55\n",
      "trainer/Policy Loss                  -768.609\n",
      "trainer/Bias Loss                     797.316\n",
      "trainer/Bias Value                     12.7439\n",
      "trainer/Policy Grad Norm              127.439\n",
      "trainer/Policy Param Norm              26.0363\n",
      "trainer/Zf1 Grad Norm               17385.3\n",
      "trainer/Zf1 Param Norm                 66.8046\n",
      "trainer/Zf2 Grad Norm               11869.9\n",
      "trainer/Zf2 Param Norm                 67.6799\n",
      "trainer/Z Expert Predictions Mean    1296.87\n",
      "trainer/Z Expert Predictions Std       87.2944\n",
      "trainer/Z Expert Predictions Max     1379.29\n",
      "trainer/Z Expert Predictions Min      481.294\n",
      "trainer/Z Policy Predictions Mean     758.102\n",
      "trainer/Z Policy Predictions Std      511.326\n",
      "trainer/Z Policy Predictions Max     1363.96\n",
      "trainer/Z Policy Predictions Min     -277.429\n",
      "trainer/Z Expert Targets Mean        1273.34\n",
      "trainer/Z Expert Targets Std          110.746\n",
      "trainer/Z Expert Targets Max         1362\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         756.871\n",
      "trainer/Z Policy Targets Std          502.53\n",
      "trainer/Z Policy Targets Max         1347.08\n",
      "trainer/Z Policy Targets Min         -260.095\n",
      "trainer/Log Pis Mean                   21.9819\n",
      "trainer/Log Pis Std                     8.35425\n",
      "trainer/Policy mu Mean                  0.170412\n",
      "trainer/Policy mu Std                   1.95131\n",
      "trainer/Policy log std Mean            -2.52758\n",
      "trainer/Policy log std Std              1.1723\n",
      "trainer/Alpha                           0.0729394\n",
      "trainer/Alpha Loss                     -0.144546\n",
      "exploration/num steps total         37779\n",
      "exploration/num paths total           124\n",
      "evaluation/num steps total         194122\n",
      "evaluation/num paths total            336\n",
      "evaluation/path length Mean           209.4\n",
      "evaluation/path length Std            138.282\n",
      "evaluation/path length Max            446\n",
      "evaluation/path length Min             11\n",
      "evaluation/Rewards Mean                 3.77565\n",
      "evaluation/Rewards Std                  1.55949\n",
      "evaluation/Rewards Max                  6.38904\n",
      "evaluation/Rewards Min                 -1.9264\n",
      "evaluation/Returns Mean               790.622\n",
      "evaluation/Returns Std                605.99\n",
      "evaluation/Returns Max               1898.01\n",
      "evaluation/Returns Min                  6.45568\n",
      "evaluation/Estimation Bias Mean      1143.4\n",
      "evaluation/Estimation Bias Std        218.058\n",
      "evaluation/EB/Q_True Mean              44.7341\n",
      "evaluation/EB/Q_True Std              102.391\n",
      "evaluation/EB/Q_Pred Mean            1188.14\n",
      "evaluation/EB/Q_Pred Std              185.238\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            790.622\n",
      "evaluation/Actions Mean                 0.0138502\n",
      "evaluation/Actions Std                  0.512884\n",
      "evaluation/Actions Max                  0.999931\n",
      "evaluation/Actions Min                 -0.999969\n",
      "time/backward_policy (s)                1.90264\n",
      "time/backward_zf1 (s)                   2.07657\n",
      "time/backward_zf2 (s)                   1.98124\n",
      "time/data sampling (s)                  0.301606\n",
      "time/data storing (s)                   0.0153166\n",
      "time/evaluation sampling (s)            1.08205\n",
      "time/exploration sampling (s)           0.340298\n",
      "time/logging (s)                        0.00391516\n",
      "time/preback_alpha (s)                  0.98059\n",
      "time/preback_policy (s)                 1.09842\n",
      "time/preback_start (s)                  0.150857\n",
      "time/preback_zf (s)                     5.2658\n",
      "time/saving (s)                         0.00938816\n",
      "time/training (s)                       2.3347\n",
      "time/epoch (s)                         17.5434\n",
      "time/total (s)                        565.099\n",
      "Epoch                                  31\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:01:51.571773 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 32 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  43000\n",
      "trainer/ZF1 Loss                       61.3927\n",
      "trainer/ZF2 Loss                       65.6253\n",
      "trainer/ZF Expert Reward               18.6591\n",
      "trainer/ZF Policy Reward                1.1737\n",
      "trainer/ZF CHI2 Term                  101.253\n",
      "trainer/Policy Loss                  -796.021\n",
      "trainer/Bias Loss                     331.364\n",
      "trainer/Bias Value                     12.8044\n",
      "trainer/Policy Grad Norm              132.293\n",
      "trainer/Policy Param Norm              26.1671\n",
      "trainer/Zf1 Grad Norm                5501.69\n",
      "trainer/Zf1 Param Norm                 67.3566\n",
      "trainer/Zf2 Grad Norm                5926.75\n",
      "trainer/Zf2 Param Norm                 68.249\n",
      "trainer/Z Expert Predictions Mean    1315.44\n",
      "trainer/Z Expert Predictions Std       88.6521\n",
      "trainer/Z Expert Predictions Max     1409.74\n",
      "trainer/Z Expert Predictions Min      936.133\n",
      "trainer/Z Policy Predictions Mean     784.493\n",
      "trainer/Z Policy Predictions Std      509.879\n",
      "trainer/Z Policy Predictions Max     1386.52\n",
      "trainer/Z Policy Predictions Min     -275.478\n",
      "trainer/Z Expert Targets Mean        1296.78\n",
      "trainer/Z Expert Targets Std           88.5652\n",
      "trainer/Z Expert Targets Max         1391.03\n",
      "trainer/Z Expert Targets Min          906.389\n",
      "trainer/Z Policy Targets Mean         783.319\n",
      "trainer/Z Policy Targets Std          504.522\n",
      "trainer/Z Policy Targets Max         1365.4\n",
      "trainer/Z Policy Targets Min         -271.989\n",
      "trainer/Log Pis Mean                   20.4638\n",
      "trainer/Log Pis Std                     7.8459\n",
      "trainer/Policy mu Mean                  0.204426\n",
      "trainer/Policy mu Std                   1.79775\n",
      "trainer/Policy log std Mean            -2.51574\n",
      "trainer/Policy log std Std              1.14158\n",
      "trainer/Alpha                           0.0768775\n",
      "trainer/Alpha Loss                     -0.0356509\n",
      "exploration/num steps total         38779\n",
      "exploration/num paths total           125\n",
      "evaluation/num steps total         202468\n",
      "evaluation/num paths total            346\n",
      "evaluation/path length Mean           834.6\n",
      "evaluation/path length Std            301.91\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            206\n",
      "evaluation/Rewards Mean                 3.80259\n",
      "evaluation/Rewards Std                  2.33404\n",
      "evaluation/Rewards Max                  6.86546\n",
      "evaluation/Rewards Min                 -4.00809\n",
      "evaluation/Returns Mean              3173.64\n",
      "evaluation/Returns Std               1666.56\n",
      "evaluation/Returns Max               4638.34\n",
      "evaluation/Returns Min                129.866\n",
      "evaluation/Estimation Bias Mean      1140.23\n",
      "evaluation/Estimation Bias Std        388.738\n",
      "evaluation/EB/Q_True Mean              39.4507\n",
      "evaluation/EB/Q_True Std              133.882\n",
      "evaluation/EB/Q_Pred Mean            1179.68\n",
      "evaluation/EB/Q_Pred Std              370.303\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3173.64\n",
      "evaluation/Actions Mean                 0.0395959\n",
      "evaluation/Actions Std                  0.582405\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9737\n",
      "time/backward_zf1 (s)                   2.10681\n",
      "time/backward_zf2 (s)                   2.0154\n",
      "time/data sampling (s)                  0.269753\n",
      "time/data storing (s)                   0.0155352\n",
      "time/evaluation sampling (s)            1.90598\n",
      "time/exploration sampling (s)           0.340924\n",
      "time/logging (s)                        0.0140371\n",
      "time/preback_alpha (s)                  1.03789\n",
      "time/preback_policy (s)                 1.17854\n",
      "time/preback_start (s)                  0.149809\n",
      "time/preback_zf (s)                     5.21445\n",
      "time/saving (s)                         0.00626406\n",
      "time/training (s)                       2.10182\n",
      "time/epoch (s)                         18.3309\n",
      "time/total (s)                        583.449\n",
      "Epoch                                  32\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:02:09.213043 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 33 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  44000\n",
      "trainer/ZF1 Loss                       49.1916\n",
      "trainer/ZF2 Loss                       46.3844\n",
      "trainer/ZF Expert Reward               20.5205\n",
      "trainer/ZF Policy Reward               -3.82825\n",
      "trainer/ZF CHI2 Term                   93.4798\n",
      "trainer/Policy Loss                  -785.246\n",
      "trainer/Bias Loss                     243.31\n",
      "trainer/Bias Value                     12.8607\n",
      "trainer/Policy Grad Norm              166.542\n",
      "trainer/Policy Param Norm              26.2945\n",
      "trainer/Zf1 Grad Norm                3554.99\n",
      "trainer/Zf1 Param Norm                 67.951\n",
      "trainer/Zf2 Grad Norm                2642.64\n",
      "trainer/Zf2 Param Norm                 68.844\n",
      "trainer/Z Expert Predictions Mean    1339.85\n",
      "trainer/Z Expert Predictions Std       81.8474\n",
      "trainer/Z Expert Predictions Max     1434.74\n",
      "trainer/Z Expert Predictions Min      974.025\n",
      "trainer/Z Policy Predictions Mean     770.189\n",
      "trainer/Z Policy Predictions Std      519.293\n",
      "trainer/Z Policy Predictions Max     1410.53\n",
      "trainer/Z Policy Predictions Min     -298.822\n",
      "trainer/Z Expert Targets Mean        1319.33\n",
      "trainer/Z Expert Targets Std           83.0696\n",
      "trainer/Z Expert Targets Max         1415.18\n",
      "trainer/Z Expert Targets Min          952.976\n",
      "trainer/Z Policy Targets Mean         774.017\n",
      "trainer/Z Policy Targets Std          508.46\n",
      "trainer/Z Policy Targets Max         1394.73\n",
      "trainer/Z Policy Targets Min         -290.585\n",
      "trainer/Log Pis Mean                   21.5586\n",
      "trainer/Log Pis Std                     8.83942\n",
      "trainer/Policy mu Mean                  0.302051\n",
      "trainer/Policy mu Std                   1.92636\n",
      "trainer/Policy log std Mean            -2.48564\n",
      "trainer/Policy log std Std              1.18908\n",
      "trainer/Alpha                           0.078643\n",
      "trainer/Alpha Loss                     -0.122571\n",
      "exploration/num steps total         39779\n",
      "exploration/num paths total           126\n",
      "evaluation/num steps total         212468\n",
      "evaluation/num paths total            356\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.43271\n",
      "evaluation/Rewards Std                  1.10465\n",
      "evaluation/Rewards Max                  6.37417\n",
      "evaluation/Rewards Min                 -2.45223\n",
      "evaluation/Returns Mean              4432.71\n",
      "evaluation/Returns Std                189.047\n",
      "evaluation/Returns Max               4730.08\n",
      "evaluation/Returns Min               3993.63\n",
      "evaluation/Estimation Bias Mean      1296.98\n",
      "evaluation/Estimation Bias Std        162.469\n",
      "evaluation/EB/Q_True Mean              40.1368\n",
      "evaluation/EB/Q_True Std              123.908\n",
      "evaluation/EB/Q_Pred Mean            1337.11\n",
      "evaluation/EB/Q_Pred Std              119.777\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4432.71\n",
      "evaluation/Actions Mean                 0.0153165\n",
      "evaluation/Actions Std                  0.531256\n",
      "evaluation/Actions Max                  0.999952\n",
      "evaluation/Actions Min                 -0.999934\n",
      "time/backward_policy (s)                1.743\n",
      "time/backward_zf1 (s)                   1.88092\n",
      "time/backward_zf2 (s)                   1.81214\n",
      "time/data sampling (s)                  0.282763\n",
      "time/data storing (s)                   0.0149762\n",
      "time/evaluation sampling (s)            1.81632\n",
      "time/exploration sampling (s)           0.336683\n",
      "time/logging (s)                        0.0127627\n",
      "time/preback_alpha (s)                  0.910078\n",
      "time/preback_policy (s)                 1.00313\n",
      "time/preback_start (s)                  0.143197\n",
      "time/preback_zf (s)                     5.16626\n",
      "time/saving (s)                         0.00626563\n",
      "time/training (s)                       2.44019\n",
      "time/epoch (s)                         17.5687\n",
      "time/total (s)                        601.043\n",
      "Epoch                                  33\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:02:27.247250 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 34 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  45000\n",
      "trainer/ZF1 Loss                       44.1158\n",
      "trainer/ZF2 Loss                       54.3701\n",
      "trainer/ZF Expert Reward               12.5561\n",
      "trainer/ZF Policy Reward               -3.38336\n",
      "trainer/ZF CHI2 Term                   84.8659\n",
      "trainer/Policy Loss                  -783.161\n",
      "trainer/Bias Loss                     188.121\n",
      "trainer/Bias Value                     12.914\n",
      "trainer/Policy Grad Norm              151.284\n",
      "trainer/Policy Param Norm              26.4283\n",
      "trainer/Zf1 Grad Norm                6436.16\n",
      "trainer/Zf1 Param Norm                 68.5198\n",
      "trainer/Zf2 Grad Norm                4398.4\n",
      "trainer/Zf2 Param Norm                 69.4492\n",
      "trainer/Z Expert Predictions Mean    1357.75\n",
      "trainer/Z Expert Predictions Std       83.5104\n",
      "trainer/Z Expert Predictions Max     1449.36\n",
      "trainer/Z Expert Predictions Min      783.04\n",
      "trainer/Z Policy Predictions Mean     768.343\n",
      "trainer/Z Policy Predictions Std      572.849\n",
      "trainer/Z Policy Predictions Max     1442.06\n",
      "trainer/Z Policy Predictions Min     -319.658\n",
      "trainer/Z Expert Targets Mean        1345.19\n",
      "trainer/Z Expert Targets Std           85.2034\n",
      "trainer/Z Expert Targets Max         1442.79\n",
      "trainer/Z Expert Targets Min          725.886\n",
      "trainer/Z Policy Targets Mean         771.726\n",
      "trainer/Z Policy Targets Std          570.143\n",
      "trainer/Z Policy Targets Max         1422.13\n",
      "trainer/Z Policy Targets Min         -311.024\n",
      "trainer/Log Pis Mean                   19.8824\n",
      "trainer/Log Pis Std                     6.70437\n",
      "trainer/Policy mu Mean                  0.164419\n",
      "trainer/Policy mu Std                   1.68765\n",
      "trainer/Policy log std Mean            -2.42275\n",
      "trainer/Policy log std Std              1.30073\n",
      "trainer/Alpha                           0.0781145\n",
      "trainer/Alpha Loss                      0.00918833\n",
      "exploration/num steps total         40779\n",
      "exploration/num paths total           127\n",
      "evaluation/num steps total         221348\n",
      "evaluation/num paths total            366\n",
      "evaluation/path length Mean           888\n",
      "evaluation/path length Std            226.982\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            358\n",
      "evaluation/Rewards Mean                 3.96072\n",
      "evaluation/Rewards Std                  2.0904\n",
      "evaluation/Rewards Max                  6.54424\n",
      "evaluation/Rewards Min                 -3.07056\n",
      "evaluation/Returns Mean              3517.12\n",
      "evaluation/Returns Std               1551.79\n",
      "evaluation/Returns Max               4672.14\n",
      "evaluation/Returns Min                 13.2764\n",
      "evaluation/Estimation Bias Mean      1254.15\n",
      "evaluation/Estimation Bias Std        424.147\n",
      "evaluation/EB/Q_True Mean              -3.82857\n",
      "evaluation/EB/Q_True Std               94.7261\n",
      "evaluation/EB/Q_Pred Mean            1250.32\n",
      "evaluation/EB/Q_Pred Std              413.923\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3517.12\n",
      "evaluation/Actions Mean                 0.00779287\n",
      "evaluation/Actions Std                  0.564026\n",
      "evaluation/Actions Max                  0.999937\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.86185\n",
      "time/backward_zf1 (s)                   1.99665\n",
      "time/backward_zf2 (s)                   1.93342\n",
      "time/data sampling (s)                  0.29412\n",
      "time/data storing (s)                   0.0149228\n",
      "time/evaluation sampling (s)            1.73862\n",
      "time/exploration sampling (s)           0.330464\n",
      "time/logging (s)                        0.0112571\n",
      "time/preback_alpha (s)                  0.971961\n",
      "time/preback_policy (s)                 1.07548\n",
      "time/preback_start (s)                  0.147275\n",
      "time/preback_zf (s)                     5.21258\n",
      "time/saving (s)                         0.00615007\n",
      "time/training (s)                       2.35993\n",
      "time/epoch (s)                         17.9547\n",
      "time/total (s)                        619.028\n",
      "Epoch                                  34\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:02:45.037354 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 35 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  46000\n",
      "trainer/ZF1 Loss                       58.7329\n",
      "trainer/ZF2 Loss                       84.0788\n",
      "trainer/ZF Expert Reward               20.727\n",
      "trainer/ZF Policy Reward                2.19163\n",
      "trainer/ZF CHI2 Term                  109.384\n",
      "trainer/Policy Loss                  -839.124\n",
      "trainer/Bias Loss                     327.194\n",
      "trainer/Bias Value                     12.9658\n",
      "trainer/Policy Grad Norm              160.725\n",
      "trainer/Policy Param Norm              26.5599\n",
      "trainer/Zf1 Grad Norm                3077.83\n",
      "trainer/Zf1 Param Norm                 69.0924\n",
      "trainer/Zf2 Grad Norm                8897.2\n",
      "trainer/Zf2 Param Norm                 70.0402\n",
      "trainer/Z Expert Predictions Mean    1374.63\n",
      "trainer/Z Expert Predictions Std       95.5442\n",
      "trainer/Z Expert Predictions Max     1475.44\n",
      "trainer/Z Expert Predictions Min      780.492\n",
      "trainer/Z Policy Predictions Mean     828.992\n",
      "trainer/Z Policy Predictions Std      532.284\n",
      "trainer/Z Policy Predictions Max     1472.16\n",
      "trainer/Z Policy Predictions Min     -337.914\n",
      "trainer/Z Expert Targets Mean        1353.9\n",
      "trainer/Z Expert Targets Std           98.3168\n",
      "trainer/Z Expert Targets Max         1460.72\n",
      "trainer/Z Expert Targets Min          789.566\n",
      "trainer/Z Policy Targets Mean         826.8\n",
      "trainer/Z Policy Targets Std          526.093\n",
      "trainer/Z Policy Targets Max         1446.26\n",
      "trainer/Z Policy Targets Min         -333.93\n",
      "trainer/Log Pis Mean                   19.6392\n",
      "trainer/Log Pis Std                     7.14585\n",
      "trainer/Policy mu Mean                  0.235265\n",
      "trainer/Policy mu Std                   1.73122\n",
      "trainer/Policy log std Mean            -2.48308\n",
      "trainer/Policy log std Std              1.21983\n",
      "trainer/Alpha                           0.0766324\n",
      "trainer/Alpha Loss                      0.0276467\n",
      "exploration/num steps total         42191\n",
      "exploration/num paths total           130\n",
      "evaluation/num steps total         230431\n",
      "evaluation/num paths total            376\n",
      "evaluation/path length Mean           908.3\n",
      "evaluation/path length Std            275.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             83\n",
      "evaluation/Rewards Mean                 3.39914\n",
      "evaluation/Rewards Std                  2.50538\n",
      "evaluation/Rewards Max                  6.95463\n",
      "evaluation/Rewards Min                 -2.79357\n",
      "evaluation/Returns Mean              3087.44\n",
      "evaluation/Returns Std               2018.83\n",
      "evaluation/Returns Max               4417.71\n",
      "evaluation/Returns Min              -1756.35\n",
      "evaluation/Estimation Bias Mean      1081.32\n",
      "evaluation/Estimation Bias Std        509.615\n",
      "evaluation/EB/Q_True Mean              42.9401\n",
      "evaluation/EB/Q_True Std              125.125\n",
      "evaluation/EB/Q_Pred Mean            1124.26\n",
      "evaluation/EB/Q_Pred Std              506.589\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3087.44\n",
      "evaluation/Actions Mean                -0.0247845\n",
      "evaluation/Actions Std                  0.607441\n",
      "evaluation/Actions Max                  0.999993\n",
      "evaluation/Actions Min                 -0.99996\n",
      "time/backward_policy (s)                1.8156\n",
      "time/backward_zf1 (s)                   1.91811\n",
      "time/backward_zf2 (s)                   1.85335\n",
      "time/data sampling (s)                  0.296389\n",
      "time/data storing (s)                   0.0158771\n",
      "time/evaluation sampling (s)            1.78191\n",
      "time/exploration sampling (s)           0.342692\n",
      "time/logging (s)                        0.011421\n",
      "time/preback_alpha (s)                  0.956948\n",
      "time/preback_policy (s)                 1.05069\n",
      "time/preback_start (s)                  0.148605\n",
      "time/preback_zf (s)                     5.17618\n",
      "time/saving (s)                         0.00737492\n",
      "time/training (s)                       2.34062\n",
      "time/epoch (s)                         17.7158\n",
      "time/total (s)                        636.772\n",
      "Epoch                                  35\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:03:02.731936 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 36 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  47000\n",
      "trainer/ZF1 Loss                       35.7563\n",
      "trainer/ZF2 Loss                       48.5884\n",
      "trainer/ZF Expert Reward               13.8595\n",
      "trainer/ZF Policy Reward               -6.40959\n",
      "trainer/ZF CHI2 Term                   82.3392\n",
      "trainer/Policy Loss                  -868.521\n",
      "trainer/Bias Loss                     244.262\n",
      "trainer/Bias Value                     13.0153\n",
      "trainer/Policy Grad Norm              119.028\n",
      "trainer/Policy Param Norm              26.7013\n",
      "trainer/Zf1 Grad Norm                3823.72\n",
      "trainer/Zf1 Param Norm                 69.6441\n",
      "trainer/Zf2 Grad Norm                5277.6\n",
      "trainer/Zf2 Param Norm                 70.6045\n",
      "trainer/Z Expert Predictions Mean    1397.21\n",
      "trainer/Z Expert Predictions Std       79.5065\n",
      "trainer/Z Expert Predictions Max     1488.94\n",
      "trainer/Z Expert Predictions Min      938.98\n",
      "trainer/Z Policy Predictions Mean     850.322\n",
      "trainer/Z Policy Predictions Std      576.135\n",
      "trainer/Z Policy Predictions Max     1474.73\n",
      "trainer/Z Policy Predictions Min     -370.034\n",
      "trainer/Z Expert Targets Mean        1383.35\n",
      "trainer/Z Expert Targets Std           76.2685\n",
      "trainer/Z Expert Targets Max         1481.43\n",
      "trainer/Z Expert Targets Min          978.988\n",
      "trainer/Z Policy Targets Mean         856.731\n",
      "trainer/Z Policy Targets Std          566.895\n",
      "trainer/Z Policy Targets Max         1462.74\n",
      "trainer/Z Policy Targets Min         -360.654\n",
      "trainer/Log Pis Mean                   20.0988\n",
      "trainer/Log Pis Std                     6.43369\n",
      "trainer/Policy mu Mean                  0.232771\n",
      "trainer/Policy mu Std                   1.65623\n",
      "trainer/Policy log std Mean            -2.54381\n",
      "trainer/Policy log std Std              1.22215\n",
      "trainer/Alpha                           0.0760511\n",
      "trainer/Alpha Loss                     -0.00751443\n",
      "exploration/num steps total         42191\n",
      "exploration/num paths total           130\n",
      "evaluation/num steps total         238698\n",
      "evaluation/num paths total            389\n",
      "evaluation/path length Mean           635.923\n",
      "evaluation/path length Std            350.149\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            169\n",
      "evaluation/Rewards Mean                 3.35088\n",
      "evaluation/Rewards Std                  2.4329\n",
      "evaluation/Rewards Max                  6.88716\n",
      "evaluation/Rewards Min                 -2.90106\n",
      "evaluation/Returns Mean              2130.9\n",
      "evaluation/Returns Std               1644.25\n",
      "evaluation/Returns Max               4431.26\n",
      "evaluation/Returns Min              -1146.12\n",
      "evaluation/Estimation Bias Mean      1101.63\n",
      "evaluation/Estimation Bias Std        494.392\n",
      "evaluation/EB/Q_True Mean              39.632\n",
      "evaluation/EB/Q_True Std              114.115\n",
      "evaluation/EB/Q_Pred Mean            1141.26\n",
      "evaluation/EB/Q_Pred Std              497.174\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2130.9\n",
      "evaluation/Actions Mean                 0.0204426\n",
      "evaluation/Actions Std                  0.591742\n",
      "evaluation/Actions Max                  0.999994\n",
      "evaluation/Actions Min                 -0.99993\n",
      "time/backward_policy (s)                1.81452\n",
      "time/backward_zf1 (s)                   1.93188\n",
      "time/backward_zf2 (s)                   1.86685\n",
      "time/data sampling (s)                  0.310181\n",
      "time/data storing (s)                   0.0143993\n",
      "time/evaluation sampling (s)            1.78455\n",
      "time/exploration sampling (s)           0.321563\n",
      "time/logging (s)                        0.0101998\n",
      "time/preback_alpha (s)                  0.970782\n",
      "time/preback_policy (s)                 1.07024\n",
      "time/preback_start (s)                  0.144368\n",
      "time/preback_zf (s)                     5.16173\n",
      "time/saving (s)                         0.00629839\n",
      "time/training (s)                       2.21937\n",
      "time/epoch (s)                         17.6269\n",
      "time/total (s)                        654.419\n",
      "Epoch                                  36\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:03:20.790080 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 37 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  48000\n",
      "trainer/ZF1 Loss                      151.752\n",
      "trainer/ZF2 Loss                       50.2677\n",
      "trainer/ZF Expert Reward               19.3673\n",
      "trainer/ZF Policy Reward               -3.5192\n",
      "trainer/ZF CHI2 Term                  144.294\n",
      "trainer/Policy Loss                  -863.325\n",
      "trainer/Bias Loss                     536.285\n",
      "trainer/Bias Value                     13.0629\n",
      "trainer/Policy Grad Norm              124.646\n",
      "trainer/Policy Param Norm              26.8403\n",
      "trainer/Zf1 Grad Norm               18723.7\n",
      "trainer/Zf1 Param Norm                 70.1645\n",
      "trainer/Zf2 Grad Norm                4171.03\n",
      "trainer/Zf2 Param Norm                 71.1253\n",
      "trainer/Z Expert Predictions Mean    1407.03\n",
      "trainer/Z Expert Predictions Std      112.866\n",
      "trainer/Z Expert Predictions Max     1514.21\n",
      "trainer/Z Expert Predictions Min      410.782\n",
      "trainer/Z Policy Predictions Mean     856.214\n",
      "trainer/Z Policy Predictions Std      570.339\n",
      "trainer/Z Policy Predictions Max     1499.4\n",
      "trainer/Z Policy Predictions Min     -355.914\n",
      "trainer/Z Expert Targets Mean        1387.66\n",
      "trainer/Z Expert Targets Std          128.668\n",
      "trainer/Z Expert Targets Max         1486.07\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         859.733\n",
      "trainer/Z Policy Targets Std          563.292\n",
      "trainer/Z Policy Targets Max         1487.54\n",
      "trainer/Z Policy Targets Min         -340.106\n",
      "trainer/Log Pis Mean                   20.6041\n",
      "trainer/Log Pis Std                     6.68899\n",
      "trainer/Policy mu Mean                  0.133218\n",
      "trainer/Policy mu Std                   1.67421\n",
      "trainer/Policy log std Mean            -2.57346\n",
      "trainer/Policy log std Std              1.13171\n",
      "trainer/Alpha                           0.0796025\n",
      "trainer/Alpha Loss                     -0.0480885\n",
      "exploration/num steps total         42191\n",
      "exploration/num paths total           130\n",
      "evaluation/num steps total         247731\n",
      "evaluation/num paths total            399\n",
      "evaluation/path length Mean           903.3\n",
      "evaluation/path length Std            290.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             33\n",
      "evaluation/Rewards Mean                 3.81364\n",
      "evaluation/Rewards Std                  2.05078\n",
      "evaluation/Rewards Max                  6.47526\n",
      "evaluation/Rewards Min                 -3.09022\n",
      "evaluation/Returns Mean              3444.86\n",
      "evaluation/Returns Std               1766.28\n",
      "evaluation/Returns Max               4439.8\n",
      "evaluation/Returns Min               -218.974\n",
      "evaluation/Estimation Bias Mean      1224.41\n",
      "evaluation/Estimation Bias Std        449.499\n",
      "evaluation/EB/Q_True Mean              43.2498\n",
      "evaluation/EB/Q_True Std              126.085\n",
      "evaluation/EB/Q_Pred Mean            1267.65\n",
      "evaluation/EB/Q_Pred Std              440.42\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3444.86\n",
      "evaluation/Actions Mean                -0.0252829\n",
      "evaluation/Actions Std                  0.552137\n",
      "evaluation/Actions Max                  0.999981\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86506\n",
      "time/backward_zf1 (s)                   1.98272\n",
      "time/backward_zf2 (s)                   1.9176\n",
      "time/data sampling (s)                  0.301243\n",
      "time/data storing (s)                   0.0150865\n",
      "time/evaluation sampling (s)            1.75421\n",
      "time/exploration sampling (s)           0.334687\n",
      "time/logging (s)                        0.0113156\n",
      "time/preback_alpha (s)                  0.988127\n",
      "time/preback_policy (s)                 1.10059\n",
      "time/preback_start (s)                  0.147945\n",
      "time/preback_zf (s)                     5.22991\n",
      "time/saving (s)                         0.00610951\n",
      "time/training (s)                       2.33687\n",
      "time/epoch (s)                         17.9915\n",
      "time/total (s)                        672.431\n",
      "Epoch                                  37\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:03:38.087160 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 38 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  49000\n",
      "trainer/ZF1 Loss                      118.479\n",
      "trainer/ZF2 Loss                      109.389\n",
      "trainer/ZF Expert Reward               13.8809\n",
      "trainer/ZF Policy Reward               -5.92609\n",
      "trainer/ZF CHI2 Term                  153.214\n",
      "trainer/Policy Loss                  -941.159\n",
      "trainer/Bias Loss                     727.685\n",
      "trainer/Bias Value                     13.1079\n",
      "trainer/Policy Grad Norm              217.329\n",
      "trainer/Policy Param Norm              26.9804\n",
      "trainer/Zf1 Grad Norm                9455.76\n",
      "trainer/Zf1 Param Norm                 70.6749\n",
      "trainer/Zf2 Grad Norm               11870.9\n",
      "trainer/Zf2 Param Norm                 71.6589\n",
      "trainer/Z Expert Predictions Mean    1422.28\n",
      "trainer/Z Expert Predictions Std      132.694\n",
      "trainer/Z Expert Predictions Max     1534.9\n",
      "trainer/Z Expert Predictions Min     -128.249\n",
      "trainer/Z Policy Predictions Mean     927.542\n",
      "trainer/Z Policy Predictions Std      567.788\n",
      "trainer/Z Policy Predictions Max     1513.12\n",
      "trainer/Z Policy Predictions Min     -363.454\n",
      "trainer/Z Expert Targets Mean        1408.4\n",
      "trainer/Z Expert Targets Std          125.815\n",
      "trainer/Z Expert Targets Max         1515.9\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         933.468\n",
      "trainer/Z Policy Targets Std          562.836\n",
      "trainer/Z Policy Targets Max         1497.86\n",
      "trainer/Z Policy Targets Min         -365.445\n",
      "trainer/Log Pis Mean                   19.67\n",
      "trainer/Log Pis Std                     5.74608\n",
      "trainer/Policy mu Mean                 -0.00573802\n",
      "trainer/Policy mu Std                   1.48924\n",
      "trainer/Policy log std Mean            -2.69451\n",
      "trainer/Policy log std Std              1.08234\n",
      "trainer/Alpha                           0.0819205\n",
      "trainer/Alpha Loss                      0.02703\n",
      "exploration/num steps total         43769\n",
      "exploration/num paths total           132\n",
      "evaluation/num steps total         256498\n",
      "evaluation/num paths total            409\n",
      "evaluation/path length Mean           876.7\n",
      "evaluation/path length Std            267.451\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            152\n",
      "evaluation/Rewards Mean                 4.3782\n",
      "evaluation/Rewards Std                  1.31212\n",
      "evaluation/Rewards Max                  7.00689\n",
      "evaluation/Rewards Min                 -2.32276\n",
      "evaluation/Returns Mean              3838.37\n",
      "evaluation/Returns Std               1163.86\n",
      "evaluation/Returns Max               4561.95\n",
      "evaluation/Returns Min                654.305\n",
      "evaluation/Estimation Bias Mean      1337.08\n",
      "evaluation/Estimation Bias Std        199.713\n",
      "evaluation/EB/Q_True Mean              46.6265\n",
      "evaluation/EB/Q_True Std              135.195\n",
      "evaluation/EB/Q_Pred Mean            1383.71\n",
      "evaluation/EB/Q_Pred Std              150.108\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3838.37\n",
      "evaluation/Actions Mean                -0.00272859\n",
      "evaluation/Actions Std                  0.530287\n",
      "evaluation/Actions Max                  0.999742\n",
      "evaluation/Actions Min                 -0.999822\n",
      "time/backward_policy (s)                1.69926\n",
      "time/backward_zf1 (s)                   1.82702\n",
      "time/backward_zf2 (s)                   1.74759\n",
      "time/data sampling (s)                  0.277613\n",
      "time/data storing (s)                   0.0145368\n",
      "time/evaluation sampling (s)            1.84316\n",
      "time/exploration sampling (s)           0.328225\n",
      "time/logging (s)                        0.0112322\n",
      "time/preback_alpha (s)                  0.896054\n",
      "time/preback_policy (s)                 0.965574\n",
      "time/preback_start (s)                  0.142408\n",
      "time/preback_zf (s)                     5.11368\n",
      "time/saving (s)                         0.00681011\n",
      "time/training (s)                       2.35664\n",
      "time/epoch (s)                         17.2298\n",
      "time/total (s)                        689.683\n",
      "Epoch                                  38\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:03:55.941376 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 39 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  50000\n",
      "trainer/ZF1 Loss                       61.9449\n",
      "trainer/ZF2 Loss                       58.681\n",
      "trainer/ZF Expert Reward               10.0786\n",
      "trainer/ZF Policy Reward               -1.24302\n",
      "trainer/ZF CHI2 Term                   91.8613\n",
      "trainer/Policy Loss                  -844.127\n",
      "trainer/Bias Loss                     284.136\n",
      "trainer/Bias Value                     13.1547\n",
      "trainer/Policy Grad Norm              164.281\n",
      "trainer/Policy Param Norm              27.1175\n",
      "trainer/Zf1 Grad Norm                2753.43\n",
      "trainer/Zf1 Param Norm                 71.201\n",
      "trainer/Zf2 Grad Norm                3460.38\n",
      "trainer/Zf2 Param Norm                 72.1788\n",
      "trainer/Z Expert Predictions Mean    1440.46\n",
      "trainer/Z Expert Predictions Std       92.3683\n",
      "trainer/Z Expert Predictions Max     1540.33\n",
      "trainer/Z Expert Predictions Min      798.514\n",
      "trainer/Z Policy Predictions Mean     833.357\n",
      "trainer/Z Policy Predictions Std      612.519\n",
      "trainer/Z Policy Predictions Max     1527.45\n",
      "trainer/Z Policy Predictions Min     -385.097\n",
      "trainer/Z Expert Targets Mean        1430.38\n",
      "trainer/Z Expert Targets Std           95.8267\n",
      "trainer/Z Expert Targets Max         1530.45\n",
      "trainer/Z Expert Targets Min          788.248\n",
      "trainer/Z Policy Targets Mean         834.6\n",
      "trainer/Z Policy Targets Std          609.577\n",
      "trainer/Z Policy Targets Max         1505.89\n",
      "trainer/Z Policy Targets Min         -378.109\n",
      "trainer/Log Pis Mean                   20.431\n",
      "trainer/Log Pis Std                     5.84832\n",
      "trainer/Policy mu Mean                  0.0155528\n",
      "trainer/Policy mu Std                   1.68574\n",
      "trainer/Policy log std Mean            -2.45271\n",
      "trainer/Policy log std Std              1.14535\n",
      "trainer/Alpha                           0.0848645\n",
      "trainer/Alpha Loss                     -0.0365763\n",
      "exploration/num steps total         44769\n",
      "exploration/num paths total           133\n",
      "evaluation/num steps total         265099\n",
      "evaluation/num paths total            421\n",
      "evaluation/path length Mean           716.75\n",
      "evaluation/path length Std            351.342\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             21\n",
      "evaluation/Rewards Mean                 3.17074\n",
      "evaluation/Rewards Std                  2.82183\n",
      "evaluation/Rewards Max                  6.83642\n",
      "evaluation/Rewards Min                 -3.66978\n",
      "evaluation/Returns Mean              2272.63\n",
      "evaluation/Returns Std               2059.97\n",
      "evaluation/Returns Max               4674.08\n",
      "evaluation/Returns Min              -1890.45\n",
      "evaluation/Estimation Bias Mean      1050.63\n",
      "evaluation/Estimation Bias Std        637.794\n",
      "evaluation/EB/Q_True Mean              49.8633\n",
      "evaluation/EB/Q_True Std              141.17\n",
      "evaluation/EB/Q_Pred Mean            1100.5\n",
      "evaluation/EB/Q_Pred Std              646.145\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2272.63\n",
      "evaluation/Actions Mean                 0.023035\n",
      "evaluation/Actions Std                  0.619927\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.81691\n",
      "time/backward_zf1 (s)                   1.92723\n",
      "time/backward_zf2 (s)                   1.85872\n",
      "time/data sampling (s)                  0.295691\n",
      "time/data storing (s)                   0.0144991\n",
      "time/evaluation sampling (s)            1.85444\n",
      "time/exploration sampling (s)           0.328349\n",
      "time/logging (s)                        0.0128765\n",
      "time/preback_alpha (s)                  0.921164\n",
      "time/preback_policy (s)                 1.02894\n",
      "time/preback_start (s)                  0.145245\n",
      "time/preback_zf (s)                     5.17205\n",
      "time/saving (s)                         0.00919866\n",
      "time/training (s)                       2.39991\n",
      "time/epoch (s)                         17.7852\n",
      "time/total (s)                        707.492\n",
      "Epoch                                  39\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:04:13.292999 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 40 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  51000\n",
      "trainer/ZF1 Loss                       57.0682\n",
      "trainer/ZF2 Loss                       56.2506\n",
      "trainer/ZF Expert Reward               20.9855\n",
      "trainer/ZF Policy Reward                4.27668\n",
      "trainer/ZF CHI2 Term                   92.3329\n",
      "trainer/Policy Loss                  -914.537\n",
      "trainer/Bias Loss                     214.99\n",
      "trainer/Bias Value                     13.1993\n",
      "trainer/Policy Grad Norm              130.059\n",
      "trainer/Policy Param Norm              27.2572\n",
      "trainer/Zf1 Grad Norm                3607.32\n",
      "trainer/Zf1 Param Norm                 71.7079\n",
      "trainer/Zf2 Grad Norm                2945.13\n",
      "trainer/Zf2 Param Norm                 72.6639\n",
      "trainer/Z Expert Predictions Mean    1472.88\n",
      "trainer/Z Expert Predictions Std       62.8648\n",
      "trainer/Z Expert Predictions Max     1552.62\n",
      "trainer/Z Expert Predictions Min     1166.89\n",
      "trainer/Z Policy Predictions Mean     904.822\n",
      "trainer/Z Policy Predictions Std      598.513\n",
      "trainer/Z Policy Predictions Max     1541.3\n",
      "trainer/Z Policy Predictions Min     -366.543\n",
      "trainer/Z Expert Targets Mean        1451.89\n",
      "trainer/Z Expert Targets Std           67.8823\n",
      "trainer/Z Expert Targets Max         1539.69\n",
      "trainer/Z Expert Targets Min         1154.3\n",
      "trainer/Z Policy Targets Mean         900.545\n",
      "trainer/Z Policy Targets Std          591.08\n",
      "trainer/Z Policy Targets Max         1535.27\n",
      "trainer/Z Policy Targets Min         -392.969\n",
      "trainer/Log Pis Mean                   19.1563\n",
      "trainer/Log Pis Std                     5.80293\n",
      "trainer/Policy mu Mean                  0.0654096\n",
      "trainer/Policy mu Std                   1.56359\n",
      "trainer/Policy log std Mean            -2.49994\n",
      "trainer/Policy log std Std              1.18291\n",
      "trainer/Alpha                           0.0838872\n",
      "trainer/Alpha Loss                      0.0707834\n",
      "exploration/num steps total         46769\n",
      "exploration/num paths total           135\n",
      "evaluation/num steps total         275099\n",
      "evaluation/num paths total            431\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.30476\n",
      "evaluation/Rewards Std                  0.95892\n",
      "evaluation/Rewards Max                  6.36631\n",
      "evaluation/Rewards Min                 -2.23862\n",
      "evaluation/Returns Mean              4304.76\n",
      "evaluation/Returns Std                 86.9955\n",
      "evaluation/Returns Max               4421.86\n",
      "evaluation/Returns Min               4127.66\n",
      "evaluation/Estimation Bias Mean      1423.74\n",
      "evaluation/Estimation Bias Std        148.994\n",
      "evaluation/EB/Q_True Mean              39.0888\n",
      "evaluation/EB/Q_True Std              120.23\n",
      "evaluation/EB/Q_Pred Mean            1462.83\n",
      "evaluation/EB/Q_Pred Std               88.9834\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4304.76\n",
      "evaluation/Actions Mean                 0.0272324\n",
      "evaluation/Actions Std                  0.523104\n",
      "evaluation/Actions Max                  0.999608\n",
      "evaluation/Actions Min                 -0.999921\n",
      "time/backward_policy (s)                1.69781\n",
      "time/backward_zf1 (s)                   1.82079\n",
      "time/backward_zf2 (s)                   1.7312\n",
      "time/data sampling (s)                  0.298349\n",
      "time/data storing (s)                   0.0142324\n",
      "time/evaluation sampling (s)            1.77086\n",
      "time/exploration sampling (s)           0.322221\n",
      "time/logging (s)                        0.011939\n",
      "time/preback_alpha (s)                  0.872604\n",
      "time/preback_policy (s)                 0.948837\n",
      "time/preback_start (s)                  0.144017\n",
      "time/preback_zf (s)                     5.15125\n",
      "time/saving (s)                         0.00652043\n",
      "time/training (s)                       2.48125\n",
      "time/epoch (s)                         17.2719\n",
      "time/total (s)                        724.796\n",
      "Epoch                                  40\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:04:30.966076 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 41 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  52000\n",
      "trainer/ZF1 Loss                       79.9523\n",
      "trainer/ZF2 Loss                       63.0732\n",
      "trainer/ZF Expert Reward               12.7538\n",
      "trainer/ZF Policy Reward               -2.39834\n",
      "trainer/ZF CHI2 Term                  106.2\n",
      "trainer/Policy Loss                  -985.002\n",
      "trainer/Bias Loss                     193.754\n",
      "trainer/Bias Value                     13.2436\n",
      "trainer/Policy Grad Norm              160.062\n",
      "trainer/Policy Param Norm              27.3903\n",
      "trainer/Zf1 Grad Norm                7321.83\n",
      "trainer/Zf1 Param Norm                 72.1872\n",
      "trainer/Zf2 Grad Norm                5953.3\n",
      "trainer/Zf2 Param Norm                 73.1364\n",
      "trainer/Z Expert Predictions Mean    1475.78\n",
      "trainer/Z Expert Predictions Std       70.9856\n",
      "trainer/Z Expert Predictions Max     1562.05\n",
      "trainer/Z Expert Predictions Min     1053.53\n",
      "trainer/Z Policy Predictions Mean     970.691\n",
      "trainer/Z Policy Predictions Std      578.262\n",
      "trainer/Z Policy Predictions Max     1547.08\n",
      "trainer/Z Policy Predictions Min     -390.723\n",
      "trainer/Z Expert Targets Mean        1463.03\n",
      "trainer/Z Expert Targets Std           71.555\n",
      "trainer/Z Expert Targets Max         1555.17\n",
      "trainer/Z Expert Targets Min         1033.76\n",
      "trainer/Z Policy Targets Mean         973.09\n",
      "trainer/Z Policy Targets Std          573.528\n",
      "trainer/Z Policy Targets Max         1529.68\n",
      "trainer/Z Policy Targets Min         -384.273\n",
      "trainer/Log Pis Mean                   19.7328\n",
      "trainer/Log Pis Std                     5.18777\n",
      "trainer/Policy mu Mean                  0.0758353\n",
      "trainer/Policy mu Std                   1.51099\n",
      "trainer/Policy log std Mean            -2.60638\n",
      "trainer/Policy log std Std              1.11868\n",
      "trainer/Alpha                           0.0811709\n",
      "trainer/Alpha Loss                      0.0216916\n",
      "exploration/num steps total         47769\n",
      "exploration/num paths total           136\n",
      "evaluation/num steps total         283117\n",
      "evaluation/num paths total            444\n",
      "evaluation/path length Mean           616.769\n",
      "evaluation/path length Std            394.343\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             39\n",
      "evaluation/Rewards Mean                 4.42642\n",
      "evaluation/Rewards Std                  1.18469\n",
      "evaluation/Rewards Max                  6.73076\n",
      "evaluation/Rewards Min                 -2.35318\n",
      "evaluation/Returns Mean              2730.08\n",
      "evaluation/Returns Std               1827.66\n",
      "evaluation/Returns Max               4588.11\n",
      "evaluation/Returns Min                 99.3515\n",
      "evaluation/Estimation Bias Mean      1399.09\n",
      "evaluation/Estimation Bias Std        191.664\n",
      "evaluation/EB/Q_True Mean              52.2807\n",
      "evaluation/EB/Q_True Std              142.707\n",
      "evaluation/EB/Q_Pred Mean            1451.37\n",
      "evaluation/EB/Q_Pred Std              109.562\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2730.08\n",
      "evaluation/Actions Mean                 0.0093541\n",
      "evaluation/Actions Std                  0.539688\n",
      "evaluation/Actions Max                  0.999646\n",
      "evaluation/Actions Min                 -0.999702\n",
      "time/backward_policy (s)                1.84811\n",
      "time/backward_zf1 (s)                   1.93342\n",
      "time/backward_zf2 (s)                   1.90616\n",
      "time/data sampling (s)                  0.260647\n",
      "time/data storing (s)                   0.0146024\n",
      "time/evaluation sampling (s)            1.92593\n",
      "time/exploration sampling (s)           0.320496\n",
      "time/logging (s)                        0.00998742\n",
      "time/preback_alpha (s)                  1.00657\n",
      "time/preback_policy (s)                 1.14251\n",
      "time/preback_start (s)                  0.140002\n",
      "time/preback_zf (s)                     5.08813\n",
      "time/saving (s)                         0.00640264\n",
      "time/training (s)                       2.00407\n",
      "time/epoch (s)                         17.607\n",
      "time/total (s)                        742.422\n",
      "Epoch                                  41\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:04:48.066985 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 42 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  53000\n",
      "trainer/ZF1 Loss                      428.467\n",
      "trainer/ZF2 Loss                      312.518\n",
      "trainer/ZF Expert Reward               18.2695\n",
      "trainer/ZF Policy Reward                5.84463\n",
      "trainer/ZF CHI2 Term                  403.572\n",
      "trainer/Policy Loss                  -986.085\n",
      "trainer/Bias Loss                    2995.18\n",
      "trainer/Bias Value                     13.2876\n",
      "trainer/Policy Grad Norm              161.724\n",
      "trainer/Policy Param Norm              27.5293\n",
      "trainer/Zf1 Grad Norm               10728\n",
      "trainer/Zf1 Param Norm                 72.6449\n",
      "trainer/Zf2 Grad Norm               25005.9\n",
      "trainer/Zf2 Param Norm                 73.5792\n",
      "trainer/Z Expert Predictions Mean    1484.31\n",
      "trainer/Z Expert Predictions Std       70.2256\n",
      "trainer/Z Expert Predictions Max     1574.33\n",
      "trainer/Z Expert Predictions Min     1078.9\n",
      "trainer/Z Policy Predictions Mean     974.586\n",
      "trainer/Z Policy Predictions Std      599.331\n",
      "trainer/Z Policy Predictions Max     1556.18\n",
      "trainer/Z Policy Predictions Min     -358.58\n",
      "trainer/Z Expert Targets Mean        1466.04\n",
      "trainer/Z Expert Targets Std          115.211\n",
      "trainer/Z Expert Targets Max         1561.19\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         968.741\n",
      "trainer/Z Policy Targets Std          594.822\n",
      "trainer/Z Policy Targets Max         1558\n",
      "trainer/Z Policy Targets Min         -344.678\n",
      "trainer/Log Pis Mean                   20.8636\n",
      "trainer/Log Pis Std                     5.90029\n",
      "trainer/Policy mu Mean                 -0.024212\n",
      "trainer/Policy mu Std                   1.53181\n",
      "trainer/Policy log std Mean            -2.72551\n",
      "trainer/Policy log std Std              1.11206\n",
      "trainer/Alpha                           0.0810055\n",
      "trainer/Alpha Loss                     -0.0699545\n",
      "exploration/num steps total         47769\n",
      "exploration/num paths total           136\n",
      "evaluation/num steps total         293117\n",
      "evaluation/num paths total            454\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.81088\n",
      "evaluation/Rewards Std                  2.245\n",
      "evaluation/Rewards Max                  6.86894\n",
      "evaluation/Rewards Min                 -2.98927\n",
      "evaluation/Returns Mean              3810.88\n",
      "evaluation/Returns Std               1997.88\n",
      "evaluation/Returns Max               4639.15\n",
      "evaluation/Returns Min              -2174.73\n",
      "evaluation/Estimation Bias Mean      1283.76\n",
      "evaluation/Estimation Bias Std        398.439\n",
      "evaluation/EB/Q_True Mean              40.4016\n",
      "evaluation/EB/Q_True Std              124.823\n",
      "evaluation/EB/Q_Pred Mean            1324.16\n",
      "evaluation/EB/Q_Pred Std              393.075\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3810.88\n",
      "evaluation/Actions Mean                 0.0264726\n",
      "evaluation/Actions Std                  0.599762\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -0.999845\n",
      "time/backward_policy (s)                1.67638\n",
      "time/backward_zf1 (s)                   1.7821\n",
      "time/backward_zf2 (s)                   1.7054\n",
      "time/data sampling (s)                  0.268686\n",
      "time/data storing (s)                   0.0139886\n",
      "time/evaluation sampling (s)            1.72239\n",
      "time/exploration sampling (s)           0.31087\n",
      "time/logging (s)                        0.0128149\n",
      "time/preback_alpha (s)                  0.867253\n",
      "time/preback_policy (s)                 0.935062\n",
      "time/preback_start (s)                  0.141026\n",
      "time/preback_zf (s)                     5.11331\n",
      "time/saving (s)                         0.00716075\n",
      "time/training (s)                       2.47269\n",
      "time/epoch (s)                         17.0291\n",
      "time/total (s)                        759.481\n",
      "Epoch                                  42\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:05:05.253160 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 43 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  54000\n",
      "trainer/ZF1 Loss                       38.5509\n",
      "trainer/ZF2 Loss                       72.4915\n",
      "trainer/ZF Expert Reward                9.76949\n",
      "trainer/ZF Policy Reward               -5.4301\n",
      "trainer/ZF CHI2 Term                   90.0607\n",
      "trainer/Policy Loss                  -975.301\n",
      "trainer/Bias Loss                     150.085\n",
      "trainer/Bias Value                     13.3283\n",
      "trainer/Policy Grad Norm              115.079\n",
      "trainer/Policy Param Norm              27.6666\n",
      "trainer/Zf1 Grad Norm                2723.35\n",
      "trainer/Zf1 Param Norm                 73.0596\n",
      "trainer/Zf2 Grad Norm                6196.6\n",
      "trainer/Zf2 Param Norm                 74.0394\n",
      "trainer/Z Expert Predictions Mean    1481.63\n",
      "trainer/Z Expert Predictions Std       92.2406\n",
      "trainer/Z Expert Predictions Max     1588.21\n",
      "trainer/Z Expert Predictions Min     1070.34\n",
      "trainer/Z Policy Predictions Mean     963.161\n",
      "trainer/Z Policy Predictions Std      581.593\n",
      "trainer/Z Policy Predictions Max     1572.64\n",
      "trainer/Z Policy Predictions Min     -361.908\n",
      "trainer/Z Expert Targets Mean        1471.86\n",
      "trainer/Z Expert Targets Std           92.7861\n",
      "trainer/Z Expert Targets Max         1581\n",
      "trainer/Z Expert Targets Min         1058.37\n",
      "trainer/Z Policy Targets Mean         968.591\n",
      "trainer/Z Policy Targets Std          575.529\n",
      "trainer/Z Policy Targets Max         1572.37\n",
      "trainer/Z Policy Targets Min         -352.936\n",
      "trainer/Log Pis Mean                   19.5352\n",
      "trainer/Log Pis Std                     5.55019\n",
      "trainer/Policy mu Mean                  0.0573384\n",
      "trainer/Policy mu Std                   1.5475\n",
      "trainer/Policy log std Mean            -2.55978\n",
      "trainer/Policy log std Std              1.11299\n",
      "trainer/Alpha                           0.0797281\n",
      "trainer/Alpha Loss                      0.0370592\n",
      "exploration/num steps total         48769\n",
      "exploration/num paths total           137\n",
      "evaluation/num steps total         302281\n",
      "evaluation/num paths total            465\n",
      "evaluation/path length Mean           833.091\n",
      "evaluation/path length Std            279.135\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            302\n",
      "evaluation/Rewards Mean                 4.40529\n",
      "evaluation/Rewards Std                  1.14158\n",
      "evaluation/Rewards Max                  6.53503\n",
      "evaluation/Rewards Min                 -2.29094\n",
      "evaluation/Returns Mean              3670\n",
      "evaluation/Returns Std               1229.74\n",
      "evaluation/Returns Max               4522.35\n",
      "evaluation/Returns Min               1316.05\n",
      "evaluation/Estimation Bias Mean      1437.54\n",
      "evaluation/Estimation Bias Std        168.496\n",
      "evaluation/EB/Q_True Mean              45.479\n",
      "evaluation/EB/Q_True Std              133.401\n",
      "evaluation/EB/Q_Pred Mean            1483.02\n",
      "evaluation/EB/Q_Pred Std              106.051\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3670\n",
      "evaluation/Actions Mean                 0.0344791\n",
      "evaluation/Actions Std                  0.539532\n",
      "evaluation/Actions Max                  0.999912\n",
      "evaluation/Actions Min                 -0.999897\n",
      "time/backward_policy (s)                1.66962\n",
      "time/backward_zf1 (s)                   1.78184\n",
      "time/backward_zf2 (s)                   1.72278\n",
      "time/data sampling (s)                  0.271526\n",
      "time/data storing (s)                   0.0143627\n",
      "time/evaluation sampling (s)            1.84643\n",
      "time/exploration sampling (s)           0.320453\n",
      "time/logging (s)                        0.0117578\n",
      "time/preback_alpha (s)                  0.873163\n",
      "time/preback_policy (s)                 0.943663\n",
      "time/preback_start (s)                  0.141206\n",
      "time/preback_zf (s)                     5.10674\n",
      "time/saving (s)                         0.00691816\n",
      "time/training (s)                       2.40735\n",
      "time/epoch (s)                         17.1178\n",
      "time/total (s)                        776.622\n",
      "Epoch                                  43\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:05:22.870058 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 44 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  55000\n",
      "trainer/ZF1 Loss                      527.112\n",
      "trainer/ZF2 Loss                      544.395\n",
      "trainer/ZF Expert Reward               16.7029\n",
      "trainer/ZF Policy Reward                4.57718\n",
      "trainer/ZF CHI2 Term                  567.653\n",
      "trainer/Policy Loss                  -985.171\n",
      "trainer/Bias Loss                     384.879\n",
      "trainer/Bias Value                     13.3689\n",
      "trainer/Policy Grad Norm              152.979\n",
      "trainer/Policy Param Norm              27.7985\n",
      "trainer/Zf1 Grad Norm                9806.66\n",
      "trainer/Zf1 Param Norm                 73.4978\n",
      "trainer/Zf2 Grad Norm               15132\n",
      "trainer/Zf2 Param Norm                 74.4693\n",
      "trainer/Z Expert Predictions Mean    1497.61\n",
      "trainer/Z Expert Predictions Std       97.8564\n",
      "trainer/Z Expert Predictions Max     1598.34\n",
      "trainer/Z Expert Predictions Min      945.146\n",
      "trainer/Z Policy Predictions Mean     974.974\n",
      "trainer/Z Policy Predictions Std      600.525\n",
      "trainer/Z Policy Predictions Max     1585.92\n",
      "trainer/Z Policy Predictions Min     -329.411\n",
      "trainer/Z Expert Targets Mean        1480.91\n",
      "trainer/Z Expert Targets Std           94.6274\n",
      "trainer/Z Expert Targets Max         1587.14\n",
      "trainer/Z Expert Targets Min          963.464\n",
      "trainer/Z Policy Targets Mean         970.396\n",
      "trainer/Z Policy Targets Std          595.477\n",
      "trainer/Z Policy Targets Max         1583.11\n",
      "trainer/Z Policy Targets Min         -313.838\n",
      "trainer/Log Pis Mean                   19.9736\n",
      "trainer/Log Pis Std                     4.72923\n",
      "trainer/Policy mu Mean                  0.0772694\n",
      "trainer/Policy mu Std                   1.51698\n",
      "trainer/Policy log std Mean            -2.61923\n",
      "trainer/Policy log std Std              1.14918\n",
      "trainer/Alpha                           0.0780635\n",
      "trainer/Alpha Loss                      0.00206149\n",
      "exploration/num steps total         50139\n",
      "exploration/num paths total           139\n",
      "evaluation/num steps total         303998\n",
      "evaluation/num paths total            475\n",
      "evaluation/path length Mean           171.7\n",
      "evaluation/path length Std            121.832\n",
      "evaluation/path length Max            447\n",
      "evaluation/path length Min             45\n",
      "evaluation/Rewards Mean                 3.78438\n",
      "evaluation/Rewards Std                  1.6663\n",
      "evaluation/Rewards Max                  6.87239\n",
      "evaluation/Rewards Min                 -2.31571\n",
      "evaluation/Returns Mean               649.778\n",
      "evaluation/Returns Std                550.725\n",
      "evaluation/Returns Max               1846.35\n",
      "evaluation/Returns Min                 83.5741\n",
      "evaluation/Estimation Bias Mean      1332.61\n",
      "evaluation/Estimation Bias Std        216.952\n",
      "evaluation/EB/Q_True Mean              69.9648\n",
      "evaluation/EB/Q_True Std              132.48\n",
      "evaluation/EB/Q_Pred Mean            1402.58\n",
      "evaluation/EB/Q_Pred Std              161.999\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            649.778\n",
      "evaluation/Actions Mean                 0.0200945\n",
      "evaluation/Actions Std                  0.545402\n",
      "evaluation/Actions Max                  0.999801\n",
      "evaluation/Actions Min                 -0.999675\n",
      "time/backward_policy (s)                1.9284\n",
      "time/backward_zf1 (s)                   2.06313\n",
      "time/backward_zf2 (s)                   1.99721\n",
      "time/data sampling (s)                  0.311349\n",
      "time/data storing (s)                   0.0151789\n",
      "time/evaluation sampling (s)            0.997156\n",
      "time/exploration sampling (s)           0.33858\n",
      "time/logging (s)                        0.00322216\n",
      "time/preback_alpha (s)                  1.0138\n",
      "time/preback_policy (s)                 1.1577\n",
      "time/preback_start (s)                  0.148781\n",
      "time/preback_zf (s)                     5.30058\n",
      "time/saving (s)                         0.00595819\n",
      "time/training (s)                       2.2584\n",
      "time/epoch (s)                         17.5394\n",
      "time/total (s)                        794.181\n",
      "Epoch                                  44\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:05:40.441722 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 45 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  56000\n",
      "trainer/ZF1 Loss                       43.0386\n",
      "trainer/ZF2 Loss                       65.4479\n",
      "trainer/ZF Expert Reward               11.6079\n",
      "trainer/ZF Policy Reward               -5.03857\n",
      "trainer/ZF CHI2 Term                   89.9571\n",
      "trainer/Policy Loss                 -1028.24\n",
      "trainer/Bias Loss                     208.362\n",
      "trainer/Bias Value                     13.4029\n",
      "trainer/Policy Grad Norm              188.234\n",
      "trainer/Policy Param Norm              27.9242\n",
      "trainer/Zf1 Grad Norm                2803.61\n",
      "trainer/Zf1 Param Norm                 73.9765\n",
      "trainer/Zf2 Grad Norm                4672.15\n",
      "trainer/Zf2 Param Norm                 74.9079\n",
      "trainer/Z Expert Predictions Mean    1515.85\n",
      "trainer/Z Expert Predictions Std       72.0999\n",
      "trainer/Z Expert Predictions Max     1610.38\n",
      "trainer/Z Expert Predictions Min     1195.72\n",
      "trainer/Z Policy Predictions Mean    1019.09\n",
      "trainer/Z Policy Predictions Std      600.576\n",
      "trainer/Z Policy Predictions Max     1599.11\n",
      "trainer/Z Policy Predictions Min     -357.05\n",
      "trainer/Z Expert Targets Mean        1504.24\n",
      "trainer/Z Expert Targets Std           71.963\n",
      "trainer/Z Expert Targets Max         1594.89\n",
      "trainer/Z Expert Targets Min         1191.48\n",
      "trainer/Z Policy Targets Mean        1024.13\n",
      "trainer/Z Policy Targets Std          597.409\n",
      "trainer/Z Policy Targets Max         1582.22\n",
      "trainer/Z Policy Targets Min         -340.365\n",
      "trainer/Log Pis Mean                   19.26\n",
      "trainer/Log Pis Std                     4.79049\n",
      "trainer/Policy mu Mean                  0.0408426\n",
      "trainer/Policy mu Std                   1.39527\n",
      "trainer/Policy log std Mean            -2.67201\n",
      "trainer/Policy log std Std              1.07849\n",
      "trainer/Alpha                           0.0746168\n",
      "trainer/Alpha Loss                      0.0552262\n",
      "exploration/num steps total         52139\n",
      "exploration/num paths total           141\n",
      "evaluation/num steps total         313314\n",
      "evaluation/num paths total            485\n",
      "evaluation/path length Mean           931.6\n",
      "evaluation/path length Std            205.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            316\n",
      "evaluation/Rewards Mean                 4.54133\n",
      "evaluation/Rewards Std                  1.01834\n",
      "evaluation/Rewards Max                  6.70974\n",
      "evaluation/Rewards Min                 -2.30734\n",
      "evaluation/Returns Mean              4230.7\n",
      "evaluation/Returns Std                965.61\n",
      "evaluation/Returns Max               4656.29\n",
      "evaluation/Returns Min               1339.7\n",
      "evaluation/Estimation Bias Mean      1484.28\n",
      "evaluation/Estimation Bias Std        155.964\n",
      "evaluation/EB/Q_True Mean              44.7017\n",
      "evaluation/EB/Q_True Std              133.145\n",
      "evaluation/EB/Q_Pred Mean            1528.98\n",
      "evaluation/EB/Q_Pred Std               81.5\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4230.7\n",
      "evaluation/Actions Mean                 0.0249924\n",
      "evaluation/Actions Std                  0.54817\n",
      "evaluation/Actions Max                  0.999934\n",
      "evaluation/Actions Min                 -0.999518\n",
      "time/backward_policy (s)                1.82042\n",
      "time/backward_zf1 (s)                   1.94017\n",
      "time/backward_zf2 (s)                   1.88725\n",
      "time/data sampling (s)                  0.252362\n",
      "time/data storing (s)                   0.0140445\n",
      "time/evaluation sampling (s)            1.74108\n",
      "time/exploration sampling (s)           0.326827\n",
      "time/logging (s)                        0.0114414\n",
      "time/preback_alpha (s)                  0.962992\n",
      "time/preback_policy (s)                 1.07879\n",
      "time/preback_start (s)                  0.14198\n",
      "time/preback_zf (s)                     5.14272\n",
      "time/saving (s)                         0.00621549\n",
      "time/training (s)                       2.177\n",
      "time/epoch (s)                         17.5033\n",
      "time/total (s)                        811.716\n",
      "Epoch                                  45\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:05:58.213564 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 46 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  57000\n",
      "trainer/ZF1 Loss                       80.4972\n",
      "trainer/ZF2 Loss                       73.7656\n",
      "trainer/ZF Expert Reward               14.3618\n",
      "trainer/ZF Policy Reward               -2.48794\n",
      "trainer/ZF CHI2 Term                  113.107\n",
      "trainer/Policy Loss                 -1080.7\n",
      "trainer/Bias Loss                     352.686\n",
      "trainer/Bias Value                     13.4384\n",
      "trainer/Policy Grad Norm              134.381\n",
      "trainer/Policy Param Norm              28.0441\n",
      "trainer/Zf1 Grad Norm                5268.18\n",
      "trainer/Zf1 Param Norm                 74.4194\n",
      "trainer/Zf2 Grad Norm                3005.35\n",
      "trainer/Zf2 Param Norm                 75.3304\n",
      "trainer/Z Expert Predictions Mean    1520.69\n",
      "trainer/Z Expert Predictions Std       89.1764\n",
      "trainer/Z Expert Predictions Max     1618.42\n",
      "trainer/Z Expert Predictions Min     1115.31\n",
      "trainer/Z Policy Predictions Mean    1070.44\n",
      "trainer/Z Policy Predictions Std      561.689\n",
      "trainer/Z Policy Predictions Max     1607.63\n",
      "trainer/Z Policy Predictions Min     -348.674\n",
      "trainer/Z Expert Targets Mean        1506.33\n",
      "trainer/Z Expert Targets Std           87.7854\n",
      "trainer/Z Expert Targets Max         1611.32\n",
      "trainer/Z Expert Targets Min         1095.95\n",
      "trainer/Z Policy Targets Mean        1072.93\n",
      "trainer/Z Policy Targets Std          553.51\n",
      "trainer/Z Policy Targets Max         1599.02\n",
      "trainer/Z Policy Targets Min         -342.932\n",
      "trainer/Log Pis Mean                   19.3194\n",
      "trainer/Log Pis Std                     5.21695\n",
      "trainer/Policy mu Mean                 -0.0613464\n",
      "trainer/Policy mu Std                   1.35102\n",
      "trainer/Policy log std Mean            -2.7451\n",
      "trainer/Policy log std Std              1.03152\n",
      "trainer/Alpha                           0.0729297\n",
      "trainer/Alpha Loss                      0.0496356\n",
      "exploration/num steps total         52139\n",
      "exploration/num paths total           141\n",
      "evaluation/num steps total         323282\n",
      "evaluation/num paths total            495\n",
      "evaluation/path length Mean           996.8\n",
      "evaluation/path length Std              9.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            968\n",
      "evaluation/Rewards Mean                 3.93378\n",
      "evaluation/Rewards Std                  2.05596\n",
      "evaluation/Rewards Max                  6.83623\n",
      "evaluation/Rewards Min                 -2.3506\n",
      "evaluation/Returns Mean              3921.2\n",
      "evaluation/Returns Std               1575.84\n",
      "evaluation/Returns Max               4580.26\n",
      "evaluation/Returns Min               -790.311\n",
      "evaluation/Estimation Bias Mean      1299.54\n",
      "evaluation/Estimation Bias Std        505.177\n",
      "evaluation/EB/Q_True Mean              41.0652\n",
      "evaluation/EB/Q_True Std              127.23\n",
      "evaluation/EB/Q_Pred Mean            1340.6\n",
      "evaluation/EB/Q_Pred Std              504.166\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3921.2\n",
      "evaluation/Actions Mean                -0.0195567\n",
      "evaluation/Actions Std                  0.569122\n",
      "evaluation/Actions Max                  0.999972\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8038\n",
      "time/backward_zf1 (s)                   1.93605\n",
      "time/backward_zf2 (s)                   1.8721\n",
      "time/data sampling (s)                  0.303172\n",
      "time/data storing (s)                   0.0156959\n",
      "time/evaluation sampling (s)            1.70399\n",
      "time/exploration sampling (s)           0.330693\n",
      "time/logging (s)                        0.0121409\n",
      "time/preback_alpha (s)                  0.934626\n",
      "time/preback_policy (s)                 1.03746\n",
      "time/preback_start (s)                  0.147372\n",
      "time/preback_zf (s)                     5.21125\n",
      "time/saving (s)                         0.00662332\n",
      "time/training (s)                       2.39028\n",
      "time/epoch (s)                         17.7053\n",
      "time/total (s)                        829.442\n",
      "Epoch                                  46\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:06:15.950526 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 47 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  58000\n",
      "trainer/ZF1 Loss                      199.658\n",
      "trainer/ZF2 Loss                      102.524\n",
      "trainer/ZF Expert Reward               16.3265\n",
      "trainer/ZF Policy Reward               -3.08757\n",
      "trainer/ZF CHI2 Term                  190.737\n",
      "trainer/Policy Loss                 -1050.73\n",
      "trainer/Bias Loss                    1279.88\n",
      "trainer/Bias Value                     13.4712\n",
      "trainer/Policy Grad Norm              144.858\n",
      "trainer/Policy Param Norm              28.1627\n",
      "trainer/Zf1 Grad Norm               35370.6\n",
      "trainer/Zf1 Param Norm                 74.8089\n",
      "trainer/Zf2 Grad Norm               31968.5\n",
      "trainer/Zf2 Param Norm                 75.7285\n",
      "trainer/Z Expert Predictions Mean    1530.58\n",
      "trainer/Z Expert Predictions Std       97.5348\n",
      "trainer/Z Expert Predictions Max     1637.45\n",
      "trainer/Z Expert Predictions Min      717.852\n",
      "trainer/Z Policy Predictions Mean    1043.62\n",
      "trainer/Z Policy Predictions Std      620.473\n",
      "trainer/Z Policy Predictions Max     1621.81\n",
      "trainer/Z Policy Predictions Min     -396.81\n",
      "trainer/Z Expert Targets Mean        1514.26\n",
      "trainer/Z Expert Targets Std          127.237\n",
      "trainer/Z Expert Targets Max         1623.25\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1046.71\n",
      "trainer/Z Policy Targets Std          613.834\n",
      "trainer/Z Policy Targets Max         1615.68\n",
      "trainer/Z Policy Targets Min         -392.817\n",
      "trainer/Log Pis Mean                   20.4366\n",
      "trainer/Log Pis Std                     5.05725\n",
      "trainer/Policy mu Mean                 -0.0744298\n",
      "trainer/Policy mu Std                   1.50326\n",
      "trainer/Policy log std Mean            -2.74697\n",
      "trainer/Policy log std Std              1.05455\n",
      "trainer/Alpha                           0.0715472\n",
      "trainer/Alpha Loss                     -0.0312395\n",
      "exploration/num steps total         52139\n",
      "exploration/num paths total           141\n",
      "evaluation/num steps total         332328\n",
      "evaluation/num paths total            505\n",
      "evaluation/path length Mean           904.6\n",
      "evaluation/path length Std            286.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             46\n",
      "evaluation/Rewards Mean                 4.51522\n",
      "evaluation/Rewards Std                  1.12502\n",
      "evaluation/Rewards Max                  6.74569\n",
      "evaluation/Rewards Min                 -2.00406\n",
      "evaluation/Returns Mean              4084.47\n",
      "evaluation/Returns Std               1327.87\n",
      "evaluation/Returns Max               4650.52\n",
      "evaluation/Returns Min                112.59\n",
      "evaluation/Estimation Bias Mean      1478.49\n",
      "evaluation/Estimation Bias Std        167.774\n",
      "evaluation/EB/Q_True Mean              45.4029\n",
      "evaluation/EB/Q_True Std              132.337\n",
      "evaluation/EB/Q_Pred Mean            1523.9\n",
      "evaluation/EB/Q_Pred Std              103.284\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4084.47\n",
      "evaluation/Actions Mean                 0.0324856\n",
      "evaluation/Actions Std                  0.535529\n",
      "evaluation/Actions Max                  0.999845\n",
      "evaluation/Actions Min                 -0.999791\n",
      "time/backward_policy (s)                1.8341\n",
      "time/backward_zf1 (s)                   1.95983\n",
      "time/backward_zf2 (s)                   1.90048\n",
      "time/data sampling (s)                  0.287753\n",
      "time/data storing (s)                   0.0140657\n",
      "time/evaluation sampling (s)            1.75379\n",
      "time/exploration sampling (s)           0.312767\n",
      "time/logging (s)                        0.0111492\n",
      "time/preback_alpha (s)                  0.964402\n",
      "time/preback_policy (s)                 1.07657\n",
      "time/preback_start (s)                  0.142028\n",
      "time/preback_zf (s)                     5.18602\n",
      "time/saving (s)                         0.00594462\n",
      "time/training (s)                       2.22019\n",
      "time/epoch (s)                         17.6691\n",
      "time/total (s)                        847.131\n",
      "Epoch                                  47\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:06:32.820404 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 48 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  59000\n",
      "trainer/ZF1 Loss                       26.1186\n",
      "trainer/ZF2 Loss                       66.1376\n",
      "trainer/ZF Expert Reward               16.6772\n",
      "trainer/ZF Policy Reward               -2.05285\n",
      "trainer/ZF CHI2 Term                   85.5498\n",
      "trainer/Policy Loss                 -1076.51\n",
      "trainer/Bias Loss                     315.929\n",
      "trainer/Bias Value                     13.5057\n",
      "trainer/Policy Grad Norm              113.433\n",
      "trainer/Policy Param Norm              28.2835\n",
      "trainer/Zf1 Grad Norm                2937.17\n",
      "trainer/Zf1 Param Norm                 75.1686\n",
      "trainer/Zf2 Grad Norm                9559.07\n",
      "trainer/Zf2 Param Norm                 76.1354\n",
      "trainer/Z Expert Predictions Mean    1539.16\n",
      "trainer/Z Expert Predictions Std      127.813\n",
      "trainer/Z Expert Predictions Max     1643.52\n",
      "trainer/Z Expert Predictions Min     -111.382\n",
      "trainer/Z Policy Predictions Mean    1067.55\n",
      "trainer/Z Policy Predictions Std      619.102\n",
      "trainer/Z Policy Predictions Max     1629.7\n",
      "trainer/Z Policy Predictions Min     -396.733\n",
      "trainer/Z Expert Targets Mean        1522.49\n",
      "trainer/Z Expert Targets Std          122.234\n",
      "trainer/Z Expert Targets Max         1624.04\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1069.61\n",
      "trainer/Z Policy Targets Std          610.927\n",
      "trainer/Z Policy Targets Max         1616.48\n",
      "trainer/Z Policy Targets Min         -386.782\n",
      "trainer/Log Pis Mean                   20.9006\n",
      "trainer/Log Pis Std                     6.68094\n",
      "trainer/Policy mu Mean                  0.0130086\n",
      "trainer/Policy mu Std                   1.5643\n",
      "trainer/Policy log std Mean            -2.76551\n",
      "trainer/Policy log std Std              1.06918\n",
      "trainer/Alpha                           0.0748646\n",
      "trainer/Alpha Loss                     -0.0674142\n",
      "exploration/num steps total         54139\n",
      "exploration/num paths total           143\n",
      "evaluation/num steps total         335825\n",
      "evaluation/num paths total            515\n",
      "evaluation/path length Mean           349.7\n",
      "evaluation/path length Std            258.694\n",
      "evaluation/path length Max            782\n",
      "evaluation/path length Min             45\n",
      "evaluation/Rewards Mean                 4.27867\n",
      "evaluation/Rewards Std                  1.46249\n",
      "evaluation/Rewards Max                  6.95653\n",
      "evaluation/Rewards Min                 -2.04472\n",
      "evaluation/Returns Mean              1496.25\n",
      "evaluation/Returns Std               1170.18\n",
      "evaluation/Returns Max               3498.89\n",
      "evaluation/Returns Min                 95.4826\n",
      "evaluation/Estimation Bias Mean      1395.18\n",
      "evaluation/Estimation Bias Std        227.212\n",
      "evaluation/EB/Q_True Mean              88.5015\n",
      "evaluation/EB/Q_True Std              177.234\n",
      "evaluation/EB/Q_Pred Mean            1483.68\n",
      "evaluation/EB/Q_Pred Std              134.057\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1496.25\n",
      "evaluation/Actions Mean                 0.0411458\n",
      "evaluation/Actions Std                  0.536906\n",
      "evaluation/Actions Max                  0.999779\n",
      "evaluation/Actions Min                 -0.999626\n",
      "time/backward_policy (s)                1.73121\n",
      "time/backward_zf1 (s)                   1.8334\n",
      "time/backward_zf2 (s)                   1.77601\n",
      "time/data sampling (s)                  0.262561\n",
      "time/data storing (s)                   0.0140673\n",
      "time/evaluation sampling (s)            1.37357\n",
      "time/exploration sampling (s)           0.321654\n",
      "time/logging (s)                        0.00503969\n",
      "time/preback_alpha (s)                  0.926322\n",
      "time/preback_policy (s)                 1.01677\n",
      "time/preback_start (s)                  0.141656\n",
      "time/preback_zf (s)                     5.11353\n",
      "time/saving (s)                         0.00653944\n",
      "time/training (s)                       2.27532\n",
      "time/epoch (s)                         16.7976\n",
      "time/total (s)                        863.95\n",
      "Epoch                                  48\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:06:50.674964 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 49 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  60000\n",
      "trainer/ZF1 Loss                       41.9437\n",
      "trainer/ZF2 Loss                       48.0638\n",
      "trainer/ZF Expert Reward               13.5292\n",
      "trainer/ZF Policy Reward                0.268144\n",
      "trainer/ZF CHI2 Term                   78.5288\n",
      "trainer/Policy Loss                 -1069.58\n",
      "trainer/Bias Loss                     196.321\n",
      "trainer/Bias Value                     13.5393\n",
      "trainer/Policy Grad Norm              128.891\n",
      "trainer/Policy Param Norm              28.3975\n",
      "trainer/Zf1 Grad Norm                4497.58\n",
      "trainer/Zf1 Param Norm                 75.5482\n",
      "trainer/Zf2 Grad Norm                3369.58\n",
      "trainer/Zf2 Param Norm                 76.4901\n",
      "trainer/Z Expert Predictions Mean    1554.98\n",
      "trainer/Z Expert Predictions Std       70.6076\n",
      "trainer/Z Expert Predictions Max     1647.08\n",
      "trainer/Z Expert Predictions Min     1231.02\n",
      "trainer/Z Policy Predictions Mean    1060.17\n",
      "trainer/Z Policy Predictions Std      639.144\n",
      "trainer/Z Policy Predictions Max     1642.32\n",
      "trainer/Z Policy Predictions Min     -430.654\n",
      "trainer/Z Expert Targets Mean        1541.45\n",
      "trainer/Z Expert Targets Std           71.2047\n",
      "trainer/Z Expert Targets Max         1635.88\n",
      "trainer/Z Expert Targets Min         1197.87\n",
      "trainer/Z Policy Targets Mean        1059.9\n",
      "trainer/Z Policy Targets Std          633.994\n",
      "trainer/Z Policy Targets Max         1619.79\n",
      "trainer/Z Policy Targets Min         -432.559\n",
      "trainer/Log Pis Mean                   20.4687\n",
      "trainer/Log Pis Std                     5.67782\n",
      "trainer/Policy mu Mean                  0.00148762\n",
      "trainer/Policy mu Std                   1.54761\n",
      "trainer/Policy log std Mean            -2.7045\n",
      "trainer/Policy log std Std              1.09857\n",
      "trainer/Alpha                           0.0803556\n",
      "trainer/Alpha Loss                     -0.0376616\n",
      "exploration/num steps total         55139\n",
      "exploration/num paths total           144\n",
      "evaluation/num steps total         345480\n",
      "evaluation/num paths total            525\n",
      "evaluation/path length Mean           965.5\n",
      "evaluation/path length Std            103.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            655\n",
      "evaluation/Rewards Mean                 4.50495\n",
      "evaluation/Rewards Std                  1.07276\n",
      "evaluation/Rewards Max                  6.6291\n",
      "evaluation/Rewards Min                 -1.95243\n",
      "evaluation/Returns Mean              4349.53\n",
      "evaluation/Returns Std                487.103\n",
      "evaluation/Returns Max               4651.73\n",
      "evaluation/Returns Min               2918.17\n",
      "evaluation/Estimation Bias Mean      1483.03\n",
      "evaluation/Estimation Bias Std        156.39\n",
      "evaluation/EB/Q_True Mean              41.9137\n",
      "evaluation/EB/Q_True Std              126.91\n",
      "evaluation/EB/Q_Pred Mean            1524.95\n",
      "evaluation/EB/Q_Pred Std               94.0491\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4349.53\n",
      "evaluation/Actions Mean                 0.010978\n",
      "evaluation/Actions Std                  0.517413\n",
      "evaluation/Actions Max                  0.999679\n",
      "evaluation/Actions Min                 -0.9997\n",
      "time/backward_policy (s)                1.84141\n",
      "time/backward_zf1 (s)                   1.98659\n",
      "time/backward_zf2 (s)                   1.91596\n",
      "time/data sampling (s)                  0.27449\n",
      "time/data storing (s)                   0.0145047\n",
      "time/evaluation sampling (s)            1.71876\n",
      "time/exploration sampling (s)           0.321296\n",
      "time/logging (s)                        0.0129446\n",
      "time/preback_alpha (s)                  0.951207\n",
      "time/preback_policy (s)                 1.0557\n",
      "time/preback_start (s)                  0.145435\n",
      "time/preback_zf (s)                     5.18653\n",
      "time/saving (s)                         0.00626066\n",
      "time/training (s)                       2.36324\n",
      "time/epoch (s)                         17.7943\n",
      "time/total (s)                        881.766\n",
      "Epoch                                  49\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:07:07.942665 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 50 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  61000\n",
      "trainer/ZF1 Loss                       36.9682\n",
      "trainer/ZF2 Loss                       29.7404\n",
      "trainer/ZF Expert Reward               11.2735\n",
      "trainer/ZF Policy Reward               -4.41942\n",
      "trainer/ZF CHI2 Term                   69.1542\n",
      "trainer/Policy Loss                 -1079.38\n",
      "trainer/Bias Loss                     170.372\n",
      "trainer/Bias Value                     13.5701\n",
      "trainer/Policy Grad Norm              127.033\n",
      "trainer/Policy Param Norm              28.5018\n",
      "trainer/Zf1 Grad Norm                2864.23\n",
      "trainer/Zf1 Param Norm                 75.8952\n",
      "trainer/Zf2 Grad Norm                3625.1\n",
      "trainer/Zf2 Param Norm                 76.8539\n",
      "trainer/Z Expert Predictions Mean    1547.13\n",
      "trainer/Z Expert Predictions Std       88.4536\n",
      "trainer/Z Expert Predictions Max     1650.05\n",
      "trainer/Z Expert Predictions Min     1161.63\n",
      "trainer/Z Policy Predictions Mean    1073.53\n",
      "trainer/Z Policy Predictions Std      625.517\n",
      "trainer/Z Policy Predictions Max     1646.66\n",
      "trainer/Z Policy Predictions Min     -442.171\n",
      "trainer/Z Expert Targets Mean        1535.86\n",
      "trainer/Z Expert Targets Std           89.9568\n",
      "trainer/Z Expert Targets Max         1637.7\n",
      "trainer/Z Expert Targets Min         1143.78\n",
      "trainer/Z Policy Targets Mean        1077.95\n",
      "trainer/Z Policy Targets Std          621.917\n",
      "trainer/Z Policy Targets Max         1636.57\n",
      "trainer/Z Policy Targets Min         -437.184\n",
      "trainer/Log Pis Mean                   20.3102\n",
      "trainer/Log Pis Std                     6.4797\n",
      "trainer/Policy mu Mean                 -0.0531603\n",
      "trainer/Policy mu Std                   1.5747\n",
      "trainer/Policy log std Mean            -2.66277\n",
      "trainer/Policy log std Std              1.12457\n",
      "trainer/Alpha                           0.0830766\n",
      "trainer/Alpha Loss                     -0.0257663\n",
      "exploration/num steps total         57668\n",
      "exploration/num paths total           147\n",
      "evaluation/num steps total         346684\n",
      "evaluation/num paths total            536\n",
      "evaluation/path length Mean           109.455\n",
      "evaluation/path length Std             66.2191\n",
      "evaluation/path length Max            234\n",
      "evaluation/path length Min             20\n",
      "evaluation/Rewards Mean                 3.35467\n",
      "evaluation/Rewards Std                  1.88794\n",
      "evaluation/Rewards Max                  6.35974\n",
      "evaluation/Rewards Min                 -1.72749\n",
      "evaluation/Returns Mean               367.184\n",
      "evaluation/Returns Std                296.419\n",
      "evaluation/Returns Max               1020.46\n",
      "evaluation/Returns Min                 20.2487\n",
      "evaluation/Estimation Bias Mean      1354.1\n",
      "evaluation/Estimation Bias Std        243.03\n",
      "evaluation/EB/Q_True Mean              56.3887\n",
      "evaluation/EB/Q_True Std              126.639\n",
      "evaluation/EB/Q_Pred Mean            1410.49\n",
      "evaluation/EB/Q_Pred Std              184.456\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns            367.184\n",
      "evaluation/Actions Mean                 0.0104804\n",
      "evaluation/Actions Std                  0.530164\n",
      "evaluation/Actions Max                  0.999514\n",
      "evaluation/Actions Min                 -0.999599\n",
      "time/backward_policy (s)                1.94467\n",
      "time/backward_zf1 (s)                   2.12882\n",
      "time/backward_zf2 (s)                   2.05925\n",
      "time/data sampling (s)                  0.29151\n",
      "time/data storing (s)                   0.014566\n",
      "time/evaluation sampling (s)            0.604144\n",
      "time/exploration sampling (s)           0.328244\n",
      "time/logging (s)                        0.00291862\n",
      "time/preback_alpha (s)                  1.03657\n",
      "time/preback_policy (s)                 1.18569\n",
      "time/preback_start (s)                  0.146527\n",
      "time/preback_zf (s)                     5.28502\n",
      "time/saving (s)                         0.00657093\n",
      "time/training (s)                       2.15492\n",
      "time/epoch (s)                         17.1894\n",
      "time/total (s)                        898.975\n",
      "Epoch                                  50\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:07:25.534919 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 51 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  62000\n",
      "trainer/ZF1 Loss                      556.694\n",
      "trainer/ZF2 Loss                      554.038\n",
      "trainer/ZF Expert Reward               12.3933\n",
      "trainer/ZF Policy Reward                6.47039\n",
      "trainer/ZF CHI2 Term                  581.45\n",
      "trainer/Policy Loss                 -1006.53\n",
      "trainer/Bias Loss                     174.911\n",
      "trainer/Bias Value                     13.5999\n",
      "trainer/Policy Grad Norm              130.74\n",
      "trainer/Policy Param Norm              28.601\n",
      "trainer/Zf1 Grad Norm                4212.15\n",
      "trainer/Zf1 Param Norm                 76.255\n",
      "trainer/Zf2 Grad Norm                3056.57\n",
      "trainer/Zf2 Param Norm                 77.2187\n",
      "trainer/Z Expert Predictions Mean    1564.47\n",
      "trainer/Z Expert Predictions Std       74.5318\n",
      "trainer/Z Expert Predictions Max     1651.5\n",
      "trainer/Z Expert Predictions Min     1163.56\n",
      "trainer/Z Policy Predictions Mean     996.932\n",
      "trainer/Z Policy Predictions Std      715.53\n",
      "trainer/Z Policy Predictions Max     1639.37\n",
      "trainer/Z Policy Predictions Min     -475.055\n",
      "trainer/Z Expert Targets Mean        1552.07\n",
      "trainer/Z Expert Targets Std           75.0579\n",
      "trainer/Z Expert Targets Max         1642.05\n",
      "trainer/Z Expert Targets Min         1145.81\n",
      "trainer/Z Policy Targets Mean         990.461\n",
      "trainer/Z Policy Targets Std          712.015\n",
      "trainer/Z Policy Targets Max         1630.4\n",
      "trainer/Z Policy Targets Min         -474.416\n",
      "trainer/Log Pis Mean                   20.3644\n",
      "trainer/Log Pis Std                     6.5764\n",
      "trainer/Policy mu Mean                 -0.259879\n",
      "trainer/Policy mu Std                   1.54475\n",
      "trainer/Policy log std Mean            -2.6415\n",
      "trainer/Policy log std Std              1.16299\n",
      "trainer/Alpha                           0.0838025\n",
      "trainer/Alpha Loss                     -0.0305384\n",
      "exploration/num steps total         57668\n",
      "exploration/num paths total           147\n",
      "evaluation/num steps total         356684\n",
      "evaluation/num paths total            546\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.99534\n",
      "evaluation/Rewards Std                  2.04628\n",
      "evaluation/Rewards Max                  6.84339\n",
      "evaluation/Rewards Min                 -3.13513\n",
      "evaluation/Returns Mean              3995.34\n",
      "evaluation/Returns Std               1593\n",
      "evaluation/Returns Max               4652.86\n",
      "evaluation/Returns Min               -774.712\n",
      "evaluation/Estimation Bias Mean      1343.1\n",
      "evaluation/Estimation Bias Std        553.886\n",
      "evaluation/EB/Q_True Mean              42.2972\n",
      "evaluation/EB/Q_True Std              131.147\n",
      "evaluation/EB/Q_Pred Mean            1385.4\n",
      "evaluation/EB/Q_Pred Std              549.606\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3995.34\n",
      "evaluation/Actions Mean                -0.0190969\n",
      "evaluation/Actions Std                  0.575807\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999989\n",
      "time/backward_policy (s)                1.8062\n",
      "time/backward_zf1 (s)                   1.90923\n",
      "time/backward_zf2 (s)                   1.85798\n",
      "time/data sampling (s)                  0.249958\n",
      "time/data storing (s)                   0.0139536\n",
      "time/evaluation sampling (s)            1.84596\n",
      "time/exploration sampling (s)           0.313932\n",
      "time/logging (s)                        0.0127764\n",
      "time/preback_alpha (s)                  0.941044\n",
      "time/preback_policy (s)                 1.05683\n",
      "time/preback_start (s)                  0.138505\n",
      "time/preback_zf (s)                     5.1293\n",
      "time/saving (s)                         0.00747379\n",
      "time/training (s)                       2.25429\n",
      "time/epoch (s)                         17.5374\n",
      "time/total (s)                        916.532\n",
      "Epoch                                  51\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:07:42.763156 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 52 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  63000\n",
      "trainer/ZF1 Loss                       50.4147\n",
      "trainer/ZF2 Loss                       39.9749\n",
      "trainer/ZF Expert Reward               12.3856\n",
      "trainer/ZF Policy Reward               -2.72229\n",
      "trainer/ZF CHI2 Term                   80.0056\n",
      "trainer/Policy Loss                 -1074.12\n",
      "trainer/Bias Loss                     186.537\n",
      "trainer/Bias Value                     13.6279\n",
      "trainer/Policy Grad Norm              123.355\n",
      "trainer/Policy Param Norm              28.6965\n",
      "trainer/Zf1 Grad Norm                5393.11\n",
      "trainer/Zf1 Param Norm                 76.6126\n",
      "trainer/Zf2 Grad Norm                2395.08\n",
      "trainer/Zf2 Param Norm                 77.6055\n",
      "trainer/Z Expert Predictions Mean    1557.42\n",
      "trainer/Z Expert Predictions Std       84.2125\n",
      "trainer/Z Expert Predictions Max     1654.72\n",
      "trainer/Z Expert Predictions Min     1221.68\n",
      "trainer/Z Policy Predictions Mean    1065.1\n",
      "trainer/Z Policy Predictions Std      654.948\n",
      "trainer/Z Policy Predictions Max     1671.41\n",
      "trainer/Z Policy Predictions Min     -506.467\n",
      "trainer/Z Expert Targets Mean        1545.03\n",
      "trainer/Z Expert Targets Std           83.7058\n",
      "trainer/Z Expert Targets Max         1649.06\n",
      "trainer/Z Expert Targets Min         1188.93\n",
      "trainer/Z Policy Targets Mean        1067.82\n",
      "trainer/Z Policy Targets Std          647.045\n",
      "trainer/Z Policy Targets Max         1645.62\n",
      "trainer/Z Policy Targets Min         -508.863\n",
      "trainer/Log Pis Mean                   19.9018\n",
      "trainer/Log Pis Std                     6.62535\n",
      "trainer/Policy mu Mean                 -0.0764767\n",
      "trainer/Policy mu Std                   1.55241\n",
      "trainer/Policy log std Mean            -2.59479\n",
      "trainer/Policy log std Std              1.12667\n",
      "trainer/Alpha                           0.0842273\n",
      "trainer/Alpha Loss                      0.00826802\n",
      "exploration/num steps total         58521\n",
      "exploration/num paths total           148\n",
      "evaluation/num steps total         358669\n",
      "evaluation/num paths total            556\n",
      "evaluation/path length Mean           198.5\n",
      "evaluation/path length Std            196.318\n",
      "evaluation/path length Max            567\n",
      "evaluation/path length Min             21\n",
      "evaluation/Rewards Mean                 3.62547\n",
      "evaluation/Rewards Std                  1.80532\n",
      "evaluation/Rewards Max                  6.7039\n",
      "evaluation/Rewards Min                 -2.21136\n",
      "evaluation/Returns Mean               719.656\n",
      "evaluation/Returns Std                836.175\n",
      "evaluation/Returns Max               2323.27\n",
      "evaluation/Returns Min                  6.52697\n",
      "evaluation/Estimation Bias Mean      1367.34\n",
      "evaluation/Estimation Bias Std        249.662\n",
      "evaluation/EB/Q_True Mean              89.526\n",
      "evaluation/EB/Q_True Std              160.864\n",
      "evaluation/EB/Q_Pred Mean            1456.86\n",
      "evaluation/EB/Q_Pred Std              170.37\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            719.656\n",
      "evaluation/Actions Mean                 0.0394813\n",
      "evaluation/Actions Std                  0.539197\n",
      "evaluation/Actions Max                  0.999258\n",
      "evaluation/Actions Min                 -0.999617\n",
      "time/backward_policy (s)                1.78181\n",
      "time/backward_zf1 (s)                   1.91802\n",
      "time/backward_zf2 (s)                   1.8268\n",
      "time/data sampling (s)                  0.289944\n",
      "time/data storing (s)                   0.014277\n",
      "time/evaluation sampling (s)            1.36125\n",
      "time/exploration sampling (s)           0.316182\n",
      "time/logging (s)                        0.00380639\n",
      "time/preback_alpha (s)                  0.921146\n",
      "time/preback_policy (s)                 0.990626\n",
      "time/preback_start (s)                  0.146935\n",
      "time/preback_zf (s)                     5.16778\n",
      "time/saving (s)                         0.00527556\n",
      "time/training (s)                       2.41029\n",
      "time/epoch (s)                         17.1541\n",
      "time/total (s)                        933.705\n",
      "Epoch                                  52\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:08:01.706165 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 53 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  64000\n",
      "trainer/ZF1 Loss                       39.1577\n",
      "trainer/ZF2 Loss                       85.8624\n",
      "trainer/ZF Expert Reward               22.4775\n",
      "trainer/ZF Policy Reward                3.92217\n",
      "trainer/ZF CHI2 Term                  100.384\n",
      "trainer/Policy Loss                 -1129.04\n",
      "trainer/Bias Loss                     487.61\n",
      "trainer/Bias Value                     13.6507\n",
      "trainer/Policy Grad Norm              122.228\n",
      "trainer/Policy Param Norm              28.7943\n",
      "trainer/Zf1 Grad Norm                4513.49\n",
      "trainer/Zf1 Param Norm                 76.9616\n",
      "trainer/Zf2 Grad Norm                3045.78\n",
      "trainer/Zf2 Param Norm                 77.9568\n",
      "trainer/Z Expert Predictions Mean    1572.47\n",
      "trainer/Z Expert Predictions Std       79.5462\n",
      "trainer/Z Expert Predictions Max     1678.16\n",
      "trainer/Z Expert Predictions Min     1185.88\n",
      "trainer/Z Policy Predictions Mean    1122.64\n",
      "trainer/Z Policy Predictions Std      645.953\n",
      "trainer/Z Policy Predictions Max     1662.42\n",
      "trainer/Z Policy Predictions Min     -525.7\n",
      "trainer/Z Expert Targets Mean        1550\n",
      "trainer/Z Expert Targets Std           87.034\n",
      "trainer/Z Expert Targets Max         1643.11\n",
      "trainer/Z Expert Targets Min          971.812\n",
      "trainer/Z Policy Targets Mean        1118.72\n",
      "trainer/Z Policy Targets Std          634.487\n",
      "trainer/Z Policy Targets Max         1643.84\n",
      "trainer/Z Policy Targets Min         -503.428\n",
      "trainer/Log Pis Mean                   19.5133\n",
      "trainer/Log Pis Std                     5.69774\n",
      "trainer/Policy mu Mean                  0.0124604\n",
      "trainer/Policy mu Std                   1.36618\n",
      "trainer/Policy log std Mean            -2.80263\n",
      "trainer/Policy log std Std              1.09259\n",
      "trainer/Alpha                           0.0806851\n",
      "trainer/Alpha Loss                      0.0392724\n",
      "exploration/num steps total         58823\n",
      "exploration/num paths total           149\n",
      "evaluation/num steps total         367829\n",
      "evaluation/num paths total            569\n",
      "evaluation/path length Mean           704.615\n",
      "evaluation/path length Std            361.68\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             47\n",
      "evaluation/Rewards Mean                 3.57546\n",
      "evaluation/Rewards Std                  2.22792\n",
      "evaluation/Rewards Max                  6.92267\n",
      "evaluation/Rewards Min                 -2.18762\n",
      "evaluation/Returns Mean              2519.32\n",
      "evaluation/Returns Std               1712.92\n",
      "evaluation/Returns Max               4374.72\n",
      "evaluation/Returns Min               -441.459\n",
      "evaluation/Estimation Bias Mean      1446.17\n",
      "evaluation/Estimation Bias Std        232.084\n",
      "evaluation/EB/Q_True Mean              -8.44611\n",
      "evaluation/EB/Q_True Std               73.3674\n",
      "evaluation/EB/Q_Pred Mean            1437.72\n",
      "evaluation/EB/Q_Pred Std              213.868\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2519.32\n",
      "evaluation/Actions Mean                 0.0235339\n",
      "evaluation/Actions Std                  0.587165\n",
      "evaluation/Actions Max                  0.999714\n",
      "evaluation/Actions Min                 -0.999966\n",
      "time/backward_policy (s)                2.02984\n",
      "time/backward_zf1 (s)                   2.23495\n",
      "time/backward_zf2 (s)                   2.1368\n",
      "time/data sampling (s)                  0.276034\n",
      "time/data storing (s)                   0.0170765\n",
      "time/evaluation sampling (s)            1.78033\n",
      "time/exploration sampling (s)           0.347967\n",
      "time/logging (s)                        0.0113935\n",
      "time/preback_alpha (s)                  1.05382\n",
      "time/preback_policy (s)                 1.20522\n",
      "time/preback_start (s)                  0.158461\n",
      "time/preback_zf (s)                     5.35579\n",
      "time/saving (s)                         0.00732644\n",
      "time/training (s)                       2.26292\n",
      "time/epoch (s)                         18.8779\n",
      "time/total (s)                        952.603\n",
      "Epoch                                  53\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:08:20.798814 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 54 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  65000\n",
      "trainer/ZF1 Loss                       45.6539\n",
      "trainer/ZF2 Loss                       43.407\n",
      "trainer/ZF Expert Reward               16.2368\n",
      "trainer/ZF Policy Reward                2.3691\n",
      "trainer/ZF CHI2 Term                   78.0549\n",
      "trainer/Policy Loss                 -1220.95\n",
      "trainer/Bias Loss                     186.259\n",
      "trainer/Bias Value                     13.6738\n",
      "trainer/Policy Grad Norm              153.157\n",
      "trainer/Policy Param Norm              28.8993\n",
      "trainer/Zf1 Grad Norm                5996.06\n",
      "trainer/Zf1 Param Norm                 77.2843\n",
      "trainer/Zf2 Grad Norm                2542.83\n",
      "trainer/Zf2 Param Norm                 78.2921\n",
      "trainer/Z Expert Predictions Mean    1578.37\n",
      "trainer/Z Expert Predictions Std       77.6258\n",
      "trainer/Z Expert Predictions Max     1666.74\n",
      "trainer/Z Expert Predictions Min     1152.08\n",
      "trainer/Z Policy Predictions Mean    1210.03\n",
      "trainer/Z Policy Predictions Std      543.601\n",
      "trainer/Z Policy Predictions Max     1656.46\n",
      "trainer/Z Policy Predictions Min     -524.173\n",
      "trainer/Z Expert Targets Mean        1562.13\n",
      "trainer/Z Expert Targets Std           75.5392\n",
      "trainer/Z Expert Targets Max         1652.67\n",
      "trainer/Z Expert Targets Min         1157.54\n",
      "trainer/Z Policy Targets Mean        1207.66\n",
      "trainer/Z Policy Targets Std          533.879\n",
      "trainer/Z Policy Targets Max         1645.89\n",
      "trainer/Z Policy Targets Min         -510.508\n",
      "trainer/Log Pis Mean                   19.8552\n",
      "trainer/Log Pis Std                     5.59813\n",
      "trainer/Policy mu Mean                  0.0446784\n",
      "trainer/Policy mu Std                   1.33841\n",
      "trainer/Policy log std Mean            -2.86206\n",
      "trainer/Policy log std Std              1.0022\n",
      "trainer/Alpha                           0.0789441\n",
      "trainer/Alpha Loss                      0.0114283\n",
      "exploration/num steps total         60823\n",
      "exploration/num paths total           151\n",
      "evaluation/num steps total         376384\n",
      "evaluation/num paths total            579\n",
      "evaluation/path length Mean           855.5\n",
      "evaluation/path length Std            306.984\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             46\n",
      "evaluation/Rewards Mean                 4.25056\n",
      "evaluation/Rewards Std                  1.46607\n",
      "evaluation/Rewards Max                  6.85627\n",
      "evaluation/Rewards Min                 -2.7644\n",
      "evaluation/Returns Mean              3636.36\n",
      "evaluation/Returns Std               1345.76\n",
      "evaluation/Returns Max               4528.14\n",
      "evaluation/Returns Min                107.795\n",
      "evaluation/Estimation Bias Mean      1455.31\n",
      "evaluation/Estimation Bias Std        251.516\n",
      "evaluation/EB/Q_True Mean              44.7903\n",
      "evaluation/EB/Q_True Std              126.72\n",
      "evaluation/EB/Q_Pred Mean            1500.1\n",
      "evaluation/EB/Q_Pred Std              218.088\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3636.36\n",
      "evaluation/Actions Mean                 0.0270538\n",
      "evaluation/Actions Std                  0.559515\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999864\n",
      "time/backward_policy (s)                2.02911\n",
      "time/backward_zf1 (s)                   2.20643\n",
      "time/backward_zf2 (s)                   2.1547\n",
      "time/data sampling (s)                  0.329034\n",
      "time/data storing (s)                   0.0150331\n",
      "time/evaluation sampling (s)            1.76861\n",
      "time/exploration sampling (s)           0.331413\n",
      "time/logging (s)                        0.0110175\n",
      "time/preback_alpha (s)                  1.03465\n",
      "time/preback_policy (s)                 1.20305\n",
      "time/preback_start (s)                  0.151956\n",
      "time/preback_zf (s)                     5.36298\n",
      "time/saving (s)                         0.0060224\n",
      "time/training (s)                       2.41878\n",
      "time/epoch (s)                         19.0228\n",
      "time/total (s)                        971.644\n",
      "Epoch                                  54\n",
      "---------------------------------  --------------\n",
      "2024-06-15 11:08:39.159380 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 55 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  66000\n",
      "trainer/ZF1 Loss                       46.4097\n",
      "trainer/ZF2 Loss                       34.3811\n",
      "trainer/ZF Expert Reward                9.25442\n",
      "trainer/ZF Policy Reward               -3.98917\n",
      "trainer/ZF CHI2 Term                   74.243\n",
      "trainer/Policy Loss                 -1138.2\n",
      "trainer/Bias Loss                     168.306\n",
      "trainer/Bias Value                     13.696\n",
      "trainer/Policy Grad Norm              106.874\n",
      "trainer/Policy Param Norm              29.0032\n",
      "trainer/Zf1 Grad Norm                4278.07\n",
      "trainer/Zf1 Param Norm                 77.5957\n",
      "trainer/Zf2 Grad Norm                2740.96\n",
      "trainer/Zf2 Param Norm                 78.6113\n",
      "trainer/Z Expert Predictions Mean    1573.66\n",
      "trainer/Z Expert Predictions Std       75.3849\n",
      "trainer/Z Expert Predictions Max     1676.9\n",
      "trainer/Z Expert Predictions Min     1077.67\n",
      "trainer/Z Policy Predictions Mean    1129.32\n",
      "trainer/Z Policy Predictions Std      597.352\n",
      "trainer/Z Policy Predictions Max     1656.53\n",
      "trainer/Z Policy Predictions Min     -537.865\n",
      "trainer/Z Expert Targets Mean        1564.4\n",
      "trainer/Z Expert Targets Std           78.2896\n",
      "trainer/Z Expert Targets Max         1669.73\n",
      "trainer/Z Expert Targets Min         1017.2\n",
      "trainer/Z Policy Targets Mean        1133.31\n",
      "trainer/Z Policy Targets Std          592.071\n",
      "trainer/Z Policy Targets Max         1658.61\n",
      "trainer/Z Policy Targets Min         -536.97\n",
      "trainer/Log Pis Mean                   20.8121\n",
      "trainer/Log Pis Std                     6.59185\n",
      "trainer/Policy mu Mean                  0.0938654\n",
      "trainer/Policy mu Std                   1.50479\n",
      "trainer/Policy log std Mean            -2.77742\n",
      "trainer/Policy log std Std              1.05259\n",
      "trainer/Alpha                           0.0779193\n",
      "trainer/Alpha Loss                     -0.0632768\n",
      "exploration/num steps total         61823\n",
      "exploration/num paths total           152\n",
      "evaluation/num steps total         384032\n",
      "evaluation/num paths total            590\n",
      "evaluation/path length Mean           695.273\n",
      "evaluation/path length Std            339.213\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             75\n",
      "evaluation/Rewards Mean                 4.20284\n",
      "evaluation/Rewards Std                  1.62992\n",
      "evaluation/Rewards Max                  7.02526\n",
      "evaluation/Rewards Min                 -2.90377\n",
      "evaluation/Returns Mean              2922.12\n",
      "evaluation/Returns Std               1606.45\n",
      "evaluation/Returns Max               4885.36\n",
      "evaluation/Returns Min                 34.9702\n",
      "evaluation/Estimation Bias Mean      1428.34\n",
      "evaluation/Estimation Bias Std        235.142\n",
      "evaluation/EB/Q_True Mean              59.1842\n",
      "evaluation/EB/Q_True Std              157.214\n",
      "evaluation/EB/Q_Pred Mean            1487.52\n",
      "evaluation/EB/Q_Pred Std              164.009\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2922.12\n",
      "evaluation/Actions Mean                 0.0201664\n",
      "evaluation/Actions Std                  0.546873\n",
      "evaluation/Actions Max                  0.99992\n",
      "evaluation/Actions Min                 -0.999767\n",
      "time/backward_policy (s)                1.90771\n",
      "time/backward_zf1 (s)                   2.10111\n",
      "time/backward_zf2 (s)                   1.98515\n",
      "time/data sampling (s)                  0.300251\n",
      "time/data storing (s)                   0.0148343\n",
      "time/evaluation sampling (s)            1.74601\n",
      "time/exploration sampling (s)           0.333247\n",
      "time/logging (s)                        0.0097364\n",
      "time/preback_alpha (s)                  0.998477\n",
      "time/preback_policy (s)                 1.11183\n",
      "time/preback_start (s)                  0.148492\n",
      "time/preback_zf (s)                     5.32643\n",
      "time/saving (s)                         0.00689405\n",
      "time/training (s)                       2.30113\n",
      "time/epoch (s)                         18.2913\n",
      "time/total (s)                        989.954\n",
      "Epoch                                  55\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:08:57.390031 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 56 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  67000\n",
      "trainer/ZF1 Loss                      117.954\n",
      "trainer/ZF2 Loss                       53.0779\n",
      "trainer/ZF Expert Reward               22.0973\n",
      "trainer/ZF Policy Reward                1.76718\n",
      "trainer/ZF CHI2 Term                  125.976\n",
      "trainer/Policy Loss                 -1139.01\n",
      "trainer/Bias Loss                     761.161\n",
      "trainer/Bias Value                     13.718\n",
      "trainer/Policy Grad Norm              148.297\n",
      "trainer/Policy Param Norm              29.1028\n",
      "trainer/Zf1 Grad Norm               16752.9\n",
      "trainer/Zf1 Param Norm                 77.9412\n",
      "trainer/Zf2 Grad Norm               10100.9\n",
      "trainer/Zf2 Param Norm                 78.9304\n",
      "trainer/Z Expert Predictions Mean    1584.11\n",
      "trainer/Z Expert Predictions Std       93.7248\n",
      "trainer/Z Expert Predictions Max     1692.72\n",
      "trainer/Z Expert Predictions Min      506.607\n",
      "trainer/Z Policy Predictions Mean    1133.87\n",
      "trainer/Z Policy Predictions Std      632.636\n",
      "trainer/Z Policy Predictions Max     1680.21\n",
      "trainer/Z Policy Predictions Min     -530.751\n",
      "trainer/Z Expert Targets Mean        1562.01\n",
      "trainer/Z Expert Targets Std          120.652\n",
      "trainer/Z Expert Targets Max         1671.37\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1132.1\n",
      "trainer/Z Policy Targets Std          622.846\n",
      "trainer/Z Policy Targets Max         1657.44\n",
      "trainer/Z Policy Targets Min         -508.986\n",
      "trainer/Log Pis Mean                   20.3337\n",
      "trainer/Log Pis Std                     5.5594\n",
      "trainer/Policy mu Mean                  0.00934625\n",
      "trainer/Policy mu Std                   1.45758\n",
      "trainer/Policy log std Mean            -2.7956\n",
      "trainer/Policy log std Std              1.06528\n",
      "trainer/Alpha                           0.0783057\n",
      "trainer/Alpha Loss                     -0.0261304\n",
      "exploration/num steps total         62643\n",
      "exploration/num paths total           153\n",
      "evaluation/num steps total         392388\n",
      "evaluation/num paths total            600\n",
      "evaluation/path length Mean           835.6\n",
      "evaluation/path length Std            333.979\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             47\n",
      "evaluation/Rewards Mean                 4.55666\n",
      "evaluation/Rewards Std                  1.05249\n",
      "evaluation/Rewards Max                  6.65578\n",
      "evaluation/Rewards Min                 -1.93471\n",
      "evaluation/Returns Mean              3807.54\n",
      "evaluation/Returns Std               1569.19\n",
      "evaluation/Returns Max               4635.16\n",
      "evaluation/Returns Min                 90.1535\n",
      "evaluation/Estimation Bias Mean      1518.84\n",
      "evaluation/Estimation Bias Std        172.821\n",
      "evaluation/EB/Q_True Mean              50.9555\n",
      "evaluation/EB/Q_True Std              142.078\n",
      "evaluation/EB/Q_Pred Mean            1569.8\n",
      "evaluation/EB/Q_Pred Std               92.6436\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3807.54\n",
      "evaluation/Actions Mean                 0.0215661\n",
      "evaluation/Actions Std                  0.541426\n",
      "evaluation/Actions Max                  0.999628\n",
      "evaluation/Actions Min                 -0.99941\n",
      "time/backward_policy (s)                1.91263\n",
      "time/backward_zf1 (s)                   2.0285\n",
      "time/backward_zf2 (s)                   1.96238\n",
      "time/data sampling (s)                  0.289603\n",
      "time/data storing (s)                   0.0139681\n",
      "time/evaluation sampling (s)            1.87724\n",
      "time/exploration sampling (s)           0.314545\n",
      "time/logging (s)                        0.0105507\n",
      "time/preback_alpha (s)                  0.998174\n",
      "time/preback_policy (s)                 1.10981\n",
      "time/preback_start (s)                  0.145757\n",
      "time/preback_zf (s)                     5.21225\n",
      "time/saving (s)                         0.00612097\n",
      "time/training (s)                       2.28109\n",
      "time/epoch (s)                         18.1626\n",
      "time/total (s)                       1008.14\n",
      "Epoch                                  56\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:09:15.820381 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 57 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  68000\n",
      "trainer/ZF1 Loss                      520.223\n",
      "trainer/ZF2 Loss                      531.941\n",
      "trainer/ZF Expert Reward               14.7444\n",
      "trainer/ZF Policy Reward                5.84091\n",
      "trainer/ZF CHI2 Term                  554.299\n",
      "trainer/Policy Loss                 -1144.96\n",
      "trainer/Bias Loss                     271.979\n",
      "trainer/Bias Value                     13.7371\n",
      "trainer/Policy Grad Norm              104.608\n",
      "trainer/Policy Param Norm              29.1999\n",
      "trainer/Zf1 Grad Norm                4108.11\n",
      "trainer/Zf1 Param Norm                 78.2414\n",
      "trainer/Zf2 Grad Norm                6749.93\n",
      "trainer/Zf2 Param Norm                 79.2355\n",
      "trainer/Z Expert Predictions Mean    1583.4\n",
      "trainer/Z Expert Predictions Std       70.1062\n",
      "trainer/Z Expert Predictions Max     1673.84\n",
      "trainer/Z Expert Predictions Min     1221.93\n",
      "trainer/Z Policy Predictions Mean    1136.97\n",
      "trainer/Z Policy Predictions Std      637.171\n",
      "trainer/Z Policy Predictions Max     1666.19\n",
      "trainer/Z Policy Predictions Min     -515.783\n",
      "trainer/Z Expert Targets Mean        1568.65\n",
      "trainer/Z Expert Targets Std           68.1099\n",
      "trainer/Z Expert Targets Max         1668.67\n",
      "trainer/Z Expert Targets Min         1206.82\n",
      "trainer/Z Policy Targets Mean        1131.13\n",
      "trainer/Z Policy Targets Std          634.702\n",
      "trainer/Z Policy Targets Max         1674.27\n",
      "trainer/Z Policy Targets Min         -518.062\n",
      "trainer/Log Pis Mean                   19.5089\n",
      "trainer/Log Pis Std                     4.92952\n",
      "trainer/Policy mu Mean                  0.0675169\n",
      "trainer/Policy mu Std                   1.31475\n",
      "trainer/Policy log std Mean            -2.8477\n",
      "trainer/Policy log std Std              1.07372\n",
      "trainer/Alpha                           0.0788016\n",
      "trainer/Alpha Loss                      0.0386997\n",
      "exploration/num steps total         62643\n",
      "exploration/num paths total           153\n",
      "evaluation/num steps total         401616\n",
      "evaluation/num paths total            610\n",
      "evaluation/path length Mean           922.8\n",
      "evaluation/path length Std            231.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            228\n",
      "evaluation/Rewards Mean                 4.19698\n",
      "evaluation/Rewards Std                  1.64172\n",
      "evaluation/Rewards Max                  6.95031\n",
      "evaluation/Rewards Min                 -2.54945\n",
      "evaluation/Returns Mean              3872.97\n",
      "evaluation/Returns Std               1283.27\n",
      "evaluation/Returns Max               4641.84\n",
      "evaluation/Returns Min                694.664\n",
      "evaluation/Estimation Bias Mean      1466.83\n",
      "evaluation/Estimation Bias Std        213.032\n",
      "evaluation/EB/Q_True Mean              45.6015\n",
      "evaluation/EB/Q_True Std              134.579\n",
      "evaluation/EB/Q_Pred Mean            1512.43\n",
      "evaluation/EB/Q_Pred Std              166.72\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3872.97\n",
      "evaluation/Actions Mean                 0.00552316\n",
      "evaluation/Actions Std                  0.54632\n",
      "evaluation/Actions Max                  0.999823\n",
      "evaluation/Actions Min                 -0.999242\n",
      "time/backward_policy (s)                2.00607\n",
      "time/backward_zf1 (s)                   2.09221\n",
      "time/backward_zf2 (s)                   2.05085\n",
      "time/data sampling (s)                  0.297521\n",
      "time/data storing (s)                   0.0149294\n",
      "time/evaluation sampling (s)            1.76643\n",
      "time/exploration sampling (s)           0.325026\n",
      "time/logging (s)                        0.0116596\n",
      "time/preback_alpha (s)                  1.05502\n",
      "time/preback_policy (s)                 1.21295\n",
      "time/preback_start (s)                  0.146598\n",
      "time/preback_zf (s)                     5.23337\n",
      "time/saving (s)                         0.0058828\n",
      "time/training (s)                       2.14653\n",
      "time/epoch (s)                         18.365\n",
      "time/total (s)                       1026.52\n",
      "Epoch                                  57\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:09:34.496804 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 58 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  69000\n",
      "trainer/ZF1 Loss                       76.3969\n",
      "trainer/ZF2 Loss                       38.7647\n",
      "trainer/ZF Expert Reward               11.9241\n",
      "trainer/ZF Policy Reward                3.08952\n",
      "trainer/ZF CHI2 Term                   86.3989\n",
      "trainer/Policy Loss                 -1158.5\n",
      "trainer/Bias Loss                     230.568\n",
      "trainer/Bias Value                     13.7566\n",
      "trainer/Policy Grad Norm               95.2686\n",
      "trainer/Policy Param Norm              29.3035\n",
      "trainer/Zf1 Grad Norm               10230.6\n",
      "trainer/Zf1 Param Norm                 78.535\n",
      "trainer/Zf2 Grad Norm                2458.36\n",
      "trainer/Zf2 Param Norm                 79.5317\n",
      "trainer/Z Expert Predictions Mean    1576.28\n",
      "trainer/Z Expert Predictions Std       74.3606\n",
      "trainer/Z Expert Predictions Max     1680.03\n",
      "trainer/Z Expert Predictions Min     1131.89\n",
      "trainer/Z Policy Predictions Mean    1148.94\n",
      "trainer/Z Policy Predictions Std      623.887\n",
      "trainer/Z Policy Predictions Max     1671.9\n",
      "trainer/Z Policy Predictions Min     -517.207\n",
      "trainer/Z Expert Targets Mean        1564.35\n",
      "trainer/Z Expert Targets Std           74.7023\n",
      "trainer/Z Expert Targets Max         1660.98\n",
      "trainer/Z Expert Targets Min         1117.35\n",
      "trainer/Z Policy Targets Mean        1145.86\n",
      "trainer/Z Policy Targets Std          617.608\n",
      "trainer/Z Policy Targets Max         1660.7\n",
      "trainer/Z Policy Targets Min         -516.479\n",
      "trainer/Log Pis Mean                   20.1854\n",
      "trainer/Log Pis Std                     5.24241\n",
      "trainer/Policy mu Mean                  0.0314078\n",
      "trainer/Policy mu Std                   1.37874\n",
      "trainer/Policy log std Mean            -2.85546\n",
      "trainer/Policy log std Std              1.01284\n",
      "trainer/Alpha                           0.0778332\n",
      "trainer/Alpha Loss                     -0.0144267\n",
      "exploration/num steps total         63643\n",
      "exploration/num paths total           154\n",
      "evaluation/num steps total         411503\n",
      "evaluation/num paths total            620\n",
      "evaluation/path length Mean           988.7\n",
      "evaluation/path length Std             33.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            887\n",
      "evaluation/Rewards Mean                 4.63415\n",
      "evaluation/Rewards Std                  1.04146\n",
      "evaluation/Rewards Max                  6.8555\n",
      "evaluation/Rewards Min                 -1.7266\n",
      "evaluation/Returns Mean              4581.78\n",
      "evaluation/Returns Std                244.061\n",
      "evaluation/Returns Max               4740.82\n",
      "evaluation/Returns Min               3911.36\n",
      "evaluation/Estimation Bias Mean      1537.75\n",
      "evaluation/Estimation Bias Std        171.772\n",
      "evaluation/EB/Q_True Mean              43.9225\n",
      "evaluation/EB/Q_True Std              134.501\n",
      "evaluation/EB/Q_Pred Mean            1581.67\n",
      "evaluation/EB/Q_Pred Std               87.8717\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4581.78\n",
      "evaluation/Actions Mean                 0.0376493\n",
      "evaluation/Actions Std                  0.534821\n",
      "evaluation/Actions Max                  0.999848\n",
      "evaluation/Actions Min                 -0.99863\n",
      "time/backward_policy (s)                1.9531\n",
      "time/backward_zf1 (s)                   2.0888\n",
      "time/backward_zf2 (s)                   2.0126\n",
      "time/data sampling (s)                  0.319043\n",
      "time/data storing (s)                   0.0145213\n",
      "time/evaluation sampling (s)            1.95596\n",
      "time/exploration sampling (s)           0.325766\n",
      "time/logging (s)                        0.0130937\n",
      "time/preback_alpha (s)                  1.00441\n",
      "time/preback_policy (s)                 1.14763\n",
      "time/preback_start (s)                  0.150166\n",
      "time/preback_zf (s)                     5.27755\n",
      "time/saving (s)                         0.00644652\n",
      "time/training (s)                       2.33542\n",
      "time/epoch (s)                         18.6045\n",
      "time/total (s)                       1045.15\n",
      "Epoch                                  58\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:09:51.945597 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 59 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  70000\n",
      "trainer/ZF1 Loss                       63.2863\n",
      "trainer/ZF2 Loss                       50.5415\n",
      "trainer/ZF Expert Reward               20.7548\n",
      "trainer/ZF Policy Reward                8.97153\n",
      "trainer/ZF CHI2 Term                   88.5768\n",
      "trainer/Policy Loss                 -1096.44\n",
      "trainer/Bias Loss                     205.396\n",
      "trainer/Bias Value                     13.7763\n",
      "trainer/Policy Grad Norm              112.932\n",
      "trainer/Policy Param Norm              29.4064\n",
      "trainer/Zf1 Grad Norm                3217.22\n",
      "trainer/Zf1 Param Norm                 78.8689\n",
      "trainer/Zf2 Grad Norm                2537.08\n",
      "trainer/Zf2 Param Norm                 79.8453\n",
      "trainer/Z Expert Predictions Mean    1586.32\n",
      "trainer/Z Expert Predictions Std       73.2062\n",
      "trainer/Z Expert Predictions Max     1711.2\n",
      "trainer/Z Expert Predictions Min     1199.03\n",
      "trainer/Z Policy Predictions Mean    1086.73\n",
      "trainer/Z Policy Predictions Std      675.067\n",
      "trainer/Z Policy Predictions Max     1659.24\n",
      "trainer/Z Policy Predictions Min     -511.747\n",
      "trainer/Z Expert Targets Mean        1565.56\n",
      "trainer/Z Expert Targets Std           73.1645\n",
      "trainer/Z Expert Targets Max         1671.42\n",
      "trainer/Z Expert Targets Min         1192.15\n",
      "trainer/Z Policy Targets Mean        1077.76\n",
      "trainer/Z Policy Targets Std          663.764\n",
      "trainer/Z Policy Targets Max         1651.62\n",
      "trainer/Z Policy Targets Min         -500.103\n",
      "trainer/Log Pis Mean                   20.0805\n",
      "trainer/Log Pis Std                     5.80139\n",
      "trainer/Policy mu Mean                  0.197033\n",
      "trainer/Policy mu Std                   1.49346\n",
      "trainer/Policy log std Mean            -2.68883\n",
      "trainer/Policy log std Std              1.06279\n",
      "trainer/Alpha                           0.0772597\n",
      "trainer/Alpha Loss                     -0.00621606\n",
      "exploration/num steps total         65273\n",
      "exploration/num paths total           156\n",
      "evaluation/num steps total         420768\n",
      "evaluation/num paths total            630\n",
      "evaluation/path length Mean           926.5\n",
      "evaluation/path length Std            220.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            265\n",
      "evaluation/Rewards Mean                 4.45834\n",
      "evaluation/Rewards Std                  1.01222\n",
      "evaluation/Rewards Max                  6.56668\n",
      "evaluation/Rewards Min                 -1.68658\n",
      "evaluation/Returns Mean              4130.65\n",
      "evaluation/Returns Std               1049.54\n",
      "evaluation/Returns Max               4600.63\n",
      "evaluation/Returns Min                986.091\n",
      "evaluation/Estimation Bias Mean      1506.18\n",
      "evaluation/Estimation Bias Std        163.174\n",
      "evaluation/EB/Q_True Mean              45.6263\n",
      "evaluation/EB/Q_True Std              134.8\n",
      "evaluation/EB/Q_Pred Mean            1551.8\n",
      "evaluation/EB/Q_Pred Std               84.178\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4130.65\n",
      "evaluation/Actions Mean                 0.0135212\n",
      "evaluation/Actions Std                  0.536343\n",
      "evaluation/Actions Max                  0.999741\n",
      "evaluation/Actions Min                 -0.998926\n",
      "time/backward_policy (s)                1.74451\n",
      "time/backward_zf1 (s)                   1.85066\n",
      "time/backward_zf2 (s)                   1.78706\n",
      "time/data sampling (s)                  0.288284\n",
      "time/data storing (s)                   0.0141313\n",
      "time/evaluation sampling (s)            1.73833\n",
      "time/exploration sampling (s)           0.313469\n",
      "time/logging (s)                        0.0130662\n",
      "time/preback_alpha (s)                  0.881723\n",
      "time/preback_policy (s)                 0.963695\n",
      "time/preback_start (s)                  0.142088\n",
      "time/preback_zf (s)                     5.14381\n",
      "time/saving (s)                         0.00638474\n",
      "time/training (s)                       2.48973\n",
      "time/epoch (s)                         17.3769\n",
      "time/total (s)                       1062.55\n",
      "Epoch                                  59\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:10:10.303550 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 60 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  71000\n",
      "trainer/ZF1 Loss                       38.9706\n",
      "trainer/ZF2 Loss                       51.5357\n",
      "trainer/ZF Expert Reward               10.0785\n",
      "trainer/ZF Policy Reward                0.965225\n",
      "trainer/ZF CHI2 Term                   73.9353\n",
      "trainer/Policy Loss                 -1204.09\n",
      "trainer/Bias Loss                     179.789\n",
      "trainer/Bias Value                     13.7981\n",
      "trainer/Policy Grad Norm               95.6953\n",
      "trainer/Policy Param Norm              29.5058\n",
      "trainer/Zf1 Grad Norm                2351.1\n",
      "trainer/Zf1 Param Norm                 79.1728\n",
      "trainer/Zf2 Grad Norm                2030.86\n",
      "trainer/Zf2 Param Norm                 80.1793\n",
      "trainer/Z Expert Predictions Mean    1579.32\n",
      "trainer/Z Expert Predictions Std       63.6073\n",
      "trainer/Z Expert Predictions Max     1652.36\n",
      "trainer/Z Expert Predictions Min     1292.99\n",
      "trainer/Z Policy Predictions Mean    1196.53\n",
      "trainer/Z Policy Predictions Std      554.513\n",
      "trainer/Z Policy Predictions Max     1644.86\n",
      "trainer/Z Policy Predictions Min     -481.756\n",
      "trainer/Z Expert Targets Mean        1569.25\n",
      "trainer/Z Expert Targets Std           68.1499\n",
      "trainer/Z Expert Targets Max         1651.5\n",
      "trainer/Z Expert Targets Min         1280.55\n",
      "trainer/Z Policy Targets Mean        1195.56\n",
      "trainer/Z Policy Targets Std          548.502\n",
      "trainer/Z Policy Targets Max         1670.16\n",
      "trainer/Z Policy Targets Min         -484.41\n",
      "trainer/Log Pis Mean                   19.7666\n",
      "trainer/Log Pis Std                     4.98715\n",
      "trainer/Policy mu Mean                  0.128197\n",
      "trainer/Policy mu Std                   1.32773\n",
      "trainer/Policy log std Mean            -2.84136\n",
      "trainer/Policy log std Std              1.03112\n",
      "trainer/Alpha                           0.0782035\n",
      "trainer/Alpha Loss                      0.0182542\n",
      "exploration/num steps total         67321\n",
      "exploration/num paths total           159\n",
      "evaluation/num steps total         429771\n",
      "evaluation/num paths total            641\n",
      "evaluation/path length Mean           818.455\n",
      "evaluation/path length Std            315.588\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             57\n",
      "evaluation/Rewards Mean                 4.52697\n",
      "evaluation/Rewards Std                  1.2618\n",
      "evaluation/Rewards Max                  6.86625\n",
      "evaluation/Rewards Min                 -2.35178\n",
      "evaluation/Returns Mean              3705.12\n",
      "evaluation/Returns Std               1505.86\n",
      "evaluation/Returns Max               4775.47\n",
      "evaluation/Returns Min                 45.3671\n",
      "evaluation/Estimation Bias Mean      1502.57\n",
      "evaluation/Estimation Bias Std        192.831\n",
      "evaluation/EB/Q_True Mean              48.5852\n",
      "evaluation/EB/Q_True Std              141.349\n",
      "evaluation/EB/Q_Pred Mean            1551.15\n",
      "evaluation/EB/Q_Pred Std              124.204\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3705.12\n",
      "evaluation/Actions Mean                 0.0189091\n",
      "evaluation/Actions Std                  0.550689\n",
      "evaluation/Actions Max                  0.999749\n",
      "evaluation/Actions Min                 -0.999515\n",
      "time/backward_policy (s)                1.95412\n",
      "time/backward_zf1 (s)                   2.08102\n",
      "time/backward_zf2 (s)                   2.03476\n",
      "time/data sampling (s)                  0.299087\n",
      "time/data storing (s)                   0.0144672\n",
      "time/evaluation sampling (s)            1.79641\n",
      "time/exploration sampling (s)           0.327724\n",
      "time/logging (s)                        0.0113629\n",
      "time/preback_alpha (s)                  1.01736\n",
      "time/preback_policy (s)                 1.18117\n",
      "time/preback_start (s)                  0.146334\n",
      "time/preback_zf (s)                     5.21967\n",
      "time/saving (s)                         0.00835478\n",
      "time/training (s)                       2.1964\n",
      "time/epoch (s)                         18.2882\n",
      "time/total (s)                       1080.86\n",
      "Epoch                                  60\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:10:28.627983 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 61 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  72000\n",
      "trainer/ZF1 Loss                       16.3664\n",
      "trainer/ZF2 Loss                       19.2964\n",
      "trainer/ZF Expert Reward               15.2901\n",
      "trainer/ZF Policy Reward               -0.554854\n",
      "trainer/ZF CHI2 Term                   53.6269\n",
      "trainer/Policy Loss                 -1117.62\n",
      "trainer/Bias Loss                     122.978\n",
      "trainer/Bias Value                     13.8142\n",
      "trainer/Policy Grad Norm               80.2415\n",
      "trainer/Policy Param Norm              29.6009\n",
      "trainer/Zf1 Grad Norm                2558.59\n",
      "trainer/Zf1 Param Norm                 79.4649\n",
      "trainer/Zf2 Grad Norm                2502.41\n",
      "trainer/Zf2 Param Norm                 80.4499\n",
      "trainer/Z Expert Predictions Mean    1572.37\n",
      "trainer/Z Expert Predictions Std      127.073\n",
      "trainer/Z Expert Predictions Max     1675.13\n",
      "trainer/Z Expert Predictions Min      -32.6058\n",
      "trainer/Z Policy Predictions Mean    1103.87\n",
      "trainer/Z Policy Predictions Std      630.242\n",
      "trainer/Z Policy Predictions Max     1672.54\n",
      "trainer/Z Policy Predictions Min     -448.473\n",
      "trainer/Z Expert Targets Mean        1557.08\n",
      "trainer/Z Expert Targets Std          124.288\n",
      "trainer/Z Expert Targets Max         1658.43\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1104.43\n",
      "trainer/Z Policy Targets Std          623.675\n",
      "trainer/Z Policy Targets Max         1657.52\n",
      "trainer/Z Policy Targets Min         -467.669\n",
      "trainer/Log Pis Mean                   20.1521\n",
      "trainer/Log Pis Std                     5.88165\n",
      "trainer/Policy mu Mean                  0.162604\n",
      "trainer/Policy mu Std                   1.49841\n",
      "trainer/Policy log std Mean            -2.6986\n",
      "trainer/Policy log std Std              1.08231\n",
      "trainer/Alpha                           0.0785207\n",
      "trainer/Alpha Loss                     -0.0119386\n",
      "exploration/num steps total         67321\n",
      "exploration/num paths total           159\n",
      "evaluation/num steps total         439771\n",
      "evaluation/num paths total            651\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.56858\n",
      "evaluation/Rewards Std                  2.45515\n",
      "evaluation/Rewards Max                  6.60065\n",
      "evaluation/Rewards Min                 -2.31556\n",
      "evaluation/Returns Mean              3568.58\n",
      "evaluation/Returns Std               2033.82\n",
      "evaluation/Returns Max               4747.08\n",
      "evaluation/Returns Min              -1566.25\n",
      "evaluation/Estimation Bias Mean      1408.64\n",
      "evaluation/Estimation Bias Std        278.147\n",
      "evaluation/EB/Q_True Mean              42.1221\n",
      "evaluation/EB/Q_True Std              129.998\n",
      "evaluation/EB/Q_Pred Mean            1450.76\n",
      "evaluation/EB/Q_Pred Std              262.475\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3568.58\n",
      "evaluation/Actions Mean                 0.0360262\n",
      "evaluation/Actions Std                  0.591297\n",
      "evaluation/Actions Max                  0.999965\n",
      "evaluation/Actions Min                 -0.99884\n",
      "time/backward_policy (s)                1.96323\n",
      "time/backward_zf1 (s)                   2.09062\n",
      "time/backward_zf2 (s)                   2.03745\n",
      "time/data sampling (s)                  0.297901\n",
      "time/data storing (s)                   0.0142608\n",
      "time/evaluation sampling (s)            1.80614\n",
      "time/exploration sampling (s)           0.316745\n",
      "time/logging (s)                        0.0139937\n",
      "time/preback_alpha (s)                  1.04484\n",
      "time/preback_policy (s)                 1.20638\n",
      "time/preback_start (s)                  0.144758\n",
      "time/preback_zf (s)                     5.23217\n",
      "time/saving (s)                         0.00720422\n",
      "time/training (s)                       2.0805\n",
      "time/epoch (s)                         18.2562\n",
      "time/total (s)                       1099.14\n",
      "Epoch                                  61\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:10:46.323536 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 62 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  73000\n",
      "trainer/ZF1 Loss                       38.1627\n",
      "trainer/ZF2 Loss                       43.1743\n",
      "trainer/ZF Expert Reward               13.1459\n",
      "trainer/ZF Policy Reward               -1.25642\n",
      "trainer/ZF CHI2 Term                   75.201\n",
      "trainer/Policy Loss                 -1172.5\n",
      "trainer/Bias Loss                     184.213\n",
      "trainer/Bias Value                     13.8291\n",
      "trainer/Policy Grad Norm              137.457\n",
      "trainer/Policy Param Norm              29.6853\n",
      "trainer/Zf1 Grad Norm                2821.51\n",
      "trainer/Zf1 Param Norm                 79.744\n",
      "trainer/Zf2 Grad Norm                2879.7\n",
      "trainer/Zf2 Param Norm                 80.7398\n",
      "trainer/Z Expert Predictions Mean    1571.82\n",
      "trainer/Z Expert Predictions Std      126.958\n",
      "trainer/Z Expert Predictions Max     1667.77\n",
      "trainer/Z Expert Predictions Min        8.4187\n",
      "trainer/Z Policy Predictions Mean    1164.64\n",
      "trainer/Z Policy Predictions Std      620.393\n",
      "trainer/Z Policy Predictions Max     1663.02\n",
      "trainer/Z Policy Predictions Min     -458.933\n",
      "trainer/Z Expert Targets Mean        1558.68\n",
      "trainer/Z Expert Targets Std          129.173\n",
      "trainer/Z Expert Targets Max         1661.11\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1165.89\n",
      "trainer/Z Policy Targets Std          614.261\n",
      "trainer/Z Policy Targets Max         1645.89\n",
      "trainer/Z Policy Targets Min         -432.708\n",
      "trainer/Log Pis Mean                   20.3336\n",
      "trainer/Log Pis Std                     5.32518\n",
      "trainer/Policy mu Mean                  0.163825\n",
      "trainer/Policy mu Std                   1.40406\n",
      "trainer/Policy log std Mean            -2.8574\n",
      "trainer/Policy log std Std              1.05315\n",
      "trainer/Alpha                           0.0806457\n",
      "trainer/Alpha Loss                     -0.0269028\n",
      "exploration/num steps total         68321\n",
      "exploration/num paths total           160\n",
      "evaluation/num steps total         448811\n",
      "evaluation/num paths total            661\n",
      "evaluation/path length Mean           904\n",
      "evaluation/path length Std            288\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             40\n",
      "evaluation/Rewards Mean                 4.32671\n",
      "evaluation/Rewards Std                  1.24643\n",
      "evaluation/Rewards Max                  6.68767\n",
      "evaluation/Rewards Min                 -3.04581\n",
      "evaluation/Returns Mean              3911.35\n",
      "evaluation/Returns Std               1289.7\n",
      "evaluation/Returns Max               4477.13\n",
      "evaluation/Returns Min                 54.0108\n",
      "evaluation/Estimation Bias Mean      1499.46\n",
      "evaluation/Estimation Bias Std        173.521\n",
      "evaluation/EB/Q_True Mean              42.5825\n",
      "evaluation/EB/Q_True Std              124.052\n",
      "evaluation/EB/Q_Pred Mean            1542.04\n",
      "evaluation/EB/Q_Pred Std              122.31\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3911.35\n",
      "evaluation/Actions Mean                 0.02775\n",
      "evaluation/Actions Std                  0.556553\n",
      "evaluation/Actions Max                  0.999601\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                1.8205\n",
      "time/backward_zf1 (s)                   1.96121\n",
      "time/backward_zf2 (s)                   1.87328\n",
      "time/data sampling (s)                  0.295371\n",
      "time/data storing (s)                   0.0142527\n",
      "time/evaluation sampling (s)            1.75476\n",
      "time/exploration sampling (s)           0.319495\n",
      "time/logging (s)                        0.0110872\n",
      "time/preback_alpha (s)                  0.962487\n",
      "time/preback_policy (s)                 1.06824\n",
      "time/preback_start (s)                  0.143996\n",
      "time/preback_zf (s)                     5.14688\n",
      "time/saving (s)                         0.00604004\n",
      "time/training (s)                       2.24579\n",
      "time/epoch (s)                         17.6234\n",
      "time/total (s)                       1116.78\n",
      "Epoch                                  62\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:11:04.431501 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 63 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  74000\n",
      "trainer/ZF1 Loss                       37.4842\n",
      "trainer/ZF2 Loss                       35.3527\n",
      "trainer/ZF Expert Reward               14.4142\n",
      "trainer/ZF Policy Reward                1.71532\n",
      "trainer/ZF CHI2 Term                   69.4113\n",
      "trainer/Policy Loss                 -1198.51\n",
      "trainer/Bias Loss                     123.464\n",
      "trainer/Bias Value                     13.8432\n",
      "trainer/Policy Grad Norm              101.449\n",
      "trainer/Policy Param Norm              29.7708\n",
      "trainer/Zf1 Grad Norm                2325.65\n",
      "trainer/Zf1 Param Norm                 80.0531\n",
      "trainer/Zf2 Grad Norm                2156.74\n",
      "trainer/Zf2 Param Norm                 81.054\n",
      "trainer/Z Expert Predictions Mean    1570.49\n",
      "trainer/Z Expert Predictions Std       77.1477\n",
      "trainer/Z Expert Predictions Max     1681.71\n",
      "trainer/Z Expert Predictions Min     1239.11\n",
      "trainer/Z Policy Predictions Mean    1190.31\n",
      "trainer/Z Policy Predictions Std      578.155\n",
      "trainer/Z Policy Predictions Max     1665.6\n",
      "trainer/Z Policy Predictions Min     -462.025\n",
      "trainer/Z Expert Targets Mean        1556.07\n",
      "trainer/Z Expert Targets Std           80.1252\n",
      "trainer/Z Expert Targets Max         1661.54\n",
      "trainer/Z Expert Targets Min         1164.25\n",
      "trainer/Z Policy Targets Mean        1188.59\n",
      "trainer/Z Policy Targets Std          570.939\n",
      "trainer/Z Policy Targets Max         1649.08\n",
      "trainer/Z Policy Targets Min         -444.071\n",
      "trainer/Log Pis Mean                   20.4989\n",
      "trainer/Log Pis Std                     5.23938\n",
      "trainer/Policy mu Mean                  0.0880326\n",
      "trainer/Policy mu Std                   1.35919\n",
      "trainer/Policy log std Mean            -2.90572\n",
      "trainer/Policy log std Std              0.9899\n",
      "trainer/Alpha                           0.0806418\n",
      "trainer/Alpha Loss                     -0.0402301\n",
      "exploration/num steps total         68321\n",
      "exploration/num paths total           160\n",
      "evaluation/num steps total         455883\n",
      "evaluation/num paths total            671\n",
      "evaluation/path length Mean           707.2\n",
      "evaluation/path length Std            365.146\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             53\n",
      "evaluation/Rewards Mean                 4.45998\n",
      "evaluation/Rewards Std                  1.25423\n",
      "evaluation/Rewards Max                  6.60127\n",
      "evaluation/Rewards Min                 -1.94637\n",
      "evaluation/Returns Mean              3154.1\n",
      "evaluation/Returns Std               1686.69\n",
      "evaluation/Returns Max               4806.08\n",
      "evaluation/Returns Min                150.011\n",
      "evaluation/Estimation Bias Mean      1474.2\n",
      "evaluation/Estimation Bias Std        196.817\n",
      "evaluation/EB/Q_True Mean              58.9246\n",
      "evaluation/EB/Q_True Std              149.59\n",
      "evaluation/EB/Q_Pred Mean            1533.13\n",
      "evaluation/EB/Q_Pred Std              126.943\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3154.1\n",
      "evaluation/Actions Mean                 0.029317\n",
      "evaluation/Actions Std                  0.55016\n",
      "evaluation/Actions Max                  0.999845\n",
      "evaluation/Actions Min                 -0.999584\n",
      "time/backward_policy (s)                1.92155\n",
      "time/backward_zf1 (s)                   2.0591\n",
      "time/backward_zf2 (s)                   1.99584\n",
      "time/data sampling (s)                  0.297737\n",
      "time/data storing (s)                   0.0148206\n",
      "time/evaluation sampling (s)            1.73673\n",
      "time/exploration sampling (s)           0.324384\n",
      "time/logging (s)                        0.00959334\n",
      "time/preback_alpha (s)                  1.03418\n",
      "time/preback_policy (s)                 1.17354\n",
      "time/preback_start (s)                  0.146367\n",
      "time/preback_zf (s)                     5.19974\n",
      "time/saving (s)                         0.00608026\n",
      "time/training (s)                       2.11723\n",
      "time/epoch (s)                         18.0369\n",
      "time/total (s)                       1134.84\n",
      "Epoch                                  63\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:11:22.527685 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 64 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  75000\n",
      "trainer/ZF1 Loss                       48.402\n",
      "trainer/ZF2 Loss                       34.2409\n",
      "trainer/ZF Expert Reward               11.4581\n",
      "trainer/ZF Policy Reward                1.05771\n",
      "trainer/ZF CHI2 Term                   72.172\n",
      "trainer/Policy Loss                 -1160.67\n",
      "trainer/Bias Loss                     140.979\n",
      "trainer/Bias Value                     13.8569\n",
      "trainer/Policy Grad Norm              136.825\n",
      "trainer/Policy Param Norm              29.8572\n",
      "trainer/Zf1 Grad Norm                6940.81\n",
      "trainer/Zf1 Param Norm                 80.361\n",
      "trainer/Zf2 Grad Norm                4332.95\n",
      "trainer/Zf2 Param Norm                 81.3699\n",
      "trainer/Z Expert Predictions Mean    1566\n",
      "trainer/Z Expert Predictions Std       75.225\n",
      "trainer/Z Expert Predictions Max     1656.83\n",
      "trainer/Z Expert Predictions Min     1218.66\n",
      "trainer/Z Policy Predictions Mean    1153.54\n",
      "trainer/Z Policy Predictions Std      663.728\n",
      "trainer/Z Policy Predictions Max     1662.95\n",
      "trainer/Z Policy Predictions Min     -467.208\n",
      "trainer/Z Expert Targets Mean        1554.55\n",
      "trainer/Z Expert Targets Std           74.5328\n",
      "trainer/Z Expert Targets Max         1666.12\n",
      "trainer/Z Expert Targets Min         1196.98\n",
      "trainer/Z Policy Targets Mean        1152.48\n",
      "trainer/Z Policy Targets Std          658.973\n",
      "trainer/Z Policy Targets Max         1658.23\n",
      "trainer/Z Policy Targets Min         -472.306\n",
      "trainer/Log Pis Mean                   20.6568\n",
      "trainer/Log Pis Std                     4.95183\n",
      "trainer/Policy mu Mean                  0.112404\n",
      "trainer/Policy mu Std                   1.41427\n",
      "trainer/Policy log std Mean            -2.86205\n",
      "trainer/Policy log std Std              1.10465\n",
      "trainer/Alpha                           0.0806596\n",
      "trainer/Alpha Loss                     -0.0529761\n",
      "exploration/num steps total         70352\n",
      "exploration/num paths total           163\n",
      "evaluation/num steps total         464160\n",
      "evaluation/num paths total            683\n",
      "evaluation/path length Mean           689.75\n",
      "evaluation/path length Std            355.23\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             62\n",
      "evaluation/Rewards Mean                 3.39585\n",
      "evaluation/Rewards Std                  2.62935\n",
      "evaluation/Rewards Max                  6.85069\n",
      "evaluation/Rewards Min                 -2.81575\n",
      "evaluation/Returns Mean              2342.29\n",
      "evaluation/Returns Std               2176.6\n",
      "evaluation/Returns Max               4534.97\n",
      "evaluation/Returns Min              -2612.74\n",
      "evaluation/Estimation Bias Mean      1361.45\n",
      "evaluation/Estimation Bias Std        297.554\n",
      "evaluation/EB/Q_True Mean              48.286\n",
      "evaluation/EB/Q_True Std              134.924\n",
      "evaluation/EB/Q_Pred Mean            1409.74\n",
      "evaluation/EB/Q_Pred Std              277.121\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2342.29\n",
      "evaluation/Actions Mean                 0.019449\n",
      "evaluation/Actions Std                  0.612308\n",
      "evaluation/Actions Max                  0.999982\n",
      "evaluation/Actions Min                 -0.999979\n",
      "time/backward_policy (s)                1.9128\n",
      "time/backward_zf1 (s)                   2.04351\n",
      "time/backward_zf2 (s)                   1.95527\n",
      "time/data sampling (s)                  0.278249\n",
      "time/data storing (s)                   0.0146805\n",
      "time/evaluation sampling (s)            1.92494\n",
      "time/exploration sampling (s)           0.322493\n",
      "time/logging (s)                        0.010592\n",
      "time/preback_alpha (s)                  1.00584\n",
      "time/preback_policy (s)                 1.13757\n",
      "time/preback_start (s)                  0.143956\n",
      "time/preback_zf (s)                     5.17635\n",
      "time/saving (s)                         0.0063693\n",
      "time/training (s)                       2.09704\n",
      "time/epoch (s)                         18.0296\n",
      "time/total (s)                       1152.89\n",
      "Epoch                                  64\n",
      "---------------------------------  --------------\n",
      "2024-06-15 11:11:40.663228 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 65 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  76000\n",
      "trainer/ZF1 Loss                       55.3427\n",
      "trainer/ZF2 Loss                       46.7751\n",
      "trainer/ZF Expert Reward               19.7119\n",
      "trainer/ZF Policy Reward                5.34348\n",
      "trainer/ZF CHI2 Term                   84.6944\n",
      "trainer/Policy Loss                 -1201.34\n",
      "trainer/Bias Loss                     152.361\n",
      "trainer/Bias Value                     13.871\n",
      "trainer/Policy Grad Norm              127.694\n",
      "trainer/Policy Param Norm              29.9396\n",
      "trainer/Zf1 Grad Norm                4148.31\n",
      "trainer/Zf1 Param Norm                 80.6459\n",
      "trainer/Zf2 Grad Norm                4080.81\n",
      "trainer/Zf2 Param Norm                 81.6664\n",
      "trainer/Z Expert Predictions Mean    1573.84\n",
      "trainer/Z Expert Predictions Std       76.7135\n",
      "trainer/Z Expert Predictions Max     1673.24\n",
      "trainer/Z Expert Predictions Min     1208.49\n",
      "trainer/Z Policy Predictions Mean    1195.98\n",
      "trainer/Z Policy Predictions Std      585.327\n",
      "trainer/Z Policy Predictions Max     1658.26\n",
      "trainer/Z Policy Predictions Min     -443.721\n",
      "trainer/Z Expert Targets Mean        1554.12\n",
      "trainer/Z Expert Targets Std           77.6799\n",
      "trainer/Z Expert Targets Max         1656.85\n",
      "trainer/Z Expert Targets Min         1190.8\n",
      "trainer/Z Policy Targets Mean        1190.63\n",
      "trainer/Z Policy Targets Std          575.749\n",
      "trainer/Z Policy Targets Max         1644.75\n",
      "trainer/Z Policy Targets Min         -424.781\n",
      "trainer/Log Pis Mean                   19.4617\n",
      "trainer/Log Pis Std                     5.00868\n",
      "trainer/Policy mu Mean                  0.0450343\n",
      "trainer/Policy mu Std                   1.28518\n",
      "trainer/Policy log std Mean            -2.90057\n",
      "trainer/Policy log std Std              0.978288\n",
      "trainer/Alpha                           0.0800661\n",
      "trainer/Alpha Loss                      0.0431025\n",
      "exploration/num steps total         71352\n",
      "exploration/num paths total           164\n",
      "evaluation/num steps total         473033\n",
      "evaluation/num paths total            693\n",
      "evaluation/path length Mean           887.3\n",
      "evaluation/path length Std            234.854\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            289\n",
      "evaluation/Rewards Mean                 3.98019\n",
      "evaluation/Rewards Std                  2.16793\n",
      "evaluation/Rewards Max                  6.73628\n",
      "evaluation/Rewards Min                 -2.23654\n",
      "evaluation/Returns Mean              3531.62\n",
      "evaluation/Returns Std               1815.39\n",
      "evaluation/Returns Max               4705.27\n",
      "evaluation/Returns Min               -802.735\n",
      "evaluation/Estimation Bias Mean      1429.9\n",
      "evaluation/Estimation Bias Std        253.253\n",
      "evaluation/EB/Q_True Mean              47.2083\n",
      "evaluation/EB/Q_True Std              137.771\n",
      "evaluation/EB/Q_Pred Mean            1477.11\n",
      "evaluation/EB/Q_Pred Std              221.639\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3531.62\n",
      "evaluation/Actions Mean                 0.0219366\n",
      "evaluation/Actions Std                  0.570802\n",
      "evaluation/Actions Max                  0.99867\n",
      "evaluation/Actions Min                 -0.999401\n",
      "time/backward_policy (s)                1.95645\n",
      "time/backward_zf1 (s)                   2.08825\n",
      "time/backward_zf2 (s)                   2.03794\n",
      "time/data sampling (s)                  0.282412\n",
      "time/data storing (s)                   0.0144371\n",
      "time/evaluation sampling (s)            1.75395\n",
      "time/exploration sampling (s)           0.322654\n",
      "time/logging (s)                        0.0116811\n",
      "time/preback_alpha (s)                  1.05767\n",
      "time/preback_policy (s)                 1.21321\n",
      "time/preback_start (s)                  0.143798\n",
      "time/preback_zf (s)                     5.17465\n",
      "time/saving (s)                         0.00618213\n",
      "time/training (s)                       2.0064\n",
      "time/epoch (s)                         18.0697\n",
      "time/total (s)                       1170.98\n",
      "Epoch                                  65\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:11:58.608461 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 66 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  77000\n",
      "trainer/ZF1 Loss                       22.1746\n",
      "trainer/ZF2 Loss                       22.1141\n",
      "trainer/ZF Expert Reward               13.5301\n",
      "trainer/ZF Policy Reward                0.969001\n",
      "trainer/ZF CHI2 Term                   54.0559\n",
      "trainer/Policy Loss                 -1220.15\n",
      "trainer/Bias Loss                     117.531\n",
      "trainer/Bias Value                     13.8822\n",
      "trainer/Policy Grad Norm              103.112\n",
      "trainer/Policy Param Norm              30.0144\n",
      "trainer/Zf1 Grad Norm                2337.48\n",
      "trainer/Zf1 Param Norm                 80.9258\n",
      "trainer/Zf2 Grad Norm                2071.81\n",
      "trainer/Zf2 Param Norm                 81.9699\n",
      "trainer/Z Expert Predictions Mean    1551.23\n",
      "trainer/Z Expert Predictions Std       86.6517\n",
      "trainer/Z Expert Predictions Max     1676.28\n",
      "trainer/Z Expert Predictions Min      974.614\n",
      "trainer/Z Policy Predictions Mean    1216.42\n",
      "trainer/Z Policy Predictions Std      564.4\n",
      "trainer/Z Policy Predictions Max     1641.63\n",
      "trainer/Z Policy Predictions Min     -436.033\n",
      "trainer/Z Expert Targets Mean        1537.7\n",
      "trainer/Z Expert Targets Std           88.4182\n",
      "trainer/Z Expert Targets Max         1649.79\n",
      "trainer/Z Expert Targets Min          951.559\n",
      "trainer/Z Policy Targets Mean        1215.45\n",
      "trainer/Z Policy Targets Std          557.684\n",
      "trainer/Z Policy Targets Max         1634.87\n",
      "trainer/Z Policy Targets Min         -432.282\n",
      "trainer/Log Pis Mean                   19.546\n",
      "trainer/Log Pis Std                     4.57985\n",
      "trainer/Policy mu Mean                  0.0501445\n",
      "trainer/Policy mu Std                   1.27418\n",
      "trainer/Policy log std Mean            -2.91924\n",
      "trainer/Policy log std Std              0.995978\n",
      "trainer/Alpha                           0.0803522\n",
      "trainer/Alpha Loss                      0.0364846\n",
      "exploration/num steps total         72352\n",
      "exploration/num paths total           165\n",
      "evaluation/num steps total         483033\n",
      "evaluation/num paths total            703\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.73425\n",
      "evaluation/Rewards Std                  1.05878\n",
      "evaluation/Rewards Max                  6.9028\n",
      "evaluation/Rewards Min                 -1.86123\n",
      "evaluation/Returns Mean              4734.25\n",
      "evaluation/Returns Std                 88.8128\n",
      "evaluation/Returns Max               4856.59\n",
      "evaluation/Returns Min               4555.27\n",
      "evaluation/Estimation Bias Mean      1512.35\n",
      "evaluation/Estimation Bias Std        158.214\n",
      "evaluation/EB/Q_True Mean              44.803\n",
      "evaluation/EB/Q_True Std              138.49\n",
      "evaluation/EB/Q_Pred Mean            1557.15\n",
      "evaluation/EB/Q_Pred Std               79.3962\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4734.25\n",
      "evaluation/Actions Mean                 0.0249023\n",
      "evaluation/Actions Std                  0.531405\n",
      "evaluation/Actions Max                  0.998944\n",
      "evaluation/Actions Min                 -0.998674\n",
      "time/backward_policy (s)                1.85282\n",
      "time/backward_zf1 (s)                   2.00013\n",
      "time/backward_zf2 (s)                   1.91593\n",
      "time/data sampling (s)                  0.307483\n",
      "time/data storing (s)                   0.0147012\n",
      "time/evaluation sampling (s)            1.77408\n",
      "time/exploration sampling (s)           0.322855\n",
      "time/logging (s)                        0.0123805\n",
      "time/preback_alpha (s)                  0.986736\n",
      "time/preback_policy (s)                 1.09962\n",
      "time/preback_start (s)                  0.147934\n",
      "time/preback_zf (s)                     5.18863\n",
      "time/saving (s)                         0.00642391\n",
      "time/training (s)                       2.24583\n",
      "time/epoch (s)                         17.8755\n",
      "time/total (s)                       1188.88\n",
      "Epoch                                  66\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:12:16.457152 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 67 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  78000\n",
      "trainer/ZF1 Loss                       41.4433\n",
      "trainer/ZF2 Loss                       39.5238\n",
      "trainer/ZF Expert Reward               12.2322\n",
      "trainer/ZF Policy Reward               -1.50267\n",
      "trainer/ZF CHI2 Term                   74.0806\n",
      "trainer/Policy Loss                 -1149.75\n",
      "trainer/Bias Loss                     137.887\n",
      "trainer/Bias Value                     13.8935\n",
      "trainer/Policy Grad Norm              149.147\n",
      "trainer/Policy Param Norm              30.0914\n",
      "trainer/Zf1 Grad Norm                2763.87\n",
      "trainer/Zf1 Param Norm                 81.2022\n",
      "trainer/Zf2 Grad Norm                5687.2\n",
      "trainer/Zf2 Param Norm                 82.2465\n",
      "trainer/Z Expert Predictions Mean    1559.62\n",
      "trainer/Z Expert Predictions Std       81.1341\n",
      "trainer/Z Expert Predictions Max     1656.21\n",
      "trainer/Z Expert Predictions Min     1161.79\n",
      "trainer/Z Policy Predictions Mean    1146.29\n",
      "trainer/Z Policy Predictions Std      610.201\n",
      "trainer/Z Policy Predictions Max     1659.02\n",
      "trainer/Z Policy Predictions Min     -424.704\n",
      "trainer/Z Expert Targets Mean        1547.39\n",
      "trainer/Z Expert Targets Std           81.6666\n",
      "trainer/Z Expert Targets Max         1662.33\n",
      "trainer/Z Expert Targets Min         1155.36\n",
      "trainer/Z Policy Targets Mean        1147.79\n",
      "trainer/Z Policy Targets Std          605.55\n",
      "trainer/Z Policy Targets Max         1639.1\n",
      "trainer/Z Policy Targets Min         -412.432\n",
      "trainer/Log Pis Mean                   20.0628\n",
      "trainer/Log Pis Std                     5.2424\n",
      "trainer/Policy mu Mean                  0.0445176\n",
      "trainer/Policy mu Std                   1.38732\n",
      "trainer/Policy log std Mean            -2.83347\n",
      "trainer/Policy log std Std              1.0482\n",
      "trainer/Alpha                           0.0796936\n",
      "trainer/Alpha Loss                     -0.00500629\n",
      "exploration/num steps total         72352\n",
      "exploration/num paths total           165\n",
      "evaluation/num steps total         493033\n",
      "evaluation/num paths total            713\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.54067\n",
      "evaluation/Rewards Std                  0.994204\n",
      "evaluation/Rewards Max                  6.55764\n",
      "evaluation/Rewards Min                 -2.38117\n",
      "evaluation/Returns Mean              4540.67\n",
      "evaluation/Returns Std                 87.8547\n",
      "evaluation/Returns Max               4666.53\n",
      "evaluation/Returns Min               4399.39\n",
      "evaluation/Estimation Bias Mean      1523.51\n",
      "evaluation/Estimation Bias Std        149.775\n",
      "evaluation/EB/Q_True Mean              42.2465\n",
      "evaluation/EB/Q_True Std              130.413\n",
      "evaluation/EB/Q_Pred Mean            1565.76\n",
      "evaluation/EB/Q_Pred Std               80.6792\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4540.67\n",
      "evaluation/Actions Mean                 0.00581628\n",
      "evaluation/Actions Std                  0.538017\n",
      "evaluation/Actions Max                  0.998177\n",
      "evaluation/Actions Min                 -0.999511\n",
      "time/backward_policy (s)                1.90506\n",
      "time/backward_zf1 (s)                   2.00301\n",
      "time/backward_zf2 (s)                   1.96199\n",
      "time/data sampling (s)                  0.283713\n",
      "time/data storing (s)                   0.0140266\n",
      "time/evaluation sampling (s)            1.81419\n",
      "time/exploration sampling (s)           0.308984\n",
      "time/logging (s)                        0.0122046\n",
      "time/preback_alpha (s)                  1.01517\n",
      "time/preback_policy (s)                 1.15271\n",
      "time/preback_start (s)                  0.139992\n",
      "time/preback_zf (s)                     5.12924\n",
      "time/saving (s)                         0.00587135\n",
      "time/training (s)                       2.03432\n",
      "time/epoch (s)                         17.7805\n",
      "time/total (s)                       1206.68\n",
      "Epoch                                  67\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:12:34.422502 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 68 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  79000\n",
      "trainer/ZF1 Loss                       20.1784\n",
      "trainer/ZF2 Loss                       21.8633\n",
      "trainer/ZF Expert Reward               17.7844\n",
      "trainer/ZF Policy Reward                4.22324\n",
      "trainer/ZF CHI2 Term                   54.7495\n",
      "trainer/Policy Loss                 -1182.99\n",
      "trainer/Bias Loss                     136.95\n",
      "trainer/Bias Value                     13.9014\n",
      "trainer/Policy Grad Norm               96.8476\n",
      "trainer/Policy Param Norm              30.1723\n",
      "trainer/Zf1 Grad Norm                1455.26\n",
      "trainer/Zf1 Param Norm                 81.515\n",
      "trainer/Zf2 Grad Norm                1734.33\n",
      "trainer/Zf2 Param Norm                 82.5574\n",
      "trainer/Z Expert Predictions Mean    1561.68\n",
      "trainer/Z Expert Predictions Std       76.1331\n",
      "trainer/Z Expert Predictions Max     1656.14\n",
      "trainer/Z Expert Predictions Min     1127.71\n",
      "trainer/Z Policy Predictions Mean    1180.62\n",
      "trainer/Z Policy Predictions Std      584.145\n",
      "trainer/Z Policy Predictions Max     1650.22\n",
      "trainer/Z Policy Predictions Min     -424.892\n",
      "trainer/Z Expert Targets Mean        1543.89\n",
      "trainer/Z Expert Targets Std           77.5775\n",
      "trainer/Z Expert Targets Max         1635.32\n",
      "trainer/Z Expert Targets Min         1089.88\n",
      "trainer/Z Policy Targets Mean        1176.4\n",
      "trainer/Z Policy Targets Std          578.826\n",
      "trainer/Z Policy Targets Max         1620.06\n",
      "trainer/Z Policy Targets Min         -442.89\n",
      "trainer/Log Pis Mean                   20.3712\n",
      "trainer/Log Pis Std                     5.3982\n",
      "trainer/Policy mu Mean                 -0.00789592\n",
      "trainer/Policy mu Std                   1.38494\n",
      "trainer/Policy log std Mean            -2.86928\n",
      "trainer/Policy log std Std              1.04105\n",
      "trainer/Alpha                           0.0789224\n",
      "trainer/Alpha Loss                     -0.0292949\n",
      "exploration/num steps total         73352\n",
      "exploration/num paths total           166\n",
      "evaluation/num steps total         503033\n",
      "evaluation/num paths total            723\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.44123\n",
      "evaluation/Rewards Std                  1.35799\n",
      "evaluation/Rewards Max                  6.80245\n",
      "evaluation/Rewards Min                 -2.30609\n",
      "evaluation/Returns Mean              4441.23\n",
      "evaluation/Returns Std                433.931\n",
      "evaluation/Returns Max               4726.17\n",
      "evaluation/Returns Min               3158.95\n",
      "evaluation/Estimation Bias Mean      1500.19\n",
      "evaluation/Estimation Bias Std        238.289\n",
      "evaluation/EB/Q_True Mean              28.2111\n",
      "evaluation/EB/Q_True Std              111.414\n",
      "evaluation/EB/Q_Pred Mean            1528.41\n",
      "evaluation/EB/Q_Pred Std              214.72\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4441.23\n",
      "evaluation/Actions Mean                 0.0199978\n",
      "evaluation/Actions Std                  0.540688\n",
      "evaluation/Actions Max                  0.999933\n",
      "evaluation/Actions Min                 -0.998923\n",
      "time/backward_policy (s)                1.94119\n",
      "time/backward_zf1 (s)                   2.03153\n",
      "time/backward_zf2 (s)                   2.00813\n",
      "time/data sampling (s)                  0.262987\n",
      "time/data storing (s)                   0.0140022\n",
      "time/evaluation sampling (s)            1.80429\n",
      "time/exploration sampling (s)           0.315508\n",
      "time/logging (s)                        0.012684\n",
      "time/preback_alpha (s)                  1.03336\n",
      "time/preback_policy (s)                 1.18202\n",
      "time/preback_start (s)                  0.141379\n",
      "time/preback_zf (s)                     5.13154\n",
      "time/saving (s)                         0.00963008\n",
      "time/training (s)                       2.01207\n",
      "time/epoch (s)                         17.9003\n",
      "time/total (s)                       1224.6\n",
      "Epoch                                  68\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:12:51.721741 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 69 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  80000\n",
      "trainer/ZF1 Loss                       30.014\n",
      "trainer/ZF2 Loss                       29.4254\n",
      "trainer/ZF Expert Reward               17.8071\n",
      "trainer/ZF Policy Reward                6.01506\n",
      "trainer/ZF CHI2 Term                   61.9452\n",
      "trainer/Policy Loss                 -1122.04\n",
      "trainer/Bias Loss                     125.201\n",
      "trainer/Bias Value                     13.906\n",
      "trainer/Policy Grad Norm              131.739\n",
      "trainer/Policy Param Norm              30.2533\n",
      "trainer/Zf1 Grad Norm                2824.33\n",
      "trainer/Zf1 Param Norm                 81.7968\n",
      "trainer/Zf2 Grad Norm                2113.73\n",
      "trainer/Zf2 Param Norm                 82.8427\n",
      "trainer/Z Expert Predictions Mean    1564.66\n",
      "trainer/Z Expert Predictions Std       68.8668\n",
      "trainer/Z Expert Predictions Max     1654.46\n",
      "trainer/Z Expert Predictions Min     1153.41\n",
      "trainer/Z Policy Predictions Mean    1114.56\n",
      "trainer/Z Policy Predictions Std      638.898\n",
      "trainer/Z Policy Predictions Max     1641.58\n",
      "trainer/Z Policy Predictions Min     -449.647\n",
      "trainer/Z Expert Targets Mean        1546.85\n",
      "trainer/Z Expert Targets Std           69.7425\n",
      "trainer/Z Expert Targets Max         1648.15\n",
      "trainer/Z Expert Targets Min         1154.01\n",
      "trainer/Z Policy Targets Mean        1108.55\n",
      "trainer/Z Policy Targets Std          633.015\n",
      "trainer/Z Policy Targets Max         1639.22\n",
      "trainer/Z Policy Targets Min         -445.583\n",
      "trainer/Log Pis Mean                   20.6398\n",
      "trainer/Log Pis Std                     5.5955\n",
      "trainer/Policy mu Mean                  0.0180793\n",
      "trainer/Policy mu Std                   1.45166\n",
      "trainer/Policy log std Mean            -2.85288\n",
      "trainer/Policy log std Std              1.0568\n",
      "trainer/Alpha                           0.0784477\n",
      "trainer/Alpha Loss                     -0.0501911\n",
      "exploration/num steps total         74352\n",
      "exploration/num paths total           167\n",
      "evaluation/num steps total         511757\n",
      "evaluation/num paths total            733\n",
      "evaluation/path length Mean           872.4\n",
      "evaluation/path length Std            280.071\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            104\n",
      "evaluation/Rewards Mean                 3.71268\n",
      "evaluation/Rewards Std                  2.43631\n",
      "evaluation/Rewards Max                  6.95533\n",
      "evaluation/Rewards Min                 -3.10519\n",
      "evaluation/Returns Mean              3238.94\n",
      "evaluation/Returns Std               1836.85\n",
      "evaluation/Returns Max               4785.31\n",
      "evaluation/Returns Min               -224.477\n",
      "evaluation/Estimation Bias Mean      1259.44\n",
      "evaluation/Estimation Bias Std        546.837\n",
      "evaluation/EB/Q_True Mean              50.1512\n",
      "evaluation/EB/Q_True Std              143.166\n",
      "evaluation/EB/Q_Pred Mean            1309.6\n",
      "evaluation/EB/Q_Pred Std              542.784\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3238.94\n",
      "evaluation/Actions Mean                 0.0347095\n",
      "evaluation/Actions Std                  0.585149\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.7223\n",
      "time/backward_zf1 (s)                   1.83493\n",
      "time/backward_zf2 (s)                   1.75456\n",
      "time/data sampling (s)                  0.263338\n",
      "time/data storing (s)                   0.0143303\n",
      "time/evaluation sampling (s)            1.73065\n",
      "time/exploration sampling (s)           0.317056\n",
      "time/logging (s)                        0.0109351\n",
      "time/preback_alpha (s)                  0.881516\n",
      "time/preback_policy (s)                 0.953743\n",
      "time/preback_start (s)                  0.140753\n",
      "time/preback_zf (s)                     5.12374\n",
      "time/saving (s)                         0.00603585\n",
      "time/training (s)                       2.4739\n",
      "time/epoch (s)                         17.2278\n",
      "time/total (s)                       1241.85\n",
      "Epoch                                  69\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:13:09.610657 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 70 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  81000\n",
      "trainer/ZF1 Loss                       44.1498\n",
      "trainer/ZF2 Loss                       74.6028\n",
      "trainer/ZF Expert Reward                8.17761\n",
      "trainer/ZF Policy Reward                0.574792\n",
      "trainer/ZF CHI2 Term                   86.8726\n",
      "trainer/Policy Loss                 -1216.8\n",
      "trainer/Bias Loss                     246.434\n",
      "trainer/Bias Value                     13.9184\n",
      "trainer/Policy Grad Norm              161.233\n",
      "trainer/Policy Param Norm              30.3302\n",
      "trainer/Zf1 Grad Norm                2171.04\n",
      "trainer/Zf1 Param Norm                 82.0676\n",
      "trainer/Zf2 Grad Norm                3186.12\n",
      "trainer/Zf2 Param Norm                 83.1198\n",
      "trainer/Z Expert Predictions Mean    1545.63\n",
      "trainer/Z Expert Predictions Std       70.0398\n",
      "trainer/Z Expert Predictions Max     1638.52\n",
      "trainer/Z Expert Predictions Min     1222.71\n",
      "trainer/Z Policy Predictions Mean    1212.25\n",
      "trainer/Z Policy Predictions Std      556.152\n",
      "trainer/Z Policy Predictions Max     1646.41\n",
      "trainer/Z Policy Predictions Min     -407.368\n",
      "trainer/Z Expert Targets Mean        1537.46\n",
      "trainer/Z Expert Targets Std           74.3344\n",
      "trainer/Z Expert Targets Max         1629.77\n",
      "trainer/Z Expert Targets Min         1166.93\n",
      "trainer/Z Policy Targets Mean        1211.67\n",
      "trainer/Z Policy Targets Std          554.08\n",
      "trainer/Z Policy Targets Max         1636.01\n",
      "trainer/Z Policy Targets Min         -399.725\n",
      "trainer/Log Pis Mean                   20.0945\n",
      "trainer/Log Pis Std                     5.05409\n",
      "trainer/Policy mu Mean                  0.0310582\n",
      "trainer/Policy mu Std                   1.27142\n",
      "trainer/Policy log std Mean            -2.99023\n",
      "trainer/Policy log std Std              0.96578\n",
      "trainer/Alpha                           0.0782828\n",
      "trainer/Alpha Loss                     -0.00739598\n",
      "exploration/num steps total         77352\n",
      "exploration/num paths total           170\n",
      "evaluation/num steps total         521757\n",
      "evaluation/num paths total            743\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.52083\n",
      "evaluation/Rewards Std                  1.15927\n",
      "evaluation/Rewards Max                  6.84519\n",
      "evaluation/Rewards Min                 -1.90357\n",
      "evaluation/Returns Mean              4520.83\n",
      "evaluation/Returns Std                124.837\n",
      "evaluation/Returns Max               4710.52\n",
      "evaluation/Returns Min               4325.93\n",
      "evaluation/Estimation Bias Mean      1473.9\n",
      "evaluation/Estimation Bias Std        167.037\n",
      "evaluation/EB/Q_True Mean              41.2839\n",
      "evaluation/EB/Q_True Std              129.377\n",
      "evaluation/EB/Q_Pred Mean            1515.19\n",
      "evaluation/EB/Q_Pred Std              104.606\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4520.83\n",
      "evaluation/Actions Mean                 0.0151502\n",
      "evaluation/Actions Std                  0.543791\n",
      "evaluation/Actions Max                  0.998865\n",
      "evaluation/Actions Min                 -0.999545\n",
      "time/backward_policy (s)                1.91958\n",
      "time/backward_zf1 (s)                   2.03275\n",
      "time/backward_zf2 (s)                   1.97218\n",
      "time/data sampling (s)                  0.276515\n",
      "time/data storing (s)                   0.0144096\n",
      "time/evaluation sampling (s)            1.77669\n",
      "time/exploration sampling (s)           0.327598\n",
      "time/logging (s)                        0.0125933\n",
      "time/preback_alpha (s)                  1.00177\n",
      "time/preback_policy (s)                 1.13362\n",
      "time/preback_start (s)                  0.141028\n",
      "time/preback_zf (s)                     5.11863\n",
      "time/saving (s)                         0.00658644\n",
      "time/training (s)                       2.09284\n",
      "time/epoch (s)                         17.8268\n",
      "time/total (s)                       1259.7\n",
      "Epoch                                  70\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:13:27.499618 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 71 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  82000\n",
      "trainer/ZF1 Loss                       53.9616\n",
      "trainer/ZF2 Loss                       50.3683\n",
      "trainer/ZF Expert Reward               14.0745\n",
      "trainer/ZF Policy Reward                3.49417\n",
      "trainer/ZF CHI2 Term                   82.5006\n",
      "trainer/Policy Loss                 -1235.53\n",
      "trainer/Bias Loss                     105.35\n",
      "trainer/Bias Value                     13.925\n",
      "trainer/Policy Grad Norm              107.552\n",
      "trainer/Policy Param Norm              30.4112\n",
      "trainer/Zf1 Grad Norm                2351.76\n",
      "trainer/Zf1 Param Norm                 82.3645\n",
      "trainer/Zf2 Grad Norm                2398.91\n",
      "trainer/Zf2 Param Norm                 83.4136\n",
      "trainer/Z Expert Predictions Mean    1549.15\n",
      "trainer/Z Expert Predictions Std       62.2015\n",
      "trainer/Z Expert Predictions Max     1649.2\n",
      "trainer/Z Expert Predictions Min     1259.15\n",
      "trainer/Z Policy Predictions Mean    1229.11\n",
      "trainer/Z Policy Predictions Std      544.514\n",
      "trainer/Z Policy Predictions Max     1633.39\n",
      "trainer/Z Policy Predictions Min     -428.605\n",
      "trainer/Z Expert Targets Mean        1535.08\n",
      "trainer/Z Expert Targets Std           63.9058\n",
      "trainer/Z Expert Targets Max         1646.08\n",
      "trainer/Z Expert Targets Min         1239.23\n",
      "trainer/Z Policy Targets Mean        1225.62\n",
      "trainer/Z Policy Targets Std          538.061\n",
      "trainer/Z Policy Targets Max         1618.07\n",
      "trainer/Z Policy Targets Min         -441.246\n",
      "trainer/Log Pis Mean                   19.9549\n",
      "trainer/Log Pis Std                     5.31714\n",
      "trainer/Policy mu Mean                  0.0311202\n",
      "trainer/Policy mu Std                   1.26871\n",
      "trainer/Policy log std Mean            -2.98826\n",
      "trainer/Policy log std Std              1.00451\n",
      "trainer/Alpha                           0.0784142\n",
      "trainer/Alpha Loss                      0.00353565\n",
      "exploration/num steps total         77972\n",
      "exploration/num paths total           171\n",
      "evaluation/num steps total         530884\n",
      "evaluation/num paths total            753\n",
      "evaluation/path length Mean           912.7\n",
      "evaluation/path length Std            261.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            127\n",
      "evaluation/Rewards Mean                 4.30718\n",
      "evaluation/Rewards Std                  1.24421\n",
      "evaluation/Rewards Max                  6.76924\n",
      "evaluation/Rewards Min                 -2.05748\n",
      "evaluation/Returns Mean              3931.17\n",
      "evaluation/Returns Std               1154.89\n",
      "evaluation/Returns Max               4536.05\n",
      "evaluation/Returns Min                498.828\n",
      "evaluation/Estimation Bias Mean      1446.8\n",
      "evaluation/Estimation Bias Std        169.08\n",
      "evaluation/EB/Q_True Mean              41.9404\n",
      "evaluation/EB/Q_True Std              123.005\n",
      "evaluation/EB/Q_Pred Mean            1488.74\n",
      "evaluation/EB/Q_Pred Std              108.621\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3931.17\n",
      "evaluation/Actions Mean                 0.0152854\n",
      "evaluation/Actions Std                  0.535598\n",
      "evaluation/Actions Max                  0.998306\n",
      "evaluation/Actions Min                 -0.998866\n",
      "time/backward_policy (s)                1.87246\n",
      "time/backward_zf1 (s)                   1.98387\n",
      "time/backward_zf2 (s)                   1.93858\n",
      "time/data sampling (s)                  0.2763\n",
      "time/data storing (s)                   0.0139619\n",
      "time/evaluation sampling (s)            1.74883\n",
      "time/exploration sampling (s)           0.32127\n",
      "time/logging (s)                        0.0111274\n",
      "time/preback_alpha (s)                  0.982976\n",
      "time/preback_policy (s)                 1.10662\n",
      "time/preback_start (s)                  0.14323\n",
      "time/preback_zf (s)                     5.1738\n",
      "time/saving (s)                         0.00865331\n",
      "time/training (s)                       2.23882\n",
      "time/epoch (s)                         17.8205\n",
      "time/total (s)                       1277.54\n",
      "Epoch                                  71\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:13:45.389244 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 72 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  83000\n",
      "trainer/ZF1 Loss                       50.9252\n",
      "trainer/ZF2 Loss                       28.6607\n",
      "trainer/ZF Expert Reward               11.8887\n",
      "trainer/ZF Policy Reward                0.506895\n",
      "trainer/ZF CHI2 Term                   70.7235\n",
      "trainer/Policy Loss                 -1192.78\n",
      "trainer/Bias Loss                     145.594\n",
      "trainer/Bias Value                     13.9294\n",
      "trainer/Policy Grad Norm              204.022\n",
      "trainer/Policy Param Norm              30.4839\n",
      "trainer/Zf1 Grad Norm                3911\n",
      "trainer/Zf1 Param Norm                 82.6541\n",
      "trainer/Zf2 Grad Norm                2306.48\n",
      "trainer/Zf2 Param Norm                 83.6684\n",
      "trainer/Z Expert Predictions Mean    1539.78\n",
      "trainer/Z Expert Predictions Std       67.1121\n",
      "trainer/Z Expert Predictions Max     1628.11\n",
      "trainer/Z Expert Predictions Min     1209.18\n",
      "trainer/Z Policy Predictions Mean    1180.98\n",
      "trainer/Z Policy Predictions Std      576.301\n",
      "trainer/Z Policy Predictions Max     1624.1\n",
      "trainer/Z Policy Predictions Min     -454.185\n",
      "trainer/Z Expert Targets Mean        1527.9\n",
      "trainer/Z Expert Targets Std           69.2725\n",
      "trainer/Z Expert Targets Max         1622.54\n",
      "trainer/Z Expert Targets Min         1194.29\n",
      "trainer/Z Policy Targets Mean        1180.48\n",
      "trainer/Z Policy Targets Std          567.743\n",
      "trainer/Z Policy Targets Max         1611.11\n",
      "trainer/Z Policy Targets Min         -418.469\n",
      "trainer/Log Pis Mean                   19.7463\n",
      "trainer/Log Pis Std                     4.61316\n",
      "trainer/Policy mu Mean                  0.0108783\n",
      "trainer/Policy mu Std                   1.25559\n",
      "trainer/Policy log std Mean            -2.95116\n",
      "trainer/Policy log std Std              1.00087\n",
      "trainer/Alpha                           0.0769082\n",
      "trainer/Alpha Loss                      0.0195143\n",
      "exploration/num steps total         79622\n",
      "exploration/num paths total           173\n",
      "evaluation/num steps total         540775\n",
      "evaluation/num paths total            763\n",
      "evaluation/path length Mean           989.1\n",
      "evaluation/path length Std             32.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            891\n",
      "evaluation/Rewards Mean                 4.6715\n",
      "evaluation/Rewards Std                  1.14188\n",
      "evaluation/Rewards Max                  6.9223\n",
      "evaluation/Rewards Min                 -1.86718\n",
      "evaluation/Returns Mean              4620.58\n",
      "evaluation/Returns Std                226.22\n",
      "evaluation/Returns Max               4853.08\n",
      "evaluation/Returns Min               4110.97\n",
      "evaluation/Estimation Bias Mean      1485.84\n",
      "evaluation/Estimation Bias Std        162.204\n",
      "evaluation/EB/Q_True Mean              42.0889\n",
      "evaluation/EB/Q_True Std              130.102\n",
      "evaluation/EB/Q_Pred Mean            1527.93\n",
      "evaluation/EB/Q_Pred Std               94.2425\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4620.58\n",
      "evaluation/Actions Mean                 0.0206233\n",
      "evaluation/Actions Std                  0.54252\n",
      "evaluation/Actions Max                  0.998192\n",
      "evaluation/Actions Min                 -0.999164\n",
      "time/backward_policy (s)                1.90042\n",
      "time/backward_zf1 (s)                   2.01125\n",
      "time/backward_zf2 (s)                   1.96144\n",
      "time/data sampling (s)                  0.27854\n",
      "time/data storing (s)                   0.0141315\n",
      "time/evaluation sampling (s)            1.76745\n",
      "time/exploration sampling (s)           0.322945\n",
      "time/logging (s)                        0.0125808\n",
      "time/preback_alpha (s)                  1.01951\n",
      "time/preback_policy (s)                 1.15332\n",
      "time/preback_start (s)                  0.14277\n",
      "time/preback_zf (s)                     5.15461\n",
      "time/saving (s)                         0.00645617\n",
      "time/training (s)                       2.07573\n",
      "time/epoch (s)                         17.8212\n",
      "time/total (s)                       1295.38\n",
      "Epoch                                  72\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:14:03.299446 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 73 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  84000\n",
      "trainer/ZF1 Loss                       24.5573\n",
      "trainer/ZF2 Loss                       47.0738\n",
      "trainer/ZF Expert Reward               15.4736\n",
      "trainer/ZF Policy Reward                2.22806\n",
      "trainer/ZF CHI2 Term                   69.4548\n",
      "trainer/Policy Loss                 -1201.05\n",
      "trainer/Bias Loss                     172.199\n",
      "trainer/Bias Value                     13.9347\n",
      "trainer/Policy Grad Norm              125.298\n",
      "trainer/Policy Param Norm              30.5537\n",
      "trainer/Zf1 Grad Norm                1570.73\n",
      "trainer/Zf1 Param Norm                 82.9433\n",
      "trainer/Zf2 Grad Norm                9660.88\n",
      "trainer/Zf2 Param Norm                 83.9792\n",
      "trainer/Z Expert Predictions Mean    1540.53\n",
      "trainer/Z Expert Predictions Std       63.6805\n",
      "trainer/Z Expert Predictions Max     1624.21\n",
      "trainer/Z Expert Predictions Min     1180.17\n",
      "trainer/Z Policy Predictions Mean    1192.97\n",
      "trainer/Z Policy Predictions Std      569.727\n",
      "trainer/Z Policy Predictions Max     1619.22\n",
      "trainer/Z Policy Predictions Min     -428.884\n",
      "trainer/Z Expert Targets Mean        1525.06\n",
      "trainer/Z Expert Targets Std           64.7525\n",
      "trainer/Z Expert Targets Max         1619.6\n",
      "trainer/Z Expert Targets Min         1155.37\n",
      "trainer/Z Policy Targets Mean        1190.74\n",
      "trainer/Z Policy Targets Std          563.643\n",
      "trainer/Z Policy Targets Max         1609.6\n",
      "trainer/Z Policy Targets Min         -424.161\n",
      "trainer/Log Pis Mean                   20.5998\n",
      "trainer/Log Pis Std                     6.66668\n",
      "trainer/Policy mu Mean                  0.0249331\n",
      "trainer/Policy mu Std                   1.34103\n",
      "trainer/Policy log std Mean            -2.9712\n",
      "trainer/Policy log std Std              0.971793\n",
      "trainer/Alpha                           0.0769212\n",
      "trainer/Alpha Loss                     -0.0461314\n",
      "exploration/num steps total         79843\n",
      "exploration/num paths total           174\n",
      "evaluation/num steps total         550184\n",
      "evaluation/num paths total            773\n",
      "evaluation/path length Mean           940.9\n",
      "evaluation/path length Std            177.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            409\n",
      "evaluation/Rewards Mean                 4.56097\n",
      "evaluation/Rewards Std                  1.041\n",
      "evaluation/Rewards Max                  6.98992\n",
      "evaluation/Rewards Min                 -1.78645\n",
      "evaluation/Returns Mean              4291.41\n",
      "evaluation/Returns Std                838.309\n",
      "evaluation/Returns Max               4868.71\n",
      "evaluation/Returns Min               1807.81\n",
      "evaluation/Estimation Bias Mean      1486.98\n",
      "evaluation/Estimation Bias Std        148.119\n",
      "evaluation/EB/Q_True Mean              42.7695\n",
      "evaluation/EB/Q_True Std              127.537\n",
      "evaluation/EB/Q_Pred Mean            1529.75\n",
      "evaluation/EB/Q_Pred Std               73.921\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4291.41\n",
      "evaluation/Actions Mean                 0.0132742\n",
      "evaluation/Actions Std                  0.538391\n",
      "evaluation/Actions Max                  0.998006\n",
      "evaluation/Actions Min                 -0.999378\n",
      "time/backward_policy (s)                1.90912\n",
      "time/backward_zf1 (s)                   2.02135\n",
      "time/backward_zf2 (s)                   1.96814\n",
      "time/data sampling (s)                  0.273608\n",
      "time/data storing (s)                   0.0140963\n",
      "time/evaluation sampling (s)            1.77698\n",
      "time/exploration sampling (s)           0.310228\n",
      "time/logging (s)                        0.0124367\n",
      "time/preback_alpha (s)                  1.00826\n",
      "time/preback_policy (s)                 1.1336\n",
      "time/preback_start (s)                  0.140216\n",
      "time/preback_zf (s)                     5.15976\n",
      "time/saving (s)                         0.00625925\n",
      "time/training (s)                       2.10946\n",
      "time/epoch (s)                         17.8435\n",
      "time/total (s)                       1313.25\n",
      "Epoch                                  73\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:14:21.315896 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 74 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  85000\n",
      "trainer/ZF1 Loss                       83.1032\n",
      "trainer/ZF2 Loss                       57.8988\n",
      "trainer/ZF Expert Reward               21.719\n",
      "trainer/ZF Policy Reward               10.3923\n",
      "trainer/ZF CHI2 Term                  101.27\n",
      "trainer/Policy Loss                 -1218.95\n",
      "trainer/Bias Loss                     228.629\n",
      "trainer/Bias Value                     13.9384\n",
      "trainer/Policy Grad Norm              114.884\n",
      "trainer/Policy Param Norm              30.6268\n",
      "trainer/Zf1 Grad Norm               18725.1\n",
      "trainer/Zf1 Param Norm                 83.232\n",
      "trainer/Zf2 Grad Norm                8756.82\n",
      "trainer/Zf2 Param Norm                 84.2522\n",
      "trainer/Z Expert Predictions Mean    1532.19\n",
      "trainer/Z Expert Predictions Std      112.008\n",
      "trainer/Z Expert Predictions Max     1640.35\n",
      "trainer/Z Expert Predictions Min      151.017\n",
      "trainer/Z Policy Predictions Mean    1213.89\n",
      "trainer/Z Policy Predictions Std      536.874\n",
      "trainer/Z Policy Predictions Max     1617.03\n",
      "trainer/Z Policy Predictions Min     -427.271\n",
      "trainer/Z Expert Targets Mean        1510.47\n",
      "trainer/Z Expert Targets Std          121.705\n",
      "trainer/Z Expert Targets Max         1610.01\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1203.5\n",
      "trainer/Z Policy Targets Std          532.864\n",
      "trainer/Z Policy Targets Max         1598.98\n",
      "trainer/Z Policy Targets Min         -420.242\n",
      "trainer/Log Pis Mean                   19.6389\n",
      "trainer/Log Pis Std                     4.59966\n",
      "trainer/Policy mu Mean                  0.0374177\n",
      "trainer/Policy mu Std                   1.20906\n",
      "trainer/Policy log std Mean            -2.98545\n",
      "trainer/Policy log std Std              0.96828\n",
      "trainer/Alpha                           0.0755724\n",
      "trainer/Alpha Loss                      0.0272868\n",
      "exploration/num steps total         80843\n",
      "exploration/num paths total           175\n",
      "evaluation/num steps total         559909\n",
      "evaluation/num paths total            783\n",
      "evaluation/path length Mean           972.5\n",
      "evaluation/path length Std             82.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            725\n",
      "evaluation/Rewards Mean                 4.54775\n",
      "evaluation/Rewards Std                  1.04075\n",
      "evaluation/Rewards Max                  6.82761\n",
      "evaluation/Rewards Min                 -2.81312\n",
      "evaluation/Returns Mean              4422.69\n",
      "evaluation/Returns Std                460.222\n",
      "evaluation/Returns Max               4721.2\n",
      "evaluation/Returns Min               3059.89\n",
      "evaluation/Estimation Bias Mean      1485.74\n",
      "evaluation/Estimation Bias Std        161.624\n",
      "evaluation/EB/Q_True Mean              42.7769\n",
      "evaluation/EB/Q_True Std              129.795\n",
      "evaluation/EB/Q_Pred Mean            1528.52\n",
      "evaluation/EB/Q_Pred Std               78.6558\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4422.69\n",
      "evaluation/Actions Mean                 0.0169471\n",
      "evaluation/Actions Std                  0.539003\n",
      "evaluation/Actions Max                  0.997821\n",
      "evaluation/Actions Min                 -0.998799\n",
      "time/backward_policy (s)                1.95739\n",
      "time/backward_zf1 (s)                   2.04564\n",
      "time/backward_zf2 (s)                   2.01344\n",
      "time/data sampling (s)                  0.275977\n",
      "time/data storing (s)                   0.0141128\n",
      "time/evaluation sampling (s)            1.74117\n",
      "time/exploration sampling (s)           0.322596\n",
      "time/logging (s)                        0.0121151\n",
      "time/preback_alpha (s)                  1.04746\n",
      "time/preback_policy (s)                 1.21258\n",
      "time/preback_start (s)                  0.141863\n",
      "time/preback_zf (s)                     5.16812\n",
      "time/saving (s)                         0.00634172\n",
      "time/training (s)                       1.99117\n",
      "time/epoch (s)                         17.95\n",
      "time/total (s)                       1331.22\n",
      "Epoch                                  74\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:14:39.505975 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 75 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  86000\n",
      "trainer/ZF1 Loss                       50.874\n",
      "trainer/ZF2 Loss                       44.7333\n",
      "trainer/ZF Expert Reward               13.2591\n",
      "trainer/ZF Policy Reward                0.582274\n",
      "trainer/ZF CHI2 Term                   79.9699\n",
      "trainer/Policy Loss                 -1137.64\n",
      "trainer/Bias Loss                     116.417\n",
      "trainer/Bias Value                     13.9471\n",
      "trainer/Policy Grad Norm              102.976\n",
      "trainer/Policy Param Norm              30.7027\n",
      "trainer/Zf1 Grad Norm                3183.42\n",
      "trainer/Zf1 Param Norm                 83.5219\n",
      "trainer/Zf2 Grad Norm                1854.83\n",
      "trainer/Zf2 Param Norm                 84.5309\n",
      "trainer/Z Expert Predictions Mean    1527.94\n",
      "trainer/Z Expert Predictions Std       68.311\n",
      "trainer/Z Expert Predictions Max     1618.58\n",
      "trainer/Z Expert Predictions Min     1207.61\n",
      "trainer/Z Policy Predictions Mean    1133.44\n",
      "trainer/Z Policy Predictions Std      613.966\n",
      "trainer/Z Policy Predictions Max     1603.92\n",
      "trainer/Z Policy Predictions Min     -443.699\n",
      "trainer/Z Expert Targets Mean        1514.68\n",
      "trainer/Z Expert Targets Std           70.1815\n",
      "trainer/Z Expert Targets Max         1607.82\n",
      "trainer/Z Expert Targets Min         1205.63\n",
      "trainer/Z Policy Targets Mean        1132.86\n",
      "trainer/Z Policy Targets Std          603.17\n",
      "trainer/Z Policy Targets Max         1611.03\n",
      "trainer/Z Policy Targets Min         -433.902\n",
      "trainer/Log Pis Mean                   19.6863\n",
      "trainer/Log Pis Std                     4.54496\n",
      "trainer/Policy mu Mean                  0.126441\n",
      "trainer/Policy mu Std                   1.28834\n",
      "trainer/Policy log std Mean            -2.87319\n",
      "trainer/Policy log std Std              1.05657\n",
      "trainer/Alpha                           0.0742378\n",
      "trainer/Alpha Loss                      0.0232912\n",
      "exploration/num steps total         81843\n",
      "exploration/num paths total           176\n",
      "evaluation/num steps total         569909\n",
      "evaluation/num paths total            793\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.55706\n",
      "evaluation/Rewards Std                  1.12204\n",
      "evaluation/Rewards Max                  7.35107\n",
      "evaluation/Rewards Min                 -1.82366\n",
      "evaluation/Returns Mean              4557.06\n",
      "evaluation/Returns Std                116.204\n",
      "evaluation/Returns Max               4722.21\n",
      "evaluation/Returns Min               4271.67\n",
      "evaluation/Estimation Bias Mean      1462.33\n",
      "evaluation/Estimation Bias Std        151.859\n",
      "evaluation/EB/Q_True Mean              41.9316\n",
      "evaluation/EB/Q_True Std              128.819\n",
      "evaluation/EB/Q_Pred Mean            1504.26\n",
      "evaluation/EB/Q_Pred Std               83.9619\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4557.06\n",
      "evaluation/Actions Mean                 0.0152419\n",
      "evaluation/Actions Std                  0.523293\n",
      "evaluation/Actions Max                  0.998279\n",
      "evaluation/Actions Min                 -0.998692\n",
      "time/backward_policy (s)                1.90741\n",
      "time/backward_zf1 (s)                   2.01109\n",
      "time/backward_zf2 (s)                   1.97402\n",
      "time/data sampling (s)                  0.286842\n",
      "time/data storing (s)                   0.0154684\n",
      "time/evaluation sampling (s)            1.79396\n",
      "time/exploration sampling (s)           0.32783\n",
      "time/logging (s)                        0.0116603\n",
      "time/preback_alpha (s)                  1.01132\n",
      "time/preback_policy (s)                 1.11979\n",
      "time/preback_start (s)                  0.147272\n",
      "time/preback_zf (s)                     5.24618\n",
      "time/saving (s)                         0.00631841\n",
      "time/training (s)                       2.26033\n",
      "time/epoch (s)                         18.1195\n",
      "time/total (s)                       1349.36\n",
      "Epoch                                  75\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:14:56.690170 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 76 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  87000\n",
      "trainer/ZF1 Loss                       82.918\n",
      "trainer/ZF2 Loss                       36.1894\n",
      "trainer/ZF Expert Reward                9.89331\n",
      "trainer/ZF Policy Reward                2.91956\n",
      "trainer/ZF CHI2 Term                   85.9243\n",
      "trainer/Policy Loss                 -1214.54\n",
      "trainer/Bias Loss                     336.814\n",
      "trainer/Bias Value                     13.9516\n",
      "trainer/Policy Grad Norm              116.377\n",
      "trainer/Policy Param Norm              30.7757\n",
      "trainer/Zf1 Grad Norm               13035.3\n",
      "trainer/Zf1 Param Norm                 83.8022\n",
      "trainer/Zf2 Grad Norm                2171.55\n",
      "trainer/Zf2 Param Norm                 84.7921\n",
      "trainer/Z Expert Predictions Mean    1524.29\n",
      "trainer/Z Expert Predictions Std       63.8499\n",
      "trainer/Z Expert Predictions Max     1612.18\n",
      "trainer/Z Expert Predictions Min     1168.23\n",
      "trainer/Z Policy Predictions Mean    1209.39\n",
      "trainer/Z Policy Predictions Std      552.532\n",
      "trainer/Z Policy Predictions Max     1579.65\n",
      "trainer/Z Policy Predictions Min     -445.876\n",
      "trainer/Z Expert Targets Mean        1514.4\n",
      "trainer/Z Expert Targets Std           66.6\n",
      "trainer/Z Expert Targets Max         1596.69\n",
      "trainer/Z Expert Targets Min         1199.85\n",
      "trainer/Z Policy Targets Mean        1206.47\n",
      "trainer/Z Policy Targets Std          547.304\n",
      "trainer/Z Policy Targets Max         1586.42\n",
      "trainer/Z Policy Targets Min         -424.843\n",
      "trainer/Log Pis Mean                   19.5928\n",
      "trainer/Log Pis Std                     4.03697\n",
      "trainer/Policy mu Mean                  0.0788582\n",
      "trainer/Policy mu Std                   1.1822\n",
      "trainer/Policy log std Mean            -3.01654\n",
      "trainer/Policy log std Std              0.931546\n",
      "trainer/Alpha                           0.0737329\n",
      "trainer/Alpha Loss                      0.030024\n",
      "exploration/num steps total         81843\n",
      "exploration/num paths total           176\n",
      "evaluation/num steps total         578934\n",
      "evaluation/num paths total            803\n",
      "evaluation/path length Mean           902.5\n",
      "evaluation/path length Std            292.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             25\n",
      "evaluation/Rewards Mean                 4.42339\n",
      "evaluation/Rewards Std                  0.964037\n",
      "evaluation/Rewards Max                  6.55344\n",
      "evaluation/Rewards Min                 -2.20032\n",
      "evaluation/Returns Mean              3992.11\n",
      "evaluation/Returns Std               1335.4\n",
      "evaluation/Returns Max               4591.94\n",
      "evaluation/Returns Min                 -2.7678\n",
      "evaluation/Estimation Bias Mean      1480.12\n",
      "evaluation/Estimation Bias Std        152.201\n",
      "evaluation/EB/Q_True Mean              44.7319\n",
      "evaluation/EB/Q_True Std              130.206\n",
      "evaluation/EB/Q_Pred Mean            1524.86\n",
      "evaluation/EB/Q_Pred Std               71.5616\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3992.11\n",
      "evaluation/Actions Mean                 0.0139493\n",
      "evaluation/Actions Std                  0.536453\n",
      "evaluation/Actions Max                  0.997419\n",
      "evaluation/Actions Min                 -0.998973\n",
      "time/backward_policy (s)                1.69871\n",
      "time/backward_zf1 (s)                   1.79686\n",
      "time/backward_zf2 (s)                   1.73822\n",
      "time/data sampling (s)                  0.265578\n",
      "time/data storing (s)                   0.0141555\n",
      "time/evaluation sampling (s)            1.75123\n",
      "time/exploration sampling (s)           0.310883\n",
      "time/logging (s)                        0.0115197\n",
      "time/preback_alpha (s)                  0.864537\n",
      "time/preback_policy (s)                 0.940664\n",
      "time/preback_start (s)                  0.137938\n",
      "time/preback_zf (s)                     5.10804\n",
      "time/saving (s)                         0.0060459\n",
      "time/training (s)                       2.47217\n",
      "time/epoch (s)                         17.1166\n",
      "time/total (s)                       1366.5\n",
      "Epoch                                  76\n",
      "---------------------------------  --------------\n",
      "2024-06-15 11:15:14.204565 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 77 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  88000\n",
      "trainer/ZF1 Loss                       36.2117\n",
      "trainer/ZF2 Loss                       40.889\n",
      "trainer/ZF Expert Reward               18.0688\n",
      "trainer/ZF Policy Reward                8.07216\n",
      "trainer/ZF CHI2 Term                   68.0859\n",
      "trainer/Policy Loss                 -1214.08\n",
      "trainer/Bias Loss                     175.812\n",
      "trainer/Bias Value                     13.955\n",
      "trainer/Policy Grad Norm              137.77\n",
      "trainer/Policy Param Norm              30.8474\n",
      "trainer/Zf1 Grad Norm                5121.33\n",
      "trainer/Zf1 Param Norm                 84.08\n",
      "trainer/Zf2 Grad Norm                6574.74\n",
      "trainer/Zf2 Param Norm                 85.0759\n",
      "trainer/Z Expert Predictions Mean    1519.25\n",
      "trainer/Z Expert Predictions Std      112.033\n",
      "trainer/Z Expert Predictions Max     1610.76\n",
      "trainer/Z Expert Predictions Min      179.415\n",
      "trainer/Z Policy Predictions Mean    1207.86\n",
      "trainer/Z Policy Predictions Std      568.577\n",
      "trainer/Z Policy Predictions Max     1600.08\n",
      "trainer/Z Policy Predictions Min     -443.754\n",
      "trainer/Z Expert Targets Mean        1501.18\n",
      "trainer/Z Expert Targets Std          120.419\n",
      "trainer/Z Expert Targets Max         1593.07\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1199.79\n",
      "trainer/Z Policy Targets Std          560.849\n",
      "trainer/Z Policy Targets Max         1590.49\n",
      "trainer/Z Policy Targets Min         -448.76\n",
      "trainer/Log Pis Mean                   19.7362\n",
      "trainer/Log Pis Std                     4.34061\n",
      "trainer/Policy mu Mean                  0.0752571\n",
      "trainer/Policy mu Std                   1.18008\n",
      "trainer/Policy log std Mean            -3.03701\n",
      "trainer/Policy log std Std              0.978946\n",
      "trainer/Alpha                           0.073933\n",
      "trainer/Alpha Loss                      0.0195042\n",
      "exploration/num steps total         81843\n",
      "exploration/num paths total           176\n",
      "evaluation/num steps total         587768\n",
      "evaluation/num paths total            814\n",
      "evaluation/path length Mean           803.091\n",
      "evaluation/path length Std            326.722\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             41\n",
      "evaluation/Rewards Mean                 4.45\n",
      "evaluation/Rewards Std                  1.19254\n",
      "evaluation/Rewards Max                  6.74062\n",
      "evaluation/Rewards Min                 -1.9628\n",
      "evaluation/Returns Mean              3573.75\n",
      "evaluation/Returns Std               1507.05\n",
      "evaluation/Returns Max               4722.33\n",
      "evaluation/Returns Min                 81.3328\n",
      "evaluation/Estimation Bias Mean      1427.52\n",
      "evaluation/Estimation Bias Std        163.143\n",
      "evaluation/EB/Q_True Mean              46.7644\n",
      "evaluation/EB/Q_True Std              135.314\n",
      "evaluation/EB/Q_Pred Mean            1474.28\n",
      "evaluation/EB/Q_Pred Std               86.0169\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3573.75\n",
      "evaluation/Actions Mean                 0.0303168\n",
      "evaluation/Actions Std                  0.546504\n",
      "evaluation/Actions Max                  0.999686\n",
      "evaluation/Actions Min                 -0.999318\n",
      "time/backward_policy (s)                1.83083\n",
      "time/backward_zf1 (s)                   1.92661\n",
      "time/backward_zf2 (s)                   1.8889\n",
      "time/data sampling (s)                  0.269486\n",
      "time/data storing (s)                   0.0142578\n",
      "time/evaluation sampling (s)            1.73634\n",
      "time/exploration sampling (s)           0.313483\n",
      "time/logging (s)                        0.011075\n",
      "time/preback_alpha (s)                  0.982729\n",
      "time/preback_policy (s)                 1.10059\n",
      "time/preback_start (s)                  0.138515\n",
      "time/preback_zf (s)                     5.10532\n",
      "time/saving (s)                         0.00616785\n",
      "time/training (s)                       2.11835\n",
      "time/epoch (s)                         17.4427\n",
      "time/total (s)                       1383.97\n",
      "Epoch                                  77\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:15:31.377272 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 78 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  89000\n",
      "trainer/ZF1 Loss                       31.8124\n",
      "trainer/ZF2 Loss                       32.2078\n",
      "trainer/ZF Expert Reward               18.6016\n",
      "trainer/ZF Policy Reward                4.39738\n",
      "trainer/ZF CHI2 Term                   66.5689\n",
      "trainer/Policy Loss                 -1085.51\n",
      "trainer/Bias Loss                     175.468\n",
      "trainer/Bias Value                     13.9568\n",
      "trainer/Policy Grad Norm              109.354\n",
      "trainer/Policy Param Norm              30.9184\n",
      "trainer/Zf1 Grad Norm                2784.53\n",
      "trainer/Zf1 Param Norm                 84.3554\n",
      "trainer/Zf2 Grad Norm                2277.04\n",
      "trainer/Zf2 Param Norm                 85.3503\n",
      "trainer/Z Expert Predictions Mean    1518.58\n",
      "trainer/Z Expert Predictions Std       66.7005\n",
      "trainer/Z Expert Predictions Max     1597.96\n",
      "trainer/Z Expert Predictions Min     1228.42\n",
      "trainer/Z Policy Predictions Mean    1080.25\n",
      "trainer/Z Policy Predictions Std      670.628\n",
      "trainer/Z Policy Predictions Max     1612.79\n",
      "trainer/Z Policy Predictions Min     -457.385\n",
      "trainer/Z Expert Targets Mean        1499.98\n",
      "trainer/Z Expert Targets Std           68.7996\n",
      "trainer/Z Expert Targets Max         1592.52\n",
      "trainer/Z Expert Targets Min         1185.88\n",
      "trainer/Z Policy Targets Mean        1075.85\n",
      "trainer/Z Policy Targets Std          663.663\n",
      "trainer/Z Policy Targets Max         1591.09\n",
      "trainer/Z Policy Targets Min         -444.514\n",
      "trainer/Log Pis Mean                   20.5602\n",
      "trainer/Log Pis Std                     4.55568\n",
      "trainer/Policy mu Mean                  0.155933\n",
      "trainer/Policy mu Std                   1.35447\n",
      "trainer/Policy log std Mean            -2.89452\n",
      "trainer/Policy log std Std              1.09411\n",
      "trainer/Alpha                           0.0748781\n",
      "trainer/Alpha Loss                     -0.041944\n",
      "exploration/num steps total         82843\n",
      "exploration/num paths total           177\n",
      "evaluation/num steps total         597768\n",
      "evaluation/num paths total            824\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63409\n",
      "evaluation/Rewards Std                  0.983226\n",
      "evaluation/Rewards Max                  6.71469\n",
      "evaluation/Rewards Min                 -1.66273\n",
      "evaluation/Returns Mean              4634.09\n",
      "evaluation/Returns Std                 72.7141\n",
      "evaluation/Returns Max               4790.02\n",
      "evaluation/Returns Min               4492.03\n",
      "evaluation/Estimation Bias Mean      1462.61\n",
      "evaluation/Estimation Bias Std        145.214\n",
      "evaluation/EB/Q_True Mean              43.0935\n",
      "evaluation/EB/Q_True Std              132.466\n",
      "evaluation/EB/Q_Pred Mean            1505.7\n",
      "evaluation/EB/Q_Pred Std               64.9477\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4634.09\n",
      "evaluation/Actions Mean                 0.0147059\n",
      "evaluation/Actions Std                  0.541993\n",
      "evaluation/Actions Max                  0.998839\n",
      "evaluation/Actions Min                 -0.999087\n",
      "time/backward_policy (s)                1.67796\n",
      "time/backward_zf1 (s)                   1.78659\n",
      "time/backward_zf2 (s)                   1.72185\n",
      "time/data sampling (s)                  0.277119\n",
      "time/data storing (s)                   0.0139205\n",
      "time/evaluation sampling (s)            1.73947\n",
      "time/exploration sampling (s)           0.312334\n",
      "time/logging (s)                        0.0124458\n",
      "time/preback_alpha (s)                  0.851597\n",
      "time/preback_policy (s)                 0.919794\n",
      "time/preback_start (s)                  0.139337\n",
      "time/preback_zf (s)                     5.10976\n",
      "time/saving (s)                         0.00575288\n",
      "time/training (s)                       2.52597\n",
      "time/epoch (s)                         17.0939\n",
      "time/total (s)                       1401.1\n",
      "Epoch                                  78\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:15:49.425893 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 79 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  90000\n",
      "trainer/ZF1 Loss                       21.7252\n",
      "trainer/ZF2 Loss                       19.7099\n",
      "trainer/ZF Expert Reward                6.96944\n",
      "trainer/ZF Policy Reward               -2.11821\n",
      "trainer/ZF CHI2 Term                   50.0305\n",
      "trainer/Policy Loss                 -1194.71\n",
      "trainer/Bias Loss                     112.552\n",
      "trainer/Bias Value                     13.9597\n",
      "trainer/Policy Grad Norm              106.003\n",
      "trainer/Policy Param Norm              30.9838\n",
      "trainer/Zf1 Grad Norm                2770.3\n",
      "trainer/Zf1 Param Norm                 84.6178\n",
      "trainer/Zf2 Grad Norm                2123.77\n",
      "trainer/Zf2 Param Norm                 85.5959\n",
      "trainer/Z Expert Predictions Mean    1510.1\n",
      "trainer/Z Expert Predictions Std       50.6785\n",
      "trainer/Z Expert Predictions Max     1591.47\n",
      "trainer/Z Expert Predictions Min     1235.36\n",
      "trainer/Z Policy Predictions Mean    1190.86\n",
      "trainer/Z Policy Predictions Std      577.795\n",
      "trainer/Z Policy Predictions Max     1565.88\n",
      "trainer/Z Policy Predictions Min     -438.675\n",
      "trainer/Z Expert Targets Mean        1503.13\n",
      "trainer/Z Expert Targets Std           51.2749\n",
      "trainer/Z Expert Targets Max         1569.95\n",
      "trainer/Z Expert Targets Min         1213.78\n",
      "trainer/Z Policy Targets Mean        1192.98\n",
      "trainer/Z Policy Targets Std          572.741\n",
      "trainer/Z Policy Targets Max         1565.28\n",
      "trainer/Z Policy Targets Min         -433.354\n",
      "trainer/Log Pis Mean                   20.4296\n",
      "trainer/Log Pis Std                     4.65568\n",
      "trainer/Policy mu Mean                  0.107983\n",
      "trainer/Policy mu Std                   1.3145\n",
      "trainer/Policy log std Mean            -2.96613\n",
      "trainer/Policy log std Std              1.02507\n",
      "trainer/Alpha                           0.0766442\n",
      "trainer/Alpha Loss                     -0.0329254\n",
      "exploration/num steps total         83843\n",
      "exploration/num paths total           178\n",
      "evaluation/num steps total         607768\n",
      "evaluation/num paths total            834\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.52963\n",
      "evaluation/Rewards Std                  0.972728\n",
      "evaluation/Rewards Max                  6.77951\n",
      "evaluation/Rewards Min                 -1.85859\n",
      "evaluation/Returns Mean              4529.63\n",
      "evaluation/Returns Std                 89.8921\n",
      "evaluation/Returns Max               4631.38\n",
      "evaluation/Returns Min               4408.36\n",
      "evaluation/Estimation Bias Mean      1457\n",
      "evaluation/Estimation Bias Std        145.676\n",
      "evaluation/EB/Q_True Mean              40.6108\n",
      "evaluation/EB/Q_True Std              125.06\n",
      "evaluation/EB/Q_Pred Mean            1497.61\n",
      "evaluation/EB/Q_Pred Std               67.8981\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4529.63\n",
      "evaluation/Actions Mean                 0.0275863\n",
      "evaluation/Actions Std                  0.535356\n",
      "evaluation/Actions Max                  0.998726\n",
      "evaluation/Actions Min                 -0.998316\n",
      "time/backward_policy (s)                1.94828\n",
      "time/backward_zf1 (s)                   2.08949\n",
      "time/backward_zf2 (s)                   2.03763\n",
      "time/data sampling (s)                  0.271953\n",
      "time/data storing (s)                   0.014728\n",
      "time/evaluation sampling (s)            1.77929\n",
      "time/exploration sampling (s)           0.319496\n",
      "time/logging (s)                        0.0121613\n",
      "time/preback_alpha (s)                  1.04998\n",
      "time/preback_policy (s)                 1.1992\n",
      "time/preback_start (s)                  0.142901\n",
      "time/preback_zf (s)                     5.14987\n",
      "time/saving (s)                         0.00588657\n",
      "time/training (s)                       1.96232\n",
      "time/epoch (s)                         17.9832\n",
      "time/total (s)                       1419.1\n",
      "Epoch                                  79\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:16:07.018291 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 80 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  91000\n",
      "trainer/ZF1 Loss                       69.5269\n",
      "trainer/ZF2 Loss                       34.0792\n",
      "trainer/ZF Expert Reward               10.8439\n",
      "trainer/ZF Policy Reward               -1.28242\n",
      "trainer/ZF CHI2 Term                   83.7939\n",
      "trainer/Policy Loss                 -1170.04\n",
      "trainer/Bias Loss                     269.374\n",
      "trainer/Bias Value                     13.9585\n",
      "trainer/Policy Grad Norm              163.461\n",
      "trainer/Policy Param Norm              31.05\n",
      "trainer/Zf1 Grad Norm                5403.87\n",
      "trainer/Zf1 Param Norm                 84.8845\n",
      "trainer/Zf2 Grad Norm                2231.09\n",
      "trainer/Zf2 Param Norm                 85.8544\n",
      "trainer/Z Expert Predictions Mean    1501.32\n",
      "trainer/Z Expert Predictions Std       75.9693\n",
      "trainer/Z Expert Predictions Max     1591.07\n",
      "trainer/Z Expert Predictions Min      878.077\n",
      "trainer/Z Policy Predictions Mean    1166.33\n",
      "trainer/Z Policy Predictions Std      573.173\n",
      "trainer/Z Policy Predictions Max     1568.5\n",
      "trainer/Z Policy Predictions Min     -435.448\n",
      "trainer/Z Expert Targets Mean        1490.48\n",
      "trainer/Z Expert Targets Std           80.6114\n",
      "trainer/Z Expert Targets Max         1581.77\n",
      "trainer/Z Expert Targets Min          856.743\n",
      "trainer/Z Policy Targets Mean        1167.61\n",
      "trainer/Z Policy Targets Std          569.681\n",
      "trainer/Z Policy Targets Max         1569.3\n",
      "trainer/Z Policy Targets Min         -422.164\n",
      "trainer/Log Pis Mean                   20.0651\n",
      "trainer/Log Pis Std                     4.75988\n",
      "trainer/Policy mu Mean                  0.190615\n",
      "trainer/Policy mu Std                   1.3028\n",
      "trainer/Policy log std Mean            -2.99397\n",
      "trainer/Policy log std Std              0.997597\n",
      "trainer/Alpha                           0.0780332\n",
      "trainer/Alpha Loss                     -0.00508087\n",
      "exploration/num steps total         86843\n",
      "exploration/num paths total           181\n",
      "evaluation/num steps total         617644\n",
      "evaluation/num paths total            844\n",
      "evaluation/path length Mean           987.6\n",
      "evaluation/path length Std             37.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            876\n",
      "evaluation/Rewards Mean                 4.61463\n",
      "evaluation/Rewards Std                  1.00745\n",
      "evaluation/Rewards Max                  6.95215\n",
      "evaluation/Rewards Min                 -1.9403\n",
      "evaluation/Returns Mean              4557.41\n",
      "evaluation/Returns Std                161.496\n",
      "evaluation/Returns Max               4720.57\n",
      "evaluation/Returns Min               4107.49\n",
      "evaluation/Estimation Bias Mean      1457.39\n",
      "evaluation/Estimation Bias Std        148.221\n",
      "evaluation/EB/Q_True Mean              42.9934\n",
      "evaluation/EB/Q_True Std              131.543\n",
      "evaluation/EB/Q_Pred Mean            1500.39\n",
      "evaluation/EB/Q_Pred Std               68.3015\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4557.41\n",
      "evaluation/Actions Mean                 0.0190826\n",
      "evaluation/Actions Std                  0.542609\n",
      "evaluation/Actions Max                  0.998755\n",
      "evaluation/Actions Min                 -0.999128\n",
      "time/backward_policy (s)                1.8055\n",
      "time/backward_zf1 (s)                   1.91267\n",
      "time/backward_zf2 (s)                   1.85256\n",
      "time/data sampling (s)                  0.275152\n",
      "time/data storing (s)                   0.0144491\n",
      "time/evaluation sampling (s)            1.75377\n",
      "time/exploration sampling (s)           0.320538\n",
      "time/logging (s)                        0.0119774\n",
      "time/preback_alpha (s)                  0.950073\n",
      "time/preback_policy (s)                 1.0508\n",
      "time/preback_start (s)                  0.145175\n",
      "time/preback_zf (s)                     5.13887\n",
      "time/saving (s)                         0.00635285\n",
      "time/training (s)                       2.28404\n",
      "time/epoch (s)                         17.5219\n",
      "time/total (s)                       1436.64\n",
      "Epoch                                  80\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:16:24.902061 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 81 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  92000\n",
      "trainer/ZF1 Loss                      470.887\n",
      "trainer/ZF2 Loss                      467.779\n",
      "trainer/ZF Expert Reward               10.8999\n",
      "trainer/ZF Policy Reward                3.38846\n",
      "trainer/ZF CHI2 Term                  496.211\n",
      "trainer/Policy Loss                 -1256.24\n",
      "trainer/Bias Loss                      85.5112\n",
      "trainer/Bias Value                     13.9585\n",
      "trainer/Policy Grad Norm              123.575\n",
      "trainer/Policy Param Norm              31.1124\n",
      "trainer/Zf1 Grad Norm                4020.76\n",
      "trainer/Zf1 Param Norm                 85.1485\n",
      "trainer/Zf2 Grad Norm                2550.36\n",
      "trainer/Zf2 Param Norm                 86.1143\n",
      "trainer/Z Expert Predictions Mean    1500.93\n",
      "trainer/Z Expert Predictions Std       61.8302\n",
      "trainer/Z Expert Predictions Max     1577.83\n",
      "trainer/Z Expert Predictions Min     1186.28\n",
      "trainer/Z Policy Predictions Mean    1253.52\n",
      "trainer/Z Policy Predictions Std      483.047\n",
      "trainer/Z Policy Predictions Max     1573.82\n",
      "trainer/Z Policy Predictions Min     -423.73\n",
      "trainer/Z Expert Targets Mean        1490.03\n",
      "trainer/Z Expert Targets Std           62.0142\n",
      "trainer/Z Expert Targets Max         1568.96\n",
      "trainer/Z Expert Targets Min         1179.46\n",
      "trainer/Z Policy Targets Mean        1250.13\n",
      "trainer/Z Policy Targets Std          483.211\n",
      "trainer/Z Policy Targets Max         1572.21\n",
      "trainer/Z Policy Targets Min         -417.182\n",
      "trainer/Log Pis Mean                   19.5619\n",
      "trainer/Log Pis Std                     4.20423\n",
      "trainer/Policy mu Mean                  0.100428\n",
      "trainer/Policy mu Std                   1.128\n",
      "trainer/Policy log std Mean            -3.05454\n",
      "trainer/Policy log std Std              0.977556\n",
      "trainer/Alpha                           0.0781459\n",
      "trainer/Alpha Loss                      0.0342402\n",
      "exploration/num steps total         86843\n",
      "exploration/num paths total           181\n",
      "evaluation/num steps total         626852\n",
      "evaluation/num paths total            854\n",
      "evaluation/path length Mean           920.8\n",
      "evaluation/path length Std            237.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            208\n",
      "evaluation/Rewards Mean                 4.62465\n",
      "evaluation/Rewards Std                  1.1033\n",
      "evaluation/Rewards Max                  6.95403\n",
      "evaluation/Rewards Min                 -1.98467\n",
      "evaluation/Returns Mean              4258.38\n",
      "evaluation/Returns Std               1130.38\n",
      "evaluation/Returns Max               4799.09\n",
      "evaluation/Returns Min                880.215\n",
      "evaluation/Estimation Bias Mean      1427.84\n",
      "evaluation/Estimation Bias Std        169.773\n",
      "evaluation/EB/Q_True Mean              46.4519\n",
      "evaluation/EB/Q_True Std              137.3\n",
      "evaluation/EB/Q_Pred Mean            1474.3\n",
      "evaluation/EB/Q_Pred Std               85.4806\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4258.38\n",
      "evaluation/Actions Mean                 0.0121755\n",
      "evaluation/Actions Std                  0.541864\n",
      "evaluation/Actions Max                  0.999985\n",
      "evaluation/Actions Min                 -0.999805\n",
      "time/backward_policy (s)                1.94116\n",
      "time/backward_zf1 (s)                   2.0399\n",
      "time/backward_zf2 (s)                   2.00877\n",
      "time/data sampling (s)                  0.274753\n",
      "time/data storing (s)                   0.0146728\n",
      "time/evaluation sampling (s)            1.76142\n",
      "time/exploration sampling (s)           0.314979\n",
      "time/logging (s)                        0.0113622\n",
      "time/preback_alpha (s)                  1.04196\n",
      "time/preback_policy (s)                 1.20093\n",
      "time/preback_start (s)                  0.141489\n",
      "time/preback_zf (s)                     5.12691\n",
      "time/saving (s)                         0.00607217\n",
      "time/training (s)                       1.93366\n",
      "time/epoch (s)                         17.818\n",
      "time/total (s)                       1454.48\n",
      "Epoch                                  81\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:16:42.576732 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 82 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  93000\n",
      "trainer/ZF1 Loss                       61.0871\n",
      "trainer/ZF2 Loss                       15.4614\n",
      "trainer/ZF Expert Reward                9.01775\n",
      "trainer/ZF Policy Reward                4.09891\n",
      "trainer/ZF CHI2 Term                   62.6805\n",
      "trainer/Policy Loss                 -1175.85\n",
      "trainer/Bias Loss                     137.234\n",
      "trainer/Bias Value                     13.9615\n",
      "trainer/Policy Grad Norm              121.675\n",
      "trainer/Policy Param Norm              31.1764\n",
      "trainer/Zf1 Grad Norm                3894.25\n",
      "trainer/Zf1 Param Norm                 85.4119\n",
      "trainer/Zf2 Grad Norm                2189.69\n",
      "trainer/Zf2 Param Norm                 86.3563\n",
      "trainer/Z Expert Predictions Mean    1488.22\n",
      "trainer/Z Expert Predictions Std       57.8333\n",
      "trainer/Z Expert Predictions Max     1564.01\n",
      "trainer/Z Expert Predictions Min     1127.32\n",
      "trainer/Z Policy Predictions Mean    1169.15\n",
      "trainer/Z Policy Predictions Std      559.942\n",
      "trainer/Z Policy Predictions Max     1550.97\n",
      "trainer/Z Policy Predictions Min     -440.554\n",
      "trainer/Z Expert Targets Mean        1479.2\n",
      "trainer/Z Expert Targets Std           61.5591\n",
      "trainer/Z Expert Targets Max         1557.11\n",
      "trainer/Z Expert Targets Min         1109.41\n",
      "trainer/Z Policy Targets Mean        1165.05\n",
      "trainer/Z Policy Targets Std          557.402\n",
      "trainer/Z Policy Targets Max         1551.62\n",
      "trainer/Z Policy Targets Min         -424.158\n",
      "trainer/Log Pis Mean                   19.6843\n",
      "trainer/Log Pis Std                     4.93365\n",
      "trainer/Policy mu Mean                  0.0870606\n",
      "trainer/Policy mu Std                   1.25513\n",
      "trainer/Policy log std Mean            -2.94134\n",
      "trainer/Policy log std Std              0.996345\n",
      "trainer/Alpha                           0.0782889\n",
      "trainer/Alpha Loss                      0.0247182\n",
      "exploration/num steps total         88843\n",
      "exploration/num paths total           183\n",
      "evaluation/num steps total         635382\n",
      "evaluation/num paths total            864\n",
      "evaluation/path length Mean           853\n",
      "evaluation/path length Std            310.026\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             45\n",
      "evaluation/Rewards Mean                 4.44633\n",
      "evaluation/Rewards Std                  1.6867\n",
      "evaluation/Rewards Max                  6.90104\n",
      "evaluation/Rewards Min                 -2.84121\n",
      "evaluation/Returns Mean              3792.72\n",
      "evaluation/Returns Std               1545.71\n",
      "evaluation/Returns Max               4878.56\n",
      "evaluation/Returns Min                109.377\n",
      "evaluation/Estimation Bias Mean      1355.07\n",
      "evaluation/Estimation Bias Std        377.626\n",
      "evaluation/EB/Q_True Mean              51.726\n",
      "evaluation/EB/Q_True Std              145.996\n",
      "evaluation/EB/Q_Pred Mean            1406.8\n",
      "evaluation/EB/Q_Pred Std              354.07\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3792.72\n",
      "evaluation/Actions Mean                 0.0602331\n",
      "evaluation/Actions Std                  0.564265\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999988\n",
      "time/backward_policy (s)                1.82351\n",
      "time/backward_zf1 (s)                   1.9588\n",
      "time/backward_zf2 (s)                   1.88271\n",
      "time/data sampling (s)                  0.279847\n",
      "time/data storing (s)                   0.0144257\n",
      "time/evaluation sampling (s)            1.68304\n",
      "time/exploration sampling (s)           0.32307\n",
      "time/logging (s)                        0.0111611\n",
      "time/preback_alpha (s)                  0.956356\n",
      "time/preback_policy (s)                 1.0524\n",
      "time/preback_start (s)                  0.143776\n",
      "time/preback_zf (s)                     5.18289\n",
      "time/saving (s)                         0.00618809\n",
      "time/training (s)                       2.28946\n",
      "time/epoch (s)                         17.6076\n",
      "time/total (s)                       1472.11\n",
      "Epoch                                  82\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:17:00.373719 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 83 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  94000\n",
      "trainer/ZF1 Loss                       21.2907\n",
      "trainer/ZF2 Loss                       27.9377\n",
      "trainer/ZF Expert Reward               13.3074\n",
      "trainer/ZF Policy Reward                0.570098\n",
      "trainer/ZF CHI2 Term                   56.8292\n",
      "trainer/Policy Loss                 -1176.35\n",
      "trainer/Bias Loss                     135.559\n",
      "trainer/Bias Value                     13.9577\n",
      "trainer/Policy Grad Norm               92.2646\n",
      "trainer/Policy Param Norm              31.2411\n",
      "trainer/Zf1 Grad Norm                1861.47\n",
      "trainer/Zf1 Param Norm                 85.6709\n",
      "trainer/Zf2 Grad Norm                4093.22\n",
      "trainer/Zf2 Param Norm                 86.6148\n",
      "trainer/Z Expert Predictions Mean    1482.79\n",
      "trainer/Z Expert Predictions Std      104.31\n",
      "trainer/Z Expert Predictions Max     1570.8\n",
      "trainer/Z Expert Predictions Min      157.706\n",
      "trainer/Z Policy Predictions Mean    1170.67\n",
      "trainer/Z Policy Predictions Std      549.074\n",
      "trainer/Z Policy Predictions Max     1562.38\n",
      "trainer/Z Policy Predictions Min     -416.692\n",
      "trainer/Z Expert Targets Mean        1469.48\n",
      "trainer/Z Expert Targets Std          111.42\n",
      "trainer/Z Expert Targets Max         1551.41\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1170.1\n",
      "trainer/Z Policy Targets Std          543.245\n",
      "trainer/Z Policy Targets Max         1545.28\n",
      "trainer/Z Policy Targets Min         -420.82\n",
      "trainer/Log Pis Mean                   19.6744\n",
      "trainer/Log Pis Std                     4.93109\n",
      "trainer/Policy mu Mean                  0.156841\n",
      "trainer/Policy mu Std                   1.23719\n",
      "trainer/Policy log std Mean            -2.95318\n",
      "trainer/Policy log std Std              1.00946\n",
      "trainer/Alpha                           0.0775715\n",
      "trainer/Alpha Loss                      0.0252589\n",
      "exploration/num steps total         89843\n",
      "exploration/num paths total           184\n",
      "evaluation/num steps total         644736\n",
      "evaluation/num paths total            876\n",
      "evaluation/path length Mean           779.5\n",
      "evaluation/path length Std            312.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             34\n",
      "evaluation/Rewards Mean                 4.58882\n",
      "evaluation/Rewards Std                  1.09229\n",
      "evaluation/Rewards Max                  6.9463\n",
      "evaluation/Rewards Min                 -2.05328\n",
      "evaluation/Returns Mean              3576.98\n",
      "evaluation/Returns Std               1505.95\n",
      "evaluation/Returns Max               4853.06\n",
      "evaluation/Returns Min                 52.5812\n",
      "evaluation/Estimation Bias Mean      1426.43\n",
      "evaluation/Estimation Bias Std        165.844\n",
      "evaluation/EB/Q_True Mean              47.7348\n",
      "evaluation/EB/Q_True Std              141.896\n",
      "evaluation/EB/Q_Pred Mean            1474.17\n",
      "evaluation/EB/Q_Pred Std               75.3749\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3576.98\n",
      "evaluation/Actions Mean                 0.0276574\n",
      "evaluation/Actions Std                  0.526767\n",
      "evaluation/Actions Max                  0.999285\n",
      "evaluation/Actions Min                 -0.999264\n",
      "time/backward_policy (s)                1.83326\n",
      "time/backward_zf1 (s)                   1.95429\n",
      "time/backward_zf2 (s)                   1.88902\n",
      "time/data sampling (s)                  0.278695\n",
      "time/data storing (s)                   0.014266\n",
      "time/evaluation sampling (s)            1.81353\n",
      "time/exploration sampling (s)           0.31872\n",
      "time/logging (s)                        0.0114822\n",
      "time/preback_alpha (s)                  0.963113\n",
      "time/preback_policy (s)                 1.08646\n",
      "time/preback_start (s)                  0.143431\n",
      "time/preback_zf (s)                     5.14632\n",
      "time/saving (s)                         0.00826588\n",
      "time/training (s)                       2.25275\n",
      "time/epoch (s)                         17.7136\n",
      "time/total (s)                       1489.86\n",
      "Epoch                                  83\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:17:18.130771 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 84 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  95000\n",
      "trainer/ZF1 Loss                      405.78\n",
      "trainer/ZF2 Loss                      387.31\n",
      "trainer/ZF Expert Reward               25.5522\n",
      "trainer/ZF Policy Reward               18.2641\n",
      "trainer/ZF CHI2 Term                  423.566\n",
      "trainer/Policy Loss                 -1194.15\n",
      "trainer/Bias Loss                     347.602\n",
      "trainer/Bias Value                     13.9534\n",
      "trainer/Policy Grad Norm              139.104\n",
      "trainer/Policy Param Norm              31.3051\n",
      "trainer/Zf1 Grad Norm                6021.69\n",
      "trainer/Zf1 Param Norm                 85.9313\n",
      "trainer/Zf2 Grad Norm                5216.65\n",
      "trainer/Zf2 Param Norm                 86.8714\n",
      "trainer/Z Expert Predictions Mean    1501.66\n",
      "trainer/Z Expert Predictions Std       55.0277\n",
      "trainer/Z Expert Predictions Max     1577.91\n",
      "trainer/Z Expert Predictions Min     1057.36\n",
      "trainer/Z Policy Predictions Mean    1194.08\n",
      "trainer/Z Policy Predictions Std      542.192\n",
      "trainer/Z Policy Predictions Max     1568.45\n",
      "trainer/Z Policy Predictions Min     -429.215\n",
      "trainer/Z Expert Targets Mean        1476.11\n",
      "trainer/Z Expert Targets Std           66.1462\n",
      "trainer/Z Expert Targets Max         1561.34\n",
      "trainer/Z Expert Targets Min          831.144\n",
      "trainer/Z Policy Targets Mean        1175.82\n",
      "trainer/Z Policy Targets Std          540.249\n",
      "trainer/Z Policy Targets Max         1548.31\n",
      "trainer/Z Policy Targets Min         -429.495\n",
      "trainer/Log Pis Mean                   19.9324\n",
      "trainer/Log Pis Std                     5.3526\n",
      "trainer/Policy mu Mean                  0.106825\n",
      "trainer/Policy mu Std                   1.23534\n",
      "trainer/Policy log std Mean            -3.02156\n",
      "trainer/Policy log std Std              0.93695\n",
      "trainer/Alpha                           0.0768561\n",
      "trainer/Alpha Loss                      0.00519712\n",
      "exploration/num steps total         90936\n",
      "exploration/num paths total           186\n",
      "evaluation/num steps total         653082\n",
      "evaluation/num paths total            886\n",
      "evaluation/path length Mean           834.6\n",
      "evaluation/path length Std            336.105\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             40\n",
      "evaluation/Rewards Mean                 4.68081\n",
      "evaluation/Rewards Std                  1.04766\n",
      "evaluation/Rewards Max                  6.67504\n",
      "evaluation/Rewards Min                 -1.7933\n",
      "evaluation/Returns Mean              3906.61\n",
      "evaluation/Returns Std               1633.79\n",
      "evaluation/Returns Max               4868.66\n",
      "evaluation/Returns Min                 87.4289\n",
      "evaluation/Estimation Bias Mean      1427.35\n",
      "evaluation/Estimation Bias Std        158.544\n",
      "evaluation/EB/Q_True Mean              50.673\n",
      "evaluation/EB/Q_True Std              141.666\n",
      "evaluation/EB/Q_Pred Mean            1478.02\n",
      "evaluation/EB/Q_Pred Std               67.2502\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3906.61\n",
      "evaluation/Actions Mean                 0.0218156\n",
      "evaluation/Actions Std                  0.548612\n",
      "evaluation/Actions Max                  0.997125\n",
      "evaluation/Actions Min                 -0.998275\n",
      "time/backward_policy (s)                1.88987\n",
      "time/backward_zf1 (s)                   2.00318\n",
      "time/backward_zf2 (s)                   1.9531\n",
      "time/data sampling (s)                  0.281173\n",
      "time/data storing (s)                   0.0146251\n",
      "time/evaluation sampling (s)            1.71464\n",
      "time/exploration sampling (s)           0.319256\n",
      "time/logging (s)                        0.0107416\n",
      "time/preback_alpha (s)                  1.00967\n",
      "time/preback_policy (s)                 1.1438\n",
      "time/preback_start (s)                  0.141398\n",
      "time/preback_zf (s)                     5.12947\n",
      "time/saving (s)                         0.00586226\n",
      "time/training (s)                       2.06886\n",
      "time/epoch (s)                         17.6856\n",
      "time/total (s)                       1507.57\n",
      "Epoch                                  84\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:17:35.651412 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 85 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  96000\n",
      "trainer/ZF1 Loss                       20.4602\n",
      "trainer/ZF2 Loss                       22.3773\n",
      "trainer/ZF Expert Reward               10.8937\n",
      "trainer/ZF Policy Reward                0.487507\n",
      "trainer/ZF CHI2 Term                   51.2562\n",
      "trainer/Policy Loss                 -1251.6\n",
      "trainer/Bias Loss                      90.0612\n",
      "trainer/Bias Value                     13.9535\n",
      "trainer/Policy Grad Norm               86.9723\n",
      "trainer/Policy Param Norm              31.3648\n",
      "trainer/Zf1 Grad Norm                2305.72\n",
      "trainer/Zf1 Param Norm                 86.1965\n",
      "trainer/Zf2 Grad Norm                2092.78\n",
      "trainer/Zf2 Param Norm                 87.125\n",
      "trainer/Z Expert Predictions Mean    1477.85\n",
      "trainer/Z Expert Predictions Std      101.179\n",
      "trainer/Z Expert Predictions Max     1572.94\n",
      "trainer/Z Expert Predictions Min       67.4566\n",
      "trainer/Z Policy Predictions Mean    1248.75\n",
      "trainer/Z Policy Predictions Std      452.593\n",
      "trainer/Z Policy Predictions Max     1552.78\n",
      "trainer/Z Policy Predictions Min     -415.117\n",
      "trainer/Z Expert Targets Mean        1466.96\n",
      "trainer/Z Expert Targets Std          105.301\n",
      "trainer/Z Expert Targets Max         1553.21\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1248.27\n",
      "trainer/Z Policy Targets Std          447.651\n",
      "trainer/Z Policy Targets Max         1542.3\n",
      "trainer/Z Policy Targets Min         -396.821\n",
      "trainer/Log Pis Mean                   19.6275\n",
      "trainer/Log Pis Std                     4.85032\n",
      "trainer/Policy mu Mean                  0.100811\n",
      "trainer/Policy mu Std                   1.16061\n",
      "trainer/Policy log std Mean            -3.08441\n",
      "trainer/Policy log std Std              0.888019\n",
      "trainer/Alpha                           0.0783434\n",
      "trainer/Alpha Loss                      0.0291798\n",
      "exploration/num steps total         91936\n",
      "exploration/num paths total           187\n",
      "evaluation/num steps total         660787\n",
      "evaluation/num paths total            896\n",
      "evaluation/path length Mean           770.5\n",
      "evaluation/path length Std            318.304\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            104\n",
      "evaluation/Rewards Mean                 4.6725\n",
      "evaluation/Rewards Std                  1.18657\n",
      "evaluation/Rewards Max                  6.85642\n",
      "evaluation/Rewards Min                 -1.73328\n",
      "evaluation/Returns Mean              3600.16\n",
      "evaluation/Returns Std               1558.34\n",
      "evaluation/Returns Max               4899.99\n",
      "evaluation/Returns Min                409.187\n",
      "evaluation/Estimation Bias Mean      1391\n",
      "evaluation/Estimation Bias Std        176.632\n",
      "evaluation/EB/Q_True Mean              56.7443\n",
      "evaluation/EB/Q_True Std              151.397\n",
      "evaluation/EB/Q_Pred Mean            1447.74\n",
      "evaluation/EB/Q_Pred Std               80.8411\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3600.16\n",
      "evaluation/Actions Mean                 0.0218022\n",
      "evaluation/Actions Std                  0.537792\n",
      "evaluation/Actions Max                  0.998441\n",
      "evaluation/Actions Min                 -0.999145\n",
      "time/backward_policy (s)                1.79107\n",
      "time/backward_zf1 (s)                   1.91149\n",
      "time/backward_zf2 (s)                   1.85305\n",
      "time/data sampling (s)                  0.283045\n",
      "time/data storing (s)                   0.0141915\n",
      "time/evaluation sampling (s)            1.72043\n",
      "time/exploration sampling (s)           0.320398\n",
      "time/logging (s)                        0.00979902\n",
      "time/preback_alpha (s)                  0.936684\n",
      "time/preback_policy (s)                 1.03606\n",
      "time/preback_start (s)                  0.141431\n",
      "time/preback_zf (s)                     5.1299\n",
      "time/saving (s)                         0.00623527\n",
      "time/training (s)                       2.2946\n",
      "time/epoch (s)                         17.4484\n",
      "time/total (s)                       1525.04\n",
      "Epoch                                  85\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:17:53.283526 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 86 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  97000\n",
      "trainer/ZF1 Loss                       39.7904\n",
      "trainer/ZF2 Loss                       71.895\n",
      "trainer/ZF Expert Reward                9.90509\n",
      "trainer/ZF Policy Reward                1.18944\n",
      "trainer/ZF CHI2 Term                   84.0673\n",
      "trainer/Policy Loss                 -1215.13\n",
      "trainer/Bias Loss                     206.037\n",
      "trainer/Bias Value                     13.9501\n",
      "trainer/Policy Grad Norm              149.613\n",
      "trainer/Policy Param Norm              31.4268\n",
      "trainer/Zf1 Grad Norm                8776.56\n",
      "trainer/Zf1 Param Norm                 86.4642\n",
      "trainer/Zf2 Grad Norm                7522.68\n",
      "trainer/Zf2 Param Norm                 87.3809\n",
      "trainer/Z Expert Predictions Mean    1472.08\n",
      "trainer/Z Expert Predictions Std       58.7641\n",
      "trainer/Z Expert Predictions Max     1547.66\n",
      "trainer/Z Expert Predictions Min     1181.45\n",
      "trainer/Z Policy Predictions Mean    1206.63\n",
      "trainer/Z Policy Predictions Std      489.814\n",
      "trainer/Z Policy Predictions Max     1541.59\n",
      "trainer/Z Policy Predictions Min     -400.191\n",
      "trainer/Z Expert Targets Mean        1462.18\n",
      "trainer/Z Expert Targets Std           56.8165\n",
      "trainer/Z Expert Targets Max         1556.42\n",
      "trainer/Z Expert Targets Min         1180.36\n",
      "trainer/Z Policy Targets Mean        1205.44\n",
      "trainer/Z Policy Targets Std          488.993\n",
      "trainer/Z Policy Targets Max         1531.4\n",
      "trainer/Z Policy Targets Min         -409.895\n",
      "trainer/Log Pis Mean                   19.706\n",
      "trainer/Log Pis Std                     4.84785\n",
      "trainer/Policy mu Mean                  0.15001\n",
      "trainer/Policy mu Std                   1.22033\n",
      "trainer/Policy log std Mean            -3.02785\n",
      "trainer/Policy log std Std              0.987429\n",
      "trainer/Alpha                           0.0787717\n",
      "trainer/Alpha Loss                      0.0231598\n",
      "exploration/num steps total         91936\n",
      "exploration/num paths total           187\n",
      "evaluation/num steps total         669840\n",
      "evaluation/num paths total            906\n",
      "evaluation/path length Mean           905.3\n",
      "evaluation/path length Std            284.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             53\n",
      "evaluation/Rewards Mean                 4.33159\n",
      "evaluation/Rewards Std                  1.8609\n",
      "evaluation/Rewards Max                  7.02677\n",
      "evaluation/Rewards Min                 -3.40689\n",
      "evaluation/Returns Mean              3921.39\n",
      "evaluation/Returns Std               1564.03\n",
      "evaluation/Returns Max               4823.37\n",
      "evaluation/Returns Min                140.291\n",
      "evaluation/Estimation Bias Mean      1320.48\n",
      "evaluation/Estimation Bias Std        403.782\n",
      "evaluation/EB/Q_True Mean              47.52\n",
      "evaluation/EB/Q_True Std              138.207\n",
      "evaluation/EB/Q_Pred Mean            1368\n",
      "evaluation/EB/Q_Pred Std              391.192\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3921.39\n",
      "evaluation/Actions Mean                 0.051667\n",
      "evaluation/Actions Std                  0.555637\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999888\n",
      "time/backward_policy (s)                1.82707\n",
      "time/backward_zf1 (s)                   1.94633\n",
      "time/backward_zf2 (s)                   1.89984\n",
      "time/data sampling (s)                  0.274794\n",
      "time/data storing (s)                   0.0145072\n",
      "time/evaluation sampling (s)            1.7498\n",
      "time/exploration sampling (s)           0.312866\n",
      "time/logging (s)                        0.0113325\n",
      "time/preback_alpha (s)                  0.981167\n",
      "time/preback_policy (s)                 1.11021\n",
      "time/preback_start (s)                  0.141882\n",
      "time/preback_zf (s)                     5.13396\n",
      "time/saving (s)                         0.00604762\n",
      "time/training (s)                       2.15607\n",
      "time/epoch (s)                         17.5659\n",
      "time/total (s)                       1542.63\n",
      "Epoch                                  86\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:18:10.666156 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 87 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  98000\n",
      "trainer/ZF1 Loss                       18.8637\n",
      "trainer/ZF2 Loss                       15.1112\n",
      "trainer/ZF Expert Reward               13.9151\n",
      "trainer/ZF Policy Reward               -0.212327\n",
      "trainer/ZF CHI2 Term                   50.8553\n",
      "trainer/Policy Loss                 -1075.52\n",
      "trainer/Bias Loss                     100.622\n",
      "trainer/Bias Value                     13.948\n",
      "trainer/Policy Grad Norm               94.5294\n",
      "trainer/Policy Param Norm              31.4892\n",
      "trainer/Zf1 Grad Norm                2821.2\n",
      "trainer/Zf1 Param Norm                 86.7119\n",
      "trainer/Zf2 Grad Norm                1367.48\n",
      "trainer/Zf2 Param Norm                 87.6129\n",
      "trainer/Z Expert Predictions Mean    1466.14\n",
      "trainer/Z Expert Predictions Std      110.613\n",
      "trainer/Z Expert Predictions Max     1552.09\n",
      "trainer/Z Expert Predictions Min       22.5011\n",
      "trainer/Z Policy Predictions Mean    1069.45\n",
      "trainer/Z Policy Predictions Std      623.908\n",
      "trainer/Z Policy Predictions Max     1531.12\n",
      "trainer/Z Policy Predictions Min     -430.254\n",
      "trainer/Z Expert Targets Mean        1452.22\n",
      "trainer/Z Expert Targets Std          111.538\n",
      "trainer/Z Expert Targets Max         1535.22\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1069.67\n",
      "trainer/Z Policy Targets Std          615.156\n",
      "trainer/Z Policy Targets Max         1527.74\n",
      "trainer/Z Policy Targets Min         -420.482\n",
      "trainer/Log Pis Mean                   19.9398\n",
      "trainer/Log Pis Std                     4.72325\n",
      "trainer/Policy mu Mean                  0.242794\n",
      "trainer/Policy mu Std                   1.39688\n",
      "trainer/Policy log std Mean            -2.85461\n",
      "trainer/Policy log std Std              1.13358\n",
      "trainer/Alpha                           0.0776904\n",
      "trainer/Alpha Loss                      0.00467746\n",
      "exploration/num steps total         91936\n",
      "exploration/num paths total           187\n",
      "evaluation/num steps total         679840\n",
      "evaluation/num paths total            916\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68377\n",
      "evaluation/Rewards Std                  1.07946\n",
      "evaluation/Rewards Max                  6.82044\n",
      "evaluation/Rewards Min                 -1.65894\n",
      "evaluation/Returns Mean              4683.77\n",
      "evaluation/Returns Std                 74.8086\n",
      "evaluation/Returns Max               4844.37\n",
      "evaluation/Returns Min               4563.95\n",
      "evaluation/Estimation Bias Mean      1412.14\n",
      "evaluation/Estimation Bias Std        152.682\n",
      "evaluation/EB/Q_True Mean              43.0044\n",
      "evaluation/EB/Q_True Std              132.656\n",
      "evaluation/EB/Q_Pred Mean            1455.15\n",
      "evaluation/EB/Q_Pred Std               71.2058\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4683.77\n",
      "evaluation/Actions Mean                 0.0111689\n",
      "evaluation/Actions Std                  0.538783\n",
      "evaluation/Actions Max                  0.997734\n",
      "evaluation/Actions Min                 -0.999265\n",
      "time/backward_policy (s)                1.73167\n",
      "time/backward_zf1 (s)                   1.85292\n",
      "time/backward_zf2 (s)                   1.79765\n",
      "time/data sampling (s)                  0.281619\n",
      "time/data storing (s)                   0.013795\n",
      "time/evaluation sampling (s)            1.75359\n",
      "time/exploration sampling (s)           0.306533\n",
      "time/logging (s)                        0.012618\n",
      "time/preback_alpha (s)                  0.897925\n",
      "time/preback_policy (s)                 0.984919\n",
      "time/preback_start (s)                  0.139819\n",
      "time/preback_zf (s)                     5.1249\n",
      "time/saving (s)                         0.00590912\n",
      "time/training (s)                       2.41388\n",
      "time/epoch (s)                         17.3177\n",
      "time/total (s)                       1559.97\n",
      "Epoch                                  87\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:18:27.938001 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 88 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  99000\n",
      "trainer/ZF1 Loss                       14.7187\n",
      "trainer/ZF2 Loss                        2.98357\n",
      "trainer/ZF Expert Reward                9.38044\n",
      "trainer/ZF Policy Reward                0.175019\n",
      "trainer/ZF CHI2 Term                   37.1257\n",
      "trainer/Policy Loss                 -1185.98\n",
      "trainer/Bias Loss                      81.2285\n",
      "trainer/Bias Value                     13.9412\n",
      "trainer/Policy Grad Norm              109.098\n",
      "trainer/Policy Param Norm              31.5423\n",
      "trainer/Zf1 Grad Norm                2638.28\n",
      "trainer/Zf1 Param Norm                 86.9752\n",
      "trainer/Zf2 Grad Norm                1833.14\n",
      "trainer/Zf2 Param Norm                 87.8666\n",
      "trainer/Z Expert Predictions Mean    1458.88\n",
      "trainer/Z Expert Predictions Std      106.577\n",
      "trainer/Z Expert Predictions Max     1543.59\n",
      "trainer/Z Expert Predictions Min       35.6745\n",
      "trainer/Z Policy Predictions Mean    1181.25\n",
      "trainer/Z Policy Predictions Std      507.954\n",
      "trainer/Z Policy Predictions Max     1527.56\n",
      "trainer/Z Policy Predictions Min     -424.868\n",
      "trainer/Z Expert Targets Mean        1449.5\n",
      "trainer/Z Expert Targets Std          108.487\n",
      "trainer/Z Expert Targets Max         1539.33\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1181.07\n",
      "trainer/Z Policy Targets Std          502.956\n",
      "trainer/Z Policy Targets Max         1518.9\n",
      "trainer/Z Policy Targets Min         -415.623\n",
      "trainer/Log Pis Mean                   19.2618\n",
      "trainer/Log Pis Std                     4.44649\n",
      "trainer/Policy mu Mean                  0.135363\n",
      "trainer/Policy mu Std                   1.20507\n",
      "trainer/Policy log std Mean            -2.98955\n",
      "trainer/Policy log std Std              0.935962\n",
      "trainer/Alpha                           0.0793084\n",
      "trainer/Alpha Loss                      0.0585482\n",
      "exploration/num steps total         92936\n",
      "exploration/num paths total           188\n",
      "evaluation/num steps total         688452\n",
      "evaluation/num paths total            926\n",
      "evaluation/path length Mean           861.2\n",
      "evaluation/path length Std            231.557\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            343\n",
      "evaluation/Rewards Mean                 4.45039\n",
      "evaluation/Rewards Std                  1.03916\n",
      "evaluation/Rewards Max                  6.5293\n",
      "evaluation/Rewards Min                 -1.88259\n",
      "evaluation/Returns Mean              3832.68\n",
      "evaluation/Returns Std               1054.4\n",
      "evaluation/Returns Max               4672.99\n",
      "evaluation/Returns Min               1543.48\n",
      "evaluation/Estimation Bias Mean      1382.99\n",
      "evaluation/Estimation Bias Std        158.005\n",
      "evaluation/EB/Q_True Mean              47.6754\n",
      "evaluation/EB/Q_True Std              135.305\n",
      "evaluation/EB/Q_Pred Mean            1430.66\n",
      "evaluation/EB/Q_Pred Std               75.6773\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3832.68\n",
      "evaluation/Actions Mean                 0.0281198\n",
      "evaluation/Actions Std                  0.523391\n",
      "evaluation/Actions Max                  0.998306\n",
      "evaluation/Actions Min                 -0.999935\n",
      "time/backward_policy (s)                1.70045\n",
      "time/backward_zf1 (s)                   1.80905\n",
      "time/backward_zf2 (s)                   1.74934\n",
      "time/data sampling (s)                  0.280922\n",
      "time/data storing (s)                   0.0144102\n",
      "time/evaluation sampling (s)            1.76897\n",
      "time/exploration sampling (s)           0.313557\n",
      "time/logging (s)                        0.0118031\n",
      "time/preback_alpha (s)                  0.884752\n",
      "time/preback_policy (s)                 0.952954\n",
      "time/preback_start (s)                  0.140818\n",
      "time/preback_zf (s)                     5.12244\n",
      "time/saving (s)                         0.00618161\n",
      "time/training (s)                       2.45029\n",
      "time/epoch (s)                         17.206\n",
      "time/total (s)                       1577.19\n",
      "Epoch                                  88\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:18:45.942192 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 89 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 100000\n",
      "trainer/ZF1 Loss                       37.8505\n",
      "trainer/ZF2 Loss                        9.08584\n",
      "trainer/ZF Expert Reward               12.0015\n",
      "trainer/ZF Policy Reward               -3.20156\n",
      "trainer/ZF CHI2 Term                   58.6458\n",
      "trainer/Policy Loss                 -1123.27\n",
      "trainer/Bias Loss                     146.116\n",
      "trainer/Bias Value                     13.9392\n",
      "trainer/Policy Grad Norm              150.049\n",
      "trainer/Policy Param Norm              31.5981\n",
      "trainer/Zf1 Grad Norm                2939.1\n",
      "trainer/Zf1 Param Norm                 87.2281\n",
      "trainer/Zf2 Grad Norm                1394.12\n",
      "trainer/Zf2 Param Norm                 88.1053\n",
      "trainer/Z Expert Predictions Mean    1456.19\n",
      "trainer/Z Expert Predictions Std       60.1776\n",
      "trainer/Z Expert Predictions Max     1542.32\n",
      "trainer/Z Expert Predictions Min     1157.41\n",
      "trainer/Z Policy Predictions Mean    1117.66\n",
      "trainer/Z Policy Predictions Std      588.176\n",
      "trainer/Z Policy Predictions Max     1523.67\n",
      "trainer/Z Policy Predictions Min     -425.973\n",
      "trainer/Z Expert Targets Mean        1444.19\n",
      "trainer/Z Expert Targets Std           62.7567\n",
      "trainer/Z Expert Targets Max         1520.55\n",
      "trainer/Z Expert Targets Min         1135.97\n",
      "trainer/Z Policy Targets Mean        1120.86\n",
      "trainer/Z Policy Targets Std          580.037\n",
      "trainer/Z Policy Targets Max         1519.27\n",
      "trainer/Z Policy Targets Min         -412.881\n",
      "trainer/Log Pis Mean                   20.1763\n",
      "trainer/Log Pis Std                     4.42714\n",
      "trainer/Policy mu Mean                  0.207235\n",
      "trainer/Policy mu Std                   1.31581\n",
      "trainer/Policy log std Mean            -2.97075\n",
      "trainer/Policy log std Std              1.06283\n",
      "trainer/Alpha                           0.0795047\n",
      "trainer/Alpha Loss                     -0.0140177\n",
      "exploration/num steps total         93936\n",
      "exploration/num paths total           189\n",
      "evaluation/num steps total         695514\n",
      "evaluation/num paths total            937\n",
      "evaluation/path length Mean           642\n",
      "evaluation/path length Std            409.125\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             31\n",
      "evaluation/Rewards Mean                 3.61451\n",
      "evaluation/Rewards Std                  2.67413\n",
      "evaluation/Rewards Max                  6.68061\n",
      "evaluation/Rewards Min                 -2.99685\n",
      "evaluation/Returns Mean              2320.52\n",
      "evaluation/Returns Std               2337.94\n",
      "evaluation/Returns Max               4743.82\n",
      "evaluation/Returns Min              -2098.88\n",
      "evaluation/Estimation Bias Mean      1145.95\n",
      "evaluation/Estimation Bias Std        587.293\n",
      "evaluation/EB/Q_True Mean              60.4648\n",
      "evaluation/EB/Q_True Std              153.095\n",
      "evaluation/EB/Q_Pred Mean            1206.42\n",
      "evaluation/EB/Q_Pred Std              589.828\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2320.52\n",
      "evaluation/Actions Mean                 0.135901\n",
      "evaluation/Actions Std                  0.599001\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999958\n",
      "time/backward_policy (s)                1.89738\n",
      "time/backward_zf1 (s)                   2.03368\n",
      "time/backward_zf2 (s)                   1.9703\n",
      "time/data sampling (s)                  0.278718\n",
      "time/data storing (s)                   0.0145788\n",
      "time/evaluation sampling (s)            1.83233\n",
      "time/exploration sampling (s)           0.319484\n",
      "time/logging (s)                        0.0122957\n",
      "time/preback_alpha (s)                  1.0248\n",
      "time/preback_policy (s)                 1.16081\n",
      "time/preback_start (s)                  0.142871\n",
      "time/preback_zf (s)                     5.17432\n",
      "time/saving (s)                         0.00644782\n",
      "time/training (s)                       2.06562\n",
      "time/epoch (s)                         17.9336\n",
      "time/total (s)                       1595.15\n",
      "Epoch                                  89\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:19:04.016340 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 90 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 101000\n",
      "trainer/ZF1 Loss                       18.1246\n",
      "trainer/ZF2 Loss                       22.5001\n",
      "trainer/ZF Expert Reward               15.4965\n",
      "trainer/ZF Policy Reward                2.7222\n",
      "trainer/ZF CHI2 Term                   53.233\n",
      "trainer/Policy Loss                 -1123.77\n",
      "trainer/Bias Loss                      82.4314\n",
      "trainer/Bias Value                     13.9317\n",
      "trainer/Policy Grad Norm              109.63\n",
      "trainer/Policy Param Norm              31.653\n",
      "trainer/Zf1 Grad Norm                4407.43\n",
      "trainer/Zf1 Param Norm                 87.4885\n",
      "trainer/Zf2 Grad Norm                3963.76\n",
      "trainer/Zf2 Param Norm                 88.3603\n",
      "trainer/Z Expert Predictions Mean    1437.86\n",
      "trainer/Z Expert Predictions Std      142.859\n",
      "trainer/Z Expert Predictions Max     1526.03\n",
      "trainer/Z Expert Predictions Min      -40.855\n",
      "trainer/Z Policy Predictions Mean    1117.41\n",
      "trainer/Z Policy Predictions Std      577.892\n",
      "trainer/Z Policy Predictions Max     1523.57\n",
      "trainer/Z Policy Predictions Min     -422.544\n",
      "trainer/Z Expert Targets Mean        1422.36\n",
      "trainer/Z Expert Targets Std          140.459\n",
      "trainer/Z Expert Targets Max         1515.58\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1114.69\n",
      "trainer/Z Policy Targets Std          569.519\n",
      "trainer/Z Policy Targets Max         1515.7\n",
      "trainer/Z Policy Targets Min         -408.679\n",
      "trainer/Log Pis Mean                   20.3498\n",
      "trainer/Log Pis Std                     4.68495\n",
      "trainer/Policy mu Mean                  0.174373\n",
      "trainer/Policy mu Std                   1.3261\n",
      "trainer/Policy log std Mean            -2.9244\n",
      "trainer/Policy log std Std              1.05994\n",
      "trainer/Alpha                           0.078894\n",
      "trainer/Alpha Loss                     -0.0275965\n",
      "exploration/num steps total         96936\n",
      "exploration/num paths total           192\n",
      "evaluation/num steps total         704575\n",
      "evaluation/num paths total            947\n",
      "evaluation/path length Mean           906.1\n",
      "evaluation/path length Std            281.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             61\n",
      "evaluation/Rewards Mean                 3.95759\n",
      "evaluation/Rewards Std                  2.29186\n",
      "evaluation/Rewards Max                  6.82246\n",
      "evaluation/Rewards Min                 -3.44897\n",
      "evaluation/Returns Mean              3585.97\n",
      "evaluation/Returns Std               2249.53\n",
      "evaluation/Returns Max               4897\n",
      "evaluation/Returns Min              -1820.65\n",
      "evaluation/Estimation Bias Mean      1189.53\n",
      "evaluation/Estimation Bias Std        557.713\n",
      "evaluation/EB/Q_True Mean              48.4923\n",
      "evaluation/EB/Q_True Std              141.675\n",
      "evaluation/EB/Q_Pred Mean            1238.02\n",
      "evaluation/EB/Q_Pred Std              556.864\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3585.97\n",
      "evaluation/Actions Mean                 0.0634028\n",
      "evaluation/Actions Std                  0.56463\n",
      "evaluation/Actions Max                  0.999991\n",
      "evaluation/Actions Min                 -0.999958\n",
      "time/backward_policy (s)                1.9682\n",
      "time/backward_zf1 (s)                   2.0753\n",
      "time/backward_zf2 (s)                   2.03735\n",
      "time/data sampling (s)                  0.272595\n",
      "time/data storing (s)                   0.0145048\n",
      "time/evaluation sampling (s)            1.74975\n",
      "time/exploration sampling (s)           0.324992\n",
      "time/logging (s)                        0.0115169\n",
      "time/preback_alpha (s)                  1.04595\n",
      "time/preback_policy (s)                 1.19064\n",
      "time/preback_start (s)                  0.143956\n",
      "time/preback_zf (s)                     5.16016\n",
      "time/saving (s)                         0.00608681\n",
      "time/training (s)                       2.00272\n",
      "time/epoch (s)                         18.0037\n",
      "time/total (s)                       1613.18\n",
      "Epoch                                  90\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:19:21.566170 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 91 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 102000\n",
      "trainer/ZF1 Loss                      456.305\n",
      "trainer/ZF2 Loss                      445.563\n",
      "trainer/ZF Expert Reward               14.6177\n",
      "trainer/ZF Policy Reward               10.1906\n",
      "trainer/ZF CHI2 Term                  475.241\n",
      "trainer/Policy Loss                 -1229.77\n",
      "trainer/Bias Loss                      91.3675\n",
      "trainer/Bias Value                     13.928\n",
      "trainer/Policy Grad Norm              108.106\n",
      "trainer/Policy Param Norm              31.7047\n",
      "trainer/Zf1 Grad Norm                1763.17\n",
      "trainer/Zf1 Param Norm                 87.7477\n",
      "trainer/Zf2 Grad Norm                1648.33\n",
      "trainer/Zf2 Param Norm                 88.5645\n",
      "trainer/Z Expert Predictions Mean    1441.01\n",
      "trainer/Z Expert Predictions Std       54.9638\n",
      "trainer/Z Expert Predictions Max     1528.38\n",
      "trainer/Z Expert Predictions Min     1201.14\n",
      "trainer/Z Policy Predictions Mean    1224.19\n",
      "trainer/Z Policy Predictions Std      457.212\n",
      "trainer/Z Policy Predictions Max     1500.92\n",
      "trainer/Z Policy Predictions Min     -431.113\n",
      "trainer/Z Expert Targets Mean        1426.39\n",
      "trainer/Z Expert Targets Std           56.4449\n",
      "trainer/Z Expert Targets Max         1502.9\n",
      "trainer/Z Expert Targets Min         1194.94\n",
      "trainer/Z Policy Targets Mean        1214\n",
      "trainer/Z Policy Targets Std          457.919\n",
      "trainer/Z Policy Targets Max         1493.59\n",
      "trainer/Z Policy Targets Min         -413.859\n",
      "trainer/Log Pis Mean                   20.0807\n",
      "trainer/Log Pis Std                     4.75753\n",
      "trainer/Policy mu Mean                  0.134091\n",
      "trainer/Policy mu Std                   1.16859\n",
      "trainer/Policy log std Mean            -3.10452\n",
      "trainer/Policy log std Std              0.901277\n",
      "trainer/Alpha                           0.0793376\n",
      "trainer/Alpha Loss                     -0.00640358\n",
      "exploration/num steps total         96936\n",
      "exploration/num paths total           192\n",
      "evaluation/num steps total         714575\n",
      "evaluation/num paths total            957\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60954\n",
      "evaluation/Rewards Std                  0.95294\n",
      "evaluation/Rewards Max                  6.47938\n",
      "evaluation/Rewards Min                 -1.71564\n",
      "evaluation/Returns Mean              4609.54\n",
      "evaluation/Returns Std                 95.7045\n",
      "evaluation/Returns Max               4761.77\n",
      "evaluation/Returns Min               4449.45\n",
      "evaluation/Estimation Bias Mean      1392.01\n",
      "evaluation/Estimation Bias Std        142.909\n",
      "evaluation/EB/Q_True Mean              41.6896\n",
      "evaluation/EB/Q_True Std              128.65\n",
      "evaluation/EB/Q_Pred Mean            1433.7\n",
      "evaluation/EB/Q_Pred Std               61.4275\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4609.54\n",
      "evaluation/Actions Mean                 0.0267179\n",
      "evaluation/Actions Std                  0.533269\n",
      "evaluation/Actions Max                  0.996707\n",
      "evaluation/Actions Min                 -0.999195\n",
      "time/backward_policy (s)                1.77169\n",
      "time/backward_zf1 (s)                   1.89958\n",
      "time/backward_zf2 (s)                   1.81825\n",
      "time/data sampling (s)                  0.278046\n",
      "time/data storing (s)                   0.0145444\n",
      "time/evaluation sampling (s)            1.70759\n",
      "time/exploration sampling (s)           0.315318\n",
      "time/logging (s)                        0.0125902\n",
      "time/preback_alpha (s)                  0.908281\n",
      "time/preback_policy (s)                 0.995882\n",
      "time/preback_start (s)                  0.141551\n",
      "time/preback_zf (s)                     5.16141\n",
      "time/saving (s)                         0.0179224\n",
      "time/training (s)                       2.43914\n",
      "time/epoch (s)                         17.4818\n",
      "time/total (s)                       1630.68\n",
      "Epoch                                  91\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:19:39.154670 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 92 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 103000\n",
      "trainer/ZF1 Loss                       27.3536\n",
      "trainer/ZF2 Loss                       24.5614\n",
      "trainer/ZF Expert Reward                9.70471\n",
      "trainer/ZF Policy Reward               -0.95144\n",
      "trainer/ZF CHI2 Term                   56.4003\n",
      "trainer/Policy Loss                 -1146.16\n",
      "trainer/Bias Loss                      91.9329\n",
      "trainer/Bias Value                     13.9232\n",
      "trainer/Policy Grad Norm              125.266\n",
      "trainer/Policy Param Norm              31.7615\n",
      "trainer/Zf1 Grad Norm                2646.54\n",
      "trainer/Zf1 Param Norm                 88.0107\n",
      "trainer/Zf2 Grad Norm                2651.74\n",
      "trainer/Zf2 Param Norm                 88.8266\n",
      "trainer/Z Expert Predictions Mean    1436.04\n",
      "trainer/Z Expert Predictions Std       51.7269\n",
      "trainer/Z Expert Predictions Max     1504.17\n",
      "trainer/Z Expert Predictions Min     1173.05\n",
      "trainer/Z Policy Predictions Mean    1141.05\n",
      "trainer/Z Policy Predictions Std      568.542\n",
      "trainer/Z Policy Predictions Max     1495.1\n",
      "trainer/Z Policy Predictions Min     -423.761\n",
      "trainer/Z Expert Targets Mean        1426.34\n",
      "trainer/Z Expert Targets Std           50.3592\n",
      "trainer/Z Expert Targets Max         1510.16\n",
      "trainer/Z Expert Targets Min         1165.06\n",
      "trainer/Z Policy Targets Mean        1142.01\n",
      "trainer/Z Policy Targets Std          562.156\n",
      "trainer/Z Policy Targets Max         1489.71\n",
      "trainer/Z Policy Targets Min         -403.572\n",
      "trainer/Log Pis Mean                   19.9865\n",
      "trainer/Log Pis Std                     4.98058\n",
      "trainer/Policy mu Mean                  0.190208\n",
      "trainer/Policy mu Std                   1.22404\n",
      "trainer/Policy log std Mean            -3.03098\n",
      "trainer/Policy log std Std              0.995447\n",
      "trainer/Alpha                           0.0790711\n",
      "trainer/Alpha Loss                      0.00106654\n",
      "exploration/num steps total         98936\n",
      "exploration/num paths total           194\n",
      "evaluation/num steps total         723746\n",
      "evaluation/num paths total            967\n",
      "evaluation/path length Mean           917.1\n",
      "evaluation/path length Std            166.029\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            566\n",
      "evaluation/Rewards Mean                 4.59718\n",
      "evaluation/Rewards Std                  0.960537\n",
      "evaluation/Rewards Max                  6.48731\n",
      "evaluation/Rewards Min                 -1.8552\n",
      "evaluation/Returns Mean              4216.07\n",
      "evaluation/Returns Std                827.103\n",
      "evaluation/Returns Max               4697.48\n",
      "evaluation/Returns Min               2458.87\n",
      "evaluation/Estimation Bias Mean      1384.22\n",
      "evaluation/Estimation Bias Std        151.639\n",
      "evaluation/EB/Q_True Mean              46.6559\n",
      "evaluation/EB/Q_True Std              136.955\n",
      "evaluation/EB/Q_Pred Mean            1430.88\n",
      "evaluation/EB/Q_Pred Std               56.5785\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4216.07\n",
      "evaluation/Actions Mean                 0.0252363\n",
      "evaluation/Actions Std                  0.520141\n",
      "evaluation/Actions Max                  0.9972\n",
      "evaluation/Actions Min                 -0.999215\n",
      "time/backward_policy (s)                1.83058\n",
      "time/backward_zf1 (s)                   1.93385\n",
      "time/backward_zf2 (s)                   1.88224\n",
      "time/data sampling (s)                  0.284788\n",
      "time/data storing (s)                   0.0141517\n",
      "time/evaluation sampling (s)            1.71868\n",
      "time/exploration sampling (s)           0.316118\n",
      "time/logging (s)                        0.0116971\n",
      "time/preback_alpha (s)                  0.959646\n",
      "time/preback_policy (s)                 1.06453\n",
      "time/preback_start (s)                  0.142984\n",
      "time/preback_zf (s)                     5.11051\n",
      "time/saving (s)                         0.00649139\n",
      "time/training (s)                       2.2394\n",
      "time/epoch (s)                         17.5157\n",
      "time/total (s)                       1648.22\n",
      "Epoch                                  92\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:19:57.207934 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 93 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 104000\n",
      "trainer/ZF1 Loss                       10.466\n",
      "trainer/ZF2 Loss                        9.02495\n",
      "trainer/ZF Expert Reward               12.7547\n",
      "trainer/ZF Policy Reward                0.87491\n",
      "trainer/ZF CHI2 Term                   41.488\n",
      "trainer/Policy Loss                 -1183.78\n",
      "trainer/Bias Loss                     104.588\n",
      "trainer/Bias Value                     13.9135\n",
      "trainer/Policy Grad Norm               98.9207\n",
      "trainer/Policy Param Norm              31.8215\n",
      "trainer/Zf1 Grad Norm                4736.9\n",
      "trainer/Zf1 Param Norm                 88.2547\n",
      "trainer/Zf2 Grad Norm                2487.56\n",
      "trainer/Zf2 Param Norm                 89.0532\n",
      "trainer/Z Expert Predictions Mean    1425.95\n",
      "trainer/Z Expert Predictions Std      110.591\n",
      "trainer/Z Expert Predictions Max     1502.97\n",
      "trainer/Z Expert Predictions Min     -126.256\n",
      "trainer/Z Policy Predictions Mean    1179.56\n",
      "trainer/Z Policy Predictions Std      529.288\n",
      "trainer/Z Policy Predictions Max     1499.78\n",
      "trainer/Z Policy Predictions Min     -434.302\n",
      "trainer/Z Expert Targets Mean        1413.19\n",
      "trainer/Z Expert Targets Std          103.904\n",
      "trainer/Z Expert Targets Max         1490.22\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1178.69\n",
      "trainer/Z Policy Targets Std          523.294\n",
      "trainer/Z Policy Targets Max         1486.44\n",
      "trainer/Z Policy Targets Min         -425.354\n",
      "trainer/Log Pis Mean                   20.0634\n",
      "trainer/Log Pis Std                     4.56845\n",
      "trainer/Policy mu Mean                  0.124469\n",
      "trainer/Policy mu Std                   1.18759\n",
      "trainer/Policy log std Mean            -3.06946\n",
      "trainer/Policy log std Std              0.967577\n",
      "trainer/Alpha                           0.0795346\n",
      "trainer/Alpha Loss                     -0.00504105\n",
      "exploration/num steps total         98936\n",
      "exploration/num paths total           194\n",
      "evaluation/num steps total         733746\n",
      "evaluation/num paths total            977\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69333\n",
      "evaluation/Rewards Std                  0.995268\n",
      "evaluation/Rewards Max                  6.74144\n",
      "evaluation/Rewards Min                 -1.9134\n",
      "evaluation/Returns Mean              4693.33\n",
      "evaluation/Returns Std                 79.7868\n",
      "evaluation/Returns Max               4833.16\n",
      "evaluation/Returns Min               4559.4\n",
      "evaluation/Estimation Bias Mean      1378.01\n",
      "evaluation/Estimation Bias Std        144.765\n",
      "evaluation/EB/Q_True Mean              42.286\n",
      "evaluation/EB/Q_True Std              130.467\n",
      "evaluation/EB/Q_Pred Mean            1420.3\n",
      "evaluation/EB/Q_Pred Std               59.0361\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4693.33\n",
      "evaluation/Actions Mean                 0.0250063\n",
      "evaluation/Actions Std                  0.5354\n",
      "evaluation/Actions Max                  0.997141\n",
      "evaluation/Actions Min                 -0.998614\n",
      "time/backward_policy (s)                1.95963\n",
      "time/backward_zf1 (s)                   2.06906\n",
      "time/backward_zf2 (s)                   2.02505\n",
      "time/data sampling (s)                  0.286581\n",
      "time/data storing (s)                   0.015296\n",
      "time/evaluation sampling (s)            1.74522\n",
      "time/exploration sampling (s)           0.320844\n",
      "time/logging (s)                        0.0154164\n",
      "time/preback_alpha (s)                  1.04049\n",
      "time/preback_policy (s)                 1.18806\n",
      "time/preback_start (s)                  0.14311\n",
      "time/preback_zf (s)                     5.17089\n",
      "time/saving (s)                         0.00593083\n",
      "time/training (s)                       2.00574\n",
      "time/epoch (s)                         17.9913\n",
      "time/total (s)                       1666.23\n",
      "Epoch                                  93\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:20:14.802542 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 94 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 105000\n",
      "trainer/ZF1 Loss                      379.848\n",
      "trainer/ZF2 Loss                      363.234\n",
      "trainer/ZF Expert Reward               13.7623\n",
      "trainer/ZF Policy Reward                3.86343\n",
      "trainer/ZF CHI2 Term                  401.086\n",
      "trainer/Policy Loss                 -1121.22\n",
      "trainer/Bias Loss                      80.3997\n",
      "trainer/Bias Value                     13.907\n",
      "trainer/Policy Grad Norm               88.5015\n",
      "trainer/Policy Param Norm              31.8736\n",
      "trainer/Zf1 Grad Norm                3670.76\n",
      "trainer/Zf1 Param Norm                 88.4953\n",
      "trainer/Zf2 Grad Norm                4216.08\n",
      "trainer/Zf2 Param Norm                 89.2969\n",
      "trainer/Z Expert Predictions Mean    1422.62\n",
      "trainer/Z Expert Predictions Std       59.7237\n",
      "trainer/Z Expert Predictions Max     1491.62\n",
      "trainer/Z Expert Predictions Min      969.308\n",
      "trainer/Z Policy Predictions Mean    1116.84\n",
      "trainer/Z Policy Predictions Std      555.431\n",
      "trainer/Z Policy Predictions Max     1480.98\n",
      "trainer/Z Policy Predictions Min     -441.595\n",
      "trainer/Z Expert Targets Mean        1408.86\n",
      "trainer/Z Expert Targets Std           61.2486\n",
      "trainer/Z Expert Targets Max         1476.83\n",
      "trainer/Z Expert Targets Min          892.271\n",
      "trainer/Z Policy Targets Mean        1112.98\n",
      "trainer/Z Policy Targets Std          553.328\n",
      "trainer/Z Policy Targets Max         1472.67\n",
      "trainer/Z Policy Targets Min         -444.43\n",
      "trainer/Log Pis Mean                   19.8445\n",
      "trainer/Log Pis Std                     4.74884\n",
      "trainer/Policy mu Mean                  0.152849\n",
      "trainer/Policy mu Std                   1.30139\n",
      "trainer/Policy log std Mean            -2.96993\n",
      "trainer/Policy log std Std              1.08393\n",
      "trainer/Alpha                           0.0802892\n",
      "trainer/Alpha Loss                      0.0124866\n",
      "exploration/num steps total        100936\n",
      "exploration/num paths total           196\n",
      "evaluation/num steps total         743203\n",
      "evaluation/num paths total            987\n",
      "evaluation/path length Mean           945.7\n",
      "evaluation/path length Std            162.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            457\n",
      "evaluation/Rewards Mean                 4.7161\n",
      "evaluation/Rewards Std                  1.02111\n",
      "evaluation/Rewards Max                  6.73606\n",
      "evaluation/Rewards Min                 -1.92198\n",
      "evaluation/Returns Mean              4460.01\n",
      "evaluation/Returns Std                777.272\n",
      "evaluation/Returns Max               4841.03\n",
      "evaluation/Returns Min               2150.58\n",
      "evaluation/Estimation Bias Mean      1372.59\n",
      "evaluation/Estimation Bias Std        155.115\n",
      "evaluation/EB/Q_True Mean              46.2351\n",
      "evaluation/EB/Q_True Std              137.95\n",
      "evaluation/EB/Q_Pred Mean            1418.83\n",
      "evaluation/EB/Q_Pred Std               63.6509\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4460.01\n",
      "evaluation/Actions Mean                 0.0281123\n",
      "evaluation/Actions Std                  0.532151\n",
      "evaluation/Actions Max                  0.998588\n",
      "evaluation/Actions Min                 -0.99918\n",
      "time/backward_policy (s)                1.77924\n",
      "time/backward_zf1 (s)                   1.90281\n",
      "time/backward_zf2 (s)                   1.82553\n",
      "time/data sampling (s)                  0.280611\n",
      "time/data storing (s)                   0.0147223\n",
      "time/evaluation sampling (s)            1.73252\n",
      "time/exploration sampling (s)           0.321173\n",
      "time/logging (s)                        0.0113237\n",
      "time/preback_alpha (s)                  0.902748\n",
      "time/preback_policy (s)                 0.990383\n",
      "time/preback_start (s)                  0.142177\n",
      "time/preback_zf (s)                     5.17013\n",
      "time/saving (s)                         0.00589679\n",
      "time/training (s)                       2.44168\n",
      "time/epoch (s)                         17.521\n",
      "time/total (s)                       1683.78\n",
      "Epoch                                  94\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:20:32.244001 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 95 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 106000\n",
      "trainer/ZF1 Loss                      460.312\n",
      "trainer/ZF2 Loss                      389.614\n",
      "trainer/ZF Expert Reward               17.031\n",
      "trainer/ZF Policy Reward               11.7992\n",
      "trainer/ZF CHI2 Term                  449.708\n",
      "trainer/Policy Loss                 -1145.06\n",
      "trainer/Bias Loss                     304.697\n",
      "trainer/Bias Value                     13.8982\n",
      "trainer/Policy Grad Norm              132.11\n",
      "trainer/Policy Param Norm              31.9297\n",
      "trainer/Zf1 Grad Norm               35544\n",
      "trainer/Zf1 Param Norm                 88.7524\n",
      "trainer/Zf2 Grad Norm                7354.63\n",
      "trainer/Zf2 Param Norm                 89.5242\n",
      "trainer/Z Expert Predictions Mean    1422.3\n",
      "trainer/Z Expert Predictions Std       57.2174\n",
      "trainer/Z Expert Predictions Max     1495.23\n",
      "trainer/Z Expert Predictions Min     1091.81\n",
      "trainer/Z Policy Predictions Mean    1126.73\n",
      "trainer/Z Policy Predictions Std      554.798\n",
      "trainer/Z Policy Predictions Max     1482.24\n",
      "trainer/Z Policy Predictions Min     -453.244\n",
      "trainer/Z Expert Targets Mean        1405.27\n",
      "trainer/Z Expert Targets Std           51.9637\n",
      "trainer/Z Expert Targets Max         1474.83\n",
      "trainer/Z Expert Targets Min         1099.91\n",
      "trainer/Z Policy Targets Mean        1114.93\n",
      "trainer/Z Policy Targets Std          550.673\n",
      "trainer/Z Policy Targets Max         1471.53\n",
      "trainer/Z Policy Targets Min         -449.716\n",
      "trainer/Log Pis Mean                   19.7107\n",
      "trainer/Log Pis Std                     4.35368\n",
      "trainer/Policy mu Mean                  0.107731\n",
      "trainer/Policy mu Std                   1.22203\n",
      "trainer/Policy log std Mean            -3.04091\n",
      "trainer/Policy log std Std              1.02041\n",
      "trainer/Alpha                           0.0798155\n",
      "trainer/Alpha Loss                      0.0230898\n",
      "exploration/num steps total        102384\n",
      "exploration/num paths total           198\n",
      "evaluation/num steps total         753203\n",
      "evaluation/num paths total            997\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.03102\n",
      "evaluation/Rewards Std                  2.0907\n",
      "evaluation/Rewards Max                  6.73975\n",
      "evaluation/Rewards Min                 -3.73781\n",
      "evaluation/Returns Mean              4031.02\n",
      "evaluation/Returns Std               1792.66\n",
      "evaluation/Returns Max               4742.45\n",
      "evaluation/Returns Min              -1341.22\n",
      "evaluation/Estimation Bias Mean      1219.82\n",
      "evaluation/Estimation Bias Std        495.608\n",
      "evaluation/EB/Q_True Mean              40.9219\n",
      "evaluation/EB/Q_True Std              126.353\n",
      "evaluation/EB/Q_Pred Mean            1260.74\n",
      "evaluation/EB/Q_Pred Std              492.119\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4031.02\n",
      "evaluation/Actions Mean                 0.0231464\n",
      "evaluation/Actions Std                  0.568674\n",
      "evaluation/Actions Max                  0.999838\n",
      "evaluation/Actions Min                 -0.999973\n",
      "time/backward_policy (s)                1.73793\n",
      "time/backward_zf1 (s)                   1.84735\n",
      "time/backward_zf2 (s)                   1.79019\n",
      "time/data sampling (s)                  0.284326\n",
      "time/data storing (s)                   0.0140304\n",
      "time/evaluation sampling (s)            1.74105\n",
      "time/exploration sampling (s)           0.314672\n",
      "time/logging (s)                        0.0119044\n",
      "time/preback_alpha (s)                  0.878046\n",
      "time/preback_policy (s)                 0.961894\n",
      "time/preback_start (s)                  0.142811\n",
      "time/preback_zf (s)                     5.12955\n",
      "time/saving (s)                         0.00654118\n",
      "time/training (s)                       2.51648\n",
      "time/epoch (s)                         17.3768\n",
      "time/total (s)                       1701.17\n",
      "Epoch                                  95\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:20:50.250833 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 96 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 107000\n",
      "trainer/ZF1 Loss                       12.0786\n",
      "trainer/ZF2 Loss                       26.75\n",
      "trainer/ZF Expert Reward               15.2373\n",
      "trainer/ZF Policy Reward                5.51782\n",
      "trainer/ZF CHI2 Term                   49.1706\n",
      "trainer/Policy Loss                 -1121.06\n",
      "trainer/Bias Loss                      59.6072\n",
      "trainer/Bias Value                     13.891\n",
      "trainer/Policy Grad Norm              114.339\n",
      "trainer/Policy Param Norm              31.981\n",
      "trainer/Zf1 Grad Norm                3186.01\n",
      "trainer/Zf1 Param Norm                 89.0034\n",
      "trainer/Zf2 Grad Norm                7101.32\n",
      "trainer/Zf2 Param Norm                 89.7644\n",
      "trainer/Z Expert Predictions Mean    1418.28\n",
      "trainer/Z Expert Predictions Std       47.3636\n",
      "trainer/Z Expert Predictions Max     1479.65\n",
      "trainer/Z Expert Predictions Min     1134.04\n",
      "trainer/Z Policy Predictions Mean    1115.07\n",
      "trainer/Z Policy Predictions Std      541.365\n",
      "trainer/Z Policy Predictions Max     1464.91\n",
      "trainer/Z Policy Predictions Min     -442.651\n",
      "trainer/Z Expert Targets Mean        1403.05\n",
      "trainer/Z Expert Targets Std           48.7213\n",
      "trainer/Z Expert Targets Max         1467.34\n",
      "trainer/Z Expert Targets Min         1112.94\n",
      "trainer/Z Policy Targets Mean        1109.55\n",
      "trainer/Z Policy Targets Std          536.811\n",
      "trainer/Z Policy Targets Max         1453.9\n",
      "trainer/Z Policy Targets Min         -430.554\n",
      "trainer/Log Pis Mean                   20.2392\n",
      "trainer/Log Pis Std                     4.94312\n",
      "trainer/Policy mu Mean                  0.166485\n",
      "trainer/Policy mu Std                   1.35195\n",
      "trainer/Policy log std Mean            -2.99656\n",
      "trainer/Policy log std Std              1.08324\n",
      "trainer/Alpha                           0.079412\n",
      "trainer/Alpha Loss                     -0.0189973\n",
      "exploration/num steps total        102384\n",
      "exploration/num paths total           198\n",
      "evaluation/num steps total         762769\n",
      "evaluation/num paths total           1007\n",
      "evaluation/path length Mean           956.6\n",
      "evaluation/path length Std            130.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            566\n",
      "evaluation/Rewards Mean                 4.55482\n",
      "evaluation/Rewards Std                  1.21864\n",
      "evaluation/Rewards Max                  6.71115\n",
      "evaluation/Rewards Min                 -3.01507\n",
      "evaluation/Returns Mean              4357.14\n",
      "evaluation/Returns Std                624.336\n",
      "evaluation/Returns Max               4881.73\n",
      "evaluation/Returns Min               2622.4\n",
      "evaluation/Estimation Bias Mean      1336.45\n",
      "evaluation/Estimation Bias Std        211.481\n",
      "evaluation/EB/Q_True Mean              44.9428\n",
      "evaluation/EB/Q_True Std              135.416\n",
      "evaluation/EB/Q_Pred Mean            1381.4\n",
      "evaluation/EB/Q_Pred Std              163.007\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4357.14\n",
      "evaluation/Actions Mean                 0.0310272\n",
      "evaluation/Actions Std                  0.54365\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.91248\n",
      "time/backward_zf1 (s)                   2.04651\n",
      "time/backward_zf2 (s)                   1.9937\n",
      "time/data sampling (s)                  0.283803\n",
      "time/data storing (s)                   0.0151562\n",
      "time/evaluation sampling (s)            1.76184\n",
      "time/exploration sampling (s)           0.317631\n",
      "time/logging (s)                        0.012676\n",
      "time/preback_alpha (s)                  1.02466\n",
      "time/preback_policy (s)                 1.16294\n",
      "time/preback_start (s)                  0.143898\n",
      "time/preback_zf (s)                     5.16819\n",
      "time/saving (s)                         0.00627569\n",
      "time/training (s)                       2.08804\n",
      "time/epoch (s)                         17.9378\n",
      "time/total (s)                       1719.13\n",
      "Epoch                                  96\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:21:08.129282 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 97 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 108000\n",
      "trainer/ZF1 Loss                       15.1117\n",
      "trainer/ZF2 Loss                       12.5885\n",
      "trainer/ZF Expert Reward               14.8207\n",
      "trainer/ZF Policy Reward                3.37424\n",
      "trainer/ZF CHI2 Term                   44.9654\n",
      "trainer/Policy Loss                 -1201.63\n",
      "trainer/Bias Loss                      73.6288\n",
      "trainer/Bias Value                     13.8808\n",
      "trainer/Policy Grad Norm              128.4\n",
      "trainer/Policy Param Norm              32.0308\n",
      "trainer/Zf1 Grad Norm                2184.56\n",
      "trainer/Zf1 Param Norm                 89.2464\n",
      "trainer/Zf2 Grad Norm                1681.13\n",
      "trainer/Zf2 Param Norm                 89.9911\n",
      "trainer/Z Expert Predictions Mean    1408.86\n",
      "trainer/Z Expert Predictions Std       48.9527\n",
      "trainer/Z Expert Predictions Max     1475.69\n",
      "trainer/Z Expert Predictions Min     1133.79\n",
      "trainer/Z Policy Predictions Mean    1195.56\n",
      "trainer/Z Policy Predictions Std      424.505\n",
      "trainer/Z Policy Predictions Max     1467.47\n",
      "trainer/Z Policy Predictions Min     -446.173\n",
      "trainer/Z Expert Targets Mean        1394.04\n",
      "trainer/Z Expert Targets Std           48.2834\n",
      "trainer/Z Expert Targets Max         1457.45\n",
      "trainer/Z Expert Targets Min         1118.72\n",
      "trainer/Z Policy Targets Mean        1192.18\n",
      "trainer/Z Policy Targets Std          418.578\n",
      "trainer/Z Policy Targets Max         1461.25\n",
      "trainer/Z Policy Targets Min         -441.824\n",
      "trainer/Log Pis Mean                   19.8675\n",
      "trainer/Log Pis Std                     4.55432\n",
      "trainer/Policy mu Mean                  0.0697484\n",
      "trainer/Policy mu Std                   1.15771\n",
      "trainer/Policy log std Mean            -3.13198\n",
      "trainer/Policy log std Std              0.892985\n",
      "trainer/Alpha                           0.0795508\n",
      "trainer/Alpha Loss                      0.0105411\n",
      "exploration/num steps total        102651\n",
      "exploration/num paths total           199\n",
      "evaluation/num steps total         771828\n",
      "evaluation/num paths total           1017\n",
      "evaluation/path length Mean           905.9\n",
      "evaluation/path length Std            282.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             59\n",
      "evaluation/Rewards Mean                 4.65832\n",
      "evaluation/Rewards Std                  1.02868\n",
      "evaluation/Rewards Max                  6.63247\n",
      "evaluation/Rewards Min                 -1.82511\n",
      "evaluation/Returns Mean              4219.97\n",
      "evaluation/Returns Std               1361.1\n",
      "evaluation/Returns Max               4828.96\n",
      "evaluation/Returns Min                150.011\n",
      "evaluation/Estimation Bias Mean      1336.2\n",
      "evaluation/Estimation Bias Std        150.394\n",
      "evaluation/EB/Q_True Mean              46.3518\n",
      "evaluation/EB/Q_True Std              135.068\n",
      "evaluation/EB/Q_Pred Mean            1382.55\n",
      "evaluation/EB/Q_Pred Std               65.3277\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4219.97\n",
      "evaluation/Actions Mean                 0.023674\n",
      "evaluation/Actions Std                  0.536608\n",
      "evaluation/Actions Max                  0.998302\n",
      "evaluation/Actions Min                 -0.999047\n",
      "time/backward_policy (s)                1.91205\n",
      "time/backward_zf1 (s)                   2.03149\n",
      "time/backward_zf2 (s)                   1.98418\n",
      "time/data sampling (s)                  0.264185\n",
      "time/data storing (s)                   0.0142565\n",
      "time/evaluation sampling (s)            1.75997\n",
      "time/exploration sampling (s)           0.312796\n",
      "time/logging (s)                        0.0111219\n",
      "time/preback_alpha (s)                  1.00832\n",
      "time/preback_policy (s)                 1.14258\n",
      "time/preback_start (s)                  0.140417\n",
      "time/preback_zf (s)                     5.14401\n",
      "time/saving (s)                         0.00598234\n",
      "time/training (s)                       2.07956\n",
      "time/epoch (s)                         17.8109\n",
      "time/total (s)                       1736.97\n",
      "Epoch                                  97\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:21:26.234215 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 98 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 109000\n",
      "trainer/ZF1 Loss                       37.6243\n",
      "trainer/ZF2 Loss                       17.8602\n",
      "trainer/ZF Expert Reward                8.04154\n",
      "trainer/ZF Policy Reward               -0.824784\n",
      "trainer/ZF CHI2 Term                   56.4669\n",
      "trainer/Policy Loss                 -1139.53\n",
      "trainer/Bias Loss                     228.314\n",
      "trainer/Bias Value                     13.8712\n",
      "trainer/Policy Grad Norm               85.2188\n",
      "trainer/Policy Param Norm              32.0837\n",
      "trainer/Zf1 Grad Norm               14665.9\n",
      "trainer/Zf1 Param Norm                 89.473\n",
      "trainer/Zf2 Grad Norm                7183.21\n",
      "trainer/Zf2 Param Norm                 90.2129\n",
      "trainer/Z Expert Predictions Mean    1394.86\n",
      "trainer/Z Expert Predictions Std       87.9255\n",
      "trainer/Z Expert Predictions Max     1465.77\n",
      "trainer/Z Expert Predictions Min      181.785\n",
      "trainer/Z Policy Predictions Mean    1131.2\n",
      "trainer/Z Policy Predictions Std      496.311\n",
      "trainer/Z Policy Predictions Max     1466.54\n",
      "trainer/Z Policy Predictions Min     -487.288\n",
      "trainer/Z Expert Targets Mean        1386.82\n",
      "trainer/Z Expert Targets Std           97.5794\n",
      "trainer/Z Expert Targets Max         1461.14\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1132.02\n",
      "trainer/Z Policy Targets Std          491.775\n",
      "trainer/Z Policy Targets Max         1444.02\n",
      "trainer/Z Policy Targets Min         -479.232\n",
      "trainer/Log Pis Mean                   20.0589\n",
      "trainer/Log Pis Std                     4.86733\n",
      "trainer/Policy mu Mean                  0.0501371\n",
      "trainer/Policy mu Std                   1.19978\n",
      "trainer/Policy log std Mean            -3.04689\n",
      "trainer/Policy log std Std              0.965669\n",
      "trainer/Alpha                           0.0805183\n",
      "trainer/Alpha Loss                     -0.00473939\n",
      "exploration/num steps total        103651\n",
      "exploration/num paths total           200\n",
      "evaluation/num steps total         781223\n",
      "evaluation/num paths total           1027\n",
      "evaluation/path length Mean           939.5\n",
      "evaluation/path length Std            181.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            395\n",
      "evaluation/Rewards Mean                 4.67397\n",
      "evaluation/Rewards Std                  1.04134\n",
      "evaluation/Rewards Max                  6.8593\n",
      "evaluation/Rewards Min                 -1.72277\n",
      "evaluation/Returns Mean              4391.2\n",
      "evaluation/Returns Std                871.752\n",
      "evaluation/Returns Max               4818.46\n",
      "evaluation/Returns Min               1790.11\n",
      "evaluation/Estimation Bias Mean      1336.2\n",
      "evaluation/Estimation Bias Std        150.896\n",
      "evaluation/EB/Q_True Mean              44.6275\n",
      "evaluation/EB/Q_True Std              132.688\n",
      "evaluation/EB/Q_Pred Mean            1380.83\n",
      "evaluation/EB/Q_Pred Std               63.2668\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4391.2\n",
      "evaluation/Actions Mean                 0.0217536\n",
      "evaluation/Actions Std                  0.542882\n",
      "evaluation/Actions Max                  0.997769\n",
      "evaluation/Actions Min                 -0.998765\n",
      "time/backward_policy (s)                1.91775\n",
      "time/backward_zf1 (s)                   2.05909\n",
      "time/backward_zf2 (s)                   2.00032\n",
      "time/data sampling (s)                  0.291475\n",
      "time/data storing (s)                   0.0149054\n",
      "time/evaluation sampling (s)            1.76641\n",
      "time/exploration sampling (s)           0.322255\n",
      "time/logging (s)                        0.0115771\n",
      "time/preback_alpha (s)                  1.03163\n",
      "time/preback_policy (s)                 1.16216\n",
      "time/preback_start (s)                  0.144917\n",
      "time/preback_zf (s)                     5.19252\n",
      "time/saving (s)                         0.00696566\n",
      "time/training (s)                       2.11025\n",
      "time/epoch (s)                         18.0322\n",
      "time/total (s)                       1755.02\n",
      "Epoch                                  98\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:21:43.850024 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 99 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 110000\n",
      "trainer/ZF1 Loss                       14.789\n",
      "trainer/ZF2 Loss                       25.8854\n",
      "trainer/ZF Expert Reward                6.67765\n",
      "trainer/ZF Policy Reward               -0.688709\n",
      "trainer/ZF CHI2 Term                   47.0769\n",
      "trainer/Policy Loss                 -1168.39\n",
      "trainer/Bias Loss                     104.074\n",
      "trainer/Bias Value                     13.8615\n",
      "trainer/Policy Grad Norm              112.194\n",
      "trainer/Policy Param Norm              32.138\n",
      "trainer/Zf1 Grad Norm                2636.6\n",
      "trainer/Zf1 Param Norm                 89.6957\n",
      "trainer/Zf2 Grad Norm                2686.49\n",
      "trainer/Zf2 Param Norm                 90.4269\n",
      "trainer/Z Expert Predictions Mean    1385.8\n",
      "trainer/Z Expert Predictions Std      102.792\n",
      "trainer/Z Expert Predictions Max     1451.35\n",
      "trainer/Z Expert Predictions Min      -84.6976\n",
      "trainer/Z Policy Predictions Mean    1158.22\n",
      "trainer/Z Policy Predictions Std      470.486\n",
      "trainer/Z Policy Predictions Max     1452.36\n",
      "trainer/Z Policy Predictions Min     -462.411\n",
      "trainer/Z Expert Targets Mean        1379.12\n",
      "trainer/Z Expert Targets Std           98.338\n",
      "trainer/Z Expert Targets Max         1447.79\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1158.91\n",
      "trainer/Z Policy Targets Std          463.132\n",
      "trainer/Z Policy Targets Max         1441.15\n",
      "trainer/Z Policy Targets Min         -453.23\n",
      "trainer/Log Pis Mean                   19.5691\n",
      "trainer/Log Pis Std                     4.71066\n",
      "trainer/Policy mu Mean                  0.0967911\n",
      "trainer/Policy mu Std                   1.16583\n",
      "trainer/Policy log std Mean            -3.07329\n",
      "trainer/Policy log std Std              0.929355\n",
      "trainer/Alpha                           0.0819961\n",
      "trainer/Alpha Loss                      0.0353315\n",
      "exploration/num steps total        104651\n",
      "exploration/num paths total           201\n",
      "evaluation/num steps total         790936\n",
      "evaluation/num paths total           1038\n",
      "evaluation/path length Mean           883\n",
      "evaluation/path length Std            277.765\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             29\n",
      "evaluation/Rewards Mean                 3.95935\n",
      "evaluation/Rewards Std                  2.21459\n",
      "evaluation/Rewards Max                  6.66098\n",
      "evaluation/Rewards Min                 -2.99897\n",
      "evaluation/Returns Mean              3496.1\n",
      "evaluation/Returns Std               2140.91\n",
      "evaluation/Returns Max               4759.75\n",
      "evaluation/Returns Min              -1863.12\n",
      "evaluation/Estimation Bias Mean      1173.04\n",
      "evaluation/Estimation Bias Std        479.916\n",
      "evaluation/EB/Q_True Mean              42.9587\n",
      "evaluation/EB/Q_True Std              130.734\n",
      "evaluation/EB/Q_Pred Mean            1216\n",
      "evaluation/EB/Q_Pred Std              474.892\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3496.1\n",
      "evaluation/Actions Mean                 0.0725712\n",
      "evaluation/Actions Std                  0.576029\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999349\n",
      "time/backward_policy (s)                1.82857\n",
      "time/backward_zf1 (s)                   1.94167\n",
      "time/backward_zf2 (s)                   1.8822\n",
      "time/data sampling (s)                  0.282687\n",
      "time/data storing (s)                   0.0142836\n",
      "time/evaluation sampling (s)            1.73705\n",
      "time/exploration sampling (s)           0.317363\n",
      "time/logging (s)                        0.0125004\n",
      "time/preback_alpha (s)                  0.962902\n",
      "time/preback_policy (s)                 1.07838\n",
      "time/preback_start (s)                  0.142692\n",
      "time/preback_zf (s)                     5.13074\n",
      "time/saving (s)                         0.00630755\n",
      "time/training (s)                       2.21155\n",
      "time/epoch (s)                         17.5489\n",
      "time/total (s)                       1772.59\n",
      "Epoch                                  99\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:22:01.357355 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 100 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 111000\n",
      "trainer/ZF1 Loss                        4.48314\n",
      "trainer/ZF2 Loss                        3.55316\n",
      "trainer/ZF Expert Reward               12.0214\n",
      "trainer/ZF Policy Reward                2.02151\n",
      "trainer/ZF CHI2 Term                   33.9006\n",
      "trainer/Policy Loss                 -1151.24\n",
      "trainer/Bias Loss                      60.6619\n",
      "trainer/Bias Value                     13.855\n",
      "trainer/Policy Grad Norm              121.669\n",
      "trainer/Policy Param Norm              32.1806\n",
      "trainer/Zf1 Grad Norm                1373.09\n",
      "trainer/Zf1 Param Norm                 89.9423\n",
      "trainer/Zf2 Grad Norm                1230.79\n",
      "trainer/Zf2 Param Norm                 90.6412\n",
      "trainer/Z Expert Predictions Mean    1383.59\n",
      "trainer/Z Expert Predictions Std       50.6941\n",
      "trainer/Z Expert Predictions Max     1452.48\n",
      "trainer/Z Expert Predictions Min     1123.12\n",
      "trainer/Z Policy Predictions Mean    1147.4\n",
      "trainer/Z Policy Predictions Std      458.169\n",
      "trainer/Z Policy Predictions Max     1445.72\n",
      "trainer/Z Policy Predictions Min     -452.67\n",
      "trainer/Z Expert Targets Mean        1371.57\n",
      "trainer/Z Expert Targets Std           50.3932\n",
      "trainer/Z Expert Targets Max         1436.34\n",
      "trainer/Z Expert Targets Min         1110.16\n",
      "trainer/Z Policy Targets Mean        1145.38\n",
      "trainer/Z Policy Targets Std          452.899\n",
      "trainer/Z Policy Targets Max         1437.94\n",
      "trainer/Z Policy Targets Min         -455.98\n",
      "trainer/Log Pis Mean                   20.0834\n",
      "trainer/Log Pis Std                     4.46123\n",
      "trainer/Policy mu Mean                  0.0750989\n",
      "trainer/Policy mu Std                   1.19147\n",
      "trainer/Policy log std Mean            -3.09692\n",
      "trainer/Policy log std Std              0.956446\n",
      "trainer/Alpha                           0.0830363\n",
      "trainer/Alpha Loss                     -0.00692397\n",
      "exploration/num steps total        106651\n",
      "exploration/num paths total           203\n",
      "evaluation/num steps total         800936\n",
      "evaluation/num paths total           1048\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66408\n",
      "evaluation/Rewards Std                  1.00816\n",
      "evaluation/Rewards Max                  6.81024\n",
      "evaluation/Rewards Min                 -1.73433\n",
      "evaluation/Returns Mean              4664.08\n",
      "evaluation/Returns Std                 92.1627\n",
      "evaluation/Returns Max               4805\n",
      "evaluation/Returns Min               4457.81\n",
      "evaluation/Estimation Bias Mean      1327.54\n",
      "evaluation/Estimation Bias Std        145.058\n",
      "evaluation/EB/Q_True Mean              43.2233\n",
      "evaluation/EB/Q_True Std              133.263\n",
      "evaluation/EB/Q_Pred Mean            1370.76\n",
      "evaluation/EB/Q_Pred Std               56.7876\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4664.08\n",
      "evaluation/Actions Mean                 0.0247497\n",
      "evaluation/Actions Std                  0.532879\n",
      "evaluation/Actions Max                  0.997856\n",
      "evaluation/Actions Min                 -0.998845\n",
      "time/backward_policy (s)                1.75872\n",
      "time/backward_zf1 (s)                   1.88552\n",
      "time/backward_zf2 (s)                   1.81288\n",
      "time/data sampling (s)                  0.281258\n",
      "time/data storing (s)                   0.0145903\n",
      "time/evaluation sampling (s)            1.74688\n",
      "time/exploration sampling (s)           0.321541\n",
      "time/logging (s)                        0.0124573\n",
      "time/preback_alpha (s)                  0.886681\n",
      "time/preback_policy (s)                 0.972187\n",
      "time/preback_start (s)                  0.142098\n",
      "time/preback_zf (s)                     5.11659\n",
      "time/saving (s)                         0.0064962\n",
      "time/training (s)                       2.48054\n",
      "time/epoch (s)                         17.4384\n",
      "time/total (s)                       1790.05\n",
      "Epoch                                 100\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:22:19.155197 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 101 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 112000\n",
      "trainer/ZF1 Loss                       29.2847\n",
      "trainer/ZF2 Loss                       18.5344\n",
      "trainer/ZF Expert Reward               18.0814\n",
      "trainer/ZF Policy Reward                4.10054\n",
      "trainer/ZF CHI2 Term                   57.586\n",
      "trainer/Policy Loss                 -1134.46\n",
      "trainer/Bias Loss                     155.045\n",
      "trainer/Bias Value                     13.8442\n",
      "trainer/Policy Grad Norm               95.8962\n",
      "trainer/Policy Param Norm              32.2264\n",
      "trainer/Zf1 Grad Norm                1273.52\n",
      "trainer/Zf1 Param Norm                 90.19\n",
      "trainer/Zf2 Grad Norm                1673.65\n",
      "trainer/Zf2 Param Norm                 90.8819\n",
      "trainer/Z Expert Predictions Mean    1386.95\n",
      "trainer/Z Expert Predictions Std       43.142\n",
      "trainer/Z Expert Predictions Max     1440.86\n",
      "trainer/Z Expert Predictions Min     1119.84\n",
      "trainer/Z Policy Predictions Mean    1130.06\n",
      "trainer/Z Policy Predictions Std      496.4\n",
      "trainer/Z Policy Predictions Max     1421.36\n",
      "trainer/Z Policy Predictions Min     -455.124\n",
      "trainer/Z Expert Targets Mean        1368.87\n",
      "trainer/Z Expert Targets Std           45.5917\n",
      "trainer/Z Expert Targets Max         1431.87\n",
      "trainer/Z Expert Targets Min         1095.63\n",
      "trainer/Z Policy Targets Mean        1125.96\n",
      "trainer/Z Policy Targets Std          490.501\n",
      "trainer/Z Policy Targets Max         1416.66\n",
      "trainer/Z Policy Targets Min         -457.084\n",
      "trainer/Log Pis Mean                   19.8945\n",
      "trainer/Log Pis Std                     4.75112\n",
      "trainer/Policy mu Mean                  0.128104\n",
      "trainer/Policy mu Std                   1.22991\n",
      "trainer/Policy log std Mean            -3.0155\n",
      "trainer/Policy log std Std              1.04199\n",
      "trainer/Alpha                           0.0834637\n",
      "trainer/Alpha Loss                      0.00880183\n",
      "exploration/num steps total        106651\n",
      "exploration/num paths total           203\n",
      "evaluation/num steps total         808694\n",
      "evaluation/num paths total           1060\n",
      "evaluation/path length Mean           646.5\n",
      "evaluation/path length Std            391.985\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             32\n",
      "evaluation/Rewards Mean                 4.47707\n",
      "evaluation/Rewards Std                  1.21511\n",
      "evaluation/Rewards Max                  6.703\n",
      "evaluation/Rewards Min                 -1.86965\n",
      "evaluation/Returns Mean              2894.43\n",
      "evaluation/Returns Std               1835.76\n",
      "evaluation/Returns Max               4792.94\n",
      "evaluation/Returns Min                 37.9813\n",
      "evaluation/Estimation Bias Mean      1274.99\n",
      "evaluation/Estimation Bias Std        180.681\n",
      "evaluation/EB/Q_True Mean              56.6956\n",
      "evaluation/EB/Q_True Std              151.219\n",
      "evaluation/EB/Q_Pred Mean            1331.69\n",
      "evaluation/EB/Q_Pred Std               89.3441\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2894.43\n",
      "evaluation/Actions Mean                 0.0246424\n",
      "evaluation/Actions Std                  0.529997\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999551\n",
      "time/backward_policy (s)                1.90677\n",
      "time/backward_zf1 (s)                   2.01573\n",
      "time/backward_zf2 (s)                   1.96988\n",
      "time/data sampling (s)                  0.274275\n",
      "time/data storing (s)                   0.0140961\n",
      "time/evaluation sampling (s)            1.77164\n",
      "time/exploration sampling (s)           0.314088\n",
      "time/logging (s)                        0.0096081\n",
      "time/preback_alpha (s)                  0.992439\n",
      "time/preback_policy (s)                 1.12229\n",
      "time/preback_start (s)                  0.139785\n",
      "time/preback_zf (s)                     5.1175\n",
      "time/saving (s)                         0.00609966\n",
      "time/training (s)                       2.06918\n",
      "time/epoch (s)                         17.7234\n",
      "time/total (s)                       1807.8\n",
      "Epoch                                 101\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:22:37.146682 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 102 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 113000\n",
      "trainer/ZF1 Loss                       11.3096\n",
      "trainer/ZF2 Loss                       10.2529\n",
      "trainer/ZF Expert Reward                9.36161\n",
      "trainer/ZF Policy Reward               -0.138804\n",
      "trainer/ZF CHI2 Term                   41.1123\n",
      "trainer/Policy Loss                 -1121.73\n",
      "trainer/Bias Loss                      74.0358\n",
      "trainer/Bias Value                     13.8343\n",
      "trainer/Policy Grad Norm              190.406\n",
      "trainer/Policy Param Norm              32.2707\n",
      "trainer/Zf1 Grad Norm                1552.26\n",
      "trainer/Zf1 Param Norm                 90.4281\n",
      "trainer/Zf2 Grad Norm                1693.05\n",
      "trainer/Zf2 Param Norm                 91.1015\n",
      "trainer/Z Expert Predictions Mean    1363.78\n",
      "trainer/Z Expert Predictions Std       51.9041\n",
      "trainer/Z Expert Predictions Max     1424.23\n",
      "trainer/Z Expert Predictions Min     1114.2\n",
      "trainer/Z Policy Predictions Mean    1115.83\n",
      "trainer/Z Policy Predictions Std      500.805\n",
      "trainer/Z Policy Predictions Max     1419.58\n",
      "trainer/Z Policy Predictions Min     -480.385\n",
      "trainer/Z Expert Targets Mean        1354.42\n",
      "trainer/Z Expert Targets Std           53.149\n",
      "trainer/Z Expert Targets Max         1419.37\n",
      "trainer/Z Expert Targets Min         1098.25\n",
      "trainer/Z Policy Targets Mean        1115.97\n",
      "trainer/Z Policy Targets Std          495.944\n",
      "trainer/Z Policy Targets Max         1422.68\n",
      "trainer/Z Policy Targets Min         -457.576\n",
      "trainer/Log Pis Mean                   21.041\n",
      "trainer/Log Pis Std                     4.96901\n",
      "trainer/Policy mu Mean                  0.150167\n",
      "trainer/Policy mu Std                   1.41885\n",
      "trainer/Policy log std Mean            -3.02051\n",
      "trainer/Policy log std Std              1.04095\n",
      "trainer/Alpha                           0.0827079\n",
      "trainer/Alpha Loss                     -0.0860966\n",
      "exploration/num steps total        108651\n",
      "exploration/num paths total           205\n",
      "evaluation/num steps total         817221\n",
      "evaluation/num paths total           1070\n",
      "evaluation/path length Mean           852.7\n",
      "evaluation/path length Std            306.424\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             75\n",
      "evaluation/Rewards Mean                 4.52884\n",
      "evaluation/Rewards Std                  1.17612\n",
      "evaluation/Rewards Max                  6.6877\n",
      "evaluation/Rewards Min                 -1.76888\n",
      "evaluation/Returns Mean              3861.74\n",
      "evaluation/Returns Std               1437.53\n",
      "evaluation/Returns Max               4806.79\n",
      "evaluation/Returns Min                193.46\n",
      "evaluation/Estimation Bias Mean      1282.55\n",
      "evaluation/Estimation Bias Std        158.482\n",
      "evaluation/EB/Q_True Mean              48.5548\n",
      "evaluation/EB/Q_True Std              136.854\n",
      "evaluation/EB/Q_Pred Mean            1331.1\n",
      "evaluation/EB/Q_Pred Std               76.4161\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3861.74\n",
      "evaluation/Actions Mean                 0.0208052\n",
      "evaluation/Actions Std                  0.533786\n",
      "evaluation/Actions Max                  0.999898\n",
      "evaluation/Actions Min                 -0.999769\n",
      "time/backward_policy (s)                1.93936\n",
      "time/backward_zf1 (s)                   2.04853\n",
      "time/backward_zf2 (s)                   2.00588\n",
      "time/data sampling (s)                  0.272856\n",
      "time/data storing (s)                   0.0143619\n",
      "time/evaluation sampling (s)            1.81426\n",
      "time/exploration sampling (s)           0.320696\n",
      "time/logging (s)                        0.011882\n",
      "time/preback_alpha (s)                  1.03791\n",
      "time/preback_policy (s)                 1.17857\n",
      "time/preback_start (s)                  0.14297\n",
      "time/preback_zf (s)                     5.12571\n",
      "time/saving (s)                         0.0216153\n",
      "time/training (s)                       1.9948\n",
      "time/epoch (s)                         17.9294\n",
      "time/total (s)                       1825.75\n",
      "Epoch                                 102\n",
      "---------------------------------  --------------\n",
      "2024-06-15 11:22:55.202490 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 103 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 114000\n",
      "trainer/ZF1 Loss                      377.422\n",
      "trainer/ZF2 Loss                      352.154\n",
      "trainer/ZF Expert Reward               11.6504\n",
      "trainer/ZF Policy Reward                6.4045\n",
      "trainer/ZF CHI2 Term                  389.921\n",
      "trainer/Policy Loss                 -1170.32\n",
      "trainer/Bias Loss                      53.0609\n",
      "trainer/Bias Value                     13.8221\n",
      "trainer/Policy Grad Norm              135.17\n",
      "trainer/Policy Param Norm              32.3164\n",
      "trainer/Zf1 Grad Norm                5078.14\n",
      "trainer/Zf1 Param Norm                 90.6759\n",
      "trainer/Zf2 Grad Norm                3301.49\n",
      "trainer/Zf2 Param Norm                 91.3331\n",
      "trainer/Z Expert Predictions Mean    1361.52\n",
      "trainer/Z Expert Predictions Std       49.0184\n",
      "trainer/Z Expert Predictions Max     1432.47\n",
      "trainer/Z Expert Predictions Min     1068.47\n",
      "trainer/Z Policy Predictions Mean    1165.74\n",
      "trainer/Z Policy Predictions Std      421.648\n",
      "trainer/Z Policy Predictions Max     1429.66\n",
      "trainer/Z Policy Predictions Min     -489.556\n",
      "trainer/Z Expert Targets Mean        1349.87\n",
      "trainer/Z Expert Targets Std           49.0178\n",
      "trainer/Z Expert Targets Max         1412.56\n",
      "trainer/Z Expert Targets Min         1035.17\n",
      "trainer/Z Policy Targets Mean        1159.34\n",
      "trainer/Z Policy Targets Std          421.994\n",
      "trainer/Z Policy Targets Max         1416.39\n",
      "trainer/Z Policy Targets Min         -464.963\n",
      "trainer/Log Pis Mean                   20.0879\n",
      "trainer/Log Pis Std                     4.01063\n",
      "trainer/Policy mu Mean                  0.0893731\n",
      "trainer/Policy mu Std                   1.11305\n",
      "trainer/Policy log std Mean            -3.1912\n",
      "trainer/Policy log std Std              0.872726\n",
      "trainer/Alpha                           0.0834167\n",
      "trainer/Alpha Loss                     -0.00733285\n",
      "exploration/num steps total        108651\n",
      "exploration/num paths total           205\n",
      "evaluation/num steps total         827221\n",
      "evaluation/num paths total           1080\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.57889\n",
      "evaluation/Rewards Std                  0.99461\n",
      "evaluation/Rewards Max                  6.91252\n",
      "evaluation/Rewards Min                 -1.50235\n",
      "evaluation/Returns Mean              4578.89\n",
      "evaluation/Returns Std                 60.2949\n",
      "evaluation/Returns Max               4658.11\n",
      "evaluation/Returns Min               4493.52\n",
      "evaluation/Estimation Bias Mean      1305.57\n",
      "evaluation/Estimation Bias Std        142.654\n",
      "evaluation/EB/Q_True Mean              42.2038\n",
      "evaluation/EB/Q_True Std              130.325\n",
      "evaluation/EB/Q_Pred Mean            1347.78\n",
      "evaluation/EB/Q_Pred Std               56.0198\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4578.89\n",
      "evaluation/Actions Mean                 0.0219631\n",
      "evaluation/Actions Std                  0.543267\n",
      "evaluation/Actions Max                  0.998386\n",
      "evaluation/Actions Min                 -0.998925\n",
      "time/backward_policy (s)                1.929\n",
      "time/backward_zf1 (s)                   2.05253\n",
      "time/backward_zf2 (s)                   2.01224\n",
      "time/data sampling (s)                  0.289919\n",
      "time/data storing (s)                   0.0145309\n",
      "time/evaluation sampling (s)            1.80647\n",
      "time/exploration sampling (s)           0.316662\n",
      "time/logging (s)                        0.0132435\n",
      "time/preback_alpha (s)                  1.03761\n",
      "time/preback_policy (s)                 1.18429\n",
      "time/preback_start (s)                  0.143019\n",
      "time/preback_zf (s)                     5.15268\n",
      "time/saving (s)                         0.0066611\n",
      "time/training (s)                       2.03354\n",
      "time/epoch (s)                         17.9924\n",
      "time/total (s)                       1843.76\n",
      "Epoch                                 103\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:23:12.618631 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 104 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 115000\n",
      "trainer/ZF1 Loss                        7.71606\n",
      "trainer/ZF2 Loss                       -1.35478\n",
      "trainer/ZF Expert Reward               13.49\n",
      "trainer/ZF Policy Reward                3.80364\n",
      "trainer/ZF CHI2 Term                   32.9412\n",
      "trainer/Policy Loss                 -1138.15\n",
      "trainer/Bias Loss                      57.6191\n",
      "trainer/Bias Value                     13.8113\n",
      "trainer/Policy Grad Norm              111.311\n",
      "trainer/Policy Param Norm              32.3639\n",
      "trainer/Zf1 Grad Norm                1204.54\n",
      "trainer/Zf1 Param Norm                 90.9181\n",
      "trainer/Zf2 Grad Norm                1006.47\n",
      "trainer/Zf2 Param Norm                 91.5486\n",
      "trainer/Z Expert Predictions Mean    1357.87\n",
      "trainer/Z Expert Predictions Std       39.4248\n",
      "trainer/Z Expert Predictions Max     1420.67\n",
      "trainer/Z Expert Predictions Min     1084.62\n",
      "trainer/Z Policy Predictions Mean    1128.52\n",
      "trainer/Z Policy Predictions Std      464.992\n",
      "trainer/Z Policy Predictions Max     1407.65\n",
      "trainer/Z Policy Predictions Min     -481.608\n",
      "trainer/Z Expert Targets Mean        1344.38\n",
      "trainer/Z Expert Targets Std           41.1526\n",
      "trainer/Z Expert Targets Max         1408.47\n",
      "trainer/Z Expert Targets Min         1067\n",
      "trainer/Z Policy Targets Mean        1124.72\n",
      "trainer/Z Policy Targets Std          458.774\n",
      "trainer/Z Policy Targets Max         1399.69\n",
      "trainer/Z Policy Targets Min         -480.743\n",
      "trainer/Log Pis Mean                   20.277\n",
      "trainer/Log Pis Std                     4.08351\n",
      "trainer/Policy mu Mean                  0.0723073\n",
      "trainer/Policy mu Std                   1.26703\n",
      "trainer/Policy log std Mean            -3.06721\n",
      "trainer/Policy log std Std              0.990292\n",
      "trainer/Alpha                           0.0843764\n",
      "trainer/Alpha Loss                     -0.02337\n",
      "exploration/num steps total        109651\n",
      "exploration/num paths total           206\n",
      "evaluation/num steps total         837019\n",
      "evaluation/num paths total           1090\n",
      "evaluation/path length Mean           979.8\n",
      "evaluation/path length Std             60.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            798\n",
      "evaluation/Rewards Mean                 4.19676\n",
      "evaluation/Rewards Std                  1.94933\n",
      "evaluation/Rewards Max                  6.86259\n",
      "evaluation/Rewards Min                 -2.81924\n",
      "evaluation/Returns Mean              4111.99\n",
      "evaluation/Returns Std               1262.36\n",
      "evaluation/Returns Max               4885.41\n",
      "evaluation/Returns Min                447.502\n",
      "evaluation/Estimation Bias Mean      1190.88\n",
      "evaluation/Estimation Bias Std        422.145\n",
      "evaluation/EB/Q_True Mean              44.0864\n",
      "evaluation/EB/Q_True Std              134.104\n",
      "evaluation/EB/Q_Pred Mean            1234.97\n",
      "evaluation/EB/Q_Pred Std              409.922\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4111.99\n",
      "evaluation/Actions Mean                 0.064197\n",
      "evaluation/Actions Std                  0.559508\n",
      "evaluation/Actions Max                  0.999944\n",
      "evaluation/Actions Min                 -0.999974\n",
      "time/backward_policy (s)                1.73066\n",
      "time/backward_zf1 (s)                   1.84188\n",
      "time/backward_zf2 (s)                   1.78069\n",
      "time/data sampling (s)                  0.27579\n",
      "time/data storing (s)                   0.0145286\n",
      "time/evaluation sampling (s)            1.75161\n",
      "time/exploration sampling (s)           0.317827\n",
      "time/logging (s)                        0.0117725\n",
      "time/preback_alpha (s)                  0.883238\n",
      "time/preback_policy (s)                 0.966301\n",
      "time/preback_start (s)                  0.14167\n",
      "time/preback_zf (s)                     5.14464\n",
      "time/saving (s)                         0.00629477\n",
      "time/training (s)                       2.475\n",
      "time/epoch (s)                         17.3419\n",
      "time/total (s)                       1861.13\n",
      "Epoch                                 104\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:23:30.503469 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 105 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 116000\n",
      "trainer/ZF1 Loss                       12.7998\n",
      "trainer/ZF2 Loss                       12.3739\n",
      "trainer/ZF Expert Reward               15.2867\n",
      "trainer/ZF Policy Reward                5.86334\n",
      "trainer/ZF CHI2 Term                   41.7411\n",
      "trainer/Policy Loss                 -1114.45\n",
      "trainer/Bias Loss                      79.2213\n",
      "trainer/Bias Value                     13.804\n",
      "trainer/Policy Grad Norm              115.721\n",
      "trainer/Policy Param Norm              32.4165\n",
      "trainer/Zf1 Grad Norm                1991.62\n",
      "trainer/Zf1 Param Norm                 91.1356\n",
      "trainer/Zf2 Grad Norm                2236.67\n",
      "trainer/Zf2 Param Norm                 91.7567\n",
      "trainer/Z Expert Predictions Mean    1342.03\n",
      "trainer/Z Expert Predictions Std      100.655\n",
      "trainer/Z Expert Predictions Max     1414.13\n",
      "trainer/Z Expert Predictions Min       32.2456\n",
      "trainer/Z Policy Predictions Mean    1111.11\n",
      "trainer/Z Policy Predictions Std      481.362\n",
      "trainer/Z Policy Predictions Max     1405.25\n",
      "trainer/Z Policy Predictions Min     -485.617\n",
      "trainer/Z Expert Targets Mean        1326.74\n",
      "trainer/Z Expert Targets Std          102.792\n",
      "trainer/Z Expert Targets Max         1398.08\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1105.25\n",
      "trainer/Z Policy Targets Std          476.678\n",
      "trainer/Z Policy Targets Max         1391.55\n",
      "trainer/Z Policy Targets Min         -489.284\n",
      "trainer/Log Pis Mean                   19.9301\n",
      "trainer/Log Pis Std                     4.55496\n",
      "trainer/Policy mu Mean                  0.136051\n",
      "trainer/Policy mu Std                   1.24511\n",
      "trainer/Policy log std Mean            -3.05506\n",
      "trainer/Policy log std Std              0.96986\n",
      "trainer/Alpha                           0.084945\n",
      "trainer/Alpha Loss                      0.00593374\n",
      "exploration/num steps total        111651\n",
      "exploration/num paths total           208\n",
      "evaluation/num steps total         846892\n",
      "evaluation/num paths total           1100\n",
      "evaluation/path length Mean           987.3\n",
      "evaluation/path length Std             38.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            873\n",
      "evaluation/Rewards Mean                 4.60541\n",
      "evaluation/Rewards Std                  1.0338\n",
      "evaluation/Rewards Max                  6.63029\n",
      "evaluation/Rewards Min                 -1.57505\n",
      "evaluation/Returns Mean              4546.92\n",
      "evaluation/Returns Std                192.934\n",
      "evaluation/Returns Max               4741.24\n",
      "evaluation/Returns Min               4059.44\n",
      "evaluation/Estimation Bias Mean      1280.98\n",
      "evaluation/Estimation Bias Std        149.813\n",
      "evaluation/EB/Q_True Mean              44.3844\n",
      "evaluation/EB/Q_True Std              135.921\n",
      "evaluation/EB/Q_Pred Mean            1325.36\n",
      "evaluation/EB/Q_Pred Std               62.8693\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4546.92\n",
      "evaluation/Actions Mean                 0.028813\n",
      "evaluation/Actions Std                  0.536908\n",
      "evaluation/Actions Max                  0.998114\n",
      "evaluation/Actions Min                 -0.999227\n",
      "time/backward_policy (s)                1.80167\n",
      "time/backward_zf1 (s)                   1.93446\n",
      "time/backward_zf2 (s)                   1.86394\n",
      "time/data sampling (s)                  0.288011\n",
      "time/data storing (s)                   0.0154141\n",
      "time/evaluation sampling (s)            1.79747\n",
      "time/exploration sampling (s)           0.325792\n",
      "time/logging (s)                        0.0121337\n",
      "time/preback_alpha (s)                  0.933229\n",
      "time/preback_policy (s)                 1.0214\n",
      "time/preback_start (s)                  0.14655\n",
      "time/preback_zf (s)                     5.21191\n",
      "time/saving (s)                         0.00626663\n",
      "time/training (s)                       2.45886\n",
      "time/epoch (s)                         17.8171\n",
      "time/total (s)                       1878.97\n",
      "Epoch                                 105\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:23:47.862529 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 106 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 117000\n",
      "trainer/ZF1 Loss                       15.9856\n",
      "trainer/ZF2 Loss                       26.4452\n",
      "trainer/ZF Expert Reward               13.2606\n",
      "trainer/ZF Policy Reward                0.834561\n",
      "trainer/ZF CHI2 Term                   54.2604\n",
      "trainer/Policy Loss                 -1145.72\n",
      "trainer/Bias Loss                     154.198\n",
      "trainer/Bias Value                     13.7962\n",
      "trainer/Policy Grad Norm              137.871\n",
      "trainer/Policy Param Norm              32.4694\n",
      "trainer/Zf1 Grad Norm                2026.45\n",
      "trainer/Zf1 Param Norm                 91.3883\n",
      "trainer/Zf2 Grad Norm                1990.65\n",
      "trainer/Zf2 Param Norm                 91.9881\n",
      "trainer/Z Expert Predictions Mean    1335.68\n",
      "trainer/Z Expert Predictions Std       51.1897\n",
      "trainer/Z Expert Predictions Max     1418.8\n",
      "trainer/Z Expert Predictions Min     1039.4\n",
      "trainer/Z Policy Predictions Mean    1141.42\n",
      "trainer/Z Policy Predictions Std      423.118\n",
      "trainer/Z Policy Predictions Max     1404.91\n",
      "trainer/Z Policy Predictions Min     -479.72\n",
      "trainer/Z Expert Targets Mean        1322.42\n",
      "trainer/Z Expert Targets Std           56.6862\n",
      "trainer/Z Expert Targets Max         1394.73\n",
      "trainer/Z Expert Targets Min          836.243\n",
      "trainer/Z Policy Targets Mean        1140.58\n",
      "trainer/Z Policy Targets Std          418.406\n",
      "trainer/Z Policy Targets Max         1385.11\n",
      "trainer/Z Policy Targets Min         -448.35\n",
      "trainer/Log Pis Mean                   20.8273\n",
      "trainer/Log Pis Std                     4.8483\n",
      "trainer/Policy mu Mean                  0.116399\n",
      "trainer/Policy mu Std                   1.31784\n",
      "trainer/Policy log std Mean            -3.12277\n",
      "trainer/Policy log std Std              0.968928\n",
      "trainer/Alpha                           0.0859028\n",
      "trainer/Alpha Loss                     -0.0710612\n",
      "exploration/num steps total        111651\n",
      "exploration/num paths total           208\n",
      "evaluation/num steps total         856137\n",
      "evaluation/num paths total           1110\n",
      "evaluation/path length Mean           924.5\n",
      "evaluation/path length Std            226.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            245\n",
      "evaluation/Rewards Mean                 4.51148\n",
      "evaluation/Rewards Std                  1.04683\n",
      "evaluation/Rewards Max                  6.72842\n",
      "evaluation/Rewards Min                 -2.35991\n",
      "evaluation/Returns Mean              4170.86\n",
      "evaluation/Returns Std               1100.5\n",
      "evaluation/Returns Max               4704.89\n",
      "evaluation/Returns Min                879.754\n",
      "evaluation/Estimation Bias Mean      1273.59\n",
      "evaluation/Estimation Bias Std        181.664\n",
      "evaluation/EB/Q_True Mean              45.4229\n",
      "evaluation/EB/Q_True Std              134.321\n",
      "evaluation/EB/Q_Pred Mean            1319.02\n",
      "evaluation/EB/Q_Pred Std              101.751\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4170.86\n",
      "evaluation/Actions Mean                 0.0305367\n",
      "evaluation/Actions Std                  0.532312\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999988\n",
      "time/backward_policy (s)                1.7302\n",
      "time/backward_zf1 (s)                   1.85164\n",
      "time/backward_zf2 (s)                   1.77823\n",
      "time/data sampling (s)                  0.281214\n",
      "time/data storing (s)                   0.0141926\n",
      "time/evaluation sampling (s)            1.68859\n",
      "time/exploration sampling (s)           0.31035\n",
      "time/logging (s)                        0.0113553\n",
      "time/preback_alpha (s)                  0.878406\n",
      "time/preback_policy (s)                 0.946382\n",
      "time/preback_start (s)                  0.139908\n",
      "time/preback_zf (s)                     5.14704\n",
      "time/saving (s)                         0.00607578\n",
      "time/training (s)                       2.4962\n",
      "time/epoch (s)                         17.2798\n",
      "time/total (s)                       1896.28\n",
      "Epoch                                 106\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:24:05.753738 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 107 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 118000\n",
      "trainer/ZF1 Loss                       26.6709\n",
      "trainer/ZF2 Loss                       22.5347\n",
      "trainer/ZF Expert Reward               15.0344\n",
      "trainer/ZF Policy Reward                3.00557\n",
      "trainer/ZF CHI2 Term                   56.6148\n",
      "trainer/Policy Loss                 -1100.2\n",
      "trainer/Bias Loss                      69.1397\n",
      "trainer/Bias Value                     13.7866\n",
      "trainer/Policy Grad Norm              101.727\n",
      "trainer/Policy Param Norm              32.523\n",
      "trainer/Zf1 Grad Norm                1347.44\n",
      "trainer/Zf1 Param Norm                 91.6253\n",
      "trainer/Zf2 Grad Norm                1203.99\n",
      "trainer/Zf2 Param Norm                 92.1819\n",
      "trainer/Z Expert Predictions Mean    1340.41\n",
      "trainer/Z Expert Predictions Std       44.3004\n",
      "trainer/Z Expert Predictions Max     1395.08\n",
      "trainer/Z Expert Predictions Min      935.318\n",
      "trainer/Z Policy Predictions Mean    1094.62\n",
      "trainer/Z Policy Predictions Std      494.164\n",
      "trainer/Z Policy Predictions Max     1392.63\n",
      "trainer/Z Policy Predictions Min     -491.993\n",
      "trainer/Z Expert Targets Mean        1325.37\n",
      "trainer/Z Expert Targets Std           44.6897\n",
      "trainer/Z Expert Targets Max         1381.92\n",
      "trainer/Z Expert Targets Min          918.941\n",
      "trainer/Z Policy Targets Mean        1091.61\n",
      "trainer/Z Policy Targets Std          485.495\n",
      "trainer/Z Policy Targets Max         1383.41\n",
      "trainer/Z Policy Targets Min         -504.207\n",
      "trainer/Log Pis Mean                   20.185\n",
      "trainer/Log Pis Std                     4.52557\n",
      "trainer/Policy mu Mean                  0.0381555\n",
      "trainer/Policy mu Std                   1.21951\n",
      "trainer/Policy log std Mean            -3.07265\n",
      "trainer/Policy log std Std              0.951186\n",
      "trainer/Alpha                           0.0866175\n",
      "trainer/Alpha Loss                     -0.0160254\n",
      "exploration/num steps total        112651\n",
      "exploration/num paths total           209\n",
      "evaluation/num steps total         864790\n",
      "evaluation/num paths total           1120\n",
      "evaluation/path length Mean           865.3\n",
      "evaluation/path length Std            300.265\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             30\n",
      "evaluation/Rewards Mean                 4.55595\n",
      "evaluation/Rewards Std                  1.00082\n",
      "evaluation/Rewards Max                  6.63597\n",
      "evaluation/Rewards Min                 -1.65457\n",
      "evaluation/Returns Mean              3942.26\n",
      "evaluation/Returns Std               1418.51\n",
      "evaluation/Returns Max               4703.19\n",
      "evaluation/Returns Min                 30.7885\n",
      "evaluation/Estimation Bias Mean      1266.38\n",
      "evaluation/Estimation Bias Std        157.208\n",
      "evaluation/EB/Q_True Mean              49.8024\n",
      "evaluation/EB/Q_True Std              142.004\n",
      "evaluation/EB/Q_Pred Mean            1316.19\n",
      "evaluation/EB/Q_Pred Std               53.5796\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3942.26\n",
      "evaluation/Actions Mean                 0.0256433\n",
      "evaluation/Actions Std                  0.535209\n",
      "evaluation/Actions Max                  0.99731\n",
      "evaluation/Actions Min                 -0.999406\n",
      "time/backward_policy (s)                1.9424\n",
      "time/backward_zf1 (s)                   2.02922\n",
      "time/backward_zf2 (s)                   1.9935\n",
      "time/data sampling (s)                  0.277495\n",
      "time/data storing (s)                   0.0143651\n",
      "time/evaluation sampling (s)            1.74433\n",
      "time/exploration sampling (s)           0.317637\n",
      "time/logging (s)                        0.0108843\n",
      "time/preback_alpha (s)                  1.0191\n",
      "time/preback_policy (s)                 1.16442\n",
      "time/preback_start (s)                  0.142483\n",
      "time/preback_zf (s)                     5.11824\n",
      "time/saving (s)                         0.00604976\n",
      "time/training (s)                       2.04585\n",
      "time/epoch (s)                         17.826\n",
      "time/total (s)                       1914.12\n",
      "Epoch                                 107\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:24:23.182685 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 108 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 119000\n",
      "trainer/ZF1 Loss                        1.33461\n",
      "trainer/ZF2 Loss                       -3.67457\n",
      "trainer/ZF Expert Reward               13.4887\n",
      "trainer/ZF Policy Reward                2.42729\n",
      "trainer/ZF CHI2 Term                   29.206\n",
      "trainer/Policy Loss                 -1148.19\n",
      "trainer/Bias Loss                      45.4162\n",
      "trainer/Bias Value                     13.7758\n",
      "trainer/Policy Grad Norm               90.8134\n",
      "trainer/Policy Param Norm              32.5745\n",
      "trainer/Zf1 Grad Norm                1118.1\n",
      "trainer/Zf1 Param Norm                 91.8642\n",
      "trainer/Zf2 Grad Norm                 839.465\n",
      "trainer/Zf2 Param Norm                 92.3902\n",
      "trainer/Z Expert Predictions Mean    1332.96\n",
      "trainer/Z Expert Predictions Std       36.1096\n",
      "trainer/Z Expert Predictions Max     1389.57\n",
      "trainer/Z Expert Predictions Min     1142.01\n",
      "trainer/Z Policy Predictions Mean    1143.12\n",
      "trainer/Z Policy Predictions Std      398.845\n",
      "trainer/Z Policy Predictions Max     1377.13\n",
      "trainer/Z Policy Predictions Min     -485.283\n",
      "trainer/Z Expert Targets Mean        1319.47\n",
      "trainer/Z Expert Targets Std           37.3377\n",
      "trainer/Z Expert Targets Max         1375.71\n",
      "trainer/Z Expert Targets Min         1113.29\n",
      "trainer/Z Policy Targets Mean        1140.69\n",
      "trainer/Z Policy Targets Std          391.966\n",
      "trainer/Z Policy Targets Max         1362.27\n",
      "trainer/Z Policy Targets Min         -459.87\n",
      "trainer/Log Pis Mean                   19.5097\n",
      "trainer/Log Pis Std                     4.33583\n",
      "trainer/Policy mu Mean                  0.0612503\n",
      "trainer/Policy mu Std                   1.16567\n",
      "trainer/Policy log std Mean            -3.06659\n",
      "trainer/Policy log std Std              0.944404\n",
      "trainer/Alpha                           0.0868641\n",
      "trainer/Alpha Loss                      0.0425925\n",
      "exploration/num steps total        113651\n",
      "exploration/num paths total           210\n",
      "evaluation/num steps total         874355\n",
      "evaluation/num paths total           1130\n",
      "evaluation/path length Mean           956.5\n",
      "evaluation/path length Std            130.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            565\n",
      "evaluation/Rewards Mean                 4.52655\n",
      "evaluation/Rewards Std                  1.0293\n",
      "evaluation/Rewards Max                  6.49104\n",
      "evaluation/Rewards Min                 -1.88944\n",
      "evaluation/Returns Mean              4329.64\n",
      "evaluation/Returns Std                617.915\n",
      "evaluation/Returns Max               4633.44\n",
      "evaluation/Returns Min               2484.13\n",
      "evaluation/Estimation Bias Mean      1258.17\n",
      "evaluation/Estimation Bias Std        150.155\n",
      "evaluation/EB/Q_True Mean              44.0857\n",
      "evaluation/EB/Q_True Std              133.127\n",
      "evaluation/EB/Q_Pred Mean            1302.25\n",
      "evaluation/EB/Q_Pred Std               65.1981\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4329.64\n",
      "evaluation/Actions Mean                 0.0328335\n",
      "evaluation/Actions Std                  0.531346\n",
      "evaluation/Actions Max                  0.999069\n",
      "evaluation/Actions Min                 -0.999414\n",
      "time/backward_policy (s)                1.7509\n",
      "time/backward_zf1 (s)                   1.86771\n",
      "time/backward_zf2 (s)                   1.79797\n",
      "time/data sampling (s)                  0.285833\n",
      "time/data storing (s)                   0.0148871\n",
      "time/evaluation sampling (s)            1.71024\n",
      "time/exploration sampling (s)           0.324476\n",
      "time/logging (s)                        0.0119432\n",
      "time/preback_alpha (s)                  0.910723\n",
      "time/preback_policy (s)                 0.987183\n",
      "time/preback_start (s)                  0.142719\n",
      "time/preback_zf (s)                     5.1488\n",
      "time/saving (s)                         0.00611567\n",
      "time/training (s)                       2.40458\n",
      "time/epoch (s)                         17.3641\n",
      "time/total (s)                       1931.51\n",
      "Epoch                                 108\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:24:41.609949 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 109 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 120000\n",
      "trainer/ZF1 Loss                        4.48072\n",
      "trainer/ZF2 Loss                       47.5739\n",
      "trainer/ZF Expert Reward               10.5234\n",
      "trainer/ZF Policy Reward                1.19881\n",
      "trainer/ZF CHI2 Term                   55.1707\n",
      "trainer/Policy Loss                 -1156.23\n",
      "trainer/Bias Loss                     169.631\n",
      "trainer/Bias Value                     13.7698\n",
      "trainer/Policy Grad Norm               96.157\n",
      "trainer/Policy Param Norm              32.6308\n",
      "trainer/Zf1 Grad Norm                2350.21\n",
      "trainer/Zf1 Param Norm                 92.0844\n",
      "trainer/Zf2 Grad Norm                8751.67\n",
      "trainer/Zf2 Param Norm                 92.6053\n",
      "trainer/Z Expert Predictions Mean    1315\n",
      "trainer/Z Expert Predictions Std       86.7893\n",
      "trainer/Z Expert Predictions Max     1382.44\n",
      "trainer/Z Expert Predictions Min      111.627\n",
      "trainer/Z Policy Predictions Mean    1148.78\n",
      "trainer/Z Policy Predictions Std      385.592\n",
      "trainer/Z Policy Predictions Max     1378.55\n",
      "trainer/Z Policy Predictions Min     -472.856\n",
      "trainer/Z Expert Targets Mean        1304.48\n",
      "trainer/Z Expert Targets Std           91.2128\n",
      "trainer/Z Expert Targets Max         1362.84\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1147.58\n",
      "trainer/Z Policy Targets Std          381.076\n",
      "trainer/Z Policy Targets Max         1369.27\n",
      "trainer/Z Policy Targets Min         -467.582\n",
      "trainer/Log Pis Mean                   20.0191\n",
      "trainer/Log Pis Std                     4.16195\n",
      "trainer/Policy mu Mean                  0.0466709\n",
      "trainer/Policy mu Std                   1.12594\n",
      "trainer/Policy log std Mean            -3.13079\n",
      "trainer/Policy log std Std              0.881499\n",
      "trainer/Alpha                           0.0890709\n",
      "trainer/Alpha Loss                     -0.00170122\n",
      "exploration/num steps total        114651\n",
      "exploration/num paths total           211\n",
      "evaluation/num steps total         884355\n",
      "evaluation/num paths total           1140\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.52418\n",
      "evaluation/Rewards Std                  1.48833\n",
      "evaluation/Rewards Max                  6.72727\n",
      "evaluation/Rewards Min                 -2.7476\n",
      "evaluation/Returns Mean              4524.18\n",
      "evaluation/Returns Std                598.692\n",
      "evaluation/Returns Max               4877.82\n",
      "evaluation/Returns Min               2747.15\n",
      "evaluation/Estimation Bias Mean      1234.31\n",
      "evaluation/Estimation Bias Std        220.512\n",
      "evaluation/EB/Q_True Mean              43.6079\n",
      "evaluation/EB/Q_True Std              134.16\n",
      "evaluation/EB/Q_Pred Mean            1277.92\n",
      "evaluation/EB/Q_Pred Std              184.262\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4524.18\n",
      "evaluation/Actions Mean                 0.0220698\n",
      "evaluation/Actions Std                  0.545792\n",
      "evaluation/Actions Max                  0.99995\n",
      "evaluation/Actions Min                 -0.999768\n",
      "time/backward_policy (s)                2.02318\n",
      "time/backward_zf1 (s)                   2.1296\n",
      "time/backward_zf2 (s)                   2.09369\n",
      "time/data sampling (s)                  0.300256\n",
      "time/data storing (s)                   0.014781\n",
      "time/evaluation sampling (s)            1.7086\n",
      "time/exploration sampling (s)           0.321514\n",
      "time/logging (s)                        0.0142038\n",
      "time/preback_alpha (s)                  1.06494\n",
      "time/preback_policy (s)                 1.22067\n",
      "time/preback_start (s)                  0.146516\n",
      "time/preback_zf (s)                     5.22731\n",
      "time/saving (s)                         0.00613533\n",
      "time/training (s)                       2.09042\n",
      "time/epoch (s)                         18.3618\n",
      "time/total (s)                       1949.89\n",
      "Epoch                                 109\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:24:59.354472 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 110 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 121000\n",
      "trainer/ZF1 Loss                      287.581\n",
      "trainer/ZF2 Loss                       16.6301\n",
      "trainer/ZF Expert Reward               15.1347\n",
      "trainer/ZF Policy Reward                7.93634\n",
      "trainer/ZF CHI2 Term                  179.181\n",
      "trainer/Policy Loss                 -1122.8\n",
      "trainer/Bias Loss                     388.793\n",
      "trainer/Bias Value                     13.7591\n",
      "trainer/Policy Grad Norm              226.461\n",
      "trainer/Policy Param Norm              32.683\n",
      "trainer/Zf1 Grad Norm               36366.2\n",
      "trainer/Zf1 Param Norm                 92.3267\n",
      "trainer/Zf2 Grad Norm                3390.65\n",
      "trainer/Zf2 Param Norm                 92.8202\n",
      "trainer/Z Expert Predictions Mean    1308.04\n",
      "trainer/Z Expert Predictions Std       85.7556\n",
      "trainer/Z Expert Predictions Max     1366.04\n",
      "trainer/Z Expert Predictions Min      318.215\n",
      "trainer/Z Policy Predictions Mean    1121.13\n",
      "trainer/Z Policy Predictions Std      405.156\n",
      "trainer/Z Policy Predictions Max     1366.05\n",
      "trainer/Z Policy Predictions Min     -482.669\n",
      "trainer/Z Expert Targets Mean        1292.91\n",
      "trainer/Z Expert Targets Std          108.297\n",
      "trainer/Z Expert Targets Max         1355.82\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1113.19\n",
      "trainer/Z Policy Targets Std          405.589\n",
      "trainer/Z Policy Targets Max         1351.09\n",
      "trainer/Z Policy Targets Min         -508.299\n",
      "trainer/Log Pis Mean                   20.0784\n",
      "trainer/Log Pis Std                     5.06956\n",
      "trainer/Policy mu Mean                  0.0584112\n",
      "trainer/Policy mu Std                   1.24966\n",
      "trainer/Policy log std Mean            -3.1127\n",
      "trainer/Policy log std Std              0.935316\n",
      "trainer/Alpha                           0.0890735\n",
      "trainer/Alpha Loss                     -0.00697903\n",
      "exploration/num steps total        116651\n",
      "exploration/num paths total           213\n",
      "evaluation/num steps total         893812\n",
      "evaluation/num paths total           1150\n",
      "evaluation/path length Mean           945.7\n",
      "evaluation/path length Std            112.717\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            661\n",
      "evaluation/Rewards Mean                 4.69914\n",
      "evaluation/Rewards Std                  1.08671\n",
      "evaluation/Rewards Max                  6.78859\n",
      "evaluation/Rewards Min                 -1.85886\n",
      "evaluation/Returns Mean              4443.98\n",
      "evaluation/Returns Std                532.905\n",
      "evaluation/Returns Max               4799.27\n",
      "evaluation/Returns Min               3160.08\n",
      "evaluation/Estimation Bias Mean      1249.26\n",
      "evaluation/Estimation Bias Std        169.741\n",
      "evaluation/EB/Q_True Mean              46.4835\n",
      "evaluation/EB/Q_True Std              138.415\n",
      "evaluation/EB/Q_Pred Mean            1295.74\n",
      "evaluation/EB/Q_Pred Std               97.7151\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4443.98\n",
      "evaluation/Actions Mean                 0.0128283\n",
      "evaluation/Actions Std                  0.53826\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999966\n",
      "time/backward_policy (s)                1.80363\n",
      "time/backward_zf1 (s)                   1.94332\n",
      "time/backward_zf2 (s)                   1.87012\n",
      "time/data sampling (s)                  0.285377\n",
      "time/data storing (s)                   0.015311\n",
      "time/evaluation sampling (s)            1.71759\n",
      "time/exploration sampling (s)           0.325459\n",
      "time/logging (s)                        0.0126302\n",
      "time/preback_alpha (s)                  0.914289\n",
      "time/preback_policy (s)                 1.00608\n",
      "time/preback_start (s)                  0.143826\n",
      "time/preback_zf (s)                     5.1873\n",
      "time/saving (s)                         0.0236304\n",
      "time/training (s)                       2.42513\n",
      "time/epoch (s)                         17.6737\n",
      "time/total (s)                       1967.58\n",
      "Epoch                                 110\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:25:17.258544 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 111 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 122000\n",
      "trainer/ZF1 Loss                      333.016\n",
      "trainer/ZF2 Loss                      288.892\n",
      "trainer/ZF Expert Reward               19.6517\n",
      "trainer/ZF Policy Reward               11.9817\n",
      "trainer/ZF CHI2 Term                  338.328\n",
      "trainer/Policy Loss                 -1085.37\n",
      "trainer/Bias Loss                      78.8468\n",
      "trainer/Bias Value                     13.7484\n",
      "trainer/Policy Grad Norm              100.437\n",
      "trainer/Policy Param Norm              32.7309\n",
      "trainer/Zf1 Grad Norm                2268.07\n",
      "trainer/Zf1 Param Norm                 92.5819\n",
      "trainer/Zf2 Grad Norm                2985.49\n",
      "trainer/Zf2 Param Norm                 93.0381\n",
      "trainer/Z Expert Predictions Mean    1314.67\n",
      "trainer/Z Expert Predictions Std       41.7304\n",
      "trainer/Z Expert Predictions Max     1375.2\n",
      "trainer/Z Expert Predictions Min     1054.28\n",
      "trainer/Z Policy Predictions Mean    1081.61\n",
      "trainer/Z Policy Predictions Std      455.661\n",
      "trainer/Z Policy Predictions Max     1370.32\n",
      "trainer/Z Policy Predictions Min     -491.809\n",
      "trainer/Z Expert Targets Mean        1295.02\n",
      "trainer/Z Expert Targets Std           43.3203\n",
      "trainer/Z Expert Targets Max         1361.85\n",
      "trainer/Z Expert Targets Min         1028.93\n",
      "trainer/Z Policy Targets Mean        1069.63\n",
      "trainer/Z Policy Targets Std          454.113\n",
      "trainer/Z Policy Targets Max         1349.42\n",
      "trainer/Z Policy Targets Min         -520.875\n",
      "trainer/Log Pis Mean                   19.9036\n",
      "trainer/Log Pis Std                     4.54731\n",
      "trainer/Policy mu Mean                  0.0548485\n",
      "trainer/Policy mu Std                   1.25392\n",
      "trainer/Policy log std Mean            -3.02419\n",
      "trainer/Policy log std Std              0.990756\n",
      "trainer/Alpha                           0.0901412\n",
      "trainer/Alpha Loss                      0.00869078\n",
      "exploration/num steps total        116651\n",
      "exploration/num paths total           213\n",
      "evaluation/num steps total         903812\n",
      "evaluation/num paths total           1160\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.58447\n",
      "evaluation/Rewards Std                  0.952848\n",
      "evaluation/Rewards Max                  6.63042\n",
      "evaluation/Rewards Min                 -1.53314\n",
      "evaluation/Returns Mean              4584.47\n",
      "evaluation/Returns Std                 79.4072\n",
      "evaluation/Returns Max               4774.13\n",
      "evaluation/Returns Min               4457.45\n",
      "evaluation/Estimation Bias Mean      1248.97\n",
      "evaluation/Estimation Bias Std        134.998\n",
      "evaluation/EB/Q_True Mean              42.152\n",
      "evaluation/EB/Q_True Std              129.748\n",
      "evaluation/EB/Q_Pred Mean            1291.13\n",
      "evaluation/EB/Q_Pred Std               47.6033\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4584.47\n",
      "evaluation/Actions Mean                 0.0312863\n",
      "evaluation/Actions Std                  0.530322\n",
      "evaluation/Actions Max                  0.998167\n",
      "evaluation/Actions Min                 -0.999517\n",
      "time/backward_policy (s)                1.86701\n",
      "time/backward_zf1 (s)                   2.00187\n",
      "time/backward_zf2 (s)                   1.93632\n",
      "time/data sampling (s)                  0.284408\n",
      "time/data storing (s)                   0.0145071\n",
      "time/evaluation sampling (s)            1.80903\n",
      "time/exploration sampling (s)           0.314574\n",
      "time/logging (s)                        0.0121159\n",
      "time/preback_alpha (s)                  0.962651\n",
      "time/preback_policy (s)                 1.07345\n",
      "time/preback_start (s)                  0.140617\n",
      "time/preback_zf (s)                     5.16595\n",
      "time/saving (s)                         0.017394\n",
      "time/training (s)                       2.23717\n",
      "time/epoch (s)                         17.8371\n",
      "time/total (s)                       1985.44\n",
      "Epoch                                 111\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:25:35.043774 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 112 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 123000\n",
      "trainer/ZF1 Loss                        1.34465\n",
      "trainer/ZF2 Loss                        4.42013\n",
      "trainer/ZF Expert Reward               14.5111\n",
      "trainer/ZF Policy Reward                5.32781\n",
      "trainer/ZF CHI2 Term                   31.751\n",
      "trainer/Policy Loss                 -1048.4\n",
      "trainer/Bias Loss                      58.5988\n",
      "trainer/Bias Value                     13.7421\n",
      "trainer/Policy Grad Norm               92.5371\n",
      "trainer/Policy Param Norm              32.7784\n",
      "trainer/Zf1 Grad Norm                1200.14\n",
      "trainer/Zf1 Param Norm                 92.8082\n",
      "trainer/Zf2 Grad Norm                1005.89\n",
      "trainer/Zf2 Param Norm                 93.2436\n",
      "trainer/Z Expert Predictions Mean    1297.56\n",
      "trainer/Z Expert Predictions Std       43.4425\n",
      "trainer/Z Expert Predictions Max     1354.41\n",
      "trainer/Z Expert Predictions Min     1079.41\n",
      "trainer/Z Policy Predictions Mean    1045.88\n",
      "trainer/Z Policy Predictions Std      483.169\n",
      "trainer/Z Policy Predictions Max     1349.38\n",
      "trainer/Z Policy Predictions Min     -476.56\n",
      "trainer/Z Expert Targets Mean        1283.05\n",
      "trainer/Z Expert Targets Std           44.9483\n",
      "trainer/Z Expert Targets Max         1343.48\n",
      "trainer/Z Expert Targets Min         1065.76\n",
      "trainer/Z Policy Targets Mean        1040.55\n",
      "trainer/Z Policy Targets Std          481.459\n",
      "trainer/Z Policy Targets Max         1344.53\n",
      "trainer/Z Policy Targets Min         -465.667\n",
      "trainer/Log Pis Mean                   19.8842\n",
      "trainer/Log Pis Std                     4.96109\n",
      "trainer/Policy mu Mean                  0.116469\n",
      "trainer/Policy mu Std                   1.34183\n",
      "trainer/Policy log std Mean            -3.02484\n",
      "trainer/Policy log std Std              1.03519\n",
      "trainer/Alpha                           0.0911043\n",
      "trainer/Alpha Loss                      0.0105512\n",
      "exploration/num steps total        118651\n",
      "exploration/num paths total           215\n",
      "evaluation/num steps total         912139\n",
      "evaluation/num paths total           1170\n",
      "evaluation/path length Mean           832.7\n",
      "evaluation/path length Std            340.043\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             28\n",
      "evaluation/Rewards Mean                 4.52814\n",
      "evaluation/Rewards Std                  1.33512\n",
      "evaluation/Rewards Max                  6.84089\n",
      "evaluation/Rewards Min                 -2.90969\n",
      "evaluation/Returns Mean              3770.58\n",
      "evaluation/Returns Std               1582.62\n",
      "evaluation/Returns Max               4819.11\n",
      "evaluation/Returns Min                 48.8135\n",
      "evaluation/Estimation Bias Mean      1205.03\n",
      "evaluation/Estimation Bias Std        218.767\n",
      "evaluation/EB/Q_True Mean              51.3183\n",
      "evaluation/EB/Q_True Std              143.34\n",
      "evaluation/EB/Q_Pred Mean            1256.35\n",
      "evaluation/EB/Q_Pred Std              170.013\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3770.58\n",
      "evaluation/Actions Mean                 0.00931585\n",
      "evaluation/Actions Std                  0.54277\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.86805\n",
      "time/backward_zf1 (s)                   1.9821\n",
      "time/backward_zf2 (s)                   1.93124\n",
      "time/data sampling (s)                  0.275217\n",
      "time/data storing (s)                   0.014113\n",
      "time/evaluation sampling (s)            1.77891\n",
      "time/exploration sampling (s)           0.318347\n",
      "time/logging (s)                        0.010334\n",
      "time/preback_alpha (s)                  0.984204\n",
      "time/preback_policy (s)                 1.11467\n",
      "time/preback_start (s)                  0.143956\n",
      "time/preback_zf (s)                     5.15299\n",
      "time/saving (s)                         0.00604202\n",
      "time/training (s)                       2.13668\n",
      "time/epoch (s)                         17.7168\n",
      "time/total (s)                       2003.18\n",
      "Epoch                                 112\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:25:52.959416 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 113 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 124000\n",
      "trainer/ZF1 Loss                      220.844\n",
      "trainer/ZF2 Loss                      245.519\n",
      "trainer/ZF Expert Reward                9.34993\n",
      "trainer/ZF Policy Reward                4.11901\n",
      "trainer/ZF CHI2 Term                  258.997\n",
      "trainer/Policy Loss                 -1114.35\n",
      "trainer/Bias Loss                      71.8932\n",
      "trainer/Bias Value                     13.7323\n",
      "trainer/Policy Grad Norm               89.17\n",
      "trainer/Policy Param Norm              32.825\n",
      "trainer/Zf1 Grad Norm                4140.61\n",
      "trainer/Zf1 Param Norm                 93.0694\n",
      "trainer/Zf2 Grad Norm                2968.57\n",
      "trainer/Zf2 Param Norm                 93.4706\n",
      "trainer/Z Expert Predictions Mean    1288.08\n",
      "trainer/Z Expert Predictions Std       44.7784\n",
      "trainer/Z Expert Predictions Max     1345.2\n",
      "trainer/Z Expert Predictions Min     1073.14\n",
      "trainer/Z Policy Predictions Mean    1110.79\n",
      "trainer/Z Policy Predictions Std      383.433\n",
      "trainer/Z Policy Predictions Max     1336.94\n",
      "trainer/Z Policy Predictions Min     -473.404\n",
      "trainer/Z Expert Targets Mean        1278.73\n",
      "trainer/Z Expert Targets Std           45.5212\n",
      "trainer/Z Expert Targets Max         1335.38\n",
      "trainer/Z Expert Targets Min         1033.16\n",
      "trainer/Z Policy Targets Mean        1106.67\n",
      "trainer/Z Policy Targets Std          385.309\n",
      "trainer/Z Policy Targets Max         1339.77\n",
      "trainer/Z Policy Targets Min         -456.724\n",
      "trainer/Log Pis Mean                   20.7926\n",
      "trainer/Log Pis Std                     5.0436\n",
      "trainer/Policy mu Mean                  0.0572946\n",
      "trainer/Policy mu Std                   1.25095\n",
      "trainer/Policy log std Mean            -3.17309\n",
      "trainer/Policy log std Std              0.932981\n",
      "trainer/Alpha                           0.0917731\n",
      "trainer/Alpha Loss                     -0.0727359\n",
      "exploration/num steps total        118651\n",
      "exploration/num paths total           215\n",
      "evaluation/num steps total         921207\n",
      "evaluation/num paths total           1180\n",
      "evaluation/path length Mean           906.8\n",
      "evaluation/path length Std            279.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             68\n",
      "evaluation/Rewards Mean                 4.63141\n",
      "evaluation/Rewards Std                  1.06128\n",
      "evaluation/Rewards Max                  6.70846\n",
      "evaluation/Rewards Min                 -1.8685\n",
      "evaluation/Returns Mean              4199.76\n",
      "evaluation/Returns Std               1346.37\n",
      "evaluation/Returns Max               4844.02\n",
      "evaluation/Returns Min                167.538\n",
      "evaluation/Estimation Bias Mean      1219.88\n",
      "evaluation/Estimation Bias Std        153.988\n",
      "evaluation/EB/Q_True Mean              47.1422\n",
      "evaluation/EB/Q_True Std              137.292\n",
      "evaluation/EB/Q_Pred Mean            1267.03\n",
      "evaluation/EB/Q_Pred Std               59.3162\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4199.76\n",
      "evaluation/Actions Mean                 0.0206668\n",
      "evaluation/Actions Std                  0.540426\n",
      "evaluation/Actions Max                  0.998734\n",
      "evaluation/Actions Min                 -0.999686\n",
      "time/backward_policy (s)                1.89603\n",
      "time/backward_zf1 (s)                   2.00062\n",
      "time/backward_zf2 (s)                   1.94627\n",
      "time/data sampling (s)                  0.284257\n",
      "time/data storing (s)                   0.0143945\n",
      "time/evaluation sampling (s)            1.74771\n",
      "time/exploration sampling (s)           0.318375\n",
      "time/logging (s)                        0.0118878\n",
      "time/preback_alpha (s)                  0.999223\n",
      "time/preback_policy (s)                 1.1267\n",
      "time/preback_start (s)                  0.144105\n",
      "time/preback_zf (s)                     5.18096\n",
      "time/saving (s)                         0.00601729\n",
      "time/training (s)                       2.17388\n",
      "time/epoch (s)                         17.8504\n",
      "time/total (s)                       2021.05\n",
      "Epoch                                 113\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:26:11.878624 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 114 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 125000\n",
      "trainer/ZF1 Loss                        7.12848\n",
      "trainer/ZF2 Loss                        3.34602\n",
      "trainer/ZF Expert Reward               12.7881\n",
      "trainer/ZF Policy Reward                0.640594\n",
      "trainer/ZF CHI2 Term                   37.2287\n",
      "trainer/Policy Loss                 -1107.21\n",
      "trainer/Bias Loss                      55.6084\n",
      "trainer/Bias Value                     13.7224\n",
      "trainer/Policy Grad Norm              127.183\n",
      "trainer/Policy Param Norm              32.8673\n",
      "trainer/Zf1 Grad Norm                1788.94\n",
      "trainer/Zf1 Param Norm                 93.315\n",
      "trainer/Zf2 Grad Norm                1264.04\n",
      "trainer/Zf2 Param Norm                 93.6919\n",
      "trainer/Z Expert Predictions Mean    1287.75\n",
      "trainer/Z Expert Predictions Std       43.0767\n",
      "trainer/Z Expert Predictions Max     1346.53\n",
      "trainer/Z Expert Predictions Min     1055.19\n",
      "trainer/Z Policy Predictions Mean    1100.97\n",
      "trainer/Z Policy Predictions Std      386.002\n",
      "trainer/Z Policy Predictions Max     1340.48\n",
      "trainer/Z Policy Predictions Min     -466.122\n",
      "trainer/Z Expert Targets Mean        1274.96\n",
      "trainer/Z Expert Targets Std           45.0554\n",
      "trainer/Z Expert Targets Max         1332.34\n",
      "trainer/Z Expert Targets Min         1050.02\n",
      "trainer/Z Policy Targets Mean        1100.33\n",
      "trainer/Z Policy Targets Std          380.479\n",
      "trainer/Z Policy Targets Max         1329.35\n",
      "trainer/Z Policy Targets Min         -454.061\n",
      "trainer/Log Pis Mean                   20.0444\n",
      "trainer/Log Pis Std                     4.22645\n",
      "trainer/Policy mu Mean                  0.0354357\n",
      "trainer/Policy mu Std                   1.15993\n",
      "trainer/Policy log std Mean            -3.13181\n",
      "trainer/Policy log std Std              0.925447\n",
      "trainer/Alpha                           0.0919521\n",
      "trainer/Alpha Loss                     -0.00408273\n",
      "exploration/num steps total        119651\n",
      "exploration/num paths total           216\n",
      "evaluation/num steps total         930447\n",
      "evaluation/num paths total           1190\n",
      "evaluation/path length Mean           924\n",
      "evaluation/path length Std            228\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            240\n",
      "evaluation/Rewards Mean                 4.59679\n",
      "evaluation/Rewards Std                  1.09471\n",
      "evaluation/Rewards Max                  6.58886\n",
      "evaluation/Rewards Min                 -1.52086\n",
      "evaluation/Returns Mean              4247.44\n",
      "evaluation/Returns Std               1108.05\n",
      "evaluation/Returns Max               4764\n",
      "evaluation/Returns Min                934.143\n",
      "evaluation/Estimation Bias Mean      1207.9\n",
      "evaluation/Estimation Bias Std        160.066\n",
      "evaluation/EB/Q_True Mean              46.9147\n",
      "evaluation/EB/Q_True Std              138.121\n",
      "evaluation/EB/Q_Pred Mean            1254.81\n",
      "evaluation/EB/Q_Pred Std               69.618\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4247.44\n",
      "evaluation/Actions Mean                 0.0212244\n",
      "evaluation/Actions Std                  0.534602\n",
      "evaluation/Actions Max                  0.999861\n",
      "evaluation/Actions Min                 -0.999746\n",
      "time/backward_policy (s)                2.12314\n",
      "time/backward_zf1 (s)                   2.21244\n",
      "time/backward_zf2 (s)                   2.17491\n",
      "time/data sampling (s)                  0.305484\n",
      "time/data storing (s)                   0.0146282\n",
      "time/evaluation sampling (s)            1.7671\n",
      "time/exploration sampling (s)           0.328253\n",
      "time/logging (s)                        0.0118311\n",
      "time/preback_alpha (s)                  1.06475\n",
      "time/preback_policy (s)                 1.22903\n",
      "time/preback_start (s)                  0.150278\n",
      "time/preback_zf (s)                     5.2155\n",
      "time/saving (s)                         0.00595644\n",
      "time/training (s)                       2.24781\n",
      "time/epoch (s)                         18.8511\n",
      "time/total (s)                       2039.92\n",
      "Epoch                                 114\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:26:29.749825 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 115 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 126000\n",
      "trainer/ZF1 Loss                       11.4469\n",
      "trainer/ZF2 Loss                        5.48883\n",
      "trainer/ZF Expert Reward               10.6329\n",
      "trainer/ZF Policy Reward                0.25257\n",
      "trainer/ZF CHI2 Term                   38.7135\n",
      "trainer/Policy Loss                 -1080.5\n",
      "trainer/Bias Loss                      79.5093\n",
      "trainer/Bias Value                     13.7207\n",
      "trainer/Policy Grad Norm              122.022\n",
      "trainer/Policy Param Norm              32.9094\n",
      "trainer/Zf1 Grad Norm                2141.43\n",
      "trainer/Zf1 Param Norm                 93.5631\n",
      "trainer/Zf2 Grad Norm                1437.27\n",
      "trainer/Zf2 Param Norm                 93.8957\n",
      "trainer/Z Expert Predictions Mean    1264.39\n",
      "trainer/Z Expert Predictions Std      100.061\n",
      "trainer/Z Expert Predictions Max     1344.08\n",
      "trainer/Z Expert Predictions Min      -46.8444\n",
      "trainer/Z Policy Predictions Mean    1076.21\n",
      "trainer/Z Policy Predictions Std      413.603\n",
      "trainer/Z Policy Predictions Max     1329.86\n",
      "trainer/Z Policy Predictions Min     -466.816\n",
      "trainer/Z Expert Targets Mean        1253.75\n",
      "trainer/Z Expert Targets Std           95.1261\n",
      "trainer/Z Expert Targets Max         1325.41\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1075.96\n",
      "trainer/Z Policy Targets Std          407.713\n",
      "trainer/Z Policy Targets Max         1313.26\n",
      "trainer/Z Policy Targets Min         -450.912\n",
      "trainer/Log Pis Mean                   20.066\n",
      "trainer/Log Pis Std                     4.98419\n",
      "trainer/Policy mu Mean                  0.12303\n",
      "trainer/Policy mu Std                   1.24443\n",
      "trainer/Policy log std Mean            -3.07286\n",
      "trainer/Policy log std Std              0.989901\n",
      "trainer/Alpha                           0.0925867\n",
      "trainer/Alpha Loss                     -0.00611421\n",
      "exploration/num steps total        121651\n",
      "exploration/num paths total           218\n",
      "evaluation/num steps total         940447\n",
      "evaluation/num paths total           1200\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.58647\n",
      "evaluation/Rewards Std                  1.0614\n",
      "evaluation/Rewards Max                  6.68908\n",
      "evaluation/Rewards Min                 -1.69375\n",
      "evaluation/Returns Mean              4586.47\n",
      "evaluation/Returns Std                 88.1667\n",
      "evaluation/Returns Max               4763.38\n",
      "evaluation/Returns Min               4459.51\n",
      "evaluation/Estimation Bias Mean      1213.97\n",
      "evaluation/Estimation Bias Std        142.934\n",
      "evaluation/EB/Q_True Mean              42.0299\n",
      "evaluation/EB/Q_True Std              129.911\n",
      "evaluation/EB/Q_Pred Mean            1256\n",
      "evaluation/EB/Q_Pred Std               58.804\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4586.47\n",
      "evaluation/Actions Mean                 0.0215626\n",
      "evaluation/Actions Std                  0.540158\n",
      "evaluation/Actions Max                  0.998028\n",
      "evaluation/Actions Min                 -0.999417\n",
      "time/backward_policy (s)                1.89878\n",
      "time/backward_zf1 (s)                   2.03894\n",
      "time/backward_zf2 (s)                   1.97455\n",
      "time/data sampling (s)                  0.28323\n",
      "time/data storing (s)                   0.0147496\n",
      "time/evaluation sampling (s)            1.76327\n",
      "time/exploration sampling (s)           0.319724\n",
      "time/logging (s)                        0.0121892\n",
      "time/preback_alpha (s)                  1.02026\n",
      "time/preback_policy (s)                 1.16145\n",
      "time/preback_start (s)                  0.141365\n",
      "time/preback_zf (s)                     5.14334\n",
      "time/saving (s)                         0.00852742\n",
      "time/training (s)                       2.0243\n",
      "time/epoch (s)                         17.8047\n",
      "time/total (s)                       2057.74\n",
      "Epoch                                 115\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:26:47.491368 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 116 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 127000\n",
      "trainer/ZF1 Loss                        0.515358\n",
      "trainer/ZF2 Loss                       17.7296\n",
      "trainer/ZF Expert Reward               12.1671\n",
      "trainer/ZF Policy Reward                2.69778\n",
      "trainer/ZF CHI2 Term                   38.2416\n",
      "trainer/Policy Loss                 -1074.75\n",
      "trainer/Bias Loss                     117.076\n",
      "trainer/Bias Value                     13.7107\n",
      "trainer/Policy Grad Norm               96.7319\n",
      "trainer/Policy Param Norm              32.9529\n",
      "trainer/Zf1 Grad Norm                1137.7\n",
      "trainer/Zf1 Param Norm                 93.8079\n",
      "trainer/Zf2 Grad Norm                5246.87\n",
      "trainer/Zf2 Param Norm                 94.1028\n",
      "trainer/Z Expert Predictions Mean    1261.16\n",
      "trainer/Z Expert Predictions Std       84.6902\n",
      "trainer/Z Expert Predictions Max     1321.47\n",
      "trainer/Z Expert Predictions Min      183.93\n",
      "trainer/Z Policy Predictions Mean    1071.12\n",
      "trainer/Z Policy Predictions Std      395.894\n",
      "trainer/Z Policy Predictions Max     1315.31\n",
      "trainer/Z Policy Predictions Min     -461.495\n",
      "trainer/Z Expert Targets Mean        1248.99\n",
      "trainer/Z Expert Targets Std           94.366\n",
      "trainer/Z Expert Targets Max         1309.89\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1068.42\n",
      "trainer/Z Policy Targets Std          390.309\n",
      "trainer/Z Policy Targets Max         1311.79\n",
      "trainer/Z Policy Targets Min         -438.631\n",
      "trainer/Log Pis Mean                   19.8482\n",
      "trainer/Log Pis Std                     3.95238\n",
      "trainer/Policy mu Mean                  0.0593952\n",
      "trainer/Policy mu Std                   1.17298\n",
      "trainer/Policy log std Mean            -3.06678\n",
      "trainer/Policy log std Std              0.971144\n",
      "trainer/Alpha                           0.0912877\n",
      "trainer/Alpha Loss                      0.0138553\n",
      "exploration/num steps total        121885\n",
      "exploration/num paths total           219\n",
      "evaluation/num steps total         950447\n",
      "evaluation/num paths total           1210\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60449\n",
      "evaluation/Rewards Std                  0.973096\n",
      "evaluation/Rewards Max                  6.57501\n",
      "evaluation/Rewards Min                 -1.60775\n",
      "evaluation/Returns Mean              4604.49\n",
      "evaluation/Returns Std                 83.5608\n",
      "evaluation/Returns Max               4729.24\n",
      "evaluation/Returns Min               4471.57\n",
      "evaluation/Estimation Bias Mean      1217.42\n",
      "evaluation/Estimation Bias Std        137.381\n",
      "evaluation/EB/Q_True Mean              41.5797\n",
      "evaluation/EB/Q_True Std              128.277\n",
      "evaluation/EB/Q_Pred Mean            1259\n",
      "evaluation/EB/Q_Pred Std               50.6833\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4604.49\n",
      "evaluation/Actions Mean                 0.0217287\n",
      "evaluation/Actions Std                  0.532994\n",
      "evaluation/Actions Max                  0.99857\n",
      "evaluation/Actions Min                 -0.999501\n",
      "time/backward_policy (s)                1.84625\n",
      "time/backward_zf1 (s)                   1.96852\n",
      "time/backward_zf2 (s)                   1.90412\n",
      "time/data sampling (s)                  0.288233\n",
      "time/data storing (s)                   0.0150281\n",
      "time/evaluation sampling (s)            1.714\n",
      "time/exploration sampling (s)           0.315901\n",
      "time/logging (s)                        0.0115592\n",
      "time/preback_alpha (s)                  0.976451\n",
      "time/preback_policy (s)                 1.085\n",
      "time/preback_start (s)                  0.143001\n",
      "time/preback_zf (s)                     5.18997\n",
      "time/saving (s)                         0.00591431\n",
      "time/training (s)                       2.20924\n",
      "time/epoch (s)                         17.6732\n",
      "time/total (s)                       2075.44\n",
      "Epoch                                 116\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:27:05.538388 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 117 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 128000\n",
      "trainer/ZF1 Loss                        5.85373\n",
      "trainer/ZF2 Loss                       -0.130074\n",
      "trainer/ZF Expert Reward               15.1114\n",
      "trainer/ZF Policy Reward                3.15863\n",
      "trainer/ZF CHI2 Term                   34.2113\n",
      "trainer/Policy Loss                 -1081.15\n",
      "trainer/Bias Loss                      56.5539\n",
      "trainer/Bias Value                     13.7063\n",
      "trainer/Policy Grad Norm              110.254\n",
      "trainer/Policy Param Norm              32.9885\n",
      "trainer/Zf1 Grad Norm                1124.83\n",
      "trainer/Zf1 Param Norm                 94.0532\n",
      "trainer/Zf2 Grad Norm                 914.062\n",
      "trainer/Zf2 Param Norm                 94.3185\n",
      "trainer/Z Expert Predictions Mean    1264.33\n",
      "trainer/Z Expert Predictions Std       46.17\n",
      "trainer/Z Expert Predictions Max     1327.72\n",
      "trainer/Z Expert Predictions Min      900.757\n",
      "trainer/Z Policy Predictions Mean    1076.39\n",
      "trainer/Z Policy Predictions Std      364.989\n",
      "trainer/Z Policy Predictions Max     1308.82\n",
      "trainer/Z Policy Predictions Min     -448.007\n",
      "trainer/Z Expert Targets Mean        1249.22\n",
      "trainer/Z Expert Targets Std           48.0375\n",
      "trainer/Z Expert Targets Max         1302.53\n",
      "trainer/Z Expert Targets Min          857.904\n",
      "trainer/Z Policy Targets Mean        1073.23\n",
      "trainer/Z Policy Targets Std          358.409\n",
      "trainer/Z Policy Targets Max         1297.72\n",
      "trainer/Z Policy Targets Min         -453.842\n",
      "trainer/Log Pis Mean                   19.5926\n",
      "trainer/Log Pis Std                     4.60835\n",
      "trainer/Policy mu Mean                  0.055635\n",
      "trainer/Policy mu Std                   1.12716\n",
      "trainer/Policy log std Mean            -3.10041\n",
      "trainer/Policy log std Std              0.923379\n",
      "trainer/Alpha                           0.0916352\n",
      "trainer/Alpha Loss                      0.0373292\n",
      "exploration/num steps total        122885\n",
      "exploration/num paths total           220\n",
      "evaluation/num steps total         960344\n",
      "evaluation/num paths total           1220\n",
      "evaluation/path length Mean           989.7\n",
      "evaluation/path length Std             30.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            897\n",
      "evaluation/Rewards Mean                 4.65599\n",
      "evaluation/Rewards Std                  0.989958\n",
      "evaluation/Rewards Max                  6.65174\n",
      "evaluation/Rewards Min                 -1.38364\n",
      "evaluation/Returns Mean              4608.03\n",
      "evaluation/Returns Std                121.103\n",
      "evaluation/Returns Max               4740.06\n",
      "evaluation/Returns Min               4334.68\n",
      "evaluation/Estimation Bias Mean      1200.97\n",
      "evaluation/Estimation Bias Std        144.144\n",
      "evaluation/EB/Q_True Mean              43.8743\n",
      "evaluation/EB/Q_True Std              134.641\n",
      "evaluation/EB/Q_Pred Mean            1244.84\n",
      "evaluation/EB/Q_Pred Std               58.0767\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4608.03\n",
      "evaluation/Actions Mean                 0.027193\n",
      "evaluation/Actions Std                  0.531791\n",
      "evaluation/Actions Max                  0.998542\n",
      "evaluation/Actions Min                 -0.999529\n",
      "time/backward_policy (s)                1.97443\n",
      "time/backward_zf1 (s)                   2.09906\n",
      "time/backward_zf2 (s)                   2.03491\n",
      "time/data sampling (s)                  0.270701\n",
      "time/data storing (s)                   0.0142153\n",
      "time/evaluation sampling (s)            1.74686\n",
      "time/exploration sampling (s)           0.315644\n",
      "time/logging (s)                        0.0136338\n",
      "time/preback_alpha (s)                  1.03189\n",
      "time/preback_policy (s)                 1.17281\n",
      "time/preback_start (s)                  0.141793\n",
      "time/preback_zf (s)                     5.15038\n",
      "time/saving (s)                         0.00671311\n",
      "time/training (s)                       2.01041\n",
      "time/epoch (s)                         17.9835\n",
      "time/total (s)                       2093.44\n",
      "Epoch                                 117\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:27:23.565480 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 118 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 129000\n",
      "trainer/ZF1 Loss                        5.21553\n",
      "trainer/ZF2 Loss                        6.09572\n",
      "trainer/ZF Expert Reward               14.4671\n",
      "trainer/ZF Policy Reward                2.95043\n",
      "trainer/ZF CHI2 Term                   36.9459\n",
      "trainer/Policy Loss                 -1072.67\n",
      "trainer/Bias Loss                      59.4672\n",
      "trainer/Bias Value                     13.7009\n",
      "trainer/Policy Grad Norm              108.465\n",
      "trainer/Policy Param Norm              33.0291\n",
      "trainer/Zf1 Grad Norm                1557.24\n",
      "trainer/Zf1 Param Norm                 94.3272\n",
      "trainer/Zf2 Grad Norm                1463.97\n",
      "trainer/Zf2 Param Norm                 94.5487\n",
      "trainer/Z Expert Predictions Mean    1242.58\n",
      "trainer/Z Expert Predictions Std      121.643\n",
      "trainer/Z Expert Predictions Max     1320.53\n",
      "trainer/Z Expert Predictions Min      -28.9205\n",
      "trainer/Z Policy Predictions Mean    1069.69\n",
      "trainer/Z Policy Predictions Std      383.399\n",
      "trainer/Z Policy Predictions Max     1300.44\n",
      "trainer/Z Policy Predictions Min     -465.766\n",
      "trainer/Z Expert Targets Mean        1228.11\n",
      "trainer/Z Expert Targets Std          119.471\n",
      "trainer/Z Expert Targets Max         1296.54\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1066.74\n",
      "trainer/Z Policy Targets Std          377.666\n",
      "trainer/Z Policy Targets Max         1289.52\n",
      "trainer/Z Policy Targets Min         -444.202\n",
      "trainer/Log Pis Mean                   19.9733\n",
      "trainer/Log Pis Std                     4.07688\n",
      "trainer/Policy mu Mean                  0.0436396\n",
      "trainer/Policy mu Std                   1.10711\n",
      "trainer/Policy log std Mean            -3.13378\n",
      "trainer/Policy log std Std              0.950395\n",
      "trainer/Alpha                           0.0914798\n",
      "trainer/Alpha Loss                      0.00243902\n",
      "exploration/num steps total        123885\n",
      "exploration/num paths total           221\n",
      "evaluation/num steps total         970344\n",
      "evaluation/num paths total           1230\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.40498\n",
      "evaluation/Rewards Std                  1.69067\n",
      "evaluation/Rewards Max                  6.86351\n",
      "evaluation/Rewards Min                 -2.96437\n",
      "evaluation/Returns Mean              4404.98\n",
      "evaluation/Returns Std                837.319\n",
      "evaluation/Returns Max               4900.79\n",
      "evaluation/Returns Min               1927.95\n",
      "evaluation/Estimation Bias Mean      1130.33\n",
      "evaluation/Estimation Bias Std        313.313\n",
      "evaluation/EB/Q_True Mean              42.7045\n",
      "evaluation/EB/Q_True Std              132.086\n",
      "evaluation/EB/Q_Pred Mean            1173.04\n",
      "evaluation/EB/Q_Pred Std              293.238\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4404.98\n",
      "evaluation/Actions Mean                 0.0397154\n",
      "evaluation/Actions Std                  0.557537\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                1.96691\n",
      "time/backward_zf1 (s)                   2.06025\n",
      "time/backward_zf2 (s)                   2.01299\n",
      "time/data sampling (s)                  0.274075\n",
      "time/data storing (s)                   0.0151806\n",
      "time/evaluation sampling (s)            1.73387\n",
      "time/exploration sampling (s)           0.323978\n",
      "time/logging (s)                        0.0122135\n",
      "time/preback_alpha (s)                  1.03433\n",
      "time/preback_policy (s)                 1.18966\n",
      "time/preback_start (s)                  0.142409\n",
      "time/preback_zf (s)                     5.14981\n",
      "time/saving (s)                         0.00636796\n",
      "time/training (s)                       2.03361\n",
      "time/epoch (s)                         17.9557\n",
      "time/total (s)                       2111.42\n",
      "Epoch                                 118\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:27:41.770220 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 119 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 130000\n",
      "trainer/ZF1 Loss                       14.3215\n",
      "trainer/ZF2 Loss                       12.3579\n",
      "trainer/ZF Expert Reward                9.43137\n",
      "trainer/ZF Policy Reward                1.83138\n",
      "trainer/ZF CHI2 Term                   40.5939\n",
      "trainer/Policy Loss                 -1039.05\n",
      "trainer/Bias Loss                      68.4142\n",
      "trainer/Bias Value                     13.6945\n",
      "trainer/Policy Grad Norm               86.3512\n",
      "trainer/Policy Param Norm              33.071\n",
      "trainer/Zf1 Grad Norm                1378.93\n",
      "trainer/Zf1 Param Norm                 94.5893\n",
      "trainer/Zf2 Grad Norm                1460.48\n",
      "trainer/Zf2 Param Norm                 94.7794\n",
      "trainer/Z Expert Predictions Mean    1245.55\n",
      "trainer/Z Expert Predictions Std       44.6471\n",
      "trainer/Z Expert Predictions Max     1303.79\n",
      "trainer/Z Expert Predictions Min     1041.63\n",
      "trainer/Z Policy Predictions Mean    1032\n",
      "trainer/Z Policy Predictions Std      417.332\n",
      "trainer/Z Policy Predictions Max     1291.99\n",
      "trainer/Z Policy Predictions Min     -448.801\n",
      "trainer/Z Expert Targets Mean        1236.12\n",
      "trainer/Z Expert Targets Std           45.2813\n",
      "trainer/Z Expert Targets Max         1292.51\n",
      "trainer/Z Expert Targets Min         1033.98\n",
      "trainer/Z Policy Targets Mean        1030.17\n",
      "trainer/Z Policy Targets Std          411.937\n",
      "trainer/Z Policy Targets Max         1291.19\n",
      "trainer/Z Policy Targets Min         -443.227\n",
      "trainer/Log Pis Mean                   19.8528\n",
      "trainer/Log Pis Std                     4.07335\n",
      "trainer/Policy mu Mean                  0.0639576\n",
      "trainer/Policy mu Std                   1.20003\n",
      "trainer/Policy log std Mean            -3.04925\n",
      "trainer/Policy log std Std              1.04494\n",
      "trainer/Alpha                           0.0924262\n",
      "trainer/Alpha Loss                      0.0136089\n",
      "exploration/num steps total        124885\n",
      "exploration/num paths total           222\n",
      "evaluation/num steps total         980344\n",
      "evaluation/num paths total           1240\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70675\n",
      "evaluation/Rewards Std                  0.935978\n",
      "evaluation/Rewards Max                  6.79865\n",
      "evaluation/Rewards Min                 -1.66053\n",
      "evaluation/Returns Mean              4706.75\n",
      "evaluation/Returns Std                 52.0648\n",
      "evaluation/Returns Max               4784.92\n",
      "evaluation/Returns Min               4607.33\n",
      "evaluation/Estimation Bias Mean      1197.34\n",
      "evaluation/Estimation Bias Std        140.035\n",
      "evaluation/EB/Q_True Mean              42.743\n",
      "evaluation/EB/Q_True Std              132.231\n",
      "evaluation/EB/Q_Pred Mean            1240.08\n",
      "evaluation/EB/Q_Pred Std               47.8397\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4706.75\n",
      "evaluation/Actions Mean                 0.0240603\n",
      "evaluation/Actions Std                  0.538717\n",
      "evaluation/Actions Max                  0.998797\n",
      "evaluation/Actions Min                 -0.999674\n",
      "time/backward_policy (s)                1.98341\n",
      "time/backward_zf1 (s)                   2.10378\n",
      "time/backward_zf2 (s)                   2.05082\n",
      "time/data sampling (s)                  0.27292\n",
      "time/data storing (s)                   0.0148858\n",
      "time/evaluation sampling (s)            1.73913\n",
      "time/exploration sampling (s)           0.320229\n",
      "time/logging (s)                        0.0117873\n",
      "time/preback_alpha (s)                  1.05229\n",
      "time/preback_policy (s)                 1.20836\n",
      "time/preback_start (s)                  0.143954\n",
      "time/preback_zf (s)                     5.20547\n",
      "time/saving (s)                         0.00588554\n",
      "time/training (s)                       2.02337\n",
      "time/epoch (s)                         18.1363\n",
      "time/total (s)                       2129.58\n",
      "Epoch                                 119\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:27:59.760809 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 120 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 131000\n",
      "trainer/ZF1 Loss                       15.5736\n",
      "trainer/ZF2 Loss                       27.4185\n",
      "trainer/ZF Expert Reward               19.2724\n",
      "trainer/ZF Policy Reward                6.72335\n",
      "trainer/ZF CHI2 Term                   54.2401\n",
      "trainer/Policy Loss                 -1050.56\n",
      "trainer/Bias Loss                      95.7781\n",
      "trainer/Bias Value                     13.6914\n",
      "trainer/Policy Grad Norm              108.984\n",
      "trainer/Policy Param Norm              33.1152\n",
      "trainer/Zf1 Grad Norm                1535.61\n",
      "trainer/Zf1 Param Norm                 94.82\n",
      "trainer/Zf2 Grad Norm                3439\n",
      "trainer/Zf2 Param Norm                 94.9926\n",
      "trainer/Z Expert Predictions Mean    1241.85\n",
      "trainer/Z Expert Predictions Std       90.4691\n",
      "trainer/Z Expert Predictions Max     1314.11\n",
      "trainer/Z Expert Predictions Min       52.6904\n",
      "trainer/Z Policy Predictions Mean    1043.77\n",
      "trainer/Z Policy Predictions Std      400.773\n",
      "trainer/Z Policy Predictions Max     1293.64\n",
      "trainer/Z Policy Predictions Min     -452.513\n",
      "trainer/Z Expert Targets Mean        1222.58\n",
      "trainer/Z Expert Targets Std           92.2927\n",
      "trainer/Z Expert Targets Max         1285.82\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1037.04\n",
      "trainer/Z Policy Targets Std          390.532\n",
      "trainer/Z Policy Targets Max         1282.16\n",
      "trainer/Z Policy Targets Min         -436.382\n",
      "trainer/Log Pis Mean                   20.399\n",
      "trainer/Log Pis Std                     4.36633\n",
      "trainer/Policy mu Mean                  0.0557159\n",
      "trainer/Policy mu Std                   1.22107\n",
      "trainer/Policy log std Mean            -3.04739\n",
      "trainer/Policy log std Std              0.985372\n",
      "trainer/Alpha                           0.0923217\n",
      "trainer/Alpha Loss                     -0.0368414\n",
      "exploration/num steps total        126885\n",
      "exploration/num paths total           224\n",
      "evaluation/num steps total         990344\n",
      "evaluation/num paths total           1250\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.57179\n",
      "evaluation/Rewards Std                  0.980942\n",
      "evaluation/Rewards Max                  6.58998\n",
      "evaluation/Rewards Min                 -1.7879\n",
      "evaluation/Returns Mean              4571.79\n",
      "evaluation/Returns Std                 93.2539\n",
      "evaluation/Returns Max               4712.34\n",
      "evaluation/Returns Min               4456.74\n",
      "evaluation/Estimation Bias Mean      1184.21\n",
      "evaluation/Estimation Bias Std        138.228\n",
      "evaluation/EB/Q_True Mean              41.0214\n",
      "evaluation/EB/Q_True Std              126.496\n",
      "evaluation/EB/Q_Pred Mean            1225.23\n",
      "evaluation/EB/Q_Pred Std               54.6046\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4571.79\n",
      "evaluation/Actions Mean                 0.018734\n",
      "evaluation/Actions Std                  0.538221\n",
      "evaluation/Actions Max                  0.998783\n",
      "evaluation/Actions Min                 -0.999052\n",
      "time/backward_policy (s)                1.91858\n",
      "time/backward_zf1 (s)                   2.02447\n",
      "time/backward_zf2 (s)                   1.96822\n",
      "time/data sampling (s)                  0.279166\n",
      "time/data storing (s)                   0.014388\n",
      "time/evaluation sampling (s)            1.73469\n",
      "time/exploration sampling (s)           0.320715\n",
      "time/logging (s)                        0.0126276\n",
      "time/preback_alpha (s)                  0.99124\n",
      "time/preback_policy (s)                 1.12985\n",
      "time/preback_start (s)                  0.144524\n",
      "time/preback_zf (s)                     5.1707\n",
      "time/saving (s)                         0.00627176\n",
      "time/training (s)                       2.21127\n",
      "time/epoch (s)                         17.9267\n",
      "time/total (s)                       2147.52\n",
      "Epoch                                 120\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:28:17.783629 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 121 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 132000\n",
      "trainer/ZF1 Loss                      293.175\n",
      "trainer/ZF2 Loss                      296.691\n",
      "trainer/ZF Expert Reward               13.2768\n",
      "trainer/ZF Policy Reward                5.61992\n",
      "trainer/ZF CHI2 Term                  322.295\n",
      "trainer/Policy Loss                 -1014.93\n",
      "trainer/Bias Loss                      61.3856\n",
      "trainer/Bias Value                     13.692\n",
      "trainer/Policy Grad Norm              213.784\n",
      "trainer/Policy Param Norm              33.1573\n",
      "trainer/Zf1 Grad Norm                1441.09\n",
      "trainer/Zf1 Param Norm                 95.0618\n",
      "trainer/Zf2 Grad Norm                2231.37\n",
      "trainer/Zf2 Param Norm                 95.1987\n",
      "trainer/Z Expert Predictions Mean    1235.99\n",
      "trainer/Z Expert Predictions Std       32.6626\n",
      "trainer/Z Expert Predictions Max     1295.29\n",
      "trainer/Z Expert Predictions Min     1046.02\n",
      "trainer/Z Policy Predictions Mean    1010.11\n",
      "trainer/Z Policy Predictions Std      415.497\n",
      "trainer/Z Policy Predictions Max     1281.58\n",
      "trainer/Z Policy Predictions Min     -446.037\n",
      "trainer/Z Expert Targets Mean        1222.71\n",
      "trainer/Z Expert Targets Std           32.2681\n",
      "trainer/Z Expert Targets Max         1283.05\n",
      "trainer/Z Expert Targets Min         1028.77\n",
      "trainer/Z Policy Targets Mean        1004.49\n",
      "trainer/Z Policy Targets Std          415.607\n",
      "trainer/Z Policy Targets Max         1273.21\n",
      "trainer/Z Policy Targets Min         -441.288\n",
      "trainer/Log Pis Mean                   19.9039\n",
      "trainer/Log Pis Std                     4.30013\n",
      "trainer/Policy mu Mean                  0.0273026\n",
      "trainer/Policy mu Std                   1.2285\n",
      "trainer/Policy log std Mean            -3.0243\n",
      "trainer/Policy log std Std              1.01282\n",
      "trainer/Alpha                           0.0921217\n",
      "trainer/Alpha Loss                      0.00884891\n",
      "exploration/num steps total        126885\n",
      "exploration/num paths total           224\n",
      "evaluation/num steps total              1.00034e+06\n",
      "evaluation/num paths total           1260\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68049\n",
      "evaluation/Rewards Std                  1.02201\n",
      "evaluation/Rewards Max                  6.89347\n",
      "evaluation/Rewards Min                 -1.44002\n",
      "evaluation/Returns Mean              4680.49\n",
      "evaluation/Returns Std                133.438\n",
      "evaluation/Returns Max               4848.61\n",
      "evaluation/Returns Min               4419.95\n",
      "evaluation/Estimation Bias Mean      1175.69\n",
      "evaluation/Estimation Bias Std        150.551\n",
      "evaluation/EB/Q_True Mean              44.1775\n",
      "evaluation/EB/Q_True Std              136.126\n",
      "evaluation/EB/Q_Pred Mean            1219.86\n",
      "evaluation/EB/Q_Pred Std               57.3743\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4680.49\n",
      "evaluation/Actions Mean                 0.0325723\n",
      "evaluation/Actions Std                  0.534777\n",
      "evaluation/Actions Max                  0.998885\n",
      "evaluation/Actions Min                 -0.998739\n",
      "time/backward_policy (s)                1.96344\n",
      "time/backward_zf1 (s)                   2.07643\n",
      "time/backward_zf2 (s)                   2.01843\n",
      "time/data sampling (s)                  0.277627\n",
      "time/data storing (s)                   0.0141141\n",
      "time/evaluation sampling (s)            1.73303\n",
      "time/exploration sampling (s)           0.311623\n",
      "time/logging (s)                        0.0118624\n",
      "time/preback_alpha (s)                  1.01981\n",
      "time/preback_policy (s)                 1.15927\n",
      "time/preback_start (s)                  0.142218\n",
      "time/preback_zf (s)                     5.14482\n",
      "time/saving (s)                         0.0177374\n",
      "time/training (s)                       2.06046\n",
      "time/epoch (s)                         17.9509\n",
      "time/total (s)                       2165.49\n",
      "Epoch                                 121\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:28:35.384121 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 122 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 133000\n",
      "trainer/ZF1 Loss                      311.045\n",
      "trainer/ZF2 Loss                      279.599\n",
      "trainer/ZF Expert Reward               14.7661\n",
      "trainer/ZF Policy Reward                9.32661\n",
      "trainer/ZF CHI2 Term                  320.42\n",
      "trainer/Policy Loss                 -1056.33\n",
      "trainer/Bias Loss                      91.5057\n",
      "trainer/Bias Value                     13.6845\n",
      "trainer/Policy Grad Norm              187.734\n",
      "trainer/Policy Param Norm              33.1939\n",
      "trainer/Zf1 Grad Norm                4895.31\n",
      "trainer/Zf1 Param Norm                 95.3232\n",
      "trainer/Zf2 Grad Norm               10066.3\n",
      "trainer/Zf2 Param Norm                 95.4348\n",
      "trainer/Z Expert Predictions Mean    1227.01\n",
      "trainer/Z Expert Predictions Std       44.3299\n",
      "trainer/Z Expert Predictions Max     1285.03\n",
      "trainer/Z Expert Predictions Min     1003.78\n",
      "trainer/Z Policy Predictions Mean    1050.91\n",
      "trainer/Z Policy Predictions Std      377.876\n",
      "trainer/Z Policy Predictions Max     1285.38\n",
      "trainer/Z Policy Predictions Min     -426.211\n",
      "trainer/Z Expert Targets Mean        1212.25\n",
      "trainer/Z Expert Targets Std           43.9218\n",
      "trainer/Z Expert Targets Max         1267.66\n",
      "trainer/Z Expert Targets Min          984.379\n",
      "trainer/Z Policy Targets Mean        1041.58\n",
      "trainer/Z Policy Targets Std          374.646\n",
      "trainer/Z Policy Targets Max         1263.51\n",
      "trainer/Z Policy Targets Min         -404.386\n",
      "trainer/Log Pis Mean                   19.8573\n",
      "trainer/Log Pis Std                     3.97497\n",
      "trainer/Policy mu Mean                  0.0489255\n",
      "trainer/Policy mu Std                   1.08411\n",
      "trainer/Policy log std Mean            -3.16735\n",
      "trainer/Policy log std Std              0.959553\n",
      "trainer/Alpha                           0.0919593\n",
      "trainer/Alpha Loss                      0.013126\n",
      "exploration/num steps total        128885\n",
      "exploration/num paths total           226\n",
      "evaluation/num steps total              1.01034e+06\n",
      "evaluation/num paths total           1270\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.25656\n",
      "evaluation/Rewards Std                  1.93782\n",
      "evaluation/Rewards Max                  6.87168\n",
      "evaluation/Rewards Min                 -3.04668\n",
      "evaluation/Returns Mean              4256.56\n",
      "evaluation/Returns Std               1300.51\n",
      "evaluation/Returns Max               4844.16\n",
      "evaluation/Returns Min                369.322\n",
      "evaluation/Estimation Bias Mean      1126.19\n",
      "evaluation/Estimation Bias Std        373.662\n",
      "evaluation/EB/Q_True Mean               0.0925906\n",
      "evaluation/EB/Q_True Std               89.3813\n",
      "evaluation/EB/Q_Pred Mean            1126.28\n",
      "evaluation/EB/Q_Pred Std              363.119\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4256.56\n",
      "evaluation/Actions Mean                 0.0518516\n",
      "evaluation/Actions Std                  0.561084\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -0.99996\n",
      "time/backward_policy (s)                1.81881\n",
      "time/backward_zf1 (s)                   1.93658\n",
      "time/backward_zf2 (s)                   1.87258\n",
      "time/data sampling (s)                  0.272611\n",
      "time/data storing (s)                   0.0145309\n",
      "time/evaluation sampling (s)            1.74041\n",
      "time/exploration sampling (s)           0.32072\n",
      "time/logging (s)                        0.0119243\n",
      "time/preback_alpha (s)                  0.949147\n",
      "time/preback_policy (s)                 1.0609\n",
      "time/preback_start (s)                  0.142966\n",
      "time/preback_zf (s)                     5.16187\n",
      "time/saving (s)                         0.00633671\n",
      "time/training (s)                       2.21917\n",
      "time/epoch (s)                         17.5286\n",
      "time/total (s)                       2183.05\n",
      "Epoch                                 122\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:28:53.444398 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 123 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 134000\n",
      "trainer/ZF1 Loss                       23.4715\n",
      "trainer/ZF2 Loss                       25.9964\n",
      "trainer/ZF Expert Reward               15.2941\n",
      "trainer/ZF Policy Reward                2.00993\n",
      "trainer/ZF CHI2 Term                   57.5594\n",
      "trainer/Policy Loss                 -1069.9\n",
      "trainer/Bias Loss                      54.2964\n",
      "trainer/Bias Value                     13.6806\n",
      "trainer/Policy Grad Norm              107.904\n",
      "trainer/Policy Param Norm              33.2315\n",
      "trainer/Zf1 Grad Norm                 956.161\n",
      "trainer/Zf1 Param Norm                 95.5788\n",
      "trainer/Zf2 Grad Norm                 945.527\n",
      "trainer/Zf2 Param Norm                 95.6463\n",
      "trainer/Z Expert Predictions Mean    1227.27\n",
      "trainer/Z Expert Predictions Std       36.6847\n",
      "trainer/Z Expert Predictions Max     1283.73\n",
      "trainer/Z Expert Predictions Min     1022.6\n",
      "trainer/Z Policy Predictions Mean    1065.44\n",
      "trainer/Z Policy Predictions Std      361.028\n",
      "trainer/Z Policy Predictions Max     1265.86\n",
      "trainer/Z Policy Predictions Min     -425.661\n",
      "trainer/Z Expert Targets Mean        1211.97\n",
      "trainer/Z Expert Targets Std           36.2282\n",
      "trainer/Z Expert Targets Max         1263.87\n",
      "trainer/Z Expert Targets Min         1023.05\n",
      "trainer/Z Policy Targets Mean        1063.43\n",
      "trainer/Z Policy Targets Std          352.042\n",
      "trainer/Z Policy Targets Max         1273.1\n",
      "trainer/Z Policy Targets Min         -417.053\n",
      "trainer/Log Pis Mean                   19.7387\n",
      "trainer/Log Pis Std                     3.66662\n",
      "trainer/Policy mu Mean                  0.0478553\n",
      "trainer/Policy mu Std                   1.03215\n",
      "trainer/Policy log std Mean            -3.21565\n",
      "trainer/Policy log std Std              0.881497\n",
      "trainer/Alpha                           0.0926221\n",
      "trainer/Alpha Loss                      0.0242073\n",
      "exploration/num steps total        128885\n",
      "exploration/num paths total           226\n",
      "evaluation/num steps total              1.02017e+06\n",
      "evaluation/num paths total           1280\n",
      "evaluation/path length Mean           982.3\n",
      "evaluation/path length Std             53.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            823\n",
      "evaluation/Rewards Mean                 4.75603\n",
      "evaluation/Rewards Std                  1.08398\n",
      "evaluation/Rewards Max                  6.81777\n",
      "evaluation/Rewards Min                 -1.96537\n",
      "evaluation/Returns Mean              4671.85\n",
      "evaluation/Returns Std                317.763\n",
      "evaluation/Returns Max               4890.03\n",
      "evaluation/Returns Min               3742.96\n",
      "evaluation/Estimation Bias Mean      1157.36\n",
      "evaluation/Estimation Bias Std        158.896\n",
      "evaluation/EB/Q_True Mean              46.1034\n",
      "evaluation/EB/Q_True Std              140.879\n",
      "evaluation/EB/Q_Pred Mean            1203.46\n",
      "evaluation/EB/Q_Pred Std               59.3466\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4671.85\n",
      "evaluation/Actions Mean                 0.0217743\n",
      "evaluation/Actions Std                  0.530573\n",
      "evaluation/Actions Max                  0.999448\n",
      "evaluation/Actions Min                 -0.999826\n",
      "time/backward_policy (s)                1.96813\n",
      "time/backward_zf1 (s)                   2.09579\n",
      "time/backward_zf2 (s)                   2.04856\n",
      "time/data sampling (s)                  0.276968\n",
      "time/data storing (s)                   0.0149408\n",
      "time/evaluation sampling (s)            1.70006\n",
      "time/exploration sampling (s)           0.314854\n",
      "time/logging (s)                        0.0112943\n",
      "time/preback_alpha (s)                  1.02444\n",
      "time/preback_policy (s)                 1.16594\n",
      "time/preback_start (s)                  0.14302\n",
      "time/preback_zf (s)                     5.15349\n",
      "time/saving (s)                         0.0059962\n",
      "time/training (s)                       2.06681\n",
      "time/epoch (s)                         17.9903\n",
      "time/total (s)                       2201.06\n",
      "Epoch                                 123\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:29:10.956129 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 124 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 135000\n",
      "trainer/ZF1 Loss                        7.79578\n",
      "trainer/ZF2 Loss                        9.72763\n",
      "trainer/ZF Expert Reward               11.8164\n",
      "trainer/ZF Policy Reward                2.35647\n",
      "trainer/ZF CHI2 Term                   37.8571\n",
      "trainer/Policy Loss                 -1007.72\n",
      "trainer/Bias Loss                      72.7941\n",
      "trainer/Bias Value                     13.6754\n",
      "trainer/Policy Grad Norm               87.3053\n",
      "trainer/Policy Param Norm              33.2723\n",
      "trainer/Zf1 Grad Norm                1028.14\n",
      "trainer/Zf1 Param Norm                 95.8267\n",
      "trainer/Zf2 Grad Norm                1445.4\n",
      "trainer/Zf2 Param Norm                 95.8672\n",
      "trainer/Z Expert Predictions Mean    1208.35\n",
      "trainer/Z Expert Predictions Std       47.4847\n",
      "trainer/Z Expert Predictions Max     1281.35\n",
      "trainer/Z Expert Predictions Min      941.342\n",
      "trainer/Z Policy Predictions Mean    1002.99\n",
      "trainer/Z Policy Predictions Std      417.58\n",
      "trainer/Z Policy Predictions Max     1267.56\n",
      "trainer/Z Policy Predictions Min     -437.76\n",
      "trainer/Z Expert Targets Mean        1196.53\n",
      "trainer/Z Expert Targets Std           46.8625\n",
      "trainer/Z Expert Targets Max         1264.04\n",
      "trainer/Z Expert Targets Min          952.421\n",
      "trainer/Z Policy Targets Mean        1000.64\n",
      "trainer/Z Policy Targets Std          409.229\n",
      "trainer/Z Policy Targets Max         1257.57\n",
      "trainer/Z Policy Targets Min         -408.36\n",
      "trainer/Log Pis Mean                   19.8338\n",
      "trainer/Log Pis Std                     4.39956\n",
      "trainer/Policy mu Mean                  0.0455761\n",
      "trainer/Policy mu Std                   1.14792\n",
      "trainer/Policy log std Mean            -3.0789\n",
      "trainer/Policy log std Std              1.01502\n",
      "trainer/Alpha                           0.0930587\n",
      "trainer/Alpha Loss                      0.0154659\n",
      "exploration/num steps total        128885\n",
      "exploration/num paths total           226\n",
      "evaluation/num steps total              1.03017e+06\n",
      "evaluation/num paths total           1290\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66734\n",
      "evaluation/Rewards Std                  0.972364\n",
      "evaluation/Rewards Max                  6.66901\n",
      "evaluation/Rewards Min                 -1.72816\n",
      "evaluation/Returns Mean              4667.34\n",
      "evaluation/Returns Std                 69.2138\n",
      "evaluation/Returns Max               4740.85\n",
      "evaluation/Returns Min               4530.56\n",
      "evaluation/Estimation Bias Mean      1164.15\n",
      "evaluation/Estimation Bias Std        136.041\n",
      "evaluation/EB/Q_True Mean              41.526\n",
      "evaluation/EB/Q_True Std              127.82\n",
      "evaluation/EB/Q_Pred Mean            1205.68\n",
      "evaluation/EB/Q_Pred Std               48.5074\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4667.34\n",
      "evaluation/Actions Mean                 0.0205653\n",
      "evaluation/Actions Std                  0.539681\n",
      "evaluation/Actions Max                  0.998526\n",
      "evaluation/Actions Min                 -0.999249\n",
      "time/backward_policy (s)                1.7546\n",
      "time/backward_zf1 (s)                   1.89442\n",
      "time/backward_zf2 (s)                   1.81453\n",
      "time/data sampling (s)                  0.263562\n",
      "time/data storing (s)                   0.0142594\n",
      "time/evaluation sampling (s)            1.7374\n",
      "time/exploration sampling (s)           0.31275\n",
      "time/logging (s)                        0.0117802\n",
      "time/preback_alpha (s)                  0.917695\n",
      "time/preback_policy (s)                 1.02631\n",
      "time/preback_start (s)                  0.142245\n",
      "time/preback_zf (s)                     5.15887\n",
      "time/saving (s)                         0.00555339\n",
      "time/training (s)                       2.38963\n",
      "time/epoch (s)                         17.4436\n",
      "time/total (s)                       2218.53\n",
      "Epoch                                 124\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:29:28.809998 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 125 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 136000\n",
      "trainer/ZF1 Loss                        1.05359\n",
      "trainer/ZF2 Loss                       -2.10198\n",
      "trainer/ZF Expert Reward               13.2962\n",
      "trainer/ZF Policy Reward                1.32204\n",
      "trainer/ZF CHI2 Term                   31.2762\n",
      "trainer/Policy Loss                 -1045.92\n",
      "trainer/Bias Loss                      45.1283\n",
      "trainer/Bias Value                     13.6701\n",
      "trainer/Policy Grad Norm              116.758\n",
      "trainer/Policy Param Norm              33.315\n",
      "trainer/Zf1 Grad Norm                 835.448\n",
      "trainer/Zf1 Param Norm                 96.1078\n",
      "trainer/Zf2 Grad Norm                1354.91\n",
      "trainer/Zf2 Param Norm                 96.096\n",
      "trainer/Z Expert Predictions Mean    1210.46\n",
      "trainer/Z Expert Predictions Std       38.61\n",
      "trainer/Z Expert Predictions Max     1269.16\n",
      "trainer/Z Expert Predictions Min      994.804\n",
      "trainer/Z Policy Predictions Mean    1041.32\n",
      "trainer/Z Policy Predictions Std      363.694\n",
      "trainer/Z Policy Predictions Max     1257.04\n",
      "trainer/Z Policy Predictions Min     -435.715\n",
      "trainer/Z Expert Targets Mean        1197.17\n",
      "trainer/Z Expert Targets Std           39.4135\n",
      "trainer/Z Expert Targets Max         1249.34\n",
      "trainer/Z Expert Targets Min          972.781\n",
      "trainer/Z Policy Targets Mean        1040\n",
      "trainer/Z Policy Targets Std          359.456\n",
      "trainer/Z Policy Targets Max         1249.03\n",
      "trainer/Z Policy Targets Min         -422.263\n",
      "trainer/Log Pis Mean                   20.0265\n",
      "trainer/Log Pis Std                     3.71926\n",
      "trainer/Policy mu Mean                  0.0175227\n",
      "trainer/Policy mu Std                   1.11484\n",
      "trainer/Policy log std Mean            -3.14609\n",
      "trainer/Policy log std Std              0.911917\n",
      "trainer/Alpha                           0.0940609\n",
      "trainer/Alpha Loss                     -0.00249499\n",
      "exploration/num steps total        130885\n",
      "exploration/num paths total           228\n",
      "evaluation/num steps total              1.03935e+06\n",
      "evaluation/num paths total           1300\n",
      "evaluation/path length Mean           918.2\n",
      "evaluation/path length Std            245.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            182\n",
      "evaluation/Rewards Mean                 4.65985\n",
      "evaluation/Rewards Std                  1.00957\n",
      "evaluation/Rewards Max                  6.82102\n",
      "evaluation/Rewards Min                 -1.72945\n",
      "evaluation/Returns Mean              4278.68\n",
      "evaluation/Returns Std               1176.9\n",
      "evaluation/Returns Max               4853.93\n",
      "evaluation/Returns Min                760.66\n",
      "evaluation/Estimation Bias Mean      1145.75\n",
      "evaluation/Estimation Bias Std        156.207\n",
      "evaluation/EB/Q_True Mean              48.46\n",
      "evaluation/EB/Q_True Std              141.939\n",
      "evaluation/EB/Q_Pred Mean            1194.21\n",
      "evaluation/EB/Q_Pred Std               54.0643\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4278.68\n",
      "evaluation/Actions Mean                 0.0204387\n",
      "evaluation/Actions Std                  0.538389\n",
      "evaluation/Actions Max                  0.998694\n",
      "evaluation/Actions Min                 -0.999369\n",
      "time/backward_policy (s)                1.86342\n",
      "time/backward_zf1 (s)                   1.9985\n",
      "time/backward_zf2 (s)                   1.92442\n",
      "time/data sampling (s)                  0.276784\n",
      "time/data storing (s)                   0.0147378\n",
      "time/evaluation sampling (s)            1.77878\n",
      "time/exploration sampling (s)           0.324079\n",
      "time/logging (s)                        0.0114605\n",
      "time/preback_alpha (s)                  0.990311\n",
      "time/preback_policy (s)                 1.1119\n",
      "time/preback_start (s)                  0.14324\n",
      "time/preback_zf (s)                     5.18621\n",
      "time/saving (s)                         0.00574823\n",
      "time/training (s)                       2.15854\n",
      "time/epoch (s)                         17.7881\n",
      "time/total (s)                       2236.33\n",
      "Epoch                                 125\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:29:46.762565 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 126 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 137000\n",
      "trainer/ZF1 Loss                       14.9248\n",
      "trainer/ZF2 Loss                        7.74681\n",
      "trainer/ZF Expert Reward               15.8015\n",
      "trainer/ZF Policy Reward                5.65559\n",
      "trainer/ZF CHI2 Term                   41.2025\n",
      "trainer/Policy Loss                 -1039.11\n",
      "trainer/Bias Loss                      55.2944\n",
      "trainer/Bias Value                     13.6669\n",
      "trainer/Policy Grad Norm               75.2802\n",
      "trainer/Policy Param Norm              33.3548\n",
      "trainer/Zf1 Grad Norm                1221.44\n",
      "trainer/Zf1 Param Norm                 96.3575\n",
      "trainer/Zf2 Grad Norm                 973.279\n",
      "trainer/Zf2 Param Norm                 96.324\n",
      "trainer/Z Expert Predictions Mean    1206.77\n",
      "trainer/Z Expert Predictions Std       37.6994\n",
      "trainer/Z Expert Predictions Max     1258.33\n",
      "trainer/Z Expert Predictions Min     1024.12\n",
      "trainer/Z Policy Predictions Mean    1035.88\n",
      "trainer/Z Policy Predictions Std      369.423\n",
      "trainer/Z Policy Predictions Max     1251.76\n",
      "trainer/Z Policy Predictions Min     -440.215\n",
      "trainer/Z Expert Targets Mean        1190.97\n",
      "trainer/Z Expert Targets Std           38.4048\n",
      "trainer/Z Expert Targets Max         1247.52\n",
      "trainer/Z Expert Targets Min          999.164\n",
      "trainer/Z Policy Targets Mean        1030.23\n",
      "trainer/Z Policy Targets Std          365.038\n",
      "trainer/Z Policy Targets Max         1248.05\n",
      "trainer/Z Policy Targets Min         -428.554\n",
      "trainer/Log Pis Mean                   19.92\n",
      "trainer/Log Pis Std                     3.98318\n",
      "trainer/Policy mu Mean                  0.0118487\n",
      "trainer/Policy mu Std                   1.08412\n",
      "trainer/Policy log std Mean            -3.16399\n",
      "trainer/Policy log std Std              0.930348\n",
      "trainer/Alpha                           0.0938299\n",
      "trainer/Alpha Loss                      0.00750783\n",
      "exploration/num steps total        131885\n",
      "exploration/num paths total           229\n",
      "evaluation/num steps total              1.04935e+06\n",
      "evaluation/num paths total           1310\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62179\n",
      "evaluation/Rewards Std                  1.05101\n",
      "evaluation/Rewards Max                  6.8243\n",
      "evaluation/Rewards Min                 -1.34918\n",
      "evaluation/Returns Mean              4621.79\n",
      "evaluation/Returns Std                 82.9233\n",
      "evaluation/Returns Max               4757.8\n",
      "evaluation/Returns Min               4475.89\n",
      "evaluation/Estimation Bias Mean      1143.22\n",
      "evaluation/Estimation Bias Std        145.499\n",
      "evaluation/EB/Q_True Mean              41.8558\n",
      "evaluation/EB/Q_True Std              128.938\n",
      "evaluation/EB/Q_Pred Mean            1185.08\n",
      "evaluation/EB/Q_Pred Std               59.4926\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4621.79\n",
      "evaluation/Actions Mean                 0.0178361\n",
      "evaluation/Actions Std                  0.533853\n",
      "evaluation/Actions Max                  0.998832\n",
      "evaluation/Actions Min                 -0.999493\n",
      "time/backward_policy (s)                1.92296\n",
      "time/backward_zf1 (s)                   2.02091\n",
      "time/backward_zf2 (s)                   1.97822\n",
      "time/data sampling (s)                  0.301745\n",
      "time/data storing (s)                   0.0140725\n",
      "time/evaluation sampling (s)            1.76337\n",
      "time/exploration sampling (s)           0.313245\n",
      "time/logging (s)                        0.0120752\n",
      "time/preback_alpha (s)                  1.03694\n",
      "time/preback_policy (s)                 1.17477\n",
      "time/preback_start (s)                  0.142386\n",
      "time/preback_zf (s)                     5.1562\n",
      "time/saving (s)                         0.00640401\n",
      "time/training (s)                       2.03963\n",
      "time/epoch (s)                         17.8829\n",
      "time/total (s)                       2254.24\n",
      "Epoch                                 126\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:30:04.716538 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 127 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 138000\n",
      "trainer/ZF1 Loss                        2.39666\n",
      "trainer/ZF2 Loss                       12.5684\n",
      "trainer/ZF Expert Reward               17.6392\n",
      "trainer/ZF Policy Reward                7.91798\n",
      "trainer/ZF CHI2 Term                   37.0803\n",
      "trainer/Policy Loss                 -1003.78\n",
      "trainer/Bias Loss                      62.4013\n",
      "trainer/Bias Value                     13.6654\n",
      "trainer/Policy Grad Norm              100.513\n",
      "trainer/Policy Param Norm              33.3952\n",
      "trainer/Zf1 Grad Norm                 816.619\n",
      "trainer/Zf1 Param Norm                 96.6266\n",
      "trainer/Zf2 Grad Norm                1092.69\n",
      "trainer/Zf2 Param Norm                 96.5571\n",
      "trainer/Z Expert Predictions Mean    1200.42\n",
      "trainer/Z Expert Predictions Std       41.3421\n",
      "trainer/Z Expert Predictions Max     1264.86\n",
      "trainer/Z Expert Predictions Min      981.401\n",
      "trainer/Z Policy Predictions Mean    1001.89\n",
      "trainer/Z Policy Predictions Std      397.838\n",
      "trainer/Z Policy Predictions Max     1257.85\n",
      "trainer/Z Policy Predictions Min     -378.818\n",
      "trainer/Z Expert Targets Mean        1182.79\n",
      "trainer/Z Expert Targets Std           43.0254\n",
      "trainer/Z Expert Targets Max         1251.59\n",
      "trainer/Z Expert Targets Min          945.666\n",
      "trainer/Z Policy Targets Mean         993.969\n",
      "trainer/Z Policy Targets Std          391.645\n",
      "trainer/Z Policy Targets Max         1236.81\n",
      "trainer/Z Policy Targets Min         -379.461\n",
      "trainer/Log Pis Mean                   20.0773\n",
      "trainer/Log Pis Std                     4.4962\n",
      "trainer/Policy mu Mean                  0.016485\n",
      "trainer/Policy mu Std                   1.12526\n",
      "trainer/Policy log std Mean            -3.14588\n",
      "trainer/Policy log std Std              0.989524\n",
      "trainer/Alpha                           0.0936203\n",
      "trainer/Alpha Loss                     -0.00724137\n",
      "exploration/num steps total        132885\n",
      "exploration/num paths total           230\n",
      "evaluation/num steps total              1.05839e+06\n",
      "evaluation/num paths total           1320\n",
      "evaluation/path length Mean           904.3\n",
      "evaluation/path length Std            287.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             43\n",
      "evaluation/Rewards Mean                 4.58875\n",
      "evaluation/Rewards Std                  1.09848\n",
      "evaluation/Rewards Max                  6.7438\n",
      "evaluation/Rewards Min                 -1.56133\n",
      "evaluation/Returns Mean              4149.6\n",
      "evaluation/Returns Std               1366.81\n",
      "evaluation/Returns Max               4818.32\n",
      "evaluation/Returns Min                 68.1763\n",
      "evaluation/Estimation Bias Mean      1126.51\n",
      "evaluation/Estimation Bias Std        148.825\n",
      "evaluation/EB/Q_True Mean              47.2875\n",
      "evaluation/EB/Q_True Std              137.727\n",
      "evaluation/EB/Q_Pred Mean            1173.8\n",
      "evaluation/EB/Q_Pred Std               58.0675\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4149.6\n",
      "evaluation/Actions Mean                 0.026346\n",
      "evaluation/Actions Std                  0.524051\n",
      "evaluation/Actions Max                  0.999626\n",
      "evaluation/Actions Min                 -0.999734\n",
      "time/backward_policy (s)                1.92455\n",
      "time/backward_zf1 (s)                   2.02688\n",
      "time/backward_zf2 (s)                   1.97398\n",
      "time/data sampling (s)                  0.292798\n",
      "time/data storing (s)                   0.0146824\n",
      "time/evaluation sampling (s)            1.73256\n",
      "time/exploration sampling (s)           0.322015\n",
      "time/logging (s)                        0.0109698\n",
      "time/preback_alpha (s)                  1.00037\n",
      "time/preback_policy (s)                 1.12311\n",
      "time/preback_start (s)                  0.144185\n",
      "time/preback_zf (s)                     5.1548\n",
      "time/saving (s)                         0.00563895\n",
      "time/training (s)                       2.15628\n",
      "time/epoch (s)                         17.8828\n",
      "time/total (s)                       2272.14\n",
      "Epoch                                 127\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:30:23.056515 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 128 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 139000\n",
      "trainer/ZF1 Loss                        8.80642\n",
      "trainer/ZF2 Loss                       10.7378\n",
      "trainer/ZF Expert Reward               13.4237\n",
      "trainer/ZF Policy Reward                5.49152\n",
      "trainer/ZF CHI2 Term                   37.5582\n",
      "trainer/Policy Loss                 -1076.18\n",
      "trainer/Bias Loss                      78.4637\n",
      "trainer/Bias Value                     13.6612\n",
      "trainer/Policy Grad Norm              116.066\n",
      "trainer/Policy Param Norm              33.4396\n",
      "trainer/Zf1 Grad Norm                1096.12\n",
      "trainer/Zf1 Param Norm                 96.8876\n",
      "trainer/Zf2 Grad Norm                1237.47\n",
      "trainer/Zf2 Param Norm                 96.7815\n",
      "trainer/Z Expert Predictions Mean    1193.62\n",
      "trainer/Z Expert Predictions Std       39.5084\n",
      "trainer/Z Expert Predictions Max     1251.89\n",
      "trainer/Z Expert Predictions Min     1019.42\n",
      "trainer/Z Policy Predictions Mean    1071.28\n",
      "trainer/Z Policy Predictions Std      288.517\n",
      "trainer/Z Policy Predictions Max     1241\n",
      "trainer/Z Policy Predictions Min     -395.769\n",
      "trainer/Z Expert Targets Mean        1180.2\n",
      "trainer/Z Expert Targets Std           40.3386\n",
      "trainer/Z Expert Targets Max         1230.46\n",
      "trainer/Z Expert Targets Min          971.162\n",
      "trainer/Z Policy Targets Mean        1065.79\n",
      "trainer/Z Policy Targets Std          283.77\n",
      "trainer/Z Policy Targets Max         1230.08\n",
      "trainer/Z Policy Targets Min         -407.47\n",
      "trainer/Log Pis Mean                   20.0544\n",
      "trainer/Log Pis Std                     3.65913\n",
      "trainer/Policy mu Mean                  0.0528131\n",
      "trainer/Policy mu Std                   0.992351\n",
      "trainer/Policy log std Mean            -3.28163\n",
      "trainer/Policy log std Std              0.830615\n",
      "trainer/Alpha                           0.0939262\n",
      "trainer/Alpha Loss                     -0.0051107\n",
      "exploration/num steps total        133885\n",
      "exploration/num paths total           231\n",
      "evaluation/num steps total              1.06662e+06\n",
      "evaluation/num paths total           1331\n",
      "evaluation/path length Mean           747.727\n",
      "evaluation/path length Std            321.366\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            229\n",
      "evaluation/Rewards Mean                 4.57177\n",
      "evaluation/Rewards Std                  1.22696\n",
      "evaluation/Rewards Max                  6.71089\n",
      "evaluation/Rewards Min                 -1.59632\n",
      "evaluation/Returns Mean              3418.43\n",
      "evaluation/Returns Std               1535.64\n",
      "evaluation/Returns Max               4903.33\n",
      "evaluation/Returns Min                886.062\n",
      "evaluation/Estimation Bias Mean      1110.9\n",
      "evaluation/Estimation Bias Std        172.226\n",
      "evaluation/EB/Q_True Mean              50.7211\n",
      "evaluation/EB/Q_True Std              141.679\n",
      "evaluation/EB/Q_Pred Mean            1161.62\n",
      "evaluation/EB/Q_Pred Std               82.2207\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3418.43\n",
      "evaluation/Actions Mean                 0.0204729\n",
      "evaluation/Actions Std                  0.522361\n",
      "evaluation/Actions Max                  0.99997\n",
      "evaluation/Actions Min                 -0.999925\n",
      "time/backward_policy (s)                1.97297\n",
      "time/backward_zf1 (s)                   2.09825\n",
      "time/backward_zf2 (s)                   2.04126\n",
      "time/data sampling (s)                  0.302749\n",
      "time/data storing (s)                   0.0151246\n",
      "time/evaluation sampling (s)            1.74208\n",
      "time/exploration sampling (s)           0.324044\n",
      "time/logging (s)                        0.010407\n",
      "time/preback_alpha (s)                  1.02547\n",
      "time/preback_policy (s)                 1.16458\n",
      "time/preback_start (s)                  0.146811\n",
      "time/preback_zf (s)                     5.22451\n",
      "time/saving (s)                         0.00622608\n",
      "time/training (s)                       2.19932\n",
      "time/epoch (s)                         18.2738\n",
      "time/total (s)                       2290.44\n",
      "Epoch                                 128\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:30:41.040607 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 129 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 140000\n",
      "trainer/ZF1 Loss                        4.30978\n",
      "trainer/ZF2 Loss                        9.47346\n",
      "trainer/ZF Expert Reward               14.1238\n",
      "trainer/ZF Policy Reward                1.23293\n",
      "trainer/ZF CHI2 Term                   39.5149\n",
      "trainer/Policy Loss                 -1010.05\n",
      "trainer/Bias Loss                      79.7616\n",
      "trainer/Bias Value                     13.6596\n",
      "trainer/Policy Grad Norm               90.3478\n",
      "trainer/Policy Param Norm              33.4793\n",
      "trainer/Zf1 Grad Norm                1175.04\n",
      "trainer/Zf1 Param Norm                 97.1262\n",
      "trainer/Zf2 Grad Norm                2503.22\n",
      "trainer/Zf2 Param Norm                 97.0181\n",
      "trainer/Z Expert Predictions Mean    1185.35\n",
      "trainer/Z Expert Predictions Std       53.9796\n",
      "trainer/Z Expert Predictions Max     1252.11\n",
      "trainer/Z Expert Predictions Min      564.67\n",
      "trainer/Z Policy Predictions Mean    1005.75\n",
      "trainer/Z Policy Predictions Std      389.52\n",
      "trainer/Z Policy Predictions Max     1234.85\n",
      "trainer/Z Policy Predictions Min     -427.239\n",
      "trainer/Z Expert Targets Mean        1171.23\n",
      "trainer/Z Expert Targets Std           50.7515\n",
      "trainer/Z Expert Targets Max         1230.63\n",
      "trainer/Z Expert Targets Min          618.394\n",
      "trainer/Z Policy Targets Mean        1004.52\n",
      "trainer/Z Policy Targets Std          382.964\n",
      "trainer/Z Policy Targets Max         1225.31\n",
      "trainer/Z Policy Targets Min         -405.946\n",
      "trainer/Log Pis Mean                   19.9317\n",
      "trainer/Log Pis Std                     4.04371\n",
      "trainer/Policy mu Mean                  0.0241125\n",
      "trainer/Policy mu Std                   1.10654\n",
      "trainer/Policy log std Mean            -3.12785\n",
      "trainer/Policy log std Std              0.993395\n",
      "trainer/Alpha                           0.0938459\n",
      "trainer/Alpha Loss                      0.0064133\n",
      "exploration/num steps total        134885\n",
      "exploration/num paths total           232\n",
      "evaluation/num steps total              1.07519e+06\n",
      "evaluation/num paths total           1341\n",
      "evaluation/path length Mean           857.6\n",
      "evaluation/path length Std            285.899\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            232\n",
      "evaluation/Rewards Mean                 4.14882\n",
      "evaluation/Rewards Std                  2.17812\n",
      "evaluation/Rewards Max                  7.06858\n",
      "evaluation/Rewards Min                 -2.69002\n",
      "evaluation/Returns Mean              3558.02\n",
      "evaluation/Returns Std               1732.1\n",
      "evaluation/Returns Max               4928.36\n",
      "evaluation/Returns Min                775.593\n",
      "evaluation/Estimation Bias Mean       983.23\n",
      "evaluation/Estimation Bias Std        457.697\n",
      "evaluation/EB/Q_True Mean              52.6688\n",
      "evaluation/EB/Q_True Std              148.773\n",
      "evaluation/EB/Q_Pred Mean            1035.9\n",
      "evaluation/EB/Q_Pred Std              440.312\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3558.02\n",
      "evaluation/Actions Mean                 0.0299221\n",
      "evaluation/Actions Std                  0.577201\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.92648\n",
      "time/backward_zf1 (s)                   2.05981\n",
      "time/backward_zf2 (s)                   1.99202\n",
      "time/data sampling (s)                  0.290034\n",
      "time/data storing (s)                   0.0148509\n",
      "time/evaluation sampling (s)            1.74193\n",
      "time/exploration sampling (s)           0.323175\n",
      "time/logging (s)                        0.0109117\n",
      "time/preback_alpha (s)                  1.00541\n",
      "time/preback_policy (s)                 1.13337\n",
      "time/preback_start (s)                  0.144053\n",
      "time/preback_zf (s)                     5.1598\n",
      "time/saving (s)                         0.00570397\n",
      "time/training (s)                       2.11191\n",
      "time/epoch (s)                         17.9195\n",
      "time/total (s)                       2308.37\n",
      "Epoch                                 129\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:30:59.395899 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 130 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 141000\n",
      "trainer/ZF1 Loss                        6.11254\n",
      "trainer/ZF2 Loss                        9.76202\n",
      "trainer/ZF Expert Reward               14.4193\n",
      "trainer/ZF Policy Reward                5.21797\n",
      "trainer/ZF CHI2 Term                   37.2531\n",
      "trainer/Policy Loss                  -977.035\n",
      "trainer/Bias Loss                      66.8632\n",
      "trainer/Bias Value                     13.6544\n",
      "trainer/Policy Grad Norm              106.952\n",
      "trainer/Policy Param Norm              33.524\n",
      "trainer/Zf1 Grad Norm                1773.78\n",
      "trainer/Zf1 Param Norm                 97.3626\n",
      "trainer/Zf2 Grad Norm                1511.7\n",
      "trainer/Zf2 Param Norm                 97.2442\n",
      "trainer/Z Expert Predictions Mean    1175.09\n",
      "trainer/Z Expert Predictions Std      108.511\n",
      "trainer/Z Expert Predictions Max     1245.24\n",
      "trainer/Z Expert Predictions Min        7.04604\n",
      "trainer/Z Policy Predictions Mean     967.673\n",
      "trainer/Z Policy Predictions Std      436.849\n",
      "trainer/Z Policy Predictions Max     1225.72\n",
      "trainer/Z Policy Predictions Min     -433.07\n",
      "trainer/Z Expert Targets Mean        1160.67\n",
      "trainer/Z Expert Targets Std          108.5\n",
      "trainer/Z Expert Targets Max         1225.53\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         962.455\n",
      "trainer/Z Policy Targets Std          431.921\n",
      "trainer/Z Policy Targets Max         1228.64\n",
      "trainer/Z Policy Targets Min         -449.124\n",
      "trainer/Log Pis Mean                   20.3177\n",
      "trainer/Log Pis Std                     4.06445\n",
      "trainer/Policy mu Mean                  0.019168\n",
      "trainer/Policy mu Std                   1.19342\n",
      "trainer/Policy log std Mean            -3.11091\n",
      "trainer/Policy log std Std              1.05578\n",
      "trainer/Alpha                           0.0949453\n",
      "trainer/Alpha Loss                     -0.0301614\n",
      "exploration/num steps total        136885\n",
      "exploration/num paths total           234\n",
      "evaluation/num steps total              1.08519e+06\n",
      "evaluation/num paths total           1351\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63554\n",
      "evaluation/Rewards Std                  1.05057\n",
      "evaluation/Rewards Max                  6.87387\n",
      "evaluation/Rewards Min                 -1.54703\n",
      "evaluation/Returns Mean              4635.54\n",
      "evaluation/Returns Std                119.408\n",
      "evaluation/Returns Max               4857.54\n",
      "evaluation/Returns Min               4432.88\n",
      "evaluation/Estimation Bias Mean      1121.97\n",
      "evaluation/Estimation Bias Std        136.857\n",
      "evaluation/EB/Q_True Mean              41.9743\n",
      "evaluation/EB/Q_True Std              129.127\n",
      "evaluation/EB/Q_Pred Mean            1163.95\n",
      "evaluation/EB/Q_Pred Std               53.0107\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4635.54\n",
      "evaluation/Actions Mean                 0.0244307\n",
      "evaluation/Actions Std                  0.527548\n",
      "evaluation/Actions Max                  0.998184\n",
      "evaluation/Actions Min                 -0.999763\n",
      "time/backward_policy (s)                2.01283\n",
      "time/backward_zf1 (s)                   2.12908\n",
      "time/backward_zf2 (s)                   2.08117\n",
      "time/data sampling (s)                  0.305327\n",
      "time/data storing (s)                   0.0150728\n",
      "time/evaluation sampling (s)            1.7602\n",
      "time/exploration sampling (s)           0.327316\n",
      "time/logging (s)                        0.0122151\n",
      "time/preback_alpha (s)                  1.04455\n",
      "time/preback_policy (s)                 1.19451\n",
      "time/preback_start (s)                  0.144522\n",
      "time/preback_zf (s)                     5.17428\n",
      "time/saving (s)                         0.00663304\n",
      "time/training (s)                       2.08234\n",
      "time/epoch (s)                         18.2901\n",
      "time/total (s)                       2326.68\n",
      "Epoch                                 130\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:31:17.930884 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 131 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 142000\n",
      "trainer/ZF1 Loss                        5.26771\n",
      "trainer/ZF2 Loss                       -2.14286\n",
      "trainer/ZF Expert Reward               15.6322\n",
      "trainer/ZF Policy Reward               -0.0726378\n",
      "trainer/ZF CHI2 Term                   36.872\n",
      "trainer/Policy Loss                  -991.807\n",
      "trainer/Bias Loss                      57.0246\n",
      "trainer/Bias Value                     13.6505\n",
      "trainer/Policy Grad Norm               91.2475\n",
      "trainer/Policy Param Norm              33.5628\n",
      "trainer/Zf1 Grad Norm                4492.39\n",
      "trainer/Zf1 Param Norm                 97.6174\n",
      "trainer/Zf2 Grad Norm                1659.11\n",
      "trainer/Zf2 Param Norm                 97.4744\n",
      "trainer/Z Expert Predictions Mean    1179.84\n",
      "trainer/Z Expert Predictions Std       38.8687\n",
      "trainer/Z Expert Predictions Max     1241.12\n",
      "trainer/Z Expert Predictions Min      909.827\n",
      "trainer/Z Policy Predictions Mean     985.945\n",
      "trainer/Z Policy Predictions Std      356.872\n",
      "trainer/Z Policy Predictions Max     1223.83\n",
      "trainer/Z Policy Predictions Min     -434.062\n",
      "trainer/Z Expert Targets Mean        1164.2\n",
      "trainer/Z Expert Targets Std           41.2398\n",
      "trainer/Z Expert Targets Max         1215.92\n",
      "trainer/Z Expert Targets Min          855.521\n",
      "trainer/Z Policy Targets Mean         986.017\n",
      "trainer/Z Policy Targets Std          351.109\n",
      "trainer/Z Policy Targets Max         1216.67\n",
      "trainer/Z Policy Targets Min         -419.718\n",
      "trainer/Log Pis Mean                   19.8028\n",
      "trainer/Log Pis Std                     4.31873\n",
      "trainer/Policy mu Mean                  0.0708847\n",
      "trainer/Policy mu Std                   1.09419\n",
      "trainer/Policy log std Mean            -3.08918\n",
      "trainer/Policy log std Std              0.961226\n",
      "trainer/Alpha                           0.094224\n",
      "trainer/Alpha Loss                      0.018585\n",
      "exploration/num steps total        136885\n",
      "exploration/num paths total           234\n",
      "evaluation/num steps total              1.09519e+06\n",
      "evaluation/num paths total           1361\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.57055\n",
      "evaluation/Rewards Std                  0.95338\n",
      "evaluation/Rewards Max                  6.53667\n",
      "evaluation/Rewards Min                 -1.55879\n",
      "evaluation/Returns Mean              4570.55\n",
      "evaluation/Returns Std                 89.9646\n",
      "evaluation/Returns Max               4664.15\n",
      "evaluation/Returns Min               4333.57\n",
      "evaluation/Estimation Bias Mean      1118.5\n",
      "evaluation/Estimation Bias Std        138.575\n",
      "evaluation/EB/Q_True Mean              42.7306\n",
      "evaluation/EB/Q_True Std              131.957\n",
      "evaluation/EB/Q_Pred Mean            1161.23\n",
      "evaluation/EB/Q_Pred Std               43.1781\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4570.55\n",
      "evaluation/Actions Mean                 0.0171499\n",
      "evaluation/Actions Std                  0.515665\n",
      "evaluation/Actions Max                  0.998006\n",
      "evaluation/Actions Min                 -0.998742\n",
      "time/backward_policy (s)                2.03676\n",
      "time/backward_zf1 (s)                   2.16634\n",
      "time/backward_zf2 (s)                   2.1245\n",
      "time/data sampling (s)                  0.296102\n",
      "time/data storing (s)                   0.0151027\n",
      "time/evaluation sampling (s)            1.84071\n",
      "time/exploration sampling (s)           0.319723\n",
      "time/logging (s)                        0.0120099\n",
      "time/preback_alpha (s)                  1.07266\n",
      "time/preback_policy (s)                 1.24698\n",
      "time/preback_start (s)                  0.143593\n",
      "time/preback_zf (s)                     5.19061\n",
      "time/saving (s)                         0.00587371\n",
      "time/training (s)                       1.99664\n",
      "time/epoch (s)                         18.4676\n",
      "time/total (s)                       2345.17\n",
      "Epoch                                 131\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:31:36.155536 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 132 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 143000\n",
      "trainer/ZF1 Loss                       20.3079\n",
      "trainer/ZF2 Loss                       23.3304\n",
      "trainer/ZF Expert Reward               12.285\n",
      "trainer/ZF Policy Reward                2.46997\n",
      "trainer/ZF CHI2 Term                   50.8862\n",
      "trainer/Policy Loss                  -996.211\n",
      "trainer/Bias Loss                      90.9406\n",
      "trainer/Bias Value                     13.6497\n",
      "trainer/Policy Grad Norm              130.356\n",
      "trainer/Policy Param Norm              33.603\n",
      "trainer/Zf1 Grad Norm                1759.13\n",
      "trainer/Zf1 Param Norm                 97.8541\n",
      "trainer/Zf2 Grad Norm                1493.31\n",
      "trainer/Zf2 Param Norm                 97.6835\n",
      "trainer/Z Expert Predictions Mean    1157.53\n",
      "trainer/Z Expert Predictions Std       90.1432\n",
      "trainer/Z Expert Predictions Max     1216.11\n",
      "trainer/Z Expert Predictions Min        3.80296\n",
      "trainer/Z Policy Predictions Mean     992.654\n",
      "trainer/Z Policy Predictions Std      376.944\n",
      "trainer/Z Policy Predictions Max     1233.27\n",
      "trainer/Z Policy Predictions Min     -413.419\n",
      "trainer/Z Expert Targets Mean        1145.24\n",
      "trainer/Z Expert Targets Std           93.3338\n",
      "trainer/Z Expert Targets Max         1209.23\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         990.184\n",
      "trainer/Z Policy Targets Std          373.685\n",
      "trainer/Z Policy Targets Max         1208.41\n",
      "trainer/Z Policy Targets Min         -416.385\n",
      "trainer/Log Pis Mean                   19.4465\n",
      "trainer/Log Pis Std                     4.14501\n",
      "trainer/Policy mu Mean                  0.017848\n",
      "trainer/Policy mu Std                   1.05277\n",
      "trainer/Policy log std Mean            -3.14909\n",
      "trainer/Policy log std Std              0.963752\n",
      "trainer/Alpha                           0.0948435\n",
      "trainer/Alpha Loss                      0.0525042\n",
      "exploration/num steps total        138885\n",
      "exploration/num paths total           236\n",
      "evaluation/num steps total              1.10513e+06\n",
      "evaluation/num paths total           1371\n",
      "evaluation/path length Mean           993.4\n",
      "evaluation/path length Std             19.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            934\n",
      "evaluation/Rewards Mean                 4.61084\n",
      "evaluation/Rewards Std                  1.06078\n",
      "evaluation/Rewards Max                  6.75679\n",
      "evaluation/Rewards Min                 -1.90331\n",
      "evaluation/Returns Mean              4580.4\n",
      "evaluation/Returns Std                119.484\n",
      "evaluation/Returns Max               4698.75\n",
      "evaluation/Returns Min               4314.83\n",
      "evaluation/Estimation Bias Mean      1114.57\n",
      "evaluation/Estimation Bias Std        142.158\n",
      "evaluation/EB/Q_True Mean              43.3243\n",
      "evaluation/EB/Q_True Std              133.358\n",
      "evaluation/EB/Q_Pred Mean            1157.89\n",
      "evaluation/EB/Q_Pred Std               56.1853\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4580.4\n",
      "evaluation/Actions Mean                 0.0293324\n",
      "evaluation/Actions Std                  0.533134\n",
      "evaluation/Actions Max                  0.999075\n",
      "evaluation/Actions Min                 -0.999846\n",
      "time/backward_policy (s)                1.96169\n",
      "time/backward_zf1 (s)                   2.0787\n",
      "time/backward_zf2 (s)                   2.04154\n",
      "time/data sampling (s)                  0.285736\n",
      "time/data storing (s)                   0.0141301\n",
      "time/evaluation sampling (s)            1.76969\n",
      "time/exploration sampling (s)           0.320669\n",
      "time/logging (s)                        0.0128846\n",
      "time/preback_alpha (s)                  1.04873\n",
      "time/preback_policy (s)                 1.20817\n",
      "time/preback_start (s)                  0.145985\n",
      "time/preback_zf (s)                     5.20583\n",
      "time/saving (s)                         0.00994019\n",
      "time/training (s)                       2.05367\n",
      "time/epoch (s)                         18.1574\n",
      "time/total (s)                       2363.35\n",
      "Epoch                                 132\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:31:54.120523 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 133 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 144000\n",
      "trainer/ZF1 Loss                      300.835\n",
      "trainer/ZF2 Loss                      318.962\n",
      "trainer/ZF Expert Reward               14.6525\n",
      "trainer/ZF Policy Reward                9.8884\n",
      "trainer/ZF CHI2 Term                  334.82\n",
      "trainer/Policy Loss                 -1007.19\n",
      "trainer/Bias Loss                     358.259\n",
      "trainer/Bias Value                     13.6491\n",
      "trainer/Policy Grad Norm               92.9671\n",
      "trainer/Policy Param Norm              33.6463\n",
      "trainer/Zf1 Grad Norm                5689.75\n",
      "trainer/Zf1 Param Norm                 98.0991\n",
      "trainer/Zf2 Grad Norm                7855.55\n",
      "trainer/Zf2 Param Norm                 97.9017\n",
      "trainer/Z Expert Predictions Mean    1158.29\n",
      "trainer/Z Expert Predictions Std       88.572\n",
      "trainer/Z Expert Predictions Max     1219.58\n",
      "trainer/Z Expert Predictions Min      165.973\n",
      "trainer/Z Policy Predictions Mean    1007.45\n",
      "trainer/Z Policy Predictions Std      353.994\n",
      "trainer/Z Policy Predictions Max     1216.16\n",
      "trainer/Z Policy Predictions Min     -435.43\n",
      "trainer/Z Expert Targets Mean        1143.64\n",
      "trainer/Z Expert Targets Std          108.708\n",
      "trainer/Z Expert Targets Max         1210.68\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         997.566\n",
      "trainer/Z Policy Targets Std          352.698\n",
      "trainer/Z Policy Targets Max         1207.09\n",
      "trainer/Z Policy Targets Min         -413.925\n",
      "trainer/Log Pis Mean                   20.3605\n",
      "trainer/Log Pis Std                     3.55876\n",
      "trainer/Policy mu Mean                  0.0410532\n",
      "trainer/Policy mu Std                   1.07065\n",
      "trainer/Policy log std Mean            -3.21033\n",
      "trainer/Policy log std Std              0.907059\n",
      "trainer/Alpha                           0.0958138\n",
      "trainer/Alpha Loss                     -0.0345442\n",
      "exploration/num steps total        138885\n",
      "exploration/num paths total           236\n",
      "evaluation/num steps total              1.11437e+06\n",
      "evaluation/num paths total           1381\n",
      "evaluation/path length Mean           924.3\n",
      "evaluation/path length Std            227.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            243\n",
      "evaluation/Rewards Mean                 4.12141\n",
      "evaluation/Rewards Std                  2.00369\n",
      "evaluation/Rewards Max                  6.62536\n",
      "evaluation/Rewards Min                 -3.41091\n",
      "evaluation/Returns Mean              3809.42\n",
      "evaluation/Returns Std               1599.62\n",
      "evaluation/Returns Max               4726.2\n",
      "evaluation/Returns Min                287.817\n",
      "evaluation/Estimation Bias Mean       995.163\n",
      "evaluation/Estimation Bias Std        401.353\n",
      "evaluation/EB/Q_True Mean              46.9706\n",
      "evaluation/EB/Q_True Std              138.203\n",
      "evaluation/EB/Q_Pred Mean            1042.13\n",
      "evaluation/EB/Q_Pred Std              386.536\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3809.42\n",
      "evaluation/Actions Mean                 0.0321176\n",
      "evaluation/Actions Std                  0.567304\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999854\n",
      "time/backward_policy (s)                1.87417\n",
      "time/backward_zf1 (s)                   1.99944\n",
      "time/backward_zf2 (s)                   1.94191\n",
      "time/data sampling (s)                  0.284613\n",
      "time/data storing (s)                   0.0146051\n",
      "time/evaluation sampling (s)            1.76462\n",
      "time/exploration sampling (s)           0.314573\n",
      "time/logging (s)                        0.0138478\n",
      "time/preback_alpha (s)                  0.978433\n",
      "time/preback_policy (s)                 1.09703\n",
      "time/preback_start (s)                  0.148892\n",
      "time/preback_zf (s)                     5.19718\n",
      "time/saving (s)                         0.00598179\n",
      "time/training (s)                       2.25979\n",
      "time/epoch (s)                         17.8951\n",
      "time/total (s)                       2381.26\n",
      "Epoch                                 133\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:32:11.959333 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 134 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 145000\n",
      "trainer/ZF1 Loss                        5.4361\n",
      "trainer/ZF2 Loss                       11.1861\n",
      "trainer/ZF Expert Reward               17.4354\n",
      "trainer/ZF Policy Reward                3.92184\n",
      "trainer/ZF CHI2 Term                   41.5647\n",
      "trainer/Policy Loss                  -983.48\n",
      "trainer/Bias Loss                     168.165\n",
      "trainer/Bias Value                     13.6517\n",
      "trainer/Policy Grad Norm               97.268\n",
      "trainer/Policy Param Norm              33.6885\n",
      "trainer/Zf1 Grad Norm                1328.56\n",
      "trainer/Zf1 Param Norm                 98.3395\n",
      "trainer/Zf2 Grad Norm                1125.24\n",
      "trainer/Zf2 Param Norm                 98.1081\n",
      "trainer/Z Expert Predictions Mean    1161.91\n",
      "trainer/Z Expert Predictions Std       33.9013\n",
      "trainer/Z Expert Predictions Max     1223.17\n",
      "trainer/Z Expert Predictions Min     1009.89\n",
      "trainer/Z Policy Predictions Mean     979.935\n",
      "trainer/Z Policy Predictions Std      376.45\n",
      "trainer/Z Policy Predictions Max     1205.56\n",
      "trainer/Z Policy Predictions Min     -428.295\n",
      "trainer/Z Expert Targets Mean        1144.48\n",
      "trainer/Z Expert Targets Std           38.2826\n",
      "trainer/Z Expert Targets Max         1194.36\n",
      "trainer/Z Expert Targets Min          847.882\n",
      "trainer/Z Policy Targets Mean         976.013\n",
      "trainer/Z Policy Targets Std          368.895\n",
      "trainer/Z Policy Targets Max         1194.19\n",
      "trainer/Z Policy Targets Min         -425.992\n",
      "trainer/Log Pis Mean                   19.9395\n",
      "trainer/Log Pis Std                     4.15381\n",
      "trainer/Policy mu Mean                  0.067011\n",
      "trainer/Policy mu Std                   1.06206\n",
      "trainer/Policy log std Mean            -3.20194\n",
      "trainer/Policy log std Std              0.923406\n",
      "trainer/Alpha                           0.0961524\n",
      "trainer/Alpha Loss                      0.00582228\n",
      "exploration/num steps total        138885\n",
      "exploration/num paths total           236\n",
      "evaluation/num steps total              1.12343e+06\n",
      "evaluation/num paths total           1391\n",
      "evaluation/path length Mean           905.9\n",
      "evaluation/path length Std            282.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             59\n",
      "evaluation/Rewards Mean                 4.46839\n",
      "evaluation/Rewards Std                  1.48649\n",
      "evaluation/Rewards Max                  6.75575\n",
      "evaluation/Rewards Min                 -3.2388\n",
      "evaluation/Returns Mean              4047.91\n",
      "evaluation/Returns Std               1410.42\n",
      "evaluation/Returns Max               4843.24\n",
      "evaluation/Returns Min                 24.5346\n",
      "evaluation/Estimation Bias Mean      1072.5\n",
      "evaluation/Estimation Bias Std        261.626\n",
      "evaluation/EB/Q_True Mean              32.0033\n",
      "evaluation/EB/Q_True Std              122.608\n",
      "evaluation/EB/Q_Pred Mean            1104.51\n",
      "evaluation/EB/Q_Pred Std              231.764\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4047.91\n",
      "evaluation/Actions Mean                 0.0307937\n",
      "evaluation/Actions Std                  0.558233\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.85989\n",
      "time/backward_zf1 (s)                   1.99072\n",
      "time/backward_zf2 (s)                   1.91871\n",
      "time/data sampling (s)                  0.286129\n",
      "time/data storing (s)                   0.0141841\n",
      "time/evaluation sampling (s)            1.74899\n",
      "time/exploration sampling (s)           0.310978\n",
      "time/logging (s)                        0.0127812\n",
      "time/preback_alpha (s)                  0.962308\n",
      "time/preback_policy (s)                 1.07309\n",
      "time/preback_start (s)                  0.142918\n",
      "time/preback_zf (s)                     5.15308\n",
      "time/saving (s)                         0.00618159\n",
      "time/training (s)                       2.2852\n",
      "time/epoch (s)                         17.7652\n",
      "time/total (s)                       2399.05\n",
      "Epoch                                 134\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:32:29.789424 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 135 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 146000\n",
      "trainer/ZF1 Loss                       12.1398\n",
      "trainer/ZF2 Loss                       10.6536\n",
      "trainer/ZF Expert Reward               13.02\n",
      "trainer/ZF Policy Reward                1.23325\n",
      "trainer/ZF CHI2 Term                   43.0724\n",
      "trainer/Policy Loss                  -981.348\n",
      "trainer/Bias Loss                     110.852\n",
      "trainer/Bias Value                     13.6536\n",
      "trainer/Policy Grad Norm              162.677\n",
      "trainer/Policy Param Norm              33.7308\n",
      "trainer/Zf1 Grad Norm                2809.73\n",
      "trainer/Zf1 Param Norm                 98.5699\n",
      "trainer/Zf2 Grad Norm                1882.13\n",
      "trainer/Zf2 Param Norm                 98.3156\n",
      "trainer/Z Expert Predictions Mean    1147.37\n",
      "trainer/Z Expert Predictions Std       86.3008\n",
      "trainer/Z Expert Predictions Max     1211.92\n",
      "trainer/Z Expert Predictions Min      140.743\n",
      "trainer/Z Policy Predictions Mean     977.34\n",
      "trainer/Z Policy Predictions Std      374.853\n",
      "trainer/Z Policy Predictions Max     1197.2\n",
      "trainer/Z Policy Predictions Min     -414.695\n",
      "trainer/Z Expert Targets Mean        1134.35\n",
      "trainer/Z Expert Targets Std           94.2871\n",
      "trainer/Z Expert Targets Max         1204.54\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         976.106\n",
      "trainer/Z Policy Targets Std          369.803\n",
      "trainer/Z Policy Targets Max         1191.11\n",
      "trainer/Z Policy Targets Min         -403.819\n",
      "trainer/Log Pis Mean                   20.0898\n",
      "trainer/Log Pis Std                     3.61902\n",
      "trainer/Policy mu Mean                  0.0518206\n",
      "trainer/Policy mu Std                   1.10031\n",
      "trainer/Policy log std Mean            -3.19511\n",
      "trainer/Policy log std Std              0.963172\n",
      "trainer/Alpha                           0.0987008\n",
      "trainer/Alpha Loss                     -0.00886723\n",
      "exploration/num steps total        140885\n",
      "exploration/num paths total           238\n",
      "evaluation/num steps total              1.13185e+06\n",
      "evaluation/num paths total           1401\n",
      "evaluation/path length Mean           842.1\n",
      "evaluation/path length Std            325.733\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             32\n",
      "evaluation/Rewards Mean                 4.7206\n",
      "evaluation/Rewards Std                  1.02334\n",
      "evaluation/Rewards Max                  6.67877\n",
      "evaluation/Rewards Min                 -1.57619\n",
      "evaluation/Returns Mean              3975.22\n",
      "evaluation/Returns Std               1599.11\n",
      "evaluation/Returns Max               4904.86\n",
      "evaluation/Returns Min                 41.4264\n",
      "evaluation/Estimation Bias Mean      1083.67\n",
      "evaluation/Estimation Bias Std        165.604\n",
      "evaluation/EB/Q_True Mean              51.7161\n",
      "evaluation/EB/Q_True Std              144.541\n",
      "evaluation/EB/Q_Pred Mean            1135.39\n",
      "evaluation/EB/Q_Pred Std               61.9158\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3975.22\n",
      "evaluation/Actions Mean                 0.0242039\n",
      "evaluation/Actions Std                  0.528555\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999784\n",
      "time/backward_policy (s)                1.83289\n",
      "time/backward_zf1 (s)                   1.9512\n",
      "time/backward_zf2 (s)                   1.87804\n",
      "time/data sampling (s)                  0.29518\n",
      "time/data storing (s)                   0.0151019\n",
      "time/evaluation sampling (s)            1.73049\n",
      "time/exploration sampling (s)           0.32705\n",
      "time/logging (s)                        0.0104495\n",
      "time/preback_alpha (s)                  0.949213\n",
      "time/preback_policy (s)                 1.0626\n",
      "time/preback_start (s)                  0.14442\n",
      "time/preback_zf (s)                     5.18663\n",
      "time/saving (s)                         0.0074417\n",
      "time/training (s)                       2.36796\n",
      "time/epoch (s)                         17.7587\n",
      "time/total (s)                       2416.84\n",
      "Epoch                                 135\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:32:47.958549 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 136 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 147000\n",
      "trainer/ZF1 Loss                        5.72639\n",
      "trainer/ZF2 Loss                        4.85305\n",
      "trainer/ZF Expert Reward               11.2944\n",
      "trainer/ZF Policy Reward                3.04824\n",
      "trainer/ZF CHI2 Term                   33.5872\n",
      "trainer/Policy Loss                  -996.895\n",
      "trainer/Bias Loss                      58.9416\n",
      "trainer/Bias Value                     13.6517\n",
      "trainer/Policy Grad Norm              114.43\n",
      "trainer/Policy Param Norm              33.7767\n",
      "trainer/Zf1 Grad Norm                1253.14\n",
      "trainer/Zf1 Param Norm                 98.8277\n",
      "trainer/Zf2 Grad Norm                 964.212\n",
      "trainer/Zf2 Param Norm                 98.5444\n",
      "trainer/Z Expert Predictions Mean    1143.86\n",
      "trainer/Z Expert Predictions Std       78.6931\n",
      "trainer/Z Expert Predictions Max     1202.38\n",
      "trainer/Z Expert Predictions Min       31.2618\n",
      "trainer/Z Policy Predictions Mean     994.449\n",
      "trainer/Z Policy Predictions Std      325.928\n",
      "trainer/Z Policy Predictions Max     1194.36\n",
      "trainer/Z Policy Predictions Min     -377.52\n",
      "trainer/Z Expert Targets Mean        1132.56\n",
      "trainer/Z Expert Targets Std           81.9864\n",
      "trainer/Z Expert Targets Max         1193.13\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         991.401\n",
      "trainer/Z Policy Targets Std          323.325\n",
      "trainer/Z Policy Targets Max         1190.93\n",
      "trainer/Z Policy Targets Min         -379.758\n",
      "trainer/Log Pis Mean                   20.2538\n",
      "trainer/Log Pis Std                     3.80741\n",
      "trainer/Policy mu Mean                  0.0305043\n",
      "trainer/Policy mu Std                   1.0168\n",
      "trainer/Policy log std Mean            -3.22688\n",
      "trainer/Policy log std Std              0.876754\n",
      "trainer/Alpha                           0.0977241\n",
      "trainer/Alpha Loss                     -0.0248059\n",
      "exploration/num steps total        141885\n",
      "exploration/num paths total           239\n",
      "evaluation/num steps total              1.14185e+06\n",
      "evaluation/num paths total           1411\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.72098\n",
      "evaluation/Rewards Std                  1.12199\n",
      "evaluation/Rewards Max                  7.06272\n",
      "evaluation/Rewards Min                 -1.64703\n",
      "evaluation/Returns Mean              4720.98\n",
      "evaluation/Returns Std                139.709\n",
      "evaluation/Returns Max               4977.23\n",
      "evaluation/Returns Min               4439.69\n",
      "evaluation/Estimation Bias Mean      1083.11\n",
      "evaluation/Estimation Bias Std        142.63\n",
      "evaluation/EB/Q_True Mean              43.5089\n",
      "evaluation/EB/Q_True Std              134.328\n",
      "evaluation/EB/Q_Pred Mean            1126.62\n",
      "evaluation/EB/Q_Pred Std               57.0441\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4720.98\n",
      "evaluation/Actions Mean                 0.0224423\n",
      "evaluation/Actions Std                  0.530851\n",
      "evaluation/Actions Max                  0.999787\n",
      "evaluation/Actions Min                 -0.999529\n",
      "time/backward_policy (s)                1.95778\n",
      "time/backward_zf1 (s)                   2.11481\n",
      "time/backward_zf2 (s)                   2.04181\n",
      "time/data sampling (s)                  0.293963\n",
      "time/data storing (s)                   0.0141119\n",
      "time/evaluation sampling (s)            1.73129\n",
      "time/exploration sampling (s)           0.315275\n",
      "time/logging (s)                        0.0124996\n",
      "time/preback_alpha (s)                  1.04937\n",
      "time/preback_policy (s)                 1.2004\n",
      "time/preback_start (s)                  0.14404\n",
      "time/preback_zf (s)                     5.19138\n",
      "time/saving (s)                         0.0065395\n",
      "time/training (s)                       2.03075\n",
      "time/epoch (s)                         18.104\n",
      "time/total (s)                       2434.96\n",
      "Epoch                                 136\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:33:06.269078 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 137 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 148000\n",
      "trainer/ZF1 Loss                        1.95999\n",
      "trainer/ZF2 Loss                        1.52315\n",
      "trainer/ZF Expert Reward               15.4305\n",
      "trainer/ZF Policy Reward                4.05898\n",
      "trainer/ZF CHI2 Term                   33.0317\n",
      "trainer/Policy Loss                  -973.862\n",
      "trainer/Bias Loss                      55.9343\n",
      "trainer/Bias Value                     13.6515\n",
      "trainer/Policy Grad Norm              112.532\n",
      "trainer/Policy Param Norm              33.8249\n",
      "trainer/Zf1 Grad Norm                 999.859\n",
      "trainer/Zf1 Param Norm                 99.0659\n",
      "trainer/Zf2 Grad Norm                 820.637\n",
      "trainer/Zf2 Param Norm                 98.7546\n",
      "trainer/Z Expert Predictions Mean    1146.42\n",
      "trainer/Z Expert Predictions Std       42.6976\n",
      "trainer/Z Expert Predictions Max     1204.7\n",
      "trainer/Z Expert Predictions Min      860.032\n",
      "trainer/Z Policy Predictions Mean     970.004\n",
      "trainer/Z Policy Predictions Std      349.928\n",
      "trainer/Z Policy Predictions Max     1187.96\n",
      "trainer/Z Policy Predictions Min     -382.131\n",
      "trainer/Z Expert Targets Mean        1130.98\n",
      "trainer/Z Expert Targets Std           45.1458\n",
      "trainer/Z Expert Targets Max         1200.66\n",
      "trainer/Z Expert Targets Min          821.708\n",
      "trainer/Z Policy Targets Mean         965.946\n",
      "trainer/Z Policy Targets Std          346.614\n",
      "trainer/Z Policy Targets Max         1194.62\n",
      "trainer/Z Policy Targets Min         -374.767\n",
      "trainer/Log Pis Mean                   20.1198\n",
      "trainer/Log Pis Std                     4.19268\n",
      "trainer/Policy mu Mean                  0.0667452\n",
      "trainer/Policy mu Std                   1.05396\n",
      "trainer/Policy log std Mean            -3.18163\n",
      "trainer/Policy log std Std              0.938866\n",
      "trainer/Alpha                           0.100258\n",
      "trainer/Alpha Loss                     -0.0120128\n",
      "exploration/num steps total        142885\n",
      "exploration/num paths total           240\n",
      "evaluation/num steps total              1.15114e+06\n",
      "evaluation/num paths total           1422\n",
      "evaluation/path length Mean           845\n",
      "evaluation/path length Std            333.339\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             19\n",
      "evaluation/Rewards Mean                 4.70638\n",
      "evaluation/Rewards Std                  1.11364\n",
      "evaluation/Rewards Max                  6.91208\n",
      "evaluation/Rewards Min                 -2.60819\n",
      "evaluation/Returns Mean              3976.89\n",
      "evaluation/Returns Std               1624.69\n",
      "evaluation/Returns Max               4908.57\n",
      "evaluation/Returns Min                 17.6818\n",
      "evaluation/Estimation Bias Mean      1078.05\n",
      "evaluation/Estimation Bias Std        164.449\n",
      "evaluation/EB/Q_True Mean              47.4972\n",
      "evaluation/EB/Q_True Std              140.905\n",
      "evaluation/EB/Q_Pred Mean            1125.54\n",
      "evaluation/EB/Q_Pred Std               70.8679\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3976.89\n",
      "evaluation/Actions Mean                 0.0213639\n",
      "evaluation/Actions Std                  0.535232\n",
      "evaluation/Actions Max                  0.999207\n",
      "evaluation/Actions Min                 -0.999467\n",
      "time/backward_policy (s)                1.98642\n",
      "time/backward_zf1 (s)                   2.09956\n",
      "time/backward_zf2 (s)                   2.06372\n",
      "time/data sampling (s)                  0.296443\n",
      "time/data storing (s)                   0.0146327\n",
      "time/evaluation sampling (s)            1.79872\n",
      "time/exploration sampling (s)           0.322972\n",
      "time/logging (s)                        0.0111696\n",
      "time/preback_alpha (s)                  1.04873\n",
      "time/preback_policy (s)                 1.20052\n",
      "time/preback_start (s)                  0.144705\n",
      "time/preback_zf (s)                     5.16149\n",
      "time/saving (s)                         0.00650623\n",
      "time/training (s)                       2.08353\n",
      "time/epoch (s)                         18.2391\n",
      "time/total (s)                       2453.22\n",
      "Epoch                                 137\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:33:24.223328 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 138 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 149000\n",
      "trainer/ZF1 Loss                       11.2245\n",
      "trainer/ZF2 Loss                        3.67421\n",
      "trainer/ZF Expert Reward               18.0972\n",
      "trainer/ZF Policy Reward                6.47866\n",
      "trainer/ZF CHI2 Term                   38.5432\n",
      "trainer/Policy Loss                  -971.895\n",
      "trainer/Bias Loss                     123.364\n",
      "trainer/Bias Value                     13.6548\n",
      "trainer/Policy Grad Norm              121.446\n",
      "trainer/Policy Param Norm              33.868\n",
      "trainer/Zf1 Grad Norm                1317.12\n",
      "trainer/Zf1 Param Norm                 99.3206\n",
      "trainer/Zf2 Grad Norm                1340.31\n",
      "trainer/Zf2 Param Norm                 98.9595\n",
      "trainer/Z Expert Predictions Mean    1137.58\n",
      "trainer/Z Expert Predictions Std       50.911\n",
      "trainer/Z Expert Predictions Max     1206.96\n",
      "trainer/Z Expert Predictions Min      781.934\n",
      "trainer/Z Policy Predictions Mean     965.684\n",
      "trainer/Z Policy Predictions Std      345.483\n",
      "trainer/Z Policy Predictions Max     1196.59\n",
      "trainer/Z Policy Predictions Min     -409.25\n",
      "trainer/Z Expert Targets Mean        1119.48\n",
      "trainer/Z Expert Targets Std           56.9903\n",
      "trainer/Z Expert Targets Max         1182.61\n",
      "trainer/Z Expert Targets Min          709.167\n",
      "trainer/Z Policy Targets Mean         959.205\n",
      "trainer/Z Policy Targets Std          339.078\n",
      "trainer/Z Policy Targets Max         1178.65\n",
      "trainer/Z Policy Targets Min         -400.597\n",
      "trainer/Log Pis Mean                   19.672\n",
      "trainer/Log Pis Std                     4.41837\n",
      "trainer/Policy mu Mean                  0.0708953\n",
      "trainer/Policy mu Std                   1.05046\n",
      "trainer/Policy log std Mean            -3.15555\n",
      "trainer/Policy log std Std              0.91961\n",
      "trainer/Alpha                           0.101265\n",
      "trainer/Alpha Loss                      0.0332132\n",
      "exploration/num steps total        143885\n",
      "exploration/num paths total           241\n",
      "evaluation/num steps total              1.16076e+06\n",
      "evaluation/num paths total           1433\n",
      "evaluation/path length Mean           874\n",
      "evaluation/path length Std            291.027\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             37\n",
      "evaluation/Rewards Mean                 4.29251\n",
      "evaluation/Rewards Std                  1.79224\n",
      "evaluation/Rewards Max                  6.84316\n",
      "evaluation/Rewards Min                 -2.73626\n",
      "evaluation/Returns Mean              3751.65\n",
      "evaluation/Returns Std               1581.66\n",
      "evaluation/Returns Max               4918.05\n",
      "evaluation/Returns Min                 69.6799\n",
      "evaluation/Estimation Bias Mean      1037.52\n",
      "evaluation/Estimation Bias Std        322.841\n",
      "evaluation/EB/Q_True Mean              10.8997\n",
      "evaluation/EB/Q_True Std               95.1168\n",
      "evaluation/EB/Q_Pred Mean            1048.42\n",
      "evaluation/EB/Q_Pred Std              310.367\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3751.65\n",
      "evaluation/Actions Mean                 0.0268387\n",
      "evaluation/Actions Std                  0.554986\n",
      "evaluation/Actions Max                  0.999963\n",
      "evaluation/Actions Min                 -0.999953\n",
      "time/backward_policy (s)                1.91511\n",
      "time/backward_zf1 (s)                   2.0338\n",
      "time/backward_zf2 (s)                   1.98754\n",
      "time/data sampling (s)                  0.286258\n",
      "time/data storing (s)                   0.0146909\n",
      "time/evaluation sampling (s)            1.76918\n",
      "time/exploration sampling (s)           0.321829\n",
      "time/logging (s)                        0.0116958\n",
      "time/preback_alpha (s)                  1.01777\n",
      "time/preback_policy (s)                 1.15666\n",
      "time/preback_start (s)                  0.141438\n",
      "time/preback_zf (s)                     5.15231\n",
      "time/saving (s)                         0.00619093\n",
      "time/training (s)                       2.07077\n",
      "time/epoch (s)                         17.8852\n",
      "time/total (s)                       2471.13\n",
      "Epoch                                 138\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:33:41.790137 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 139 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 150000\n",
      "trainer/ZF1 Loss                      251.237\n",
      "trainer/ZF2 Loss                      245.539\n",
      "trainer/ZF Expert Reward               15\n",
      "trainer/ZF Policy Reward                6.79368\n",
      "trainer/ZF CHI2 Term                  276.199\n",
      "trainer/Policy Loss                  -963.043\n",
      "trainer/Bias Loss                      50.9005\n",
      "trainer/Bias Value                     13.6527\n",
      "trainer/Policy Grad Norm              118.832\n",
      "trainer/Policy Param Norm              33.9121\n",
      "trainer/Zf1 Grad Norm                1577.58\n",
      "trainer/Zf1 Param Norm                 99.572\n",
      "trainer/Zf2 Grad Norm                1753.98\n",
      "trainer/Zf2 Param Norm                 99.1604\n",
      "trainer/Z Expert Predictions Mean    1138.07\n",
      "trainer/Z Expert Predictions Std       35.6451\n",
      "trainer/Z Expert Predictions Max     1199.35\n",
      "trainer/Z Expert Predictions Min      950.673\n",
      "trainer/Z Policy Predictions Mean     959.15\n",
      "trainer/Z Policy Predictions Std      353.886\n",
      "trainer/Z Policy Predictions Max     1186.75\n",
      "trainer/Z Policy Predictions Min     -389.605\n",
      "trainer/Z Expert Targets Mean        1123.07\n",
      "trainer/Z Expert Targets Std           36.2488\n",
      "trainer/Z Expert Targets Max         1177.4\n",
      "trainer/Z Expert Targets Min          928.614\n",
      "trainer/Z Policy Targets Mean         952.357\n",
      "trainer/Z Policy Targets Std          354.531\n",
      "trainer/Z Policy Targets Max         1169.02\n",
      "trainer/Z Policy Targets Min         -386.875\n",
      "trainer/Log Pis Mean                   19.8033\n",
      "trainer/Log Pis Std                     4.20761\n",
      "trainer/Policy mu Mean                  0.0504226\n",
      "trainer/Policy mu Std                   1.06313\n",
      "trainer/Policy log std Mean            -3.18519\n",
      "trainer/Policy log std Std              0.94509\n",
      "trainer/Alpha                           0.100362\n",
      "trainer/Alpha Loss                      0.01974\n",
      "exploration/num steps total        144885\n",
      "exploration/num paths total           242\n",
      "evaluation/num steps total              1.17076e+06\n",
      "evaluation/num paths total           1443\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63912\n",
      "evaluation/Rewards Std                  1.02456\n",
      "evaluation/Rewards Max                  6.65895\n",
      "evaluation/Rewards Min                 -1.56841\n",
      "evaluation/Returns Mean              4639.12\n",
      "evaluation/Returns Std                 69.7003\n",
      "evaluation/Returns Max               4807.8\n",
      "evaluation/Returns Min               4545\n",
      "evaluation/Estimation Bias Mean      1073.9\n",
      "evaluation/Estimation Bias Std        142.355\n",
      "evaluation/EB/Q_True Mean              43.1066\n",
      "evaluation/EB/Q_True Std              132.534\n",
      "evaluation/EB/Q_Pred Mean            1117.01\n",
      "evaluation/EB/Q_Pred Std               53.1209\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4639.12\n",
      "evaluation/Actions Mean                 0.0159073\n",
      "evaluation/Actions Std                  0.538135\n",
      "evaluation/Actions Max                  0.998393\n",
      "evaluation/Actions Min                 -0.999385\n",
      "time/backward_policy (s)                1.79306\n",
      "time/backward_zf1 (s)                   1.90291\n",
      "time/backward_zf2 (s)                   1.83419\n",
      "time/data sampling (s)                  0.289273\n",
      "time/data storing (s)                   0.0145121\n",
      "time/evaluation sampling (s)            1.72422\n",
      "time/exploration sampling (s)           0.316879\n",
      "time/logging (s)                        0.0122144\n",
      "time/preback_alpha (s)                  0.92566\n",
      "time/preback_policy (s)                 1.01962\n",
      "time/preback_start (s)                  0.142287\n",
      "time/preback_zf (s)                     5.1554\n",
      "time/saving (s)                         0.00636203\n",
      "time/training (s)                       2.36465\n",
      "time/epoch (s)                         17.5012\n",
      "time/total (s)                       2488.65\n",
      "Epoch                                 139\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:33:59.908739 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 140 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 151000\n",
      "trainer/ZF1 Loss                        3.4564\n",
      "trainer/ZF2 Loss                        8.55429\n",
      "trainer/ZF Expert Reward               13.3821\n",
      "trainer/ZF Policy Reward                3.2328\n",
      "trainer/ZF CHI2 Term                   35.247\n",
      "trainer/Policy Loss                  -963.253\n",
      "trainer/Bias Loss                      54.5887\n",
      "trainer/Bias Value                     13.6555\n",
      "trainer/Policy Grad Norm              117.245\n",
      "trainer/Policy Param Norm              33.9544\n",
      "trainer/Zf1 Grad Norm                1140.66\n",
      "trainer/Zf1 Param Norm                 99.8314\n",
      "trainer/Zf2 Grad Norm                1310.85\n",
      "trainer/Zf2 Param Norm                 99.3965\n",
      "trainer/Z Expert Predictions Mean    1121.4\n",
      "trainer/Z Expert Predictions Std       82.2088\n",
      "trainer/Z Expert Predictions Max     1186.44\n",
      "trainer/Z Expert Predictions Min       -5.95751\n",
      "trainer/Z Policy Predictions Mean     956.201\n",
      "trainer/Z Policy Predictions Std      348.764\n",
      "trainer/Z Policy Predictions Max     1180.58\n",
      "trainer/Z Policy Predictions Min     -392.383\n",
      "trainer/Z Expert Targets Mean        1108.02\n",
      "trainer/Z Expert Targets Std           81.3383\n",
      "trainer/Z Expert Targets Max         1165.49\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         952.968\n",
      "trainer/Z Policy Targets Std          343.411\n",
      "trainer/Z Policy Targets Max         1165.85\n",
      "trainer/Z Policy Targets Min         -394.001\n",
      "trainer/Log Pis Mean                   19.2852\n",
      "trainer/Log Pis Std                     4.05992\n",
      "trainer/Policy mu Mean                  0.0358393\n",
      "trainer/Policy mu Std                   1.05637\n",
      "trainer/Policy log std Mean            -3.11564\n",
      "trainer/Policy log std Std              0.96236\n",
      "trainer/Alpha                           0.10261\n",
      "trainer/Alpha Loss                      0.0733515\n",
      "exploration/num steps total        146885\n",
      "exploration/num paths total           244\n",
      "evaluation/num steps total              1.17978e+06\n",
      "evaluation/num paths total           1453\n",
      "evaluation/path length Mean           902.2\n",
      "evaluation/path length Std            293.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             22\n",
      "evaluation/Rewards Mean                 4.62339\n",
      "evaluation/Rewards Std                  1.00932\n",
      "evaluation/Rewards Max                  6.63278\n",
      "evaluation/Rewards Min                 -1.67411\n",
      "evaluation/Returns Mean              4171.22\n",
      "evaluation/Returns Std               1383.51\n",
      "evaluation/Returns Max               4754.99\n",
      "evaluation/Returns Min                 34.0469\n",
      "evaluation/Estimation Bias Mean      1058.63\n",
      "evaluation/Estimation Bias Std        147.301\n",
      "evaluation/EB/Q_True Mean              48.1443\n",
      "evaluation/EB/Q_True Std              140.657\n",
      "evaluation/EB/Q_Pred Mean            1106.78\n",
      "evaluation/EB/Q_Pred Std               48.28\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4171.22\n",
      "evaluation/Actions Mean                 0.021629\n",
      "evaluation/Actions Std                  0.533554\n",
      "evaluation/Actions Max                  0.998911\n",
      "evaluation/Actions Min                 -0.999603\n",
      "time/backward_policy (s)                1.93691\n",
      "time/backward_zf1 (s)                   2.06066\n",
      "time/backward_zf2 (s)                   1.99549\n",
      "time/data sampling (s)                  0.290497\n",
      "time/data storing (s)                   0.0146753\n",
      "time/evaluation sampling (s)            1.81321\n",
      "time/exploration sampling (s)           0.325486\n",
      "time/logging (s)                        0.0113465\n",
      "time/preback_alpha (s)                  1.02763\n",
      "time/preback_policy (s)                 1.16524\n",
      "time/preback_start (s)                  0.145213\n",
      "time/preback_zf (s)                     5.1664\n",
      "time/saving (s)                         0.00592795\n",
      "time/training (s)                       2.08888\n",
      "time/epoch (s)                         18.0476\n",
      "time/total (s)                       2506.72\n",
      "Epoch                                 140\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:34:17.545379 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 141 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 152000\n",
      "trainer/ZF1 Loss                      218.922\n",
      "trainer/ZF2 Loss                      240.861\n",
      "trainer/ZF Expert Reward                8.0921\n",
      "trainer/ZF Policy Reward               -0.80233\n",
      "trainer/ZF CHI2 Term                  258.595\n",
      "trainer/Policy Loss                 -1008.2\n",
      "trainer/Bias Loss                      95.0332\n",
      "trainer/Bias Value                     13.658\n",
      "trainer/Policy Grad Norm              121.349\n",
      "trainer/Policy Param Norm              33.9972\n",
      "trainer/Zf1 Grad Norm                3037.09\n",
      "trainer/Zf1 Param Norm                100.079\n",
      "trainer/Zf2 Grad Norm                3020.49\n",
      "trainer/Zf2 Param Norm                 99.613\n",
      "trainer/Z Expert Predictions Mean    1113.98\n",
      "trainer/Z Expert Predictions Std       41.94\n",
      "trainer/Z Expert Predictions Max     1176.44\n",
      "trainer/Z Expert Predictions Min      800.959\n",
      "trainer/Z Policy Predictions Mean    1001.81\n",
      "trainer/Z Policy Predictions Std      246.722\n",
      "trainer/Z Policy Predictions Max     1171.62\n",
      "trainer/Z Policy Predictions Min     -370.298\n",
      "trainer/Z Expert Targets Mean        1105.89\n",
      "trainer/Z Expert Targets Std           46.091\n",
      "trainer/Z Expert Targets Max         1173.07\n",
      "trainer/Z Expert Targets Min          780.115\n",
      "trainer/Z Policy Targets Mean        1002.61\n",
      "trainer/Z Policy Targets Std          250.408\n",
      "trainer/Z Policy Targets Max         1163.76\n",
      "trainer/Z Policy Targets Min         -365.378\n",
      "trainer/Log Pis Mean                   20.0092\n",
      "trainer/Log Pis Std                     3.22899\n",
      "trainer/Policy mu Mean                  0.0455105\n",
      "trainer/Policy mu Std                   0.966477\n",
      "trainer/Policy log std Mean            -3.28843\n",
      "trainer/Policy log std Std              0.844701\n",
      "trainer/Alpha                           0.103547\n",
      "trainer/Alpha Loss                     -0.000949631\n",
      "exploration/num steps total        146885\n",
      "exploration/num paths total           244\n",
      "evaluation/num steps total              1.18771e+06\n",
      "evaluation/num paths total           1463\n",
      "evaluation/path length Mean           793\n",
      "evaluation/path length Std            389.218\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             17\n",
      "evaluation/Rewards Mean                 4.60109\n",
      "evaluation/Rewards Std                  1.19138\n",
      "evaluation/Rewards Max                  6.82585\n",
      "evaluation/Rewards Min                 -2.47917\n",
      "evaluation/Returns Mean              3648.67\n",
      "evaluation/Returns Std               1834.91\n",
      "evaluation/Returns Max               4837.53\n",
      "evaluation/Returns Min                 -0.104484\n",
      "evaluation/Estimation Bias Mean      1035.52\n",
      "evaluation/Estimation Bias Std        170.34\n",
      "evaluation/EB/Q_True Mean              55.5902\n",
      "evaluation/EB/Q_True Std              150.718\n",
      "evaluation/EB/Q_Pred Mean            1091.11\n",
      "evaluation/EB/Q_Pred Std               69.723\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3648.67\n",
      "evaluation/Actions Mean                 0.0265777\n",
      "evaluation/Actions Std                  0.536562\n",
      "evaluation/Actions Max                  0.999746\n",
      "evaluation/Actions Min                 -0.999712\n",
      "time/backward_policy (s)                1.77947\n",
      "time/backward_zf1 (s)                   1.89661\n",
      "time/backward_zf2 (s)                   1.84665\n",
      "time/data sampling (s)                  0.295296\n",
      "time/data storing (s)                   0.0148424\n",
      "time/evaluation sampling (s)            1.76991\n",
      "time/exploration sampling (s)           0.315678\n",
      "time/logging (s)                        0.01019\n",
      "time/preback_alpha (s)                  0.926026\n",
      "time/preback_policy (s)                 1.01398\n",
      "time/preback_start (s)                  0.143582\n",
      "time/preback_zf (s)                     5.15298\n",
      "time/saving (s)                         0.00589778\n",
      "time/training (s)                       2.39471\n",
      "time/epoch (s)                         17.5658\n",
      "time/total (s)                       2524.31\n",
      "Epoch                                 141\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:34:35.752512 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 142 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 153000\n",
      "trainer/ZF1 Loss                      171.478\n",
      "trainer/ZF2 Loss                      219.54\n",
      "trainer/ZF Expert Reward               13.4012\n",
      "trainer/ZF Policy Reward                6.15846\n",
      "trainer/ZF CHI2 Term                  223.088\n",
      "trainer/Policy Loss                  -975.779\n",
      "trainer/Bias Loss                      51.6538\n",
      "trainer/Bias Value                     13.6628\n",
      "trainer/Policy Grad Norm              120.632\n",
      "trainer/Policy Param Norm              34.0374\n",
      "trainer/Zf1 Grad Norm                2882.22\n",
      "trainer/Zf1 Param Norm                100.329\n",
      "trainer/Zf2 Grad Norm                1336.51\n",
      "trainer/Zf2 Param Norm                 99.8313\n",
      "trainer/Z Expert Predictions Mean    1113.81\n",
      "trainer/Z Expert Predictions Std       38.6988\n",
      "trainer/Z Expert Predictions Max     1169.04\n",
      "trainer/Z Expert Predictions Min      923.13\n",
      "trainer/Z Policy Predictions Mean     973.365\n",
      "trainer/Z Policy Predictions Std      306.466\n",
      "trainer/Z Policy Predictions Max     1156.13\n",
      "trainer/Z Policy Predictions Min     -390.279\n",
      "trainer/Z Expert Targets Mean        1100.41\n",
      "trainer/Z Expert Targets Std           39.1915\n",
      "trainer/Z Expert Targets Max         1163.36\n",
      "trainer/Z Expert Targets Min          920.602\n",
      "trainer/Z Policy Targets Mean         967.206\n",
      "trainer/Z Policy Targets Std          306.66\n",
      "trainer/Z Policy Targets Max         1149.26\n",
      "trainer/Z Policy Targets Min         -371.487\n",
      "trainer/Log Pis Mean                   20.5418\n",
      "trainer/Log Pis Std                     3.96671\n",
      "trainer/Policy mu Mean                  0.0580652\n",
      "trainer/Policy mu Std                   1.06411\n",
      "trainer/Policy log std Mean            -3.22135\n",
      "trainer/Policy log std Std              0.904249\n",
      "trainer/Alpha                           0.104988\n",
      "trainer/Alpha Loss                     -0.0568824\n",
      "exploration/num steps total        148885\n",
      "exploration/num paths total           246\n",
      "evaluation/num steps total              1.19771e+06\n",
      "evaluation/num paths total           1473\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.19749\n",
      "evaluation/Rewards Std                  1.89053\n",
      "evaluation/Rewards Max                  6.84728\n",
      "evaluation/Rewards Min                 -2.85835\n",
      "evaluation/Returns Mean              4197.49\n",
      "evaluation/Returns Std               1160.34\n",
      "evaluation/Returns Max               4844.25\n",
      "evaluation/Returns Min                732.226\n",
      "evaluation/Estimation Bias Mean       973.716\n",
      "evaluation/Estimation Bias Std        310.056\n",
      "evaluation/EB/Q_True Mean              43.1754\n",
      "evaluation/EB/Q_True Std              133.077\n",
      "evaluation/EB/Q_Pred Mean            1016.89\n",
      "evaluation/EB/Q_Pred Std              289.979\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4197.49\n",
      "evaluation/Actions Mean                 0.0436714\n",
      "evaluation/Actions Std                  0.557575\n",
      "evaluation/Actions Max                  0.999994\n",
      "evaluation/Actions Min                 -0.999862\n",
      "time/backward_policy (s)                1.89912\n",
      "time/backward_zf1 (s)                   2.01149\n",
      "time/backward_zf2 (s)                   1.94383\n",
      "time/data sampling (s)                  0.296389\n",
      "time/data storing (s)                   0.0155821\n",
      "time/evaluation sampling (s)            1.7533\n",
      "time/exploration sampling (s)           0.340189\n",
      "time/logging (s)                        0.0126648\n",
      "time/preback_alpha (s)                  0.991768\n",
      "time/preback_policy (s)                 1.10867\n",
      "time/preback_start (s)                  0.14763\n",
      "time/preback_zf (s)                     5.25604\n",
      "time/saving (s)                         0.00652764\n",
      "time/training (s)                       2.35667\n",
      "time/epoch (s)                         18.1399\n",
      "time/total (s)                       2542.47\n",
      "Epoch                                 142\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:34:54.007954 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 143 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 154000\n",
      "trainer/ZF1 Loss                      144.447\n",
      "trainer/ZF2 Loss                       11.4658\n",
      "trainer/ZF Expert Reward               12.5943\n",
      "trainer/ZF Policy Reward                4.01703\n",
      "trainer/ZF CHI2 Term                  106.11\n",
      "trainer/Policy Loss                  -965.363\n",
      "trainer/Bias Loss                      52.7898\n",
      "trainer/Bias Value                     13.6626\n",
      "trainer/Policy Grad Norm              104.864\n",
      "trainer/Policy Param Norm              34.0758\n",
      "trainer/Zf1 Grad Norm                1727.2\n",
      "trainer/Zf1 Param Norm                100.55\n",
      "trainer/Zf2 Grad Norm                2080.72\n",
      "trainer/Zf2 Param Norm                100.033\n",
      "trainer/Z Expert Predictions Mean    1106.61\n",
      "trainer/Z Expert Predictions Std       80.642\n",
      "trainer/Z Expert Predictions Max     1165.61\n",
      "trainer/Z Expert Predictions Min      -19.6629\n",
      "trainer/Z Policy Predictions Mean     960.063\n",
      "trainer/Z Policy Predictions Std      313.334\n",
      "trainer/Z Policy Predictions Max     1162.29\n",
      "trainer/Z Policy Predictions Min     -390.637\n",
      "trainer/Z Expert Targets Mean        1094.02\n",
      "trainer/Z Expert Targets Std           80.2422\n",
      "trainer/Z Expert Targets Max         1161.64\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         956.046\n",
      "trainer/Z Policy Targets Std          313.537\n",
      "trainer/Z Policy Targets Max         1150.26\n",
      "trainer/Z Policy Targets Min         -373.293\n",
      "trainer/Log Pis Mean                   19.7747\n",
      "trainer/Log Pis Std                     4.03625\n",
      "trainer/Policy mu Mean                  0.0319599\n",
      "trainer/Policy mu Std                   1.0105\n",
      "trainer/Policy log std Mean            -3.20075\n",
      "trainer/Policy log std Std              0.902263\n",
      "trainer/Alpha                           0.104196\n",
      "trainer/Alpha Loss                      0.0234759\n",
      "exploration/num steps total        148885\n",
      "exploration/num paths total           246\n",
      "evaluation/num steps total              1.20771e+06\n",
      "evaluation/num paths total           1483\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67391\n",
      "evaluation/Rewards Std                  1.04733\n",
      "evaluation/Rewards Max                  6.7673\n",
      "evaluation/Rewards Min                 -1.61472\n",
      "evaluation/Returns Mean              4673.91\n",
      "evaluation/Returns Std                134.208\n",
      "evaluation/Returns Max               4925.97\n",
      "evaluation/Returns Min               4431.47\n",
      "evaluation/Estimation Bias Mean      1048.53\n",
      "evaluation/Estimation Bias Std        142.67\n",
      "evaluation/EB/Q_True Mean              42.4948\n",
      "evaluation/EB/Q_True Std              131.054\n",
      "evaluation/EB/Q_Pred Mean            1091.03\n",
      "evaluation/EB/Q_Pred Std               57.6831\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4673.91\n",
      "evaluation/Actions Mean                 0.0244561\n",
      "evaluation/Actions Std                  0.536138\n",
      "evaluation/Actions Max                  0.999427\n",
      "evaluation/Actions Min                 -0.999675\n",
      "time/backward_policy (s)                1.97201\n",
      "time/backward_zf1 (s)                   2.11678\n",
      "time/backward_zf2 (s)                   2.04853\n",
      "time/data sampling (s)                  0.303926\n",
      "time/data storing (s)                   0.01416\n",
      "time/evaluation sampling (s)            1.71086\n",
      "time/exploration sampling (s)           0.313793\n",
      "time/logging (s)                        0.0116991\n",
      "time/preback_alpha (s)                  1.05284\n",
      "time/preback_policy (s)                 1.19635\n",
      "time/preback_start (s)                  0.145883\n",
      "time/preback_zf (s)                     5.20907\n",
      "time/saving (s)                         0.00638805\n",
      "time/training (s)                       2.0847\n",
      "time/epoch (s)                         18.187\n",
      "time/total (s)                       2560.68\n",
      "Epoch                                 143\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:35:11.841057 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 144 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 155000\n",
      "trainer/ZF1 Loss                       11.3096\n",
      "trainer/ZF2 Loss                       11.1885\n",
      "trainer/ZF Expert Reward               11.947\n",
      "trainer/ZF Policy Reward                2.22286\n",
      "trainer/ZF CHI2 Term                   40.8272\n",
      "trainer/Policy Loss                  -932.663\n",
      "trainer/Bias Loss                      55.1604\n",
      "trainer/Bias Value                     13.6657\n",
      "trainer/Policy Grad Norm              105.303\n",
      "trainer/Policy Param Norm              34.1191\n",
      "trainer/Zf1 Grad Norm                1072.79\n",
      "trainer/Zf1 Param Norm                100.803\n",
      "trainer/Zf2 Grad Norm                1380.45\n",
      "trainer/Zf2 Param Norm                100.25\n",
      "trainer/Z Expert Predictions Mean    1103.99\n",
      "trainer/Z Expert Predictions Std       44.8033\n",
      "trainer/Z Expert Predictions Max     1158.17\n",
      "trainer/Z Expert Predictions Min      758.787\n",
      "trainer/Z Policy Predictions Mean     927.936\n",
      "trainer/Z Policy Predictions Std      345.473\n",
      "trainer/Z Policy Predictions Max     1147.77\n",
      "trainer/Z Policy Predictions Min     -387.166\n",
      "trainer/Z Expert Targets Mean        1092.05\n",
      "trainer/Z Expert Targets Std           44.5148\n",
      "trainer/Z Expert Targets Max         1145.36\n",
      "trainer/Z Expert Targets Min          741.71\n",
      "trainer/Z Policy Targets Mean         925.713\n",
      "trainer/Z Policy Targets Std          340.081\n",
      "trainer/Z Policy Targets Max         1144.63\n",
      "trainer/Z Policy Targets Min         -375.411\n",
      "trainer/Log Pis Mean                   20.0546\n",
      "trainer/Log Pis Std                     4.38511\n",
      "trainer/Policy mu Mean                  0.0783066\n",
      "trainer/Policy mu Std                   1.0768\n",
      "trainer/Policy log std Mean            -3.20252\n",
      "trainer/Policy log std Std              0.953602\n",
      "trainer/Alpha                           0.103742\n",
      "trainer/Alpha Loss                     -0.00566567\n",
      "exploration/num steps total        148885\n",
      "exploration/num paths total           246\n",
      "evaluation/num steps total              1.21771e+06\n",
      "evaluation/num paths total           1493\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.59731\n",
      "evaluation/Rewards Std                  1.01408\n",
      "evaluation/Rewards Max                  6.56268\n",
      "evaluation/Rewards Min                 -1.67071\n",
      "evaluation/Returns Mean              4597.31\n",
      "evaluation/Returns Std                 90.8874\n",
      "evaluation/Returns Max               4716.04\n",
      "evaluation/Returns Min               4404.71\n",
      "evaluation/Estimation Bias Mean      1042.35\n",
      "evaluation/Estimation Bias Std        137.787\n",
      "evaluation/EB/Q_True Mean              42.0387\n",
      "evaluation/EB/Q_True Std              129.379\n",
      "evaluation/EB/Q_Pred Mean            1084.38\n",
      "evaluation/EB/Q_Pred Std               51.7403\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4597.31\n",
      "evaluation/Actions Mean                 0.0259635\n",
      "evaluation/Actions Std                  0.536352\n",
      "evaluation/Actions Max                  0.999314\n",
      "evaluation/Actions Min                 -0.999694\n",
      "time/backward_policy (s)                1.83384\n",
      "time/backward_zf1 (s)                   1.9467\n",
      "time/backward_zf2 (s)                   1.88644\n",
      "time/data sampling (s)                  0.284623\n",
      "time/data storing (s)                   0.0152495\n",
      "time/evaluation sampling (s)            1.72888\n",
      "time/exploration sampling (s)           0.32053\n",
      "time/logging (s)                        0.011995\n",
      "time/preback_alpha (s)                  0.956218\n",
      "time/preback_policy (s)                 1.05318\n",
      "time/preback_start (s)                  0.144454\n",
      "time/preback_zf (s)                     5.20588\n",
      "time/saving (s)                         0.00593512\n",
      "time/training (s)                       2.37277\n",
      "time/epoch (s)                         17.7667\n",
      "time/total (s)                       2578.46\n",
      "Epoch                                 144\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:35:30.212754 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 145 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 156000\n",
      "trainer/ZF1 Loss                       -1.12577\n",
      "trainer/ZF2 Loss                        1.07008\n",
      "trainer/ZF Expert Reward               11.3237\n",
      "trainer/ZF Policy Reward                2.48984\n",
      "trainer/ZF CHI2 Term                   28.7307\n",
      "trainer/Policy Loss                  -954.678\n",
      "trainer/Bias Loss                      52.5731\n",
      "trainer/Bias Value                     13.6758\n",
      "trainer/Policy Grad Norm               99.6119\n",
      "trainer/Policy Param Norm              34.1598\n",
      "trainer/Zf1 Grad Norm                1247.47\n",
      "trainer/Zf1 Param Norm                101.059\n",
      "trainer/Zf2 Grad Norm                1017.66\n",
      "trainer/Zf2 Param Norm                100.467\n",
      "trainer/Z Expert Predictions Mean    1100.44\n",
      "trainer/Z Expert Predictions Std       33.0729\n",
      "trainer/Z Expert Predictions Max     1160.95\n",
      "trainer/Z Expert Predictions Min      922.725\n",
      "trainer/Z Policy Predictions Mean     949.575\n",
      "trainer/Z Policy Predictions Std      314.924\n",
      "trainer/Z Policy Predictions Max     1134\n",
      "trainer/Z Policy Predictions Min     -393.133\n",
      "trainer/Z Expert Targets Mean        1089.12\n",
      "trainer/Z Expert Targets Std           34.9586\n",
      "trainer/Z Expert Targets Max         1149.19\n",
      "trainer/Z Expert Targets Min          912.424\n",
      "trainer/Z Policy Targets Mean         947.085\n",
      "trainer/Z Policy Targets Std          309.787\n",
      "trainer/Z Policy Targets Max         1135.83\n",
      "trainer/Z Policy Targets Min         -387.645\n",
      "trainer/Log Pis Mean                   20.1259\n",
      "trainer/Log Pis Std                     3.8982\n",
      "trainer/Policy mu Mean                  0.0715197\n",
      "trainer/Policy mu Std                   1.06987\n",
      "trainer/Policy log std Mean            -3.18035\n",
      "trainer/Policy log std Std              0.942184\n",
      "trainer/Alpha                           0.105154\n",
      "trainer/Alpha Loss                     -0.0132401\n",
      "exploration/num steps total        150885\n",
      "exploration/num paths total           248\n",
      "evaluation/num steps total              1.22771e+06\n",
      "evaluation/num paths total           1503\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.5757\n",
      "evaluation/Rewards Std                  0.978838\n",
      "evaluation/Rewards Max                  6.50338\n",
      "evaluation/Rewards Min                 -1.86504\n",
      "evaluation/Returns Mean              4575.7\n",
      "evaluation/Returns Std                 92.4004\n",
      "evaluation/Returns Max               4755.02\n",
      "evaluation/Returns Min               4446.05\n",
      "evaluation/Estimation Bias Mean      1043.34\n",
      "evaluation/Estimation Bias Std        140.198\n",
      "evaluation/EB/Q_True Mean              42.0141\n",
      "evaluation/EB/Q_True Std              129.649\n",
      "evaluation/EB/Q_Pred Mean            1085.36\n",
      "evaluation/EB/Q_Pred Std               50.7493\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4575.7\n",
      "evaluation/Actions Mean                 0.0180942\n",
      "evaluation/Actions Std                  0.534872\n",
      "evaluation/Actions Max                  0.998657\n",
      "evaluation/Actions Min                 -0.998792\n",
      "time/backward_policy (s)                1.97143\n",
      "time/backward_zf1 (s)                   2.13958\n",
      "time/backward_zf2 (s)                   2.07235\n",
      "time/data sampling (s)                  0.287485\n",
      "time/data storing (s)                   0.0146774\n",
      "time/evaluation sampling (s)            1.82685\n",
      "time/exploration sampling (s)           0.323773\n",
      "time/logging (s)                        0.0121163\n",
      "time/preback_alpha (s)                  1.03715\n",
      "time/preback_policy (s)                 1.1905\n",
      "time/preback_start (s)                  0.14592\n",
      "time/preback_zf (s)                     5.18298\n",
      "time/saving (s)                         0.0063482\n",
      "time/training (s)                       2.09282\n",
      "time/epoch (s)                         18.304\n",
      "time/total (s)                       2596.79\n",
      "Epoch                                 145\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:35:48.329121 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 146 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 157000\n",
      "trainer/ZF1 Loss                        7.73385\n",
      "trainer/ZF2 Loss                       13.1967\n",
      "trainer/ZF Expert Reward               15.3904\n",
      "trainer/ZF Policy Reward                5.25203\n",
      "trainer/ZF CHI2 Term                   40.3311\n",
      "trainer/Policy Loss                  -921.959\n",
      "trainer/Bias Loss                      67.7468\n",
      "trainer/Bias Value                     13.6793\n",
      "trainer/Policy Grad Norm              137.914\n",
      "trainer/Policy Param Norm              34.2022\n",
      "trainer/Zf1 Grad Norm                1345.67\n",
      "trainer/Zf1 Param Norm                101.311\n",
      "trainer/Zf2 Grad Norm                 967.535\n",
      "trainer/Zf2 Param Norm                100.683\n",
      "trainer/Z Expert Predictions Mean    1098.23\n",
      "trainer/Z Expert Predictions Std       37.2787\n",
      "trainer/Z Expert Predictions Max     1145.31\n",
      "trainer/Z Expert Predictions Min      806.779\n",
      "trainer/Z Policy Predictions Mean     919.511\n",
      "trainer/Z Policy Predictions Std      344.588\n",
      "trainer/Z Policy Predictions Max     1133.98\n",
      "trainer/Z Policy Predictions Min     -380.58\n",
      "trainer/Z Expert Targets Mean        1082.84\n",
      "trainer/Z Expert Targets Std           39.9915\n",
      "trainer/Z Expert Targets Max         1136.3\n",
      "trainer/Z Expert Targets Min          761.113\n",
      "trainer/Z Policy Targets Mean         914.259\n",
      "trainer/Z Policy Targets Std          339.826\n",
      "trainer/Z Policy Targets Max         1129.39\n",
      "trainer/Z Policy Targets Min         -374.77\n",
      "trainer/Log Pis Mean                   19.9267\n",
      "trainer/Log Pis Std                     4.35964\n",
      "trainer/Policy mu Mean                  0.0243334\n",
      "trainer/Policy mu Std                   1.14067\n",
      "trainer/Policy log std Mean            -3.09108\n",
      "trainer/Policy log std Std              1.0389\n",
      "trainer/Alpha                           0.105579\n",
      "trainer/Alpha Loss                      0.00773621\n",
      "exploration/num steps total        151885\n",
      "exploration/num paths total           249\n",
      "evaluation/num steps total              1.23771e+06\n",
      "evaluation/num paths total           1513\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60089\n",
      "evaluation/Rewards Std                  0.950709\n",
      "evaluation/Rewards Max                  6.49604\n",
      "evaluation/Rewards Min                 -1.56065\n",
      "evaluation/Returns Mean              4600.89\n",
      "evaluation/Returns Std                116.921\n",
      "evaluation/Returns Max               4807.65\n",
      "evaluation/Returns Min               4432.86\n",
      "evaluation/Estimation Bias Mean      1042.88\n",
      "evaluation/Estimation Bias Std        138.108\n",
      "evaluation/EB/Q_True Mean              43.6568\n",
      "evaluation/EB/Q_True Std              134.46\n",
      "evaluation/EB/Q_Pred Mean            1086.54\n",
      "evaluation/EB/Q_Pred Std               44.9296\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4600.89\n",
      "evaluation/Actions Mean                 0.0290773\n",
      "evaluation/Actions Std                  0.535703\n",
      "evaluation/Actions Max                  0.99886\n",
      "evaluation/Actions Min                 -0.999333\n",
      "time/backward_policy (s)                1.91667\n",
      "time/backward_zf1 (s)                   2.03523\n",
      "time/backward_zf2 (s)                   1.97242\n",
      "time/data sampling (s)                  0.292202\n",
      "time/data storing (s)                   0.0148608\n",
      "time/evaluation sampling (s)            1.79035\n",
      "time/exploration sampling (s)           0.317033\n",
      "time/logging (s)                        0.0118843\n",
      "time/preback_alpha (s)                  1.02762\n",
      "time/preback_policy (s)                 1.16391\n",
      "time/preback_start (s)                  0.145231\n",
      "time/preback_zf (s)                     5.22821\n",
      "time/saving (s)                         0.00627684\n",
      "time/training (s)                       2.12759\n",
      "time/epoch (s)                         18.0495\n",
      "time/total (s)                       2614.85\n",
      "Epoch                                 146\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:36:06.250489 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 147 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 158000\n",
      "trainer/ZF1 Loss                       14.7555\n",
      "trainer/ZF2 Loss                       11.0706\n",
      "trainer/ZF Expert Reward               14.0014\n",
      "trainer/ZF Policy Reward                4.52412\n",
      "trainer/ZF CHI2 Term                   42.2794\n",
      "trainer/Policy Loss                  -952.156\n",
      "trainer/Bias Loss                      79.8207\n",
      "trainer/Bias Value                     13.6832\n",
      "trainer/Policy Grad Norm              115.604\n",
      "trainer/Policy Param Norm              34.2425\n",
      "trainer/Zf1 Grad Norm                1105.04\n",
      "trainer/Zf1 Param Norm                101.55\n",
      "trainer/Zf2 Grad Norm                1174.93\n",
      "trainer/Zf2 Param Norm                100.902\n",
      "trainer/Z Expert Predictions Mean    1093.13\n",
      "trainer/Z Expert Predictions Std       34.9615\n",
      "trainer/Z Expert Predictions Max     1147.28\n",
      "trainer/Z Expert Predictions Min      907.538\n",
      "trainer/Z Policy Predictions Mean     946.662\n",
      "trainer/Z Policy Predictions Std      314.418\n",
      "trainer/Z Policy Predictions Max     1141.98\n",
      "trainer/Z Policy Predictions Min     -424.307\n",
      "trainer/Z Expert Targets Mean        1079.12\n",
      "trainer/Z Expert Targets Std           37.3279\n",
      "trainer/Z Expert Targets Max         1132.89\n",
      "trainer/Z Expert Targets Min          894.645\n",
      "trainer/Z Policy Targets Mean         942.138\n",
      "trainer/Z Policy Targets Std          309.408\n",
      "trainer/Z Policy Targets Max         1130.44\n",
      "trainer/Z Policy Targets Min         -399.199\n",
      "trainer/Log Pis Mean                   20.09\n",
      "trainer/Log Pis Std                     3.90971\n",
      "trainer/Policy mu Mean                  0.0678609\n",
      "trainer/Policy mu Std                   1.01757\n",
      "trainer/Policy log std Mean            -3.23207\n",
      "trainer/Policy log std Std              0.910128\n",
      "trainer/Alpha                           0.105704\n",
      "trainer/Alpha Loss                     -0.00950889\n",
      "exploration/num steps total        152885\n",
      "exploration/num paths total           250\n",
      "evaluation/num steps total              1.24771e+06\n",
      "evaluation/num paths total           1523\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.59243\n",
      "evaluation/Rewards Std                  1.0251\n",
      "evaluation/Rewards Max                  6.7919\n",
      "evaluation/Rewards Min                 -1.71447\n",
      "evaluation/Returns Mean              4592.43\n",
      "evaluation/Returns Std                114.032\n",
      "evaluation/Returns Max               4727.25\n",
      "evaluation/Returns Min               4324.96\n",
      "evaluation/Estimation Bias Mean      1026.69\n",
      "evaluation/Estimation Bias Std        141.987\n",
      "evaluation/EB/Q_True Mean              42.2575\n",
      "evaluation/EB/Q_True Std              130.141\n",
      "evaluation/EB/Q_Pred Mean            1068.95\n",
      "evaluation/EB/Q_Pred Std               56.5365\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4592.43\n",
      "evaluation/Actions Mean                 0.033669\n",
      "evaluation/Actions Std                  0.534556\n",
      "evaluation/Actions Max                  0.999869\n",
      "evaluation/Actions Min                 -0.999518\n",
      "time/backward_policy (s)                1.90518\n",
      "time/backward_zf1 (s)                   2.01889\n",
      "time/backward_zf2 (s)                   1.96589\n",
      "time/data sampling (s)                  0.282881\n",
      "time/data storing (s)                   0.0150148\n",
      "time/evaluation sampling (s)            1.69907\n",
      "time/exploration sampling (s)           0.322396\n",
      "time/logging (s)                        0.0127612\n",
      "time/preback_alpha (s)                  0.98361\n",
      "time/preback_policy (s)                 1.11664\n",
      "time/preback_start (s)                  0.14401\n",
      "time/preback_zf (s)                     5.17382\n",
      "time/saving (s)                         0.00692328\n",
      "time/training (s)                       2.20464\n",
      "time/epoch (s)                         17.8517\n",
      "time/total (s)                       2632.73\n",
      "Epoch                                 147\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:36:24.182279 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 148 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 159000\n",
      "trainer/ZF1 Loss                       -0.585234\n",
      "trainer/ZF2 Loss                       -0.320501\n",
      "trainer/ZF Expert Reward               13.6027\n",
      "trainer/ZF Policy Reward                2.79697\n",
      "trainer/ZF CHI2 Term                   30.4254\n",
      "trainer/Policy Loss                  -909.707\n",
      "trainer/Bias Loss                      62.7458\n",
      "trainer/Bias Value                     13.6884\n",
      "trainer/Policy Grad Norm              118.169\n",
      "trainer/Policy Param Norm              34.2846\n",
      "trainer/Zf1 Grad Norm                1060.32\n",
      "trainer/Zf1 Param Norm                101.797\n",
      "trainer/Zf2 Grad Norm                1025.58\n",
      "trainer/Zf2 Param Norm                101.105\n",
      "trainer/Z Expert Predictions Mean    1082.85\n",
      "trainer/Z Expert Predictions Std       41.6314\n",
      "trainer/Z Expert Predictions Max     1151.63\n",
      "trainer/Z Expert Predictions Min      782.076\n",
      "trainer/Z Policy Predictions Mean     906.374\n",
      "trainer/Z Policy Predictions Std      357.124\n",
      "trainer/Z Policy Predictions Max     1148.27\n",
      "trainer/Z Policy Predictions Min     -384.62\n",
      "trainer/Z Expert Targets Mean        1069.25\n",
      "trainer/Z Expert Targets Std           43.7213\n",
      "trainer/Z Expert Targets Max         1126.05\n",
      "trainer/Z Expert Targets Min          744.022\n",
      "trainer/Z Policy Targets Mean         903.577\n",
      "trainer/Z Policy Targets Std          352.129\n",
      "trainer/Z Policy Targets Max         1117.28\n",
      "trainer/Z Policy Targets Min         -392.546\n",
      "trainer/Log Pis Mean                   20.2753\n",
      "trainer/Log Pis Std                     3.74772\n",
      "trainer/Policy mu Mean                  0.106137\n",
      "trainer/Policy mu Std                   1.10167\n",
      "trainer/Policy log std Mean            -3.15329\n",
      "trainer/Policy log std Std              1.01665\n",
      "trainer/Alpha                           0.107358\n",
      "trainer/Alpha Loss                     -0.0295592\n",
      "exploration/num steps total        153885\n",
      "exploration/num paths total           251\n",
      "evaluation/num steps total              1.25731e+06\n",
      "evaluation/num paths total           1533\n",
      "evaluation/path length Mean           960.3\n",
      "evaluation/path length Std            119.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            603\n",
      "evaluation/Rewards Mean                 4.58774\n",
      "evaluation/Rewards Std                  1.30919\n",
      "evaluation/Rewards Max                  6.64697\n",
      "evaluation/Rewards Min                 -3.76726\n",
      "evaluation/Returns Mean              4405.6\n",
      "evaluation/Returns Std                651.739\n",
      "evaluation/Returns Max               4853.31\n",
      "evaluation/Returns Min               2676.79\n",
      "evaluation/Estimation Bias Mean       999.849\n",
      "evaluation/Estimation Bias Std        214.757\n",
      "evaluation/EB/Q_True Mean              45.3044\n",
      "evaluation/EB/Q_True Std              136.341\n",
      "evaluation/EB/Q_Pred Mean            1045.15\n",
      "evaluation/EB/Q_Pred Std              166.196\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4405.6\n",
      "evaluation/Actions Mean                 0.0221912\n",
      "evaluation/Actions Std                  0.545531\n",
      "evaluation/Actions Max                  0.999988\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.94401\n",
      "time/backward_zf1 (s)                   2.06492\n",
      "time/backward_zf2 (s)                   2.01057\n",
      "time/data sampling (s)                  0.276982\n",
      "time/data storing (s)                   0.0144936\n",
      "time/evaluation sampling (s)            1.73685\n",
      "time/exploration sampling (s)           0.31568\n",
      "time/logging (s)                        0.0117155\n",
      "time/preback_alpha (s)                  1.03813\n",
      "time/preback_policy (s)                 1.17516\n",
      "time/preback_start (s)                  0.142695\n",
      "time/preback_zf (s)                     5.1328\n",
      "time/saving (s)                         0.00623561\n",
      "time/training (s)                       1.98863\n",
      "time/epoch (s)                         17.8589\n",
      "time/total (s)                       2650.61\n",
      "Epoch                                 148\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:36:41.963635 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 149 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 160000\n",
      "trainer/ZF1 Loss                        6.55791\n",
      "trainer/ZF2 Loss                       11.5137\n",
      "trainer/ZF Expert Reward               11.7615\n",
      "trainer/ZF Policy Reward                0.956149\n",
      "trainer/ZF CHI2 Term                   39.4857\n",
      "trainer/Policy Loss                  -942.889\n",
      "trainer/Bias Loss                      66.4615\n",
      "trainer/Bias Value                     13.6951\n",
      "trainer/Policy Grad Norm              204.3\n",
      "trainer/Policy Param Norm              34.3256\n",
      "trainer/Zf1 Grad Norm                1421.38\n",
      "trainer/Zf1 Param Norm                102.049\n",
      "trainer/Zf2 Grad Norm                3233.14\n",
      "trainer/Zf2 Param Norm                101.326\n",
      "trainer/Z Expert Predictions Mean    1078.15\n",
      "trainer/Z Expert Predictions Std       37.732\n",
      "trainer/Z Expert Predictions Max     1138.01\n",
      "trainer/Z Expert Predictions Min      815.527\n",
      "trainer/Z Policy Predictions Mean     935.336\n",
      "trainer/Z Policy Predictions Std      300.005\n",
      "trainer/Z Policy Predictions Max     1126.51\n",
      "trainer/Z Policy Predictions Min     -403.072\n",
      "trainer/Z Expert Targets Mean        1066.38\n",
      "trainer/Z Expert Targets Std           39.6391\n",
      "trainer/Z Expert Targets Max         1124.02\n",
      "trainer/Z Expert Targets Min          779.216\n",
      "trainer/Z Policy Targets Mean         934.38\n",
      "trainer/Z Policy Targets Std          294.987\n",
      "trainer/Z Policy Targets Max         1124.73\n",
      "trainer/Z Policy Targets Min         -396.088\n",
      "trainer/Log Pis Mean                   19.843\n",
      "trainer/Log Pis Std                     4.07097\n",
      "trainer/Policy mu Mean                  0.00931707\n",
      "trainer/Policy mu Std                   1.01484\n",
      "trainer/Policy log std Mean            -3.223\n",
      "trainer/Policy log std Std              0.926824\n",
      "trainer/Alpha                           0.107671\n",
      "trainer/Alpha Loss                      0.01691\n",
      "exploration/num steps total        154885\n",
      "exploration/num paths total           252\n",
      "evaluation/num steps total              1.26731e+06\n",
      "evaluation/num paths total           1543\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66227\n",
      "evaluation/Rewards Std                  0.979744\n",
      "evaluation/Rewards Max                  6.83978\n",
      "evaluation/Rewards Min                 -1.92675\n",
      "evaluation/Returns Mean              4662.27\n",
      "evaluation/Returns Std                119.423\n",
      "evaluation/Returns Max               4833.29\n",
      "evaluation/Returns Min               4453\n",
      "evaluation/Estimation Bias Mean      1023.17\n",
      "evaluation/Estimation Bias Std        147.264\n",
      "evaluation/EB/Q_True Mean              43.6155\n",
      "evaluation/EB/Q_True Std              134.62\n",
      "evaluation/EB/Q_Pred Mean            1066.78\n",
      "evaluation/EB/Q_Pred Std               51.0414\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4662.27\n",
      "evaluation/Actions Mean                 0.0238434\n",
      "evaluation/Actions Std                  0.532734\n",
      "evaluation/Actions Max                  0.999269\n",
      "evaluation/Actions Min                 -0.999312\n",
      "time/backward_policy (s)                1.79434\n",
      "time/backward_zf1 (s)                   1.94381\n",
      "time/backward_zf2 (s)                   1.86682\n",
      "time/data sampling (s)                  0.290911\n",
      "time/data storing (s)                   0.0147921\n",
      "time/evaluation sampling (s)            1.74224\n",
      "time/exploration sampling (s)           0.319033\n",
      "time/logging (s)                        0.0125215\n",
      "time/preback_alpha (s)                  0.930264\n",
      "time/preback_policy (s)                 1.01605\n",
      "time/preback_start (s)                  0.14457\n",
      "time/preback_zf (s)                     5.19043\n",
      "time/saving (s)                         0.00630487\n",
      "time/training (s)                       2.44123\n",
      "time/epoch (s)                         17.7133\n",
      "time/total (s)                       2668.35\n",
      "Epoch                                 149\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:36:59.514838 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 150 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 161000\n",
      "trainer/ZF1 Loss                        9.32121\n",
      "trainer/ZF2 Loss                        9.10596\n",
      "trainer/ZF Expert Reward               15.0447\n",
      "trainer/ZF Policy Reward                3.71469\n",
      "trainer/ZF CHI2 Term                   40.8017\n",
      "trainer/Policy Loss                  -914.811\n",
      "trainer/Bias Loss                      77.8465\n",
      "trainer/Bias Value                     13.6997\n",
      "trainer/Policy Grad Norm              111.082\n",
      "trainer/Policy Param Norm              34.3675\n",
      "trainer/Zf1 Grad Norm                1252.94\n",
      "trainer/Zf1 Param Norm                102.303\n",
      "trainer/Zf2 Grad Norm                1083.13\n",
      "trainer/Zf2 Param Norm                101.527\n",
      "trainer/Z Expert Predictions Mean    1077.25\n",
      "trainer/Z Expert Predictions Std       43.3646\n",
      "trainer/Z Expert Predictions Max     1133.31\n",
      "trainer/Z Expert Predictions Min      860.42\n",
      "trainer/Z Policy Predictions Mean     911.265\n",
      "trainer/Z Policy Predictions Std      335.637\n",
      "trainer/Z Policy Predictions Max     1122.31\n",
      "trainer/Z Policy Predictions Min     -403.681\n",
      "trainer/Z Expert Targets Mean        1062.21\n",
      "trainer/Z Expert Targets Std           44.3199\n",
      "trainer/Z Expert Targets Max         1111.76\n",
      "trainer/Z Expert Targets Min          839.31\n",
      "trainer/Z Policy Targets Mean         907.551\n",
      "trainer/Z Policy Targets Std          329.801\n",
      "trainer/Z Policy Targets Max         1116.23\n",
      "trainer/Z Policy Targets Min         -400.348\n",
      "trainer/Log Pis Mean                   20.4626\n",
      "trainer/Log Pis Std                     4.03083\n",
      "trainer/Policy mu Mean                  0.0825943\n",
      "trainer/Policy mu Std                   1.09984\n",
      "trainer/Policy log std Mean            -3.19018\n",
      "trainer/Policy log std Std              0.970494\n",
      "trainer/Alpha                           0.108197\n",
      "trainer/Alpha Loss                     -0.0500542\n",
      "exploration/num steps total        156885\n",
      "exploration/num paths total           254\n",
      "evaluation/num steps total              1.27731e+06\n",
      "evaluation/num paths total           1553\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63463\n",
      "evaluation/Rewards Std                  0.993916\n",
      "evaluation/Rewards Max                  6.79636\n",
      "evaluation/Rewards Min                 -1.90731\n",
      "evaluation/Returns Mean              4634.63\n",
      "evaluation/Returns Std                136.063\n",
      "evaluation/Returns Max               4825.98\n",
      "evaluation/Returns Min               4387.89\n",
      "evaluation/Estimation Bias Mean      1012.08\n",
      "evaluation/Estimation Bias Std        139.983\n",
      "evaluation/EB/Q_True Mean              43.0345\n",
      "evaluation/EB/Q_True Std              132.456\n",
      "evaluation/EB/Q_Pred Mean            1055.12\n",
      "evaluation/EB/Q_Pred Std               53.0557\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4634.63\n",
      "evaluation/Actions Mean                 0.0216336\n",
      "evaluation/Actions Std                  0.540402\n",
      "evaluation/Actions Max                  0.999339\n",
      "evaluation/Actions Min                 -0.999439\n",
      "time/backward_policy (s)                1.75363\n",
      "time/backward_zf1 (s)                   1.89075\n",
      "time/backward_zf2 (s)                   1.80233\n",
      "time/data sampling (s)                  0.284348\n",
      "time/data storing (s)                   0.0146873\n",
      "time/evaluation sampling (s)            1.78816\n",
      "time/exploration sampling (s)           0.319595\n",
      "time/logging (s)                        0.0122955\n",
      "time/preback_alpha (s)                  0.89687\n",
      "time/preback_policy (s)                 0.96715\n",
      "time/preback_start (s)                  0.144007\n",
      "time/preback_zf (s)                     5.15376\n",
      "time/saving (s)                         0.00647463\n",
      "time/training (s)                       2.45051\n",
      "time/epoch (s)                         17.4846\n",
      "time/total (s)                       2685.85\n",
      "Epoch                                 150\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:37:17.490659 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 151 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 162000\n",
      "trainer/ZF1 Loss                       15.491\n",
      "trainer/ZF2 Loss                       14.2493\n",
      "trainer/ZF Expert Reward               13.0634\n",
      "trainer/ZF Policy Reward                1.72325\n",
      "trainer/ZF CHI2 Term                   46.1141\n",
      "trainer/Policy Loss                  -929.758\n",
      "trainer/Bias Loss                     106.38\n",
      "trainer/Bias Value                     13.7099\n",
      "trainer/Policy Grad Norm               95.5335\n",
      "trainer/Policy Param Norm              34.4118\n",
      "trainer/Zf1 Grad Norm                1579.03\n",
      "trainer/Zf1 Param Norm                102.552\n",
      "trainer/Zf2 Grad Norm                1913.12\n",
      "trainer/Zf2 Param Norm                101.748\n",
      "trainer/Z Expert Predictions Mean    1062.61\n",
      "trainer/Z Expert Predictions Std       56.8169\n",
      "trainer/Z Expert Predictions Max     1121.23\n",
      "trainer/Z Expert Predictions Min      481.086\n",
      "trainer/Z Policy Predictions Mean     927.799\n",
      "trainer/Z Policy Predictions Std      287.939\n",
      "trainer/Z Policy Predictions Max     1116.32\n",
      "trainer/Z Policy Predictions Min     -407.99\n",
      "trainer/Z Expert Targets Mean        1049.55\n",
      "trainer/Z Expert Targets Std           63.6507\n",
      "trainer/Z Expert Targets Max         1108.69\n",
      "trainer/Z Expert Targets Min          318.624\n",
      "trainer/Z Policy Targets Mean         926.076\n",
      "trainer/Z Policy Targets Std          283.067\n",
      "trainer/Z Policy Targets Max         1110.82\n",
      "trainer/Z Policy Targets Min         -423.57\n",
      "trainer/Log Pis Mean                   20.1048\n",
      "trainer/Log Pis Std                     4.13678\n",
      "trainer/Policy mu Mean                  0.0378674\n",
      "trainer/Policy mu Std                   1.02791\n",
      "trainer/Policy log std Mean            -3.22085\n",
      "trainer/Policy log std Std              0.908532\n",
      "trainer/Alpha                           0.109418\n",
      "trainer/Alpha Loss                     -0.011467\n",
      "exploration/num steps total        156885\n",
      "exploration/num paths total           254\n",
      "evaluation/num steps total              1.28731e+06\n",
      "evaluation/num paths total           1563\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70511\n",
      "evaluation/Rewards Std                  0.93596\n",
      "evaluation/Rewards Max                  6.62839\n",
      "evaluation/Rewards Min                 -1.56261\n",
      "evaluation/Returns Mean              4705.11\n",
      "evaluation/Returns Std                 83.7386\n",
      "evaluation/Returns Max               4803.13\n",
      "evaluation/Returns Min               4554.77\n",
      "evaluation/Estimation Bias Mean      1008.11\n",
      "evaluation/Estimation Bias Std        141.968\n",
      "evaluation/EB/Q_True Mean              43.576\n",
      "evaluation/EB/Q_True Std              134.084\n",
      "evaluation/EB/Q_Pred Mean            1051.69\n",
      "evaluation/EB/Q_Pred Std               49.1055\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4705.11\n",
      "evaluation/Actions Mean                 0.0277065\n",
      "evaluation/Actions Std                  0.536827\n",
      "evaluation/Actions Max                  0.999585\n",
      "evaluation/Actions Min                 -0.999209\n",
      "time/backward_policy (s)                1.84921\n",
      "time/backward_zf1 (s)                   1.9866\n",
      "time/backward_zf2 (s)                   1.91633\n",
      "time/data sampling (s)                  0.293304\n",
      "time/data storing (s)                   0.0143149\n",
      "time/evaluation sampling (s)            1.79895\n",
      "time/exploration sampling (s)           0.3121\n",
      "time/logging (s)                        0.0118744\n",
      "time/preback_alpha (s)                  0.973465\n",
      "time/preback_policy (s)                 1.07946\n",
      "time/preback_start (s)                  0.146266\n",
      "time/preback_zf (s)                     5.20932\n",
      "time/saving (s)                         0.00640824\n",
      "time/training (s)                       2.3077\n",
      "time/epoch (s)                         17.9053\n",
      "time/total (s)                       2703.78\n",
      "Epoch                                 151\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:37:35.603049 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 152 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 163000\n",
      "trainer/ZF1 Loss                        8.40295\n",
      "trainer/ZF2 Loss                       14.1882\n",
      "trainer/ZF Expert Reward                9.36439\n",
      "trainer/ZF Policy Reward                0.951654\n",
      "trainer/ZF CHI2 Term                   39.7518\n",
      "trainer/Policy Loss                  -942.519\n",
      "trainer/Bias Loss                      80.4937\n",
      "trainer/Bias Value                     13.7185\n",
      "trainer/Policy Grad Norm              177.479\n",
      "trainer/Policy Param Norm              34.4524\n",
      "trainer/Zf1 Grad Norm                1310.96\n",
      "trainer/Zf1 Param Norm                102.778\n",
      "trainer/Zf2 Grad Norm                1852\n",
      "trainer/Zf2 Param Norm                101.972\n",
      "trainer/Z Expert Predictions Mean    1055.56\n",
      "trainer/Z Expert Predictions Std       53.5473\n",
      "trainer/Z Expert Predictions Max     1123.57\n",
      "trainer/Z Expert Predictions Min      548.579\n",
      "trainer/Z Policy Predictions Mean     940.004\n",
      "trainer/Z Policy Predictions Std      265.36\n",
      "trainer/Z Policy Predictions Max     1123.35\n",
      "trainer/Z Policy Predictions Min     -359.647\n",
      "trainer/Z Expert Targets Mean        1046.2\n",
      "trainer/Z Expert Targets Std           53.8114\n",
      "trainer/Z Expert Targets Max         1111.58\n",
      "trainer/Z Expert Targets Min          495.78\n",
      "trainer/Z Policy Targets Mean         939.052\n",
      "trainer/Z Policy Targets Std          260.703\n",
      "trainer/Z Policy Targets Max         1108.98\n",
      "trainer/Z Policy Targets Min         -335.655\n",
      "trainer/Log Pis Mean                   20.246\n",
      "trainer/Log Pis Std                     3.8685\n",
      "trainer/Policy mu Mean                  0.0378541\n",
      "trainer/Policy mu Std                   0.971974\n",
      "trainer/Policy log std Mean            -3.30964\n",
      "trainer/Policy log std Std              0.857\n",
      "trainer/Alpha                           0.109437\n",
      "trainer/Alpha Loss                     -0.026918\n",
      "exploration/num steps total        158885\n",
      "exploration/num paths total           256\n",
      "evaluation/num steps total              1.29731e+06\n",
      "evaluation/num paths total           1573\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69709\n",
      "evaluation/Rewards Std                  1.00901\n",
      "evaluation/Rewards Max                  6.57104\n",
      "evaluation/Rewards Min                 -1.27899\n",
      "evaluation/Returns Mean              4697.09\n",
      "evaluation/Returns Std                105.973\n",
      "evaluation/Returns Max               4902.4\n",
      "evaluation/Returns Min               4512.98\n",
      "evaluation/Estimation Bias Mean      1001.58\n",
      "evaluation/Estimation Bias Std        145.709\n",
      "evaluation/EB/Q_True Mean              42.8707\n",
      "evaluation/EB/Q_True Std              132.301\n",
      "evaluation/EB/Q_Pred Mean            1044.45\n",
      "evaluation/EB/Q_Pred Std               56.1086\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4697.09\n",
      "evaluation/Actions Mean                 0.023484\n",
      "evaluation/Actions Std                  0.531743\n",
      "evaluation/Actions Max                  0.999129\n",
      "evaluation/Actions Min                 -0.998863\n",
      "time/backward_policy (s)                1.90681\n",
      "time/backward_zf1 (s)                   2.05304\n",
      "time/backward_zf2 (s)                   1.99171\n",
      "time/data sampling (s)                  0.279367\n",
      "time/data storing (s)                   0.0144183\n",
      "time/evaluation sampling (s)            1.70479\n",
      "time/exploration sampling (s)           0.322376\n",
      "time/logging (s)                        0.0132709\n",
      "time/preback_alpha (s)                  1.00257\n",
      "time/preback_policy (s)                 1.13534\n",
      "time/preback_start (s)                  0.145963\n",
      "time/preback_zf (s)                     5.22489\n",
      "time/saving (s)                         0.00762512\n",
      "time/training (s)                       2.24355\n",
      "time/epoch (s)                         18.0457\n",
      "time/total (s)                       2721.84\n",
      "Epoch                                 152\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:37:53.599992 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 153 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 164000\n",
      "trainer/ZF1 Loss                        0.168812\n",
      "trainer/ZF2 Loss                       -1.864\n",
      "trainer/ZF Expert Reward               13.6036\n",
      "trainer/ZF Policy Reward                1.44024\n",
      "trainer/ZF CHI2 Term                   31.147\n",
      "trainer/Policy Loss                  -904.356\n",
      "trainer/Bias Loss                      51.1304\n",
      "trainer/Bias Value                     13.7255\n",
      "trainer/Policy Grad Norm              111.636\n",
      "trainer/Policy Param Norm              34.4954\n",
      "trainer/Zf1 Grad Norm                1032.49\n",
      "trainer/Zf1 Param Norm                103.022\n",
      "trainer/Zf2 Grad Norm                 917.818\n",
      "trainer/Zf2 Param Norm                102.198\n",
      "trainer/Z Expert Predictions Mean    1056.07\n",
      "trainer/Z Expert Predictions Std       47.5516\n",
      "trainer/Z Expert Predictions Max     1118.35\n",
      "trainer/Z Expert Predictions Min      764.029\n",
      "trainer/Z Policy Predictions Mean     899.873\n",
      "trainer/Z Policy Predictions Std      320.602\n",
      "trainer/Z Policy Predictions Max     1105.7\n",
      "trainer/Z Policy Predictions Min     -402.074\n",
      "trainer/Z Expert Targets Mean        1042.47\n",
      "trainer/Z Expert Targets Std           48.5918\n",
      "trainer/Z Expert Targets Max         1109.08\n",
      "trainer/Z Expert Targets Min          744.244\n",
      "trainer/Z Policy Targets Mean         898.433\n",
      "trainer/Z Policy Targets Std          315.301\n",
      "trainer/Z Policy Targets Max         1091.5\n",
      "trainer/Z Policy Targets Min         -388.551\n",
      "trainer/Log Pis Mean                   20.0316\n",
      "trainer/Log Pis Std                     4.08982\n",
      "trainer/Policy mu Mean                  0.0932115\n",
      "trainer/Policy mu Std                   1.0698\n",
      "trainer/Policy log std Mean            -3.16051\n",
      "trainer/Policy log std Std              0.972014\n",
      "trainer/Alpha                           0.110836\n",
      "trainer/Alpha Loss                     -0.00349677\n",
      "exploration/num steps total        158885\n",
      "exploration/num paths total           256\n",
      "evaluation/num steps total              1.30636e+06\n",
      "evaluation/num paths total           1583\n",
      "evaluation/path length Mean           904.8\n",
      "evaluation/path length Std            233.179\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            223\n",
      "evaluation/Rewards Mean                 4.6059\n",
      "evaluation/Rewards Std                  1.11102\n",
      "evaluation/Rewards Max                  6.93416\n",
      "evaluation/Rewards Min                 -1.66022\n",
      "evaluation/Returns Mean              4167.41\n",
      "evaluation/Returns Std               1077.23\n",
      "evaluation/Returns Max               4702.5\n",
      "evaluation/Returns Min                999.785\n",
      "evaluation/Estimation Bias Mean       985.41\n",
      "evaluation/Estimation Bias Std        155.34\n",
      "evaluation/EB/Q_True Mean              47.3732\n",
      "evaluation/EB/Q_True Std              138.612\n",
      "evaluation/EB/Q_Pred Mean            1032.78\n",
      "evaluation/EB/Q_Pred Std               75.4657\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4167.41\n",
      "evaluation/Actions Mean                 0.0258854\n",
      "evaluation/Actions Std                  0.531981\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90487\n",
      "time/backward_zf1 (s)                   2.03426\n",
      "time/backward_zf2 (s)                   1.984\n",
      "time/data sampling (s)                  0.282406\n",
      "time/data storing (s)                   0.0154317\n",
      "time/evaluation sampling (s)            1.73996\n",
      "time/exploration sampling (s)           0.320551\n",
      "time/logging (s)                        0.0106709\n",
      "time/preback_alpha (s)                  0.994703\n",
      "time/preback_policy (s)                 1.10971\n",
      "time/preback_start (s)                  0.145195\n",
      "time/preback_zf (s)                     5.18439\n",
      "time/saving (s)                         0.00581853\n",
      "time/training (s)                       2.19048\n",
      "time/epoch (s)                         17.9225\n",
      "time/total (s)                       2739.79\n",
      "Epoch                                 153\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:38:11.946179 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 154 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 165000\n",
      "trainer/ZF1 Loss                        2.66119\n",
      "trainer/ZF2 Loss                       -2.61208\n",
      "trainer/ZF Expert Reward               15.2022\n",
      "trainer/ZF Policy Reward                3.78976\n",
      "trainer/ZF CHI2 Term                   31.8611\n",
      "trainer/Policy Loss                  -916.849\n",
      "trainer/Bias Loss                      45.9575\n",
      "trainer/Bias Value                     13.7339\n",
      "trainer/Policy Grad Norm              145.612\n",
      "trainer/Policy Param Norm              34.5351\n",
      "trainer/Zf1 Grad Norm                1045.33\n",
      "trainer/Zf1 Param Norm                103.26\n",
      "trainer/Zf2 Grad Norm                 930.188\n",
      "trainer/Zf2 Param Norm                102.404\n",
      "trainer/Z Expert Predictions Mean    1058.17\n",
      "trainer/Z Expert Predictions Std       33.6479\n",
      "trainer/Z Expert Predictions Max     1111.86\n",
      "trainer/Z Expert Predictions Min      865.14\n",
      "trainer/Z Policy Predictions Mean     909.373\n",
      "trainer/Z Policy Predictions Std      308.583\n",
      "trainer/Z Policy Predictions Max     1115.06\n",
      "trainer/Z Policy Predictions Min     -326.878\n",
      "trainer/Z Expert Targets Mean        1042.97\n",
      "trainer/Z Expert Targets Std           35.9446\n",
      "trainer/Z Expert Targets Max         1102.87\n",
      "trainer/Z Expert Targets Min          850.672\n",
      "trainer/Z Policy Targets Mean         905.584\n",
      "trainer/Z Policy Targets Std          304.083\n",
      "trainer/Z Policy Targets Max         1098.34\n",
      "trainer/Z Policy Targets Min         -315.545\n",
      "trainer/Log Pis Mean                   20.6304\n",
      "trainer/Log Pis Std                     3.79658\n",
      "trainer/Policy mu Mean                  0.0529111\n",
      "trainer/Policy mu Std                   1.05984\n",
      "trainer/Policy log std Mean            -3.22976\n",
      "trainer/Policy log std Std              0.96436\n",
      "trainer/Alpha                           0.112824\n",
      "trainer/Alpha Loss                     -0.0711264\n",
      "exploration/num steps total        158885\n",
      "exploration/num paths total           256\n",
      "evaluation/num steps total              1.31636e+06\n",
      "evaluation/num paths total           1593\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62916\n",
      "evaluation/Rewards Std                  0.985291\n",
      "evaluation/Rewards Max                  6.6964\n",
      "evaluation/Rewards Min                 -2.21952\n",
      "evaluation/Returns Mean              4629.16\n",
      "evaluation/Returns Std                125.494\n",
      "evaluation/Returns Max               4855.55\n",
      "evaluation/Returns Min               4486.19\n",
      "evaluation/Estimation Bias Mean       985.976\n",
      "evaluation/Estimation Bias Std        149.955\n",
      "evaluation/EB/Q_True Mean              43.1699\n",
      "evaluation/EB/Q_True Std              133.181\n",
      "evaluation/EB/Q_Pred Mean            1029.15\n",
      "evaluation/EB/Q_Pred Std               59.9815\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4629.16\n",
      "evaluation/Actions Mean                 0.0162904\n",
      "evaluation/Actions Std                  0.540557\n",
      "evaluation/Actions Max                  0.999328\n",
      "evaluation/Actions Min                 -0.999572\n",
      "time/backward_policy (s)                1.97286\n",
      "time/backward_zf1 (s)                   2.12591\n",
      "time/backward_zf2 (s)                   2.04818\n",
      "time/data sampling (s)                  0.291512\n",
      "time/data storing (s)                   0.0152416\n",
      "time/evaluation sampling (s)            1.76086\n",
      "time/exploration sampling (s)           0.317328\n",
      "time/logging (s)                        0.0122608\n",
      "time/preback_alpha (s)                  1.0464\n",
      "time/preback_policy (s)                 1.19599\n",
      "time/preback_start (s)                  0.145098\n",
      "time/preback_zf (s)                     5.25911\n",
      "time/saving (s)                         0.00568572\n",
      "time/training (s)                       2.08492\n",
      "time/epoch (s)                         18.2814\n",
      "time/total (s)                       2758.09\n",
      "Epoch                                 154\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:38:29.820928 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 155 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 166000\n",
      "trainer/ZF1 Loss                       15.1721\n",
      "trainer/ZF2 Loss                       10.4914\n",
      "trainer/ZF Expert Reward               13.4102\n",
      "trainer/ZF Policy Reward                1.68516\n",
      "trainer/ZF CHI2 Term                   44.2715\n",
      "trainer/Policy Loss                  -915.239\n",
      "trainer/Bias Loss                      53.176\n",
      "trainer/Bias Value                     13.7418\n",
      "trainer/Policy Grad Norm              113.666\n",
      "trainer/Policy Param Norm              34.5723\n",
      "trainer/Zf1 Grad Norm                1735.42\n",
      "trainer/Zf1 Param Norm                103.509\n",
      "trainer/Zf2 Grad Norm                1300.94\n",
      "trainer/Zf2 Param Norm                102.616\n",
      "trainer/Z Expert Predictions Mean    1052.95\n",
      "trainer/Z Expert Predictions Std       35.1159\n",
      "trainer/Z Expert Predictions Max     1109.86\n",
      "trainer/Z Expert Predictions Min      861.296\n",
      "trainer/Z Policy Predictions Mean     910.48\n",
      "trainer/Z Policy Predictions Std      311.756\n",
      "trainer/Z Policy Predictions Max     1094.09\n",
      "trainer/Z Policy Predictions Min     -423.914\n",
      "trainer/Z Expert Targets Mean        1039.53\n",
      "trainer/Z Expert Targets Std           34.5468\n",
      "trainer/Z Expert Targets Max         1095.72\n",
      "trainer/Z Expert Targets Min          856.666\n",
      "trainer/Z Policy Targets Mean         908.795\n",
      "trainer/Z Policy Targets Std          302.293\n",
      "trainer/Z Policy Targets Max         1087.61\n",
      "trainer/Z Policy Targets Min         -406.551\n",
      "trainer/Log Pis Mean                   19.9138\n",
      "trainer/Log Pis Std                     3.78907\n",
      "trainer/Policy mu Mean                  0.0424391\n",
      "trainer/Policy mu Std                   0.938535\n",
      "trainer/Policy log std Mean            -3.30804\n",
      "trainer/Policy log std Std              0.872589\n",
      "trainer/Alpha                           0.11281\n",
      "trainer/Alpha Loss                      0.00972902\n",
      "exploration/num steps total        160885\n",
      "exploration/num paths total           258\n",
      "evaluation/num steps total              1.32636e+06\n",
      "evaluation/num paths total           1603\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.1021\n",
      "evaluation/Rewards Std                  2.05772\n",
      "evaluation/Rewards Max                  6.57121\n",
      "evaluation/Rewards Min                 -3.21759\n",
      "evaluation/Returns Mean              4102.1\n",
      "evaluation/Returns Std               1630.57\n",
      "evaluation/Returns Max               4843.76\n",
      "evaluation/Returns Min               -776.644\n",
      "evaluation/Estimation Bias Mean       884.008\n",
      "evaluation/Estimation Bias Std        359.539\n",
      "evaluation/EB/Q_True Mean              43.6347\n",
      "evaluation/EB/Q_True Std              134.424\n",
      "evaluation/EB/Q_Pred Mean             927.643\n",
      "evaluation/EB/Q_Pred Std              343.307\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4102.1\n",
      "evaluation/Actions Mean                -0.00646306\n",
      "evaluation/Actions Std                  0.573954\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.91257\n",
      "time/backward_zf1 (s)                   2.01773\n",
      "time/backward_zf2 (s)                   1.95806\n",
      "time/data sampling (s)                  0.287191\n",
      "time/data storing (s)                   0.0145818\n",
      "time/evaluation sampling (s)            1.72677\n",
      "time/exploration sampling (s)           0.318691\n",
      "time/logging (s)                        0.0118358\n",
      "time/preback_alpha (s)                  0.99301\n",
      "time/preback_policy (s)                 1.11738\n",
      "time/preback_start (s)                  0.143953\n",
      "time/preback_zf (s)                     5.14768\n",
      "time/saving (s)                         0.00585714\n",
      "time/training (s)                       2.15086\n",
      "time/epoch (s)                         17.8062\n",
      "time/total (s)                       2775.92\n",
      "Epoch                                 155\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:38:48.555192 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 156 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 167000\n",
      "trainer/ZF1 Loss                       -0.337574\n",
      "trainer/ZF2 Loss                        1.62861\n",
      "trainer/ZF Expert Reward               13.9861\n",
      "trainer/ZF Policy Reward                2.73631\n",
      "trainer/ZF CHI2 Term                   31.8454\n",
      "trainer/Policy Loss                  -893.959\n",
      "trainer/Bias Loss                      61.2938\n",
      "trainer/Bias Value                     13.7504\n",
      "trainer/Policy Grad Norm              106.15\n",
      "trainer/Policy Param Norm              34.6033\n",
      "trainer/Zf1 Grad Norm                1368.81\n",
      "trainer/Zf1 Param Norm                103.751\n",
      "trainer/Zf2 Grad Norm                1227.03\n",
      "trainer/Zf2 Param Norm                102.829\n",
      "trainer/Z Expert Predictions Mean    1041.13\n",
      "trainer/Z Expert Predictions Std       57.8853\n",
      "trainer/Z Expert Predictions Max     1097.4\n",
      "trainer/Z Expert Predictions Min      365.713\n",
      "trainer/Z Policy Predictions Mean     890.55\n",
      "trainer/Z Policy Predictions Std      327.549\n",
      "trainer/Z Policy Predictions Max     1089.06\n",
      "trainer/Z Policy Predictions Min     -410.393\n",
      "trainer/Z Expert Targets Mean        1027.14\n",
      "trainer/Z Expert Targets Std           57.9816\n",
      "trainer/Z Expert Targets Max         1084.69\n",
      "trainer/Z Expert Targets Min          382.286\n",
      "trainer/Z Policy Targets Mean         887.813\n",
      "trainer/Z Policy Targets Std          324.258\n",
      "trainer/Z Policy Targets Max         1086.17\n",
      "trainer/Z Policy Targets Min         -415.845\n",
      "trainer/Log Pis Mean                   20.1517\n",
      "trainer/Log Pis Std                     4.09842\n",
      "trainer/Policy mu Mean                  0.0931587\n",
      "trainer/Policy mu Std                   1.04803\n",
      "trainer/Policy log std Mean            -3.24348\n",
      "trainer/Policy log std Std              0.943844\n",
      "trainer/Alpha                           0.11291\n",
      "trainer/Alpha Loss                     -0.0171223\n",
      "exploration/num steps total        161885\n",
      "exploration/num paths total           259\n",
      "evaluation/num steps total              1.33636e+06\n",
      "evaluation/num paths total           1613\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.72097\n",
      "evaluation/Rewards Std                  1.01301\n",
      "evaluation/Rewards Max                  6.67422\n",
      "evaluation/Rewards Min                 -1.57118\n",
      "evaluation/Returns Mean              4720.97\n",
      "evaluation/Returns Std                119.826\n",
      "evaluation/Returns Max               4964.27\n",
      "evaluation/Returns Min               4542.89\n",
      "evaluation/Estimation Bias Mean       975.954\n",
      "evaluation/Estimation Bias Std        143.749\n",
      "evaluation/EB/Q_True Mean              43.5291\n",
      "evaluation/EB/Q_True Std              133.927\n",
      "evaluation/EB/Q_Pred Mean            1019.48\n",
      "evaluation/EB/Q_Pred Std               55.0605\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4720.97\n",
      "evaluation/Actions Mean                 0.0174374\n",
      "evaluation/Actions Std                  0.539625\n",
      "evaluation/Actions Max                  0.999357\n",
      "evaluation/Actions Min                 -0.999646\n",
      "time/backward_policy (s)                2.05749\n",
      "time/backward_zf1 (s)                   2.19984\n",
      "time/backward_zf2 (s)                   2.13647\n",
      "time/data sampling (s)                  0.317628\n",
      "time/data storing (s)                   0.0144126\n",
      "time/evaluation sampling (s)            1.79286\n",
      "time/exploration sampling (s)           0.319101\n",
      "time/logging (s)                        0.0126232\n",
      "time/preback_alpha (s)                  1.08579\n",
      "time/preback_policy (s)                 1.23572\n",
      "time/preback_start (s)                  0.147958\n",
      "time/preback_zf (s)                     5.22908\n",
      "time/saving (s)                         0.00671121\n",
      "time/training (s)                       2.11219\n",
      "time/epoch (s)                         18.6679\n",
      "time/total (s)                       2794.6\n",
      "Epoch                                 156\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:39:06.686170 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 157 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 168000\n",
      "trainer/ZF1 Loss                        2.75873\n",
      "trainer/ZF2 Loss                        2.21251\n",
      "trainer/ZF Expert Reward               11.5618\n",
      "trainer/ZF Policy Reward                1.03949\n",
      "trainer/ZF CHI2 Term                   32.9505\n",
      "trainer/Policy Loss                  -911.852\n",
      "trainer/Bias Loss                      57.3016\n",
      "trainer/Bias Value                     13.7575\n",
      "trainer/Policy Grad Norm              120.763\n",
      "trainer/Policy Param Norm              34.6416\n",
      "trainer/Zf1 Grad Norm                1395.94\n",
      "trainer/Zf1 Param Norm                103.993\n",
      "trainer/Zf2 Grad Norm                1176.66\n",
      "trainer/Zf2 Param Norm                103.046\n",
      "trainer/Z Expert Predictions Mean    1033.47\n",
      "trainer/Z Expert Predictions Std       75.1705\n",
      "trainer/Z Expert Predictions Max     1096.32\n",
      "trainer/Z Expert Predictions Min      -23.473\n",
      "trainer/Z Policy Predictions Mean     907.386\n",
      "trainer/Z Policy Predictions Std      311.216\n",
      "trainer/Z Policy Predictions Max     1087.03\n",
      "trainer/Z Policy Predictions Min     -401.474\n",
      "trainer/Z Expert Targets Mean        1021.9\n",
      "trainer/Z Expert Targets Std           74.7327\n",
      "trainer/Z Expert Targets Max         1088.97\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         906.347\n",
      "trainer/Z Policy Targets Std          307.496\n",
      "trainer/Z Policy Targets Max         1076.03\n",
      "trainer/Z Policy Targets Min         -394.89\n",
      "trainer/Log Pis Mean                   20.1439\n",
      "trainer/Log Pis Std                     3.51282\n",
      "trainer/Policy mu Mean                  0.0454506\n",
      "trainer/Policy mu Std                   0.994103\n",
      "trainer/Policy log std Mean            -3.29472\n",
      "trainer/Policy log std Std              0.898104\n",
      "trainer/Alpha                           0.113998\n",
      "trainer/Alpha Loss                     -0.0164059\n",
      "exploration/num steps total        162885\n",
      "exploration/num paths total           260\n",
      "evaluation/num steps total              1.34537e+06\n",
      "evaluation/num paths total           1623\n",
      "evaluation/path length Mean           901\n",
      "evaluation/path length Std            297\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             10\n",
      "evaluation/Rewards Mean                 4.51925\n",
      "evaluation/Rewards Std                  1.33627\n",
      "evaluation/Rewards Max                  6.59544\n",
      "evaluation/Rewards Min                 -2.58066\n",
      "evaluation/Returns Mean              4071.84\n",
      "evaluation/Returns Std               1407.76\n",
      "evaluation/Returns Max               4833.48\n",
      "evaluation/Returns Min                  2.18759\n",
      "evaluation/Estimation Bias Mean       952.036\n",
      "evaluation/Estimation Bias Std        170.616\n",
      "evaluation/EB/Q_True Mean              48.1774\n",
      "evaluation/EB/Q_True Std              139.696\n",
      "evaluation/EB/Q_Pred Mean            1000.21\n",
      "evaluation/EB/Q_Pred Std               97.1471\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4071.84\n",
      "evaluation/Actions Mean                 0.0199867\n",
      "evaluation/Actions Std                  0.537154\n",
      "evaluation/Actions Max                  0.999693\n",
      "evaluation/Actions Min                 -0.999595\n",
      "time/backward_policy (s)                1.93387\n",
      "time/backward_zf1 (s)                   2.07013\n",
      "time/backward_zf2 (s)                   2.014\n",
      "time/data sampling (s)                  0.289634\n",
      "time/data storing (s)                   0.0147641\n",
      "time/evaluation sampling (s)            1.77032\n",
      "time/exploration sampling (s)           0.321866\n",
      "time/logging (s)                        0.0110296\n",
      "time/preback_alpha (s)                  1.02157\n",
      "time/preback_policy (s)                 1.1438\n",
      "time/preback_start (s)                  0.146074\n",
      "time/preback_zf (s)                     5.18145\n",
      "time/saving (s)                         0.00619092\n",
      "time/training (s)                       2.13449\n",
      "time/epoch (s)                         18.0592\n",
      "time/total (s)                       2812.68\n",
      "Epoch                                 157\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:39:25.065187 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 158 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 169000\n",
      "trainer/ZF1 Loss                       13.298\n",
      "trainer/ZF2 Loss                       14.2798\n",
      "trainer/ZF Expert Reward               11.3305\n",
      "trainer/ZF Policy Reward                3.48188\n",
      "trainer/ZF CHI2 Term                   42.3013\n",
      "trainer/Policy Loss                  -902.287\n",
      "trainer/Bias Loss                      59.567\n",
      "trainer/Bias Value                     13.7636\n",
      "trainer/Policy Grad Norm              126.044\n",
      "trainer/Policy Param Norm              34.684\n",
      "trainer/Zf1 Grad Norm                2019.37\n",
      "trainer/Zf1 Param Norm                104.222\n",
      "trainer/Zf2 Grad Norm                1599.16\n",
      "trainer/Zf2 Param Norm                103.236\n",
      "trainer/Z Expert Predictions Mean    1031.09\n",
      "trainer/Z Expert Predictions Std       43.1508\n",
      "trainer/Z Expert Predictions Max     1083.92\n",
      "trainer/Z Expert Predictions Min      701.149\n",
      "trainer/Z Policy Predictions Mean     897.563\n",
      "trainer/Z Policy Predictions Std      296.14\n",
      "trainer/Z Policy Predictions Max     1082.17\n",
      "trainer/Z Policy Predictions Min     -397.894\n",
      "trainer/Z Expert Targets Mean        1019.76\n",
      "trainer/Z Expert Targets Std           44.3559\n",
      "trainer/Z Expert Targets Max         1075.47\n",
      "trainer/Z Expert Targets Min          703.934\n",
      "trainer/Z Policy Targets Mean         894.082\n",
      "trainer/Z Policy Targets Std          292.528\n",
      "trainer/Z Policy Targets Max         1076.48\n",
      "trainer/Z Policy Targets Min         -397.839\n",
      "trainer/Log Pis Mean                   20.8726\n",
      "trainer/Log Pis Std                     3.5525\n",
      "trainer/Policy mu Mean                  0.0394588\n",
      "trainer/Policy mu Std                   1.07496\n",
      "trainer/Policy log std Mean            -3.28136\n",
      "trainer/Policy log std Std              0.918422\n",
      "trainer/Alpha                           0.114247\n",
      "trainer/Alpha Loss                     -0.0996802\n",
      "exploration/num steps total        163885\n",
      "exploration/num paths total           261\n",
      "evaluation/num steps total              1.35513e+06\n",
      "evaluation/num paths total           1633\n",
      "evaluation/path length Mean           975.9\n",
      "evaluation/path length Std             72.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            759\n",
      "evaluation/Rewards Mean                 4.19842\n",
      "evaluation/Rewards Std                  1.92584\n",
      "evaluation/Rewards Max                  6.64882\n",
      "evaluation/Rewards Min                 -2.49511\n",
      "evaluation/Returns Mean              4097.24\n",
      "evaluation/Returns Std               1432.66\n",
      "evaluation/Returns Max               4762.12\n",
      "evaluation/Returns Min                -71.9743\n",
      "evaluation/Estimation Bias Mean       890.831\n",
      "evaluation/Estimation Bias Std        302.401\n",
      "evaluation/EB/Q_True Mean              43.525\n",
      "evaluation/EB/Q_True Std              132.732\n",
      "evaluation/EB/Q_Pred Mean             934.356\n",
      "evaluation/EB/Q_Pred Std              280.717\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4097.24\n",
      "evaluation/Actions Mean                 0.0534804\n",
      "evaluation/Actions Std                  0.564804\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999739\n",
      "time/backward_policy (s)                1.98081\n",
      "time/backward_zf1 (s)                   2.11952\n",
      "time/backward_zf2 (s)                   2.05389\n",
      "time/data sampling (s)                  0.306832\n",
      "time/data storing (s)                   0.0140742\n",
      "time/evaluation sampling (s)            1.74429\n",
      "time/exploration sampling (s)           0.316734\n",
      "time/logging (s)                        0.0133489\n",
      "time/preback_alpha (s)                  1.01594\n",
      "time/preback_policy (s)                 1.16021\n",
      "time/preback_start (s)                  0.145189\n",
      "time/preback_zf (s)                     5.21752\n",
      "time/saving (s)                         0.00749787\n",
      "time/training (s)                       2.21884\n",
      "time/epoch (s)                         18.3147\n",
      "time/total (s)                       2831.02\n",
      "Epoch                                 158\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:39:42.708538 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 159 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 170000\n",
      "trainer/ZF1 Loss                      165.605\n",
      "trainer/ZF2 Loss                      178.73\n",
      "trainer/ZF Expert Reward               10.6506\n",
      "trainer/ZF Policy Reward                3.45901\n",
      "trainer/ZF CHI2 Term                  199.299\n",
      "trainer/Policy Loss                  -838.055\n",
      "trainer/Bias Loss                      57.2581\n",
      "trainer/Bias Value                     13.7721\n",
      "trainer/Policy Grad Norm              122.666\n",
      "trainer/Policy Param Norm              34.723\n",
      "trainer/Zf1 Grad Norm                4443.02\n",
      "trainer/Zf1 Param Norm                104.454\n",
      "trainer/Zf2 Grad Norm                3198.11\n",
      "trainer/Zf2 Param Norm                103.439\n",
      "trainer/Z Expert Predictions Mean    1024.77\n",
      "trainer/Z Expert Predictions Std       42.1319\n",
      "trainer/Z Expert Predictions Max     1080\n",
      "trainer/Z Expert Predictions Min      730.703\n",
      "trainer/Z Policy Predictions Mean     836.889\n",
      "trainer/Z Policy Predictions Std      372.017\n",
      "trainer/Z Policy Predictions Max     1071.34\n",
      "trainer/Z Policy Predictions Min     -405.788\n",
      "trainer/Z Expert Targets Mean        1014.12\n",
      "trainer/Z Expert Targets Std           44.1516\n",
      "trainer/Z Expert Targets Max         1068.92\n",
      "trainer/Z Expert Targets Min          694.275\n",
      "trainer/Z Policy Targets Mean         833.43\n",
      "trainer/Z Policy Targets Std          368.568\n",
      "trainer/Z Policy Targets Max         1062.46\n",
      "trainer/Z Policy Targets Min         -399.611\n",
      "trainer/Log Pis Mean                   20.1415\n",
      "trainer/Log Pis Std                     4.2395\n",
      "trainer/Policy mu Mean                  0.0112654\n",
      "trainer/Policy mu Std                   1.15819\n",
      "trainer/Policy log std Mean            -3.10105\n",
      "trainer/Policy log std Std              1.03332\n",
      "trainer/Alpha                           0.115083\n",
      "trainer/Alpha Loss                     -0.0162867\n",
      "exploration/num steps total        164885\n",
      "exploration/num paths total           262\n",
      "evaluation/num steps total              1.36513e+06\n",
      "evaluation/num paths total           1643\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64614\n",
      "evaluation/Rewards Std                  1.35223\n",
      "evaluation/Rewards Max                  7.02403\n",
      "evaluation/Rewards Min                 -3.06327\n",
      "evaluation/Returns Mean              4646.14\n",
      "evaluation/Returns Std                395.719\n",
      "evaluation/Returns Max               4957.54\n",
      "evaluation/Returns Min               3497.25\n",
      "evaluation/Estimation Bias Mean       941.124\n",
      "evaluation/Estimation Bias Std        228.288\n",
      "evaluation/EB/Q_True Mean              44.1739\n",
      "evaluation/EB/Q_True Std              136.217\n",
      "evaluation/EB/Q_Pred Mean             985.298\n",
      "evaluation/EB/Q_Pred Std              191.145\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4646.14\n",
      "evaluation/Actions Mean                 0.0149227\n",
      "evaluation/Actions Std                  0.545262\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.78478\n",
      "time/backward_zf1 (s)                   1.91797\n",
      "time/backward_zf2 (s)                   1.83244\n",
      "time/data sampling (s)                  0.291785\n",
      "time/data storing (s)                   0.0144763\n",
      "time/evaluation sampling (s)            1.76459\n",
      "time/exploration sampling (s)           0.316668\n",
      "time/logging (s)                        0.0125638\n",
      "time/preback_alpha (s)                  0.909659\n",
      "time/preback_policy (s)                 1.00202\n",
      "time/preback_start (s)                  0.142972\n",
      "time/preback_zf (s)                     5.15573\n",
      "time/saving (s)                         0.00672719\n",
      "time/training (s)                       2.42233\n",
      "time/epoch (s)                         17.5747\n",
      "time/total (s)                       2848.61\n",
      "Epoch                                 159\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:40:01.929553 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 160 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 171000\n",
      "trainer/ZF1 Loss                        1.01638\n",
      "trainer/ZF2 Loss                        2.15015\n",
      "trainer/ZF Expert Reward               15.6306\n",
      "trainer/ZF Policy Reward                3.59532\n",
      "trainer/ZF CHI2 Term                   33.6303\n",
      "trainer/Policy Loss                  -890.674\n",
      "trainer/Bias Loss                      58.8213\n",
      "trainer/Bias Value                     13.7824\n",
      "trainer/Policy Grad Norm              131.174\n",
      "trainer/Policy Param Norm              34.7598\n",
      "trainer/Zf1 Grad Norm                1335.49\n",
      "trainer/Zf1 Param Norm                104.685\n",
      "trainer/Zf2 Grad Norm                 979.402\n",
      "trainer/Zf2 Param Norm                103.636\n",
      "trainer/Z Expert Predictions Mean    1026.74\n",
      "trainer/Z Expert Predictions Std       34.6807\n",
      "trainer/Z Expert Predictions Max     1082.55\n",
      "trainer/Z Expert Predictions Min      849.081\n",
      "trainer/Z Policy Predictions Mean     890.034\n",
      "trainer/Z Policy Predictions Std      278.639\n",
      "trainer/Z Policy Predictions Max     1068.45\n",
      "trainer/Z Policy Predictions Min     -406.943\n",
      "trainer/Z Expert Targets Mean        1011.11\n",
      "trainer/Z Expert Targets Std           36.2106\n",
      "trainer/Z Expert Targets Max         1069.97\n",
      "trainer/Z Expert Targets Min          796.103\n",
      "trainer/Z Policy Targets Mean         886.439\n",
      "trainer/Z Policy Targets Std          274.815\n",
      "trainer/Z Policy Targets Max         1066.82\n",
      "trainer/Z Policy Targets Min         -397.818\n",
      "trainer/Log Pis Mean                   20.2139\n",
      "trainer/Log Pis Std                     3.9024\n",
      "trainer/Policy mu Mean                  0.0195924\n",
      "trainer/Policy mu Std                   1.03605\n",
      "trainer/Policy log std Mean            -3.2447\n",
      "trainer/Policy log std Std              0.89825\n",
      "trainer/Alpha                           0.115422\n",
      "trainer/Alpha Loss                     -0.0246845\n",
      "exploration/num steps total        166885\n",
      "exploration/num paths total           264\n",
      "evaluation/num steps total              1.37513e+06\n",
      "evaluation/num paths total           1653\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.76816\n",
      "evaluation/Rewards Std                  1.01011\n",
      "evaluation/Rewards Max                  6.90318\n",
      "evaluation/Rewards Min                 -1.66794\n",
      "evaluation/Returns Mean              4768.16\n",
      "evaluation/Returns Std                 99.8925\n",
      "evaluation/Returns Max               4917.83\n",
      "evaluation/Returns Min               4575.87\n",
      "evaluation/Estimation Bias Mean       965.521\n",
      "evaluation/Estimation Bias Std        148.529\n",
      "evaluation/EB/Q_True Mean              43.3044\n",
      "evaluation/EB/Q_True Std              134.025\n",
      "evaluation/EB/Q_Pred Mean            1008.83\n",
      "evaluation/EB/Q_Pred Std               59.6153\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4768.16\n",
      "evaluation/Actions Mean                 0.0244572\n",
      "evaluation/Actions Std                  0.537879\n",
      "evaluation/Actions Max                  0.999653\n",
      "evaluation/Actions Min                 -0.999602\n",
      "time/backward_policy (s)                2.03165\n",
      "time/backward_zf1 (s)                   2.21885\n",
      "time/backward_zf2 (s)                   2.08232\n",
      "time/data sampling (s)                  0.348086\n",
      "time/data storing (s)                   0.0161159\n",
      "time/evaluation sampling (s)            1.93946\n",
      "time/exploration sampling (s)           0.333782\n",
      "time/logging (s)                        0.0132858\n",
      "time/preback_alpha (s)                  1.03554\n",
      "time/preback_policy (s)                 1.16115\n",
      "time/preback_start (s)                  0.163293\n",
      "time/preback_zf (s)                     5.41535\n",
      "time/saving (s)                         0.0100393\n",
      "time/training (s)                       2.38064\n",
      "time/epoch (s)                         19.1496\n",
      "time/total (s)                       2867.78\n",
      "Epoch                                 160\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:40:21.027045 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 161 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 172000\n",
      "trainer/ZF1 Loss                        3.66226\n",
      "trainer/ZF2 Loss                        5.57627\n",
      "trainer/ZF Expert Reward               17.4877\n",
      "trainer/ZF Policy Reward                4.3393\n",
      "trainer/ZF CHI2 Term                   37.3284\n",
      "trainer/Policy Loss                  -876.103\n",
      "trainer/Bias Loss                      59.6784\n",
      "trainer/Bias Value                     13.7905\n",
      "trainer/Policy Grad Norm              127.954\n",
      "trainer/Policy Param Norm              34.8031\n",
      "trainer/Zf1 Grad Norm                1175.26\n",
      "trainer/Zf1 Param Norm                104.923\n",
      "trainer/Zf2 Grad Norm                2289.81\n",
      "trainer/Zf2 Param Norm                103.845\n",
      "trainer/Z Expert Predictions Mean    1019.38\n",
      "trainer/Z Expert Predictions Std       43.1767\n",
      "trainer/Z Expert Predictions Max     1077.22\n",
      "trainer/Z Expert Predictions Min      672.249\n",
      "trainer/Z Policy Predictions Mean     873.889\n",
      "trainer/Z Policy Predictions Std      313.237\n",
      "trainer/Z Policy Predictions Max     1063.64\n",
      "trainer/Z Policy Predictions Min     -410.277\n",
      "trainer/Z Expert Targets Mean        1001.89\n",
      "trainer/Z Expert Targets Std           44.8448\n",
      "trainer/Z Expert Targets Max         1058.71\n",
      "trainer/Z Expert Targets Min          640.303\n",
      "trainer/Z Policy Targets Mean         869.55\n",
      "trainer/Z Policy Targets Std          306.168\n",
      "trainer/Z Policy Targets Max         1052.82\n",
      "trainer/Z Policy Targets Min         -416.022\n",
      "trainer/Log Pis Mean                   19.7584\n",
      "trainer/Log Pis Std                     4.19387\n",
      "trainer/Policy mu Mean                  0.0690098\n",
      "trainer/Policy mu Std                   1.00519\n",
      "trainer/Policy log std Mean            -3.21643\n",
      "trainer/Policy log std Std              0.91857\n",
      "trainer/Alpha                           0.11524\n",
      "trainer/Alpha Loss                      0.0278467\n",
      "exploration/num steps total        166885\n",
      "exploration/num paths total           264\n",
      "evaluation/num steps total              1.38499e+06\n",
      "evaluation/num paths total           1663\n",
      "evaluation/path length Mean           986.3\n",
      "evaluation/path length Std             41.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            863\n",
      "evaluation/Rewards Mean                 4.68169\n",
      "evaluation/Rewards Std                  1.02866\n",
      "evaluation/Rewards Max                  6.81704\n",
      "evaluation/Rewards Min                 -1.28542\n",
      "evaluation/Returns Mean              4617.55\n",
      "evaluation/Returns Std                207.997\n",
      "evaluation/Returns Max               4842.87\n",
      "evaluation/Returns Min               4042.56\n",
      "evaluation/Estimation Bias Mean       953.449\n",
      "evaluation/Estimation Bias Std        145.954\n",
      "evaluation/EB/Q_True Mean              43.4067\n",
      "evaluation/EB/Q_True Std              132.623\n",
      "evaluation/EB/Q_Pred Mean             996.856\n",
      "evaluation/EB/Q_Pred Std               57.5188\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4617.55\n",
      "evaluation/Actions Mean                 0.0216413\n",
      "evaluation/Actions Std                  0.539206\n",
      "evaluation/Actions Max                  0.999664\n",
      "evaluation/Actions Min                 -0.999788\n",
      "time/backward_policy (s)                2.10342\n",
      "time/backward_zf1 (s)                   2.24045\n",
      "time/backward_zf2 (s)                   2.18285\n",
      "time/data sampling (s)                  0.320399\n",
      "time/data storing (s)                   0.0151953\n",
      "time/evaluation sampling (s)            1.7997\n",
      "time/exploration sampling (s)           0.325909\n",
      "time/logging (s)                        0.0121804\n",
      "time/preback_alpha (s)                  1.07732\n",
      "time/preback_policy (s)                 1.23884\n",
      "time/preback_start (s)                  0.152394\n",
      "time/preback_zf (s)                     5.34166\n",
      "time/saving (s)                         0.00628213\n",
      "time/training (s)                       2.20893\n",
      "time/epoch (s)                         19.0255\n",
      "time/total (s)                       2886.82\n",
      "Epoch                                 161\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:40:39.755846 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 162 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 173000\n",
      "trainer/ZF1 Loss                        6.16067\n",
      "trainer/ZF2 Loss                        4.75322\n",
      "trainer/ZF Expert Reward               13.2841\n",
      "trainer/ZF Policy Reward                1.29723\n",
      "trainer/ZF CHI2 Term                   36.5397\n",
      "trainer/Policy Loss                  -887.133\n",
      "trainer/Bias Loss                      61.8523\n",
      "trainer/Bias Value                     13.8003\n",
      "trainer/Policy Grad Norm              115.28\n",
      "trainer/Policy Param Norm              34.8423\n",
      "trainer/Zf1 Grad Norm                1444.54\n",
      "trainer/Zf1 Param Norm                105.15\n",
      "trainer/Zf2 Grad Norm                1003.1\n",
      "trainer/Zf2 Param Norm                104.052\n",
      "trainer/Z Expert Predictions Mean    1015.79\n",
      "trainer/Z Expert Predictions Std       40.9862\n",
      "trainer/Z Expert Predictions Max     1075.31\n",
      "trainer/Z Expert Predictions Min      779.917\n",
      "trainer/Z Policy Predictions Mean     883.34\n",
      "trainer/Z Policy Predictions Std      257.434\n",
      "trainer/Z Policy Predictions Max     1066.35\n",
      "trainer/Z Policy Predictions Min     -349.373\n",
      "trainer/Z Expert Targets Mean        1002.51\n",
      "trainer/Z Expert Targets Std           40.5833\n",
      "trainer/Z Expert Targets Max         1059.63\n",
      "trainer/Z Expert Targets Min          785.488\n",
      "trainer/Z Policy Targets Mean         882.042\n",
      "trainer/Z Policy Targets Std          250.697\n",
      "trainer/Z Policy Targets Max         1052.59\n",
      "trainer/Z Policy Targets Min         -335.282\n",
      "trainer/Log Pis Mean                   19.2888\n",
      "trainer/Log Pis Std                     4.11282\n",
      "trainer/Policy mu Mean                  0.0559884\n",
      "trainer/Policy mu Std                   0.973674\n",
      "trainer/Policy log std Mean            -3.16726\n",
      "trainer/Policy log std Std              0.871036\n",
      "trainer/Alpha                           0.114889\n",
      "trainer/Alpha Loss                      0.0817137\n",
      "exploration/num steps total        168885\n",
      "exploration/num paths total           266\n",
      "evaluation/num steps total              1.39395e+06\n",
      "evaluation/num paths total           1673\n",
      "evaluation/path length Mean           895.6\n",
      "evaluation/path length Std            291.552\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             23\n",
      "evaluation/Rewards Mean                 4.62125\n",
      "evaluation/Rewards Std                  1.01264\n",
      "evaluation/Rewards Max                  6.71229\n",
      "evaluation/Rewards Min                 -1.6453\n",
      "evaluation/Returns Mean              4138.79\n",
      "evaluation/Returns Std               1373.76\n",
      "evaluation/Returns Max               4685.22\n",
      "evaluation/Returns Min                 23.1996\n",
      "evaluation/Estimation Bias Mean       943.095\n",
      "evaluation/Estimation Bias Std        152.234\n",
      "evaluation/EB/Q_True Mean              48.0151\n",
      "evaluation/EB/Q_True Std              139.503\n",
      "evaluation/EB/Q_Pred Mean             991.11\n",
      "evaluation/EB/Q_Pred Std               62.7546\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4138.79\n",
      "evaluation/Actions Mean                 0.010645\n",
      "evaluation/Actions Std                  0.543999\n",
      "evaluation/Actions Max                  0.999712\n",
      "evaluation/Actions Min                 -0.998985\n",
      "time/backward_policy (s)                1.96554\n",
      "time/backward_zf1 (s)                   2.18663\n",
      "time/backward_zf2 (s)                   2.10157\n",
      "time/data sampling (s)                  0.315864\n",
      "time/data storing (s)                   0.0151978\n",
      "time/evaluation sampling (s)            1.75308\n",
      "time/exploration sampling (s)           0.32671\n",
      "time/logging (s)                        0.0114648\n",
      "time/preback_alpha (s)                  1.03791\n",
      "time/preback_policy (s)                 1.18277\n",
      "time/preback_start (s)                  0.151205\n",
      "time/preback_zf (s)                     5.35801\n",
      "time/saving (s)                         0.0127157\n",
      "time/training (s)                       2.23679\n",
      "time/epoch (s)                         18.6555\n",
      "time/total (s)                       2905.5\n",
      "Epoch                                 162\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:40:58.222267 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 163 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 174000\n",
      "trainer/ZF1 Loss                        0.140984\n",
      "trainer/ZF2 Loss                        6.38963\n",
      "trainer/ZF Expert Reward               15.4792\n",
      "trainer/ZF Policy Reward                3.77783\n",
      "trainer/ZF CHI2 Term                   34.3551\n",
      "trainer/Policy Loss                  -879.505\n",
      "trainer/Bias Loss                      82.7403\n",
      "trainer/Bias Value                     13.8106\n",
      "trainer/Policy Grad Norm              142.174\n",
      "trainer/Policy Param Norm              34.8808\n",
      "trainer/Zf1 Grad Norm                1266.82\n",
      "trainer/Zf1 Param Norm                105.361\n",
      "trainer/Zf2 Grad Norm                1493.7\n",
      "trainer/Zf2 Param Norm                104.24\n",
      "trainer/Z Expert Predictions Mean    1013.31\n",
      "trainer/Z Expert Predictions Std       35.3363\n",
      "trainer/Z Expert Predictions Max     1075.72\n",
      "trainer/Z Expert Predictions Min      809.619\n",
      "trainer/Z Policy Predictions Mean     876.663\n",
      "trainer/Z Policy Predictions Std      310.421\n",
      "trainer/Z Policy Predictions Max     1058.51\n",
      "trainer/Z Policy Predictions Min     -437.211\n",
      "trainer/Z Expert Targets Mean         997.834\n",
      "trainer/Z Expert Targets Std           37.2267\n",
      "trainer/Z Expert Targets Max         1052.95\n",
      "trainer/Z Expert Targets Min          777.655\n",
      "trainer/Z Policy Targets Mean         872.885\n",
      "trainer/Z Policy Targets Std          305.66\n",
      "trainer/Z Policy Targets Max         1049.28\n",
      "trainer/Z Policy Targets Min         -428.192\n",
      "trainer/Log Pis Mean                   19.5842\n",
      "trainer/Log Pis Std                     4.24004\n",
      "trainer/Policy mu Mean                  0.062811\n",
      "trainer/Policy mu Std                   0.996013\n",
      "trainer/Policy log std Mean            -3.21284\n",
      "trainer/Policy log std Std              0.900476\n",
      "trainer/Alpha                           0.116982\n",
      "trainer/Alpha Loss                      0.0486429\n",
      "exploration/num steps total        168885\n",
      "exploration/num paths total           266\n",
      "evaluation/num steps total              1.40395e+06\n",
      "evaluation/num paths total           1683\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.61531\n",
      "evaluation/Rewards Std                  1.06396\n",
      "evaluation/Rewards Max                  6.73387\n",
      "evaluation/Rewards Min                 -1.53083\n",
      "evaluation/Returns Mean              4615.31\n",
      "evaluation/Returns Std                 99.9029\n",
      "evaluation/Returns Max               4701.61\n",
      "evaluation/Returns Min               4379.93\n",
      "evaluation/Estimation Bias Mean       939.367\n",
      "evaluation/Estimation Bias Std        142.826\n",
      "evaluation/EB/Q_True Mean              43.0883\n",
      "evaluation/EB/Q_True Std              133.207\n",
      "evaluation/EB/Q_Pred Mean             982.455\n",
      "evaluation/EB/Q_Pred Std               58.7469\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4615.31\n",
      "evaluation/Actions Mean                 0.0252247\n",
      "evaluation/Actions Std                  0.531379\n",
      "evaluation/Actions Max                  0.999467\n",
      "evaluation/Actions Min                 -0.999825\n",
      "time/backward_policy (s)                1.89628\n",
      "time/backward_zf1 (s)                   2.10955\n",
      "time/backward_zf2 (s)                   1.99809\n",
      "time/data sampling (s)                  0.326229\n",
      "time/data storing (s)                   0.0150492\n",
      "time/evaluation sampling (s)            1.82703\n",
      "time/exploration sampling (s)           0.322082\n",
      "time/logging (s)                        0.0126047\n",
      "time/preback_alpha (s)                  0.976977\n",
      "time/preback_policy (s)                 1.08166\n",
      "time/preback_start (s)                  0.149027\n",
      "time/preback_zf (s)                     5.2939\n",
      "time/saving (s)                         0.00636291\n",
      "time/training (s)                       2.37537\n",
      "time/epoch (s)                         18.3902\n",
      "time/total (s)                       2923.92\n",
      "Epoch                                 163\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:41:16.467585 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 164 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 175000\n",
      "trainer/ZF1 Loss                        2.50228\n",
      "trainer/ZF2 Loss                       -2.3935\n",
      "trainer/ZF Expert Reward               13.7226\n",
      "trainer/ZF Policy Reward                2.18072\n",
      "trainer/ZF CHI2 Term                   31.5341\n",
      "trainer/Policy Loss                  -873.59\n",
      "trainer/Bias Loss                      53.353\n",
      "trainer/Bias Value                     13.8159\n",
      "trainer/Policy Grad Norm              141.841\n",
      "trainer/Policy Param Norm              34.9196\n",
      "trainer/Zf1 Grad Norm                1574.96\n",
      "trainer/Zf1 Param Norm                105.599\n",
      "trainer/Zf2 Grad Norm                1160.78\n",
      "trainer/Zf2 Param Norm                104.431\n",
      "trainer/Z Expert Predictions Mean    1006.64\n",
      "trainer/Z Expert Predictions Std       45.6287\n",
      "trainer/Z Expert Predictions Max     1064.43\n",
      "trainer/Z Expert Predictions Min      622.602\n",
      "trainer/Z Policy Predictions Mean     870.196\n",
      "trainer/Z Policy Predictions Std      297.994\n",
      "trainer/Z Policy Predictions Max     1058.93\n",
      "trainer/Z Policy Predictions Min     -429.7\n",
      "trainer/Z Expert Targets Mean         992.922\n",
      "trainer/Z Expert Targets Std           45.2386\n",
      "trainer/Z Expert Targets Max         1062.52\n",
      "trainer/Z Expert Targets Min          608.882\n",
      "trainer/Z Policy Targets Mean         868.015\n",
      "trainer/Z Policy Targets Std          293.385\n",
      "trainer/Z Policy Targets Max         1044.79\n",
      "trainer/Z Policy Targets Min         -440.493\n",
      "trainer/Log Pis Mean                   20.1392\n",
      "trainer/Log Pis Std                     3.64698\n",
      "trainer/Policy mu Mean                  0.0579361\n",
      "trainer/Policy mu Std                   1.0089\n",
      "trainer/Policy log std Mean            -3.24165\n",
      "trainer/Policy log std Std              0.908092\n",
      "trainer/Alpha                           0.116039\n",
      "trainer/Alpha Loss                     -0.0161542\n",
      "exploration/num steps total        169240\n",
      "exploration/num paths total           267\n",
      "evaluation/num steps total              1.4119e+06\n",
      "evaluation/num paths total           1693\n",
      "evaluation/path length Mean           795\n",
      "evaluation/path length Std            323.04\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            173\n",
      "evaluation/Rewards Mean                 4.63764\n",
      "evaluation/Rewards Std                  1.12539\n",
      "evaluation/Rewards Max                  6.75122\n",
      "evaluation/Rewards Min                 -2.98384\n",
      "evaluation/Returns Mean              3686.93\n",
      "evaluation/Returns Std               1559.19\n",
      "evaluation/Returns Max               4799.42\n",
      "evaluation/Returns Min                722.888\n",
      "evaluation/Estimation Bias Mean       929.409\n",
      "evaluation/Estimation Bias Std        171.135\n",
      "evaluation/EB/Q_True Mean              54.9835\n",
      "evaluation/EB/Q_True Std              149.203\n",
      "evaluation/EB/Q_Pred Mean             984.392\n",
      "evaluation/EB/Q_Pred Std               71.4664\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3686.93\n",
      "evaluation/Actions Mean                 0.019334\n",
      "evaluation/Actions Std                  0.539577\n",
      "evaluation/Actions Max                  0.999675\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.91371\n",
      "time/backward_zf1 (s)                   2.0505\n",
      "time/backward_zf2 (s)                   1.98114\n",
      "time/data sampling (s)                  0.312125\n",
      "time/data storing (s)                   0.0153594\n",
      "time/evaluation sampling (s)            1.75718\n",
      "time/exploration sampling (s)           0.324114\n",
      "time/logging (s)                        0.00963113\n",
      "time/preback_alpha (s)                  0.981596\n",
      "time/preback_policy (s)                 1.08501\n",
      "time/preback_start (s)                  0.150216\n",
      "time/preback_zf (s)                     5.23658\n",
      "time/saving (s)                         0.00572218\n",
      "time/training (s)                       2.34897\n",
      "time/epoch (s)                         18.1719\n",
      "time/total (s)                       2942.11\n",
      "Epoch                                 164\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:41:34.579110 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 165 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 176000\n",
      "trainer/ZF1 Loss                        9.65399\n",
      "trainer/ZF2 Loss                        9.9441\n",
      "trainer/ZF Expert Reward               15.5842\n",
      "trainer/ZF Policy Reward                3.84748\n",
      "trainer/ZF CHI2 Term                   41.198\n",
      "trainer/Policy Loss                  -826.179\n",
      "trainer/Bias Loss                      58.4004\n",
      "trainer/Bias Value                     13.8331\n",
      "trainer/Policy Grad Norm              106.682\n",
      "trainer/Policy Param Norm              34.9571\n",
      "trainer/Zf1 Grad Norm                1135.9\n",
      "trainer/Zf1 Param Norm                105.813\n",
      "trainer/Zf2 Grad Norm                 937.026\n",
      "trainer/Zf2 Param Norm                104.618\n",
      "trainer/Z Expert Predictions Mean    1003.78\n",
      "trainer/Z Expert Predictions Std       39.9529\n",
      "trainer/Z Expert Predictions Max     1062.72\n",
      "trainer/Z Expert Predictions Min      803.506\n",
      "trainer/Z Policy Predictions Mean     825.487\n",
      "trainer/Z Policy Predictions Std      343.843\n",
      "trainer/Z Policy Predictions Max     1048.7\n",
      "trainer/Z Policy Predictions Min     -432.633\n",
      "trainer/Z Expert Targets Mean         988.192\n",
      "trainer/Z Expert Targets Std           41.156\n",
      "trainer/Z Expert Targets Max         1053.29\n",
      "trainer/Z Expert Targets Min          788.251\n",
      "trainer/Z Policy Targets Mean         821.639\n",
      "trainer/Z Policy Targets Std          337.12\n",
      "trainer/Z Policy Targets Max         1044.15\n",
      "trainer/Z Policy Targets Min         -432.177\n",
      "trainer/Log Pis Mean                   19.8608\n",
      "trainer/Log Pis Std                     4.65053\n",
      "trainer/Policy mu Mean                  0.0138478\n",
      "trainer/Policy mu Std                   1.10947\n",
      "trainer/Policy log std Mean            -3.11689\n",
      "trainer/Policy log std Std              0.986859\n",
      "trainer/Alpha                           0.117277\n",
      "trainer/Alpha Loss                      0.0163227\n",
      "exploration/num steps total        171240\n",
      "exploration/num paths total           269\n",
      "evaluation/num steps total              1.4219e+06\n",
      "evaluation/num paths total           1703\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67643\n",
      "evaluation/Rewards Std                  0.963708\n",
      "evaluation/Rewards Max                  6.72936\n",
      "evaluation/Rewards Min                 -1.48783\n",
      "evaluation/Returns Mean              4676.43\n",
      "evaluation/Returns Std                 93.3618\n",
      "evaluation/Returns Max               4859.52\n",
      "evaluation/Returns Min               4536.13\n",
      "evaluation/Estimation Bias Mean       941.216\n",
      "evaluation/Estimation Bias Std        142.825\n",
      "evaluation/EB/Q_True Mean              43.5987\n",
      "evaluation/EB/Q_True Std              134.914\n",
      "evaluation/EB/Q_Pred Mean             984.815\n",
      "evaluation/EB/Q_Pred Std               50.2722\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4676.43\n",
      "evaluation/Actions Mean                 0.0202703\n",
      "evaluation/Actions Std                  0.54055\n",
      "evaluation/Actions Max                  0.999489\n",
      "evaluation/Actions Min                 -0.999711\n",
      "time/backward_policy (s)                1.94135\n",
      "time/backward_zf1 (s)                   2.06698\n",
      "time/backward_zf2 (s)                   2.015\n",
      "time/data sampling (s)                  0.302522\n",
      "time/data storing (s)                   0.0143666\n",
      "time/evaluation sampling (s)            1.74017\n",
      "time/exploration sampling (s)           0.321152\n",
      "time/logging (s)                        0.0126764\n",
      "time/preback_alpha (s)                  1.04095\n",
      "time/preback_policy (s)                 1.16636\n",
      "time/preback_start (s)                  0.147558\n",
      "time/preback_zf (s)                     5.18409\n",
      "time/saving (s)                         0.00652599\n",
      "time/training (s)                       2.08716\n",
      "time/epoch (s)                         18.0469\n",
      "time/total (s)                       2960.18\n",
      "Epoch                                 165\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:41:52.556442 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 166 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 177000\n",
      "trainer/ZF1 Loss                        3.1988\n",
      "trainer/ZF2 Loss                        4.26496\n",
      "trainer/ZF Expert Reward               15.2846\n",
      "trainer/ZF Policy Reward                2.88734\n",
      "trainer/ZF CHI2 Term                   35.6315\n",
      "trainer/Policy Loss                  -829.857\n",
      "trainer/Bias Loss                      56.5978\n",
      "trainer/Bias Value                     13.8431\n",
      "trainer/Policy Grad Norm              106.917\n",
      "trainer/Policy Param Norm              34.9927\n",
      "trainer/Zf1 Grad Norm                1084.2\n",
      "trainer/Zf1 Param Norm                106.032\n",
      "trainer/Zf2 Grad Norm                1008.88\n",
      "trainer/Zf2 Param Norm                104.835\n",
      "trainer/Z Expert Predictions Mean    1003.24\n",
      "trainer/Z Expert Predictions Std       35.8372\n",
      "trainer/Z Expert Predictions Max     1064.78\n",
      "trainer/Z Expert Predictions Min      797.764\n",
      "trainer/Z Policy Predictions Mean     824.713\n",
      "trainer/Z Policy Predictions Std      349.504\n",
      "trainer/Z Policy Predictions Max     1068.7\n",
      "trainer/Z Policy Predictions Min     -441.699\n",
      "trainer/Z Expert Targets Mean         987.957\n",
      "trainer/Z Expert Targets Std           36.4043\n",
      "trainer/Z Expert Targets Max         1047.24\n",
      "trainer/Z Expert Targets Min          792.671\n",
      "trainer/Z Policy Targets Mean         821.825\n",
      "trainer/Z Policy Targets Std          344.131\n",
      "trainer/Z Policy Targets Max         1047.09\n",
      "trainer/Z Policy Targets Min         -453.792\n",
      "trainer/Log Pis Mean                   19.6993\n",
      "trainer/Log Pis Std                     4.21436\n",
      "trainer/Policy mu Mean                  0.0382431\n",
      "trainer/Policy mu Std                   1.08363\n",
      "trainer/Policy log std Mean            -3.10299\n",
      "trainer/Policy log std Std              1.02197\n",
      "trainer/Alpha                           0.117473\n",
      "trainer/Alpha Loss                      0.0353261\n",
      "exploration/num steps total        172654\n",
      "exploration/num paths total           272\n",
      "evaluation/num steps total              1.4319e+06\n",
      "evaluation/num paths total           1713\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67995\n",
      "evaluation/Rewards Std                  0.962917\n",
      "evaluation/Rewards Max                  6.67632\n",
      "evaluation/Rewards Min                 -1.75113\n",
      "evaluation/Returns Mean              4679.95\n",
      "evaluation/Returns Std                 74.7426\n",
      "evaluation/Returns Max               4818.2\n",
      "evaluation/Returns Min               4582.46\n",
      "evaluation/Estimation Bias Mean       943.303\n",
      "evaluation/Estimation Bias Std        136.251\n",
      "evaluation/EB/Q_True Mean              42.4988\n",
      "evaluation/EB/Q_True Std              130.879\n",
      "evaluation/EB/Q_Pred Mean             985.801\n",
      "evaluation/EB/Q_Pred Std               50.3449\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4679.95\n",
      "evaluation/Actions Mean                 0.0219772\n",
      "evaluation/Actions Std                  0.53663\n",
      "evaluation/Actions Max                  0.99956\n",
      "evaluation/Actions Min                 -0.999802\n",
      "time/backward_policy (s)                1.8672\n",
      "time/backward_zf1 (s)                   2.00537\n",
      "time/backward_zf2 (s)                   1.93443\n",
      "time/data sampling (s)                  0.3034\n",
      "time/data storing (s)                   0.0153578\n",
      "time/evaluation sampling (s)            1.74043\n",
      "time/exploration sampling (s)           0.324997\n",
      "time/logging (s)                        0.0134039\n",
      "time/preback_alpha (s)                  0.982856\n",
      "time/preback_policy (s)                 1.08861\n",
      "time/preback_start (s)                  0.150271\n",
      "time/preback_zf (s)                     5.23914\n",
      "time/saving (s)                         0.00641168\n",
      "time/training (s)                       2.2383\n",
      "time/epoch (s)                         17.9102\n",
      "time/total (s)                       2978.11\n",
      "Epoch                                 166\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:42:10.690281 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 167 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 178000\n",
      "trainer/ZF1 Loss                      184.377\n",
      "trainer/ZF2 Loss                      190.298\n",
      "trainer/ZF Expert Reward               18.4517\n",
      "trainer/ZF Policy Reward               10.8987\n",
      "trainer/ZF CHI2 Term                  214.513\n",
      "trainer/Policy Loss                  -841.401\n",
      "trainer/Bias Loss                      76.3455\n",
      "trainer/Bias Value                     13.855\n",
      "trainer/Policy Grad Norm              127.092\n",
      "trainer/Policy Param Norm              35.031\n",
      "trainer/Zf1 Grad Norm                1683.58\n",
      "trainer/Zf1 Param Norm                106.257\n",
      "trainer/Zf2 Grad Norm                1626.24\n",
      "trainer/Zf2 Param Norm                105.018\n",
      "trainer/Z Expert Predictions Mean     990.841\n",
      "trainer/Z Expert Predictions Std       62.8176\n",
      "trainer/Z Expert Predictions Max     1057.7\n",
      "trainer/Z Expert Predictions Min      412.004\n",
      "trainer/Z Policy Predictions Mean     841.357\n",
      "trainer/Z Policy Predictions Std      345.926\n",
      "trainer/Z Policy Predictions Max     1053.57\n",
      "trainer/Z Policy Predictions Min     -437.052\n",
      "trainer/Z Expert Targets Mean         972.39\n",
      "trainer/Z Expert Targets Std           61.8661\n",
      "trainer/Z Expert Targets Max         1040.34\n",
      "trainer/Z Expert Targets Min          465.242\n",
      "trainer/Z Policy Targets Mean         830.458\n",
      "trainer/Z Policy Targets Std          344.972\n",
      "trainer/Z Policy Targets Max         1039.91\n",
      "trainer/Z Policy Targets Min         -433.356\n",
      "trainer/Log Pis Mean                   19.8211\n",
      "trainer/Log Pis Std                     4.06449\n",
      "trainer/Policy mu Mean                  0.0574507\n",
      "trainer/Policy mu Std                   1.01346\n",
      "trainer/Policy log std Mean            -3.20616\n",
      "trainer/Policy log std Std              0.985338\n",
      "trainer/Alpha                           0.119368\n",
      "trainer/Alpha Loss                      0.0213574\n",
      "exploration/num steps total        173654\n",
      "exploration/num paths total           273\n",
      "evaluation/num steps total              1.44134e+06\n",
      "evaluation/num paths total           1723\n",
      "evaluation/path length Mean           944.5\n",
      "evaluation/path length Std            166.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            445\n",
      "evaluation/Rewards Mean                 4.62775\n",
      "evaluation/Rewards Std                  0.949422\n",
      "evaluation/Rewards Max                  6.75997\n",
      "evaluation/Rewards Min                 -1.9591\n",
      "evaluation/Returns Mean              4370.91\n",
      "evaluation/Returns Std                808.914\n",
      "evaluation/Returns Max               4786.31\n",
      "evaluation/Returns Min               1951\n",
      "evaluation/Estimation Bias Mean       931.083\n",
      "evaluation/Estimation Bias Std        153.786\n",
      "evaluation/EB/Q_True Mean              45.0639\n",
      "evaluation/EB/Q_True Std              134.89\n",
      "evaluation/EB/Q_Pred Mean             976.147\n",
      "evaluation/EB/Q_Pred Std               59.5232\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4370.91\n",
      "evaluation/Actions Mean                 0.0196902\n",
      "evaluation/Actions Std                  0.530876\n",
      "evaluation/Actions Max                  0.999477\n",
      "evaluation/Actions Min                 -0.999787\n",
      "time/backward_policy (s)                1.89138\n",
      "time/backward_zf1 (s)                   2.05433\n",
      "time/backward_zf2 (s)                   1.97534\n",
      "time/data sampling (s)                  0.300713\n",
      "time/data storing (s)                   0.0146136\n",
      "time/evaluation sampling (s)            1.74466\n",
      "time/exploration sampling (s)           0.32095\n",
      "time/logging (s)                        0.0122087\n",
      "time/preback_alpha (s)                  1.00956\n",
      "time/preback_policy (s)                 1.14925\n",
      "time/preback_start (s)                  0.148811\n",
      "time/preback_zf (s)                     5.2168\n",
      "time/saving (s)                         0.00611542\n",
      "time/training (s)                       2.21671\n",
      "time/epoch (s)                         18.0614\n",
      "time/total (s)                       2996.19\n",
      "Epoch                                 167\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:42:28.534598 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 168 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 179000\n",
      "trainer/ZF1 Loss                       12.1087\n",
      "trainer/ZF2 Loss                        5.06595\n",
      "trainer/ZF Expert Reward               12.4204\n",
      "trainer/ZF Policy Reward                2.0886\n",
      "trainer/ZF CHI2 Term                   38.6501\n",
      "trainer/Policy Loss                  -848.19\n",
      "trainer/Bias Loss                      56.6241\n",
      "trainer/Bias Value                     13.8681\n",
      "trainer/Policy Grad Norm              140.694\n",
      "trainer/Policy Param Norm              35.0689\n",
      "trainer/Zf1 Grad Norm                1687.71\n",
      "trainer/Zf1 Param Norm                106.505\n",
      "trainer/Zf2 Grad Norm                1270.39\n",
      "trainer/Zf2 Param Norm                105.238\n",
      "trainer/Z Expert Predictions Mean     989.487\n",
      "trainer/Z Expert Predictions Std       35.9664\n",
      "trainer/Z Expert Predictions Max     1052.68\n",
      "trainer/Z Expert Predictions Min      781.985\n",
      "trainer/Z Policy Predictions Mean     846.15\n",
      "trainer/Z Policy Predictions Std      296.321\n",
      "trainer/Z Policy Predictions Max     1037.61\n",
      "trainer/Z Policy Predictions Min     -468.017\n",
      "trainer/Z Expert Targets Mean         977.067\n",
      "trainer/Z Expert Targets Std           36.3459\n",
      "trainer/Z Expert Targets Max         1039.16\n",
      "trainer/Z Expert Targets Min          750.875\n",
      "trainer/Z Policy Targets Mean         844.062\n",
      "trainer/Z Policy Targets Std          291.626\n",
      "trainer/Z Policy Targets Max         1023.85\n",
      "trainer/Z Policy Targets Min         -447.719\n",
      "trainer/Log Pis Mean                   19.9303\n",
      "trainer/Log Pis Std                     4.0557\n",
      "trainer/Policy mu Mean                  0.0622066\n",
      "trainer/Policy mu Std                   1.0314\n",
      "trainer/Policy log std Mean            -3.21807\n",
      "trainer/Policy log std Std              0.955813\n",
      "trainer/Alpha                           0.120296\n",
      "trainer/Alpha Loss                      0.00837893\n",
      "exploration/num steps total        174654\n",
      "exploration/num paths total           274\n",
      "evaluation/num steps total              1.45134e+06\n",
      "evaluation/num paths total           1733\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.58799\n",
      "evaluation/Rewards Std                  0.931531\n",
      "evaluation/Rewards Max                  6.56263\n",
      "evaluation/Rewards Min                 -1.78127\n",
      "evaluation/Returns Mean              4587.99\n",
      "evaluation/Returns Std                 70.3643\n",
      "evaluation/Returns Max               4722.54\n",
      "evaluation/Returns Min               4495.33\n",
      "evaluation/Estimation Bias Mean       929.428\n",
      "evaluation/Estimation Bias Std        134.408\n",
      "evaluation/EB/Q_True Mean              41.5279\n",
      "evaluation/EB/Q_True Std              127.994\n",
      "evaluation/EB/Q_Pred Mean             970.956\n",
      "evaluation/EB/Q_Pred Std               47.9808\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4587.99\n",
      "evaluation/Actions Mean                 0.0196424\n",
      "evaluation/Actions Std                  0.539565\n",
      "evaluation/Actions Max                  0.999475\n",
      "evaluation/Actions Min                 -0.998894\n",
      "time/backward_policy (s)                1.83048\n",
      "time/backward_zf1 (s)                   1.95869\n",
      "time/backward_zf2 (s)                   1.8891\n",
      "time/data sampling (s)                  0.300003\n",
      "time/data storing (s)                   0.0150718\n",
      "time/evaluation sampling (s)            1.77731\n",
      "time/exploration sampling (s)           0.320536\n",
      "time/logging (s)                        0.0122749\n",
      "time/preback_alpha (s)                  0.944424\n",
      "time/preback_policy (s)                 1.04998\n",
      "time/preback_start (s)                  0.145889\n",
      "time/preback_zf (s)                     5.17146\n",
      "time/saving (s)                         0.00641077\n",
      "time/training (s)                       2.35271\n",
      "time/epoch (s)                         17.7744\n",
      "time/total (s)                       3013.99\n",
      "Epoch                                 168\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:42:46.802681 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 169 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 180000\n",
      "trainer/ZF1 Loss                      178.517\n",
      "trainer/ZF2 Loss                      151.741\n",
      "trainer/ZF Expert Reward               10.84\n",
      "trainer/ZF Policy Reward                1.05541\n",
      "trainer/ZF CHI2 Term                  194.849\n",
      "trainer/Policy Loss                  -828.466\n",
      "trainer/Bias Loss                     122.049\n",
      "trainer/Bias Value                     13.8792\n",
      "trainer/Policy Grad Norm              132.67\n",
      "trainer/Policy Param Norm              35.1046\n",
      "trainer/Zf1 Grad Norm                3118.64\n",
      "trainer/Zf1 Param Norm                106.728\n",
      "trainer/Zf2 Grad Norm                3187.38\n",
      "trainer/Zf2 Param Norm                105.431\n",
      "trainer/Z Expert Predictions Mean     976.728\n",
      "trainer/Z Expert Predictions Std       78.7598\n",
      "trainer/Z Expert Predictions Max     1047.11\n",
      "trainer/Z Expert Predictions Min       44.2218\n",
      "trainer/Z Policy Predictions Mean     824.832\n",
      "trainer/Z Policy Predictions Std      314.993\n",
      "trainer/Z Policy Predictions Max     1026.1\n",
      "trainer/Z Policy Predictions Min     -479.67\n",
      "trainer/Z Expert Targets Mean         965.888\n",
      "trainer/Z Expert Targets Std           83.7846\n",
      "trainer/Z Expert Targets Max         1042.08\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         823.777\n",
      "trainer/Z Policy Targets Std          315.72\n",
      "trainer/Z Policy Targets Max         1038.71\n",
      "trainer/Z Policy Targets Min         -463.968\n",
      "trainer/Log Pis Mean                   20.1364\n",
      "trainer/Log Pis Std                     4.19448\n",
      "trainer/Policy mu Mean                  0.0446288\n",
      "trainer/Policy mu Std                   1.08436\n",
      "trainer/Policy log std Mean            -3.16437\n",
      "trainer/Policy log std Std              0.984376\n",
      "trainer/Alpha                           0.121014\n",
      "trainer/Alpha Loss                     -0.0165109\n",
      "exploration/num steps total        175654\n",
      "exploration/num paths total           275\n",
      "evaluation/num steps total              1.46014e+06\n",
      "evaluation/num paths total           1744\n",
      "evaluation/path length Mean           800\n",
      "evaluation/path length Std            371.661\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             22\n",
      "evaluation/Rewards Mean                 4.64537\n",
      "evaluation/Rewards Std                  1.09868\n",
      "evaluation/Rewards Max                  6.69616\n",
      "evaluation/Rewards Min                 -2.09913\n",
      "evaluation/Returns Mean              3716.3\n",
      "evaluation/Returns Std               1782.06\n",
      "evaluation/Returns Max               4795.85\n",
      "evaluation/Returns Min                 -5.47726\n",
      "evaluation/Estimation Bias Mean       912.285\n",
      "evaluation/Estimation Bias Std        165.486\n",
      "evaluation/EB/Q_True Mean              49.1031\n",
      "evaluation/EB/Q_True Std              140.942\n",
      "evaluation/EB/Q_Pred Mean             961.388\n",
      "evaluation/EB/Q_Pred Std               64.4984\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3716.3\n",
      "evaluation/Actions Mean                 0.00994982\n",
      "evaluation/Actions Std                  0.539548\n",
      "evaluation/Actions Max                  0.99933\n",
      "evaluation/Actions Min                 -0.999826\n",
      "time/backward_policy (s)                1.95926\n",
      "time/backward_zf1 (s)                   2.07695\n",
      "time/backward_zf2 (s)                   2.01652\n",
      "time/data sampling (s)                  0.301564\n",
      "time/data storing (s)                   0.0154596\n",
      "time/evaluation sampling (s)            1.75891\n",
      "time/exploration sampling (s)           0.326415\n",
      "time/logging (s)                        0.0110187\n",
      "time/preback_alpha (s)                  1.0394\n",
      "time/preback_policy (s)                 1.18922\n",
      "time/preback_start (s)                  0.150155\n",
      "time/preback_zf (s)                     5.22729\n",
      "time/saving (s)                         0.00623778\n",
      "time/training (s)                       2.11368\n",
      "time/epoch (s)                         18.1921\n",
      "time/total (s)                       3032.2\n",
      "Epoch                                 169\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:43:05.244802 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 170 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 181000\n",
      "trainer/ZF1 Loss                      108.276\n",
      "trainer/ZF2 Loss                       44.8183\n",
      "trainer/ZF Expert Reward               13.7703\n",
      "trainer/ZF Policy Reward                7.26526\n",
      "trainer/ZF CHI2 Term                  103.066\n",
      "trainer/Policy Loss                  -831.244\n",
      "trainer/Bias Loss                      55.9577\n",
      "trainer/Bias Value                     13.8939\n",
      "trainer/Policy Grad Norm              138.785\n",
      "trainer/Policy Param Norm              35.1415\n",
      "trainer/Zf1 Grad Norm                2224.91\n",
      "trainer/Zf1 Param Norm                106.973\n",
      "trainer/Zf2 Grad Norm                5672.39\n",
      "trainer/Zf2 Param Norm                105.658\n",
      "trainer/Z Expert Predictions Mean     979.587\n",
      "trainer/Z Expert Predictions Std       47.7857\n",
      "trainer/Z Expert Predictions Max     1043.18\n",
      "trainer/Z Expert Predictions Min      579.455\n",
      "trainer/Z Policy Predictions Mean     830.537\n",
      "trainer/Z Policy Predictions Std      314.473\n",
      "trainer/Z Policy Predictions Max     1034.84\n",
      "trainer/Z Policy Predictions Min     -481.311\n",
      "trainer/Z Expert Targets Mean         965.817\n",
      "trainer/Z Expert Targets Std           49.1605\n",
      "trainer/Z Expert Targets Max         1022.75\n",
      "trainer/Z Expert Targets Min          559.005\n",
      "trainer/Z Policy Targets Mean         823.272\n",
      "trainer/Z Policy Targets Std          311.403\n",
      "trainer/Z Policy Targets Max         1023.37\n",
      "trainer/Z Policy Targets Min         -446.224\n",
      "trainer/Log Pis Mean                   20.216\n",
      "trainer/Log Pis Std                     3.91605\n",
      "trainer/Policy mu Mean                  0.0570281\n",
      "trainer/Policy mu Std                   1.04538\n",
      "trainer/Policy log std Mean            -3.18774\n",
      "trainer/Policy log std Std              0.94745\n",
      "trainer/Alpha                           0.121511\n",
      "trainer/Alpha Loss                     -0.0262498\n",
      "exploration/num steps total        176654\n",
      "exploration/num paths total           276\n",
      "evaluation/num steps total              1.46989e+06\n",
      "evaluation/num paths total           1754\n",
      "evaluation/path length Mean           974.5\n",
      "evaluation/path length Std             76.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            745\n",
      "evaluation/Rewards Mean                 4.64955\n",
      "evaluation/Rewards Std                  0.952771\n",
      "evaluation/Rewards Max                  6.59962\n",
      "evaluation/Rewards Min                 -1.52566\n",
      "evaluation/Returns Mean              4530.98\n",
      "evaluation/Returns Std                357.941\n",
      "evaluation/Returns Max               4797.75\n",
      "evaluation/Returns Min               3484.65\n",
      "evaluation/Estimation Bias Mean       921.805\n",
      "evaluation/Estimation Bias Std        147.924\n",
      "evaluation/EB/Q_True Mean              43.4355\n",
      "evaluation/EB/Q_True Std              132.578\n",
      "evaluation/EB/Q_Pred Mean             965.241\n",
      "evaluation/EB/Q_Pred Std               58.3777\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4530.98\n",
      "evaluation/Actions Mean                 0.0210589\n",
      "evaluation/Actions Std                  0.530595\n",
      "evaluation/Actions Max                  0.999377\n",
      "evaluation/Actions Min                 -0.999904\n",
      "time/backward_policy (s)                1.96033\n",
      "time/backward_zf1 (s)                   2.09019\n",
      "time/backward_zf2 (s)                   2.02887\n",
      "time/data sampling (s)                  0.31204\n",
      "time/data storing (s)                   0.0152031\n",
      "time/evaluation sampling (s)            1.76011\n",
      "time/exploration sampling (s)           0.328153\n",
      "time/logging (s)                        0.0129301\n",
      "time/preback_alpha (s)                  1.00442\n",
      "time/preback_policy (s)                 1.13507\n",
      "time/preback_start (s)                  0.149504\n",
      "time/preback_zf (s)                     5.25448\n",
      "time/saving (s)                         0.00625435\n",
      "time/training (s)                       2.31398\n",
      "time/epoch (s)                         18.3716\n",
      "time/total (s)                       3050.6\n",
      "Epoch                                 170\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:43:23.564643 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 171 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 182000\n",
      "trainer/ZF1 Loss                       15.7116\n",
      "trainer/ZF2 Loss                       11.7376\n",
      "trainer/ZF Expert Reward               19.5787\n",
      "trainer/ZF Policy Reward                8.68266\n",
      "trainer/ZF CHI2 Term                   44.6594\n",
      "trainer/Policy Loss                  -858.815\n",
      "trainer/Bias Loss                      72.4317\n",
      "trainer/Bias Value                     13.9054\n",
      "trainer/Policy Grad Norm              164.628\n",
      "trainer/Policy Param Norm              35.176\n",
      "trainer/Zf1 Grad Norm                1532.01\n",
      "trainer/Zf1 Param Norm                107.203\n",
      "trainer/Zf2 Grad Norm                1223.59\n",
      "trainer/Zf2 Param Norm                105.858\n",
      "trainer/Z Expert Predictions Mean     986.361\n",
      "trainer/Z Expert Predictions Std       36.8589\n",
      "trainer/Z Expert Predictions Max     1061.17\n",
      "trainer/Z Expert Predictions Min      760.409\n",
      "trainer/Z Policy Predictions Mean     857.277\n",
      "trainer/Z Policy Predictions Std      264.537\n",
      "trainer/Z Policy Predictions Max     1026.74\n",
      "trainer/Z Policy Predictions Min     -375.226\n",
      "trainer/Z Expert Targets Mean         966.783\n",
      "trainer/Z Expert Targets Std           38.1995\n",
      "trainer/Z Expert Targets Max         1024.58\n",
      "trainer/Z Expert Targets Min          740.355\n",
      "trainer/Z Policy Targets Mean         848.595\n",
      "trainer/Z Policy Targets Std          260.203\n",
      "trainer/Z Policy Targets Max         1020.81\n",
      "trainer/Z Policy Targets Min         -384.124\n",
      "trainer/Log Pis Mean                   20.2411\n",
      "trainer/Log Pis Std                     3.9555\n",
      "trainer/Policy mu Mean                  0.0624055\n",
      "trainer/Policy mu Std                   1.02938\n",
      "trainer/Policy log std Mean            -3.28259\n",
      "trainer/Policy log std Std              0.894075\n",
      "trainer/Alpha                           0.122022\n",
      "trainer/Alpha Loss                     -0.0294187\n",
      "exploration/num steps total        176654\n",
      "exploration/num paths total           276\n",
      "evaluation/num steps total              1.47962e+06\n",
      "evaluation/num paths total           1764\n",
      "evaluation/path length Mean           973\n",
      "evaluation/path length Std             81\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            730\n",
      "evaluation/Rewards Mean                 4.72942\n",
      "evaluation/Rewards Std                  0.991455\n",
      "evaluation/Rewards Max                  6.68493\n",
      "evaluation/Rewards Min                 -1.49825\n",
      "evaluation/Returns Mean              4601.72\n",
      "evaluation/Returns Std                374.379\n",
      "evaluation/Returns Max               4989.45\n",
      "evaluation/Returns Min               3518.48\n",
      "evaluation/Estimation Bias Mean       913.664\n",
      "evaluation/Estimation Bias Std        148.848\n",
      "evaluation/EB/Q_True Mean              44.5605\n",
      "evaluation/EB/Q_True Std              136.759\n",
      "evaluation/EB/Q_Pred Mean             958.225\n",
      "evaluation/EB/Q_Pred Std               52.0833\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4601.72\n",
      "evaluation/Actions Mean                 0.0252055\n",
      "evaluation/Actions Std                  0.538114\n",
      "evaluation/Actions Max                  0.999555\n",
      "evaluation/Actions Min                 -0.999756\n",
      "time/backward_policy (s)                1.96486\n",
      "time/backward_zf1 (s)                   2.05777\n",
      "time/backward_zf2 (s)                   2.00573\n",
      "time/data sampling (s)                  0.302045\n",
      "time/data storing (s)                   0.01509\n",
      "time/evaluation sampling (s)            1.79055\n",
      "time/exploration sampling (s)           0.321386\n",
      "time/logging (s)                        0.0120362\n",
      "time/preback_alpha (s)                  1.02152\n",
      "time/preback_policy (s)                 1.16021\n",
      "time/preback_start (s)                  0.144728\n",
      "time/preback_zf (s)                     5.24227\n",
      "time/saving (s)                         0.00602665\n",
      "time/training (s)                       2.20357\n",
      "time/epoch (s)                         18.2478\n",
      "time/total (s)                       3068.87\n",
      "Epoch                                 171\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:43:41.438976 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 172 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 183000\n",
      "trainer/ZF1 Loss                        4.83446\n",
      "trainer/ZF2 Loss                       10.2047\n",
      "trainer/ZF Expert Reward               10.5642\n",
      "trainer/ZF Policy Reward               -1.35528\n",
      "trainer/ZF CHI2 Term                   39.2336\n",
      "trainer/Policy Loss                  -822.025\n",
      "trainer/Bias Loss                      82.8499\n",
      "trainer/Bias Value                     13.9188\n",
      "trainer/Policy Grad Norm              107.734\n",
      "trainer/Policy Param Norm              35.2066\n",
      "trainer/Zf1 Grad Norm                1724.13\n",
      "trainer/Zf1 Param Norm                107.429\n",
      "trainer/Zf2 Grad Norm                2150.63\n",
      "trainer/Zf2 Param Norm                106.07\n",
      "trainer/Z Expert Predictions Mean     964.079\n",
      "trainer/Z Expert Predictions Std       71.0217\n",
      "trainer/Z Expert Predictions Max     1034.39\n",
      "trainer/Z Expert Predictions Min       89.3811\n",
      "trainer/Z Policy Predictions Mean     817.741\n",
      "trainer/Z Policy Predictions Std      330.3\n",
      "trainer/Z Policy Predictions Max     1017.66\n",
      "trainer/Z Policy Predictions Min     -490.739\n",
      "trainer/Z Expert Targets Mean         953.515\n",
      "trainer/Z Expert Targets Std           77.1778\n",
      "trainer/Z Expert Targets Max         1025.04\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         819.096\n",
      "trainer/Z Policy Targets Std          327.698\n",
      "trainer/Z Policy Targets Max         1016.19\n",
      "trainer/Z Policy Targets Min         -470.845\n",
      "trainer/Log Pis Mean                   19.9944\n",
      "trainer/Log Pis Std                     4.42995\n",
      "trainer/Policy mu Mean                  0.0505418\n",
      "trainer/Policy mu Std                   1.05423\n",
      "trainer/Policy log std Mean            -3.22208\n",
      "trainer/Policy log std Std              1.00355\n",
      "trainer/Alpha                           0.122275\n",
      "trainer/Alpha Loss                      0.000683042\n",
      "exploration/num steps total        177654\n",
      "exploration/num paths total           277\n",
      "evaluation/num steps total              1.48869e+06\n",
      "evaluation/num paths total           1775\n",
      "evaluation/path length Mean           824.909\n",
      "evaluation/path length Std            371.472\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             23\n",
      "evaluation/Rewards Mean                 4.65329\n",
      "evaluation/Rewards Std                  1.12017\n",
      "evaluation/Rewards Max                  6.81602\n",
      "evaluation/Rewards Min                 -1.28608\n",
      "evaluation/Returns Mean              3838.54\n",
      "evaluation/Returns Std               1787.92\n",
      "evaluation/Returns Max               4855.95\n",
      "evaluation/Returns Min                 16.839\n",
      "evaluation/Estimation Bias Mean       898.93\n",
      "evaluation/Estimation Bias Std        154.388\n",
      "evaluation/EB/Q_True Mean              46.98\n",
      "evaluation/EB/Q_True Std              138.239\n",
      "evaluation/EB/Q_Pred Mean             945.91\n",
      "evaluation/EB/Q_Pred Std               63.3671\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3838.54\n",
      "evaluation/Actions Mean                 0.0228073\n",
      "evaluation/Actions Std                  0.54088\n",
      "evaluation/Actions Max                  0.999788\n",
      "evaluation/Actions Min                 -0.999606\n",
      "time/backward_policy (s)                1.87189\n",
      "time/backward_zf1 (s)                   1.9987\n",
      "time/backward_zf2 (s)                   1.93132\n",
      "time/data sampling (s)                  0.283356\n",
      "time/data storing (s)                   0.0146218\n",
      "time/evaluation sampling (s)            1.74325\n",
      "time/exploration sampling (s)           0.321174\n",
      "time/logging (s)                        0.0120177\n",
      "time/preback_alpha (s)                  0.978659\n",
      "time/preback_policy (s)                 1.09387\n",
      "time/preback_start (s)                  0.144035\n",
      "time/preback_zf (s)                     5.18275\n",
      "time/saving (s)                         0.00592856\n",
      "time/training (s)                       2.22493\n",
      "time/epoch (s)                         17.8065\n",
      "time/total (s)                       3086.69\n",
      "Epoch                                 172\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:43:59.767404 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 173 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 184000\n",
      "trainer/ZF1 Loss                        8.09826\n",
      "trainer/ZF2 Loss                        3.50495\n",
      "trainer/ZF Expert Reward               12.4377\n",
      "trainer/ZF Policy Reward                2.7079\n",
      "trainer/ZF CHI2 Term                   35.0042\n",
      "trainer/Policy Loss                  -801.977\n",
      "trainer/Bias Loss                      63.3606\n",
      "trainer/Bias Value                     13.9319\n",
      "trainer/Policy Grad Norm              118.908\n",
      "trainer/Policy Param Norm              35.2383\n",
      "trainer/Zf1 Grad Norm                1084.4\n",
      "trainer/Zf1 Param Norm                107.663\n",
      "trainer/Zf2 Grad Norm                1136.33\n",
      "trainer/Zf2 Param Norm                106.286\n",
      "trainer/Z Expert Predictions Mean     965.605\n",
      "trainer/Z Expert Predictions Std       37.0757\n",
      "trainer/Z Expert Predictions Max     1027.38\n",
      "trainer/Z Expert Predictions Min      770.65\n",
      "trainer/Z Policy Predictions Mean     800.081\n",
      "trainer/Z Policy Predictions Std      339.643\n",
      "trainer/Z Policy Predictions Max     1012.92\n",
      "trainer/Z Policy Predictions Min     -474.434\n",
      "trainer/Z Expert Targets Mean         953.167\n",
      "trainer/Z Expert Targets Std           38.4623\n",
      "trainer/Z Expert Targets Max         1019.22\n",
      "trainer/Z Expert Targets Min          756.079\n",
      "trainer/Z Policy Targets Mean         797.374\n",
      "trainer/Z Policy Targets Std          334.526\n",
      "trainer/Z Policy Targets Max         1001.9\n",
      "trainer/Z Policy Targets Min         -481.371\n",
      "trainer/Log Pis Mean                   19.6695\n",
      "trainer/Log Pis Std                     4.47518\n",
      "trainer/Policy mu Mean                  0.0582773\n",
      "trainer/Policy mu Std                   0.974985\n",
      "trainer/Policy log std Mean            -3.21\n",
      "trainer/Policy log std Std              0.9362\n",
      "trainer/Alpha                           0.123623\n",
      "trainer/Alpha Loss                      0.0408634\n",
      "exploration/num steps total        177654\n",
      "exploration/num paths total           277\n",
      "evaluation/num steps total              1.49869e+06\n",
      "evaluation/num paths total           1785\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69919\n",
      "evaluation/Rewards Std                  1.04568\n",
      "evaluation/Rewards Max                  6.76656\n",
      "evaluation/Rewards Min                 -2.11533\n",
      "evaluation/Returns Mean              4699.19\n",
      "evaluation/Returns Std                113.142\n",
      "evaluation/Returns Max               4887.03\n",
      "evaluation/Returns Min               4503\n",
      "evaluation/Estimation Bias Mean       900.849\n",
      "evaluation/Estimation Bias Std        146.042\n",
      "evaluation/EB/Q_True Mean              43.1009\n",
      "evaluation/EB/Q_True Std              132.572\n",
      "evaluation/EB/Q_Pred Mean             943.949\n",
      "evaluation/EB/Q_Pred Std               61.0154\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4699.19\n",
      "evaluation/Actions Mean                 0.0248317\n",
      "evaluation/Actions Std                  0.534254\n",
      "evaluation/Actions Max                  0.999525\n",
      "evaluation/Actions Min                 -0.999671\n",
      "time/backward_policy (s)                1.97958\n",
      "time/backward_zf1 (s)                   2.12457\n",
      "time/backward_zf2 (s)                   2.06905\n",
      "time/data sampling (s)                  0.307875\n",
      "time/data storing (s)                   0.0159742\n",
      "time/evaluation sampling (s)            1.74314\n",
      "time/exploration sampling (s)           0.327992\n",
      "time/logging (s)                        0.0154788\n",
      "time/preback_alpha (s)                  1.04812\n",
      "time/preback_policy (s)                 1.19762\n",
      "time/preback_start (s)                  0.146858\n",
      "time/preback_zf (s)                     5.18933\n",
      "time/saving (s)                         0.00791919\n",
      "time/training (s)                       2.08959\n",
      "time/epoch (s)                         18.2631\n",
      "time/total (s)                       3104.98\n",
      "Epoch                                 173\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:44:17.555271 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 174 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 185000\n",
      "trainer/ZF1 Loss                        2.16308\n",
      "trainer/ZF2 Loss                        2.06383\n",
      "trainer/ZF Expert Reward               17.1514\n",
      "trainer/ZF Policy Reward                4.91763\n",
      "trainer/ZF CHI2 Term                   34.4436\n",
      "trainer/Policy Loss                  -845.353\n",
      "trainer/Bias Loss                      69.6362\n",
      "trainer/Bias Value                     13.9453\n",
      "trainer/Policy Grad Norm              133.812\n",
      "trainer/Policy Param Norm              35.272\n",
      "trainer/Zf1 Grad Norm                1527.14\n",
      "trainer/Zf1 Param Norm                107.893\n",
      "trainer/Zf2 Grad Norm                 903.871\n",
      "trainer/Zf2 Param Norm                106.494\n",
      "trainer/Z Expert Predictions Mean     961.316\n",
      "trainer/Z Expert Predictions Std       68.6658\n",
      "trainer/Z Expert Predictions Max     1016.48\n",
      "trainer/Z Expert Predictions Min       53.63\n",
      "trainer/Z Policy Predictions Mean     841.403\n",
      "trainer/Z Policy Predictions Std      282.98\n",
      "trainer/Z Policy Predictions Max     1006.43\n",
      "trainer/Z Policy Predictions Min     -518.895\n",
      "trainer/Z Expert Targets Mean         944.164\n",
      "trainer/Z Expert Targets Std           72.4079\n",
      "trainer/Z Expert Targets Max         1014.8\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         836.485\n",
      "trainer/Z Policy Targets Std          279.608\n",
      "trainer/Z Policy Targets Max          998.704\n",
      "trainer/Z Policy Targets Min         -504.342\n",
      "trainer/Log Pis Mean                   20.2993\n",
      "trainer/Log Pis Std                     3.89934\n",
      "trainer/Policy mu Mean                  0.0413705\n",
      "trainer/Policy mu Std                   1.00651\n",
      "trainer/Policy log std Mean            -3.25811\n",
      "trainer/Policy log std Std              0.913443\n",
      "trainer/Alpha                           0.1224\n",
      "trainer/Alpha Loss                     -0.0366375\n",
      "exploration/num steps total        178654\n",
      "exploration/num paths total           278\n",
      "evaluation/num steps total              1.50869e+06\n",
      "evaluation/num paths total           1795\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.75314\n",
      "evaluation/Rewards Std                  1.01744\n",
      "evaluation/Rewards Max                  7.07211\n",
      "evaluation/Rewards Min                 -1.56086\n",
      "evaluation/Returns Mean              4753.14\n",
      "evaluation/Returns Std                 84.7716\n",
      "evaluation/Returns Max               4878.36\n",
      "evaluation/Returns Min               4605.27\n",
      "evaluation/Estimation Bias Mean       900.32\n",
      "evaluation/Estimation Bias Std        149.618\n",
      "evaluation/EB/Q_True Mean              45.0141\n",
      "evaluation/EB/Q_True Std              138.717\n",
      "evaluation/EB/Q_Pred Mean             945.334\n",
      "evaluation/EB/Q_Pred Std               56.4236\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4753.14\n",
      "evaluation/Actions Mean                 0.0213669\n",
      "evaluation/Actions Std                  0.539596\n",
      "evaluation/Actions Max                  0.999723\n",
      "evaluation/Actions Min                 -0.999879\n",
      "time/backward_policy (s)                1.87194\n",
      "time/backward_zf1 (s)                   1.98194\n",
      "time/backward_zf2 (s)                   1.91558\n",
      "time/data sampling (s)                  0.291782\n",
      "time/data storing (s)                   0.0143766\n",
      "time/evaluation sampling (s)            1.7043\n",
      "time/exploration sampling (s)           0.315077\n",
      "time/logging (s)                        0.012107\n",
      "time/preback_alpha (s)                  0.969943\n",
      "time/preback_policy (s)                 1.08129\n",
      "time/preback_start (s)                  0.144794\n",
      "time/preback_zf (s)                     5.15655\n",
      "time/saving (s)                         0.00563745\n",
      "time/training (s)                       2.25365\n",
      "time/epoch (s)                         17.719\n",
      "time/total (s)                       3122.71\n",
      "Epoch                                 174\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:44:36.175326 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 175 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 186000\n",
      "trainer/ZF1 Loss                        4.81599\n",
      "trainer/ZF2 Loss                        1.94673\n",
      "trainer/ZF Expert Reward               14\n",
      "trainer/ZF Policy Reward                1.80233\n",
      "trainer/ZF CHI2 Term                   35.5279\n",
      "trainer/Policy Loss                  -837.507\n",
      "trainer/Bias Loss                      86.1968\n",
      "trainer/Bias Value                     13.9574\n",
      "trainer/Policy Grad Norm              112.637\n",
      "trainer/Policy Param Norm              35.3075\n",
      "trainer/Zf1 Grad Norm                1701.44\n",
      "trainer/Zf1 Param Norm                108.114\n",
      "trainer/Zf2 Grad Norm                1340.23\n",
      "trainer/Zf2 Param Norm                106.689\n",
      "trainer/Z Expert Predictions Mean     955.211\n",
      "trainer/Z Expert Predictions Std       76.9145\n",
      "trainer/Z Expert Predictions Max     1029.37\n",
      "trainer/Z Expert Predictions Min      -57.681\n",
      "trainer/Z Policy Predictions Mean     836.108\n",
      "trainer/Z Policy Predictions Std      296.736\n",
      "trainer/Z Policy Predictions Max     1002.11\n",
      "trainer/Z Policy Predictions Min     -506.703\n",
      "trainer/Z Expert Targets Mean         941.211\n",
      "trainer/Z Expert Targets Std           73.5665\n",
      "trainer/Z Expert Targets Max         1006.75\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         834.306\n",
      "trainer/Z Policy Targets Std          290.21\n",
      "trainer/Z Policy Targets Max          996.417\n",
      "trainer/Z Policy Targets Min         -486.532\n",
      "trainer/Log Pis Mean                   20.1504\n",
      "trainer/Log Pis Std                     4.13636\n",
      "trainer/Policy mu Mean                  0.0447408\n",
      "trainer/Policy mu Std                   0.989455\n",
      "trainer/Policy log std Mean            -3.24489\n",
      "trainer/Policy log std Std              0.901247\n",
      "trainer/Alpha                           0.124049\n",
      "trainer/Alpha Loss                     -0.0186604\n",
      "exploration/num steps total        180654\n",
      "exploration/num paths total           280\n",
      "evaluation/num steps total              1.51719e+06\n",
      "evaluation/num paths total           1805\n",
      "evaluation/path length Mean           849.9\n",
      "evaluation/path length Std            310.863\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             69\n",
      "evaluation/Rewards Mean                 4.60383\n",
      "evaluation/Rewards Std                  1.07084\n",
      "evaluation/Rewards Max                  6.54231\n",
      "evaluation/Rewards Min                 -2.71432\n",
      "evaluation/Returns Mean              3912.79\n",
      "evaluation/Returns Std               1543.93\n",
      "evaluation/Returns Max               4733.6\n",
      "evaluation/Returns Min                -59.6791\n",
      "evaluation/Estimation Bias Mean       886.082\n",
      "evaluation/Estimation Bias Std        194.289\n",
      "evaluation/EB/Q_True Mean              51.0013\n",
      "evaluation/EB/Q_True Std              143.226\n",
      "evaluation/EB/Q_Pred Mean             937.083\n",
      "evaluation/EB/Q_Pred Std              104.111\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3912.79\n",
      "evaluation/Actions Mean                 0.0219694\n",
      "evaluation/Actions Std                  0.537916\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999925\n",
      "time/backward_policy (s)                2.04838\n",
      "time/backward_zf1 (s)                   2.1781\n",
      "time/backward_zf2 (s)                   2.12092\n",
      "time/data sampling (s)                  0.299287\n",
      "time/data storing (s)                   0.0152117\n",
      "time/evaluation sampling (s)            1.72347\n",
      "time/exploration sampling (s)           0.326642\n",
      "time/logging (s)                        0.0112406\n",
      "time/preback_alpha (s)                  1.04448\n",
      "time/preback_policy (s)                 1.18626\n",
      "time/preback_start (s)                  0.147756\n",
      "time/preback_zf (s)                     5.2429\n",
      "time/saving (s)                         0.00614237\n",
      "time/training (s)                       2.2009\n",
      "time/epoch (s)                         18.5517\n",
      "time/total (s)                       3141.28\n",
      "Epoch                                 175\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:44:54.455753 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 176 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 187000\n",
      "trainer/ZF1 Loss                        6.90207\n",
      "trainer/ZF2 Loss                        3.38332\n",
      "trainer/ZF Expert Reward               15.7475\n",
      "trainer/ZF Policy Reward                4.24239\n",
      "trainer/ZF CHI2 Term                   36.3342\n",
      "trainer/Policy Loss                  -826.278\n",
      "trainer/Bias Loss                      57.7762\n",
      "trainer/Bias Value                     13.9684\n",
      "trainer/Policy Grad Norm              121.569\n",
      "trainer/Policy Param Norm              35.3438\n",
      "trainer/Zf1 Grad Norm                 915.28\n",
      "trainer/Zf1 Param Norm                108.319\n",
      "trainer/Zf2 Grad Norm                1150.61\n",
      "trainer/Zf2 Param Norm                106.891\n",
      "trainer/Z Expert Predictions Mean     958.298\n",
      "trainer/Z Expert Predictions Std       38.0946\n",
      "trainer/Z Expert Predictions Max     1015.26\n",
      "trainer/Z Expert Predictions Min      748.721\n",
      "trainer/Z Policy Predictions Mean     825.453\n",
      "trainer/Z Policy Predictions Std      304.488\n",
      "trainer/Z Policy Predictions Max     1000.99\n",
      "trainer/Z Policy Predictions Min     -496.712\n",
      "trainer/Z Expert Targets Mean         942.551\n",
      "trainer/Z Expert Targets Std           40.615\n",
      "trainer/Z Expert Targets Max         1008.86\n",
      "trainer/Z Expert Targets Min          730.221\n",
      "trainer/Z Policy Targets Mean         821.211\n",
      "trainer/Z Policy Targets Std          302.252\n",
      "trainer/Z Policy Targets Max          991.915\n",
      "trainer/Z Policy Targets Min         -500.236\n",
      "trainer/Log Pis Mean                   19.8852\n",
      "trainer/Log Pis Std                     3.78865\n",
      "trainer/Policy mu Mean                  0.0526574\n",
      "trainer/Policy mu Std                   0.996263\n",
      "trainer/Policy log std Mean            -3.26069\n",
      "trainer/Policy log std Std              0.885565\n",
      "trainer/Alpha                           0.122608\n",
      "trainer/Alpha Loss                      0.0140785\n",
      "exploration/num steps total        182654\n",
      "exploration/num paths total           282\n",
      "evaluation/num steps total              1.52592e+06\n",
      "evaluation/num paths total           1815\n",
      "evaluation/path length Mean           873.2\n",
      "evaluation/path length Std            262.903\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            211\n",
      "evaluation/Rewards Mean                 4.65977\n",
      "evaluation/Rewards Std                  1.07279\n",
      "evaluation/Rewards Max                  6.81963\n",
      "evaluation/Rewards Min                 -1.62672\n",
      "evaluation/Returns Mean              4068.91\n",
      "evaluation/Returns Std               1255.73\n",
      "evaluation/Returns Max               4782.88\n",
      "evaluation/Returns Min                911.188\n",
      "evaluation/Estimation Bias Mean       880.98\n",
      "evaluation/Estimation Bias Std        152.417\n",
      "evaluation/EB/Q_True Mean              48.5563\n",
      "evaluation/EB/Q_True Std              139.328\n",
      "evaluation/EB/Q_Pred Mean             929.536\n",
      "evaluation/EB/Q_Pred Std               56.3117\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4068.91\n",
      "evaluation/Actions Mean                 0.0318629\n",
      "evaluation/Actions Std                  0.531867\n",
      "evaluation/Actions Max                  0.999584\n",
      "evaluation/Actions Min                 -0.999732\n",
      "time/backward_policy (s)                1.93988\n",
      "time/backward_zf1 (s)                   2.06922\n",
      "time/backward_zf2 (s)                   2.01343\n",
      "time/data sampling (s)                  0.296749\n",
      "time/data storing (s)                   0.0148243\n",
      "time/evaluation sampling (s)            1.82805\n",
      "time/exploration sampling (s)           0.327648\n",
      "time/logging (s)                        0.0110204\n",
      "time/preback_alpha (s)                  1.03608\n",
      "time/preback_policy (s)                 1.17362\n",
      "time/preback_start (s)                  0.146679\n",
      "time/preback_zf (s)                     5.21441\n",
      "time/saving (s)                         0.00613312\n",
      "time/training (s)                       2.13352\n",
      "time/epoch (s)                         18.2113\n",
      "time/total (s)                       3159.52\n",
      "Epoch                                 176\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:45:12.778385 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 177 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 188000\n",
      "trainer/ZF1 Loss                        1.0013\n",
      "trainer/ZF2 Loss                        2.02538\n",
      "trainer/ZF Expert Reward               12.4369\n",
      "trainer/ZF Policy Reward                0.662065\n",
      "trainer/ZF CHI2 Term                   32.7719\n",
      "trainer/Policy Loss                  -796.302\n",
      "trainer/Bias Loss                      55.3171\n",
      "trainer/Bias Value                     13.9831\n",
      "trainer/Policy Grad Norm              144.342\n",
      "trainer/Policy Param Norm              35.3786\n",
      "trainer/Zf1 Grad Norm                1081.57\n",
      "trainer/Zf1 Param Norm                108.522\n",
      "trainer/Zf2 Grad Norm                1414.42\n",
      "trainer/Zf2 Param Norm                107.085\n",
      "trainer/Z Expert Predictions Mean     946.736\n",
      "trainer/Z Expert Predictions Std       42.8593\n",
      "trainer/Z Expert Predictions Max     1012.65\n",
      "trainer/Z Expert Predictions Min      690.673\n",
      "trainer/Z Policy Predictions Mean     790.765\n",
      "trainer/Z Policy Predictions Std      326.723\n",
      "trainer/Z Policy Predictions Max      996.012\n",
      "trainer/Z Policy Predictions Min     -524.501\n",
      "trainer/Z Expert Targets Mean         934.299\n",
      "trainer/Z Expert Targets Std           44.1341\n",
      "trainer/Z Expert Targets Max          997.225\n",
      "trainer/Z Expert Targets Min          671.512\n",
      "trainer/Z Policy Targets Mean         790.103\n",
      "trainer/Z Policy Targets Std          321.79\n",
      "trainer/Z Policy Targets Max          998.744\n",
      "trainer/Z Policy Targets Min         -517.046\n",
      "trainer/Log Pis Mean                   19.6805\n",
      "trainer/Log Pis Std                     4.32203\n",
      "trainer/Policy mu Mean                  0.070492\n",
      "trainer/Policy mu Std                   1.01798\n",
      "trainer/Policy log std Mean            -3.20108\n",
      "trainer/Policy log std Std              0.938885\n",
      "trainer/Alpha                           0.122693\n",
      "trainer/Alpha Loss                      0.0392048\n",
      "exploration/num steps total        183654\n",
      "exploration/num paths total           283\n",
      "evaluation/num steps total              1.53592e+06\n",
      "evaluation/num paths total           1825\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68113\n",
      "evaluation/Rewards Std                  0.972872\n",
      "evaluation/Rewards Max                  6.95961\n",
      "evaluation/Rewards Min                 -1.90652\n",
      "evaluation/Returns Mean              4681.13\n",
      "evaluation/Returns Std                 87.534\n",
      "evaluation/Returns Max               4832.74\n",
      "evaluation/Returns Min               4543.4\n",
      "evaluation/Estimation Bias Mean       893.522\n",
      "evaluation/Estimation Bias Std        138.577\n",
      "evaluation/EB/Q_True Mean              42.1044\n",
      "evaluation/EB/Q_True Std              129.721\n",
      "evaluation/EB/Q_Pred Mean             935.626\n",
      "evaluation/EB/Q_Pred Std               48.7282\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4681.13\n",
      "evaluation/Actions Mean                 0.0216219\n",
      "evaluation/Actions Std                  0.53634\n",
      "evaluation/Actions Max                  0.999658\n",
      "evaluation/Actions Min                 -0.999688\n",
      "time/backward_policy (s)                1.90499\n",
      "time/backward_zf1 (s)                   2.06122\n",
      "time/backward_zf2 (s)                   1.98569\n",
      "time/data sampling (s)                  0.312126\n",
      "time/data storing (s)                   0.0166225\n",
      "time/evaluation sampling (s)            1.73904\n",
      "time/exploration sampling (s)           0.340388\n",
      "time/logging (s)                        0.0126481\n",
      "time/preback_alpha (s)                  0.986565\n",
      "time/preback_policy (s)                 1.11172\n",
      "time/preback_start (s)                  0.149581\n",
      "time/preback_zf (s)                     5.26017\n",
      "time/saving (s)                         0.00810344\n",
      "time/training (s)                       2.36707\n",
      "time/epoch (s)                         18.2559\n",
      "time/total (s)                       3177.79\n",
      "Epoch                                 177\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:45:31.101021 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 178 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 189000\n",
      "trainer/ZF1 Loss                        5.53513\n",
      "trainer/ZF2 Loss                        3.44551\n",
      "trainer/ZF Expert Reward               14.5341\n",
      "trainer/ZF Policy Reward                2.49163\n",
      "trainer/ZF CHI2 Term                   36.616\n",
      "trainer/Policy Loss                  -827.448\n",
      "trainer/Bias Loss                      52.4536\n",
      "trainer/Bias Value                     13.9943\n",
      "trainer/Policy Grad Norm              126.38\n",
      "trainer/Policy Param Norm              35.4132\n",
      "trainer/Zf1 Grad Norm                1532.43\n",
      "trainer/Zf1 Param Norm                108.736\n",
      "trainer/Zf2 Grad Norm                1064.8\n",
      "trainer/Zf2 Param Norm                107.263\n",
      "trainer/Z Expert Predictions Mean     950.971\n",
      "trainer/Z Expert Predictions Std       41.1224\n",
      "trainer/Z Expert Predictions Max     1022.59\n",
      "trainer/Z Expert Predictions Min      641.966\n",
      "trainer/Z Policy Predictions Mean     824.889\n",
      "trainer/Z Policy Predictions Std      290.454\n",
      "trainer/Z Policy Predictions Max      997.394\n",
      "trainer/Z Policy Predictions Min     -533.585\n",
      "trainer/Z Expert Targets Mean         936.436\n",
      "trainer/Z Expert Targets Std           43.6075\n",
      "trainer/Z Expert Targets Max         1008.17\n",
      "trainer/Z Expert Targets Min          581.303\n",
      "trainer/Z Policy Targets Mean         822.398\n",
      "trainer/Z Policy Targets Std          286.364\n",
      "trainer/Z Policy Targets Max          984.135\n",
      "trainer/Z Policy Targets Min         -531.399\n",
      "trainer/Log Pis Mean                   20.286\n",
      "trainer/Log Pis Std                     4.03664\n",
      "trainer/Policy mu Mean                  0.00889568\n",
      "trainer/Policy mu Std                   0.986111\n",
      "trainer/Policy log std Mean            -3.27871\n",
      "trainer/Policy log std Std              0.889147\n",
      "trainer/Alpha                           0.124832\n",
      "trainer/Alpha Loss                     -0.0357062\n",
      "exploration/num steps total        184654\n",
      "exploration/num paths total           284\n",
      "evaluation/num steps total              1.54592e+06\n",
      "evaluation/num paths total           1835\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65845\n",
      "evaluation/Rewards Std                  0.957483\n",
      "evaluation/Rewards Max                  6.70965\n",
      "evaluation/Rewards Min                 -1.92289\n",
      "evaluation/Returns Mean              4658.45\n",
      "evaluation/Returns Std                 56.9433\n",
      "evaluation/Returns Max               4736.12\n",
      "evaluation/Returns Min               4578.38\n",
      "evaluation/Estimation Bias Mean       885.459\n",
      "evaluation/Estimation Bias Std        138.678\n",
      "evaluation/EB/Q_True Mean              42.9787\n",
      "evaluation/EB/Q_True Std              132.8\n",
      "evaluation/EB/Q_Pred Mean             928.438\n",
      "evaluation/EB/Q_Pred Std               48.2269\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4658.45\n",
      "evaluation/Actions Mean                 0.0220703\n",
      "evaluation/Actions Std                  0.535681\n",
      "evaluation/Actions Max                  0.999471\n",
      "evaluation/Actions Min                 -0.999761\n",
      "time/backward_policy (s)                1.96154\n",
      "time/backward_zf1 (s)                   2.08504\n",
      "time/backward_zf2 (s)                   2.02312\n",
      "time/data sampling (s)                  0.31484\n",
      "time/data storing (s)                   0.0149298\n",
      "time/evaluation sampling (s)            1.79408\n",
      "time/exploration sampling (s)           0.323935\n",
      "time/logging (s)                        0.0119097\n",
      "time/preback_alpha (s)                  1.03753\n",
      "time/preback_policy (s)                 1.17015\n",
      "time/preback_start (s)                  0.153512\n",
      "time/preback_zf (s)                     5.20023\n",
      "time/saving (s)                         0.0211049\n",
      "time/training (s)                       2.14148\n",
      "time/epoch (s)                         18.2534\n",
      "time/total (s)                       3196.06\n",
      "Epoch                                 178\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:45:49.331708 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 179 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 190000\n",
      "trainer/ZF1 Loss                       40.5682\n",
      "trainer/ZF2 Loss                       76.2931\n",
      "trainer/ZF Expert Reward               13.0389\n",
      "trainer/ZF Policy Reward                2.6619\n",
      "trainer/ZF CHI2 Term                   88.8175\n",
      "trainer/Policy Loss                  -792.112\n",
      "trainer/Bias Loss                      61.798\n",
      "trainer/Bias Value                     14.0068\n",
      "trainer/Policy Grad Norm              107.456\n",
      "trainer/Policy Param Norm              35.449\n",
      "trainer/Zf1 Grad Norm                3348.87\n",
      "trainer/Zf1 Param Norm                108.941\n",
      "trainer/Zf2 Grad Norm                2996.05\n",
      "trainer/Zf2 Param Norm                107.447\n",
      "trainer/Z Expert Predictions Mean     939.209\n",
      "trainer/Z Expert Predictions Std       50.8514\n",
      "trainer/Z Expert Predictions Max     1003.56\n",
      "trainer/Z Expert Predictions Min      631.823\n",
      "trainer/Z Policy Predictions Mean     786.603\n",
      "trainer/Z Policy Predictions Std      332.796\n",
      "trainer/Z Policy Predictions Max      992.497\n",
      "trainer/Z Policy Predictions Min     -497.411\n",
      "trainer/Z Expert Targets Mean         926.17\n",
      "trainer/Z Expert Targets Std           52.0087\n",
      "trainer/Z Expert Targets Max          995.247\n",
      "trainer/Z Expert Targets Min          590.483\n",
      "trainer/Z Policy Targets Mean         783.941\n",
      "trainer/Z Policy Targets Std          331.027\n",
      "trainer/Z Policy Targets Max          995.308\n",
      "trainer/Z Policy Targets Min         -479.325\n",
      "trainer/Log Pis Mean                   20.212\n",
      "trainer/Log Pis Std                     4.01059\n",
      "trainer/Policy mu Mean                  0.0443118\n",
      "trainer/Policy mu Std                   1.02243\n",
      "trainer/Policy log std Mean            -3.24577\n",
      "trainer/Policy log std Std              0.946206\n",
      "trainer/Alpha                           0.125038\n",
      "trainer/Alpha Loss                     -0.0265058\n",
      "exploration/num steps total        185654\n",
      "exploration/num paths total           285\n",
      "evaluation/num steps total              1.55592e+06\n",
      "evaluation/num paths total           1845\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64744\n",
      "evaluation/Rewards Std                  1.05406\n",
      "evaluation/Rewards Max                  6.80364\n",
      "evaluation/Rewards Min                 -1.66667\n",
      "evaluation/Returns Mean              4647.44\n",
      "evaluation/Returns Std                129.27\n",
      "evaluation/Returns Max               4824.22\n",
      "evaluation/Returns Min               4365.97\n",
      "evaluation/Estimation Bias Mean       873.99\n",
      "evaluation/Estimation Bias Std        147.182\n",
      "evaluation/EB/Q_True Mean              42.7982\n",
      "evaluation/EB/Q_True Std              131.705\n",
      "evaluation/EB/Q_Pred Mean             916.788\n",
      "evaluation/EB/Q_Pred Std               56.3608\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4647.44\n",
      "evaluation/Actions Mean                 0.0267831\n",
      "evaluation/Actions Std                  0.531016\n",
      "evaluation/Actions Max                  0.999823\n",
      "evaluation/Actions Min                 -0.999825\n",
      "time/backward_policy (s)                1.94965\n",
      "time/backward_zf1 (s)                   2.08945\n",
      "time/backward_zf2 (s)                   2.017\n",
      "time/data sampling (s)                  0.312159\n",
      "time/data storing (s)                   0.0147898\n",
      "time/evaluation sampling (s)            1.70845\n",
      "time/exploration sampling (s)           0.322477\n",
      "time/logging (s)                        0.0125969\n",
      "time/preback_alpha (s)                  1.00739\n",
      "time/preback_policy (s)                 1.12315\n",
      "time/preback_start (s)                  0.150363\n",
      "time/preback_zf (s)                     5.19753\n",
      "time/saving (s)                         0.00623633\n",
      "time/training (s)                       2.25089\n",
      "time/epoch (s)                         18.1621\n",
      "time/total (s)                       3214.25\n",
      "Epoch                                 179\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:46:07.441477 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 180 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 191000\n",
      "trainer/ZF1 Loss                       10.8359\n",
      "trainer/ZF2 Loss                        9.04277\n",
      "trainer/ZF Expert Reward               15.506\n",
      "trainer/ZF Policy Reward                4.066\n",
      "trainer/ZF CHI2 Term                   41.0993\n",
      "trainer/Policy Loss                  -781.495\n",
      "trainer/Bias Loss                      52.871\n",
      "trainer/Bias Value                     14.0167\n",
      "trainer/Policy Grad Norm              130.645\n",
      "trainer/Policy Param Norm              35.4801\n",
      "trainer/Zf1 Grad Norm                1416.8\n",
      "trainer/Zf1 Param Norm                109.153\n",
      "trainer/Zf2 Grad Norm                1035.32\n",
      "trainer/Zf2 Param Norm                107.636\n",
      "trainer/Z Expert Predictions Mean     940.875\n",
      "trainer/Z Expert Predictions Std       41.2939\n",
      "trainer/Z Expert Predictions Max      992.22\n",
      "trainer/Z Expert Predictions Min      736.485\n",
      "trainer/Z Policy Predictions Mean     778.897\n",
      "trainer/Z Policy Predictions Std      338.999\n",
      "trainer/Z Policy Predictions Max      987.565\n",
      "trainer/Z Policy Predictions Min     -524.221\n",
      "trainer/Z Expert Targets Mean         925.369\n",
      "trainer/Z Expert Targets Std           42.8046\n",
      "trainer/Z Expert Targets Max          981.379\n",
      "trainer/Z Expert Targets Min          710.586\n",
      "trainer/Z Policy Targets Mean         774.831\n",
      "trainer/Z Policy Targets Std          334.521\n",
      "trainer/Z Policy Targets Max          971.285\n",
      "trainer/Z Policy Targets Min         -513.26\n",
      "trainer/Log Pis Mean                   19.9191\n",
      "trainer/Log Pis Std                     4.41422\n",
      "trainer/Policy mu Mean                  0.0339252\n",
      "trainer/Policy mu Std                   1.04028\n",
      "trainer/Policy log std Mean            -3.18192\n",
      "trainer/Policy log std Std              0.973507\n",
      "trainer/Alpha                           0.126864\n",
      "trainer/Alpha Loss                      0.0102677\n",
      "exploration/num steps total        186654\n",
      "exploration/num paths total           286\n",
      "evaluation/num steps total              1.56496e+06\n",
      "evaluation/num paths total           1855\n",
      "evaluation/path length Mean           903.6\n",
      "evaluation/path length Std            289.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             36\n",
      "evaluation/Rewards Mean                 4.59273\n",
      "evaluation/Rewards Std                  0.989704\n",
      "evaluation/Rewards Max                  6.53755\n",
      "evaluation/Rewards Min                 -1.9364\n",
      "evaluation/Returns Mean              4149.99\n",
      "evaluation/Returns Std               1376.37\n",
      "evaluation/Returns Max               4716.22\n",
      "evaluation/Returns Min                 28.271\n",
      "evaluation/Estimation Bias Mean       870.91\n",
      "evaluation/Estimation Bias Std        156.235\n",
      "evaluation/EB/Q_True Mean              46.7705\n",
      "evaluation/EB/Q_True Std              136.354\n",
      "evaluation/EB/Q_Pred Mean             917.681\n",
      "evaluation/EB/Q_Pred Std               55.6048\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4149.99\n",
      "evaluation/Actions Mean                 0.0191492\n",
      "evaluation/Actions Std                  0.531656\n",
      "evaluation/Actions Max                  0.999817\n",
      "evaluation/Actions Min                 -0.999369\n",
      "time/backward_policy (s)                1.9432\n",
      "time/backward_zf1 (s)                   2.07961\n",
      "time/backward_zf2 (s)                   2.0381\n",
      "time/data sampling (s)                  0.294008\n",
      "time/data storing (s)                   0.015063\n",
      "time/evaluation sampling (s)            1.74263\n",
      "time/exploration sampling (s)           0.319329\n",
      "time/logging (s)                        0.012977\n",
      "time/preback_alpha (s)                  1.04361\n",
      "time/preback_policy (s)                 1.18431\n",
      "time/preback_start (s)                  0.147812\n",
      "time/preback_zf (s)                     5.18811\n",
      "time/saving (s)                         0.00642713\n",
      "time/training (s)                       2.02675\n",
      "time/epoch (s)                         18.0419\n",
      "time/total (s)                       3232.31\n",
      "Epoch                                 180\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:46:25.649184 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 181 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 192000\n",
      "trainer/ZF1 Loss                       -0.298414\n",
      "trainer/ZF2 Loss                        3.17545\n",
      "trainer/ZF Expert Reward               14.3913\n",
      "trainer/ZF Policy Reward                2.69696\n",
      "trainer/ZF CHI2 Term                   32.8449\n",
      "trainer/Policy Loss                  -774.789\n",
      "trainer/Bias Loss                      48.4101\n",
      "trainer/Bias Value                     14.0302\n",
      "trainer/Policy Grad Norm              144.731\n",
      "trainer/Policy Param Norm              35.5126\n",
      "trainer/Zf1 Grad Norm                1183.06\n",
      "trainer/Zf1 Param Norm                109.356\n",
      "trainer/Zf2 Grad Norm                1528.98\n",
      "trainer/Zf2 Param Norm                107.825\n",
      "trainer/Z Expert Predictions Mean     932.836\n",
      "trainer/Z Expert Predictions Std       72.0383\n",
      "trainer/Z Expert Predictions Max      991.822\n",
      "trainer/Z Expert Predictions Min        1.7753\n",
      "trainer/Z Policy Predictions Mean     770.575\n",
      "trainer/Z Policy Predictions Std      340.226\n",
      "trainer/Z Policy Predictions Max      988.211\n",
      "trainer/Z Policy Predictions Min     -520.305\n",
      "trainer/Z Expert Targets Mean         918.444\n",
      "trainer/Z Expert Targets Std           72.3645\n",
      "trainer/Z Expert Targets Max          981.684\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         767.878\n",
      "trainer/Z Policy Targets Std          337.64\n",
      "trainer/Z Policy Targets Max          976.12\n",
      "trainer/Z Policy Targets Min         -514.093\n",
      "trainer/Log Pis Mean                   19.9112\n",
      "trainer/Log Pis Std                     4.4139\n",
      "trainer/Policy mu Mean                  0.0873977\n",
      "trainer/Policy mu Std                   1.0479\n",
      "trainer/Policy log std Mean            -3.17858\n",
      "trainer/Policy log std Std              0.948353\n",
      "trainer/Alpha                           0.128383\n",
      "trainer/Alpha Loss                      0.0113965\n",
      "exploration/num steps total        186654\n",
      "exploration/num paths total           286\n",
      "evaluation/num steps total              1.57496e+06\n",
      "evaluation/num paths total           1865\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69991\n",
      "evaluation/Rewards Std                  0.952132\n",
      "evaluation/Rewards Max                  6.86013\n",
      "evaluation/Rewards Min                 -1.53607\n",
      "evaluation/Returns Mean              4699.91\n",
      "evaluation/Returns Std                 77.7605\n",
      "evaluation/Returns Max               4816.42\n",
      "evaluation/Returns Min               4559.55\n",
      "evaluation/Estimation Bias Mean       878.39\n",
      "evaluation/Estimation Bias Std        139.711\n",
      "evaluation/EB/Q_True Mean              41.8722\n",
      "evaluation/EB/Q_True Std              130.124\n",
      "evaluation/EB/Q_Pred Mean             920.262\n",
      "evaluation/EB/Q_Pred Std               53.4173\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4699.91\n",
      "evaluation/Actions Mean                 0.0230389\n",
      "evaluation/Actions Std                  0.534522\n",
      "evaluation/Actions Max                  0.99943\n",
      "evaluation/Actions Min                 -0.99941\n",
      "time/backward_policy (s)                1.97619\n",
      "time/backward_zf1 (s)                   2.09589\n",
      "time/backward_zf2 (s)                   2.044\n",
      "time/data sampling (s)                  0.30195\n",
      "time/data storing (s)                   0.0140637\n",
      "time/evaluation sampling (s)            1.74816\n",
      "time/exploration sampling (s)           0.311432\n",
      "time/logging (s)                        0.0116833\n",
      "time/preback_alpha (s)                  1.03392\n",
      "time/preback_policy (s)                 1.17868\n",
      "time/preback_start (s)                  0.144819\n",
      "time/preback_zf (s)                     5.19721\n",
      "time/saving (s)                         0.00603932\n",
      "time/training (s)                       2.07393\n",
      "time/epoch (s)                         18.138\n",
      "time/total (s)                       3250.47\n",
      "Epoch                                 181\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:46:43.516390 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 182 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 193000\n",
      "trainer/ZF1 Loss                       22.0714\n",
      "trainer/ZF2 Loss                       13.2901\n",
      "trainer/ZF Expert Reward               13.1112\n",
      "trainer/ZF Policy Reward                1.98362\n",
      "trainer/ZF CHI2 Term                   47.9425\n",
      "trainer/Policy Loss                  -768.035\n",
      "trainer/Bias Loss                     125.355\n",
      "trainer/Bias Value                     14.0427\n",
      "trainer/Policy Grad Norm              142.311\n",
      "trainer/Policy Param Norm              35.5424\n",
      "trainer/Zf1 Grad Norm                2701.02\n",
      "trainer/Zf1 Param Norm                109.557\n",
      "trainer/Zf2 Grad Norm                1653.06\n",
      "trainer/Zf2 Param Norm                108.013\n",
      "trainer/Z Expert Predictions Mean     926.981\n",
      "trainer/Z Expert Predictions Std       82.5905\n",
      "trainer/Z Expert Predictions Max      984.141\n",
      "trainer/Z Expert Predictions Min     -168.669\n",
      "trainer/Z Policy Predictions Mean     766.12\n",
      "trainer/Z Policy Predictions Std      337.754\n",
      "trainer/Z Policy Predictions Max      973.272\n",
      "trainer/Z Policy Predictions Min     -532.89\n",
      "trainer/Z Expert Targets Mean         913.87\n",
      "trainer/Z Expert Targets Std           74.2389\n",
      "trainer/Z Expert Targets Max          977.689\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         764.136\n",
      "trainer/Z Policy Targets Std          332.317\n",
      "trainer/Z Policy Targets Max          962.389\n",
      "trainer/Z Policy Targets Min         -541.084\n",
      "trainer/Log Pis Mean                   19.3275\n",
      "trainer/Log Pis Std                     4.47323\n",
      "trainer/Policy mu Mean                  0.0298511\n",
      "trainer/Policy mu Std                   1.03836\n",
      "trainer/Policy log std Mean            -3.11812\n",
      "trainer/Policy log std Std              0.978194\n",
      "trainer/Alpha                           0.127939\n",
      "trainer/Alpha Loss                      0.0860453\n",
      "exploration/num steps total        187654\n",
      "exploration/num paths total           287\n",
      "evaluation/num steps total              1.58496e+06\n",
      "evaluation/num paths total           1875\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67001\n",
      "evaluation/Rewards Std                  1.02076\n",
      "evaluation/Rewards Max                  6.8279\n",
      "evaluation/Rewards Min                 -1.90086\n",
      "evaluation/Returns Mean              4670.01\n",
      "evaluation/Returns Std                155.103\n",
      "evaluation/Returns Max               4904.47\n",
      "evaluation/Returns Min               4349.55\n",
      "evaluation/Estimation Bias Mean       869.463\n",
      "evaluation/Estimation Bias Std        134.093\n",
      "evaluation/EB/Q_True Mean              39.8383\n",
      "evaluation/EB/Q_True Std              122.574\n",
      "evaluation/EB/Q_Pred Mean             909.302\n",
      "evaluation/EB/Q_Pred Std               55.7146\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4670.01\n",
      "evaluation/Actions Mean                 0.0242467\n",
      "evaluation/Actions Std                  0.530696\n",
      "evaluation/Actions Max                  0.999259\n",
      "evaluation/Actions Min                 -0.999476\n",
      "time/backward_policy (s)                1.83888\n",
      "time/backward_zf1 (s)                   1.9855\n",
      "time/backward_zf2 (s)                   1.9027\n",
      "time/data sampling (s)                  0.285851\n",
      "time/data storing (s)                   0.0147468\n",
      "time/evaluation sampling (s)            1.76487\n",
      "time/exploration sampling (s)           0.317723\n",
      "time/logging (s)                        0.0144453\n",
      "time/preback_alpha (s)                  0.952152\n",
      "time/preback_policy (s)                 1.05917\n",
      "time/preback_start (s)                  0.145766\n",
      "time/preback_zf (s)                     5.18819\n",
      "time/saving (s)                         0.00658853\n",
      "time/training (s)                       2.31774\n",
      "time/epoch (s)                         17.7943\n",
      "time/total (s)                       3268.29\n",
      "Epoch                                 182\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:47:02.230122 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 183 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 194000\n",
      "trainer/ZF1 Loss                       15.3629\n",
      "trainer/ZF2 Loss                        9.8676\n",
      "trainer/ZF Expert Reward               15.5718\n",
      "trainer/ZF Policy Reward                6.86273\n",
      "trainer/ZF CHI2 Term                   41.3048\n",
      "trainer/Policy Loss                  -775.066\n",
      "trainer/Bias Loss                      60.3566\n",
      "trainer/Bias Value                     14.0563\n",
      "trainer/Policy Grad Norm              131.755\n",
      "trainer/Policy Param Norm              35.576\n",
      "trainer/Zf1 Grad Norm                1286.24\n",
      "trainer/Zf1 Param Norm                109.753\n",
      "trainer/Zf2 Grad Norm                1302.27\n",
      "trainer/Zf2 Param Norm                108.187\n",
      "trainer/Z Expert Predictions Mean     926.564\n",
      "trainer/Z Expert Predictions Std       58.0619\n",
      "trainer/Z Expert Predictions Max      992.826\n",
      "trainer/Z Expert Predictions Min      339.643\n",
      "trainer/Z Policy Predictions Mean     772.49\n",
      "trainer/Z Policy Predictions Std      322.912\n",
      "trainer/Z Policy Predictions Max      977.88\n",
      "trainer/Z Policy Predictions Min     -522.644\n",
      "trainer/Z Expert Targets Mean         910.992\n",
      "trainer/Z Expert Targets Std           59.8182\n",
      "trainer/Z Expert Targets Max          976.295\n",
      "trainer/Z Expert Targets Min          333.564\n",
      "trainer/Z Policy Targets Mean         765.628\n",
      "trainer/Z Policy Targets Std          317.562\n",
      "trainer/Z Policy Targets Max          959.351\n",
      "trainer/Z Policy Targets Min         -506.554\n",
      "trainer/Log Pis Mean                   20.1823\n",
      "trainer/Log Pis Std                     3.90014\n",
      "trainer/Policy mu Mean                  0.0718647\n",
      "trainer/Policy mu Std                   1.07177\n",
      "trainer/Policy log std Mean            -3.16727\n",
      "trainer/Policy log std Std              0.989822\n",
      "trainer/Alpha                           0.130082\n",
      "trainer/Alpha Loss                     -0.0237094\n",
      "exploration/num steps total        187654\n",
      "exploration/num paths total           287\n",
      "evaluation/num steps total              1.59496e+06\n",
      "evaluation/num paths total           1885\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7722\n",
      "evaluation/Rewards Std                  1.00904\n",
      "evaluation/Rewards Max                  6.98425\n",
      "evaluation/Rewards Min                 -2.23794\n",
      "evaluation/Returns Mean              4772.2\n",
      "evaluation/Returns Std                101.815\n",
      "evaluation/Returns Max               4985.5\n",
      "evaluation/Returns Min               4622.46\n",
      "evaluation/Estimation Bias Mean       863.876\n",
      "evaluation/Estimation Bias Std        141.812\n",
      "evaluation/EB/Q_True Mean              43.6798\n",
      "evaluation/EB/Q_True Std              134.806\n",
      "evaluation/EB/Q_Pred Mean             907.556\n",
      "evaluation/EB/Q_Pred Std               54.8467\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4772.2\n",
      "evaluation/Actions Mean                 0.0279356\n",
      "evaluation/Actions Std                  0.535468\n",
      "evaluation/Actions Max                  0.999514\n",
      "evaluation/Actions Min                 -0.999387\n",
      "time/backward_policy (s)                2.0091\n",
      "time/backward_zf1 (s)                   2.14585\n",
      "time/backward_zf2 (s)                   2.10709\n",
      "time/data sampling (s)                  0.29464\n",
      "time/data storing (s)                   0.0159011\n",
      "time/evaluation sampling (s)            1.73194\n",
      "time/exploration sampling (s)           0.325915\n",
      "time/logging (s)                        0.0116735\n",
      "time/preback_alpha (s)                  1.05866\n",
      "time/preback_policy (s)                 1.20012\n",
      "time/preback_start (s)                  0.151076\n",
      "time/preback_zf (s)                     5.28983\n",
      "time/saving (s)                         0.0057644\n",
      "time/training (s)                       2.29221\n",
      "time/epoch (s)                         18.6398\n",
      "time/total (s)                       3286.95\n",
      "Epoch                                 183\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:47:20.213381 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 184 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 195000\n",
      "trainer/ZF1 Loss                        5.61547\n",
      "trainer/ZF2 Loss                        4.61672\n",
      "trainer/ZF Expert Reward               11.1094\n",
      "trainer/ZF Policy Reward                1.16485\n",
      "trainer/ZF CHI2 Term                   35.0127\n",
      "trainer/Policy Loss                  -786.571\n",
      "trainer/Bias Loss                      69.3958\n",
      "trainer/Bias Value                     14.0672\n",
      "trainer/Policy Grad Norm              133.7\n",
      "trainer/Policy Param Norm              35.6055\n",
      "trainer/Zf1 Grad Norm                1337.67\n",
      "trainer/Zf1 Param Norm                109.945\n",
      "trainer/Zf2 Grad Norm                1315.81\n",
      "trainer/Zf2 Param Norm                108.364\n",
      "trainer/Z Expert Predictions Mean     920.68\n",
      "trainer/Z Expert Predictions Std       39.357\n",
      "trainer/Z Expert Predictions Max      998.352\n",
      "trainer/Z Expert Predictions Min      639.547\n",
      "trainer/Z Policy Predictions Mean     782.41\n",
      "trainer/Z Policy Predictions Std      325.514\n",
      "trainer/Z Policy Predictions Max      973.932\n",
      "trainer/Z Policy Predictions Min     -522.36\n",
      "trainer/Z Expert Targets Mean         909.571\n",
      "trainer/Z Expert Targets Std           43.5299\n",
      "trainer/Z Expert Targets Max          988.976\n",
      "trainer/Z Expert Targets Min          591.266\n",
      "trainer/Z Policy Targets Mean         781.245\n",
      "trainer/Z Policy Targets Std          322.088\n",
      "trainer/Z Policy Targets Max          956.914\n",
      "trainer/Z Policy Targets Min         -513.822\n",
      "trainer/Log Pis Mean                   20.1536\n",
      "trainer/Log Pis Std                     4.47735\n",
      "trainer/Policy mu Mean                  0.066624\n",
      "trainer/Policy mu Std                   1.02063\n",
      "trainer/Policy log std Mean            -3.2521\n",
      "trainer/Policy log std Std              0.942625\n",
      "trainer/Alpha                           0.131177\n",
      "trainer/Alpha Loss                     -0.0201499\n",
      "exploration/num steps total        188654\n",
      "exploration/num paths total           288\n",
      "evaluation/num steps total              1.60496e+06\n",
      "evaluation/num paths total           1895\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66784\n",
      "evaluation/Rewards Std                  1.31672\n",
      "evaluation/Rewards Max                  6.942\n",
      "evaluation/Rewards Min                 -2.3277\n",
      "evaluation/Returns Mean              4667.84\n",
      "evaluation/Returns Std                292.237\n",
      "evaluation/Returns Max               4925.68\n",
      "evaluation/Returns Min               3846.41\n",
      "evaluation/Estimation Bias Mean       851.374\n",
      "evaluation/Estimation Bias Std        156.165\n",
      "evaluation/EB/Q_True Mean              42.1721\n",
      "evaluation/EB/Q_True Std              130.425\n",
      "evaluation/EB/Q_Pred Mean             893.546\n",
      "evaluation/EB/Q_Pred Std               92.2295\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4667.84\n",
      "evaluation/Actions Mean                 0.0183524\n",
      "evaluation/Actions Std                  0.554266\n",
      "evaluation/Actions Max                  0.999895\n",
      "evaluation/Actions Min                 -0.999813\n",
      "time/backward_policy (s)                1.87424\n",
      "time/backward_zf1 (s)                   2.00671\n",
      "time/backward_zf2 (s)                   1.91364\n",
      "time/data sampling (s)                  0.284229\n",
      "time/data storing (s)                   0.0151527\n",
      "time/evaluation sampling (s)            1.75391\n",
      "time/exploration sampling (s)           0.318063\n",
      "time/logging (s)                        0.0131687\n",
      "time/preback_alpha (s)                  0.966567\n",
      "time/preback_policy (s)                 1.0638\n",
      "time/preback_start (s)                  0.148508\n",
      "time/preback_zf (s)                     5.1931\n",
      "time/saving (s)                         0.00579077\n",
      "time/training (s)                       2.35946\n",
      "time/epoch (s)                         17.9163\n",
      "time/total (s)                       3304.89\n",
      "Epoch                                 184\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:47:38.108327 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 185 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 196000\n",
      "trainer/ZF1 Loss                      176.036\n",
      "trainer/ZF2 Loss                      160.849\n",
      "trainer/ZF Expert Reward               13.1078\n",
      "trainer/ZF Policy Reward                3.43018\n",
      "trainer/ZF CHI2 Term                  198.156\n",
      "trainer/Policy Loss                  -779.853\n",
      "trainer/Bias Loss                      57.9198\n",
      "trainer/Bias Value                     14.0772\n",
      "trainer/Policy Grad Norm              141.478\n",
      "trainer/Policy Param Norm              35.6403\n",
      "trainer/Zf1 Grad Norm                1482.83\n",
      "trainer/Zf1 Param Norm                110.154\n",
      "trainer/Zf2 Grad Norm                1537.45\n",
      "trainer/Zf2 Param Norm                108.549\n",
      "trainer/Z Expert Predictions Mean     922.737\n",
      "trainer/Z Expert Predictions Std       40.3348\n",
      "trainer/Z Expert Predictions Max      981.998\n",
      "trainer/Z Expert Predictions Min      646.038\n",
      "trainer/Z Policy Predictions Mean     777.991\n",
      "trainer/Z Policy Predictions Std      288.968\n",
      "trainer/Z Policy Predictions Max      967.802\n",
      "trainer/Z Policy Predictions Min     -550.813\n",
      "trainer/Z Expert Targets Mean         909.629\n",
      "trainer/Z Expert Targets Std           41.9443\n",
      "trainer/Z Expert Targets Max          973.401\n",
      "trainer/Z Expert Targets Min          644.705\n",
      "trainer/Z Policy Targets Mean         774.561\n",
      "trainer/Z Policy Targets Std          288.034\n",
      "trainer/Z Policy Targets Max          954.148\n",
      "trainer/Z Policy Targets Min         -536.126\n",
      "trainer/Log Pis Mean                   20.2379\n",
      "trainer/Log Pis Std                     3.8463\n",
      "trainer/Policy mu Mean                  0.0548243\n",
      "trainer/Policy mu Std                   1.02677\n",
      "trainer/Policy log std Mean            -3.23321\n",
      "trainer/Policy log std Std              0.892129\n",
      "trainer/Alpha                           0.131239\n",
      "trainer/Alpha Loss                     -0.0312218\n",
      "exploration/num steps total        190654\n",
      "exploration/num paths total           290\n",
      "evaluation/num steps total              1.61479e+06\n",
      "evaluation/num paths total           1905\n",
      "evaluation/path length Mean           982.7\n",
      "evaluation/path length Std             51.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            827\n",
      "evaluation/Rewards Mean                 4.6742\n",
      "evaluation/Rewards Std                  0.994384\n",
      "evaluation/Rewards Max                  6.75824\n",
      "evaluation/Rewards Min                 -1.6102\n",
      "evaluation/Returns Mean              4593.34\n",
      "evaluation/Returns Std                202.684\n",
      "evaluation/Returns Max               4776.92\n",
      "evaluation/Returns Min               4025.93\n",
      "evaluation/Estimation Bias Mean       851.958\n",
      "evaluation/Estimation Bias Std        142.586\n",
      "evaluation/EB/Q_True Mean              43.4508\n",
      "evaluation/EB/Q_True Std              132.351\n",
      "evaluation/EB/Q_Pred Mean             895.409\n",
      "evaluation/EB/Q_Pred Std               56.9196\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4593.34\n",
      "evaluation/Actions Mean                 0.0222881\n",
      "evaluation/Actions Std                  0.535006\n",
      "evaluation/Actions Max                  0.999738\n",
      "evaluation/Actions Min                 -0.999417\n",
      "time/backward_policy (s)                1.82756\n",
      "time/backward_zf1 (s)                   1.97391\n",
      "time/backward_zf2 (s)                   1.87469\n",
      "time/data sampling (s)                  0.29114\n",
      "time/data storing (s)                   0.0153261\n",
      "time/evaluation sampling (s)            1.74181\n",
      "time/exploration sampling (s)           0.324582\n",
      "time/logging (s)                        0.0130367\n",
      "time/preback_alpha (s)                  0.93218\n",
      "time/preback_policy (s)                 1.02115\n",
      "time/preback_start (s)                  0.147762\n",
      "time/preback_zf (s)                     5.19396\n",
      "time/saving (s)                         0.00656223\n",
      "time/training (s)                       2.4578\n",
      "time/epoch (s)                         17.8215\n",
      "time/total (s)                       3322.73\n",
      "Epoch                                 185\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:47:56.118530 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 186 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 197000\n",
      "trainer/ZF1 Loss                       13.636\n",
      "trainer/ZF2 Loss                        9.95406\n",
      "trainer/ZF Expert Reward               14.9359\n",
      "trainer/ZF Policy Reward                0.833615\n",
      "trainer/ZF CHI2 Term                   45.8945\n",
      "trainer/Policy Loss                  -780.733\n",
      "trainer/Bias Loss                     117.069\n",
      "trainer/Bias Value                     14.0898\n",
      "trainer/Policy Grad Norm              122.136\n",
      "trainer/Policy Param Norm              35.6724\n",
      "trainer/Zf1 Grad Norm                1351.11\n",
      "trainer/Zf1 Param Norm                110.349\n",
      "trainer/Zf2 Grad Norm                1269.27\n",
      "trainer/Zf2 Param Norm                108.72\n",
      "trainer/Z Expert Predictions Mean     918.205\n",
      "trainer/Z Expert Predictions Std       45.1936\n",
      "trainer/Z Expert Predictions Max      978.872\n",
      "trainer/Z Expert Predictions Min      547.309\n",
      "trainer/Z Policy Predictions Mean     777.318\n",
      "trainer/Z Policy Predictions Std      289.856\n",
      "trainer/Z Policy Predictions Max      958.201\n",
      "trainer/Z Policy Predictions Min     -501.854\n",
      "trainer/Z Expert Targets Mean         903.269\n",
      "trainer/Z Expert Targets Std           50.4349\n",
      "trainer/Z Expert Targets Max          969.998\n",
      "trainer/Z Expert Targets Min          526.723\n",
      "trainer/Z Policy Targets Mean         776.485\n",
      "trainer/Z Policy Targets Std          287.411\n",
      "trainer/Z Policy Targets Max          947.845\n",
      "trainer/Z Policy Targets Min         -514.652\n",
      "trainer/Log Pis Mean                   20.1991\n",
      "trainer/Log Pis Std                     3.93295\n",
      "trainer/Policy mu Mean                  0.0718986\n",
      "trainer/Policy mu Std                   1.0943\n",
      "trainer/Policy log std Mean            -3.18801\n",
      "trainer/Policy log std Std              0.95848\n",
      "trainer/Alpha                           0.132273\n",
      "trainer/Alpha Loss                     -0.0263348\n",
      "exploration/num steps total        192654\n",
      "exploration/num paths total           292\n",
      "evaluation/num steps total              1.624e+06\n",
      "evaluation/num paths total           1915\n",
      "evaluation/path length Mean           921.5\n",
      "evaluation/path length Std            235.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            215\n",
      "evaluation/Rewards Mean                 4.67662\n",
      "evaluation/Rewards Std                  1.13328\n",
      "evaluation/Rewards Max                  6.82967\n",
      "evaluation/Rewards Min                 -1.56899\n",
      "evaluation/Returns Mean              4309.51\n",
      "evaluation/Returns Std               1131.86\n",
      "evaluation/Returns Max               4778.13\n",
      "evaluation/Returns Min                928.035\n",
      "evaluation/Estimation Bias Mean       836.274\n",
      "evaluation/Estimation Bias Std        159.186\n",
      "evaluation/EB/Q_True Mean              46.7792\n",
      "evaluation/EB/Q_True Std              138.536\n",
      "evaluation/EB/Q_Pred Mean             883.053\n",
      "evaluation/EB/Q_Pred Std               74.3935\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4309.51\n",
      "evaluation/Actions Mean                 0.026409\n",
      "evaluation/Actions Std                  0.539297\n",
      "evaluation/Actions Max                  0.999501\n",
      "evaluation/Actions Min                 -0.999761\n",
      "time/backward_policy (s)                1.84231\n",
      "time/backward_zf1 (s)                   1.98385\n",
      "time/backward_zf2 (s)                   1.91381\n",
      "time/data sampling (s)                  0.302916\n",
      "time/data storing (s)                   0.0141933\n",
      "time/evaluation sampling (s)            1.81172\n",
      "time/exploration sampling (s)           0.323891\n",
      "time/logging (s)                        0.0136653\n",
      "time/preback_alpha (s)                  0.967567\n",
      "time/preback_policy (s)                 1.08163\n",
      "time/preback_start (s)                  0.146545\n",
      "time/preback_zf (s)                     5.2201\n",
      "time/saving (s)                         0.00801482\n",
      "time/training (s)                       2.31141\n",
      "time/epoch (s)                         17.9416\n",
      "time/total (s)                       3340.7\n",
      "Epoch                                 186\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:48:13.887006 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 187 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 198000\n",
      "trainer/ZF1 Loss                      106.028\n",
      "trainer/ZF2 Loss                      100.242\n",
      "trainer/ZF Expert Reward               17.5674\n",
      "trainer/ZF Policy Reward                5.79061\n",
      "trainer/ZF CHI2 Term                  134.176\n",
      "trainer/Policy Loss                  -731.985\n",
      "trainer/Bias Loss                     104.701\n",
      "trainer/Bias Value                     14.1009\n",
      "trainer/Policy Grad Norm              161.989\n",
      "trainer/Policy Param Norm              35.7044\n",
      "trainer/Zf1 Grad Norm                1709.31\n",
      "trainer/Zf1 Param Norm                110.53\n",
      "trainer/Zf2 Grad Norm                1823.65\n",
      "trainer/Zf2 Param Norm                108.891\n",
      "trainer/Z Expert Predictions Mean     914.737\n",
      "trainer/Z Expert Predictions Std       45.2209\n",
      "trainer/Z Expert Predictions Max      990.695\n",
      "trainer/Z Expert Predictions Min      641.835\n",
      "trainer/Z Policy Predictions Mean     730.303\n",
      "trainer/Z Policy Predictions Std      364.879\n",
      "trainer/Z Policy Predictions Max      977.857\n",
      "trainer/Z Policy Predictions Min     -539.384\n",
      "trainer/Z Expert Targets Mean         897.169\n",
      "trainer/Z Expert Targets Std           49.6029\n",
      "trainer/Z Expert Targets Max          972.287\n",
      "trainer/Z Expert Targets Min          617.599\n",
      "trainer/Z Policy Targets Mean         724.513\n",
      "trainer/Z Policy Targets Std          361.356\n",
      "trainer/Z Policy Targets Max          954.344\n",
      "trainer/Z Policy Targets Min         -533.963\n",
      "trainer/Log Pis Mean                   19.4592\n",
      "trainer/Log Pis Std                     4.4891\n",
      "trainer/Policy mu Mean                  0.0361318\n",
      "trainer/Policy mu Std                   1.06033\n",
      "trainer/Policy log std Mean            -3.13036\n",
      "trainer/Policy log std Std              1.00351\n",
      "trainer/Alpha                           0.132512\n",
      "trainer/Alpha Loss                      0.0716673\n",
      "exploration/num steps total        193654\n",
      "exploration/num paths total           293\n",
      "evaluation/num steps total              1.63373e+06\n",
      "evaluation/num paths total           1925\n",
      "evaluation/path length Mean           973\n",
      "evaluation/path length Std             81\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            730\n",
      "evaluation/Rewards Mean                 4.61209\n",
      "evaluation/Rewards Std                  1.03136\n",
      "evaluation/Rewards Max                  6.86084\n",
      "evaluation/Rewards Min                 -1.60286\n",
      "evaluation/Returns Mean              4487.57\n",
      "evaluation/Returns Std                375.982\n",
      "evaluation/Returns Max               4766.43\n",
      "evaluation/Returns Min               3398.16\n",
      "evaluation/Estimation Bias Mean       848.455\n",
      "evaluation/Estimation Bias Std        143.796\n",
      "evaluation/EB/Q_True Mean              43.187\n",
      "evaluation/EB/Q_True Std              131.358\n",
      "evaluation/EB/Q_Pred Mean             891.642\n",
      "evaluation/EB/Q_Pred Std               55.7075\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4487.57\n",
      "evaluation/Actions Mean                 0.0193474\n",
      "evaluation/Actions Std                  0.53734\n",
      "evaluation/Actions Max                  0.999669\n",
      "evaluation/Actions Min                 -0.999694\n",
      "time/backward_policy (s)                1.79099\n",
      "time/backward_zf1 (s)                   1.92007\n",
      "time/backward_zf2 (s)                   1.83913\n",
      "time/data sampling (s)                  0.301479\n",
      "time/data storing (s)                   0.0149724\n",
      "time/evaluation sampling (s)            1.73046\n",
      "time/exploration sampling (s)           0.323344\n",
      "time/logging (s)                        0.0121288\n",
      "time/preback_alpha (s)                  0.933776\n",
      "time/preback_policy (s)                 1.02544\n",
      "time/preback_start (s)                  0.145648\n",
      "time/preback_zf (s)                     5.20483\n",
      "time/saving (s)                         0.00624668\n",
      "time/training (s)                       2.44744\n",
      "time/epoch (s)                         17.696\n",
      "time/total (s)                       3358.41\n",
      "Epoch                                 187\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:48:31.817412 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 188 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 199000\n",
      "trainer/ZF1 Loss                       14.9535\n",
      "trainer/ZF2 Loss                        6.67511\n",
      "trainer/ZF Expert Reward               12.8237\n",
      "trainer/ZF Policy Reward                0.817557\n",
      "trainer/ZF CHI2 Term                   42.4583\n",
      "trainer/Policy Loss                  -713.052\n",
      "trainer/Bias Loss                      67.7652\n",
      "trainer/Bias Value                     14.1106\n",
      "trainer/Policy Grad Norm              111.242\n",
      "trainer/Policy Param Norm              35.7337\n",
      "trainer/Zf1 Grad Norm                1783.04\n",
      "trainer/Zf1 Param Norm                110.724\n",
      "trainer/Zf2 Grad Norm                1378.06\n",
      "trainer/Zf2 Param Norm                109.084\n",
      "trainer/Z Expert Predictions Mean     908.784\n",
      "trainer/Z Expert Predictions Std       42.1056\n",
      "trainer/Z Expert Predictions Max      968.304\n",
      "trainer/Z Expert Predictions Min      635.566\n",
      "trainer/Z Policy Predictions Mean     709.699\n",
      "trainer/Z Policy Predictions Std      391.248\n",
      "trainer/Z Policy Predictions Max      949.675\n",
      "trainer/Z Policy Predictions Min     -528.614\n",
      "trainer/Z Expert Targets Mean         895.96\n",
      "trainer/Z Expert Targets Std           44.222\n",
      "trainer/Z Expert Targets Max          953.541\n",
      "trainer/Z Expert Targets Min          615.755\n",
      "trainer/Z Policy Targets Mean         708.881\n",
      "trainer/Z Policy Targets Std          385.987\n",
      "trainer/Z Policy Targets Max          946.296\n",
      "trainer/Z Policy Targets Min         -532.317\n",
      "trainer/Log Pis Mean                   19.8362\n",
      "trainer/Log Pis Std                     4.29945\n",
      "trainer/Policy mu Mean                  0.104929\n",
      "trainer/Policy mu Std                   1.13885\n",
      "trainer/Policy log std Mean            -3.08468\n",
      "trainer/Policy log std Std              1.08644\n",
      "trainer/Alpha                           0.133448\n",
      "trainer/Alpha Loss                      0.0218629\n",
      "exploration/num steps total        194654\n",
      "exploration/num paths total           294\n",
      "evaluation/num steps total              1.6418e+06\n",
      "evaluation/num paths total           1935\n",
      "evaluation/path length Mean           806.9\n",
      "evaluation/path length Std            386.201\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             33\n",
      "evaluation/Rewards Mean                 4.70508\n",
      "evaluation/Rewards Std                  1.05808\n",
      "evaluation/Rewards Max                  6.78746\n",
      "evaluation/Rewards Min                 -1.60439\n",
      "evaluation/Returns Mean              3796.53\n",
      "evaluation/Returns Std               1870.74\n",
      "evaluation/Returns Max               4999.61\n",
      "evaluation/Returns Min                 57.8206\n",
      "evaluation/Estimation Bias Mean       831.123\n",
      "evaluation/Estimation Bias Std        158.383\n",
      "evaluation/EB/Q_True Mean              54.3044\n",
      "evaluation/EB/Q_True Std              148.162\n",
      "evaluation/EB/Q_Pred Mean             885.427\n",
      "evaluation/EB/Q_Pred Std               57.971\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3796.53\n",
      "evaluation/Actions Mean                 0.0206504\n",
      "evaluation/Actions Std                  0.538096\n",
      "evaluation/Actions Max                  0.999896\n",
      "evaluation/Actions Min                 -0.99931\n",
      "time/backward_policy (s)                1.88648\n",
      "time/backward_zf1 (s)                   2.0321\n",
      "time/backward_zf2 (s)                   1.95248\n",
      "time/data sampling (s)                  0.30277\n",
      "time/data storing (s)                   0.0145216\n",
      "time/evaluation sampling (s)            1.72424\n",
      "time/exploration sampling (s)           0.318001\n",
      "time/logging (s)                        0.0106338\n",
      "time/preback_alpha (s)                  0.999493\n",
      "time/preback_policy (s)                 1.10568\n",
      "time/preback_start (s)                  0.143875\n",
      "time/preback_zf (s)                     5.16686\n",
      "time/saving (s)                         0.00613205\n",
      "time/training (s)                       2.18275\n",
      "time/epoch (s)                         17.846\n",
      "time/total (s)                       3376.29\n",
      "Epoch                                 188\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:48:49.647304 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 189 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 200000\n",
      "trainer/ZF1 Loss                       12.9827\n",
      "trainer/ZF2 Loss                        9.68567\n",
      "trainer/ZF Expert Reward               16.2367\n",
      "trainer/ZF Policy Reward                4.33852\n",
      "trainer/ZF CHI2 Term                   43.1211\n",
      "trainer/Policy Loss                  -771.67\n",
      "trainer/Bias Loss                      67.3048\n",
      "trainer/Bias Value                     14.1218\n",
      "trainer/Policy Grad Norm              136.347\n",
      "trainer/Policy Param Norm              35.7667\n",
      "trainer/Zf1 Grad Norm                1166.75\n",
      "trainer/Zf1 Param Norm                110.913\n",
      "trainer/Zf2 Grad Norm                 944.235\n",
      "trainer/Zf2 Param Norm                109.256\n",
      "trainer/Z Expert Predictions Mean     908.183\n",
      "trainer/Z Expert Predictions Std       39.3567\n",
      "trainer/Z Expert Predictions Max      975.422\n",
      "trainer/Z Expert Predictions Min      674.503\n",
      "trainer/Z Policy Predictions Mean     770.073\n",
      "trainer/Z Policy Predictions Std      307.137\n",
      "trainer/Z Policy Predictions Max      945.477\n",
      "trainer/Z Policy Predictions Min     -530.039\n",
      "trainer/Z Expert Targets Mean         891.946\n",
      "trainer/Z Expert Targets Std           41.8929\n",
      "trainer/Z Expert Targets Max          960.475\n",
      "trainer/Z Expert Targets Min          650.761\n",
      "trainer/Z Policy Targets Mean         765.735\n",
      "trainer/Z Policy Targets Std          303.281\n",
      "trainer/Z Policy Targets Max          943.963\n",
      "trainer/Z Policy Targets Min         -506.785\n",
      "trainer/Log Pis Mean                   20.0896\n",
      "trainer/Log Pis Std                     4.00819\n",
      "trainer/Policy mu Mean                  0.0294585\n",
      "trainer/Policy mu Std                   0.968425\n",
      "trainer/Policy log std Mean            -3.25427\n",
      "trainer/Policy log std Std              0.88747\n",
      "trainer/Alpha                           0.133437\n",
      "trainer/Alpha Loss                     -0.0119586\n",
      "exploration/num steps total        195654\n",
      "exploration/num paths total           295\n",
      "evaluation/num steps total              1.65083e+06\n",
      "evaluation/num paths total           1945\n",
      "evaluation/path length Mean           903\n",
      "evaluation/path length Std            291\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             30\n",
      "evaluation/Rewards Mean                 4.61867\n",
      "evaluation/Rewards Std                  1.02659\n",
      "evaluation/Rewards Max                  6.75881\n",
      "evaluation/Rewards Min                 -1.61896\n",
      "evaluation/Returns Mean              4170.66\n",
      "evaluation/Returns Std               1379.73\n",
      "evaluation/Returns Max               4800.75\n",
      "evaluation/Returns Min                 51.6219\n",
      "evaluation/Estimation Bias Mean       837.656\n",
      "evaluation/Estimation Bias Std        154.993\n",
      "evaluation/EB/Q_True Mean              47.531\n",
      "evaluation/EB/Q_True Std              138.785\n",
      "evaluation/EB/Q_Pred Mean             885.187\n",
      "evaluation/EB/Q_Pred Std               59.1916\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4170.66\n",
      "evaluation/Actions Mean                 0.0208096\n",
      "evaluation/Actions Std                  0.543093\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999565\n",
      "time/backward_policy (s)                1.80707\n",
      "time/backward_zf1 (s)                   1.94619\n",
      "time/backward_zf2 (s)                   1.86581\n",
      "time/data sampling (s)                  0.296745\n",
      "time/data storing (s)                   0.014064\n",
      "time/evaluation sampling (s)            1.73824\n",
      "time/exploration sampling (s)           0.31303\n",
      "time/logging (s)                        0.0114673\n",
      "time/preback_alpha (s)                  0.939877\n",
      "time/preback_policy (s)                 1.03563\n",
      "time/preback_start (s)                  0.1441\n",
      "time/preback_zf (s)                     5.21713\n",
      "time/saving (s)                         0.00601959\n",
      "time/training (s)                       2.42778\n",
      "time/epoch (s)                         17.7632\n",
      "time/total (s)                       3394.08\n",
      "Epoch                                 189\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:49:07.904229 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 190 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 201000\n",
      "trainer/ZF1 Loss                       -0.165077\n",
      "trainer/ZF2 Loss                       -1.95618\n",
      "trainer/ZF Expert Reward               15.5322\n",
      "trainer/ZF Policy Reward               -0.0366808\n",
      "trainer/ZF CHI2 Term                   34.2144\n",
      "trainer/Policy Loss                  -764.543\n",
      "trainer/Bias Loss                      66.6909\n",
      "trainer/Bias Value                     14.1368\n",
      "trainer/Policy Grad Norm              126.017\n",
      "trainer/Policy Param Norm              35.8015\n",
      "trainer/Zf1 Grad Norm                 880.861\n",
      "trainer/Zf1 Param Norm                111.106\n",
      "trainer/Zf2 Grad Norm                1110.7\n",
      "trainer/Zf2 Param Norm                109.419\n",
      "trainer/Z Expert Predictions Mean     902.345\n",
      "trainer/Z Expert Predictions Std       45.296\n",
      "trainer/Z Expert Predictions Max      979.376\n",
      "trainer/Z Expert Predictions Min      652.838\n",
      "trainer/Z Policy Predictions Mean     763.166\n",
      "trainer/Z Policy Predictions Std      304.213\n",
      "trainer/Z Policy Predictions Max      943.922\n",
      "trainer/Z Policy Predictions Min     -541.251\n",
      "trainer/Z Expert Targets Mean         886.813\n",
      "trainer/Z Expert Targets Std           46.5294\n",
      "trainer/Z Expert Targets Max          958.783\n",
      "trainer/Z Expert Targets Min          637.71\n",
      "trainer/Z Policy Targets Mean         763.203\n",
      "trainer/Z Policy Targets Std          298.624\n",
      "trainer/Z Policy Targets Max          939.033\n",
      "trainer/Z Policy Targets Min         -510.446\n",
      "trainer/Log Pis Mean                   19.9052\n",
      "trainer/Log Pis Std                     4.29906\n",
      "trainer/Policy mu Mean                  0.0932351\n",
      "trainer/Policy mu Std                   1.02022\n",
      "trainer/Policy log std Mean            -3.26547\n",
      "trainer/Policy log std Std              0.921434\n",
      "trainer/Alpha                           0.134434\n",
      "trainer/Alpha Loss                      0.01274\n",
      "exploration/num steps total        196654\n",
      "exploration/num paths total           296\n",
      "evaluation/num steps total              1.65903e+06\n",
      "evaluation/num paths total           1955\n",
      "evaluation/path length Mean           820.2\n",
      "evaluation/path length Std            360.44\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             46\n",
      "evaluation/Rewards Mean                 4.19657\n",
      "evaluation/Rewards Std                  2.05763\n",
      "evaluation/Rewards Max                  6.90189\n",
      "evaluation/Rewards Min                 -3.72996\n",
      "evaluation/Returns Mean              3442.03\n",
      "evaluation/Returns Std               1985.58\n",
      "evaluation/Returns Max               4803.99\n",
      "evaluation/Returns Min                134.912\n",
      "evaluation/Estimation Bias Mean       776.565\n",
      "evaluation/Estimation Bias Std        344.183\n",
      "evaluation/EB/Q_True Mean               3.08729\n",
      "evaluation/EB/Q_True Std               91.702\n",
      "evaluation/EB/Q_Pred Mean             779.652\n",
      "evaluation/EB/Q_Pred Std              330.068\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3442.03\n",
      "evaluation/Actions Mean                 0.0460916\n",
      "evaluation/Actions Std                  0.568655\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99997\n",
      "time/backward_policy (s)                1.9345\n",
      "time/backward_zf1 (s)                   2.09779\n",
      "time/backward_zf2 (s)                   2.02672\n",
      "time/data sampling (s)                  0.308033\n",
      "time/data storing (s)                   0.0158658\n",
      "time/evaluation sampling (s)            1.71545\n",
      "time/exploration sampling (s)           0.334723\n",
      "time/logging (s)                        0.0101081\n",
      "time/preback_alpha (s)                  1.03366\n",
      "time/preback_policy (s)                 1.17089\n",
      "time/preback_start (s)                  0.148949\n",
      "time/preback_zf (s)                     5.21271\n",
      "time/saving (s)                         0.00606729\n",
      "time/training (s)                       2.16874\n",
      "time/epoch (s)                         18.1842\n",
      "time/total (s)                       3412.28\n",
      "Epoch                                 190\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:49:26.478978 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 191 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 202000\n",
      "trainer/ZF1 Loss                       13.5621\n",
      "trainer/ZF2 Loss                       10.744\n",
      "trainer/ZF Expert Reward               11.2019\n",
      "trainer/ZF Policy Reward                3.34818\n",
      "trainer/ZF CHI2 Term                   39.3625\n",
      "trainer/Policy Loss                  -733.959\n",
      "trainer/Bias Loss                      63.2824\n",
      "trainer/Bias Value                     14.1495\n",
      "trainer/Policy Grad Norm              130.336\n",
      "trainer/Policy Param Norm              35.8345\n",
      "trainer/Zf1 Grad Norm                1164.99\n",
      "trainer/Zf1 Param Norm                111.288\n",
      "trainer/Zf2 Grad Norm                1319.79\n",
      "trainer/Zf2 Param Norm                109.6\n",
      "trainer/Z Expert Predictions Mean     896.131\n",
      "trainer/Z Expert Predictions Std       66.0723\n",
      "trainer/Z Expert Predictions Max      964.334\n",
      "trainer/Z Expert Predictions Min        7.74309\n",
      "trainer/Z Policy Predictions Mean     732.538\n",
      "trainer/Z Policy Predictions Std      366.476\n",
      "trainer/Z Policy Predictions Max      957.558\n",
      "trainer/Z Policy Predictions Min     -547.466\n",
      "trainer/Z Expert Targets Mean         884.929\n",
      "trainer/Z Expert Targets Std           67.8462\n",
      "trainer/Z Expert Targets Max          945.085\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         729.189\n",
      "trainer/Z Policy Targets Std          361.216\n",
      "trainer/Z Policy Targets Max          939.534\n",
      "trainer/Z Policy Targets Min         -528.621\n",
      "trainer/Log Pis Mean                   19.5513\n",
      "trainer/Log Pis Std                     4.25414\n",
      "trainer/Policy mu Mean                  0.0813054\n",
      "trainer/Policy mu Std                   1.00949\n",
      "trainer/Policy log std Mean            -3.18823\n",
      "trainer/Policy log std Std              0.974035\n",
      "trainer/Alpha                           0.136105\n",
      "trainer/Alpha Loss                      0.0610729\n",
      "exploration/num steps total        196654\n",
      "exploration/num paths total           296\n",
      "evaluation/num steps total              1.66843e+06\n",
      "evaluation/num paths total           1965\n",
      "evaluation/path length Mean           939.8\n",
      "evaluation/path length Std            180.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            398\n",
      "evaluation/Rewards Mean                 4.7017\n",
      "evaluation/Rewards Std                  1.08832\n",
      "evaluation/Rewards Max                  6.75378\n",
      "evaluation/Rewards Min                 -1.70334\n",
      "evaluation/Returns Mean              4418.66\n",
      "evaluation/Returns Std                905.701\n",
      "evaluation/Returns Max               4842.67\n",
      "evaluation/Returns Min               1720.77\n",
      "evaluation/Estimation Bias Mean       832.491\n",
      "evaluation/Estimation Bias Std        154.718\n",
      "evaluation/EB/Q_True Mean              44.4415\n",
      "evaluation/EB/Q_True Std              132.641\n",
      "evaluation/EB/Q_Pred Mean             876.932\n",
      "evaluation/EB/Q_Pred Std               61.6977\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4418.66\n",
      "evaluation/Actions Mean                 0.0286275\n",
      "evaluation/Actions Std                  0.545097\n",
      "evaluation/Actions Max                  0.99937\n",
      "evaluation/Actions Min                 -0.999677\n",
      "time/backward_policy (s)                2.02824\n",
      "time/backward_zf1 (s)                   2.19101\n",
      "time/backward_zf2 (s)                   2.10866\n",
      "time/data sampling (s)                  0.306043\n",
      "time/data storing (s)                   0.0159217\n",
      "time/evaluation sampling (s)            1.74377\n",
      "time/exploration sampling (s)           0.324827\n",
      "time/logging (s)                        0.0113934\n",
      "time/preback_alpha (s)                  1.04981\n",
      "time/preback_policy (s)                 1.21431\n",
      "time/preback_start (s)                  0.146706\n",
      "time/preback_zf (s)                     5.23308\n",
      "time/saving (s)                         0.00610395\n",
      "time/training (s)                       2.12823\n",
      "time/epoch (s)                         18.5081\n",
      "time/total (s)                       3430.81\n",
      "Epoch                                 191\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:49:44.234223 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 192 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 203000\n",
      "trainer/ZF1 Loss                       45.2764\n",
      "trainer/ZF2 Loss                       21.1026\n",
      "trainer/ZF Expert Reward               12.639\n",
      "trainer/ZF Policy Reward                1.73193\n",
      "trainer/ZF CHI2 Term                   64.2673\n",
      "trainer/Policy Loss                  -772.003\n",
      "trainer/Bias Loss                      65.3608\n",
      "trainer/Bias Value                     14.1635\n",
      "trainer/Policy Grad Norm              158.284\n",
      "trainer/Policy Param Norm              35.8641\n",
      "trainer/Zf1 Grad Norm                6593.09\n",
      "trainer/Zf1 Param Norm                111.453\n",
      "trainer/Zf2 Grad Norm                1564.94\n",
      "trainer/Zf2 Param Norm                109.777\n",
      "trainer/Z Expert Predictions Mean     893.386\n",
      "trainer/Z Expert Predictions Std       43.4891\n",
      "trainer/Z Expert Predictions Max      957.762\n",
      "trainer/Z Expert Predictions Min      693.482\n",
      "trainer/Z Policy Predictions Mean     770.968\n",
      "trainer/Z Policy Predictions Std      280.378\n",
      "trainer/Z Policy Predictions Max      959.646\n",
      "trainer/Z Policy Predictions Min     -525.347\n",
      "trainer/Z Expert Targets Mean         880.747\n",
      "trainer/Z Expert Targets Std           46.6845\n",
      "trainer/Z Expert Targets Max          946.567\n",
      "trainer/Z Expert Targets Min          636.791\n",
      "trainer/Z Policy Targets Mean         769.236\n",
      "trainer/Z Policy Targets Std          275.434\n",
      "trainer/Z Policy Targets Max          939.521\n",
      "trainer/Z Policy Targets Min         -527.283\n",
      "trainer/Log Pis Mean                   20.3745\n",
      "trainer/Log Pis Std                     3.87182\n",
      "trainer/Policy mu Mean                  0.0627593\n",
      "trainer/Policy mu Std                   1.04265\n",
      "trainer/Policy log std Mean            -3.26818\n",
      "trainer/Policy log std Std              0.910193\n",
      "trainer/Alpha                           0.13571\n",
      "trainer/Alpha Loss                     -0.0508168\n",
      "exploration/num steps total        197654\n",
      "exploration/num paths total           297\n",
      "evaluation/num steps total              1.67843e+06\n",
      "evaluation/num paths total           1975\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.22726\n",
      "evaluation/Rewards Std                  2.07078\n",
      "evaluation/Rewards Max                  6.85858\n",
      "evaluation/Rewards Min                 -3.66502\n",
      "evaluation/Returns Mean              4227.26\n",
      "evaluation/Returns Std               1449.38\n",
      "evaluation/Returns Max               4905.98\n",
      "evaluation/Returns Min               -112.992\n",
      "evaluation/Estimation Bias Mean       746.135\n",
      "evaluation/Estimation Bias Std        322.289\n",
      "evaluation/EB/Q_True Mean              42.0305\n",
      "evaluation/EB/Q_True Std              129.218\n",
      "evaluation/EB/Q_Pred Mean             788.165\n",
      "evaluation/EB/Q_Pred Std              306.807\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4227.26\n",
      "evaluation/Actions Mean                 0.0389278\n",
      "evaluation/Actions Std                  0.579197\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.80095\n",
      "time/backward_zf1 (s)                   1.93103\n",
      "time/backward_zf2 (s)                   1.86101\n",
      "time/data sampling (s)                  0.300388\n",
      "time/data storing (s)                   0.015524\n",
      "time/evaluation sampling (s)            1.7525\n",
      "time/exploration sampling (s)           0.334478\n",
      "time/logging (s)                        0.0121318\n",
      "time/preback_alpha (s)                  0.940637\n",
      "time/preback_policy (s)                 1.03672\n",
      "time/preback_start (s)                  0.144112\n",
      "time/preback_zf (s)                     5.15071\n",
      "time/saving (s)                         0.00640219\n",
      "time/training (s)                       2.40337\n",
      "time/epoch (s)                         17.69\n",
      "time/total (s)                       3448.52\n",
      "Epoch                                 192\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:50:02.306374 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 193 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 204000\n",
      "trainer/ZF1 Loss                       46.7299\n",
      "trainer/ZF2 Loss                       24.7778\n",
      "trainer/ZF Expert Reward               15.5575\n",
      "trainer/ZF Policy Reward                4.45341\n",
      "trainer/ZF CHI2 Term                   67.1936\n",
      "trainer/Policy Loss                  -791.797\n",
      "trainer/Bias Loss                     222.51\n",
      "trainer/Bias Value                     14.1743\n",
      "trainer/Policy Grad Norm              139.399\n",
      "trainer/Policy Param Norm              35.8989\n",
      "trainer/Zf1 Grad Norm                7521.82\n",
      "trainer/Zf1 Param Norm                111.644\n",
      "trainer/Zf2 Grad Norm                3336.11\n",
      "trainer/Zf2 Param Norm                109.937\n",
      "trainer/Z Expert Predictions Mean     884.883\n",
      "trainer/Z Expert Predictions Std       79.7163\n",
      "trainer/Z Expert Predictions Max      961.95\n",
      "trainer/Z Expert Predictions Min       36.6455\n",
      "trainer/Z Policy Predictions Mean     792.415\n",
      "trainer/Z Policy Predictions Std      214.424\n",
      "trainer/Z Policy Predictions Max      937.649\n",
      "trainer/Z Policy Predictions Min     -492.207\n",
      "trainer/Z Expert Targets Mean         869.326\n",
      "trainer/Z Expert Targets Std           91.5107\n",
      "trainer/Z Expert Targets Max          941.358\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         787.962\n",
      "trainer/Z Policy Targets Std          210.211\n",
      "trainer/Z Policy Targets Max          934.323\n",
      "trainer/Z Policy Targets Min         -463.902\n",
      "trainer/Log Pis Mean                   20.5411\n",
      "trainer/Log Pis Std                     3.96351\n",
      "trainer/Policy mu Mean                  0.0401025\n",
      "trainer/Policy mu Std                   0.936321\n",
      "trainer/Policy log std Mean            -3.3768\n",
      "trainer/Policy log std Std              0.830136\n",
      "trainer/Alpha                           0.137227\n",
      "trainer/Alpha Loss                     -0.0742474\n",
      "exploration/num steps total        197654\n",
      "exploration/num paths total           297\n",
      "evaluation/num steps total              1.6881e+06\n",
      "evaluation/num paths total           1985\n",
      "evaluation/path length Mean           966.8\n",
      "evaluation/path length Std             99.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            668\n",
      "evaluation/Rewards Mean                 4.68305\n",
      "evaluation/Rewards Std                  1.03745\n",
      "evaluation/Rewards Max                  6.76461\n",
      "evaluation/Rewards Min                 -1.87508\n",
      "evaluation/Returns Mean              4527.58\n",
      "evaluation/Returns Std                503.18\n",
      "evaluation/Returns Max               4842.27\n",
      "evaluation/Returns Min               3033.48\n",
      "evaluation/Estimation Bias Mean       821.278\n",
      "evaluation/Estimation Bias Std        146.91\n",
      "evaluation/EB/Q_True Mean              44.1214\n",
      "evaluation/EB/Q_True Std              133.563\n",
      "evaluation/EB/Q_Pred Mean             865.399\n",
      "evaluation/EB/Q_Pred Std               59.6606\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4527.58\n",
      "evaluation/Actions Mean                 0.0180026\n",
      "evaluation/Actions Std                  0.540453\n",
      "evaluation/Actions Max                  0.999658\n",
      "evaluation/Actions Min                 -0.999296\n",
      "time/backward_policy (s)                1.94902\n",
      "time/backward_zf1 (s)                   2.07847\n",
      "time/backward_zf2 (s)                   2.00852\n",
      "time/data sampling (s)                  0.302911\n",
      "time/data storing (s)                   0.0150819\n",
      "time/evaluation sampling (s)            1.727\n",
      "time/exploration sampling (s)           0.318799\n",
      "time/logging (s)                        0.0112802\n",
      "time/preback_alpha (s)                  1.03392\n",
      "time/preback_policy (s)                 1.16825\n",
      "time/preback_start (s)                  0.144243\n",
      "time/preback_zf (s)                     5.1694\n",
      "time/saving (s)                         0.00578646\n",
      "time/training (s)                       2.07104\n",
      "time/epoch (s)                         18.0037\n",
      "time/total (s)                       3466.54\n",
      "Epoch                                 193\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:50:20.618973 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 194 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 205000\n",
      "trainer/ZF1 Loss                        8.83267\n",
      "trainer/ZF2 Loss                        9.6207\n",
      "trainer/ZF Expert Reward               14.235\n",
      "trainer/ZF Policy Reward                2.13311\n",
      "trainer/ZF CHI2 Term                   41.3358\n",
      "trainer/Policy Loss                  -763.338\n",
      "trainer/Bias Loss                      70.2848\n",
      "trainer/Bias Value                     14.1853\n",
      "trainer/Policy Grad Norm              130.912\n",
      "trainer/Policy Param Norm              35.9287\n",
      "trainer/Zf1 Grad Norm                1693.05\n",
      "trainer/Zf1 Param Norm                111.83\n",
      "trainer/Zf2 Grad Norm                1181.09\n",
      "trainer/Zf2 Param Norm                110.111\n",
      "trainer/Z Expert Predictions Mean     883.928\n",
      "trainer/Z Expert Predictions Std       46.0422\n",
      "trainer/Z Expert Predictions Max      952.576\n",
      "trainer/Z Expert Predictions Min      639.36\n",
      "trainer/Z Policy Predictions Mean     759.442\n",
      "trainer/Z Policy Predictions Std      286.299\n",
      "trainer/Z Policy Predictions Max      940.298\n",
      "trainer/Z Policy Predictions Min     -525.525\n",
      "trainer/Z Expert Targets Mean         869.693\n",
      "trainer/Z Expert Targets Std           45.7759\n",
      "trainer/Z Expert Targets Max          938.862\n",
      "trainer/Z Expert Targets Min          621.71\n",
      "trainer/Z Policy Targets Mean         757.309\n",
      "trainer/Z Policy Targets Std          281.791\n",
      "trainer/Z Policy Targets Max          928.683\n",
      "trainer/Z Policy Targets Min         -523.223\n",
      "trainer/Log Pis Mean                   20.2093\n",
      "trainer/Log Pis Std                     3.89331\n",
      "trainer/Policy mu Mean                  0.0548966\n",
      "trainer/Policy mu Std                   1.03862\n",
      "trainer/Policy log std Mean            -3.2279\n",
      "trainer/Policy log std Std              0.924607\n",
      "trainer/Alpha                           0.138162\n",
      "trainer/Alpha Loss                     -0.0289225\n",
      "exploration/num steps total        198654\n",
      "exploration/num paths total           298\n",
      "evaluation/num steps total              1.6981e+06\n",
      "evaluation/num paths total           1995\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.76709\n",
      "evaluation/Rewards Std                  1.10675\n",
      "evaluation/Rewards Max                  7.05233\n",
      "evaluation/Rewards Min                 -2.87555\n",
      "evaluation/Returns Mean              4767.09\n",
      "evaluation/Returns Std                143.75\n",
      "evaluation/Returns Max               4895.9\n",
      "evaluation/Returns Min               4388.86\n",
      "evaluation/Estimation Bias Mean       818.643\n",
      "evaluation/Estimation Bias Std        149.223\n",
      "evaluation/EB/Q_True Mean              44.0384\n",
      "evaluation/EB/Q_True Std              135.71\n",
      "evaluation/EB/Q_Pred Mean             862.681\n",
      "evaluation/EB/Q_Pred Std               67.6013\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4767.09\n",
      "evaluation/Actions Mean                 0.0268793\n",
      "evaluation/Actions Std                  0.535682\n",
      "evaluation/Actions Max                  0.999713\n",
      "evaluation/Actions Min                 -0.999937\n",
      "time/backward_policy (s)                1.95044\n",
      "time/backward_zf1 (s)                   2.08259\n",
      "time/backward_zf2 (s)                   2.02976\n",
      "time/data sampling (s)                  0.295619\n",
      "time/data storing (s)                   0.0160781\n",
      "time/evaluation sampling (s)            1.76116\n",
      "time/exploration sampling (s)           0.328326\n",
      "time/logging (s)                        0.0123107\n",
      "time/preback_alpha (s)                  1.02495\n",
      "time/preback_policy (s)                 1.16347\n",
      "time/preback_start (s)                  0.146566\n",
      "time/preback_zf (s)                     5.25053\n",
      "time/saving (s)                         0.0187893\n",
      "time/training (s)                       2.16485\n",
      "time/epoch (s)                         18.2454\n",
      "time/total (s)                       3484.81\n",
      "Epoch                                 194\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:50:38.929522 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 195 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 206000\n",
      "trainer/ZF1 Loss                        2.08484\n",
      "trainer/ZF2 Loss                       -2.18069\n",
      "trainer/ZF Expert Reward               13.8303\n",
      "trainer/ZF Policy Reward                0.896903\n",
      "trainer/ZF CHI2 Term                   32.372\n",
      "trainer/Policy Loss                  -747.028\n",
      "trainer/Bias Loss                      46.6183\n",
      "trainer/Bias Value                     14.1966\n",
      "trainer/Policy Grad Norm              129.524\n",
      "trainer/Policy Param Norm              35.9585\n",
      "trainer/Zf1 Grad Norm                1254.6\n",
      "trainer/Zf1 Param Norm                112.005\n",
      "trainer/Zf2 Grad Norm                1168.52\n",
      "trainer/Zf2 Param Norm                110.29\n",
      "trainer/Z Expert Predictions Mean     883.896\n",
      "trainer/Z Expert Predictions Std       65.2563\n",
      "trainer/Z Expert Predictions Max      955.497\n",
      "trainer/Z Expert Predictions Min       -2.30657\n",
      "trainer/Z Policy Predictions Mean     746.923\n",
      "trainer/Z Policy Predictions Std      300.328\n",
      "trainer/Z Policy Predictions Max      935.96\n",
      "trainer/Z Policy Predictions Min     -556.545\n",
      "trainer/Z Expert Targets Mean         870.065\n",
      "trainer/Z Expert Targets Std           64.3655\n",
      "trainer/Z Expert Targets Max          930.685\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         746.026\n",
      "trainer/Z Policy Targets Std          296.244\n",
      "trainer/Z Policy Targets Max          909.538\n",
      "trainer/Z Policy Targets Min         -535.571\n",
      "trainer/Log Pis Mean                   19.6833\n",
      "trainer/Log Pis Std                     4.27466\n",
      "trainer/Policy mu Mean                  0.0977557\n",
      "trainer/Policy mu Std                   0.963766\n",
      "trainer/Policy log std Mean            -3.2513\n",
      "trainer/Policy log std Std              0.937028\n",
      "trainer/Alpha                           0.138356\n",
      "trainer/Alpha Loss                      0.0438143\n",
      "exploration/num steps total        200654\n",
      "exploration/num paths total           300\n",
      "evaluation/num steps total              1.7081e+06\n",
      "evaluation/num paths total           2005\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7012\n",
      "evaluation/Rewards Std                  1.04982\n",
      "evaluation/Rewards Max                  6.74108\n",
      "evaluation/Rewards Min                 -1.68034\n",
      "evaluation/Returns Mean              4701.2\n",
      "evaluation/Returns Std                118.211\n",
      "evaluation/Returns Max               4845.63\n",
      "evaluation/Returns Min               4482.38\n",
      "evaluation/Estimation Bias Mean       819.638\n",
      "evaluation/Estimation Bias Std        147.785\n",
      "evaluation/EB/Q_True Mean              42.4151\n",
      "evaluation/EB/Q_True Std              130.513\n",
      "evaluation/EB/Q_Pred Mean             862.053\n",
      "evaluation/EB/Q_Pred Std               59.9753\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4701.2\n",
      "evaluation/Actions Mean                 0.0179255\n",
      "evaluation/Actions Std                  0.546188\n",
      "evaluation/Actions Max                  0.999686\n",
      "evaluation/Actions Min                 -0.999495\n",
      "time/backward_policy (s)                1.97289\n",
      "time/backward_zf1 (s)                   2.10656\n",
      "time/backward_zf2 (s)                   2.04753\n",
      "time/data sampling (s)                  0.305698\n",
      "time/data storing (s)                   0.0159383\n",
      "time/evaluation sampling (s)            1.7376\n",
      "time/exploration sampling (s)           0.334554\n",
      "time/logging (s)                        0.0119819\n",
      "time/preback_alpha (s)                  1.03359\n",
      "time/preback_policy (s)                 1.17766\n",
      "time/preback_start (s)                  0.146274\n",
      "time/preback_zf (s)                     5.20514\n",
      "time/saving (s)                         0.00600645\n",
      "time/training (s)                       2.14121\n",
      "time/epoch (s)                         18.2426\n",
      "time/total (s)                       3503.07\n",
      "Epoch                                 195\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:50:57.523908 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 196 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 207000\n",
      "trainer/ZF1 Loss                       12.2118\n",
      "trainer/ZF2 Loss                       10.5421\n",
      "trainer/ZF Expert Reward               18.4644\n",
      "trainer/ZF Policy Reward                6.02792\n",
      "trainer/ZF CHI2 Term                   43.7943\n",
      "trainer/Policy Loss                  -760.896\n",
      "trainer/Bias Loss                      55.4266\n",
      "trainer/Bias Value                     14.2093\n",
      "trainer/Policy Grad Norm              139.996\n",
      "trainer/Policy Param Norm              35.9882\n",
      "trainer/Zf1 Grad Norm                1962.05\n",
      "trainer/Zf1 Param Norm                112.195\n",
      "trainer/Zf2 Grad Norm                1282.8\n",
      "trainer/Zf2 Param Norm                110.461\n",
      "trainer/Z Expert Predictions Mean     883.749\n",
      "trainer/Z Expert Predictions Std       41.9147\n",
      "trainer/Z Expert Predictions Max      945.719\n",
      "trainer/Z Expert Predictions Min      585.493\n",
      "trainer/Z Policy Predictions Mean     758.939\n",
      "trainer/Z Policy Predictions Std      265.671\n",
      "trainer/Z Policy Predictions Max      928.696\n",
      "trainer/Z Policy Predictions Min     -506.83\n",
      "trainer/Z Expert Targets Mean         865.284\n",
      "trainer/Z Expert Targets Std           42.959\n",
      "trainer/Z Expert Targets Max          928.687\n",
      "trainer/Z Expert Targets Min          555.703\n",
      "trainer/Z Policy Targets Mean         752.911\n",
      "trainer/Z Policy Targets Std          261.038\n",
      "trainer/Z Policy Targets Max          920.879\n",
      "trainer/Z Policy Targets Min         -503.674\n",
      "trainer/Log Pis Mean                   20.1827\n",
      "trainer/Log Pis Std                     3.53526\n",
      "trainer/Policy mu Mean                  0.036312\n",
      "trainer/Policy mu Std                   0.988131\n",
      "trainer/Policy log std Mean            -3.27655\n",
      "trainer/Policy log std Std              0.909189\n",
      "trainer/Alpha                           0.138095\n",
      "trainer/Alpha Loss                     -0.0252272\n",
      "exploration/num steps total        202654\n",
      "exploration/num paths total           302\n",
      "evaluation/num steps total              1.71789e+06\n",
      "evaluation/num paths total           2015\n",
      "evaluation/path length Mean           979.3\n",
      "evaluation/path length Std             62.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            793\n",
      "evaluation/Rewards Mean                 4.67663\n",
      "evaluation/Rewards Std                  1.06971\n",
      "evaluation/Rewards Max                  6.70723\n",
      "evaluation/Rewards Min                 -2.17589\n",
      "evaluation/Returns Mean              4579.82\n",
      "evaluation/Returns Std                294.535\n",
      "evaluation/Returns Max               4872.57\n",
      "evaluation/Returns Min               3777.21\n",
      "evaluation/Estimation Bias Mean       808.373\n",
      "evaluation/Estimation Bias Std        157.582\n",
      "evaluation/EB/Q_True Mean              45.6957\n",
      "evaluation/EB/Q_True Std              139.833\n",
      "evaluation/EB/Q_Pred Mean             854.069\n",
      "evaluation/EB/Q_Pred Std               64.9581\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4579.82\n",
      "evaluation/Actions Mean                 0.0220828\n",
      "evaluation/Actions Std                  0.538579\n",
      "evaluation/Actions Max                  0.999808\n",
      "evaluation/Actions Min                 -0.999713\n",
      "time/backward_policy (s)                2.02082\n",
      "time/backward_zf1 (s)                   2.14724\n",
      "time/backward_zf2 (s)                   2.08695\n",
      "time/data sampling (s)                  0.310873\n",
      "time/data storing (s)                   0.0159671\n",
      "time/evaluation sampling (s)            1.78023\n",
      "time/exploration sampling (s)           0.333773\n",
      "time/logging (s)                        0.0118743\n",
      "time/preback_alpha (s)                  1.05212\n",
      "time/preback_policy (s)                 1.20314\n",
      "time/preback_start (s)                  0.148129\n",
      "time/preback_zf (s)                     5.24061\n",
      "time/saving (s)                         0.00791143\n",
      "time/training (s)                       2.16478\n",
      "time/epoch (s)                         18.5244\n",
      "time/total (s)                       3521.61\n",
      "Epoch                                 196\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:51:15.698853 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 197 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 208000\n",
      "trainer/ZF1 Loss                        9.92984\n",
      "trainer/ZF2 Loss                        9.55621\n",
      "trainer/ZF Expert Reward               15.6386\n",
      "trainer/ZF Policy Reward                4.53032\n",
      "trainer/ZF CHI2 Term                   40.4826\n",
      "trainer/Policy Loss                  -736.026\n",
      "trainer/Bias Loss                      63.4135\n",
      "trainer/Bias Value                     14.2218\n",
      "trainer/Policy Grad Norm              118.763\n",
      "trainer/Policy Param Norm              36.0166\n",
      "trainer/Zf1 Grad Norm                1055.75\n",
      "trainer/Zf1 Param Norm                112.342\n",
      "trainer/Zf2 Grad Norm                1208.37\n",
      "trainer/Zf2 Param Norm                110.614\n",
      "trainer/Z Expert Predictions Mean     877.758\n",
      "trainer/Z Expert Predictions Std       37.2281\n",
      "trainer/Z Expert Predictions Max      942.737\n",
      "trainer/Z Expert Predictions Min      719.117\n",
      "trainer/Z Policy Predictions Mean     734.962\n",
      "trainer/Z Policy Predictions Std      307.43\n",
      "trainer/Z Policy Predictions Max      922.331\n",
      "trainer/Z Policy Predictions Min     -505.482\n",
      "trainer/Z Expert Targets Mean         862.12\n",
      "trainer/Z Expert Targets Std           38.9433\n",
      "trainer/Z Expert Targets Max          932.132\n",
      "trainer/Z Expert Targets Min          690.734\n",
      "trainer/Z Policy Targets Mean         730.432\n",
      "trainer/Z Policy Targets Std          302.355\n",
      "trainer/Z Policy Targets Max          922.786\n",
      "trainer/Z Policy Targets Min         -489.202\n",
      "trainer/Log Pis Mean                   19.8296\n",
      "trainer/Log Pis Std                     4.10736\n",
      "trainer/Policy mu Mean                  0.0783074\n",
      "trainer/Policy mu Std                   1.04896\n",
      "trainer/Policy log std Mean            -3.18203\n",
      "trainer/Policy log std Std              0.98218\n",
      "trainer/Alpha                           0.13851\n",
      "trainer/Alpha Loss                      0.0236083\n",
      "exploration/num steps total        203654\n",
      "exploration/num paths total           303\n",
      "evaluation/num steps total              1.72789e+06\n",
      "evaluation/num paths total           2025\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60114\n",
      "evaluation/Rewards Std                  0.931164\n",
      "evaluation/Rewards Max                  6.67016\n",
      "evaluation/Rewards Min                 -1.73603\n",
      "evaluation/Returns Mean              4601.14\n",
      "evaluation/Returns Std                 69.7279\n",
      "evaluation/Returns Max               4721.69\n",
      "evaluation/Returns Min               4460.33\n",
      "evaluation/Estimation Bias Mean       808.124\n",
      "evaluation/Estimation Bias Std        139.016\n",
      "evaluation/EB/Q_True Mean              41.7665\n",
      "evaluation/EB/Q_True Std              128.484\n",
      "evaluation/EB/Q_Pred Mean             849.891\n",
      "evaluation/EB/Q_Pred Std               51.2209\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4601.14\n",
      "evaluation/Actions Mean                 0.0193606\n",
      "evaluation/Actions Std                  0.530677\n",
      "evaluation/Actions Max                  0.999806\n",
      "evaluation/Actions Min                 -0.99968\n",
      "time/backward_policy (s)                1.90626\n",
      "time/backward_zf1 (s)                   2.03018\n",
      "time/backward_zf2 (s)                   1.94564\n",
      "time/data sampling (s)                  0.301074\n",
      "time/data storing (s)                   0.0161634\n",
      "time/evaluation sampling (s)            1.74217\n",
      "time/exploration sampling (s)           0.33581\n",
      "time/logging (s)                        0.0165415\n",
      "time/preback_alpha (s)                  0.992932\n",
      "time/preback_policy (s)                 1.10452\n",
      "time/preback_start (s)                  0.1484\n",
      "time/preback_zf (s)                     5.23455\n",
      "time/saving (s)                         0.0081943\n",
      "time/training (s)                       2.32853\n",
      "time/epoch (s)                         18.111\n",
      "time/total (s)                       3539.74\n",
      "Epoch                                 197\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:51:33.827944 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 198 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 209000\n",
      "trainer/ZF1 Loss                        6.02176\n",
      "trainer/ZF2 Loss                        6.01998\n",
      "trainer/ZF Expert Reward               11.9245\n",
      "trainer/ZF Policy Reward                0.774175\n",
      "trainer/ZF CHI2 Term                   37.4673\n",
      "trainer/Policy Loss                  -729.361\n",
      "trainer/Bias Loss                      53.119\n",
      "trainer/Bias Value                     14.2294\n",
      "trainer/Policy Grad Norm              111.851\n",
      "trainer/Policy Param Norm              36.0473\n",
      "trainer/Zf1 Grad Norm                1558.47\n",
      "trainer/Zf1 Param Norm                112.511\n",
      "trainer/Zf2 Grad Norm                1157.03\n",
      "trainer/Zf2 Param Norm                110.781\n",
      "trainer/Z Expert Predictions Mean     870.839\n",
      "trainer/Z Expert Predictions Std       38.7707\n",
      "trainer/Z Expert Predictions Max      947.547\n",
      "trainer/Z Expert Predictions Min      679.53\n",
      "trainer/Z Policy Predictions Mean     725.081\n",
      "trainer/Z Policy Predictions Std      303.528\n",
      "trainer/Z Policy Predictions Max      902.734\n",
      "trainer/Z Policy Predictions Min     -546.096\n",
      "trainer/Z Expert Targets Mean         858.914\n",
      "trainer/Z Expert Targets Std           40.3224\n",
      "trainer/Z Expert Targets Max          925.466\n",
      "trainer/Z Expert Targets Min          670.191\n",
      "trainer/Z Policy Targets Mean         724.307\n",
      "trainer/Z Policy Targets Std          299.21\n",
      "trainer/Z Policy Targets Max          899.31\n",
      "trainer/Z Policy Targets Min         -544.96\n",
      "trainer/Log Pis Mean                   20.5011\n",
      "trainer/Log Pis Std                     3.93886\n",
      "trainer/Policy mu Mean                  0.0901863\n",
      "trainer/Policy mu Std                   1.05806\n",
      "trainer/Policy log std Mean            -3.20754\n",
      "trainer/Policy log std Std              0.995364\n",
      "trainer/Alpha                           0.141607\n",
      "trainer/Alpha Loss                     -0.0709604\n",
      "exploration/num steps total        204654\n",
      "exploration/num paths total           304\n",
      "evaluation/num steps total              1.73682e+06\n",
      "evaluation/num paths total           2035\n",
      "evaluation/path length Mean           892.8\n",
      "evaluation/path length Std            214.586\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            444\n",
      "evaluation/Rewards Mean                 4.78916\n",
      "evaluation/Rewards Std                  0.970346\n",
      "evaluation/Rewards Max                  7.07015\n",
      "evaluation/Rewards Min                 -1.63248\n",
      "evaluation/Returns Mean              4275.77\n",
      "evaluation/Returns Std               1045.41\n",
      "evaluation/Returns Max               4884.99\n",
      "evaluation/Returns Min               2107.64\n",
      "evaluation/Estimation Bias Mean       801.435\n",
      "evaluation/Estimation Bias Std        157.123\n",
      "evaluation/EB/Q_True Mean              49.7562\n",
      "evaluation/EB/Q_True Std              144.366\n",
      "evaluation/EB/Q_Pred Mean             851.191\n",
      "evaluation/EB/Q_Pred Std               55.247\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4275.77\n",
      "evaluation/Actions Mean                 0.0232522\n",
      "evaluation/Actions Std                  0.536901\n",
      "evaluation/Actions Max                  0.999818\n",
      "evaluation/Actions Min                 -0.999465\n",
      "time/backward_policy (s)                1.91636\n",
      "time/backward_zf1 (s)                   2.04075\n",
      "time/backward_zf2 (s)                   1.98134\n",
      "time/data sampling (s)                  0.297396\n",
      "time/data storing (s)                   0.0147169\n",
      "time/evaluation sampling (s)            1.79266\n",
      "time/exploration sampling (s)           0.321341\n",
      "time/logging (s)                        0.0108807\n",
      "time/preback_alpha (s)                  1.01415\n",
      "time/preback_policy (s)                 1.13877\n",
      "time/preback_start (s)                  0.146869\n",
      "time/preback_zf (s)                     5.18816\n",
      "time/saving (s)                         0.00599718\n",
      "time/training (s)                       2.18739\n",
      "time/epoch (s)                         18.0568\n",
      "time/total (s)                       3557.82\n",
      "Epoch                                 198\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:51:52.335808 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 199 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 210000\n",
      "trainer/ZF1 Loss                        8.14238\n",
      "trainer/ZF2 Loss                       -1.01586\n",
      "trainer/ZF Expert Reward               12.759\n",
      "trainer/ZF Policy Reward                1.06295\n",
      "trainer/ZF CHI2 Term                   35.1258\n",
      "trainer/Policy Loss                  -749.352\n",
      "trainer/Bias Loss                      45.791\n",
      "trainer/Bias Value                     14.2419\n",
      "trainer/Policy Grad Norm              125.089\n",
      "trainer/Policy Param Norm              36.073\n",
      "trainer/Zf1 Grad Norm                1363.01\n",
      "trainer/Zf1 Param Norm                112.687\n",
      "trainer/Zf2 Grad Norm                1142.42\n",
      "trainer/Zf2 Param Norm                110.949\n",
      "trainer/Z Expert Predictions Mean     861.817\n",
      "trainer/Z Expert Predictions Std       69.9551\n",
      "trainer/Z Expert Predictions Max      943.351\n",
      "trainer/Z Expert Predictions Min       13.7309\n",
      "trainer/Z Policy Predictions Mean     748.657\n",
      "trainer/Z Policy Predictions Std      252.726\n",
      "trainer/Z Policy Predictions Max      915.278\n",
      "trainer/Z Policy Predictions Min     -550.773\n",
      "trainer/Z Expert Targets Mean         849.058\n",
      "trainer/Z Expert Targets Std           70.6975\n",
      "trainer/Z Expert Targets Max          919.321\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         747.594\n",
      "trainer/Z Policy Targets Std          250.145\n",
      "trainer/Z Policy Targets Max          905.679\n",
      "trainer/Z Policy Targets Min         -560.511\n",
      "trainer/Log Pis Mean                   20.0672\n",
      "trainer/Log Pis Std                     4.36625\n",
      "trainer/Policy mu Mean                  0.0574695\n",
      "trainer/Policy mu Std                   1.02153\n",
      "trainer/Policy log std Mean            -3.20751\n",
      "trainer/Policy log std Std              0.8866\n",
      "trainer/Alpha                           0.14121\n",
      "trainer/Alpha Loss                     -0.00948424\n",
      "exploration/num steps total        205654\n",
      "exploration/num paths total           305\n",
      "evaluation/num steps total              1.74682e+06\n",
      "evaluation/num paths total           2045\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.74342\n",
      "evaluation/Rewards Std                  1.01978\n",
      "evaluation/Rewards Max                  7.1787\n",
      "evaluation/Rewards Min                 -1.38898\n",
      "evaluation/Returns Mean              4743.42\n",
      "evaluation/Returns Std                115.16\n",
      "evaluation/Returns Max               4955.98\n",
      "evaluation/Returns Min               4554.2\n",
      "evaluation/Estimation Bias Mean       799.514\n",
      "evaluation/Estimation Bias Std        156.499\n",
      "evaluation/EB/Q_True Mean              44.8849\n",
      "evaluation/EB/Q_True Std              138.31\n",
      "evaluation/EB/Q_Pred Mean             844.399\n",
      "evaluation/EB/Q_Pred Std               60.2921\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4743.42\n",
      "evaluation/Actions Mean                 0.0174629\n",
      "evaluation/Actions Std                  0.538546\n",
      "evaluation/Actions Max                  0.999546\n",
      "evaluation/Actions Min                 -0.999689\n",
      "time/backward_policy (s)                1.98679\n",
      "time/backward_zf1 (s)                   2.13329\n",
      "time/backward_zf2 (s)                   2.0713\n",
      "time/data sampling (s)                  0.307955\n",
      "time/data storing (s)                   0.0153165\n",
      "time/evaluation sampling (s)            1.8004\n",
      "time/exploration sampling (s)           0.326787\n",
      "time/logging (s)                        0.0130942\n",
      "time/preback_alpha (s)                  1.04354\n",
      "time/preback_policy (s)                 1.20415\n",
      "time/preback_start (s)                  0.145971\n",
      "time/preback_zf (s)                     5.2415\n",
      "time/saving (s)                         0.00745273\n",
      "time/training (s)                       2.14536\n",
      "time/epoch (s)                         18.4429\n",
      "time/total (s)                       3576.28\n",
      "Epoch                                 199\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:52:10.460921 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 200 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 211000\n",
      "trainer/ZF1 Loss                        6.23905\n",
      "trainer/ZF2 Loss                        4.94171\n",
      "trainer/ZF Expert Reward               14.4856\n",
      "trainer/ZF Policy Reward                3.27486\n",
      "trainer/ZF CHI2 Term                   36.2709\n",
      "trainer/Policy Loss                  -726.286\n",
      "trainer/Bias Loss                      60.6953\n",
      "trainer/Bias Value                     14.2534\n",
      "trainer/Policy Grad Norm              162.564\n",
      "trainer/Policy Param Norm              36.1037\n",
      "trainer/Zf1 Grad Norm                1233.98\n",
      "trainer/Zf1 Param Norm                112.874\n",
      "trainer/Zf2 Grad Norm                1126.08\n",
      "trainer/Zf2 Param Norm                111.132\n",
      "trainer/Z Expert Predictions Mean     868.14\n",
      "trainer/Z Expert Predictions Std       34.2031\n",
      "trainer/Z Expert Predictions Max      921.531\n",
      "trainer/Z Expert Predictions Min      664.422\n",
      "trainer/Z Policy Predictions Mean     725.201\n",
      "trainer/Z Policy Predictions Std      291.531\n",
      "trainer/Z Policy Predictions Max      908.613\n",
      "trainer/Z Policy Predictions Min     -559.293\n",
      "trainer/Z Expert Targets Mean         853.655\n",
      "trainer/Z Expert Targets Std           35.9755\n",
      "trainer/Z Expert Targets Max          911.091\n",
      "trainer/Z Expert Targets Min          640.246\n",
      "trainer/Z Policy Targets Mean         721.926\n",
      "trainer/Z Policy Targets Std          286.992\n",
      "trainer/Z Policy Targets Max          898.353\n",
      "trainer/Z Policy Targets Min         -540.709\n",
      "trainer/Log Pis Mean                   19.6664\n",
      "trainer/Log Pis Std                     4.11425\n",
      "trainer/Policy mu Mean                  0.0553346\n",
      "trainer/Policy mu Std                   0.967633\n",
      "trainer/Policy log std Mean            -3.23039\n",
      "trainer/Policy log std Std              0.908922\n",
      "trainer/Alpha                           0.141474\n",
      "trainer/Alpha Loss                      0.0471945\n",
      "exploration/num steps total        206654\n",
      "exploration/num paths total           306\n",
      "evaluation/num steps total              1.7563e+06\n",
      "evaluation/num paths total           2055\n",
      "evaluation/path length Mean           948\n",
      "evaluation/path length Std            156\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            480\n",
      "evaluation/Rewards Mean                 4.70381\n",
      "evaluation/Rewards Std                  0.998545\n",
      "evaluation/Rewards Max                  6.68798\n",
      "evaluation/Rewards Min                 -1.58963\n",
      "evaluation/Returns Mean              4459.21\n",
      "evaluation/Returns Std                730.003\n",
      "evaluation/Returns Max               4824.44\n",
      "evaluation/Returns Min               2298.15\n",
      "evaluation/Estimation Bias Mean       794.959\n",
      "evaluation/Estimation Bias Std        149.443\n",
      "evaluation/EB/Q_True Mean              45.898\n",
      "evaluation/EB/Q_True Std              137.235\n",
      "evaluation/EB/Q_Pred Mean             840.857\n",
      "evaluation/EB/Q_Pred Std               51.6141\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4459.21\n",
      "evaluation/Actions Mean                 0.0269054\n",
      "evaluation/Actions Std                  0.53924\n",
      "evaluation/Actions Max                  0.999635\n",
      "evaluation/Actions Min                 -0.999696\n",
      "time/backward_policy (s)                1.90245\n",
      "time/backward_zf1 (s)                   2.06275\n",
      "time/backward_zf2 (s)                   1.99492\n",
      "time/data sampling (s)                  0.292703\n",
      "time/data storing (s)                   0.0157742\n",
      "time/evaluation sampling (s)            1.71721\n",
      "time/exploration sampling (s)           0.328962\n",
      "time/logging (s)                        0.0124204\n",
      "time/preback_alpha (s)                  1.01372\n",
      "time/preback_policy (s)                 1.1507\n",
      "time/preback_start (s)                  0.146235\n",
      "time/preback_zf (s)                     5.21504\n",
      "time/saving (s)                         0.00658346\n",
      "time/training (s)                       2.19745\n",
      "time/epoch (s)                         18.0569\n",
      "time/total (s)                       3594.35\n",
      "Epoch                                 200\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:52:28.489643 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 201 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 212000\n",
      "trainer/ZF1 Loss                       11.2678\n",
      "trainer/ZF2 Loss                       10.4895\n",
      "trainer/ZF Expert Reward                9.94758\n",
      "trainer/ZF Policy Reward                0.628649\n",
      "trainer/ZF CHI2 Term                   39.8929\n",
      "trainer/Policy Loss                  -735.594\n",
      "trainer/Bias Loss                      62.5363\n",
      "trainer/Bias Value                     14.2642\n",
      "trainer/Policy Grad Norm              130.985\n",
      "trainer/Policy Param Norm              36.1337\n",
      "trainer/Zf1 Grad Norm                1457.63\n",
      "trainer/Zf1 Param Norm                113.055\n",
      "trainer/Zf2 Grad Norm                1434.27\n",
      "trainer/Zf2 Param Norm                111.308\n",
      "trainer/Z Expert Predictions Mean     849.826\n",
      "trainer/Z Expert Predictions Std       71.0567\n",
      "trainer/Z Expert Predictions Max      919.737\n",
      "trainer/Z Expert Predictions Min       17.114\n",
      "trainer/Z Policy Predictions Mean     731.982\n",
      "trainer/Z Policy Predictions Std      289.333\n",
      "trainer/Z Policy Predictions Max      901.288\n",
      "trainer/Z Policy Predictions Min     -575.111\n",
      "trainer/Z Expert Targets Mean         839.879\n",
      "trainer/Z Expert Targets Std           72.8868\n",
      "trainer/Z Expert Targets Max          919.5\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         731.353\n",
      "trainer/Z Policy Targets Std          285.287\n",
      "trainer/Z Policy Targets Max          891.238\n",
      "trainer/Z Policy Targets Min         -564.424\n",
      "trainer/Log Pis Mean                   19.8943\n",
      "trainer/Log Pis Std                     4.07592\n",
      "trainer/Policy mu Mean                  0.0665862\n",
      "trainer/Policy mu Std                   0.949561\n",
      "trainer/Policy log std Mean            -3.25441\n",
      "trainer/Policy log std Std              0.883348\n",
      "trainer/Alpha                           0.141647\n",
      "trainer/Alpha Loss                      0.0149675\n",
      "exploration/num steps total        206654\n",
      "exploration/num paths total           306\n",
      "evaluation/num steps total              1.7663e+06\n",
      "evaluation/num paths total           2065\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.47403\n",
      "evaluation/Rewards Std                  1.50983\n",
      "evaluation/Rewards Max                  6.76969\n",
      "evaluation/Rewards Min                 -2.68655\n",
      "evaluation/Returns Mean              4474.03\n",
      "evaluation/Returns Std                606.144\n",
      "evaluation/Returns Max               4875.9\n",
      "evaluation/Returns Min               2680.51\n",
      "evaluation/Estimation Bias Mean       782.365\n",
      "evaluation/Estimation Bias Std        233.824\n",
      "evaluation/EB/Q_True Mean              23.2264\n",
      "evaluation/EB/Q_True Std              113.054\n",
      "evaluation/EB/Q_Pred Mean             805.591\n",
      "evaluation/EB/Q_Pred Std              210.649\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4474.03\n",
      "evaluation/Actions Mean                 0.0313632\n",
      "evaluation/Actions Std                  0.550166\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999947\n",
      "time/backward_policy (s)                1.92609\n",
      "time/backward_zf1 (s)                   2.05567\n",
      "time/backward_zf2 (s)                   1.99801\n",
      "time/data sampling (s)                  0.298835\n",
      "time/data storing (s)                   0.0150492\n",
      "time/evaluation sampling (s)            1.69401\n",
      "time/exploration sampling (s)           0.317882\n",
      "time/logging (s)                        0.0120822\n",
      "time/preback_alpha (s)                  1.029\n",
      "time/preback_policy (s)                 1.17048\n",
      "time/preback_start (s)                  0.143773\n",
      "time/preback_zf (s)                     5.19206\n",
      "time/saving (s)                         0.00579369\n",
      "time/training (s)                       2.09926\n",
      "time/epoch (s)                         17.958\n",
      "time/total (s)                       3612.33\n",
      "Epoch                                 201\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 11:52:46.285087 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 202 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 213000\n",
      "trainer/ZF1 Loss                        9.26288\n",
      "trainer/ZF2 Loss                        7.42465\n",
      "trainer/ZF Expert Reward               16.915\n",
      "trainer/ZF Policy Reward                3.89818\n",
      "trainer/ZF CHI2 Term                   41.1518\n",
      "trainer/Policy Loss                  -714.17\n",
      "trainer/Bias Loss                      48.4309\n",
      "trainer/Bias Value                     14.2749\n",
      "trainer/Policy Grad Norm              126.782\n",
      "trainer/Policy Param Norm              36.164\n",
      "trainer/Zf1 Grad Norm                1188.65\n",
      "trainer/Zf1 Param Norm                113.214\n",
      "trainer/Zf2 Grad Norm                1206.54\n",
      "trainer/Zf2 Param Norm                111.478\n",
      "trainer/Z Expert Predictions Mean     862.413\n",
      "trainer/Z Expert Predictions Std       41.7165\n",
      "trainer/Z Expert Predictions Max      928.857\n",
      "trainer/Z Expert Predictions Min      599.353\n",
      "trainer/Z Policy Predictions Mean     712.802\n",
      "trainer/Z Policy Predictions Std      311.744\n",
      "trainer/Z Policy Predictions Max      913.211\n",
      "trainer/Z Policy Predictions Min     -566.798\n",
      "trainer/Z Expert Targets Mean         845.498\n",
      "trainer/Z Expert Targets Std           41.6597\n",
      "trainer/Z Expert Targets Max          914.331\n",
      "trainer/Z Expert Targets Min          577.051\n",
      "trainer/Z Policy Targets Mean         708.904\n",
      "trainer/Z Policy Targets Std          307.861\n",
      "trainer/Z Policy Targets Max          903.547\n",
      "trainer/Z Policy Targets Min         -556.587\n",
      "trainer/Log Pis Mean                   19.9912\n",
      "trainer/Log Pis Std                     4.34627\n",
      "trainer/Policy mu Mean                  0.0225644\n",
      "trainer/Policy mu Std                   1.0401\n",
      "trainer/Policy log std Mean            -3.18984\n",
      "trainer/Policy log std Std              0.962194\n",
      "trainer/Alpha                           0.142012\n",
      "trainer/Alpha Loss                      0.00125542\n",
      "exploration/num steps total        207654\n",
      "exploration/num paths total           307\n",
      "evaluation/num steps total              1.77604e+06\n",
      "evaluation/num paths total           2075\n",
      "evaluation/path length Mean           974.3\n",
      "evaluation/path length Std             77.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            743\n",
      "evaluation/Rewards Mean                 4.0082\n",
      "evaluation/Rewards Std                  2.19152\n",
      "evaluation/Rewards Max                  6.81897\n",
      "evaluation/Rewards Min                 -4.3212\n",
      "evaluation/Returns Mean              3905.19\n",
      "evaluation/Returns Std               1286.46\n",
      "evaluation/Returns Max               4841.86\n",
      "evaluation/Returns Min               1051.45\n",
      "evaluation/Estimation Bias Mean       711.374\n",
      "evaluation/Estimation Bias Std        360.612\n",
      "evaluation/EB/Q_True Mean               6.79618\n",
      "evaluation/EB/Q_True Std               88.1861\n",
      "evaluation/EB/Q_Pred Mean             718.17\n",
      "evaluation/EB/Q_Pred Std              351.18\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3905.19\n",
      "evaluation/Actions Mean                 0.051914\n",
      "evaluation/Actions Std                  0.5771\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999939\n",
      "time/backward_policy (s)                1.84515\n",
      "time/backward_zf1 (s)                   1.953\n",
      "time/backward_zf2 (s)                   1.88381\n",
      "time/data sampling (s)                  0.280166\n",
      "time/data storing (s)                   0.0147917\n",
      "time/evaluation sampling (s)            1.74058\n",
      "time/exploration sampling (s)           0.318944\n",
      "time/logging (s)                        0.0119841\n",
      "time/preback_alpha (s)                  0.953659\n",
      "time/preback_policy (s)                 1.06539\n",
      "time/preback_start (s)                  0.146775\n",
      "time/preback_zf (s)                     5.16084\n",
      "time/saving (s)                         0.00635555\n",
      "time/training (s)                       2.3464\n",
      "time/epoch (s)                         17.7278\n",
      "time/total (s)                       3630.08\n",
      "Epoch                                 202\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:53:04.103106 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 203 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 214000\n",
      "trainer/ZF1 Loss                        4.63527\n",
      "trainer/ZF2 Loss                        3.26506\n",
      "trainer/ZF Expert Reward               16.089\n",
      "trainer/ZF Policy Reward                2.89434\n",
      "trainer/ZF CHI2 Term                   36.5698\n",
      "trainer/Policy Loss                  -724.846\n",
      "trainer/Bias Loss                      50.0783\n",
      "trainer/Bias Value                     14.2857\n",
      "trainer/Policy Grad Norm              113.714\n",
      "trainer/Policy Param Norm              36.1927\n",
      "trainer/Zf1 Grad Norm                1052.26\n",
      "trainer/Zf1 Param Norm                113.381\n",
      "trainer/Zf2 Grad Norm                 929.755\n",
      "trainer/Zf2 Param Norm                111.637\n",
      "trainer/Z Expert Predictions Mean     853.755\n",
      "trainer/Z Expert Predictions Std       50.824\n",
      "trainer/Z Expert Predictions Max      928.452\n",
      "trainer/Z Expert Predictions Min      499.907\n",
      "trainer/Z Policy Predictions Mean     723.813\n",
      "trainer/Z Policy Predictions Std      273.981\n",
      "trainer/Z Policy Predictions Max      900.563\n",
      "trainer/Z Policy Predictions Min     -559.186\n",
      "trainer/Z Expert Targets Mean         837.665\n",
      "trainer/Z Expert Targets Std           53.6127\n",
      "trainer/Z Expert Targets Max          910.002\n",
      "trainer/Z Expert Targets Min          477.974\n",
      "trainer/Z Policy Targets Mean         720.919\n",
      "trainer/Z Policy Targets Std          270.715\n",
      "trainer/Z Policy Targets Max          887.775\n",
      "trainer/Z Policy Targets Min         -554.595\n",
      "trainer/Log Pis Mean                   19.6212\n",
      "trainer/Log Pis Std                     4.38373\n",
      "trainer/Policy mu Mean                  0.0447652\n",
      "trainer/Policy mu Std                   0.93731\n",
      "trainer/Policy log std Mean            -3.23387\n",
      "trainer/Policy log std Std              0.860909\n",
      "trainer/Alpha                           0.142579\n",
      "trainer/Alpha Loss                      0.0540139\n",
      "exploration/num steps total        208458\n",
      "exploration/num paths total           308\n",
      "evaluation/num steps total              1.78604e+06\n",
      "evaluation/num paths total           2085\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65097\n",
      "evaluation/Rewards Std                  0.961669\n",
      "evaluation/Rewards Max                  6.89644\n",
      "evaluation/Rewards Min                 -1.59848\n",
      "evaluation/Returns Mean              4650.97\n",
      "evaluation/Returns Std                 56.216\n",
      "evaluation/Returns Max               4723.19\n",
      "evaluation/Returns Min               4526.81\n",
      "evaluation/Estimation Bias Mean       785.666\n",
      "evaluation/Estimation Bias Std        138.21\n",
      "evaluation/EB/Q_True Mean              41.5981\n",
      "evaluation/EB/Q_True Std              128.523\n",
      "evaluation/EB/Q_Pred Mean             827.264\n",
      "evaluation/EB/Q_Pred Std               52.1524\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4650.97\n",
      "evaluation/Actions Mean                 0.0223248\n",
      "evaluation/Actions Std                  0.532542\n",
      "evaluation/Actions Max                  0.999751\n",
      "evaluation/Actions Min                 -0.999677\n",
      "time/backward_policy (s)                1.84845\n",
      "time/backward_zf1 (s)                   2.0002\n",
      "time/backward_zf2 (s)                   1.92291\n",
      "time/data sampling (s)                  0.290418\n",
      "time/data storing (s)                   0.0149705\n",
      "time/evaluation sampling (s)            1.74693\n",
      "time/exploration sampling (s)           0.321828\n",
      "time/logging (s)                        0.011747\n",
      "time/preback_alpha (s)                  0.989293\n",
      "time/preback_policy (s)                 1.09949\n",
      "time/preback_start (s)                  0.146146\n",
      "time/preback_zf (s)                     5.17107\n",
      "time/saving (s)                         0.00586247\n",
      "time/training (s)                       2.18048\n",
      "time/epoch (s)                         17.7498\n",
      "time/total (s)                       3647.85\n",
      "Epoch                                 203\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:53:21.892651 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 204 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 215000\n",
      "trainer/ZF1 Loss                      126.105\n",
      "trainer/ZF2 Loss                      133.627\n",
      "trainer/ZF Expert Reward               13.5154\n",
      "trainer/ZF Policy Reward                3.82285\n",
      "trainer/ZF CHI2 Term                  159.625\n",
      "trainer/Policy Loss                  -686.918\n",
      "trainer/Bias Loss                      49.5368\n",
      "trainer/Bias Value                     14.296\n",
      "trainer/Policy Grad Norm              157.205\n",
      "trainer/Policy Param Norm              36.2229\n",
      "trainer/Zf1 Grad Norm                2207.58\n",
      "trainer/Zf1 Param Norm                113.556\n",
      "trainer/Zf2 Grad Norm                1683.3\n",
      "trainer/Zf2 Param Norm                111.806\n",
      "trainer/Z Expert Predictions Mean     849.854\n",
      "trainer/Z Expert Predictions Std       45.0183\n",
      "trainer/Z Expert Predictions Max      917.155\n",
      "trainer/Z Expert Predictions Min      601.819\n",
      "trainer/Z Policy Predictions Mean     685.667\n",
      "trainer/Z Policy Predictions Std      333.376\n",
      "trainer/Z Policy Predictions Max      892.806\n",
      "trainer/Z Policy Predictions Min     -584.49\n",
      "trainer/Z Expert Targets Mean         836.339\n",
      "trainer/Z Expert Targets Std           46.7629\n",
      "trainer/Z Expert Targets Max          915.215\n",
      "trainer/Z Expert Targets Min          576.24\n",
      "trainer/Z Policy Targets Mean         681.844\n",
      "trainer/Z Policy Targets Std          331.634\n",
      "trainer/Z Policy Targets Max          894.336\n",
      "trainer/Z Policy Targets Min         -587.339\n",
      "trainer/Log Pis Mean                   20.2693\n",
      "trainer/Log Pis Std                     3.93995\n",
      "trainer/Policy mu Mean                  0.0751305\n",
      "trainer/Policy mu Std                   1.06491\n",
      "trainer/Policy log std Mean            -3.20014\n",
      "trainer/Policy log std Std              1.00387\n",
      "trainer/Alpha                           0.143557\n",
      "trainer/Alpha Loss                     -0.0386563\n",
      "exploration/num steps total        209458\n",
      "exploration/num paths total           309\n",
      "evaluation/num steps total              1.79509e+06\n",
      "evaluation/num paths total           2095\n",
      "evaluation/path length Mean           904.7\n",
      "evaluation/path length Std            285.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             47\n",
      "evaluation/Rewards Mean                 4.70312\n",
      "evaluation/Rewards Std                  1.02208\n",
      "evaluation/Rewards Max                  6.92373\n",
      "evaluation/Rewards Min                 -1.83417\n",
      "evaluation/Returns Mean              4254.91\n",
      "evaluation/Returns Std               1385.95\n",
      "evaluation/Returns Max               4900.05\n",
      "evaluation/Returns Min                108.383\n",
      "evaluation/Estimation Bias Mean       772.374\n",
      "evaluation/Estimation Bias Std        152.482\n",
      "evaluation/EB/Q_True Mean              47.6366\n",
      "evaluation/EB/Q_True Std              138.525\n",
      "evaluation/EB/Q_Pred Mean             820.01\n",
      "evaluation/EB/Q_Pred Std               55.6073\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4254.91\n",
      "evaluation/Actions Mean                 0.0275227\n",
      "evaluation/Actions Std                  0.530269\n",
      "evaluation/Actions Max                  0.999701\n",
      "evaluation/Actions Min                 -0.999069\n",
      "time/backward_policy (s)                1.80452\n",
      "time/backward_zf1 (s)                   1.92164\n",
      "time/backward_zf2 (s)                   1.85617\n",
      "time/data sampling (s)                  0.293631\n",
      "time/data storing (s)                   0.0142842\n",
      "time/evaluation sampling (s)            1.78916\n",
      "time/exploration sampling (s)           0.317098\n",
      "time/logging (s)                        0.0113887\n",
      "time/preback_alpha (s)                  0.934676\n",
      "time/preback_policy (s)                 1.02862\n",
      "time/preback_start (s)                  0.148091\n",
      "time/preback_zf (s)                     5.17645\n",
      "time/saving (s)                         0.00599561\n",
      "time/training (s)                       2.41944\n",
      "time/epoch (s)                         17.7212\n",
      "time/total (s)                       3665.59\n",
      "Epoch                                 204\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:53:40.071282 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 205 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 216000\n",
      "trainer/ZF1 Loss                        6.32771\n",
      "trainer/ZF2 Loss                        4.81536\n",
      "trainer/ZF Expert Reward               15.2465\n",
      "trainer/ZF Policy Reward                2.89456\n",
      "trainer/ZF CHI2 Term                   37.685\n",
      "trainer/Policy Loss                  -720.137\n",
      "trainer/Bias Loss                      53.3766\n",
      "trainer/Bias Value                     14.3062\n",
      "trainer/Policy Grad Norm              124.899\n",
      "trainer/Policy Param Norm              36.2493\n",
      "trainer/Zf1 Grad Norm                1198.03\n",
      "trainer/Zf1 Param Norm                113.738\n",
      "trainer/Zf2 Grad Norm                 957.765\n",
      "trainer/Zf2 Param Norm                111.985\n",
      "trainer/Z Expert Predictions Mean     846.183\n",
      "trainer/Z Expert Predictions Std       45.0087\n",
      "trainer/Z Expert Predictions Max      916.203\n",
      "trainer/Z Expert Predictions Min      557.322\n",
      "trainer/Z Policy Predictions Mean     720.742\n",
      "trainer/Z Policy Predictions Std      280.094\n",
      "trainer/Z Policy Predictions Max      904.662\n",
      "trainer/Z Policy Predictions Min     -582.054\n",
      "trainer/Z Expert Targets Mean         830.937\n",
      "trainer/Z Expert Targets Std           47.0242\n",
      "trainer/Z Expert Targets Max          895.935\n",
      "trainer/Z Expert Targets Min          530.272\n",
      "trainer/Z Policy Targets Mean         717.848\n",
      "trainer/Z Policy Targets Std          274.539\n",
      "trainer/Z Policy Targets Max          887.799\n",
      "trainer/Z Policy Targets Min         -568.403\n",
      "trainer/Log Pis Mean                   19.9612\n",
      "trainer/Log Pis Std                     4.18626\n",
      "trainer/Policy mu Mean                  0.049552\n",
      "trainer/Policy mu Std                   0.971526\n",
      "trainer/Policy log std Mean            -3.25638\n",
      "trainer/Policy log std Std              0.93556\n",
      "trainer/Alpha                           0.14475\n",
      "trainer/Alpha Loss                      0.00562212\n",
      "exploration/num steps total        210458\n",
      "exploration/num paths total           310\n",
      "evaluation/num steps total              1.80474e+06\n",
      "evaluation/num paths total           2105\n",
      "evaluation/path length Mean           964.9\n",
      "evaluation/path length Std            105.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            649\n",
      "evaluation/Rewards Mean                 4.65754\n",
      "evaluation/Rewards Std                  1.0078\n",
      "evaluation/Rewards Max                  6.78167\n",
      "evaluation/Rewards Min                 -1.84715\n",
      "evaluation/Returns Mean              4494.06\n",
      "evaluation/Returns Std                523.64\n",
      "evaluation/Returns Max               4782.21\n",
      "evaluation/Returns Min               2933.9\n",
      "evaluation/Estimation Bias Mean       770.614\n",
      "evaluation/Estimation Bias Std        148.094\n",
      "evaluation/EB/Q_True Mean              44.5847\n",
      "evaluation/EB/Q_True Std              134.396\n",
      "evaluation/EB/Q_Pred Mean             815.199\n",
      "evaluation/EB/Q_Pred Std               56.0017\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4494.06\n",
      "evaluation/Actions Mean                 0.0211702\n",
      "evaluation/Actions Std                  0.530661\n",
      "evaluation/Actions Max                  0.999792\n",
      "evaluation/Actions Min                 -0.999777\n",
      "time/backward_policy (s)                1.95802\n",
      "time/backward_zf1 (s)                   2.08627\n",
      "time/backward_zf2 (s)                   2.02607\n",
      "time/data sampling (s)                  0.307477\n",
      "time/data storing (s)                   0.0148559\n",
      "time/evaluation sampling (s)            1.71248\n",
      "time/exploration sampling (s)           0.320722\n",
      "time/logging (s)                        0.0123057\n",
      "time/preback_alpha (s)                  1.03348\n",
      "time/preback_policy (s)                 1.18438\n",
      "time/preback_start (s)                  0.146457\n",
      "time/preback_zf (s)                     5.17807\n",
      "time/saving (s)                         0.00854107\n",
      "time/training (s)                       2.11996\n",
      "time/epoch (s)                         18.1091\n",
      "time/total (s)                       3683.72\n",
      "Epoch                                 205\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:53:58.165024 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 206 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 217000\n",
      "trainer/ZF1 Loss                       14.6818\n",
      "trainer/ZF2 Loss                       14.5881\n",
      "trainer/ZF Expert Reward               12.6557\n",
      "trainer/ZF Policy Reward                3.33105\n",
      "trainer/ZF CHI2 Term                   43.5254\n",
      "trainer/Policy Loss                  -710.399\n",
      "trainer/Bias Loss                      55.3237\n",
      "trainer/Bias Value                     14.3184\n",
      "trainer/Policy Grad Norm              164.164\n",
      "trainer/Policy Param Norm              36.2787\n",
      "trainer/Zf1 Grad Norm                1461.35\n",
      "trainer/Zf1 Param Norm                113.914\n",
      "trainer/Zf2 Grad Norm                1296.42\n",
      "trainer/Zf2 Param Norm                112.149\n",
      "trainer/Z Expert Predictions Mean     843.861\n",
      "trainer/Z Expert Predictions Std       38.5722\n",
      "trainer/Z Expert Predictions Max      907.212\n",
      "trainer/Z Expert Predictions Min      632.185\n",
      "trainer/Z Policy Predictions Mean     708.36\n",
      "trainer/Z Policy Predictions Std      275.483\n",
      "trainer/Z Policy Predictions Max      893.186\n",
      "trainer/Z Policy Predictions Min     -556.1\n",
      "trainer/Z Expert Targets Mean         831.206\n",
      "trainer/Z Expert Targets Std           40.3322\n",
      "trainer/Z Expert Targets Max          895.947\n",
      "trainer/Z Expert Targets Min          606.335\n",
      "trainer/Z Policy Targets Mean         705.029\n",
      "trainer/Z Policy Targets Std          272.855\n",
      "trainer/Z Policy Targets Max          878.757\n",
      "trainer/Z Policy Targets Min         -541.374\n",
      "trainer/Log Pis Mean                   19.7634\n",
      "trainer/Log Pis Std                     4.32129\n",
      "trainer/Policy mu Mean                  0.0696919\n",
      "trainer/Policy mu Std                   1.00199\n",
      "trainer/Policy log std Mean            -3.21313\n",
      "trainer/Policy log std Std              0.946017\n",
      "trainer/Alpha                           0.145066\n",
      "trainer/Alpha Loss                      0.0343291\n",
      "exploration/num steps total        212458\n",
      "exploration/num paths total           312\n",
      "evaluation/num steps total              1.81336e+06\n",
      "evaluation/num paths total           2116\n",
      "evaluation/path length Mean           783.545\n",
      "evaluation/path length Std            361.73\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             51\n",
      "evaluation/Rewards Mean                 4.6194\n",
      "evaluation/Rewards Std                  1.14405\n",
      "evaluation/Rewards Max                  7.14925\n",
      "evaluation/Rewards Min                 -1.79841\n",
      "evaluation/Returns Mean              3619.51\n",
      "evaluation/Returns Std               1757.53\n",
      "evaluation/Returns Max               4915.69\n",
      "evaluation/Returns Min                103.366\n",
      "evaluation/Estimation Bias Mean       753.054\n",
      "evaluation/Estimation Bias Std        174.119\n",
      "evaluation/EB/Q_True Mean              52.3914\n",
      "evaluation/EB/Q_True Std              148.853\n",
      "evaluation/EB/Q_Pred Mean             805.446\n",
      "evaluation/EB/Q_Pred Std               71.3598\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3619.51\n",
      "evaluation/Actions Mean                 0.025937\n",
      "evaluation/Actions Std                  0.537232\n",
      "evaluation/Actions Max                  0.99971\n",
      "evaluation/Actions Min                 -0.999761\n",
      "time/backward_policy (s)                1.90372\n",
      "time/backward_zf1 (s)                   2.03139\n",
      "time/backward_zf2 (s)                   1.96136\n",
      "time/data sampling (s)                  0.305115\n",
      "time/data storing (s)                   0.0154372\n",
      "time/evaluation sampling (s)            1.78085\n",
      "time/exploration sampling (s)           0.333632\n",
      "time/logging (s)                        0.0104302\n",
      "time/preback_alpha (s)                  1.02814\n",
      "time/preback_policy (s)                 1.14431\n",
      "time/preback_start (s)                  0.147298\n",
      "time/preback_zf (s)                     5.20748\n",
      "time/saving (s)                         0.00639801\n",
      "time/training (s)                       2.14788\n",
      "time/epoch (s)                         18.0235\n",
      "time/total (s)                       3701.77\n",
      "Epoch                                 206\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:54:16.503695 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 207 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 218000\n",
      "trainer/ZF1 Loss                       37.4353\n",
      "trainer/ZF2 Loss                       28.9274\n",
      "trainer/ZF Expert Reward               14.8086\n",
      "trainer/ZF Policy Reward                7.4862\n",
      "trainer/ZF CHI2 Term                   60.5952\n",
      "trainer/Policy Loss                  -714.42\n",
      "trainer/Bias Loss                      56.0969\n",
      "trainer/Bias Value                     14.3272\n",
      "trainer/Policy Grad Norm              128.038\n",
      "trainer/Policy Param Norm              36.3089\n",
      "trainer/Zf1 Grad Norm                1911.49\n",
      "trainer/Zf1 Param Norm                114.083\n",
      "trainer/Zf2 Grad Norm                1525.45\n",
      "trainer/Zf2 Param Norm                112.317\n",
      "trainer/Z Expert Predictions Mean     842.413\n",
      "trainer/Z Expert Predictions Std       39.7548\n",
      "trainer/Z Expert Predictions Max      902.404\n",
      "trainer/Z Expert Predictions Min      643.556\n",
      "trainer/Z Policy Predictions Mean     714.712\n",
      "trainer/Z Policy Predictions Std      288.309\n",
      "trainer/Z Policy Predictions Max      880.02\n",
      "trainer/Z Policy Predictions Min     -541.141\n",
      "trainer/Z Expert Targets Mean         827.604\n",
      "trainer/Z Expert Targets Std           39.5497\n",
      "trainer/Z Expert Targets Max          888.478\n",
      "trainer/Z Expert Targets Min          633.555\n",
      "trainer/Z Policy Targets Mean         707.226\n",
      "trainer/Z Policy Targets Std          283.759\n",
      "trainer/Z Policy Targets Max          887.466\n",
      "trainer/Z Policy Targets Min         -535.364\n",
      "trainer/Log Pis Mean                   20.2944\n",
      "trainer/Log Pis Std                     4.34767\n",
      "trainer/Policy mu Mean                  0.02003\n",
      "trainer/Policy mu Std                   1.05775\n",
      "trainer/Policy log std Mean            -3.21797\n",
      "trainer/Policy log std Std              0.944416\n",
      "trainer/Alpha                           0.143541\n",
      "trainer/Alpha Loss                     -0.042264\n",
      "exploration/num steps total        213458\n",
      "exploration/num paths total           313\n",
      "evaluation/num steps total              1.82336e+06\n",
      "evaluation/num paths total           2126\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70917\n",
      "evaluation/Rewards Std                  1.03204\n",
      "evaluation/Rewards Max                  6.84622\n",
      "evaluation/Rewards Min                 -2.12967\n",
      "evaluation/Returns Mean              4709.17\n",
      "evaluation/Returns Std                 99.8691\n",
      "evaluation/Returns Max               4852.52\n",
      "evaluation/Returns Min               4511.51\n",
      "evaluation/Estimation Bias Mean       770.557\n",
      "evaluation/Estimation Bias Std        148.265\n",
      "evaluation/EB/Q_True Mean              43.4278\n",
      "evaluation/EB/Q_True Std              133.713\n",
      "evaluation/EB/Q_Pred Mean             813.984\n",
      "evaluation/EB/Q_Pred Std               58.6549\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4709.17\n",
      "evaluation/Actions Mean                 0.0152622\n",
      "evaluation/Actions Std                  0.546986\n",
      "evaluation/Actions Max                  0.999672\n",
      "evaluation/Actions Min                 -0.999283\n",
      "time/backward_policy (s)                1.94859\n",
      "time/backward_zf1 (s)                   2.10822\n",
      "time/backward_zf2 (s)                   2.03839\n",
      "time/data sampling (s)                  0.305822\n",
      "time/data storing (s)                   0.014602\n",
      "time/evaluation sampling (s)            1.76664\n",
      "time/exploration sampling (s)           0.3238\n",
      "time/logging (s)                        0.0123272\n",
      "time/preback_alpha (s)                  1.03513\n",
      "time/preback_policy (s)                 1.15235\n",
      "time/preback_start (s)                  0.149514\n",
      "time/preback_zf (s)                     5.24238\n",
      "time/saving (s)                         0.00639802\n",
      "time/training (s)                       2.16848\n",
      "time/epoch (s)                         18.2727\n",
      "time/total (s)                       3720.06\n",
      "Epoch                                 207\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:54:34.525806 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 208 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 219000\n",
      "trainer/ZF1 Loss                        7.75691\n",
      "trainer/ZF2 Loss                        4.5318\n",
      "trainer/ZF Expert Reward               15.3894\n",
      "trainer/ZF Policy Reward                2.17969\n",
      "trainer/ZF CHI2 Term                   39.0546\n",
      "trainer/Policy Loss                  -715.301\n",
      "trainer/Bias Loss                      55.2374\n",
      "trainer/Bias Value                     14.3408\n",
      "trainer/Policy Grad Norm              153.509\n",
      "trainer/Policy Param Norm              36.3358\n",
      "trainer/Zf1 Grad Norm                1265.67\n",
      "trainer/Zf1 Param Norm                114.252\n",
      "trainer/Zf2 Grad Norm                1504.1\n",
      "trainer/Zf2 Param Norm                112.487\n",
      "trainer/Z Expert Predictions Mean     839.703\n",
      "trainer/Z Expert Predictions Std       32.661\n",
      "trainer/Z Expert Predictions Max      911.524\n",
      "trainer/Z Expert Predictions Min      701.869\n",
      "trainer/Z Policy Predictions Mean     714.287\n",
      "trainer/Z Policy Predictions Std      277.898\n",
      "trainer/Z Policy Predictions Max      897.03\n",
      "trainer/Z Policy Predictions Min     -563.111\n",
      "trainer/Z Expert Targets Mean         824.314\n",
      "trainer/Z Expert Targets Std           34.8082\n",
      "trainer/Z Expert Targets Max          880.873\n",
      "trainer/Z Expert Targets Min          675.015\n",
      "trainer/Z Policy Targets Mean         712.107\n",
      "trainer/Z Policy Targets Std          273.896\n",
      "trainer/Z Policy Targets Max          871.305\n",
      "trainer/Z Policy Targets Min         -547.773\n",
      "trainer/Log Pis Mean                   19.8995\n",
      "trainer/Log Pis Std                     3.8608\n",
      "trainer/Policy mu Mean                  0.0441853\n",
      "trainer/Policy mu Std                   0.98102\n",
      "trainer/Policy log std Mean            -3.2439\n",
      "trainer/Policy log std Std              0.901533\n",
      "trainer/Alpha                           0.144976\n",
      "trainer/Alpha Loss                      0.0145642\n",
      "exploration/num steps total        214458\n",
      "exploration/num paths total           314\n",
      "evaluation/num steps total              1.83316e+06\n",
      "evaluation/num paths total           2136\n",
      "evaluation/path length Mean           980.2\n",
      "evaluation/path length Std             59.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            802\n",
      "evaluation/Rewards Mean                 4.66289\n",
      "evaluation/Rewards Std                  1.03661\n",
      "evaluation/Rewards Max                  6.76737\n",
      "evaluation/Rewards Min                 -3.13489\n",
      "evaluation/Returns Mean              4570.56\n",
      "evaluation/Returns Std                374.284\n",
      "evaluation/Returns Max               4949.51\n",
      "evaluation/Returns Min               3589.71\n",
      "evaluation/Estimation Bias Mean       765.365\n",
      "evaluation/Estimation Bias Std        156.047\n",
      "evaluation/EB/Q_True Mean              46.2946\n",
      "evaluation/EB/Q_True Std              141.067\n",
      "evaluation/EB/Q_Pred Mean             811.659\n",
      "evaluation/EB/Q_Pred Std               58.7278\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4570.56\n",
      "evaluation/Actions Mean                 0.025694\n",
      "evaluation/Actions Std                  0.534303\n",
      "evaluation/Actions Max                  0.999832\n",
      "evaluation/Actions Min                 -0.999604\n",
      "time/backward_policy (s)                1.85276\n",
      "time/backward_zf1 (s)                   2.01438\n",
      "time/backward_zf2 (s)                   1.91109\n",
      "time/data sampling (s)                  0.307417\n",
      "time/data storing (s)                   0.0147791\n",
      "time/evaluation sampling (s)            1.74154\n",
      "time/exploration sampling (s)           0.31991\n",
      "time/logging (s)                        0.0119142\n",
      "time/preback_alpha (s)                  0.940249\n",
      "time/preback_policy (s)                 1.03296\n",
      "time/preback_start (s)                  0.145961\n",
      "time/preback_zf (s)                     5.21373\n",
      "time/saving (s)                         0.00641115\n",
      "time/training (s)                       2.43881\n",
      "time/epoch (s)                         17.9519\n",
      "time/total (s)                       3738.03\n",
      "Epoch                                 208\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:54:52.747243 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 209 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 220000\n",
      "trainer/ZF1 Loss                        1.72482\n",
      "trainer/ZF2 Loss                       -3.80903\n",
      "trainer/ZF Expert Reward               14.5875\n",
      "trainer/ZF Policy Reward                1.02771\n",
      "trainer/ZF CHI2 Term                   32.0931\n",
      "trainer/Policy Loss                  -693.304\n",
      "trainer/Bias Loss                      50.0127\n",
      "trainer/Bias Value                     14.35\n",
      "trainer/Policy Grad Norm              134.639\n",
      "trainer/Policy Param Norm              36.3643\n",
      "trainer/Zf1 Grad Norm                1764.21\n",
      "trainer/Zf1 Param Norm                114.421\n",
      "trainer/Zf2 Grad Norm                1119.78\n",
      "trainer/Zf2 Param Norm                112.672\n",
      "trainer/Z Expert Predictions Mean     831.423\n",
      "trainer/Z Expert Predictions Std       65.1955\n",
      "trainer/Z Expert Predictions Max      898.589\n",
      "trainer/Z Expert Predictions Min       13.3921\n",
      "trainer/Z Policy Predictions Mean     691.483\n",
      "trainer/Z Policy Predictions Std      304.222\n",
      "trainer/Z Policy Predictions Max      878.694\n",
      "trainer/Z Policy Predictions Min     -588.624\n",
      "trainer/Z Expert Targets Mean         816.836\n",
      "trainer/Z Expert Targets Std           66.1616\n",
      "trainer/Z Expert Targets Max          883.419\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         690.456\n",
      "trainer/Z Policy Targets Std          299.854\n",
      "trainer/Z Policy Targets Max          874.964\n",
      "trainer/Z Policy Targets Min         -590.554\n",
      "trainer/Log Pis Mean                   19.7732\n",
      "trainer/Log Pis Std                     4.05266\n",
      "trainer/Policy mu Mean                  0.0205347\n",
      "trainer/Policy mu Std                   0.971992\n",
      "trainer/Policy log std Mean            -3.24447\n",
      "trainer/Policy log std Std              0.914005\n",
      "trainer/Alpha                           0.14469\n",
      "trainer/Alpha Loss                      0.0328157\n",
      "exploration/num steps total        215458\n",
      "exploration/num paths total           315\n",
      "evaluation/num steps total              1.84316e+06\n",
      "evaluation/num paths total           2146\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67852\n",
      "evaluation/Rewards Std                  1.05821\n",
      "evaluation/Rewards Max                  6.91567\n",
      "evaluation/Rewards Min                 -1.97997\n",
      "evaluation/Returns Mean              4678.52\n",
      "evaluation/Returns Std                 94.3955\n",
      "evaluation/Returns Max               4812.26\n",
      "evaluation/Returns Min               4506.13\n",
      "evaluation/Estimation Bias Mean       755.913\n",
      "evaluation/Estimation Bias Std        151.762\n",
      "evaluation/EB/Q_True Mean              44.4352\n",
      "evaluation/EB/Q_True Std              137.46\n",
      "evaluation/EB/Q_Pred Mean             800.349\n",
      "evaluation/EB/Q_Pred Std               60.267\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4678.52\n",
      "evaluation/Actions Mean                 0.0183348\n",
      "evaluation/Actions Std                  0.536261\n",
      "evaluation/Actions Max                  0.999631\n",
      "evaluation/Actions Min                 -0.99959\n",
      "time/backward_policy (s)                1.94095\n",
      "time/backward_zf1 (s)                   2.05599\n",
      "time/backward_zf2 (s)                   2.00291\n",
      "time/data sampling (s)                  0.309655\n",
      "time/data storing (s)                   0.0151657\n",
      "time/evaluation sampling (s)            1.76632\n",
      "time/exploration sampling (s)           0.323223\n",
      "time/logging (s)                        0.0122832\n",
      "time/preback_alpha (s)                  1.00507\n",
      "time/preback_policy (s)                 1.12635\n",
      "time/preback_start (s)                  0.146812\n",
      "time/preback_zf (s)                     5.2038\n",
      "time/saving (s)                         0.00641035\n",
      "time/training (s)                       2.2397\n",
      "time/epoch (s)                         18.1546\n",
      "time/total (s)                       3756.2\n",
      "Epoch                                 209\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:55:10.172186 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 210 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 221000\n",
      "trainer/ZF1 Loss                       10.0039\n",
      "trainer/ZF2 Loss                        5.28376\n",
      "trainer/ZF Expert Reward               14.1828\n",
      "trainer/ZF Policy Reward                2.77327\n",
      "trainer/ZF CHI2 Term                   38.7531\n",
      "trainer/Policy Loss                  -689.438\n",
      "trainer/Bias Loss                      42.1625\n",
      "trainer/Bias Value                     14.3607\n",
      "trainer/Policy Grad Norm              122.093\n",
      "trainer/Policy Param Norm              36.3964\n",
      "trainer/Zf1 Grad Norm                1172.1\n",
      "trainer/Zf1 Param Norm                114.596\n",
      "trainer/Zf2 Grad Norm                1215.72\n",
      "trainer/Zf2 Param Norm                112.83\n",
      "trainer/Z Expert Predictions Mean     830.778\n",
      "trainer/Z Expert Predictions Std       40.6922\n",
      "trainer/Z Expert Predictions Max      887.897\n",
      "trainer/Z Expert Predictions Min      634.692\n",
      "trainer/Z Policy Predictions Mean     687.76\n",
      "trainer/Z Policy Predictions Std      307.995\n",
      "trainer/Z Policy Predictions Max      866.055\n",
      "trainer/Z Policy Predictions Min     -566.155\n",
      "trainer/Z Expert Targets Mean         816.596\n",
      "trainer/Z Expert Targets Std           42.575\n",
      "trainer/Z Expert Targets Max          880.8\n",
      "trainer/Z Expert Targets Min          611.228\n",
      "trainer/Z Policy Targets Mean         684.987\n",
      "trainer/Z Policy Targets Std          304.308\n",
      "trainer/Z Policy Targets Max          860.823\n",
      "trainer/Z Policy Targets Min         -564.047\n",
      "trainer/Log Pis Mean                   19.8988\n",
      "trainer/Log Pis Std                     4.43794\n",
      "trainer/Policy mu Mean                  0.0490555\n",
      "trainer/Policy mu Std                   1.04629\n",
      "trainer/Policy log std Mean            -3.20127\n",
      "trainer/Policy log std Std              0.968124\n",
      "trainer/Alpha                           0.146303\n",
      "trainer/Alpha Loss                      0.0148084\n",
      "exploration/num steps total        216458\n",
      "exploration/num paths total           316\n",
      "evaluation/num steps total              1.85316e+06\n",
      "evaluation/num paths total           2156\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62905\n",
      "evaluation/Rewards Std                  0.978641\n",
      "evaluation/Rewards Max                  6.74829\n",
      "evaluation/Rewards Min                 -1.51526\n",
      "evaluation/Returns Mean              4629.05\n",
      "evaluation/Returns Std                112.055\n",
      "evaluation/Returns Max               4751.02\n",
      "evaluation/Returns Min               4335.78\n",
      "evaluation/Estimation Bias Mean       768.136\n",
      "evaluation/Estimation Bias Std        141.15\n",
      "evaluation/EB/Q_True Mean              42.7419\n",
      "evaluation/EB/Q_True Std              131.831\n",
      "evaluation/EB/Q_Pred Mean             810.878\n",
      "evaluation/EB/Q_Pred Std               57.6698\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4629.05\n",
      "evaluation/Actions Mean                 0.0229812\n",
      "evaluation/Actions Std                  0.529563\n",
      "evaluation/Actions Max                  0.999422\n",
      "evaluation/Actions Min                 -0.999518\n",
      "time/backward_policy (s)                1.73594\n",
      "time/backward_zf1 (s)                   1.87088\n",
      "time/backward_zf2 (s)                   1.7958\n",
      "time/data sampling (s)                  0.289604\n",
      "time/data storing (s)                   0.0143393\n",
      "time/evaluation sampling (s)            1.76224\n",
      "time/exploration sampling (s)           0.314319\n",
      "time/logging (s)                        0.0131319\n",
      "time/preback_alpha (s)                  0.907307\n",
      "time/preback_policy (s)                 0.981883\n",
      "time/preback_start (s)                  0.143559\n",
      "time/preback_zf (s)                     5.14151\n",
      "time/saving (s)                         0.00645319\n",
      "time/training (s)                       2.38282\n",
      "time/epoch (s)                         17.3598\n",
      "time/total (s)                       3773.58\n",
      "Epoch                                 210\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:55:28.517170 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 211 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 222000\n",
      "trainer/ZF1 Loss                       19.8477\n",
      "trainer/ZF2 Loss                       13.9174\n",
      "trainer/ZF Expert Reward               17.5638\n",
      "trainer/ZF Policy Reward                5.83647\n",
      "trainer/ZF CHI2 Term                   48.3046\n",
      "trainer/Policy Loss                  -656.05\n",
      "trainer/Bias Loss                     118.03\n",
      "trainer/Bias Value                     14.3732\n",
      "trainer/Policy Grad Norm              141.407\n",
      "trainer/Policy Param Norm              36.4257\n",
      "trainer/Zf1 Grad Norm                1444.75\n",
      "trainer/Zf1 Param Norm                114.747\n",
      "trainer/Zf2 Grad Norm                1658.4\n",
      "trainer/Zf2 Param Norm                112.975\n",
      "trainer/Z Expert Predictions Mean     827.95\n",
      "trainer/Z Expert Predictions Std       43.8063\n",
      "trainer/Z Expert Predictions Max      900.414\n",
      "trainer/Z Expert Predictions Min      549.939\n",
      "trainer/Z Policy Predictions Mean     658.513\n",
      "trainer/Z Policy Predictions Std      354.203\n",
      "trainer/Z Policy Predictions Max      879.06\n",
      "trainer/Z Policy Predictions Min     -602.849\n",
      "trainer/Z Expert Targets Mean         810.386\n",
      "trainer/Z Expert Targets Std           50.2146\n",
      "trainer/Z Expert Targets Max          876.88\n",
      "trainer/Z Expert Targets Min          457.891\n",
      "trainer/Z Policy Targets Mean         652.677\n",
      "trainer/Z Policy Targets Std          352.452\n",
      "trainer/Z Policy Targets Max          862.38\n",
      "trainer/Z Policy Targets Min         -608.029\n",
      "trainer/Log Pis Mean                   19.8936\n",
      "trainer/Log Pis Std                     4.26511\n",
      "trainer/Policy mu Mean                  0.0740343\n",
      "trainer/Policy mu Std                   1.09066\n",
      "trainer/Policy log std Mean            -3.12791\n",
      "trainer/Policy log std Std              1.02633\n",
      "trainer/Alpha                           0.147305\n",
      "trainer/Alpha Loss                      0.0156694\n",
      "exploration/num steps total        216458\n",
      "exploration/num paths total           316\n",
      "evaluation/num steps total              1.86316e+06\n",
      "evaluation/num paths total           2166\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70823\n",
      "evaluation/Rewards Std                  1.07293\n",
      "evaluation/Rewards Max                  6.75061\n",
      "evaluation/Rewards Min                 -1.49583\n",
      "evaluation/Returns Mean              4708.23\n",
      "evaluation/Returns Std                143.181\n",
      "evaluation/Returns Max               4965.34\n",
      "evaluation/Returns Min               4369.39\n",
      "evaluation/Estimation Bias Mean       756.524\n",
      "evaluation/Estimation Bias Std        148.037\n",
      "evaluation/EB/Q_True Mean              43.6396\n",
      "evaluation/EB/Q_True Std              134.487\n",
      "evaluation/EB/Q_Pred Mean             800.163\n",
      "evaluation/EB/Q_Pred Std               66.5366\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4708.23\n",
      "evaluation/Actions Mean                 0.0194321\n",
      "evaluation/Actions Std                  0.535646\n",
      "evaluation/Actions Max                  0.999734\n",
      "evaluation/Actions Min                 -0.999615\n",
      "time/backward_policy (s)                1.95346\n",
      "time/backward_zf1 (s)                   2.08955\n",
      "time/backward_zf2 (s)                   2.01267\n",
      "time/data sampling (s)                  0.290291\n",
      "time/data storing (s)                   0.015235\n",
      "time/evaluation sampling (s)            1.80001\n",
      "time/exploration sampling (s)           0.324392\n",
      "time/logging (s)                        0.0122993\n",
      "time/preback_alpha (s)                  1.01442\n",
      "time/preback_policy (s)                 1.13582\n",
      "time/preback_start (s)                  0.147534\n",
      "time/preback_zf (s)                     5.21808\n",
      "time/saving (s)                         0.00637432\n",
      "time/training (s)                       2.23988\n",
      "time/epoch (s)                         18.26\n",
      "time/total (s)                       3791.88\n",
      "Epoch                                 211\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:55:46.782106 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 212 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 223000\n",
      "trainer/ZF1 Loss                       12.6471\n",
      "trainer/ZF2 Loss                       12.8588\n",
      "trainer/ZF Expert Reward               13.8683\n",
      "trainer/ZF Policy Reward                3.01685\n",
      "trainer/ZF CHI2 Term                   43.2649\n",
      "trainer/Policy Loss                  -718.464\n",
      "trainer/Bias Loss                      59.469\n",
      "trainer/Bias Value                     14.3832\n",
      "trainer/Policy Grad Norm              200.241\n",
      "trainer/Policy Param Norm              36.4553\n",
      "trainer/Zf1 Grad Norm                1465.8\n",
      "trainer/Zf1 Param Norm                114.926\n",
      "trainer/Zf2 Grad Norm                1464.94\n",
      "trainer/Zf2 Param Norm                113.146\n",
      "trainer/Z Expert Predictions Mean     825.376\n",
      "trainer/Z Expert Predictions Std       42.0829\n",
      "trainer/Z Expert Predictions Max      885.857\n",
      "trainer/Z Expert Predictions Min      556.188\n",
      "trainer/Z Policy Predictions Mean     716.795\n",
      "trainer/Z Policy Predictions Std      237.424\n",
      "trainer/Z Policy Predictions Max      868.261\n",
      "trainer/Z Policy Predictions Min     -561.223\n",
      "trainer/Z Expert Targets Mean         811.508\n",
      "trainer/Z Expert Targets Std           44.6338\n",
      "trainer/Z Expert Targets Max          881.531\n",
      "trainer/Z Expert Targets Min          514.723\n",
      "trainer/Z Policy Targets Mean         713.778\n",
      "trainer/Z Policy Targets Std          234.176\n",
      "trainer/Z Policy Targets Max          850.571\n",
      "trainer/Z Policy Targets Min         -554.837\n",
      "trainer/Log Pis Mean                   19.8591\n",
      "trainer/Log Pis Std                     4.19915\n",
      "trainer/Policy mu Mean                  0.0302948\n",
      "trainer/Policy mu Std                   0.936912\n",
      "trainer/Policy log std Mean            -3.31611\n",
      "trainer/Policy log std Std              0.854458\n",
      "trainer/Alpha                           0.148318\n",
      "trainer/Alpha Loss                      0.0209009\n",
      "exploration/num steps total        217458\n",
      "exploration/num paths total           317\n",
      "evaluation/num steps total              1.87316e+06\n",
      "evaluation/num paths total           2176\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69956\n",
      "evaluation/Rewards Std                  1.10373\n",
      "evaluation/Rewards Max                  6.78344\n",
      "evaluation/Rewards Min                 -2.35841\n",
      "evaluation/Returns Mean              4699.56\n",
      "evaluation/Returns Std                167.692\n",
      "evaluation/Returns Max               4905.25\n",
      "evaluation/Returns Min               4378.6\n",
      "evaluation/Estimation Bias Mean       748.762\n",
      "evaluation/Estimation Bias Std        157.58\n",
      "evaluation/EB/Q_True Mean              44.847\n",
      "evaluation/EB/Q_True Std              138.351\n",
      "evaluation/EB/Q_Pred Mean             793.609\n",
      "evaluation/EB/Q_Pred Std               71.2545\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4699.56\n",
      "evaluation/Actions Mean                 0.0230642\n",
      "evaluation/Actions Std                  0.539149\n",
      "evaluation/Actions Max                  0.999874\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.92556\n",
      "time/backward_zf1 (s)                   2.04706\n",
      "time/backward_zf2 (s)                   1.97796\n",
      "time/data sampling (s)                  0.283939\n",
      "time/data storing (s)                   0.0148315\n",
      "time/evaluation sampling (s)            1.73236\n",
      "time/exploration sampling (s)           0.323297\n",
      "time/logging (s)                        0.0124184\n",
      "time/preback_alpha (s)                  0.969884\n",
      "time/preback_policy (s)                 1.07348\n",
      "time/preback_start (s)                  0.149981\n",
      "time/preback_zf (s)                     5.23469\n",
      "time/saving (s)                         0.00614828\n",
      "time/training (s)                       2.44123\n",
      "time/epoch (s)                         18.1928\n",
      "time/total (s)                       3810.09\n",
      "Epoch                                 212\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:56:04.726958 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 213 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 224000\n",
      "trainer/ZF1 Loss                      151.321\n",
      "trainer/ZF2 Loss                      139.337\n",
      "trainer/ZF Expert Reward               14.7505\n",
      "trainer/ZF Policy Reward                3.43518\n",
      "trainer/ZF CHI2 Term                  176.116\n",
      "trainer/Policy Loss                  -667.434\n",
      "trainer/Bias Loss                      46.5494\n",
      "trainer/Bias Value                     14.3962\n",
      "trainer/Policy Grad Norm              155.868\n",
      "trainer/Policy Param Norm              36.483\n",
      "trainer/Zf1 Grad Norm                2137.7\n",
      "trainer/Zf1 Param Norm                115.1\n",
      "trainer/Zf2 Grad Norm                2242.79\n",
      "trainer/Zf2 Param Norm                113.308\n",
      "trainer/Z Expert Predictions Mean     817.652\n",
      "trainer/Z Expert Predictions Std       46.9498\n",
      "trainer/Z Expert Predictions Max      885.118\n",
      "trainer/Z Expert Predictions Min      467.845\n",
      "trainer/Z Policy Predictions Mean     667.312\n",
      "trainer/Z Policy Predictions Std      315.509\n",
      "trainer/Z Policy Predictions Max      859.294\n",
      "trainer/Z Policy Predictions Min     -614.473\n",
      "trainer/Z Expert Targets Mean         802.901\n",
      "trainer/Z Expert Targets Std           48.9683\n",
      "trainer/Z Expert Targets Max          877.53\n",
      "trainer/Z Expert Targets Min          435.4\n",
      "trainer/Z Policy Targets Mean         663.877\n",
      "trainer/Z Policy Targets Std          310.837\n",
      "trainer/Z Policy Targets Max          856.541\n",
      "trainer/Z Policy Targets Min         -620.384\n",
      "trainer/Log Pis Mean                   19.6678\n",
      "trainer/Log Pis Std                     4.2583\n",
      "trainer/Policy mu Mean                  0.0495691\n",
      "trainer/Policy mu Std                   0.976096\n",
      "trainer/Policy log std Mean            -3.20981\n",
      "trainer/Policy log std Std              0.973415\n",
      "trainer/Alpha                           0.147636\n",
      "trainer/Alpha Loss                      0.0490519\n",
      "exploration/num steps total        218884\n",
      "exploration/num paths total           319\n",
      "evaluation/num steps total              1.88316e+06\n",
      "evaluation/num paths total           2186\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68943\n",
      "evaluation/Rewards Std                  0.953331\n",
      "evaluation/Rewards Max                  6.74684\n",
      "evaluation/Rewards Min                 -1.5701\n",
      "evaluation/Returns Mean              4689.43\n",
      "evaluation/Returns Std                102.473\n",
      "evaluation/Returns Max               4861.9\n",
      "evaluation/Returns Min               4542.8\n",
      "evaluation/Estimation Bias Mean       760.881\n",
      "evaluation/Estimation Bias Std        140.833\n",
      "evaluation/EB/Q_True Mean              43.0521\n",
      "evaluation/EB/Q_True Std              132.458\n",
      "evaluation/EB/Q_Pred Mean             803.933\n",
      "evaluation/EB/Q_Pred Std               51.269\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4689.43\n",
      "evaluation/Actions Mean                 0.0210306\n",
      "evaluation/Actions Std                  0.541019\n",
      "evaluation/Actions Max                  0.999699\n",
      "evaluation/Actions Min                 -0.999387\n",
      "time/backward_policy (s)                1.85742\n",
      "time/backward_zf1 (s)                   2.00054\n",
      "time/backward_zf2 (s)                   1.92032\n",
      "time/data sampling (s)                  0.293137\n",
      "time/data storing (s)                   0.0146553\n",
      "time/evaluation sampling (s)            1.75557\n",
      "time/exploration sampling (s)           0.322844\n",
      "time/logging (s)                        0.0118505\n",
      "time/preback_alpha (s)                  0.93654\n",
      "time/preback_policy (s)                 1.03074\n",
      "time/preback_start (s)                  0.146889\n",
      "time/preback_zf (s)                     5.18936\n",
      "time/saving (s)                         0.00629764\n",
      "time/training (s)                       2.39015\n",
      "time/epoch (s)                         17.8763\n",
      "time/total (s)                       3827.99\n",
      "Epoch                                 213\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:56:22.941636 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 214 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 225000\n",
      "trainer/ZF1 Loss                       12.2822\n",
      "trainer/ZF2 Loss                       10.9191\n",
      "trainer/ZF Expert Reward               16.3633\n",
      "trainer/ZF Policy Reward                4.66415\n",
      "trainer/ZF CHI2 Term                   43.3714\n",
      "trainer/Policy Loss                  -702.234\n",
      "trainer/Bias Loss                      55.6982\n",
      "trainer/Bias Value                     14.4057\n",
      "trainer/Policy Grad Norm              158.225\n",
      "trainer/Policy Param Norm              36.5133\n",
      "trainer/Zf1 Grad Norm                1135.23\n",
      "trainer/Zf1 Param Norm                115.263\n",
      "trainer/Zf2 Grad Norm                1145.61\n",
      "trainer/Zf2 Param Norm                113.481\n",
      "trainer/Z Expert Predictions Mean     817.291\n",
      "trainer/Z Expert Predictions Std       46.4547\n",
      "trainer/Z Expert Predictions Max      891.61\n",
      "trainer/Z Expert Predictions Min      596.307\n",
      "trainer/Z Policy Predictions Mean     701.561\n",
      "trainer/Z Policy Predictions Std      265.154\n",
      "trainer/Z Policy Predictions Max      861.495\n",
      "trainer/Z Policy Predictions Min     -599.884\n",
      "trainer/Z Expert Targets Mean         800.928\n",
      "trainer/Z Expert Targets Std           46.9817\n",
      "trainer/Z Expert Targets Max          872.444\n",
      "trainer/Z Expert Targets Min          567.464\n",
      "trainer/Z Policy Targets Mean         696.896\n",
      "trainer/Z Policy Targets Std          261.281\n",
      "trainer/Z Policy Targets Max          851.164\n",
      "trainer/Z Policy Targets Min         -581.308\n",
      "trainer/Log Pis Mean                   20.2744\n",
      "trainer/Log Pis Std                     4.09263\n",
      "trainer/Policy mu Mean                  0.0106116\n",
      "trainer/Policy mu Std                   0.979937\n",
      "trainer/Policy log std Mean            -3.28802\n",
      "trainer/Policy log std Std              0.891013\n",
      "trainer/Alpha                           0.14738\n",
      "trainer/Alpha Loss                     -0.0404425\n",
      "exploration/num steps total        219884\n",
      "exploration/num paths total           320\n",
      "evaluation/num steps total              1.89316e+06\n",
      "evaluation/num paths total           2196\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.58867\n",
      "evaluation/Rewards Std                  1.22294\n",
      "evaluation/Rewards Max                  6.56748\n",
      "evaluation/Rewards Min                 -3.69481\n",
      "evaluation/Returns Mean              4588.67\n",
      "evaluation/Returns Std                247.875\n",
      "evaluation/Returns Max               4862.36\n",
      "evaluation/Returns Min               3906.92\n",
      "evaluation/Estimation Bias Mean       733.792\n",
      "evaluation/Estimation Bias Std        190.474\n",
      "evaluation/EB/Q_True Mean              41.8649\n",
      "evaluation/EB/Q_True Std              128.386\n",
      "evaluation/EB/Q_Pred Mean             775.657\n",
      "evaluation/EB/Q_Pred Std              148.664\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4588.67\n",
      "evaluation/Actions Mean                 0.033343\n",
      "evaluation/Actions Std                  0.535783\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.95937\n",
      "time/backward_zf1 (s)                   2.09067\n",
      "time/backward_zf2 (s)                   2.02854\n",
      "time/data sampling (s)                  0.300975\n",
      "time/data storing (s)                   0.014197\n",
      "time/evaluation sampling (s)            1.74182\n",
      "time/exploration sampling (s)           0.315473\n",
      "time/logging (s)                        0.0121416\n",
      "time/preback_alpha (s)                  1.03703\n",
      "time/preback_policy (s)                 1.18041\n",
      "time/preback_start (s)                  0.146023\n",
      "time/preback_zf (s)                     5.21361\n",
      "time/saving (s)                         0.00626358\n",
      "time/training (s)                       2.09842\n",
      "time/epoch (s)                         18.145\n",
      "time/total (s)                       3846.15\n",
      "Epoch                                 214\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:56:40.986235 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 215 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 226000\n",
      "trainer/ZF1 Loss                        4.89056\n",
      "trainer/ZF2 Loss                        1.81079\n",
      "trainer/ZF Expert Reward               16.3441\n",
      "trainer/ZF Policy Reward                2.25772\n",
      "trainer/ZF CHI2 Term                   37.099\n",
      "trainer/Policy Loss                  -682.427\n",
      "trainer/Bias Loss                      64.3902\n",
      "trainer/Bias Value                     14.4167\n",
      "trainer/Policy Grad Norm              159.278\n",
      "trainer/Policy Param Norm              36.5387\n",
      "trainer/Zf1 Grad Norm                1183.7\n",
      "trainer/Zf1 Param Norm                115.428\n",
      "trainer/Zf2 Grad Norm                 918.117\n",
      "trainer/Zf2 Param Norm                113.632\n",
      "trainer/Z Expert Predictions Mean     813.019\n",
      "trainer/Z Expert Predictions Std       48.8754\n",
      "trainer/Z Expert Predictions Max      876.519\n",
      "trainer/Z Expert Predictions Min      443.062\n",
      "trainer/Z Policy Predictions Mean     684.001\n",
      "trainer/Z Policy Predictions Std      271.451\n",
      "trainer/Z Policy Predictions Max      872.141\n",
      "trainer/Z Policy Predictions Min     -541.68\n",
      "trainer/Z Expert Targets Mean         796.675\n",
      "trainer/Z Expert Targets Std           50.4807\n",
      "trainer/Z Expert Targets Max          868.454\n",
      "trainer/Z Expert Targets Min          434.47\n",
      "trainer/Z Policy Targets Mean         681.743\n",
      "trainer/Z Policy Targets Std          267.179\n",
      "trainer/Z Policy Targets Max          850.661\n",
      "trainer/Z Policy Targets Min         -550.107\n",
      "trainer/Log Pis Mean                   19.8605\n",
      "trainer/Log Pis Std                     4.23659\n",
      "trainer/Policy mu Mean                  0.0763423\n",
      "trainer/Policy mu Std                   0.969477\n",
      "trainer/Policy log std Mean            -3.24141\n",
      "trainer/Policy log std Std              0.903405\n",
      "trainer/Alpha                           0.147885\n",
      "trainer/Alpha Loss                      0.0206303\n",
      "exploration/num steps total        220884\n",
      "exploration/num paths total           321\n",
      "evaluation/num steps total              1.90316e+06\n",
      "evaluation/num paths total           2206\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.58323\n",
      "evaluation/Rewards Std                  0.979134\n",
      "evaluation/Rewards Max                  6.92326\n",
      "evaluation/Rewards Min                 -1.76781\n",
      "evaluation/Returns Mean              4583.23\n",
      "evaluation/Returns Std                 80.1156\n",
      "evaluation/Returns Max               4747.39\n",
      "evaluation/Returns Min               4412.34\n",
      "evaluation/Estimation Bias Mean       742.557\n",
      "evaluation/Estimation Bias Std        141.38\n",
      "evaluation/EB/Q_True Mean              42.0912\n",
      "evaluation/EB/Q_True Std              129.379\n",
      "evaluation/EB/Q_Pred Mean             784.648\n",
      "evaluation/EB/Q_Pred Std               56.5255\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4583.23\n",
      "evaluation/Actions Mean                 0.0218144\n",
      "evaluation/Actions Std                  0.543922\n",
      "evaluation/Actions Max                  0.999685\n",
      "evaluation/Actions Min                 -0.99976\n",
      "time/backward_policy (s)                1.93967\n",
      "time/backward_zf1 (s)                   2.05618\n",
      "time/backward_zf2 (s)                   1.99353\n",
      "time/data sampling (s)                  0.297015\n",
      "time/data storing (s)                   0.0148363\n",
      "time/evaluation sampling (s)            1.70754\n",
      "time/exploration sampling (s)           0.319771\n",
      "time/logging (s)                        0.0132973\n",
      "time/preback_alpha (s)                  1.02161\n",
      "time/preback_policy (s)                 1.15136\n",
      "time/preback_start (s)                  0.145917\n",
      "time/preback_zf (s)                     5.17828\n",
      "time/saving (s)                         0.0210862\n",
      "time/training (s)                       2.11777\n",
      "time/epoch (s)                         17.9779\n",
      "time/total (s)                       3864.15\n",
      "Epoch                                 215\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:56:59.295207 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 216 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 227000\n",
      "trainer/ZF1 Loss                       16.8457\n",
      "trainer/ZF2 Loss                       14.2933\n",
      "trainer/ZF Expert Reward               12.2086\n",
      "trainer/ZF Policy Reward                3.51877\n",
      "trainer/ZF CHI2 Term                   44.4193\n",
      "trainer/Policy Loss                  -681.066\n",
      "trainer/Bias Loss                      55.5085\n",
      "trainer/Bias Value                     14.4277\n",
      "trainer/Policy Grad Norm              159.728\n",
      "trainer/Policy Param Norm              36.5655\n",
      "trainer/Zf1 Grad Norm                1329.46\n",
      "trainer/Zf1 Param Norm                115.601\n",
      "trainer/Zf2 Grad Norm                1519.27\n",
      "trainer/Zf2 Param Norm                113.807\n",
      "trainer/Z Expert Predictions Mean     800.598\n",
      "trainer/Z Expert Predictions Std       48.2158\n",
      "trainer/Z Expert Predictions Max      876.078\n",
      "trainer/Z Expert Predictions Min      597.665\n",
      "trainer/Z Policy Predictions Mean     680.669\n",
      "trainer/Z Policy Predictions Std      271.834\n",
      "trainer/Z Policy Predictions Max      858.545\n",
      "trainer/Z Policy Predictions Min     -596.046\n",
      "trainer/Z Expert Targets Mean         788.39\n",
      "trainer/Z Expert Targets Std           50.7596\n",
      "trainer/Z Expert Targets Max          863.44\n",
      "trainer/Z Expert Targets Min          577.957\n",
      "trainer/Z Policy Targets Mean         677.15\n",
      "trainer/Z Policy Targets Std          269.239\n",
      "trainer/Z Policy Targets Max          845.134\n",
      "trainer/Z Policy Targets Min         -586.777\n",
      "trainer/Log Pis Mean                   20.3636\n",
      "trainer/Log Pis Std                     4.36229\n",
      "trainer/Policy mu Mean                  0.0387785\n",
      "trainer/Policy mu Std                   1.06413\n",
      "trainer/Policy log std Mean            -3.22924\n",
      "trainer/Policy log std Std              0.957086\n",
      "trainer/Alpha                           0.148301\n",
      "trainer/Alpha Loss                     -0.0539175\n",
      "exploration/num steps total        222884\n",
      "exploration/num paths total           323\n",
      "evaluation/num steps total              1.91316e+06\n",
      "evaluation/num paths total           2216\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.35282\n",
      "evaluation/Rewards Std                  1.64587\n",
      "evaluation/Rewards Max                  6.76826\n",
      "evaluation/Rewards Min                 -2.86541\n",
      "evaluation/Returns Mean              4352.82\n",
      "evaluation/Returns Std                838.641\n",
      "evaluation/Returns Max               4812.05\n",
      "evaluation/Returns Min               1849.43\n",
      "evaluation/Estimation Bias Mean       683.069\n",
      "evaluation/Estimation Bias Std        270.837\n",
      "evaluation/EB/Q_True Mean              42.5105\n",
      "evaluation/EB/Q_True Std              131.044\n",
      "evaluation/EB/Q_Pred Mean             725.58\n",
      "evaluation/EB/Q_Pred Std              246.899\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4352.82\n",
      "evaluation/Actions Mean                 0.04216\n",
      "evaluation/Actions Std                  0.552183\n",
      "evaluation/Actions Max                  0.999916\n",
      "evaluation/Actions Min                 -0.999788\n",
      "time/backward_policy (s)                1.98342\n",
      "time/backward_zf1 (s)                   2.09358\n",
      "time/backward_zf2 (s)                   2.02293\n",
      "time/data sampling (s)                  0.294996\n",
      "time/data storing (s)                   0.014443\n",
      "time/evaluation sampling (s)            1.7656\n",
      "time/exploration sampling (s)           0.326909\n",
      "time/logging (s)                        0.0121224\n",
      "time/preback_alpha (s)                  1.04933\n",
      "time/preback_policy (s)                 1.17601\n",
      "time/preback_start (s)                  0.148241\n",
      "time/preback_zf (s)                     5.20413\n",
      "time/saving (s)                         0.00630893\n",
      "time/training (s)                       2.14104\n",
      "time/epoch (s)                         18.2391\n",
      "time/total (s)                       3882.41\n",
      "Epoch                                 216\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:57:16.816525 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 217 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 228000\n",
      "trainer/ZF1 Loss                       10.5634\n",
      "trainer/ZF2 Loss                        5.26865\n",
      "trainer/ZF Expert Reward               12.3701\n",
      "trainer/ZF Policy Reward               -0.377021\n",
      "trainer/ZF CHI2 Term                   40.9141\n",
      "trainer/Policy Loss                  -671.443\n",
      "trainer/Bias Loss                      55.4695\n",
      "trainer/Bias Value                     14.437\n",
      "trainer/Policy Grad Norm              129.822\n",
      "trainer/Policy Param Norm              36.5953\n",
      "trainer/Zf1 Grad Norm                1674.21\n",
      "trainer/Zf1 Param Norm                115.756\n",
      "trainer/Zf2 Grad Norm                1284.96\n",
      "trainer/Zf2 Param Norm                113.957\n",
      "trainer/Z Expert Predictions Mean     806.045\n",
      "trainer/Z Expert Predictions Std       37.5475\n",
      "trainer/Z Expert Predictions Max      868.166\n",
      "trainer/Z Expert Predictions Min      616.355\n",
      "trainer/Z Policy Predictions Mean     669.25\n",
      "trainer/Z Policy Predictions Std      307.57\n",
      "trainer/Z Policy Predictions Max      855.967\n",
      "trainer/Z Policy Predictions Min     -583\n",
      "trainer/Z Expert Targets Mean         793.675\n",
      "trainer/Z Expert Targets Std           38.6027\n",
      "trainer/Z Expert Targets Max          862.649\n",
      "trainer/Z Expert Targets Min          602.421\n",
      "trainer/Z Policy Targets Mean         669.627\n",
      "trainer/Z Policy Targets Std          304.501\n",
      "trainer/Z Policy Targets Max          851.394\n",
      "trainer/Z Policy Targets Min         -580.867\n",
      "trainer/Log Pis Mean                   20.4556\n",
      "trainer/Log Pis Std                     3.85385\n",
      "trainer/Policy mu Mean                  0.0570523\n",
      "trainer/Policy mu Std                   1.00023\n",
      "trainer/Policy log std Mean            -3.25871\n",
      "trainer/Policy log std Std              0.949147\n",
      "trainer/Alpha                           0.148047\n",
      "trainer/Alpha Loss                     -0.067441\n",
      "exploration/num steps total        223884\n",
      "exploration/num paths total           324\n",
      "evaluation/num steps total              1.92316e+06\n",
      "evaluation/num paths total           2226\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6883\n",
      "evaluation/Rewards Std                  0.99557\n",
      "evaluation/Rewards Max                  6.78863\n",
      "evaluation/Rewards Min                 -1.6016\n",
      "evaluation/Returns Mean              4688.3\n",
      "evaluation/Returns Std                 85.8414\n",
      "evaluation/Returns Max               4806.83\n",
      "evaluation/Returns Min               4579.68\n",
      "evaluation/Estimation Bias Mean       735.13\n",
      "evaluation/Estimation Bias Std        152.738\n",
      "evaluation/EB/Q_True Mean              44.1717\n",
      "evaluation/EB/Q_True Std              136.251\n",
      "evaluation/EB/Q_Pred Mean             779.302\n",
      "evaluation/EB/Q_Pred Std               59.7316\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4688.3\n",
      "evaluation/Actions Mean                 0.0198001\n",
      "evaluation/Actions Std                  0.543701\n",
      "evaluation/Actions Max                  0.999691\n",
      "evaluation/Actions Min                 -0.999679\n",
      "time/backward_policy (s)                1.78571\n",
      "time/backward_zf1 (s)                   1.90675\n",
      "time/backward_zf2 (s)                   1.82853\n",
      "time/data sampling (s)                  0.291997\n",
      "time/data storing (s)                   0.0144631\n",
      "time/evaluation sampling (s)            1.68276\n",
      "time/exploration sampling (s)           0.316592\n",
      "time/logging (s)                        0.0120703\n",
      "time/preback_alpha (s)                  0.932611\n",
      "time/preback_policy (s)                 1.01072\n",
      "time/preback_start (s)                  0.14673\n",
      "time/preback_zf (s)                     5.16132\n",
      "time/saving (s)                         0.00629599\n",
      "time/training (s)                       2.35254\n",
      "time/epoch (s)                         17.4491\n",
      "time/total (s)                       3899.88\n",
      "Epoch                                 217\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:57:34.796413 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 218 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 229000\n",
      "trainer/ZF1 Loss                        7.22571\n",
      "trainer/ZF2 Loss                        8.39466\n",
      "trainer/ZF Expert Reward               12.3397\n",
      "trainer/ZF Policy Reward                1.25131\n",
      "trainer/ZF CHI2 Term                   38.8144\n",
      "trainer/Policy Loss                  -684.672\n",
      "trainer/Bias Loss                      58.9079\n",
      "trainer/Bias Value                     14.4451\n",
      "trainer/Policy Grad Norm              127.278\n",
      "trainer/Policy Param Norm              36.6294\n",
      "trainer/Zf1 Grad Norm                1514.02\n",
      "trainer/Zf1 Param Norm                115.914\n",
      "trainer/Zf2 Grad Norm                1577.3\n",
      "trainer/Zf2 Param Norm                114.118\n",
      "trainer/Z Expert Predictions Mean     795.847\n",
      "trainer/Z Expert Predictions Std       46.9092\n",
      "trainer/Z Expert Predictions Max      865.216\n",
      "trainer/Z Expert Predictions Min      546.562\n",
      "trainer/Z Policy Predictions Mean     683.162\n",
      "trainer/Z Policy Predictions Std      256.79\n",
      "trainer/Z Policy Predictions Max      852.125\n",
      "trainer/Z Policy Predictions Min     -536.503\n",
      "trainer/Z Expert Targets Mean         783.507\n",
      "trainer/Z Expert Targets Std           47.9997\n",
      "trainer/Z Expert Targets Max          856.57\n",
      "trainer/Z Expert Targets Min          522.417\n",
      "trainer/Z Policy Targets Mean         681.911\n",
      "trainer/Z Policy Targets Std          254.082\n",
      "trainer/Z Policy Targets Max          841.18\n",
      "trainer/Z Policy Targets Min         -545.318\n",
      "trainer/Log Pis Mean                   20.117\n",
      "trainer/Log Pis Std                     3.80271\n",
      "trainer/Policy mu Mean                  0.0708913\n",
      "trainer/Policy mu Std                   0.900259\n",
      "trainer/Policy log std Mean            -3.35558\n",
      "trainer/Policy log std Std              0.849863\n",
      "trainer/Alpha                           0.147871\n",
      "trainer/Alpha Loss                     -0.0172969\n",
      "exploration/num steps total        224884\n",
      "exploration/num paths total           325\n",
      "evaluation/num steps total              1.93316e+06\n",
      "evaluation/num paths total           2236\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68064\n",
      "evaluation/Rewards Std                  0.930081\n",
      "evaluation/Rewards Max                  6.66407\n",
      "evaluation/Rewards Min                 -1.69462\n",
      "evaluation/Returns Mean              4680.64\n",
      "evaluation/Returns Std                 80.3325\n",
      "evaluation/Returns Max               4811.29\n",
      "evaluation/Returns Min               4560.28\n",
      "evaluation/Estimation Bias Mean       735.341\n",
      "evaluation/Estimation Bias Std        146.078\n",
      "evaluation/EB/Q_True Mean              44.2676\n",
      "evaluation/EB/Q_True Std              136.185\n",
      "evaluation/EB/Q_Pred Mean             779.609\n",
      "evaluation/EB/Q_Pred Std               51.4837\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4680.64\n",
      "evaluation/Actions Mean                 0.0289742\n",
      "evaluation/Actions Std                  0.536512\n",
      "evaluation/Actions Max                  0.999508\n",
      "evaluation/Actions Min                 -0.999472\n",
      "time/backward_policy (s)                1.92597\n",
      "time/backward_zf1 (s)                   2.06135\n",
      "time/backward_zf2 (s)                   1.99877\n",
      "time/data sampling (s)                  0.292413\n",
      "time/data storing (s)                   0.0146022\n",
      "time/evaluation sampling (s)            1.68374\n",
      "time/exploration sampling (s)           0.318949\n",
      "time/logging (s)                        0.0118312\n",
      "time/preback_alpha (s)                  1.0167\n",
      "time/preback_policy (s)                 1.13366\n",
      "time/preback_start (s)                  0.147096\n",
      "time/preback_zf (s)                     5.17686\n",
      "time/saving (s)                         0.00631153\n",
      "time/training (s)                       2.12576\n",
      "time/epoch (s)                         17.914\n",
      "time/total (s)                       3917.82\n",
      "Epoch                                 218\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:57:53.015913 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 219 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 230000\n",
      "trainer/ZF1 Loss                       89.146\n",
      "trainer/ZF2 Loss                       79.8967\n",
      "trainer/ZF Expert Reward               13.1328\n",
      "trainer/ZF Policy Reward                2.02065\n",
      "trainer/ZF CHI2 Term                  115.416\n",
      "trainer/Policy Loss                  -667.237\n",
      "trainer/Bias Loss                      50.4516\n",
      "trainer/Bias Value                     14.4559\n",
      "trainer/Policy Grad Norm              166.529\n",
      "trainer/Policy Param Norm              36.6611\n",
      "trainer/Zf1 Grad Norm                1608.97\n",
      "trainer/Zf1 Param Norm                116.077\n",
      "trainer/Zf2 Grad Norm                1204.48\n",
      "trainer/Zf2 Param Norm                114.285\n",
      "trainer/Z Expert Predictions Mean     794.913\n",
      "trainer/Z Expert Predictions Std       64.0021\n",
      "trainer/Z Expert Predictions Max      877.642\n",
      "trainer/Z Expert Predictions Min        7.51464\n",
      "trainer/Z Policy Predictions Mean     666.912\n",
      "trainer/Z Policy Predictions Std      281.125\n",
      "trainer/Z Policy Predictions Max      835.95\n",
      "trainer/Z Policy Predictions Min     -573.228\n",
      "trainer/Z Expert Targets Mean         781.78\n",
      "trainer/Z Expert Targets Std           65.1325\n",
      "trainer/Z Expert Targets Max          850.548\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         664.891\n",
      "trainer/Z Policy Targets Std          268.846\n",
      "trainer/Z Policy Targets Max          841.556\n",
      "trainer/Z Policy Targets Min         -532.855\n",
      "trainer/Log Pis Mean                   19.9818\n",
      "trainer/Log Pis Std                     4.03533\n",
      "trainer/Policy mu Mean                  0.0378495\n",
      "trainer/Policy mu Std                   0.92456\n",
      "trainer/Policy log std Mean            -3.26822\n",
      "trainer/Policy log std Std              0.895696\n",
      "trainer/Alpha                           0.149848\n",
      "trainer/Alpha Loss                      0.00272105\n",
      "exploration/num steps total        224884\n",
      "exploration/num paths total           325\n",
      "evaluation/num steps total              1.94316e+06\n",
      "evaluation/num paths total           2246\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63603\n",
      "evaluation/Rewards Std                  1.01573\n",
      "evaluation/Rewards Max                  6.73765\n",
      "evaluation/Rewards Min                 -1.79848\n",
      "evaluation/Returns Mean              4636.03\n",
      "evaluation/Returns Std                 47.9284\n",
      "evaluation/Returns Max               4750.17\n",
      "evaluation/Returns Min               4576.94\n",
      "evaluation/Estimation Bias Mean       727.664\n",
      "evaluation/Estimation Bias Std        141.716\n",
      "evaluation/EB/Q_True Mean              42.1286\n",
      "evaluation/EB/Q_True Std              129.901\n",
      "evaluation/EB/Q_Pred Mean             769.793\n",
      "evaluation/EB/Q_Pred Std               59.8401\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4636.03\n",
      "evaluation/Actions Mean                 0.0139614\n",
      "evaluation/Actions Std                  0.539769\n",
      "evaluation/Actions Max                  0.999967\n",
      "evaluation/Actions Min                 -0.999575\n",
      "time/backward_policy (s)                1.95746\n",
      "time/backward_zf1 (s)                   2.07717\n",
      "time/backward_zf2 (s)                   2.02589\n",
      "time/data sampling (s)                  0.29179\n",
      "time/data storing (s)                   0.0166616\n",
      "time/evaluation sampling (s)            1.75876\n",
      "time/exploration sampling (s)           0.332424\n",
      "time/logging (s)                        0.0118741\n",
      "time/preback_alpha (s)                  1.02787\n",
      "time/preback_policy (s)                 1.1693\n",
      "time/preback_start (s)                  0.148683\n",
      "time/preback_zf (s)                     5.18625\n",
      "time/saving (s)                         0.007057\n",
      "time/training (s)                       2.13866\n",
      "time/epoch (s)                         18.1498\n",
      "time/total (s)                       3935.99\n",
      "Epoch                                 219\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:58:10.692275 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 220 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 231000\n",
      "trainer/ZF1 Loss                        6.17815\n",
      "trainer/ZF2 Loss                        6.20844\n",
      "trainer/ZF Expert Reward               16.2917\n",
      "trainer/ZF Policy Reward                5.46373\n",
      "trainer/ZF CHI2 Term                   37.2282\n",
      "trainer/Policy Loss                  -686.89\n",
      "trainer/Bias Loss                      47.2802\n",
      "trainer/Bias Value                     14.4679\n",
      "trainer/Policy Grad Norm              142.585\n",
      "trainer/Policy Param Norm              36.69\n",
      "trainer/Zf1 Grad Norm                1343.86\n",
      "trainer/Zf1 Param Norm                116.23\n",
      "trainer/Zf2 Grad Norm                1049.94\n",
      "trainer/Zf2 Param Norm                114.421\n",
      "trainer/Z Expert Predictions Mean     795.906\n",
      "trainer/Z Expert Predictions Std       40.8816\n",
      "trainer/Z Expert Predictions Max      865.756\n",
      "trainer/Z Expert Predictions Min      570.004\n",
      "trainer/Z Policy Predictions Mean     686.826\n",
      "trainer/Z Policy Predictions Std      251.983\n",
      "trainer/Z Policy Predictions Max      847.112\n",
      "trainer/Z Policy Predictions Min     -636.588\n",
      "trainer/Z Expert Targets Mean         779.615\n",
      "trainer/Z Expert Targets Std           43.215\n",
      "trainer/Z Expert Targets Max          852.569\n",
      "trainer/Z Expert Targets Min          557.883\n",
      "trainer/Z Policy Targets Mean         681.362\n",
      "trainer/Z Policy Targets Std          247.93\n",
      "trainer/Z Policy Targets Max          828.312\n",
      "trainer/Z Policy Targets Min         -625.676\n",
      "trainer/Log Pis Mean                   20.411\n",
      "trainer/Log Pis Std                     4.46125\n",
      "trainer/Policy mu Mean                  0.0237375\n",
      "trainer/Policy mu Std                   0.957055\n",
      "trainer/Policy log std Mean            -3.32884\n",
      "trainer/Policy log std Std              0.89274\n",
      "trainer/Alpha                           0.148635\n",
      "trainer/Alpha Loss                     -0.0610926\n",
      "exploration/num steps total        225884\n",
      "exploration/num paths total           326\n",
      "evaluation/num steps total              1.95316e+06\n",
      "evaluation/num paths total           2256\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.21315\n",
      "evaluation/Rewards Std                  1.94437\n",
      "evaluation/Rewards Max                  6.6598\n",
      "evaluation/Rewards Min                 -2.98828\n",
      "evaluation/Returns Mean              4213.15\n",
      "evaluation/Returns Std               1445.61\n",
      "evaluation/Returns Max               4815.93\n",
      "evaluation/Returns Min               -112.376\n",
      "evaluation/Estimation Bias Mean       645.024\n",
      "evaluation/Estimation Bias Std        322.613\n",
      "evaluation/EB/Q_True Mean              40.7937\n",
      "evaluation/EB/Q_True Std              125.208\n",
      "evaluation/EB/Q_Pred Mean             685.817\n",
      "evaluation/EB/Q_Pred Std              309.248\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4213.15\n",
      "evaluation/Actions Mean                 0.0550962\n",
      "evaluation/Actions Std                  0.566661\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.78833\n",
      "time/backward_zf1 (s)                   1.91088\n",
      "time/backward_zf2 (s)                   1.82883\n",
      "time/data sampling (s)                  0.279488\n",
      "time/data storing (s)                   0.0146955\n",
      "time/evaluation sampling (s)            1.76154\n",
      "time/exploration sampling (s)           0.321776\n",
      "time/logging (s)                        0.0121708\n",
      "time/preback_alpha (s)                  0.929408\n",
      "time/preback_policy (s)                 1.0106\n",
      "time/preback_start (s)                  0.145939\n",
      "time/preback_zf (s)                     5.17563\n",
      "time/saving (s)                         0.00620921\n",
      "time/training (s)                       2.41975\n",
      "time/epoch (s)                         17.6052\n",
      "time/total (s)                       3953.61\n",
      "Epoch                                 220\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:58:28.530357 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 221 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 232000\n",
      "trainer/ZF1 Loss                      131.61\n",
      "trainer/ZF2 Loss                      128.429\n",
      "trainer/ZF Expert Reward               15.6426\n",
      "trainer/ZF Policy Reward                4.96155\n",
      "trainer/ZF CHI2 Term                  160.685\n",
      "trainer/Policy Loss                  -658.896\n",
      "trainer/Bias Loss                      45.9527\n",
      "trainer/Bias Value                     14.4789\n",
      "trainer/Policy Grad Norm              150.988\n",
      "trainer/Policy Param Norm              36.7228\n",
      "trainer/Zf1 Grad Norm                1552.71\n",
      "trainer/Zf1 Param Norm                116.381\n",
      "trainer/Zf2 Grad Norm                1359\n",
      "trainer/Zf2 Param Norm                114.572\n",
      "trainer/Z Expert Predictions Mean     792.847\n",
      "trainer/Z Expert Predictions Std       38.4825\n",
      "trainer/Z Expert Predictions Max      854.77\n",
      "trainer/Z Expert Predictions Min      513.197\n",
      "trainer/Z Policy Predictions Mean     659.018\n",
      "trainer/Z Policy Predictions Std      289.915\n",
      "trainer/Z Policy Predictions Max      831.215\n",
      "trainer/Z Policy Predictions Min     -597.118\n",
      "trainer/Z Expert Targets Mean         777.205\n",
      "trainer/Z Expert Targets Std           40.422\n",
      "trainer/Z Expert Targets Max          841.649\n",
      "trainer/Z Expert Targets Min          492.076\n",
      "trainer/Z Policy Targets Mean         654.057\n",
      "trainer/Z Policy Targets Std          289.241\n",
      "trainer/Z Policy Targets Max          820.712\n",
      "trainer/Z Policy Targets Min         -587.12\n",
      "trainer/Log Pis Mean                   20.1867\n",
      "trainer/Log Pis Std                     3.66247\n",
      "trainer/Policy mu Mean                  0.0351959\n",
      "trainer/Policy mu Std                   1.03752\n",
      "trainer/Policy log std Mean            -3.21823\n",
      "trainer/Policy log std Std              0.974084\n",
      "trainer/Alpha                           0.150369\n",
      "trainer/Alpha Loss                     -0.028072\n",
      "exploration/num steps total        225884\n",
      "exploration/num paths total           326\n",
      "evaluation/num steps total              1.96316e+06\n",
      "evaluation/num paths total           2266\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.81193\n",
      "evaluation/Rewards Std                  1.00275\n",
      "evaluation/Rewards Max                  6.94046\n",
      "evaluation/Rewards Min                 -1.56325\n",
      "evaluation/Returns Mean              4811.93\n",
      "evaluation/Returns Std                 86.8601\n",
      "evaluation/Returns Max               4979.25\n",
      "evaluation/Returns Min               4677.26\n",
      "evaluation/Estimation Bias Mean       718.069\n",
      "evaluation/Estimation Bias Std        143.821\n",
      "evaluation/EB/Q_True Mean              43.688\n",
      "evaluation/EB/Q_True Std              134.782\n",
      "evaluation/EB/Q_Pred Mean             761.758\n",
      "evaluation/EB/Q_Pred Std               56.8766\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4811.93\n",
      "evaluation/Actions Mean                 0.0237602\n",
      "evaluation/Actions Std                  0.536704\n",
      "evaluation/Actions Max                  0.999748\n",
      "evaluation/Actions Min                 -0.999784\n",
      "time/backward_policy (s)                1.85066\n",
      "time/backward_zf1 (s)                   1.98251\n",
      "time/backward_zf2 (s)                   1.92258\n",
      "time/data sampling (s)                  0.272505\n",
      "time/data storing (s)                   0.0148086\n",
      "time/evaluation sampling (s)            1.71349\n",
      "time/exploration sampling (s)           0.314851\n",
      "time/logging (s)                        0.0120999\n",
      "time/preback_alpha (s)                  0.978161\n",
      "time/preback_policy (s)                 1.09222\n",
      "time/preback_start (s)                  0.14735\n",
      "time/preback_zf (s)                     5.20377\n",
      "time/saving (s)                         0.00639003\n",
      "time/training (s)                       2.25263\n",
      "time/epoch (s)                         17.764\n",
      "time/total (s)                       3971.4\n",
      "Epoch                                 221\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:58:46.352710 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 222 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 233000\n",
      "trainer/ZF1 Loss                        4.34716\n",
      "trainer/ZF2 Loss                        8.88318\n",
      "trainer/ZF Expert Reward               16.6488\n",
      "trainer/ZF Policy Reward                2.67753\n",
      "trainer/ZF CHI2 Term                   40.2197\n",
      "trainer/Policy Loss                  -677.366\n",
      "trainer/Bias Loss                      61.1478\n",
      "trainer/Bias Value                     14.4888\n",
      "trainer/Policy Grad Norm              153.427\n",
      "trainer/Policy Param Norm              36.75\n",
      "trainer/Zf1 Grad Norm                1147.2\n",
      "trainer/Zf1 Param Norm                116.535\n",
      "trainer/Zf2 Grad Norm                1104.62\n",
      "trainer/Zf2 Param Norm                114.724\n",
      "trainer/Z Expert Predictions Mean     789.092\n",
      "trainer/Z Expert Predictions Std       43.0395\n",
      "trainer/Z Expert Predictions Max      874.307\n",
      "trainer/Z Expert Predictions Min      493.458\n",
      "trainer/Z Policy Predictions Mean     677.011\n",
      "trainer/Z Policy Predictions Std      239.749\n",
      "trainer/Z Policy Predictions Max      835.452\n",
      "trainer/Z Policy Predictions Min     -508.908\n",
      "trainer/Z Expert Targets Mean         772.443\n",
      "trainer/Z Expert Targets Std           46.0699\n",
      "trainer/Z Expert Targets Max          854.512\n",
      "trainer/Z Expert Targets Min          458.436\n",
      "trainer/Z Policy Targets Mean         674.333\n",
      "trainer/Z Policy Targets Std          233.543\n",
      "trainer/Z Policy Targets Max          815.271\n",
      "trainer/Z Policy Targets Min         -498.513\n",
      "trainer/Log Pis Mean                   19.8316\n",
      "trainer/Log Pis Std                     3.7098\n",
      "trainer/Policy mu Mean                  0.0439365\n",
      "trainer/Policy mu Std                   0.94662\n",
      "trainer/Policy log std Mean            -3.29605\n",
      "trainer/Policy log std Std              0.873709\n",
      "trainer/Alpha                           0.150776\n",
      "trainer/Alpha Loss                      0.0253898\n",
      "exploration/num steps total        226884\n",
      "exploration/num paths total           327\n",
      "evaluation/num steps total              1.97316e+06\n",
      "evaluation/num paths total           2276\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69782\n",
      "evaluation/Rewards Std                  1.00424\n",
      "evaluation/Rewards Max                  6.85581\n",
      "evaluation/Rewards Min                 -1.56363\n",
      "evaluation/Returns Mean              4697.82\n",
      "evaluation/Returns Std                 91.0789\n",
      "evaluation/Returns Max               4848.97\n",
      "evaluation/Returns Min               4504.85\n",
      "evaluation/Estimation Bias Mean       716.454\n",
      "evaluation/Estimation Bias Std        140.871\n",
      "evaluation/EB/Q_True Mean              41.624\n",
      "evaluation/EB/Q_True Std              128.068\n",
      "evaluation/EB/Q_Pred Mean             758.078\n",
      "evaluation/EB/Q_Pred Std               62.7798\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4697.82\n",
      "evaluation/Actions Mean                 0.0188789\n",
      "evaluation/Actions Std                  0.538064\n",
      "evaluation/Actions Max                  0.999741\n",
      "evaluation/Actions Min                 -0.999898\n",
      "time/backward_policy (s)                1.80464\n",
      "time/backward_zf1 (s)                   1.9411\n",
      "time/backward_zf2 (s)                   1.86403\n",
      "time/data sampling (s)                  0.263795\n",
      "time/data storing (s)                   0.0140898\n",
      "time/evaluation sampling (s)            1.80397\n",
      "time/exploration sampling (s)           0.311384\n",
      "time/logging (s)                        0.0153719\n",
      "time/preback_alpha (s)                  0.934651\n",
      "time/preback_policy (s)                 1.04302\n",
      "time/preback_start (s)                  0.145033\n",
      "time/preback_zf (s)                     5.20569\n",
      "time/saving (s)                         0.0227646\n",
      "time/training (s)                       2.38346\n",
      "time/epoch (s)                         17.753\n",
      "time/total (s)                       3989.18\n",
      "Epoch                                 222\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:59:04.664057 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 223 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 234000\n",
      "trainer/ZF1 Loss                        9.03645\n",
      "trainer/ZF2 Loss                        4.63824\n",
      "trainer/ZF Expert Reward               15.9538\n",
      "trainer/ZF Policy Reward                3.96421\n",
      "trainer/ZF CHI2 Term                   38.4206\n",
      "trainer/Policy Loss                  -667.73\n",
      "trainer/Bias Loss                      60.5839\n",
      "trainer/Bias Value                     14.4984\n",
      "trainer/Policy Grad Norm              174.605\n",
      "trainer/Policy Param Norm              36.7773\n",
      "trainer/Zf1 Grad Norm                1525.92\n",
      "trainer/Zf1 Param Norm                116.69\n",
      "trainer/Zf2 Grad Norm                1008.96\n",
      "trainer/Zf2 Param Norm                114.88\n",
      "trainer/Z Expert Predictions Mean     788.051\n",
      "trainer/Z Expert Predictions Std       41.5182\n",
      "trainer/Z Expert Predictions Max      858.155\n",
      "trainer/Z Expert Predictions Min      585.237\n",
      "trainer/Z Policy Predictions Mean     667.76\n",
      "trainer/Z Policy Predictions Std      253.279\n",
      "trainer/Z Policy Predictions Max      835.005\n",
      "trainer/Z Policy Predictions Min     -582.6\n",
      "trainer/Z Expert Targets Mean         772.097\n",
      "trainer/Z Expert Targets Std           42.424\n",
      "trainer/Z Expert Targets Max          851.832\n",
      "trainer/Z Expert Targets Min          567.679\n",
      "trainer/Z Policy Targets Mean         663.796\n",
      "trainer/Z Policy Targets Std          248.195\n",
      "trainer/Z Policy Targets Max          833.226\n",
      "trainer/Z Policy Targets Min         -566.22\n",
      "trainer/Log Pis Mean                   19.7916\n",
      "trainer/Log Pis Std                     4.09531\n",
      "trainer/Policy mu Mean                  0.0701549\n",
      "trainer/Policy mu Std                   0.917255\n",
      "trainer/Policy log std Mean            -3.31737\n",
      "trainer/Policy log std Std              0.862866\n",
      "trainer/Alpha                           0.151964\n",
      "trainer/Alpha Loss                      0.0316776\n",
      "exploration/num steps total        228884\n",
      "exploration/num paths total           329\n",
      "evaluation/num steps total              1.98297e+06\n",
      "evaluation/num paths total           2286\n",
      "evaluation/path length Mean           980.6\n",
      "evaluation/path length Std             58.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            806\n",
      "evaluation/Rewards Mean                 4.73768\n",
      "evaluation/Rewards Std                  0.973838\n",
      "evaluation/Rewards Max                  6.79011\n",
      "evaluation/Rewards Min                 -1.62968\n",
      "evaluation/Returns Mean              4645.77\n",
      "evaluation/Returns Std                311.247\n",
      "evaluation/Returns Max               4901.79\n",
      "evaluation/Returns Min               3767.59\n",
      "evaluation/Estimation Bias Mean       713.332\n",
      "evaluation/Estimation Bias Std        146.847\n",
      "evaluation/EB/Q_True Mean              43.916\n",
      "evaluation/EB/Q_True Std              134.12\n",
      "evaluation/EB/Q_Pred Mean             757.248\n",
      "evaluation/EB/Q_Pred Std               57.0654\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4645.77\n",
      "evaluation/Actions Mean                 0.0162733\n",
      "evaluation/Actions Std                  0.541686\n",
      "evaluation/Actions Max                  0.999762\n",
      "evaluation/Actions Min                 -0.9996\n",
      "time/backward_policy (s)                1.97865\n",
      "time/backward_zf1 (s)                   2.11975\n",
      "time/backward_zf2 (s)                   2.04202\n",
      "time/data sampling (s)                  0.287388\n",
      "time/data storing (s)                   0.0146706\n",
      "time/evaluation sampling (s)            1.81304\n",
      "time/exploration sampling (s)           0.324308\n",
      "time/logging (s)                        0.013511\n",
      "time/preback_alpha (s)                  1.04306\n",
      "time/preback_policy (s)                 1.17439\n",
      "time/preback_start (s)                  0.146548\n",
      "time/preback_zf (s)                     5.18476\n",
      "time/saving (s)                         0.00624014\n",
      "time/training (s)                       2.0895\n",
      "time/epoch (s)                         18.2378\n",
      "time/total (s)                       4007.44\n",
      "Epoch                                 223\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:59:22.409864 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 224 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 235000\n",
      "trainer/ZF1 Loss                      127.335\n",
      "trainer/ZF2 Loss                      116.585\n",
      "trainer/ZF Expert Reward               13.9676\n",
      "trainer/ZF Policy Reward                7.09456\n",
      "trainer/ZF CHI2 Term                  148.498\n",
      "trainer/Policy Loss                  -657.633\n",
      "trainer/Bias Loss                      52.4375\n",
      "trainer/Bias Value                     14.5086\n",
      "trainer/Policy Grad Norm              124.194\n",
      "trainer/Policy Param Norm              36.8064\n",
      "trainer/Zf1 Grad Norm                1532.18\n",
      "trainer/Zf1 Param Norm                116.841\n",
      "trainer/Zf2 Grad Norm                1318.2\n",
      "trainer/Zf2 Param Norm                115.033\n",
      "trainer/Z Expert Predictions Mean     785.551\n",
      "trainer/Z Expert Predictions Std       35.3354\n",
      "trainer/Z Expert Predictions Max      850.877\n",
      "trainer/Z Expert Predictions Min      624.005\n",
      "trainer/Z Policy Predictions Mean     658.004\n",
      "trainer/Z Policy Predictions Std      279.958\n",
      "trainer/Z Policy Predictions Max      834.425\n",
      "trainer/Z Policy Predictions Min     -636.861\n",
      "trainer/Z Expert Targets Mean         771.583\n",
      "trainer/Z Expert Targets Std           37.2577\n",
      "trainer/Z Expert Targets Max          848.209\n",
      "trainer/Z Expert Targets Min          575.612\n",
      "trainer/Z Policy Targets Mean         650.909\n",
      "trainer/Z Policy Targets Std          279.037\n",
      "trainer/Z Policy Targets Max          820.194\n",
      "trainer/Z Policy Targets Min         -630.795\n",
      "trainer/Log Pis Mean                   19.864\n",
      "trainer/Log Pis Std                     4.02642\n",
      "trainer/Policy mu Mean                  0.0351453\n",
      "trainer/Policy mu Std                   0.946844\n",
      "trainer/Policy log std Mean            -3.26836\n",
      "trainer/Policy log std Std              0.894213\n",
      "trainer/Alpha                           0.15062\n",
      "trainer/Alpha Loss                      0.0204806\n",
      "exploration/num steps total        229884\n",
      "exploration/num paths total           330\n",
      "evaluation/num steps total              1.99297e+06\n",
      "evaluation/num paths total           2296\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67424\n",
      "evaluation/Rewards Std                  1.01153\n",
      "evaluation/Rewards Max                  6.60543\n",
      "evaluation/Rewards Min                 -1.46871\n",
      "evaluation/Returns Mean              4674.24\n",
      "evaluation/Returns Std                 95.7559\n",
      "evaluation/Returns Max               4796.23\n",
      "evaluation/Returns Min               4491.78\n",
      "evaluation/Estimation Bias Mean       707.456\n",
      "evaluation/Estimation Bias Std        146.695\n",
      "evaluation/EB/Q_True Mean              43.5007\n",
      "evaluation/EB/Q_True Std              134.574\n",
      "evaluation/EB/Q_Pred Mean             750.957\n",
      "evaluation/EB/Q_Pred Std               58.9557\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4674.24\n",
      "evaluation/Actions Mean                 0.0260071\n",
      "evaluation/Actions Std                  0.537481\n",
      "evaluation/Actions Max                  0.999722\n",
      "evaluation/Actions Min                 -0.999879\n",
      "time/backward_policy (s)                1.80712\n",
      "time/backward_zf1 (s)                   1.94489\n",
      "time/backward_zf2 (s)                   1.8742\n",
      "time/data sampling (s)                  0.292696\n",
      "time/data storing (s)                   0.0144955\n",
      "time/evaluation sampling (s)            1.70374\n",
      "time/exploration sampling (s)           0.317428\n",
      "time/logging (s)                        0.0126701\n",
      "time/preback_alpha (s)                  0.918953\n",
      "time/preback_policy (s)                 1.01544\n",
      "time/preback_start (s)                  0.147889\n",
      "time/preback_zf (s)                     5.18102\n",
      "time/saving (s)                         0.00617282\n",
      "time/training (s)                       2.4371\n",
      "time/epoch (s)                         17.6738\n",
      "time/total (s)                       4025.14\n",
      "Epoch                                 224\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:59:40.099171 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 225 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 236000\n",
      "trainer/ZF1 Loss                       22.7611\n",
      "trainer/ZF2 Loss                       13.4049\n",
      "trainer/ZF Expert Reward               16.3804\n",
      "trainer/ZF Policy Reward                5.83406\n",
      "trainer/ZF CHI2 Term                   47.8215\n",
      "trainer/Policy Loss                  -634.567\n",
      "trainer/Bias Loss                      47.2194\n",
      "trainer/Bias Value                     14.5199\n",
      "trainer/Policy Grad Norm              152.637\n",
      "trainer/Policy Param Norm              36.8375\n",
      "trainer/Zf1 Grad Norm                1265.98\n",
      "trainer/Zf1 Param Norm                116.99\n",
      "trainer/Zf2 Grad Norm                1183.11\n",
      "trainer/Zf2 Param Norm                115.193\n",
      "trainer/Z Expert Predictions Mean     778.192\n",
      "trainer/Z Expert Predictions Std       47.8365\n",
      "trainer/Z Expert Predictions Max      864.83\n",
      "trainer/Z Expert Predictions Min      468.762\n",
      "trainer/Z Policy Predictions Mean     634.272\n",
      "trainer/Z Policy Predictions Std      289.944\n",
      "trainer/Z Policy Predictions Max      818.798\n",
      "trainer/Z Policy Predictions Min     -626.124\n",
      "trainer/Z Expert Targets Mean         761.811\n",
      "trainer/Z Expert Targets Std           49.901\n",
      "trainer/Z Expert Targets Max          843.607\n",
      "trainer/Z Expert Targets Min          436.428\n",
      "trainer/Z Policy Targets Mean         628.438\n",
      "trainer/Z Policy Targets Std          285.627\n",
      "trainer/Z Policy Targets Max          816.321\n",
      "trainer/Z Policy Targets Min         -606.577\n",
      "trainer/Log Pis Mean                   19.3859\n",
      "trainer/Log Pis Std                     4.46741\n",
      "trainer/Policy mu Mean                  0.0744673\n",
      "trainer/Policy mu Std                   0.969288\n",
      "trainer/Policy log std Mean            -3.20367\n",
      "trainer/Policy log std Std              0.935002\n",
      "trainer/Alpha                           0.152183\n",
      "trainer/Alpha Loss                      0.093448\n",
      "exploration/num steps total        230884\n",
      "exploration/num paths total           331\n",
      "evaluation/num steps total              2.00297e+06\n",
      "evaluation/num paths total           2306\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70209\n",
      "evaluation/Rewards Std                  1.08116\n",
      "evaluation/Rewards Max                  6.86984\n",
      "evaluation/Rewards Min                 -1.53883\n",
      "evaluation/Returns Mean              4702.09\n",
      "evaluation/Returns Std                140.028\n",
      "evaluation/Returns Max               4980.11\n",
      "evaluation/Returns Min               4460.11\n",
      "evaluation/Estimation Bias Mean       695.451\n",
      "evaluation/Estimation Bias Std        140.232\n",
      "evaluation/EB/Q_True Mean              41.6457\n",
      "evaluation/EB/Q_True Std              128.439\n",
      "evaluation/EB/Q_Pred Mean             737.096\n",
      "evaluation/EB/Q_Pred Std               64.436\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4702.09\n",
      "evaluation/Actions Mean                 0.0220351\n",
      "evaluation/Actions Std                  0.538679\n",
      "evaluation/Actions Max                  0.999757\n",
      "evaluation/Actions Min                 -0.999782\n",
      "time/backward_policy (s)                1.85043\n",
      "time/backward_zf1 (s)                   1.95569\n",
      "time/backward_zf2 (s)                   1.89172\n",
      "time/data sampling (s)                  0.294031\n",
      "time/data storing (s)                   0.0141409\n",
      "time/evaluation sampling (s)            1.72144\n",
      "time/exploration sampling (s)           0.315391\n",
      "time/logging (s)                        0.0117921\n",
      "time/preback_alpha (s)                  0.985424\n",
      "time/preback_policy (s)                 1.10059\n",
      "time/preback_start (s)                  0.144988\n",
      "time/preback_zf (s)                     5.14771\n",
      "time/saving (s)                         0.00611161\n",
      "time/training (s)                       2.1681\n",
      "time/epoch (s)                         17.6076\n",
      "time/total (s)                       4042.78\n",
      "Epoch                                 225\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 11:59:58.062040 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 226 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 237000\n",
      "trainer/ZF1 Loss                       17.9043\n",
      "trainer/ZF2 Loss                       12.0302\n",
      "trainer/ZF Expert Reward               14.1744\n",
      "trainer/ZF Policy Reward                2.08997\n",
      "trainer/ZF CHI2 Term                   46.8031\n",
      "trainer/Policy Loss                  -648.276\n",
      "trainer/Bias Loss                      53.9529\n",
      "trainer/Bias Value                     14.5309\n",
      "trainer/Policy Grad Norm              186.832\n",
      "trainer/Policy Param Norm              36.8655\n",
      "trainer/Zf1 Grad Norm                1578.2\n",
      "trainer/Zf1 Param Norm                117.154\n",
      "trainer/Zf2 Grad Norm                1391.56\n",
      "trainer/Zf2 Param Norm                115.348\n",
      "trainer/Z Expert Predictions Mean     776.147\n",
      "trainer/Z Expert Predictions Std       43.4376\n",
      "trainer/Z Expert Predictions Max      850.472\n",
      "trainer/Z Expert Predictions Min      550.463\n",
      "trainer/Z Policy Predictions Mean     647.39\n",
      "trainer/Z Policy Predictions Std      287.616\n",
      "trainer/Z Policy Predictions Max      808.922\n",
      "trainer/Z Policy Predictions Min     -624.287\n",
      "trainer/Z Expert Targets Mean         761.973\n",
      "trainer/Z Expert Targets Std           45.3408\n",
      "trainer/Z Expert Targets Max          823.501\n",
      "trainer/Z Expert Targets Min          510.214\n",
      "trainer/Z Policy Targets Mean         645.3\n",
      "trainer/Z Policy Targets Std          282.54\n",
      "trainer/Z Policy Targets Max          819.015\n",
      "trainer/Z Policy Targets Min         -624.965\n",
      "trainer/Log Pis Mean                   19.9509\n",
      "trainer/Log Pis Std                     4.15535\n",
      "trainer/Policy mu Mean                  0.0403976\n",
      "trainer/Policy mu Std                   0.973631\n",
      "trainer/Policy log std Mean            -3.27029\n",
      "trainer/Policy log std Std              0.938151\n",
      "trainer/Alpha                           0.153825\n",
      "trainer/Alpha Loss                      0.00754938\n",
      "exploration/num steps total        232884\n",
      "exploration/num paths total           333\n",
      "evaluation/num steps total              2.01297e+06\n",
      "evaluation/num paths total           2316\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.73092\n",
      "evaluation/Rewards Std                  0.983475\n",
      "evaluation/Rewards Max                  6.7353\n",
      "evaluation/Rewards Min                 -1.71625\n",
      "evaluation/Returns Mean              4730.92\n",
      "evaluation/Returns Std                 81.4762\n",
      "evaluation/Returns Max               4896.15\n",
      "evaluation/Returns Min               4605.59\n",
      "evaluation/Estimation Bias Mean       705.045\n",
      "evaluation/Estimation Bias Std        146.002\n",
      "evaluation/EB/Q_True Mean              43.6748\n",
      "evaluation/EB/Q_True Std              134.802\n",
      "evaluation/EB/Q_Pred Mean             748.72\n",
      "evaluation/EB/Q_Pred Std               55.5126\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4730.92\n",
      "evaluation/Actions Mean                 0.0248716\n",
      "evaluation/Actions Std                  0.536138\n",
      "evaluation/Actions Max                  0.99959\n",
      "evaluation/Actions Min                 -0.999773\n",
      "time/backward_policy (s)                1.86439\n",
      "time/backward_zf1 (s)                   2.00454\n",
      "time/backward_zf2 (s)                   1.94459\n",
      "time/data sampling (s)                  0.300865\n",
      "time/data storing (s)                   0.0145904\n",
      "time/evaluation sampling (s)            1.75747\n",
      "time/exploration sampling (s)           0.325335\n",
      "time/logging (s)                        0.0122326\n",
      "time/preback_alpha (s)                  0.984472\n",
      "time/preback_policy (s)                 1.10306\n",
      "time/preback_start (s)                  0.146518\n",
      "time/preback_zf (s)                     5.17355\n",
      "time/saving (s)                         0.00623532\n",
      "time/training (s)                       2.25547\n",
      "time/epoch (s)                         17.8933\n",
      "time/total (s)                       4060.69\n",
      "Epoch                                 226\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:00:16.586792 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 227 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 238000\n",
      "trainer/ZF1 Loss                       11.0715\n",
      "trainer/ZF2 Loss                        7.40647\n",
      "trainer/ZF Expert Reward               12.1688\n",
      "trainer/ZF Policy Reward                1.41222\n",
      "trainer/ZF CHI2 Term                   39.698\n",
      "trainer/Policy Loss                  -638.162\n",
      "trainer/Bias Loss                      58.4963\n",
      "trainer/Bias Value                     14.5406\n",
      "trainer/Policy Grad Norm              171.41\n",
      "trainer/Policy Param Norm              36.8943\n",
      "trainer/Zf1 Grad Norm                1479.39\n",
      "trainer/Zf1 Param Norm                117.305\n",
      "trainer/Zf2 Grad Norm                1352.16\n",
      "trainer/Zf2 Param Norm                115.51\n",
      "trainer/Z Expert Predictions Mean     768.796\n",
      "trainer/Z Expert Predictions Std       39.2059\n",
      "trainer/Z Expert Predictions Max      838.01\n",
      "trainer/Z Expert Predictions Min      565.406\n",
      "trainer/Z Policy Predictions Mean     635.219\n",
      "trainer/Z Policy Predictions Std      277.268\n",
      "trainer/Z Policy Predictions Max      819.815\n",
      "trainer/Z Policy Predictions Min     -602.65\n",
      "trainer/Z Expert Targets Mean         756.627\n",
      "trainer/Z Expert Targets Std           41.1823\n",
      "trainer/Z Expert Targets Max          822.9\n",
      "trainer/Z Expert Targets Min          543.324\n",
      "trainer/Z Policy Targets Mean         633.806\n",
      "trainer/Z Policy Targets Std          275.072\n",
      "trainer/Z Policy Targets Max          819.543\n",
      "trainer/Z Policy Targets Min         -598.583\n",
      "trainer/Log Pis Mean                   19.9015\n",
      "trainer/Log Pis Std                     4.00895\n",
      "trainer/Policy mu Mean                  0.0579951\n",
      "trainer/Policy mu Std                   0.9627\n",
      "trainer/Policy log std Mean            -3.27832\n",
      "trainer/Policy log std Std              0.936981\n",
      "trainer/Alpha                           0.154347\n",
      "trainer/Alpha Loss                      0.0152045\n",
      "exploration/num steps total        233884\n",
      "exploration/num paths total           334\n",
      "evaluation/num steps total              2.02265e+06\n",
      "evaluation/num paths total           2326\n",
      "evaluation/path length Mean           968.7\n",
      "evaluation/path length Std             93.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            687\n",
      "evaluation/Rewards Mean                 4.6391\n",
      "evaluation/Rewards Std                  1.01374\n",
      "evaluation/Rewards Max                  6.63915\n",
      "evaluation/Rewards Min                 -1.67472\n",
      "evaluation/Returns Mean              4493.89\n",
      "evaluation/Returns Std                493.469\n",
      "evaluation/Returns Max               4777.87\n",
      "evaluation/Returns Min               3034.19\n",
      "evaluation/Estimation Bias Mean       693.942\n",
      "evaluation/Estimation Bias Std        154.081\n",
      "evaluation/EB/Q_True Mean              43.049\n",
      "evaluation/EB/Q_True Std              130.208\n",
      "evaluation/EB/Q_Pred Mean             736.991\n",
      "evaluation/EB/Q_Pred Std               69.456\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4493.89\n",
      "evaluation/Actions Mean                 0.0225018\n",
      "evaluation/Actions Std                  0.539794\n",
      "evaluation/Actions Max                  0.999535\n",
      "evaluation/Actions Min                 -0.999737\n",
      "time/backward_policy (s)                2.01132\n",
      "time/backward_zf1 (s)                   2.15461\n",
      "time/backward_zf2 (s)                   2.0775\n",
      "time/data sampling (s)                  0.303161\n",
      "time/data storing (s)                   0.0152464\n",
      "time/evaluation sampling (s)            1.72952\n",
      "time/exploration sampling (s)           0.327334\n",
      "time/logging (s)                        0.0130329\n",
      "time/preback_alpha (s)                  1.05545\n",
      "time/preback_policy (s)                 1.20328\n",
      "time/preback_start (s)                  0.148705\n",
      "time/preback_zf (s)                     5.24108\n",
      "time/saving (s)                         0.00616711\n",
      "time/training (s)                       2.16773\n",
      "time/epoch (s)                         18.4541\n",
      "time/total (s)                       4079.17\n",
      "Epoch                                 227\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:00:34.592228 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 228 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 239000\n",
      "trainer/ZF1 Loss                        4.53236\n",
      "trainer/ZF2 Loss                        6.48496\n",
      "trainer/ZF Expert Reward               13.4694\n",
      "trainer/ZF Policy Reward                0.191715\n",
      "trainer/ZF CHI2 Term                   38.7265\n",
      "trainer/Policy Loss                  -645.746\n",
      "trainer/Bias Loss                      62.1118\n",
      "trainer/Bias Value                     14.5487\n",
      "trainer/Policy Grad Norm              142.785\n",
      "trainer/Policy Param Norm              36.9233\n",
      "trainer/Zf1 Grad Norm                1421.34\n",
      "trainer/Zf1 Param Norm                117.457\n",
      "trainer/Zf2 Grad Norm                1540.29\n",
      "trainer/Zf2 Param Norm                115.665\n",
      "trainer/Z Expert Predictions Mean     765.42\n",
      "trainer/Z Expert Predictions Std       60.8367\n",
      "trainer/Z Expert Predictions Max      837.322\n",
      "trainer/Z Expert Predictions Min      -32.4496\n",
      "trainer/Z Policy Predictions Mean     643.877\n",
      "trainer/Z Policy Predictions Std      265.273\n",
      "trainer/Z Policy Predictions Max      809.178\n",
      "trainer/Z Policy Predictions Min     -666.08\n",
      "trainer/Z Expert Targets Mean         751.951\n",
      "trainer/Z Expert Targets Std           60.0017\n",
      "trainer/Z Expert Targets Max          822.552\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         643.685\n",
      "trainer/Z Policy Targets Std          261.576\n",
      "trainer/Z Policy Targets Max          820.842\n",
      "trainer/Z Policy Targets Min         -665.95\n",
      "trainer/Log Pis Mean                   20.1416\n",
      "trainer/Log Pis Std                     4.30901\n",
      "trainer/Policy mu Mean                  0.0442954\n",
      "trainer/Policy mu Std                   1.00527\n",
      "trainer/Policy log std Mean            -3.25959\n",
      "trainer/Policy log std Std              0.932506\n",
      "trainer/Alpha                           0.154141\n",
      "trainer/Alpha Loss                     -0.0218289\n",
      "exploration/num steps total        234918\n",
      "exploration/num paths total           336\n",
      "evaluation/num steps total              2.03265e+06\n",
      "evaluation/num paths total           2336\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62498\n",
      "evaluation/Rewards Std                  0.920423\n",
      "evaluation/Rewards Max                  6.83995\n",
      "evaluation/Rewards Min                 -1.53079\n",
      "evaluation/Returns Mean              4624.98\n",
      "evaluation/Returns Std                 57.1764\n",
      "evaluation/Returns Max               4727.5\n",
      "evaluation/Returns Min               4545.54\n",
      "evaluation/Estimation Bias Mean       704.557\n",
      "evaluation/Estimation Bias Std        140.606\n",
      "evaluation/EB/Q_True Mean              43.2308\n",
      "evaluation/EB/Q_True Std              133.09\n",
      "evaluation/EB/Q_Pred Mean             747.788\n",
      "evaluation/EB/Q_Pred Std               50.3146\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4624.98\n",
      "evaluation/Actions Mean                 0.0198774\n",
      "evaluation/Actions Std                  0.537939\n",
      "evaluation/Actions Max                  0.999812\n",
      "evaluation/Actions Min                 -0.999239\n",
      "time/backward_policy (s)                1.9139\n",
      "time/backward_zf1 (s)                   2.04973\n",
      "time/backward_zf2 (s)                   1.9747\n",
      "time/data sampling (s)                  0.30614\n",
      "time/data storing (s)                   0.0140427\n",
      "time/evaluation sampling (s)            1.74065\n",
      "time/exploration sampling (s)           0.316725\n",
      "time/logging (s)                        0.0118325\n",
      "time/preback_alpha (s)                  1.00709\n",
      "time/preback_policy (s)                 1.13063\n",
      "time/preback_start (s)                  0.144232\n",
      "time/preback_zf (s)                     5.17466\n",
      "time/saving (s)                         0.00625645\n",
      "time/training (s)                       2.14312\n",
      "time/epoch (s)                         17.9337\n",
      "time/total (s)                       4097.13\n",
      "Epoch                                 228\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:00:52.980254 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 229 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 240000\n",
      "trainer/ZF1 Loss                        9.99109\n",
      "trainer/ZF2 Loss                        7.07576\n",
      "trainer/ZF Expert Reward               18.0989\n",
      "trainer/ZF Policy Reward                6.85524\n",
      "trainer/ZF CHI2 Term                   39.8617\n",
      "trainer/Policy Loss                  -686.906\n",
      "trainer/Bias Loss                      51.7554\n",
      "trainer/Bias Value                     14.556\n",
      "trainer/Policy Grad Norm              139.053\n",
      "trainer/Policy Param Norm              36.9504\n",
      "trainer/Zf1 Grad Norm                1020.66\n",
      "trainer/Zf1 Param Norm                117.61\n",
      "trainer/Zf2 Grad Norm                1054.73\n",
      "trainer/Zf2 Param Norm                115.811\n",
      "trainer/Z Expert Predictions Mean     762.525\n",
      "trainer/Z Expert Predictions Std       48.9699\n",
      "trainer/Z Expert Predictions Max      829.408\n",
      "trainer/Z Expert Predictions Min      481.536\n",
      "trainer/Z Policy Predictions Mean     687.763\n",
      "trainer/Z Policy Predictions Std      189.799\n",
      "trainer/Z Policy Predictions Max      807.859\n",
      "trainer/Z Policy Predictions Min     -651.256\n",
      "trainer/Z Expert Targets Mean         744.426\n",
      "trainer/Z Expert Targets Std           50.6265\n",
      "trainer/Z Expert Targets Max          816.274\n",
      "trainer/Z Expert Targets Min          446.415\n",
      "trainer/Z Policy Targets Mean         680.908\n",
      "trainer/Z Policy Targets Std          187.062\n",
      "trainer/Z Policy Targets Max          813.276\n",
      "trainer/Z Policy Targets Min         -639.311\n",
      "trainer/Log Pis Mean                   20.2875\n",
      "trainer/Log Pis Std                     3.35631\n",
      "trainer/Policy mu Mean                  0.026486\n",
      "trainer/Policy mu Std                   0.866969\n",
      "trainer/Policy log std Mean            -3.42932\n",
      "trainer/Policy log std Std              0.76133\n",
      "trainer/Alpha                           0.154053\n",
      "trainer/Alpha Loss                     -0.0442906\n",
      "exploration/num steps total        234988\n",
      "exploration/num paths total           337\n",
      "evaluation/num steps total              2.04265e+06\n",
      "evaluation/num paths total           2346\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70648\n",
      "evaluation/Rewards Std                  0.939768\n",
      "evaluation/Rewards Max                  6.79619\n",
      "evaluation/Rewards Min                 -1.36728\n",
      "evaluation/Returns Mean              4706.48\n",
      "evaluation/Returns Std                 69.2512\n",
      "evaluation/Returns Max               4817.02\n",
      "evaluation/Returns Min               4553.86\n",
      "evaluation/Estimation Bias Mean       696.99\n",
      "evaluation/Estimation Bias Std        142.197\n",
      "evaluation/EB/Q_True Mean              43.4337\n",
      "evaluation/EB/Q_True Std              134.401\n",
      "evaluation/EB/Q_Pred Mean             740.424\n",
      "evaluation/EB/Q_Pred Std               52.0375\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4706.48\n",
      "evaluation/Actions Mean                 0.0253594\n",
      "evaluation/Actions Std                  0.533956\n",
      "evaluation/Actions Max                  0.999587\n",
      "evaluation/Actions Min                 -0.99968\n",
      "time/backward_policy (s)                1.96987\n",
      "time/backward_zf1 (s)                   2.09956\n",
      "time/backward_zf2 (s)                   2.04821\n",
      "time/data sampling (s)                  0.300481\n",
      "time/data storing (s)                   0.0142211\n",
      "time/evaluation sampling (s)            1.81527\n",
      "time/exploration sampling (s)           0.310029\n",
      "time/logging (s)                        0.0117936\n",
      "time/preback_alpha (s)                  1.04838\n",
      "time/preback_policy (s)                 1.19082\n",
      "time/preback_start (s)                  0.146624\n",
      "time/preback_zf (s)                     5.22267\n",
      "time/saving (s)                         0.00566067\n",
      "time/training (s)                       2.13667\n",
      "time/epoch (s)                         18.3203\n",
      "time/total (s)                       4115.46\n",
      "Epoch                                 229\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:01:10.848021 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 230 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 241000\n",
      "trainer/ZF1 Loss                      154.429\n",
      "trainer/ZF2 Loss                      133.454\n",
      "trainer/ZF Expert Reward               15.2973\n",
      "trainer/ZF Policy Reward                8.25178\n",
      "trainer/ZF CHI2 Term                  170.799\n",
      "trainer/Policy Loss                  -644.919\n",
      "trainer/Bias Loss                      65.1681\n",
      "trainer/Bias Value                     14.5665\n",
      "trainer/Policy Grad Norm              136.375\n",
      "trainer/Policy Param Norm              36.9754\n",
      "trainer/Zf1 Grad Norm                1633.32\n",
      "trainer/Zf1 Param Norm                117.771\n",
      "trainer/Zf2 Grad Norm                1535.1\n",
      "trainer/Zf2 Param Norm                115.959\n",
      "trainer/Z Expert Predictions Mean     755.932\n",
      "trainer/Z Expert Predictions Std       64.0365\n",
      "trainer/Z Expert Predictions Max      830.3\n",
      "trainer/Z Expert Predictions Min       37.035\n",
      "trainer/Z Policy Predictions Mean     641.811\n",
      "trainer/Z Policy Predictions Std      257.736\n",
      "trainer/Z Policy Predictions Max      807.292\n",
      "trainer/Z Policy Predictions Min     -626.276\n",
      "trainer/Z Expert Targets Mean         740.635\n",
      "trainer/Z Expert Targets Std           67.6909\n",
      "trainer/Z Expert Targets Max          816.566\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         633.559\n",
      "trainer/Z Policy Targets Std          260.416\n",
      "trainer/Z Policy Targets Max          797.414\n",
      "trainer/Z Policy Targets Min         -603.183\n",
      "trainer/Log Pis Mean                   20.0121\n",
      "trainer/Log Pis Std                     4.12068\n",
      "trainer/Policy mu Mean                  0.0522396\n",
      "trainer/Policy mu Std                   0.934242\n",
      "trainer/Policy log std Mean            -3.2836\n",
      "trainer/Policy log std Std              0.882231\n",
      "trainer/Alpha                           0.154016\n",
      "trainer/Alpha Loss                     -0.00186572\n",
      "exploration/num steps total        235988\n",
      "exploration/num paths total           338\n",
      "evaluation/num steps total              2.05173e+06\n",
      "evaluation/num paths total           2356\n",
      "evaluation/path length Mean           907.7\n",
      "evaluation/path length Std            276.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             77\n",
      "evaluation/Rewards Mean                 4.62797\n",
      "evaluation/Rewards Std                  1.0007\n",
      "evaluation/Rewards Max                  6.9324\n",
      "evaluation/Rewards Min                 -1.41047\n",
      "evaluation/Returns Mean              4200.81\n",
      "evaluation/Returns Std               1309.24\n",
      "evaluation/Returns Max               4735.32\n",
      "evaluation/Returns Min                276.622\n",
      "evaluation/Estimation Bias Mean       684.306\n",
      "evaluation/Estimation Bias Std        149.841\n",
      "evaluation/EB/Q_True Mean              46.471\n",
      "evaluation/EB/Q_True Std              135.542\n",
      "evaluation/EB/Q_Pred Mean             730.777\n",
      "evaluation/EB/Q_Pred Std               60.3725\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4200.81\n",
      "evaluation/Actions Mean                 0.0185939\n",
      "evaluation/Actions Std                  0.536645\n",
      "evaluation/Actions Max                  0.999711\n",
      "evaluation/Actions Min                 -0.999782\n",
      "time/backward_policy (s)                1.82005\n",
      "time/backward_zf1 (s)                   1.97745\n",
      "time/backward_zf2 (s)                   1.87553\n",
      "time/data sampling (s)                  0.288334\n",
      "time/data storing (s)                   0.0153905\n",
      "time/evaluation sampling (s)            1.76491\n",
      "time/exploration sampling (s)           0.324566\n",
      "time/logging (s)                        0.0110638\n",
      "time/preback_alpha (s)                  0.938542\n",
      "time/preback_policy (s)                 1.02394\n",
      "time/preback_start (s)                  0.147925\n",
      "time/preback_zf (s)                     5.18997\n",
      "time/saving (s)                         0.00589639\n",
      "time/training (s)                       2.41555\n",
      "time/epoch (s)                         17.7991\n",
      "time/total (s)                       4133.28\n",
      "Epoch                                 230\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:01:29.064228 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 231 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 242000\n",
      "trainer/ZF1 Loss                       17.9446\n",
      "trainer/ZF2 Loss                       23.1383\n",
      "trainer/ZF Expert Reward               13.9749\n",
      "trainer/ZF Policy Reward                7.24368\n",
      "trainer/ZF CHI2 Term                   46.9732\n",
      "trainer/Policy Loss                  -630.572\n",
      "trainer/Bias Loss                      65.0756\n",
      "trainer/Bias Value                     14.5745\n",
      "trainer/Policy Grad Norm              164.344\n",
      "trainer/Policy Param Norm              37.0048\n",
      "trainer/Zf1 Grad Norm                1410.73\n",
      "trainer/Zf1 Param Norm                117.909\n",
      "trainer/Zf2 Grad Norm                1376.11\n",
      "trainer/Zf2 Param Norm                116.128\n",
      "trainer/Z Expert Predictions Mean     756.39\n",
      "trainer/Z Expert Predictions Std       45.0908\n",
      "trainer/Z Expert Predictions Max      825.351\n",
      "trainer/Z Expert Predictions Min      398.19\n",
      "trainer/Z Policy Predictions Mean     632.797\n",
      "trainer/Z Policy Predictions Std      273.815\n",
      "trainer/Z Policy Predictions Max      803.812\n",
      "trainer/Z Policy Predictions Min     -631.76\n",
      "trainer/Z Expert Targets Mean         742.415\n",
      "trainer/Z Expert Targets Std           46.8579\n",
      "trainer/Z Expert Targets Max          805.572\n",
      "trainer/Z Expert Targets Min          390.163\n",
      "trainer/Z Policy Targets Mean         625.554\n",
      "trainer/Z Policy Targets Std          268.974\n",
      "trainer/Z Policy Targets Max          795.203\n",
      "trainer/Z Policy Targets Min         -622.519\n",
      "trainer/Log Pis Mean                   19.8995\n",
      "trainer/Log Pis Std                     4.08378\n",
      "trainer/Policy mu Mean                  0.0172353\n",
      "trainer/Policy mu Std                   1.01566\n",
      "trainer/Policy log std Mean            -3.23419\n",
      "trainer/Policy log std Std              0.899711\n",
      "trainer/Alpha                           0.154643\n",
      "trainer/Alpha Loss                      0.0155396\n",
      "exploration/num steps total        235988\n",
      "exploration/num paths total           338\n",
      "evaluation/num steps total              2.06173e+06\n",
      "evaluation/num paths total           2366\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68471\n",
      "evaluation/Rewards Std                  0.97042\n",
      "evaluation/Rewards Max                  6.86969\n",
      "evaluation/Rewards Min                 -1.79288\n",
      "evaluation/Returns Mean              4684.71\n",
      "evaluation/Returns Std                 59.4879\n",
      "evaluation/Returns Max               4786.58\n",
      "evaluation/Returns Min               4576.56\n",
      "evaluation/Estimation Bias Mean       689.364\n",
      "evaluation/Estimation Bias Std        142.018\n",
      "evaluation/EB/Q_True Mean              42.7382\n",
      "evaluation/EB/Q_True Std              131.528\n",
      "evaluation/EB/Q_Pred Mean             732.102\n",
      "evaluation/EB/Q_Pred Std               55.3249\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4684.71\n",
      "evaluation/Actions Mean                 0.0171588\n",
      "evaluation/Actions Std                  0.539407\n",
      "evaluation/Actions Max                  0.999644\n",
      "evaluation/Actions Min                 -0.9995\n",
      "time/backward_policy (s)                1.93424\n",
      "time/backward_zf1 (s)                   2.09158\n",
      "time/backward_zf2 (s)                   2.02221\n",
      "time/data sampling (s)                  0.311897\n",
      "time/data storing (s)                   0.0150045\n",
      "time/evaluation sampling (s)            1.72106\n",
      "time/exploration sampling (s)           0.321323\n",
      "time/logging (s)                        0.0123814\n",
      "time/preback_alpha (s)                  1.04192\n",
      "time/preback_policy (s)                 1.17204\n",
      "time/preback_start (s)                  0.147761\n",
      "time/preback_zf (s)                     5.22945\n",
      "time/saving (s)                         0.00705578\n",
      "time/training (s)                       2.12122\n",
      "time/epoch (s)                         18.1491\n",
      "time/total (s)                       4151.45\n",
      "Epoch                                 231\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:01:47.536592 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 232 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 243000\n",
      "trainer/ZF1 Loss                       90.1573\n",
      "trainer/ZF2 Loss                      100.367\n",
      "trainer/ZF Expert Reward               15.9901\n",
      "trainer/ZF Policy Reward                7.22864\n",
      "trainer/ZF CHI2 Term                  124.048\n",
      "trainer/Policy Loss                  -624.065\n",
      "trainer/Bias Loss                      51.3763\n",
      "trainer/Bias Value                     14.5835\n",
      "trainer/Policy Grad Norm              163.71\n",
      "trainer/Policy Param Norm              37.0313\n",
      "trainer/Zf1 Grad Norm                1687.72\n",
      "trainer/Zf1 Param Norm                118.056\n",
      "trainer/Zf2 Grad Norm                1669.05\n",
      "trainer/Zf2 Param Norm                116.267\n",
      "trainer/Z Expert Predictions Mean     754.085\n",
      "trainer/Z Expert Predictions Std       37.9914\n",
      "trainer/Z Expert Predictions Max      832.52\n",
      "trainer/Z Expert Predictions Min      567.612\n",
      "trainer/Z Policy Predictions Mean     630.539\n",
      "trainer/Z Policy Predictions Std      254.95\n",
      "trainer/Z Policy Predictions Max      801.137\n",
      "trainer/Z Policy Predictions Min     -649.447\n",
      "trainer/Z Expert Targets Mean         738.094\n",
      "trainer/Z Expert Targets Std           38.7143\n",
      "trainer/Z Expert Targets Max          806.754\n",
      "trainer/Z Expert Targets Min          543.734\n",
      "trainer/Z Policy Targets Mean         623.31\n",
      "trainer/Z Policy Targets Std          255.289\n",
      "trainer/Z Policy Targets Max          802.612\n",
      "trainer/Z Policy Targets Min         -644.661\n",
      "trainer/Log Pis Mean                   20.2265\n",
      "trainer/Log Pis Std                     3.88478\n",
      "trainer/Policy mu Mean                  0.0523396\n",
      "trainer/Policy mu Std                   0.992426\n",
      "trainer/Policy log std Mean            -3.27076\n",
      "trainer/Policy log std Std              0.922211\n",
      "trainer/Alpha                           0.155949\n",
      "trainer/Alpha Loss                     -0.0353209\n",
      "exploration/num steps total        236988\n",
      "exploration/num paths total           339\n",
      "evaluation/num steps total              2.07173e+06\n",
      "evaluation/num paths total           2376\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62497\n",
      "evaluation/Rewards Std                  1.02777\n",
      "evaluation/Rewards Max                  6.69009\n",
      "evaluation/Rewards Min                 -3.11559\n",
      "evaluation/Returns Mean              4624.97\n",
      "evaluation/Returns Std                125.55\n",
      "evaluation/Returns Max               4773.54\n",
      "evaluation/Returns Min               4428.51\n",
      "evaluation/Estimation Bias Mean       681.326\n",
      "evaluation/Estimation Bias Std        143.03\n",
      "evaluation/EB/Q_True Mean              42.2215\n",
      "evaluation/EB/Q_True Std              130.063\n",
      "evaluation/EB/Q_Pred Mean             723.548\n",
      "evaluation/EB/Q_Pred Std               62.9045\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4624.97\n",
      "evaluation/Actions Mean                 0.023964\n",
      "evaluation/Actions Std                  0.536959\n",
      "evaluation/Actions Max                  0.999689\n",
      "evaluation/Actions Min                 -0.999869\n",
      "time/backward_policy (s)                2.02241\n",
      "time/backward_zf1 (s)                   2.14567\n",
      "time/backward_zf2 (s)                   2.06823\n",
      "time/data sampling (s)                  0.290351\n",
      "time/data storing (s)                   0.0154449\n",
      "time/evaluation sampling (s)            1.69156\n",
      "time/exploration sampling (s)           0.326115\n",
      "time/logging (s)                        0.0130475\n",
      "time/preback_alpha (s)                  1.04833\n",
      "time/preback_policy (s)                 1.18815\n",
      "time/preback_start (s)                  0.148815\n",
      "time/preback_zf (s)                     5.2473\n",
      "time/saving (s)                         0.00580264\n",
      "time/training (s)                       2.1928\n",
      "time/epoch (s)                         18.404\n",
      "time/total (s)                       4169.87\n",
      "Epoch                                 232\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:02:05.760377 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 233 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 244000\n",
      "trainer/ZF1 Loss                        9.7492\n",
      "trainer/ZF2 Loss                        7.71903\n",
      "trainer/ZF Expert Reward               13.7102\n",
      "trainer/ZF Policy Reward                2.61793\n",
      "trainer/ZF CHI2 Term                   39.795\n",
      "trainer/Policy Loss                  -625.461\n",
      "trainer/Bias Loss                      60.2064\n",
      "trainer/Bias Value                     14.5926\n",
      "trainer/Policy Grad Norm              168.823\n",
      "trainer/Policy Param Norm              37.0606\n",
      "trainer/Zf1 Grad Norm                1197.22\n",
      "trainer/Zf1 Param Norm                118.2\n",
      "trainer/Zf2 Grad Norm                1149.15\n",
      "trainer/Zf2 Param Norm                116.411\n",
      "trainer/Z Expert Predictions Mean     748.493\n",
      "trainer/Z Expert Predictions Std       42.2\n",
      "trainer/Z Expert Predictions Max      820.881\n",
      "trainer/Z Expert Predictions Min      536.017\n",
      "trainer/Z Policy Predictions Mean     627.409\n",
      "trainer/Z Policy Predictions Std      274.018\n",
      "trainer/Z Policy Predictions Max      805.559\n",
      "trainer/Z Policy Predictions Min     -603.651\n",
      "trainer/Z Expert Targets Mean         734.783\n",
      "trainer/Z Expert Targets Std           45.0445\n",
      "trainer/Z Expert Targets Max          811.607\n",
      "trainer/Z Expert Targets Min          512.637\n",
      "trainer/Z Policy Targets Mean         624.792\n",
      "trainer/Z Policy Targets Std          269.536\n",
      "trainer/Z Policy Targets Max          805.076\n",
      "trainer/Z Policy Targets Min         -587.169\n",
      "trainer/Log Pis Mean                   20.1703\n",
      "trainer/Log Pis Std                     4.49852\n",
      "trainer/Policy mu Mean                  0.0545173\n",
      "trainer/Policy mu Std                   0.992774\n",
      "trainer/Policy log std Mean            -3.2695\n",
      "trainer/Policy log std Std              0.901977\n",
      "trainer/Alpha                           0.154536\n",
      "trainer/Alpha Loss                     -0.0263197\n",
      "exploration/num steps total        238988\n",
      "exploration/num paths total           341\n",
      "evaluation/num steps total              2.0809e+06\n",
      "evaluation/num paths total           2386\n",
      "evaluation/path length Mean           916.6\n",
      "evaluation/path length Std            245.241\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            181\n",
      "evaluation/Rewards Mean                 4.72795\n",
      "evaluation/Rewards Std                  1.03983\n",
      "evaluation/Rewards Max                  7.09626\n",
      "evaluation/Rewards Min                 -1.61091\n",
      "evaluation/Returns Mean              4333.64\n",
      "evaluation/Returns Std               1184.68\n",
      "evaluation/Returns Max               4903.78\n",
      "evaluation/Returns Min                801.109\n",
      "evaluation/Estimation Bias Mean       673.807\n",
      "evaluation/Estimation Bias Std        161.016\n",
      "evaluation/EB/Q_True Mean              49.0636\n",
      "evaluation/EB/Q_True Std              144.217\n",
      "evaluation/EB/Q_Pred Mean             722.871\n",
      "evaluation/EB/Q_Pred Std               65.332\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4333.64\n",
      "evaluation/Actions Mean                 0.0228267\n",
      "evaluation/Actions Std                  0.546175\n",
      "evaluation/Actions Max                  0.999809\n",
      "evaluation/Actions Min                 -0.999542\n",
      "time/backward_policy (s)                1.93615\n",
      "time/backward_zf1 (s)                   2.06243\n",
      "time/backward_zf2 (s)                   1.98579\n",
      "time/data sampling (s)                  0.295671\n",
      "time/data storing (s)                   0.0146282\n",
      "time/evaluation sampling (s)            1.73285\n",
      "time/exploration sampling (s)           0.321703\n",
      "time/logging (s)                        0.011942\n",
      "time/preback_alpha (s)                  0.978645\n",
      "time/preback_policy (s)                 1.10257\n",
      "time/preback_start (s)                  0.147212\n",
      "time/preback_zf (s)                     5.21643\n",
      "time/saving (s)                         0.00594182\n",
      "time/training (s)                       2.3377\n",
      "time/epoch (s)                         18.1497\n",
      "time/total (s)                       4188.05\n",
      "Epoch                                 233\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 12:02:24.240257 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 234 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 245000\n",
      "trainer/ZF1 Loss                        7.72222\n",
      "trainer/ZF2 Loss                        2.65273\n",
      "trainer/ZF Expert Reward               17.248\n",
      "trainer/ZF Policy Reward                2.6313\n",
      "trainer/ZF CHI2 Term                   40.0285\n",
      "trainer/Policy Loss                  -626.656\n",
      "trainer/Bias Loss                      61.1761\n",
      "trainer/Bias Value                     14.6008\n",
      "trainer/Policy Grad Norm              145.279\n",
      "trainer/Policy Param Norm              37.0897\n",
      "trainer/Zf1 Grad Norm                1169.19\n",
      "trainer/Zf1 Param Norm                118.334\n",
      "trainer/Zf2 Grad Norm                1022.67\n",
      "trainer/Zf2 Param Norm                116.564\n",
      "trainer/Z Expert Predictions Mean     742.772\n",
      "trainer/Z Expert Predictions Std       62.0089\n",
      "trainer/Z Expert Predictions Max      835.052\n",
      "trainer/Z Expert Predictions Min       29.9713\n",
      "trainer/Z Policy Predictions Mean     626.467\n",
      "trainer/Z Policy Predictions Std      259.796\n",
      "trainer/Z Policy Predictions Max      802.731\n",
      "trainer/Z Policy Predictions Min     -640.733\n",
      "trainer/Z Expert Targets Mean         725.524\n",
      "trainer/Z Expert Targets Std           62.9458\n",
      "trainer/Z Expert Targets Max          801.887\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         623.836\n",
      "trainer/Z Policy Targets Std          255.561\n",
      "trainer/Z Policy Targets Max          805.957\n",
      "trainer/Z Policy Targets Min         -621.034\n",
      "trainer/Log Pis Mean                   20.4286\n",
      "trainer/Log Pis Std                     4.51722\n",
      "trainer/Policy mu Mean                  0.00545216\n",
      "trainer/Policy mu Std                   1.03582\n",
      "trainer/Policy log std Mean            -3.27006\n",
      "trainer/Policy log std Std              0.958479\n",
      "trainer/Alpha                           0.153517\n",
      "trainer/Alpha Loss                     -0.0657996\n",
      "exploration/num steps total        239988\n",
      "exploration/num paths total           342\n",
      "evaluation/num steps total              2.0909e+06\n",
      "evaluation/num paths total           2396\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.71578\n",
      "evaluation/Rewards Std                  0.94994\n",
      "evaluation/Rewards Max                  6.72304\n",
      "evaluation/Rewards Min                 -1.66095\n",
      "evaluation/Returns Mean              4715.78\n",
      "evaluation/Returns Std                 42.3331\n",
      "evaluation/Returns Max               4771.07\n",
      "evaluation/Returns Min               4638.19\n",
      "evaluation/Estimation Bias Mean       675.357\n",
      "evaluation/Estimation Bias Std        144.535\n",
      "evaluation/EB/Q_True Mean              43.1918\n",
      "evaluation/EB/Q_True Std              133.568\n",
      "evaluation/EB/Q_Pred Mean             718.549\n",
      "evaluation/EB/Q_Pred Std               54.7908\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4715.78\n",
      "evaluation/Actions Mean                 0.0219631\n",
      "evaluation/Actions Std                  0.545102\n",
      "evaluation/Actions Max                  0.999917\n",
      "evaluation/Actions Min                 -0.999501\n",
      "time/backward_policy (s)                1.99284\n",
      "time/backward_zf1 (s)                   2.14555\n",
      "time/backward_zf2 (s)                   2.06838\n",
      "time/data sampling (s)                  0.318858\n",
      "time/data storing (s)                   0.0156449\n",
      "time/evaluation sampling (s)            1.71437\n",
      "time/exploration sampling (s)           0.327579\n",
      "time/logging (s)                        0.0127986\n",
      "time/preback_alpha (s)                  1.04258\n",
      "time/preback_policy (s)                 1.16381\n",
      "time/preback_start (s)                  0.151021\n",
      "time/preback_zf (s)                     5.2468\n",
      "time/saving (s)                         0.00675035\n",
      "time/training (s)                       2.20369\n",
      "time/epoch (s)                         18.4107\n",
      "time/total (s)                       4206.48\n",
      "Epoch                                 234\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 12:02:42.396216 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 235 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 246000\n",
      "trainer/ZF1 Loss                       10.1572\n",
      "trainer/ZF2 Loss                       12.7721\n",
      "trainer/ZF Expert Reward               12.0793\n",
      "trainer/ZF Policy Reward                1.2344\n",
      "trainer/ZF CHI2 Term                   42.336\n",
      "trainer/Policy Loss                  -626.634\n",
      "trainer/Bias Loss                      63.0912\n",
      "trainer/Bias Value                     14.6082\n",
      "trainer/Policy Grad Norm              175.577\n",
      "trainer/Policy Param Norm              37.1179\n",
      "trainer/Zf1 Grad Norm                1460.64\n",
      "trainer/Zf1 Param Norm                118.472\n",
      "trainer/Zf2 Grad Norm                1470.39\n",
      "trainer/Zf2 Param Norm                116.701\n",
      "trainer/Z Expert Predictions Mean     738.61\n",
      "trainer/Z Expert Predictions Std       50.4463\n",
      "trainer/Z Expert Predictions Max      811.125\n",
      "trainer/Z Expert Predictions Min      414.905\n",
      "trainer/Z Policy Predictions Mean     624.777\n",
      "trainer/Z Policy Predictions Std      245.828\n",
      "trainer/Z Policy Predictions Max      786.372\n",
      "trainer/Z Policy Predictions Min     -553.811\n",
      "trainer/Z Expert Targets Mean         726.531\n",
      "trainer/Z Expert Targets Std           53.0719\n",
      "trainer/Z Expert Targets Max          798.54\n",
      "trainer/Z Expert Targets Min          411.993\n",
      "trainer/Z Policy Targets Mean         623.543\n",
      "trainer/Z Policy Targets Std          244.633\n",
      "trainer/Z Policy Targets Max          787.445\n",
      "trainer/Z Policy Targets Min         -552.328\n",
      "trainer/Log Pis Mean                   20.2287\n",
      "trainer/Log Pis Std                     4.43456\n",
      "trainer/Policy mu Mean                  0.0537216\n",
      "trainer/Policy mu Std                   0.989779\n",
      "trainer/Policy log std Mean            -3.26656\n",
      "trainer/Policy log std Std              0.926316\n",
      "trainer/Alpha                           0.155518\n",
      "trainer/Alpha Loss                     -0.0355681\n",
      "exploration/num steps total        240988\n",
      "exploration/num paths total           343\n",
      "evaluation/num steps total              2.1009e+06\n",
      "evaluation/num paths total           2406\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.71614\n",
      "evaluation/Rewards Std                  0.983365\n",
      "evaluation/Rewards Max                  6.76862\n",
      "evaluation/Rewards Min                 -1.80107\n",
      "evaluation/Returns Mean              4716.14\n",
      "evaluation/Returns Std                 95.9917\n",
      "evaluation/Returns Max               4864.67\n",
      "evaluation/Returns Min               4526.29\n",
      "evaluation/Estimation Bias Mean       668.314\n",
      "evaluation/Estimation Bias Std        150.332\n",
      "evaluation/EB/Q_True Mean              44.3304\n",
      "evaluation/EB/Q_True Std              136.351\n",
      "evaluation/EB/Q_Pred Mean             712.644\n",
      "evaluation/EB/Q_Pred Std               56.6129\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4716.14\n",
      "evaluation/Actions Mean                 0.025489\n",
      "evaluation/Actions Std                  0.536313\n",
      "evaluation/Actions Max                  0.999629\n",
      "evaluation/Actions Min                 -0.999889\n",
      "time/backward_policy (s)                1.93674\n",
      "time/backward_zf1 (s)                   2.06913\n",
      "time/backward_zf2 (s)                   1.99924\n",
      "time/data sampling (s)                  0.309415\n",
      "time/data storing (s)                   0.0142834\n",
      "time/evaluation sampling (s)            1.7776\n",
      "time/exploration sampling (s)           0.319107\n",
      "time/logging (s)                        0.0120173\n",
      "time/preback_alpha (s)                  0.999676\n",
      "time/preback_policy (s)                 1.1228\n",
      "time/preback_start (s)                  0.14764\n",
      "time/preback_zf (s)                     5.17289\n",
      "time/saving (s)                         0.00580851\n",
      "time/training (s)                       2.19222\n",
      "time/epoch (s)                         18.0786\n",
      "time/total (s)                       4224.59\n",
      "Epoch                                 235\n",
      "---------------------------------  ---------------\n",
      "2024-06-15 12:03:00.236821 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 236 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 247000\n",
      "trainer/ZF1 Loss                        9.0109\n",
      "trainer/ZF2 Loss                        7.87302\n",
      "trainer/ZF Expert Reward               10.3335\n",
      "trainer/ZF Policy Reward               -1.83537\n",
      "trainer/ZF CHI2 Term                   40.0088\n",
      "trainer/Policy Loss                  -607.846\n",
      "trainer/Bias Loss                      53.9205\n",
      "trainer/Bias Value                     14.6174\n",
      "trainer/Policy Grad Norm              141.703\n",
      "trainer/Policy Param Norm              37.1443\n",
      "trainer/Zf1 Grad Norm                1552.73\n",
      "trainer/Zf1 Param Norm                118.619\n",
      "trainer/Zf2 Grad Norm                1627.88\n",
      "trainer/Zf2 Param Norm                116.86\n",
      "trainer/Z Expert Predictions Mean     738.066\n",
      "trainer/Z Expert Predictions Std       38.0769\n",
      "trainer/Z Expert Predictions Max      807.883\n",
      "trainer/Z Expert Predictions Min      492.494\n",
      "trainer/Z Policy Predictions Mean     603.608\n",
      "trainer/Z Policy Predictions Std      267.39\n",
      "trainer/Z Policy Predictions Max      782.401\n",
      "trainer/Z Policy Predictions Min     -655.686\n",
      "trainer/Z Expert Targets Mean         727.732\n",
      "trainer/Z Expert Targets Std           40.0252\n",
      "trainer/Z Expert Targets Max          803.077\n",
      "trainer/Z Expert Targets Min          468.367\n",
      "trainer/Z Policy Targets Mean         605.444\n",
      "trainer/Z Policy Targets Std          263.248\n",
      "trainer/Z Policy Targets Max          780.544\n",
      "trainer/Z Policy Targets Min         -628.19\n",
      "trainer/Log Pis Mean                   19.5939\n",
      "trainer/Log Pis Std                     4.16681\n",
      "trainer/Policy mu Mean                  0.0625488\n",
      "trainer/Policy mu Std                   0.995595\n",
      "trainer/Policy log std Mean            -3.22383\n",
      "trainer/Policy log std Std              0.939471\n",
      "trainer/Alpha                           0.155574\n",
      "trainer/Alpha Loss                      0.0631774\n",
      "exploration/num steps total        242988\n",
      "exploration/num paths total           345\n",
      "evaluation/num steps total              2.10993e+06\n",
      "evaluation/num paths total           2416\n",
      "evaluation/path length Mean           903.2\n",
      "evaluation/path length Std            290.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             32\n",
      "evaluation/Rewards Mean                 4.76393\n",
      "evaluation/Rewards Std                  1.01617\n",
      "evaluation/Rewards Max                  6.86984\n",
      "evaluation/Rewards Min                 -2.08565\n",
      "evaluation/Returns Mean              4302.78\n",
      "evaluation/Returns Std               1417.3\n",
      "evaluation/Returns Max               4867.36\n",
      "evaluation/Returns Min                 54.2329\n",
      "evaluation/Estimation Bias Mean       666.06\n",
      "evaluation/Estimation Bias Std        155.931\n",
      "evaluation/EB/Q_True Mean              48.5239\n",
      "evaluation/EB/Q_True Std              141.22\n",
      "evaluation/EB/Q_Pred Mean             714.584\n",
      "evaluation/EB/Q_Pred Std               59.6971\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4302.78\n",
      "evaluation/Actions Mean                 0.0178558\n",
      "evaluation/Actions Std                  0.53566\n",
      "evaluation/Actions Max                  0.999462\n",
      "evaluation/Actions Min                 -0.999755\n",
      "time/backward_policy (s)                1.80468\n",
      "time/backward_zf1 (s)                   1.94905\n",
      "time/backward_zf2 (s)                   1.86205\n",
      "time/data sampling (s)                  0.3024\n",
      "time/data storing (s)                   0.0153916\n",
      "time/evaluation sampling (s)            1.7911\n",
      "time/exploration sampling (s)           0.328495\n",
      "time/logging (s)                        0.0111806\n",
      "time/preback_alpha (s)                  0.938766\n",
      "time/preback_policy (s)                 1.03464\n",
      "time/preback_start (s)                  0.147441\n",
      "time/preback_zf (s)                     5.19225\n",
      "time/saving (s)                         0.00589992\n",
      "time/training (s)                       2.37567\n",
      "time/epoch (s)                         17.759\n",
      "time/total (s)                       4242.38\n",
      "Epoch                                 236\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:03:18.311032 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 237 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 248000\n",
      "trainer/ZF1 Loss                       16.1243\n",
      "trainer/ZF2 Loss                       11.0577\n",
      "trainer/ZF Expert Reward               17.4323\n",
      "trainer/ZF Policy Reward                5.16672\n",
      "trainer/ZF CHI2 Term                   45.3167\n",
      "trainer/Policy Loss                  -600.801\n",
      "trainer/Bias Loss                      63.6646\n",
      "trainer/Bias Value                     14.6268\n",
      "trainer/Policy Grad Norm              159.512\n",
      "trainer/Policy Param Norm              37.1718\n",
      "trainer/Zf1 Grad Norm                1524.34\n",
      "trainer/Zf1 Param Norm                118.766\n",
      "trainer/Zf2 Grad Norm                1296.33\n",
      "trainer/Zf2 Param Norm                116.998\n",
      "trainer/Z Expert Predictions Mean     739.984\n",
      "trainer/Z Expert Predictions Std       45.4662\n",
      "trainer/Z Expert Predictions Max      809.373\n",
      "trainer/Z Expert Predictions Min      447.581\n",
      "trainer/Z Policy Predictions Mean     600.722\n",
      "trainer/Z Policy Predictions Std      304.258\n",
      "trainer/Z Policy Predictions Max      788.582\n",
      "trainer/Z Policy Predictions Min     -654.278\n",
      "trainer/Z Expert Targets Mean         722.551\n",
      "trainer/Z Expert Targets Std           47.4174\n",
      "trainer/Z Expert Targets Max          789.557\n",
      "trainer/Z Expert Targets Min          417.403\n",
      "trainer/Z Policy Targets Mean         595.555\n",
      "trainer/Z Policy Targets Std          299.93\n",
      "trainer/Z Policy Targets Max          785.179\n",
      "trainer/Z Policy Targets Min         -642.457\n",
      "trainer/Log Pis Mean                   19.6566\n",
      "trainer/Log Pis Std                     4.49814\n",
      "trainer/Policy mu Mean                  0.0400753\n",
      "trainer/Policy mu Std                   1.00583\n",
      "trainer/Policy log std Mean            -3.20791\n",
      "trainer/Policy log std Std              0.961927\n",
      "trainer/Alpha                           0.154884\n",
      "trainer/Alpha Loss                      0.053184\n",
      "exploration/num steps total        243988\n",
      "exploration/num paths total           346\n",
      "evaluation/num steps total              2.11993e+06\n",
      "evaluation/num paths total           2426\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7084\n",
      "evaluation/Rewards Std                  0.931104\n",
      "evaluation/Rewards Max                  7.06585\n",
      "evaluation/Rewards Min                 -1.37484\n",
      "evaluation/Returns Mean              4708.4\n",
      "evaluation/Returns Std                 89.6349\n",
      "evaluation/Returns Max               4815.45\n",
      "evaluation/Returns Min               4571.77\n",
      "evaluation/Estimation Bias Mean       670.756\n",
      "evaluation/Estimation Bias Std        141.981\n",
      "evaluation/EB/Q_True Mean              42.0757\n",
      "evaluation/EB/Q_True Std              129.878\n",
      "evaluation/EB/Q_Pred Mean             712.831\n",
      "evaluation/EB/Q_Pred Std               52.1485\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4708.4\n",
      "evaluation/Actions Mean                 0.0214772\n",
      "evaluation/Actions Std                  0.538407\n",
      "evaluation/Actions Max                  0.999696\n",
      "evaluation/Actions Min                 -0.999774\n",
      "time/backward_policy (s)                1.94062\n",
      "time/backward_zf1 (s)                   2.06468\n",
      "time/backward_zf2 (s)                   2.00046\n",
      "time/data sampling (s)                  0.309594\n",
      "time/data storing (s)                   0.0143671\n",
      "time/evaluation sampling (s)            1.71681\n",
      "time/exploration sampling (s)           0.31646\n",
      "time/logging (s)                        0.0125807\n",
      "time/preback_alpha (s)                  1.03116\n",
      "time/preback_policy (s)                 1.1733\n",
      "time/preback_start (s)                  0.144903\n",
      "time/preback_zf (s)                     5.17835\n",
      "time/saving (s)                         0.00746391\n",
      "time/training (s)                       2.09665\n",
      "time/epoch (s)                         18.0074\n",
      "time/total (s)                       4260.4\n",
      "Epoch                                 237\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:03:36.362115 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 238 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 249000\n",
      "trainer/ZF1 Loss                        6.46616\n",
      "trainer/ZF2 Loss                        2.13846\n",
      "trainer/ZF Expert Reward               12.6499\n",
      "trainer/ZF Policy Reward                0.359864\n",
      "trainer/ZF CHI2 Term                   36.1811\n",
      "trainer/Policy Loss                  -625.484\n",
      "trainer/Bias Loss                      53.6304\n",
      "trainer/Bias Value                     14.6372\n",
      "trainer/Policy Grad Norm              137.855\n",
      "trainer/Policy Param Norm              37.1997\n",
      "trainer/Zf1 Grad Norm                1630.18\n",
      "trainer/Zf1 Param Norm                118.902\n",
      "trainer/Zf2 Grad Norm                1408.02\n",
      "trainer/Zf2 Param Norm                117.15\n",
      "trainer/Z Expert Predictions Mean     735.388\n",
      "trainer/Z Expert Predictions Std       45.7952\n",
      "trainer/Z Expert Predictions Max      806.6\n",
      "trainer/Z Expert Predictions Min      505.356\n",
      "trainer/Z Policy Predictions Mean     626.114\n",
      "trainer/Z Policy Predictions Std      227.798\n",
      "trainer/Z Policy Predictions Max      780.502\n",
      "trainer/Z Policy Predictions Min     -608.68\n",
      "trainer/Z Expert Targets Mean         722.738\n",
      "trainer/Z Expert Targets Std           47.6125\n",
      "trainer/Z Expert Targets Max          791.511\n",
      "trainer/Z Expert Targets Min          485.054\n",
      "trainer/Z Policy Targets Mean         625.754\n",
      "trainer/Z Policy Targets Std          225.735\n",
      "trainer/Z Policy Targets Max          766.839\n",
      "trainer/Z Policy Targets Min         -596.775\n",
      "trainer/Log Pis Mean                   19.7866\n",
      "trainer/Log Pis Std                     3.95565\n",
      "trainer/Policy mu Mean                  0.0617219\n",
      "trainer/Policy mu Std                   0.887366\n",
      "trainer/Policy log std Mean            -3.34436\n",
      "trainer/Policy log std Std              0.862436\n",
      "trainer/Alpha                           0.153622\n",
      "trainer/Alpha Loss                      0.0327903\n",
      "exploration/num steps total        243988\n",
      "exploration/num paths total           346\n",
      "evaluation/num steps total              2.12993e+06\n",
      "evaluation/num paths total           2436\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68149\n",
      "evaluation/Rewards Std                  1.01006\n",
      "evaluation/Rewards Max                  6.76664\n",
      "evaluation/Rewards Min                 -1.23436\n",
      "evaluation/Returns Mean              4681.49\n",
      "evaluation/Returns Std                103.871\n",
      "evaluation/Returns Max               4818.42\n",
      "evaluation/Returns Min               4509.99\n",
      "evaluation/Estimation Bias Mean       661.731\n",
      "evaluation/Estimation Bias Std        151.023\n",
      "evaluation/EB/Q_True Mean              43.8367\n",
      "evaluation/EB/Q_True Std              134.68\n",
      "evaluation/EB/Q_Pred Mean             705.568\n",
      "evaluation/EB/Q_Pred Std               62.6795\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4681.49\n",
      "evaluation/Actions Mean                 0.0241605\n",
      "evaluation/Actions Std                  0.539208\n",
      "evaluation/Actions Max                  0.999609\n",
      "evaluation/Actions Min                 -0.999966\n",
      "time/backward_policy (s)                1.91939\n",
      "time/backward_zf1 (s)                   2.0664\n",
      "time/backward_zf2 (s)                   1.99527\n",
      "time/data sampling (s)                  0.29955\n",
      "time/data storing (s)                   0.014295\n",
      "time/evaluation sampling (s)            1.74775\n",
      "time/exploration sampling (s)           0.316919\n",
      "time/logging (s)                        0.0173726\n",
      "time/preback_alpha (s)                  0.998104\n",
      "time/preback_policy (s)                 1.12892\n",
      "time/preback_start (s)                  0.143946\n",
      "time/preback_zf (s)                     5.1832\n",
      "time/saving (s)                         0.0060131\n",
      "time/training (s)                       2.14772\n",
      "time/epoch (s)                         17.9849\n",
      "time/total (s)                       4278.41\n",
      "Epoch                                 238\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:03:54.612666 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 239 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 250000\n",
      "trainer/ZF1 Loss                        5.48055\n",
      "trainer/ZF2 Loss                        5.39585\n",
      "trainer/ZF Expert Reward               13.5632\n",
      "trainer/ZF Policy Reward               -0.947634\n",
      "trainer/ZF CHI2 Term                   39.5651\n",
      "trainer/Policy Loss                  -618.992\n",
      "trainer/Bias Loss                      41.4864\n",
      "trainer/Bias Value                     14.6481\n",
      "trainer/Policy Grad Norm              173.988\n",
      "trainer/Policy Param Norm              37.2261\n",
      "trainer/Zf1 Grad Norm                1545.8\n",
      "trainer/Zf1 Param Norm                119.054\n",
      "trainer/Zf2 Grad Norm                1398.38\n",
      "trainer/Zf2 Param Norm                117.298\n",
      "trainer/Z Expert Predictions Mean     730.558\n",
      "trainer/Z Expert Predictions Std       46.5111\n",
      "trainer/Z Expert Predictions Max      822.062\n",
      "trainer/Z Expert Predictions Min      521.994\n",
      "trainer/Z Policy Predictions Mean     616.543\n",
      "trainer/Z Policy Predictions Std      243.331\n",
      "trainer/Z Policy Predictions Max      785.8\n",
      "trainer/Z Policy Predictions Min     -597.691\n",
      "trainer/Z Expert Targets Mean         716.994\n",
      "trainer/Z Expert Targets Std           48.0655\n",
      "trainer/Z Expert Targets Max          789.07\n",
      "trainer/Z Expert Targets Min          507.623\n",
      "trainer/Z Policy Targets Mean         617.491\n",
      "trainer/Z Policy Targets Std          238.778\n",
      "trainer/Z Policy Targets Max          775.125\n",
      "trainer/Z Policy Targets Min         -579.895\n",
      "trainer/Log Pis Mean                   19.8141\n",
      "trainer/Log Pis Std                     3.9787\n",
      "trainer/Policy mu Mean                  0.0483538\n",
      "trainer/Policy mu Std                   0.930097\n",
      "trainer/Policy log std Mean            -3.2977\n",
      "trainer/Policy log std Std              0.85183\n",
      "trainer/Alpha                           0.155307\n",
      "trainer/Alpha Loss                      0.0288679\n",
      "exploration/num steps total        244988\n",
      "exploration/num paths total           347\n",
      "evaluation/num steps total              2.13899e+06\n",
      "evaluation/num paths total           2446\n",
      "evaluation/path length Mean           906.2\n",
      "evaluation/path length Std            189.206\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            476\n",
      "evaluation/Rewards Mean                 4.73858\n",
      "evaluation/Rewards Std                  1.03508\n",
      "evaluation/Rewards Max                  6.88105\n",
      "evaluation/Rewards Min                 -1.79887\n",
      "evaluation/Returns Mean              4294.1\n",
      "evaluation/Returns Std                888.011\n",
      "evaluation/Returns Max               4860.15\n",
      "evaluation/Returns Min               2267.51\n",
      "evaluation/Estimation Bias Mean       649.798\n",
      "evaluation/Estimation Bias Std        153.242\n",
      "evaluation/EB/Q_True Mean              45.8256\n",
      "evaluation/EB/Q_True Std              133.929\n",
      "evaluation/EB/Q_Pred Mean             695.624\n",
      "evaluation/EB/Q_Pred Std               73.2435\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4294.1\n",
      "evaluation/Actions Mean                 0.0241911\n",
      "evaluation/Actions Std                  0.536934\n",
      "evaluation/Actions Max                  0.999877\n",
      "evaluation/Actions Min                 -0.999921\n",
      "time/backward_policy (s)                1.90922\n",
      "time/backward_zf1 (s)                   2.06079\n",
      "time/backward_zf2 (s)                   1.98404\n",
      "time/data sampling (s)                  0.291779\n",
      "time/data storing (s)                   0.0152052\n",
      "time/evaluation sampling (s)            1.73776\n",
      "time/exploration sampling (s)           0.324752\n",
      "time/logging (s)                        0.0113807\n",
      "time/preback_alpha (s)                  0.960223\n",
      "time/preback_policy (s)                 1.07402\n",
      "time/preback_start (s)                  0.148539\n",
      "time/preback_zf (s)                     5.24252\n",
      "time/saving (s)                         0.00593745\n",
      "time/training (s)                       2.40721\n",
      "time/epoch (s)                         18.1734\n",
      "time/total (s)                       4296.61\n",
      "Epoch                                 239\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:04:12.713605 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 240 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 251000\n",
      "trainer/ZF1 Loss                       14.0808\n",
      "trainer/ZF2 Loss                        9.86446\n",
      "trainer/ZF Expert Reward               15.7822\n",
      "trainer/ZF Policy Reward                5.38463\n",
      "trainer/ZF CHI2 Term                   42.1524\n",
      "trainer/Policy Loss                  -634.669\n",
      "trainer/Bias Loss                      50.8348\n",
      "trainer/Bias Value                     14.6584\n",
      "trainer/Policy Grad Norm              155.523\n",
      "trainer/Policy Param Norm              37.2504\n",
      "trainer/Zf1 Grad Norm                1402.41\n",
      "trainer/Zf1 Param Norm                119.193\n",
      "trainer/Zf2 Grad Norm                1404.58\n",
      "trainer/Zf2 Param Norm                117.444\n",
      "trainer/Z Expert Predictions Mean     734.32\n",
      "trainer/Z Expert Predictions Std       37.3632\n",
      "trainer/Z Expert Predictions Max      793.77\n",
      "trainer/Z Expert Predictions Min      527.736\n",
      "trainer/Z Policy Predictions Mean     636.82\n",
      "trainer/Z Policy Predictions Std      208.768\n",
      "trainer/Z Policy Predictions Max      799.993\n",
      "trainer/Z Policy Predictions Min     -573.125\n",
      "trainer/Z Expert Targets Mean         718.538\n",
      "trainer/Z Expert Targets Std           37.7944\n",
      "trainer/Z Expert Targets Max          784.821\n",
      "trainer/Z Expert Targets Min          512.506\n",
      "trainer/Z Policy Targets Mean         631.435\n",
      "trainer/Z Policy Targets Std          206.956\n",
      "trainer/Z Policy Targets Max          765.236\n",
      "trainer/Z Policy Targets Min         -574.165\n",
      "trainer/Log Pis Mean                   19.982\n",
      "trainer/Log Pis Std                     3.96308\n",
      "trainer/Policy mu Mean                  0.0195615\n",
      "trainer/Policy mu Std                   0.885265\n",
      "trainer/Policy log std Mean            -3.35833\n",
      "trainer/Policy log std Std              0.826618\n",
      "trainer/Alpha                           0.156182\n",
      "trainer/Alpha Loss                      0.00280401\n",
      "exploration/num steps total        245988\n",
      "exploration/num paths total           348\n",
      "evaluation/num steps total              2.14899e+06\n",
      "evaluation/num paths total           2456\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.71818\n",
      "evaluation/Rewards Std                  1.00379\n",
      "evaluation/Rewards Max                  6.77265\n",
      "evaluation/Rewards Min                 -1.53599\n",
      "evaluation/Returns Mean              4718.18\n",
      "evaluation/Returns Std                 98.7896\n",
      "evaluation/Returns Max               4909.83\n",
      "evaluation/Returns Min               4618.1\n",
      "evaluation/Estimation Bias Mean       656.876\n",
      "evaluation/Estimation Bias Std        145.019\n",
      "evaluation/EB/Q_True Mean              42.8686\n",
      "evaluation/EB/Q_True Std              132.458\n",
      "evaluation/EB/Q_Pred Mean             699.745\n",
      "evaluation/EB/Q_Pred Std               58.6952\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4718.18\n",
      "evaluation/Actions Mean                 0.0173474\n",
      "evaluation/Actions Std                  0.53849\n",
      "evaluation/Actions Max                  0.999517\n",
      "evaluation/Actions Min                 -0.999902\n",
      "time/backward_policy (s)                1.92665\n",
      "time/backward_zf1 (s)                   2.05198\n",
      "time/backward_zf2 (s)                   1.9838\n",
      "time/data sampling (s)                  0.309409\n",
      "time/data storing (s)                   0.0158258\n",
      "time/evaluation sampling (s)            1.66321\n",
      "time/exploration sampling (s)           0.333945\n",
      "time/logging (s)                        0.0123607\n",
      "time/preback_alpha (s)                  0.988171\n",
      "time/preback_policy (s)                 1.098\n",
      "time/preback_start (s)                  0.147988\n",
      "time/preback_zf (s)                     5.20837\n",
      "time/saving (s)                         0.00641894\n",
      "time/training (s)                       2.28469\n",
      "time/epoch (s)                         18.0308\n",
      "time/total (s)                       4314.66\n",
      "Epoch                                 240\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:04:31.178820 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 241 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 252000\n",
      "trainer/ZF1 Loss                        7.56665\n",
      "trainer/ZF2 Loss                        2.71692\n",
      "trainer/ZF Expert Reward               13.2809\n",
      "trainer/ZF Policy Reward                1.02653\n",
      "trainer/ZF CHI2 Term                   36.7446\n",
      "trainer/Policy Loss                  -575.951\n",
      "trainer/Bias Loss                      51.8022\n",
      "trainer/Bias Value                     14.6693\n",
      "trainer/Policy Grad Norm              150.357\n",
      "trainer/Policy Param Norm              37.2741\n",
      "trainer/Zf1 Grad Norm                1137.84\n",
      "trainer/Zf1 Param Norm                119.345\n",
      "trainer/Zf2 Grad Norm                1413.53\n",
      "trainer/Zf2 Param Norm                117.582\n",
      "trainer/Z Expert Predictions Mean     723.554\n",
      "trainer/Z Expert Predictions Std       49.2563\n",
      "trainer/Z Expert Predictions Max      795.218\n",
      "trainer/Z Expert Predictions Min      464.927\n",
      "trainer/Z Policy Predictions Mean     577.427\n",
      "trainer/Z Policy Predictions Std      308.38\n",
      "trainer/Z Policy Predictions Max      776.559\n",
      "trainer/Z Policy Predictions Min     -695.992\n",
      "trainer/Z Expert Targets Mean         710.273\n",
      "trainer/Z Expert Targets Std           51.7249\n",
      "trainer/Z Expert Targets Max          784.153\n",
      "trainer/Z Expert Targets Min          448.841\n",
      "trainer/Z Policy Targets Mean         576.4\n",
      "trainer/Z Policy Targets Std          305.044\n",
      "trainer/Z Policy Targets Max          768.028\n",
      "trainer/Z Policy Targets Min         -695.936\n",
      "trainer/Log Pis Mean                   19.5439\n",
      "trainer/Log Pis Std                     4.58849\n",
      "trainer/Policy mu Mean                  0.01374\n",
      "trainer/Policy mu Std                   0.996575\n",
      "trainer/Policy log std Mean            -3.19095\n",
      "trainer/Policy log std Std              0.980013\n",
      "trainer/Alpha                           0.155849\n",
      "trainer/Alpha Loss                      0.0710871\n",
      "exploration/num steps total        245988\n",
      "exploration/num paths total           348\n",
      "evaluation/num steps total              2.15831e+06\n",
      "evaluation/num paths total           2466\n",
      "evaluation/path length Mean           932.3\n",
      "evaluation/path length Std            203.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            323\n",
      "evaluation/Rewards Mean                 4.69488\n",
      "evaluation/Rewards Std                  0.988954\n",
      "evaluation/Rewards Max                  6.8731\n",
      "evaluation/Rewards Min                 -1.57251\n",
      "evaluation/Returns Mean              4377.04\n",
      "evaluation/Returns Std                981.885\n",
      "evaluation/Returns Max               4805.9\n",
      "evaluation/Returns Min               1436.85\n",
      "evaluation/Estimation Bias Mean       650.337\n",
      "evaluation/Estimation Bias Std        159.661\n",
      "evaluation/EB/Q_True Mean              47.258\n",
      "evaluation/EB/Q_True Std              139.92\n",
      "evaluation/EB/Q_Pred Mean             697.595\n",
      "evaluation/EB/Q_Pred Std               63.4095\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4377.04\n",
      "evaluation/Actions Mean                 0.0195454\n",
      "evaluation/Actions Std                  0.542189\n",
      "evaluation/Actions Max                  0.999687\n",
      "evaluation/Actions Min                 -0.999561\n",
      "time/backward_policy (s)                1.97654\n",
      "time/backward_zf1 (s)                   2.10915\n",
      "time/backward_zf2 (s)                   2.04609\n",
      "time/data sampling (s)                  0.299408\n",
      "time/data storing (s)                   0.0142117\n",
      "time/evaluation sampling (s)            1.73984\n",
      "time/exploration sampling (s)           0.318086\n",
      "time/logging (s)                        0.0112252\n",
      "time/preback_alpha (s)                  1.01883\n",
      "time/preback_policy (s)                 1.15051\n",
      "time/preback_start (s)                  0.148105\n",
      "time/preback_zf (s)                     5.2544\n",
      "time/saving (s)                         0.00597932\n",
      "time/training (s)                       2.29857\n",
      "time/epoch (s)                         18.3909\n",
      "time/total (s)                       4333.07\n",
      "Epoch                                 241\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:04:49.572511 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 242 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 253000\n",
      "trainer/ZF1 Loss                        7.28829\n",
      "trainer/ZF2 Loss                        8.91642\n",
      "trainer/ZF Expert Reward               17.577\n",
      "trainer/ZF Policy Reward                5.51904\n",
      "trainer/ZF CHI2 Term                   39.8296\n",
      "trainer/Policy Loss                  -582.193\n",
      "trainer/Bias Loss                      70.4217\n",
      "trainer/Bias Value                     14.6802\n",
      "trainer/Policy Grad Norm              133.1\n",
      "trainer/Policy Param Norm              37.2951\n",
      "trainer/Zf1 Grad Norm                1007.98\n",
      "trainer/Zf1 Param Norm                119.5\n",
      "trainer/Zf2 Grad Norm                 959.436\n",
      "trainer/Zf2 Param Norm                117.743\n",
      "trainer/Z Expert Predictions Mean     727.388\n",
      "trainer/Z Expert Predictions Std       44.8278\n",
      "trainer/Z Expert Predictions Max      794.496\n",
      "trainer/Z Expert Predictions Min      441.558\n",
      "trainer/Z Policy Predictions Mean     582.299\n",
      "trainer/Z Policy Predictions Std      303.429\n",
      "trainer/Z Policy Predictions Max      772.479\n",
      "trainer/Z Policy Predictions Min     -701.737\n",
      "trainer/Z Expert Targets Mean         709.811\n",
      "trainer/Z Expert Targets Std           46.943\n",
      "trainer/Z Expert Targets Max          788.986\n",
      "trainer/Z Expert Targets Min          424.548\n",
      "trainer/Z Policy Targets Mean         576.78\n",
      "trainer/Z Policy Targets Std          298.935\n",
      "trainer/Z Policy Targets Max          764.074\n",
      "trainer/Z Policy Targets Min         -692.523\n",
      "trainer/Log Pis Mean                   19.868\n",
      "trainer/Log Pis Std                     4.41157\n",
      "trainer/Policy mu Mean                  0.024166\n",
      "trainer/Policy mu Std                   0.99562\n",
      "trainer/Policy log std Mean            -3.21964\n",
      "trainer/Policy log std Std              0.95105\n",
      "trainer/Alpha                           0.156731\n",
      "trainer/Alpha Loss                      0.0206937\n",
      "exploration/num steps total        247443\n",
      "exploration/num paths total           350\n",
      "evaluation/num steps total              2.16831e+06\n",
      "evaluation/num paths total           2476\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6821\n",
      "evaluation/Rewards Std                  0.949482\n",
      "evaluation/Rewards Max                  6.83486\n",
      "evaluation/Rewards Min                 -1.68445\n",
      "evaluation/Returns Mean              4682.1\n",
      "evaluation/Returns Std                 87.1482\n",
      "evaluation/Returns Max               4853.24\n",
      "evaluation/Returns Min               4523.54\n",
      "evaluation/Estimation Bias Mean       655.784\n",
      "evaluation/Estimation Bias Std        137.939\n",
      "evaluation/EB/Q_True Mean              41.396\n",
      "evaluation/EB/Q_True Std              127.308\n",
      "evaluation/EB/Q_Pred Mean             697.18\n",
      "evaluation/EB/Q_Pred Std               55.4326\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4682.1\n",
      "evaluation/Actions Mean                 0.0232596\n",
      "evaluation/Actions Std                  0.538197\n",
      "evaluation/Actions Max                  0.999684\n",
      "evaluation/Actions Min                 -0.999673\n",
      "time/backward_policy (s)                1.98434\n",
      "time/backward_zf1 (s)                   2.10044\n",
      "time/backward_zf2 (s)                   2.04193\n",
      "time/data sampling (s)                  0.303489\n",
      "time/data storing (s)                   0.0142108\n",
      "time/evaluation sampling (s)            1.79121\n",
      "time/exploration sampling (s)           0.318475\n",
      "time/logging (s)                        0.0125155\n",
      "time/preback_alpha (s)                  1.01629\n",
      "time/preback_policy (s)                 1.15936\n",
      "time/preback_start (s)                  0.146103\n",
      "time/preback_zf (s)                     5.2105\n",
      "time/saving (s)                         0.00592395\n",
      "time/training (s)                       2.21861\n",
      "time/epoch (s)                         18.3234\n",
      "time/total (s)                       4351.42\n",
      "Epoch                                 242\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:05:07.829848 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 243 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 254000\n",
      "trainer/ZF1 Loss                       44.9939\n",
      "trainer/ZF2 Loss                       47.2903\n",
      "trainer/ZF Expert Reward               15.3158\n",
      "trainer/ZF Policy Reward                3.3208\n",
      "trainer/ZF CHI2 Term                   78.0101\n",
      "trainer/Policy Loss                  -609.908\n",
      "trainer/Bias Loss                      54.1419\n",
      "trainer/Bias Value                     14.6927\n",
      "trainer/Policy Grad Norm              147.209\n",
      "trainer/Policy Param Norm              37.3182\n",
      "trainer/Zf1 Grad Norm                1125.9\n",
      "trainer/Zf1 Param Norm                119.644\n",
      "trainer/Zf2 Grad Norm                1041.31\n",
      "trainer/Zf2 Param Norm                117.891\n",
      "trainer/Z Expert Predictions Mean     721.249\n",
      "trainer/Z Expert Predictions Std       38.3394\n",
      "trainer/Z Expert Predictions Max      798.609\n",
      "trainer/Z Expert Predictions Min      525.269\n",
      "trainer/Z Policy Predictions Mean     610.279\n",
      "trainer/Z Policy Predictions Std      249.316\n",
      "trainer/Z Policy Predictions Max      765.057\n",
      "trainer/Z Policy Predictions Min     -696.025\n",
      "trainer/Z Expert Targets Mean         705.934\n",
      "trainer/Z Expert Targets Std           39.4608\n",
      "trainer/Z Expert Targets Max          785.527\n",
      "trainer/Z Expert Targets Min          505.217\n",
      "trainer/Z Policy Targets Mean         606.958\n",
      "trainer/Z Policy Targets Std          240.258\n",
      "trainer/Z Policy Targets Max          765.908\n",
      "trainer/Z Policy Targets Min         -673.252\n",
      "trainer/Log Pis Mean                   20.0738\n",
      "trainer/Log Pis Std                     4.09199\n",
      "trainer/Policy mu Mean                  0.0536498\n",
      "trainer/Policy mu Std                   0.964479\n",
      "trainer/Policy log std Mean            -3.30433\n",
      "trainer/Policy log std Std              0.887517\n",
      "trainer/Alpha                           0.156148\n",
      "trainer/Alpha Loss                     -0.0115161\n",
      "exploration/num steps total        249443\n",
      "exploration/num paths total           352\n",
      "evaluation/num steps total              2.17741e+06\n",
      "evaluation/num paths total           2486\n",
      "evaluation/path length Mean           910\n",
      "evaluation/path length Std            270\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            100\n",
      "evaluation/Rewards Mean                 4.71838\n",
      "evaluation/Rewards Std                  1.04508\n",
      "evaluation/Rewards Max                  6.9265\n",
      "evaluation/Rewards Min                 -1.53397\n",
      "evaluation/Returns Mean              4293.73\n",
      "evaluation/Returns Std               1319.89\n",
      "evaluation/Returns Max               4805.49\n",
      "evaluation/Returns Min                337.6\n",
      "evaluation/Estimation Bias Mean       645.254\n",
      "evaluation/Estimation Bias Std        156.994\n",
      "evaluation/EB/Q_True Mean              47.2558\n",
      "evaluation/EB/Q_True Std              138.749\n",
      "evaluation/EB/Q_Pred Mean             692.51\n",
      "evaluation/EB/Q_Pred Std               67.8258\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4293.73\n",
      "evaluation/Actions Mean                 0.0182882\n",
      "evaluation/Actions Std                  0.539715\n",
      "evaluation/Actions Max                  0.999699\n",
      "evaluation/Actions Min                 -0.999525\n",
      "time/backward_policy (s)                1.96288\n",
      "time/backward_zf1 (s)                   2.11103\n",
      "time/backward_zf2 (s)                   2.02653\n",
      "time/data sampling (s)                  0.294649\n",
      "time/data storing (s)                   0.0150765\n",
      "time/evaluation sampling (s)            1.70935\n",
      "time/exploration sampling (s)           0.328401\n",
      "time/logging (s)                        0.0118342\n",
      "time/preback_alpha (s)                  1.02302\n",
      "time/preback_policy (s)                 1.13868\n",
      "time/preback_start (s)                  0.148796\n",
      "time/preback_zf (s)                     5.22729\n",
      "time/saving (s)                         0.00595075\n",
      "time/training (s)                       2.18255\n",
      "time/epoch (s)                         18.186\n",
      "time/total (s)                       4369.63\n",
      "Epoch                                 243\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:05:25.860888 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 244 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 255000\n",
      "trainer/ZF1 Loss                       11.8903\n",
      "trainer/ZF2 Loss                        7.55701\n",
      "trainer/ZF Expert Reward               17.1169\n",
      "trainer/ZF Policy Reward                4.05213\n",
      "trainer/ZF CHI2 Term                   42.2518\n",
      "trainer/Policy Loss                  -577.309\n",
      "trainer/Bias Loss                      65.9346\n",
      "trainer/Bias Value                     14.7053\n",
      "trainer/Policy Grad Norm              191.117\n",
      "trainer/Policy Param Norm              37.3381\n",
      "trainer/Zf1 Grad Norm                1245.43\n",
      "trainer/Zf1 Param Norm                119.803\n",
      "trainer/Zf2 Grad Norm                1197.49\n",
      "trainer/Zf2 Param Norm                118.049\n",
      "trainer/Z Expert Predictions Mean     719.356\n",
      "trainer/Z Expert Predictions Std       45.3591\n",
      "trainer/Z Expert Predictions Max      790.997\n",
      "trainer/Z Expert Predictions Min      452.852\n",
      "trainer/Z Policy Predictions Mean     579.502\n",
      "trainer/Z Policy Predictions Std      303.358\n",
      "trainer/Z Policy Predictions Max      770.909\n",
      "trainer/Z Policy Predictions Min     -680.246\n",
      "trainer/Z Expert Targets Mean         702.239\n",
      "trainer/Z Expert Targets Std           49.1812\n",
      "trainer/Z Expert Targets Max          786.417\n",
      "trainer/Z Expert Targets Min          408.706\n",
      "trainer/Z Policy Targets Mean         575.45\n",
      "trainer/Z Policy Targets Std          297.237\n",
      "trainer/Z Policy Targets Max          751.407\n",
      "trainer/Z Policy Targets Min         -665.567\n",
      "trainer/Log Pis Mean                   19.66\n",
      "trainer/Log Pis Std                     4.84301\n",
      "trainer/Policy mu Mean                  0.00981473\n",
      "trainer/Policy mu Std                   0.933893\n",
      "trainer/Policy log std Mean            -3.26181\n",
      "trainer/Policy log std Std              0.942218\n",
      "trainer/Alpha                           0.155895\n",
      "trainer/Alpha Loss                      0.0530021\n",
      "exploration/num steps total        250443\n",
      "exploration/num paths total           353\n",
      "evaluation/num steps total              2.18741e+06\n",
      "evaluation/num paths total           2496\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67613\n",
      "evaluation/Rewards Std                  0.949502\n",
      "evaluation/Rewards Max                  6.6264\n",
      "evaluation/Rewards Min                 -1.67759\n",
      "evaluation/Returns Mean              4676.13\n",
      "evaluation/Returns Std                 63.3751\n",
      "evaluation/Returns Max               4840.15\n",
      "evaluation/Returns Min               4606.91\n",
      "evaluation/Estimation Bias Mean       648.69\n",
      "evaluation/Estimation Bias Std        142.848\n",
      "evaluation/EB/Q_True Mean              42.4922\n",
      "evaluation/EB/Q_True Std              130.7\n",
      "evaluation/EB/Q_Pred Mean             691.182\n",
      "evaluation/EB/Q_Pred Std               57.6648\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4676.13\n",
      "evaluation/Actions Mean                 0.0228427\n",
      "evaluation/Actions Std                  0.534716\n",
      "evaluation/Actions Max                  0.999489\n",
      "evaluation/Actions Min                 -0.99922\n",
      "time/backward_policy (s)                1.89924\n",
      "time/backward_zf1 (s)                   2.02597\n",
      "time/backward_zf2 (s)                   1.95146\n",
      "time/data sampling (s)                  0.308719\n",
      "time/data storing (s)                   0.0145231\n",
      "time/evaluation sampling (s)            1.70415\n",
      "time/exploration sampling (s)           0.322206\n",
      "time/logging (s)                        0.0121367\n",
      "time/preback_alpha (s)                  0.997962\n",
      "time/preback_policy (s)                 1.11122\n",
      "time/preback_start (s)                  0.147286\n",
      "time/preback_zf (s)                     5.2001\n",
      "time/saving (s)                         0.0058735\n",
      "time/training (s)                       2.26087\n",
      "time/epoch (s)                         17.9617\n",
      "time/total (s)                       4387.61\n",
      "Epoch                                 244\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:05:43.906110 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 245 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 256000\n",
      "trainer/ZF1 Loss                       15.969\n",
      "trainer/ZF2 Loss                       16.1958\n",
      "trainer/ZF Expert Reward               11.9988\n",
      "trainer/ZF Policy Reward                1.23625\n",
      "trainer/ZF CHI2 Term                   46.878\n",
      "trainer/Policy Loss                  -604.319\n",
      "trainer/Bias Loss                      66.1436\n",
      "trainer/Bias Value                     14.7187\n",
      "trainer/Policy Grad Norm              191.164\n",
      "trainer/Policy Param Norm              37.3642\n",
      "trainer/Zf1 Grad Norm                1535.47\n",
      "trainer/Zf1 Param Norm                119.945\n",
      "trainer/Zf2 Grad Norm                1447.17\n",
      "trainer/Zf2 Param Norm                118.192\n",
      "trainer/Z Expert Predictions Mean     709.819\n",
      "trainer/Z Expert Predictions Std       48.8912\n",
      "trainer/Z Expert Predictions Max      795.227\n",
      "trainer/Z Expert Predictions Min      444.811\n",
      "trainer/Z Policy Predictions Mean     606.908\n",
      "trainer/Z Policy Predictions Std      239.713\n",
      "trainer/Z Policy Predictions Max      765.745\n",
      "trainer/Z Policy Predictions Min     -692.443\n",
      "trainer/Z Expert Targets Mean         697.82\n",
      "trainer/Z Expert Targets Std           50.7051\n",
      "trainer/Z Expert Targets Max          778.713\n",
      "trainer/Z Expert Targets Min          400.269\n",
      "trainer/Z Policy Targets Mean         605.671\n",
      "trainer/Z Policy Targets Std          234.724\n",
      "trainer/Z Policy Targets Max          758.711\n",
      "trainer/Z Policy Targets Min         -684.785\n",
      "trainer/Log Pis Mean                   20.2354\n",
      "trainer/Log Pis Std                     4.26149\n",
      "trainer/Policy mu Mean                  0.0412394\n",
      "trainer/Policy mu Std                   0.916219\n",
      "trainer/Policy log std Mean            -3.34232\n",
      "trainer/Policy log std Std              0.865279\n",
      "trainer/Alpha                           0.154338\n",
      "trainer/Alpha Loss                     -0.0363295\n",
      "exploration/num steps total        251443\n",
      "exploration/num paths total           354\n",
      "evaluation/num steps total              2.19741e+06\n",
      "evaluation/num paths total           2506\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69749\n",
      "evaluation/Rewards Std                  1.04394\n",
      "evaluation/Rewards Max                  6.86991\n",
      "evaluation/Rewards Min                 -2.30769\n",
      "evaluation/Returns Mean              4697.49\n",
      "evaluation/Returns Std                176.406\n",
      "evaluation/Returns Max               4865.32\n",
      "evaluation/Returns Min               4239.56\n",
      "evaluation/Estimation Bias Mean       637.775\n",
      "evaluation/Estimation Bias Std        146.573\n",
      "evaluation/EB/Q_True Mean              43.2411\n",
      "evaluation/EB/Q_True Std              133.056\n",
      "evaluation/EB/Q_Pred Mean             681.016\n",
      "evaluation/EB/Q_Pred Std               64.2807\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4697.49\n",
      "evaluation/Actions Mean                 0.0196513\n",
      "evaluation/Actions Std                  0.544207\n",
      "evaluation/Actions Max                  0.999754\n",
      "evaluation/Actions Min                 -0.999823\n",
      "time/backward_policy (s)                1.905\n",
      "time/backward_zf1 (s)                   2.04839\n",
      "time/backward_zf2 (s)                   1.97012\n",
      "time/data sampling (s)                  0.303271\n",
      "time/data storing (s)                   0.014839\n",
      "time/evaluation sampling (s)            1.71817\n",
      "time/exploration sampling (s)           0.322016\n",
      "time/logging (s)                        0.0132555\n",
      "time/preback_alpha (s)                  0.991333\n",
      "time/preback_policy (s)                 1.11481\n",
      "time/preback_start (s)                  0.145421\n",
      "time/preback_zf (s)                     5.18347\n",
      "time/saving (s)                         0.0254274\n",
      "time/training (s)                       2.22338\n",
      "time/epoch (s)                         17.9789\n",
      "time/total (s)                       4405.61\n",
      "Epoch                                 245\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:06:02.717531 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 246 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 257000\n",
      "trainer/ZF1 Loss                       98.7381\n",
      "trainer/ZF2 Loss                       82.9913\n",
      "trainer/ZF Expert Reward               12.5933\n",
      "trainer/ZF Policy Reward                3.63928\n",
      "trainer/ZF CHI2 Term                  119.978\n",
      "trainer/Policy Loss                  -575.417\n",
      "trainer/Bias Loss                      61.7631\n",
      "trainer/Bias Value                     14.7331\n",
      "trainer/Policy Grad Norm              131.447\n",
      "trainer/Policy Param Norm              37.3889\n",
      "trainer/Zf1 Grad Norm                2279.61\n",
      "trainer/Zf1 Param Norm                120.09\n",
      "trainer/Zf2 Grad Norm                1959.69\n",
      "trainer/Zf2 Param Norm                118.352\n",
      "trainer/Z Expert Predictions Mean     712.062\n",
      "trainer/Z Expert Predictions Std       41.733\n",
      "trainer/Z Expert Predictions Max      788.776\n",
      "trainer/Z Expert Predictions Min      460.057\n",
      "trainer/Z Policy Predictions Mean     572.698\n",
      "trainer/Z Policy Predictions Std      278.365\n",
      "trainer/Z Policy Predictions Max      772.758\n",
      "trainer/Z Policy Predictions Min     -753.049\n",
      "trainer/Z Expert Targets Mean         699.469\n",
      "trainer/Z Expert Targets Std           44.6495\n",
      "trainer/Z Expert Targets Max          775.141\n",
      "trainer/Z Expert Targets Min          440.946\n",
      "trainer/Z Policy Targets Mean         569.058\n",
      "trainer/Z Policy Targets Std          274.949\n",
      "trainer/Z Policy Targets Max          761.049\n",
      "trainer/Z Policy Targets Min         -729.639\n",
      "trainer/Log Pis Mean                   20.3632\n",
      "trainer/Log Pis Std                     4.26637\n",
      "trainer/Policy mu Mean                  0.0331716\n",
      "trainer/Policy mu Std                   1.00494\n",
      "trainer/Policy log std Mean            -3.27202\n",
      "trainer/Policy log std Std              0.950862\n",
      "trainer/Alpha                           0.155335\n",
      "trainer/Alpha Loss                     -0.0564083\n",
      "exploration/num steps total        253443\n",
      "exploration/num paths total           356\n",
      "evaluation/num steps total              2.20741e+06\n",
      "evaluation/num paths total           2516\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.76287\n",
      "evaluation/Rewards Std                  0.944013\n",
      "evaluation/Rewards Max                  7.15024\n",
      "evaluation/Rewards Min                 -1.64774\n",
      "evaluation/Returns Mean              4762.87\n",
      "evaluation/Returns Std                 76.1877\n",
      "evaluation/Returns Max               4895.43\n",
      "evaluation/Returns Min               4633.73\n",
      "evaluation/Estimation Bias Mean       644.839\n",
      "evaluation/Estimation Bias Std        144.64\n",
      "evaluation/EB/Q_True Mean              43.068\n",
      "evaluation/EB/Q_True Std              133.602\n",
      "evaluation/EB/Q_Pred Mean             687.907\n",
      "evaluation/EB/Q_Pred Std               55.191\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4762.87\n",
      "evaluation/Actions Mean                 0.0232922\n",
      "evaluation/Actions Std                  0.536403\n",
      "evaluation/Actions Max                  0.999267\n",
      "evaluation/Actions Min                 -0.999666\n",
      "time/backward_policy (s)                2.05418\n",
      "time/backward_zf1 (s)                   2.17091\n",
      "time/backward_zf2 (s)                   2.11497\n",
      "time/data sampling (s)                  0.309852\n",
      "time/data storing (s)                   0.0162958\n",
      "time/evaluation sampling (s)            1.78848\n",
      "time/exploration sampling (s)           0.342702\n",
      "time/logging (s)                        0.0122997\n",
      "time/preback_alpha (s)                  1.05604\n",
      "time/preback_policy (s)                 1.20092\n",
      "time/preback_start (s)                  0.151682\n",
      "time/preback_zf (s)                     5.2576\n",
      "time/saving (s)                         0.00652217\n",
      "time/training (s)                       2.2591\n",
      "time/epoch (s)                         18.7416\n",
      "time/total (s)                       4424.37\n",
      "Epoch                                 246\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:06:21.047533 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 247 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 258000\n",
      "trainer/ZF1 Loss                       14.2142\n",
      "trainer/ZF2 Loss                       13.3624\n",
      "trainer/ZF Expert Reward               13.9487\n",
      "trainer/ZF Policy Reward                4.82662\n",
      "trainer/ZF CHI2 Term                   42.6004\n",
      "trainer/Policy Loss                  -563.375\n",
      "trainer/Bias Loss                      55.9177\n",
      "trainer/Bias Value                     14.7441\n",
      "trainer/Policy Grad Norm              159.687\n",
      "trainer/Policy Param Norm              37.4108\n",
      "trainer/Zf1 Grad Norm                1286.8\n",
      "trainer/Zf1 Param Norm                120.245\n",
      "trainer/Zf2 Grad Norm                1281.01\n",
      "trainer/Zf2 Param Norm                118.53\n",
      "trainer/Z Expert Predictions Mean     709.824\n",
      "trainer/Z Expert Predictions Std       39.4653\n",
      "trainer/Z Expert Predictions Max      792.684\n",
      "trainer/Z Expert Predictions Min      554.3\n",
      "trainer/Z Policy Predictions Mean     565.11\n",
      "trainer/Z Policy Predictions Std      318.179\n",
      "trainer/Z Policy Predictions Max      757.798\n",
      "trainer/Z Policy Predictions Min     -734.421\n",
      "trainer/Z Expert Targets Mean         695.875\n",
      "trainer/Z Expert Targets Std           41.5794\n",
      "trainer/Z Expert Targets Max          765.974\n",
      "trainer/Z Expert Targets Min          487.673\n",
      "trainer/Z Policy Targets Mean         560.284\n",
      "trainer/Z Policy Targets Std          316.105\n",
      "trainer/Z Policy Targets Max          762.05\n",
      "trainer/Z Policy Targets Min         -695.451\n",
      "trainer/Log Pis Mean                   19.8889\n",
      "trainer/Log Pis Std                     4.59924\n",
      "trainer/Policy mu Mean                  0.0376541\n",
      "trainer/Policy mu Std                   0.986416\n",
      "trainer/Policy log std Mean            -3.26847\n",
      "trainer/Policy log std Std              0.976637\n",
      "trainer/Alpha                           0.155936\n",
      "trainer/Alpha Loss                      0.0173177\n",
      "exploration/num steps total        253443\n",
      "exploration/num paths total           356\n",
      "evaluation/num steps total              2.21741e+06\n",
      "evaluation/num paths total           2526\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62789\n",
      "evaluation/Rewards Std                  0.901492\n",
      "evaluation/Rewards Max                  6.92728\n",
      "evaluation/Rewards Min                 -1.59539\n",
      "evaluation/Returns Mean              4627.89\n",
      "evaluation/Returns Std                 54.3732\n",
      "evaluation/Returns Max               4711.97\n",
      "evaluation/Returns Min               4548.41\n",
      "evaluation/Estimation Bias Mean       645.141\n",
      "evaluation/Estimation Bias Std        136.179\n",
      "evaluation/EB/Q_True Mean              41.7374\n",
      "evaluation/EB/Q_True Std              128.605\n",
      "evaluation/EB/Q_Pred Mean             686.878\n",
      "evaluation/EB/Q_Pred Std               51.6259\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4627.89\n",
      "evaluation/Actions Mean                 0.0203145\n",
      "evaluation/Actions Std                  0.537032\n",
      "evaluation/Actions Max                  0.999479\n",
      "evaluation/Actions Min                 -0.999665\n",
      "time/backward_policy (s)                2.00908\n",
      "time/backward_zf1 (s)                   2.09915\n",
      "time/backward_zf2 (s)                   2.04844\n",
      "time/data sampling (s)                  0.302012\n",
      "time/data storing (s)                   0.0147156\n",
      "time/evaluation sampling (s)            1.76503\n",
      "time/exploration sampling (s)           0.316947\n",
      "time/logging (s)                        0.0118957\n",
      "time/preback_alpha (s)                  1.04281\n",
      "time/preback_policy (s)                 1.17712\n",
      "time/preback_start (s)                  0.145267\n",
      "time/preback_zf (s)                     5.18823\n",
      "time/saving (s)                         0.00621076\n",
      "time/training (s)                       2.1288\n",
      "time/epoch (s)                         18.2557\n",
      "time/total (s)                       4442.65\n",
      "Epoch                                 247\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:06:39.350939 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 248 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 259000\n",
      "trainer/ZF1 Loss                       15.3848\n",
      "trainer/ZF2 Loss                       13.6748\n",
      "trainer/ZF Expert Reward               18.3048\n",
      "trainer/ZF Policy Reward                3.37759\n",
      "trainer/ZF CHI2 Term                   49.7003\n",
      "trainer/Policy Loss                  -609.117\n",
      "trainer/Bias Loss                      67.0465\n",
      "trainer/Bias Value                     14.7576\n",
      "trainer/Policy Grad Norm              145.167\n",
      "trainer/Policy Param Norm              37.4377\n",
      "trainer/Zf1 Grad Norm                1377.87\n",
      "trainer/Zf1 Param Norm                120.4\n",
      "trainer/Zf2 Grad Norm                1384.45\n",
      "trainer/Zf2 Param Norm                118.674\n",
      "trainer/Z Expert Predictions Mean     705.24\n",
      "trainer/Z Expert Predictions Std       51.8997\n",
      "trainer/Z Expert Predictions Max      787.083\n",
      "trainer/Z Expert Predictions Min      459.905\n",
      "trainer/Z Policy Predictions Mean     609.721\n",
      "trainer/Z Policy Predictions Std      223.897\n",
      "trainer/Z Policy Predictions Max      768.856\n",
      "trainer/Z Policy Predictions Min     -742.559\n",
      "trainer/Z Expert Targets Mean         686.935\n",
      "trainer/Z Expert Targets Std           55.3951\n",
      "trainer/Z Expert Targets Max          767.376\n",
      "trainer/Z Expert Targets Min          438.384\n",
      "trainer/Z Policy Targets Mean         606.344\n",
      "trainer/Z Policy Targets Std          218.776\n",
      "trainer/Z Policy Targets Max          745.709\n",
      "trainer/Z Policy Targets Min         -763.848\n",
      "trainer/Log Pis Mean                   20.4478\n",
      "trainer/Log Pis Std                     3.71864\n",
      "trainer/Policy mu Mean                  0.0206379\n",
      "trainer/Policy mu Std                   0.940374\n",
      "trainer/Policy log std Mean            -3.37183\n",
      "trainer/Policy log std Std              0.826275\n",
      "trainer/Alpha                           0.156815\n",
      "trainer/Alpha Loss                     -0.070218\n",
      "exploration/num steps total        253443\n",
      "exploration/num paths total           356\n",
      "evaluation/num steps total              2.22741e+06\n",
      "evaluation/num paths total           2536\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62621\n",
      "evaluation/Rewards Std                  0.923463\n",
      "evaluation/Rewards Max                  6.85214\n",
      "evaluation/Rewards Min                 -1.65246\n",
      "evaluation/Returns Mean              4626.21\n",
      "evaluation/Returns Std                 66.0398\n",
      "evaluation/Returns Max               4765.32\n",
      "evaluation/Returns Min               4509.75\n",
      "evaluation/Estimation Bias Mean       632.625\n",
      "evaluation/Estimation Bias Std        142.745\n",
      "evaluation/EB/Q_True Mean              42.4066\n",
      "evaluation/EB/Q_True Std              130.895\n",
      "evaluation/EB/Q_Pred Mean             675.031\n",
      "evaluation/EB/Q_Pred Std               59.1313\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4626.21\n",
      "evaluation/Actions Mean                 0.0230366\n",
      "evaluation/Actions Std                  0.535197\n",
      "evaluation/Actions Max                  0.99975\n",
      "evaluation/Actions Min                 -0.999636\n",
      "time/backward_policy (s)                1.94632\n",
      "time/backward_zf1 (s)                   2.10725\n",
      "time/backward_zf2 (s)                   2.03114\n",
      "time/data sampling (s)                  0.285592\n",
      "time/data storing (s)                   0.0147524\n",
      "time/evaluation sampling (s)            1.75779\n",
      "time/exploration sampling (s)           0.320042\n",
      "time/logging (s)                        0.0148638\n",
      "time/preback_alpha (s)                  1.03578\n",
      "time/preback_policy (s)                 1.15969\n",
      "time/preback_start (s)                  0.148682\n",
      "time/preback_zf (s)                     5.23\n",
      "time/saving (s)                         0.00566124\n",
      "time/training (s)                       2.168\n",
      "time/epoch (s)                         18.2256\n",
      "time/total (s)                       4460.9\n",
      "Epoch                                 248\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:06:57.663743 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 249 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 260000\n",
      "trainer/ZF1 Loss                       20.4969\n",
      "trainer/ZF2 Loss                       17.4668\n",
      "trainer/ZF Expert Reward               12.2481\n",
      "trainer/ZF Policy Reward                1.30145\n",
      "trainer/ZF CHI2 Term                   50.0123\n",
      "trainer/Policy Loss                  -579.726\n",
      "trainer/Bias Loss                      84.8346\n",
      "trainer/Bias Value                     14.7731\n",
      "trainer/Policy Grad Norm              148.921\n",
      "trainer/Policy Param Norm              37.461\n",
      "trainer/Zf1 Grad Norm                1474.18\n",
      "trainer/Zf1 Param Norm                120.532\n",
      "trainer/Zf2 Grad Norm                1629.68\n",
      "trainer/Zf2 Param Norm                118.808\n",
      "trainer/Z Expert Predictions Mean     698.46\n",
      "trainer/Z Expert Predictions Std       50.3726\n",
      "trainer/Z Expert Predictions Max      763.23\n",
      "trainer/Z Expert Predictions Min      392.196\n",
      "trainer/Z Policy Predictions Mean     580.991\n",
      "trainer/Z Policy Predictions Std      274.791\n",
      "trainer/Z Policy Predictions Max      751.361\n",
      "trainer/Z Policy Predictions Min     -760.864\n",
      "trainer/Z Expert Targets Mean         686.212\n",
      "trainer/Z Expert Targets Std           53.4073\n",
      "trainer/Z Expert Targets Max          754.421\n",
      "trainer/Z Expert Targets Min          372.346\n",
      "trainer/Z Policy Targets Mean         579.689\n",
      "trainer/Z Policy Targets Std          271.814\n",
      "trainer/Z Policy Targets Max          760.15\n",
      "trainer/Z Policy Targets Min         -738.816\n",
      "trainer/Log Pis Mean                   20.2866\n",
      "trainer/Log Pis Std                     4.15632\n",
      "trainer/Policy mu Mean                  0.0493863\n",
      "trainer/Policy mu Std                   0.911381\n",
      "trainer/Policy log std Mean            -3.3774\n",
      "trainer/Policy log std Std              0.884894\n",
      "trainer/Alpha                           0.157241\n",
      "trainer/Alpha Loss                     -0.0450627\n",
      "exploration/num steps total        254443\n",
      "exploration/num paths total           357\n",
      "evaluation/num steps total              2.23741e+06\n",
      "evaluation/num paths total           2546\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65615\n",
      "evaluation/Rewards Std                  0.954875\n",
      "evaluation/Rewards Max                  6.73497\n",
      "evaluation/Rewards Min                 -1.84956\n",
      "evaluation/Returns Mean              4656.15\n",
      "evaluation/Returns Std                 87.1962\n",
      "evaluation/Returns Max               4730.88\n",
      "evaluation/Returns Min               4464.6\n",
      "evaluation/Estimation Bias Mean       636.544\n",
      "evaluation/Estimation Bias Std        147.383\n",
      "evaluation/EB/Q_True Mean              41.8102\n",
      "evaluation/EB/Q_True Std              128.774\n",
      "evaluation/EB/Q_Pred Mean             678.354\n",
      "evaluation/EB/Q_Pred Std               58.3245\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4656.15\n",
      "evaluation/Actions Mean                 0.0229881\n",
      "evaluation/Actions Std                  0.54055\n",
      "evaluation/Actions Max                  0.99977\n",
      "evaluation/Actions Min                 -0.999774\n",
      "time/backward_policy (s)                1.98829\n",
      "time/backward_zf1 (s)                   2.11855\n",
      "time/backward_zf2 (s)                   2.05455\n",
      "time/data sampling (s)                  0.284327\n",
      "time/data storing (s)                   0.0158649\n",
      "time/evaluation sampling (s)            1.75168\n",
      "time/exploration sampling (s)           0.323862\n",
      "time/logging (s)                        0.0125455\n",
      "time/preback_alpha (s)                  1.04069\n",
      "time/preback_policy (s)                 1.17168\n",
      "time/preback_start (s)                  0.149255\n",
      "time/preback_zf (s)                     5.21117\n",
      "time/saving (s)                         0.00550417\n",
      "time/training (s)                       2.11295\n",
      "time/epoch (s)                         18.2409\n",
      "time/total (s)                       4479.16\n",
      "Epoch                                 249\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:07:15.637232 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 250 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 261000\n",
      "trainer/ZF1 Loss                      115.238\n",
      "trainer/ZF2 Loss                      108.946\n",
      "trainer/ZF Expert Reward               14.4591\n",
      "trainer/ZF Policy Reward                6.03698\n",
      "trainer/ZF CHI2 Term                  140.421\n",
      "trainer/Policy Loss                  -570.418\n",
      "trainer/Bias Loss                      51.1375\n",
      "trainer/Bias Value                     14.7846\n",
      "trainer/Policy Grad Norm              174.632\n",
      "trainer/Policy Param Norm              37.4861\n",
      "trainer/Zf1 Grad Norm                1578.85\n",
      "trainer/Zf1 Param Norm                120.661\n",
      "trainer/Zf2 Grad Norm                1411.84\n",
      "trainer/Zf2 Param Norm                118.946\n",
      "trainer/Z Expert Predictions Mean     698.042\n",
      "trainer/Z Expert Predictions Std       44.7563\n",
      "trainer/Z Expert Predictions Max      769.145\n",
      "trainer/Z Expert Predictions Min      460.077\n",
      "trainer/Z Policy Predictions Mean     573.282\n",
      "trainer/Z Policy Predictions Std      269.316\n",
      "trainer/Z Policy Predictions Max      749.229\n",
      "trainer/Z Policy Predictions Min     -766.597\n",
      "trainer/Z Expert Targets Mean         683.583\n",
      "trainer/Z Expert Targets Std           46.5353\n",
      "trainer/Z Expert Targets Max          751.112\n",
      "trainer/Z Expert Targets Min          422.673\n",
      "trainer/Z Policy Targets Mean         567.245\n",
      "trainer/Z Policy Targets Std          266.446\n",
      "trainer/Z Policy Targets Max          774.784\n",
      "trainer/Z Policy Targets Min         -764.401\n",
      "trainer/Log Pis Mean                   20.1077\n",
      "trainer/Log Pis Std                     4.44797\n",
      "trainer/Policy mu Mean                  0.0237268\n",
      "trainer/Policy mu Std                   0.987877\n",
      "trainer/Policy log std Mean            -3.24877\n",
      "trainer/Policy log std Std              0.913426\n",
      "trainer/Alpha                           0.159316\n",
      "trainer/Alpha Loss                     -0.0171586\n",
      "exploration/num steps total        255443\n",
      "exploration/num paths total           358\n",
      "evaluation/num steps total              2.24645e+06\n",
      "evaluation/num paths total           2556\n",
      "evaluation/path length Mean           903.6\n",
      "evaluation/path length Std            289.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             36\n",
      "evaluation/Rewards Mean                 4.6531\n",
      "evaluation/Rewards Std                  1.15292\n",
      "evaluation/Rewards Max                  6.69325\n",
      "evaluation/Rewards Min                 -3.13524\n",
      "evaluation/Returns Mean              4204.54\n",
      "evaluation/Returns Std               1381.71\n",
      "evaluation/Returns Max               4796.36\n",
      "evaluation/Returns Min                 80.421\n",
      "evaluation/Estimation Bias Mean       619.692\n",
      "evaluation/Estimation Bias Std        161.633\n",
      "evaluation/EB/Q_True Mean              47.906\n",
      "evaluation/EB/Q_True Std              139.133\n",
      "evaluation/EB/Q_Pred Mean             667.598\n",
      "evaluation/EB/Q_Pred Std               78.6375\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4204.54\n",
      "evaluation/Actions Mean                 0.0211254\n",
      "evaluation/Actions Std                  0.54414\n",
      "evaluation/Actions Max                  0.999713\n",
      "evaluation/Actions Min                 -0.999773\n",
      "time/backward_policy (s)                1.87404\n",
      "time/backward_zf1 (s)                   1.99038\n",
      "time/backward_zf2 (s)                   1.91764\n",
      "time/data sampling (s)                  0.293419\n",
      "time/data storing (s)                   0.0155421\n",
      "time/evaluation sampling (s)            1.73053\n",
      "time/exploration sampling (s)           0.323674\n",
      "time/logging (s)                        0.0110789\n",
      "time/preback_alpha (s)                  0.966612\n",
      "time/preback_policy (s)                 1.06401\n",
      "time/preback_start (s)                  0.148705\n",
      "time/preback_zf (s)                     5.22107\n",
      "time/saving (s)                         0.00598361\n",
      "time/training (s)                       2.34153\n",
      "time/epoch (s)                         17.9042\n",
      "time/total (s)                       4497.09\n",
      "Epoch                                 250\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:07:33.626170 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 251 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 262000\n",
      "trainer/ZF1 Loss                       95.7441\n",
      "trainer/ZF2 Loss                       94.4364\n",
      "trainer/ZF Expert Reward               16.467\n",
      "trainer/ZF Policy Reward                6.71266\n",
      "trainer/ZF CHI2 Term                  124.772\n",
      "trainer/Policy Loss                  -596.657\n",
      "trainer/Bias Loss                      56.5918\n",
      "trainer/Bias Value                     14.7954\n",
      "trainer/Policy Grad Norm              177.841\n",
      "trainer/Policy Param Norm              37.5109\n",
      "trainer/Zf1 Grad Norm                1921.34\n",
      "trainer/Zf1 Param Norm                120.796\n",
      "trainer/Zf2 Grad Norm                1627.22\n",
      "trainer/Zf2 Param Norm                119.084\n",
      "trainer/Z Expert Predictions Mean     703.501\n",
      "trainer/Z Expert Predictions Std       44.7594\n",
      "trainer/Z Expert Predictions Max      779.228\n",
      "trainer/Z Expert Predictions Min      498.666\n",
      "trainer/Z Policy Predictions Mean     599.049\n",
      "trainer/Z Policy Predictions Std      237.534\n",
      "trainer/Z Policy Predictions Max      744.25\n",
      "trainer/Z Policy Predictions Min     -789.247\n",
      "trainer/Z Expert Targets Mean         687.034\n",
      "trainer/Z Expert Targets Std           47.091\n",
      "trainer/Z Expert Targets Max          759.349\n",
      "trainer/Z Expert Targets Min          477.65\n",
      "trainer/Z Policy Targets Mean         592.336\n",
      "trainer/Z Policy Targets Std          235.685\n",
      "trainer/Z Policy Targets Max          735.413\n",
      "trainer/Z Policy Targets Min         -752.589\n",
      "trainer/Log Pis Mean                   20.129\n",
      "trainer/Log Pis Std                     4.25841\n",
      "trainer/Policy mu Mean                  0.0551876\n",
      "trainer/Policy mu Std                   0.946103\n",
      "trainer/Policy log std Mean            -3.32318\n",
      "trainer/Policy log std Std              0.864137\n",
      "trainer/Alpha                           0.159789\n",
      "trainer/Alpha Loss                     -0.0206124\n",
      "exploration/num steps total        255443\n",
      "exploration/num paths total           358\n",
      "evaluation/num steps total              2.25645e+06\n",
      "evaluation/num paths total           2566\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69714\n",
      "evaluation/Rewards Std                  1.00639\n",
      "evaluation/Rewards Max                  7.01258\n",
      "evaluation/Rewards Min                 -1.817\n",
      "evaluation/Returns Mean              4697.14\n",
      "evaluation/Returns Std                120.573\n",
      "evaluation/Returns Max               4899.34\n",
      "evaluation/Returns Min               4438.8\n",
      "evaluation/Estimation Bias Mean       622.903\n",
      "evaluation/Estimation Bias Std        136.796\n",
      "evaluation/EB/Q_True Mean              40.8034\n",
      "evaluation/EB/Q_True Std              126.033\n",
      "evaluation/EB/Q_Pred Mean             663.707\n",
      "evaluation/EB/Q_Pred Std               64.5287\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4697.14\n",
      "evaluation/Actions Mean                 0.0186606\n",
      "evaluation/Actions Std                  0.541759\n",
      "evaluation/Actions Max                  0.999719\n",
      "evaluation/Actions Min                 -0.999781\n",
      "time/backward_policy (s)                1.88587\n",
      "time/backward_zf1 (s)                   2.00356\n",
      "time/backward_zf2 (s)                   1.94336\n",
      "time/data sampling (s)                  0.313596\n",
      "time/data storing (s)                   0.0147866\n",
      "time/evaluation sampling (s)            1.76924\n",
      "time/exploration sampling (s)           0.317782\n",
      "time/logging (s)                        0.0129605\n",
      "time/preback_alpha (s)                  0.994162\n",
      "time/preback_policy (s)                 1.11704\n",
      "time/preback_start (s)                  0.145634\n",
      "time/preback_zf (s)                     5.21238\n",
      "time/saving (s)                         0.00610476\n",
      "time/training (s)                       2.18616\n",
      "time/epoch (s)                         17.9226\n",
      "time/total (s)                       4515.03\n",
      "Epoch                                 251\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:07:52.356086 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 252 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 263000\n",
      "trainer/ZF1 Loss                       10.3748\n",
      "trainer/ZF2 Loss                        6.93649\n",
      "trainer/ZF Expert Reward               12.1786\n",
      "trainer/ZF Policy Reward               -0.832541\n",
      "trainer/ZF CHI2 Term                   41.5863\n",
      "trainer/Policy Loss                  -583.023\n",
      "trainer/Bias Loss                      58.6559\n",
      "trainer/Bias Value                     14.8079\n",
      "trainer/Policy Grad Norm              196.569\n",
      "trainer/Policy Param Norm              37.5359\n",
      "trainer/Zf1 Grad Norm                1666.46\n",
      "trainer/Zf1 Param Norm                120.932\n",
      "trainer/Zf2 Grad Norm                1207.73\n",
      "trainer/Zf2 Param Norm                119.224\n",
      "trainer/Z Expert Predictions Mean     691.549\n",
      "trainer/Z Expert Predictions Std       61.8751\n",
      "trainer/Z Expert Predictions Max      759.11\n",
      "trainer/Z Expert Predictions Min        7.79401\n",
      "trainer/Z Policy Predictions Mean     582.426\n",
      "trainer/Z Policy Predictions Std      239.156\n",
      "trainer/Z Policy Predictions Max      747.431\n",
      "trainer/Z Policy Predictions Min     -747.096\n",
      "trainer/Z Expert Targets Mean         679.371\n",
      "trainer/Z Expert Targets Std           63.083\n",
      "trainer/Z Expert Targets Max          756.539\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         583.259\n",
      "trainer/Z Policy Targets Std          234.003\n",
      "trainer/Z Policy Targets Max          740.883\n",
      "trainer/Z Policy Targets Min         -753.11\n",
      "trainer/Log Pis Mean                   20.1208\n",
      "trainer/Log Pis Std                     3.95845\n",
      "trainer/Policy mu Mean                  0.0248639\n",
      "trainer/Policy mu Std                   0.947355\n",
      "trainer/Policy log std Mean            -3.33197\n",
      "trainer/Policy log std Std              0.853741\n",
      "trainer/Alpha                           0.160456\n",
      "trainer/Alpha Loss                     -0.019384\n",
      "exploration/num steps total        257443\n",
      "exploration/num paths total           360\n",
      "evaluation/num steps total              2.26645e+06\n",
      "evaluation/num paths total           2576\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62132\n",
      "evaluation/Rewards Std                  0.930515\n",
      "evaluation/Rewards Max                  6.64549\n",
      "evaluation/Rewards Min                 -1.99867\n",
      "evaluation/Returns Mean              4621.32\n",
      "evaluation/Returns Std                 69.7571\n",
      "evaluation/Returns Max               4777.68\n",
      "evaluation/Returns Min               4526.61\n",
      "evaluation/Estimation Bias Mean       631.884\n",
      "evaluation/Estimation Bias Std        140.076\n",
      "evaluation/EB/Q_True Mean              42.5673\n",
      "evaluation/EB/Q_True Std              131.055\n",
      "evaluation/EB/Q_Pred Mean             674.452\n",
      "evaluation/EB/Q_Pred Std               54.6641\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4621.32\n",
      "evaluation/Actions Mean                 0.017981\n",
      "evaluation/Actions Std                  0.532146\n",
      "evaluation/Actions Max                  0.998799\n",
      "evaluation/Actions Min                 -0.999754\n",
      "time/backward_policy (s)                2.04209\n",
      "time/backward_zf1 (s)                   2.17139\n",
      "time/backward_zf2 (s)                   2.11057\n",
      "time/data sampling (s)                  0.30789\n",
      "time/data storing (s)                   0.0149477\n",
      "time/evaluation sampling (s)            1.77243\n",
      "time/exploration sampling (s)           0.327647\n",
      "time/logging (s)                        0.0143916\n",
      "time/preback_alpha (s)                  1.05287\n",
      "time/preback_policy (s)                 1.18769\n",
      "time/preback_start (s)                  0.149965\n",
      "time/preback_zf (s)                     5.28485\n",
      "time/saving (s)                         0.00610105\n",
      "time/training (s)                       2.21904\n",
      "time/epoch (s)                         18.6619\n",
      "time/total (s)                       4533.71\n",
      "Epoch                                 252\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:08:10.105763 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 253 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 264000\n",
      "trainer/ZF1 Loss                       84.6628\n",
      "trainer/ZF2 Loss                       73.7031\n",
      "trainer/ZF Expert Reward               16.4651\n",
      "trainer/ZF Policy Reward                3.1365\n",
      "trainer/ZF CHI2 Term                  112.258\n",
      "trainer/Policy Loss                  -574.794\n",
      "trainer/Bias Loss                      66.436\n",
      "trainer/Bias Value                     14.8213\n",
      "trainer/Policy Grad Norm              195.88\n",
      "trainer/Policy Param Norm              37.5594\n",
      "trainer/Zf1 Grad Norm                1805.73\n",
      "trainer/Zf1 Param Norm                121.07\n",
      "trainer/Zf2 Grad Norm                1753.79\n",
      "trainer/Zf2 Param Norm                119.346\n",
      "trainer/Z Expert Predictions Mean     689.496\n",
      "trainer/Z Expert Predictions Std       61.0031\n",
      "trainer/Z Expert Predictions Max      762.329\n",
      "trainer/Z Expert Predictions Min       -4.02176\n",
      "trainer/Z Policy Predictions Mean     573.868\n",
      "trainer/Z Policy Predictions Std      273.477\n",
      "trainer/Z Policy Predictions Max      745.754\n",
      "trainer/Z Policy Predictions Min     -772.591\n",
      "trainer/Z Expert Targets Mean         673.031\n",
      "trainer/Z Expert Targets Std           63.7445\n",
      "trainer/Z Expert Targets Max          761.676\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         570.732\n",
      "trainer/Z Policy Targets Std          274.973\n",
      "trainer/Z Policy Targets Max          731.103\n",
      "trainer/Z Policy Targets Min         -759.546\n",
      "trainer/Log Pis Mean                   19.9457\n",
      "trainer/Log Pis Std                     4.57355\n",
      "trainer/Policy mu Mean                  0.0380394\n",
      "trainer/Policy mu Std                   0.886287\n",
      "trainer/Policy log std Mean            -3.34149\n",
      "trainer/Policy log std Std              0.876462\n",
      "trainer/Alpha                           0.15945\n",
      "trainer/Alpha Loss                      0.0086616\n",
      "exploration/num steps total        259443\n",
      "exploration/num paths total           362\n",
      "evaluation/num steps total              2.27645e+06\n",
      "evaluation/num paths total           2586\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65562\n",
      "evaluation/Rewards Std                  0.96048\n",
      "evaluation/Rewards Max                  6.64953\n",
      "evaluation/Rewards Min                 -1.94978\n",
      "evaluation/Returns Mean              4655.62\n",
      "evaluation/Returns Std                118.198\n",
      "evaluation/Returns Max               4843.34\n",
      "evaluation/Returns Min               4416.73\n",
      "evaluation/Estimation Bias Mean       623.375\n",
      "evaluation/Estimation Bias Std        139.658\n",
      "evaluation/EB/Q_True Mean              42.5015\n",
      "evaluation/EB/Q_True Std              131.217\n",
      "evaluation/EB/Q_Pred Mean             665.876\n",
      "evaluation/EB/Q_Pred Std               57.5789\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4655.62\n",
      "evaluation/Actions Mean                 0.024543\n",
      "evaluation/Actions Std                  0.532549\n",
      "evaluation/Actions Max                  0.99957\n",
      "evaluation/Actions Min                 -0.999782\n",
      "time/backward_policy (s)                1.80255\n",
      "time/backward_zf1 (s)                   1.95886\n",
      "time/backward_zf2 (s)                   1.85963\n",
      "time/data sampling (s)                  0.294366\n",
      "time/data storing (s)                   0.0145518\n",
      "time/evaluation sampling (s)            1.74458\n",
      "time/exploration sampling (s)           0.320087\n",
      "time/logging (s)                        0.0124429\n",
      "time/preback_alpha (s)                  0.923936\n",
      "time/preback_policy (s)                 1.00949\n",
      "time/preback_start (s)                  0.146294\n",
      "time/preback_zf (s)                     5.15932\n",
      "time/saving (s)                         0.00799543\n",
      "time/training (s)                       2.42456\n",
      "time/epoch (s)                         17.6787\n",
      "time/total (s)                       4551.41\n",
      "Epoch                                 253\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:08:28.417421 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 254 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 265000\n",
      "trainer/ZF1 Loss                        7.78218\n",
      "trainer/ZF2 Loss                        9.49732\n",
      "trainer/ZF Expert Reward               13.839\n",
      "trainer/ZF Policy Reward                3.78485\n",
      "trainer/ZF CHI2 Term                   38.6788\n",
      "trainer/Policy Loss                  -576.052\n",
      "trainer/Bias Loss                      64.4188\n",
      "trainer/Bias Value                     14.8343\n",
      "trainer/Policy Grad Norm              185.85\n",
      "trainer/Policy Param Norm              37.5854\n",
      "trainer/Zf1 Grad Norm                1324.35\n",
      "trainer/Zf1 Param Norm                121.211\n",
      "trainer/Zf2 Grad Norm                1483.35\n",
      "trainer/Zf2 Param Norm                119.499\n",
      "trainer/Z Expert Predictions Mean     684.424\n",
      "trainer/Z Expert Predictions Std       56.3677\n",
      "trainer/Z Expert Predictions Max      774.125\n",
      "trainer/Z Expert Predictions Min      383.452\n",
      "trainer/Z Policy Predictions Mean     578.407\n",
      "trainer/Z Policy Predictions Std      255.183\n",
      "trainer/Z Policy Predictions Max      740.024\n",
      "trainer/Z Policy Predictions Min     -792.755\n",
      "trainer/Z Expert Targets Mean         670.585\n",
      "trainer/Z Expert Targets Std           60.0288\n",
      "trainer/Z Expert Targets Max          757.459\n",
      "trainer/Z Expert Targets Min          331.387\n",
      "trainer/Z Policy Targets Mean         574.622\n",
      "trainer/Z Policy Targets Std          253.92\n",
      "trainer/Z Policy Targets Max          731.308\n",
      "trainer/Z Policy Targets Min         -800.141\n",
      "trainer/Log Pis Mean                   20.1868\n",
      "trainer/Log Pis Std                     4.1167\n",
      "trainer/Policy mu Mean                  0.0278193\n",
      "trainer/Policy mu Std                   0.913876\n",
      "trainer/Policy log std Mean            -3.33999\n",
      "trainer/Policy log std Std              0.842604\n",
      "trainer/Alpha                           0.160173\n",
      "trainer/Alpha Loss                     -0.0299163\n",
      "exploration/num steps total        260443\n",
      "exploration/num paths total           363\n",
      "evaluation/num steps total              2.28645e+06\n",
      "evaluation/num paths total           2596\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63146\n",
      "evaluation/Rewards Std                  0.91044\n",
      "evaluation/Rewards Max                  6.61782\n",
      "evaluation/Rewards Min                 -1.74447\n",
      "evaluation/Returns Mean              4631.46\n",
      "evaluation/Returns Std                 87.2604\n",
      "evaluation/Returns Max               4828.46\n",
      "evaluation/Returns Min               4505.13\n",
      "evaluation/Estimation Bias Mean       623.874\n",
      "evaluation/Estimation Bias Std        136.178\n",
      "evaluation/EB/Q_True Mean              41.8711\n",
      "evaluation/EB/Q_True Std              128.694\n",
      "evaluation/EB/Q_Pred Mean             665.745\n",
      "evaluation/EB/Q_Pred Std               52.3683\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4631.46\n",
      "evaluation/Actions Mean                 0.0170996\n",
      "evaluation/Actions Std                  0.531557\n",
      "evaluation/Actions Max                  0.999507\n",
      "evaluation/Actions Min                 -0.999867\n",
      "time/backward_policy (s)                1.94652\n",
      "time/backward_zf1 (s)                   2.0923\n",
      "time/backward_zf2 (s)                   2.0052\n",
      "time/data sampling (s)                  0.300483\n",
      "time/data storing (s)                   0.0152886\n",
      "time/evaluation sampling (s)            1.74831\n",
      "time/exploration sampling (s)           0.322878\n",
      "time/logging (s)                        0.0120834\n",
      "time/preback_alpha (s)                  1.02852\n",
      "time/preback_policy (s)                 1.16379\n",
      "time/preback_start (s)                  0.149822\n",
      "time/preback_zf (s)                     5.2602\n",
      "time/saving (s)                         0.00792292\n",
      "time/training (s)                       2.18898\n",
      "time/epoch (s)                         18.2423\n",
      "time/total (s)                       4569.67\n",
      "Epoch                                 254\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:08:46.891572 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 255 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 266000\n",
      "trainer/ZF1 Loss                       17.6324\n",
      "trainer/ZF2 Loss                       14.2897\n",
      "trainer/ZF Expert Reward               14.0688\n",
      "trainer/ZF Policy Reward                1.90562\n",
      "trainer/ZF CHI2 Term                   48.2442\n",
      "trainer/Policy Loss                  -551.809\n",
      "trainer/Bias Loss                      89.5203\n",
      "trainer/Bias Value                     14.8464\n",
      "trainer/Policy Grad Norm              153.793\n",
      "trainer/Policy Param Norm              37.6128\n",
      "trainer/Zf1 Grad Norm                1427.77\n",
      "trainer/Zf1 Param Norm                121.336\n",
      "trainer/Zf2 Grad Norm                1442.32\n",
      "trainer/Zf2 Param Norm                119.638\n",
      "trainer/Z Expert Predictions Mean     687.571\n",
      "trainer/Z Expert Predictions Std       41.643\n",
      "trainer/Z Expert Predictions Max      765.774\n",
      "trainer/Z Expert Predictions Min      447.454\n",
      "trainer/Z Policy Predictions Mean     549.876\n",
      "trainer/Z Policy Predictions Std      284.752\n",
      "trainer/Z Policy Predictions Max      743.359\n",
      "trainer/Z Policy Predictions Min     -764.797\n",
      "trainer/Z Expert Targets Mean         673.502\n",
      "trainer/Z Expert Targets Std           43.8819\n",
      "trainer/Z Expert Targets Max          760.678\n",
      "trainer/Z Expert Targets Min          395.407\n",
      "trainer/Z Policy Targets Mean         547.971\n",
      "trainer/Z Policy Targets Std          279.852\n",
      "trainer/Z Policy Targets Max          735.565\n",
      "trainer/Z Policy Targets Min         -747.346\n",
      "trainer/Log Pis Mean                   20.3232\n",
      "trainer/Log Pis Std                     4.06756\n",
      "trainer/Policy mu Mean                  0.0245573\n",
      "trainer/Policy mu Std                   0.994318\n",
      "trainer/Policy log std Mean            -3.2858\n",
      "trainer/Policy log std Std              0.964227\n",
      "trainer/Alpha                           0.16014\n",
      "trainer/Alpha Loss                     -0.051757\n",
      "exploration/num steps total        261443\n",
      "exploration/num paths total           364\n",
      "evaluation/num steps total              2.29645e+06\n",
      "evaluation/num paths total           2606\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70407\n",
      "evaluation/Rewards Std                  0.982197\n",
      "evaluation/Rewards Max                  6.67779\n",
      "evaluation/Rewards Min                 -1.52517\n",
      "evaluation/Returns Mean              4704.07\n",
      "evaluation/Returns Std                 96.7338\n",
      "evaluation/Returns Max               4838.82\n",
      "evaluation/Returns Min               4574.05\n",
      "evaluation/Estimation Bias Mean       612.592\n",
      "evaluation/Estimation Bias Std        145.479\n",
      "evaluation/EB/Q_True Mean              43.6959\n",
      "evaluation/EB/Q_True Std              134.314\n",
      "evaluation/EB/Q_Pred Mean             656.288\n",
      "evaluation/EB/Q_Pred Std               60.8718\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4704.07\n",
      "evaluation/Actions Mean                 0.0240648\n",
      "evaluation/Actions Std                  0.536444\n",
      "evaluation/Actions Max                  0.999358\n",
      "evaluation/Actions Min                 -0.999918\n",
      "time/backward_policy (s)                1.9879\n",
      "time/backward_zf1 (s)                   2.11281\n",
      "time/backward_zf2 (s)                   2.08195\n",
      "time/data sampling (s)                  0.318023\n",
      "time/data storing (s)                   0.0154406\n",
      "time/evaluation sampling (s)            1.7557\n",
      "time/exploration sampling (s)           0.325399\n",
      "time/logging (s)                        0.0118436\n",
      "time/preback_alpha (s)                  1.0435\n",
      "time/preback_policy (s)                 1.1804\n",
      "time/preback_start (s)                  0.150834\n",
      "time/preback_zf (s)                     5.24499\n",
      "time/saving (s)                         0.00763928\n",
      "time/training (s)                       2.16717\n",
      "time/epoch (s)                         18.4036\n",
      "time/total (s)                       4588.1\n",
      "Epoch                                 255\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:09:05.236507 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 256 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 267000\n",
      "trainer/ZF1 Loss                       85.1715\n",
      "trainer/ZF2 Loss                       79.4793\n",
      "trainer/ZF Expert Reward               15.4075\n",
      "trainer/ZF Policy Reward                6.40928\n",
      "trainer/ZF CHI2 Term                  110.69\n",
      "trainer/Policy Loss                  -534.901\n",
      "trainer/Bias Loss                      57.7596\n",
      "trainer/Bias Value                     14.862\n",
      "trainer/Policy Grad Norm              152.157\n",
      "trainer/Policy Param Norm              37.6388\n",
      "trainer/Zf1 Grad Norm                2118.22\n",
      "trainer/Zf1 Param Norm                121.482\n",
      "trainer/Zf2 Grad Norm                1967.03\n",
      "trainer/Zf2 Param Norm                119.77\n",
      "trainer/Z Expert Predictions Mean     679.537\n",
      "trainer/Z Expert Predictions Std       50.249\n",
      "trainer/Z Expert Predictions Max      761.863\n",
      "trainer/Z Expert Predictions Min      452.538\n",
      "trainer/Z Policy Predictions Mean     534.644\n",
      "trainer/Z Policy Predictions Std      316.024\n",
      "trainer/Z Policy Predictions Max      738.76\n",
      "trainer/Z Policy Predictions Min     -806.532\n",
      "trainer/Z Expert Targets Mean         664.13\n",
      "trainer/Z Expert Targets Std           53.6565\n",
      "trainer/Z Expert Targets Max          749.824\n",
      "trainer/Z Expert Targets Min          404.395\n",
      "trainer/Z Policy Targets Mean         528.235\n",
      "trainer/Z Policy Targets Std          314.905\n",
      "trainer/Z Policy Targets Max          721.281\n",
      "trainer/Z Policy Targets Min         -805.37\n",
      "trainer/Log Pis Mean                   19.5622\n",
      "trainer/Log Pis Std                     4.20256\n",
      "trainer/Policy mu Mean                  0.0384028\n",
      "trainer/Policy mu Std                   0.943909\n",
      "trainer/Policy log std Mean            -3.2632\n",
      "trainer/Policy log std Std              0.935831\n",
      "trainer/Alpha                           0.161826\n",
      "trainer/Alpha Loss                      0.0708484\n",
      "exploration/num steps total        263443\n",
      "exploration/num paths total           366\n",
      "evaluation/num steps total              2.30645e+06\n",
      "evaluation/num paths total           2616\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.71491\n",
      "evaluation/Rewards Std                  0.970535\n",
      "evaluation/Rewards Max                  6.83644\n",
      "evaluation/Rewards Min                 -1.78539\n",
      "evaluation/Returns Mean              4714.91\n",
      "evaluation/Returns Std                 90.6417\n",
      "evaluation/Returns Max               4853.61\n",
      "evaluation/Returns Min               4552.59\n",
      "evaluation/Estimation Bias Mean       607.092\n",
      "evaluation/Estimation Bias Std        144.811\n",
      "evaluation/EB/Q_True Mean              43.0491\n",
      "evaluation/EB/Q_True Std              132.334\n",
      "evaluation/EB/Q_Pred Mean             650.141\n",
      "evaluation/EB/Q_Pred Std               60.0197\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4714.91\n",
      "evaluation/Actions Mean                 0.0178986\n",
      "evaluation/Actions Std                  0.534909\n",
      "evaluation/Actions Max                  0.999147\n",
      "evaluation/Actions Min                 -0.999774\n",
      "time/backward_policy (s)                1.9404\n",
      "time/backward_zf1 (s)                   2.08633\n",
      "time/backward_zf2 (s)                   2.00365\n",
      "time/data sampling (s)                  0.310018\n",
      "time/data storing (s)                   0.0151722\n",
      "time/evaluation sampling (s)            1.73995\n",
      "time/exploration sampling (s)           0.328689\n",
      "time/logging (s)                        0.0123085\n",
      "time/preback_alpha (s)                  1.02396\n",
      "time/preback_policy (s)                 1.15615\n",
      "time/preback_start (s)                  0.151829\n",
      "time/preback_zf (s)                     5.24369\n",
      "time/saving (s)                         0.00886756\n",
      "time/training (s)                       2.25385\n",
      "time/epoch (s)                         18.2749\n",
      "time/total (s)                       4606.39\n",
      "Epoch                                 256\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:09:23.269916 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 257 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 268000\n",
      "trainer/ZF1 Loss                       21.3667\n",
      "trainer/ZF2 Loss                       12.2689\n",
      "trainer/ZF Expert Reward               12.1268\n",
      "trainer/ZF Policy Reward                2.80578\n",
      "trainer/ZF CHI2 Term                   45.752\n",
      "trainer/Policy Loss                  -524.943\n",
      "trainer/Bias Loss                      65.8489\n",
      "trainer/Bias Value                     14.8737\n",
      "trainer/Policy Grad Norm              172.069\n",
      "trainer/Policy Param Norm              37.6641\n",
      "trainer/Zf1 Grad Norm                2165.38\n",
      "trainer/Zf1 Param Norm                121.623\n",
      "trainer/Zf2 Grad Norm                1436.53\n",
      "trainer/Zf2 Param Norm                119.92\n",
      "trainer/Z Expert Predictions Mean     681.19\n",
      "trainer/Z Expert Predictions Std       42.153\n",
      "trainer/Z Expert Predictions Max      758.321\n",
      "trainer/Z Expert Predictions Min      470.326\n",
      "trainer/Z Policy Predictions Mean     524.013\n",
      "trainer/Z Policy Predictions Std      341.553\n",
      "trainer/Z Policy Predictions Max      721.799\n",
      "trainer/Z Policy Predictions Min     -817.261\n",
      "trainer/Z Expert Targets Mean         669.063\n",
      "trainer/Z Expert Targets Std           43.3604\n",
      "trainer/Z Expert Targets Max          744.025\n",
      "trainer/Z Expert Targets Min          451.164\n",
      "trainer/Z Policy Targets Mean         521.207\n",
      "trainer/Z Policy Targets Std          335.794\n",
      "trainer/Z Policy Targets Max          723.59\n",
      "trainer/Z Policy Targets Min         -802.907\n",
      "trainer/Log Pis Mean                   19.8113\n",
      "trainer/Log Pis Std                     4.8227\n",
      "trainer/Policy mu Mean                  0.067455\n",
      "trainer/Policy mu Std                   1.01592\n",
      "trainer/Policy log std Mean            -3.17555\n",
      "trainer/Policy log std Std              1.02827\n",
      "trainer/Alpha                           0.162963\n",
      "trainer/Alpha Loss                      0.0307574\n",
      "exploration/num steps total        263443\n",
      "exploration/num paths total           366\n",
      "evaluation/num steps total              2.31645e+06\n",
      "evaluation/num paths total           2626\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.716\n",
      "evaluation/Rewards Std                  0.910269\n",
      "evaluation/Rewards Max                  6.79107\n",
      "evaluation/Rewards Min                 -1.72956\n",
      "evaluation/Returns Mean              4716\n",
      "evaluation/Returns Std                 71.8724\n",
      "evaluation/Returns Max               4839.69\n",
      "evaluation/Returns Min               4609.52\n",
      "evaluation/Estimation Bias Mean       616.83\n",
      "evaluation/Estimation Bias Std        144.44\n",
      "evaluation/EB/Q_True Mean              44.5199\n",
      "evaluation/EB/Q_True Std              136.815\n",
      "evaluation/EB/Q_Pred Mean             661.35\n",
      "evaluation/EB/Q_Pred Std               53.8265\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4716\n",
      "evaluation/Actions Mean                 0.0254726\n",
      "evaluation/Actions Std                  0.537728\n",
      "evaluation/Actions Max                  0.999711\n",
      "evaluation/Actions Min                 -0.999612\n",
      "time/backward_policy (s)                1.88432\n",
      "time/backward_zf1 (s)                   2.00349\n",
      "time/backward_zf2 (s)                   1.93284\n",
      "time/data sampling (s)                  0.302214\n",
      "time/data storing (s)                   0.0146818\n",
      "time/evaluation sampling (s)            1.76866\n",
      "time/exploration sampling (s)           0.319102\n",
      "time/logging (s)                        0.0119471\n",
      "time/preback_alpha (s)                  0.978832\n",
      "time/preback_policy (s)                 1.09315\n",
      "time/preback_start (s)                  0.147101\n",
      "time/preback_zf (s)                     5.20232\n",
      "time/saving (s)                         0.00627728\n",
      "time/training (s)                       2.29305\n",
      "time/epoch (s)                         17.958\n",
      "time/total (s)                       4624.37\n",
      "Epoch                                 257\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:09:41.614131 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 258 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 269000\n",
      "trainer/ZF1 Loss                       12.7878\n",
      "trainer/ZF2 Loss                       18.6494\n",
      "trainer/ZF Expert Reward               17.9789\n",
      "trainer/ZF Policy Reward                6.37469\n",
      "trainer/ZF CHI2 Term                   46.758\n",
      "trainer/Policy Loss                  -546.353\n",
      "trainer/Bias Loss                      64.6664\n",
      "trainer/Bias Value                     14.8876\n",
      "trainer/Policy Grad Norm              174.983\n",
      "trainer/Policy Param Norm              37.6881\n",
      "trainer/Zf1 Grad Norm                1012.97\n",
      "trainer/Zf1 Param Norm                121.741\n",
      "trainer/Zf2 Grad Norm                1179.84\n",
      "trainer/Zf2 Param Norm                120.055\n",
      "trainer/Z Expert Predictions Mean     682.306\n",
      "trainer/Z Expert Predictions Std       42.7486\n",
      "trainer/Z Expert Predictions Max      765.153\n",
      "trainer/Z Expert Predictions Min      502.326\n",
      "trainer/Z Policy Predictions Mean     549.269\n",
      "trainer/Z Policy Predictions Std      301.079\n",
      "trainer/Z Policy Predictions Max      737.017\n",
      "trainer/Z Policy Predictions Min     -808.076\n",
      "trainer/Z Expert Targets Mean         664.327\n",
      "trainer/Z Expert Targets Std           45.3741\n",
      "trainer/Z Expert Targets Max          746.188\n",
      "trainer/Z Expert Targets Min          480.803\n",
      "trainer/Z Policy Targets Mean         542.894\n",
      "trainer/Z Policy Targets Std          295.198\n",
      "trainer/Z Policy Targets Max          724.617\n",
      "trainer/Z Policy Targets Min         -788.164\n",
      "trainer/Log Pis Mean                   19.6315\n",
      "trainer/Log Pis Std                     4.62235\n",
      "trainer/Policy mu Mean                  0.0496621\n",
      "trainer/Policy mu Std                   0.923292\n",
      "trainer/Policy log std Mean            -3.27769\n",
      "trainer/Policy log std Std              0.900426\n",
      "trainer/Alpha                           0.163757\n",
      "trainer/Alpha Loss                      0.0603416\n",
      "exploration/num steps total        263443\n",
      "exploration/num paths total           366\n",
      "evaluation/num steps total              2.32645e+06\n",
      "evaluation/num paths total           2636\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6916\n",
      "evaluation/Rewards Std                  0.964706\n",
      "evaluation/Rewards Max                  6.76953\n",
      "evaluation/Rewards Min                 -1.41346\n",
      "evaluation/Returns Mean              4691.6\n",
      "evaluation/Returns Std                 70.6898\n",
      "evaluation/Returns Max               4808.77\n",
      "evaluation/Returns Min               4578.86\n",
      "evaluation/Estimation Bias Mean       611.332\n",
      "evaluation/Estimation Bias Std        147.31\n",
      "evaluation/EB/Q_True Mean              42.7862\n",
      "evaluation/EB/Q_True Std              132.039\n",
      "evaluation/EB/Q_Pred Mean             654.118\n",
      "evaluation/EB/Q_Pred Std               57.4955\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4691.6\n",
      "evaluation/Actions Mean                 0.0186634\n",
      "evaluation/Actions Std                  0.542476\n",
      "evaluation/Actions Max                  0.999755\n",
      "evaluation/Actions Min                 -0.999844\n",
      "time/backward_policy (s)                1.9357\n",
      "time/backward_zf1 (s)                   2.10033\n",
      "time/backward_zf2 (s)                   2.04637\n",
      "time/data sampling (s)                  0.289337\n",
      "time/data storing (s)                   0.0162766\n",
      "time/evaluation sampling (s)            1.72263\n",
      "time/exploration sampling (s)           0.33059\n",
      "time/logging (s)                        0.0115101\n",
      "time/preback_alpha (s)                  0.997517\n",
      "time/preback_policy (s)                 1.12755\n",
      "time/preback_start (s)                  0.148738\n",
      "time/preback_zf (s)                     5.26346\n",
      "time/saving (s)                         0.00550833\n",
      "time/training (s)                       2.27572\n",
      "time/epoch (s)                         18.2712\n",
      "time/total (s)                       4642.67\n",
      "Epoch                                 258\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:10:00.228594 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 259 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 270000\n",
      "trainer/ZF1 Loss                       15.1215\n",
      "trainer/ZF2 Loss                        8.05054\n",
      "trainer/ZF Expert Reward               18.0265\n",
      "trainer/ZF Policy Reward                3.87756\n",
      "trainer/ZF CHI2 Term                   44.4784\n",
      "trainer/Policy Loss                  -498.318\n",
      "trainer/Bias Loss                      66.1336\n",
      "trainer/Bias Value                     14.8998\n",
      "trainer/Policy Grad Norm              160.787\n",
      "trainer/Policy Param Norm              37.7116\n",
      "trainer/Zf1 Grad Norm                1568.81\n",
      "trainer/Zf1 Param Norm                121.876\n",
      "trainer/Zf2 Grad Norm                1195.02\n",
      "trainer/Zf2 Param Norm                120.186\n",
      "trainer/Z Expert Predictions Mean     675.25\n",
      "trainer/Z Expert Predictions Std       49.2116\n",
      "trainer/Z Expert Predictions Max      759.455\n",
      "trainer/Z Expert Predictions Min      397.126\n",
      "trainer/Z Policy Predictions Mean     499.24\n",
      "trainer/Z Policy Predictions Std      346.349\n",
      "trainer/Z Policy Predictions Max      723.056\n",
      "trainer/Z Policy Predictions Min     -806.581\n",
      "trainer/Z Expert Targets Mean         657.224\n",
      "trainer/Z Expert Targets Std           52.8997\n",
      "trainer/Z Expert Targets Max          741.069\n",
      "trainer/Z Expert Targets Min          357.776\n",
      "trainer/Z Policy Targets Mean         495.362\n",
      "trainer/Z Policy Targets Std          342.584\n",
      "trainer/Z Policy Targets Max          721.538\n",
      "trainer/Z Policy Targets Min         -792.379\n",
      "trainer/Log Pis Mean                   18.9327\n",
      "trainer/Log Pis Std                     4.88182\n",
      "trainer/Policy mu Mean                  0.0472154\n",
      "trainer/Policy mu Std                   1.02442\n",
      "trainer/Policy log std Mean            -3.09583\n",
      "trainer/Policy log std Std              1.01442\n",
      "trainer/Alpha                           0.163008\n",
      "trainer/Alpha Loss                      0.173984\n",
      "exploration/num steps total        264443\n",
      "exploration/num paths total           367\n",
      "evaluation/num steps total              2.33645e+06\n",
      "evaluation/num paths total           2646\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66456\n",
      "evaluation/Rewards Std                  0.941738\n",
      "evaluation/Rewards Max                  6.61692\n",
      "evaluation/Rewards Min                 -1.51796\n",
      "evaluation/Returns Mean              4664.56\n",
      "evaluation/Returns Std                 50.0561\n",
      "evaluation/Returns Max               4719.81\n",
      "evaluation/Returns Min               4570.67\n",
      "evaluation/Estimation Bias Mean       603.286\n",
      "evaluation/Estimation Bias Std        142.307\n",
      "evaluation/EB/Q_True Mean              42.923\n",
      "evaluation/EB/Q_True Std              132.305\n",
      "evaluation/EB/Q_Pred Mean             646.209\n",
      "evaluation/EB/Q_Pred Std               55.0123\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4664.56\n",
      "evaluation/Actions Mean                 0.0190425\n",
      "evaluation/Actions Std                  0.533375\n",
      "evaluation/Actions Max                  0.999804\n",
      "evaluation/Actions Min                 -0.999787\n",
      "time/backward_policy (s)                2.01922\n",
      "time/backward_zf1 (s)                   2.18053\n",
      "time/backward_zf2 (s)                   2.09912\n",
      "time/data sampling (s)                  0.295908\n",
      "time/data storing (s)                   0.0146532\n",
      "time/evaluation sampling (s)            1.75829\n",
      "time/exploration sampling (s)           0.322115\n",
      "time/logging (s)                        0.0122602\n",
      "time/preback_alpha (s)                  1.06703\n",
      "time/preback_policy (s)                 1.20245\n",
      "time/preback_start (s)                  0.150441\n",
      "time/preback_zf (s)                     5.27836\n",
      "time/saving (s)                         0.00550278\n",
      "time/training (s)                       2.13724\n",
      "time/epoch (s)                         18.5431\n",
      "time/total (s)                       4661.23\n",
      "Epoch                                 259\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:10:18.540343 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 260 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 271000\n",
      "trainer/ZF1 Loss                      115.093\n",
      "trainer/ZF2 Loss                      109.799\n",
      "trainer/ZF Expert Reward               11.7728\n",
      "trainer/ZF Policy Reward                4.67927\n",
      "trainer/ZF CHI2 Term                  139.126\n",
      "trainer/Policy Loss                  -539.335\n",
      "trainer/Bias Loss                      54.462\n",
      "trainer/Bias Value                     14.9127\n",
      "trainer/Policy Grad Norm              137.523\n",
      "trainer/Policy Param Norm              37.734\n",
      "trainer/Zf1 Grad Norm                1955.71\n",
      "trainer/Zf1 Param Norm                121.994\n",
      "trainer/Zf2 Grad Norm                1729.89\n",
      "trainer/Zf2 Param Norm                120.325\n",
      "trainer/Z Expert Predictions Mean     674.379\n",
      "trainer/Z Expert Predictions Std       36.9699\n",
      "trainer/Z Expert Predictions Max      744.66\n",
      "trainer/Z Expert Predictions Min      498.532\n",
      "trainer/Z Policy Predictions Mean     539.036\n",
      "trainer/Z Policy Predictions Std      300.83\n",
      "trainer/Z Policy Predictions Max      712.019\n",
      "trainer/Z Policy Predictions Min     -806.476\n",
      "trainer/Z Expert Targets Mean         662.606\n",
      "trainer/Z Expert Targets Std           40.3592\n",
      "trainer/Z Expert Targets Max          727.482\n",
      "trainer/Z Expert Targets Min          475.546\n",
      "trainer/Z Policy Targets Mean         534.357\n",
      "trainer/Z Policy Targets Std          297.853\n",
      "trainer/Z Policy Targets Max          709.712\n",
      "trainer/Z Policy Targets Min         -795.447\n",
      "trainer/Log Pis Mean                   19.7845\n",
      "trainer/Log Pis Std                     4.02274\n",
      "trainer/Policy mu Mean                  0.0213216\n",
      "trainer/Policy mu Std                   0.93026\n",
      "trainer/Policy log std Mean            -3.31473\n",
      "trainer/Policy log std Std              0.887153\n",
      "trainer/Alpha                           0.16378\n",
      "trainer/Alpha Loss                      0.035298\n",
      "exploration/num steps total        265443\n",
      "exploration/num paths total           368\n",
      "evaluation/num steps total              2.34584e+06\n",
      "evaluation/num paths total           2657\n",
      "evaluation/path length Mean           853.818\n",
      "evaluation/path length Std            316.119\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             52\n",
      "evaluation/Rewards Mean                 4.68558\n",
      "evaluation/Rewards Std                  1.08406\n",
      "evaluation/Rewards Max                  6.80434\n",
      "evaluation/Rewards Min                 -1.62993\n",
      "evaluation/Returns Mean              4000.63\n",
      "evaluation/Returns Std               1518.97\n",
      "evaluation/Returns Max               4852.14\n",
      "evaluation/Returns Min                150.711\n",
      "evaluation/Estimation Bias Mean       589.434\n",
      "evaluation/Estimation Bias Std        163.978\n",
      "evaluation/EB/Q_True Mean              46.8963\n",
      "evaluation/EB/Q_True Std              139.528\n",
      "evaluation/EB/Q_Pred Mean             636.331\n",
      "evaluation/EB/Q_Pred Std               71.2297\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4000.63\n",
      "evaluation/Actions Mean                 0.0256137\n",
      "evaluation/Actions Std                  0.540282\n",
      "evaluation/Actions Max                  0.999786\n",
      "evaluation/Actions Min                 -0.999837\n",
      "time/backward_policy (s)                1.95513\n",
      "time/backward_zf1 (s)                   2.09902\n",
      "time/backward_zf2 (s)                   2.03807\n",
      "time/data sampling (s)                  0.298495\n",
      "time/data storing (s)                   0.0154149\n",
      "time/evaluation sampling (s)            1.75015\n",
      "time/exploration sampling (s)           0.325907\n",
      "time/logging (s)                        0.0118637\n",
      "time/preback_alpha (s)                  1.02033\n",
      "time/preback_policy (s)                 1.1577\n",
      "time/preback_start (s)                  0.147228\n",
      "time/preback_zf (s)                     5.235\n",
      "time/saving (s)                         0.00604103\n",
      "time/training (s)                       2.18338\n",
      "time/epoch (s)                         18.2437\n",
      "time/total (s)                       4679.49\n",
      "Epoch                                 260\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:10:36.761638 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 261 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 272000\n",
      "trainer/ZF1 Loss                        3.83742\n",
      "trainer/ZF2 Loss                        5.78632\n",
      "trainer/ZF Expert Reward               14.9455\n",
      "trainer/ZF Policy Reward                1.85401\n",
      "trainer/ZF CHI2 Term                   37.5633\n",
      "trainer/Policy Loss                  -545.138\n",
      "trainer/Bias Loss                      68.6609\n",
      "trainer/Bias Value                     14.9257\n",
      "trainer/Policy Grad Norm              152.146\n",
      "trainer/Policy Param Norm              37.7558\n",
      "trainer/Zf1 Grad Norm                1257.77\n",
      "trainer/Zf1 Param Norm                122.126\n",
      "trainer/Zf2 Grad Norm                1386.77\n",
      "trainer/Zf2 Param Norm                120.467\n",
      "trainer/Z Expert Predictions Mean     665.182\n",
      "trainer/Z Expert Predictions Std       66.1234\n",
      "trainer/Z Expert Predictions Max      745.56\n",
      "trainer/Z Expert Predictions Min      -41.116\n",
      "trainer/Z Policy Predictions Mean     548.023\n",
      "trainer/Z Policy Predictions Std      289.333\n",
      "trainer/Z Policy Predictions Max      711.917\n",
      "trainer/Z Policy Predictions Min     -813.61\n",
      "trainer/Z Expert Targets Mean         650.236\n",
      "trainer/Z Expert Targets Std           65.9793\n",
      "trainer/Z Expert Targets Max          727.692\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         546.169\n",
      "trainer/Z Policy Targets Std          285.33\n",
      "trainer/Z Policy Targets Max          712.66\n",
      "trainer/Z Policy Targets Min         -784.64\n",
      "trainer/Log Pis Mean                   19.8585\n",
      "trainer/Log Pis Std                     4.76437\n",
      "trainer/Policy mu Mean                  0.0494408\n",
      "trainer/Policy mu Std                   0.910075\n",
      "trainer/Policy log std Mean            -3.30158\n",
      "trainer/Policy log std Std              0.878123\n",
      "trainer/Alpha                           0.166314\n",
      "trainer/Alpha Loss                      0.0235347\n",
      "exploration/num steps total        265443\n",
      "exploration/num paths total           368\n",
      "evaluation/num steps total              2.35584e+06\n",
      "evaluation/num paths total           2667\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60358\n",
      "evaluation/Rewards Std                  0.970364\n",
      "evaluation/Rewards Max                  6.686\n",
      "evaluation/Rewards Min                 -1.61899\n",
      "evaluation/Returns Mean              4603.58\n",
      "evaluation/Returns Std                 99.1913\n",
      "evaluation/Returns Max               4740.53\n",
      "evaluation/Returns Min               4472.46\n",
      "evaluation/Estimation Bias Mean       596.747\n",
      "evaluation/Estimation Bias Std        143.26\n",
      "evaluation/EB/Q_True Mean              42.7585\n",
      "evaluation/EB/Q_True Std              131.746\n",
      "evaluation/EB/Q_Pred Mean             639.505\n",
      "evaluation/EB/Q_Pred Std               59.2538\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4603.58\n",
      "evaluation/Actions Mean                 0.0270915\n",
      "evaluation/Actions Std                  0.539273\n",
      "evaluation/Actions Max                  0.999213\n",
      "evaluation/Actions Min                 -0.999671\n",
      "time/backward_policy (s)                1.97785\n",
      "time/backward_zf1 (s)                   2.08008\n",
      "time/backward_zf2 (s)                   2.03652\n",
      "time/data sampling (s)                  0.305089\n",
      "time/data storing (s)                   0.0144472\n",
      "time/evaluation sampling (s)            1.73901\n",
      "time/exploration sampling (s)           0.314374\n",
      "time/logging (s)                        0.0124256\n",
      "time/preback_alpha (s)                  1.02645\n",
      "time/preback_policy (s)                 1.16658\n",
      "time/preback_start (s)                  0.147072\n",
      "time/preback_zf (s)                     5.17826\n",
      "time/saving (s)                         0.0055316\n",
      "time/training (s)                       2.1448\n",
      "time/epoch (s)                         18.1485\n",
      "time/total (s)                       4697.67\n",
      "Epoch                                 261\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:10:54.882225 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 262 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 273000\n",
      "trainer/ZF1 Loss                      104.888\n",
      "trainer/ZF2 Loss                      106.984\n",
      "trainer/ZF Expert Reward               14.0199\n",
      "trainer/ZF Policy Reward                5.31199\n",
      "trainer/ZF CHI2 Term                  134.403\n",
      "trainer/Policy Loss                  -548.734\n",
      "trainer/Bias Loss                      77.3838\n",
      "trainer/Bias Value                     14.9365\n",
      "trainer/Policy Grad Norm              172.063\n",
      "trainer/Policy Param Norm              37.7785\n",
      "trainer/Zf1 Grad Norm                2248.98\n",
      "trainer/Zf1 Param Norm                122.255\n",
      "trainer/Zf2 Grad Norm                2506.78\n",
      "trainer/Zf2 Param Norm                120.592\n",
      "trainer/Z Expert Predictions Mean     662.224\n",
      "trainer/Z Expert Predictions Std       53.3912\n",
      "trainer/Z Expert Predictions Max      742.497\n",
      "trainer/Z Expert Predictions Min      219.304\n",
      "trainer/Z Policy Predictions Mean     549.234\n",
      "trainer/Z Policy Predictions Std      254.262\n",
      "trainer/Z Policy Predictions Max      727.582\n",
      "trainer/Z Policy Predictions Min     -806.323\n",
      "trainer/Z Expert Targets Mean         648.204\n",
      "trainer/Z Expert Targets Std           55.2679\n",
      "trainer/Z Expert Targets Max          728.696\n",
      "trainer/Z Expert Targets Min          193.558\n",
      "trainer/Z Policy Targets Mean         543.922\n",
      "trainer/Z Policy Targets Std          253.833\n",
      "trainer/Z Policy Targets Max          723.84\n",
      "trainer/Z Policy Targets Min         -760.459\n",
      "trainer/Log Pis Mean                   19.9584\n",
      "trainer/Log Pis Std                     4.16582\n",
      "trainer/Policy mu Mean                  0.054853\n",
      "trainer/Policy mu Std                   0.929037\n",
      "trainer/Policy log std Mean            -3.28854\n",
      "trainer/Policy log std Std              0.91557\n",
      "trainer/Alpha                           0.165435\n",
      "trainer/Alpha Loss                      0.00687703\n",
      "exploration/num steps total        267443\n",
      "exploration/num paths total           370\n",
      "evaluation/num steps total              2.36584e+06\n",
      "evaluation/num paths total           2677\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64884\n",
      "evaluation/Rewards Std                  0.952353\n",
      "evaluation/Rewards Max                  7.03422\n",
      "evaluation/Rewards Min                 -1.41609\n",
      "evaluation/Returns Mean              4648.84\n",
      "evaluation/Returns Std                 91.4867\n",
      "evaluation/Returns Max               4753.5\n",
      "evaluation/Returns Min               4440.09\n",
      "evaluation/Estimation Bias Mean       591.629\n",
      "evaluation/Estimation Bias Std        150.137\n",
      "evaluation/EB/Q_True Mean              43.5773\n",
      "evaluation/EB/Q_True Std              134.408\n",
      "evaluation/EB/Q_Pred Mean             635.207\n",
      "evaluation/EB/Q_Pred Std               58.9277\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4648.84\n",
      "evaluation/Actions Mean                 0.0219868\n",
      "evaluation/Actions Std                  0.542208\n",
      "evaluation/Actions Max                  0.999177\n",
      "evaluation/Actions Min                 -0.999669\n",
      "time/backward_policy (s)                1.89869\n",
      "time/backward_zf1 (s)                   2.04955\n",
      "time/backward_zf2 (s)                   1.96392\n",
      "time/data sampling (s)                  0.300319\n",
      "time/data storing (s)                   0.0150106\n",
      "time/evaluation sampling (s)            1.72548\n",
      "time/exploration sampling (s)           0.32291\n",
      "time/logging (s)                        0.012528\n",
      "time/preback_alpha (s)                  0.981464\n",
      "time/preback_policy (s)                 1.08988\n",
      "time/preback_start (s)                  0.148601\n",
      "time/preback_zf (s)                     5.24347\n",
      "time/saving (s)                         0.00729719\n",
      "time/training (s)                       2.28904\n",
      "time/epoch (s)                         18.0482\n",
      "time/total (s)                       4715.74\n",
      "Epoch                                 262\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:11:12.581136 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 263 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 274000\n",
      "trainer/ZF1 Loss                       12.1027\n",
      "trainer/ZF2 Loss                       11.4287\n",
      "trainer/ZF Expert Reward               15.8813\n",
      "trainer/ZF Policy Reward                4.90701\n",
      "trainer/ZF CHI2 Term                   41.9701\n",
      "trainer/Policy Loss                  -543.665\n",
      "trainer/Bias Loss                      71.7349\n",
      "trainer/Bias Value                     14.948\n",
      "trainer/Policy Grad Norm              177.346\n",
      "trainer/Policy Param Norm              37.8022\n",
      "trainer/Zf1 Grad Norm                1125.12\n",
      "trainer/Zf1 Param Norm                122.395\n",
      "trainer/Zf2 Grad Norm                1245.85\n",
      "trainer/Zf2 Param Norm                120.721\n",
      "trainer/Z Expert Predictions Mean     660.408\n",
      "trainer/Z Expert Predictions Std       44.0218\n",
      "trainer/Z Expert Predictions Max      737.354\n",
      "trainer/Z Expert Predictions Min      447.041\n",
      "trainer/Z Policy Predictions Mean     544.459\n",
      "trainer/Z Policy Predictions Std      241.425\n",
      "trainer/Z Policy Predictions Max      736.955\n",
      "trainer/Z Policy Predictions Min     -798.592\n",
      "trainer/Z Expert Targets Mean         644.527\n",
      "trainer/Z Expert Targets Std           47.7368\n",
      "trainer/Z Expert Targets Max          719.237\n",
      "trainer/Z Expert Targets Min          405.773\n",
      "trainer/Z Policy Targets Mean         539.552\n",
      "trainer/Z Policy Targets Std          236.271\n",
      "trainer/Z Policy Targets Max          707.521\n",
      "trainer/Z Policy Targets Min         -775.625\n",
      "trainer/Log Pis Mean                   19.4243\n",
      "trainer/Log Pis Std                     4.34537\n",
      "trainer/Policy mu Mean                  0.0201395\n",
      "trainer/Policy mu Std                   0.942805\n",
      "trainer/Policy log std Mean            -3.24304\n",
      "trainer/Policy log std Std              0.875785\n",
      "trainer/Alpha                           0.166911\n",
      "trainer/Alpha Loss                      0.0960997\n",
      "exploration/num steps total        269443\n",
      "exploration/num paths total           372\n",
      "evaluation/num steps total              2.37516e+06\n",
      "evaluation/num paths total           2687\n",
      "evaluation/path length Mean           932.1\n",
      "evaluation/path length Std            203.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            321\n",
      "evaluation/Rewards Mean                 4.58213\n",
      "evaluation/Rewards Std                  0.995438\n",
      "evaluation/Rewards Max                  6.67333\n",
      "evaluation/Rewards Min                 -1.77397\n",
      "evaluation/Returns Mean              4271\n",
      "evaluation/Returns Std                961.538\n",
      "evaluation/Returns Max               4688.81\n",
      "evaluation/Returns Min               1392.5\n",
      "evaluation/Estimation Bias Mean       590.96\n",
      "evaluation/Estimation Bias Std        150.085\n",
      "evaluation/EB/Q_True Mean              46.2335\n",
      "evaluation/EB/Q_True Std              136.987\n",
      "evaluation/EB/Q_Pred Mean             637.194\n",
      "evaluation/EB/Q_Pred Std               57.5558\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4271\n",
      "evaluation/Actions Mean                 0.0242713\n",
      "evaluation/Actions Std                  0.539435\n",
      "evaluation/Actions Max                  0.999241\n",
      "evaluation/Actions Min                 -0.999258\n",
      "time/backward_policy (s)                1.76658\n",
      "time/backward_zf1 (s)                   1.91476\n",
      "time/backward_zf2 (s)                   1.8335\n",
      "time/data sampling (s)                  0.287281\n",
      "time/data storing (s)                   0.0152346\n",
      "time/evaluation sampling (s)            1.83381\n",
      "time/exploration sampling (s)           0.322378\n",
      "time/logging (s)                        0.0121742\n",
      "time/preback_alpha (s)                  0.923551\n",
      "time/preback_policy (s)                 1.0106\n",
      "time/preback_start (s)                  0.145949\n",
      "time/preback_zf (s)                     5.15544\n",
      "time/saving (s)                         0.00999288\n",
      "time/training (s)                       2.39947\n",
      "time/epoch (s)                         17.6307\n",
      "time/total (s)                       4733.39\n",
      "Epoch                                 263\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:11:30.545792 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 264 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 275000\n",
      "trainer/ZF1 Loss                       13.6195\n",
      "trainer/ZF2 Loss                       15.7345\n",
      "trainer/ZF Expert Reward               15.7542\n",
      "trainer/ZF Policy Reward                5.47973\n",
      "trainer/ZF CHI2 Term                   44.3704\n",
      "trainer/Policy Loss                  -486.666\n",
      "trainer/Bias Loss                      53.7623\n",
      "trainer/Bias Value                     14.9583\n",
      "trainer/Policy Grad Norm              156.654\n",
      "trainer/Policy Param Norm              37.8219\n",
      "trainer/Zf1 Grad Norm                1327.72\n",
      "trainer/Zf1 Param Norm                122.521\n",
      "trainer/Zf2 Grad Norm                1464.09\n",
      "trainer/Zf2 Param Norm                120.865\n",
      "trainer/Z Expert Predictions Mean     658.88\n",
      "trainer/Z Expert Predictions Std       53.4653\n",
      "trainer/Z Expert Predictions Max      731.242\n",
      "trainer/Z Expert Predictions Min      263.879\n",
      "trainer/Z Policy Predictions Mean     489.743\n",
      "trainer/Z Policy Predictions Std      333.702\n",
      "trainer/Z Policy Predictions Max      707.698\n",
      "trainer/Z Policy Predictions Min     -769.29\n",
      "trainer/Z Expert Targets Mean         643.126\n",
      "trainer/Z Expert Targets Std           54.8062\n",
      "trainer/Z Expert Targets Max          726.601\n",
      "trainer/Z Expert Targets Min          252.686\n",
      "trainer/Z Policy Targets Mean         484.264\n",
      "trainer/Z Policy Targets Std          329.234\n",
      "trainer/Z Policy Targets Max          714.481\n",
      "trainer/Z Policy Targets Min         -758.74\n",
      "trainer/Log Pis Mean                   19.6151\n",
      "trainer/Log Pis Std                     4.7901\n",
      "trainer/Policy mu Mean                 -0.0109765\n",
      "trainer/Policy mu Std                   0.940163\n",
      "trainer/Policy log std Mean            -3.22367\n",
      "trainer/Policy log std Std              0.98049\n",
      "trainer/Alpha                           0.167003\n",
      "trainer/Alpha Loss                      0.0642863\n",
      "exploration/num steps total        270443\n",
      "exploration/num paths total           373\n",
      "evaluation/num steps total              2.38516e+06\n",
      "evaluation/num paths total           2697\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70872\n",
      "evaluation/Rewards Std                  0.917681\n",
      "evaluation/Rewards Max                  6.71953\n",
      "evaluation/Rewards Min                 -1.50181\n",
      "evaluation/Returns Mean              4708.72\n",
      "evaluation/Returns Std                 64.2621\n",
      "evaluation/Returns Max               4825.41\n",
      "evaluation/Returns Min               4569.24\n",
      "evaluation/Estimation Bias Mean       589.461\n",
      "evaluation/Estimation Bias Std        144.437\n",
      "evaluation/EB/Q_True Mean              43.2991\n",
      "evaluation/EB/Q_True Std              133.185\n",
      "evaluation/EB/Q_Pred Mean             632.76\n",
      "evaluation/EB/Q_Pred Std               53.856\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4708.72\n",
      "evaluation/Actions Mean                 0.0253682\n",
      "evaluation/Actions Std                  0.539625\n",
      "evaluation/Actions Max                  0.999513\n",
      "evaluation/Actions Min                 -0.999565\n",
      "time/backward_policy (s)                1.87756\n",
      "time/backward_zf1 (s)                   2.00744\n",
      "time/backward_zf2 (s)                   1.93961\n",
      "time/data sampling (s)                  0.305615\n",
      "time/data storing (s)                   0.0147553\n",
      "time/evaluation sampling (s)            1.7968\n",
      "time/exploration sampling (s)           0.319874\n",
      "time/logging (s)                        0.0126379\n",
      "time/preback_alpha (s)                  0.998517\n",
      "time/preback_policy (s)                 1.13065\n",
      "time/preback_start (s)                  0.146421\n",
      "time/preback_zf (s)                     5.17284\n",
      "time/saving (s)                         0.00644368\n",
      "time/training (s)                       2.15908\n",
      "time/epoch (s)                         17.8883\n",
      "time/total (s)                       4751.3\n",
      "Epoch                                 264\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:11:48.667722 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 265 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 276000\n",
      "trainer/ZF1 Loss                       20.0873\n",
      "trainer/ZF2 Loss                       12.9749\n",
      "trainer/ZF Expert Reward               10.9239\n",
      "trainer/ZF Policy Reward                2.06602\n",
      "trainer/ZF CHI2 Term                   45.3525\n",
      "trainer/Policy Loss                  -531.481\n",
      "trainer/Bias Loss                      80.5262\n",
      "trainer/Bias Value                     14.9723\n",
      "trainer/Policy Grad Norm              178.819\n",
      "trainer/Policy Param Norm              37.8471\n",
      "trainer/Zf1 Grad Norm                2018.92\n",
      "trainer/Zf1 Param Norm                122.644\n",
      "trainer/Zf2 Grad Norm                1712.17\n",
      "trainer/Zf2 Param Norm                120.983\n",
      "trainer/Z Expert Predictions Mean     655.269\n",
      "trainer/Z Expert Predictions Std       37.7352\n",
      "trainer/Z Expert Predictions Max      722.618\n",
      "trainer/Z Expert Predictions Min      492.617\n",
      "trainer/Z Policy Predictions Mean     533.691\n",
      "trainer/Z Policy Predictions Std      278.947\n",
      "trainer/Z Policy Predictions Max      701.938\n",
      "trainer/Z Policy Predictions Min     -724.414\n",
      "trainer/Z Expert Targets Mean         644.345\n",
      "trainer/Z Expert Targets Std           40.144\n",
      "trainer/Z Expert Targets Max          718.416\n",
      "trainer/Z Expert Targets Min          487.276\n",
      "trainer/Z Policy Targets Mean         531.625\n",
      "trainer/Z Policy Targets Std          276.318\n",
      "trainer/Z Policy Targets Max          716.685\n",
      "trainer/Z Policy Targets Min         -724.195\n",
      "trainer/Log Pis Mean                   20.1651\n",
      "trainer/Log Pis Std                     3.99481\n",
      "trainer/Policy mu Mean                  0.0497145\n",
      "trainer/Policy mu Std                   0.909076\n",
      "trainer/Policy log std Mean            -3.34396\n",
      "trainer/Policy log std Std              0.875556\n",
      "trainer/Alpha                           0.1639\n",
      "trainer/Alpha Loss                     -0.0270616\n",
      "exploration/num steps total        271443\n",
      "exploration/num paths total           374\n",
      "evaluation/num steps total              2.39482e+06\n",
      "evaluation/num paths total           2707\n",
      "evaluation/path length Mean           965.8\n",
      "evaluation/path length Std            102.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            658\n",
      "evaluation/Rewards Mean                 4.73616\n",
      "evaluation/Rewards Std                  1.03707\n",
      "evaluation/Rewards Max                  6.88845\n",
      "evaluation/Rewards Min                 -1.64457\n",
      "evaluation/Returns Mean              4574.18\n",
      "evaluation/Returns Std                543.977\n",
      "evaluation/Returns Max               4865.25\n",
      "evaluation/Returns Min               2958.73\n",
      "evaluation/Estimation Bias Mean       579.44\n",
      "evaluation/Estimation Bias Std        159.857\n",
      "evaluation/EB/Q_True Mean              46.2185\n",
      "evaluation/EB/Q_True Std              139.922\n",
      "evaluation/EB/Q_Pred Mean             625.659\n",
      "evaluation/EB/Q_Pred Std               61.3207\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4574.18\n",
      "evaluation/Actions Mean                 0.0228401\n",
      "evaluation/Actions Std                  0.542532\n",
      "evaluation/Actions Max                  0.999899\n",
      "evaluation/Actions Min                 -0.999643\n",
      "time/backward_policy (s)                1.92372\n",
      "time/backward_zf1 (s)                   2.03905\n",
      "time/backward_zf2 (s)                   1.98112\n",
      "time/data sampling (s)                  0.311258\n",
      "time/data storing (s)                   0.0152291\n",
      "time/evaluation sampling (s)            1.72475\n",
      "time/exploration sampling (s)           0.321775\n",
      "time/logging (s)                        0.0128504\n",
      "time/preback_alpha (s)                  1.00494\n",
      "time/preback_policy (s)                 1.13143\n",
      "time/preback_start (s)                  0.148726\n",
      "time/preback_zf (s)                     5.21204\n",
      "time/saving (s)                         0.00618643\n",
      "time/training (s)                       2.21613\n",
      "time/epoch (s)                         18.0492\n",
      "time/total (s)                       4769.37\n",
      "Epoch                                 265\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:12:06.733953 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 266 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 277000\n",
      "trainer/ZF1 Loss                       87.9415\n",
      "trainer/ZF2 Loss                       89.1682\n",
      "trainer/ZF Expert Reward               17.9768\n",
      "trainer/ZF Policy Reward                9.56156\n",
      "trainer/ZF CHI2 Term                  117.072\n",
      "trainer/Policy Loss                  -530.278\n",
      "trainer/Bias Loss                      62.0762\n",
      "trainer/Bias Value                     14.9868\n",
      "trainer/Policy Grad Norm              155.901\n",
      "trainer/Policy Param Norm              37.8679\n",
      "trainer/Zf1 Grad Norm                1550.91\n",
      "trainer/Zf1 Param Norm                122.776\n",
      "trainer/Zf2 Grad Norm                1422.01\n",
      "trainer/Zf2 Param Norm                121.102\n",
      "trainer/Z Expert Predictions Mean     650.749\n",
      "trainer/Z Expert Predictions Std       55.1955\n",
      "trainer/Z Expert Predictions Max      727.73\n",
      "trainer/Z Expert Predictions Min       66.3001\n",
      "trainer/Z Policy Predictions Mean     535.108\n",
      "trainer/Z Policy Predictions Std      269.422\n",
      "trainer/Z Policy Predictions Max      712.319\n",
      "trainer/Z Policy Predictions Min     -728.852\n",
      "trainer/Z Expert Targets Mean         632.773\n",
      "trainer/Z Expert Targets Std           58.8598\n",
      "trainer/Z Expert Targets Max          715.797\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         525.546\n",
      "trainer/Z Policy Targets Std          267.624\n",
      "trainer/Z Policy Targets Max          696.792\n",
      "trainer/Z Policy Targets Min         -735.642\n",
      "trainer/Log Pis Mean                   20.3051\n",
      "trainer/Log Pis Std                     4.37474\n",
      "trainer/Policy mu Mean                  0.0679873\n",
      "trainer/Policy mu Std                   0.924345\n",
      "trainer/Policy log std Mean            -3.31421\n",
      "trainer/Policy log std Std              0.888424\n",
      "trainer/Alpha                           0.166185\n",
      "trainer/Alpha Loss                     -0.0507083\n",
      "exploration/num steps total        273443\n",
      "exploration/num paths total           376\n",
      "evaluation/num steps total              2.40463e+06\n",
      "evaluation/num paths total           2717\n",
      "evaluation/path length Mean           981\n",
      "evaluation/path length Std             57\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            810\n",
      "evaluation/Rewards Mean                 4.66901\n",
      "evaluation/Rewards Std                  1.01541\n",
      "evaluation/Rewards Max                  6.89513\n",
      "evaluation/Rewards Min                 -1.68912\n",
      "evaluation/Returns Mean              4580.3\n",
      "evaluation/Returns Std                270.044\n",
      "evaluation/Returns Max               4782.81\n",
      "evaluation/Returns Min               3810.88\n",
      "evaluation/Estimation Bias Mean       578.393\n",
      "evaluation/Estimation Bias Std        149.439\n",
      "evaluation/EB/Q_True Mean              44.1802\n",
      "evaluation/EB/Q_True Std              134.576\n",
      "evaluation/EB/Q_Pred Mean             622.573\n",
      "evaluation/EB/Q_Pred Std               65.7724\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4580.3\n",
      "evaluation/Actions Mean                 0.0216205\n",
      "evaluation/Actions Std                  0.538443\n",
      "evaluation/Actions Max                  0.999965\n",
      "evaluation/Actions Min                 -0.999603\n",
      "time/backward_policy (s)                1.88655\n",
      "time/backward_zf1 (s)                   2.03133\n",
      "time/backward_zf2 (s)                   1.95527\n",
      "time/data sampling (s)                  0.314878\n",
      "time/data storing (s)                   0.0144963\n",
      "time/evaluation sampling (s)            1.69189\n",
      "time/exploration sampling (s)           0.325363\n",
      "time/logging (s)                        0.0119621\n",
      "time/preback_alpha (s)                  0.975208\n",
      "time/preback_policy (s)                 1.08482\n",
      "time/preback_start (s)                  0.14728\n",
      "time/preback_zf (s)                     5.23062\n",
      "time/saving (s)                         0.00606486\n",
      "time/training (s)                       2.31803\n",
      "time/epoch (s)                         17.9938\n",
      "time/total (s)                       4787.39\n",
      "Epoch                                 266\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:12:24.646696 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 267 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 278000\n",
      "trainer/ZF1 Loss                       24.4712\n",
      "trainer/ZF2 Loss                       14.2138\n",
      "trainer/ZF Expert Reward               16.0678\n",
      "trainer/ZF Policy Reward                8.33591\n",
      "trainer/ZF CHI2 Term                   47.1478\n",
      "trainer/Policy Loss                  -529.897\n",
      "trainer/Bias Loss                      60.8665\n",
      "trainer/Bias Value                     14.9961\n",
      "trainer/Policy Grad Norm              153.269\n",
      "trainer/Policy Param Norm              37.8894\n",
      "trainer/Zf1 Grad Norm                1832.61\n",
      "trainer/Zf1 Param Norm                122.895\n",
      "trainer/Zf2 Grad Norm                1484.14\n",
      "trainer/Zf2 Param Norm                121.245\n",
      "trainer/Z Expert Predictions Mean     651.221\n",
      "trainer/Z Expert Predictions Std       43.8899\n",
      "trainer/Z Expert Predictions Max      723.74\n",
      "trainer/Z Expert Predictions Min      434.404\n",
      "trainer/Z Policy Predictions Mean     534.512\n",
      "trainer/Z Policy Predictions Std      263.552\n",
      "trainer/Z Policy Predictions Max      711.094\n",
      "trainer/Z Policy Predictions Min     -775.927\n",
      "trainer/Z Expert Targets Mean         635.153\n",
      "trainer/Z Expert Targets Std           45.8759\n",
      "trainer/Z Expert Targets Max          704.843\n",
      "trainer/Z Expert Targets Min          439.332\n",
      "trainer/Z Policy Targets Mean         526.176\n",
      "trainer/Z Policy Targets Std          260.147\n",
      "trainer/Z Policy Targets Max          706.657\n",
      "trainer/Z Policy Targets Min         -793.751\n",
      "trainer/Log Pis Mean                   20.2763\n",
      "trainer/Log Pis Std                     4.02029\n",
      "trainer/Policy mu Mean                  0.0387084\n",
      "trainer/Policy mu Std                   0.965598\n",
      "trainer/Policy log std Mean            -3.30541\n",
      "trainer/Policy log std Std              0.899517\n",
      "trainer/Alpha                           0.165375\n",
      "trainer/Alpha Loss                     -0.0456847\n",
      "exploration/num steps total        273443\n",
      "exploration/num paths total           376\n",
      "evaluation/num steps total              2.41463e+06\n",
      "evaluation/num paths total           2727\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68816\n",
      "evaluation/Rewards Std                  0.934021\n",
      "evaluation/Rewards Max                  6.83891\n",
      "evaluation/Rewards Min                 -1.96962\n",
      "evaluation/Returns Mean              4688.16\n",
      "evaluation/Returns Std                 92.4978\n",
      "evaluation/Returns Max               4832.92\n",
      "evaluation/Returns Min               4497.82\n",
      "evaluation/Estimation Bias Mean       582.893\n",
      "evaluation/Estimation Bias Std        141.217\n",
      "evaluation/EB/Q_True Mean              42.7397\n",
      "evaluation/EB/Q_True Std              131.618\n",
      "evaluation/EB/Q_Pred Mean             625.633\n",
      "evaluation/EB/Q_Pred Std               53.8464\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4688.16\n",
      "evaluation/Actions Mean                 0.0220819\n",
      "evaluation/Actions Std                  0.535054\n",
      "evaluation/Actions Max                  0.998757\n",
      "evaluation/Actions Min                 -0.999783\n",
      "time/backward_policy (s)                1.84715\n",
      "time/backward_zf1 (s)                   1.9669\n",
      "time/backward_zf2 (s)                   1.88562\n",
      "time/data sampling (s)                  0.311693\n",
      "time/data storing (s)                   0.0150205\n",
      "time/evaluation sampling (s)            1.73697\n",
      "time/exploration sampling (s)           0.317253\n",
      "time/logging (s)                        0.01214\n",
      "time/preback_alpha (s)                  0.952346\n",
      "time/preback_policy (s)                 1.05309\n",
      "time/preback_start (s)                  0.14534\n",
      "time/preback_zf (s)                     5.21407\n",
      "time/saving (s)                         0.00637211\n",
      "time/training (s)                       2.37598\n",
      "time/epoch (s)                         17.8399\n",
      "time/total (s)                       4805.25\n",
      "Epoch                                 267\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:12:42.841144 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 268 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 279000\n",
      "trainer/ZF1 Loss                       28.9234\n",
      "trainer/ZF2 Loss                       31.2057\n",
      "trainer/ZF Expert Reward               16.8789\n",
      "trainer/ZF Policy Reward                9.9971\n",
      "trainer/ZF CHI2 Term                   57.0339\n",
      "trainer/Policy Loss                  -532.534\n",
      "trainer/Bias Loss                      70.6861\n",
      "trainer/Bias Value                     15.0057\n",
      "trainer/Policy Grad Norm              140.341\n",
      "trainer/Policy Param Norm              37.9149\n",
      "trainer/Zf1 Grad Norm                1757.06\n",
      "trainer/Zf1 Param Norm                123.027\n",
      "trainer/Zf2 Grad Norm                1884.87\n",
      "trainer/Zf2 Param Norm                121.382\n",
      "trainer/Z Expert Predictions Mean     649.297\n",
      "trainer/Z Expert Predictions Std       44.4855\n",
      "trainer/Z Expert Predictions Max      728.213\n",
      "trainer/Z Expert Predictions Min      453.385\n",
      "trainer/Z Policy Predictions Mean     536.812\n",
      "trainer/Z Policy Predictions Std      263.001\n",
      "trainer/Z Policy Predictions Max      700.621\n",
      "trainer/Z Policy Predictions Min     -781.039\n",
      "trainer/Z Expert Targets Mean         632.418\n",
      "trainer/Z Expert Targets Std           46.6907\n",
      "trainer/Z Expert Targets Max          721.176\n",
      "trainer/Z Expert Targets Min          419.593\n",
      "trainer/Z Policy Targets Mean         526.815\n",
      "trainer/Z Policy Targets Std          259.992\n",
      "trainer/Z Policy Targets Max          700.416\n",
      "trainer/Z Policy Targets Min         -777.727\n",
      "trainer/Log Pis Mean                   20.2904\n",
      "trainer/Log Pis Std                     4.02911\n",
      "trainer/Policy mu Mean                  0.0240288\n",
      "trainer/Policy mu Std                   0.952986\n",
      "trainer/Policy log std Mean            -3.30889\n",
      "trainer/Policy log std Std              0.870449\n",
      "trainer/Alpha                           0.16483\n",
      "trainer/Alpha Loss                     -0.0478704\n",
      "exploration/num steps total        273443\n",
      "exploration/num paths total           376\n",
      "evaluation/num steps total              2.42463e+06\n",
      "evaluation/num paths total           2737\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64518\n",
      "evaluation/Rewards Std                  0.997434\n",
      "evaluation/Rewards Max                  6.57733\n",
      "evaluation/Rewards Min                 -2.80066\n",
      "evaluation/Returns Mean              4645.18\n",
      "evaluation/Returns Std                115.782\n",
      "evaluation/Returns Max               4772.98\n",
      "evaluation/Returns Min               4350.36\n",
      "evaluation/Estimation Bias Mean       575.31\n",
      "evaluation/Estimation Bias Std        135.527\n",
      "evaluation/EB/Q_True Mean              39.7705\n",
      "evaluation/EB/Q_True Std              123.749\n",
      "evaluation/EB/Q_Pred Mean             615.08\n",
      "evaluation/EB/Q_Pred Std               63.354\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4645.18\n",
      "evaluation/Actions Mean                 0.0261561\n",
      "evaluation/Actions Std                  0.536763\n",
      "evaluation/Actions Max                  0.999236\n",
      "evaluation/Actions Min                 -0.999546\n",
      "time/backward_policy (s)                1.91604\n",
      "time/backward_zf1 (s)                   2.06312\n",
      "time/backward_zf2 (s)                   1.99466\n",
      "time/data sampling (s)                  0.28833\n",
      "time/data storing (s)                   0.0148691\n",
      "time/evaluation sampling (s)            1.78749\n",
      "time/exploration sampling (s)           0.321959\n",
      "time/logging (s)                        0.0127222\n",
      "time/preback_alpha (s)                  0.991571\n",
      "time/preback_policy (s)                 1.11667\n",
      "time/preback_start (s)                  0.146889\n",
      "time/preback_zf (s)                     5.20787\n",
      "time/saving (s)                         0.00599462\n",
      "time/training (s)                       2.25423\n",
      "time/epoch (s)                         18.1224\n",
      "time/total (s)                       4823.4\n",
      "Epoch                                 268\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:13:01.185494 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 269 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 280000\n",
      "trainer/ZF1 Loss                       29.4213\n",
      "trainer/ZF2 Loss                       28.4673\n",
      "trainer/ZF Expert Reward               15.333\n",
      "trainer/ZF Policy Reward                3.38436\n",
      "trainer/ZF CHI2 Term                   61.0805\n",
      "trainer/Policy Loss                  -533.073\n",
      "trainer/Bias Loss                      56.9792\n",
      "trainer/Bias Value                     15.0162\n",
      "trainer/Policy Grad Norm              152.914\n",
      "trainer/Policy Param Norm              37.9431\n",
      "trainer/Zf1 Grad Norm                1789.75\n",
      "trainer/Zf1 Param Norm                123.141\n",
      "trainer/Zf2 Grad Norm                1352.18\n",
      "trainer/Zf2 Param Norm                121.498\n",
      "trainer/Z Expert Predictions Mean     647.21\n",
      "trainer/Z Expert Predictions Std       46.3664\n",
      "trainer/Z Expert Predictions Max      720.924\n",
      "trainer/Z Expert Predictions Min      415.516\n",
      "trainer/Z Policy Predictions Mean     532.811\n",
      "trainer/Z Policy Predictions Std      250.134\n",
      "trainer/Z Policy Predictions Max      692.315\n",
      "trainer/Z Policy Predictions Min     -744.676\n",
      "trainer/Z Expert Targets Mean         631.877\n",
      "trainer/Z Expert Targets Std           49.315\n",
      "trainer/Z Expert Targets Max          720.071\n",
      "trainer/Z Expert Targets Min          390.268\n",
      "trainer/Z Policy Targets Mean         529.427\n",
      "trainer/Z Policy Targets Std          244.522\n",
      "trainer/Z Policy Targets Max          674.583\n",
      "trainer/Z Policy Targets Min         -725.547\n",
      "trainer/Log Pis Mean                   20.3914\n",
      "trainer/Log Pis Std                     3.9487\n",
      "trainer/Policy mu Mean                  0.0298734\n",
      "trainer/Policy mu Std                   0.892631\n",
      "trainer/Policy log std Mean            -3.37518\n",
      "trainer/Policy log std Std              0.851638\n",
      "trainer/Alpha                           0.164789\n",
      "trainer/Alpha Loss                     -0.0644999\n",
      "exploration/num steps total        274443\n",
      "exploration/num paths total           377\n",
      "evaluation/num steps total              2.43368e+06\n",
      "evaluation/num paths total           2747\n",
      "evaluation/path length Mean           904.7\n",
      "evaluation/path length Std            285.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             47\n",
      "evaluation/Rewards Mean                 4.68864\n",
      "evaluation/Rewards Std                  1.03675\n",
      "evaluation/Rewards Max                  6.76151\n",
      "evaluation/Rewards Min                 -1.87067\n",
      "evaluation/Returns Mean              4241.81\n",
      "evaluation/Returns Std               1380.17\n",
      "evaluation/Returns Max               4935.7\n",
      "evaluation/Returns Min                122.262\n",
      "evaluation/Estimation Bias Mean       549.283\n",
      "evaluation/Estimation Bias Std        155.453\n",
      "evaluation/EB/Q_True Mean              47.7431\n",
      "evaluation/EB/Q_True Std              139.382\n",
      "evaluation/EB/Q_Pred Mean             597.026\n",
      "evaluation/EB/Q_Pred Std               62.3062\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4241.81\n",
      "evaluation/Actions Mean                 0.0230579\n",
      "evaluation/Actions Std                  0.533479\n",
      "evaluation/Actions Max                  0.99979\n",
      "evaluation/Actions Min                 -0.999915\n",
      "time/backward_policy (s)                1.95903\n",
      "time/backward_zf1 (s)                   2.09861\n",
      "time/backward_zf2 (s)                   2.02439\n",
      "time/data sampling (s)                  0.293834\n",
      "time/data storing (s)                   0.0148556\n",
      "time/evaluation sampling (s)            1.73016\n",
      "time/exploration sampling (s)           0.319286\n",
      "time/logging (s)                        0.0115535\n",
      "time/preback_alpha (s)                  1.00761\n",
      "time/preback_policy (s)                 1.13884\n",
      "time/preback_start (s)                  0.148588\n",
      "time/preback_zf (s)                     5.22246\n",
      "time/saving (s)                         0.00587208\n",
      "time/training (s)                       2.2877\n",
      "time/epoch (s)                         18.2628\n",
      "time/total (s)                       4841.69\n",
      "Epoch                                 269\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:13:18.926732 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 270 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 281000\n",
      "trainer/ZF1 Loss                       17.3172\n",
      "trainer/ZF2 Loss                       12.3621\n",
      "trainer/ZF Expert Reward               12.7197\n",
      "trainer/ZF Policy Reward               -1.00923\n",
      "trainer/ZF CHI2 Term                   48.5921\n",
      "trainer/Policy Loss                  -506.106\n",
      "trainer/Bias Loss                      64.2537\n",
      "trainer/Bias Value                     15.0259\n",
      "trainer/Policy Grad Norm              178.179\n",
      "trainer/Policy Param Norm              37.9645\n",
      "trainer/Zf1 Grad Norm                1888.51\n",
      "trainer/Zf1 Param Norm                123.265\n",
      "trainer/Zf2 Grad Norm                1527.82\n",
      "trainer/Zf2 Param Norm                121.639\n",
      "trainer/Z Expert Predictions Mean     637.206\n",
      "trainer/Z Expert Predictions Std       45.3768\n",
      "trainer/Z Expert Predictions Max      728.937\n",
      "trainer/Z Expert Predictions Min      429.324\n",
      "trainer/Z Policy Predictions Mean     505.022\n",
      "trainer/Z Policy Predictions Std      291.241\n",
      "trainer/Z Policy Predictions Max      687.021\n",
      "trainer/Z Policy Predictions Min     -795.256\n",
      "trainer/Z Expert Targets Mean         624.486\n",
      "trainer/Z Expert Targets Std           47.1034\n",
      "trainer/Z Expert Targets Max          720.72\n",
      "trainer/Z Expert Targets Min          427.688\n",
      "trainer/Z Policy Targets Mean         506.031\n",
      "trainer/Z Policy Targets Std          284.472\n",
      "trainer/Z Policy Targets Max          683.149\n",
      "trainer/Z Policy Targets Min         -779.375\n",
      "trainer/Log Pis Mean                   20.2258\n",
      "trainer/Log Pis Std                     4.37263\n",
      "trainer/Policy mu Mean                  0.0669683\n",
      "trainer/Policy mu Std                   0.998125\n",
      "trainer/Policy log std Mean            -3.29083\n",
      "trainer/Policy log std Std              0.952334\n",
      "trainer/Alpha                           0.165975\n",
      "trainer/Alpha Loss                     -0.0374734\n",
      "exploration/num steps total        275443\n",
      "exploration/num paths total           378\n",
      "evaluation/num steps total              2.44368e+06\n",
      "evaluation/num paths total           2757\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6292\n",
      "evaluation/Rewards Std                  0.922322\n",
      "evaluation/Rewards Max                  6.76234\n",
      "evaluation/Rewards Min                 -1.43397\n",
      "evaluation/Returns Mean              4629.2\n",
      "evaluation/Returns Std                 44.4183\n",
      "evaluation/Returns Max               4731.39\n",
      "evaluation/Returns Min               4575.89\n",
      "evaluation/Estimation Bias Mean       572.916\n",
      "evaluation/Estimation Bias Std        143.662\n",
      "evaluation/EB/Q_True Mean              43.6519\n",
      "evaluation/EB/Q_True Std              134.165\n",
      "evaluation/EB/Q_Pred Mean             616.568\n",
      "evaluation/EB/Q_Pred Std               55.8736\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4629.2\n",
      "evaluation/Actions Mean                 0.0173176\n",
      "evaluation/Actions Std                  0.538918\n",
      "evaluation/Actions Max                  0.999426\n",
      "evaluation/Actions Min                 -0.999478\n",
      "time/backward_policy (s)                1.80911\n",
      "time/backward_zf1 (s)                   1.94255\n",
      "time/backward_zf2 (s)                   1.8551\n",
      "time/data sampling (s)                  0.317934\n",
      "time/data storing (s)                   0.0148746\n",
      "time/evaluation sampling (s)            1.69717\n",
      "time/exploration sampling (s)           0.323538\n",
      "time/logging (s)                        0.0123449\n",
      "time/preback_alpha (s)                  0.929746\n",
      "time/preback_policy (s)                 1.03319\n",
      "time/preback_start (s)                  0.145983\n",
      "time/preback_zf (s)                     5.16788\n",
      "time/saving (s)                         0.00577815\n",
      "time/training (s)                       2.40682\n",
      "time/epoch (s)                         17.662\n",
      "time/total (s)                       4859.39\n",
      "Epoch                                 270\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:13:37.332745 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 271 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 282000\n",
      "trainer/ZF1 Loss                       76.4887\n",
      "trainer/ZF2 Loss                       55.1004\n",
      "trainer/ZF Expert Reward               14.9857\n",
      "trainer/ZF Policy Reward                6.35583\n",
      "trainer/ZF CHI2 Term                   94.0624\n",
      "trainer/Policy Loss                  -524.89\n",
      "trainer/Bias Loss                      58.2355\n",
      "trainer/Bias Value                     15.0381\n",
      "trainer/Policy Grad Norm              174.081\n",
      "trainer/Policy Param Norm              37.9868\n",
      "trainer/Zf1 Grad Norm                1547.32\n",
      "trainer/Zf1 Param Norm                123.398\n",
      "trainer/Zf2 Grad Norm                1429.78\n",
      "trainer/Zf2 Param Norm                121.771\n",
      "trainer/Z Expert Predictions Mean     638.678\n",
      "trainer/Z Expert Predictions Std       44.628\n",
      "trainer/Z Expert Predictions Max      711.487\n",
      "trainer/Z Expert Predictions Min      434.345\n",
      "trainer/Z Policy Predictions Mean     525.01\n",
      "trainer/Z Policy Predictions Std      248.207\n",
      "trainer/Z Policy Predictions Max      704.342\n",
      "trainer/Z Policy Predictions Min     -757.705\n",
      "trainer/Z Expert Targets Mean         623.693\n",
      "trainer/Z Expert Targets Std           46.7573\n",
      "trainer/Z Expert Targets Max          711.672\n",
      "trainer/Z Expert Targets Min          393.978\n",
      "trainer/Z Policy Targets Mean         518.654\n",
      "trainer/Z Policy Targets Std          247.914\n",
      "trainer/Z Policy Targets Max          686.106\n",
      "trainer/Z Policy Targets Min         -766.851\n",
      "trainer/Log Pis Mean                   19.8364\n",
      "trainer/Log Pis Std                     4.24992\n",
      "trainer/Policy mu Mean                  0.0468284\n",
      "trainer/Policy mu Std                   0.965271\n",
      "trainer/Policy log std Mean            -3.27213\n",
      "trainer/Policy log std Std              0.905242\n",
      "trainer/Alpha                           0.167289\n",
      "trainer/Alpha Loss                      0.0273649\n",
      "exploration/num steps total        275443\n",
      "exploration/num paths total           378\n",
      "evaluation/num steps total              2.45368e+06\n",
      "evaluation/num paths total           2767\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.76155\n",
      "evaluation/Rewards Std                  0.964264\n",
      "evaluation/Rewards Max                  7.16608\n",
      "evaluation/Rewards Min                 -1.63029\n",
      "evaluation/Returns Mean              4761.55\n",
      "evaluation/Returns Std                 49.2719\n",
      "evaluation/Returns Max               4850.62\n",
      "evaluation/Returns Min               4693.65\n",
      "evaluation/Estimation Bias Mean       561.57\n",
      "evaluation/Estimation Bias Std        147.585\n",
      "evaluation/EB/Q_True Mean              43.6859\n",
      "evaluation/EB/Q_True Std              134.457\n",
      "evaluation/EB/Q_Pred Mean             605.256\n",
      "evaluation/EB/Q_Pred Std               59.0053\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4761.55\n",
      "evaluation/Actions Mean                 0.0210177\n",
      "evaluation/Actions Std                  0.53283\n",
      "evaluation/Actions Max                  0.999165\n",
      "evaluation/Actions Min                 -0.99988\n",
      "time/backward_policy (s)                1.95854\n",
      "time/backward_zf1 (s)                   2.11076\n",
      "time/backward_zf2 (s)                   2.05571\n",
      "time/data sampling (s)                  0.304549\n",
      "time/data storing (s)                   0.0159519\n",
      "time/evaluation sampling (s)            1.71726\n",
      "time/exploration sampling (s)           0.325836\n",
      "time/logging (s)                        0.011656\n",
      "time/preback_alpha (s)                  1.027\n",
      "time/preback_policy (s)                 1.16465\n",
      "time/preback_start (s)                  0.149381\n",
      "time/preback_zf (s)                     5.26361\n",
      "time/saving (s)                         0.00569742\n",
      "time/training (s)                       2.22105\n",
      "time/epoch (s)                         18.3316\n",
      "time/total (s)                       4877.74\n",
      "Epoch                                 271\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:13:55.363669 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 272 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 283000\n",
      "trainer/ZF1 Loss                       13.7593\n",
      "trainer/ZF2 Loss                        5.58707\n",
      "trainer/ZF Expert Reward               14.6578\n",
      "trainer/ZF Policy Reward                2.61036\n",
      "trainer/ZF CHI2 Term                   41.3018\n",
      "trainer/Policy Loss                  -517.979\n",
      "trainer/Bias Loss                      80.178\n",
      "trainer/Bias Value                     15.0473\n",
      "trainer/Policy Grad Norm              187.611\n",
      "trainer/Policy Param Norm              38.0072\n",
      "trainer/Zf1 Grad Norm                1636.86\n",
      "trainer/Zf1 Param Norm                123.521\n",
      "trainer/Zf2 Grad Norm                1300.5\n",
      "trainer/Zf2 Param Norm                121.895\n",
      "trainer/Z Expert Predictions Mean     637.011\n",
      "trainer/Z Expert Predictions Std       47.6217\n",
      "trainer/Z Expert Predictions Max      726.54\n",
      "trainer/Z Expert Predictions Min      392.664\n",
      "trainer/Z Policy Predictions Mean     519.563\n",
      "trainer/Z Policy Predictions Std      266.952\n",
      "trainer/Z Policy Predictions Max      697.093\n",
      "trainer/Z Policy Predictions Min     -775.67\n",
      "trainer/Z Expert Targets Mean         622.353\n",
      "trainer/Z Expert Targets Std           52.3208\n",
      "trainer/Z Expert Targets Max          700.378\n",
      "trainer/Z Expert Targets Min          357.762\n",
      "trainer/Z Policy Targets Mean         516.953\n",
      "trainer/Z Policy Targets Std          267.119\n",
      "trainer/Z Policy Targets Max          682.583\n",
      "trainer/Z Policy Targets Min         -774.145\n",
      "trainer/Log Pis Mean                   19.7789\n",
      "trainer/Log Pis Std                     4.18097\n",
      "trainer/Policy mu Mean                  0.0341081\n",
      "trainer/Policy mu Std                   0.888477\n",
      "trainer/Policy log std Mean            -3.32374\n",
      "trainer/Policy log std Std              0.854572\n",
      "trainer/Alpha                           0.167563\n",
      "trainer/Alpha Loss                      0.0370415\n",
      "exploration/num steps total        277443\n",
      "exploration/num paths total           380\n",
      "evaluation/num steps total              2.46368e+06\n",
      "evaluation/num paths total           2777\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69317\n",
      "evaluation/Rewards Std                  0.979869\n",
      "evaluation/Rewards Max                  7.00234\n",
      "evaluation/Rewards Min                 -1.39823\n",
      "evaluation/Returns Mean              4693.17\n",
      "evaluation/Returns Std                 74.9278\n",
      "evaluation/Returns Max               4793.99\n",
      "evaluation/Returns Min               4532.93\n",
      "evaluation/Estimation Bias Mean       563.565\n",
      "evaluation/Estimation Bias Std        149.661\n",
      "evaluation/EB/Q_True Mean              43.6893\n",
      "evaluation/EB/Q_True Std              134.701\n",
      "evaluation/EB/Q_Pred Mean             607.254\n",
      "evaluation/EB/Q_Pred Std               59.4647\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4693.17\n",
      "evaluation/Actions Mean                 0.0212497\n",
      "evaluation/Actions Std                  0.534897\n",
      "evaluation/Actions Max                  0.999587\n",
      "evaluation/Actions Min                 -0.999381\n",
      "time/backward_policy (s)                1.91879\n",
      "time/backward_zf1 (s)                   2.06188\n",
      "time/backward_zf2 (s)                   1.97774\n",
      "time/data sampling (s)                  0.300747\n",
      "time/data storing (s)                   0.0143298\n",
      "time/evaluation sampling (s)            1.73652\n",
      "time/exploration sampling (s)           0.317929\n",
      "time/logging (s)                        0.0121107\n",
      "time/preback_alpha (s)                  0.992633\n",
      "time/preback_policy (s)                 1.10436\n",
      "time/preback_start (s)                  0.146471\n",
      "time/preback_zf (s)                     5.16925\n",
      "time/saving (s)                         0.00571294\n",
      "time/training (s)                       2.20421\n",
      "time/epoch (s)                         17.9627\n",
      "time/total (s)                       4895.72\n",
      "Epoch                                 272\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:14:13.505556 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 273 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 284000\n",
      "trainer/ZF1 Loss                       17.0273\n",
      "trainer/ZF2 Loss                       15.6073\n",
      "trainer/ZF Expert Reward               16.2065\n",
      "trainer/ZF Policy Reward                7.61132\n",
      "trainer/ZF CHI2 Term                   45.0267\n",
      "trainer/Policy Loss                  -534.369\n",
      "trainer/Bias Loss                      56.2064\n",
      "trainer/Bias Value                     15.0607\n",
      "trainer/Policy Grad Norm              161.019\n",
      "trainer/Policy Param Norm              38.0312\n",
      "trainer/Zf1 Grad Norm                1264.02\n",
      "trainer/Zf1 Param Norm                123.666\n",
      "trainer/Zf2 Grad Norm                1433.4\n",
      "trainer/Zf2 Param Norm                122.028\n",
      "trainer/Z Expert Predictions Mean     638.189\n",
      "trainer/Z Expert Predictions Std       41.1298\n",
      "trainer/Z Expert Predictions Max      711.678\n",
      "trainer/Z Expert Predictions Min      418.472\n",
      "trainer/Z Policy Predictions Mean     539.542\n",
      "trainer/Z Policy Predictions Std      208.42\n",
      "trainer/Z Policy Predictions Max      694.504\n",
      "trainer/Z Policy Predictions Min     -752.398\n",
      "trainer/Z Expert Targets Mean         621.982\n",
      "trainer/Z Expert Targets Std           43.4519\n",
      "trainer/Z Expert Targets Max          700.807\n",
      "trainer/Z Expert Targets Min          395.604\n",
      "trainer/Z Policy Targets Mean         531.931\n",
      "trainer/Z Policy Targets Std          204.196\n",
      "trainer/Z Policy Targets Max          688.749\n",
      "trainer/Z Policy Targets Min         -706.615\n",
      "trainer/Log Pis Mean                   20.3174\n",
      "trainer/Log Pis Std                     4.16675\n",
      "trainer/Policy mu Mean                  0.018044\n",
      "trainer/Policy mu Std                   0.920003\n",
      "trainer/Policy log std Mean            -3.35275\n",
      "trainer/Policy log std Std              0.820246\n",
      "trainer/Alpha                           0.167546\n",
      "trainer/Alpha Loss                     -0.0531792\n",
      "exploration/num steps total        279443\n",
      "exploration/num paths total           382\n",
      "evaluation/num steps total              2.47368e+06\n",
      "evaluation/num paths total           2787\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.59284\n",
      "evaluation/Rewards Std                  0.961934\n",
      "evaluation/Rewards Max                  6.66633\n",
      "evaluation/Rewards Min                 -1.40135\n",
      "evaluation/Returns Mean              4592.84\n",
      "evaluation/Returns Std                 72.6881\n",
      "evaluation/Returns Max               4742.48\n",
      "evaluation/Returns Min               4488.66\n",
      "evaluation/Estimation Bias Mean       560.053\n",
      "evaluation/Estimation Bias Std        140.141\n",
      "evaluation/EB/Q_True Mean              41.2045\n",
      "evaluation/EB/Q_True Std              126.973\n",
      "evaluation/EB/Q_Pred Mean             601.258\n",
      "evaluation/EB/Q_Pred Std               60.6199\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4592.84\n",
      "evaluation/Actions Mean                 0.017883\n",
      "evaluation/Actions Std                  0.53696\n",
      "evaluation/Actions Max                  0.999539\n",
      "evaluation/Actions Min                 -0.999613\n",
      "time/backward_policy (s)                1.88528\n",
      "time/backward_zf1 (s)                   2.02801\n",
      "time/backward_zf2 (s)                   1.94719\n",
      "time/data sampling (s)                  0.299511\n",
      "time/data storing (s)                   0.0145275\n",
      "time/evaluation sampling (s)            1.78439\n",
      "time/exploration sampling (s)           0.322568\n",
      "time/logging (s)                        0.0125266\n",
      "time/preback_alpha (s)                  0.96303\n",
      "time/preback_policy (s)                 1.07848\n",
      "time/preback_start (s)                  0.148473\n",
      "time/preback_zf (s)                     5.21376\n",
      "time/saving (s)                         0.00630667\n",
      "time/training (s)                       2.36722\n",
      "time/epoch (s)                         18.0713\n",
      "time/total (s)                       4913.82\n",
      "Epoch                                 273\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:14:31.795670 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 274 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 285000\n",
      "trainer/ZF1 Loss                       23.3672\n",
      "trainer/ZF2 Loss                       29.1332\n",
      "trainer/ZF Expert Reward               15.1643\n",
      "trainer/ZF Policy Reward                7.34899\n",
      "trainer/ZF CHI2 Term                   53.8147\n",
      "trainer/Policy Loss                  -511.549\n",
      "trainer/Bias Loss                      59.2098\n",
      "trainer/Bias Value                     15.0717\n",
      "trainer/Policy Grad Norm              165.515\n",
      "trainer/Policy Param Norm              38.0566\n",
      "trainer/Zf1 Grad Norm                1447.1\n",
      "trainer/Zf1 Param Norm                123.785\n",
      "trainer/Zf2 Grad Norm                1476.39\n",
      "trainer/Zf2 Param Norm                122.165\n",
      "trainer/Z Expert Predictions Mean     634.765\n",
      "trainer/Z Expert Predictions Std       40.9618\n",
      "trainer/Z Expert Predictions Max      709.537\n",
      "trainer/Z Expert Predictions Min      411.213\n",
      "trainer/Z Policy Predictions Mean     515.322\n",
      "trainer/Z Policy Predictions Std      249.909\n",
      "trainer/Z Policy Predictions Max      669.628\n",
      "trainer/Z Policy Predictions Min     -705.126\n",
      "trainer/Z Expert Targets Mean         619.601\n",
      "trainer/Z Expert Targets Std           43.5252\n",
      "trainer/Z Expert Targets Max          691.756\n",
      "trainer/Z Expert Targets Min          397.872\n",
      "trainer/Z Policy Targets Mean         507.973\n",
      "trainer/Z Policy Targets Std          245.488\n",
      "trainer/Z Policy Targets Max          686.474\n",
      "trainer/Z Policy Targets Min         -690.656\n",
      "trainer/Log Pis Mean                   19.9488\n",
      "trainer/Log Pis Std                     4.05232\n",
      "trainer/Policy mu Mean                  0.0299359\n",
      "trainer/Policy mu Std                   0.896634\n",
      "trainer/Policy log std Mean            -3.32905\n",
      "trainer/Policy log std Std              0.884588\n",
      "trainer/Alpha                           0.16692\n",
      "trainer/Alpha Loss                      0.00855337\n",
      "exploration/num steps total        280443\n",
      "exploration/num paths total           383\n",
      "evaluation/num steps total              2.48368e+06\n",
      "evaluation/num paths total           2797\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62725\n",
      "evaluation/Rewards Std                  0.91878\n",
      "evaluation/Rewards Max                  6.58861\n",
      "evaluation/Rewards Min                 -1.52286\n",
      "evaluation/Returns Mean              4627.25\n",
      "evaluation/Returns Std                 67.1335\n",
      "evaluation/Returns Max               4734.62\n",
      "evaluation/Returns Min               4511.76\n",
      "evaluation/Estimation Bias Mean       559.692\n",
      "evaluation/Estimation Bias Std        138.622\n",
      "evaluation/EB/Q_True Mean              42.2963\n",
      "evaluation/EB/Q_True Std              130.635\n",
      "evaluation/EB/Q_Pred Mean             601.989\n",
      "evaluation/EB/Q_Pred Std               53.6162\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4627.25\n",
      "evaluation/Actions Mean                 0.0215742\n",
      "evaluation/Actions Std                  0.535834\n",
      "evaluation/Actions Max                  0.998906\n",
      "evaluation/Actions Min                 -0.999601\n",
      "time/backward_policy (s)                1.95209\n",
      "time/backward_zf1 (s)                   2.09153\n",
      "time/backward_zf2 (s)                   2.01921\n",
      "time/data sampling (s)                  0.303516\n",
      "time/data storing (s)                   0.0159636\n",
      "time/evaluation sampling (s)            1.7502\n",
      "time/exploration sampling (s)           0.332317\n",
      "time/logging (s)                        0.0117735\n",
      "time/preback_alpha (s)                  1.01915\n",
      "time/preback_policy (s)                 1.14474\n",
      "time/preback_start (s)                  0.151154\n",
      "time/preback_zf (s)                     5.21871\n",
      "time/saving (s)                         0.00757738\n",
      "time/training (s)                       2.20228\n",
      "time/epoch (s)                         18.2202\n",
      "time/total (s)                       4932.06\n",
      "Epoch                                 274\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:14:50.321915 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 275 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 286000\n",
      "trainer/ZF1 Loss                       13.0744\n",
      "trainer/ZF2 Loss                        6.44294\n",
      "trainer/ZF Expert Reward               12.4749\n",
      "trainer/ZF Policy Reward               -0.985532\n",
      "trainer/ZF CHI2 Term                   43.3332\n",
      "trainer/Policy Loss                  -501.629\n",
      "trainer/Bias Loss                      67.4091\n",
      "trainer/Bias Value                     15.0835\n",
      "trainer/Policy Grad Norm              167.376\n",
      "trainer/Policy Param Norm              38.0802\n",
      "trainer/Zf1 Grad Norm                1720.16\n",
      "trainer/Zf1 Param Norm                123.904\n",
      "trainer/Zf2 Grad Norm                1607.99\n",
      "trainer/Zf2 Param Norm                122.288\n",
      "trainer/Z Expert Predictions Mean     623.363\n",
      "trainer/Z Expert Predictions Std       45.3735\n",
      "trainer/Z Expert Predictions Max      704.151\n",
      "trainer/Z Expert Predictions Min      360.764\n",
      "trainer/Z Policy Predictions Mean     501.772\n",
      "trainer/Z Policy Predictions Std      264.108\n",
      "trainer/Z Policy Predictions Max      684.08\n",
      "trainer/Z Policy Predictions Min     -758.26\n",
      "trainer/Z Expert Targets Mean         610.888\n",
      "trainer/Z Expert Targets Std           47.2639\n",
      "trainer/Z Expert Targets Max          687.035\n",
      "trainer/Z Expert Targets Min          345.838\n",
      "trainer/Z Policy Targets Mean         502.757\n",
      "trainer/Z Policy Targets Std          259.206\n",
      "trainer/Z Policy Targets Max          674.46\n",
      "trainer/Z Policy Targets Min         -756.749\n",
      "trainer/Log Pis Mean                   20.3173\n",
      "trainer/Log Pis Std                     4.52196\n",
      "trainer/Policy mu Mean                  0.0182803\n",
      "trainer/Policy mu Std                   0.958493\n",
      "trainer/Policy log std Mean            -3.32129\n",
      "trainer/Policy log std Std              0.932378\n",
      "trainer/Alpha                           0.167674\n",
      "trainer/Alpha Loss                     -0.0531965\n",
      "exploration/num steps total        281443\n",
      "exploration/num paths total           384\n",
      "evaluation/num steps total              2.49368e+06\n",
      "evaluation/num paths total           2807\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66418\n",
      "evaluation/Rewards Std                  1.00944\n",
      "evaluation/Rewards Max                  6.86389\n",
      "evaluation/Rewards Min                 -1.8512\n",
      "evaluation/Returns Mean              4664.18\n",
      "evaluation/Returns Std                 74.5037\n",
      "evaluation/Returns Max               4802.7\n",
      "evaluation/Returns Min               4511.47\n",
      "evaluation/Estimation Bias Mean       550.676\n",
      "evaluation/Estimation Bias Std        145.27\n",
      "evaluation/EB/Q_True Mean              43.093\n",
      "evaluation/EB/Q_True Std              132.696\n",
      "evaluation/EB/Q_Pred Mean             593.769\n",
      "evaluation/EB/Q_Pred Std               59.1032\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4664.18\n",
      "evaluation/Actions Mean                 0.0205538\n",
      "evaluation/Actions Std                  0.540315\n",
      "evaluation/Actions Max                  0.999253\n",
      "evaluation/Actions Min                 -0.999868\n",
      "time/backward_policy (s)                2.01214\n",
      "time/backward_zf1 (s)                   2.15461\n",
      "time/backward_zf2 (s)                   2.09224\n",
      "time/data sampling (s)                  0.318086\n",
      "time/data storing (s)                   0.0148755\n",
      "time/evaluation sampling (s)            1.74139\n",
      "time/exploration sampling (s)           0.326517\n",
      "time/logging (s)                        0.0120496\n",
      "time/preback_alpha (s)                  1.057\n",
      "time/preback_policy (s)                 1.19186\n",
      "time/preback_start (s)                  0.151168\n",
      "time/preback_zf (s)                     5.22329\n",
      "time/saving (s)                         0.006118\n",
      "time/training (s)                       2.14836\n",
      "time/epoch (s)                         18.4497\n",
      "time/total (s)                       4950.53\n",
      "Epoch                                 275\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:15:08.687171 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 276 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 287000\n",
      "trainer/ZF1 Loss                       73.8982\n",
      "trainer/ZF2 Loss                       63.8858\n",
      "trainer/ZF Expert Reward               14.4973\n",
      "trainer/ZF Policy Reward                4.75683\n",
      "trainer/ZF CHI2 Term                   98.2257\n",
      "trainer/Policy Loss                  -486.259\n",
      "trainer/Bias Loss                      56.1333\n",
      "trainer/Bias Value                     15.095\n",
      "trainer/Policy Grad Norm              213.424\n",
      "trainer/Policy Param Norm              38.1039\n",
      "trainer/Zf1 Grad Norm                1351.7\n",
      "trainer/Zf1 Param Norm                124.029\n",
      "trainer/Zf2 Grad Norm                2001.84\n",
      "trainer/Zf2 Param Norm                122.412\n",
      "trainer/Z Expert Predictions Mean     619.526\n",
      "trainer/Z Expert Predictions Std       62.2472\n",
      "trainer/Z Expert Predictions Max      696.785\n",
      "trainer/Z Expert Predictions Min       18.8295\n",
      "trainer/Z Policy Predictions Mean     488.062\n",
      "trainer/Z Policy Predictions Std      282.715\n",
      "trainer/Z Policy Predictions Max      675.484\n",
      "trainer/Z Policy Predictions Min     -771.449\n",
      "trainer/Z Expert Targets Mean         605.029\n",
      "trainer/Z Expert Targets Std           63.6646\n",
      "trainer/Z Expert Targets Max          692.064\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         483.305\n",
      "trainer/Z Policy Targets Std          278.245\n",
      "trainer/Z Policy Targets Max          674.92\n",
      "trainer/Z Policy Targets Min         -754.807\n",
      "trainer/Log Pis Mean                   19.7911\n",
      "trainer/Log Pis Std                     4.57409\n",
      "trainer/Policy mu Mean                  0.0113169\n",
      "trainer/Policy mu Std                   0.939775\n",
      "trainer/Policy log std Mean            -3.26112\n",
      "trainer/Policy log std Std              0.961437\n",
      "trainer/Alpha                           0.168795\n",
      "trainer/Alpha Loss                      0.0352599\n",
      "exploration/num steps total        283443\n",
      "exploration/num paths total           386\n",
      "evaluation/num steps total              2.50047e+06\n",
      "evaluation/num paths total           2817\n",
      "evaluation/path length Mean           679.1\n",
      "evaluation/path length Std            398.918\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             68\n",
      "evaluation/Rewards Mean                 4.73358\n",
      "evaluation/Rewards Std                  1.08338\n",
      "evaluation/Rewards Max                  6.86084\n",
      "evaluation/Rewards Min                 -2.0374\n",
      "evaluation/Returns Mean              3214.58\n",
      "evaluation/Returns Std               1956.18\n",
      "evaluation/Returns Max               4891.66\n",
      "evaluation/Returns Min                207.864\n",
      "evaluation/Estimation Bias Mean       518.914\n",
      "evaluation/Estimation Bias Std        191.037\n",
      "evaluation/EB/Q_True Mean              66.5303\n",
      "evaluation/EB/Q_True Std              164.501\n",
      "evaluation/EB/Q_Pred Mean             585.444\n",
      "evaluation/EB/Q_Pred Std               68.6061\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3214.58\n",
      "evaluation/Actions Mean                 0.0235751\n",
      "evaluation/Actions Std                  0.543829\n",
      "evaluation/Actions Max                  0.99994\n",
      "evaluation/Actions Min                 -0.99973\n",
      "time/backward_policy (s)                1.93789\n",
      "time/backward_zf1 (s)                   2.0727\n",
      "time/backward_zf2 (s)                   2.00923\n",
      "time/data sampling (s)                  0.314661\n",
      "time/data storing (s)                   0.014772\n",
      "time/evaluation sampling (s)            1.73451\n",
      "time/exploration sampling (s)           0.324862\n",
      "time/logging (s)                        0.00873482\n",
      "time/preback_alpha (s)                  1.02661\n",
      "time/preback_policy (s)                 1.16992\n",
      "time/preback_start (s)                  0.15256\n",
      "time/preback_zf (s)                     5.26102\n",
      "time/saving (s)                         0.00582003\n",
      "time/training (s)                       2.25855\n",
      "time/epoch (s)                         18.2918\n",
      "time/total (s)                       4968.84\n",
      "Epoch                                 276\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:15:26.832017 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 277 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 288000\n",
      "trainer/ZF1 Loss                       19.9428\n",
      "trainer/ZF2 Loss                       17.8824\n",
      "trainer/ZF Expert Reward               14.3858\n",
      "trainer/ZF Policy Reward                4.13745\n",
      "trainer/ZF CHI2 Term                   49.0907\n",
      "trainer/Policy Loss                  -520.063\n",
      "trainer/Bias Loss                      68.0782\n",
      "trainer/Bias Value                     15.1064\n",
      "trainer/Policy Grad Norm              203.262\n",
      "trainer/Policy Param Norm              38.129\n",
      "trainer/Zf1 Grad Norm                1613.7\n",
      "trainer/Zf1 Param Norm                124.153\n",
      "trainer/Zf2 Grad Norm                1485.81\n",
      "trainer/Zf2 Param Norm                122.539\n",
      "trainer/Z Expert Predictions Mean     624.843\n",
      "trainer/Z Expert Predictions Std       39.9025\n",
      "trainer/Z Expert Predictions Max      709.04\n",
      "trainer/Z Expert Predictions Min      440.881\n",
      "trainer/Z Policy Predictions Mean     523.492\n",
      "trainer/Z Policy Predictions Std      225.347\n",
      "trainer/Z Policy Predictions Max      671.957\n",
      "trainer/Z Policy Predictions Min     -694.22\n",
      "trainer/Z Expert Targets Mean         610.457\n",
      "trainer/Z Expert Targets Std           41.5076\n",
      "trainer/Z Expert Targets Max          696.166\n",
      "trainer/Z Expert Targets Min          418.678\n",
      "trainer/Z Policy Targets Mean         519.355\n",
      "trainer/Z Policy Targets Std          220.868\n",
      "trainer/Z Policy Targets Max          666.783\n",
      "trainer/Z Policy Targets Min         -676.624\n",
      "trainer/Log Pis Mean                   20.131\n",
      "trainer/Log Pis Std                     4.17253\n",
      "trainer/Policy mu Mean                  0.0181222\n",
      "trainer/Policy mu Std                   0.880821\n",
      "trainer/Policy log std Mean            -3.37926\n",
      "trainer/Policy log std Std              0.815184\n",
      "trainer/Alpha                           0.167993\n",
      "trainer/Alpha Loss                     -0.0220147\n",
      "exploration/num steps total        283443\n",
      "exploration/num paths total           386\n",
      "evaluation/num steps total              2.51047e+06\n",
      "evaluation/num paths total           2827\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7019\n",
      "evaluation/Rewards Std                  0.975306\n",
      "evaluation/Rewards Max                  6.99704\n",
      "evaluation/Rewards Min                 -1.50735\n",
      "evaluation/Returns Mean              4701.9\n",
      "evaluation/Returns Std                 74.4175\n",
      "evaluation/Returns Max               4812.7\n",
      "evaluation/Returns Min               4569.35\n",
      "evaluation/Estimation Bias Mean       545.232\n",
      "evaluation/Estimation Bias Std        146.819\n",
      "evaluation/EB/Q_True Mean              42.2718\n",
      "evaluation/EB/Q_True Std              130.255\n",
      "evaluation/EB/Q_Pred Mean             587.504\n",
      "evaluation/EB/Q_Pred Std               57.0945\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4701.9\n",
      "evaluation/Actions Mean                 0.0221119\n",
      "evaluation/Actions Std                  0.534613\n",
      "evaluation/Actions Max                  0.999382\n",
      "evaluation/Actions Min                 -0.999457\n",
      "time/backward_policy (s)                1.88362\n",
      "time/backward_zf1 (s)                   2.053\n",
      "time/backward_zf2 (s)                   1.96018\n",
      "time/data sampling (s)                  0.312153\n",
      "time/data storing (s)                   0.0146876\n",
      "time/evaluation sampling (s)            1.68928\n",
      "time/exploration sampling (s)           0.319486\n",
      "time/logging (s)                        0.012021\n",
      "time/preback_alpha (s)                  0.971362\n",
      "time/preback_policy (s)                 1.07223\n",
      "time/preback_start (s)                  0.148615\n",
      "time/preback_zf (s)                     5.23294\n",
      "time/saving (s)                         0.00623959\n",
      "time/training (s)                       2.40162\n",
      "time/epoch (s)                         18.0774\n",
      "time/total (s)                       4986.94\n",
      "Epoch                                 277\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:15:45.273535 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 278 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 289000\n",
      "trainer/ZF1 Loss                       17.9141\n",
      "trainer/ZF2 Loss                        9.84773\n",
      "trainer/ZF Expert Reward               13.3434\n",
      "trainer/ZF Policy Reward                1.77874\n",
      "trainer/ZF CHI2 Term                   45.4626\n",
      "trainer/Policy Loss                  -515.848\n",
      "trainer/Bias Loss                      69.8088\n",
      "trainer/Bias Value                     15.1215\n",
      "trainer/Policy Grad Norm              190.489\n",
      "trainer/Policy Param Norm              38.151\n",
      "trainer/Zf1 Grad Norm                2120.12\n",
      "trainer/Zf1 Param Norm                124.267\n",
      "trainer/Zf2 Grad Norm                1294.21\n",
      "trainer/Zf2 Param Norm                122.672\n",
      "trainer/Z Expert Predictions Mean     621.282\n",
      "trainer/Z Expert Predictions Std       43.4531\n",
      "trainer/Z Expert Predictions Max      707.302\n",
      "trainer/Z Expert Predictions Min      402.713\n",
      "trainer/Z Policy Predictions Mean     517.173\n",
      "trainer/Z Policy Predictions Std      229.747\n",
      "trainer/Z Policy Predictions Max      661.371\n",
      "trainer/Z Policy Predictions Min     -734.22\n",
      "trainer/Z Expert Targets Mean         607.938\n",
      "trainer/Z Expert Targets Std           44.8228\n",
      "trainer/Z Expert Targets Max          671.979\n",
      "trainer/Z Expert Targets Min          368.129\n",
      "trainer/Z Policy Targets Mean         515.394\n",
      "trainer/Z Policy Targets Std          225.95\n",
      "trainer/Z Policy Targets Max          664.794\n",
      "trainer/Z Policy Targets Min         -711.019\n",
      "trainer/Log Pis Mean                   20.2192\n",
      "trainer/Log Pis Std                     3.83128\n",
      "trainer/Policy mu Mean                  0.0209548\n",
      "trainer/Policy mu Std                   0.913059\n",
      "trainer/Policy log std Mean            -3.34446\n",
      "trainer/Policy log std Std              0.828803\n",
      "trainer/Alpha                           0.168778\n",
      "trainer/Alpha Loss                     -0.037002\n",
      "exploration/num steps total        283443\n",
      "exploration/num paths total           386\n",
      "evaluation/num steps total              2.52047e+06\n",
      "evaluation/num paths total           2837\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68058\n",
      "evaluation/Rewards Std                  0.969418\n",
      "evaluation/Rewards Max                  6.8445\n",
      "evaluation/Rewards Min                 -1.67296\n",
      "evaluation/Returns Mean              4680.58\n",
      "evaluation/Returns Std                 78.6787\n",
      "evaluation/Returns Max               4817.68\n",
      "evaluation/Returns Min               4547.63\n",
      "evaluation/Estimation Bias Mean       540.271\n",
      "evaluation/Estimation Bias Std        143.346\n",
      "evaluation/EB/Q_True Mean              42.0773\n",
      "evaluation/EB/Q_True Std              130.004\n",
      "evaluation/EB/Q_Pred Mean             582.348\n",
      "evaluation/EB/Q_Pred Std               60.9086\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4680.58\n",
      "evaluation/Actions Mean                 0.0220197\n",
      "evaluation/Actions Std                  0.543129\n",
      "evaluation/Actions Max                  0.999594\n",
      "evaluation/Actions Min                 -0.999819\n",
      "time/backward_policy (s)                1.98737\n",
      "time/backward_zf1 (s)                   2.13264\n",
      "time/backward_zf2 (s)                   2.05868\n",
      "time/data sampling (s)                  0.318093\n",
      "time/data storing (s)                   0.0145916\n",
      "time/evaluation sampling (s)            1.77466\n",
      "time/exploration sampling (s)           0.314071\n",
      "time/logging (s)                        0.0115062\n",
      "time/preback_alpha (s)                  1.01077\n",
      "time/preback_policy (s)                 1.13692\n",
      "time/preback_start (s)                  0.1468\n",
      "time/preback_zf (s)                     5.23491\n",
      "time/saving (s)                         0.00616397\n",
      "time/training (s)                       2.22008\n",
      "time/epoch (s)                         18.3673\n",
      "time/total (s)                       5005.33\n",
      "Epoch                                 278\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:16:03.376257 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 279 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 290000\n",
      "trainer/ZF1 Loss                       21.9278\n",
      "trainer/ZF2 Loss                       21.2907\n",
      "trainer/ZF Expert Reward               11.827\n",
      "trainer/ZF Policy Reward                0.435796\n",
      "trainer/ZF CHI2 Term                   53.1224\n",
      "trainer/Policy Loss                  -523.065\n",
      "trainer/Bias Loss                      67.002\n",
      "trainer/Bias Value                     15.136\n",
      "trainer/Policy Grad Norm              181.438\n",
      "trainer/Policy Param Norm              38.1725\n",
      "trainer/Zf1 Grad Norm                1701.19\n",
      "trainer/Zf1 Param Norm                124.383\n",
      "trainer/Zf2 Grad Norm                1703.22\n",
      "trainer/Zf2 Param Norm                122.786\n",
      "trainer/Z Expert Predictions Mean     613.587\n",
      "trainer/Z Expert Predictions Std       43.7696\n",
      "trainer/Z Expert Predictions Max      687.914\n",
      "trainer/Z Expert Predictions Min      386.69\n",
      "trainer/Z Policy Predictions Mean     521.773\n",
      "trainer/Z Policy Predictions Std      195.886\n",
      "trainer/Z Policy Predictions Max      674.074\n",
      "trainer/Z Policy Predictions Min     -656.05\n",
      "trainer/Z Expert Targets Mean         601.76\n",
      "trainer/Z Expert Targets Std           45.7107\n",
      "trainer/Z Expert Targets Max          684.283\n",
      "trainer/Z Expert Targets Min          373.591\n",
      "trainer/Z Policy Targets Mean         521.337\n",
      "trainer/Z Policy Targets Std          192.813\n",
      "trainer/Z Policy Targets Max          662.742\n",
      "trainer/Z Policy Targets Min         -631.279\n",
      "trainer/Log Pis Mean                   20.3252\n",
      "trainer/Log Pis Std                     3.49691\n",
      "trainer/Policy mu Mean                  0.0423015\n",
      "trainer/Policy mu Std                   0.91909\n",
      "trainer/Policy log std Mean            -3.38093\n",
      "trainer/Policy log std Std              0.819715\n",
      "trainer/Alpha                           0.169049\n",
      "trainer/Alpha Loss                     -0.0549692\n",
      "exploration/num steps total        284443\n",
      "exploration/num paths total           387\n",
      "evaluation/num steps total              2.53021e+06\n",
      "evaluation/num paths total           2847\n",
      "evaluation/path length Mean           973.7\n",
      "evaluation/path length Std             78.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            737\n",
      "evaluation/Rewards Mean                 4.68504\n",
      "evaluation/Rewards Std                  1.04789\n",
      "evaluation/Rewards Max                  6.8369\n",
      "evaluation/Rewards Min                 -1.71074\n",
      "evaluation/Returns Mean              4561.82\n",
      "evaluation/Returns Std                441.165\n",
      "evaluation/Returns Max               4791.13\n",
      "evaluation/Returns Min               3253.12\n",
      "evaluation/Estimation Bias Mean       534.125\n",
      "evaluation/Estimation Bias Std        158.236\n",
      "evaluation/EB/Q_True Mean              44.5183\n",
      "evaluation/EB/Q_True Std              135.33\n",
      "evaluation/EB/Q_Pred Mean             578.644\n",
      "evaluation/EB/Q_Pred Std               70.5981\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4561.82\n",
      "evaluation/Actions Mean                 0.0261361\n",
      "evaluation/Actions Std                  0.540706\n",
      "evaluation/Actions Max                  0.999981\n",
      "evaluation/Actions Min                 -0.999551\n",
      "time/backward_policy (s)                1.8961\n",
      "time/backward_zf1 (s)                   2.03764\n",
      "time/backward_zf2 (s)                   1.93983\n",
      "time/data sampling (s)                  0.297709\n",
      "time/data storing (s)                   0.0145195\n",
      "time/evaluation sampling (s)            1.7824\n",
      "time/exploration sampling (s)           0.318159\n",
      "time/logging (s)                        0.0176268\n",
      "time/preback_alpha (s)                  0.991214\n",
      "time/preback_policy (s)                 1.0998\n",
      "time/preback_start (s)                  0.148012\n",
      "time/preback_zf (s)                     5.21129\n",
      "time/saving (s)                         0.00769737\n",
      "time/training (s)                       2.27556\n",
      "time/epoch (s)                         18.0376\n",
      "time/total (s)                       5023.39\n",
      "Epoch                                 279\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:16:21.502549 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 280 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 291000\n",
      "trainer/ZF1 Loss                       28.2678\n",
      "trainer/ZF2 Loss                       20.8463\n",
      "trainer/ZF Expert Reward               13.5027\n",
      "trainer/ZF Policy Reward                4.23561\n",
      "trainer/ZF CHI2 Term                   54.1239\n",
      "trainer/Policy Loss                  -481.79\n",
      "trainer/Bias Loss                      58.4021\n",
      "trainer/Bias Value                     15.1461\n",
      "trainer/Policy Grad Norm              164.451\n",
      "trainer/Policy Param Norm              38.1975\n",
      "trainer/Zf1 Grad Norm                1675.54\n",
      "trainer/Zf1 Param Norm                124.51\n",
      "trainer/Zf2 Grad Norm                1513.45\n",
      "trainer/Zf2 Param Norm                122.905\n",
      "trainer/Z Expert Predictions Mean     611.29\n",
      "trainer/Z Expert Predictions Std       44.1283\n",
      "trainer/Z Expert Predictions Max      680.562\n",
      "trainer/Z Expert Predictions Min      380.621\n",
      "trainer/Z Policy Predictions Mean     480.575\n",
      "trainer/Z Policy Predictions Std      284.595\n",
      "trainer/Z Policy Predictions Max      668.239\n",
      "trainer/Z Policy Predictions Min     -719.202\n",
      "trainer/Z Expert Targets Mean         597.787\n",
      "trainer/Z Expert Targets Std           45.9029\n",
      "trainer/Z Expert Targets Max          682.06\n",
      "trainer/Z Expert Targets Min          362.045\n",
      "trainer/Z Policy Targets Mean         476.34\n",
      "trainer/Z Policy Targets Std          280.812\n",
      "trainer/Z Policy Targets Max          650.471\n",
      "trainer/Z Policy Targets Min         -724.272\n",
      "trainer/Log Pis Mean                   20.5048\n",
      "trainer/Log Pis Std                     3.97195\n",
      "trainer/Policy mu Mean                  0.0301382\n",
      "trainer/Policy mu Std                   0.984439\n",
      "trainer/Policy log std Mean            -3.31074\n",
      "trainer/Policy log std Std              0.939874\n",
      "trainer/Alpha                           0.170687\n",
      "trainer/Alpha Loss                     -0.0861592\n",
      "exploration/num steps total        285443\n",
      "exploration/num paths total           388\n",
      "evaluation/num steps total              2.54021e+06\n",
      "evaluation/num paths total           2857\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6963\n",
      "evaluation/Rewards Std                  0.943244\n",
      "evaluation/Rewards Max                  6.59849\n",
      "evaluation/Rewards Min                 -1.44531\n",
      "evaluation/Returns Mean              4696.3\n",
      "evaluation/Returns Std                110.748\n",
      "evaluation/Returns Max               4853.52\n",
      "evaluation/Returns Min               4508.25\n",
      "evaluation/Estimation Bias Mean       547.652\n",
      "evaluation/Estimation Bias Std        141.487\n",
      "evaluation/EB/Q_True Mean              41.4575\n",
      "evaluation/EB/Q_True Std              127.922\n",
      "evaluation/EB/Q_Pred Mean             589.109\n",
      "evaluation/EB/Q_Pred Std               56.7999\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4696.3\n",
      "evaluation/Actions Mean                 0.0214035\n",
      "evaluation/Actions Std                  0.542141\n",
      "evaluation/Actions Max                  0.999015\n",
      "evaluation/Actions Min                 -0.999564\n",
      "time/backward_policy (s)                1.9002\n",
      "time/backward_zf1 (s)                   2.02257\n",
      "time/backward_zf2 (s)                   1.96256\n",
      "time/data sampling (s)                  0.31096\n",
      "time/data storing (s)                   0.0152201\n",
      "time/evaluation sampling (s)            1.75655\n",
      "time/exploration sampling (s)           0.32373\n",
      "time/logging (s)                        0.0133216\n",
      "time/preback_alpha (s)                  0.987695\n",
      "time/preback_policy (s)                 1.11424\n",
      "time/preback_start (s)                  0.148767\n",
      "time/preback_zf (s)                     5.20169\n",
      "time/saving (s)                         0.00624444\n",
      "time/training (s)                       2.28867\n",
      "time/epoch (s)                         18.0524\n",
      "time/total (s)                       5041.46\n",
      "Epoch                                 280\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:16:39.652204 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 281 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 292000\n",
      "trainer/ZF1 Loss                       27.69\n",
      "trainer/ZF2 Loss                       25.4516\n",
      "trainer/ZF Expert Reward               18.7405\n",
      "trainer/ZF Policy Reward                4.06144\n",
      "trainer/ZF CHI2 Term                   61.4191\n",
      "trainer/Policy Loss                  -483.639\n",
      "trainer/Bias Loss                      78.6336\n",
      "trainer/Bias Value                     15.1602\n",
      "trainer/Policy Grad Norm              179.527\n",
      "trainer/Policy Param Norm              38.2203\n",
      "trainer/Zf1 Grad Norm                1490.21\n",
      "trainer/Zf1 Param Norm                124.622\n",
      "trainer/Zf2 Grad Norm                1873.93\n",
      "trainer/Zf2 Param Norm                123.017\n",
      "trainer/Z Expert Predictions Mean     609.066\n",
      "trainer/Z Expert Predictions Std       59.3353\n",
      "trainer/Z Expert Predictions Max      693.543\n",
      "trainer/Z Expert Predictions Min       87.6622\n",
      "trainer/Z Policy Predictions Mean     485.356\n",
      "trainer/Z Policy Predictions Std      251.39\n",
      "trainer/Z Policy Predictions Max      664.685\n",
      "trainer/Z Policy Predictions Min     -700.276\n",
      "trainer/Z Expert Targets Mean         590.326\n",
      "trainer/Z Expert Targets Std           63.3592\n",
      "trainer/Z Expert Targets Max          688.618\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         481.295\n",
      "trainer/Z Policy Targets Std          246.393\n",
      "trainer/Z Policy Targets Max          661.13\n",
      "trainer/Z Policy Targets Min         -687.633\n",
      "trainer/Log Pis Mean                   20.373\n",
      "trainer/Log Pis Std                     3.87249\n",
      "trainer/Policy mu Mean                  0.0317608\n",
      "trainer/Policy mu Std                   1.00083\n",
      "trainer/Policy log std Mean            -3.27128\n",
      "trainer/Policy log std Std              0.904161\n",
      "trainer/Alpha                           0.169516\n",
      "trainer/Alpha Loss                     -0.0632338\n",
      "exploration/num steps total        285443\n",
      "exploration/num paths total           388\n",
      "evaluation/num steps total              2.55021e+06\n",
      "evaluation/num paths total           2867\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63431\n",
      "evaluation/Rewards Std                  1.03111\n",
      "evaluation/Rewards Max                  6.77967\n",
      "evaluation/Rewards Min                 -1.8201\n",
      "evaluation/Returns Mean              4634.31\n",
      "evaluation/Returns Std                110.618\n",
      "evaluation/Returns Max               4772.39\n",
      "evaluation/Returns Min               4418.23\n",
      "evaluation/Estimation Bias Mean       534.732\n",
      "evaluation/Estimation Bias Std        151.861\n",
      "evaluation/EB/Q_True Mean              43.8741\n",
      "evaluation/EB/Q_True Std              134.792\n",
      "evaluation/EB/Q_Pred Mean             578.606\n",
      "evaluation/EB/Q_Pred Std               63.3593\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4634.31\n",
      "evaluation/Actions Mean                 0.0196762\n",
      "evaluation/Actions Std                  0.535085\n",
      "evaluation/Actions Max                  0.999853\n",
      "evaluation/Actions Min                 -0.999938\n",
      "time/backward_policy (s)                1.96242\n",
      "time/backward_zf1 (s)                   2.07485\n",
      "time/backward_zf2 (s)                   2.0092\n",
      "time/data sampling (s)                  0.288857\n",
      "time/data storing (s)                   0.0144985\n",
      "time/evaluation sampling (s)            1.75217\n",
      "time/exploration sampling (s)           0.313086\n",
      "time/logging (s)                        0.0115871\n",
      "time/preback_alpha (s)                  1.01927\n",
      "time/preback_policy (s)                 1.14705\n",
      "time/preback_start (s)                  0.145822\n",
      "time/preback_zf (s)                     5.1935\n",
      "time/saving (s)                         0.0056207\n",
      "time/training (s)                       2.14203\n",
      "time/epoch (s)                         18.08\n",
      "time/total (s)                       5059.56\n",
      "Epoch                                 281\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:16:58.107643 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 282 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 293000\n",
      "trainer/ZF1 Loss                       79.5006\n",
      "trainer/ZF2 Loss                       84.1056\n",
      "trainer/ZF Expert Reward               15.5947\n",
      "trainer/ZF Policy Reward                4.48783\n",
      "trainer/ZF CHI2 Term                  112.241\n",
      "trainer/Policy Loss                  -491.267\n",
      "trainer/Bias Loss                      58.6977\n",
      "trainer/Bias Value                     15.1715\n",
      "trainer/Policy Grad Norm              211.543\n",
      "trainer/Policy Param Norm              38.2421\n",
      "trainer/Zf1 Grad Norm                1526.86\n",
      "trainer/Zf1 Param Norm                124.744\n",
      "trainer/Zf2 Grad Norm                1321.44\n",
      "trainer/Zf2 Param Norm                123.139\n",
      "trainer/Z Expert Predictions Mean     606.611\n",
      "trainer/Z Expert Predictions Std       45.589\n",
      "trainer/Z Expert Predictions Max      685.861\n",
      "trainer/Z Expert Predictions Min      396.551\n",
      "trainer/Z Policy Predictions Mean     493.876\n",
      "trainer/Z Policy Predictions Std      228.118\n",
      "trainer/Z Policy Predictions Max      665.144\n",
      "trainer/Z Policy Predictions Min     -717.912\n",
      "trainer/Z Expert Targets Mean         591.016\n",
      "trainer/Z Expert Targets Std           46.727\n",
      "trainer/Z Expert Targets Max          670.306\n",
      "trainer/Z Expert Targets Min          392.405\n",
      "trainer/Z Policy Targets Mean         489.388\n",
      "trainer/Z Policy Targets Std          225.283\n",
      "trainer/Z Policy Targets Max          651.373\n",
      "trainer/Z Policy Targets Min         -705.406\n",
      "trainer/Log Pis Mean                   19.526\n",
      "trainer/Log Pis Std                     4.33787\n",
      "trainer/Policy mu Mean                  0.0395351\n",
      "trainer/Policy mu Std                   0.858054\n",
      "trainer/Policy log std Mean            -3.30928\n",
      "trainer/Policy log std Std              0.846206\n",
      "trainer/Alpha                           0.170356\n",
      "trainer/Alpha Loss                      0.0807492\n",
      "exploration/num steps total        287443\n",
      "exploration/num paths total           390\n",
      "evaluation/num steps total              2.56021e+06\n",
      "evaluation/num paths total           2877\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7249\n",
      "evaluation/Rewards Std                  1.00316\n",
      "evaluation/Rewards Max                  6.85418\n",
      "evaluation/Rewards Min                 -2.03521\n",
      "evaluation/Returns Mean              4724.9\n",
      "evaluation/Returns Std                 98.0752\n",
      "evaluation/Returns Max               4848.65\n",
      "evaluation/Returns Min               4508.83\n",
      "evaluation/Estimation Bias Mean       533.108\n",
      "evaluation/Estimation Bias Std        138.866\n",
      "evaluation/EB/Q_True Mean              41.196\n",
      "evaluation/EB/Q_True Std              128.7\n",
      "evaluation/EB/Q_Pred Mean             574.304\n",
      "evaluation/EB/Q_Pred Std               58.1229\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4724.9\n",
      "evaluation/Actions Mean                 0.0295746\n",
      "evaluation/Actions Std                  0.538438\n",
      "evaluation/Actions Max                  0.999774\n",
      "evaluation/Actions Min                 -0.999852\n",
      "time/backward_policy (s)                1.99485\n",
      "time/backward_zf1 (s)                   2.12846\n",
      "time/backward_zf2 (s)                   2.04708\n",
      "time/data sampling (s)                  0.308866\n",
      "time/data storing (s)                   0.0154314\n",
      "time/evaluation sampling (s)            1.72345\n",
      "time/exploration sampling (s)           0.331801\n",
      "time/logging (s)                        0.0124384\n",
      "time/preback_alpha (s)                  1.00559\n",
      "time/preback_policy (s)                 1.12881\n",
      "time/preback_start (s)                  0.149821\n",
      "time/preback_zf (s)                     5.23834\n",
      "time/saving (s)                         0.00558947\n",
      "time/training (s)                       2.29782\n",
      "time/epoch (s)                         18.3884\n",
      "time/total (s)                       5077.97\n",
      "Epoch                                 282\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:17:16.627488 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 283 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 294000\n",
      "trainer/ZF1 Loss                       14.7314\n",
      "trainer/ZF2 Loss                       16.8751\n",
      "trainer/ZF Expert Reward               18.9785\n",
      "trainer/ZF Policy Reward                6.16094\n",
      "trainer/ZF CHI2 Term                   48.7331\n",
      "trainer/Policy Loss                  -490.275\n",
      "trainer/Bias Loss                      80.3011\n",
      "trainer/Bias Value                     15.1848\n",
      "trainer/Policy Grad Norm              179.628\n",
      "trainer/Policy Param Norm              38.2627\n",
      "trainer/Zf1 Grad Norm                1384.91\n",
      "trainer/Zf1 Param Norm                124.855\n",
      "trainer/Zf2 Grad Norm                1547.11\n",
      "trainer/Zf2 Param Norm                123.279\n",
      "trainer/Z Expert Predictions Mean     611.406\n",
      "trainer/Z Expert Predictions Std       56.785\n",
      "trainer/Z Expert Predictions Max      686.714\n",
      "trainer/Z Expert Predictions Min      -17.8952\n",
      "trainer/Z Policy Predictions Mean     492.641\n",
      "trainer/Z Policy Predictions Std      233.491\n",
      "trainer/Z Policy Predictions Max      662.381\n",
      "trainer/Z Policy Predictions Min     -702.032\n",
      "trainer/Z Expert Targets Mean         592.427\n",
      "trainer/Z Expert Targets Std           56.6021\n",
      "trainer/Z Expert Targets Max          672.083\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         486.48\n",
      "trainer/Z Policy Targets Std          229.561\n",
      "trainer/Z Policy Targets Max          652.945\n",
      "trainer/Z Policy Targets Min         -697.505\n",
      "trainer/Log Pis Mean                   20.3154\n",
      "trainer/Log Pis Std                     3.95098\n",
      "trainer/Policy mu Mean                  0.0521906\n",
      "trainer/Policy mu Std                   0.947018\n",
      "trainer/Policy log std Mean            -3.29711\n",
      "trainer/Policy log std Std              0.877893\n",
      "trainer/Alpha                           0.17241\n",
      "trainer/Alpha Loss                     -0.0543777\n",
      "exploration/num steps total        289443\n",
      "exploration/num paths total           392\n",
      "evaluation/num steps total              2.57001e+06\n",
      "evaluation/num paths total           2887\n",
      "evaluation/path length Mean           980.1\n",
      "evaluation/path length Std             59.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            801\n",
      "evaluation/Rewards Mean                 4.70928\n",
      "evaluation/Rewards Std                  0.934632\n",
      "evaluation/Rewards Max                  6.7206\n",
      "evaluation/Rewards Min                 -1.2289\n",
      "evaluation/Returns Mean              4615.57\n",
      "evaluation/Returns Std                271.651\n",
      "evaluation/Returns Max               4799.16\n",
      "evaluation/Returns Min               3836.88\n",
      "evaluation/Estimation Bias Mean       528.226\n",
      "evaluation/Estimation Bias Std        148.214\n",
      "evaluation/EB/Q_True Mean              44.5281\n",
      "evaluation/EB/Q_True Std              135.713\n",
      "evaluation/EB/Q_Pred Mean             572.755\n",
      "evaluation/EB/Q_Pred Std               58.5029\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4615.57\n",
      "evaluation/Actions Mean                 0.0215723\n",
      "evaluation/Actions Std                  0.535929\n",
      "evaluation/Actions Max                  0.999605\n",
      "evaluation/Actions Min                 -0.999563\n",
      "time/backward_policy (s)                1.98388\n",
      "time/backward_zf1 (s)                   2.12537\n",
      "time/backward_zf2 (s)                   2.05465\n",
      "time/data sampling (s)                  0.304246\n",
      "time/data storing (s)                   0.0150131\n",
      "time/evaluation sampling (s)            1.7811\n",
      "time/exploration sampling (s)           0.327141\n",
      "time/logging (s)                        0.0124371\n",
      "time/preback_alpha (s)                  1.05689\n",
      "time/preback_policy (s)                 1.17452\n",
      "time/preback_start (s)                  0.151522\n",
      "time/preback_zf (s)                     5.28623\n",
      "time/saving (s)                         0.00601994\n",
      "time/training (s)                       2.172\n",
      "time/epoch (s)                         18.451\n",
      "time/total (s)                       5096.44\n",
      "Epoch                                 283\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:17:35.061322 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 284 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 295000\n",
      "trainer/ZF1 Loss                       63.1983\n",
      "trainer/ZF2 Loss                       58.7619\n",
      "trainer/ZF Expert Reward               17.6383\n",
      "trainer/ZF Policy Reward                6.96268\n",
      "trainer/ZF CHI2 Term                   91.5834\n",
      "trainer/Policy Loss                  -493.057\n",
      "trainer/Bias Loss                      56.8673\n",
      "trainer/Bias Value                     15.1957\n",
      "trainer/Policy Grad Norm              180.949\n",
      "trainer/Policy Param Norm              38.2833\n",
      "trainer/Zf1 Grad Norm                1605.78\n",
      "trainer/Zf1 Param Norm                124.976\n",
      "trainer/Zf2 Grad Norm                1361.19\n",
      "trainer/Zf2 Param Norm                123.404\n",
      "trainer/Z Expert Predictions Mean     607.05\n",
      "trainer/Z Expert Predictions Std       38.1058\n",
      "trainer/Z Expert Predictions Max      678.177\n",
      "trainer/Z Expert Predictions Min      434.397\n",
      "trainer/Z Policy Predictions Mean     496.722\n",
      "trainer/Z Policy Predictions Std      223.869\n",
      "trainer/Z Policy Predictions Max      652.659\n",
      "trainer/Z Policy Predictions Min     -716.246\n",
      "trainer/Z Expert Targets Mean         589.412\n",
      "trainer/Z Expert Targets Std           41.0809\n",
      "trainer/Z Expert Targets Max          667.842\n",
      "trainer/Z Expert Targets Min          399.555\n",
      "trainer/Z Policy Targets Mean         489.759\n",
      "trainer/Z Policy Targets Std          223.33\n",
      "trainer/Z Policy Targets Max          659.148\n",
      "trainer/Z Policy Targets Min         -710.431\n",
      "trainer/Log Pis Mean                   20.129\n",
      "trainer/Log Pis Std                     3.80079\n",
      "trainer/Policy mu Mean                  0.0298921\n",
      "trainer/Policy mu Std                   0.865185\n",
      "trainer/Policy log std Mean            -3.38371\n",
      "trainer/Policy log std Std              0.806596\n",
      "trainer/Alpha                           0.170705\n",
      "trainer/Alpha Loss                     -0.0220172\n",
      "exploration/num steps total        290443\n",
      "exploration/num paths total           393\n",
      "evaluation/num steps total              2.57902e+06\n",
      "evaluation/num paths total           2897\n",
      "evaluation/path length Mean           901.8\n",
      "evaluation/path length Std            294.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             18\n",
      "evaluation/Rewards Mean                 4.70779\n",
      "evaluation/Rewards Std                  0.975169\n",
      "evaluation/Rewards Max                  6.88654\n",
      "evaluation/Rewards Min                 -2.56504\n",
      "evaluation/Returns Mean              4245.48\n",
      "evaluation/Returns Std               1415.23\n",
      "evaluation/Returns Max               4919.34\n",
      "evaluation/Returns Min                 11.3877\n",
      "evaluation/Estimation Bias Mean       520.993\n",
      "evaluation/Estimation Bias Std        155.516\n",
      "evaluation/EB/Q_True Mean              48.7285\n",
      "evaluation/EB/Q_True Std              141.722\n",
      "evaluation/EB/Q_Pred Mean             569.721\n",
      "evaluation/EB/Q_Pred Std               59.9677\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4245.48\n",
      "evaluation/Actions Mean                 0.0262775\n",
      "evaluation/Actions Std                  0.53397\n",
      "evaluation/Actions Max                  0.99965\n",
      "evaluation/Actions Min                 -0.999722\n",
      "time/backward_policy (s)                1.99542\n",
      "time/backward_zf1 (s)                   2.15829\n",
      "time/backward_zf2 (s)                   2.08467\n",
      "time/data sampling (s)                  0.311158\n",
      "time/data storing (s)                   0.0146284\n",
      "time/evaluation sampling (s)            1.72168\n",
      "time/exploration sampling (s)           0.325405\n",
      "time/logging (s)                        0.0156023\n",
      "time/preback_alpha (s)                  1.04172\n",
      "time/preback_policy (s)                 1.17817\n",
      "time/preback_start (s)                  0.148735\n",
      "time/preback_zf (s)                     5.23267\n",
      "time/saving (s)                         0.00616314\n",
      "time/training (s)                       2.12867\n",
      "time/epoch (s)                         18.363\n",
      "time/total (s)                       5114.82\n",
      "Epoch                                 284\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:17:53.299339 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 285 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 296000\n",
      "trainer/ZF1 Loss                       15.315\n",
      "trainer/ZF2 Loss                        8.24786\n",
      "trainer/ZF Expert Reward               17.3131\n",
      "trainer/ZF Policy Reward                5.37842\n",
      "trainer/ZF CHI2 Term                   43.2141\n",
      "trainer/Policy Loss                  -471.025\n",
      "trainer/Bias Loss                      67.2051\n",
      "trainer/Bias Value                     15.2069\n",
      "trainer/Policy Grad Norm              171.619\n",
      "trainer/Policy Param Norm              38.303\n",
      "trainer/Zf1 Grad Norm                1349.93\n",
      "trainer/Zf1 Param Norm                125.095\n",
      "trainer/Zf2 Grad Norm                1194.34\n",
      "trainer/Zf2 Param Norm                123.538\n",
      "trainer/Z Expert Predictions Mean     600.618\n",
      "trainer/Z Expert Predictions Std       48.1903\n",
      "trainer/Z Expert Predictions Max      685.133\n",
      "trainer/Z Expert Predictions Min      385.83\n",
      "trainer/Z Policy Predictions Mean     473.596\n",
      "trainer/Z Policy Predictions Std      279.569\n",
      "trainer/Z Policy Predictions Max      661.96\n",
      "trainer/Z Policy Predictions Min     -728.03\n",
      "trainer/Z Expert Targets Mean         583.305\n",
      "trainer/Z Expert Targets Std           50.1\n",
      "trainer/Z Expert Targets Max          670.5\n",
      "trainer/Z Expert Targets Min          357.152\n",
      "trainer/Z Policy Targets Mean         468.217\n",
      "trainer/Z Policy Targets Std          276.847\n",
      "trainer/Z Policy Targets Max          650.152\n",
      "trainer/Z Policy Targets Min         -717.205\n",
      "trainer/Log Pis Mean                   19.6949\n",
      "trainer/Log Pis Std                     4.75097\n",
      "trainer/Policy mu Mean                  0.0526431\n",
      "trainer/Policy mu Std                   0.93554\n",
      "trainer/Policy log std Mean            -3.27625\n",
      "trainer/Policy log std Std              0.931268\n",
      "trainer/Alpha                           0.171019\n",
      "trainer/Alpha Loss                      0.0521831\n",
      "exploration/num steps total        291443\n",
      "exploration/num paths total           394\n",
      "evaluation/num steps total              2.58814e+06\n",
      "evaluation/num paths total           2907\n",
      "evaluation/path length Mean           911.7\n",
      "evaluation/path length Std            264.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            117\n",
      "evaluation/Rewards Mean                 4.63563\n",
      "evaluation/Rewards Std                  0.980831\n",
      "evaluation/Rewards Max                  6.89216\n",
      "evaluation/Rewards Min                 -1.60649\n",
      "evaluation/Returns Mean              4226.3\n",
      "evaluation/Returns Std               1265.72\n",
      "evaluation/Returns Max               4775.62\n",
      "evaluation/Returns Min                443.527\n",
      "evaluation/Estimation Bias Mean       521.996\n",
      "evaluation/Estimation Bias Std        151.148\n",
      "evaluation/EB/Q_True Mean              46.1822\n",
      "evaluation/EB/Q_True Std              136.543\n",
      "evaluation/EB/Q_Pred Mean             568.178\n",
      "evaluation/EB/Q_Pred Std               63.4777\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4226.3\n",
      "evaluation/Actions Mean                 0.0150217\n",
      "evaluation/Actions Std                  0.542748\n",
      "evaluation/Actions Max                  0.999648\n",
      "evaluation/Actions Min                 -0.999472\n",
      "time/backward_policy (s)                1.92027\n",
      "time/backward_zf1 (s)                   2.06535\n",
      "time/backward_zf2 (s)                   1.98052\n",
      "time/data sampling (s)                  0.322509\n",
      "time/data storing (s)                   0.0158617\n",
      "time/evaluation sampling (s)            1.75954\n",
      "time/exploration sampling (s)           0.331198\n",
      "time/logging (s)                        0.0117069\n",
      "time/preback_alpha (s)                  1.00597\n",
      "time/preback_policy (s)                 1.13148\n",
      "time/preback_start (s)                  0.148583\n",
      "time/preback_zf (s)                     5.2332\n",
      "time/saving (s)                         0.00606967\n",
      "time/training (s)                       2.22934\n",
      "time/epoch (s)                         18.1616\n",
      "time/total (s)                       5133.01\n",
      "Epoch                                 285\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:18:11.243793 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 286 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 297000\n",
      "trainer/ZF1 Loss                       23.8224\n",
      "trainer/ZF2 Loss                       17.4294\n",
      "trainer/ZF Expert Reward               18.6069\n",
      "trainer/ZF Policy Reward                8.83284\n",
      "trainer/ZF CHI2 Term                   50.2163\n",
      "trainer/Policy Loss                  -486.063\n",
      "trainer/Bias Loss                      87.2448\n",
      "trainer/Bias Value                     15.2182\n",
      "trainer/Policy Grad Norm              203.653\n",
      "trainer/Policy Param Norm              38.3228\n",
      "trainer/Zf1 Grad Norm                1728.68\n",
      "trainer/Zf1 Param Norm                125.206\n",
      "trainer/Zf2 Grad Norm                1401.76\n",
      "trainer/Zf2 Param Norm                123.652\n",
      "trainer/Z Expert Predictions Mean     597.832\n",
      "trainer/Z Expert Predictions Std       54.8689\n",
      "trainer/Z Expert Predictions Max      667.705\n",
      "trainer/Z Expert Predictions Min       74.1935\n",
      "trainer/Z Policy Predictions Mean     487.308\n",
      "trainer/Z Policy Predictions Std      244.186\n",
      "trainer/Z Policy Predictions Max      638.859\n",
      "trainer/Z Policy Predictions Min     -699.85\n",
      "trainer/Z Expert Targets Mean         579.225\n",
      "trainer/Z Expert Targets Std           59.5179\n",
      "trainer/Z Expert Targets Max          669.73\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         478.475\n",
      "trainer/Z Policy Targets Std          238.762\n",
      "trainer/Z Policy Targets Max          628.678\n",
      "trainer/Z Policy Targets Min         -688.464\n",
      "trainer/Log Pis Mean                   20.0165\n",
      "trainer/Log Pis Std                     4.53858\n",
      "trainer/Policy mu Mean                  0.017931\n",
      "trainer/Policy mu Std                   0.964102\n",
      "trainer/Policy log std Mean            -3.28092\n",
      "trainer/Policy log std Std              0.918121\n",
      "trainer/Alpha                           0.172756\n",
      "trainer/Alpha Loss                     -0.00284763\n",
      "exploration/num steps total        293443\n",
      "exploration/num paths total           396\n",
      "evaluation/num steps total              2.59792e+06\n",
      "evaluation/num paths total           2917\n",
      "evaluation/path length Mean           977.8\n",
      "evaluation/path length Std             66.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            778\n",
      "evaluation/Rewards Mean                 4.66222\n",
      "evaluation/Rewards Std                  1.04262\n",
      "evaluation/Rewards Max                  6.75083\n",
      "evaluation/Rewards Min                 -1.69282\n",
      "evaluation/Returns Mean              4558.72\n",
      "evaluation/Returns Std                344.043\n",
      "evaluation/Returns Max               4900.72\n",
      "evaluation/Returns Min               3610.74\n",
      "evaluation/Estimation Bias Mean       506.707\n",
      "evaluation/Estimation Bias Std        155.062\n",
      "evaluation/EB/Q_True Mean              45.1069\n",
      "evaluation/EB/Q_True Std              137.329\n",
      "evaluation/EB/Q_Pred Mean             551.813\n",
      "evaluation/EB/Q_Pred Std               66.3042\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4558.72\n",
      "evaluation/Actions Mean                 0.0175566\n",
      "evaluation/Actions Std                  0.53723\n",
      "evaluation/Actions Max                  0.999408\n",
      "evaluation/Actions Min                 -0.999687\n",
      "time/backward_policy (s)                1.86424\n",
      "time/backward_zf1 (s)                   2.00427\n",
      "time/backward_zf2 (s)                   1.91388\n",
      "time/data sampling (s)                  0.31303\n",
      "time/data storing (s)                   0.0157036\n",
      "time/evaluation sampling (s)            1.72528\n",
      "time/exploration sampling (s)           0.331151\n",
      "time/logging (s)                        0.0122378\n",
      "time/preback_alpha (s)                  0.948517\n",
      "time/preback_policy (s)                 1.05533\n",
      "time/preback_start (s)                  0.145926\n",
      "time/preback_zf (s)                     5.17245\n",
      "time/saving (s)                         0.00651361\n",
      "time/training (s)                       2.36775\n",
      "time/epoch (s)                         17.8763\n",
      "time/total (s)                       5150.9\n",
      "Epoch                                 286\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:18:28.913778 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 287 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 298000\n",
      "trainer/ZF1 Loss                       16.7604\n",
      "trainer/ZF2 Loss                        8.46872\n",
      "trainer/ZF Expert Reward               13.3012\n",
      "trainer/ZF Policy Reward                1.58045\n",
      "trainer/ZF CHI2 Term                   43.8757\n",
      "trainer/Policy Loss                  -474.234\n",
      "trainer/Bias Loss                      56.886\n",
      "trainer/Bias Value                     15.2307\n",
      "trainer/Policy Grad Norm              168.671\n",
      "trainer/Policy Param Norm              38.3413\n",
      "trainer/Zf1 Grad Norm                1707.48\n",
      "trainer/Zf1 Param Norm                125.34\n",
      "trainer/Zf2 Grad Norm                1508.01\n",
      "trainer/Zf2 Param Norm                123.782\n",
      "trainer/Z Expert Predictions Mean     592.744\n",
      "trainer/Z Expert Predictions Std       44.6244\n",
      "trainer/Z Expert Predictions Max      672.135\n",
      "trainer/Z Expert Predictions Min      362.7\n",
      "trainer/Z Policy Predictions Mean     472.962\n",
      "trainer/Z Policy Predictions Std      244.515\n",
      "trainer/Z Policy Predictions Max      650.844\n",
      "trainer/Z Policy Predictions Min     -711.792\n",
      "trainer/Z Expert Targets Mean         579.442\n",
      "trainer/Z Expert Targets Std           45.3909\n",
      "trainer/Z Expert Targets Max          658.347\n",
      "trainer/Z Expert Targets Min          338.106\n",
      "trainer/Z Policy Targets Mean         471.382\n",
      "trainer/Z Policy Targets Std          239.646\n",
      "trainer/Z Policy Targets Max          648.465\n",
      "trainer/Z Policy Targets Min         -709.977\n",
      "trainer/Log Pis Mean                   19.7378\n",
      "trainer/Log Pis Std                     4.65496\n",
      "trainer/Policy mu Mean                  0.0365489\n",
      "trainer/Policy mu Std                   0.908006\n",
      "trainer/Policy log std Mean            -3.2919\n",
      "trainer/Policy log std Std              0.886145\n",
      "trainer/Alpha                           0.172758\n",
      "trainer/Alpha Loss                      0.0453002\n",
      "exploration/num steps total        293443\n",
      "exploration/num paths total           396\n",
      "evaluation/num steps total              2.60792e+06\n",
      "evaluation/num paths total           2927\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6926\n",
      "evaluation/Rewards Std                  0.940672\n",
      "evaluation/Rewards Max                  6.57009\n",
      "evaluation/Rewards Min                 -1.57967\n",
      "evaluation/Returns Mean              4692.6\n",
      "evaluation/Returns Std                 72.7843\n",
      "evaluation/Returns Max               4801.12\n",
      "evaluation/Returns Min               4576.8\n",
      "evaluation/Estimation Bias Mean       519.538\n",
      "evaluation/Estimation Bias Std        143.546\n",
      "evaluation/EB/Q_True Mean              43.8494\n",
      "evaluation/EB/Q_True Std              134.684\n",
      "evaluation/EB/Q_Pred Mean             563.388\n",
      "evaluation/EB/Q_Pred Std               54.9882\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4692.6\n",
      "evaluation/Actions Mean                 0.0219313\n",
      "evaluation/Actions Std                  0.535895\n",
      "evaluation/Actions Max                  0.999377\n",
      "evaluation/Actions Min                 -0.99985\n",
      "time/backward_policy (s)                1.78169\n",
      "time/backward_zf1 (s)                   1.92139\n",
      "time/backward_zf2 (s)                   1.83231\n",
      "time/data sampling (s)                  0.320128\n",
      "time/data storing (s)                   0.0150338\n",
      "time/evaluation sampling (s)            1.7693\n",
      "time/exploration sampling (s)           0.320401\n",
      "time/logging (s)                        0.0119706\n",
      "time/preback_alpha (s)                  0.922429\n",
      "time/preback_policy (s)                 0.99254\n",
      "time/preback_start (s)                  0.144061\n",
      "time/preback_zf (s)                     5.15615\n",
      "time/saving (s)                         0.00765254\n",
      "time/training (s)                       2.40084\n",
      "time/epoch (s)                         17.5959\n",
      "time/total (s)                       5168.52\n",
      "Epoch                                 287\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:18:46.961950 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 288 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 299000\n",
      "trainer/ZF1 Loss                        9.56392\n",
      "trainer/ZF2 Loss                       14.3666\n",
      "trainer/ZF Expert Reward               16.9373\n",
      "trainer/ZF Policy Reward                3.9466\n",
      "trainer/ZF CHI2 Term                   44.5349\n",
      "trainer/Policy Loss                  -492.778\n",
      "trainer/Bias Loss                      78.4296\n",
      "trainer/Bias Value                     15.2416\n",
      "trainer/Policy Grad Norm              209.18\n",
      "trainer/Policy Param Norm              38.3649\n",
      "trainer/Zf1 Grad Norm                1361.44\n",
      "trainer/Zf1 Param Norm                125.461\n",
      "trainer/Zf2 Grad Norm                1522.88\n",
      "trainer/Zf2 Param Norm                123.915\n",
      "trainer/Z Expert Predictions Mean     589.018\n",
      "trainer/Z Expert Predictions Std       57.0747\n",
      "trainer/Z Expert Predictions Max      653.614\n",
      "trainer/Z Expert Predictions Min       38.3919\n",
      "trainer/Z Policy Predictions Mean     494.14\n",
      "trainer/Z Policy Predictions Std      202.294\n",
      "trainer/Z Policy Predictions Max      636.066\n",
      "trainer/Z Policy Predictions Min     -739.33\n",
      "trainer/Z Expert Targets Mean         572.081\n",
      "trainer/Z Expert Targets Std           61.2673\n",
      "trainer/Z Expert Targets Max          652.495\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         490.193\n",
      "trainer/Z Policy Targets Std          198.933\n",
      "trainer/Z Policy Targets Max          643.96\n",
      "trainer/Z Policy Targets Min         -731.122\n",
      "trainer/Log Pis Mean                   19.7767\n",
      "trainer/Log Pis Std                     4.13222\n",
      "trainer/Policy mu Mean                  0.0139294\n",
      "trainer/Policy mu Std                   0.892661\n",
      "trainer/Policy log std Mean            -3.31708\n",
      "trainer/Policy log std Std              0.858396\n",
      "trainer/Alpha                           0.172172\n",
      "trainer/Alpha Loss                      0.0384417\n",
      "exploration/num steps total        293443\n",
      "exploration/num paths total           396\n",
      "evaluation/num steps total              2.61792e+06\n",
      "evaluation/num paths total           2937\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66578\n",
      "evaluation/Rewards Std                  1.00861\n",
      "evaluation/Rewards Max                  6.71582\n",
      "evaluation/Rewards Min                 -1.49594\n",
      "evaluation/Returns Mean              4665.78\n",
      "evaluation/Returns Std                112.228\n",
      "evaluation/Returns Max               4784.02\n",
      "evaluation/Returns Min               4445.02\n",
      "evaluation/Estimation Bias Mean       511.77\n",
      "evaluation/Estimation Bias Std        150.123\n",
      "evaluation/EB/Q_True Mean              43.6642\n",
      "evaluation/EB/Q_True Std              134.69\n",
      "evaluation/EB/Q_Pred Mean             555.435\n",
      "evaluation/EB/Q_Pred Std               67.8611\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4665.78\n",
      "evaluation/Actions Mean                 0.023376\n",
      "evaluation/Actions Std                  0.533824\n",
      "evaluation/Actions Max                  0.999794\n",
      "evaluation/Actions Min                 -0.999638\n",
      "time/backward_policy (s)                1.86233\n",
      "time/backward_zf1 (s)                   2.01531\n",
      "time/backward_zf2 (s)                   1.93418\n",
      "time/data sampling (s)                  0.303864\n",
      "time/data storing (s)                   0.0145748\n",
      "time/evaluation sampling (s)            1.75593\n",
      "time/exploration sampling (s)           0.314019\n",
      "time/logging (s)                        0.0119059\n",
      "time/preback_alpha (s)                  0.969703\n",
      "time/preback_policy (s)                 1.07165\n",
      "time/preback_start (s)                  0.146842\n",
      "time/preback_zf (s)                     5.23685\n",
      "time/saving (s)                         0.00599447\n",
      "time/training (s)                       2.33687\n",
      "time/epoch (s)                         17.98\n",
      "time/total (s)                       5186.52\n",
      "Epoch                                 288\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:19:05.498943 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 289 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 300000\n",
      "trainer/ZF1 Loss                        6.8617\n",
      "trainer/ZF2 Loss                        8.449\n",
      "trainer/ZF Expert Reward               18.0594\n",
      "trainer/ZF Policy Reward                6.59895\n",
      "trainer/ZF CHI2 Term                   38.8556\n",
      "trainer/Policy Loss                  -470.481\n",
      "trainer/Bias Loss                      52.6852\n",
      "trainer/Bias Value                     15.2542\n",
      "trainer/Policy Grad Norm              208.23\n",
      "trainer/Policy Param Norm              38.3874\n",
      "trainer/Zf1 Grad Norm                1216.51\n",
      "trainer/Zf1 Param Norm                125.582\n",
      "trainer/Zf2 Grad Norm                1126.93\n",
      "trainer/Zf2 Param Norm                124.047\n",
      "trainer/Z Expert Predictions Mean     585.773\n",
      "trainer/Z Expert Predictions Std       50.5163\n",
      "trainer/Z Expert Predictions Max      667.611\n",
      "trainer/Z Expert Predictions Min      331.954\n",
      "trainer/Z Policy Predictions Mean     474.327\n",
      "trainer/Z Policy Predictions Std      242.887\n",
      "trainer/Z Policy Predictions Max      639.083\n",
      "trainer/Z Policy Predictions Min     -738.622\n",
      "trainer/Z Expert Targets Mean         567.714\n",
      "trainer/Z Expert Targets Std           52.5269\n",
      "trainer/Z Expert Targets Max          654.153\n",
      "trainer/Z Expert Targets Min          317.325\n",
      "trainer/Z Policy Targets Mean         467.728\n",
      "trainer/Z Policy Targets Std          238.933\n",
      "trainer/Z Policy Targets Max          623.352\n",
      "trainer/Z Policy Targets Min         -744.026\n",
      "trainer/Log Pis Mean                   19.9392\n",
      "trainer/Log Pis Std                     4.07025\n",
      "trainer/Policy mu Mean                  0.0433658\n",
      "trainer/Policy mu Std                   0.962675\n",
      "trainer/Policy log std Mean            -3.29405\n",
      "trainer/Policy log std Std              0.902275\n",
      "trainer/Alpha                           0.174934\n",
      "trainer/Alpha Loss                      0.0106431\n",
      "exploration/num steps total        294443\n",
      "exploration/num paths total           397\n",
      "evaluation/num steps total              2.62792e+06\n",
      "evaluation/num paths total           2947\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66866\n",
      "evaluation/Rewards Std                  0.921162\n",
      "evaluation/Rewards Max                  6.61491\n",
      "evaluation/Rewards Min                 -1.4828\n",
      "evaluation/Returns Mean              4668.66\n",
      "evaluation/Returns Std                 96.2151\n",
      "evaluation/Returns Max               4822.99\n",
      "evaluation/Returns Min               4534.36\n",
      "evaluation/Estimation Bias Mean       515.539\n",
      "evaluation/Estimation Bias Std        139.309\n",
      "evaluation/EB/Q_True Mean              41.2331\n",
      "evaluation/EB/Q_True Std              127.211\n",
      "evaluation/EB/Q_Pred Mean             556.772\n",
      "evaluation/EB/Q_Pred Std               57.6564\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4668.66\n",
      "evaluation/Actions Mean                 0.0190444\n",
      "evaluation/Actions Std                  0.538168\n",
      "evaluation/Actions Max                  0.999616\n",
      "evaluation/Actions Min                 -0.999692\n",
      "time/backward_policy (s)                1.97815\n",
      "time/backward_zf1 (s)                   2.15369\n",
      "time/backward_zf2 (s)                   2.07411\n",
      "time/data sampling (s)                  0.304361\n",
      "time/data storing (s)                   0.0157818\n",
      "time/evaluation sampling (s)            1.84205\n",
      "time/exploration sampling (s)           0.329783\n",
      "time/logging (s)                        0.012578\n",
      "time/preback_alpha (s)                  1.02944\n",
      "time/preback_policy (s)                 1.15898\n",
      "time/preback_start (s)                  0.149461\n",
      "time/preback_zf (s)                     5.2312\n",
      "time/saving (s)                         0.00566755\n",
      "time/training (s)                       2.18122\n",
      "time/epoch (s)                         18.4665\n",
      "time/total (s)                       5205.01\n",
      "Epoch                                 289\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:19:23.703083 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 290 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 301000\n",
      "trainer/ZF1 Loss                       24.2821\n",
      "trainer/ZF2 Loss                       12.9124\n",
      "trainer/ZF Expert Reward               12.6454\n",
      "trainer/ZF Policy Reward               -0.597356\n",
      "trainer/ZF CHI2 Term                   51.4303\n",
      "trainer/Policy Loss                  -464.759\n",
      "trainer/Bias Loss                      58.5059\n",
      "trainer/Bias Value                     15.2674\n",
      "trainer/Policy Grad Norm              190.396\n",
      "trainer/Policy Param Norm              38.4051\n",
      "trainer/Zf1 Grad Norm                1978.46\n",
      "trainer/Zf1 Param Norm                125.702\n",
      "trainer/Zf2 Grad Norm                1612.82\n",
      "trainer/Zf2 Param Norm                124.159\n",
      "trainer/Z Expert Predictions Mean     577.014\n",
      "trainer/Z Expert Predictions Std       55.0816\n",
      "trainer/Z Expert Predictions Max      661.698\n",
      "trainer/Z Expert Predictions Min      212.275\n",
      "trainer/Z Policy Predictions Mean     463.546\n",
      "trainer/Z Policy Predictions Std      258.03\n",
      "trainer/Z Policy Predictions Max      636.498\n",
      "trainer/Z Policy Predictions Min     -722.682\n",
      "trainer/Z Expert Targets Mean         564.369\n",
      "trainer/Z Expert Targets Std           57.2668\n",
      "trainer/Z Expert Targets Max          644.76\n",
      "trainer/Z Expert Targets Min          199.648\n",
      "trainer/Z Policy Targets Mean         464.143\n",
      "trainer/Z Policy Targets Std          257.621\n",
      "trainer/Z Policy Targets Max          632.523\n",
      "trainer/Z Policy Targets Min         -725.225\n",
      "trainer/Log Pis Mean                   19.7881\n",
      "trainer/Log Pis Std                     4.25386\n",
      "trainer/Policy mu Mean                  0.0218304\n",
      "trainer/Policy mu Std                   0.898531\n",
      "trainer/Policy log std Mean            -3.30328\n",
      "trainer/Policy log std Std              0.876293\n",
      "trainer/Alpha                           0.175751\n",
      "trainer/Alpha Loss                      0.0372457\n",
      "exploration/num steps total        295443\n",
      "exploration/num paths total           398\n",
      "evaluation/num steps total              2.63717e+06\n",
      "evaluation/num paths total           2957\n",
      "evaluation/path length Mean           925\n",
      "evaluation/path length Std            225\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            250\n",
      "evaluation/Rewards Mean                 4.60834\n",
      "evaluation/Rewards Std                  1.05899\n",
      "evaluation/Rewards Max                  6.87548\n",
      "evaluation/Rewards Min                 -2.53559\n",
      "evaluation/Returns Mean              4262.71\n",
      "evaluation/Returns Std               1068.44\n",
      "evaluation/Returns Max               4772.25\n",
      "evaluation/Returns Min               1069.04\n",
      "evaluation/Estimation Bias Mean       495.098\n",
      "evaluation/Estimation Bias Std        152.938\n",
      "evaluation/EB/Q_True Mean              44.3629\n",
      "evaluation/EB/Q_True Std              130.963\n",
      "evaluation/EB/Q_Pred Mean             539.461\n",
      "evaluation/EB/Q_Pred Std               67.8947\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4262.71\n",
      "evaluation/Actions Mean                 0.0242189\n",
      "evaluation/Actions Std                  0.53692\n",
      "evaluation/Actions Max                  0.999521\n",
      "evaluation/Actions Min                 -0.999909\n",
      "time/backward_policy (s)                1.91909\n",
      "time/backward_zf1 (s)                   2.05857\n",
      "time/backward_zf2 (s)                   1.97868\n",
      "time/data sampling (s)                  0.305607\n",
      "time/data storing (s)                   0.014952\n",
      "time/evaluation sampling (s)            1.71426\n",
      "time/exploration sampling (s)           0.320551\n",
      "time/logging (s)                        0.0116055\n",
      "time/preback_alpha (s)                  1.01276\n",
      "time/preback_policy (s)                 1.14298\n",
      "time/preback_start (s)                  0.149204\n",
      "time/preback_zf (s)                     5.23679\n",
      "time/saving (s)                         0.00604026\n",
      "time/training (s)                       2.26175\n",
      "time/epoch (s)                         18.1328\n",
      "time/total (s)                       5223.16\n",
      "Epoch                                 290\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:19:42.016500 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 291 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 302000\n",
      "trainer/ZF1 Loss                       15.8959\n",
      "trainer/ZF2 Loss                       18.6086\n",
      "trainer/ZF Expert Reward               13.5974\n",
      "trainer/ZF Policy Reward                4.21482\n",
      "trainer/ZF CHI2 Term                   46.3694\n",
      "trainer/Policy Loss                  -470.054\n",
      "trainer/Bias Loss                      65.1052\n",
      "trainer/Bias Value                     15.2814\n",
      "trainer/Policy Grad Norm              187.4\n",
      "trainer/Policy Param Norm              38.4268\n",
      "trainer/Zf1 Grad Norm                1661.21\n",
      "trainer/Zf1 Param Norm                125.815\n",
      "trainer/Zf2 Grad Norm                1482.29\n",
      "trainer/Zf2 Param Norm                124.273\n",
      "trainer/Z Expert Predictions Mean     581.941\n",
      "trainer/Z Expert Predictions Std       42.4125\n",
      "trainer/Z Expert Predictions Max      660.913\n",
      "trainer/Z Expert Predictions Min      358.71\n",
      "trainer/Z Policy Predictions Mean     471.134\n",
      "trainer/Z Policy Predictions Std      230.561\n",
      "trainer/Z Policy Predictions Max      670.197\n",
      "trainer/Z Policy Predictions Min     -710.41\n",
      "trainer/Z Expert Targets Mean         568.343\n",
      "trainer/Z Expert Targets Std           45.2679\n",
      "trainer/Z Expert Targets Max          644.9\n",
      "trainer/Z Expert Targets Min          344.175\n",
      "trainer/Z Policy Targets Mean         466.919\n",
      "trainer/Z Policy Targets Std          228.097\n",
      "trainer/Z Policy Targets Max          647.26\n",
      "trainer/Z Policy Targets Min         -692.176\n",
      "trainer/Log Pis Mean                   19.9339\n",
      "trainer/Log Pis Std                     4.29268\n",
      "trainer/Policy mu Mean                  0.021689\n",
      "trainer/Policy mu Std                   0.885168\n",
      "trainer/Policy log std Mean            -3.35596\n",
      "trainer/Policy log std Std              0.847613\n",
      "trainer/Alpha                           0.175947\n",
      "trainer/Alpha Loss                      0.011629\n",
      "exploration/num steps total        295443\n",
      "exploration/num paths total           398\n",
      "evaluation/num steps total              2.64666e+06\n",
      "evaluation/num paths total           2967\n",
      "evaluation/path length Mean           949\n",
      "evaluation/path length Std            153\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            490\n",
      "evaluation/Rewards Mean                 4.65667\n",
      "evaluation/Rewards Std                  1.02811\n",
      "evaluation/Rewards Max                  6.67551\n",
      "evaluation/Rewards Min                 -1.85119\n",
      "evaluation/Returns Mean              4419.18\n",
      "evaluation/Returns Std                764.909\n",
      "evaluation/Returns Max               4884.01\n",
      "evaluation/Returns Min               2147.55\n",
      "evaluation/Estimation Bias Mean       500.354\n",
      "evaluation/Estimation Bias Std        161.048\n",
      "evaluation/EB/Q_True Mean              47.1644\n",
      "evaluation/EB/Q_True Std              141.757\n",
      "evaluation/EB/Q_Pred Mean             547.518\n",
      "evaluation/EB/Q_Pred Std               68.3029\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4419.18\n",
      "evaluation/Actions Mean                 0.0271151\n",
      "evaluation/Actions Std                  0.535356\n",
      "evaluation/Actions Max                  0.999151\n",
      "evaluation/Actions Min                 -0.999739\n",
      "time/backward_policy (s)                1.96248\n",
      "time/backward_zf1 (s)                   2.09983\n",
      "time/backward_zf2 (s)                   2.02617\n",
      "time/data sampling (s)                  0.32331\n",
      "time/data storing (s)                   0.0161038\n",
      "time/evaluation sampling (s)            1.71765\n",
      "time/exploration sampling (s)           0.33218\n",
      "time/logging (s)                        0.0125101\n",
      "time/preback_alpha (s)                  1.0187\n",
      "time/preback_policy (s)                 1.1413\n",
      "time/preback_start (s)                  0.148773\n",
      "time/preback_zf (s)                     5.213\n",
      "time/saving (s)                         0.00624847\n",
      "time/training (s)                       2.22371\n",
      "time/epoch (s)                         18.242\n",
      "time/total (s)                       5241.43\n",
      "Epoch                                 291\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:20:00.906236 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 292 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 303000\n",
      "trainer/ZF1 Loss                       20.9511\n",
      "trainer/ZF2 Loss                       16.8717\n",
      "trainer/ZF Expert Reward               17.5998\n",
      "trainer/ZF Policy Reward                5.93475\n",
      "trainer/ZF CHI2 Term                   50.0183\n",
      "trainer/Policy Loss                  -478.31\n",
      "trainer/Bias Loss                      54.2713\n",
      "trainer/Bias Value                     15.2943\n",
      "trainer/Policy Grad Norm              177.349\n",
      "trainer/Policy Param Norm              38.4459\n",
      "trainer/Zf1 Grad Norm                1348.67\n",
      "trainer/Zf1 Param Norm                125.914\n",
      "trainer/Zf2 Grad Norm                1207.21\n",
      "trainer/Zf2 Param Norm                124.407\n",
      "trainer/Z Expert Predictions Mean     583.929\n",
      "trainer/Z Expert Predictions Std       45.2976\n",
      "trainer/Z Expert Predictions Max      659.741\n",
      "trainer/Z Expert Predictions Min      367.992\n",
      "trainer/Z Policy Predictions Mean     481.283\n",
      "trainer/Z Policy Predictions Std      177.509\n",
      "trainer/Z Policy Predictions Max      636.886\n",
      "trainer/Z Policy Predictions Min     -688.07\n",
      "trainer/Z Expert Targets Mean         566.329\n",
      "trainer/Z Expert Targets Std           47.3928\n",
      "trainer/Z Expert Targets Max          654.232\n",
      "trainer/Z Expert Targets Min          342.842\n",
      "trainer/Z Policy Targets Mean         475.349\n",
      "trainer/Z Policy Targets Std          175.4\n",
      "trainer/Z Policy Targets Max          625.553\n",
      "trainer/Z Policy Targets Min         -687.443\n",
      "trainer/Log Pis Mean                   19.6382\n",
      "trainer/Log Pis Std                     4.26298\n",
      "trainer/Policy mu Mean                  0.0337734\n",
      "trainer/Policy mu Std                   0.902332\n",
      "trainer/Policy log std Mean            -3.25663\n",
      "trainer/Policy log std Std              0.857461\n",
      "trainer/Alpha                           0.174898\n",
      "trainer/Alpha Loss                      0.0632718\n",
      "exploration/num steps total        297443\n",
      "exploration/num paths total           400\n",
      "evaluation/num steps total              2.65551e+06\n",
      "evaluation/num paths total           2977\n",
      "evaluation/path length Mean           885\n",
      "evaluation/path length Std            235.391\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            313\n",
      "evaluation/Rewards Mean                 4.64908\n",
      "evaluation/Rewards Std                  1.05168\n",
      "evaluation/Rewards Max                  6.71801\n",
      "evaluation/Rewards Min                 -1.65986\n",
      "evaluation/Returns Mean              4114.43\n",
      "evaluation/Returns Std               1131.21\n",
      "evaluation/Returns Max               4818.53\n",
      "evaluation/Returns Min               1388.71\n",
      "evaluation/Estimation Bias Mean       494.237\n",
      "evaluation/Estimation Bias Std        158.371\n",
      "evaluation/EB/Q_True Mean              48.178\n",
      "evaluation/EB/Q_True Std              138.32\n",
      "evaluation/EB/Q_Pred Mean             542.415\n",
      "evaluation/EB/Q_Pred Std               69.3961\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4114.43\n",
      "evaluation/Actions Mean                 0.0231224\n",
      "evaluation/Actions Std                  0.538471\n",
      "evaluation/Actions Max                  0.999686\n",
      "evaluation/Actions Min                 -0.999668\n",
      "time/backward_policy (s)                2.04283\n",
      "time/backward_zf1 (s)                   2.18525\n",
      "time/backward_zf2 (s)                   2.12826\n",
      "time/data sampling (s)                  0.331363\n",
      "time/data storing (s)                   0.0152293\n",
      "time/evaluation sampling (s)            1.74705\n",
      "time/exploration sampling (s)           0.332113\n",
      "time/logging (s)                        0.0109759\n",
      "time/preback_alpha (s)                  1.05008\n",
      "time/preback_policy (s)                 1.18642\n",
      "time/preback_start (s)                  0.152487\n",
      "time/preback_zf (s)                     5.28072\n",
      "time/saving (s)                         0.00596773\n",
      "time/training (s)                       2.34754\n",
      "time/epoch (s)                         18.8163\n",
      "time/total (s)                       5260.26\n",
      "Epoch                                 292\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:20:19.369837 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 293 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 304000\n",
      "trainer/ZF1 Loss                       32.1637\n",
      "trainer/ZF2 Loss                       24.7988\n",
      "trainer/ZF Expert Reward               14.2144\n",
      "trainer/ZF Policy Reward                4.64705\n",
      "trainer/ZF CHI2 Term                   57.423\n",
      "trainer/Policy Loss                  -473.699\n",
      "trainer/Bias Loss                      63.1628\n",
      "trainer/Bias Value                     15.3077\n",
      "trainer/Policy Grad Norm              156.897\n",
      "trainer/Policy Param Norm              38.4684\n",
      "trainer/Zf1 Grad Norm                1717.16\n",
      "trainer/Zf1 Param Norm                126.022\n",
      "trainer/Zf2 Grad Norm                1679.29\n",
      "trainer/Zf2 Param Norm                124.518\n",
      "trainer/Z Expert Predictions Mean     568.767\n",
      "trainer/Z Expert Predictions Std       61.9289\n",
      "trainer/Z Expert Predictions Max      651.443\n",
      "trainer/Z Expert Predictions Min       25.2668\n",
      "trainer/Z Policy Predictions Mean     473.053\n",
      "trainer/Z Policy Predictions Std      192.226\n",
      "trainer/Z Policy Predictions Max      621.59\n",
      "trainer/Z Policy Predictions Min     -675.333\n",
      "trainer/Z Expert Targets Mean         554.552\n",
      "trainer/Z Expert Targets Std           64.5797\n",
      "trainer/Z Expert Targets Max          634.944\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         468.406\n",
      "trainer/Z Policy Targets Std          191.239\n",
      "trainer/Z Policy Targets Max          612.367\n",
      "trainer/Z Policy Targets Min         -675.21\n",
      "trainer/Log Pis Mean                   19.5701\n",
      "trainer/Log Pis Std                     4.25214\n",
      "trainer/Policy mu Mean                  0.0248992\n",
      "trainer/Policy mu Std                   0.937493\n",
      "trainer/Policy log std Mean            -3.26889\n",
      "trainer/Policy log std Std              0.862505\n",
      "trainer/Alpha                           0.176041\n",
      "trainer/Alpha Loss                      0.0756763\n",
      "exploration/num steps total        299443\n",
      "exploration/num paths total           402\n",
      "evaluation/num steps total              2.66551e+06\n",
      "evaluation/num paths total           2987\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64145\n",
      "evaluation/Rewards Std                  0.960299\n",
      "evaluation/Rewards Max                  6.77195\n",
      "evaluation/Rewards Min                 -1.75801\n",
      "evaluation/Returns Mean              4641.45\n",
      "evaluation/Returns Std                 98.8835\n",
      "evaluation/Returns Max               4760.28\n",
      "evaluation/Returns Min               4434.74\n",
      "evaluation/Estimation Bias Mean       505.029\n",
      "evaluation/Estimation Bias Std        142.101\n",
      "evaluation/EB/Q_True Mean              42.9621\n",
      "evaluation/EB/Q_True Std              132.705\n",
      "evaluation/EB/Q_Pred Mean             547.991\n",
      "evaluation/EB/Q_Pred Std               57.3146\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4641.45\n",
      "evaluation/Actions Mean                 0.0188709\n",
      "evaluation/Actions Std                  0.542158\n",
      "evaluation/Actions Max                  0.999073\n",
      "evaluation/Actions Min                 -0.999479\n",
      "time/backward_policy (s)                1.98176\n",
      "time/backward_zf1 (s)                   2.16356\n",
      "time/backward_zf2 (s)                   2.04738\n",
      "time/data sampling (s)                  0.322044\n",
      "time/data storing (s)                   0.0153202\n",
      "time/evaluation sampling (s)            1.72337\n",
      "time/exploration sampling (s)           0.327119\n",
      "time/logging (s)                        0.0130357\n",
      "time/preback_alpha (s)                  1.02996\n",
      "time/preback_policy (s)                 1.15534\n",
      "time/preback_start (s)                  0.149009\n",
      "time/preback_zf (s)                     5.23691\n",
      "time/saving (s)                         0.00639245\n",
      "time/training (s)                       2.22433\n",
      "time/epoch (s)                         18.3955\n",
      "time/total (s)                       5278.68\n",
      "Epoch                                 293\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:20:37.444044 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 294 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 305000\n",
      "trainer/ZF1 Loss                        9.9515\n",
      "trainer/ZF2 Loss                        6.19698\n",
      "trainer/ZF Expert Reward               17.3066\n",
      "trainer/ZF Policy Reward                5.4366\n",
      "trainer/ZF CHI2 Term                   40.1074\n",
      "trainer/Policy Loss                  -459.437\n",
      "trainer/Bias Loss                      46.9587\n",
      "trainer/Bias Value                     15.3176\n",
      "trainer/Policy Grad Norm              205.749\n",
      "trainer/Policy Param Norm              38.4886\n",
      "trainer/Zf1 Grad Norm                1220.55\n",
      "trainer/Zf1 Param Norm                126.14\n",
      "trainer/Zf2 Grad Norm                1088.98\n",
      "trainer/Zf2 Param Norm                124.644\n",
      "trainer/Z Expert Predictions Mean     578.582\n",
      "trainer/Z Expert Predictions Std       41.3888\n",
      "trainer/Z Expert Predictions Max      660.853\n",
      "trainer/Z Expert Predictions Min      378.233\n",
      "trainer/Z Policy Predictions Mean     462.262\n",
      "trainer/Z Policy Predictions Std      250.079\n",
      "trainer/Z Policy Predictions Max      630.559\n",
      "trainer/Z Policy Predictions Min     -699.082\n",
      "trainer/Z Expert Targets Mean         561.276\n",
      "trainer/Z Expert Targets Std           43.5912\n",
      "trainer/Z Expert Targets Max          640.238\n",
      "trainer/Z Expert Targets Min          318.231\n",
      "trainer/Z Policy Targets Mean         456.825\n",
      "trainer/Z Policy Targets Std          247.305\n",
      "trainer/Z Policy Targets Max          623.778\n",
      "trainer/Z Policy Targets Min         -686.759\n",
      "trainer/Log Pis Mean                   20.3669\n",
      "trainer/Log Pis Std                     4.2484\n",
      "trainer/Policy mu Mean                  0.0336821\n",
      "trainer/Policy mu Std                   0.938601\n",
      "trainer/Policy log std Mean            -3.32882\n",
      "trainer/Policy log std Std              0.89414\n",
      "trainer/Alpha                           0.17663\n",
      "trainer/Alpha Loss                     -0.064799\n",
      "exploration/num steps total        300443\n",
      "exploration/num paths total           403\n",
      "evaluation/num steps total              2.67472e+06\n",
      "evaluation/num paths total           2997\n",
      "evaluation/path length Mean           921.5\n",
      "evaluation/path length Std            235.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            215\n",
      "evaluation/Rewards Mean                 4.67296\n",
      "evaluation/Rewards Std                  1.0984\n",
      "evaluation/Rewards Max                  6.80533\n",
      "evaluation/Rewards Min                 -2.64892\n",
      "evaluation/Returns Mean              4306.14\n",
      "evaluation/Returns Std               1133.09\n",
      "evaluation/Returns Max               4919.06\n",
      "evaluation/Returns Min                938.747\n",
      "evaluation/Estimation Bias Mean       485.895\n",
      "evaluation/Estimation Bias Std        169.006\n",
      "evaluation/EB/Q_True Mean              46.5115\n",
      "evaluation/EB/Q_True Std              137.01\n",
      "evaluation/EB/Q_Pred Mean             532.406\n",
      "evaluation/EB/Q_Pred Std               73.2377\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4306.14\n",
      "evaluation/Actions Mean                 0.0165771\n",
      "evaluation/Actions Std                  0.538107\n",
      "evaluation/Actions Max                  0.999547\n",
      "evaluation/Actions Min                 -0.999752\n",
      "time/backward_policy (s)                1.8621\n",
      "time/backward_zf1 (s)                   1.98642\n",
      "time/backward_zf2 (s)                   1.91384\n",
      "time/data sampling (s)                  0.310873\n",
      "time/data storing (s)                   0.0147597\n",
      "time/evaluation sampling (s)            1.76961\n",
      "time/exploration sampling (s)           0.320103\n",
      "time/logging (s)                        0.0109211\n",
      "time/preback_alpha (s)                  0.968974\n",
      "time/preback_policy (s)                 1.07633\n",
      "time/preback_start (s)                  0.14759\n",
      "time/preback_zf (s)                     5.24283\n",
      "time/saving (s)                         0.00605611\n",
      "time/training (s)                       2.37197\n",
      "time/epoch (s)                         18.0024\n",
      "time/total (s)                       5296.7\n",
      "Epoch                                 294\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:20:55.693411 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 295 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 306000\n",
      "trainer/ZF1 Loss                       11.7705\n",
      "trainer/ZF2 Loss                       15.1072\n",
      "trainer/ZF Expert Reward               17.4903\n",
      "trainer/ZF Policy Reward                6.05802\n",
      "trainer/ZF CHI2 Term                   44.6178\n",
      "trainer/Policy Loss                  -478.993\n",
      "trainer/Bias Loss                      61.3052\n",
      "trainer/Bias Value                     15.3277\n",
      "trainer/Policy Grad Norm              152.574\n",
      "trainer/Policy Param Norm              38.5107\n",
      "trainer/Zf1 Grad Norm                1230.81\n",
      "trainer/Zf1 Param Norm                126.242\n",
      "trainer/Zf2 Grad Norm                1162.58\n",
      "trainer/Zf2 Param Norm                124.768\n",
      "trainer/Z Expert Predictions Mean     577.745\n",
      "trainer/Z Expert Predictions Std       43.2911\n",
      "trainer/Z Expert Predictions Max      658.863\n",
      "trainer/Z Expert Predictions Min      337.803\n",
      "trainer/Z Policy Predictions Mean     480.847\n",
      "trainer/Z Policy Predictions Std      198.822\n",
      "trainer/Z Policy Predictions Max      619.205\n",
      "trainer/Z Policy Predictions Min     -706.681\n",
      "trainer/Z Expert Targets Mean         560.255\n",
      "trainer/Z Expert Targets Std           44.8908\n",
      "trainer/Z Expert Targets Max          650.272\n",
      "trainer/Z Expert Targets Min          295.995\n",
      "trainer/Z Policy Targets Mean         474.789\n",
      "trainer/Z Policy Targets Std          194.418\n",
      "trainer/Z Policy Targets Max          609.368\n",
      "trainer/Z Policy Targets Min         -684.627\n",
      "trainer/Log Pis Mean                   19.9461\n",
      "trainer/Log Pis Std                     4.55862\n",
      "trainer/Policy mu Mean                  0.0370698\n",
      "trainer/Policy mu Std                   0.881701\n",
      "trainer/Policy log std Mean            -3.38104\n",
      "trainer/Policy log std Std              0.82932\n",
      "trainer/Alpha                           0.176559\n",
      "trainer/Alpha Loss                      0.00951007\n",
      "exploration/num steps total        301443\n",
      "exploration/num paths total           404\n",
      "evaluation/num steps total              2.68375e+06\n",
      "evaluation/num paths total           3007\n",
      "evaluation/path length Mean           902.1\n",
      "evaluation/path length Std            293.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             21\n",
      "evaluation/Rewards Mean                 4.77151\n",
      "evaluation/Rewards Std                  1.02998\n",
      "evaluation/Rewards Max                  6.923\n",
      "evaluation/Rewards Min                 -1.54915\n",
      "evaluation/Returns Mean              4304.38\n",
      "evaluation/Returns Std               1424.19\n",
      "evaluation/Returns Max               4854.93\n",
      "evaluation/Returns Min                 36.0473\n",
      "evaluation/Estimation Bias Mean       481.436\n",
      "evaluation/Estimation Bias Std        155.295\n",
      "evaluation/EB/Q_True Mean              49.0596\n",
      "evaluation/EB/Q_True Std              143.064\n",
      "evaluation/EB/Q_Pred Mean             530.495\n",
      "evaluation/EB/Q_Pred Std               61.4617\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4304.38\n",
      "evaluation/Actions Mean                 0.0180144\n",
      "evaluation/Actions Std                  0.536428\n",
      "evaluation/Actions Max                  0.999505\n",
      "evaluation/Actions Min                 -0.999631\n",
      "time/backward_policy (s)                1.904\n",
      "time/backward_zf1 (s)                   2.06593\n",
      "time/backward_zf2 (s)                   1.98125\n",
      "time/data sampling (s)                  0.327838\n",
      "time/data storing (s)                   0.015191\n",
      "time/evaluation sampling (s)            1.77554\n",
      "time/exploration sampling (s)           0.326683\n",
      "time/logging (s)                        0.0113992\n",
      "time/preback_alpha (s)                  1.00716\n",
      "time/preback_policy (s)                 1.12801\n",
      "time/preback_start (s)                  0.146876\n",
      "time/preback_zf (s)                     5.21733\n",
      "time/saving (s)                         0.00592725\n",
      "time/training (s)                       2.26553\n",
      "time/epoch (s)                         18.1787\n",
      "time/total (s)                       5314.9\n",
      "Epoch                                 295\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:21:14.335428 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 296 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 307000\n",
      "trainer/ZF1 Loss                       82.2618\n",
      "trainer/ZF2 Loss                       79.2512\n",
      "trainer/ZF Expert Reward               15.8312\n",
      "trainer/ZF Policy Reward                6.21307\n",
      "trainer/ZF CHI2 Term                  110.487\n",
      "trainer/Policy Loss                  -464.506\n",
      "trainer/Bias Loss                      62.8805\n",
      "trainer/Bias Value                     15.3384\n",
      "trainer/Policy Grad Norm              179.515\n",
      "trainer/Policy Param Norm              38.5308\n",
      "trainer/Zf1 Grad Norm                1708.72\n",
      "trainer/Zf1 Param Norm                126.35\n",
      "trainer/Zf2 Grad Norm                1749.77\n",
      "trainer/Zf2 Param Norm                124.897\n",
      "trainer/Z Expert Predictions Mean     567.612\n",
      "trainer/Z Expert Predictions Std       43.7904\n",
      "trainer/Z Expert Predictions Max      647.054\n",
      "trainer/Z Expert Predictions Min      340.888\n",
      "trainer/Z Policy Predictions Mean     470.209\n",
      "trainer/Z Policy Predictions Std      207.611\n",
      "trainer/Z Policy Predictions Max      625.749\n",
      "trainer/Z Policy Predictions Min     -706.549\n",
      "trainer/Z Expert Targets Mean         551.78\n",
      "trainer/Z Expert Targets Std           44.7868\n",
      "trainer/Z Expert Targets Max          632.011\n",
      "trainer/Z Expert Targets Min          323.153\n",
      "trainer/Z Policy Targets Mean         463.996\n",
      "trainer/Z Policy Targets Std          206.454\n",
      "trainer/Z Policy Targets Max          612.442\n",
      "trainer/Z Policy Targets Min         -715.493\n",
      "trainer/Log Pis Mean                   20.3157\n",
      "trainer/Log Pis Std                     3.78203\n",
      "trainer/Policy mu Mean                  0.0241682\n",
      "trainer/Policy mu Std                   0.922766\n",
      "trainer/Policy log std Mean            -3.37651\n",
      "trainer/Policy log std Std              0.843971\n",
      "trainer/Alpha                           0.176523\n",
      "trainer/Alpha Loss                     -0.0557275\n",
      "exploration/num steps total        303443\n",
      "exploration/num paths total           406\n",
      "evaluation/num steps total              2.69277e+06\n",
      "evaluation/num paths total           3017\n",
      "evaluation/path length Mean           902\n",
      "evaluation/path length Std            294\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             20\n",
      "evaluation/Rewards Mean                 4.62358\n",
      "evaluation/Rewards Std                  0.969525\n",
      "evaluation/Rewards Max                  6.68389\n",
      "evaluation/Rewards Min                 -1.67282\n",
      "evaluation/Returns Mean              4170.47\n",
      "evaluation/Returns Std               1382.65\n",
      "evaluation/Returns Max               4718.12\n",
      "evaluation/Returns Min                 25.7079\n",
      "evaluation/Estimation Bias Mean       489.019\n",
      "evaluation/Estimation Bias Std        146.774\n",
      "evaluation/EB/Q_True Mean              46.9757\n",
      "evaluation/EB/Q_True Std              136.416\n",
      "evaluation/EB/Q_Pred Mean             535.995\n",
      "evaluation/EB/Q_Pred Std               57.4747\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4170.47\n",
      "evaluation/Actions Mean                 0.0194728\n",
      "evaluation/Actions Std                  0.536951\n",
      "evaluation/Actions Max                  0.998714\n",
      "evaluation/Actions Min                 -0.999689\n",
      "time/backward_policy (s)                2.01778\n",
      "time/backward_zf1 (s)                   2.17633\n",
      "time/backward_zf2 (s)                   2.10707\n",
      "time/data sampling (s)                  0.321173\n",
      "time/data storing (s)                   0.0153066\n",
      "time/evaluation sampling (s)            1.78033\n",
      "time/exploration sampling (s)           0.328687\n",
      "time/logging (s)                        0.011136\n",
      "time/preback_alpha (s)                  1.05358\n",
      "time/preback_policy (s)                 1.20828\n",
      "time/preback_start (s)                  0.148748\n",
      "time/preback_zf (s)                     5.25559\n",
      "time/saving (s)                         0.00593469\n",
      "time/training (s)                       2.13771\n",
      "time/epoch (s)                         18.5677\n",
      "time/total (s)                       5333.49\n",
      "Epoch                                 296\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:21:32.531001 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 297 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 308000\n",
      "trainer/ZF1 Loss                       72.0893\n",
      "trainer/ZF2 Loss                       65.2547\n",
      "trainer/ZF Expert Reward               17.7246\n",
      "trainer/ZF Policy Reward                6.96296\n",
      "trainer/ZF CHI2 Term                   99.5331\n",
      "trainer/Policy Loss                  -458.757\n",
      "trainer/Bias Loss                      59.6852\n",
      "trainer/Bias Value                     15.3503\n",
      "trainer/Policy Grad Norm              199.857\n",
      "trainer/Policy Param Norm              38.5494\n",
      "trainer/Zf1 Grad Norm                1859.29\n",
      "trainer/Zf1 Param Norm                126.461\n",
      "trainer/Zf2 Grad Norm                1443.29\n",
      "trainer/Zf2 Param Norm                124.998\n",
      "trainer/Z Expert Predictions Mean     568.574\n",
      "trainer/Z Expert Predictions Std       53.8897\n",
      "trainer/Z Expert Predictions Max      647.832\n",
      "trainer/Z Expert Predictions Min       54.6446\n",
      "trainer/Z Policy Predictions Mean     462.649\n",
      "trainer/Z Policy Predictions Std      229.402\n",
      "trainer/Z Policy Predictions Max      632.751\n",
      "trainer/Z Policy Predictions Min     -700.633\n",
      "trainer/Z Expert Targets Mean         550.85\n",
      "trainer/Z Expert Targets Std           56.5854\n",
      "trainer/Z Expert Targets Max          638.69\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         455.686\n",
      "trainer/Z Policy Targets Std          229.547\n",
      "trainer/Z Policy Targets Max          626.284\n",
      "trainer/Z Policy Targets Min         -703.234\n",
      "trainer/Log Pis Mean                   20.3025\n",
      "trainer/Log Pis Std                     3.7587\n",
      "trainer/Policy mu Mean                  0.0154551\n",
      "trainer/Policy mu Std                   0.916696\n",
      "trainer/Policy log std Mean            -3.36381\n",
      "trainer/Policy log std Std              0.867438\n",
      "trainer/Alpha                           0.176254\n",
      "trainer/Alpha Loss                     -0.0533164\n",
      "exploration/num steps total        303443\n",
      "exploration/num paths total           406\n",
      "evaluation/num steps total              2.70277e+06\n",
      "evaluation/num paths total           3027\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64207\n",
      "evaluation/Rewards Std                  0.930659\n",
      "evaluation/Rewards Max                  6.65689\n",
      "evaluation/Rewards Min                 -1.67836\n",
      "evaluation/Returns Mean              4642.07\n",
      "evaluation/Returns Std                 56.114\n",
      "evaluation/Returns Max               4717.7\n",
      "evaluation/Returns Min               4530.09\n",
      "evaluation/Estimation Bias Mean       493.216\n",
      "evaluation/Estimation Bias Std        137.366\n",
      "evaluation/EB/Q_True Mean              41.4602\n",
      "evaluation/EB/Q_True Std              127.407\n",
      "evaluation/EB/Q_Pred Mean             534.677\n",
      "evaluation/EB/Q_Pred Std               54.9112\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4642.07\n",
      "evaluation/Actions Mean                 0.0206197\n",
      "evaluation/Actions Std                  0.540225\n",
      "evaluation/Actions Max                  0.999572\n",
      "evaluation/Actions Min                 -0.999772\n",
      "time/backward_policy (s)                1.90864\n",
      "time/backward_zf1 (s)                   2.07925\n",
      "time/backward_zf2 (s)                   1.98524\n",
      "time/data sampling (s)                  0.322919\n",
      "time/data storing (s)                   0.0149038\n",
      "time/evaluation sampling (s)            1.75185\n",
      "time/exploration sampling (s)           0.319578\n",
      "time/logging (s)                        0.0129235\n",
      "time/preback_alpha (s)                  1.0012\n",
      "time/preback_policy (s)                 1.12101\n",
      "time/preback_start (s)                  0.147051\n",
      "time/preback_zf (s)                     5.21804\n",
      "time/saving (s)                         0.00633608\n",
      "time/training (s)                       2.23625\n",
      "time/epoch (s)                         18.1252\n",
      "time/total (s)                       5351.64\n",
      "Epoch                                 297\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:21:50.898143 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 298 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 309000\n",
      "trainer/ZF1 Loss                       18.5755\n",
      "trainer/ZF2 Loss                       21.6827\n",
      "trainer/ZF Expert Reward               13.5438\n",
      "trainer/ZF Policy Reward                4.37155\n",
      "trainer/ZF CHI2 Term                   48.7732\n",
      "trainer/Policy Loss                  -438.201\n",
      "trainer/Bias Loss                      67.3319\n",
      "trainer/Bias Value                     15.3587\n",
      "trainer/Policy Grad Norm              159.253\n",
      "trainer/Policy Param Norm              38.5677\n",
      "trainer/Zf1 Grad Norm                1442.51\n",
      "trainer/Zf1 Param Norm                126.578\n",
      "trainer/Zf2 Grad Norm                1712.16\n",
      "trainer/Zf2 Param Norm                125.133\n",
      "trainer/Z Expert Predictions Mean     560.144\n",
      "trainer/Z Expert Predictions Std       44.343\n",
      "trainer/Z Expert Predictions Max      641.868\n",
      "trainer/Z Expert Predictions Min      334.902\n",
      "trainer/Z Policy Predictions Mean     441.729\n",
      "trainer/Z Policy Predictions Std      258.053\n",
      "trainer/Z Policy Predictions Max      621.25\n",
      "trainer/Z Policy Predictions Min     -720.422\n",
      "trainer/Z Expert Targets Mean         546.6\n",
      "trainer/Z Expert Targets Std           47.1567\n",
      "trainer/Z Expert Targets Max          634.52\n",
      "trainer/Z Expert Targets Min          298.882\n",
      "trainer/Z Policy Targets Mean         437.358\n",
      "trainer/Z Policy Targets Std          253.76\n",
      "trainer/Z Policy Targets Max          613.161\n",
      "trainer/Z Policy Targets Min         -703.901\n",
      "trainer/Log Pis Mean                   19.6685\n",
      "trainer/Log Pis Std                     4.48328\n",
      "trainer/Policy mu Mean                  0.0133916\n",
      "trainer/Policy mu Std                   0.933005\n",
      "trainer/Policy log std Mean            -3.29669\n",
      "trainer/Policy log std Std              0.889744\n",
      "trainer/Alpha                           0.175462\n",
      "trainer/Alpha Loss                      0.0581669\n",
      "exploration/num steps total        303443\n",
      "exploration/num paths total           406\n",
      "evaluation/num steps total              2.71277e+06\n",
      "evaluation/num paths total           3037\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66077\n",
      "evaluation/Rewards Std                  1.06765\n",
      "evaluation/Rewards Max                  6.82909\n",
      "evaluation/Rewards Min                 -2.80226\n",
      "evaluation/Returns Mean              4660.77\n",
      "evaluation/Returns Std                 77.2822\n",
      "evaluation/Returns Max               4853.61\n",
      "evaluation/Returns Min               4576.96\n",
      "evaluation/Estimation Bias Mean       475.139\n",
      "evaluation/Estimation Bias Std        150.98\n",
      "evaluation/EB/Q_True Mean              43.2894\n",
      "evaluation/EB/Q_True Std              134.206\n",
      "evaluation/EB/Q_Pred Mean             518.428\n",
      "evaluation/EB/Q_Pred Std               69.8891\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4660.77\n",
      "evaluation/Actions Mean                 0.0222409\n",
      "evaluation/Actions Std                  0.535376\n",
      "evaluation/Actions Max                  0.999905\n",
      "evaluation/Actions Min                 -0.999806\n",
      "time/backward_policy (s)                1.96899\n",
      "time/backward_zf1 (s)                   2.05928\n",
      "time/backward_zf2 (s)                   2.01066\n",
      "time/data sampling (s)                  0.331309\n",
      "time/data storing (s)                   0.015875\n",
      "time/evaluation sampling (s)            1.71219\n",
      "time/exploration sampling (s)           0.323976\n",
      "time/logging (s)                        0.0136029\n",
      "time/preback_alpha (s)                  1.02373\n",
      "time/preback_policy (s)                 1.15468\n",
      "time/preback_start (s)                  0.148416\n",
      "time/preback_zf (s)                     5.24714\n",
      "time/saving (s)                         0.0114232\n",
      "time/training (s)                       2.27613\n",
      "time/epoch (s)                         18.2974\n",
      "time/total (s)                       5369.95\n",
      "Epoch                                 298\n",
      "---------------------------------  ----------------\n",
      "2024-06-15 12:22:09.532021 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_15_10_52_07_0000--s-2] Epoch 299 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 310000\n",
      "trainer/ZF1 Loss                       85.4067\n",
      "trainer/ZF2 Loss                       86.8786\n",
      "trainer/ZF Expert Reward               11.7623\n",
      "trainer/ZF Policy Reward               -4.87707\n",
      "trainer/ZF CHI2 Term                  122.358\n",
      "trainer/Policy Loss                  -445.24\n",
      "trainer/Bias Loss                      67.5675\n",
      "trainer/Bias Value                     15.3671\n",
      "trainer/Policy Grad Norm              167.118\n",
      "trainer/Policy Param Norm              38.5865\n",
      "trainer/Zf1 Grad Norm                1808.65\n",
      "trainer/Zf1 Param Norm                126.702\n",
      "trainer/Zf2 Grad Norm                2108.16\n",
      "trainer/Zf2 Param Norm                125.252\n",
      "trainer/Z Expert Predictions Mean     555.954\n",
      "trainer/Z Expert Predictions Std       54.4791\n",
      "trainer/Z Expert Predictions Max      621.269\n",
      "trainer/Z Expert Predictions Min      -20.3405\n",
      "trainer/Z Policy Predictions Mean     445.503\n",
      "trainer/Z Policy Predictions Std      226.961\n",
      "trainer/Z Policy Predictions Max      622.748\n",
      "trainer/Z Policy Predictions Min     -707.881\n",
      "trainer/Z Expert Targets Mean         544.192\n",
      "trainer/Z Expert Targets Std           54.3566\n",
      "trainer/Z Expert Targets Max          616.145\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         450.38\n",
      "trainer/Z Policy Targets Std          216.423\n",
      "trainer/Z Policy Targets Max          607.258\n",
      "trainer/Z Policy Targets Min         -708.49\n",
      "trainer/Log Pis Mean                   19.7739\n",
      "trainer/Log Pis Std                     4.31026\n",
      "trainer/Policy mu Mean                 -0.00558554\n",
      "trainer/Policy mu Std                   0.906739\n",
      "trainer/Policy log std Mean            -3.31639\n",
      "trainer/Policy log std Std              0.872579\n",
      "trainer/Alpha                           0.176673\n",
      "trainer/Alpha Loss                      0.039947\n",
      "exploration/num steps total        304443\n",
      "exploration/num paths total           407\n",
      "evaluation/num steps total              2.72253e+06\n",
      "evaluation/num paths total           3048\n",
      "evaluation/path length Mean           887.818\n",
      "evaluation/path length Std            239.785\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            314\n",
      "evaluation/Rewards Mean                 4.7\n",
      "evaluation/Rewards Std                  0.968968\n",
      "evaluation/Rewards Max                  6.81802\n",
      "evaluation/Rewards Min                 -1.96591\n",
      "evaluation/Returns Mean              4172.75\n",
      "evaluation/Returns Std               1184.24\n",
      "evaluation/Returns Max               4780.42\n",
      "evaluation/Returns Min               1325.06\n",
      "evaluation/Estimation Bias Mean       483.39\n",
      "evaluation/Estimation Bias Std        158.384\n",
      "evaluation/EB/Q_True Mean              44.4279\n",
      "evaluation/EB/Q_True Std              136.101\n",
      "evaluation/EB/Q_Pred Mean             527.818\n",
      "evaluation/EB/Q_Pred Std               61.0304\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4172.75\n",
      "evaluation/Actions Mean                 0.0241747\n",
      "evaluation/Actions Std                  0.539968\n",
      "evaluation/Actions Max                  0.999409\n",
      "evaluation/Actions Min                 -0.999869\n",
      "time/backward_policy (s)                1.97664\n",
      "time/backward_zf1 (s)                   2.14472\n",
      "time/backward_zf2 (s)                   2.04934\n",
      "time/data sampling (s)                  0.314603\n",
      "time/data storing (s)                   0.0156343\n",
      "time/evaluation sampling (s)            1.71731\n",
      "time/exploration sampling (s)           0.327998\n",
      "time/logging (s)                        0.0115873\n",
      "time/preback_alpha (s)                  1.01029\n",
      "time/preback_policy (s)                 1.13832\n",
      "time/preback_start (s)                  0.150804\n",
      "time/preback_zf (s)                     5.29404\n",
      "time/saving (s)                         0.00625695\n",
      "time/training (s)                       2.40276\n",
      "time/epoch (s)                         18.5603\n",
      "time/total (s)                       5388.53\n",
      "Epoch                                 299\n",
      "---------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    experiment(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6679a-5037-44ff-a459-897c0ee8c8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

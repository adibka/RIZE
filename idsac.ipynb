{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd095125-6be1-4c22-8760-d1fba60ab86d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## experiment (tqc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603bc9d-5ced-4410-9d8b-bc74345fd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_tqc(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant['layer_size']\n",
    "    num_quantiles = variant['num_quantiles']\n",
    "    n_nets = variant['n_nets']\n",
    "    \n",
    "    zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    target_zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = TruncIDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        zf=zf,\n",
    "        target_zf=target_zf,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b40f96-5af4-4fc9-8f5d-34bacdc440d8",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df783e4e-ddf6-45d9-8b26-6863e89107f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.data_management.torch_replay_buffer import TorchReplayBuffer\n",
    "from rlkit.envs import make_env\n",
    "from rlkit.envs.vecenv import SubprocVectorEnv, VectorEnv\n",
    "from rlkit.launchers.launcher_util import set_seed, setup_logger\n",
    "from rlkit.samplers.data_collector import (VecMdpPathCollector, VecMdpStepCollector)\n",
    "from rlkit.torch.idsac.idsac import IDSACTrainer\n",
    "from rlkit.torch.idsac.networks import QuantileMlp, Critic, softmax\n",
    "from rlkit.torch.networks import FlattenMlp\n",
    "from rlkit.torch.sac.policies import MakeDeterministic, TanhGaussianPolicy\n",
    "from rlkit.torch.torch_iq_algorithm import TorchVecOnlineIQAlgorithm\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba84c8-f8f8-4272-8885-83a6c028ee37",
   "metadata": {},
   "source": [
    "# experiment (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c847e24-53fa-4f9b-850b-c7b648d30304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant[\"layer_size\"]\n",
    "    num_quantiles = variant[\"num_quantiles\"]\n",
    "    tau_type = variant[\"trainer_kwargs\"][\"tau_type\"]\n",
    "    \n",
    "    zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M // 2],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    target_policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M // 2],\n",
    "    )\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "        zf1,\n",
    "        tau_type,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = IDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        target_policy=target_policy,\n",
    "        zf1=zf1,\n",
    "        zf2=zf2,\n",
    "        target_zf1=target_zf1,\n",
    "        target_zf2=target_zf2,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e380543-9ff2-4947-8cda-2f5b05957627",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fa2c3c-ae22-4830-bad1-8b99032cb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(dsac_cfg_path,\n",
    "               expert_path,\n",
    "               iq_cfg_path='configs/dsac-normal-iqn-neutral/iq.yaml',\n",
    "               cql_cfg_path='configs/dsac-normal-iqn-neutral/cql.yaml'\n",
    "              ):\n",
    "    \n",
    "    with open(dsac_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        variant = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    with open(iq_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        iq_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    with open(cql_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        cql_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    iq_cfg['expert_path'] = expert_path\n",
    "    variant['iq_kwargs'] = iq_cfg\n",
    "    variant['cql_kwargs'] = cql_cfg\n",
    "    return variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40faac3-2a8c-49fc-bece-f891df61d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = get_config(dsac_cfg_path='configs/dsac-normal-iqn-neutral/walker2d.yaml',\n",
    "                     expert_path='experts/Walker2d-v2_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00203431-e8bc-4e42-977f-298ec40d51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:10:29.913135 +0330 | Variant:\n",
      "2024-06-18 17:10:29.914386 +0330 | {\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"min_num_steps_before_training\": 10000,\n",
      "    \"num_epochs\": 300,\n",
      "    \"num_eval_paths_per_epoch\": 10,\n",
      "    \"num_expl_steps_per_train_loop\": 1000,\n",
      "    \"num_trains_per_train_loop\": 1000\n",
      "  },\n",
      "  \"env\": \"Walker2d-v2\",\n",
      "  \"seed\": 0,\n",
      "  \"expectation_z\": false,\n",
      "  \"eval_env_num\": 10,\n",
      "  \"expl_env_num\": 10,\n",
      "  \"layer_size\": 256,\n",
      "  \"num_quantiles\": 24,\n",
      "  \"replay_buffer_size\": 1000000,\n",
      "  \"trainer_kwargs\": {\n",
      "    \"alpha\": 0.01,\n",
      "    \"discount\": 0.99,\n",
      "    \"policy_lr\": 0.0001,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"tau_type\": \"iqn\",\n",
      "    \"target_entropy\": -20.0,\n",
      "    \"use_automatic_entropy_tuning\": true,\n",
      "    \"zf_lr\": 0.0003,\n",
      "    \"bias\": 15.0,\n",
      "    \"bias_lr\": 0.0001,\n",
      "    \"use_automatic_bias_tuning\": true\n",
      "  },\n",
      "  \"version\": \"normal-iqn-neutral\",\n",
      "  \"iq_kwargs\": {\n",
      "    \"expert_path\": \"experts/Walker2d-v2_25.pkl\",\n",
      "    \"subsample_freq\": 1,\n",
      "    \"demos\": 10,\n",
      "    \"regularize\": true,\n",
      "    \"div\": null,\n",
      "    \"loss\": \"value_policy\",\n",
      "    \"alpha\": 2.5\n",
      "  },\n",
      "  \"cql_kwargs\": {\n",
      "    \"use_cql\": false,\n",
      "    \"cql_weight\": 0.05,\n",
      "    \"num_random\": 10,\n",
      "    \"with_lagrange\": false,\n",
      "    \"lagrange_thresh\": 10.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    ptu.set_gpu_mode(True, 0)\n",
    "    # device = torch.device('cuda:0')\n",
    "seed = variant[\"seed\"]\n",
    "set_seed(seed)\n",
    "log_prefix = \"_\".join([\"idsac\", variant[\"env\"][:-3].lower(), str(variant[\"version\"])])\n",
    "setup_logger(log_prefix, variant=variant, seed=seed)\n",
    "variant[\"device\"] = ptu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9e0ac-93fd-4003-bfd1-29f851badba5",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa21b2b4-9bf0-4965-91a7-ff8ca706fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddie/venvs/IQ/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:10:48.433283 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 0 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 11000\n",
      "trainer/ZF1 Loss                      15.3016\n",
      "trainer/ZF2 Loss                      15.6766\n",
      "trainer/ZF Expert Reward              -0.0170665\n",
      "trainer/ZF Policy Reward               0.197594\n",
      "trainer/ZF CHI2 Term                  11.3075\n",
      "trainer/Policy Loss                    0.0337991\n",
      "trainer/Bias Loss                    112.787\n",
      "trainer/Bias Value                    14.9999\n",
      "trainer/Policy Grad Norm               0.0396595\n",
      "trainer/Policy Param Norm             13.5063\n",
      "trainer/Zf1 Grad Norm                 18.609\n",
      "trainer/Zf1 Param Norm                32.0715\n",
      "trainer/Zf2 Grad Norm                 25.7322\n",
      "trainer/Zf2 Param Norm                32.1185\n",
      "trainer/Z Expert Predictions Mean     -0.198331\n",
      "trainer/Z Expert Predictions Std       0.176043\n",
      "trainer/Z Expert Predictions Max       0.283181\n",
      "trainer/Z Expert Predictions Min      -0.848714\n",
      "trainer/Z Policy Predictions Mean     -0.00310445\n",
      "trainer/Z Policy Predictions Std       0.178577\n",
      "trainer/Z Policy Predictions Max       0.52661\n",
      "trainer/Z Policy Predictions Min      -0.592293\n",
      "trainer/Z Expert Targets Mean         -0.181265\n",
      "trainer/Z Expert Targets Std           0.195864\n",
      "trainer/Z Expert Targets Max           0.426813\n",
      "trainer/Z Expert Targets Min          -0.817482\n",
      "trainer/Z Policy Targets Mean         -0.200699\n",
      "trainer/Z Policy Targets Std           0.186897\n",
      "trainer/Z Policy Targets Max           0.365141\n",
      "trainer/Z Policy Targets Min          -0.88876\n",
      "trainer/Log Pis Mean                  -4.007\n",
      "trainer/Log Pis Std                    0.55223\n",
      "trainer/Policy mu Mean                -0.000169506\n",
      "trainer/Policy mu Std                  0.0012992\n",
      "trainer/Policy log std Mean            0.000258591\n",
      "trainer/Policy log std Std             0.00135177\n",
      "trainer/Alpha                          0.009999\n",
      "trainer/Alpha Loss                     0.24007\n",
      "exploration/num steps total        10262\n",
      "exploration/num paths total          471\n",
      "evaluation/num steps total           836\n",
      "evaluation/num paths total            10\n",
      "evaluation/path length Mean           83.6\n",
      "evaluation/path length Std             1.56205\n",
      "evaluation/path length Max            88\n",
      "evaluation/path length Min            82\n",
      "evaluation/Rewards Mean                1.28653\n",
      "evaluation/Rewards Std                 0.549997\n",
      "evaluation/Rewards Max                 2.90463\n",
      "evaluation/Rewards Min                 0.758588\n",
      "evaluation/Returns Mean              107.554\n",
      "evaluation/Returns Std                 3.0187\n",
      "evaluation/Returns Max               115.432\n",
      "evaluation/Returns Min               104.06\n",
      "evaluation/Estimation Bias Mean       47.0929\n",
      "evaluation/Estimation Bias Std        27.031\n",
      "evaluation/EB/Q_True Mean              5.47355\n",
      "evaluation/EB/Q_True Std              16.9312\n",
      "evaluation/EB/Q_Pred Mean             52.5665\n",
      "evaluation/EB/Q_Pred Std              19.8484\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           107.554\n",
      "evaluation/Actions Mean                0.484628\n",
      "evaluation/Actions Std                 0.624486\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.966823\n",
      "time/backward_policy (s)               1.87225\n",
      "time/backward_zf1 (s)                  1.96834\n",
      "time/backward_zf2 (s)                  1.96069\n",
      "time/data sampling (s)                 0.176108\n",
      "time/data storing (s)                  0.0133859\n",
      "time/evaluation sampling (s)           0.148554\n",
      "time/exploration sampling (s)          0.523452\n",
      "time/logging (s)                       0.00244711\n",
      "time/preback_alpha (s)                 1.0317\n",
      "time/preback_policy (s)                1.17975\n",
      "time/preback_start (s)                 0.110969\n",
      "time/preback_zf (s)                    4.99454\n",
      "time/saving (s)                        0.00481638\n",
      "time/training (s)                      1.90012\n",
      "time/epoch (s)                        15.8871\n",
      "time/total (s)                        21.5507\n",
      "Epoch                                  0\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:11:03.795087 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 1 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 12000\n",
      "trainer/ZF1 Loss                     -42.1976\n",
      "trainer/ZF2 Loss                     -42.184\n",
      "trainer/ZF Expert Reward              16.3632\n",
      "trainer/ZF Policy Reward              -9.29032\n",
      "trainer/ZF CHI2 Term                   6.45333\n",
      "trainer/Policy Loss                   20.5077\n",
      "trainer/Bias Loss                      1.03893\n",
      "trainer/Bias Value                    14.9645\n",
      "trainer/Policy Grad Norm              19.3832\n",
      "trainer/Policy Param Norm             15.6387\n",
      "trainer/Zf1 Grad Norm                 62.3184\n",
      "trainer/Zf1 Param Norm                34.5852\n",
      "trainer/Zf2 Grad Norm                 41.043\n",
      "trainer/Zf2 Param Norm                34.473\n",
      "trainer/Z Expert Predictions Mean     68.738\n",
      "trainer/Z Expert Predictions Std       1.07815\n",
      "trainer/Z Expert Predictions Max      68.9189\n",
      "trainer/Z Expert Predictions Min      47.4278\n",
      "trainer/Z Policy Predictions Mean    -31.1949\n",
      "trainer/Z Policy Predictions Std      13.1617\n",
      "trainer/Z Policy Predictions Max      68.2427\n",
      "trainer/Z Policy Predictions Min     -40.5158\n",
      "trainer/Z Expert Targets Mean         52.3748\n",
      "trainer/Z Expert Targets Std           0.974739\n",
      "trainer/Z Expert Targets Max          52.7675\n",
      "trainer/Z Expert Targets Min          32.6366\n",
      "trainer/Z Policy Targets Mean        -21.9045\n",
      "trainer/Z Policy Targets Std          13.424\n",
      "trainer/Z Policy Targets Max          52.3012\n",
      "trainer/Z Policy Targets Min         -32.9107\n",
      "trainer/Log Pis Mean                  23.2229\n",
      "trainer/Log Pis Std                    8.12397\n",
      "trainer/Policy mu Mean                 2.0045\n",
      "trainer/Policy mu Std                  2.01269\n",
      "trainer/Policy log std Mean           -1.55379\n",
      "trainer/Policy log std Std             1.2239\n",
      "trainer/Alpha                          0.00963363\n",
      "trainer/Alpha Loss                    -0.031047\n",
      "exploration/num steps total        11226\n",
      "exploration/num paths total          479\n",
      "evaluation/num steps total          1601\n",
      "evaluation/num paths total            20\n",
      "evaluation/path length Mean           76.5\n",
      "evaluation/path length Std             3.98121\n",
      "evaluation/path length Max            85\n",
      "evaluation/path length Min            72\n",
      "evaluation/Rewards Mean                1.06457\n",
      "evaluation/Rewards Std                 0.678226\n",
      "evaluation/Rewards Max                 2.57513\n",
      "evaluation/Rewards Min                 0.028496\n",
      "evaluation/Returns Mean               81.4392\n",
      "evaluation/Returns Std                10.1404\n",
      "evaluation/Returns Max               102.881\n",
      "evaluation/Returns Min                69.5993\n",
      "evaluation/Estimation Bias Mean      132.296\n",
      "evaluation/Estimation Bias Std        21.1866\n",
      "evaluation/EB/Q_True Mean              3.54029\n",
      "evaluation/EB/Q_True Std              11.032\n",
      "evaluation/EB/Q_Pred Mean            135.836\n",
      "evaluation/EB/Q_Pred Std              17.0522\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            81.4392\n",
      "evaluation/Actions Mean                0.508037\n",
      "evaluation/Actions Std                 0.534273\n",
      "evaluation/Actions Max                 0.9999\n",
      "evaluation/Actions Min                -0.992566\n",
      "time/backward_policy (s)               1.7159\n",
      "time/backward_zf1 (s)                  1.84557\n",
      "time/backward_zf2 (s)                  1.78813\n",
      "time/data sampling (s)                 0.193008\n",
      "time/data storing (s)                  0.0135722\n",
      "time/evaluation sampling (s)           0.25101\n",
      "time/exploration sampling (s)          0.196824\n",
      "time/logging (s)                       0.00200311\n",
      "time/preback_alpha (s)                 0.893079\n",
      "time/preback_policy (s)                0.975545\n",
      "time/preback_start (s)                 0.113397\n",
      "time/preback_zf (s)                    5.00988\n",
      "time/saving (s)                        0.00514517\n",
      "time/training (s)                      2.29618\n",
      "time/epoch (s)                        15.2992\n",
      "time/total (s)                        36.8686\n",
      "Epoch                                  1\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:11:20.014216 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 2 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 13000\n",
      "trainer/ZF1 Loss                     -42.7114\n",
      "trainer/ZF2 Loss                     -42.7003\n",
      "trainer/ZF Expert Reward              20.5561\n",
      "trainer/ZF Policy Reward             -10.8908\n",
      "trainer/ZF CHI2 Term                  11.3028\n",
      "trainer/Policy Loss                    3.15332\n",
      "trainer/Bias Loss                     15.6857\n",
      "trainer/Bias Value                    15.0725\n",
      "trainer/Policy Grad Norm              28.5532\n",
      "trainer/Policy Param Norm             17.0309\n",
      "trainer/Zf1 Grad Norm                107.132\n",
      "trainer/Zf1 Param Norm                37.6511\n",
      "trainer/Zf2 Grad Norm                161.894\n",
      "trainer/Zf2 Param Norm                37.2315\n",
      "trainer/Z Expert Predictions Mean    154.326\n",
      "trainer/Z Expert Predictions Std       5.56085\n",
      "trainer/Z Expert Predictions Max     155.455\n",
      "trainer/Z Expert Predictions Min      88.3017\n",
      "trainer/Z Policy Predictions Mean    -18.332\n",
      "trainer/Z Policy Predictions Std      34.6628\n",
      "trainer/Z Policy Predictions Max     136.67\n",
      "trainer/Z Policy Predictions Min     -58.2847\n",
      "trainer/Z Expert Targets Mean        133.77\n",
      "trainer/Z Expert Targets Std           5.50478\n",
      "trainer/Z Expert Targets Max         135.361\n",
      "trainer/Z Expert Targets Min          73.2689\n",
      "trainer/Z Policy Targets Mean         -7.44123\n",
      "trainer/Z Policy Targets Std          34.4373\n",
      "trainer/Z Policy Targets Max         126.605\n",
      "trainer/Z Policy Targets Min         -55.1741\n",
      "trainer/Log Pis Mean                  22.7898\n",
      "trainer/Log Pis Std                    8.32816\n",
      "trainer/Policy mu Mean                 1.12898\n",
      "trainer/Policy mu Std                  2.03677\n",
      "trainer/Policy log std Mean           -2.40482\n",
      "trainer/Policy log std Std             1.14697\n",
      "trainer/Alpha                          0.0103868\n",
      "trainer/Alpha Loss                    -0.0289752\n",
      "exploration/num steps total        12282\n",
      "exploration/num paths total          487\n",
      "evaluation/num steps total          2936\n",
      "evaluation/num paths total            30\n",
      "evaluation/path length Mean          133.5\n",
      "evaluation/path length Std             1.9105\n",
      "evaluation/path length Max           135\n",
      "evaluation/path length Min           129\n",
      "evaluation/Rewards Mean                2.01426\n",
      "evaluation/Rewards Std                 1.22393\n",
      "evaluation/Rewards Max                 4.27513\n",
      "evaluation/Rewards Min                 0.162014\n",
      "evaluation/Returns Mean              268.904\n",
      "evaluation/Returns Std                 1.98143\n",
      "evaluation/Returns Max               270.977\n",
      "evaluation/Returns Min               264.98\n",
      "evaluation/Estimation Bias Mean      174.044\n",
      "evaluation/Estimation Bias Std        58.1387\n",
      "evaluation/EB/Q_True Mean             11.0903\n",
      "evaluation/EB/Q_True Std              36.4954\n",
      "evaluation/EB/Q_Pred Mean            185.135\n",
      "evaluation/EB/Q_Pred Std              44.7479\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           268.904\n",
      "evaluation/Actions Mean                0.488666\n",
      "evaluation/Actions Std                 0.572238\n",
      "evaluation/Actions Max                 0.999931\n",
      "evaluation/Actions Min                -0.99047\n",
      "time/backward_policy (s)               1.89447\n",
      "time/backward_zf1 (s)                  2.03801\n",
      "time/backward_zf2 (s)                  1.95948\n",
      "time/data sampling (s)                 0.21933\n",
      "time/data storing (s)                  0.0151743\n",
      "time/evaluation sampling (s)           0.216149\n",
      "time/exploration sampling (s)          0.209654\n",
      "time/logging (s)                       0.00272962\n",
      "time/preback_alpha (s)                 0.976177\n",
      "time/preback_policy (s)                1.11694\n",
      "time/preback_start (s)                 0.123913\n",
      "time/preback_zf (s)                    5.1366\n",
      "time/saving (s)                        0.00599454\n",
      "time/training (s)                      2.23957\n",
      "time/epoch (s)                        16.1542\n",
      "time/total (s)                        53.0415\n",
      "Epoch                                  2\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:11:36.499147 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 3 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 14000\n",
      "trainer/ZF1 Loss                     -39.0249\n",
      "trainer/ZF2 Loss                     -38.981\n",
      "trainer/ZF Expert Reward              22.4687\n",
      "trainer/ZF Policy Reward              -9.21814\n",
      "trainer/ZF CHI2 Term                  11.1468\n",
      "trainer/Policy Loss                   -8.72982\n",
      "trainer/Bias Loss                     28.115\n",
      "trainer/Bias Value                    15.2029\n",
      "trainer/Policy Grad Norm              26.6865\n",
      "trainer/Policy Param Norm             18.1992\n",
      "trainer/Zf1 Grad Norm                123.606\n",
      "trainer/Zf1 Param Norm                40.4525\n",
      "trainer/Zf2 Grad Norm                147.256\n",
      "trainer/Zf2 Param Norm                39.8932\n",
      "trainer/Z Expert Predictions Mean    244.762\n",
      "trainer/Z Expert Predictions Std      14.2291\n",
      "trainer/Z Expert Predictions Max     248.472\n",
      "trainer/Z Expert Predictions Min     153.96\n",
      "trainer/Z Policy Predictions Mean     -8.6249\n",
      "trainer/Z Policy Predictions Std      55.3725\n",
      "trainer/Z Policy Predictions Max     237.135\n",
      "trainer/Z Policy Predictions Min     -66.8948\n",
      "trainer/Z Expert Targets Mean        222.293\n",
      "trainer/Z Expert Targets Std          13.1769\n",
      "trainer/Z Expert Targets Max         226.593\n",
      "trainer/Z Expert Targets Min         139.014\n",
      "trainer/Z Policy Targets Mean          0.59324\n",
      "trainer/Z Policy Targets Std          54.0951\n",
      "trainer/Z Policy Targets Max         219.933\n",
      "trainer/Z Policy Targets Min         -61.86\n",
      "trainer/Log Pis Mean                  18.6494\n",
      "trainer/Log Pis Std                    7.7785\n",
      "trainer/Policy mu Mean                 0.424119\n",
      "trainer/Policy mu Std                  1.97444\n",
      "trainer/Policy log std Mean           -2.28591\n",
      "trainer/Policy log std Std             1.11939\n",
      "trainer/Alpha                          0.0105796\n",
      "trainer/Alpha Loss                     0.0142891\n",
      "exploration/num steps total        13437\n",
      "exploration/num paths total          497\n",
      "evaluation/num steps total          4374\n",
      "evaluation/num paths total            40\n",
      "evaluation/path length Mean          143.8\n",
      "evaluation/path length Std             1.53623\n",
      "evaluation/path length Max           147\n",
      "evaluation/path length Min           141\n",
      "evaluation/Rewards Mean                2.73577\n",
      "evaluation/Rewards Std                 1.68231\n",
      "evaluation/Rewards Max                 7.47967\n",
      "evaluation/Rewards Min                 0.255288\n",
      "evaluation/Returns Mean              393.403\n",
      "evaluation/Returns Std                 3.80256\n",
      "evaluation/Returns Max               401.205\n",
      "evaluation/Returns Min               386.678\n",
      "evaluation/Estimation Bias Mean      226.774\n",
      "evaluation/Estimation Bias Std        68.6004\n",
      "evaluation/EB/Q_True Mean             16.7082\n",
      "evaluation/EB/Q_True Std              53.2622\n",
      "evaluation/EB/Q_Pred Mean            243.483\n",
      "evaluation/EB/Q_Pred Std              45.0686\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           393.403\n",
      "evaluation/Actions Mean                0.344722\n",
      "evaluation/Actions Std                 0.674424\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.91082\n",
      "time/backward_zf1 (s)                  2.06042\n",
      "time/backward_zf2 (s)                  1.99872\n",
      "time/data sampling (s)                 0.231351\n",
      "time/data storing (s)                  0.015119\n",
      "time/evaluation sampling (s)           0.299597\n",
      "time/exploration sampling (s)          0.210386\n",
      "time/logging (s)                       0.00550968\n",
      "time/preback_alpha (s)                 0.990816\n",
      "time/preback_policy (s)                1.13588\n",
      "time/preback_start (s)                 0.126711\n",
      "time/preback_zf (s)                    5.16805\n",
      "time/saving (s)                        0.0105787\n",
      "time/training (s)                      2.25417\n",
      "time/epoch (s)                        16.4181\n",
      "time/total (s)                        69.4817\n",
      "Epoch                                  3\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:11:53.700131 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 4 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 15000\n",
      "trainer/ZF1 Loss                     -39.299\n",
      "trainer/ZF2 Loss                     -39.8555\n",
      "trainer/ZF Expert Reward              23.0285\n",
      "trainer/ZF Policy Reward              -9.82984\n",
      "trainer/ZF CHI2 Term                  14.3737\n",
      "trainer/Policy Loss                  -53.2877\n",
      "trainer/Bias Loss                     35.5117\n",
      "trainer/Bias Value                    15.32\n",
      "trainer/Policy Grad Norm              70.0472\n",
      "trainer/Policy Param Norm             19.3143\n",
      "trainer/Zf1 Grad Norm                281.419\n",
      "trainer/Zf1 Param Norm                42.9795\n",
      "trainer/Zf2 Grad Norm                307.479\n",
      "trainer/Zf2 Param Norm                42.3474\n",
      "trainer/Z Expert Predictions Mean    331.429\n",
      "trainer/Z Expert Predictions Std      29.5852\n",
      "trainer/Z Expert Predictions Max     341.584\n",
      "trainer/Z Expert Predictions Min     171.198\n",
      "trainer/Z Policy Predictions Mean     31.8376\n",
      "trainer/Z Policy Predictions Std      84.7448\n",
      "trainer/Z Policy Predictions Max     248.147\n",
      "trainer/Z Policy Predictions Min     -77.277\n",
      "trainer/Z Expert Targets Mean        308.4\n",
      "trainer/Z Expert Targets Std          27.9109\n",
      "trainer/Z Expert Targets Max         318.932\n",
      "trainer/Z Expert Targets Min         151.269\n",
      "trainer/Z Policy Targets Mean         41.6674\n",
      "trainer/Z Policy Targets Std          85.3058\n",
      "trainer/Z Policy Targets Max         263.981\n",
      "trainer/Z Policy Targets Min         -71.4118\n",
      "trainer/Log Pis Mean                  21.3057\n",
      "trainer/Log Pis Std                    9.26574\n",
      "trainer/Policy mu Mean                 0.428938\n",
      "trainer/Policy mu Std                  2.10149\n",
      "trainer/Policy log std Mean           -2.66173\n",
      "trainer/Policy log std Std             1.25951\n",
      "trainer/Alpha                          0.0107429\n",
      "trainer/Alpha Loss                    -0.0140259\n",
      "exploration/num steps total        14525\n",
      "exploration/num paths total          505\n",
      "evaluation/num steps total         14374\n",
      "evaluation/num paths total            50\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                1.15865\n",
      "evaluation/Rewards Std                 0.54599\n",
      "evaluation/Rewards Max                 4.09201\n",
      "evaluation/Rewards Min                 0.274164\n",
      "evaluation/Returns Mean             1158.65\n",
      "evaluation/Returns Std                 2.36747\n",
      "evaluation/Returns Max              1164.18\n",
      "evaluation/Returns Min              1155.31\n",
      "evaluation/Estimation Bias Mean       90.7724\n",
      "evaluation/Estimation Bias Std        82.0149\n",
      "evaluation/EB/Q_True Mean             10.026\n",
      "evaluation/EB/Q_True Std              32.0639\n",
      "evaluation/EB/Q_Pred Mean            100.798\n",
      "evaluation/EB/Q_Pred Std              77.39\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1158.65\n",
      "evaluation/Actions Mean                0.34716\n",
      "evaluation/Actions Std                 0.498234\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999666\n",
      "time/backward_policy (s)               1.8006\n",
      "time/backward_zf1 (s)                  1.94799\n",
      "time/backward_zf2 (s)                  1.86582\n",
      "time/data sampling (s)                 0.201916\n",
      "time/data storing (s)                  0.0146668\n",
      "time/evaluation sampling (s)           1.52297\n",
      "time/exploration sampling (s)          0.19901\n",
      "time/logging (s)                       0.0115482\n",
      "time/preback_alpha (s)                 0.918444\n",
      "time/preback_policy (s)                1.0198\n",
      "time/preback_start (s)                 0.118662\n",
      "time/preback_zf (s)                    5.13146\n",
      "time/saving (s)                        0.00519105\n",
      "time/training (s)                      2.38245\n",
      "time/epoch (s)                        17.1405\n",
      "time/total (s)                        86.6432\n",
      "Epoch                                  4\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:12:09.256268 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 5 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 16000\n",
      "trainer/ZF1 Loss                     -39.806\n",
      "trainer/ZF2 Loss                     -38.5644\n",
      "trainer/ZF Expert Reward              24.5584\n",
      "trainer/ZF Policy Reward              -6.60655\n",
      "trainer/ZF CHI2 Term                  15.5524\n",
      "trainer/Policy Loss                  -60.499\n",
      "trainer/Bias Loss                     48.1657\n",
      "trainer/Bias Value                    15.4284\n",
      "trainer/Policy Grad Norm              44.9511\n",
      "trainer/Policy Param Norm             20.0835\n",
      "trainer/Zf1 Grad Norm                168.571\n",
      "trainer/Zf1 Param Norm                45.1824\n",
      "trainer/Zf2 Grad Norm                362.962\n",
      "trainer/Zf2 Param Norm                44.5588\n",
      "trainer/Z Expert Predictions Mean    417.912\n",
      "trainer/Z Expert Predictions Std      29.1134\n",
      "trainer/Z Expert Predictions Max     428.678\n",
      "trainer/Z Expert Predictions Min     237.232\n",
      "trainer/Z Policy Predictions Mean     41.0256\n",
      "trainer/Z Policy Predictions Std     101.382\n",
      "trainer/Z Policy Predictions Max     324.2\n",
      "trainer/Z Policy Predictions Min     -76.4182\n",
      "trainer/Z Expert Targets Mean        393.354\n",
      "trainer/Z Expert Targets Std          29.5375\n",
      "trainer/Z Expert Targets Max         406.501\n",
      "trainer/Z Expert Targets Min         205.536\n",
      "trainer/Z Policy Targets Mean         47.6322\n",
      "trainer/Z Policy Targets Std          98.8724\n",
      "trainer/Z Policy Targets Max         328.851\n",
      "trainer/Z Policy Targets Min         -68.7339\n",
      "trainer/Log Pis Mean                  23.8107\n",
      "trainer/Log Pis Std                   10.5793\n",
      "trainer/Policy mu Mean                 0.326357\n",
      "trainer/Policy mu Std                  2.62306\n",
      "trainer/Policy log std Mean           -2.60892\n",
      "trainer/Policy log std Std             1.57072\n",
      "trainer/Alpha                          0.0122895\n",
      "trainer/Alpha Loss                    -0.046825\n",
      "exploration/num steps total        15629\n",
      "exploration/num paths total          513\n",
      "evaluation/num steps total         15587\n",
      "evaluation/num paths total            60\n",
      "evaluation/path length Mean          121.3\n",
      "evaluation/path length Std             1.00499\n",
      "evaluation/path length Max           123\n",
      "evaluation/path length Min           120\n",
      "evaluation/Rewards Mean                2.15939\n",
      "evaluation/Rewards Std                 1.28941\n",
      "evaluation/Rewards Max                 4.11169\n",
      "evaluation/Rewards Min                 0.168917\n",
      "evaluation/Returns Mean              261.934\n",
      "evaluation/Returns Std                 1.52987\n",
      "evaluation/Returns Max               264.492\n",
      "evaluation/Returns Min               259.839\n",
      "evaluation/Estimation Bias Mean      282.287\n",
      "evaluation/Estimation Bias Std        95.9636\n",
      "evaluation/EB/Q_True Mean             11.8238\n",
      "evaluation/EB/Q_True Std              37.4738\n",
      "evaluation/EB/Q_Pred Mean            294.111\n",
      "evaluation/EB/Q_Pred Std              92.1241\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           261.934\n",
      "evaluation/Actions Mean                0.463412\n",
      "evaluation/Actions Std                 0.561472\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.99962\n",
      "time/backward_policy (s)               1.77201\n",
      "time/backward_zf1 (s)                  1.87711\n",
      "time/backward_zf2 (s)                  1.82698\n",
      "time/data sampling (s)                 0.198585\n",
      "time/data storing (s)                  0.013679\n",
      "time/evaluation sampling (s)           0.18634\n",
      "time/exploration sampling (s)          0.193317\n",
      "time/logging (s)                       0.00248378\n",
      "time/preback_alpha (s)                 0.934745\n",
      "time/preback_policy (s)                1.02856\n",
      "time/preback_start (s)                 0.115659\n",
      "time/preback_zf (s)                    5.04617\n",
      "time/saving (s)                        0.00476957\n",
      "time/training (s)                      2.27952\n",
      "time/epoch (s)                        15.4799\n",
      "time/total (s)                       102.145\n",
      "Epoch                                  5\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:12:25.455159 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 6 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 17000\n",
      "trainer/ZF1 Loss                       4.16915\n",
      "trainer/ZF2 Loss                       5.07782\n",
      "trainer/ZF Expert Reward              24.5133\n",
      "trainer/ZF Policy Reward             -11.1444\n",
      "trainer/ZF CHI2 Term                  64.7187\n",
      "trainer/Policy Loss                 -105.419\n",
      "trainer/Bias Loss                    491.365\n",
      "trainer/Bias Value                    15.532\n",
      "trainer/Policy Grad Norm             102.679\n",
      "trainer/Policy Param Norm             20.5696\n",
      "trainer/Zf1 Grad Norm                709.497\n",
      "trainer/Zf1 Param Norm                46.9753\n",
      "trainer/Zf2 Grad Norm                615.781\n",
      "trainer/Zf2 Param Norm                46.4538\n",
      "trainer/Z Expert Predictions Mean    482.519\n",
      "trainer/Z Expert Predictions Std      42.0155\n",
      "trainer/Z Expert Predictions Max     504.825\n",
      "trainer/Z Expert Predictions Min     266.211\n",
      "trainer/Z Policy Predictions Mean     82.2238\n",
      "trainer/Z Policy Predictions Std     134.713\n",
      "trainer/Z Policy Predictions Max     380.618\n",
      "trainer/Z Policy Predictions Min     -71.5208\n",
      "trainer/Z Expert Targets Mean        458.006\n",
      "trainer/Z Expert Targets Std          49.3038\n",
      "trainer/Z Expert Targets Max         484.295\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         93.3683\n",
      "trainer/Z Policy Targets Std         135.056\n",
      "trainer/Z Policy Targets Max         393.295\n",
      "trainer/Z Policy Targets Min         -62.8788\n",
      "trainer/Log Pis Mean                  24.6843\n",
      "trainer/Log Pis Std                    9.44433\n",
      "trainer/Policy mu Mean                 0.751455\n",
      "trainer/Policy mu Std                  2.75427\n",
      "trainer/Policy log std Mean           -2.53859\n",
      "trainer/Policy log std Std             1.58298\n",
      "trainer/Alpha                          0.0139382\n",
      "trainer/Alpha Loss                    -0.0652841\n",
      "exploration/num steps total        16096\n",
      "exploration/num paths total          517\n",
      "evaluation/num steps total         17484\n",
      "evaluation/num paths total            70\n",
      "evaluation/path length Mean          189.7\n",
      "evaluation/path length Std             2.86531\n",
      "evaluation/path length Max           194\n",
      "evaluation/path length Min           184\n",
      "evaluation/Rewards Mean                1.27574\n",
      "evaluation/Rewards Std                 1.25374\n",
      "evaluation/Rewards Max                 4.40731\n",
      "evaluation/Rewards Min                -1.70362\n",
      "evaluation/Returns Mean              242.009\n",
      "evaluation/Returns Std                 1.93893\n",
      "evaluation/Returns Max               244.184\n",
      "evaluation/Returns Min               237.319\n",
      "evaluation/Estimation Bias Mean      195.662\n",
      "evaluation/Estimation Bias Std       163.564\n",
      "evaluation/EB/Q_True Mean              6.92213\n",
      "evaluation/EB/Q_True Std              28.0652\n",
      "evaluation/EB/Q_Pred Mean            202.584\n",
      "evaluation/EB/Q_Pred Std             166.892\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           242.009\n",
      "evaluation/Actions Mean                0.380285\n",
      "evaluation/Actions Std                 0.619626\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999692\n",
      "time/backward_policy (s)               1.81421\n",
      "time/backward_zf1 (s)                  1.89978\n",
      "time/backward_zf2 (s)                  1.81289\n",
      "time/data sampling (s)                 0.214122\n",
      "time/data storing (s)                  0.0149664\n",
      "time/evaluation sampling (s)           0.600734\n",
      "time/exploration sampling (s)          0.202145\n",
      "time/logging (s)                       0.00330337\n",
      "time/preback_alpha (s)                 0.906064\n",
      "time/preback_policy (s)                0.992322\n",
      "time/preback_start (s)                 0.120251\n",
      "time/preback_zf (s)                    5.11511\n",
      "time/saving (s)                        0.00483151\n",
      "time/training (s)                      2.43524\n",
      "time/epoch (s)                        16.136\n",
      "time/total (s)                       118.299\n",
      "Epoch                                  6\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:12:41.595702 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 7 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 18000\n",
      "trainer/ZF1 Loss                     -37.1859\n",
      "trainer/ZF2 Loss                     -37.5038\n",
      "trainer/ZF Expert Reward              25.3272\n",
      "trainer/ZF Policy Reward              -9.93347\n",
      "trainer/ZF CHI2 Term                  22.1958\n",
      "trainer/Policy Loss                 -136.234\n",
      "trainer/Bias Loss                     70.7257\n",
      "trainer/Bias Value                    15.6327\n",
      "trainer/Policy Grad Norm              92.2696\n",
      "trainer/Policy Param Norm             21.1149\n",
      "trainer/Zf1 Grad Norm                517.753\n",
      "trainer/Zf1 Param Norm                48.4479\n",
      "trainer/Zf2 Grad Norm                471.969\n",
      "trainer/Zf2 Param Norm                47.986\n",
      "trainer/Z Expert Predictions Mean    527.13\n",
      "trainer/Z Expert Predictions Std      61.0392\n",
      "trainer/Z Expert Predictions Max     573.741\n",
      "trainer/Z Expert Predictions Min     296.015\n",
      "trainer/Z Policy Predictions Mean    114.21\n",
      "trainer/Z Policy Predictions Std     148.511\n",
      "trainer/Z Policy Predictions Max     458.837\n",
      "trainer/Z Policy Predictions Min     -73.6396\n",
      "trainer/Z Expert Targets Mean        501.803\n",
      "trainer/Z Expert Targets Std          60.5352\n",
      "trainer/Z Expert Targets Max         552.888\n",
      "trainer/Z Expert Targets Min         284.395\n",
      "trainer/Z Policy Targets Mean        124.144\n",
      "trainer/Z Policy Targets Std         147.511\n",
      "trainer/Z Policy Targets Max         458.217\n",
      "trainer/Z Policy Targets Min         -76.9687\n",
      "trainer/Log Pis Mean                  24.5252\n",
      "trainer/Log Pis Std                   10.1303\n",
      "trainer/Policy mu Mean                 1.0846\n",
      "trainer/Policy mu Std                  2.47543\n",
      "trainer/Policy log std Mean           -2.63326\n",
      "trainer/Policy log std Std             1.54425\n",
      "trainer/Alpha                          0.0155466\n",
      "trainer/Alpha Loss                    -0.0703435\n",
      "exploration/num steps total        16562\n",
      "exploration/num paths total          521\n",
      "evaluation/num steps total         20223\n",
      "evaluation/num paths total            80\n",
      "evaluation/path length Mean          273.9\n",
      "evaluation/path length Std            57.6965\n",
      "evaluation/path length Max           405\n",
      "evaluation/path length Min           216\n",
      "evaluation/Rewards Mean                2.53525\n",
      "evaluation/Rewards Std                 1.4903\n",
      "evaluation/Rewards Max                 6.42493\n",
      "evaluation/Rewards Min                -1.39816\n",
      "evaluation/Returns Mean              694.406\n",
      "evaluation/Returns Std               117.741\n",
      "evaluation/Returns Max               980.179\n",
      "evaluation/Returns Min               578.378\n",
      "evaluation/Estimation Bias Mean      286.828\n",
      "evaluation/Estimation Bias Std       157.552\n",
      "evaluation/EB/Q_True Mean             18.6922\n",
      "evaluation/EB/Q_True Std              64.0433\n",
      "evaluation/EB/Q_Pred Mean            305.521\n",
      "evaluation/EB/Q_Pred Std             150.524\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           694.406\n",
      "evaluation/Actions Mean                0.521601\n",
      "evaluation/Actions Std                 0.567248\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999763\n",
      "time/backward_policy (s)               1.8082\n",
      "time/backward_zf1 (s)                  1.94939\n",
      "time/backward_zf2 (s)                  1.88901\n",
      "time/data sampling (s)                 0.213203\n",
      "time/data storing (s)                  0.0137646\n",
      "time/evaluation sampling (s)           0.639505\n",
      "time/exploration sampling (s)          0.193624\n",
      "time/logging (s)                       0.00408361\n",
      "time/preback_alpha (s)                 0.961261\n",
      "time/preback_policy (s)                1.0729\n",
      "time/preback_start (s)                 0.118838\n",
      "time/preback_zf (s)                    5.05957\n",
      "time/saving (s)                        0.00500582\n",
      "time/training (s)                      2.14652\n",
      "time/epoch (s)                        16.0749\n",
      "time/total (s)                       134.395\n",
      "Epoch                                  7\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:12:56.967498 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 8 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 19000\n",
      "trainer/ZF1 Loss                     -32.9775\n",
      "trainer/ZF2 Loss                     -32.3329\n",
      "trainer/ZF Expert Reward              24.8479\n",
      "trainer/ZF Policy Reward             -10.8699\n",
      "trainer/ZF CHI2 Term                  25.1781\n",
      "trainer/Policy Loss                 -148.784\n",
      "trainer/Bias Loss                     77.9942\n",
      "trainer/Bias Value                    15.7314\n",
      "trainer/Policy Grad Norm             125.216\n",
      "trainer/Policy Param Norm             21.5593\n",
      "trainer/Zf1 Grad Norm                561.571\n",
      "trainer/Zf1 Param Norm                49.8296\n",
      "trainer/Zf2 Grad Norm                732.413\n",
      "trainer/Zf2 Param Norm                49.4014\n",
      "trainer/Z Expert Predictions Mean    556.574\n",
      "trainer/Z Expert Predictions Std      67.0211\n",
      "trainer/Z Expert Predictions Max     634.673\n",
      "trainer/Z Expert Predictions Min     328.393\n",
      "trainer/Z Policy Predictions Mean    128.88\n",
      "trainer/Z Policy Predictions Std     154.044\n",
      "trainer/Z Policy Predictions Max     502.481\n",
      "trainer/Z Policy Predictions Min     -80.3444\n",
      "trainer/Z Expert Targets Mean        531.726\n",
      "trainer/Z Expert Targets Std          66.3207\n",
      "trainer/Z Expert Targets Max         614.237\n",
      "trainer/Z Expert Targets Min         298.544\n",
      "trainer/Z Policy Targets Mean        139.75\n",
      "trainer/Z Policy Targets Std         153.413\n",
      "trainer/Z Policy Targets Max         513.879\n",
      "trainer/Z Policy Targets Min         -87.3652\n",
      "trainer/Log Pis Mean                  22.3389\n",
      "trainer/Log Pis Std                    7.92716\n",
      "trainer/Policy mu Mean                 1.09585\n",
      "trainer/Policy mu Std                  2.0864\n",
      "trainer/Policy log std Mean           -2.55744\n",
      "trainer/Policy log std Std             1.56077\n",
      "trainer/Alpha                          0.017163\n",
      "trainer/Alpha Loss                    -0.0401398\n",
      "exploration/num steps total        17303\n",
      "exploration/num paths total          524\n",
      "evaluation/num steps total         21633\n",
      "evaluation/num paths total            90\n",
      "evaluation/path length Mean          141\n",
      "evaluation/path length Std             1.34164\n",
      "evaluation/path length Max           143\n",
      "evaluation/path length Min           139\n",
      "evaluation/Rewards Mean                2.93461\n",
      "evaluation/Rewards Std                 2.07157\n",
      "evaluation/Rewards Max                 6.85919\n",
      "evaluation/Rewards Min                 0.103208\n",
      "evaluation/Returns Mean              413.781\n",
      "evaluation/Returns Std                 2.24924\n",
      "evaluation/Returns Max               417.654\n",
      "evaluation/Returns Min               410.404\n",
      "evaluation/Estimation Bias Mean      436.06\n",
      "evaluation/Estimation Bias Std       118.117\n",
      "evaluation/EB/Q_True Mean             18.1119\n",
      "evaluation/EB/Q_True Std              57.0201\n",
      "evaluation/EB/Q_Pred Mean            454.172\n",
      "evaluation/EB/Q_Pred Std             107.04\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           413.781\n",
      "evaluation/Actions Mean                0.442825\n",
      "evaluation/Actions Std                 0.610431\n",
      "evaluation/Actions Max                 0.99999\n",
      "evaluation/Actions Min                -0.999688\n",
      "time/backward_policy (s)               1.69933\n",
      "time/backward_zf1 (s)                  1.8275\n",
      "time/backward_zf2 (s)                  1.74826\n",
      "time/data sampling (s)                 0.223185\n",
      "time/data storing (s)                  0.0143797\n",
      "time/evaluation sampling (s)           0.264083\n",
      "time/exploration sampling (s)          0.202969\n",
      "time/logging (s)                       0.00269531\n",
      "time/preback_alpha (s)                 0.895049\n",
      "time/preback_policy (s)                0.97816\n",
      "time/preback_start (s)                 0.12239\n",
      "time/preback_zf (s)                    5.02399\n",
      "time/saving (s)                        0.00495017\n",
      "time/training (s)                      2.30085\n",
      "time/epoch (s)                        15.3078\n",
      "time/total (s)                       149.722\n",
      "Epoch                                  8\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:13:12.459774 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 9 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 20000\n",
      "trainer/ZF1 Loss                     -27.8105\n",
      "trainer/ZF2 Loss                     -25.2232\n",
      "trainer/ZF Expert Reward              25.6035\n",
      "trainer/ZF Policy Reward              -6.78726\n",
      "trainer/ZF CHI2 Term                  27.4493\n",
      "trainer/Policy Loss                 -169.011\n",
      "trainer/Bias Loss                     94.854\n",
      "trainer/Bias Value                    15.8289\n",
      "trainer/Policy Grad Norm             128.562\n",
      "trainer/Policy Param Norm             22.0197\n",
      "trainer/Zf1 Grad Norm                466.601\n",
      "trainer/Zf1 Param Norm                51.1393\n",
      "trainer/Zf2 Grad Norm                476.298\n",
      "trainer/Zf2 Param Norm                50.7004\n",
      "trainer/Z Expert Predictions Mean    595.699\n",
      "trainer/Z Expert Predictions Std      80.3428\n",
      "trainer/Z Expert Predictions Max     689.44\n",
      "trainer/Z Expert Predictions Min     376.16\n",
      "trainer/Z Policy Predictions Mean    144.367\n",
      "trainer/Z Policy Predictions Std     162.956\n",
      "trainer/Z Policy Predictions Max     572.271\n",
      "trainer/Z Policy Predictions Min     -66.9852\n",
      "trainer/Z Expert Targets Mean        570.096\n",
      "trainer/Z Expert Targets Std          81.167\n",
      "trainer/Z Expert Targets Max         668.492\n",
      "trainer/Z Expert Targets Min         346.536\n",
      "trainer/Z Policy Targets Mean        151.155\n",
      "trainer/Z Policy Targets Std         161.738\n",
      "trainer/Z Policy Targets Max         581.66\n",
      "trainer/Z Policy Targets Min         -57.3395\n",
      "trainer/Log Pis Mean                  21.7933\n",
      "trainer/Log Pis Std                    8.11795\n",
      "trainer/Policy mu Mean                 1.13867\n",
      "trainer/Policy mu Std                  2.02828\n",
      "trainer/Policy log std Mean           -2.52057\n",
      "trainer/Policy log std Std             1.34225\n",
      "trainer/Alpha                          0.0184548\n",
      "trainer/Alpha Loss                    -0.0330936\n",
      "exploration/num steps total        18017\n",
      "exploration/num paths total          527\n",
      "evaluation/num steps total         23044\n",
      "evaluation/num paths total           100\n",
      "evaluation/path length Mean          141.1\n",
      "evaluation/path length Std             4.41475\n",
      "evaluation/path length Max           149\n",
      "evaluation/path length Min           137\n",
      "evaluation/Rewards Mean                2.97139\n",
      "evaluation/Rewards Std                 2.12111\n",
      "evaluation/Rewards Max                 6.89959\n",
      "evaluation/Rewards Min                 0.0823205\n",
      "evaluation/Returns Mean              419.263\n",
      "evaluation/Returns Std                21.2287\n",
      "evaluation/Returns Max               454.664\n",
      "evaluation/Returns Min               399.551\n",
      "evaluation/Estimation Bias Mean      479.397\n",
      "evaluation/Estimation Bias Std       112.25\n",
      "evaluation/EB/Q_True Mean             20.0539\n",
      "evaluation/EB/Q_True Std              62.0009\n",
      "evaluation/EB/Q_Pred Mean            499.451\n",
      "evaluation/EB/Q_Pred Std              95.7433\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           419.263\n",
      "evaluation/Actions Mean                0.406914\n",
      "evaluation/Actions Std                 0.631882\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999929\n",
      "time/backward_policy (s)               1.71561\n",
      "time/backward_zf1 (s)                  1.82496\n",
      "time/backward_zf2 (s)                  1.76351\n",
      "time/data sampling (s)                 0.22273\n",
      "time/data storing (s)                  0.0150153\n",
      "time/evaluation sampling (s)           0.241288\n",
      "time/exploration sampling (s)          0.20484\n",
      "time/logging (s)                       0.0028372\n",
      "time/preback_alpha (s)                 0.88968\n",
      "time/preback_policy (s)                0.963619\n",
      "time/preback_start (s)                 0.121261\n",
      "time/preback_zf (s)                    5.0305\n",
      "time/saving (s)                        0.00501115\n",
      "time/training (s)                      2.42618\n",
      "time/epoch (s)                        15.427\n",
      "time/total (s)                       165.17\n",
      "Epoch                                  9\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:13:28.914321 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 10 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 21000\n",
      "trainer/ZF1 Loss                     -20.1592\n",
      "trainer/ZF2 Loss                     -22.59\n",
      "trainer/ZF Expert Reward              25.5343\n",
      "trainer/ZF Policy Reward              -9.79009\n",
      "trainer/ZF CHI2 Term                  35.2356\n",
      "trainer/Policy Loss                 -190.99\n",
      "trainer/Bias Loss                    109\n",
      "trainer/Bias Value                    15.9258\n",
      "trainer/Policy Grad Norm             134.017\n",
      "trainer/Policy Param Norm             22.3886\n",
      "trainer/Zf1 Grad Norm               1127.77\n",
      "trainer/Zf1 Param Norm                52.2542\n",
      "trainer/Zf2 Grad Norm                750.225\n",
      "trainer/Zf2 Param Norm                51.8765\n",
      "trainer/Z Expert Predictions Mean    652.31\n",
      "trainer/Z Expert Predictions Std      74.5661\n",
      "trainer/Z Expert Predictions Max     741.584\n",
      "trainer/Z Expert Predictions Min     349.839\n",
      "trainer/Z Policy Predictions Mean    173.174\n",
      "trainer/Z Policy Predictions Std     178.34\n",
      "trainer/Z Policy Predictions Max     591.443\n",
      "trainer/Z Policy Predictions Min     -69.235\n",
      "trainer/Z Expert Targets Mean        626.775\n",
      "trainer/Z Expert Targets Std          73.1141\n",
      "trainer/Z Expert Targets Max         721.703\n",
      "trainer/Z Expert Targets Min         366.461\n",
      "trainer/Z Policy Targets Mean        182.965\n",
      "trainer/Z Policy Targets Std         178.654\n",
      "trainer/Z Policy Targets Max         588.985\n",
      "trainer/Z Policy Targets Min         -70.2966\n",
      "trainer/Log Pis Mean                  21.5009\n",
      "trainer/Log Pis Std                    7.63051\n",
      "trainer/Policy mu Mean                 1.08697\n",
      "trainer/Policy mu Std                  2.1465\n",
      "trainer/Policy log std Mean           -2.60405\n",
      "trainer/Policy log std Std             1.28416\n",
      "trainer/Alpha                          0.0200308\n",
      "trainer/Alpha Loss                    -0.0300606\n",
      "exploration/num steps total        18303\n",
      "exploration/num paths total          529\n",
      "evaluation/num steps total         27554\n",
      "evaluation/num paths total           110\n",
      "evaluation/path length Mean          451\n",
      "evaluation/path length Std            97.4002\n",
      "evaluation/path length Max           616\n",
      "evaluation/path length Min           329\n",
      "evaluation/Rewards Mean                2.9232\n",
      "evaluation/Rewards Std                 1.60555\n",
      "evaluation/Rewards Max                 6.19005\n",
      "evaluation/Rewards Min                -1.93335\n",
      "evaluation/Returns Mean             1318.36\n",
      "evaluation/Returns Std               274.406\n",
      "evaluation/Returns Max              1705.44\n",
      "evaluation/Returns Min               783.371\n",
      "evaluation/Estimation Bias Mean      446.291\n",
      "evaluation/Estimation Bias Std       195.859\n",
      "evaluation/EB/Q_True Mean             24.0399\n",
      "evaluation/EB/Q_True Std              76.2079\n",
      "evaluation/EB/Q_Pred Mean            470.331\n",
      "evaluation/EB/Q_Pred Std             191.366\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1318.36\n",
      "evaluation/Actions Mean                0.436621\n",
      "evaluation/Actions Std                 0.619184\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999582\n",
      "time/backward_policy (s)               1.73148\n",
      "time/backward_zf1 (s)                  1.83863\n",
      "time/backward_zf2 (s)                  1.77234\n",
      "time/data sampling (s)                 0.234159\n",
      "time/data storing (s)                  0.0142449\n",
      "time/evaluation sampling (s)           1.14955\n",
      "time/exploration sampling (s)          0.198625\n",
      "time/logging (s)                       0.0066948\n",
      "time/preback_alpha (s)                 0.885743\n",
      "time/preback_policy (s)                0.961934\n",
      "time/preback_start (s)                 0.122302\n",
      "time/preback_zf (s)                    5.05536\n",
      "time/saving (s)                        0.00490074\n",
      "time/training (s)                      2.41632\n",
      "time/epoch (s)                        16.3923\n",
      "time/total (s)                       181.583\n",
      "Epoch                                 10\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:13:45.226020 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 11 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 22000\n",
      "trainer/ZF1 Loss                     -22.8512\n",
      "trainer/ZF2 Loss                     -25.0726\n",
      "trainer/ZF Expert Reward              23.9138\n",
      "trainer/ZF Policy Reward             -10.4543\n",
      "trainer/ZF CHI2 Term                  31.0974\n",
      "trainer/Policy Loss                 -229.541\n",
      "trainer/Bias Loss                     84.2914\n",
      "trainer/Bias Value                    16.0222\n",
      "trainer/Policy Grad Norm             162.429\n",
      "trainer/Policy Param Norm             22.7058\n",
      "trainer/Zf1 Grad Norm               1551.7\n",
      "trainer/Zf1 Param Norm                53.2502\n",
      "trainer/Zf2 Grad Norm               1152.64\n",
      "trainer/Zf2 Param Norm                52.8954\n",
      "trainer/Z Expert Predictions Mean    715.229\n",
      "trainer/Z Expert Predictions Std      76.6837\n",
      "trainer/Z Expert Predictions Max     790.659\n",
      "trainer/Z Expert Predictions Min     438.136\n",
      "trainer/Z Policy Predictions Mean    203.223\n",
      "trainer/Z Policy Predictions Std     194.651\n",
      "trainer/Z Policy Predictions Max     626.247\n",
      "trainer/Z Policy Predictions Min     -68.1001\n",
      "trainer/Z Expert Targets Mean        691.315\n",
      "trainer/Z Expert Targets Std          73.2503\n",
      "trainer/Z Expert Targets Max         771.016\n",
      "trainer/Z Expert Targets Min         435.148\n",
      "trainer/Z Policy Targets Mean        213.677\n",
      "trainer/Z Policy Targets Std         195.093\n",
      "trainer/Z Policy Targets Max         627.47\n",
      "trainer/Z Policy Targets Min         -70.9305\n",
      "trainer/Log Pis Mean                  20.9002\n",
      "trainer/Log Pis Std                    7.14432\n",
      "trainer/Policy mu Mean                 1.01941\n",
      "trainer/Policy mu Std                  2.00115\n",
      "trainer/Policy log std Mean           -2.58965\n",
      "trainer/Policy log std Std             1.22583\n",
      "trainer/Alpha                          0.0216354\n",
      "trainer/Alpha Loss                    -0.0194745\n",
      "exploration/num steps total        19298\n",
      "exploration/num paths total          531\n",
      "evaluation/num steps total         29299\n",
      "evaluation/num paths total           120\n",
      "evaluation/path length Mean          174.5\n",
      "evaluation/path length Std             9.12414\n",
      "evaluation/path length Max           197\n",
      "evaluation/path length Min           167\n",
      "evaluation/Rewards Mean                3.34233\n",
      "evaluation/Rewards Std                 2.05822\n",
      "evaluation/Rewards Max                 6.2249\n",
      "evaluation/Rewards Min                 0.0943547\n",
      "evaluation/Returns Mean              583.236\n",
      "evaluation/Returns Std                49.3407\n",
      "evaluation/Returns Max               709.448\n",
      "evaluation/Returns Min               552.035\n",
      "evaluation/Estimation Bias Mean      602.554\n",
      "evaluation/Estimation Bias Std       141.847\n",
      "evaluation/EB/Q_True Mean             28.2578\n",
      "evaluation/EB/Q_True Std              84.602\n",
      "evaluation/EB/Q_Pred Mean            630.812\n",
      "evaluation/EB/Q_Pred Std             115.544\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           583.236\n",
      "evaluation/Actions Mean                0.464059\n",
      "evaluation/Actions Std                 0.600862\n",
      "evaluation/Actions Max                 0.999998\n",
      "evaluation/Actions Min                -0.999701\n",
      "time/backward_policy (s)               1.85714\n",
      "time/backward_zf1 (s)                  2.01595\n",
      "time/backward_zf2 (s)                  1.96404\n",
      "time/data sampling (s)                 0.232494\n",
      "time/data storing (s)                  0.013899\n",
      "time/evaluation sampling (s)           0.307431\n",
      "time/exploration sampling (s)          0.201013\n",
      "time/logging (s)                       0.00286488\n",
      "time/preback_alpha (s)                 0.967057\n",
      "time/preback_policy (s)                1.07497\n",
      "time/preback_start (s)                 0.123149\n",
      "time/preback_zf (s)                    5.171\n",
      "time/saving (s)                        0.00484954\n",
      "time/training (s)                      2.30905\n",
      "time/epoch (s)                        16.2449\n",
      "time/total (s)                       197.845\n",
      "Epoch                                 11\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:14:00.543885 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 12 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 23000\n",
      "trainer/ZF1 Loss                     -24.4132\n",
      "trainer/ZF2 Loss                     -22.9317\n",
      "trainer/ZF Expert Reward              22.7725\n",
      "trainer/ZF Policy Reward              -5.65925\n",
      "trainer/ZF CHI2 Term                  25.0846\n",
      "trainer/Policy Loss                 -260.244\n",
      "trainer/Bias Loss                     58.7236\n",
      "trainer/Bias Value                    16.1164\n",
      "trainer/Policy Grad Norm              89.1467\n",
      "trainer/Policy Param Norm             22.9458\n",
      "trainer/Zf1 Grad Norm                398.445\n",
      "trainer/Zf1 Param Norm                54.1559\n",
      "trainer/Zf2 Grad Norm                489.219\n",
      "trainer/Zf2 Param Norm                53.8578\n",
      "trainer/Z Expert Predictions Mean    779.455\n",
      "trainer/Z Expert Predictions Std      62.8834\n",
      "trainer/Z Expert Predictions Max     838.991\n",
      "trainer/Z Expert Predictions Min     494.436\n",
      "trainer/Z Policy Predictions Mean    236.118\n",
      "trainer/Z Policy Predictions Std     228.799\n",
      "trainer/Z Policy Predictions Max     810.786\n",
      "trainer/Z Policy Predictions Min     -48.4378\n",
      "trainer/Z Expert Targets Mean        756.683\n",
      "trainer/Z Expert Targets Std          61.7333\n",
      "trainer/Z Expert Targets Max         817.993\n",
      "trainer/Z Expert Targets Min         496.666\n",
      "trainer/Z Policy Targets Mean        241.777\n",
      "trainer/Z Policy Targets Std         226.229\n",
      "trainer/Z Policy Targets Max         797.1\n",
      "trainer/Z Policy Targets Min         -49.7274\n",
      "trainer/Log Pis Mean                  20.5306\n",
      "trainer/Log Pis Std                    6.40219\n",
      "trainer/Policy mu Mean                 1.09599\n",
      "trainer/Policy mu Std                  1.88594\n",
      "trainer/Policy log std Mean           -2.52016\n",
      "trainer/Policy log std Std             1.18403\n",
      "trainer/Alpha                          0.0232251\n",
      "trainer/Alpha Loss                    -0.0123219\n",
      "exploration/num steps total        21726\n",
      "exploration/num paths total          537\n",
      "evaluation/num steps total         32052\n",
      "evaluation/num paths total           130\n",
      "evaluation/path length Mean          275.3\n",
      "evaluation/path length Std             3.60694\n",
      "evaluation/path length Max           280\n",
      "evaluation/path length Min           267\n",
      "evaluation/Rewards Mean                3.59105\n",
      "evaluation/Rewards Std                 1.56719\n",
      "evaluation/Rewards Max                 5.99827\n",
      "evaluation/Rewards Min                 0.170466\n",
      "evaluation/Returns Mean              988.615\n",
      "evaluation/Returns Std                18.9993\n",
      "evaluation/Returns Max              1011.69\n",
      "evaluation/Returns Min               948.348\n",
      "evaluation/Estimation Bias Mean      626.321\n",
      "evaluation/Estimation Bias Std       174.445\n",
      "evaluation/EB/Q_True Mean             28.2323\n",
      "evaluation/EB/Q_True Std              88.6207\n",
      "evaluation/EB/Q_Pred Mean            654.553\n",
      "evaluation/EB/Q_Pred Std             152.011\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           988.615\n",
      "evaluation/Actions Mean                0.527435\n",
      "evaluation/Actions Std                 0.582608\n",
      "evaluation/Actions Max                 0.999997\n",
      "evaluation/Actions Min                -0.998962\n",
      "time/backward_policy (s)               1.66073\n",
      "time/backward_zf1 (s)                  1.75449\n",
      "time/backward_zf2 (s)                  1.69273\n",
      "time/data sampling (s)                 0.207067\n",
      "time/data storing (s)                  0.013811\n",
      "time/evaluation sampling (s)           0.460628\n",
      "time/exploration sampling (s)          0.198636\n",
      "time/logging (s)                       0.0042933\n",
      "time/preback_alpha (s)                 0.85188\n",
      "time/preback_policy (s)                0.918245\n",
      "time/preback_start (s)                 0.114372\n",
      "time/preback_zf (s)                    4.983\n",
      "time/saving (s)                        0.00491716\n",
      "time/training (s)                      2.3947\n",
      "time/epoch (s)                        15.2595\n",
      "time/total (s)                       213.122\n",
      "Epoch                                 12\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:14:16.754236 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 13 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 24000\n",
      "trainer/ZF1 Loss                      87.4298\n",
      "trainer/ZF2 Loss                      81.9612\n",
      "trainer/ZF Expert Reward              26.4156\n",
      "trainer/ZF Policy Reward              -6.78119\n",
      "trainer/ZF CHI2 Term                 138.049\n",
      "trainer/Policy Loss                 -304.4\n",
      "trainer/Bias Loss                   1110.01\n",
      "trainer/Bias Value                    16.2108\n",
      "trainer/Policy Grad Norm             124.616\n",
      "trainer/Policy Param Norm             23.1906\n",
      "trainer/Zf1 Grad Norm               1031.97\n",
      "trainer/Zf1 Param Norm                55.156\n",
      "trainer/Zf2 Grad Norm               1538.53\n",
      "trainer/Zf2 Param Norm                54.902\n",
      "trainer/Z Expert Predictions Mean    824.271\n",
      "trainer/Z Expert Predictions Std      74.7291\n",
      "trainer/Z Expert Predictions Max     895.759\n",
      "trainer/Z Expert Predictions Min     529.178\n",
      "trainer/Z Policy Predictions Mean    280.953\n",
      "trainer/Z Policy Predictions Std     269.71\n",
      "trainer/Z Policy Predictions Max     838.408\n",
      "trainer/Z Policy Predictions Min     -65.6916\n",
      "trainer/Z Expert Targets Mean        797.855\n",
      "trainer/Z Expert Targets Std          87.7704\n",
      "trainer/Z Expert Targets Max         873.622\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        287.734\n",
      "trainer/Z Policy Targets Std         265.68\n",
      "trainer/Z Policy Targets Max         817.349\n",
      "trainer/Z Policy Targets Min         -67.565\n",
      "trainer/Log Pis Mean                  20.3608\n",
      "trainer/Log Pis Std                    6.49682\n",
      "trainer/Policy mu Mean                 1.10808\n",
      "trainer/Policy mu Std                  1.9238\n",
      "trainer/Policy log std Mean           -2.50237\n",
      "trainer/Policy log std Std             1.23734\n",
      "trainer/Alpha                          0.0246508\n",
      "trainer/Alpha Loss                    -0.00889405\n",
      "exploration/num steps total        22506\n",
      "exploration/num paths total          540\n",
      "evaluation/num steps total         34792\n",
      "evaluation/num paths total           140\n",
      "evaluation/path length Mean          274\n",
      "evaluation/path length Std            37.6855\n",
      "evaluation/path length Max           387\n",
      "evaluation/path length Min           259\n",
      "evaluation/Rewards Mean                3.32953\n",
      "evaluation/Rewards Std                 1.41885\n",
      "evaluation/Rewards Max                 5.79603\n",
      "evaluation/Rewards Min                 0.21867\n",
      "evaluation/Returns Mean              912.292\n",
      "evaluation/Returns Std               119.195\n",
      "evaluation/Returns Max              1269.59\n",
      "evaluation/Returns Min               863.57\n",
      "evaluation/Estimation Bias Mean      586.461\n",
      "evaluation/Estimation Bias Std       225.049\n",
      "evaluation/EB/Q_True Mean             37.7943\n",
      "evaluation/EB/Q_True Std              99.0158\n",
      "evaluation/EB/Q_Pred Mean            624.255\n",
      "evaluation/EB/Q_Pred Std             208.506\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           912.292\n",
      "evaluation/Actions Mean                0.500247\n",
      "evaluation/Actions Std                 0.57127\n",
      "evaluation/Actions Max                 0.999989\n",
      "evaluation/Actions Min                -0.998081\n",
      "time/backward_policy (s)               1.80316\n",
      "time/backward_zf1 (s)                  1.93425\n",
      "time/backward_zf2 (s)                  1.87715\n",
      "time/data sampling (s)                 0.231191\n",
      "time/data storing (s)                  0.0139768\n",
      "time/evaluation sampling (s)           0.615063\n",
      "time/exploration sampling (s)          0.197664\n",
      "time/logging (s)                       0.00426759\n",
      "time/preback_alpha (s)                 0.946429\n",
      "time/preback_policy (s)                1.05321\n",
      "time/preback_start (s)                 0.122791\n",
      "time/preback_zf (s)                    5.08369\n",
      "time/saving (s)                        0.0051944\n",
      "time/training (s)                      2.25708\n",
      "time/epoch (s)                        16.1451\n",
      "time/total (s)                       229.287\n",
      "Epoch                                 13\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:14:32.873364 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 14 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 25000\n",
      "trainer/ZF1 Loss                     -14.6245\n",
      "trainer/ZF2 Loss                     -16.6197\n",
      "trainer/ZF Expert Reward              24.4155\n",
      "trainer/ZF Policy Reward              -8.66857\n",
      "trainer/ZF CHI2 Term                  36.8889\n",
      "trainer/Policy Loss                 -312.538\n",
      "trainer/Bias Loss                    102.005\n",
      "trainer/Bias Value                    16.305\n",
      "trainer/Policy Grad Norm             122.857\n",
      "trainer/Policy Param Norm             23.4193\n",
      "trainer/Zf1 Grad Norm               1354.55\n",
      "trainer/Zf1 Param Norm                56.1331\n",
      "trainer/Zf2 Grad Norm               1134.07\n",
      "trainer/Zf2 Param Norm                55.8955\n",
      "trainer/Z Expert Predictions Mean    855.235\n",
      "trainer/Z Expert Predictions Std      86.918\n",
      "trainer/Z Expert Predictions Max     946.171\n",
      "trainer/Z Expert Predictions Min     541.031\n",
      "trainer/Z Policy Predictions Mean    286.701\n",
      "trainer/Z Policy Predictions Std     271.257\n",
      "trainer/Z Policy Predictions Max     875.154\n",
      "trainer/Z Policy Predictions Min     -55.5873\n",
      "trainer/Z Expert Targets Mean        830.819\n",
      "trainer/Z Expert Targets Std          87.5707\n",
      "trainer/Z Expert Targets Max         926.178\n",
      "trainer/Z Expert Targets Min         561.7\n",
      "trainer/Z Policy Targets Mean        295.369\n",
      "trainer/Z Policy Targets Std         269.894\n",
      "trainer/Z Policy Targets Max         881.322\n",
      "trainer/Z Policy Targets Min         -42.8749\n",
      "trainer/Log Pis Mean                  19.6231\n",
      "trainer/Log Pis Std                    5.47375\n",
      "trainer/Policy mu Mean                 0.994461\n",
      "trainer/Policy mu Std                  1.72926\n",
      "trainer/Policy log std Mean           -2.65575\n",
      "trainer/Policy log std Std             1.18124\n",
      "trainer/Alpha                          0.0256862\n",
      "trainer/Alpha Loss                     0.00967974\n",
      "exploration/num steps total        23534\n",
      "exploration/num paths total          543\n",
      "evaluation/num steps total         36919\n",
      "evaluation/num paths total           150\n",
      "evaluation/path length Mean          212.7\n",
      "evaluation/path length Std             2.86531\n",
      "evaluation/path length Max           218\n",
      "evaluation/path length Min           208\n",
      "evaluation/Rewards Mean                3.20176\n",
      "evaluation/Rewards Std                 1.62922\n",
      "evaluation/Rewards Max                 5.72173\n",
      "evaluation/Rewards Min                 0.0946793\n",
      "evaluation/Returns Mean              681.014\n",
      "evaluation/Returns Std                13.2364\n",
      "evaluation/Returns Max               701.225\n",
      "evaluation/Returns Min               654.126\n",
      "evaluation/Estimation Bias Mean      646.763\n",
      "evaluation/Estimation Bias Std       249.295\n",
      "evaluation/EB/Q_True Mean             23.3423\n",
      "evaluation/EB/Q_True Std              73.998\n",
      "evaluation/EB/Q_Pred Mean            670.105\n",
      "evaluation/EB/Q_Pred Std             242.669\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           681.014\n",
      "evaluation/Actions Mean                0.430581\n",
      "evaluation/Actions Std                 0.599452\n",
      "evaluation/Actions Max                 0.999884\n",
      "evaluation/Actions Min                -0.996456\n",
      "time/backward_policy (s)               1.82\n",
      "time/backward_zf1 (s)                  1.97319\n",
      "time/backward_zf2 (s)                  1.88257\n",
      "time/data sampling (s)                 0.233448\n",
      "time/data storing (s)                  0.0146074\n",
      "time/evaluation sampling (s)           0.338698\n",
      "time/exploration sampling (s)          0.203045\n",
      "time/logging (s)                       0.0040053\n",
      "time/preback_alpha (s)                 0.955503\n",
      "time/preback_policy (s)                1.05765\n",
      "time/preback_start (s)                 0.124504\n",
      "time/preback_zf (s)                    5.13283\n",
      "time/saving (s)                        0.00480416\n",
      "time/training (s)                      2.30991\n",
      "time/epoch (s)                        16.0548\n",
      "time/total (s)                       245.36\n",
      "Epoch                                 14\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:14:48.138593 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 15 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 26000\n",
      "trainer/ZF1 Loss                      -5.97098\n",
      "trainer/ZF2 Loss                      -0.563766\n",
      "trainer/ZF Expert Reward              25.9633\n",
      "trainer/ZF Policy Reward              -3.38016\n",
      "trainer/ZF CHI2 Term                  45.3762\n",
      "trainer/Policy Loss                 -330.553\n",
      "trainer/Bias Loss                    135.829\n",
      "trainer/Bias Value                    16.3987\n",
      "trainer/Policy Grad Norm              97.3397\n",
      "trainer/Policy Param Norm             23.6389\n",
      "trainer/Zf1 Grad Norm               1168.06\n",
      "trainer/Zf1 Param Norm                57.1098\n",
      "trainer/Zf2 Grad Norm               1661.14\n",
      "trainer/Zf2 Param Norm                56.8564\n",
      "trainer/Z Expert Predictions Mean    890.282\n",
      "trainer/Z Expert Predictions Std      91.6237\n",
      "trainer/Z Expert Predictions Max     997.535\n",
      "trainer/Z Expert Predictions Min     604.731\n",
      "trainer/Z Policy Predictions Mean    300.957\n",
      "trainer/Z Policy Predictions Std     285.485\n",
      "trainer/Z Policy Predictions Max     856.5\n",
      "trainer/Z Policy Predictions Min     -80.8105\n",
      "trainer/Z Expert Targets Mean        864.318\n",
      "trainer/Z Expert Targets Std          93.9745\n",
      "trainer/Z Expert Targets Max         975.949\n",
      "trainer/Z Expert Targets Min         593.725\n",
      "trainer/Z Policy Targets Mean        304.337\n",
      "trainer/Z Policy Targets Std         281.693\n",
      "trainer/Z Policy Targets Max         866.879\n",
      "trainer/Z Policy Targets Min         -76.1837\n",
      "trainer/Log Pis Mean                  19.4951\n",
      "trainer/Log Pis Std                    6.21868\n",
      "trainer/Policy mu Mean                 0.910072\n",
      "trainer/Policy mu Std                  1.73645\n",
      "trainer/Policy log std Mean           -2.73168\n",
      "trainer/Policy log std Std             1.24797\n",
      "trainer/Alpha                          0.0250631\n",
      "trainer/Alpha Loss                     0.0126558\n",
      "exploration/num steps total        24363\n",
      "exploration/num paths total          546\n",
      "evaluation/num steps total         38904\n",
      "evaluation/num paths total           160\n",
      "evaluation/path length Mean          198.5\n",
      "evaluation/path length Std            10.2396\n",
      "evaluation/path length Max           228\n",
      "evaluation/path length Min           192\n",
      "evaluation/Rewards Mean                3.2796\n",
      "evaluation/Rewards Std                 1.76136\n",
      "evaluation/Rewards Max                 6.27271\n",
      "evaluation/Rewards Min                 0.101709\n",
      "evaluation/Returns Mean              651.001\n",
      "evaluation/Returns Std                36.4801\n",
      "evaluation/Returns Max               756.046\n",
      "evaluation/Returns Min               625.798\n",
      "evaluation/Estimation Bias Mean      643.181\n",
      "evaluation/Estimation Bias Std       291.733\n",
      "evaluation/EB/Q_True Mean             26.8884\n",
      "evaluation/EB/Q_True Std              81.0447\n",
      "evaluation/EB/Q_Pred Mean            670.069\n",
      "evaluation/EB/Q_Pred Std             284.731\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           651.001\n",
      "evaluation/Actions Mean                0.347732\n",
      "evaluation/Actions Std                 0.622529\n",
      "evaluation/Actions Max                 0.999989\n",
      "evaluation/Actions Min                -0.999506\n",
      "time/backward_policy (s)               1.63918\n",
      "time/backward_zf1 (s)                  1.75734\n",
      "time/backward_zf2 (s)                  1.69081\n",
      "time/data sampling (s)                 0.219229\n",
      "time/data storing (s)                  0.0141178\n",
      "time/evaluation sampling (s)           0.37929\n",
      "time/exploration sampling (s)          0.195569\n",
      "time/logging (s)                       0.00370767\n",
      "time/preback_alpha (s)                 0.862658\n",
      "time/preback_policy (s)                0.921346\n",
      "time/preback_start (s)                 0.118487\n",
      "time/preback_zf (s)                    4.99918\n",
      "time/saving (s)                        0.00504251\n",
      "time/training (s)                      2.39264\n",
      "time/epoch (s)                        15.1986\n",
      "time/total (s)                       260.581\n",
      "Epoch                                 15\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:15:04.400329 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 16 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 27000\n",
      "trainer/ZF1 Loss                     179.694\n",
      "trainer/ZF2 Loss                     175.372\n",
      "trainer/ZF Expert Reward              25.6892\n",
      "trainer/ZF Policy Reward              -7.76219\n",
      "trainer/ZF CHI2 Term                 230.508\n",
      "trainer/Policy Loss                 -344.289\n",
      "trainer/Bias Loss                   1972.57\n",
      "trainer/Bias Value                    16.4934\n",
      "trainer/Policy Grad Norm             140.511\n",
      "trainer/Policy Param Norm             23.8724\n",
      "trainer/Zf1 Grad Norm               1573.95\n",
      "trainer/Zf1 Param Norm                57.8869\n",
      "trainer/Zf2 Grad Norm               1212.37\n",
      "trainer/Zf2 Param Norm                57.6377\n",
      "trainer/Z Expert Predictions Mean    932.703\n",
      "trainer/Z Expert Predictions Std      83.9617\n",
      "trainer/Z Expert Predictions Max    1041.44\n",
      "trainer/Z Expert Predictions Min     587.617\n",
      "trainer/Z Policy Predictions Mean    315.19\n",
      "trainer/Z Policy Predictions Std     312.837\n",
      "trainer/Z Policy Predictions Max     936.563\n",
      "trainer/Z Policy Predictions Min     -75.0738\n",
      "trainer/Z Expert Targets Mean        907.014\n",
      "trainer/Z Expert Targets Std         101.635\n",
      "trainer/Z Expert Targets Max        1023.68\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        322.952\n",
      "trainer/Z Policy Targets Std         311.071\n",
      "trainer/Z Policy Targets Max         945.055\n",
      "trainer/Z Policy Targets Min         -78.846\n",
      "trainer/Log Pis Mean                  19.7204\n",
      "trainer/Log Pis Std                    7.01028\n",
      "trainer/Policy mu Mean                 0.942763\n",
      "trainer/Policy mu Std                  1.93577\n",
      "trainer/Policy log std Mean           -2.55152\n",
      "trainer/Policy log std Std             1.24291\n",
      "trainer/Alpha                          0.0245125\n",
      "trainer/Alpha Loss                     0.00685223\n",
      "exploration/num steps total        25653\n",
      "exploration/num paths total          551\n",
      "evaluation/num steps total         41167\n",
      "evaluation/num paths total           170\n",
      "evaluation/path length Mean          226.3\n",
      "evaluation/path length Std             1.1\n",
      "evaluation/path length Max           228\n",
      "evaluation/path length Min           225\n",
      "evaluation/Rewards Mean                3.51133\n",
      "evaluation/Rewards Std                 1.79215\n",
      "evaluation/Rewards Max                 6.23979\n",
      "evaluation/Rewards Min                 0.0604514\n",
      "evaluation/Returns Mean              794.615\n",
      "evaluation/Returns Std                 2.24291\n",
      "evaluation/Returns Max               799.579\n",
      "evaluation/Returns Min               791.989\n",
      "evaluation/Estimation Bias Mean      711.387\n",
      "evaluation/Estimation Bias Std       321.421\n",
      "evaluation/EB/Q_True Mean             25.555\n",
      "evaluation/EB/Q_True Std              81.8873\n",
      "evaluation/EB/Q_Pred Mean            736.942\n",
      "evaluation/EB/Q_Pred Std             318.532\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           794.615\n",
      "evaluation/Actions Mean                0.369124\n",
      "evaluation/Actions Std                 0.629829\n",
      "evaluation/Actions Max                 0.999998\n",
      "evaluation/Actions Min                -0.999376\n",
      "time/backward_policy (s)               1.86848\n",
      "time/backward_zf1 (s)                  2.00828\n",
      "time/backward_zf2 (s)                  1.91252\n",
      "time/data sampling (s)                 0.2341\n",
      "time/data storing (s)                  0.014515\n",
      "time/evaluation sampling (s)           0.510278\n",
      "time/exploration sampling (s)          0.204132\n",
      "time/logging (s)                       0.00380686\n",
      "time/preback_alpha (s)                 0.980788\n",
      "time/preback_policy (s)                1.10186\n",
      "time/preback_start (s)                 0.123082\n",
      "time/preback_zf (s)                    5.0614\n",
      "time/saving (s)                        0.00493155\n",
      "time/training (s)                      2.16192\n",
      "time/epoch (s)                        16.1901\n",
      "time/total (s)                       276.798\n",
      "Epoch                                 16\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:15:20.761878 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 17 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 28000\n",
      "trainer/ZF1 Loss                       5.19697\n",
      "trainer/ZF2 Loss                      -0.263786\n",
      "trainer/ZF Expert Reward              19.8037\n",
      "trainer/ZF Policy Reward              -6.39974\n",
      "trainer/ZF CHI2 Term                  48.5856\n",
      "trainer/Policy Loss                 -383.172\n",
      "trainer/Bias Loss                    137.909\n",
      "trainer/Bias Value                    16.587\n",
      "trainer/Policy Grad Norm             225.942\n",
      "trainer/Policy Param Norm             24.1212\n",
      "trainer/Zf1 Grad Norm               1118.07\n",
      "trainer/Zf1 Param Norm                58.5794\n",
      "trainer/Zf2 Grad Norm               2153.98\n",
      "trainer/Zf2 Param Norm                58.3574\n",
      "trainer/Z Expert Predictions Mean    969.482\n",
      "trainer/Z Expert Predictions Std      80.5206\n",
      "trainer/Z Expert Predictions Max    1074.2\n",
      "trainer/Z Expert Predictions Min     579.164\n",
      "trainer/Z Policy Predictions Mean    359.337\n",
      "trainer/Z Policy Predictions Std     318.331\n",
      "trainer/Z Policy Predictions Max    1026.31\n",
      "trainer/Z Policy Predictions Min     -86.9458\n",
      "trainer/Z Expert Targets Mean        949.679\n",
      "trainer/Z Expert Targets Std          77.2751\n",
      "trainer/Z Expert Targets Max        1057.68\n",
      "trainer/Z Expert Targets Min         582.854\n",
      "trainer/Z Policy Targets Mean        365.737\n",
      "trainer/Z Policy Targets Std         315.626\n",
      "trainer/Z Policy Targets Max        1011.92\n",
      "trainer/Z Policy Targets Min         -90.6263\n",
      "trainer/Log Pis Mean                  20.1167\n",
      "trainer/Log Pis Std                    7.1715\n",
      "trainer/Policy mu Mean                 0.96361\n",
      "trainer/Policy mu Std                  1.91815\n",
      "trainer/Policy log std Mean           -2.56886\n",
      "trainer/Policy log std Std             1.23156\n",
      "trainer/Alpha                          0.0270275\n",
      "trainer/Alpha Loss                    -0.00315465\n",
      "exploration/num steps total        26099\n",
      "exploration/num paths total          553\n",
      "evaluation/num steps total         44763\n",
      "evaluation/num paths total           180\n",
      "evaluation/path length Mean          359.6\n",
      "evaluation/path length Std            89.2258\n",
      "evaluation/path length Max           539\n",
      "evaluation/path length Min           260\n",
      "evaluation/Rewards Mean                3.34351\n",
      "evaluation/Rewards Std                 1.47563\n",
      "evaluation/Rewards Max                 6.16374\n",
      "evaluation/Rewards Min                 0.0236527\n",
      "evaluation/Returns Mean             1202.33\n",
      "evaluation/Returns Std               294.105\n",
      "evaluation/Returns Max              1841.06\n",
      "evaluation/Returns Min               919.446\n",
      "evaluation/Estimation Bias Mean      679.95\n",
      "evaluation/Estimation Bias Std       306.781\n",
      "evaluation/EB/Q_True Mean             44.3306\n",
      "evaluation/EB/Q_True Std             110.419\n",
      "evaluation/EB/Q_Pred Mean            724.281\n",
      "evaluation/EB/Q_Pred Std             299.29\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1202.33\n",
      "evaluation/Actions Mean                0.452035\n",
      "evaluation/Actions Std                 0.60394\n",
      "evaluation/Actions Max                 0.999997\n",
      "evaluation/Actions Min                -0.999969\n",
      "time/backward_policy (s)               1.78117\n",
      "time/backward_zf1 (s)                  1.91084\n",
      "time/backward_zf2 (s)                  1.84006\n",
      "time/data sampling (s)                 0.232878\n",
      "time/data storing (s)                  0.013803\n",
      "time/evaluation sampling (s)           0.809838\n",
      "time/exploration sampling (s)          0.192764\n",
      "time/logging (s)                       0.00867127\n",
      "time/preback_alpha (s)                 0.904664\n",
      "time/preback_policy (s)                1.00706\n",
      "time/preback_start (s)                 0.12143\n",
      "time/preback_zf (s)                    5.08096\n",
      "time/saving (s)                        0.00712321\n",
      "time/training (s)                      2.38954\n",
      "time/epoch (s)                        16.3008\n",
      "time/total (s)                       293.12\n",
      "Epoch                                 17\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:15:36.533339 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 18 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 29000\n",
      "trainer/ZF1 Loss                       5.27575\n",
      "trainer/ZF2 Loss                       6.79916\n",
      "trainer/ZF Expert Reward              28.3536\n",
      "trainer/ZF Policy Reward              -1.53382\n",
      "trainer/ZF CHI2 Term                  55.7038\n",
      "trainer/Policy Loss                 -399.364\n",
      "trainer/Bias Loss                    154.935\n",
      "trainer/Bias Value                    16.6793\n",
      "trainer/Policy Grad Norm             272.196\n",
      "trainer/Policy Param Norm             24.3755\n",
      "trainer/Zf1 Grad Norm               1711.87\n",
      "trainer/Zf1 Param Norm                59.2166\n",
      "trainer/Zf2 Grad Norm               1574.9\n",
      "trainer/Zf2 Param Norm                58.964\n",
      "trainer/Z Expert Predictions Mean    993.456\n",
      "trainer/Z Expert Predictions Std      80.6817\n",
      "trainer/Z Expert Predictions Max    1105.25\n",
      "trainer/Z Expert Predictions Min     592.973\n",
      "trainer/Z Policy Predictions Mean    383.021\n",
      "trainer/Z Policy Predictions Std     352.69\n",
      "trainer/Z Policy Predictions Max    1043.32\n",
      "trainer/Z Policy Predictions Min     -81.2615\n",
      "trainer/Z Expert Targets Mean        965.103\n",
      "trainer/Z Expert Targets Std          80.1829\n",
      "trainer/Z Expert Targets Max        1083.15\n",
      "trainer/Z Expert Targets Min         599.832\n",
      "trainer/Z Policy Targets Mean        384.555\n",
      "trainer/Z Policy Targets Std         344.817\n",
      "trainer/Z Policy Targets Max        1037.12\n",
      "trainer/Z Policy Targets Min         -71.3926\n",
      "trainer/Log Pis Mean                  19.9787\n",
      "trainer/Log Pis Std                    6.98572\n",
      "trainer/Policy mu Mean                 1.01223\n",
      "trainer/Policy mu Std                  1.85412\n",
      "trainer/Policy log std Mean           -2.62317\n",
      "trainer/Policy log std Std             1.22779\n",
      "trainer/Alpha                          0.0289981\n",
      "trainer/Alpha Loss                     0.000616972\n",
      "exploration/num steps total        27932\n",
      "exploration/num paths total          559\n",
      "evaluation/num steps total         46635\n",
      "evaluation/num paths total           190\n",
      "evaluation/path length Mean          187.2\n",
      "evaluation/path length Std            11.7541\n",
      "evaluation/path length Max           209\n",
      "evaluation/path length Min           173\n",
      "evaluation/Rewards Mean                3.41513\n",
      "evaluation/Rewards Std                 1.90555\n",
      "evaluation/Rewards Max                 6.7065\n",
      "evaluation/Rewards Min                 0.180129\n",
      "evaluation/Returns Mean              639.313\n",
      "evaluation/Returns Std                62.3139\n",
      "evaluation/Returns Max               754.025\n",
      "evaluation/Returns Min               558.174\n",
      "evaluation/Estimation Bias Mean      746.694\n",
      "evaluation/Estimation Bias Std       284.416\n",
      "evaluation/EB/Q_True Mean             28.3675\n",
      "evaluation/EB/Q_True Std              85.3691\n",
      "evaluation/EB/Q_Pred Mean            775.062\n",
      "evaluation/EB/Q_Pred Std             275.621\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           639.313\n",
      "evaluation/Actions Mean                0.448225\n",
      "evaluation/Actions Std                 0.623349\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999708\n",
      "time/backward_policy (s)               1.74657\n",
      "time/backward_zf1 (s)                  1.86778\n",
      "time/backward_zf2 (s)                  1.79158\n",
      "time/data sampling (s)                 0.237594\n",
      "time/data storing (s)                  0.0142954\n",
      "time/evaluation sampling (s)           0.366481\n",
      "time/exploration sampling (s)          0.201533\n",
      "time/logging (s)                       0.00314283\n",
      "time/preback_alpha (s)                 0.903476\n",
      "time/preback_policy (s)                0.988347\n",
      "time/preback_start (s)                 0.122297\n",
      "time/preback_zf (s)                    5.06746\n",
      "time/saving (s)                        0.00472964\n",
      "time/training (s)                      2.38322\n",
      "time/epoch (s)                        15.6985\n",
      "time/total (s)                       308.841\n",
      "Epoch                                 18\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:15:52.252059 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 19 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 30000\n",
      "trainer/ZF1 Loss                       5.8727\n",
      "trainer/ZF2 Loss                       5.72246\n",
      "trainer/ZF Expert Reward              24.9731\n",
      "trainer/ZF Policy Reward              -5.09577\n",
      "trainer/ZF CHI2 Term                  55.8069\n",
      "trainer/Policy Loss                 -389.495\n",
      "trainer/Bias Loss                    169.177\n",
      "trainer/Bias Value                    16.77\n",
      "trainer/Policy Grad Norm             105.307\n",
      "trainer/Policy Param Norm             24.6289\n",
      "trainer/Zf1 Grad Norm               1293.69\n",
      "trainer/Zf1 Param Norm                59.7482\n",
      "trainer/Zf2 Grad Norm               1659.57\n",
      "trainer/Zf2 Param Norm                59.5235\n",
      "trainer/Z Expert Predictions Mean   1003.82\n",
      "trainer/Z Expert Predictions Std      90.5693\n",
      "trainer/Z Expert Predictions Max    1128.9\n",
      "trainer/Z Expert Predictions Min     650.481\n",
      "trainer/Z Policy Predictions Mean    361.571\n",
      "trainer/Z Policy Predictions Std     354.795\n",
      "trainer/Z Policy Predictions Max    1089.67\n",
      "trainer/Z Policy Predictions Min     -88.6041\n",
      "trainer/Z Expert Targets Mean        978.848\n",
      "trainer/Z Expert Targets Std          87.1317\n",
      "trainer/Z Expert Targets Max        1109.18\n",
      "trainer/Z Expert Targets Min         630.418\n",
      "trainer/Z Policy Targets Mean        366.667\n",
      "trainer/Z Policy Targets Std         348.666\n",
      "trainer/Z Policy Targets Max        1070.92\n",
      "trainer/Z Policy Targets Min         -84.776\n",
      "trainer/Log Pis Mean                  20.1418\n",
      "trainer/Log Pis Std                    6.71258\n",
      "trainer/Policy mu Mean                 1.1525\n",
      "trainer/Policy mu Std                  1.8745\n",
      "trainer/Policy log std Mean           -2.46238\n",
      "trainer/Policy log std Std             1.17897\n",
      "trainer/Alpha                          0.0314377\n",
      "trainer/Alpha Loss                    -0.00445813\n",
      "exploration/num steps total        28581\n",
      "exploration/num paths total          562\n",
      "evaluation/num steps total         49639\n",
      "evaluation/num paths total           200\n",
      "evaluation/path length Mean          300.4\n",
      "evaluation/path length Std            32.7573\n",
      "evaluation/path length Max           380\n",
      "evaluation/path length Min           273\n",
      "evaluation/Rewards Mean                3.57867\n",
      "evaluation/Rewards Std                 1.70114\n",
      "evaluation/Rewards Max                 6.33514\n",
      "evaluation/Rewards Min                -0.727381\n",
      "evaluation/Returns Mean             1075.03\n",
      "evaluation/Returns Std               169.733\n",
      "evaluation/Returns Max              1533.75\n",
      "evaluation/Returns Min               816.987\n",
      "evaluation/Estimation Bias Mean      771.377\n",
      "evaluation/Estimation Bias Std       317.06\n",
      "evaluation/EB/Q_True Mean             42.4145\n",
      "evaluation/EB/Q_True Std             118.708\n",
      "evaluation/EB/Q_Pred Mean            813.792\n",
      "evaluation/EB/Q_Pred Std             302.313\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1075.03\n",
      "evaluation/Actions Mean                0.517097\n",
      "evaluation/Actions Std                 0.601935\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.69198\n",
      "time/backward_zf1 (s)                  1.81568\n",
      "time/backward_zf2 (s)                  1.73362\n",
      "time/data sampling (s)                 0.225267\n",
      "time/data storing (s)                  0.0137336\n",
      "time/evaluation sampling (s)           0.602656\n",
      "time/exploration sampling (s)          0.191072\n",
      "time/logging (s)                       0.00455558\n",
      "time/preback_alpha (s)                 0.884336\n",
      "time/preback_policy (s)                0.945772\n",
      "time/preback_start (s)                 0.120514\n",
      "time/preback_zf (s)                    5.0304\n",
      "time/saving (s)                        0.00488992\n",
      "time/training (s)                      2.39057\n",
      "time/epoch (s)                        15.655\n",
      "time/total (s)                       324.516\n",
      "Epoch                                 19\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:16:07.523508 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 20 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 31000\n",
      "trainer/ZF1 Loss                      30.4355\n",
      "trainer/ZF2 Loss                      25.2314\n",
      "trainer/ZF Expert Reward              31.0135\n",
      "trainer/ZF Policy Reward               2.78484\n",
      "trainer/ZF CHI2 Term                  77.1093\n",
      "trainer/Policy Loss                 -504.784\n",
      "trainer/Bias Loss                    235.227\n",
      "trainer/Bias Value                    16.86\n",
      "trainer/Policy Grad Norm             168.278\n",
      "trainer/Policy Param Norm             24.8679\n",
      "trainer/Zf1 Grad Norm               1907.85\n",
      "trainer/Zf1 Param Norm                60.3793\n",
      "trainer/Zf2 Grad Norm               1726.38\n",
      "trainer/Zf2 Param Norm                60.1703\n",
      "trainer/Z Expert Predictions Mean   1030.18\n",
      "trainer/Z Expert Predictions Std      81.59\n",
      "trainer/Z Expert Predictions Max    1149.02\n",
      "trainer/Z Expert Predictions Min     694.935\n",
      "trainer/Z Policy Predictions Mean    485.562\n",
      "trainer/Z Policy Predictions Std     362.991\n",
      "trainer/Z Policy Predictions Max    1084.71\n",
      "trainer/Z Policy Predictions Min     -73.8922\n",
      "trainer/Z Expert Targets Mean        999.162\n",
      "trainer/Z Expert Targets Std          81.9075\n",
      "trainer/Z Expert Targets Max        1130.96\n",
      "trainer/Z Expert Targets Min         609.846\n",
      "trainer/Z Policy Targets Mean        482.777\n",
      "trainer/Z Policy Targets Std         357.156\n",
      "trainer/Z Policy Targets Max        1088.16\n",
      "trainer/Z Policy Targets Min         -79.1729\n",
      "trainer/Log Pis Mean                  21.2599\n",
      "trainer/Log Pis Std                    6.48201\n",
      "trainer/Policy mu Mean                 1.10205\n",
      "trainer/Policy mu Std                  1.81882\n",
      "trainer/Policy log std Mean           -2.70682\n",
      "trainer/Policy log std Std             1.17192\n",
      "trainer/Alpha                          0.0349028\n",
      "trainer/Alpha Loss                    -0.0439664\n",
      "exploration/num steps total        29908\n",
      "exploration/num paths total          568\n",
      "evaluation/num steps total         51756\n",
      "evaluation/num paths total           210\n",
      "evaluation/path length Mean          211.7\n",
      "evaluation/path length Std             6.85638\n",
      "evaluation/path length Max           225\n",
      "evaluation/path length Min           203\n",
      "evaluation/Rewards Mean                3.70252\n",
      "evaluation/Rewards Std                 1.97297\n",
      "evaluation/Rewards Max                 6.27186\n",
      "evaluation/Rewards Min                 0.241342\n",
      "evaluation/Returns Mean              783.823\n",
      "evaluation/Returns Std                36.2446\n",
      "evaluation/Returns Max               861.539\n",
      "evaluation/Returns Min               745.828\n",
      "evaluation/Estimation Bias Mean      801.705\n",
      "evaluation/Estimation Bias Std       235.177\n",
      "evaluation/EB/Q_True Mean             29.5091\n",
      "evaluation/EB/Q_True Std              91.1589\n",
      "evaluation/EB/Q_Pred Mean            831.214\n",
      "evaluation/EB/Q_Pred Std             222.711\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           783.823\n",
      "evaluation/Actions Mean                0.48974\n",
      "evaluation/Actions Std                 0.589668\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.99982\n",
      "time/backward_policy (s)               1.64743\n",
      "time/backward_zf1 (s)                  1.77855\n",
      "time/backward_zf2 (s)                  1.69072\n",
      "time/data sampling (s)                 0.220491\n",
      "time/data storing (s)                  0.0137406\n",
      "time/evaluation sampling (s)           0.389834\n",
      "time/exploration sampling (s)          0.19525\n",
      "time/logging (s)                       0.00352684\n",
      "time/preback_alpha (s)                 0.855309\n",
      "time/preback_policy (s)                0.922718\n",
      "time/preback_start (s)                 0.119065\n",
      "time/preback_zf (s)                    4.98796\n",
      "time/saving (s)                        0.0053991\n",
      "time/training (s)                      2.3771\n",
      "time/epoch (s)                        15.2071\n",
      "time/total (s)                       339.744\n",
      "Epoch                                 20\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:16:24.142556 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 21 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 32000\n",
      "trainer/ZF1 Loss                     503.531\n",
      "trainer/ZF2 Loss                     488.749\n",
      "trainer/ZF Expert Reward              37.1163\n",
      "trainer/ZF Policy Reward               0.75845\n",
      "trainer/ZF CHI2 Term                 551.955\n",
      "trainer/Policy Loss                 -513.13\n",
      "trainer/Bias Loss                   4915.4\n",
      "trainer/Bias Value                    16.9479\n",
      "trainer/Policy Grad Norm             273.226\n",
      "trainer/Policy Param Norm             25.062\n",
      "trainer/Zf1 Grad Norm               2710.68\n",
      "trainer/Zf1 Param Norm                60.9974\n",
      "trainer/Zf2 Grad Norm               2212.64\n",
      "trainer/Zf2 Param Norm                60.8011\n",
      "trainer/Z Expert Predictions Mean   1056.85\n",
      "trainer/Z Expert Predictions Std      81.5757\n",
      "trainer/Z Expert Predictions Max    1169.63\n",
      "trainer/Z Expert Predictions Min     783.835\n",
      "trainer/Z Policy Predictions Mean    492.291\n",
      "trainer/Z Policy Predictions Std     371.905\n",
      "trainer/Z Policy Predictions Max    1104.18\n",
      "trainer/Z Policy Predictions Min     -73.3192\n",
      "trainer/Z Expert Targets Mean       1019.74\n",
      "trainer/Z Expert Targets Std         122.831\n",
      "trainer/Z Expert Targets Max        1151.12\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        491.533\n",
      "trainer/Z Policy Targets Std         367.192\n",
      "trainer/Z Policy Targets Max        1084.19\n",
      "trainer/Z Policy Targets Min         -83.0221\n",
      "trainer/Log Pis Mean                  19.6542\n",
      "trainer/Log Pis Std                    6.10344\n",
      "trainer/Policy mu Mean                 1.0898\n",
      "trainer/Policy mu Std                  1.73925\n",
      "trainer/Policy log std Mean           -2.59093\n",
      "trainer/Policy log std Std             1.1474\n",
      "trainer/Alpha                          0.0365993\n",
      "trainer/Alpha Loss                     0.0126569\n",
      "exploration/num steps total        30348\n",
      "exploration/num paths total          569\n",
      "evaluation/num steps total         54344\n",
      "evaluation/num paths total           220\n",
      "evaluation/path length Mean          258.8\n",
      "evaluation/path length Std            41.7224\n",
      "evaluation/path length Max           356\n",
      "evaluation/path length Min           193\n",
      "evaluation/Rewards Mean                3.87567\n",
      "evaluation/Rewards Std                 1.80742\n",
      "evaluation/Rewards Max                 7.93913\n",
      "evaluation/Rewards Min                 0.316094\n",
      "evaluation/Returns Mean             1003.02\n",
      "evaluation/Returns Std               191.667\n",
      "evaluation/Returns Max              1473.58\n",
      "evaluation/Returns Min               700.407\n",
      "evaluation/Estimation Bias Mean      745.439\n",
      "evaluation/Estimation Bias Std       298.176\n",
      "evaluation/EB/Q_True Mean             46.3748\n",
      "evaluation/EB/Q_True Std             123.592\n",
      "evaluation/EB/Q_Pred Mean            791.814\n",
      "evaluation/EB/Q_Pred Std             271.63\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1003.02\n",
      "evaluation/Actions Mean                0.507002\n",
      "evaluation/Actions Std                 0.607869\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.86248\n",
      "time/backward_zf1 (s)                  1.98178\n",
      "time/backward_zf2 (s)                  1.92706\n",
      "time/data sampling (s)                 0.241601\n",
      "time/data storing (s)                  0.0143893\n",
      "time/evaluation sampling (s)           0.5644\n",
      "time/exploration sampling (s)          0.198643\n",
      "time/logging (s)                       0.00422532\n",
      "time/preback_alpha (s)                 0.954283\n",
      "time/preback_policy (s)                1.06166\n",
      "time/preback_start (s)                 0.125575\n",
      "time/preback_zf (s)                    5.15962\n",
      "time/saving (s)                        0.00500068\n",
      "time/training (s)                      2.4504\n",
      "time/epoch (s)                        16.5511\n",
      "time/total (s)                       356.317\n",
      "Epoch                                 21\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:16:41.576406 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 22 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 33000\n",
      "trainer/ZF1 Loss                      17.1971\n",
      "trainer/ZF2 Loss                      34.496\n",
      "trainer/ZF Expert Reward              28.3219\n",
      "trainer/ZF Policy Reward              -1.76958\n",
      "trainer/ZF CHI2 Term                  76.2861\n",
      "trainer/Policy Loss                 -520.495\n",
      "trainer/Bias Loss                    258.088\n",
      "trainer/Bias Value                    17.0337\n",
      "trainer/Policy Grad Norm             300.447\n",
      "trainer/Policy Param Norm             25.2249\n",
      "trainer/Zf1 Grad Norm               1749.91\n",
      "trainer/Zf1 Param Norm                61.64\n",
      "trainer/Zf2 Grad Norm               2146.65\n",
      "trainer/Zf2 Param Norm                61.4385\n",
      "trainer/Z Expert Predictions Mean   1065.12\n",
      "trainer/Z Expert Predictions Std      87.896\n",
      "trainer/Z Expert Predictions Max    1201.81\n",
      "trainer/Z Expert Predictions Min     599.609\n",
      "trainer/Z Policy Predictions Mean    498.941\n",
      "trainer/Z Policy Predictions Std     362.179\n",
      "trainer/Z Policy Predictions Max    1107\n",
      "trainer/Z Policy Predictions Min    -102.597\n",
      "trainer/Z Expert Targets Mean       1036.8\n",
      "trainer/Z Expert Targets Std          93.0092\n",
      "trainer/Z Expert Targets Max        1179.46\n",
      "trainer/Z Expert Targets Min         538.23\n",
      "trainer/Z Policy Targets Mean        500.71\n",
      "trainer/Z Policy Targets Std         358.48\n",
      "trainer/Z Policy Targets Max        1103.3\n",
      "trainer/Z Policy Targets Min         -96.7444\n",
      "trainer/Log Pis Mean                  20.5536\n",
      "trainer/Log Pis Std                    6.69053\n",
      "trainer/Policy mu Mean                 1.20505\n",
      "trainer/Policy mu Std                  1.82634\n",
      "trainer/Policy log std Mean           -2.4849\n",
      "trainer/Policy log std Std             1.15207\n",
      "trainer/Alpha                          0.037583\n",
      "trainer/Alpha Loss                    -0.0208054\n",
      "exploration/num steps total        32037\n",
      "exploration/num paths total          576\n",
      "evaluation/num steps total         57144\n",
      "evaluation/num paths total           230\n",
      "evaluation/path length Mean          280\n",
      "evaluation/path length Std            12.3288\n",
      "evaluation/path length Max           298\n",
      "evaluation/path length Min           257\n",
      "evaluation/Rewards Mean                3.3372\n",
      "evaluation/Rewards Std                 1.41961\n",
      "evaluation/Rewards Max                 5.97558\n",
      "evaluation/Rewards Min                 0.236594\n",
      "evaluation/Returns Mean              934.415\n",
      "evaluation/Returns Std                58.0011\n",
      "evaluation/Returns Max              1042.24\n",
      "evaluation/Returns Min               841.973\n",
      "evaluation/Estimation Bias Mean      718.659\n",
      "evaluation/Estimation Bias Std       332.204\n",
      "evaluation/EB/Q_True Mean             28.8292\n",
      "evaluation/EB/Q_True Std              89.0947\n",
      "evaluation/EB/Q_Pred Mean            747.488\n",
      "evaluation/EB/Q_Pred Std             326.335\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           934.415\n",
      "evaluation/Actions Mean                0.515243\n",
      "evaluation/Actions Std                 0.583928\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999613\n",
      "time/backward_policy (s)               2.05325\n",
      "time/backward_zf1 (s)                  2.20727\n",
      "time/backward_zf2 (s)                  2.12987\n",
      "time/data sampling (s)                 0.264617\n",
      "time/data storing (s)                  0.0160743\n",
      "time/evaluation sampling (s)           0.480242\n",
      "time/exploration sampling (s)          0.213317\n",
      "time/logging (s)                       0.00412871\n",
      "time/preback_alpha (s)                 1.05549\n",
      "time/preback_policy (s)                1.21681\n",
      "time/preback_start (s)                 0.130319\n",
      "time/preback_zf (s)                    5.23364\n",
      "time/saving (s)                        0.00489829\n",
      "time/training (s)                      2.29853\n",
      "time/epoch (s)                        17.3085\n",
      "time/total (s)                       373.699\n",
      "Epoch                                 22\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:16:57.607802 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 23 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 34000\n",
      "trainer/ZF1 Loss                      43.6522\n",
      "trainer/ZF2 Loss                      33.6306\n",
      "trainer/ZF Expert Reward              23.349\n",
      "trainer/ZF Policy Reward              -3.25498\n",
      "trainer/ZF CHI2 Term                  84.1441\n",
      "trainer/Policy Loss                 -555.489\n",
      "trainer/Bias Loss                    158.1\n",
      "trainer/Bias Value                    17.1166\n",
      "trainer/Policy Grad Norm              98.8978\n",
      "trainer/Policy Param Norm             25.3607\n",
      "trainer/Zf1 Grad Norm               2406.51\n",
      "trainer/Zf1 Param Norm                62.2861\n",
      "trainer/Zf2 Grad Norm               1711.49\n",
      "trainer/Zf2 Param Norm                62.057\n",
      "trainer/Z Expert Predictions Mean   1057.01\n",
      "trainer/Z Expert Predictions Std     111.206\n",
      "trainer/Z Expert Predictions Max    1224.9\n",
      "trainer/Z Expert Predictions Min     770.912\n",
      "trainer/Z Policy Predictions Mean    522.085\n",
      "trainer/Z Policy Predictions Std     353.423\n",
      "trainer/Z Policy Predictions Max    1128.89\n",
      "trainer/Z Policy Predictions Min     -68.9838\n",
      "trainer/Z Expert Targets Mean       1033.66\n",
      "trainer/Z Expert Targets Std         108.682\n",
      "trainer/Z Expert Targets Max        1207.63\n",
      "trainer/Z Expert Targets Min         786.213\n",
      "trainer/Z Policy Targets Mean        525.34\n",
      "trainer/Z Policy Targets Std         348.388\n",
      "trainer/Z Policy Targets Max        1124.96\n",
      "trainer/Z Policy Targets Min         -75.9209\n",
      "trainer/Log Pis Mean                  19.0896\n",
      "trainer/Log Pis Std                    5.93393\n",
      "trainer/Policy mu Mean                 1.17031\n",
      "trainer/Policy mu Std                  1.70737\n",
      "trainer/Policy log std Mean           -2.54491\n",
      "trainer/Policy log std Std             1.13035\n",
      "trainer/Alpha                          0.0380339\n",
      "trainer/Alpha Loss                     0.0346247\n",
      "exploration/num steps total        32037\n",
      "exploration/num paths total          576\n",
      "evaluation/num steps total         61514\n",
      "evaluation/num paths total           240\n",
      "evaluation/path length Mean          437\n",
      "evaluation/path length Std           117.553\n",
      "evaluation/path length Max           711\n",
      "evaluation/path length Min           312\n",
      "evaluation/Rewards Mean                3.50238\n",
      "evaluation/Rewards Std                 1.33687\n",
      "evaluation/Rewards Max                 6.704\n",
      "evaluation/Rewards Min                 0.301227\n",
      "evaluation/Returns Mean             1530.54\n",
      "evaluation/Returns Std               403.108\n",
      "evaluation/Returns Max              2417.04\n",
      "evaluation/Returns Min              1064.94\n",
      "evaluation/Estimation Bias Mean      637.561\n",
      "evaluation/Estimation Bias Std       328.563\n",
      "evaluation/EB/Q_True Mean             49.5326\n",
      "evaluation/EB/Q_True Std             117.003\n",
      "evaluation/EB/Q_Pred Mean            687.093\n",
      "evaluation/EB/Q_Pred Std             319.377\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1530.54\n",
      "evaluation/Actions Mean                0.442158\n",
      "evaluation/Actions Std                 0.60728\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999896\n",
      "time/backward_policy (s)               1.68254\n",
      "time/backward_zf1 (s)                  1.7775\n",
      "time/backward_zf2 (s)                  1.73433\n",
      "time/data sampling (s)                 0.204722\n",
      "time/data storing (s)                  0.0137693\n",
      "time/evaluation sampling (s)           1.03613\n",
      "time/exploration sampling (s)          0.187432\n",
      "time/logging (s)                       0.00596622\n",
      "time/preback_alpha (s)                 0.860932\n",
      "time/preback_policy (s)                0.930541\n",
      "time/preback_start (s)                 0.112158\n",
      "time/preback_zf (s)                    4.99128\n",
      "time/saving (s)                        0.00477545\n",
      "time/training (s)                      2.43008\n",
      "time/epoch (s)                        15.9722\n",
      "time/total (s)                       389.69\n",
      "Epoch                                 23\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:17:14.416358 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 24 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 35000\n",
      "trainer/ZF1 Loss                      35.888\n",
      "trainer/ZF2 Loss                      35.8618\n",
      "trainer/ZF Expert Reward              19.8257\n",
      "trainer/ZF Policy Reward              -2.6862\n",
      "trainer/ZF CHI2 Term                  78.2639\n",
      "trainer/Policy Loss                 -586.242\n",
      "trainer/Bias Loss                    213.996\n",
      "trainer/Bias Value                    17.1978\n",
      "trainer/Policy Grad Norm             103.833\n",
      "trainer/Policy Param Norm             25.4849\n",
      "trainer/Zf1 Grad Norm               2656.9\n",
      "trainer/Zf1 Param Norm                62.8679\n",
      "trainer/Zf2 Grad Norm               3194.94\n",
      "trainer/Zf2 Param Norm                62.5675\n",
      "trainer/Z Expert Predictions Mean   1062.66\n",
      "trainer/Z Expert Predictions Std     124.546\n",
      "trainer/Z Expert Predictions Max    1233.26\n",
      "trainer/Z Expert Predictions Min     773.227\n",
      "trainer/Z Policy Predictions Mean    559.168\n",
      "trainer/Z Policy Predictions Std     340.866\n",
      "trainer/Z Policy Predictions Max    1148.17\n",
      "trainer/Z Policy Predictions Min     -75.7578\n",
      "trainer/Z Expert Targets Mean       1042.84\n",
      "trainer/Z Expert Targets Std         121.031\n",
      "trainer/Z Expert Targets Max        1211.36\n",
      "trainer/Z Expert Targets Min         751.775\n",
      "trainer/Z Policy Targets Mean        561.854\n",
      "trainer/Z Policy Targets Std         337.839\n",
      "trainer/Z Policy Targets Max        1135.02\n",
      "trainer/Z Policy Targets Min         -68.1827\n",
      "trainer/Log Pis Mean                  20.0779\n",
      "trainer/Log Pis Std                    5.99386\n",
      "trainer/Policy mu Mean                 1.13063\n",
      "trainer/Policy mu Std                  1.74195\n",
      "trainer/Policy log std Mean           -2.61348\n",
      "trainer/Policy log std Std             1.12444\n",
      "trainer/Alpha                          0.0393682\n",
      "trainer/Alpha Loss                    -0.00306655\n",
      "exploration/num steps total        32424\n",
      "exploration/num paths total          577\n",
      "evaluation/num steps total         66351\n",
      "evaluation/num paths total           250\n",
      "evaluation/path length Mean          483.7\n",
      "evaluation/path length Std           184.2\n",
      "evaluation/path length Max           752\n",
      "evaluation/path length Min           256\n",
      "evaluation/Rewards Mean                3.13083\n",
      "evaluation/Rewards Std                 1.4096\n",
      "evaluation/Rewards Max                 6.34166\n",
      "evaluation/Rewards Min                 0.193044\n",
      "evaluation/Returns Mean             1514.38\n",
      "evaluation/Returns Std               564.096\n",
      "evaluation/Returns Max              2361.83\n",
      "evaluation/Returns Min               854.804\n",
      "evaluation/Estimation Bias Mean      618.79\n",
      "evaluation/Estimation Bias Std       324.184\n",
      "evaluation/EB/Q_True Mean             43.9748\n",
      "evaluation/EB/Q_True Std             107.463\n",
      "evaluation/EB/Q_Pred Mean            662.764\n",
      "evaluation/EB/Q_Pred Std             321.703\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1514.38\n",
      "evaluation/Actions Mean                0.373036\n",
      "evaluation/Actions Std                 0.642225\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999879\n",
      "time/backward_policy (s)               1.89079\n",
      "time/backward_zf1 (s)                  2.01718\n",
      "time/backward_zf2 (s)                  1.98662\n",
      "time/data sampling (s)                 0.205022\n",
      "time/data storing (s)                  0.013649\n",
      "time/evaluation sampling (s)           1.13902\n",
      "time/exploration sampling (s)          0.189105\n",
      "time/logging (s)                       0.006282\n",
      "time/preback_alpha (s)                 1.02346\n",
      "time/preback_policy (s)                1.17111\n",
      "time/preback_start (s)                 0.114219\n",
      "time/preback_zf (s)                    5.02796\n",
      "time/saving (s)                        0.00489376\n",
      "time/training (s)                      1.95045\n",
      "time/epoch (s)                        16.7398\n",
      "time/total (s)                       406.455\n",
      "Epoch                                 24\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:17:30.001688 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 25 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 36000\n",
      "trainer/ZF1 Loss                      27.414\n",
      "trainer/ZF2 Loss                      22.391\n",
      "trainer/ZF Expert Reward              25.8783\n",
      "trainer/ZF Policy Reward               0.0182657\n",
      "trainer/ZF CHI2 Term                  70.6322\n",
      "trainer/Policy Loss                 -572.485\n",
      "trainer/Bias Loss                    215.528\n",
      "trainer/Bias Value                    17.2797\n",
      "trainer/Policy Grad Norm             188.4\n",
      "trainer/Policy Param Norm             25.6373\n",
      "trainer/Zf1 Grad Norm               1568.37\n",
      "trainer/Zf1 Param Norm                63.3795\n",
      "trainer/Zf2 Grad Norm               1318.41\n",
      "trainer/Zf2 Param Norm                63.0374\n",
      "trainer/Z Expert Predictions Mean   1074.21\n",
      "trainer/Z Expert Predictions Std     126.874\n",
      "trainer/Z Expert Predictions Max    1255.24\n",
      "trainer/Z Expert Predictions Min     744.071\n",
      "trainer/Z Policy Predictions Mean    549.357\n",
      "trainer/Z Policy Predictions Std     351.275\n",
      "trainer/Z Policy Predictions Max    1178.38\n",
      "trainer/Z Policy Predictions Min     -99.4814\n",
      "trainer/Z Expert Targets Mean       1048.34\n",
      "trainer/Z Expert Targets Std         125.054\n",
      "trainer/Z Expert Targets Max        1226.51\n",
      "trainer/Z Expert Targets Min         736.881\n",
      "trainer/Z Policy Targets Mean        549.339\n",
      "trainer/Z Policy Targets Std         347.626\n",
      "trainer/Z Policy Targets Max        1159.78\n",
      "trainer/Z Policy Targets Min         -80.6875\n",
      "trainer/Log Pis Mean                  20.0704\n",
      "trainer/Log Pis Std                    5.67259\n",
      "trainer/Policy mu Mean                 1.10638\n",
      "trainer/Policy mu Std                  1.75153\n",
      "trainer/Policy log std Mean           -2.58457\n",
      "trainer/Policy log std Std             1.12803\n",
      "trainer/Alpha                          0.0391461\n",
      "trainer/Alpha Loss                    -0.00275557\n",
      "exploration/num steps total        32424\n",
      "exploration/num paths total          577\n",
      "evaluation/num steps total         68444\n",
      "evaluation/num paths total           260\n",
      "evaluation/path length Mean          209.3\n",
      "evaluation/path length Std             8.68389\n",
      "evaluation/path length Max           229\n",
      "evaluation/path length Min           201\n",
      "evaluation/Rewards Mean                3.65817\n",
      "evaluation/Rewards Std                 2.00873\n",
      "evaluation/Rewards Max                 7.59064\n",
      "evaluation/Rewards Min                 0.138236\n",
      "evaluation/Returns Mean              765.655\n",
      "evaluation/Returns Std                32.6718\n",
      "evaluation/Returns Max               842.897\n",
      "evaluation/Returns Min               746.027\n",
      "evaluation/Estimation Bias Mean      831.883\n",
      "evaluation/Estimation Bias Std       321.716\n",
      "evaluation/EB/Q_True Mean             29.2778\n",
      "evaluation/EB/Q_True Std              89.7629\n",
      "evaluation/EB/Q_Pred Mean            861.16\n",
      "evaluation/EB/Q_Pred Std             315.253\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           765.655\n",
      "evaluation/Actions Mean                0.468986\n",
      "evaluation/Actions Std                 0.615608\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999987\n",
      "time/backward_policy (s)               1.7663\n",
      "time/backward_zf1 (s)                  1.86579\n",
      "time/backward_zf2 (s)                  1.82053\n",
      "time/data sampling (s)                 0.214893\n",
      "time/data storing (s)                  0.0137694\n",
      "time/evaluation sampling (s)           0.353294\n",
      "time/exploration sampling (s)          0.18643\n",
      "time/logging (s)                       0.00351665\n",
      "time/preback_alpha (s)                 0.940009\n",
      "time/preback_policy (s)                1.03625\n",
      "time/preback_start (s)                 0.115339\n",
      "time/preback_zf (s)                    5.02008\n",
      "time/saving (s)                        0.00501108\n",
      "time/training (s)                      2.17846\n",
      "time/epoch (s)                        15.5197\n",
      "time/total (s)                       421.993\n",
      "Epoch                                 25\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:17:46.160791 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 26 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 37000\n",
      "trainer/ZF1 Loss                      96.2575\n",
      "trainer/ZF2 Loss                      93.1293\n",
      "trainer/ZF Expert Reward              21.8822\n",
      "trainer/ZF Policy Reward              -5.30092\n",
      "trainer/ZF CHI2 Term                 141.197\n",
      "trainer/Policy Loss                 -586.58\n",
      "trainer/Bias Loss                    278.925\n",
      "trainer/Bias Value                    17.3618\n",
      "trainer/Policy Grad Norm             164.905\n",
      "trainer/Policy Param Norm             25.7947\n",
      "trainer/Zf1 Grad Norm               3404.88\n",
      "trainer/Zf1 Param Norm                63.8177\n",
      "trainer/Zf2 Grad Norm               2991.98\n",
      "trainer/Zf2 Param Norm                63.4315\n",
      "trainer/Z Expert Predictions Mean   1061.57\n",
      "trainer/Z Expert Predictions Std     136.769\n",
      "trainer/Z Expert Predictions Max    1259.77\n",
      "trainer/Z Expert Predictions Min     661.205\n",
      "trainer/Z Policy Predictions Mean    566.754\n",
      "trainer/Z Policy Predictions Std     350.552\n",
      "trainer/Z Policy Predictions Max    1179.07\n",
      "trainer/Z Policy Predictions Min     -28.2479\n",
      "trainer/Z Expert Targets Mean       1039.69\n",
      "trainer/Z Expert Targets Std         133.261\n",
      "trainer/Z Expert Targets Max        1231.11\n",
      "trainer/Z Expert Targets Min         657.862\n",
      "trainer/Z Policy Targets Mean        572.055\n",
      "trainer/Z Policy Targets Std         350.562\n",
      "trainer/Z Policy Targets Max        1174.02\n",
      "trainer/Z Policy Targets Min         -24.7603\n",
      "trainer/Log Pis Mean                  19.5154\n",
      "trainer/Log Pis Std                    6.452\n",
      "trainer/Policy mu Mean                 1.20463\n",
      "trainer/Policy mu Std                  1.79048\n",
      "trainer/Policy log std Mean           -2.46195\n",
      "trainer/Policy log std Std             1.13904\n",
      "trainer/Alpha                          0.0387148\n",
      "trainer/Alpha Loss                     0.0187605\n",
      "exploration/num steps total        34819\n",
      "exploration/num paths total          583\n",
      "evaluation/num steps total         70479\n",
      "evaluation/num paths total           270\n",
      "evaluation/path length Mean          203.5\n",
      "evaluation/path length Std             8.20061\n",
      "evaluation/path length Max           214\n",
      "evaluation/path length Min           190\n",
      "evaluation/Rewards Mean                3.622\n",
      "evaluation/Rewards Std                 1.96313\n",
      "evaluation/Rewards Max                 6.94032\n",
      "evaluation/Rewards Min                 0.141756\n",
      "evaluation/Returns Mean              737.077\n",
      "evaluation/Returns Std                29.5209\n",
      "evaluation/Returns Max               779.309\n",
      "evaluation/Returns Min               679.985\n",
      "evaluation/Estimation Bias Mean      834.027\n",
      "evaluation/Estimation Bias Std       372.451\n",
      "evaluation/EB/Q_True Mean             26.9615\n",
      "evaluation/EB/Q_True Std              84.3424\n",
      "evaluation/EB/Q_Pred Mean            860.989\n",
      "evaluation/EB/Q_Pred Std             369.953\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           737.077\n",
      "evaluation/Actions Mean                0.475783\n",
      "evaluation/Actions Std                 0.60754\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999847\n",
      "time/backward_policy (s)               1.84852\n",
      "time/backward_zf1 (s)                  2.00227\n",
      "time/backward_zf2 (s)                  1.93689\n",
      "time/data sampling (s)                 0.225637\n",
      "time/data storing (s)                  0.01377\n",
      "time/evaluation sampling (s)           0.363282\n",
      "time/exploration sampling (s)          0.198203\n",
      "time/logging (s)                       0.00343114\n",
      "time/preback_alpha (s)                 0.988022\n",
      "time/preback_policy (s)                1.10085\n",
      "time/preback_start (s)                 0.116846\n",
      "time/preback_zf (s)                    5.1375\n",
      "time/saving (s)                        0.00467345\n",
      "time/training (s)                      2.15573\n",
      "time/epoch (s)                        16.0956\n",
      "time/total (s)                       438.107\n",
      "Epoch                                 26\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:18:02.385067 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 27 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 38000\n",
      "trainer/ZF1 Loss                      96.395\n",
      "trainer/ZF2 Loss                     131.68\n",
      "trainer/ZF Expert Reward              17.6617\n",
      "trainer/ZF Policy Reward              -7.97213\n",
      "trainer/ZF CHI2 Term                 159.654\n",
      "trainer/Policy Loss                 -530.466\n",
      "trainer/Bias Loss                    238.785\n",
      "trainer/Bias Value                    17.4439\n",
      "trainer/Policy Grad Norm             112.856\n",
      "trainer/Policy Param Norm             25.9171\n",
      "trainer/Zf1 Grad Norm               4038.02\n",
      "trainer/Zf1 Param Norm                64.2858\n",
      "trainer/Zf2 Grad Norm               4749.33\n",
      "trainer/Zf2 Param Norm                63.8511\n",
      "trainer/Z Expert Predictions Mean   1072\n",
      "trainer/Z Expert Predictions Std     153.299\n",
      "trainer/Z Expert Predictions Max    1277.64\n",
      "trainer/Z Expert Predictions Min     692.877\n",
      "trainer/Z Policy Predictions Mean    512.811\n",
      "trainer/Z Policy Predictions Std     350.121\n",
      "trainer/Z Policy Predictions Max    1206.36\n",
      "trainer/Z Policy Predictions Min     -69.6851\n",
      "trainer/Z Expert Targets Mean       1054.34\n",
      "trainer/Z Expert Targets Std         152.201\n",
      "trainer/Z Expert Targets Max        1262.06\n",
      "trainer/Z Expert Targets Min         670.287\n",
      "trainer/Z Policy Targets Mean        520.783\n",
      "trainer/Z Policy Targets Std         349.502\n",
      "trainer/Z Policy Targets Max        1189.16\n",
      "trainer/Z Policy Targets Min         -70.6695\n",
      "trainer/Log Pis Mean                  20.1842\n",
      "trainer/Log Pis Std                    6.38804\n",
      "trainer/Policy mu Mean                 1.2801\n",
      "trainer/Policy mu Std                  1.81227\n",
      "trainer/Policy log std Mean           -2.45107\n",
      "trainer/Policy log std Std             1.17634\n",
      "trainer/Alpha                          0.0394509\n",
      "trainer/Alpha Loss                    -0.00726502\n",
      "exploration/num steps total        34819\n",
      "exploration/num paths total          583\n",
      "evaluation/num steps total         74730\n",
      "evaluation/num paths total           280\n",
      "evaluation/path length Mean          425.1\n",
      "evaluation/path length Std           130.279\n",
      "evaluation/path length Max           632\n",
      "evaluation/path length Min           273\n",
      "evaluation/Rewards Mean                3.43464\n",
      "evaluation/Rewards Std                 1.46813\n",
      "evaluation/Rewards Max                 6.94405\n",
      "evaluation/Rewards Min                 0.118013\n",
      "evaluation/Returns Mean             1460.06\n",
      "evaluation/Returns Std               406.93\n",
      "evaluation/Returns Max              2337.91\n",
      "evaluation/Returns Min               974.793\n",
      "evaluation/Estimation Bias Mean      640.515\n",
      "evaluation/Estimation Bias Std       347.699\n",
      "evaluation/EB/Q_True Mean             49.0521\n",
      "evaluation/EB/Q_True Std             122.52\n",
      "evaluation/EB/Q_Pred Mean            689.567\n",
      "evaluation/EB/Q_Pred Std             343.137\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1460.06\n",
      "evaluation/Actions Mean                0.449218\n",
      "evaluation/Actions Std                 0.615727\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999894\n",
      "time/backward_policy (s)               1.74853\n",
      "time/backward_zf1 (s)                  1.86131\n",
      "time/backward_zf2 (s)                  1.79513\n",
      "time/data sampling (s)                 0.220942\n",
      "time/data storing (s)                  0.0135372\n",
      "time/evaluation sampling (s)           0.967645\n",
      "time/exploration sampling (s)          0.188454\n",
      "time/logging (s)                       0.00689704\n",
      "time/preback_alpha (s)                 0.912089\n",
      "time/preback_policy (s)                1.00248\n",
      "time/preback_start (s)                 0.114612\n",
      "time/preback_zf (s)                    5.0538\n",
      "time/saving (s)                        0.00586146\n",
      "time/training (s)                      2.27149\n",
      "time/epoch (s)                        16.1628\n",
      "time/total (s)                       454.29\n",
      "Epoch                                 27\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:18:18.869556 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 28 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 39000\n",
      "trainer/ZF1 Loss                      29.5782\n",
      "trainer/ZF2 Loss                      32.3266\n",
      "trainer/ZF Expert Reward              17.437\n",
      "trainer/ZF Policy Reward              -7.614\n",
      "trainer/ZF CHI2 Term                  76.1921\n",
      "trainer/Policy Loss                 -533.862\n",
      "trainer/Bias Loss                    254.262\n",
      "trainer/Bias Value                    17.5257\n",
      "trainer/Policy Grad Norm             149.05\n",
      "trainer/Policy Param Norm             26.0506\n",
      "trainer/Zf1 Grad Norm               3515.57\n",
      "trainer/Zf1 Param Norm                64.8421\n",
      "trainer/Zf2 Grad Norm               3259.84\n",
      "trainer/Zf2 Param Norm                64.4007\n",
      "trainer/Z Expert Predictions Mean   1056.71\n",
      "trainer/Z Expert Predictions Std     175.78\n",
      "trainer/Z Expert Predictions Max    1314.76\n",
      "trainer/Z Expert Predictions Min     400.943\n",
      "trainer/Z Policy Predictions Mean    507.279\n",
      "trainer/Z Policy Predictions Std     359.376\n",
      "trainer/Z Policy Predictions Max    1221.41\n",
      "trainer/Z Policy Predictions Min     -55.8036\n",
      "trainer/Z Expert Targets Mean       1039.27\n",
      "trainer/Z Expert Targets Std         173.144\n",
      "trainer/Z Expert Targets Max        1289.84\n",
      "trainer/Z Expert Targets Min         356.109\n",
      "trainer/Z Policy Targets Mean        514.893\n",
      "trainer/Z Policy Targets Std         356.768\n",
      "trainer/Z Policy Targets Max        1222.83\n",
      "trainer/Z Policy Targets Min         -53.8165\n",
      "trainer/Log Pis Mean                  20.3927\n",
      "trainer/Log Pis Std                    6.61821\n",
      "trainer/Policy mu Mean                 1.32084\n",
      "trainer/Policy mu Std                  1.79514\n",
      "trainer/Policy log std Mean           -2.4638\n",
      "trainer/Policy log std Std             1.1505\n",
      "trainer/Alpha                          0.0405611\n",
      "trainer/Alpha Loss                    -0.0159266\n",
      "exploration/num steps total        35474\n",
      "exploration/num paths total          584\n",
      "evaluation/num steps total         78600\n",
      "evaluation/num paths total           290\n",
      "evaluation/path length Mean          387\n",
      "evaluation/path length Std           153.261\n",
      "evaluation/path length Max           661\n",
      "evaluation/path length Min           237\n",
      "evaluation/Rewards Mean                3.34972\n",
      "evaluation/Rewards Std                 1.4889\n",
      "evaluation/Rewards Max                 7.54758\n",
      "evaluation/Rewards Min                 0.0479605\n",
      "evaluation/Returns Mean             1296.34\n",
      "evaluation/Returns Std               578.469\n",
      "evaluation/Returns Max              2353.97\n",
      "evaluation/Returns Min               703.001\n",
      "evaluation/Estimation Bias Mean      645.679\n",
      "evaluation/Estimation Bias Std       324.633\n",
      "evaluation/EB/Q_True Mean             54.6259\n",
      "evaluation/EB/Q_True Std             123.734\n",
      "evaluation/EB/Q_Pred Mean            700.305\n",
      "evaluation/EB/Q_Pred Std             320.521\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1296.34\n",
      "evaluation/Actions Mean                0.4765\n",
      "evaluation/Actions Std                 0.60038\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999986\n",
      "time/backward_policy (s)               1.74239\n",
      "time/backward_zf1 (s)                  1.89499\n",
      "time/backward_zf2 (s)                  1.81156\n",
      "time/data sampling (s)                 0.230071\n",
      "time/data storing (s)                  0.0138818\n",
      "time/evaluation sampling (s)           1.02469\n",
      "time/exploration sampling (s)          0.192192\n",
      "time/logging (s)                       0.00522596\n",
      "time/preback_alpha (s)                 0.917565\n",
      "time/preback_policy (s)                1.00414\n",
      "time/preback_start (s)                 0.118345\n",
      "time/preback_zf (s)                    5.08484\n",
      "time/saving (s)                        0.00503625\n",
      "time/training (s)                      2.36401\n",
      "time/epoch (s)                        16.4089\n",
      "time/total (s)                       470.726\n",
      "Epoch                                 28\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:18:35.549592 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 29 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 40000\n",
      "trainer/ZF1 Loss                      41.5366\n",
      "trainer/ZF2 Loss                      28.6134\n",
      "trainer/ZF Expert Reward              21.8194\n",
      "trainer/ZF Policy Reward              -4.2896\n",
      "trainer/ZF CHI2 Term                  79.4277\n",
      "trainer/Policy Loss                 -533.608\n",
      "trainer/Bias Loss                    269.152\n",
      "trainer/Bias Value                    17.6076\n",
      "trainer/Policy Grad Norm             124.153\n",
      "trainer/Policy Param Norm             26.1814\n",
      "trainer/Zf1 Grad Norm               4227.62\n",
      "trainer/Zf1 Param Norm                65.3962\n",
      "trainer/Zf2 Grad Norm               3011.56\n",
      "trainer/Zf2 Param Norm                64.9872\n",
      "trainer/Z Expert Predictions Mean   1067.69\n",
      "trainer/Z Expert Predictions Std     167.024\n",
      "trainer/Z Expert Predictions Max    1341.01\n",
      "trainer/Z Expert Predictions Min     555.797\n",
      "trainer/Z Policy Predictions Mean    511.84\n",
      "trainer/Z Policy Predictions Std     353.231\n",
      "trainer/Z Policy Predictions Max    1279.78\n",
      "trainer/Z Policy Predictions Min     -75.8909\n",
      "trainer/Z Expert Targets Mean       1045.87\n",
      "trainer/Z Expert Targets Std         167.014\n",
      "trainer/Z Expert Targets Max        1316.99\n",
      "trainer/Z Expert Targets Min         471.761\n",
      "trainer/Z Policy Targets Mean        516.13\n",
      "trainer/Z Policy Targets Std         351.374\n",
      "trainer/Z Policy Targets Max        1260.4\n",
      "trainer/Z Policy Targets Min         -72.8658\n",
      "trainer/Log Pis Mean                  18.428\n",
      "trainer/Log Pis Std                    6.10613\n",
      "trainer/Policy mu Mean                 1.09215\n",
      "trainer/Policy mu Std                  1.68562\n",
      "trainer/Policy log std Mean           -2.48122\n",
      "trainer/Policy log std Std             1.12229\n",
      "trainer/Alpha                          0.0402205\n",
      "trainer/Alpha Loss                     0.063228\n",
      "exploration/num steps total        36420\n",
      "exploration/num paths total          587\n",
      "evaluation/num steps total         81737\n",
      "evaluation/num paths total           300\n",
      "evaluation/path length Mean          313.7\n",
      "evaluation/path length Std           125.018\n",
      "evaluation/path length Max           519\n",
      "evaluation/path length Min           204\n",
      "evaluation/Rewards Mean                2.72449\n",
      "evaluation/Rewards Std                 1.44611\n",
      "evaluation/Rewards Max                 7.08902\n",
      "evaluation/Rewards Min                 0.0121298\n",
      "evaluation/Returns Mean              854.672\n",
      "evaluation/Returns Std               476.399\n",
      "evaluation/Returns Max              1714.92\n",
      "evaluation/Returns Min               483.267\n",
      "evaluation/Estimation Bias Mean      603.297\n",
      "evaluation/Estimation Bias Std       354.995\n",
      "evaluation/EB/Q_True Mean             34.0745\n",
      "evaluation/EB/Q_True Std              82.688\n",
      "evaluation/EB/Q_Pred Mean            637.371\n",
      "evaluation/EB/Q_Pred Std             345.855\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           854.672\n",
      "evaluation/Actions Mean                0.433547\n",
      "evaluation/Actions Std                 0.598374\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999968\n",
      "time/backward_policy (s)               1.78914\n",
      "time/backward_zf1 (s)                  1.93139\n",
      "time/backward_zf2 (s)                  1.85623\n",
      "time/data sampling (s)                 0.249524\n",
      "time/data storing (s)                  0.0140347\n",
      "time/evaluation sampling (s)           1.02185\n",
      "time/exploration sampling (s)          0.198029\n",
      "time/logging (s)                       0.00457582\n",
      "time/preback_alpha (s)                 0.953684\n",
      "time/preback_policy (s)                1.04865\n",
      "time/preback_start (s)                 0.12339\n",
      "time/preback_zf (s)                    5.10589\n",
      "time/saving (s)                        0.0158956\n",
      "time/training (s)                      2.30148\n",
      "time/epoch (s)                        16.6138\n",
      "time/total (s)                       487.357\n",
      "Epoch                                 29\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:18:52.609246 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 30 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 41000\n",
      "trainer/ZF1 Loss                      58.5153\n",
      "trainer/ZF2 Loss                      46.2013\n",
      "trainer/ZF Expert Reward              24.5463\n",
      "trainer/ZF Policy Reward              -3.66251\n",
      "trainer/ZF CHI2 Term                  99.8758\n",
      "trainer/Policy Loss                 -577.292\n",
      "trainer/Bias Loss                    363.273\n",
      "trainer/Bias Value                    17.6873\n",
      "trainer/Policy Grad Norm             159.405\n",
      "trainer/Policy Param Norm             26.3208\n",
      "trainer/Zf1 Grad Norm               3394.34\n",
      "trainer/Zf1 Param Norm                65.9282\n",
      "trainer/Zf2 Grad Norm               3109.97\n",
      "trainer/Zf2 Param Norm                65.5408\n",
      "trainer/Z Expert Predictions Mean   1108.29\n",
      "trainer/Z Expert Predictions Std     163.474\n",
      "trainer/Z Expert Predictions Max    1366.65\n",
      "trainer/Z Expert Predictions Min     402.878\n",
      "trainer/Z Policy Predictions Mean    549.514\n",
      "trainer/Z Policy Predictions Std     365.948\n",
      "trainer/Z Policy Predictions Max    1320.77\n",
      "trainer/Z Policy Predictions Min     -71.1776\n",
      "trainer/Z Expert Targets Mean       1083.75\n",
      "trainer/Z Expert Targets Std         165.022\n",
      "trainer/Z Expert Targets Max        1343.49\n",
      "trainer/Z Expert Targets Min         374.557\n",
      "trainer/Z Policy Targets Mean        553.176\n",
      "trainer/Z Policy Targets Std         364.192\n",
      "trainer/Z Policy Targets Max        1315.46\n",
      "trainer/Z Policy Targets Min         -59.0331\n",
      "trainer/Log Pis Mean                  19.5037\n",
      "trainer/Log Pis Std                    7.00673\n",
      "trainer/Policy mu Mean                 1.17588\n",
      "trainer/Policy mu Std                  1.77931\n",
      "trainer/Policy log std Mean           -2.48061\n",
      "trainer/Policy log std Std             1.16985\n",
      "trainer/Alpha                          0.0400489\n",
      "trainer/Alpha Loss                     0.0198756\n",
      "exploration/num steps total        37944\n",
      "exploration/num paths total          590\n",
      "evaluation/num steps total         86825\n",
      "evaluation/num paths total           310\n",
      "evaluation/path length Mean          508.8\n",
      "evaluation/path length Std           149.879\n",
      "evaluation/path length Max           893\n",
      "evaluation/path length Min           298\n",
      "evaluation/Rewards Mean                3.53549\n",
      "evaluation/Rewards Std                 1.3638\n",
      "evaluation/Rewards Max                 6.60155\n",
      "evaluation/Rewards Min                 0.0464742\n",
      "evaluation/Returns Mean             1798.86\n",
      "evaluation/Returns Std               484.615\n",
      "evaluation/Returns Max              2951.47\n",
      "evaluation/Returns Min              1115.81\n",
      "evaluation/Estimation Bias Mean      629.56\n",
      "evaluation/Estimation Bias Std       316.831\n",
      "evaluation/EB/Q_True Mean             50.8328\n",
      "evaluation/EB/Q_True Std             119.458\n",
      "evaluation/EB/Q_Pred Mean            680.393\n",
      "evaluation/EB/Q_Pred Std             315.073\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1798.86\n",
      "evaluation/Actions Mean                0.486088\n",
      "evaluation/Actions Std                 0.614854\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.77562\n",
      "time/backward_zf1 (s)                  1.91226\n",
      "time/backward_zf2 (s)                  1.82456\n",
      "time/data sampling (s)                 0.247022\n",
      "time/data storing (s)                  0.0139418\n",
      "time/evaluation sampling (s)           1.48827\n",
      "time/exploration sampling (s)          0.204297\n",
      "time/logging (s)                       0.0076737\n",
      "time/preback_alpha (s)                 0.931772\n",
      "time/preback_policy (s)                1.00722\n",
      "time/preback_start (s)                 0.124014\n",
      "time/preback_zf (s)                    5.1194\n",
      "time/saving (s)                        0.00593857\n",
      "time/training (s)                      2.33594\n",
      "time/epoch (s)                        16.9979\n",
      "time/total (s)                       504.373\n",
      "Epoch                                 30\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:19:09.135254 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 31 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 42000\n",
      "trainer/ZF1 Loss                      39.7688\n",
      "trainer/ZF2 Loss                      34.6239\n",
      "trainer/ZF Expert Reward              29.7205\n",
      "trainer/ZF Policy Reward              -3.50736\n",
      "trainer/ZF CHI2 Term                  90.5383\n",
      "trainer/Policy Loss                 -533.981\n",
      "trainer/Bias Loss                    388.069\n",
      "trainer/Bias Value                    17.7669\n",
      "trainer/Policy Grad Norm             161.179\n",
      "trainer/Policy Param Norm             26.4713\n",
      "trainer/Zf1 Grad Norm               2910.66\n",
      "trainer/Zf1 Param Norm                66.4877\n",
      "trainer/Zf2 Grad Norm               3307.48\n",
      "trainer/Zf2 Param Norm                66.1458\n",
      "trainer/Z Expert Predictions Mean   1097.69\n",
      "trainer/Z Expert Predictions Std     176.844\n",
      "trainer/Z Expert Predictions Max    1379.22\n",
      "trainer/Z Expert Predictions Min     338.733\n",
      "trainer/Z Policy Predictions Mean    523.866\n",
      "trainer/Z Policy Predictions Std     404.081\n",
      "trainer/Z Policy Predictions Max    1342.42\n",
      "trainer/Z Policy Predictions Min     -65.9938\n",
      "trainer/Z Expert Targets Mean       1067.97\n",
      "trainer/Z Expert Targets Std         178.068\n",
      "trainer/Z Expert Targets Max        1355.99\n",
      "trainer/Z Expert Targets Min         306.395\n",
      "trainer/Z Policy Targets Mean        527.373\n",
      "trainer/Z Policy Targets Std         404.828\n",
      "trainer/Z Policy Targets Max        1327.35\n",
      "trainer/Z Policy Targets Min         -52.9741\n",
      "trainer/Log Pis Mean                  20.3174\n",
      "trainer/Log Pis Std                    6.72191\n",
      "trainer/Policy mu Mean                 1.23611\n",
      "trainer/Policy mu Std                  1.80131\n",
      "trainer/Policy log std Mean           -2.50041\n",
      "trainer/Policy log std Std             1.26564\n",
      "trainer/Alpha                          0.0407809\n",
      "trainer/Alpha Loss                    -0.0129418\n",
      "exploration/num steps total        39159\n",
      "exploration/num paths total          592\n",
      "evaluation/num steps total         89221\n",
      "evaluation/num paths total           320\n",
      "evaluation/path length Mean          239.6\n",
      "evaluation/path length Std            48.6132\n",
      "evaluation/path length Max           357\n",
      "evaluation/path length Min           197\n",
      "evaluation/Rewards Mean                3.81878\n",
      "evaluation/Rewards Std                 1.94689\n",
      "evaluation/Rewards Max                 7.05095\n",
      "evaluation/Rewards Min                 0.0940004\n",
      "evaluation/Returns Mean              914.979\n",
      "evaluation/Returns Std               268.842\n",
      "evaluation/Returns Max              1565.95\n",
      "evaluation/Returns Min               683.505\n",
      "evaluation/Estimation Bias Mean      881.222\n",
      "evaluation/Estimation Bias Std       353.643\n",
      "evaluation/EB/Q_True Mean             54.1401\n",
      "evaluation/EB/Q_True Std             136.858\n",
      "evaluation/EB/Q_Pred Mean            935.362\n",
      "evaluation/EB/Q_Pred Std             339.499\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           914.979\n",
      "evaluation/Actions Mean                0.504358\n",
      "evaluation/Actions Std                 0.608708\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999985\n",
      "time/backward_policy (s)               1.82852\n",
      "time/backward_zf1 (s)                  2.0239\n",
      "time/backward_zf2 (s)                  1.91351\n",
      "time/data sampling (s)                 0.249224\n",
      "time/data storing (s)                  0.0149615\n",
      "time/evaluation sampling (s)           0.54789\n",
      "time/exploration sampling (s)          0.211915\n",
      "time/logging (s)                       0.00366933\n",
      "time/preback_alpha (s)                 0.986455\n",
      "time/preback_policy (s)                1.08523\n",
      "time/preback_start (s)                 0.122738\n",
      "time/preback_zf (s)                    5.17329\n",
      "time/saving (s)                        0.0050571\n",
      "time/training (s)                      2.27703\n",
      "time/epoch (s)                        16.4434\n",
      "time/total (s)                       520.845\n",
      "Epoch                                 31\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:19:26.118914 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 32 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 43000\n",
      "trainer/ZF1 Loss                      70.0595\n",
      "trainer/ZF2 Loss                      62.5814\n",
      "trainer/ZF Expert Reward              35.113\n",
      "trainer/ZF Policy Reward              -3.16883\n",
      "trainer/ZF CHI2 Term                 123.89\n",
      "trainer/Policy Loss                 -580.417\n",
      "trainer/Bias Loss                    470.032\n",
      "trainer/Bias Value                    17.8469\n",
      "trainer/Policy Grad Norm             217.972\n",
      "trainer/Policy Param Norm             26.6222\n",
      "trainer/Zf1 Grad Norm               3723.28\n",
      "trainer/Zf1 Param Norm                67.0297\n",
      "trainer/Zf2 Grad Norm               4493.4\n",
      "trainer/Zf2 Param Norm                66.711\n",
      "trainer/Z Expert Predictions Mean   1119.92\n",
      "trainer/Z Expert Predictions Std     162.53\n",
      "trainer/Z Expert Predictions Max    1389.15\n",
      "trainer/Z Expert Predictions Min     402.556\n",
      "trainer/Z Policy Predictions Mean    566.714\n",
      "trainer/Z Policy Predictions Std     399.966\n",
      "trainer/Z Policy Predictions Max    1361.16\n",
      "trainer/Z Policy Predictions Min     -60.2989\n",
      "trainer/Z Expert Targets Mean       1084.81\n",
      "trainer/Z Expert Targets Std         166.781\n",
      "trainer/Z Expert Targets Max        1373.2\n",
      "trainer/Z Expert Targets Min         292.075\n",
      "trainer/Z Policy Targets Mean        569.883\n",
      "trainer/Z Policy Targets Std         398.601\n",
      "trainer/Z Policy Targets Max        1358.81\n",
      "trainer/Z Policy Targets Min         -52.7034\n",
      "trainer/Log Pis Mean                  19.4824\n",
      "trainer/Log Pis Std                    6.08777\n",
      "trainer/Policy mu Mean                 1.18251\n",
      "trainer/Policy mu Std                  1.7253\n",
      "trainer/Policy log std Mean           -2.49211\n",
      "trainer/Policy log std Std             1.18218\n",
      "trainer/Alpha                          0.0441015\n",
      "trainer/Alpha Loss                     0.0228279\n",
      "exploration/num steps total        40952\n",
      "exploration/num paths total          595\n",
      "evaluation/num steps total         91426\n",
      "evaluation/num paths total           330\n",
      "evaluation/path length Mean          220.5\n",
      "evaluation/path length Std            18.2934\n",
      "evaluation/path length Max           265\n",
      "evaluation/path length Min           205\n",
      "evaluation/Rewards Mean                3.67764\n",
      "evaluation/Rewards Std                 1.96449\n",
      "evaluation/Rewards Max                 7.59731\n",
      "evaluation/Rewards Min                 0.0633802\n",
      "evaluation/Returns Mean              810.919\n",
      "evaluation/Returns Std               104.802\n",
      "evaluation/Returns Max              1082.61\n",
      "evaluation/Returns Min               733.552\n",
      "evaluation/Estimation Bias Mean      922.633\n",
      "evaluation/Estimation Bias Std       402.947\n",
      "evaluation/EB/Q_True Mean             37.9188\n",
      "evaluation/EB/Q_True Std             108.989\n",
      "evaluation/EB/Q_Pred Mean            960.552\n",
      "evaluation/EB/Q_Pred Std             394.208\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           810.919\n",
      "evaluation/Actions Mean                0.490649\n",
      "evaluation/Actions Std                 0.613831\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.99946\n",
      "time/backward_zf1 (s)                  2.15586\n",
      "time/backward_zf2 (s)                  2.10109\n",
      "time/data sampling (s)                 0.256248\n",
      "time/data storing (s)                  0.0149146\n",
      "time/evaluation sampling (s)           0.47676\n",
      "time/exploration sampling (s)          0.208912\n",
      "time/logging (s)                       0.00399449\n",
      "time/preback_alpha (s)                 1.04708\n",
      "time/preback_policy (s)                1.19034\n",
      "time/preback_start (s)                 0.124848\n",
      "time/preback_zf (s)                    5.18331\n",
      "time/saving (s)                        0.00480974\n",
      "time/training (s)                      2.1493\n",
      "time/epoch (s)                        16.9169\n",
      "time/total (s)                       537.78\n",
      "Epoch                                 32\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:19:43.009660 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 33 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 44000\n",
      "trainer/ZF1 Loss                      52.348\n",
      "trainer/ZF2 Loss                      64.9355\n",
      "trainer/ZF Expert Reward              24.7178\n",
      "trainer/ZF Policy Reward              -4.13515\n",
      "trainer/ZF CHI2 Term                 109.293\n",
      "trainer/Policy Loss                 -555.483\n",
      "trainer/Bias Loss                    484.55\n",
      "trainer/Bias Value                    17.9239\n",
      "trainer/Policy Grad Norm             268.188\n",
      "trainer/Policy Param Norm             26.7787\n",
      "trainer/Zf1 Grad Norm               4609.57\n",
      "trainer/Zf1 Param Norm                67.4886\n",
      "trainer/Zf2 Grad Norm               3862.15\n",
      "trainer/Zf2 Param Norm                67.1604\n",
      "trainer/Z Expert Predictions Mean   1109.7\n",
      "trainer/Z Expert Predictions Std     158.618\n",
      "trainer/Z Expert Predictions Max    1409.09\n",
      "trainer/Z Expert Predictions Min     128.785\n",
      "trainer/Z Policy Predictions Mean    542.294\n",
      "trainer/Z Policy Predictions Std     411.369\n",
      "trainer/Z Policy Predictions Max    1370.31\n",
      "trainer/Z Policy Predictions Min    -133.605\n",
      "trainer/Z Expert Targets Mean       1084.98\n",
      "trainer/Z Expert Targets Std         162.733\n",
      "trainer/Z Expert Targets Max        1402.16\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        546.429\n",
      "trainer/Z Policy Targets Std         410.325\n",
      "trainer/Z Policy Targets Max        1371.75\n",
      "trainer/Z Policy Targets Min         -96.1945\n",
      "trainer/Log Pis Mean                  22.018\n",
      "trainer/Log Pis Std                    6.22565\n",
      "trainer/Policy mu Mean                 1.44924\n",
      "trainer/Policy mu Std                  1.8797\n",
      "trainer/Policy log std Mean           -2.5159\n",
      "trainer/Policy log std Std             1.2981\n",
      "trainer/Alpha                          0.046039\n",
      "trainer/Alpha Loss                    -0.0928934\n",
      "exploration/num steps total        41884\n",
      "exploration/num paths total          598\n",
      "evaluation/num steps total         95576\n",
      "evaluation/num paths total           340\n",
      "evaluation/path length Mean          415\n",
      "evaluation/path length Std           108.444\n",
      "evaluation/path length Max           630\n",
      "evaluation/path length Min           242\n",
      "evaluation/Rewards Mean                3.90542\n",
      "evaluation/Rewards Std                 1.50859\n",
      "evaluation/Rewards Max                 7.32675\n",
      "evaluation/Rewards Min                 0.108935\n",
      "evaluation/Returns Mean             1620.75\n",
      "evaluation/Returns Std               493.794\n",
      "evaluation/Returns Max              2800.01\n",
      "evaluation/Returns Min               914.209\n",
      "evaluation/Estimation Bias Mean      744.726\n",
      "evaluation/Estimation Bias Std       372.868\n",
      "evaluation/EB/Q_True Mean             48.1965\n",
      "evaluation/EB/Q_True Std             122.527\n",
      "evaluation/EB/Q_Pred Mean            792.923\n",
      "evaluation/EB/Q_Pred Std             364.825\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1620.75\n",
      "evaluation/Actions Mean                0.522889\n",
      "evaluation/Actions Std                 0.606479\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.86717\n",
      "time/backward_zf1 (s)                  2.04215\n",
      "time/backward_zf2 (s)                  1.9869\n",
      "time/data sampling (s)                 0.238042\n",
      "time/data storing (s)                  0.0139482\n",
      "time/evaluation sampling (s)           0.947841\n",
      "time/exploration sampling (s)          0.198592\n",
      "time/logging (s)                       0.00594158\n",
      "time/preback_alpha (s)                 1.01652\n",
      "time/preback_policy (s)                1.14153\n",
      "time/preback_start (s)                 0.120932\n",
      "time/preback_zf (s)                    5.13448\n",
      "time/saving (s)                        0.00492922\n",
      "time/training (s)                      2.10766\n",
      "time/epoch (s)                        16.8266\n",
      "time/total (s)                       554.624\n",
      "Epoch                                 33\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:19:59.193254 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 34 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 45000\n",
      "trainer/ZF1 Loss                      48.8269\n",
      "trainer/ZF2 Loss                      50.2752\n",
      "trainer/ZF Expert Reward              25.3008\n",
      "trainer/ZF Policy Reward              -8.38851\n",
      "trainer/ZF CHI2 Term                 105.254\n",
      "trainer/Policy Loss                 -573.073\n",
      "trainer/Bias Loss                    410.598\n",
      "trainer/Bias Value                    18.0005\n",
      "trainer/Policy Grad Norm             228.57\n",
      "trainer/Policy Param Norm             26.9411\n",
      "trainer/Zf1 Grad Norm               7141.94\n",
      "trainer/Zf1 Param Norm                67.9566\n",
      "trainer/Zf2 Grad Norm               7657.47\n",
      "trainer/Zf2 Param Norm                67.6309\n",
      "trainer/Z Expert Predictions Mean   1103.25\n",
      "trainer/Z Expert Predictions Std     153.167\n",
      "trainer/Z Expert Predictions Max    1407.29\n",
      "trainer/Z Expert Predictions Min     193.016\n",
      "trainer/Z Policy Predictions Mean    555.222\n",
      "trainer/Z Policy Predictions Std     424.522\n",
      "trainer/Z Policy Predictions Max    1409.06\n",
      "trainer/Z Policy Predictions Min     -61.8204\n",
      "trainer/Z Expert Targets Mean       1077.95\n",
      "trainer/Z Expert Targets Std         163.688\n",
      "trainer/Z Expert Targets Max        1391.55\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        563.611\n",
      "trainer/Z Policy Targets Std         423.006\n",
      "trainer/Z Policy Targets Max        1416.34\n",
      "trainer/Z Policy Targets Min         -62.1774\n",
      "trainer/Log Pis Mean                  22.2364\n",
      "trainer/Log Pis Std                    6.12788\n",
      "trainer/Policy mu Mean                 1.2546\n",
      "trainer/Policy mu Std                  1.92984\n",
      "trainer/Policy log std Mean           -2.70724\n",
      "trainer/Policy log std Std             1.26037\n",
      "trainer/Alpha                          0.0507278\n",
      "trainer/Alpha Loss                    -0.113417\n",
      "exploration/num steps total        42783\n",
      "exploration/num paths total          601\n",
      "evaluation/num steps total         97842\n",
      "evaluation/num paths total           350\n",
      "evaluation/path length Mean          226.6\n",
      "evaluation/path length Std            56.8651\n",
      "evaluation/path length Max           299\n",
      "evaluation/path length Min           151\n",
      "evaluation/Rewards Mean                3.62234\n",
      "evaluation/Rewards Std                 1.90053\n",
      "evaluation/Rewards Max                 7.38925\n",
      "evaluation/Rewards Min                 0.1031\n",
      "evaluation/Returns Mean              820.823\n",
      "evaluation/Returns Std               259.058\n",
      "evaluation/Returns Max              1190.93\n",
      "evaluation/Returns Min               472.293\n",
      "evaluation/Estimation Bias Mean      855.797\n",
      "evaluation/Estimation Bias Std       416.082\n",
      "evaluation/EB/Q_True Mean             29.581\n",
      "evaluation/EB/Q_True Std              82.9152\n",
      "evaluation/EB/Q_Pred Mean            885.378\n",
      "evaluation/EB/Q_Pred Std             422.647\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           820.823\n",
      "evaluation/Actions Mean                0.475253\n",
      "evaluation/Actions Std                 0.600867\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.80323\n",
      "time/backward_zf1 (s)                  1.92586\n",
      "time/backward_zf2 (s)                  1.86971\n",
      "time/data sampling (s)                 0.239134\n",
      "time/data storing (s)                  0.0141232\n",
      "time/evaluation sampling (s)           0.475317\n",
      "time/exploration sampling (s)          0.19711\n",
      "time/logging (s)                       0.00374673\n",
      "time/preback_alpha (s)                 0.942525\n",
      "time/preback_policy (s)                1.03411\n",
      "time/preback_start (s)                 0.122468\n",
      "time/preback_zf (s)                    5.10982\n",
      "time/saving (s)                        0.00471179\n",
      "time/training (s)                      2.3732\n",
      "time/epoch (s)                        16.1151\n",
      "time/total (s)                       570.757\n",
      "Epoch                                 34\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:20:15.922465 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 35 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  46000\n",
      "trainer/ZF1 Loss                      429.126\n",
      "trainer/ZF2 Loss                      432.097\n",
      "trainer/ZF Expert Reward               28.1828\n",
      "trainer/ZF Policy Reward               -4.24403\n",
      "trainer/ZF CHI2 Term                  482.472\n",
      "trainer/Policy Loss                  -613.823\n",
      "trainer/Bias Loss                    3918.32\n",
      "trainer/Bias Value                     18.0767\n",
      "trainer/Policy Grad Norm              295.99\n",
      "trainer/Policy Param Norm              27.073\n",
      "trainer/Zf1 Grad Norm                7779.92\n",
      "trainer/Zf1 Param Norm                 68.3963\n",
      "trainer/Zf2 Grad Norm                9815.44\n",
      "trainer/Zf2 Param Norm                 68.0692\n",
      "trainer/Z Expert Predictions Mean    1095.5\n",
      "trainer/Z Expert Predictions Std      143.699\n",
      "trainer/Z Expert Predictions Max     1432.72\n",
      "trainer/Z Expert Predictions Min      591.283\n",
      "trainer/Z Policy Predictions Mean     596.785\n",
      "trainer/Z Policy Predictions Std      452.607\n",
      "trainer/Z Policy Predictions Max     1401.7\n",
      "trainer/Z Policy Predictions Min      -57.5162\n",
      "trainer/Z Expert Targets Mean        1067.32\n",
      "trainer/Z Expert Targets Std          174.281\n",
      "trainer/Z Expert Targets Max         1430.9\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         601.029\n",
      "trainer/Z Policy Targets Std          453.054\n",
      "trainer/Z Policy Targets Max         1397.65\n",
      "trainer/Z Policy Targets Min          -55.2617\n",
      "trainer/Log Pis Mean                   19.6304\n",
      "trainer/Log Pis Std                     5.7043\n",
      "trainer/Policy mu Mean                  1.21459\n",
      "trainer/Policy mu Std                   1.83005\n",
      "trainer/Policy log std Mean            -2.52211\n",
      "trainer/Policy log std Std              1.26553\n",
      "trainer/Alpha                           0.0540574\n",
      "trainer/Alpha Loss                      0.0199813\n",
      "exploration/num steps total         43114\n",
      "exploration/num paths total           602\n",
      "evaluation/num steps total         105898\n",
      "evaluation/num paths total            362\n",
      "evaluation/path length Mean           671.333\n",
      "evaluation/path length Std            262.947\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            305\n",
      "evaluation/Rewards Mean                 3.68391\n",
      "evaluation/Rewards Std                  1.38245\n",
      "evaluation/Rewards Max                  6.73794\n",
      "evaluation/Rewards Min                 -1.22008\n",
      "evaluation/Returns Mean              2473.13\n",
      "evaluation/Returns Std               1053.82\n",
      "evaluation/Returns Max               4247.78\n",
      "evaluation/Returns Min               1106.12\n",
      "evaluation/Estimation Bias Mean       618.138\n",
      "evaluation/Estimation Bias Std        361.784\n",
      "evaluation/EB/Q_True Mean              40.2185\n",
      "evaluation/EB/Q_True Std              117.515\n",
      "evaluation/EB/Q_Pred Mean             658.356\n",
      "evaluation/EB/Q_Pred Std              359.721\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2473.13\n",
      "evaluation/Actions Mean                 0.438287\n",
      "evaluation/Actions Std                  0.625861\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.7115\n",
      "time/backward_zf1 (s)                   1.84338\n",
      "time/backward_zf2 (s)                   1.76737\n",
      "time/data sampling (s)                  0.230012\n",
      "time/data storing (s)                   0.0140274\n",
      "time/evaluation sampling (s)            1.50539\n",
      "time/exploration sampling (s)           0.195609\n",
      "time/logging (s)                        0.0100695\n",
      "time/preback_alpha (s)                  0.900876\n",
      "time/preback_policy (s)                 0.979409\n",
      "time/preback_start (s)                  0.118417\n",
      "time/preback_zf (s)                     5.04737\n",
      "time/saving (s)                         0.00754251\n",
      "time/training (s)                       2.34018\n",
      "time/epoch (s)                         16.6712\n",
      "time/total (s)                        587.448\n",
      "Epoch                                  35\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:20:33.546497 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 36 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  47000\n",
      "trainer/ZF1 Loss                       26.6017\n",
      "trainer/ZF2 Loss                       37.7733\n",
      "trainer/ZF Expert Reward               20.094\n",
      "trainer/ZF Policy Reward               -5.24628\n",
      "trainer/ZF CHI2 Term                   77.0118\n",
      "trainer/Policy Loss                  -542.636\n",
      "trainer/Bias Loss                     233.55\n",
      "trainer/Bias Value                     18.1511\n",
      "trainer/Policy Grad Norm              285.874\n",
      "trainer/Policy Param Norm              27.1981\n",
      "trainer/Zf1 Grad Norm                4516.23\n",
      "trainer/Zf1 Param Norm                 68.8503\n",
      "trainer/Zf2 Grad Norm                3156.48\n",
      "trainer/Zf2 Param Norm                 68.551\n",
      "trainer/Z Expert Predictions Mean    1091.35\n",
      "trainer/Z Expert Predictions Std      158.982\n",
      "trainer/Z Expert Predictions Max     1456.04\n",
      "trainer/Z Expert Predictions Min      621.087\n",
      "trainer/Z Policy Predictions Mean     522.873\n",
      "trainer/Z Policy Predictions Std      460.961\n",
      "trainer/Z Policy Predictions Max     1406.87\n",
      "trainer/Z Policy Predictions Min      -95.8319\n",
      "trainer/Z Expert Targets Mean        1071.25\n",
      "trainer/Z Expert Targets Std          158.484\n",
      "trainer/Z Expert Targets Max         1439.26\n",
      "trainer/Z Expert Targets Min          626.475\n",
      "trainer/Z Policy Targets Mean         528.119\n",
      "trainer/Z Policy Targets Std          457.993\n",
      "trainer/Z Policy Targets Max         1418.15\n",
      "trainer/Z Policy Targets Min         -108.483\n",
      "trainer/Log Pis Mean                   19.6809\n",
      "trainer/Log Pis Std                     5.71147\n",
      "trainer/Policy mu Mean                  1.20132\n",
      "trainer/Policy mu Std                   1.83767\n",
      "trainer/Policy log std Mean            -2.42886\n",
      "trainer/Policy log std Std              1.27422\n",
      "trainer/Alpha                           0.0548096\n",
      "trainer/Alpha Loss                      0.0174908\n",
      "exploration/num steps total         43558\n",
      "exploration/num paths total           603\n",
      "evaluation/num steps total         110987\n",
      "evaluation/num paths total            372\n",
      "evaluation/path length Mean           508.9\n",
      "evaluation/path length Std            147.28\n",
      "evaluation/path length Max            708\n",
      "evaluation/path length Min            332\n",
      "evaluation/Rewards Mean                 3.88957\n",
      "evaluation/Rewards Std                  1.3621\n",
      "evaluation/Rewards Max                  6.26705\n",
      "evaluation/Rewards Min                  0.171449\n",
      "evaluation/Returns Mean              1979.4\n",
      "evaluation/Returns Std                577.492\n",
      "evaluation/Returns Max               2935.21\n",
      "evaluation/Returns Min               1300.34\n",
      "evaluation/Estimation Bias Mean       636.332\n",
      "evaluation/Estimation Bias Std        384.564\n",
      "evaluation/EB/Q_True Mean              40.4688\n",
      "evaluation/EB/Q_True Std              109.473\n",
      "evaluation/EB/Q_Pred Mean             676.801\n",
      "evaluation/EB/Q_Pred Std              385.924\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1979.4\n",
      "evaluation/Actions Mean                 0.47226\n",
      "evaluation/Actions Std                  0.621491\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.89917\n",
      "time/backward_zf1 (s)                   2.12701\n",
      "time/backward_zf2 (s)                   2.035\n",
      "time/data sampling (s)                  0.263329\n",
      "time/data storing (s)                   0.0142726\n",
      "time/evaluation sampling (s)            1.2483\n",
      "time/exploration sampling (s)           0.203024\n",
      "time/logging (s)                        0.00656142\n",
      "time/preback_alpha (s)                  0.997346\n",
      "time/preback_policy (s)                 1.11045\n",
      "time/preback_start (s)                  0.12614\n",
      "time/preback_zf (s)                     5.19466\n",
      "time/saving (s)                         0.00477753\n",
      "time/training (s)                       2.32431\n",
      "time/epoch (s)                         17.5543\n",
      "time/total (s)                        605.02\n",
      "Epoch                                  36\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:20:50.562706 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 37 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  48000\n",
      "trainer/ZF1 Loss                       51.6923\n",
      "trainer/ZF2 Loss                       54.5505\n",
      "trainer/ZF Expert Reward               24.9744\n",
      "trainer/ZF Policy Reward               -5.18787\n",
      "trainer/ZF CHI2 Term                  102.205\n",
      "trainer/Policy Loss                  -577.638\n",
      "trainer/Bias Loss                     275.914\n",
      "trainer/Bias Value                     18.2264\n",
      "trainer/Policy Grad Norm              208.556\n",
      "trainer/Policy Param Norm              27.3268\n",
      "trainer/Zf1 Grad Norm                4482.69\n",
      "trainer/Zf1 Param Norm                 69.2947\n",
      "trainer/Zf2 Grad Norm                2894.03\n",
      "trainer/Zf2 Param Norm                 68.9844\n",
      "trainer/Z Expert Predictions Mean    1074.71\n",
      "trainer/Z Expert Predictions Std      166.518\n",
      "trainer/Z Expert Predictions Max     1455.11\n",
      "trainer/Z Expert Predictions Min      497.271\n",
      "trainer/Z Policy Predictions Mean     568.006\n",
      "trainer/Z Policy Predictions Std      454.74\n",
      "trainer/Z Policy Predictions Max     1424.88\n",
      "trainer/Z Policy Predictions Min      -62.2635\n",
      "trainer/Z Expert Targets Mean        1049.73\n",
      "trainer/Z Expert Targets Std          168.214\n",
      "trainer/Z Expert Targets Max         1442.88\n",
      "trainer/Z Expert Targets Min          523.145\n",
      "trainer/Z Policy Targets Mean         573.194\n",
      "trainer/Z Policy Targets Std          449.797\n",
      "trainer/Z Policy Targets Max         1420.57\n",
      "trainer/Z Policy Targets Min          -57.1325\n",
      "trainer/Log Pis Mean                   19.1125\n",
      "trainer/Log Pis Std                     5.27966\n",
      "trainer/Policy mu Mean                  1.15034\n",
      "trainer/Policy mu Std                   1.7032\n",
      "trainer/Policy log std Mean            -2.48067\n",
      "trainer/Policy log std Std              1.17127\n",
      "trainer/Alpha                           0.0512002\n",
      "trainer/Alpha Loss                      0.0454448\n",
      "exploration/num steps total         44245\n",
      "exploration/num paths total           605\n",
      "evaluation/num steps total         115181\n",
      "evaluation/num paths total            382\n",
      "evaluation/path length Mean           419.4\n",
      "evaluation/path length Std            134.318\n",
      "evaluation/path length Max            731\n",
      "evaluation/path length Min            295\n",
      "evaluation/Rewards Mean                 3.31978\n",
      "evaluation/Rewards Std                  1.33001\n",
      "evaluation/Rewards Max                  6.3364\n",
      "evaluation/Rewards Min                  0.170041\n",
      "evaluation/Returns Mean              1392.32\n",
      "evaluation/Returns Std                466.387\n",
      "evaluation/Returns Max               2444.4\n",
      "evaluation/Returns Min               1025.01\n",
      "evaluation/Estimation Bias Mean       576.927\n",
      "evaluation/Estimation Bias Std        468.625\n",
      "evaluation/EB/Q_True Mean              52.2122\n",
      "evaluation/EB/Q_True Std              119.226\n",
      "evaluation/EB/Q_Pred Mean             629.139\n",
      "evaluation/EB/Q_Pred Std              474.845\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1392.32\n",
      "evaluation/Actions Mean                 0.386497\n",
      "evaluation/Actions Std                  0.643358\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999965\n",
      "time/backward_policy (s)                1.84912\n",
      "time/backward_zf1 (s)                   1.99168\n",
      "time/backward_zf2 (s)                   1.92034\n",
      "time/data sampling (s)                  0.244816\n",
      "time/data storing (s)                   0.014812\n",
      "time/evaluation sampling (s)            1.12137\n",
      "time/exploration sampling (s)           0.200683\n",
      "time/logging (s)                        0.00565196\n",
      "time/preback_alpha (s)                  0.949851\n",
      "time/preback_policy (s)                 1.06003\n",
      "time/preback_start (s)                  0.125223\n",
      "time/preback_zf (s)                     5.10733\n",
      "time/saving (s)                         0.00493415\n",
      "time/training (s)                       2.34743\n",
      "time/epoch (s)                         16.9433\n",
      "time/total (s)                        621.989\n",
      "Epoch                                  37\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:21:07.324200 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 38 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  49000\n",
      "trainer/ZF1 Loss                      350.467\n",
      "trainer/ZF2 Loss                      359.909\n",
      "trainer/ZF Expert Reward               36.0132\n",
      "trainer/ZF Policy Reward                4.74347\n",
      "trainer/ZF CHI2 Term                  406.329\n",
      "trainer/Policy Loss                  -583.605\n",
      "trainer/Bias Loss                    3439.29\n",
      "trainer/Bias Value                     18.3001\n",
      "trainer/Policy Grad Norm              197.302\n",
      "trainer/Policy Param Norm              27.4428\n",
      "trainer/Zf1 Grad Norm               10139.2\n",
      "trainer/Zf1 Param Norm                 69.7249\n",
      "trainer/Zf2 Grad Norm                9491.88\n",
      "trainer/Zf2 Param Norm                 69.4352\n",
      "trainer/Z Expert Predictions Mean    1103.1\n",
      "trainer/Z Expert Predictions Std      167.111\n",
      "trainer/Z Expert Predictions Max     1434.16\n",
      "trainer/Z Expert Predictions Min      296.244\n",
      "trainer/Z Policy Predictions Mean     577.939\n",
      "trainer/Z Policy Predictions Std      462.936\n",
      "trainer/Z Policy Predictions Max     1409.33\n",
      "trainer/Z Policy Predictions Min      -92.2654\n",
      "trainer/Z Expert Targets Mean        1067.09\n",
      "trainer/Z Expert Targets Std          195.57\n",
      "trainer/Z Expert Targets Max         1431.47\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         573.196\n",
      "trainer/Z Policy Targets Std          457.844\n",
      "trainer/Z Policy Targets Max         1408.99\n",
      "trainer/Z Policy Targets Min          -82.9356\n",
      "trainer/Log Pis Mean                   20.0715\n",
      "trainer/Log Pis Std                     5.79753\n",
      "trainer/Policy mu Mean                  1.06158\n",
      "trainer/Policy mu Std                   1.7265\n",
      "trainer/Policy log std Mean            -2.736\n",
      "trainer/Policy log std Std              1.18621\n",
      "trainer/Alpha                           0.0472528\n",
      "trainer/Alpha Loss                     -0.00338006\n",
      "exploration/num steps total         44245\n",
      "exploration/num paths total           605\n",
      "evaluation/num steps total         119556\n",
      "evaluation/num paths total            392\n",
      "evaluation/path length Mean           437.5\n",
      "evaluation/path length Std            142.575\n",
      "evaluation/path length Max            744\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 3.7444\n",
      "evaluation/Rewards Std                  1.37025\n",
      "evaluation/Rewards Max                  6.7292\n",
      "evaluation/Rewards Min                  0.130778\n",
      "evaluation/Returns Mean              1638.17\n",
      "evaluation/Returns Std                560.506\n",
      "evaluation/Returns Max               2829.21\n",
      "evaluation/Returns Min               1230.62\n",
      "evaluation/Estimation Bias Mean       608.538\n",
      "evaluation/Estimation Bias Std        475.782\n",
      "evaluation/EB/Q_True Mean              58.6547\n",
      "evaluation/EB/Q_True Std              135.155\n",
      "evaluation/EB/Q_Pred Mean             667.193\n",
      "evaluation/EB/Q_Pred Std              474.924\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1638.17\n",
      "evaluation/Actions Mean                 0.404897\n",
      "evaluation/Actions Std                  0.638653\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999991\n",
      "time/backward_policy (s)                1.8659\n",
      "time/backward_zf1 (s)                   1.97034\n",
      "time/backward_zf2 (s)                   1.92743\n",
      "time/data sampling (s)                  0.220919\n",
      "time/data storing (s)                   0.0141505\n",
      "time/evaluation sampling (s)            1.0687\n",
      "time/exploration sampling (s)           0.195057\n",
      "time/logging (s)                        0.00614015\n",
      "time/preback_alpha (s)                  0.993335\n",
      "time/preback_policy (s)                 1.11211\n",
      "time/preback_start (s)                  0.119013\n",
      "time/preback_zf (s)                     5.05712\n",
      "time/saving (s)                         0.00528846\n",
      "time/training (s)                       2.14195\n",
      "time/epoch (s)                         16.6974\n",
      "time/total (s)                        638.706\n",
      "Epoch                                  38\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:21:24.022793 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 39 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  50000\n",
      "trainer/ZF1 Loss                       68.2894\n",
      "trainer/ZF2 Loss                       57.4052\n",
      "trainer/ZF Expert Reward               23.4871\n",
      "trainer/ZF Policy Reward               -6.05209\n",
      "trainer/ZF CHI2 Term                  111.877\n",
      "trainer/Policy Loss                  -568.406\n",
      "trainer/Bias Loss                     229.7\n",
      "trainer/Bias Value                     18.3762\n",
      "trainer/Policy Grad Norm              228.132\n",
      "trainer/Policy Param Norm              27.547\n",
      "trainer/Zf1 Grad Norm                4814.96\n",
      "trainer/Zf1 Param Norm                 70.1706\n",
      "trainer/Zf2 Grad Norm                5759.7\n",
      "trainer/Zf2 Param Norm                 69.9398\n",
      "trainer/Z Expert Predictions Mean    1109.2\n",
      "trainer/Z Expert Predictions Std      183.937\n",
      "trainer/Z Expert Predictions Max     1478.89\n",
      "trainer/Z Expert Predictions Min      666.147\n",
      "trainer/Z Policy Predictions Mean     550.817\n",
      "trainer/Z Policy Predictions Std      477.953\n",
      "trainer/Z Policy Predictions Max     1442.03\n",
      "trainer/Z Policy Predictions Min      -95.7457\n",
      "trainer/Z Expert Targets Mean        1085.72\n",
      "trainer/Z Expert Targets Std          185.626\n",
      "trainer/Z Expert Targets Max         1464.92\n",
      "trainer/Z Expert Targets Min          664.542\n",
      "trainer/Z Policy Targets Mean         556.869\n",
      "trainer/Z Policy Targets Std          476.38\n",
      "trainer/Z Policy Targets Max         1426.69\n",
      "trainer/Z Policy Targets Min          -86.7134\n",
      "trainer/Log Pis Mean                   19.6878\n",
      "trainer/Log Pis Std                     5.89604\n",
      "trainer/Policy mu Mean                  1.06205\n",
      "trainer/Policy mu Std                   1.68541\n",
      "trainer/Policy log std Mean            -2.66575\n",
      "trainer/Policy log std Std              1.18604\n",
      "trainer/Alpha                           0.0436211\n",
      "trainer/Alpha Loss                      0.0136184\n",
      "exploration/num steps total         46237\n",
      "exploration/num paths total           607\n",
      "evaluation/num steps total         124159\n",
      "evaluation/num paths total            402\n",
      "evaluation/path length Mean           460.3\n",
      "evaluation/path length Std             85.7159\n",
      "evaluation/path length Max            604\n",
      "evaluation/path length Min            321\n",
      "evaluation/Rewards Mean                 3.81513\n",
      "evaluation/Rewards Std                  1.35368\n",
      "evaluation/Rewards Max                  7.54178\n",
      "evaluation/Rewards Min                  0.128923\n",
      "evaluation/Returns Mean              1756.1\n",
      "evaluation/Returns Std                401.743\n",
      "evaluation/Returns Max               2437.95\n",
      "evaluation/Returns Min               1110.52\n",
      "evaluation/Estimation Bias Mean       620.572\n",
      "evaluation/Estimation Bias Std        454.423\n",
      "evaluation/EB/Q_True Mean              47.2335\n",
      "evaluation/EB/Q_True Std              127.108\n",
      "evaluation/EB/Q_Pred Mean             667.806\n",
      "evaluation/EB/Q_Pred Std              450.953\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1756.1\n",
      "evaluation/Actions Mean                 0.408756\n",
      "evaluation/Actions Std                  0.627922\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.85872\n",
      "time/backward_zf1 (s)                   1.98275\n",
      "time/backward_zf2 (s)                   1.9329\n",
      "time/data sampling (s)                  0.243829\n",
      "time/data storing (s)                   0.0143211\n",
      "time/evaluation sampling (s)            0.923347\n",
      "time/exploration sampling (s)           0.199673\n",
      "time/logging (s)                        0.00639377\n",
      "time/preback_alpha (s)                  0.959374\n",
      "time/preback_policy (s)                 1.07783\n",
      "time/preback_start (s)                  0.121255\n",
      "time/preback_zf (s)                     5.09206\n",
      "time/saving (s)                         0.00540173\n",
      "time/training (s)                       2.21574\n",
      "time/epoch (s)                         16.6336\n",
      "time/total (s)                        655.359\n",
      "Epoch                                  39\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:21:41.174834 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 40 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  51000\n",
      "trainer/ZF1 Loss                       49.2616\n",
      "trainer/ZF2 Loss                       57.9916\n",
      "trainer/ZF Expert Reward               20.9837\n",
      "trainer/ZF Policy Reward              -10.2588\n",
      "trainer/ZF CHI2 Term                  103.825\n",
      "trainer/Policy Loss                  -588.047\n",
      "trainer/Bias Loss                     247.659\n",
      "trainer/Bias Value                     18.4502\n",
      "trainer/Policy Grad Norm              268.373\n",
      "trainer/Policy Param Norm              27.6368\n",
      "trainer/Zf1 Grad Norm                5150.48\n",
      "trainer/Zf1 Param Norm                 70.6564\n",
      "trainer/Zf2 Grad Norm                5456.96\n",
      "trainer/Zf2 Param Norm                 70.4506\n",
      "trainer/Z Expert Predictions Mean    1128.21\n",
      "trainer/Z Expert Predictions Std      165.992\n",
      "trainer/Z Expert Predictions Max     1461.74\n",
      "trainer/Z Expert Predictions Min      692.087\n",
      "trainer/Z Policy Predictions Mean     560.66\n",
      "trainer/Z Policy Predictions Std      477.027\n",
      "trainer/Z Policy Predictions Max     1435.65\n",
      "trainer/Z Policy Predictions Min     -108.327\n",
      "trainer/Z Expert Targets Mean        1107.22\n",
      "trainer/Z Expert Targets Std          167.955\n",
      "trainer/Z Expert Targets Max         1461.35\n",
      "trainer/Z Expert Targets Min          681.769\n",
      "trainer/Z Policy Targets Mean         570.919\n",
      "trainer/Z Policy Targets Std          477.557\n",
      "trainer/Z Policy Targets Max         1450.01\n",
      "trainer/Z Policy Targets Min         -113.501\n",
      "trainer/Log Pis Mean                   19.1479\n",
      "trainer/Log Pis Std                     5.5825\n",
      "trainer/Policy mu Mean                  0.960922\n",
      "trainer/Policy mu Std                   1.58919\n",
      "trainer/Policy log std Mean            -2.80132\n",
      "trainer/Policy log std Std              1.15307\n",
      "trainer/Alpha                           0.0407246\n",
      "trainer/Alpha Loss                      0.0347032\n",
      "exploration/num steps total         46816\n",
      "exploration/num paths total           608\n",
      "evaluation/num steps total         127849\n",
      "evaluation/num paths total            412\n",
      "evaluation/path length Mean           369\n",
      "evaluation/path length Std             26.8216\n",
      "evaluation/path length Max            407\n",
      "evaluation/path length Min            328\n",
      "evaluation/Rewards Mean                 4.17878\n",
      "evaluation/Rewards Std                  1.67639\n",
      "evaluation/Rewards Max                  7.11061\n",
      "evaluation/Rewards Min                  0.136949\n",
      "evaluation/Returns Mean              1541.97\n",
      "evaluation/Returns Std                140.727\n",
      "evaluation/Returns Max               1745.59\n",
      "evaluation/Returns Min               1320.44\n",
      "evaluation/Estimation Bias Mean       856.649\n",
      "evaluation/Estimation Bias Std        396.99\n",
      "evaluation/EB/Q_True Mean              40.1684\n",
      "evaluation/EB/Q_True Std              119.74\n",
      "evaluation/EB/Q_Pred Mean             896.817\n",
      "evaluation/EB/Q_Pred Std              382.912\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1541.97\n",
      "evaluation/Actions Mean                 0.466592\n",
      "evaluation/Actions Std                  0.610055\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999939\n",
      "time/backward_policy (s)                1.99622\n",
      "time/backward_zf1 (s)                   2.116\n",
      "time/backward_zf2 (s)                   2.06992\n",
      "time/data sampling (s)                  0.261194\n",
      "time/data storing (s)                   0.014587\n",
      "time/evaluation sampling (s)            0.673228\n",
      "time/exploration sampling (s)           0.198438\n",
      "time/logging (s)                        0.010945\n",
      "time/preback_alpha (s)                  1.03418\n",
      "time/preback_policy (s)                 1.19182\n",
      "time/preback_start (s)                  0.124906\n",
      "time/preback_zf (s)                     5.1658\n",
      "time/saving (s)                         0.0231316\n",
      "time/training (s)                       2.20848\n",
      "time/epoch (s)                         17.0888\n",
      "time/total (s)                        672.469\n",
      "Epoch                                  40\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:21:56.891949 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 41 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  52000\n",
      "trainer/ZF1 Loss                       71.5304\n",
      "trainer/ZF2 Loss                       59.479\n",
      "trainer/ZF Expert Reward               28.9114\n",
      "trainer/ZF Policy Reward               -2.85826\n",
      "trainer/ZF CHI2 Term                  116.861\n",
      "trainer/Policy Loss                  -527.407\n",
      "trainer/Bias Loss                     313.891\n",
      "trainer/Bias Value                     18.524\n",
      "trainer/Policy Grad Norm              156.598\n",
      "trainer/Policy Param Norm              27.74\n",
      "trainer/Zf1 Grad Norm                6140.5\n",
      "trainer/Zf1 Param Norm                 71.183\n",
      "trainer/Zf2 Grad Norm                7476.25\n",
      "trainer/Zf2 Param Norm                 70.9962\n",
      "trainer/Z Expert Predictions Mean    1146.89\n",
      "trainer/Z Expert Predictions Std      176.058\n",
      "trainer/Z Expert Predictions Max     1500.88\n",
      "trainer/Z Expert Predictions Min      237.548\n",
      "trainer/Z Policy Predictions Mean     510.844\n",
      "trainer/Z Policy Predictions Std      469.274\n",
      "trainer/Z Policy Predictions Max     1457.2\n",
      "trainer/Z Policy Predictions Min     -110.726\n",
      "trainer/Z Expert Targets Mean        1117.97\n",
      "trainer/Z Expert Targets Std          174.345\n",
      "trainer/Z Expert Targets Max         1496.38\n",
      "trainer/Z Expert Targets Min          240.9\n",
      "trainer/Z Policy Targets Mean         513.703\n",
      "trainer/Z Policy Targets Std          465.663\n",
      "trainer/Z Policy Targets Max         1479.89\n",
      "trainer/Z Policy Targets Min          -96.4849\n",
      "trainer/Log Pis Mean                   19.7846\n",
      "trainer/Log Pis Std                     5.42043\n",
      "trainer/Policy mu Mean                  1.09899\n",
      "trainer/Policy mu Std                   1.63068\n",
      "trainer/Policy log std Mean            -2.71769\n",
      "trainer/Policy log std Std              1.10174\n",
      "trainer/Alpha                           0.0384889\n",
      "trainer/Alpha Loss                      0.00828939\n",
      "exploration/num steps total         49736\n",
      "exploration/num paths total           613\n",
      "evaluation/num steps total         130901\n",
      "evaluation/num paths total            422\n",
      "evaluation/path length Mean           305.2\n",
      "evaluation/path length Std             23.7689\n",
      "evaluation/path length Max            356\n",
      "evaluation/path length Min            255\n",
      "evaluation/Rewards Mean                 4.20752\n",
      "evaluation/Rewards Std                  1.89176\n",
      "evaluation/Rewards Max                  7.49061\n",
      "evaluation/Rewards Min                  0.153089\n",
      "evaluation/Returns Mean              1284.14\n",
      "evaluation/Returns Std                127.572\n",
      "evaluation/Returns Max               1553.14\n",
      "evaluation/Returns Min               1009.05\n",
      "evaluation/Estimation Bias Mean       983.09\n",
      "evaluation/Estimation Bias Std        378.181\n",
      "evaluation/EB/Q_True Mean              42.1699\n",
      "evaluation/EB/Q_True Std              122.67\n",
      "evaluation/EB/Q_Pred Mean            1025.26\n",
      "evaluation/EB/Q_Pred Std              366.579\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1284.14\n",
      "evaluation/Actions Mean                 0.476667\n",
      "evaluation/Actions Std                  0.616074\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999951\n",
      "time/backward_policy (s)                1.66516\n",
      "time/backward_zf1 (s)                   1.80645\n",
      "time/backward_zf2 (s)                   1.72472\n",
      "time/data sampling (s)                  0.238153\n",
      "time/data storing (s)                   0.0137861\n",
      "time/evaluation sampling (s)            0.590281\n",
      "time/exploration sampling (s)           0.199554\n",
      "time/logging (s)                        0.00469663\n",
      "time/preback_alpha (s)                  0.859008\n",
      "time/preback_policy (s)                 0.927685\n",
      "time/preback_start (s)                  0.118847\n",
      "time/preback_zf (s)                     5.02378\n",
      "time/saving (s)                         0.00519388\n",
      "time/training (s)                       2.46522\n",
      "time/epoch (s)                         15.6425\n",
      "time/total (s)                        688.134\n",
      "Epoch                                  41\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:22:13.101250 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 42 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  53000\n",
      "trainer/ZF1 Loss                       73.2691\n",
      "trainer/ZF2 Loss                       75.4509\n",
      "trainer/ZF Expert Reward               26.2265\n",
      "trainer/ZF Policy Reward               -6.69761\n",
      "trainer/ZF CHI2 Term                  127.612\n",
      "trainer/Policy Loss                  -570.212\n",
      "trainer/Bias Loss                     485.684\n",
      "trainer/Bias Value                     18.5986\n",
      "trainer/Policy Grad Norm              199.001\n",
      "trainer/Policy Param Norm              27.8709\n",
      "trainer/Zf1 Grad Norm                7204.63\n",
      "trainer/Zf1 Param Norm                 71.7309\n",
      "trainer/Zf2 Grad Norm               10599.5\n",
      "trainer/Zf2 Param Norm                 71.5721\n",
      "trainer/Z Expert Predictions Mean    1162.95\n",
      "trainer/Z Expert Predictions Std      176.241\n",
      "trainer/Z Expert Predictions Max     1513.59\n",
      "trainer/Z Expert Predictions Min      547.889\n",
      "trainer/Z Policy Predictions Mean     546.539\n",
      "trainer/Z Policy Predictions Std      522.439\n",
      "trainer/Z Policy Predictions Max     1500.33\n",
      "trainer/Z Policy Predictions Min     -122.997\n",
      "trainer/Z Expert Targets Mean        1136.72\n",
      "trainer/Z Expert Targets Std          178.892\n",
      "trainer/Z Expert Targets Max         1512.2\n",
      "trainer/Z Expert Targets Min          475.727\n",
      "trainer/Z Policy Targets Mean         553.236\n",
      "trainer/Z Policy Targets Std          525.936\n",
      "trainer/Z Policy Targets Max         1495.37\n",
      "trainer/Z Policy Targets Min         -125.716\n",
      "trainer/Log Pis Mean                   20.5334\n",
      "trainer/Log Pis Std                     5.79221\n",
      "trainer/Policy mu Mean                  1.07572\n",
      "trainer/Policy mu Std                   1.66581\n",
      "trainer/Policy log std Mean            -2.82272\n",
      "trainer/Policy log std Std              1.1965\n",
      "trainer/Alpha                           0.0376415\n",
      "trainer/Alpha Loss                     -0.0200761\n",
      "exploration/num steps total         50684\n",
      "exploration/num paths total           614\n",
      "evaluation/num steps total         133455\n",
      "evaluation/num paths total            432\n",
      "evaluation/path length Mean           255.4\n",
      "evaluation/path length Std              4.24735\n",
      "evaluation/path length Max            264\n",
      "evaluation/path length Min            250\n",
      "evaluation/Rewards Mean                 3.92528\n",
      "evaluation/Rewards Std                  1.94608\n",
      "evaluation/Rewards Max                  7.48542\n",
      "evaluation/Rewards Min                  0.13572\n",
      "evaluation/Returns Mean              1002.52\n",
      "evaluation/Returns Std                 13.5866\n",
      "evaluation/Returns Max               1032.79\n",
      "evaluation/Returns Min                983.346\n",
      "evaluation/Estimation Bias Mean      1036.85\n",
      "evaluation/Estimation Bias Std        393.836\n",
      "evaluation/EB/Q_True Mean              30.9977\n",
      "evaluation/EB/Q_True Std               97.1164\n",
      "evaluation/EB/Q_Pred Mean            1067.85\n",
      "evaluation/EB/Q_Pred Std              389.236\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1002.52\n",
      "evaluation/Actions Mean                 0.472397\n",
      "evaluation/Actions Std                  0.599537\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999932\n",
      "time/backward_policy (s)                1.80097\n",
      "time/backward_zf1 (s)                   1.9369\n",
      "time/backward_zf2 (s)                   1.87811\n",
      "time/data sampling (s)                  0.254458\n",
      "time/data storing (s)                   0.0146516\n",
      "time/evaluation sampling (s)            0.478651\n",
      "time/exploration sampling (s)           0.200367\n",
      "time/logging (s)                        0.00720405\n",
      "time/preback_alpha (s)                  0.953144\n",
      "time/preback_policy (s)                 1.06033\n",
      "time/preback_start (s)                  0.1238\n",
      "time/preback_zf (s)                     5.1205\n",
      "time/saving (s)                         0.00583618\n",
      "time/training (s)                       2.3114\n",
      "time/epoch (s)                         16.1463\n",
      "time/total (s)                        704.3\n",
      "Epoch                                  42\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:22:30.189999 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 43 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  54000\n",
      "trainer/ZF1 Loss                       65.0313\n",
      "trainer/ZF2 Loss                       62.2577\n",
      "trainer/ZF Expert Reward               27.1655\n",
      "trainer/ZF Policy Reward               -2.10976\n",
      "trainer/ZF CHI2 Term                  112.658\n",
      "trainer/Policy Loss                  -595.754\n",
      "trainer/Bias Loss                     330.947\n",
      "trainer/Bias Value                     18.6723\n",
      "trainer/Policy Grad Norm              178.994\n",
      "trainer/Policy Param Norm              27.9961\n",
      "trainer/Zf1 Grad Norm                5625.15\n",
      "trainer/Zf1 Param Norm                 72.2495\n",
      "trainer/Zf2 Grad Norm                5290.44\n",
      "trainer/Zf2 Param Norm                 72.1222\n",
      "trainer/Z Expert Predictions Mean    1179.96\n",
      "trainer/Z Expert Predictions Std      172.513\n",
      "trainer/Z Expert Predictions Max     1538.59\n",
      "trainer/Z Expert Predictions Min      573.058\n",
      "trainer/Z Policy Predictions Mean     575.168\n",
      "trainer/Z Policy Predictions Std      518.746\n",
      "trainer/Z Policy Predictions Max     1497.24\n",
      "trainer/Z Policy Predictions Min     -122.028\n",
      "trainer/Z Expert Targets Mean        1152.8\n",
      "trainer/Z Expert Targets Std          176.512\n",
      "trainer/Z Expert Targets Max         1528.25\n",
      "trainer/Z Expert Targets Min          434.567\n",
      "trainer/Z Policy Targets Mean         577.278\n",
      "trainer/Z Policy Targets Std          515.784\n",
      "trainer/Z Policy Targets Max         1476.57\n",
      "trainer/Z Policy Targets Min         -111.793\n",
      "trainer/Log Pis Mean                   19.9379\n",
      "trainer/Log Pis Std                     4.96115\n",
      "trainer/Policy mu Mean                  1.04116\n",
      "trainer/Policy mu Std                   1.60865\n",
      "trainer/Policy log std Mean            -2.83053\n",
      "trainer/Policy log std Std              1.19688\n",
      "trainer/Alpha                           0.0382521\n",
      "trainer/Alpha Loss                      0.00237724\n",
      "exploration/num steps total         51585\n",
      "exploration/num paths total           617\n",
      "evaluation/num steps total         135922\n",
      "evaluation/num paths total            442\n",
      "evaluation/path length Mean           246.7\n",
      "evaluation/path length Std              7.6948\n",
      "evaluation/path length Max            255\n",
      "evaluation/path length Min            230\n",
      "evaluation/Rewards Mean                 3.92896\n",
      "evaluation/Rewards Std                  2.01649\n",
      "evaluation/Rewards Max                  7.18593\n",
      "evaluation/Rewards Min                  0.134259\n",
      "evaluation/Returns Mean               969.274\n",
      "evaluation/Returns Std                 40.9393\n",
      "evaluation/Returns Max               1008.94\n",
      "evaluation/Returns Min                880.474\n",
      "evaluation/Estimation Bias Mean      1007.97\n",
      "evaluation/Estimation Bias Std        433.158\n",
      "evaluation/EB/Q_True Mean              31.2142\n",
      "evaluation/EB/Q_True Std               97.5696\n",
      "evaluation/EB/Q_Pred Mean            1039.18\n",
      "evaluation/EB/Q_Pred Std              420.527\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            969.274\n",
      "evaluation/Actions Mean                 0.485014\n",
      "evaluation/Actions Std                  0.597319\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.95048\n",
      "time/backward_zf1 (s)                   2.07226\n",
      "time/backward_zf2 (s)                   1.99595\n",
      "time/data sampling (s)                  0.27342\n",
      "time/data storing (s)                   0.01508\n",
      "time/evaluation sampling (s)            0.40067\n",
      "time/exploration sampling (s)           0.205491\n",
      "time/logging (s)                        0.00381051\n",
      "time/preback_alpha (s)                  0.982217\n",
      "time/preback_policy (s)                 1.10749\n",
      "time/preback_start (s)                  0.131262\n",
      "time/preback_zf (s)                     5.30238\n",
      "time/saving (s)                         0.00479341\n",
      "time/training (s)                       2.5638\n",
      "time/epoch (s)                         17.0091\n",
      "time/total (s)                        721.334\n",
      "Epoch                                  43\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:22:46.777249 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 44 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  55000\n",
      "trainer/ZF1 Loss                      105.167\n",
      "trainer/ZF2 Loss                       81.838\n",
      "trainer/ZF Expert Reward               22.1214\n",
      "trainer/ZF Policy Reward               -3.02586\n",
      "trainer/ZF CHI2 Term                  139.243\n",
      "trainer/Policy Loss                  -630.576\n",
      "trainer/Bias Loss                     367.062\n",
      "trainer/Bias Value                     18.7426\n",
      "trainer/Policy Grad Norm              222.066\n",
      "trainer/Policy Param Norm              28.1125\n",
      "trainer/Zf1 Grad Norm                7159.65\n",
      "trainer/Zf1 Param Norm                 72.7528\n",
      "trainer/Zf2 Grad Norm                5493.8\n",
      "trainer/Zf2 Param Norm                 72.6708\n",
      "trainer/Z Expert Predictions Mean    1184.73\n",
      "trainer/Z Expert Predictions Std      178.079\n",
      "trainer/Z Expert Predictions Max     1541.09\n",
      "trainer/Z Expert Predictions Min      159.874\n",
      "trainer/Z Policy Predictions Mean     601.719\n",
      "trainer/Z Policy Predictions Std      527.32\n",
      "trainer/Z Policy Predictions Max     1514.39\n",
      "trainer/Z Policy Predictions Min     -141.789\n",
      "trainer/Z Expert Targets Mean        1162.61\n",
      "trainer/Z Expert Targets Std          183.054\n",
      "trainer/Z Expert Targets Max         1537.8\n",
      "trainer/Z Expert Targets Min          123.769\n",
      "trainer/Z Policy Targets Mean         604.744\n",
      "trainer/Z Policy Targets Std          526.381\n",
      "trainer/Z Policy Targets Max         1512.54\n",
      "trainer/Z Policy Targets Min         -140.676\n",
      "trainer/Log Pis Mean                   20.8012\n",
      "trainer/Log Pis Std                     6.07027\n",
      "trainer/Policy mu Mean                  1.05037\n",
      "trainer/Policy mu Std                   1.74827\n",
      "trainer/Policy log std Mean            -2.83611\n",
      "trainer/Policy log std Std              1.20198\n",
      "trainer/Alpha                           0.0402008\n",
      "trainer/Alpha Loss                     -0.0322065\n",
      "exploration/num steps total         52933\n",
      "exploration/num paths total           621\n",
      "evaluation/num steps total         138460\n",
      "evaluation/num paths total            452\n",
      "evaluation/path length Mean           253.8\n",
      "evaluation/path length Std              1.32665\n",
      "evaluation/path length Max            256\n",
      "evaluation/path length Min            252\n",
      "evaluation/Rewards Mean                 3.90585\n",
      "evaluation/Rewards Std                  1.9353\n",
      "evaluation/Rewards Max                  7.00491\n",
      "evaluation/Rewards Min                  0.138667\n",
      "evaluation/Returns Mean               991.306\n",
      "evaluation/Returns Std                  5.54841\n",
      "evaluation/Returns Max               1003.48\n",
      "evaluation/Returns Min                981.88\n",
      "evaluation/Estimation Bias Mean      1025.17\n",
      "evaluation/Estimation Bias Std        437.347\n",
      "evaluation/EB/Q_True Mean              30.0433\n",
      "evaluation/EB/Q_True Std               95.4831\n",
      "evaluation/EB/Q_Pred Mean            1055.21\n",
      "evaluation/EB/Q_Pred Std              434.912\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            991.306\n",
      "evaluation/Actions Mean                 0.471077\n",
      "evaluation/Actions Std                  0.603228\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.98163\n",
      "time/backward_zf1 (s)                   2.11725\n",
      "time/backward_zf2 (s)                   2.07555\n",
      "time/data sampling (s)                  0.228272\n",
      "time/data storing (s)                   0.0140039\n",
      "time/evaluation sampling (s)            0.391346\n",
      "time/exploration sampling (s)           0.194375\n",
      "time/logging (s)                        0.00393242\n",
      "time/preback_alpha (s)                  1.04793\n",
      "time/preback_policy (s)                 1.22456\n",
      "time/preback_start (s)                  0.11606\n",
      "time/preback_zf (s)                     5.13406\n",
      "time/saving (s)                         0.00476165\n",
      "time/training (s)                       1.98616\n",
      "time/epoch (s)                         16.5199\n",
      "time/total (s)                        737.875\n",
      "Epoch                                  44\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:23:03.660415 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 45 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  56000\n",
      "trainer/ZF1 Loss                       46.7304\n",
      "trainer/ZF2 Loss                       59.4919\n",
      "trainer/ZF Expert Reward               27.667\n",
      "trainer/ZF Policy Reward               -4.81243\n",
      "trainer/ZF CHI2 Term                  106.124\n",
      "trainer/Policy Loss                  -620.51\n",
      "trainer/Bias Loss                     344.449\n",
      "trainer/Bias Value                     18.8109\n",
      "trainer/Policy Grad Norm              169.662\n",
      "trainer/Policy Param Norm              28.2222\n",
      "trainer/Zf1 Grad Norm                5841.76\n",
      "trainer/Zf1 Param Norm                 73.254\n",
      "trainer/Zf2 Grad Norm                4429.58\n",
      "trainer/Zf2 Param Norm                 73.1758\n",
      "trainer/Z Expert Predictions Mean    1211.68\n",
      "trainer/Z Expert Predictions Std      166.278\n",
      "trainer/Z Expert Predictions Max     1555.12\n",
      "trainer/Z Expert Predictions Min      219.981\n",
      "trainer/Z Policy Predictions Mean     600.251\n",
      "trainer/Z Policy Predictions Std      551.299\n",
      "trainer/Z Policy Predictions Max     1526.91\n",
      "trainer/Z Policy Predictions Min     -146.197\n",
      "trainer/Z Expert Targets Mean        1184.01\n",
      "trainer/Z Expert Targets Std          174.265\n",
      "trainer/Z Expert Targets Max         1547.4\n",
      "trainer/Z Expert Targets Min          219.246\n",
      "trainer/Z Policy Targets Mean         605.063\n",
      "trainer/Z Policy Targets Std          550.478\n",
      "trainer/Z Policy Targets Max         1510.94\n",
      "trainer/Z Policy Targets Min         -158.05\n",
      "trainer/Log Pis Mean                   20.7407\n",
      "trainer/Log Pis Std                     5.94242\n",
      "trainer/Policy mu Mean                  1.0336\n",
      "trainer/Policy mu Std                   1.71989\n",
      "trainer/Policy log std Mean            -2.84569\n",
      "trainer/Policy log std Std              1.19228\n",
      "trainer/Alpha                           0.0419667\n",
      "trainer/Alpha Loss                     -0.0310816\n",
      "exploration/num steps total         54568\n",
      "exploration/num paths total           624\n",
      "evaluation/num steps total         143711\n",
      "evaluation/num paths total            462\n",
      "evaluation/path length Mean           525.1\n",
      "evaluation/path length Std            122.058\n",
      "evaluation/path length Max            738\n",
      "evaluation/path length Min            349\n",
      "evaluation/Rewards Mean                 4.46039\n",
      "evaluation/Rewards Std                  1.48963\n",
      "evaluation/Rewards Max                  6.64897\n",
      "evaluation/Rewards Min                  0.137224\n",
      "evaluation/Returns Mean              2342.15\n",
      "evaluation/Returns Std                618.135\n",
      "evaluation/Returns Max               3425.11\n",
      "evaluation/Returns Min               1435.39\n",
      "evaluation/Estimation Bias Mean       900.917\n",
      "evaluation/Estimation Bias Std        410.759\n",
      "evaluation/EB/Q_True Mean              60.0214\n",
      "evaluation/EB/Q_True Std              153.571\n",
      "evaluation/EB/Q_Pred Mean             960.939\n",
      "evaluation/EB/Q_Pred Std              391.13\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2342.15\n",
      "evaluation/Actions Mean                 0.486579\n",
      "evaluation/Actions Std                  0.617536\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999979\n",
      "time/backward_policy (s)                1.86603\n",
      "time/backward_zf1 (s)                   1.97605\n",
      "time/backward_zf2 (s)                   1.9267\n",
      "time/data sampling (s)                  0.232896\n",
      "time/data storing (s)                   0.0148045\n",
      "time/evaluation sampling (s)            1.08867\n",
      "time/exploration sampling (s)           0.199439\n",
      "time/logging (s)                        0.00660375\n",
      "time/preback_alpha (s)                  0.969599\n",
      "time/preback_policy (s)                 1.09247\n",
      "time/preback_start (s)                  0.11855\n",
      "time/preback_zf (s)                     5.10056\n",
      "time/saving (s)                         0.0051785\n",
      "time/training (s)                       2.22096\n",
      "time/epoch (s)                         16.8185\n",
      "time/total (s)                        754.715\n",
      "Epoch                                  45\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:23:20.362959 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 46 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  57000\n",
      "trainer/ZF1 Loss                      130.115\n",
      "trainer/ZF2 Loss                      115.59\n",
      "trainer/ZF Expert Reward               34.8095\n",
      "trainer/ZF Policy Reward               -3.54562\n",
      "trainer/ZF CHI2 Term                  181.183\n",
      "trainer/Policy Loss                  -612.92\n",
      "trainer/Bias Loss                     694.979\n",
      "trainer/Bias Value                     18.8769\n",
      "trainer/Policy Grad Norm              253.612\n",
      "trainer/Policy Param Norm              28.3297\n",
      "trainer/Zf1 Grad Norm                7767.63\n",
      "trainer/Zf1 Param Norm                 73.7379\n",
      "trainer/Zf2 Grad Norm                7840.69\n",
      "trainer/Zf2 Param Norm                 73.6943\n",
      "trainer/Z Expert Predictions Mean    1195.69\n",
      "trainer/Z Expert Predictions Std      182.678\n",
      "trainer/Z Expert Predictions Max     1567.16\n",
      "trainer/Z Expert Predictions Min      189.018\n",
      "trainer/Z Policy Predictions Mean     591.157\n",
      "trainer/Z Policy Predictions Std      534.634\n",
      "trainer/Z Policy Predictions Max     1540.34\n",
      "trainer/Z Policy Predictions Min     -142.7\n",
      "trainer/Z Expert Targets Mean        1160.88\n",
      "trainer/Z Expert Targets Std          187.933\n",
      "trainer/Z Expert Targets Max         1550.39\n",
      "trainer/Z Expert Targets Min          285.523\n",
      "trainer/Z Policy Targets Mean         594.702\n",
      "trainer/Z Policy Targets Std          529.225\n",
      "trainer/Z Policy Targets Max         1522.53\n",
      "trainer/Z Policy Targets Min         -165.156\n",
      "trainer/Log Pis Mean                   20.1768\n",
      "trainer/Log Pis Std                     5.18155\n",
      "trainer/Policy mu Mean                  1.09495\n",
      "trainer/Policy mu Std                   1.6381\n",
      "trainer/Policy log std Mean            -2.76686\n",
      "trainer/Policy log std Std              1.12925\n",
      "trainer/Alpha                           0.0430527\n",
      "trainer/Alpha Loss                     -0.00761043\n",
      "exploration/num steps total         55094\n",
      "exploration/num paths total           626\n",
      "evaluation/num steps total         149220\n",
      "evaluation/num paths total            472\n",
      "evaluation/path length Mean           550.9\n",
      "evaluation/path length Std            179.446\n",
      "evaluation/path length Max            889\n",
      "evaluation/path length Min            332\n",
      "evaluation/Rewards Mean                 4.26055\n",
      "evaluation/Rewards Std                  1.39721\n",
      "evaluation/Rewards Max                  6.97868\n",
      "evaluation/Rewards Min                  0.147586\n",
      "evaluation/Returns Mean              2347.14\n",
      "evaluation/Returns Std                857.562\n",
      "evaluation/Returns Max               4032.12\n",
      "evaluation/Returns Min               1339.21\n",
      "evaluation/Estimation Bias Mean       791.282\n",
      "evaluation/Estimation Bias Std        445.765\n",
      "evaluation/EB/Q_True Mean              68.3809\n",
      "evaluation/EB/Q_True Std              160.399\n",
      "evaluation/EB/Q_Pred Mean             859.663\n",
      "evaluation/EB/Q_Pred Std              435.156\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2347.14\n",
      "evaluation/Actions Mean                 0.48715\n",
      "evaluation/Actions Std                  0.601578\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74154\n",
      "time/backward_zf1 (s)                   1.89717\n",
      "time/backward_zf2 (s)                   1.81801\n",
      "time/data sampling (s)                  0.231337\n",
      "time/data storing (s)                   0.0145298\n",
      "time/evaluation sampling (s)            1.23721\n",
      "time/exploration sampling (s)           0.196088\n",
      "time/logging (s)                        0.00738444\n",
      "time/preback_alpha (s)                  0.895054\n",
      "time/preback_policy (s)                 0.983843\n",
      "time/preback_start (s)                  0.119017\n",
      "time/preback_zf (s)                     5.07665\n",
      "time/saving (s)                         0.00553742\n",
      "time/training (s)                       2.41318\n",
      "time/epoch (s)                         16.6366\n",
      "time/total (s)                        771.373\n",
      "Epoch                                  46\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:23:37.932876 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 47 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  58000\n",
      "trainer/ZF1 Loss                       98.6052\n",
      "trainer/ZF2 Loss                       88.3245\n",
      "trainer/ZF Expert Reward               18.8859\n",
      "trainer/ZF Policy Reward               -6.78341\n",
      "trainer/ZF CHI2 Term                  139.028\n",
      "trainer/Policy Loss                  -659.605\n",
      "trainer/Bias Loss                     353.45\n",
      "trainer/Bias Value                     18.9426\n",
      "trainer/Policy Grad Norm              184.243\n",
      "trainer/Policy Param Norm              28.4474\n",
      "trainer/Zf1 Grad Norm                5947.27\n",
      "trainer/Zf1 Param Norm                 74.2455\n",
      "trainer/Zf2 Grad Norm               10148.6\n",
      "trainer/Zf2 Param Norm                 74.1803\n",
      "trainer/Z Expert Predictions Mean    1196.27\n",
      "trainer/Z Expert Predictions Std      191.501\n",
      "trainer/Z Expert Predictions Max     1568.25\n",
      "trainer/Z Expert Predictions Min      274.456\n",
      "trainer/Z Policy Predictions Mean     633.647\n",
      "trainer/Z Policy Predictions Std      532.304\n",
      "trainer/Z Policy Predictions Max     1528.76\n",
      "trainer/Z Policy Predictions Min     -199.99\n",
      "trainer/Z Expert Targets Mean        1177.38\n",
      "trainer/Z Expert Targets Std          193.676\n",
      "trainer/Z Expert Targets Max         1559.7\n",
      "trainer/Z Expert Targets Min          203.906\n",
      "trainer/Z Policy Targets Mean         640.43\n",
      "trainer/Z Policy Targets Std          531.912\n",
      "trainer/Z Policy Targets Max         1526.8\n",
      "trainer/Z Policy Targets Min         -187.654\n",
      "trainer/Log Pis Mean                   20.0949\n",
      "trainer/Log Pis Std                     5.40935\n",
      "trainer/Policy mu Mean                  1.05036\n",
      "trainer/Policy mu Std                   1.68569\n",
      "trainer/Policy log std Mean            -2.78325\n",
      "trainer/Policy log std Std              1.15598\n",
      "trainer/Alpha                           0.0449583\n",
      "trainer/Alpha Loss                     -0.00426564\n",
      "exploration/num steps total         55094\n",
      "exploration/num paths total           626\n",
      "evaluation/num steps total         157050\n",
      "evaluation/num paths total            483\n",
      "evaluation/path length Mean           711.818\n",
      "evaluation/path length Std            239.286\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            363\n",
      "evaluation/Rewards Mean                 4.47351\n",
      "evaluation/Rewards Std                  1.30392\n",
      "evaluation/Rewards Max                  8.18118\n",
      "evaluation/Rewards Min                  0.159903\n",
      "evaluation/Returns Mean              3184.33\n",
      "evaluation/Returns Std               1177.67\n",
      "evaluation/Returns Max               4675.89\n",
      "evaluation/Returns Min               1453.96\n",
      "evaluation/Estimation Bias Mean       913.159\n",
      "evaluation/Estimation Bias Std        392.498\n",
      "evaluation/EB/Q_True Mean              56.2186\n",
      "evaluation/EB/Q_True Std              150.917\n",
      "evaluation/EB/Q_Pred Mean             969.378\n",
      "evaluation/EB/Q_Pred Std              367.393\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3184.33\n",
      "evaluation/Actions Mean                 0.490143\n",
      "evaluation/Actions Std                  0.610174\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.96297\n",
      "time/backward_zf1 (s)                   2.09335\n",
      "time/backward_zf2 (s)                   2.05296\n",
      "time/data sampling (s)                  0.239535\n",
      "time/data storing (s)                   0.0148556\n",
      "time/evaluation sampling (s)            1.36149\n",
      "time/exploration sampling (s)           0.193024\n",
      "time/logging (s)                        0.00961833\n",
      "time/preback_alpha (s)                  1.04705\n",
      "time/preback_policy (s)                 1.20821\n",
      "time/preback_start (s)                  0.122828\n",
      "time/preback_zf (s)                     5.13554\n",
      "time/saving (s)                         0.0051718\n",
      "time/training (s)                       2.05809\n",
      "time/epoch (s)                         17.5047\n",
      "time/total (s)                        788.899\n",
      "Epoch                                  47\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:23:54.859550 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 48 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  59000\n",
      "trainer/ZF1 Loss                      195.597\n",
      "trainer/ZF2 Loss                      197.069\n",
      "trainer/ZF Expert Reward               18.5684\n",
      "trainer/ZF Policy Reward               -7.13411\n",
      "trainer/ZF CHI2 Term                  241.5\n",
      "trainer/Policy Loss                  -631.249\n",
      "trainer/Bias Loss                     250.858\n",
      "trainer/Bias Value                     19.0091\n",
      "trainer/Policy Grad Norm              199.95\n",
      "trainer/Policy Param Norm              28.5573\n",
      "trainer/Zf1 Grad Norm                9855.84\n",
      "trainer/Zf1 Param Norm                 74.7419\n",
      "trainer/Zf2 Grad Norm               11727.3\n",
      "trainer/Zf2 Param Norm                 74.6345\n",
      "trainer/Z Expert Predictions Mean    1196.55\n",
      "trainer/Z Expert Predictions Std      189.414\n",
      "trainer/Z Expert Predictions Max     1583.38\n",
      "trainer/Z Expert Predictions Min       96.3485\n",
      "trainer/Z Policy Predictions Mean     611.121\n",
      "trainer/Z Policy Predictions Std      546.284\n",
      "trainer/Z Policy Predictions Max     1546.86\n",
      "trainer/Z Policy Predictions Min     -183.052\n",
      "trainer/Z Expert Targets Mean        1177.99\n",
      "trainer/Z Expert Targets Std          192.099\n",
      "trainer/Z Expert Targets Max         1577.35\n",
      "trainer/Z Expert Targets Min           33.4561\n",
      "trainer/Z Policy Targets Mean         618.255\n",
      "trainer/Z Policy Targets Std          546.376\n",
      "trainer/Z Policy Targets Max         1543.78\n",
      "trainer/Z Policy Targets Min         -177.253\n",
      "trainer/Log Pis Mean                   19.6615\n",
      "trainer/Log Pis Std                     5.22457\n",
      "trainer/Policy mu Mean                  1.04042\n",
      "trainer/Policy mu Std                   1.68271\n",
      "trainer/Policy log std Mean            -2.68395\n",
      "trainer/Policy log std Std              1.16676\n",
      "trainer/Alpha                           0.0463543\n",
      "trainer/Alpha Loss                      0.0156923\n",
      "exploration/num steps total         55904\n",
      "exploration/num paths total           628\n",
      "evaluation/num steps total         160916\n",
      "evaluation/num paths total            493\n",
      "evaluation/path length Mean           386.6\n",
      "evaluation/path length Std             76.1238\n",
      "evaluation/path length Max            533\n",
      "evaluation/path length Min            261\n",
      "evaluation/Rewards Mean                 4.34182\n",
      "evaluation/Rewards Std                  1.69253\n",
      "evaluation/Rewards Max                  8.35899\n",
      "evaluation/Rewards Min                  0.148484\n",
      "evaluation/Returns Mean              1678.55\n",
      "evaluation/Returns Std                399.105\n",
      "evaluation/Returns Max               2480.11\n",
      "evaluation/Returns Min               1022.51\n",
      "evaluation/Estimation Bias Mean       984.728\n",
      "evaluation/Estimation Bias Std        409.478\n",
      "evaluation/EB/Q_True Mean              45.8593\n",
      "evaluation/EB/Q_True Std              122.827\n",
      "evaluation/EB/Q_Pred Mean            1030.59\n",
      "evaluation/EB/Q_Pred Std              402.595\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1678.55\n",
      "evaluation/Actions Mean                 0.491073\n",
      "evaluation/Actions Std                  0.608406\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.91841\n",
      "time/backward_zf1 (s)                   2.07018\n",
      "time/backward_zf2 (s)                   2.01934\n",
      "time/data sampling (s)                  0.24169\n",
      "time/data storing (s)                   0.0144219\n",
      "time/evaluation sampling (s)            0.89625\n",
      "time/exploration sampling (s)           0.195982\n",
      "time/logging (s)                        0.00550077\n",
      "time/preback_alpha (s)                  1.01997\n",
      "time/preback_policy (s)                 1.16699\n",
      "time/preback_start (s)                  0.118192\n",
      "time/preback_zf (s)                     5.12328\n",
      "time/saving (s)                         0.00470444\n",
      "time/training (s)                       2.06371\n",
      "time/epoch (s)                         16.8586\n",
      "time/total (s)                        805.775\n",
      "Epoch                                  48\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:24:12.473576 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 49 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  60000\n",
      "trainer/ZF1 Loss                       73.7672\n",
      "trainer/ZF2 Loss                       98.5008\n",
      "trainer/ZF Expert Reward               20.7724\n",
      "trainer/ZF Policy Reward               -0.597414\n",
      "trainer/ZF CHI2 Term                  127.537\n",
      "trainer/Policy Loss                  -662.236\n",
      "trainer/Bias Loss                     355.722\n",
      "trainer/Bias Value                     19.0748\n",
      "trainer/Policy Grad Norm              232.62\n",
      "trainer/Policy Param Norm              28.672\n",
      "trainer/Zf1 Grad Norm                9179.58\n",
      "trainer/Zf1 Param Norm                 75.2145\n",
      "trainer/Zf2 Grad Norm                7896.04\n",
      "trainer/Zf2 Param Norm                 75.0734\n",
      "trainer/Z Expert Predictions Mean    1219.77\n",
      "trainer/Z Expert Predictions Std      175.233\n",
      "trainer/Z Expert Predictions Max     1596.36\n",
      "trainer/Z Expert Predictions Min      473.915\n",
      "trainer/Z Policy Predictions Mean     643.499\n",
      "trainer/Z Policy Predictions Std      556.649\n",
      "trainer/Z Policy Predictions Max     1565.13\n",
      "trainer/Z Policy Predictions Min     -193.803\n",
      "trainer/Z Expert Targets Mean        1199\n",
      "trainer/Z Expert Targets Std          181.67\n",
      "trainer/Z Expert Targets Max         1582.69\n",
      "trainer/Z Expert Targets Min          461.416\n",
      "trainer/Z Policy Targets Mean         644.097\n",
      "trainer/Z Policy Targets Std          555.577\n",
      "trainer/Z Policy Targets Max         1553.03\n",
      "trainer/Z Policy Targets Min         -163.188\n",
      "trainer/Log Pis Mean                   20.2353\n",
      "trainer/Log Pis Std                     5.66509\n",
      "trainer/Policy mu Mean                  1.06812\n",
      "trainer/Policy mu Std                   1.71319\n",
      "trainer/Policy log std Mean            -2.71268\n",
      "trainer/Policy log std Std              1.21036\n",
      "trainer/Alpha                           0.0477287\n",
      "trainer/Alpha Loss                     -0.0112308\n",
      "exploration/num steps total         56287\n",
      "exploration/num paths total           629\n",
      "evaluation/num steps total         165612\n",
      "evaluation/num paths total            503\n",
      "evaluation/path length Mean           469.6\n",
      "evaluation/path length Std             81.6544\n",
      "evaluation/path length Max            623\n",
      "evaluation/path length Min            324\n",
      "evaluation/Rewards Mean                 4.64545\n",
      "evaluation/Rewards Std                  1.65271\n",
      "evaluation/Rewards Max                  8.98309\n",
      "evaluation/Rewards Min                  0.17136\n",
      "evaluation/Returns Mean              2181.5\n",
      "evaluation/Returns Std                456.596\n",
      "evaluation/Returns Max               3052.7\n",
      "evaluation/Returns Min               1369.62\n",
      "evaluation/Estimation Bias Mean      1025.51\n",
      "evaluation/Estimation Bias Std        401.19\n",
      "evaluation/EB/Q_True Mean              48.8533\n",
      "evaluation/EB/Q_True Std              133.639\n",
      "evaluation/EB/Q_Pred Mean            1074.37\n",
      "evaluation/EB/Q_Pred Std              380.755\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2181.5\n",
      "evaluation/Actions Mean                 0.494866\n",
      "evaluation/Actions Std                  0.624318\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.9982\n",
      "time/backward_zf1 (s)                   2.15255\n",
      "time/backward_zf2 (s)                   2.10561\n",
      "time/data sampling (s)                  0.237316\n",
      "time/data storing (s)                   0.0141023\n",
      "time/evaluation sampling (s)            1.16117\n",
      "time/exploration sampling (s)           0.193375\n",
      "time/logging (s)                        0.00650897\n",
      "time/preback_alpha (s)                  1.06387\n",
      "time/preback_policy (s)                 1.21052\n",
      "time/preback_start (s)                  0.122553\n",
      "time/preback_zf (s)                     5.17838\n",
      "time/saving (s)                         0.00505399\n",
      "time/training (s)                       2.09946\n",
      "time/epoch (s)                         17.5487\n",
      "time/total (s)                        823.342\n",
      "Epoch                                  49\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:24:29.210103 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 50 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  61000\n",
      "trainer/ZF1 Loss                      145.148\n",
      "trainer/ZF2 Loss                      118.175\n",
      "trainer/ZF Expert Reward               25.1605\n",
      "trainer/ZF Policy Reward                1.68334\n",
      "trainer/ZF CHI2 Term                  175.177\n",
      "trainer/Policy Loss                  -738.68\n",
      "trainer/Bias Loss                     447.299\n",
      "trainer/Bias Value                     19.1392\n",
      "trainer/Policy Grad Norm              274.154\n",
      "trainer/Policy Param Norm              28.798\n",
      "trainer/Zf1 Grad Norm               10224.5\n",
      "trainer/Zf1 Param Norm                 75.7034\n",
      "trainer/Zf2 Grad Norm               10171.2\n",
      "trainer/Zf2 Param Norm                 75.5247\n",
      "trainer/Z Expert Predictions Mean    1229.93\n",
      "trainer/Z Expert Predictions Std      174.816\n",
      "trainer/Z Expert Predictions Max     1605.35\n",
      "trainer/Z Expert Predictions Min      116.51\n",
      "trainer/Z Policy Predictions Mean     719.537\n",
      "trainer/Z Policy Predictions Std      546.496\n",
      "trainer/Z Policy Predictions Max     1587.37\n",
      "trainer/Z Policy Predictions Min     -149.569\n",
      "trainer/Z Expert Targets Mean        1204.77\n",
      "trainer/Z Expert Targets Std          174.703\n",
      "trainer/Z Expert Targets Max         1578.4\n",
      "trainer/Z Expert Targets Min          146.973\n",
      "trainer/Z Policy Targets Mean         717.854\n",
      "trainer/Z Policy Targets Std          544.587\n",
      "trainer/Z Policy Targets Max         1574.78\n",
      "trainer/Z Policy Targets Min         -119.229\n",
      "trainer/Log Pis Mean                   20.2407\n",
      "trainer/Log Pis Std                     5.29231\n",
      "trainer/Policy mu Mean                  1.03857\n",
      "trainer/Policy mu Std                   1.69209\n",
      "trainer/Policy log std Mean            -2.74133\n",
      "trainer/Policy log std Std              1.16528\n",
      "trainer/Alpha                           0.0494632\n",
      "trainer/Alpha Loss                     -0.0119079\n",
      "exploration/num steps total         57976\n",
      "exploration/num paths total           632\n",
      "evaluation/num steps total         168253\n",
      "evaluation/num paths total            513\n",
      "evaluation/path length Mean           264.1\n",
      "evaluation/path length Std             21.5845\n",
      "evaluation/path length Max            301\n",
      "evaluation/path length Min            233\n",
      "evaluation/Rewards Mean                 4.09058\n",
      "evaluation/Rewards Std                  2.03695\n",
      "evaluation/Rewards Max                  8.94988\n",
      "evaluation/Rewards Min                  0.0880717\n",
      "evaluation/Returns Mean              1080.32\n",
      "evaluation/Returns Std                131.819\n",
      "evaluation/Returns Max               1299.24\n",
      "evaluation/Returns Min                891.149\n",
      "evaluation/Estimation Bias Mean       931.25\n",
      "evaluation/Estimation Bias Std        512.568\n",
      "evaluation/EB/Q_True Mean              39.2665\n",
      "evaluation/EB/Q_True Std              116.049\n",
      "evaluation/EB/Q_Pred Mean             970.516\n",
      "evaluation/EB/Q_Pred Std              499.74\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1080.32\n",
      "evaluation/Actions Mean                 0.471881\n",
      "evaluation/Actions Std                  0.622388\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.97579\n",
      "time/backward_zf1 (s)                   2.10936\n",
      "time/backward_zf2 (s)                   2.07065\n",
      "time/data sampling (s)                  0.237402\n",
      "time/data storing (s)                   0.014378\n",
      "time/evaluation sampling (s)            0.466353\n",
      "time/exploration sampling (s)           0.197435\n",
      "time/logging (s)                        0.00399144\n",
      "time/preback_alpha (s)                  1.02773\n",
      "time/preback_policy (s)                 1.17962\n",
      "time/preback_start (s)                  0.120568\n",
      "time/preback_zf (s)                     5.12617\n",
      "time/saving (s)                         0.00497818\n",
      "time/training (s)                       2.13381\n",
      "time/epoch (s)                         16.6682\n",
      "time/total (s)                        840.03\n",
      "Epoch                                  50\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:24:46.662991 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 51 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  62000\n",
      "trainer/ZF1 Loss                      119.33\n",
      "trainer/ZF2 Loss                      109.981\n",
      "trainer/ZF Expert Reward               11.9964\n",
      "trainer/ZF Policy Reward              -10.1007\n",
      "trainer/ZF CHI2 Term                  157.432\n",
      "trainer/Policy Loss                  -695.042\n",
      "trainer/Bias Loss                     501.039\n",
      "trainer/Bias Value                     19.2028\n",
      "trainer/Policy Grad Norm              204.141\n",
      "trainer/Policy Param Norm              28.9203\n",
      "trainer/Zf1 Grad Norm               15075.9\n",
      "trainer/Zf1 Param Norm                 76.1745\n",
      "trainer/Zf2 Grad Norm               13286.4\n",
      "trainer/Zf2 Param Norm                 75.9883\n",
      "trainer/Z Expert Predictions Mean    1203.06\n",
      "trainer/Z Expert Predictions Std      214.292\n",
      "trainer/Z Expert Predictions Max     1576.95\n",
      "trainer/Z Expert Predictions Min      156.934\n",
      "trainer/Z Policy Predictions Mean     668.875\n",
      "trainer/Z Policy Predictions Std      559.001\n",
      "trainer/Z Policy Predictions Max     1567.28\n",
      "trainer/Z Policy Predictions Min     -190.457\n",
      "trainer/Z Expert Targets Mean        1191.07\n",
      "trainer/Z Expert Targets Std          212.99\n",
      "trainer/Z Expert Targets Max         1569.55\n",
      "trainer/Z Expert Targets Min          168.635\n",
      "trainer/Z Policy Targets Mean         678.976\n",
      "trainer/Z Policy Targets Std          559.222\n",
      "trainer/Z Policy Targets Max         1560.56\n",
      "trainer/Z Policy Targets Min         -172.585\n",
      "trainer/Log Pis Mean                   20.8884\n",
      "trainer/Log Pis Std                     5.68927\n",
      "trainer/Policy mu Mean                  1.03668\n",
      "trainer/Policy mu Std                   1.78518\n",
      "trainer/Policy log std Mean            -2.76055\n",
      "trainer/Policy log std Std              1.19382\n",
      "trainer/Alpha                           0.051916\n",
      "trainer/Alpha Loss                     -0.0461148\n",
      "exploration/num steps total         59204\n",
      "exploration/num paths total           634\n",
      "evaluation/num steps total         174389\n",
      "evaluation/num paths total            523\n",
      "evaluation/path length Mean           613.6\n",
      "evaluation/path length Std            165.752\n",
      "evaluation/path length Max            901\n",
      "evaluation/path length Min            418\n",
      "evaluation/Rewards Mean                 5.01214\n",
      "evaluation/Rewards Std                  1.61803\n",
      "evaluation/Rewards Max                  8.25624\n",
      "evaluation/Rewards Min                  0.136283\n",
      "evaluation/Returns Mean              3075.45\n",
      "evaluation/Returns Std                977.388\n",
      "evaluation/Returns Max               4771.08\n",
      "evaluation/Returns Min               1931.8\n",
      "evaluation/Estimation Bias Mean      1084.92\n",
      "evaluation/Estimation Bias Std        366.019\n",
      "evaluation/EB/Q_True Mean              72.8671\n",
      "evaluation/EB/Q_True Std              181.264\n",
      "evaluation/EB/Q_Pred Mean            1157.79\n",
      "evaluation/EB/Q_Pred Std              328.984\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3075.45\n",
      "evaluation/Actions Mean                 0.514751\n",
      "evaluation/Actions Std                  0.63302\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.96475\n",
      "time/backward_zf1 (s)                   2.09969\n",
      "time/backward_zf2 (s)                   2.05174\n",
      "time/data sampling (s)                  0.24404\n",
      "time/data storing (s)                   0.0147007\n",
      "time/evaluation sampling (s)            1.28008\n",
      "time/exploration sampling (s)           0.199154\n",
      "time/logging (s)                        0.00793327\n",
      "time/preback_alpha (s)                  1.05662\n",
      "time/preback_policy (s)                 1.2152\n",
      "time/preback_start (s)                  0.119285\n",
      "time/preback_zf (s)                     5.10222\n",
      "time/saving (s)                         0.004941\n",
      "time/training (s)                       2.03314\n",
      "time/epoch (s)                         17.3935\n",
      "time/total (s)                        857.44\n",
      "Epoch                                  51\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:25:03.329849 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 52 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  63000\n",
      "trainer/ZF1 Loss                      118.772\n",
      "trainer/ZF2 Loss                      112.618\n",
      "trainer/ZF Expert Reward               29.5699\n",
      "trainer/ZF Policy Reward                5.50573\n",
      "trainer/ZF CHI2 Term                  159.659\n",
      "trainer/Policy Loss                  -699.895\n",
      "trainer/Bias Loss                     402.518\n",
      "trainer/Bias Value                     19.2639\n",
      "trainer/Policy Grad Norm              206.51\n",
      "trainer/Policy Param Norm              29.0356\n",
      "trainer/Zf1 Grad Norm               12744.8\n",
      "trainer/Zf1 Param Norm                 76.6431\n",
      "trainer/Zf2 Grad Norm                7891.7\n",
      "trainer/Zf2 Param Norm                 76.4672\n",
      "trainer/Z Expert Predictions Mean    1254.88\n",
      "trainer/Z Expert Predictions Std      197.394\n",
      "trainer/Z Expert Predictions Max     1612.67\n",
      "trainer/Z Expert Predictions Min      156.322\n",
      "trainer/Z Policy Predictions Mean     689.683\n",
      "trainer/Z Policy Predictions Std      538.418\n",
      "trainer/Z Policy Predictions Max     1591.08\n",
      "trainer/Z Policy Predictions Min     -181.707\n",
      "trainer/Z Expert Targets Mean        1225.31\n",
      "trainer/Z Expert Targets Std          204.299\n",
      "trainer/Z Expert Targets Max         1594.69\n",
      "trainer/Z Expert Targets Min          160.894\n",
      "trainer/Z Policy Targets Mean         684.177\n",
      "trainer/Z Policy Targets Std          535.948\n",
      "trainer/Z Policy Targets Max         1580.2\n",
      "trainer/Z Policy Targets Min         -198.835\n",
      "trainer/Log Pis Mean                   20.101\n",
      "trainer/Log Pis Std                     6.05639\n",
      "trainer/Policy mu Mean                  0.9768\n",
      "trainer/Policy mu Std                   1.79934\n",
      "trainer/Policy log std Mean            -2.66285\n",
      "trainer/Policy log std Std              1.14237\n",
      "trainer/Alpha                           0.0536426\n",
      "trainer/Alpha Loss                     -0.0054193\n",
      "exploration/num steps total         59847\n",
      "exploration/num paths total           635\n",
      "evaluation/num steps total         177997\n",
      "evaluation/num paths total            533\n",
      "evaluation/path length Mean           360.8\n",
      "evaluation/path length Std             37.8254\n",
      "evaluation/path length Max            453\n",
      "evaluation/path length Min            332\n",
      "evaluation/Rewards Mean                 4.34307\n",
      "evaluation/Rewards Std                  1.81871\n",
      "evaluation/Rewards Max                  7.59616\n",
      "evaluation/Rewards Min                  0.122507\n",
      "evaluation/Returns Mean              1566.98\n",
      "evaluation/Returns Std                219.396\n",
      "evaluation/Returns Max               2095.63\n",
      "evaluation/Returns Min               1392.7\n",
      "evaluation/Estimation Bias Mean       988.58\n",
      "evaluation/Estimation Bias Std        492.117\n",
      "evaluation/EB/Q_True Mean              39.8669\n",
      "evaluation/EB/Q_True Std              113.704\n",
      "evaluation/EB/Q_Pred Mean            1028.45\n",
      "evaluation/EB/Q_Pred Std              496.074\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1566.98\n",
      "evaluation/Actions Mean                 0.483953\n",
      "evaluation/Actions Std                  0.635848\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.80422\n",
      "time/backward_zf1 (s)                   1.93769\n",
      "time/backward_zf2 (s)                   1.8502\n",
      "time/data sampling (s)                  0.238181\n",
      "time/data storing (s)                   0.0139316\n",
      "time/evaluation sampling (s)            0.961907\n",
      "time/exploration sampling (s)           0.190334\n",
      "time/logging (s)                        0.00570057\n",
      "time/preback_alpha (s)                  0.900517\n",
      "time/preback_policy (s)                 0.988901\n",
      "time/preback_start (s)                  0.118724\n",
      "time/preback_zf (s)                     5.12828\n",
      "time/saving (s)                         0.00487476\n",
      "time/training (s)                       2.45536\n",
      "time/epoch (s)                         16.5988\n",
      "time/total (s)                        874.058\n",
      "Epoch                                  52\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:25:21.062224 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 53 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  64000\n",
      "trainer/ZF1 Loss                      173.603\n",
      "trainer/ZF2 Loss                      171.107\n",
      "trainer/ZF Expert Reward                7.85018\n",
      "trainer/ZF Policy Reward              -12.3925\n",
      "trainer/ZF CHI2 Term                  212.246\n",
      "trainer/Policy Loss                  -689.702\n",
      "trainer/Bias Loss                     436.966\n",
      "trainer/Bias Value                     19.3214\n",
      "trainer/Policy Grad Norm              187.822\n",
      "trainer/Policy Param Norm              29.1475\n",
      "trainer/Zf1 Grad Norm               17240.5\n",
      "trainer/Zf1 Param Norm                 77.1122\n",
      "trainer/Zf2 Grad Norm               12493.2\n",
      "trainer/Zf2 Param Norm                 76.9329\n",
      "trainer/Z Expert Predictions Mean    1254.87\n",
      "trainer/Z Expert Predictions Std      190.029\n",
      "trainer/Z Expert Predictions Max     1593.98\n",
      "trainer/Z Expert Predictions Min      358.607\n",
      "trainer/Z Policy Predictions Mean     669.449\n",
      "trainer/Z Policy Predictions Std      551.858\n",
      "trainer/Z Policy Predictions Max     1588.57\n",
      "trainer/Z Policy Predictions Min     -181.176\n",
      "trainer/Z Expert Targets Mean        1247.02\n",
      "trainer/Z Expert Targets Std          190.454\n",
      "trainer/Z Expert Targets Max         1591.41\n",
      "trainer/Z Expert Targets Min          384.358\n",
      "trainer/Z Policy Targets Mean         681.841\n",
      "trainer/Z Policy Targets Std          553.866\n",
      "trainer/Z Policy Targets Max         1596.53\n",
      "trainer/Z Policy Targets Min         -210.656\n",
      "trainer/Log Pis Mean                   19.8467\n",
      "trainer/Log Pis Std                     5.58251\n",
      "trainer/Policy mu Mean                  0.995344\n",
      "trainer/Policy mu Std                   1.80206\n",
      "trainer/Policy log std Mean            -2.61403\n",
      "trainer/Policy log std Std              1.19112\n",
      "trainer/Alpha                           0.0560539\n",
      "trainer/Alpha Loss                      0.00859169\n",
      "exploration/num steps total         61408\n",
      "exploration/num paths total           637\n",
      "evaluation/num steps total         187108\n",
      "evaluation/num paths total            543\n",
      "evaluation/path length Mean           911.1\n",
      "evaluation/path length Std            187.488\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            418\n",
      "evaluation/Rewards Mean                 5.1641\n",
      "evaluation/Rewards Std                  1.34974\n",
      "evaluation/Rewards Max                  7.78754\n",
      "evaluation/Rewards Min                  0.135743\n",
      "evaluation/Returns Mean              4705.02\n",
      "evaluation/Returns Std               1071.11\n",
      "evaluation/Returns Max               5345.2\n",
      "evaluation/Returns Min               1899.95\n",
      "evaluation/Estimation Bias Mean      1232.25\n",
      "evaluation/Estimation Bias Std        276.15\n",
      "evaluation/EB/Q_True Mean              54.6947\n",
      "evaluation/EB/Q_True Std              160.234\n",
      "evaluation/EB/Q_Pred Mean            1286.94\n",
      "evaluation/EB/Q_Pred Std              224.011\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4705.02\n",
      "evaluation/Actions Mean                 0.534961\n",
      "evaluation/Actions Std                  0.62023\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999966\n",
      "time/backward_policy (s)                1.99976\n",
      "time/backward_zf1 (s)                   2.10868\n",
      "time/backward_zf2 (s)                   2.07612\n",
      "time/data sampling (s)                  0.227592\n",
      "time/data storing (s)                   0.014062\n",
      "time/evaluation sampling (s)            1.4019\n",
      "time/exploration sampling (s)           0.200332\n",
      "time/logging (s)                        0.0116434\n",
      "time/preback_alpha (s)                  1.06086\n",
      "time/preback_policy (s)                 1.23144\n",
      "time/preback_start (s)                  0.119209\n",
      "time/preback_zf (s)                     5.14308\n",
      "time/saving (s)                         0.0054372\n",
      "time/training (s)                       2.04923\n",
      "time/epoch (s)                         17.6494\n",
      "time/total (s)                        891.75\n",
      "Epoch                                  53\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:25:38.103245 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 54 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  65000\n",
      "trainer/ZF1 Loss                      137.46\n",
      "trainer/ZF2 Loss                      157.231\n",
      "trainer/ZF Expert Reward               34.9028\n",
      "trainer/ZF Policy Reward                2.59743\n",
      "trainer/ZF CHI2 Term                  199.384\n",
      "trainer/Policy Loss                  -692.83\n",
      "trainer/Bias Loss                    1097.63\n",
      "trainer/Bias Value                     19.3794\n",
      "trainer/Policy Grad Norm              284.871\n",
      "trainer/Policy Param Norm              29.2591\n",
      "trainer/Zf1 Grad Norm               10200.8\n",
      "trainer/Zf1 Param Norm                 77.5845\n",
      "trainer/Zf2 Grad Norm               12202.6\n",
      "trainer/Zf2 Param Norm                 77.3841\n",
      "trainer/Z Expert Predictions Mean    1277.5\n",
      "trainer/Z Expert Predictions Std      210.416\n",
      "trainer/Z Expert Predictions Max     1611.6\n",
      "trainer/Z Expert Predictions Min      199.736\n",
      "trainer/Z Policy Predictions Mean     684.678\n",
      "trainer/Z Policy Predictions Std      553.83\n",
      "trainer/Z Policy Predictions Max     1588.1\n",
      "trainer/Z Policy Predictions Min     -190.858\n",
      "trainer/Z Expert Targets Mean        1242.6\n",
      "trainer/Z Expert Targets Std          229.07\n",
      "trainer/Z Expert Targets Max         1599.31\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         682.081\n",
      "trainer/Z Policy Targets Std          550.166\n",
      "trainer/Z Policy Targets Max         1587.67\n",
      "trainer/Z Policy Targets Min         -180.532\n",
      "trainer/Log Pis Mean                   19.9318\n",
      "trainer/Log Pis Std                     6.06192\n",
      "trainer/Policy mu Mean                  1.01517\n",
      "trainer/Policy mu Std                   1.84581\n",
      "trainer/Policy log std Mean            -2.57262\n",
      "trainer/Policy log std Std              1.16942\n",
      "trainer/Alpha                           0.05927\n",
      "trainer/Alpha Loss                      0.00404297\n",
      "exploration/num steps total         62523\n",
      "exploration/num paths total           640\n",
      "evaluation/num steps total         192601\n",
      "evaluation/num paths total            553\n",
      "evaluation/path length Mean           549.3\n",
      "evaluation/path length Std            121.56\n",
      "evaluation/path length Max            807\n",
      "evaluation/path length Min            348\n",
      "evaluation/Rewards Mean                 4.99194\n",
      "evaluation/Rewards Std                  1.67859\n",
      "evaluation/Rewards Max                  8.08261\n",
      "evaluation/Rewards Min                  0.115701\n",
      "evaluation/Returns Mean              2742.08\n",
      "evaluation/Returns Std                713.636\n",
      "evaluation/Returns Max               4268.2\n",
      "evaluation/Returns Min               1561.01\n",
      "evaluation/Estimation Bias Mean      1120.1\n",
      "evaluation/Estimation Bias Std        404.117\n",
      "evaluation/EB/Q_True Mean              72.3972\n",
      "evaluation/EB/Q_True Std              180.605\n",
      "evaluation/EB/Q_Pred Mean            1192.49\n",
      "evaluation/EB/Q_Pred Std              364.046\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2742.08\n",
      "evaluation/Actions Mean                 0.510101\n",
      "evaluation/Actions Std                  0.625673\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.86734\n",
      "time/backward_zf1 (s)                   2.00829\n",
      "time/backward_zf2 (s)                   1.95437\n",
      "time/data sampling (s)                  0.248982\n",
      "time/data storing (s)                   0.0150088\n",
      "time/evaluation sampling (s)            1.17262\n",
      "time/exploration sampling (s)           0.201436\n",
      "time/logging (s)                        0.00889354\n",
      "time/preback_alpha (s)                  0.974025\n",
      "time/preback_policy (s)                 1.08708\n",
      "time/preback_start (s)                  0.118073\n",
      "time/preback_zf (s)                     5.08297\n",
      "time/saving (s)                         0.00862204\n",
      "time/training (s)                       2.22174\n",
      "time/epoch (s)                         16.9694\n",
      "time/total (s)                        908.742\n",
      "Epoch                                  54\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:25:55.615723 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 55 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  66000\n",
      "trainer/ZF1 Loss                      124.089\n",
      "trainer/ZF2 Loss                      124.814\n",
      "trainer/ZF Expert Reward               22.247\n",
      "trainer/ZF Policy Reward                4.29183\n",
      "trainer/ZF CHI2 Term                  162.683\n",
      "trainer/Policy Loss                  -731.532\n",
      "trainer/Bias Loss                     428.122\n",
      "trainer/Bias Value                     19.4374\n",
      "trainer/Policy Grad Norm              409.731\n",
      "trainer/Policy Param Norm              29.3828\n",
      "trainer/Zf1 Grad Norm                6964.42\n",
      "trainer/Zf1 Param Norm                 78.0196\n",
      "trainer/Zf2 Grad Norm                5831.03\n",
      "trainer/Zf2 Param Norm                 77.8048\n",
      "trainer/Z Expert Predictions Mean    1279.94\n",
      "trainer/Z Expert Predictions Std      219.39\n",
      "trainer/Z Expert Predictions Max     1614.17\n",
      "trainer/Z Expert Predictions Min      223.964\n",
      "trainer/Z Policy Predictions Mean     708.952\n",
      "trainer/Z Policy Predictions Std      570.589\n",
      "trainer/Z Policy Predictions Max     1607.29\n",
      "trainer/Z Policy Predictions Min     -157.444\n",
      "trainer/Z Expert Targets Mean        1257.69\n",
      "trainer/Z Expert Targets Std          226.579\n",
      "trainer/Z Expert Targets Max         1606.43\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         704.66\n",
      "trainer/Z Policy Targets Std          571.388\n",
      "trainer/Z Policy Targets Max         1601.28\n",
      "trainer/Z Policy Targets Min         -154.089\n",
      "trainer/Log Pis Mean                   20.4817\n",
      "trainer/Log Pis Std                     6.38311\n",
      "trainer/Policy mu Mean                  1.02688\n",
      "trainer/Policy mu Std                   1.91084\n",
      "trainer/Policy log std Mean            -2.58913\n",
      "trainer/Policy log std Std              1.1973\n",
      "trainer/Alpha                           0.0635504\n",
      "trainer/Alpha Loss                     -0.0306101\n",
      "exploration/num steps total         62523\n",
      "exploration/num paths total           640\n",
      "evaluation/num steps total         201135\n",
      "evaluation/num paths total            563\n",
      "evaluation/path length Mean           853.4\n",
      "evaluation/path length Std            220.776\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            350\n",
      "evaluation/Rewards Mean                 5.26123\n",
      "evaluation/Rewards Std                  1.46196\n",
      "evaluation/Rewards Max                  7.70527\n",
      "evaluation/Rewards Min                  0.1158\n",
      "evaluation/Returns Mean              4489.93\n",
      "evaluation/Returns Std               1293.99\n",
      "evaluation/Returns Max               5353.51\n",
      "evaluation/Returns Min               1525.1\n",
      "evaluation/Estimation Bias Mean      1183.05\n",
      "evaluation/Estimation Bias Std        348.921\n",
      "evaluation/EB/Q_True Mean              59.384\n",
      "evaluation/EB/Q_True Std              167.894\n",
      "evaluation/EB/Q_Pred Mean            1242.43\n",
      "evaluation/EB/Q_Pred Std              288.478\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4489.93\n",
      "evaluation/Actions Mean                 0.53332\n",
      "evaluation/Actions Std                  0.634929\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999983\n",
      "time/backward_policy (s)                1.92827\n",
      "time/backward_zf1 (s)                   2.04425\n",
      "time/backward_zf2 (s)                   2.00054\n",
      "time/data sampling (s)                  0.241865\n",
      "time/data storing (s)                   0.0153481\n",
      "time/evaluation sampling (s)            1.43324\n",
      "time/exploration sampling (s)           0.192283\n",
      "time/logging (s)                        0.0102341\n",
      "time/preback_alpha (s)                  1.01406\n",
      "time/preback_policy (s)                 1.15536\n",
      "time/preback_start (s)                  0.118501\n",
      "time/preback_zf (s)                     5.13343\n",
      "time/saving (s)                         0.00503589\n",
      "time/training (s)                       2.15206\n",
      "time/epoch (s)                         17.4445\n",
      "time/total (s)                        926.206\n",
      "Epoch                                  55\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:26:13.300076 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 56 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  67000\n",
      "trainer/ZF1 Loss                      584.646\n",
      "trainer/ZF2 Loss                      576.392\n",
      "trainer/ZF Expert Reward               22.9561\n",
      "trainer/ZF Policy Reward                0.334575\n",
      "trainer/ZF CHI2 Term                  623.559\n",
      "trainer/Policy Loss                  -816.694\n",
      "trainer/Bias Loss                    3990.42\n",
      "trainer/Bias Value                     19.4924\n",
      "trainer/Policy Grad Norm              197.973\n",
      "trainer/Policy Param Norm              29.498\n",
      "trainer/Zf1 Grad Norm                7643.85\n",
      "trainer/Zf1 Param Norm                 78.4453\n",
      "trainer/Zf2 Grad Norm                8307.77\n",
      "trainer/Zf2 Param Norm                 78.1974\n",
      "trainer/Z Expert Predictions Mean    1281.32\n",
      "trainer/Z Expert Predictions Std      212.245\n",
      "trainer/Z Expert Predictions Max     1617.26\n",
      "trainer/Z Expert Predictions Min      162.273\n",
      "trainer/Z Policy Predictions Mean     794.736\n",
      "trainer/Z Policy Predictions Std      536.949\n",
      "trainer/Z Policy Predictions Max     1628.23\n",
      "trainer/Z Policy Predictions Min     -171.292\n",
      "trainer/Z Expert Targets Mean        1258.36\n",
      "trainer/Z Expert Targets Std          232.815\n",
      "trainer/Z Expert Targets Max         1613.47\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         794.401\n",
      "trainer/Z Policy Targets Std          534.421\n",
      "trainer/Z Policy Targets Max         1624.72\n",
      "trainer/Z Policy Targets Min         -165.055\n",
      "trainer/Log Pis Mean                   20.6242\n",
      "trainer/Log Pis Std                     6.25641\n",
      "trainer/Policy mu Mean                  1.11058\n",
      "trainer/Policy mu Std                   1.8517\n",
      "trainer/Policy log std Mean            -2.62388\n",
      "trainer/Policy log std Std              1.14187\n",
      "trainer/Alpha                           0.069146\n",
      "trainer/Alpha Loss                     -0.04316\n",
      "exploration/num steps total         62937\n",
      "exploration/num paths total           641\n",
      "evaluation/num steps total         209650\n",
      "evaluation/num paths total            573\n",
      "evaluation/path length Mean           851.5\n",
      "evaluation/path length Std            228.713\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            444\n",
      "evaluation/Rewards Mean                 5.13035\n",
      "evaluation/Rewards Std                  1.41491\n",
      "evaluation/Rewards Max                  7.63795\n",
      "evaluation/Rewards Min                  0.135505\n",
      "evaluation/Returns Mean              4368.49\n",
      "evaluation/Returns Std               1300.97\n",
      "evaluation/Returns Max               5237.66\n",
      "evaluation/Returns Min               2050.55\n",
      "evaluation/Estimation Bias Mean      1277.89\n",
      "evaluation/Estimation Bias Std        332.293\n",
      "evaluation/EB/Q_True Mean              57.831\n",
      "evaluation/EB/Q_True Std              163.234\n",
      "evaluation/EB/Q_Pred Mean            1335.72\n",
      "evaluation/EB/Q_Pred Std              255.395\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4368.49\n",
      "evaluation/Actions Mean                 0.506501\n",
      "evaluation/Actions Std                  0.638668\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999954\n",
      "time/backward_policy (s)                1.98968\n",
      "time/backward_zf1 (s)                   2.12213\n",
      "time/backward_zf2 (s)                   2.08028\n",
      "time/data sampling (s)                  0.25249\n",
      "time/data storing (s)                   0.0152994\n",
      "time/evaluation sampling (s)            1.44864\n",
      "time/exploration sampling (s)           0.196025\n",
      "time/logging (s)                        0.0110415\n",
      "time/preback_alpha (s)                  1.05472\n",
      "time/preback_policy (s)                 1.20675\n",
      "time/preback_start (s)                  0.120387\n",
      "time/preback_zf (s)                     5.09995\n",
      "time/saving (s)                         0.00796382\n",
      "time/training (s)                       2.00812\n",
      "time/epoch (s)                         17.6135\n",
      "time/total (s)                        943.844\n",
      "Epoch                                  56\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:26:31.223627 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 57 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  68000\n",
      "trainer/ZF1 Loss                      125.327\n",
      "trainer/ZF2 Loss                      105.361\n",
      "trainer/ZF Expert Reward               29.6596\n",
      "trainer/ZF Policy Reward                2.79316\n",
      "trainer/ZF CHI2 Term                  161.717\n",
      "trainer/Policy Loss                  -831.489\n",
      "trainer/Bias Loss                     545.812\n",
      "trainer/Bias Value                     19.5452\n",
      "trainer/Policy Grad Norm              240.024\n",
      "trainer/Policy Param Norm              29.6101\n",
      "trainer/Zf1 Grad Norm                8662.41\n",
      "trainer/Zf1 Param Norm                 78.888\n",
      "trainer/Zf2 Grad Norm                5607.68\n",
      "trainer/Zf2 Param Norm                 78.6126\n",
      "trainer/Z Expert Predictions Mean    1329.54\n",
      "trainer/Z Expert Predictions Std      202.66\n",
      "trainer/Z Expert Predictions Max     1656.41\n",
      "trainer/Z Expert Predictions Min      347.341\n",
      "trainer/Z Policy Predictions Mean     814.766\n",
      "trainer/Z Policy Predictions Std      559.59\n",
      "trainer/Z Policy Predictions Max     1650.98\n",
      "trainer/Z Policy Predictions Min     -173.807\n",
      "trainer/Z Expert Targets Mean        1299.88\n",
      "trainer/Z Expert Targets Std          208.722\n",
      "trainer/Z Expert Targets Max         1642.5\n",
      "trainer/Z Expert Targets Min          325.788\n",
      "trainer/Z Policy Targets Mean         811.972\n",
      "trainer/Z Policy Targets Std          556.324\n",
      "trainer/Z Policy Targets Max         1637.45\n",
      "trainer/Z Policy Targets Min         -135.959\n",
      "trainer/Log Pis Mean                   19.7034\n",
      "trainer/Log Pis Std                     5.202\n",
      "trainer/Policy mu Mean                  1.07548\n",
      "trainer/Policy mu Std                   1.87978\n",
      "trainer/Policy log std Mean            -2.49438\n",
      "trainer/Policy log std Std              1.1478\n",
      "trainer/Alpha                           0.072655\n",
      "trainer/Alpha Loss                      0.0215486\n",
      "exploration/num steps total         62937\n",
      "exploration/num paths total           641\n",
      "evaluation/num steps total         218910\n",
      "evaluation/num paths total            583\n",
      "evaluation/path length Mean           926\n",
      "evaluation/path length Std            131.964\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            593\n",
      "evaluation/Rewards Mean                 5.01346\n",
      "evaluation/Rewards Std                  1.32495\n",
      "evaluation/Rewards Max                  7.62731\n",
      "evaluation/Rewards Min                  0.126803\n",
      "evaluation/Returns Mean              4642.46\n",
      "evaluation/Returns Std                759.744\n",
      "evaluation/Returns Max               5170.85\n",
      "evaluation/Returns Min               2811.71\n",
      "evaluation/Estimation Bias Mean      1257.22\n",
      "evaluation/Estimation Bias Std        304.385\n",
      "evaluation/EB/Q_True Mean              52.8313\n",
      "evaluation/EB/Q_True Std              156.43\n",
      "evaluation/EB/Q_Pred Mean            1310.05\n",
      "evaluation/EB/Q_Pred Std              240.927\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4642.46\n",
      "evaluation/Actions Mean                 0.508466\n",
      "evaluation/Actions Std                  0.641406\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.02044\n",
      "time/backward_zf1 (s)                   2.1997\n",
      "time/backward_zf2 (s)                   2.13609\n",
      "time/data sampling (s)                  0.261354\n",
      "time/data storing (s)                   0.0161441\n",
      "time/evaluation sampling (s)            1.41529\n",
      "time/exploration sampling (s)           0.193956\n",
      "time/logging (s)                        0.0111552\n",
      "time/preback_alpha (s)                  1.07271\n",
      "time/preback_policy (s)                 1.23343\n",
      "time/preback_start (s)                  0.12166\n",
      "time/preback_zf (s)                     5.1518\n",
      "time/saving (s)                         0.00543627\n",
      "time/training (s)                       2.00735\n",
      "time/epoch (s)                         17.8465\n",
      "time/total (s)                        961.72\n",
      "Epoch                                  57\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:26:48.612273 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 58 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                  69000\n",
      "trainer/ZF1 Loss                       99.2902\n",
      "trainer/ZF2 Loss                       84.6391\n",
      "trainer/ZF Expert Reward               21.5993\n",
      "trainer/ZF Policy Reward               -2.00015\n",
      "trainer/ZF CHI2 Term                  135.367\n",
      "trainer/Policy Loss                  -823.28\n",
      "trainer/Bias Loss                     373.852\n",
      "trainer/Bias Value                     19.5983\n",
      "trainer/Policy Grad Norm              210.967\n",
      "trainer/Policy Param Norm              29.721\n",
      "trainer/Zf1 Grad Norm                5791.31\n",
      "trainer/Zf1 Param Norm                 79.328\n",
      "trainer/Zf2 Grad Norm                4420.97\n",
      "trainer/Zf2 Param Norm                 79.0318\n",
      "trainer/Z Expert Predictions Mean    1331.47\n",
      "trainer/Z Expert Predictions Std      193.172\n",
      "trainer/Z Expert Predictions Max     1665.37\n",
      "trainer/Z Expert Predictions Min      387.112\n",
      "trainer/Z Policy Predictions Mean     805.168\n",
      "trainer/Z Policy Predictions Std      545.119\n",
      "trainer/Z Policy Predictions Max     1647.43\n",
      "trainer/Z Policy Predictions Min     -104.531\n",
      "trainer/Z Expert Targets Mean        1309.87\n",
      "trainer/Z Expert Targets Std          197.676\n",
      "trainer/Z Expert Targets Max         1662.11\n",
      "trainer/Z Expert Targets Min          279.739\n",
      "trainer/Z Policy Targets Mean         807.168\n",
      "trainer/Z Policy Targets Std          542.124\n",
      "trainer/Z Policy Targets Max         1644.66\n",
      "trainer/Z Policy Targets Min         -128.218\n",
      "trainer/Log Pis Mean                   20.0032\n",
      "trainer/Log Pis Std                     5.59696\n",
      "trainer/Policy mu Mean                  1.15555\n",
      "trainer/Policy mu Std                   1.95471\n",
      "trainer/Policy log std Mean            -2.34257\n",
      "trainer/Policy log std Std              1.15968\n",
      "trainer/Alpha                           0.0783166\n",
      "trainer/Alpha Loss                     -0.000253296\n",
      "exploration/num steps total         63937\n",
      "exploration/num paths total           642\n",
      "evaluation/num steps total         227666\n",
      "evaluation/num paths total            593\n",
      "evaluation/path length Mean           875.6\n",
      "evaluation/path length Std            139.644\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            620\n",
      "evaluation/Rewards Mean                 4.43318\n",
      "evaluation/Rewards Std                  1.89612\n",
      "evaluation/Rewards Max                  9.37486\n",
      "evaluation/Rewards Min                 -1.17606\n",
      "evaluation/Returns Mean              3881.69\n",
      "evaluation/Returns Std               1019.99\n",
      "evaluation/Returns Max               5212.45\n",
      "evaluation/Returns Min               1847.14\n",
      "evaluation/Estimation Bias Mean      1119.92\n",
      "evaluation/Estimation Bias Std        426.119\n",
      "evaluation/EB/Q_True Mean              54.8867\n",
      "evaluation/EB/Q_True Std              157.463\n",
      "evaluation/EB/Q_Pred Mean            1174.81\n",
      "evaluation/EB/Q_Pred Std              407.77\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3881.69\n",
      "evaluation/Actions Mean                 0.528586\n",
      "evaluation/Actions Std                  0.613881\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.81919\n",
      "time/backward_zf1 (s)                   1.96678\n",
      "time/backward_zf2 (s)                   1.88899\n",
      "time/data sampling (s)                  0.253\n",
      "time/data storing (s)                   0.0150934\n",
      "time/evaluation sampling (s)            1.46745\n",
      "time/exploration sampling (s)           0.204474\n",
      "time/logging (s)                        0.0140743\n",
      "time/preback_alpha (s)                  0.919736\n",
      "time/preback_policy (s)                 1.02392\n",
      "time/preback_start (s)                  0.119901\n",
      "time/preback_zf (s)                     5.15006\n",
      "time/saving (s)                         0.00525137\n",
      "time/training (s)                       2.47058\n",
      "time/epoch (s)                         17.3185\n",
      "time/total (s)                        979.065\n",
      "Epoch                                  58\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:27:06.151365 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 59 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  70000\n",
      "trainer/ZF1 Loss                       85.6801\n",
      "trainer/ZF2 Loss                      106.151\n",
      "trainer/ZF Expert Reward               15.0082\n",
      "trainer/ZF Policy Reward               -5.34832\n",
      "trainer/ZF CHI2 Term                  136.374\n",
      "trainer/Policy Loss                  -830.231\n",
      "trainer/Bias Loss                     245.413\n",
      "trainer/Bias Value                     19.6486\n",
      "trainer/Policy Grad Norm              230.734\n",
      "trainer/Policy Param Norm              29.83\n",
      "trainer/Zf1 Grad Norm                8572.98\n",
      "trainer/Zf1 Param Norm                 79.7683\n",
      "trainer/Zf2 Grad Norm               11317.9\n",
      "trainer/Zf2 Param Norm                 79.4417\n",
      "trainer/Z Expert Predictions Mean    1346.84\n",
      "trainer/Z Expert Predictions Std      196.723\n",
      "trainer/Z Expert Predictions Max     1675.54\n",
      "trainer/Z Expert Predictions Min      393.868\n",
      "trainer/Z Policy Predictions Mean     801.423\n",
      "trainer/Z Policy Predictions Std      535.417\n",
      "trainer/Z Policy Predictions Max     1670.52\n",
      "trainer/Z Policy Predictions Min     -206.564\n",
      "trainer/Z Expert Targets Mean        1331.83\n",
      "trainer/Z Expert Targets Std          194.18\n",
      "trainer/Z Expert Targets Max         1667.97\n",
      "trainer/Z Expert Targets Min          386.82\n",
      "trainer/Z Policy Targets Mean         806.771\n",
      "trainer/Z Policy Targets Std          536.09\n",
      "trainer/Z Policy Targets Max         1665.08\n",
      "trainer/Z Policy Targets Min         -216.2\n",
      "trainer/Log Pis Mean                   20.3048\n",
      "trainer/Log Pis Std                     6.26675\n",
      "trainer/Policy mu Mean                  1.16029\n",
      "trainer/Policy mu Std                   1.99382\n",
      "trainer/Policy log std Mean            -2.40802\n",
      "trainer/Policy log std Std              1.10881\n",
      "trainer/Alpha                           0.0812029\n",
      "trainer/Alpha Loss                     -0.0247481\n",
      "exploration/num steps total         64430\n",
      "exploration/num paths total           643\n",
      "evaluation/num steps total         237078\n",
      "evaluation/num paths total            603\n",
      "evaluation/path length Mean           941.2\n",
      "evaluation/path length Std            176.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            412\n",
      "evaluation/Rewards Mean                 5.03446\n",
      "evaluation/Rewards Std                  1.36108\n",
      "evaluation/Rewards Max                  7.49086\n",
      "evaluation/Rewards Min                  0.0710736\n",
      "evaluation/Returns Mean              4738.43\n",
      "evaluation/Returns Std                979.854\n",
      "evaluation/Returns Max               5111.68\n",
      "evaluation/Returns Min               1800.75\n",
      "evaluation/Estimation Bias Mean      1357.57\n",
      "evaluation/Estimation Bias Std        241.032\n",
      "evaluation/EB/Q_True Mean              50.0983\n",
      "evaluation/EB/Q_True Std              149.382\n",
      "evaluation/EB/Q_Pred Mean            1407.67\n",
      "evaluation/EB/Q_Pred Std              164.282\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4738.43\n",
      "evaluation/Actions Mean                 0.51796\n",
      "evaluation/Actions Std                  0.638413\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999951\n",
      "time/backward_policy (s)                1.88243\n",
      "time/backward_zf1 (s)                   2.02763\n",
      "time/backward_zf2 (s)                   1.95354\n",
      "time/data sampling (s)                  0.257986\n",
      "time/data storing (s)                   0.0145869\n",
      "time/evaluation sampling (s)            1.47041\n",
      "time/exploration sampling (s)           0.197278\n",
      "time/logging (s)                        0.0117555\n",
      "time/preback_alpha (s)                  0.977199\n",
      "time/preback_policy (s)                 1.07992\n",
      "time/preback_start (s)                  0.120277\n",
      "time/preback_zf (s)                     5.16086\n",
      "time/saving (s)                         0.00501082\n",
      "time/training (s)                       2.30993\n",
      "time/epoch (s)                         17.4688\n",
      "time/total (s)                        996.555\n",
      "Epoch                                  59\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:27:24.055461 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 60 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  71000\n",
      "trainer/ZF1 Loss                       77.868\n",
      "trainer/ZF2 Loss                       83.5145\n",
      "trainer/ZF Expert Reward               25.3683\n",
      "trainer/ZF Policy Reward               -1.17811\n",
      "trainer/ZF CHI2 Term                  127.324\n",
      "trainer/Policy Loss                  -818.305\n",
      "trainer/Bias Loss                     356.782\n",
      "trainer/Bias Value                     19.6986\n",
      "trainer/Policy Grad Norm              220.221\n",
      "trainer/Policy Param Norm              29.9303\n",
      "trainer/Zf1 Grad Norm                5686.52\n",
      "trainer/Zf1 Param Norm                 80.2029\n",
      "trainer/Zf2 Grad Norm                6824.64\n",
      "trainer/Zf2 Param Norm                 79.8506\n",
      "trainer/Z Expert Predictions Mean    1371.6\n",
      "trainer/Z Expert Predictions Std      189.764\n",
      "trainer/Z Expert Predictions Max     1700.88\n",
      "trainer/Z Expert Predictions Min      342.221\n",
      "trainer/Z Policy Predictions Mean     800.843\n",
      "trainer/Z Policy Predictions Std      542.939\n",
      "trainer/Z Policy Predictions Max     1692.04\n",
      "trainer/Z Policy Predictions Min     -159.07\n",
      "trainer/Z Expert Targets Mean        1346.23\n",
      "trainer/Z Expert Targets Std          190.549\n",
      "trainer/Z Expert Targets Max         1687.5\n",
      "trainer/Z Expert Targets Min          331.423\n",
      "trainer/Z Policy Targets Mean         802.021\n",
      "trainer/Z Policy Targets Std          536.85\n",
      "trainer/Z Policy Targets Max         1671.77\n",
      "trainer/Z Policy Targets Min         -157.342\n",
      "trainer/Log Pis Mean                   20.2892\n",
      "trainer/Log Pis Std                     5.68999\n",
      "trainer/Policy mu Mean                  1.09135\n",
      "trainer/Policy mu Std                   1.93324\n",
      "trainer/Policy log std Mean            -2.40693\n",
      "trainer/Policy log std Std              1.09415\n",
      "trainer/Alpha                           0.0824606\n",
      "trainer/Alpha Loss                     -0.0238439\n",
      "exploration/num steps total         66430\n",
      "exploration/num paths total           645\n",
      "evaluation/num steps total         247031\n",
      "evaluation/num paths total            613\n",
      "evaluation/path length Mean           995.3\n",
      "evaluation/path length Std             14.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            953\n",
      "evaluation/Rewards Mean                 4.68755\n",
      "evaluation/Rewards Std                  1.21851\n",
      "evaluation/Rewards Max                  7.91393\n",
      "evaluation/Rewards Min                  0.0930144\n",
      "evaluation/Returns Mean              4665.52\n",
      "evaluation/Returns Std                173.166\n",
      "evaluation/Returns Max               4810.34\n",
      "evaluation/Returns Min               4195.77\n",
      "evaluation/Estimation Bias Mean      1185.99\n",
      "evaluation/Estimation Bias Std        305.412\n",
      "evaluation/EB/Q_True Mean              45.3508\n",
      "evaluation/EB/Q_True Std              139.67\n",
      "evaluation/EB/Q_Pred Mean            1231.34\n",
      "evaluation/EB/Q_Pred Std              251.436\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4665.52\n",
      "evaluation/Actions Mean                 0.506241\n",
      "evaluation/Actions Std                  0.639171\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999915\n",
      "time/backward_policy (s)                2.02678\n",
      "time/backward_zf1 (s)                   2.16025\n",
      "time/backward_zf2 (s)                   2.10598\n",
      "time/data sampling (s)                  0.258283\n",
      "time/data storing (s)                   0.0144746\n",
      "time/evaluation sampling (s)            1.40704\n",
      "time/exploration sampling (s)           0.197997\n",
      "time/logging (s)                        0.0118537\n",
      "time/preback_alpha (s)                  1.06699\n",
      "time/preback_policy (s)                 1.21765\n",
      "time/preback_start (s)                  0.121163\n",
      "time/preback_zf (s)                     5.19168\n",
      "time/saving (s)                         0.0055505\n",
      "time/training (s)                       2.05327\n",
      "time/epoch (s)                         17.839\n",
      "time/total (s)                       1014.41\n",
      "Epoch                                  60\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:27:41.883053 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 61 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  72000\n",
      "trainer/ZF1 Loss                      506.627\n",
      "trainer/ZF2 Loss                      512.332\n",
      "trainer/ZF Expert Reward               24.0772\n",
      "trainer/ZF Policy Reward               -0.538137\n",
      "trainer/ZF CHI2 Term                  554.182\n",
      "trainer/Policy Loss                  -836.099\n",
      "trainer/Bias Loss                    4263.95\n",
      "trainer/Bias Value                     19.7473\n",
      "trainer/Policy Grad Norm              163.807\n",
      "trainer/Policy Param Norm              30.0281\n",
      "trainer/Zf1 Grad Norm                7355.42\n",
      "trainer/Zf1 Param Norm                 80.6243\n",
      "trainer/Zf2 Grad Norm                8445.25\n",
      "trainer/Zf2 Param Norm                 80.2434\n",
      "trainer/Z Expert Predictions Mean    1394.97\n",
      "trainer/Z Expert Predictions Std      172.551\n",
      "trainer/Z Expert Predictions Max     1715.34\n",
      "trainer/Z Expert Predictions Min      334.632\n",
      "trainer/Z Policy Predictions Mean     819.06\n",
      "trainer/Z Policy Predictions Std      538.683\n",
      "trainer/Z Policy Predictions Max     1712.28\n",
      "trainer/Z Policy Predictions Min     -204.527\n",
      "trainer/Z Expert Targets Mean        1370.89\n",
      "trainer/Z Expert Targets Std          193.842\n",
      "trainer/Z Expert Targets Max         1693.98\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         819.598\n",
      "trainer/Z Policy Targets Std          532.157\n",
      "trainer/Z Policy Targets Max         1696.73\n",
      "trainer/Z Policy Targets Min         -196.258\n",
      "trainer/Log Pis Mean                   20.2908\n",
      "trainer/Log Pis Std                     5.91264\n",
      "trainer/Policy mu Mean                  1.16852\n",
      "trainer/Policy mu Std                   2.03091\n",
      "trainer/Policy log std Mean            -2.33285\n",
      "trainer/Policy log std Std              1.11232\n",
      "trainer/Alpha                           0.0826901\n",
      "trainer/Alpha Loss                     -0.0240498\n",
      "exploration/num steps total         67430\n",
      "exploration/num paths total           646\n",
      "evaluation/num steps total         257031\n",
      "evaluation/num paths total            623\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.98898\n",
      "evaluation/Rewards Std                  1.28724\n",
      "evaluation/Rewards Max                  7.46934\n",
      "evaluation/Rewards Min                  0.0766835\n",
      "evaluation/Returns Mean              4988.98\n",
      "evaluation/Returns Std                116.705\n",
      "evaluation/Returns Max               5147.39\n",
      "evaluation/Returns Min               4794.73\n",
      "evaluation/Estimation Bias Mean      1331.47\n",
      "evaluation/Estimation Bias Std        208.446\n",
      "evaluation/EB/Q_True Mean              45.227\n",
      "evaluation/EB/Q_True Std              139.215\n",
      "evaluation/EB/Q_Pred Mean            1376.7\n",
      "evaluation/EB/Q_Pred Std              168.263\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4988.98\n",
      "evaluation/Actions Mean                 0.507744\n",
      "evaluation/Actions Std                  0.633661\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999932\n",
      "time/backward_policy (s)                1.98188\n",
      "time/backward_zf1 (s)                   2.12435\n",
      "time/backward_zf2 (s)                   2.09106\n",
      "time/data sampling (s)                  0.254826\n",
      "time/data storing (s)                   0.0145977\n",
      "time/evaluation sampling (s)            1.47632\n",
      "time/exploration sampling (s)           0.197267\n",
      "time/logging (s)                        0.0145411\n",
      "time/preback_alpha (s)                  1.06421\n",
      "time/preback_policy (s)                 1.22765\n",
      "time/preback_start (s)                  0.120903\n",
      "time/preback_zf (s)                     5.16443\n",
      "time/saving (s)                         0.0058829\n",
      "time/training (s)                       2.02453\n",
      "time/epoch (s)                         17.7624\n",
      "time/total (s)                       1032.2\n",
      "Epoch                                  61\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:27:59.490752 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 62 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  73000\n",
      "trainer/ZF1 Loss                      449.607\n",
      "trainer/ZF2 Loss                      475.538\n",
      "trainer/ZF Expert Reward               23.7799\n",
      "trainer/ZF Policy Reward               -1.04945\n",
      "trainer/ZF CHI2 Term                  506.578\n",
      "trainer/Policy Loss                  -899.068\n",
      "trainer/Bias Loss                     447.7\n",
      "trainer/Bias Value                     19.7942\n",
      "trainer/Policy Grad Norm              303.842\n",
      "trainer/Policy Param Norm              30.1238\n",
      "trainer/Zf1 Grad Norm                9217.39\n",
      "trainer/Zf1 Param Norm                 81.0428\n",
      "trainer/Zf2 Grad Norm                7272.96\n",
      "trainer/Zf2 Param Norm                 80.6234\n",
      "trainer/Z Expert Predictions Mean    1398.93\n",
      "trainer/Z Expert Predictions Std      178.357\n",
      "trainer/Z Expert Predictions Max     1735.75\n",
      "trainer/Z Expert Predictions Min      491.933\n",
      "trainer/Z Policy Predictions Mean     893.07\n",
      "trainer/Z Policy Predictions Std      548.023\n",
      "trainer/Z Policy Predictions Max     1719.97\n",
      "trainer/Z Policy Predictions Min     -172.661\n",
      "trainer/Z Expert Targets Mean        1375.16\n",
      "trainer/Z Expert Targets Std          181.383\n",
      "trainer/Z Expert Targets Max         1720.81\n",
      "trainer/Z Expert Targets Min          494.985\n",
      "trainer/Z Policy Targets Mean         894.12\n",
      "trainer/Z Policy Targets Std          544.661\n",
      "trainer/Z Policy Targets Max         1703.05\n",
      "trainer/Z Policy Targets Min         -197.485\n",
      "trainer/Log Pis Mean                   19.3695\n",
      "trainer/Log Pis Std                     5.60142\n",
      "trainer/Policy mu Mean                  1.15303\n",
      "trainer/Policy mu Std                   1.89056\n",
      "trainer/Policy log std Mean            -2.36025\n",
      "trainer/Policy log std Std              1.06854\n",
      "trainer/Alpha                           0.0833176\n",
      "trainer/Alpha Loss                      0.0525326\n",
      "exploration/num steps total         67430\n",
      "exploration/num paths total           646\n",
      "evaluation/num steps total         267031\n",
      "evaluation/num paths total            633\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.05855\n",
      "evaluation/Rewards Std                  1.29884\n",
      "evaluation/Rewards Max                  7.24694\n",
      "evaluation/Rewards Min                  0.0901408\n",
      "evaluation/Returns Mean              5058.55\n",
      "evaluation/Returns Std                 28.3306\n",
      "evaluation/Returns Max               5098.13\n",
      "evaluation/Returns Min               5009.31\n",
      "evaluation/Estimation Bias Mean      1392.74\n",
      "evaluation/Estimation Bias Std        194.29\n",
      "evaluation/EB/Q_True Mean              47.5667\n",
      "evaluation/EB/Q_True Std              147.149\n",
      "evaluation/EB/Q_Pred Mean            1440.3\n",
      "evaluation/EB/Q_Pred Std              126.503\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5058.55\n",
      "evaluation/Actions Mean                 0.510482\n",
      "evaluation/Actions Std                  0.640607\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999862\n",
      "time/backward_policy (s)                1.97845\n",
      "time/backward_zf1 (s)                   2.11118\n",
      "time/backward_zf2 (s)                   2.05717\n",
      "time/data sampling (s)                  0.25105\n",
      "time/data storing (s)                   0.0139707\n",
      "time/evaluation sampling (s)            1.40117\n",
      "time/exploration sampling (s)           0.190757\n",
      "time/logging (s)                        0.0150554\n",
      "time/preback_alpha (s)                  1.04837\n",
      "time/preback_policy (s)                 1.20908\n",
      "time/preback_start (s)                  0.119098\n",
      "time/preback_zf (s)                     5.12666\n",
      "time/saving (s)                         0.00541728\n",
      "time/training (s)                       2.01578\n",
      "time/epoch (s)                         17.5432\n",
      "time/total (s)                       1049.76\n",
      "Epoch                                  62\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:28:17.141825 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 63 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  74000\n",
      "trainer/ZF1 Loss                      124.115\n",
      "trainer/ZF2 Loss                      102.1\n",
      "trainer/ZF Expert Reward               26.0102\n",
      "trainer/ZF Policy Reward                0.405388\n",
      "trainer/ZF CHI2 Term                  158.391\n",
      "trainer/Policy Loss                  -874.215\n",
      "trainer/Bias Loss                     311.176\n",
      "trainer/Bias Value                     19.8397\n",
      "trainer/Policy Grad Norm              205.91\n",
      "trainer/Policy Param Norm              30.2148\n",
      "trainer/Zf1 Grad Norm                8600.88\n",
      "trainer/Zf1 Param Norm                 81.4891\n",
      "trainer/Zf2 Grad Norm                6542.17\n",
      "trainer/Zf2 Param Norm                 81.0219\n",
      "trainer/Z Expert Predictions Mean    1415.3\n",
      "trainer/Z Expert Predictions Std      153.779\n",
      "trainer/Z Expert Predictions Max     1748.58\n",
      "trainer/Z Expert Predictions Min      845.405\n",
      "trainer/Z Policy Predictions Mean     858.442\n",
      "trainer/Z Policy Predictions Std      530.23\n",
      "trainer/Z Policy Predictions Max     1735.37\n",
      "trainer/Z Policy Predictions Min     -150.932\n",
      "trainer/Z Expert Targets Mean        1389.29\n",
      "trainer/Z Expert Targets Std          156.448\n",
      "trainer/Z Expert Targets Max         1730.03\n",
      "trainer/Z Expert Targets Min          853.744\n",
      "trainer/Z Policy Targets Mean         858.037\n",
      "trainer/Z Policy Targets Std          527.247\n",
      "trainer/Z Policy Targets Max         1722.64\n",
      "trainer/Z Policy Targets Min         -157.703\n",
      "trainer/Log Pis Mean                   19.8773\n",
      "trainer/Log Pis Std                     6.28433\n",
      "trainer/Policy mu Mean                  1.24696\n",
      "trainer/Policy mu Std                   2.04546\n",
      "trainer/Policy log std Mean            -2.26697\n",
      "trainer/Policy log std Std              1.12352\n",
      "trainer/Alpha                           0.0839076\n",
      "trainer/Alpha Loss                      0.0102949\n",
      "exploration/num steps total         69430\n",
      "exploration/num paths total           648\n",
      "evaluation/num steps total         277031\n",
      "evaluation/num paths total            643\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.96372\n",
      "evaluation/Rewards Std                  1.27064\n",
      "evaluation/Rewards Max                  7.24721\n",
      "evaluation/Rewards Min                  0.150163\n",
      "evaluation/Returns Mean              4963.72\n",
      "evaluation/Returns Std                 44.4994\n",
      "evaluation/Returns Max               5028.31\n",
      "evaluation/Returns Min               4887.14\n",
      "evaluation/Estimation Bias Mean      1362.77\n",
      "evaluation/Estimation Bias Std        200.423\n",
      "evaluation/EB/Q_True Mean              46.3413\n",
      "evaluation/EB/Q_True Std              142.852\n",
      "evaluation/EB/Q_Pred Mean            1409.11\n",
      "evaluation/EB/Q_Pred Std              151.635\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4963.72\n",
      "evaluation/Actions Mean                 0.515156\n",
      "evaluation/Actions Std                  0.652327\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999809\n",
      "time/backward_policy (s)                1.9641\n",
      "time/backward_zf1 (s)                   2.08102\n",
      "time/backward_zf2 (s)                   2.05054\n",
      "time/data sampling (s)                  0.246741\n",
      "time/data storing (s)                   0.0142827\n",
      "time/evaluation sampling (s)            1.45765\n",
      "time/exploration sampling (s)           0.195888\n",
      "time/logging (s)                        0.0204882\n",
      "time/preback_alpha (s)                  1.05893\n",
      "time/preback_policy (s)                 1.21767\n",
      "time/preback_start (s)                  0.120021\n",
      "time/preback_zf (s)                     5.14639\n",
      "time/saving (s)                         0.00731239\n",
      "time/training (s)                       2.00735\n",
      "time/epoch (s)                         17.5884\n",
      "time/total (s)                       1067.37\n",
      "Epoch                                  63\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:28:34.374133 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 64 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  75000\n",
      "trainer/ZF1 Loss                       73.7824\n",
      "trainer/ZF2 Loss                       87.4598\n",
      "trainer/ZF Expert Reward               26.2854\n",
      "trainer/ZF Policy Reward                2.77398\n",
      "trainer/ZF CHI2 Term                  123.821\n",
      "trainer/Policy Loss                  -935.054\n",
      "trainer/Bias Loss                     414.372\n",
      "trainer/Bias Value                     19.8818\n",
      "trainer/Policy Grad Norm              261.173\n",
      "trainer/Policy Param Norm              30.3093\n",
      "trainer/Zf1 Grad Norm                5373.2\n",
      "trainer/Zf1 Param Norm                 81.9141\n",
      "trainer/Zf2 Grad Norm                7801.36\n",
      "trainer/Zf2 Param Norm                 81.4082\n",
      "trainer/Z Expert Predictions Mean    1424\n",
      "trainer/Z Expert Predictions Std      216.473\n",
      "trainer/Z Expert Predictions Max     1757.01\n",
      "trainer/Z Expert Predictions Min      342.867\n",
      "trainer/Z Policy Predictions Mean     912.481\n",
      "trainer/Z Policy Predictions Std      527.839\n",
      "trainer/Z Policy Predictions Max     1757.3\n",
      "trainer/Z Policy Predictions Min     -109.619\n",
      "trainer/Z Expert Targets Mean        1397.71\n",
      "trainer/Z Expert Targets Std          218.369\n",
      "trainer/Z Expert Targets Max         1742.47\n",
      "trainer/Z Expert Targets Min          315.253\n",
      "trainer/Z Policy Targets Mean         909.707\n",
      "trainer/Z Policy Targets Std          523.814\n",
      "trainer/Z Policy Targets Max         1744.03\n",
      "trainer/Z Policy Targets Min         -130.894\n",
      "trainer/Log Pis Mean                   19.8869\n",
      "trainer/Log Pis Std                     5.84692\n",
      "trainer/Policy mu Mean                  1.1284\n",
      "trainer/Policy mu Std                   1.93668\n",
      "trainer/Policy log std Mean            -2.3697\n",
      "trainer/Policy log std Std              1.07915\n",
      "trainer/Alpha                           0.0841318\n",
      "trainer/Alpha Loss                      0.00951578\n",
      "exploration/num steps total         71430\n",
      "exploration/num paths total           650\n",
      "evaluation/num steps total         287031\n",
      "evaluation/num paths total            653\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.02222\n",
      "evaluation/Rewards Std                  1.29822\n",
      "evaluation/Rewards Max                  7.16081\n",
      "evaluation/Rewards Min                  0.0862513\n",
      "evaluation/Returns Mean              5022.22\n",
      "evaluation/Returns Std                 62.3107\n",
      "evaluation/Returns Max               5126.3\n",
      "evaluation/Returns Min               4927.02\n",
      "evaluation/Estimation Bias Mean      1448.4\n",
      "evaluation/Estimation Bias Std        183.196\n",
      "evaluation/EB/Q_True Mean              46.4743\n",
      "evaluation/EB/Q_True Std              143.578\n",
      "evaluation/EB/Q_Pred Mean            1494.88\n",
      "evaluation/EB/Q_Pred Std              116.747\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5022.22\n",
      "evaluation/Actions Mean                 0.513139\n",
      "evaluation/Actions Std                  0.630475\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999794\n",
      "time/backward_policy (s)                1.7875\n",
      "time/backward_zf1 (s)                   1.93795\n",
      "time/backward_zf2 (s)                   1.86891\n",
      "time/data sampling (s)                  0.251012\n",
      "time/data storing (s)                   0.0141147\n",
      "time/evaluation sampling (s)            1.40504\n",
      "time/exploration sampling (s)           0.199254\n",
      "time/logging (s)                        0.0119818\n",
      "time/preback_alpha (s)                  0.89261\n",
      "time/preback_policy (s)                 0.990332\n",
      "time/preback_start (s)                  0.117883\n",
      "time/preback_zf (s)                     5.12403\n",
      "time/saving (s)                         0.00534523\n",
      "time/training (s)                       2.54145\n",
      "time/epoch (s)                         17.1474\n",
      "time/total (s)                       1084.54\n",
      "Epoch                                  64\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:28:51.397780 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 65 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  76000\n",
      "trainer/ZF1 Loss                      192.551\n",
      "trainer/ZF2 Loss                      125.255\n",
      "trainer/ZF Expert Reward               31.3942\n",
      "trainer/ZF Policy Reward                6.0547\n",
      "trainer/ZF CHI2 Term                  204.578\n",
      "trainer/Policy Loss                  -930.5\n",
      "trainer/Bias Loss                     435.975\n",
      "trainer/Bias Value                     19.9221\n",
      "trainer/Policy Grad Norm              213.403\n",
      "trainer/Policy Param Norm              30.3996\n",
      "trainer/Zf1 Grad Norm                8920.51\n",
      "trainer/Zf1 Param Norm                 82.349\n",
      "trainer/Zf2 Grad Norm                8884.25\n",
      "trainer/Zf2 Param Norm                 81.8033\n",
      "trainer/Z Expert Predictions Mean    1463.17\n",
      "trainer/Z Expert Predictions Std      179.955\n",
      "trainer/Z Expert Predictions Max     1776.61\n",
      "trainer/Z Expert Predictions Min      699.815\n",
      "trainer/Z Policy Predictions Mean     916.605\n",
      "trainer/Z Policy Predictions Std      542.196\n",
      "trainer/Z Policy Predictions Max     1759.05\n",
      "trainer/Z Policy Predictions Min     -273.276\n",
      "trainer/Z Expert Targets Mean        1431.78\n",
      "trainer/Z Expert Targets Std          186.802\n",
      "trainer/Z Expert Targets Max         1769.33\n",
      "trainer/Z Expert Targets Min          617.142\n",
      "trainer/Z Policy Targets Mean         910.55\n",
      "trainer/Z Policy Targets Std          536.275\n",
      "trainer/Z Policy Targets Max         1753.56\n",
      "trainer/Z Policy Targets Min         -309.901\n",
      "trainer/Log Pis Mean                   20.5406\n",
      "trainer/Log Pis Std                     6.19764\n",
      "trainer/Policy mu Mean                  1.16349\n",
      "trainer/Policy mu Std                   2.01653\n",
      "trainer/Policy log std Mean            -2.30679\n",
      "trainer/Policy log std Std              1.07793\n",
      "trainer/Alpha                           0.085763\n",
      "trainer/Alpha Loss                     -0.0463601\n",
      "exploration/num steps total         71430\n",
      "exploration/num paths total           650\n",
      "evaluation/num steps total         297031\n",
      "evaluation/num paths total            663\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.05586\n",
      "evaluation/Rewards Std                  1.33365\n",
      "evaluation/Rewards Max                  7.2978\n",
      "evaluation/Rewards Min                  0.0372404\n",
      "evaluation/Returns Mean              5055.86\n",
      "evaluation/Returns Std                 32.7663\n",
      "evaluation/Returns Max               5111.97\n",
      "evaluation/Returns Min               4999.22\n",
      "evaluation/Estimation Bias Mean      1458.09\n",
      "evaluation/Estimation Bias Std        196.516\n",
      "evaluation/EB/Q_True Mean              48.1728\n",
      "evaluation/EB/Q_True Std              148.743\n",
      "evaluation/EB/Q_Pred Mean            1506.26\n",
      "evaluation/EB/Q_Pred Std              128.57\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5055.86\n",
      "evaluation/Actions Mean                 0.510917\n",
      "evaluation/Actions Std                  0.627864\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999564\n",
      "time/backward_policy (s)                1.74879\n",
      "time/backward_zf1 (s)                   1.89392\n",
      "time/backward_zf2 (s)                   1.79999\n",
      "time/data sampling (s)                  0.246747\n",
      "time/data storing (s)                   0.0137348\n",
      "time/evaluation sampling (s)            1.45052\n",
      "time/exploration sampling (s)           0.18636\n",
      "time/logging (s)                        0.0195799\n",
      "time/preback_alpha (s)                  0.88404\n",
      "time/preback_policy (s)                 0.951521\n",
      "time/preback_start (s)                  0.115029\n",
      "time/preback_zf (s)                     5.12222\n",
      "time/saving (s)                         0.0232136\n",
      "time/training (s)                       2.51174\n",
      "time/epoch (s)                         16.9674\n",
      "time/total (s)                       1101.53\n",
      "Epoch                                  65\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:29:09.314471 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 66 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  77000\n",
      "trainer/ZF1 Loss                       83.4018\n",
      "trainer/ZF2 Loss                       94.2946\n",
      "trainer/ZF Expert Reward               14.5651\n",
      "trainer/ZF Policy Reward               -4.46177\n",
      "trainer/ZF CHI2 Term                  127.661\n",
      "trainer/Policy Loss                  -983.735\n",
      "trainer/Bias Loss                     322.092\n",
      "trainer/Bias Value                     19.9623\n",
      "trainer/Policy Grad Norm              262.627\n",
      "trainer/Policy Param Norm              30.4796\n",
      "trainer/Zf1 Grad Norm               10699.9\n",
      "trainer/Zf1 Param Norm                 82.7902\n",
      "trainer/Zf2 Grad Norm                9666.37\n",
      "trainer/Zf2 Param Norm                 82.2177\n",
      "trainer/Z Expert Predictions Mean    1479.94\n",
      "trainer/Z Expert Predictions Std      170.116\n",
      "trainer/Z Expert Predictions Max     1803.39\n",
      "trainer/Z Expert Predictions Min      640.698\n",
      "trainer/Z Policy Predictions Mean     959.409\n",
      "trainer/Z Policy Predictions Std      537.706\n",
      "trainer/Z Policy Predictions Max     1777.15\n",
      "trainer/Z Policy Predictions Min     -181.844\n",
      "trainer/Z Expert Targets Mean        1465.38\n",
      "trainer/Z Expert Targets Std          167.364\n",
      "trainer/Z Expert Targets Max         1785.89\n",
      "trainer/Z Expert Targets Min          634.53\n",
      "trainer/Z Policy Targets Mean         963.871\n",
      "trainer/Z Policy Targets Std          533.872\n",
      "trainer/Z Policy Targets Max         1771.97\n",
      "trainer/Z Policy Targets Min         -159.104\n",
      "trainer/Log Pis Mean                   19.9862\n",
      "trainer/Log Pis Std                     5.77869\n",
      "trainer/Policy mu Mean                  1.18761\n",
      "trainer/Policy mu Std                   1.94809\n",
      "trainer/Policy log std Mean            -2.4048\n",
      "trainer/Policy log std Std              1.1091\n",
      "trainer/Alpha                           0.0864964\n",
      "trainer/Alpha Loss                      0.00119261\n",
      "exploration/num steps total         73197\n",
      "exploration/num paths total           652\n",
      "evaluation/num steps total         307031\n",
      "evaluation/num paths total            673\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.99639\n",
      "evaluation/Rewards Std                  1.29194\n",
      "evaluation/Rewards Max                  7.17712\n",
      "evaluation/Rewards Min                  0.133494\n",
      "evaluation/Returns Mean              4996.39\n",
      "evaluation/Returns Std                 24.9088\n",
      "evaluation/Returns Max               5038.42\n",
      "evaluation/Returns Min               4962.67\n",
      "evaluation/Estimation Bias Mean      1452.93\n",
      "evaluation/Estimation Bias Std        195.728\n",
      "evaluation/EB/Q_True Mean              47.5668\n",
      "evaluation/EB/Q_True Std              146.864\n",
      "evaluation/EB/Q_Pred Mean            1500.5\n",
      "evaluation/EB/Q_Pred Std              129.488\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4996.39\n",
      "evaluation/Actions Mean                 0.524698\n",
      "evaluation/Actions Std                  0.623082\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999529\n",
      "time/backward_policy (s)                2.01052\n",
      "time/backward_zf1 (s)                   2.17586\n",
      "time/backward_zf2 (s)                   2.11913\n",
      "time/data sampling (s)                  0.245567\n",
      "time/data storing (s)                   0.0143905\n",
      "time/evaluation sampling (s)            1.46231\n",
      "time/exploration sampling (s)           0.198694\n",
      "time/logging (s)                        0.0156777\n",
      "time/preback_alpha (s)                  1.07024\n",
      "time/preback_policy (s)                 1.219\n",
      "time/preback_start (s)                  0.123556\n",
      "time/preback_zf (s)                     5.18012\n",
      "time/saving (s)                         0.00541811\n",
      "time/training (s)                       2.00548\n",
      "time/epoch (s)                         17.846\n",
      "time/total (s)                       1119.39\n",
      "Epoch                                  66\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:29:26.594251 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 67 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  78000\n",
      "trainer/ZF1 Loss                      126.228\n",
      "trainer/ZF2 Loss                      151.815\n",
      "trainer/ZF Expert Reward               16.2013\n",
      "trainer/ZF Policy Reward               -4.35024\n",
      "trainer/ZF CHI2 Term                  179.991\n",
      "trainer/Policy Loss                  -979.727\n",
      "trainer/Bias Loss                     283.922\n",
      "trainer/Bias Value                     19.999\n",
      "trainer/Policy Grad Norm              202.194\n",
      "trainer/Policy Param Norm              30.5583\n",
      "trainer/Zf1 Grad Norm                9303.29\n",
      "trainer/Zf1 Param Norm                 83.2497\n",
      "trainer/Zf2 Grad Norm               10104.5\n",
      "trainer/Zf2 Param Norm                 82.6194\n",
      "trainer/Z Expert Predictions Mean    1487.89\n",
      "trainer/Z Expert Predictions Std      167.057\n",
      "trainer/Z Expert Predictions Max     1799.39\n",
      "trainer/Z Expert Predictions Min      658.641\n",
      "trainer/Z Policy Predictions Mean     953.724\n",
      "trainer/Z Policy Predictions Std      537.696\n",
      "trainer/Z Policy Predictions Max     1795.88\n",
      "trainer/Z Policy Predictions Min     -322.759\n",
      "trainer/Z Expert Targets Mean        1471.69\n",
      "trainer/Z Expert Targets Std          165.304\n",
      "trainer/Z Expert Targets Max         1783.05\n",
      "trainer/Z Expert Targets Min          655.663\n",
      "trainer/Z Policy Targets Mean         958.074\n",
      "trainer/Z Policy Targets Std          534.913\n",
      "trainer/Z Policy Targets Max         1791.75\n",
      "trainer/Z Policy Targets Min         -342.042\n",
      "trainer/Log Pis Mean                   20.6235\n",
      "trainer/Log Pis Std                     5.56407\n",
      "trainer/Policy mu Mean                  1.24863\n",
      "trainer/Policy mu Std                   1.9671\n",
      "trainer/Policy log std Mean            -2.31613\n",
      "trainer/Policy log std Std              1.09789\n",
      "trainer/Alpha                           0.0867812\n",
      "trainer/Alpha Loss                     -0.0541117\n",
      "exploration/num steps total         73197\n",
      "exploration/num paths total           652\n",
      "evaluation/num steps total         317031\n",
      "evaluation/num paths total            683\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.04228\n",
      "evaluation/Rewards Std                  1.28785\n",
      "evaluation/Rewards Max                  7.21531\n",
      "evaluation/Rewards Min                  0.11624\n",
      "evaluation/Returns Mean              5042.28\n",
      "evaluation/Returns Std                 17.0185\n",
      "evaluation/Returns Max               5066.66\n",
      "evaluation/Returns Min               5016.51\n",
      "evaluation/Estimation Bias Mean      1491.99\n",
      "evaluation/Estimation Bias Std        189.844\n",
      "evaluation/EB/Q_True Mean              47.6307\n",
      "evaluation/EB/Q_True Std              147.026\n",
      "evaluation/EB/Q_Pred Mean            1539.62\n",
      "evaluation/EB/Q_Pred Std              117.928\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5042.28\n",
      "evaluation/Actions Mean                 0.50798\n",
      "evaluation/Actions Std                  0.640606\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999772\n",
      "time/backward_policy (s)                1.84329\n",
      "time/backward_zf1 (s)                   1.99335\n",
      "time/backward_zf2 (s)                   1.94271\n",
      "time/data sampling (s)                  0.245625\n",
      "time/data storing (s)                   0.0142437\n",
      "time/evaluation sampling (s)            1.38672\n",
      "time/exploration sampling (s)           0.195109\n",
      "time/logging (s)                        0.0120482\n",
      "time/preback_alpha (s)                  0.931965\n",
      "time/preback_policy (s)                 1.03766\n",
      "time/preback_start (s)                  0.118774\n",
      "time/preback_zf (s)                     5.1105\n",
      "time/saving (s)                         0.00777092\n",
      "time/training (s)                       2.36535\n",
      "time/epoch (s)                         17.2051\n",
      "time/total (s)                       1136.62\n",
      "Epoch                                  67\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:29:44.309557 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 68 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  79000\n",
      "trainer/ZF1 Loss                      125.317\n",
      "trainer/ZF2 Loss                      123.241\n",
      "trainer/ZF Expert Reward               18.6733\n",
      "trainer/ZF Policy Reward                3.75065\n",
      "trainer/ZF CHI2 Term                  158.823\n",
      "trainer/Policy Loss                  -945.201\n",
      "trainer/Bias Loss                     224.944\n",
      "trainer/Bias Value                     20.0334\n",
      "trainer/Policy Grad Norm              244.298\n",
      "trainer/Policy Param Norm              30.6297\n",
      "trainer/Zf1 Grad Norm                6899.61\n",
      "trainer/Zf1 Param Norm                 83.7098\n",
      "trainer/Zf2 Grad Norm                4807.8\n",
      "trainer/Zf2 Param Norm                 83.0265\n",
      "trainer/Z Expert Predictions Mean    1539.54\n",
      "trainer/Z Expert Predictions Std      135.787\n",
      "trainer/Z Expert Predictions Max     1804.72\n",
      "trainer/Z Expert Predictions Min      983.475\n",
      "trainer/Z Policy Predictions Mean     929.879\n",
      "trainer/Z Policy Predictions Std      552.989\n",
      "trainer/Z Policy Predictions Max     1796.17\n",
      "trainer/Z Policy Predictions Min     -209.817\n",
      "trainer/Z Expert Targets Mean        1520.86\n",
      "trainer/Z Expert Targets Std          133.021\n",
      "trainer/Z Expert Targets Max         1793.28\n",
      "trainer/Z Expert Targets Min          978.99\n",
      "trainer/Z Policy Targets Mean         926.128\n",
      "trainer/Z Policy Targets Std          549.649\n",
      "trainer/Z Policy Targets Max         1783.57\n",
      "trainer/Z Policy Targets Min         -263.033\n",
      "trainer/Log Pis Mean                   19.8187\n",
      "trainer/Log Pis Std                     6.18989\n",
      "trainer/Policy mu Mean                  1.20376\n",
      "trainer/Policy mu Std                   2.01187\n",
      "trainer/Policy log std Mean            -2.27716\n",
      "trainer/Policy log std Std              1.08844\n",
      "trainer/Alpha                           0.0869157\n",
      "trainer/Alpha Loss                      0.0157628\n",
      "exploration/num steps total         73197\n",
      "exploration/num paths total           652\n",
      "evaluation/num steps total         327031\n",
      "evaluation/num paths total            693\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.01805\n",
      "evaluation/Rewards Std                  1.27962\n",
      "evaluation/Rewards Max                  7.31795\n",
      "evaluation/Rewards Min                  0.144563\n",
      "evaluation/Returns Mean              5018.05\n",
      "evaluation/Returns Std                 27.8912\n",
      "evaluation/Returns Max               5059.05\n",
      "evaluation/Returns Min               4969.65\n",
      "evaluation/Estimation Bias Mean      1465.45\n",
      "evaluation/Estimation Bias Std        187.547\n",
      "evaluation/EB/Q_True Mean              46.8809\n",
      "evaluation/EB/Q_True Std              144.966\n",
      "evaluation/EB/Q_Pred Mean            1512.33\n",
      "evaluation/EB/Q_Pred Std              126.169\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5018.05\n",
      "evaluation/Actions Mean                 0.512874\n",
      "evaluation/Actions Std                  0.643718\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99992\n",
      "time/backward_policy (s)                1.9696\n",
      "time/backward_zf1 (s)                   2.08967\n",
      "time/backward_zf2 (s)                   2.04184\n",
      "time/data sampling (s)                  0.241702\n",
      "time/data storing (s)                   0.0152265\n",
      "time/evaluation sampling (s)            1.39956\n",
      "time/exploration sampling (s)           0.196012\n",
      "time/logging (s)                        0.0114213\n",
      "time/preback_alpha (s)                  1.02951\n",
      "time/preback_policy (s)                 1.16148\n",
      "time/preback_start (s)                  0.121194\n",
      "time/preback_zf (s)                     5.16811\n",
      "time/saving (s)                         0.00521128\n",
      "time/training (s)                       2.19723\n",
      "time/epoch (s)                         17.6478\n",
      "time/total (s)                       1154.29\n",
      "Epoch                                  68\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:30:02.374933 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 69 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  80000\n",
      "trainer/ZF1 Loss                      602.121\n",
      "trainer/ZF2 Loss                      553.43\n",
      "trainer/ZF Expert Reward               23.6535\n",
      "trainer/ZF Policy Reward                1.32105\n",
      "trainer/ZF CHI2 Term                  620.46\n",
      "trainer/Policy Loss                 -1014.52\n",
      "trainer/Bias Loss                    5054.65\n",
      "trainer/Bias Value                     20.0682\n",
      "trainer/Policy Grad Norm              368.991\n",
      "trainer/Policy Param Norm              30.7083\n",
      "trainer/Zf1 Grad Norm                7269.7\n",
      "trainer/Zf1 Param Norm                 84.1622\n",
      "trainer/Zf2 Grad Norm                7704.46\n",
      "trainer/Zf2 Param Norm                 83.4401\n",
      "trainer/Z Expert Predictions Mean    1528.73\n",
      "trainer/Z Expert Predictions Std      192.783\n",
      "trainer/Z Expert Predictions Max     1828.47\n",
      "trainer/Z Expert Predictions Min      554.828\n",
      "trainer/Z Policy Predictions Mean    1002.35\n",
      "trainer/Z Policy Predictions Std      551.426\n",
      "trainer/Z Policy Predictions Max     1824.49\n",
      "trainer/Z Policy Predictions Min     -242.232\n",
      "trainer/Z Expert Targets Mean        1505.08\n",
      "trainer/Z Expert Targets Std          213.446\n",
      "trainer/Z Expert Targets Max         1806.27\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1001.02\n",
      "trainer/Z Policy Targets Std          548.293\n",
      "trainer/Z Policy Targets Max         1799.4\n",
      "trainer/Z Policy Targets Min         -161.851\n",
      "trainer/Log Pis Mean                   20.558\n",
      "trainer/Log Pis Std                     5.20765\n",
      "trainer/Policy mu Mean                  1.18758\n",
      "trainer/Policy mu Std                   1.8796\n",
      "trainer/Policy log std Mean            -2.43699\n",
      "trainer/Policy log std Std              1.04766\n",
      "trainer/Alpha                           0.0866226\n",
      "trainer/Alpha Loss                     -0.0483306\n",
      "exploration/num steps total         74197\n",
      "exploration/num paths total           653\n",
      "evaluation/num steps total         337031\n",
      "evaluation/num paths total            703\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.96749\n",
      "evaluation/Rewards Std                  1.2581\n",
      "evaluation/Rewards Max                  7.09672\n",
      "evaluation/Rewards Min                  0.146363\n",
      "evaluation/Returns Mean              4967.49\n",
      "evaluation/Returns Std                 26.004\n",
      "evaluation/Returns Max               5024.05\n",
      "evaluation/Returns Min               4931.89\n",
      "evaluation/Estimation Bias Mean      1483.02\n",
      "evaluation/Estimation Bias Std        187.484\n",
      "evaluation/EB/Q_True Mean              47.0285\n",
      "evaluation/EB/Q_True Std              144.939\n",
      "evaluation/EB/Q_Pred Mean            1530.05\n",
      "evaluation/EB/Q_Pred Std              121.607\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4967.49\n",
      "evaluation/Actions Mean                 0.501352\n",
      "evaluation/Actions Std                  0.65253\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999842\n",
      "time/backward_policy (s)                2.06462\n",
      "time/backward_zf1 (s)                   2.20395\n",
      "time/backward_zf2 (s)                   2.16421\n",
      "time/data sampling (s)                  0.247952\n",
      "time/data storing (s)                   0.0150413\n",
      "time/evaluation sampling (s)            1.38295\n",
      "time/exploration sampling (s)           0.200074\n",
      "time/logging (s)                        0.0115377\n",
      "time/preback_alpha (s)                  1.07891\n",
      "time/preback_policy (s)                 1.25144\n",
      "time/preback_start (s)                  0.124127\n",
      "time/preback_zf (s)                     5.16467\n",
      "time/saving (s)                         0.00515559\n",
      "time/training (s)                       2.08172\n",
      "time/epoch (s)                         17.9964\n",
      "time/total (s)                       1172.31\n",
      "Epoch                                  69\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:30:20.137851 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 70 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  81000\n",
      "trainer/ZF1 Loss                       84.5372\n",
      "trainer/ZF2 Loss                       80.8407\n",
      "trainer/ZF Expert Reward               20.6683\n",
      "trainer/ZF Policy Reward               -3.94302\n",
      "trainer/ZF CHI2 Term                  127.586\n",
      "trainer/Policy Loss                  -993.436\n",
      "trainer/Bias Loss                     302.945\n",
      "trainer/Bias Value                     20.1021\n",
      "trainer/Policy Grad Norm              325.674\n",
      "trainer/Policy Param Norm              30.7895\n",
      "trainer/Zf1 Grad Norm                8884.33\n",
      "trainer/Zf1 Param Norm                 84.6527\n",
      "trainer/Zf2 Grad Norm               10538.6\n",
      "trainer/Zf2 Param Norm                 83.868\n",
      "trainer/Z Expert Predictions Mean    1563.74\n",
      "trainer/Z Expert Predictions Std      155.128\n",
      "trainer/Z Expert Predictions Max     1832.64\n",
      "trainer/Z Expert Predictions Min      886.148\n",
      "trainer/Z Policy Predictions Mean     974.172\n",
      "trainer/Z Policy Predictions Std      553.301\n",
      "trainer/Z Policy Predictions Max     1782\n",
      "trainer/Z Policy Predictions Min     -287.953\n",
      "trainer/Z Expert Targets Mean        1543.07\n",
      "trainer/Z Expert Targets Std          151.952\n",
      "trainer/Z Expert Targets Max         1810.27\n",
      "trainer/Z Expert Targets Min          848.393\n",
      "trainer/Z Policy Targets Mean         978.115\n",
      "trainer/Z Policy Targets Std          548.058\n",
      "trainer/Z Policy Targets Max         1814.9\n",
      "trainer/Z Policy Targets Min         -275.783\n",
      "trainer/Log Pis Mean                   20.4903\n",
      "trainer/Log Pis Std                     5.59626\n",
      "trainer/Policy mu Mean                  1.22701\n",
      "trainer/Policy mu Std                   2.02888\n",
      "trainer/Policy log std Mean            -2.21636\n",
      "trainer/Policy log std Std              1.10885\n",
      "trainer/Alpha                           0.0877463\n",
      "trainer/Alpha Loss                     -0.0430176\n",
      "exploration/num steps total         76197\n",
      "exploration/num paths total           655\n",
      "evaluation/num steps total         347031\n",
      "evaluation/num paths total            713\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20041\n",
      "evaluation/Rewards Std                  1.31771\n",
      "evaluation/Rewards Max                  7.35488\n",
      "evaluation/Rewards Min                  0.131572\n",
      "evaluation/Returns Mean              5200.41\n",
      "evaluation/Returns Std                 21.8766\n",
      "evaluation/Returns Max               5235.82\n",
      "evaluation/Returns Min               5157.43\n",
      "evaluation/Estimation Bias Mean      1573.84\n",
      "evaluation/Estimation Bias Std        193.278\n",
      "evaluation/EB/Q_True Mean              48.731\n",
      "evaluation/EB/Q_True Std              150.484\n",
      "evaluation/EB/Q_Pred Mean            1622.57\n",
      "evaluation/EB/Q_Pred Std              121.951\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5200.41\n",
      "evaluation/Actions Mean                 0.511863\n",
      "evaluation/Actions Std                  0.629694\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999871\n",
      "time/backward_policy (s)                1.97931\n",
      "time/backward_zf1 (s)                   2.12302\n",
      "time/backward_zf2 (s)                   2.06913\n",
      "time/data sampling (s)                  0.247219\n",
      "time/data storing (s)                   0.0145072\n",
      "time/evaluation sampling (s)            1.38735\n",
      "time/exploration sampling (s)           0.19784\n",
      "time/logging (s)                        0.0117082\n",
      "time/preback_alpha (s)                  1.03305\n",
      "time/preback_policy (s)                 1.19079\n",
      "time/preback_start (s)                  0.121534\n",
      "time/preback_zf (s)                     5.15181\n",
      "time/saving (s)                         0.00544128\n",
      "time/training (s)                       2.16245\n",
      "time/epoch (s)                         17.6952\n",
      "time/total (s)                       1190.02\n",
      "Epoch                                  70\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:30:37.934859 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 71 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  82000\n",
      "trainer/ZF1 Loss                       62.642\n",
      "trainer/ZF2 Loss                       55.6075\n",
      "trainer/ZF Expert Reward               25.3182\n",
      "trainer/ZF Policy Reward                6.30939\n",
      "trainer/ZF CHI2 Term                   97.0548\n",
      "trainer/Policy Loss                 -1050.97\n",
      "trainer/Bias Loss                     244.483\n",
      "trainer/Bias Value                     20.1357\n",
      "trainer/Policy Grad Norm              249.798\n",
      "trainer/Policy Param Norm              30.8642\n",
      "trainer/Zf1 Grad Norm                8074.25\n",
      "trainer/Zf1 Param Norm                 85.1343\n",
      "trainer/Zf2 Grad Norm                8421.57\n",
      "trainer/Zf2 Param Norm                 84.3062\n",
      "trainer/Z Expert Predictions Mean    1595.21\n",
      "trainer/Z Expert Predictions Std      142.429\n",
      "trainer/Z Expert Predictions Max     1845.61\n",
      "trainer/Z Expert Predictions Min      843.296\n",
      "trainer/Z Policy Predictions Mean    1033.03\n",
      "trainer/Z Policy Predictions Std      545.583\n",
      "trainer/Z Policy Predictions Max     1816.21\n",
      "trainer/Z Policy Predictions Min     -219.441\n",
      "trainer/Z Expert Targets Mean        1569.89\n",
      "trainer/Z Expert Targets Std          140.46\n",
      "trainer/Z Expert Targets Max         1825.25\n",
      "trainer/Z Expert Targets Min          864.095\n",
      "trainer/Z Policy Targets Mean        1026.72\n",
      "trainer/Z Policy Targets Std          539.204\n",
      "trainer/Z Policy Targets Max         1796.41\n",
      "trainer/Z Policy Targets Min         -237.391\n",
      "trainer/Log Pis Mean                   19.1123\n",
      "trainer/Log Pis Std                     4.92033\n",
      "trainer/Policy mu Mean                  1.22524\n",
      "trainer/Policy mu Std                   1.84681\n",
      "trainer/Policy log std Mean            -2.2446\n",
      "trainer/Policy log std Std              1.02418\n",
      "trainer/Alpha                           0.0906817\n",
      "trainer/Alpha Loss                      0.0804984\n",
      "exploration/num steps total         77197\n",
      "exploration/num paths total           656\n",
      "evaluation/num steps total         357031\n",
      "evaluation/num paths total            723\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18402\n",
      "evaluation/Rewards Std                  1.32169\n",
      "evaluation/Rewards Max                  7.34655\n",
      "evaluation/Rewards Min                  0.150499\n",
      "evaluation/Returns Mean              5184.02\n",
      "evaluation/Returns Std                 15.8201\n",
      "evaluation/Returns Max               5204.99\n",
      "evaluation/Returns Min               5154.2\n",
      "evaluation/Estimation Bias Mean      1534.67\n",
      "evaluation/Estimation Bias Std        208.163\n",
      "evaluation/EB/Q_True Mean              49.2161\n",
      "evaluation/EB/Q_True Std              152.001\n",
      "evaluation/EB/Q_Pred Mean            1583.88\n",
      "evaluation/EB/Q_Pred Std              141.298\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5184.02\n",
      "evaluation/Actions Mean                 0.490561\n",
      "evaluation/Actions Std                  0.642891\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999915\n",
      "time/backward_policy (s)                1.97004\n",
      "time/backward_zf1 (s)                   2.11847\n",
      "time/backward_zf2 (s)                   2.06497\n",
      "time/data sampling (s)                  0.254943\n",
      "time/data storing (s)                   0.0150274\n",
      "time/evaluation sampling (s)            1.39757\n",
      "time/exploration sampling (s)           0.196801\n",
      "time/logging (s)                        0.0120964\n",
      "time/preback_alpha (s)                  1.02819\n",
      "time/preback_policy (s)                 1.16531\n",
      "time/preback_start (s)                  0.122437\n",
      "time/preback_zf (s)                     5.18099\n",
      "time/saving (s)                         0.00533022\n",
      "time/training (s)                       2.19518\n",
      "time/epoch (s)                         17.7274\n",
      "time/total (s)                       1207.77\n",
      "Epoch                                  71\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:30:55.080944 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 72 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  83000\n",
      "trainer/ZF1 Loss                      125.876\n",
      "trainer/ZF2 Loss                       90.406\n",
      "trainer/ZF Expert Reward               16.8733\n",
      "trainer/ZF Policy Reward               -4.17036\n",
      "trainer/ZF CHI2 Term                  148.734\n",
      "trainer/Policy Loss                 -1079.78\n",
      "trainer/Bias Loss                     225.853\n",
      "trainer/Bias Value                     20.1668\n",
      "trainer/Policy Grad Norm              223.206\n",
      "trainer/Policy Param Norm              30.9449\n",
      "trainer/Zf1 Grad Norm                5249.75\n",
      "trainer/Zf1 Param Norm                 85.5595\n",
      "trainer/Zf2 Grad Norm                7563.74\n",
      "trainer/Zf2 Param Norm                 84.711\n",
      "trainer/Z Expert Predictions Mean    1585.3\n",
      "trainer/Z Expert Predictions Std      172.975\n",
      "trainer/Z Expert Predictions Max     1821.78\n",
      "trainer/Z Expert Predictions Min      665.955\n",
      "trainer/Z Policy Predictions Mean    1057.56\n",
      "trainer/Z Policy Predictions Std      565.217\n",
      "trainer/Z Policy Predictions Max     1808.96\n",
      "trainer/Z Policy Predictions Min     -244.339\n",
      "trainer/Z Expert Targets Mean        1568.43\n",
      "trainer/Z Expert Targets Std          171.239\n",
      "trainer/Z Expert Targets Max         1808.99\n",
      "trainer/Z Expert Targets Min          668.409\n",
      "trainer/Z Policy Targets Mean        1061.73\n",
      "trainer/Z Policy Targets Std          562.343\n",
      "trainer/Z Policy Targets Max         1815.67\n",
      "trainer/Z Policy Targets Min         -224.31\n",
      "trainer/Log Pis Mean                   19.7464\n",
      "trainer/Log Pis Std                     5.49427\n",
      "trainer/Policy mu Mean                  1.27683\n",
      "trainer/Policy mu Std                   1.85653\n",
      "trainer/Policy log std Mean            -2.31801\n",
      "trainer/Policy log std Std              1.06843\n",
      "trainer/Alpha                           0.0907175\n",
      "trainer/Alpha Loss                      0.0230053\n",
      "exploration/num steps total         77197\n",
      "exploration/num paths total           656\n",
      "evaluation/num steps total         367031\n",
      "evaluation/num paths total            733\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20763\n",
      "evaluation/Rewards Std                  1.34194\n",
      "evaluation/Rewards Max                  7.41549\n",
      "evaluation/Rewards Min                  0.104888\n",
      "evaluation/Returns Mean              5207.63\n",
      "evaluation/Returns Std                 12.9278\n",
      "evaluation/Returns Max               5232.44\n",
      "evaluation/Returns Min               5190.62\n",
      "evaluation/Estimation Bias Mean      1608.04\n",
      "evaluation/Estimation Bias Std        184.379\n",
      "evaluation/EB/Q_True Mean              49.128\n",
      "evaluation/EB/Q_True Std              151.584\n",
      "evaluation/EB/Q_Pred Mean            1657.16\n",
      "evaluation/EB/Q_Pred Std              112.685\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5207.63\n",
      "evaluation/Actions Mean                 0.513743\n",
      "evaluation/Actions Std                  0.626535\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999785\n",
      "time/backward_policy (s)                1.7489\n",
      "time/backward_zf1 (s)                   1.89441\n",
      "time/backward_zf2 (s)                   1.80128\n",
      "time/data sampling (s)                  0.249818\n",
      "time/data storing (s)                   0.0142274\n",
      "time/evaluation sampling (s)            1.51781\n",
      "time/exploration sampling (s)           0.190385\n",
      "time/logging (s)                        0.0142714\n",
      "time/preback_alpha (s)                  0.88575\n",
      "time/preback_policy (s)                 0.954838\n",
      "time/preback_start (s)                  0.119212\n",
      "time/preback_zf (s)                     5.12272\n",
      "time/saving (s)                         0.00536923\n",
      "time/training (s)                       2.56107\n",
      "time/epoch (s)                         17.0801\n",
      "time/total (s)                       1224.88\n",
      "Epoch                                  72\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:31:12.834770 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 73 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  84000\n",
      "trainer/ZF1 Loss                      118.5\n",
      "trainer/ZF2 Loss                       91.5976\n",
      "trainer/ZF Expert Reward               31.4842\n",
      "trainer/ZF Policy Reward                8.33337\n",
      "trainer/ZF CHI2 Term                  148.221\n",
      "trainer/Policy Loss                 -1083.41\n",
      "trainer/Bias Loss                     318.444\n",
      "trainer/Bias Value                     20.1974\n",
      "trainer/Policy Grad Norm              270.182\n",
      "trainer/Policy Param Norm              31.0326\n",
      "trainer/Zf1 Grad Norm                7533.89\n",
      "trainer/Zf1 Param Norm                 85.9718\n",
      "trainer/Zf2 Grad Norm                7148.68\n",
      "trainer/Zf2 Param Norm                 85.0852\n",
      "trainer/Z Expert Predictions Mean    1614.6\n",
      "trainer/Z Expert Predictions Std      185.255\n",
      "trainer/Z Expert Predictions Max     1818.57\n",
      "trainer/Z Expert Predictions Min      484.226\n",
      "trainer/Z Policy Predictions Mean    1065.95\n",
      "trainer/Z Policy Predictions Std      576.905\n",
      "trainer/Z Policy Predictions Max     1837.68\n",
      "trainer/Z Policy Predictions Min     -234.682\n",
      "trainer/Z Expert Targets Mean        1583.11\n",
      "trainer/Z Expert Targets Std          188.716\n",
      "trainer/Z Expert Targets Max         1797.54\n",
      "trainer/Z Expert Targets Min          471.858\n",
      "trainer/Z Policy Targets Mean        1057.61\n",
      "trainer/Z Policy Targets Std          571.663\n",
      "trainer/Z Policy Targets Max         1815.38\n",
      "trainer/Z Policy Targets Min         -251.705\n",
      "trainer/Log Pis Mean                   20.2241\n",
      "trainer/Log Pis Std                     5.81897\n",
      "trainer/Policy mu Mean                  1.22495\n",
      "trainer/Policy mu Std                   1.96102\n",
      "trainer/Policy log std Mean            -2.27382\n",
      "trainer/Policy log std Std              1.12124\n",
      "trainer/Alpha                           0.0893132\n",
      "trainer/Alpha Loss                     -0.0200187\n",
      "exploration/num steps total         79197\n",
      "exploration/num paths total           658\n",
      "evaluation/num steps total         377031\n",
      "evaluation/num paths total            743\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07612\n",
      "evaluation/Rewards Std                  1.28147\n",
      "evaluation/Rewards Max                  7.25178\n",
      "evaluation/Rewards Min                  0.103278\n",
      "evaluation/Returns Mean              5076.12\n",
      "evaluation/Returns Std                 20.7711\n",
      "evaluation/Returns Max               5120.15\n",
      "evaluation/Returns Min               5038.67\n",
      "evaluation/Estimation Bias Mean      1538.08\n",
      "evaluation/Estimation Bias Std        211.934\n",
      "evaluation/EB/Q_True Mean              47.9999\n",
      "evaluation/EB/Q_True Std              148.286\n",
      "evaluation/EB/Q_Pred Mean            1586.08\n",
      "evaluation/EB/Q_Pred Std              149.017\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5076.12\n",
      "evaluation/Actions Mean                 0.487729\n",
      "evaluation/Actions Std                  0.639241\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999937\n",
      "time/backward_policy (s)                1.97148\n",
      "time/backward_zf1 (s)                   2.11344\n",
      "time/backward_zf2 (s)                   2.05996\n",
      "time/data sampling (s)                  0.249153\n",
      "time/data storing (s)                   0.0143827\n",
      "time/evaluation sampling (s)            1.48127\n",
      "time/exploration sampling (s)           0.197061\n",
      "time/logging (s)                        0.0117992\n",
      "time/preback_alpha (s)                  1.05172\n",
      "time/preback_policy (s)                 1.20411\n",
      "time/preback_start (s)                  0.118992\n",
      "time/preback_zf (s)                     5.14044\n",
      "time/saving (s)                         0.00519628\n",
      "time/training (s)                       2.06291\n",
      "time/epoch (s)                         17.6819\n",
      "time/total (s)                       1242.58\n",
      "Epoch                                  73\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:31:30.820905 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 74 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  85000\n",
      "trainer/ZF1 Loss                      105.922\n",
      "trainer/ZF2 Loss                       77.8089\n",
      "trainer/ZF Expert Reward               19.8064\n",
      "trainer/ZF Policy Reward                2.25647\n",
      "trainer/ZF CHI2 Term                  128.773\n",
      "trainer/Policy Loss                 -1100.99\n",
      "trainer/Bias Loss                     406.414\n",
      "trainer/Bias Value                     20.2258\n",
      "trainer/Policy Grad Norm              239.602\n",
      "trainer/Policy Param Norm              31.1212\n",
      "trainer/Zf1 Grad Norm                7761.08\n",
      "trainer/Zf1 Param Norm                 86.3734\n",
      "trainer/Zf2 Grad Norm                8599.84\n",
      "trainer/Zf2 Param Norm                 85.4703\n",
      "trainer/Z Expert Predictions Mean    1617.24\n",
      "trainer/Z Expert Predictions Std      152.346\n",
      "trainer/Z Expert Predictions Max     1841.21\n",
      "trainer/Z Expert Predictions Min      937.864\n",
      "trainer/Z Policy Predictions Mean    1085.16\n",
      "trainer/Z Policy Predictions Std      552.746\n",
      "trainer/Z Policy Predictions Max     1814.37\n",
      "trainer/Z Policy Predictions Min     -192.207\n",
      "trainer/Z Expert Targets Mean        1597.43\n",
      "trainer/Z Expert Targets Std          160.083\n",
      "trainer/Z Expert Targets Max         1822.55\n",
      "trainer/Z Expert Targets Min          856.303\n",
      "trainer/Z Policy Targets Mean        1082.91\n",
      "trainer/Z Policy Targets Std          554.965\n",
      "trainer/Z Policy Targets Max         1811.01\n",
      "trainer/Z Policy Targets Min         -197.267\n",
      "trainer/Log Pis Mean                   19.5538\n",
      "trainer/Log Pis Std                     5.50243\n",
      "trainer/Policy mu Mean                  1.14662\n",
      "trainer/Policy mu Std                   1.98312\n",
      "trainer/Policy log std Mean            -2.22601\n",
      "trainer/Policy log std Std              1.06527\n",
      "trainer/Alpha                           0.0892429\n",
      "trainer/Alpha Loss                      0.039826\n",
      "exploration/num steps total         81197\n",
      "exploration/num paths total           660\n",
      "evaluation/num steps total         387031\n",
      "evaluation/num paths total            753\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16802\n",
      "evaluation/Rewards Std                  1.30076\n",
      "evaluation/Rewards Max                  7.19389\n",
      "evaluation/Rewards Min                  0.114189\n",
      "evaluation/Returns Mean              5168.02\n",
      "evaluation/Returns Std                 20.7105\n",
      "evaluation/Returns Max               5198.53\n",
      "evaluation/Returns Min               5137.58\n",
      "evaluation/Estimation Bias Mean      1582.94\n",
      "evaluation/Estimation Bias Std        189.843\n",
      "evaluation/EB/Q_True Mean              48.8454\n",
      "evaluation/EB/Q_True Std              151.002\n",
      "evaluation/EB/Q_Pred Mean            1631.78\n",
      "evaluation/EB/Q_Pred Std              116.587\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5168.02\n",
      "evaluation/Actions Mean                 0.476789\n",
      "evaluation/Actions Std                  0.643358\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999962\n",
      "time/backward_policy (s)                2.05138\n",
      "time/backward_zf1 (s)                   2.19096\n",
      "time/backward_zf2 (s)                   2.15707\n",
      "time/data sampling (s)                  0.252395\n",
      "time/data storing (s)                   0.014834\n",
      "time/evaluation sampling (s)            1.39703\n",
      "time/exploration sampling (s)           0.201327\n",
      "time/logging (s)                        0.0117506\n",
      "time/preback_alpha (s)                  1.06105\n",
      "time/preback_policy (s)                 1.22738\n",
      "time/preback_start (s)                  0.121187\n",
      "time/preback_zf (s)                     5.13686\n",
      "time/saving (s)                         0.00539495\n",
      "time/training (s)                       2.08853\n",
      "time/epoch (s)                         17.9172\n",
      "time/total (s)                       1260.52\n",
      "Epoch                                  74\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:31:48.607292 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 75 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  86000\n",
      "trainer/ZF1 Loss                      644.314\n",
      "trainer/ZF2 Loss                      638.62\n",
      "trainer/ZF Expert Reward               20.1636\n",
      "trainer/ZF Policy Reward               -6.55376\n",
      "trainer/ZF CHI2 Term                  688.258\n",
      "trainer/Policy Loss                 -1090.14\n",
      "trainer/Bias Loss                    5891.21\n",
      "trainer/Bias Value                     20.2524\n",
      "trainer/Policy Grad Norm              285.35\n",
      "trainer/Policy Param Norm              31.2101\n",
      "trainer/Zf1 Grad Norm                9900.11\n",
      "trainer/Zf1 Param Norm                 86.7909\n",
      "trainer/Zf2 Grad Norm                9839.85\n",
      "trainer/Zf2 Param Norm                 85.8512\n",
      "trainer/Z Expert Predictions Mean    1622.48\n",
      "trainer/Z Expert Predictions Std      172.988\n",
      "trainer/Z Expert Predictions Max     1837.03\n",
      "trainer/Z Expert Predictions Min      824.577\n",
      "trainer/Z Policy Predictions Mean    1071.35\n",
      "trainer/Z Policy Predictions Std      551.5\n",
      "trainer/Z Policy Predictions Max     1810.24\n",
      "trainer/Z Policy Predictions Min     -180.792\n",
      "trainer/Z Expert Targets Mean        1602.32\n",
      "trainer/Z Expert Targets Std          196.42\n",
      "trainer/Z Expert Targets Max         1817.29\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1077.9\n",
      "trainer/Z Policy Targets Std          548.546\n",
      "trainer/Z Policy Targets Max         1806.61\n",
      "trainer/Z Policy Targets Min         -208.927\n",
      "trainer/Log Pis Mean                   20.2762\n",
      "trainer/Log Pis Std                     5.5185\n",
      "trainer/Policy mu Mean                  1.2333\n",
      "trainer/Policy mu Std                   1.96122\n",
      "trainer/Policy log std Mean            -2.31266\n",
      "trainer/Policy log std Std              1.07608\n",
      "trainer/Alpha                           0.0905145\n",
      "trainer/Alpha Loss                     -0.0249945\n",
      "exploration/num steps total         81197\n",
      "exploration/num paths total           660\n",
      "evaluation/num steps total         397031\n",
      "evaluation/num paths total            763\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20024\n",
      "evaluation/Rewards Std                  1.35115\n",
      "evaluation/Rewards Max                  7.3954\n",
      "evaluation/Rewards Min                  0.0583289\n",
      "evaluation/Returns Mean              5200.24\n",
      "evaluation/Returns Std                 50.0367\n",
      "evaluation/Returns Max               5283.11\n",
      "evaluation/Returns Min               5109.81\n",
      "evaluation/Estimation Bias Mean      1593.68\n",
      "evaluation/Estimation Bias Std        199.1\n",
      "evaluation/EB/Q_True Mean              49.4338\n",
      "evaluation/EB/Q_True Std              152.308\n",
      "evaluation/EB/Q_Pred Mean            1643.11\n",
      "evaluation/EB/Q_Pred Std              121.17\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5200.24\n",
      "evaluation/Actions Mean                 0.502098\n",
      "evaluation/Actions Std                  0.637941\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999985\n",
      "time/backward_policy (s)                1.95546\n",
      "time/backward_zf1 (s)                   2.10599\n",
      "time/backward_zf2 (s)                   2.03949\n",
      "time/data sampling (s)                  0.261783\n",
      "time/data storing (s)                   0.0137972\n",
      "time/evaluation sampling (s)            1.41333\n",
      "time/exploration sampling (s)           0.187961\n",
      "time/logging (s)                        0.011731\n",
      "time/preback_alpha (s)                  1.04215\n",
      "time/preback_policy (s)                 1.16792\n",
      "time/preback_start (s)                  0.121557\n",
      "time/preback_zf (s)                     5.19006\n",
      "time/saving (s)                         0.00527047\n",
      "time/training (s)                       2.2036\n",
      "time/epoch (s)                         17.7201\n",
      "time/total (s)                       1278.26\n",
      "Epoch                                  75\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:32:06.466255 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 76 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                  87000\n",
      "trainer/ZF1 Loss                       85.4968\n",
      "trainer/ZF2 Loss                       89.7467\n",
      "trainer/ZF Expert Reward               19.9238\n",
      "trainer/ZF Policy Reward               -5.53359\n",
      "trainer/ZF CHI2 Term                  132.871\n",
      "trainer/Policy Loss                 -1123.85\n",
      "trainer/Bias Loss                     237.489\n",
      "trainer/Bias Value                     20.2779\n",
      "trainer/Policy Grad Norm              232.257\n",
      "trainer/Policy Param Norm              31.2986\n",
      "trainer/Zf1 Grad Norm                5921.32\n",
      "trainer/Zf1 Param Norm                 87.2114\n",
      "trainer/Zf2 Grad Norm               10277\n",
      "trainer/Zf2 Param Norm                 86.248\n",
      "trainer/Z Expert Predictions Mean    1640.08\n",
      "trainer/Z Expert Predictions Std      160.868\n",
      "trainer/Z Expert Predictions Max     1861.49\n",
      "trainer/Z Expert Predictions Min      833.435\n",
      "trainer/Z Policy Predictions Mean    1101.64\n",
      "trainer/Z Policy Predictions Std      558.426\n",
      "trainer/Z Policy Predictions Max     1791.93\n",
      "trainer/Z Policy Predictions Min     -218.367\n",
      "trainer/Z Expert Targets Mean        1620.15\n",
      "trainer/Z Expert Targets Std          161.239\n",
      "trainer/Z Expert Targets Max         1843.27\n",
      "trainer/Z Expert Targets Min          789.634\n",
      "trainer/Z Policy Targets Mean        1107.18\n",
      "trainer/Z Policy Targets Std          547.988\n",
      "trainer/Z Policy Targets Max         1787.13\n",
      "trainer/Z Policy Targets Min         -194.409\n",
      "trainer/Log Pis Mean                   19.9915\n",
      "trainer/Log Pis Std                     5.51654\n",
      "trainer/Policy mu Mean                  1.22411\n",
      "trainer/Policy mu Std                   1.93928\n",
      "trainer/Policy log std Mean            -2.30742\n",
      "trainer/Policy log std Std              1.06533\n",
      "trainer/Alpha                           0.0914653\n",
      "trainer/Alpha Loss                      0.000780597\n",
      "exploration/num steps total         83197\n",
      "exploration/num paths total           662\n",
      "evaluation/num steps total         407031\n",
      "evaluation/num paths total            773\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.02996\n",
      "evaluation/Rewards Std                  1.27265\n",
      "evaluation/Rewards Max                  7.26157\n",
      "evaluation/Rewards Min                  0.103091\n",
      "evaluation/Returns Mean              5029.96\n",
      "evaluation/Returns Std                 25.5281\n",
      "evaluation/Returns Max               5080.74\n",
      "evaluation/Returns Min               4991.63\n",
      "evaluation/Estimation Bias Mean      1607.41\n",
      "evaluation/Estimation Bias Std        185.452\n",
      "evaluation/EB/Q_True Mean              47.4932\n",
      "evaluation/EB/Q_True Std              146.713\n",
      "evaluation/EB/Q_Pred Mean            1654.91\n",
      "evaluation/EB/Q_Pred Std              121.216\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5029.96\n",
      "evaluation/Actions Mean                 0.497042\n",
      "evaluation/Actions Std                  0.635316\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999967\n",
      "time/backward_policy (s)                2.02336\n",
      "time/backward_zf1 (s)                   2.15624\n",
      "time/backward_zf2 (s)                   2.09673\n",
      "time/data sampling (s)                  0.259501\n",
      "time/data storing (s)                   0.0147784\n",
      "time/evaluation sampling (s)            1.4435\n",
      "time/exploration sampling (s)           0.199079\n",
      "time/logging (s)                        0.0123947\n",
      "time/preback_alpha (s)                  1.06818\n",
      "time/preback_policy (s)                 1.22652\n",
      "time/preback_start (s)                  0.122678\n",
      "time/preback_zf (s)                     5.13774\n",
      "time/saving (s)                         0.00532199\n",
      "time/training (s)                       2.02359\n",
      "time/epoch (s)                         17.7896\n",
      "time/total (s)                       1296.07\n",
      "Epoch                                  76\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:32:23.531609 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 77 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  88000\n",
      "trainer/ZF1 Loss                       70.6931\n",
      "trainer/ZF2 Loss                       64.0876\n",
      "trainer/ZF Expert Reward               22.5686\n",
      "trainer/ZF Policy Reward                1.02474\n",
      "trainer/ZF CHI2 Term                  108.532\n",
      "trainer/Policy Loss                 -1169.52\n",
      "trainer/Bias Loss                     280.475\n",
      "trainer/Bias Value                     20.3036\n",
      "trainer/Policy Grad Norm              208.75\n",
      "trainer/Policy Param Norm              31.3854\n",
      "trainer/Zf1 Grad Norm                7827.49\n",
      "trainer/Zf1 Param Norm                 87.6217\n",
      "trainer/Zf2 Grad Norm                7858.96\n",
      "trainer/Zf2 Param Norm                 86.6369\n",
      "trainer/Z Expert Predictions Mean    1650.12\n",
      "trainer/Z Expert Predictions Std      176.733\n",
      "trainer/Z Expert Predictions Max     1870.67\n",
      "trainer/Z Expert Predictions Min      794.816\n",
      "trainer/Z Policy Predictions Mean    1162.12\n",
      "trainer/Z Policy Predictions Std      547.038\n",
      "trainer/Z Policy Predictions Max     1779.71\n",
      "trainer/Z Policy Predictions Min     -189.596\n",
      "trainer/Z Expert Targets Mean        1627.55\n",
      "trainer/Z Expert Targets Std          175.732\n",
      "trainer/Z Expert Targets Max         1849.45\n",
      "trainer/Z Expert Targets Min          736.953\n",
      "trainer/Z Policy Targets Mean        1161.09\n",
      "trainer/Z Policy Targets Std          536.374\n",
      "trainer/Z Policy Targets Max         1767.54\n",
      "trainer/Z Policy Targets Min         -183.467\n",
      "trainer/Log Pis Mean                   19.7962\n",
      "trainer/Log Pis Std                     6.31104\n",
      "trainer/Policy mu Mean                  1.16437\n",
      "trainer/Policy mu Std                   1.99216\n",
      "trainer/Policy log std Mean            -2.32117\n",
      "trainer/Policy log std Std              1.03869\n",
      "trainer/Alpha                           0.0910425\n",
      "trainer/Alpha Loss                      0.0185588\n",
      "exploration/num steps total         83197\n",
      "exploration/num paths total           662\n",
      "evaluation/num steps total         417031\n",
      "evaluation/num paths total            783\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10527\n",
      "evaluation/Rewards Std                  1.32165\n",
      "evaluation/Rewards Max                  7.35559\n",
      "evaluation/Rewards Min                  0.0786231\n",
      "evaluation/Returns Mean              5105.27\n",
      "evaluation/Returns Std                 30.2314\n",
      "evaluation/Returns Max               5156.13\n",
      "evaluation/Returns Min               5072.55\n",
      "evaluation/Estimation Bias Mean      1619.42\n",
      "evaluation/Estimation Bias Std        189.462\n",
      "evaluation/EB/Q_True Mean              48.4792\n",
      "evaluation/EB/Q_True Std              149.849\n",
      "evaluation/EB/Q_Pred Mean            1667.9\n",
      "evaluation/EB/Q_Pred Std              115.203\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5105.27\n",
      "evaluation/Actions Mean                 0.485002\n",
      "evaluation/Actions Std                  0.640001\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999987\n",
      "time/backward_policy (s)                1.76096\n",
      "time/backward_zf1 (s)                   1.89672\n",
      "time/backward_zf2 (s)                   1.84369\n",
      "time/data sampling (s)                  0.249481\n",
      "time/data storing (s)                   0.0145165\n",
      "time/evaluation sampling (s)            1.38444\n",
      "time/exploration sampling (s)           0.190623\n",
      "time/logging (s)                        0.0117065\n",
      "time/preback_alpha (s)                  0.88946\n",
      "time/preback_policy (s)                 0.977608\n",
      "time/preback_start (s)                  0.118818\n",
      "time/preback_zf (s)                     5.11233\n",
      "time/saving (s)                         0.00532026\n",
      "time/training (s)                       2.542\n",
      "time/epoch (s)                         16.9977\n",
      "time/total (s)                       1313.09\n",
      "Epoch                                  77\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:32:41.223853 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 78 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  89000\n",
      "trainer/ZF1 Loss                      112.535\n",
      "trainer/ZF2 Loss                       92.6381\n",
      "trainer/ZF Expert Reward               19.5186\n",
      "trainer/ZF Policy Reward               -2.21011\n",
      "trainer/ZF CHI2 Term                  143.876\n",
      "trainer/Policy Loss                 -1114.49\n",
      "trainer/Bias Loss                     348.389\n",
      "trainer/Bias Value                     20.3269\n",
      "trainer/Policy Grad Norm              291.747\n",
      "trainer/Policy Param Norm              31.4756\n",
      "trainer/Zf1 Grad Norm                5933.14\n",
      "trainer/Zf1 Param Norm                 88.0246\n",
      "trainer/Zf2 Grad Norm                5580.19\n",
      "trainer/Zf2 Param Norm                 87.0361\n",
      "trainer/Z Expert Predictions Mean    1659.78\n",
      "trainer/Z Expert Predictions Std      157.99\n",
      "trainer/Z Expert Predictions Max     1866.07\n",
      "trainer/Z Expert Predictions Min      975.686\n",
      "trainer/Z Policy Predictions Mean    1098.59\n",
      "trainer/Z Policy Predictions Std      607.968\n",
      "trainer/Z Policy Predictions Max     1787.72\n",
      "trainer/Z Policy Predictions Min     -199.776\n",
      "trainer/Z Expert Targets Mean        1640.26\n",
      "trainer/Z Expert Targets Std          159.414\n",
      "trainer/Z Expert Targets Max         1855.01\n",
      "trainer/Z Expert Targets Min          922.169\n",
      "trainer/Z Policy Targets Mean        1100.8\n",
      "trainer/Z Policy Targets Std          602.438\n",
      "trainer/Z Policy Targets Max         1775.2\n",
      "trainer/Z Policy Targets Min         -193.053\n",
      "trainer/Log Pis Mean                   19.758\n",
      "trainer/Log Pis Std                     5.56282\n",
      "trainer/Policy mu Mean                  1.12032\n",
      "trainer/Policy mu Std                   1.99434\n",
      "trainer/Policy log std Mean            -2.3183\n",
      "trainer/Policy log std Std              1.05754\n",
      "trainer/Alpha                           0.0920342\n",
      "trainer/Alpha Loss                      0.0222676\n",
      "exploration/num steps total         83197\n",
      "exploration/num paths total           662\n",
      "evaluation/num steps total         427031\n",
      "evaluation/num paths total            793\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15482\n",
      "evaluation/Rewards Std                  1.32009\n",
      "evaluation/Rewards Max                  7.32872\n",
      "evaluation/Rewards Min                  0.0931499\n",
      "evaluation/Returns Mean              5154.82\n",
      "evaluation/Returns Std                 23.544\n",
      "evaluation/Returns Max               5195.08\n",
      "evaluation/Returns Min               5125.31\n",
      "evaluation/Estimation Bias Mean      1584.12\n",
      "evaluation/Estimation Bias Std        223.758\n",
      "evaluation/EB/Q_True Mean              48.8111\n",
      "evaluation/EB/Q_True Std              150.921\n",
      "evaluation/EB/Q_Pred Mean            1632.93\n",
      "evaluation/EB/Q_Pred Std              166.548\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5154.82\n",
      "evaluation/Actions Mean                 0.486337\n",
      "evaluation/Actions Std                  0.644932\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99998\n",
      "time/backward_policy (s)                1.95725\n",
      "time/backward_zf1 (s)                   2.11992\n",
      "time/backward_zf2 (s)                   2.05172\n",
      "time/data sampling (s)                  0.245498\n",
      "time/data storing (s)                   0.0153502\n",
      "time/evaluation sampling (s)            1.43052\n",
      "time/exploration sampling (s)           0.192868\n",
      "time/logging (s)                        0.0118178\n",
      "time/preback_alpha (s)                  1.03355\n",
      "time/preback_policy (s)                 1.1759\n",
      "time/preback_start (s)                  0.119686\n",
      "time/preback_zf (s)                     5.15506\n",
      "time/saving (s)                         0.00538903\n",
      "time/training (s)                       2.11138\n",
      "time/epoch (s)                         17.6259\n",
      "time/total (s)                       1330.73\n",
      "Epoch                                  78\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:32:58.833980 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 79 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  90000\n",
      "trainer/ZF1 Loss                      504.949\n",
      "trainer/ZF2 Loss                      431.479\n",
      "trainer/ZF Expert Reward               25.5563\n",
      "trainer/ZF Policy Reward               -0.393872\n",
      "trainer/ZF CHI2 Term                  513.707\n",
      "trainer/Policy Loss                 -1188.2\n",
      "trainer/Bias Loss                    4158.25\n",
      "trainer/Bias Value                     20.3508\n",
      "trainer/Policy Grad Norm              284.343\n",
      "trainer/Policy Param Norm              31.5738\n",
      "trainer/Zf1 Grad Norm               15162.8\n",
      "trainer/Zf1 Param Norm                 88.4139\n",
      "trainer/Zf2 Grad Norm               13706.7\n",
      "trainer/Zf2 Param Norm                 87.4006\n",
      "trainer/Z Expert Predictions Mean    1668.66\n",
      "trainer/Z Expert Predictions Std      155.742\n",
      "trainer/Z Expert Predictions Max     1858.93\n",
      "trainer/Z Expert Predictions Min      807.267\n",
      "trainer/Z Policy Predictions Mean    1177.31\n",
      "trainer/Z Policy Predictions Std      552.169\n",
      "trainer/Z Policy Predictions Max     1818.01\n",
      "trainer/Z Policy Predictions Min     -220.644\n",
      "trainer/Z Expert Targets Mean        1643.1\n",
      "trainer/Z Expert Targets Std          186.346\n",
      "trainer/Z Expert Targets Max         1844.59\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1177.7\n",
      "trainer/Z Policy Targets Std          550.472\n",
      "trainer/Z Policy Targets Max         1798.62\n",
      "trainer/Z Policy Targets Min         -216.422\n",
      "trainer/Log Pis Mean                   19.7406\n",
      "trainer/Log Pis Std                     5.8206\n",
      "trainer/Policy mu Mean                  1.20146\n",
      "trainer/Policy mu Std                   1.97334\n",
      "trainer/Policy log std Mean            -2.31708\n",
      "trainer/Policy log std Std              1.07527\n",
      "trainer/Alpha                           0.0937198\n",
      "trainer/Alpha Loss                      0.0243082\n",
      "exploration/num steps total         84197\n",
      "exploration/num paths total           663\n",
      "evaluation/num steps total         437031\n",
      "evaluation/num paths total            803\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08528\n",
      "evaluation/Rewards Std                  1.31979\n",
      "evaluation/Rewards Max                  7.36593\n",
      "evaluation/Rewards Min                  0.0817847\n",
      "evaluation/Returns Mean              5085.28\n",
      "evaluation/Returns Std                 40.2544\n",
      "evaluation/Returns Max               5149.07\n",
      "evaluation/Returns Min               5024.16\n",
      "evaluation/Estimation Bias Mean      1613.13\n",
      "evaluation/Estimation Bias Std        195.861\n",
      "evaluation/EB/Q_True Mean              48.7055\n",
      "evaluation/EB/Q_True Std              150.581\n",
      "evaluation/EB/Q_Pred Mean            1661.83\n",
      "evaluation/EB/Q_Pred Std              118.899\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5085.28\n",
      "evaluation/Actions Mean                 0.513519\n",
      "evaluation/Actions Std                  0.618477\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999948\n",
      "time/backward_policy (s)                1.91454\n",
      "time/backward_zf1 (s)                   2.03928\n",
      "time/backward_zf2 (s)                   1.998\n",
      "time/data sampling (s)                  0.242407\n",
      "time/data storing (s)                   0.0138079\n",
      "time/evaluation sampling (s)            1.54639\n",
      "time/exploration sampling (s)           0.190512\n",
      "time/logging (s)                        0.0118696\n",
      "time/preback_alpha (s)                  1.00881\n",
      "time/preback_policy (s)                 1.13857\n",
      "time/preback_start (s)                  0.119763\n",
      "time/preback_zf (s)                     5.12737\n",
      "time/saving (s)                         0.00489996\n",
      "time/training (s)                       2.18639\n",
      "time/epoch (s)                         17.5426\n",
      "time/total (s)                       1348.3\n",
      "Epoch                                  79\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:33:16.591102 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 80 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  91000\n",
      "trainer/ZF1 Loss                       95.6842\n",
      "trainer/ZF2 Loss                      112.557\n",
      "trainer/ZF Expert Reward               17.7175\n",
      "trainer/ZF Policy Reward                3.76065\n",
      "trainer/ZF CHI2 Term                  137.9\n",
      "trainer/Policy Loss                 -1212.93\n",
      "trainer/Bias Loss                     293.016\n",
      "trainer/Bias Value                     20.3727\n",
      "trainer/Policy Grad Norm              373.157\n",
      "trainer/Policy Param Norm              31.6652\n",
      "trainer/Zf1 Grad Norm                8009.46\n",
      "trainer/Zf1 Param Norm                 88.8313\n",
      "trainer/Zf2 Grad Norm                7177.58\n",
      "trainer/Zf2 Param Norm                 87.7836\n",
      "trainer/Z Expert Predictions Mean    1653.84\n",
      "trainer/Z Expert Predictions Std      186.213\n",
      "trainer/Z Expert Predictions Max     1873.67\n",
      "trainer/Z Expert Predictions Min      854.527\n",
      "trainer/Z Policy Predictions Mean    1195.36\n",
      "trainer/Z Policy Predictions Std      554.97\n",
      "trainer/Z Policy Predictions Max     1816.29\n",
      "trainer/Z Policy Predictions Min     -239.174\n",
      "trainer/Z Expert Targets Mean        1636.12\n",
      "trainer/Z Expert Targets Std          187.406\n",
      "trainer/Z Expert Targets Max         1851.37\n",
      "trainer/Z Expert Targets Min          760.345\n",
      "trainer/Z Policy Targets Mean        1191.6\n",
      "trainer/Z Policy Targets Std          554.29\n",
      "trainer/Z Policy Targets Max         1785.57\n",
      "trainer/Z Policy Targets Min         -296.57\n",
      "trainer/Log Pis Mean                   20.0226\n",
      "trainer/Log Pis Std                     5.73879\n",
      "trainer/Policy mu Mean                  1.23587\n",
      "trainer/Policy mu Std                   1.94944\n",
      "trainer/Policy log std Mean            -2.26011\n",
      "trainer/Policy log std Std              1.06952\n",
      "trainer/Alpha                           0.0941434\n",
      "trainer/Alpha Loss                     -0.00213055\n",
      "exploration/num steps total         86197\n",
      "exploration/num paths total           665\n",
      "evaluation/num steps total         446982\n",
      "evaluation/num paths total            813\n",
      "evaluation/path length Mean           995.1\n",
      "evaluation/path length Std             14.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            951\n",
      "evaluation/Rewards Mean                 5.07353\n",
      "evaluation/Rewards Std                  1.30402\n",
      "evaluation/Rewards Max                  7.0872\n",
      "evaluation/Rewards Min                  0.093097\n",
      "evaluation/Returns Mean              5048.67\n",
      "evaluation/Returns Std                 75.5926\n",
      "evaluation/Returns Max               5108.44\n",
      "evaluation/Returns Min               4833.73\n",
      "evaluation/Estimation Bias Mean      1590.79\n",
      "evaluation/Estimation Bias Std        292.29\n",
      "evaluation/EB/Q_True Mean              48.4633\n",
      "evaluation/EB/Q_True Std              149.223\n",
      "evaluation/EB/Q_Pred Mean            1639.26\n",
      "evaluation/EB/Q_Pred Std              223.599\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5048.67\n",
      "evaluation/Actions Mean                 0.494189\n",
      "evaluation/Actions Std                  0.638975\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.97481\n",
      "time/backward_zf1 (s)                   2.11308\n",
      "time/backward_zf2 (s)                   2.068\n",
      "time/data sampling (s)                  0.245396\n",
      "time/data storing (s)                   0.0140797\n",
      "time/evaluation sampling (s)            1.40389\n",
      "time/exploration sampling (s)           0.198399\n",
      "time/logging (s)                        0.0118826\n",
      "time/preback_alpha (s)                  1.06016\n",
      "time/preback_policy (s)                 1.2363\n",
      "time/preback_start (s)                  0.122969\n",
      "time/preback_zf (s)                     5.17694\n",
      "time/saving (s)                         0.00538023\n",
      "time/training (s)                       2.05935\n",
      "time/epoch (s)                         17.6906\n",
      "time/total (s)                       1366.01\n",
      "Epoch                                  80\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:33:34.126355 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 81 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  92000\n",
      "trainer/ZF1 Loss                       69.6886\n",
      "trainer/ZF2 Loss                       77.8902\n",
      "trainer/ZF Expert Reward               15.8992\n",
      "trainer/ZF Policy Reward               -4.81354\n",
      "trainer/ZF CHI2 Term                  114.731\n",
      "trainer/Policy Loss                 -1170.61\n",
      "trainer/Bias Loss                     262.779\n",
      "trainer/Bias Value                     20.392\n",
      "trainer/Policy Grad Norm              201.572\n",
      "trainer/Policy Param Norm              31.7587\n",
      "trainer/Zf1 Grad Norm                8593.95\n",
      "trainer/Zf1 Param Norm                 89.2465\n",
      "trainer/Zf2 Grad Norm                8125.18\n",
      "trainer/Zf2 Param Norm                 88.1763\n",
      "trainer/Z Expert Predictions Mean    1683.13\n",
      "trainer/Z Expert Predictions Std      177.124\n",
      "trainer/Z Expert Predictions Max     1870.17\n",
      "trainer/Z Expert Predictions Min      692.52\n",
      "trainer/Z Policy Predictions Mean    1147.21\n",
      "trainer/Z Policy Predictions Std      552.194\n",
      "trainer/Z Policy Predictions Max     1816.13\n",
      "trainer/Z Policy Predictions Min     -255.143\n",
      "trainer/Z Expert Targets Mean        1667.23\n",
      "trainer/Z Expert Targets Std          173.978\n",
      "trainer/Z Expert Targets Max         1852.09\n",
      "trainer/Z Expert Targets Min          646.287\n",
      "trainer/Z Policy Targets Mean        1152.03\n",
      "trainer/Z Policy Targets Std          549.429\n",
      "trainer/Z Policy Targets Max         1802.97\n",
      "trainer/Z Policy Targets Min         -233.363\n",
      "trainer/Log Pis Mean                   20.4327\n",
      "trainer/Log Pis Std                     6.0524\n",
      "trainer/Policy mu Mean                  1.15102\n",
      "trainer/Policy mu Std                   1.95277\n",
      "trainer/Policy log std Mean            -2.33129\n",
      "trainer/Policy log std Std              1.02409\n",
      "trainer/Alpha                           0.0967656\n",
      "trainer/Alpha Loss                     -0.0418683\n",
      "exploration/num steps total         87197\n",
      "exploration/num paths total           666\n",
      "evaluation/num steps total         456982\n",
      "evaluation/num paths total            823\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13017\n",
      "evaluation/Rewards Std                  1.33124\n",
      "evaluation/Rewards Max                  7.25868\n",
      "evaluation/Rewards Min                  0.0678958\n",
      "evaluation/Returns Mean              5130.17\n",
      "evaluation/Returns Std                 25.1014\n",
      "evaluation/Returns Max               5170.16\n",
      "evaluation/Returns Min               5102.24\n",
      "evaluation/Estimation Bias Mean      1674.75\n",
      "evaluation/Estimation Bias Std        191.298\n",
      "evaluation/EB/Q_True Mean              48.3277\n",
      "evaluation/EB/Q_True Std              149.32\n",
      "evaluation/EB/Q_Pred Mean            1723.08\n",
      "evaluation/EB/Q_Pred Std              111.143\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5130.17\n",
      "evaluation/Actions Mean                 0.495995\n",
      "evaluation/Actions Std                  0.64623\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999914\n",
      "time/backward_policy (s)                1.89149\n",
      "time/backward_zf1 (s)                   2.03857\n",
      "time/backward_zf2 (s)                   1.98781\n",
      "time/data sampling (s)                  0.250397\n",
      "time/data storing (s)                   0.0142714\n",
      "time/evaluation sampling (s)            1.46365\n",
      "time/exploration sampling (s)           0.195039\n",
      "time/logging (s)                        0.0124244\n",
      "time/preback_alpha (s)                  0.974164\n",
      "time/preback_policy (s)                 1.09941\n",
      "time/preback_start (s)                  0.12022\n",
      "time/preback_zf (s)                     5.13964\n",
      "time/saving (s)                         0.00525019\n",
      "time/training (s)                       2.272\n",
      "time/epoch (s)                         17.4643\n",
      "time/total (s)                       1383.49\n",
      "Epoch                                  81\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:33:51.687778 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 82 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  93000\n",
      "trainer/ZF1 Loss                      127.009\n",
      "trainer/ZF2 Loss                      142.344\n",
      "trainer/ZF Expert Reward               23.3239\n",
      "trainer/ZF Policy Reward                3.51557\n",
      "trainer/ZF CHI2 Term                  174.239\n",
      "trainer/Policy Loss                 -1120.2\n",
      "trainer/Bias Loss                     312.244\n",
      "trainer/Bias Value                     20.4096\n",
      "trainer/Policy Grad Norm              263.507\n",
      "trainer/Policy Param Norm              31.8522\n",
      "trainer/Zf1 Grad Norm                7156.88\n",
      "trainer/Zf1 Param Norm                 89.6368\n",
      "trainer/Zf2 Grad Norm               10937.6\n",
      "trainer/Zf2 Param Norm                 88.5262\n",
      "trainer/Z Expert Predictions Mean    1682.78\n",
      "trainer/Z Expert Predictions Std      175.084\n",
      "trainer/Z Expert Predictions Max     1877.51\n",
      "trainer/Z Expert Predictions Min      178.175\n",
      "trainer/Z Policy Predictions Mean    1104.47\n",
      "trainer/Z Policy Predictions Std      589.882\n",
      "trainer/Z Policy Predictions Max     1813.73\n",
      "trainer/Z Policy Predictions Min     -346.318\n",
      "trainer/Z Expert Targets Mean        1659.46\n",
      "trainer/Z Expert Targets Std          181.188\n",
      "trainer/Z Expert Targets Max         1853.08\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1100.96\n",
      "trainer/Z Policy Targets Std          586.398\n",
      "trainer/Z Policy Targets Max         1798.8\n",
      "trainer/Z Policy Targets Min         -371.274\n",
      "trainer/Log Pis Mean                   19.9538\n",
      "trainer/Log Pis Std                     5.61269\n",
      "trainer/Policy mu Mean                  1.14747\n",
      "trainer/Policy mu Std                   2.003\n",
      "trainer/Policy log std Mean            -2.23291\n",
      "trainer/Policy log std Std              1.08107\n",
      "trainer/Alpha                           0.0981715\n",
      "trainer/Alpha Loss                      0.00453308\n",
      "exploration/num steps total         87197\n",
      "exploration/num paths total           666\n",
      "evaluation/num steps total         466982\n",
      "evaluation/num paths total            833\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.89115\n",
      "evaluation/Rewards Std                  1.26177\n",
      "evaluation/Rewards Max                  6.6704\n",
      "evaluation/Rewards Min                  0.0657479\n",
      "evaluation/Returns Mean              4891.15\n",
      "evaluation/Returns Std                 29.6425\n",
      "evaluation/Returns Max               4943.86\n",
      "evaluation/Returns Min               4855.95\n",
      "evaluation/Estimation Bias Mean      1599.88\n",
      "evaluation/Estimation Bias Std        204.551\n",
      "evaluation/EB/Q_True Mean              45.8709\n",
      "evaluation/EB/Q_True Std              141.871\n",
      "evaluation/EB/Q_Pred Mean            1645.75\n",
      "evaluation/EB/Q_Pred Std              150.764\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4891.15\n",
      "evaluation/Actions Mean                 0.500629\n",
      "evaluation/Actions Std                  0.640255\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999869\n",
      "time/backward_policy (s)                1.9372\n",
      "time/backward_zf1 (s)                   2.06566\n",
      "time/backward_zf2 (s)                   2.01924\n",
      "time/data sampling (s)                  0.254765\n",
      "time/data storing (s)                   0.0140306\n",
      "time/evaluation sampling (s)            1.41922\n",
      "time/exploration sampling (s)           0.192449\n",
      "time/logging (s)                        0.0118919\n",
      "time/preback_alpha (s)                  1.01265\n",
      "time/preback_policy (s)                 1.15329\n",
      "time/preback_start (s)                  0.122045\n",
      "time/preback_zf (s)                     5.1185\n",
      "time/saving (s)                         0.00480782\n",
      "time/training (s)                       2.16339\n",
      "time/epoch (s)                         17.4891\n",
      "time/total (s)                       1401.01\n",
      "Epoch                                  82\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:34:09.756841 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 83 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  94000\n",
      "trainer/ZF1 Loss                       68.0444\n",
      "trainer/ZF2 Loss                       81.6794\n",
      "trainer/ZF Expert Reward               28.1697\n",
      "trainer/ZF Policy Reward                9.6021\n",
      "trainer/ZF CHI2 Term                  112.736\n",
      "trainer/Policy Loss                 -1232.64\n",
      "trainer/Bias Loss                     263.323\n",
      "trainer/Bias Value                     20.4276\n",
      "trainer/Policy Grad Norm              276.885\n",
      "trainer/Policy Param Norm              31.9364\n",
      "trainer/Zf1 Grad Norm                6425.05\n",
      "trainer/Zf1 Param Norm                 90.0312\n",
      "trainer/Zf2 Grad Norm                5414.44\n",
      "trainer/Zf2 Param Norm                 88.8839\n",
      "trainer/Z Expert Predictions Mean    1704.32\n",
      "trainer/Z Expert Predictions Std      157.649\n",
      "trainer/Z Expert Predictions Max     1898.17\n",
      "trainer/Z Expert Predictions Min      874.813\n",
      "trainer/Z Policy Predictions Mean    1219.54\n",
      "trainer/Z Policy Predictions Std      561.829\n",
      "trainer/Z Policy Predictions Max     1847.64\n",
      "trainer/Z Policy Predictions Min     -310.668\n",
      "trainer/Z Expert Targets Mean        1676.15\n",
      "trainer/Z Expert Targets Std          160.887\n",
      "trainer/Z Expert Targets Max         1865.24\n",
      "trainer/Z Expert Targets Min          744.43\n",
      "trainer/Z Policy Targets Mean        1209.94\n",
      "trainer/Z Policy Targets Std          556.616\n",
      "trainer/Z Policy Targets Max         1844.51\n",
      "trainer/Z Policy Targets Min         -280.619\n",
      "trainer/Log Pis Mean                   19.5013\n",
      "trainer/Log Pis Std                     5.76572\n",
      "trainer/Policy mu Mean                  1.13377\n",
      "trainer/Policy mu Std                   2.00182\n",
      "trainer/Policy log std Mean            -2.18718\n",
      "trainer/Policy log std Std              1.07782\n",
      "trainer/Alpha                           0.10034\n",
      "trainer/Alpha Loss                      0.0500396\n",
      "exploration/num steps total         89197\n",
      "exploration/num paths total           668\n",
      "evaluation/num steps total         476982\n",
      "evaluation/num paths total            843\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.11102\n",
      "evaluation/Rewards Std                  1.32073\n",
      "evaluation/Rewards Max                  7.18699\n",
      "evaluation/Rewards Min                  0.0724143\n",
      "evaluation/Returns Mean              5111.02\n",
      "evaluation/Returns Std                 34.8421\n",
      "evaluation/Returns Max               5173.49\n",
      "evaluation/Returns Min               5061.67\n",
      "evaluation/Estimation Bias Mean      1642.54\n",
      "evaluation/Estimation Bias Std        176.738\n",
      "evaluation/EB/Q_True Mean              48.51\n",
      "evaluation/EB/Q_True Std              150.014\n",
      "evaluation/EB/Q_Pred Mean            1691.05\n",
      "evaluation/EB/Q_Pred Std               89.9742\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5111.02\n",
      "evaluation/Actions Mean                 0.506938\n",
      "evaluation/Actions Std                  0.629111\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999925\n",
      "time/backward_policy (s)                2.0547\n",
      "time/backward_zf1 (s)                   2.20829\n",
      "time/backward_zf2 (s)                   2.15513\n",
      "time/data sampling (s)                  0.253528\n",
      "time/data storing (s)                   0.0162551\n",
      "time/evaluation sampling (s)            1.37826\n",
      "time/exploration sampling (s)           0.205372\n",
      "time/logging (s)                        0.0116309\n",
      "time/preback_alpha (s)                  1.0631\n",
      "time/preback_policy (s)                 1.22466\n",
      "time/preback_start (s)                  0.123537\n",
      "time/preback_zf (s)                     5.16963\n",
      "time/saving (s)                         0.00519399\n",
      "time/training (s)                       2.13164\n",
      "time/epoch (s)                         18.0009\n",
      "time/total (s)                       1419.03\n",
      "Epoch                                  83\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:34:27.667172 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 84 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  95000\n",
      "trainer/ZF1 Loss                       95.2185\n",
      "trainer/ZF2 Loss                       85.1361\n",
      "trainer/ZF Expert Reward               22.4338\n",
      "trainer/ZF Policy Reward                4.56123\n",
      "trainer/ZF CHI2 Term                  127.326\n",
      "trainer/Policy Loss                 -1174.94\n",
      "trainer/Bias Loss                     320.948\n",
      "trainer/Bias Value                     20.4449\n",
      "trainer/Policy Grad Norm              265.408\n",
      "trainer/Policy Param Norm              32.0205\n",
      "trainer/Zf1 Grad Norm                5203.68\n",
      "trainer/Zf1 Param Norm                 90.4403\n",
      "trainer/Zf2 Grad Norm                6184.68\n",
      "trainer/Zf2 Param Norm                 89.2718\n",
      "trainer/Z Expert Predictions Mean    1703.69\n",
      "trainer/Z Expert Predictions Std      154.728\n",
      "trainer/Z Expert Predictions Max     1894.55\n",
      "trainer/Z Expert Predictions Min      888.358\n",
      "trainer/Z Policy Predictions Mean    1156.72\n",
      "trainer/Z Policy Predictions Std      586.808\n",
      "trainer/Z Policy Predictions Max     1843.29\n",
      "trainer/Z Policy Predictions Min     -360.936\n",
      "trainer/Z Expert Targets Mean        1681.26\n",
      "trainer/Z Expert Targets Std          156.862\n",
      "trainer/Z Expert Targets Max         1864.97\n",
      "trainer/Z Expert Targets Min          908.217\n",
      "trainer/Z Policy Targets Mean        1152.16\n",
      "trainer/Z Policy Targets Std          582.189\n",
      "trainer/Z Policy Targets Max         1819.94\n",
      "trainer/Z Policy Targets Min         -379.868\n",
      "trainer/Log Pis Mean                   19.4709\n",
      "trainer/Log Pis Std                     5.72484\n",
      "trainer/Policy mu Mean                  1.20655\n",
      "trainer/Policy mu Std                   1.96428\n",
      "trainer/Policy log std Mean            -2.20175\n",
      "trainer/Policy log std Std              1.07352\n",
      "trainer/Alpha                           0.100095\n",
      "trainer/Alpha Loss                      0.0529585\n",
      "exploration/num steps total         91197\n",
      "exploration/num paths total           670\n",
      "evaluation/num steps total         486982\n",
      "evaluation/num paths total            853\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18248\n",
      "evaluation/Rewards Std                  1.35727\n",
      "evaluation/Rewards Max                  7.39981\n",
      "evaluation/Rewards Min                  0.0716657\n",
      "evaluation/Returns Mean              5182.48\n",
      "evaluation/Returns Std                 11.3964\n",
      "evaluation/Returns Max               5195.8\n",
      "evaluation/Returns Min               5166.32\n",
      "evaluation/Estimation Bias Mean      1664.54\n",
      "evaluation/Estimation Bias Std        181.209\n",
      "evaluation/EB/Q_True Mean              48.9456\n",
      "evaluation/EB/Q_True Std              151.342\n",
      "evaluation/EB/Q_Pred Mean            1713.48\n",
      "evaluation/EB/Q_Pred Std              115.079\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5182.48\n",
      "evaluation/Actions Mean                 0.498049\n",
      "evaluation/Actions Std                  0.645534\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999953\n",
      "time/backward_policy (s)                2.03329\n",
      "time/backward_zf1 (s)                   2.171\n",
      "time/backward_zf2 (s)                   2.12997\n",
      "time/data sampling (s)                  0.25912\n",
      "time/data storing (s)                   0.0141014\n",
      "time/evaluation sampling (s)            1.411\n",
      "time/exploration sampling (s)           0.19973\n",
      "time/logging (s)                        0.0116707\n",
      "time/preback_alpha (s)                  1.06597\n",
      "time/preback_policy (s)                 1.23087\n",
      "time/preback_start (s)                  0.120997\n",
      "time/preback_zf (s)                     5.15084\n",
      "time/saving (s)                         0.00541896\n",
      "time/training (s)                       2.03891\n",
      "time/epoch (s)                         17.8429\n",
      "time/total (s)                       1436.89\n",
      "Epoch                                  84\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:34:45.960851 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 85 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  96000\n",
      "trainer/ZF1 Loss                       89.9167\n",
      "trainer/ZF2 Loss                       92.8527\n",
      "trainer/ZF Expert Reward               20.8824\n",
      "trainer/ZF Policy Reward               -0.363477\n",
      "trainer/ZF CHI2 Term                  132.139\n",
      "trainer/Policy Loss                 -1264.91\n",
      "trainer/Bias Loss                     327.26\n",
      "trainer/Bias Value                     20.4611\n",
      "trainer/Policy Grad Norm              267.2\n",
      "trainer/Policy Param Norm              32.1041\n",
      "trainer/Zf1 Grad Norm                8642.71\n",
      "trainer/Zf1 Param Norm                 90.8261\n",
      "trainer/Zf2 Grad Norm                7957.51\n",
      "trainer/Zf2 Param Norm                 89.623\n",
      "trainer/Z Expert Predictions Mean    1708.74\n",
      "trainer/Z Expert Predictions Std      173.043\n",
      "trainer/Z Expert Predictions Max     1928.92\n",
      "trainer/Z Expert Predictions Min      787.697\n",
      "trainer/Z Policy Predictions Mean    1251.9\n",
      "trainer/Z Policy Predictions Std      509.258\n",
      "trainer/Z Policy Predictions Max     1861.75\n",
      "trainer/Z Policy Predictions Min     -208.138\n",
      "trainer/Z Expert Targets Mean        1687.86\n",
      "trainer/Z Expert Targets Std          169.247\n",
      "trainer/Z Expert Targets Max         1901.11\n",
      "trainer/Z Expert Targets Min          764.921\n",
      "trainer/Z Policy Targets Mean        1252.27\n",
      "trainer/Z Policy Targets Std          502.448\n",
      "trainer/Z Policy Targets Max         1826.81\n",
      "trainer/Z Policy Targets Min         -241.552\n",
      "trainer/Log Pis Mean                   19.7052\n",
      "trainer/Log Pis Std                     4.93624\n",
      "trainer/Policy mu Mean                  1.18774\n",
      "trainer/Policy mu Std                   1.91872\n",
      "trainer/Policy log std Mean            -2.21909\n",
      "trainer/Policy log std Std              1.03726\n",
      "trainer/Alpha                           0.0983133\n",
      "trainer/Alpha Loss                      0.0289854\n",
      "exploration/num steps total         91197\n",
      "exploration/num paths total           670\n",
      "evaluation/num steps total         496982\n",
      "evaluation/num paths total            863\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13825\n",
      "evaluation/Rewards Std                  1.32506\n",
      "evaluation/Rewards Max                  6.96945\n",
      "evaluation/Rewards Min                  0.108275\n",
      "evaluation/Returns Mean              5138.25\n",
      "evaluation/Returns Std                 25.9579\n",
      "evaluation/Returns Max               5171.56\n",
      "evaluation/Returns Min               5083.63\n",
      "evaluation/Estimation Bias Mean      1697.41\n",
      "evaluation/Estimation Bias Std        193.203\n",
      "evaluation/EB/Q_True Mean              48.8881\n",
      "evaluation/EB/Q_True Std              151.003\n",
      "evaluation/EB/Q_Pred Mean            1746.29\n",
      "evaluation/EB/Q_Pred Std              122.867\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5138.25\n",
      "evaluation/Actions Mean                 0.50784\n",
      "evaluation/Actions Std                  0.648823\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999931\n",
      "time/backward_policy (s)                2.0906\n",
      "time/backward_zf1 (s)                   2.23402\n",
      "time/backward_zf2 (s)                   2.17077\n",
      "time/data sampling (s)                  0.271163\n",
      "time/data storing (s)                   0.0165603\n",
      "time/evaluation sampling (s)            1.41037\n",
      "time/exploration sampling (s)           0.199828\n",
      "time/logging (s)                        0.0118906\n",
      "time/preback_alpha (s)                  1.09214\n",
      "time/preback_policy (s)                 1.25406\n",
      "time/preback_start (s)                  0.123679\n",
      "time/preback_zf (s)                     5.22885\n",
      "time/saving (s)                         0.00627586\n",
      "time/training (s)                       2.11271\n",
      "time/epoch (s)                         18.2229\n",
      "time/total (s)                       1455.14\n",
      "Epoch                                  85\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:35:03.662540 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 86 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  97000\n",
      "trainer/ZF1 Loss                       61.6842\n",
      "trainer/ZF2 Loss                       50.9461\n",
      "trainer/ZF Expert Reward               23.5692\n",
      "trainer/ZF Policy Reward               -1.33935\n",
      "trainer/ZF CHI2 Term                  101.4\n",
      "trainer/Policy Loss                 -1205.3\n",
      "trainer/Bias Loss                     265.506\n",
      "trainer/Bias Value                     20.4757\n",
      "trainer/Policy Grad Norm              219.146\n",
      "trainer/Policy Param Norm              32.1845\n",
      "trainer/Zf1 Grad Norm                7114.48\n",
      "trainer/Zf1 Param Norm                 91.2278\n",
      "trainer/Zf2 Grad Norm                6233.86\n",
      "trainer/Zf2 Param Norm                 90.0151\n",
      "trainer/Z Expert Predictions Mean    1732.92\n",
      "trainer/Z Expert Predictions Std      132.412\n",
      "trainer/Z Expert Predictions Max     1935.26\n",
      "trainer/Z Expert Predictions Min     1182.27\n",
      "trainer/Z Policy Predictions Mean    1188.74\n",
      "trainer/Z Policy Predictions Std      598.951\n",
      "trainer/Z Policy Predictions Max     1874.54\n",
      "trainer/Z Policy Predictions Min     -320.401\n",
      "trainer/Z Expert Targets Mean        1709.35\n",
      "trainer/Z Expert Targets Std          132.006\n",
      "trainer/Z Expert Targets Max         1906.87\n",
      "trainer/Z Expert Targets Min         1142.08\n",
      "trainer/Z Policy Targets Mean        1190.08\n",
      "trainer/Z Policy Targets Std          590.459\n",
      "trainer/Z Policy Targets Max         1844.89\n",
      "trainer/Z Policy Targets Min         -356.258\n",
      "trainer/Log Pis Mean                   20.3801\n",
      "trainer/Log Pis Std                     5.58285\n",
      "trainer/Policy mu Mean                  1.25573\n",
      "trainer/Policy mu Std                   1.98899\n",
      "trainer/Policy log std Mean            -2.25515\n",
      "trainer/Policy log std Std              1.11826\n",
      "trainer/Alpha                           0.0993913\n",
      "trainer/Alpha Loss                     -0.0377738\n",
      "exploration/num steps total         93197\n",
      "exploration/num paths total           672\n",
      "evaluation/num steps total         506982\n",
      "evaluation/num paths total            873\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17728\n",
      "evaluation/Rewards Std                  1.34904\n",
      "evaluation/Rewards Max                  7.32957\n",
      "evaluation/Rewards Min                  0.066768\n",
      "evaluation/Returns Mean              5177.28\n",
      "evaluation/Returns Std                 26.1988\n",
      "evaluation/Returns Max               5211.24\n",
      "evaluation/Returns Min               5117.18\n",
      "evaluation/Estimation Bias Mean      1688.67\n",
      "evaluation/Estimation Bias Std        191.922\n",
      "evaluation/EB/Q_True Mean              48.461\n",
      "evaluation/EB/Q_True Std              149.904\n",
      "evaluation/EB/Q_Pred Mean            1737.14\n",
      "evaluation/EB/Q_Pred Std              126.157\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5177.28\n",
      "evaluation/Actions Mean                 0.505625\n",
      "evaluation/Actions Std                  0.645079\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999958\n",
      "time/backward_policy (s)                1.95401\n",
      "time/backward_zf1 (s)                   2.11327\n",
      "time/backward_zf2 (s)                   2.06067\n",
      "time/data sampling (s)                  0.265767\n",
      "time/data storing (s)                   0.0140581\n",
      "time/evaluation sampling (s)            1.38012\n",
      "time/exploration sampling (s)           0.200454\n",
      "time/logging (s)                        0.0132358\n",
      "time/preback_alpha (s)                  1.01879\n",
      "time/preback_policy (s)                 1.16618\n",
      "time/preback_start (s)                  0.122637\n",
      "time/preback_zf (s)                     5.14608\n",
      "time/saving (s)                         0.00556345\n",
      "time/training (s)                       2.17275\n",
      "time/epoch (s)                         17.6336\n",
      "time/total (s)                       1472.79\n",
      "Epoch                                  86\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:35:21.393553 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 87 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  98000\n",
      "trainer/ZF1 Loss                      665.425\n",
      "trainer/ZF2 Loss                      633.94\n",
      "trainer/ZF Expert Reward               26.405\n",
      "trainer/ZF Policy Reward               -0.551344\n",
      "trainer/ZF CHI2 Term                  696.19\n",
      "trainer/Policy Loss                 -1236.53\n",
      "trainer/Bias Loss                    6246.84\n",
      "trainer/Bias Value                     20.4914\n",
      "trainer/Policy Grad Norm              264.142\n",
      "trainer/Policy Param Norm              32.2639\n",
      "trainer/Zf1 Grad Norm                7595.48\n",
      "trainer/Zf1 Param Norm                 91.6139\n",
      "trainer/Zf2 Grad Norm                7249.86\n",
      "trainer/Zf2 Param Norm                 90.4091\n",
      "trainer/Z Expert Predictions Mean    1715.13\n",
      "trainer/Z Expert Predictions Std      170.172\n",
      "trainer/Z Expert Predictions Max     1929.81\n",
      "trainer/Z Expert Predictions Min      794.413\n",
      "trainer/Z Policy Predictions Mean    1225.61\n",
      "trainer/Z Policy Predictions Std      565.372\n",
      "trainer/Z Policy Predictions Max     1872.4\n",
      "trainer/Z Policy Predictions Min     -183.456\n",
      "trainer/Z Expert Targets Mean        1688.73\n",
      "trainer/Z Expert Targets Std          203.143\n",
      "trainer/Z Expert Targets Max         1899.28\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1226.16\n",
      "trainer/Z Policy Targets Std          556.759\n",
      "trainer/Z Policy Targets Max         1830.63\n",
      "trainer/Z Policy Targets Min         -190.828\n",
      "trainer/Log Pis Mean                   19.7494\n",
      "trainer/Log Pis Std                     5.5833\n",
      "trainer/Policy mu Mean                  1.22269\n",
      "trainer/Policy mu Std                   1.93935\n",
      "trainer/Policy log std Mean            -2.24561\n",
      "trainer/Policy log std Std              1.0722\n",
      "trainer/Alpha                           0.101299\n",
      "trainer/Alpha Loss                      0.0253806\n",
      "exploration/num steps total         93197\n",
      "exploration/num paths total           672\n",
      "evaluation/num steps total         516982\n",
      "evaluation/num paths total            883\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12798\n",
      "evaluation/Rewards Std                  1.31106\n",
      "evaluation/Rewards Max                  7.54617\n",
      "evaluation/Rewards Min                  0.0895359\n",
      "evaluation/Returns Mean              5127.98\n",
      "evaluation/Returns Std                 32.5622\n",
      "evaluation/Returns Max               5157.7\n",
      "evaluation/Returns Min               5045.99\n",
      "evaluation/Estimation Bias Mean      1658.51\n",
      "evaluation/Estimation Bias Std        227.994\n",
      "evaluation/EB/Q_True Mean              48.3487\n",
      "evaluation/EB/Q_True Std              149.435\n",
      "evaluation/EB/Q_Pred Mean            1706.86\n",
      "evaluation/EB/Q_Pred Std              184.266\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5127.98\n",
      "evaluation/Actions Mean                 0.504954\n",
      "evaluation/Actions Std                  0.641372\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.94473\n",
      "time/backward_zf1 (s)                   2.06118\n",
      "time/backward_zf2 (s)                   2.03635\n",
      "time/data sampling (s)                  0.258577\n",
      "time/data storing (s)                   0.0141979\n",
      "time/evaluation sampling (s)            1.42668\n",
      "time/exploration sampling (s)           0.190889\n",
      "time/logging (s)                        0.0156951\n",
      "time/preback_alpha (s)                  1.01253\n",
      "time/preback_policy (s)                 1.13471\n",
      "time/preback_start (s)                  0.121874\n",
      "time/preback_zf (s)                     5.18465\n",
      "time/saving (s)                         0.00524005\n",
      "time/training (s)                       2.25838\n",
      "time/epoch (s)                         17.6657\n",
      "time/total (s)                       1490.48\n",
      "Epoch                                  87\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:35:39.133676 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 88 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  99000\n",
      "trainer/ZF1 Loss                       63.1833\n",
      "trainer/ZF2 Loss                       76.9439\n",
      "trainer/ZF Expert Reward               17.5651\n",
      "trainer/ZF Policy Reward                1.32891\n",
      "trainer/ZF CHI2 Term                  106.202\n",
      "trainer/Policy Loss                 -1205.2\n",
      "trainer/Bias Loss                     298.095\n",
      "trainer/Bias Value                     20.5049\n",
      "trainer/Policy Grad Norm              217.208\n",
      "trainer/Policy Param Norm              32.3387\n",
      "trainer/Zf1 Grad Norm                7503.77\n",
      "trainer/Zf1 Param Norm                 92.0089\n",
      "trainer/Zf2 Grad Norm               10823.2\n",
      "trainer/Zf2 Param Norm                 90.7948\n",
      "trainer/Z Expert Predictions Mean    1727.02\n",
      "trainer/Z Expert Predictions Std      162.596\n",
      "trainer/Z Expert Predictions Max     1947.52\n",
      "trainer/Z Expert Predictions Min      851.94\n",
      "trainer/Z Policy Predictions Mean    1186.21\n",
      "trainer/Z Policy Predictions Std      616.022\n",
      "trainer/Z Policy Predictions Max     1923.44\n",
      "trainer/Z Policy Predictions Min     -433.414\n",
      "trainer/Z Expert Targets Mean        1709.45\n",
      "trainer/Z Expert Targets Std          159.269\n",
      "trainer/Z Expert Targets Max         1913.85\n",
      "trainer/Z Expert Targets Min          824.839\n",
      "trainer/Z Policy Targets Mean        1184.88\n",
      "trainer/Z Policy Targets Std          612.187\n",
      "trainer/Z Policy Targets Max         1866.91\n",
      "trainer/Z Policy Targets Min         -434.424\n",
      "trainer/Log Pis Mean                   20.1028\n",
      "trainer/Log Pis Std                     6.23928\n",
      "trainer/Policy mu Mean                  1.26244\n",
      "trainer/Policy mu Std                   2.0299\n",
      "trainer/Policy log std Mean            -2.17282\n",
      "trainer/Policy log std Std              1.10491\n",
      "trainer/Alpha                           0.102571\n",
      "trainer/Alpha Loss                     -0.0105435\n",
      "exploration/num steps total         93197\n",
      "exploration/num paths total           672\n",
      "evaluation/num steps total         526751\n",
      "evaluation/num paths total            893\n",
      "evaluation/path length Mean           976.9\n",
      "evaluation/path length Std             69.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            769\n",
      "evaluation/Rewards Mean                 4.87833\n",
      "evaluation/Rewards Std                  1.27117\n",
      "evaluation/Rewards Max                  7.31135\n",
      "evaluation/Rewards Min                  0.0972771\n",
      "evaluation/Returns Mean              4765.64\n",
      "evaluation/Returns Std                342.908\n",
      "evaluation/Returns Max               5073.59\n",
      "evaluation/Returns Min               3761.24\n",
      "evaluation/Estimation Bias Mean      1585.38\n",
      "evaluation/Estimation Bias Std        205.635\n",
      "evaluation/EB/Q_True Mean              47.2379\n",
      "evaluation/EB/Q_True Std              143.959\n",
      "evaluation/EB/Q_Pred Mean            1632.62\n",
      "evaluation/EB/Q_Pred Std              132.252\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4765.64\n",
      "evaluation/Actions Mean                 0.521702\n",
      "evaluation/Actions Std                  0.619669\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999969\n",
      "time/backward_policy (s)                1.96283\n",
      "time/backward_zf1 (s)                   2.14962\n",
      "time/backward_zf2 (s)                   2.08013\n",
      "time/data sampling (s)                  0.24762\n",
      "time/data storing (s)                   0.0145622\n",
      "time/evaluation sampling (s)            1.36986\n",
      "time/exploration sampling (s)           0.1943\n",
      "time/logging (s)                        0.0137289\n",
      "time/preback_alpha (s)                  1.03065\n",
      "time/preback_policy (s)                 1.18569\n",
      "time/preback_start (s)                  0.119284\n",
      "time/preback_zf (s)                     5.17604\n",
      "time/saving (s)                         0.00562771\n",
      "time/training (s)                       2.11914\n",
      "time/epoch (s)                         17.6691\n",
      "time/total (s)                       1508.17\n",
      "Epoch                                  88\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:35:57.075181 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 89 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 100000\n",
      "trainer/ZF1 Loss                       78.5443\n",
      "trainer/ZF2 Loss                       69.3832\n",
      "trainer/ZF Expert Reward               19.2774\n",
      "trainer/ZF Policy Reward               -3.41949\n",
      "trainer/ZF CHI2 Term                  116.608\n",
      "trainer/Policy Loss                 -1203.27\n",
      "trainer/Bias Loss                     248.735\n",
      "trainer/Bias Value                     20.5171\n",
      "trainer/Policy Grad Norm              315.12\n",
      "trainer/Policy Param Norm              32.4082\n",
      "trainer/Zf1 Grad Norm                6498.27\n",
      "trainer/Zf1 Param Norm                 92.3971\n",
      "trainer/Zf2 Grad Norm                6925.34\n",
      "trainer/Zf2 Param Norm                 91.1603\n",
      "trainer/Z Expert Predictions Mean    1716.59\n",
      "trainer/Z Expert Predictions Std      170.189\n",
      "trainer/Z Expert Predictions Max     1955.24\n",
      "trainer/Z Expert Predictions Min      802.891\n",
      "trainer/Z Policy Predictions Mean    1184.03\n",
      "trainer/Z Policy Predictions Std      581.999\n",
      "trainer/Z Policy Predictions Max     1863.02\n",
      "trainer/Z Policy Predictions Min     -348.764\n",
      "trainer/Z Expert Targets Mean        1697.31\n",
      "trainer/Z Expert Targets Std          168.292\n",
      "trainer/Z Expert Targets Max         1923.72\n",
      "trainer/Z Expert Targets Min          773.073\n",
      "trainer/Z Policy Targets Mean        1187.45\n",
      "trainer/Z Policy Targets Std          581.195\n",
      "trainer/Z Policy Targets Max         1875.58\n",
      "trainer/Z Policy Targets Min         -291.779\n",
      "trainer/Log Pis Mean                   20.1484\n",
      "trainer/Log Pis Std                     5.19481\n",
      "trainer/Policy mu Mean                  1.18817\n",
      "trainer/Policy mu Std                   1.97809\n",
      "trainer/Policy log std Mean            -2.23652\n",
      "trainer/Policy log std Std              1.06513\n",
      "trainer/Alpha                           0.104671\n",
      "trainer/Alpha Loss                     -0.0155378\n",
      "exploration/num steps total         94197\n",
      "exploration/num paths total           673\n",
      "evaluation/num steps total         536751\n",
      "evaluation/num paths total            903\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.178\n",
      "evaluation/Rewards Std                  1.35549\n",
      "evaluation/Rewards Max                  7.42908\n",
      "evaluation/Rewards Min                  0.0754762\n",
      "evaluation/Returns Mean              5178\n",
      "evaluation/Returns Std                 38.04\n",
      "evaluation/Returns Max               5231.27\n",
      "evaluation/Returns Min               5107.61\n",
      "evaluation/Estimation Bias Mean      1647.41\n",
      "evaluation/Estimation Bias Std        192.789\n",
      "evaluation/EB/Q_True Mean              48.8972\n",
      "evaluation/EB/Q_True Std              150.938\n",
      "evaluation/EB/Q_Pred Mean            1696.31\n",
      "evaluation/EB/Q_Pred Std              127.722\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5178\n",
      "evaluation/Actions Mean                 0.510995\n",
      "evaluation/Actions Std                  0.632547\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                2.0194\n",
      "time/backward_zf1 (s)                   2.14861\n",
      "time/backward_zf2 (s)                   2.11548\n",
      "time/data sampling (s)                  0.248108\n",
      "time/data storing (s)                   0.0160014\n",
      "time/evaluation sampling (s)            1.45487\n",
      "time/exploration sampling (s)           0.204308\n",
      "time/logging (s)                        0.0119635\n",
      "time/preback_alpha (s)                  1.06644\n",
      "time/preback_policy (s)                 1.22153\n",
      "time/preback_start (s)                  0.123445\n",
      "time/preback_zf (s)                     5.16289\n",
      "time/saving (s)                         0.00525543\n",
      "time/training (s)                       2.07332\n",
      "time/epoch (s)                         17.8716\n",
      "time/total (s)                       1526.06\n",
      "Epoch                                  89\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:36:14.919247 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 90 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 101000\n",
      "trainer/ZF1 Loss                       88.0531\n",
      "trainer/ZF2 Loss                       76.401\n",
      "trainer/ZF Expert Reward               24.0295\n",
      "trainer/ZF Policy Reward                4.15618\n",
      "trainer/ZF CHI2 Term                  121.121\n",
      "trainer/Policy Loss                 -1248.56\n",
      "trainer/Bias Loss                     258.417\n",
      "trainer/Bias Value                     20.5294\n",
      "trainer/Policy Grad Norm              441.103\n",
      "trainer/Policy Param Norm              32.4779\n",
      "trainer/Zf1 Grad Norm                7455.57\n",
      "trainer/Zf1 Param Norm                 92.7781\n",
      "trainer/Zf2 Grad Norm                7126.47\n",
      "trainer/Zf2 Param Norm                 91.5065\n",
      "trainer/Z Expert Predictions Mean    1739.89\n",
      "trainer/Z Expert Predictions Std      151.04\n",
      "trainer/Z Expert Predictions Max     1949.75\n",
      "trainer/Z Expert Predictions Min      887.909\n",
      "trainer/Z Policy Predictions Mean    1242.99\n",
      "trainer/Z Policy Predictions Std      543.535\n",
      "trainer/Z Policy Predictions Max     1910.76\n",
      "trainer/Z Policy Predictions Min     -171.631\n",
      "trainer/Z Expert Targets Mean        1715.86\n",
      "trainer/Z Expert Targets Std          151.05\n",
      "trainer/Z Expert Targets Max         1922.69\n",
      "trainer/Z Expert Targets Min          764.945\n",
      "trainer/Z Policy Targets Mean        1238.83\n",
      "trainer/Z Policy Targets Std          535.907\n",
      "trainer/Z Policy Targets Max         1883.2\n",
      "trainer/Z Policy Targets Min         -198.014\n",
      "trainer/Log Pis Mean                   19.2126\n",
      "trainer/Log Pis Std                     5.51569\n",
      "trainer/Policy mu Mean                  1.16573\n",
      "trainer/Policy mu Std                   1.89392\n",
      "trainer/Policy log std Mean            -2.20063\n",
      "trainer/Policy log std Std              1.04339\n",
      "trainer/Alpha                           0.105445\n",
      "trainer/Alpha Loss                      0.0830326\n",
      "exploration/num steps total         96197\n",
      "exploration/num paths total           675\n",
      "evaluation/num steps total         546293\n",
      "evaluation/num paths total            913\n",
      "evaluation/path length Mean           954.2\n",
      "evaluation/path length Std            103.554\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            663\n",
      "evaluation/Rewards Mean                 5.05605\n",
      "evaluation/Rewards Std                  1.31465\n",
      "evaluation/Rewards Max                  7.5204\n",
      "evaluation/Rewards Min                  0.103493\n",
      "evaluation/Returns Mean              4824.49\n",
      "evaluation/Returns Std                566.477\n",
      "evaluation/Returns Max               5222.57\n",
      "evaluation/Returns Min               3232.98\n",
      "evaluation/Estimation Bias Mean      1591.71\n",
      "evaluation/Estimation Bias Std        346.626\n",
      "evaluation/EB/Q_True Mean              51.7786\n",
      "evaluation/EB/Q_True Std              155.574\n",
      "evaluation/EB/Q_Pred Mean            1643.49\n",
      "evaluation/EB/Q_Pred Std              288.534\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4824.49\n",
      "evaluation/Actions Mean                 0.513339\n",
      "evaluation/Actions Std                  0.636479\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99395\n",
      "time/backward_zf1 (s)                   2.13179\n",
      "time/backward_zf2 (s)                   2.07733\n",
      "time/data sampling (s)                  0.252875\n",
      "time/data storing (s)                   0.0150131\n",
      "time/evaluation sampling (s)            1.43537\n",
      "time/exploration sampling (s)           0.200585\n",
      "time/logging (s)                        0.0113898\n",
      "time/preback_alpha (s)                  1.03575\n",
      "time/preback_policy (s)                 1.20781\n",
      "time/preback_start (s)                  0.122688\n",
      "time/preback_zf (s)                     5.14511\n",
      "time/saving (s)                         0.00511641\n",
      "time/training (s)                       2.1329\n",
      "time/epoch (s)                         17.7677\n",
      "time/total (s)                       1543.85\n",
      "Epoch                                  90\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:36:33.034988 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 91 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 102000\n",
      "trainer/ZF1 Loss                       57.6508\n",
      "trainer/ZF2 Loss                       48.0672\n",
      "trainer/ZF Expert Reward               21.0619\n",
      "trainer/ZF Policy Reward               -5.49446\n",
      "trainer/ZF CHI2 Term                   99.1688\n",
      "trainer/Policy Loss                 -1256.48\n",
      "trainer/Bias Loss                     177.46\n",
      "trainer/Bias Value                     20.5441\n",
      "trainer/Policy Grad Norm              204.543\n",
      "trainer/Policy Param Norm              32.5465\n",
      "trainer/Zf1 Grad Norm                7346.29\n",
      "trainer/Zf1 Param Norm                 93.1516\n",
      "trainer/Zf2 Grad Norm                7694.28\n",
      "trainer/Zf2 Param Norm                 91.8798\n",
      "trainer/Z Expert Predictions Mean    1738.5\n",
      "trainer/Z Expert Predictions Std      164.275\n",
      "trainer/Z Expert Predictions Max     1962.51\n",
      "trainer/Z Expert Predictions Min      813.942\n",
      "trainer/Z Policy Predictions Mean    1238.72\n",
      "trainer/Z Policy Predictions Std      567.399\n",
      "trainer/Z Policy Predictions Max     1938.22\n",
      "trainer/Z Policy Predictions Min     -284.204\n",
      "trainer/Z Expert Targets Mean        1717.44\n",
      "trainer/Z Expert Targets Std          162.136\n",
      "trainer/Z Expert Targets Max         1932.05\n",
      "trainer/Z Expert Targets Min          750.002\n",
      "trainer/Z Policy Targets Mean        1244.22\n",
      "trainer/Z Policy Targets Std          561.798\n",
      "trainer/Z Policy Targets Max         1940.84\n",
      "trainer/Z Policy Targets Min         -288.018\n",
      "trainer/Log Pis Mean                   19.953\n",
      "trainer/Log Pis Std                     5.5439\n",
      "trainer/Policy mu Mean                  1.22271\n",
      "trainer/Policy mu Std                   2.01884\n",
      "trainer/Policy log std Mean            -2.19415\n",
      "trainer/Policy log std Std              1.08356\n",
      "trainer/Alpha                           0.104978\n",
      "trainer/Alpha Loss                      0.00493638\n",
      "exploration/num steps total         97197\n",
      "exploration/num paths total           676\n",
      "evaluation/num steps total         556293\n",
      "evaluation/num paths total            923\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16334\n",
      "evaluation/Rewards Std                  1.31144\n",
      "evaluation/Rewards Max                  7.50255\n",
      "evaluation/Rewards Min                  0.141502\n",
      "evaluation/Returns Mean              5163.34\n",
      "evaluation/Returns Std                 45.9056\n",
      "evaluation/Returns Max               5258.74\n",
      "evaluation/Returns Min               5075.2\n",
      "evaluation/Estimation Bias Mean      1713.61\n",
      "evaluation/Estimation Bias Std        211.432\n",
      "evaluation/EB/Q_True Mean              48.5418\n",
      "evaluation/EB/Q_True Std              149.888\n",
      "evaluation/EB/Q_Pred Mean            1762.15\n",
      "evaluation/EB/Q_Pred Std              129.816\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5163.34\n",
      "evaluation/Actions Mean                 0.517236\n",
      "evaluation/Actions Std                  0.634105\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                2.05361\n",
      "time/backward_zf1 (s)                   2.19813\n",
      "time/backward_zf2 (s)                   2.15341\n",
      "time/data sampling (s)                  0.259738\n",
      "time/data storing (s)                   0.0151305\n",
      "time/evaluation sampling (s)            1.45405\n",
      "time/exploration sampling (s)           0.201908\n",
      "time/logging (s)                        0.0121892\n",
      "time/preback_alpha (s)                  1.06602\n",
      "time/preback_policy (s)                 1.21736\n",
      "time/preback_start (s)                  0.124049\n",
      "time/preback_zf (s)                     5.18389\n",
      "time/saving (s)                         0.00536231\n",
      "time/training (s)                       2.10399\n",
      "time/epoch (s)                         18.0488\n",
      "time/total (s)                       1561.92\n",
      "Epoch                                  91\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:36:50.623251 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 92 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 103000\n",
      "trainer/ZF1 Loss                      399.625\n",
      "trainer/ZF2 Loss                      422.015\n",
      "trainer/ZF Expert Reward               32.1685\n",
      "trainer/ZF Policy Reward                7.49561\n",
      "trainer/ZF CHI2 Term                  454.96\n",
      "trainer/Policy Loss                 -1292.1\n",
      "trainer/Bias Loss                    3820.02\n",
      "trainer/Bias Value                     20.5569\n",
      "trainer/Policy Grad Norm              356.534\n",
      "trainer/Policy Param Norm              32.618\n",
      "trainer/Zf1 Grad Norm               13131.1\n",
      "trainer/Zf1 Param Norm                 93.5144\n",
      "trainer/Zf2 Grad Norm               11728.1\n",
      "trainer/Zf2 Param Norm                 92.2104\n",
      "trainer/Z Expert Predictions Mean    1724.4\n",
      "trainer/Z Expert Predictions Std      171.005\n",
      "trainer/Z Expert Predictions Max     1948.35\n",
      "trainer/Z Expert Predictions Min      930.813\n",
      "trainer/Z Policy Predictions Mean    1285.87\n",
      "trainer/Z Policy Predictions Std      565.453\n",
      "trainer/Z Policy Predictions Max     1936.85\n",
      "trainer/Z Policy Predictions Min     -298.065\n",
      "trainer/Z Expert Targets Mean        1692.23\n",
      "trainer/Z Expert Targets Std          203.045\n",
      "trainer/Z Expert Targets Max         1941.5\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1278.37\n",
      "trainer/Z Policy Targets Std          554.126\n",
      "trainer/Z Policy Targets Max         1900.68\n",
      "trainer/Z Policy Targets Min         -314.796\n",
      "trainer/Log Pis Mean                   19.6636\n",
      "trainer/Log Pis Std                     5.09254\n",
      "trainer/Policy mu Mean                  1.22492\n",
      "trainer/Policy mu Std                   1.96134\n",
      "trainer/Policy log std Mean            -2.25229\n",
      "trainer/Policy log std Std              1.09856\n",
      "trainer/Alpha                           0.104193\n",
      "trainer/Alpha Loss                      0.0350534\n",
      "exploration/num steps total         97197\n",
      "exploration/num paths total           676\n",
      "evaluation/num steps total         565178\n",
      "evaluation/num paths total            933\n",
      "evaluation/path length Mean           888.5\n",
      "evaluation/path length Std            173.959\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            537\n",
      "evaluation/Rewards Mean                 5.09046\n",
      "evaluation/Rewards Std                  1.36389\n",
      "evaluation/Rewards Max                  7.57046\n",
      "evaluation/Rewards Min                  0.107872\n",
      "evaluation/Returns Mean              4522.87\n",
      "evaluation/Returns Std                988.166\n",
      "evaluation/Returns Max               5220.34\n",
      "evaluation/Returns Min               2521.45\n",
      "evaluation/Estimation Bias Mean      1586.63\n",
      "evaluation/Estimation Bias Std        372.054\n",
      "evaluation/EB/Q_True Mean              55.2683\n",
      "evaluation/EB/Q_True Std              159.704\n",
      "evaluation/EB/Q_Pred Mean            1641.9\n",
      "evaluation/EB/Q_Pred Std              309.778\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4522.87\n",
      "evaluation/Actions Mean                 0.507519\n",
      "evaluation/Actions Std                  0.637782\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89503\n",
      "time/backward_zf1 (s)                   2.05557\n",
      "time/backward_zf2 (s)                   1.95894\n",
      "time/data sampling (s)                  0.26812\n",
      "time/data storing (s)                   0.0143446\n",
      "time/evaluation sampling (s)            1.41186\n",
      "time/exploration sampling (s)           0.192177\n",
      "time/logging (s)                        0.0107893\n",
      "time/preback_alpha (s)                  0.936403\n",
      "time/preback_policy (s)                 1.03899\n",
      "time/preback_start (s)                  0.121469\n",
      "time/preback_zf (s)                     5.16345\n",
      "time/saving (s)                         0.00544789\n",
      "time/training (s)                       2.44296\n",
      "time/epoch (s)                         17.5156\n",
      "time/total (s)                       1579.46\n",
      "Epoch                                  92\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:37:08.238660 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 93 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 104000\n",
      "trainer/ZF1 Loss                       78.9564\n",
      "trainer/ZF2 Loss                       63.2337\n",
      "trainer/ZF Expert Reward               17.9649\n",
      "trainer/ZF Policy Reward                1.31199\n",
      "trainer/ZF CHI2 Term                  107.718\n",
      "trainer/Policy Loss                 -1284.01\n",
      "trainer/Bias Loss                     242.426\n",
      "trainer/Bias Value                     20.5701\n",
      "trainer/Policy Grad Norm              257.018\n",
      "trainer/Policy Param Norm              32.6908\n",
      "trainer/Zf1 Grad Norm                6024.73\n",
      "trainer/Zf1 Param Norm                 93.8634\n",
      "trainer/Zf2 Grad Norm                6411.4\n",
      "trainer/Zf2 Param Norm                 92.5211\n",
      "trainer/Z Expert Predictions Mean    1730.71\n",
      "trainer/Z Expert Predictions Std      174.857\n",
      "trainer/Z Expert Predictions Max     1945.85\n",
      "trainer/Z Expert Predictions Min      826.712\n",
      "trainer/Z Policy Predictions Mean    1270.89\n",
      "trainer/Z Policy Predictions Std      538.58\n",
      "trainer/Z Policy Predictions Max     1938.55\n",
      "trainer/Z Policy Predictions Min     -363.275\n",
      "trainer/Z Expert Targets Mean        1712.75\n",
      "trainer/Z Expert Targets Std          174.275\n",
      "trainer/Z Expert Targets Max         1938.31\n",
      "trainer/Z Expert Targets Min          818.915\n",
      "trainer/Z Policy Targets Mean        1269.58\n",
      "trainer/Z Policy Targets Std          535.039\n",
      "trainer/Z Policy Targets Max         1920.61\n",
      "trainer/Z Policy Targets Min         -331.904\n",
      "trainer/Log Pis Mean                   20.1723\n",
      "trainer/Log Pis Std                     5.89591\n",
      "trainer/Policy mu Mean                  1.24036\n",
      "trainer/Policy mu Std                   2.00315\n",
      "trainer/Policy log std Mean            -2.15858\n",
      "trainer/Policy log std Std              1.07179\n",
      "trainer/Alpha                           0.105219\n",
      "trainer/Alpha Loss                     -0.0181231\n",
      "exploration/num steps total         99197\n",
      "exploration/num paths total           678\n",
      "evaluation/num steps total         575178\n",
      "evaluation/num paths total            943\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18513\n",
      "evaluation/Rewards Std                  1.32729\n",
      "evaluation/Rewards Max                  7.81721\n",
      "evaluation/Rewards Min                  0.141607\n",
      "evaluation/Returns Mean              5185.13\n",
      "evaluation/Returns Std                 57.8462\n",
      "evaluation/Returns Max               5314.51\n",
      "evaluation/Returns Min               5093.73\n",
      "evaluation/Estimation Bias Mean      1635.25\n",
      "evaluation/Estimation Bias Std        188.346\n",
      "evaluation/EB/Q_True Mean              48.4718\n",
      "evaluation/EB/Q_True Std              149.603\n",
      "evaluation/EB/Q_Pred Mean            1683.73\n",
      "evaluation/EB/Q_Pred Std              112.192\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5185.13\n",
      "evaluation/Actions Mean                 0.542814\n",
      "evaluation/Actions Std                  0.616786\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999972\n",
      "time/backward_policy (s)                1.91333\n",
      "time/backward_zf1 (s)                   2.06927\n",
      "time/backward_zf2 (s)                   2.00644\n",
      "time/data sampling (s)                  0.266373\n",
      "time/data storing (s)                   0.0140439\n",
      "time/evaluation sampling (s)            1.46649\n",
      "time/exploration sampling (s)           0.19573\n",
      "time/logging (s)                        0.0120681\n",
      "time/preback_alpha (s)                  1.01114\n",
      "time/preback_policy (s)                 1.14942\n",
      "time/preback_start (s)                  0.121677\n",
      "time/preback_zf (s)                     5.12209\n",
      "time/saving (s)                         0.00542102\n",
      "time/training (s)                       2.19119\n",
      "time/epoch (s)                         17.5447\n",
      "time/total (s)                       1597.03\n",
      "Epoch                                  93\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:37:26.127126 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 94 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 105000\n",
      "trainer/ZF1 Loss                      311.175\n",
      "trainer/ZF2 Loss                      295.683\n",
      "trainer/ZF Expert Reward               16.1503\n",
      "trainer/ZF Policy Reward                3.50041\n",
      "trainer/ZF CHI2 Term                  335.846\n",
      "trainer/Policy Loss                 -1319.97\n",
      "trainer/Bias Loss                     519.852\n",
      "trainer/Bias Value                     20.5795\n",
      "trainer/Policy Grad Norm              249.924\n",
      "trainer/Policy Param Norm              32.7566\n",
      "trainer/Zf1 Grad Norm               16125.1\n",
      "trainer/Zf1 Param Norm                 94.2178\n",
      "trainer/Zf2 Grad Norm               11313.4\n",
      "trainer/Zf2 Param Norm                 92.8567\n",
      "trainer/Z Expert Predictions Mean    1730.87\n",
      "trainer/Z Expert Predictions Std      164.369\n",
      "trainer/Z Expert Predictions Max     1950.44\n",
      "trainer/Z Expert Predictions Min      867.212\n",
      "trainer/Z Policy Predictions Mean    1305.2\n",
      "trainer/Z Policy Predictions Std      550.839\n",
      "trainer/Z Policy Predictions Max     1915.24\n",
      "trainer/Z Policy Predictions Min     -453.125\n",
      "trainer/Z Expert Targets Mean        1714.72\n",
      "trainer/Z Expert Targets Std          163.48\n",
      "trainer/Z Expert Targets Max         1932.12\n",
      "trainer/Z Expert Targets Min          857.738\n",
      "trainer/Z Policy Targets Mean        1301.7\n",
      "trainer/Z Policy Targets Std          548.416\n",
      "trainer/Z Policy Targets Max         1872.05\n",
      "trainer/Z Policy Targets Min         -469.876\n",
      "trainer/Log Pis Mean                   19.9668\n",
      "trainer/Log Pis Std                     5.68156\n",
      "trainer/Policy mu Mean                  1.28786\n",
      "trainer/Policy mu Std                   1.9091\n",
      "trainer/Policy log std Mean            -2.16576\n",
      "trainer/Policy log std Std              1.04439\n",
      "trainer/Alpha                           0.104248\n",
      "trainer/Alpha Loss                      0.00346253\n",
      "exploration/num steps total        101197\n",
      "exploration/num paths total           680\n",
      "evaluation/num steps total         585178\n",
      "evaluation/num paths total            953\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.06418\n",
      "evaluation/Rewards Std                  1.32587\n",
      "evaluation/Rewards Max                  7.57025\n",
      "evaluation/Rewards Min                  0.116488\n",
      "evaluation/Returns Mean              5064.18\n",
      "evaluation/Returns Std                 95.4728\n",
      "evaluation/Returns Max               5189.02\n",
      "evaluation/Returns Min               4864.38\n",
      "evaluation/Estimation Bias Mean      1594.51\n",
      "evaluation/Estimation Bias Std        194.497\n",
      "evaluation/EB/Q_True Mean              48.2473\n",
      "evaluation/EB/Q_True Std              148.748\n",
      "evaluation/EB/Q_Pred Mean            1642.76\n",
      "evaluation/EB/Q_Pred Std              118.954\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5064.18\n",
      "evaluation/Actions Mean                 0.530526\n",
      "evaluation/Actions Std                  0.627383\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999929\n",
      "time/backward_policy (s)                2.02174\n",
      "time/backward_zf1 (s)                   2.19908\n",
      "time/backward_zf2 (s)                   2.12088\n",
      "time/data sampling (s)                  0.250905\n",
      "time/data storing (s)                   0.0140875\n",
      "time/evaluation sampling (s)            1.47873\n",
      "time/exploration sampling (s)           0.195665\n",
      "time/logging (s)                        0.0116574\n",
      "time/preback_alpha (s)                  1.0623\n",
      "time/preback_policy (s)                 1.21387\n",
      "time/preback_start (s)                  0.119627\n",
      "time/preback_zf (s)                     5.1252\n",
      "time/saving (s)                         0.00550696\n",
      "time/training (s)                       1.99462\n",
      "time/epoch (s)                         17.8139\n",
      "time/total (s)                       1614.87\n",
      "Epoch                                  94\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:37:43.773824 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 95 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 106000\n",
      "trainer/ZF1 Loss                       81.6649\n",
      "trainer/ZF2 Loss                       68.2375\n",
      "trainer/ZF Expert Reward               10.9679\n",
      "trainer/ZF Policy Reward               -7.00708\n",
      "trainer/ZF CHI2 Term                  112.543\n",
      "trainer/Policy Loss                 -1323.03\n",
      "trainer/Bias Loss                     313.082\n",
      "trainer/Bias Value                     20.5881\n",
      "trainer/Policy Grad Norm              291.016\n",
      "trainer/Policy Param Norm              32.8247\n",
      "trainer/Zf1 Grad Norm               12731\n",
      "trainer/Zf1 Param Norm                 94.5928\n",
      "trainer/Zf2 Grad Norm               10156.9\n",
      "trainer/Zf2 Param Norm                 93.2329\n",
      "trainer/Z Expert Predictions Mean    1713.36\n",
      "trainer/Z Expert Predictions Std      193.22\n",
      "trainer/Z Expert Predictions Max     1957.65\n",
      "trainer/Z Expert Predictions Min      892.682\n",
      "trainer/Z Policy Predictions Mean    1310.26\n",
      "trainer/Z Policy Predictions Std      567.892\n",
      "trainer/Z Policy Predictions Max     1906.85\n",
      "trainer/Z Policy Predictions Min     -419.577\n",
      "trainer/Z Expert Targets Mean        1702.39\n",
      "trainer/Z Expert Targets Std          192.72\n",
      "trainer/Z Expert Targets Max         1944.68\n",
      "trainer/Z Expert Targets Min          851.776\n",
      "trainer/Z Policy Targets Mean        1317.27\n",
      "trainer/Z Policy Targets Std          563.148\n",
      "trainer/Z Policy Targets Max         1887.18\n",
      "trainer/Z Policy Targets Min         -348.414\n",
      "trainer/Log Pis Mean                   19.8152\n",
      "trainer/Log Pis Std                     5.05219\n",
      "trainer/Policy mu Mean                  1.23324\n",
      "trainer/Policy mu Std                   1.90432\n",
      "trainer/Policy log std Mean            -2.2404\n",
      "trainer/Policy log std Std              1.05478\n",
      "trainer/Alpha                           0.104555\n",
      "trainer/Alpha Loss                      0.0193221\n",
      "exploration/num steps total        101197\n",
      "exploration/num paths total           680\n",
      "evaluation/num steps total         595178\n",
      "evaluation/num paths total            963\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17817\n",
      "evaluation/Rewards Std                  1.32407\n",
      "evaluation/Rewards Max                  7.52261\n",
      "evaluation/Rewards Min                  0.113781\n",
      "evaluation/Returns Mean              5178.17\n",
      "evaluation/Returns Std                 23.2616\n",
      "evaluation/Returns Max               5216.45\n",
      "evaluation/Returns Min               5140.09\n",
      "evaluation/Estimation Bias Mean      1724.26\n",
      "evaluation/Estimation Bias Std        204.675\n",
      "evaluation/EB/Q_True Mean              49.2181\n",
      "evaluation/EB/Q_True Std              152.121\n",
      "evaluation/EB/Q_Pred Mean            1773.48\n",
      "evaluation/EB/Q_Pred Std              116.464\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5178.17\n",
      "evaluation/Actions Mean                 0.515225\n",
      "evaluation/Actions Std                  0.626671\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.90426\n",
      "time/backward_zf1 (s)                   2.00903\n",
      "time/backward_zf2 (s)                   1.96083\n",
      "time/data sampling (s)                  0.276059\n",
      "time/data storing (s)                   0.0149207\n",
      "time/evaluation sampling (s)            1.40187\n",
      "time/exploration sampling (s)           0.192776\n",
      "time/logging (s)                        0.0114529\n",
      "time/preback_alpha (s)                  0.931436\n",
      "time/preback_policy (s)                 1.04215\n",
      "time/preback_start (s)                  0.121833\n",
      "time/preback_zf (s)                     5.15692\n",
      "time/saving (s)                         0.00536983\n",
      "time/training (s)                       2.551\n",
      "time/epoch (s)                         17.5799\n",
      "time/total (s)                       1632.47\n",
      "Epoch                                  95\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:38:01.762353 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 96 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 107000\n",
      "trainer/ZF1 Loss                       73.7858\n",
      "trainer/ZF2 Loss                      110.328\n",
      "trainer/ZF Expert Reward               23.2611\n",
      "trainer/ZF Policy Reward                5.69923\n",
      "trainer/ZF CHI2 Term                  129.342\n",
      "trainer/Policy Loss                 -1323.83\n",
      "trainer/Bias Loss                     341.061\n",
      "trainer/Bias Value                     20.5987\n",
      "trainer/Policy Grad Norm              213.879\n",
      "trainer/Policy Param Norm              32.8965\n",
      "trainer/Zf1 Grad Norm                8562.58\n",
      "trainer/Zf1 Param Norm                 94.9458\n",
      "trainer/Zf2 Grad Norm               11287.8\n",
      "trainer/Zf2 Param Norm                 93.574\n",
      "trainer/Z Expert Predictions Mean    1739.07\n",
      "trainer/Z Expert Predictions Std      168.474\n",
      "trainer/Z Expert Predictions Max     1958.87\n",
      "trainer/Z Expert Predictions Min      670.262\n",
      "trainer/Z Policy Predictions Mean    1313.79\n",
      "trainer/Z Policy Predictions Std      544.805\n",
      "trainer/Z Policy Predictions Max     1922.08\n",
      "trainer/Z Policy Predictions Min     -369.5\n",
      "trainer/Z Expert Targets Mean        1715.81\n",
      "trainer/Z Expert Targets Std          170.691\n",
      "trainer/Z Expert Targets Max         1933.52\n",
      "trainer/Z Expert Targets Min          656.563\n",
      "trainer/Z Policy Targets Mean        1308.09\n",
      "trainer/Z Policy Targets Std          533.474\n",
      "trainer/Z Policy Targets Max         1927.21\n",
      "trainer/Z Policy Targets Min         -341.95\n",
      "trainer/Log Pis Mean                   19.923\n",
      "trainer/Log Pis Std                     5.23764\n",
      "trainer/Policy mu Mean                  1.30158\n",
      "trainer/Policy mu Std                   1.96149\n",
      "trainer/Policy log std Mean            -2.13096\n",
      "trainer/Policy log std Std              1.03141\n",
      "trainer/Alpha                           0.104807\n",
      "trainer/Alpha Loss                      0.00806733\n",
      "exploration/num steps total        103197\n",
      "exploration/num paths total           682\n",
      "evaluation/num steps total         605178\n",
      "evaluation/num paths total            973\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.22453\n",
      "evaluation/Rewards Std                  1.36009\n",
      "evaluation/Rewards Max                  7.69835\n",
      "evaluation/Rewards Min                  0.0492157\n",
      "evaluation/Returns Mean              5224.53\n",
      "evaluation/Returns Std                 61.2909\n",
      "evaluation/Returns Max               5340.66\n",
      "evaluation/Returns Min               5125.84\n",
      "evaluation/Estimation Bias Mean      1683.09\n",
      "evaluation/Estimation Bias Std        197.362\n",
      "evaluation/EB/Q_True Mean              49.3773\n",
      "evaluation/EB/Q_True Std              152.549\n",
      "evaluation/EB/Q_Pred Mean            1732.47\n",
      "evaluation/EB/Q_Pred Std              133.803\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5224.53\n",
      "evaluation/Actions Mean                 0.516014\n",
      "evaluation/Actions Std                  0.625996\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999961\n",
      "time/backward_policy (s)                2.01854\n",
      "time/backward_zf1 (s)                   2.15845\n",
      "time/backward_zf2 (s)                   2.11119\n",
      "time/data sampling (s)                  0.272196\n",
      "time/data storing (s)                   0.0143071\n",
      "time/evaluation sampling (s)            1.41087\n",
      "time/exploration sampling (s)           0.199491\n",
      "time/logging (s)                        0.012261\n",
      "time/preback_alpha (s)                  1.06915\n",
      "time/preback_policy (s)                 1.2309\n",
      "time/preback_start (s)                  0.123479\n",
      "time/preback_zf (s)                     5.20413\n",
      "time/saving (s)                         0.00543622\n",
      "time/training (s)                       2.09152\n",
      "time/epoch (s)                         17.9219\n",
      "time/total (s)                       1650.41\n",
      "Epoch                                  96\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:38:19.608168 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 97 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 108000\n",
      "trainer/ZF1 Loss                       60.1307\n",
      "trainer/ZF2 Loss                       76.4843\n",
      "trainer/ZF Expert Reward               24.6191\n",
      "trainer/ZF Policy Reward               -1.44474\n",
      "trainer/ZF CHI2 Term                  114.446\n",
      "trainer/Policy Loss                 -1316.64\n",
      "trainer/Bias Loss                     405.604\n",
      "trainer/Bias Value                     20.6086\n",
      "trainer/Policy Grad Norm              287.738\n",
      "trainer/Policy Param Norm              32.9701\n",
      "trainer/Zf1 Grad Norm                7612.65\n",
      "trainer/Zf1 Param Norm                 95.2674\n",
      "trainer/Zf2 Grad Norm                7985.34\n",
      "trainer/Zf2 Param Norm                 93.8729\n",
      "trainer/Z Expert Predictions Mean    1730.12\n",
      "trainer/Z Expert Predictions Std      171.955\n",
      "trainer/Z Expert Predictions Max     1958.82\n",
      "trainer/Z Expert Predictions Min      671.046\n",
      "trainer/Z Policy Predictions Mean    1301.98\n",
      "trainer/Z Policy Predictions Std      543.114\n",
      "trainer/Z Policy Predictions Max     1900.19\n",
      "trainer/Z Policy Predictions Min     -152.32\n",
      "trainer/Z Expert Targets Mean        1705.5\n",
      "trainer/Z Expert Targets Std          170.84\n",
      "trainer/Z Expert Targets Max         1924.19\n",
      "trainer/Z Expert Targets Min          635.143\n",
      "trainer/Z Policy Targets Mean        1303.42\n",
      "trainer/Z Policy Targets Std          531.174\n",
      "trainer/Z Policy Targets Max         1864.41\n",
      "trainer/Z Policy Targets Min         -181.25\n",
      "trainer/Log Pis Mean                   20.2778\n",
      "trainer/Log Pis Std                     5.32518\n",
      "trainer/Policy mu Mean                  1.18248\n",
      "trainer/Policy mu Std                   1.97346\n",
      "trainer/Policy log std Mean            -2.22409\n",
      "trainer/Policy log std Std              1.04803\n",
      "trainer/Alpha                           0.10482\n",
      "trainer/Alpha Loss                     -0.0291188\n",
      "exploration/num steps total        103197\n",
      "exploration/num paths total           682\n",
      "evaluation/num steps total         615178\n",
      "evaluation/num paths total            983\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14853\n",
      "evaluation/Rewards Std                  1.30242\n",
      "evaluation/Rewards Max                  7.39618\n",
      "evaluation/Rewards Min                  0.143355\n",
      "evaluation/Returns Mean              5148.53\n",
      "evaluation/Returns Std                 53.1218\n",
      "evaluation/Returns Max               5211.5\n",
      "evaluation/Returns Min               5010.01\n",
      "evaluation/Estimation Bias Mean      1667.06\n",
      "evaluation/Estimation Bias Std        180.05\n",
      "evaluation/EB/Q_True Mean              48.9132\n",
      "evaluation/EB/Q_True Std              151.029\n",
      "evaluation/EB/Q_Pred Mean            1715.97\n",
      "evaluation/EB/Q_Pred Std              115.381\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5148.53\n",
      "evaluation/Actions Mean                 0.519524\n",
      "evaluation/Actions Std                  0.632451\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999867\n",
      "time/backward_policy (s)                1.99203\n",
      "time/backward_zf1 (s)                   2.15626\n",
      "time/backward_zf2 (s)                   2.10745\n",
      "time/data sampling (s)                  0.259604\n",
      "time/data storing (s)                   0.0142232\n",
      "time/evaluation sampling (s)            1.4018\n",
      "time/exploration sampling (s)           0.190021\n",
      "time/logging (s)                        0.0115603\n",
      "time/preback_alpha (s)                  1.03447\n",
      "time/preback_policy (s)                 1.18124\n",
      "time/preback_start (s)                  0.121579\n",
      "time/preback_zf (s)                     5.16609\n",
      "time/saving (s)                         0.00554708\n",
      "time/training (s)                       2.13409\n",
      "time/epoch (s)                         17.776\n",
      "time/total (s)                       1668.21\n",
      "Epoch                                  97\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:38:37.165188 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 98 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 109000\n",
      "trainer/ZF1 Loss                       57.7725\n",
      "trainer/ZF2 Loss                       76.478\n",
      "trainer/ZF Expert Reward               15.6742\n",
      "trainer/ZF Policy Reward               -4.79032\n",
      "trainer/ZF CHI2 Term                  107.017\n",
      "trainer/Policy Loss                 -1298.24\n",
      "trainer/Bias Loss                     250.74\n",
      "trainer/Bias Value                     20.6192\n",
      "trainer/Policy Grad Norm              283.842\n",
      "trainer/Policy Param Norm              33.0436\n",
      "trainer/Zf1 Grad Norm                7365.69\n",
      "trainer/Zf1 Param Norm                 95.5955\n",
      "trainer/Zf2 Grad Norm                7142.43\n",
      "trainer/Zf2 Param Norm                 94.1717\n",
      "trainer/Z Expert Predictions Mean    1742.96\n",
      "trainer/Z Expert Predictions Std      142.545\n",
      "trainer/Z Expert Predictions Max     1945.2\n",
      "trainer/Z Expert Predictions Min     1246.04\n",
      "trainer/Z Policy Predictions Mean    1277.24\n",
      "trainer/Z Policy Predictions Std      547.039\n",
      "trainer/Z Policy Predictions Max     1884.4\n",
      "trainer/Z Policy Predictions Min     -368.625\n",
      "trainer/Z Expert Targets Mean        1727.29\n",
      "trainer/Z Expert Targets Std          141.873\n",
      "trainer/Z Expert Targets Max         1939.92\n",
      "trainer/Z Expert Targets Min         1222.6\n",
      "trainer/Z Policy Targets Mean        1282.03\n",
      "trainer/Z Policy Targets Std          542.189\n",
      "trainer/Z Policy Targets Max         1877.03\n",
      "trainer/Z Policy Targets Min         -313.188\n",
      "trainer/Log Pis Mean                   19.6234\n",
      "trainer/Log Pis Std                     5.62277\n",
      "trainer/Policy mu Mean                  1.17775\n",
      "trainer/Policy mu Std                   1.95077\n",
      "trainer/Policy log std Mean            -2.19763\n",
      "trainer/Policy log std Std              1.07732\n",
      "trainer/Alpha                           0.10599\n",
      "trainer/Alpha Loss                      0.0399178\n",
      "exploration/num steps total        103197\n",
      "exploration/num paths total           682\n",
      "evaluation/num steps total         624621\n",
      "evaluation/num paths total            993\n",
      "evaluation/path length Mean           944.3\n",
      "evaluation/path length Std            167.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            443\n",
      "evaluation/Rewards Mean                 5.0934\n",
      "evaluation/Rewards Std                  1.32562\n",
      "evaluation/Rewards Max                  7.37594\n",
      "evaluation/Rewards Min                  0.11543\n",
      "evaluation/Returns Mean              4809.69\n",
      "evaluation/Returns Std                933.883\n",
      "evaluation/Returns Max               5234.13\n",
      "evaluation/Returns Min               2044.41\n",
      "evaluation/Estimation Bias Mean      1620.78\n",
      "evaluation/Estimation Bias Std        311.522\n",
      "evaluation/EB/Q_True Mean              51.8224\n",
      "evaluation/EB/Q_True Std              154.882\n",
      "evaluation/EB/Q_Pred Mean            1672.6\n",
      "evaluation/EB/Q_Pred Std              250.283\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4809.69\n",
      "evaluation/Actions Mean                 0.505126\n",
      "evaluation/Actions Std                  0.633048\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.9268\n",
      "time/backward_zf1 (s)                   2.07311\n",
      "time/backward_zf2 (s)                   2.00048\n",
      "time/data sampling (s)                  0.247592\n",
      "time/data storing (s)                   0.0151651\n",
      "time/evaluation sampling (s)            1.41622\n",
      "time/exploration sampling (s)           0.198066\n",
      "time/logging (s)                        0.0108758\n",
      "time/preback_alpha (s)                  1.00348\n",
      "time/preback_policy (s)                 1.12433\n",
      "time/preback_start (s)                  0.121021\n",
      "time/preback_zf (s)                     5.1261\n",
      "time/saving (s)                         0.00534614\n",
      "time/training (s)                       2.2218\n",
      "time/epoch (s)                         17.4904\n",
      "time/total (s)                       1685.72\n",
      "Epoch                                  98\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:38:54.879951 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 99 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 110000\n",
      "trainer/ZF1 Loss                      105.531\n",
      "trainer/ZF2 Loss                       89.0964\n",
      "trainer/ZF Expert Reward               17.8934\n",
      "trainer/ZF Policy Reward                6.1123\n",
      "trainer/ZF CHI2 Term                  129.133\n",
      "trainer/Policy Loss                 -1302.58\n",
      "trainer/Bias Loss                     454.288\n",
      "trainer/Bias Value                     20.6278\n",
      "trainer/Policy Grad Norm              313.139\n",
      "trainer/Policy Param Norm              33.1175\n",
      "trainer/Zf1 Grad Norm               10760.3\n",
      "trainer/Zf1 Param Norm                 95.9371\n",
      "trainer/Zf2 Grad Norm                7607.8\n",
      "trainer/Zf2 Param Norm                 94.4838\n",
      "trainer/Z Expert Predictions Mean    1749.31\n",
      "trainer/Z Expert Predictions Std      139.8\n",
      "trainer/Z Expert Predictions Max     1942\n",
      "trainer/Z Expert Predictions Min     1260.56\n",
      "trainer/Z Policy Predictions Mean    1284.37\n",
      "trainer/Z Policy Predictions Std      552.388\n",
      "trainer/Z Policy Predictions Max     1920.97\n",
      "trainer/Z Policy Predictions Min     -444.1\n",
      "trainer/Z Expert Targets Mean        1731.42\n",
      "trainer/Z Expert Targets Std          141.848\n",
      "trainer/Z Expert Targets Max         1916.64\n",
      "trainer/Z Expert Targets Min         1173.02\n",
      "trainer/Z Policy Targets Mean        1278.26\n",
      "trainer/Z Policy Targets Std          549.837\n",
      "trainer/Z Policy Targets Max         1915.76\n",
      "trainer/Z Policy Targets Min         -512.581\n",
      "trainer/Log Pis Mean                   20.2399\n",
      "trainer/Log Pis Std                     5.54625\n",
      "trainer/Policy mu Mean                  1.24775\n",
      "trainer/Policy mu Std                   2.0023\n",
      "trainer/Policy log std Mean            -2.21846\n",
      "trainer/Policy log std Std              1.08757\n",
      "trainer/Alpha                           0.107745\n",
      "trainer/Alpha Loss                     -0.0258447\n",
      "exploration/num steps total        104197\n",
      "exploration/num paths total           683\n",
      "evaluation/num steps total         634621\n",
      "evaluation/num paths total           1003\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.23029\n",
      "evaluation/Rewards Std                  1.34444\n",
      "evaluation/Rewards Max                  7.3991\n",
      "evaluation/Rewards Min                  0.123999\n",
      "evaluation/Returns Mean              5230.29\n",
      "evaluation/Returns Std                 24.2411\n",
      "evaluation/Returns Max               5258.19\n",
      "evaluation/Returns Min               5174.62\n",
      "evaluation/Estimation Bias Mean      1634.96\n",
      "evaluation/Estimation Bias Std        185.05\n",
      "evaluation/EB/Q_True Mean              49.5137\n",
      "evaluation/EB/Q_True Std              152.702\n",
      "evaluation/EB/Q_Pred Mean            1684.47\n",
      "evaluation/EB/Q_Pred Std              110.743\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5230.29\n",
      "evaluation/Actions Mean                 0.50834\n",
      "evaluation/Actions Std                  0.635383\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999991\n",
      "time/backward_policy (s)                1.89534\n",
      "time/backward_zf1 (s)                   2.05922\n",
      "time/backward_zf2 (s)                   1.99189\n",
      "time/data sampling (s)                  0.260507\n",
      "time/data storing (s)                   0.0149497\n",
      "time/evaluation sampling (s)            1.40807\n",
      "time/exploration sampling (s)           0.196378\n",
      "time/logging (s)                        0.0134769\n",
      "time/preback_alpha (s)                  1.00488\n",
      "time/preback_policy (s)                 1.11375\n",
      "time/preback_start (s)                  0.123667\n",
      "time/preback_zf (s)                     5.2489\n",
      "time/saving (s)                         0.00491016\n",
      "time/training (s)                       2.31453\n",
      "time/epoch (s)                         17.6505\n",
      "time/total (s)                       1703.39\n",
      "Epoch                                  99\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:39:12.823587 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 100 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 111000\n",
      "trainer/ZF1 Loss                       99.3468\n",
      "trainer/ZF2 Loss                       94.2509\n",
      "trainer/ZF Expert Reward               11.0301\n",
      "trainer/ZF Policy Reward                0.190447\n",
      "trainer/ZF CHI2 Term                  127.385\n",
      "trainer/Policy Loss                 -1305.87\n",
      "trainer/Bias Loss                     316.582\n",
      "trainer/Bias Value                     20.6361\n",
      "trainer/Policy Grad Norm              282.369\n",
      "trainer/Policy Param Norm              33.1927\n",
      "trainer/Zf1 Grad Norm                8921.97\n",
      "trainer/Zf1 Param Norm                 96.2715\n",
      "trainer/Zf2 Grad Norm                7276.22\n",
      "trainer/Zf2 Param Norm                 94.7889\n",
      "trainer/Z Expert Predictions Mean    1713.65\n",
      "trainer/Z Expert Predictions Std      157.084\n",
      "trainer/Z Expert Predictions Max     1955.51\n",
      "trainer/Z Expert Predictions Min     1001.58\n",
      "trainer/Z Policy Predictions Mean    1291.92\n",
      "trainer/Z Policy Predictions Std      540.847\n",
      "trainer/Z Policy Predictions Max     1903.28\n",
      "trainer/Z Policy Predictions Min     -231.5\n",
      "trainer/Z Expert Targets Mean        1702.62\n",
      "trainer/Z Expert Targets Std          160.327\n",
      "trainer/Z Expert Targets Max         1932.93\n",
      "trainer/Z Expert Targets Min         1016.77\n",
      "trainer/Z Policy Targets Mean        1291.73\n",
      "trainer/Z Policy Targets Std          543.737\n",
      "trainer/Z Policy Targets Max         1900.48\n",
      "trainer/Z Policy Targets Min         -364.311\n",
      "trainer/Log Pis Mean                   19.9455\n",
      "trainer/Log Pis Std                     5.17429\n",
      "trainer/Policy mu Mean                  1.28205\n",
      "trainer/Policy mu Std                   1.95091\n",
      "trainer/Policy log std Mean            -2.20092\n",
      "trainer/Policy log std Std              1.07938\n",
      "trainer/Alpha                           0.105307\n",
      "trainer/Alpha Loss                      0.00573505\n",
      "exploration/num steps total        106197\n",
      "exploration/num paths total           685\n",
      "evaluation/num steps total         644621\n",
      "evaluation/num paths total           1013\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14267\n",
      "evaluation/Rewards Std                  1.29866\n",
      "evaluation/Rewards Max                  7.07861\n",
      "evaluation/Rewards Min                  0.112936\n",
      "evaluation/Returns Mean              5142.67\n",
      "evaluation/Returns Std                 12.8465\n",
      "evaluation/Returns Max               5166.79\n",
      "evaluation/Returns Min               5118.04\n",
      "evaluation/Estimation Bias Mean      1709.88\n",
      "evaluation/Estimation Bias Std        182.666\n",
      "evaluation/EB/Q_True Mean              48.5918\n",
      "evaluation/EB/Q_True Std              149.939\n",
      "evaluation/EB/Q_Pred Mean            1758.48\n",
      "evaluation/EB/Q_Pred Std               99.7787\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5142.67\n",
      "evaluation/Actions Mean                 0.510213\n",
      "evaluation/Actions Std                  0.639396\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999677\n",
      "time/backward_policy (s)                2.04249\n",
      "time/backward_zf1 (s)                   2.17105\n",
      "time/backward_zf2 (s)                   2.12187\n",
      "time/data sampling (s)                  0.26247\n",
      "time/data storing (s)                   0.014492\n",
      "time/evaluation sampling (s)            1.41476\n",
      "time/exploration sampling (s)           0.197324\n",
      "time/logging (s)                        0.0122893\n",
      "time/preback_alpha (s)                  1.04629\n",
      "time/preback_policy (s)                 1.19056\n",
      "time/preback_start (s)                  0.122728\n",
      "time/preback_zf (s)                     5.16812\n",
      "time/saving (s)                         0.0054192\n",
      "time/training (s)                       2.10539\n",
      "time/epoch (s)                         17.8753\n",
      "time/total (s)                       1721.28\n",
      "Epoch                                 100\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:39:30.512508 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 101 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 112000\n",
      "trainer/ZF1 Loss                      783.467\n",
      "trainer/ZF2 Loss                      757.271\n",
      "trainer/ZF Expert Reward               28.1962\n",
      "trainer/ZF Policy Reward               17.862\n",
      "trainer/ZF CHI2 Term                  800.21\n",
      "trainer/Policy Loss                 -1301.65\n",
      "trainer/Bias Loss                     664.771\n",
      "trainer/Bias Value                     20.645\n",
      "trainer/Policy Grad Norm              213.219\n",
      "trainer/Policy Param Norm              33.2655\n",
      "trainer/Zf1 Grad Norm               10274.4\n",
      "trainer/Zf1 Param Norm                 96.6012\n",
      "trainer/Zf2 Grad Norm               13097.1\n",
      "trainer/Zf2 Param Norm                 95.1038\n",
      "trainer/Z Expert Predictions Mean    1744.86\n",
      "trainer/Z Expert Predictions Std      151.016\n",
      "trainer/Z Expert Predictions Max     1961.26\n",
      "trainer/Z Expert Predictions Min     1062.23\n",
      "trainer/Z Policy Predictions Mean    1292.34\n",
      "trainer/Z Policy Predictions Std      539.767\n",
      "trainer/Z Policy Predictions Max     1931.98\n",
      "trainer/Z Policy Predictions Min     -383.528\n",
      "trainer/Z Expert Targets Mean        1716.66\n",
      "trainer/Z Expert Targets Std          148.98\n",
      "trainer/Z Expert Targets Max         1935.21\n",
      "trainer/Z Expert Targets Min         1092.24\n",
      "trainer/Z Policy Targets Mean        1274.48\n",
      "trainer/Z Policy Targets Std          540.706\n",
      "trainer/Z Policy Targets Max         1925.23\n",
      "trainer/Z Policy Targets Min         -427.802\n",
      "trainer/Log Pis Mean                   19.7034\n",
      "trainer/Log Pis Std                     5.4235\n",
      "trainer/Policy mu Mean                  1.18657\n",
      "trainer/Policy mu Std                   1.91284\n",
      "trainer/Policy log std Mean            -2.23154\n",
      "trainer/Policy log std Std              1.04233\n",
      "trainer/Alpha                           0.107691\n",
      "trainer/Alpha Loss                      0.031941\n",
      "exploration/num steps total        107197\n",
      "exploration/num paths total           686\n",
      "evaluation/num steps total         654621\n",
      "evaluation/num paths total           1023\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1422\n",
      "evaluation/Rewards Std                  1.29069\n",
      "evaluation/Rewards Max                  7.07047\n",
      "evaluation/Rewards Min                  0.128169\n",
      "evaluation/Returns Mean              5142.2\n",
      "evaluation/Returns Std                 28.9342\n",
      "evaluation/Returns Max               5191.69\n",
      "evaluation/Returns Min               5092.76\n",
      "evaluation/Estimation Bias Mean      1691.08\n",
      "evaluation/Estimation Bias Std        201.65\n",
      "evaluation/EB/Q_True Mean              48.48\n",
      "evaluation/EB/Q_True Std              149.728\n",
      "evaluation/EB/Q_Pred Mean            1739.56\n",
      "evaluation/EB/Q_Pred Std              130.796\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5142.2\n",
      "evaluation/Actions Mean                 0.515073\n",
      "evaluation/Actions Std                  0.639828\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999934\n",
      "time/backward_policy (s)                1.89647\n",
      "time/backward_zf1 (s)                   2.07443\n",
      "time/backward_zf2 (s)                   1.98756\n",
      "time/data sampling (s)                  0.260078\n",
      "time/data storing (s)                   0.0145575\n",
      "time/evaluation sampling (s)            1.42489\n",
      "time/exploration sampling (s)           0.197721\n",
      "time/logging (s)                        0.0120826\n",
      "time/preback_alpha (s)                  0.938915\n",
      "time/preback_policy (s)                 1.05169\n",
      "time/preback_start (s)                  0.121008\n",
      "time/preback_zf (s)                     5.18533\n",
      "time/saving (s)                         0.00523625\n",
      "time/training (s)                       2.44841\n",
      "time/epoch (s)                         17.6184\n",
      "time/total (s)                       1738.92\n",
      "Epoch                                 101\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:39:48.501778 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 102 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 113000\n",
      "trainer/ZF1 Loss                      703.473\n",
      "trainer/ZF2 Loss                      699.934\n",
      "trainer/ZF Expert Reward               32.1426\n",
      "trainer/ZF Policy Reward                8.8702\n",
      "trainer/ZF CHI2 Term                  744.651\n",
      "trainer/Policy Loss                 -1338.65\n",
      "trainer/Bias Loss                    6691.75\n",
      "trainer/Bias Value                     20.6532\n",
      "trainer/Policy Grad Norm              202.156\n",
      "trainer/Policy Param Norm              33.3382\n",
      "trainer/Zf1 Grad Norm                8481.84\n",
      "trainer/Zf1 Param Norm                 96.9206\n",
      "trainer/Zf2 Grad Norm                7842.18\n",
      "trainer/Zf2 Param Norm                 95.3999\n",
      "trainer/Z Expert Predictions Mean    1726.95\n",
      "trainer/Z Expert Predictions Std      181.894\n",
      "trainer/Z Expert Predictions Max     1953.08\n",
      "trainer/Z Expert Predictions Min      618.699\n",
      "trainer/Z Policy Predictions Mean    1324.65\n",
      "trainer/Z Policy Predictions Std      513.297\n",
      "trainer/Z Policy Predictions Max     1926.13\n",
      "trainer/Z Policy Predictions Min     -313.332\n",
      "trainer/Z Expert Targets Mean        1694.81\n",
      "trainer/Z Expert Targets Std          212.664\n",
      "trainer/Z Expert Targets Max         1923.18\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1315.78\n",
      "trainer/Z Policy Targets Std          505.93\n",
      "trainer/Z Policy Targets Max         1895.27\n",
      "trainer/Z Policy Targets Min         -320.143\n",
      "trainer/Log Pis Mean                   19.8744\n",
      "trainer/Log Pis Std                     5.38948\n",
      "trainer/Policy mu Mean                  1.26813\n",
      "trainer/Policy mu Std                   1.90437\n",
      "trainer/Policy log std Mean            -2.22053\n",
      "trainer/Policy log std Std              1.06878\n",
      "trainer/Alpha                           0.108053\n",
      "trainer/Alpha Loss                      0.0135748\n",
      "exploration/num steps total        107197\n",
      "exploration/num paths total           686\n",
      "evaluation/num steps total         663017\n",
      "evaluation/num paths total           1033\n",
      "evaluation/path length Mean           839.6\n",
      "evaluation/path length Std            255.083\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            311\n",
      "evaluation/Rewards Mean                 5.01944\n",
      "evaluation/Rewards Std                  1.36119\n",
      "evaluation/Rewards Max                  7.55562\n",
      "evaluation/Rewards Min                  0.118141\n",
      "evaluation/Returns Mean              4214.32\n",
      "evaluation/Returns Std               1412.96\n",
      "evaluation/Returns Max               5198.04\n",
      "evaluation/Returns Min               1287.03\n",
      "evaluation/Estimation Bias Mean      1546.97\n",
      "evaluation/Estimation Bias Std        382.946\n",
      "evaluation/EB/Q_True Mean              57.1593\n",
      "evaluation/EB/Q_True Std              160.175\n",
      "evaluation/EB/Q_Pred Mean            1604.13\n",
      "evaluation/EB/Q_Pred Std              310.496\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4214.32\n",
      "evaluation/Actions Mean                 0.531965\n",
      "evaluation/Actions Std                  0.632527\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                2.02966\n",
      "time/backward_zf1 (s)                   2.17017\n",
      "time/backward_zf2 (s)                   2.12604\n",
      "time/data sampling (s)                  0.266199\n",
      "time/data storing (s)                   0.0142014\n",
      "time/evaluation sampling (s)            1.42156\n",
      "time/exploration sampling (s)           0.194648\n",
      "time/logging (s)                        0.0103565\n",
      "time/preback_alpha (s)                  1.06519\n",
      "time/preback_policy (s)                 1.2348\n",
      "time/preback_start (s)                  0.120184\n",
      "time/preback_zf (s)                     5.17382\n",
      "time/saving (s)                         0.0053276\n",
      "time/training (s)                       2.08848\n",
      "time/epoch (s)                         17.9206\n",
      "time/total (s)                       1756.86\n",
      "Epoch                                 102\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:40:06.809060 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 103 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 114000\n",
      "trainer/ZF1 Loss                       75.2715\n",
      "trainer/ZF2 Loss                       63.6817\n",
      "trainer/ZF Expert Reward               18.0638\n",
      "trainer/ZF Policy Reward                4.65346\n",
      "trainer/ZF CHI2 Term                  102.807\n",
      "trainer/Policy Loss                 -1382.65\n",
      "trainer/Bias Loss                     197.104\n",
      "trainer/Bias Value                     20.6632\n",
      "trainer/Policy Grad Norm              256.691\n",
      "trainer/Policy Param Norm              33.409\n",
      "trainer/Zf1 Grad Norm                6430.26\n",
      "trainer/Zf1 Param Norm                 97.2342\n",
      "trainer/Zf2 Grad Norm                4940.02\n",
      "trainer/Zf2 Param Norm                 95.6732\n",
      "trainer/Z Expert Predictions Mean    1724.95\n",
      "trainer/Z Expert Predictions Std      172.09\n",
      "trainer/Z Expert Predictions Max     1950.33\n",
      "trainer/Z Expert Predictions Min      821.786\n",
      "trainer/Z Policy Predictions Mean    1374.8\n",
      "trainer/Z Policy Predictions Std      501.643\n",
      "trainer/Z Policy Predictions Max     1897.22\n",
      "trainer/Z Policy Predictions Min     -191.64\n",
      "trainer/Z Expert Targets Mean        1706.89\n",
      "trainer/Z Expert Targets Std          170.347\n",
      "trainer/Z Expert Targets Max         1922.8\n",
      "trainer/Z Expert Targets Min          796.368\n",
      "trainer/Z Policy Targets Mean        1370.14\n",
      "trainer/Z Policy Targets Std          496.921\n",
      "trainer/Z Policy Targets Max         1878.18\n",
      "trainer/Z Policy Targets Min         -180.154\n",
      "trainer/Log Pis Mean                   20.1211\n",
      "trainer/Log Pis Std                     5.19389\n",
      "trainer/Policy mu Mean                  1.2985\n",
      "trainer/Policy mu Std                   1.92098\n",
      "trainer/Policy log std Mean            -2.20203\n",
      "trainer/Policy log std Std              1.07019\n",
      "trainer/Alpha                           0.109913\n",
      "trainer/Alpha Loss                     -0.0133145\n",
      "exploration/num steps total        109197\n",
      "exploration/num paths total           688\n",
      "evaluation/num steps total         673017\n",
      "evaluation/num paths total           1043\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18467\n",
      "evaluation/Rewards Std                  1.31776\n",
      "evaluation/Rewards Max                  7.55672\n",
      "evaluation/Rewards Min                  0.120029\n",
      "evaluation/Returns Mean              5184.67\n",
      "evaluation/Returns Std                 38.2129\n",
      "evaluation/Returns Max               5240.84\n",
      "evaluation/Returns Min               5098.09\n",
      "evaluation/Estimation Bias Mean      1688.95\n",
      "evaluation/Estimation Bias Std        190.068\n",
      "evaluation/EB/Q_True Mean              49.0528\n",
      "evaluation/EB/Q_True Std              151.434\n",
      "evaluation/EB/Q_Pred Mean            1738.01\n",
      "evaluation/EB/Q_Pred Std              123.666\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5184.67\n",
      "evaluation/Actions Mean                 0.510896\n",
      "evaluation/Actions Std                  0.642677\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999872\n",
      "time/backward_policy (s)                2.08222\n",
      "time/backward_zf1 (s)                   2.24525\n",
      "time/backward_zf2 (s)                   2.18185\n",
      "time/data sampling (s)                  0.287328\n",
      "time/data storing (s)                   0.0167452\n",
      "time/evaluation sampling (s)            1.44775\n",
      "time/exploration sampling (s)           0.21515\n",
      "time/logging (s)                        0.0126195\n",
      "time/preback_alpha (s)                  1.08187\n",
      "time/preback_policy (s)                 1.23702\n",
      "time/preback_start (s)                  0.126508\n",
      "time/preback_zf (s)                     5.17827\n",
      "time/saving (s)                         0.00544448\n",
      "time/training (s)                       2.12276\n",
      "time/epoch (s)                         18.2408\n",
      "time/total (s)                       1775.12\n",
      "Epoch                                 103\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:40:24.748757 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 104 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 115000\n",
      "trainer/ZF1 Loss                       66.0634\n",
      "trainer/ZF2 Loss                       66.9482\n",
      "trainer/ZF Expert Reward               17.0375\n",
      "trainer/ZF Policy Reward                2.24861\n",
      "trainer/ZF CHI2 Term                  101.374\n",
      "trainer/Policy Loss                 -1353.05\n",
      "trainer/Bias Loss                     357.625\n",
      "trainer/Bias Value                     20.6719\n",
      "trainer/Policy Grad Norm              283.416\n",
      "trainer/Policy Param Norm              33.4838\n",
      "trainer/Zf1 Grad Norm                7146.72\n",
      "trainer/Zf1 Param Norm                 97.5419\n",
      "trainer/Zf2 Grad Norm                8915.66\n",
      "trainer/Zf2 Param Norm                 95.9683\n",
      "trainer/Z Expert Predictions Mean    1702.69\n",
      "trainer/Z Expert Predictions Std      198.582\n",
      "trainer/Z Expert Predictions Max     1936.4\n",
      "trainer/Z Expert Predictions Min      181.452\n",
      "trainer/Z Policy Predictions Mean    1339.32\n",
      "trainer/Z Policy Predictions Std      500.271\n",
      "trainer/Z Policy Predictions Max     1935.75\n",
      "trainer/Z Policy Predictions Min     -311.353\n",
      "trainer/Z Expert Targets Mean        1685.65\n",
      "trainer/Z Expert Targets Std          209.663\n",
      "trainer/Z Expert Targets Max         1930.11\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1337.07\n",
      "trainer/Z Policy Targets Std          497.367\n",
      "trainer/Z Policy Targets Max         1927.33\n",
      "trainer/Z Policy Targets Min         -359.714\n",
      "trainer/Log Pis Mean                   20.2818\n",
      "trainer/Log Pis Std                     5.79226\n",
      "trainer/Policy mu Mean                  1.24465\n",
      "trainer/Policy mu Std                   2.00366\n",
      "trainer/Policy log std Mean            -2.21475\n",
      "trainer/Policy log std Std              1.06125\n",
      "trainer/Alpha                           0.110271\n",
      "trainer/Alpha Loss                     -0.0310748\n",
      "exploration/num steps total        111197\n",
      "exploration/num paths total           690\n",
      "evaluation/num steps total         683017\n",
      "evaluation/num paths total           1053\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1669\n",
      "evaluation/Rewards Std                  1.29903\n",
      "evaluation/Rewards Max                  7.07799\n",
      "evaluation/Rewards Min                  0.142759\n",
      "evaluation/Returns Mean              5166.9\n",
      "evaluation/Returns Std                 18.5689\n",
      "evaluation/Returns Max               5192.68\n",
      "evaluation/Returns Min               5131.34\n",
      "evaluation/Estimation Bias Mean      1719.93\n",
      "evaluation/Estimation Bias Std        195.947\n",
      "evaluation/EB/Q_True Mean              48.5502\n",
      "evaluation/EB/Q_True Std              149.73\n",
      "evaluation/EB/Q_Pred Mean            1768.48\n",
      "evaluation/EB/Q_Pred Std              140.63\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5166.9\n",
      "evaluation/Actions Mean                 0.51138\n",
      "evaluation/Actions Std                  0.646751\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999953\n",
      "time/backward_policy (s)                1.95528\n",
      "time/backward_zf1 (s)                   2.15606\n",
      "time/backward_zf2 (s)                   2.03202\n",
      "time/data sampling (s)                  0.282884\n",
      "time/data storing (s)                   0.0170139\n",
      "time/evaluation sampling (s)            1.42179\n",
      "time/exploration sampling (s)           0.217541\n",
      "time/logging (s)                        0.011958\n",
      "time/preback_alpha (s)                  1.00717\n",
      "time/preback_policy (s)                 1.1072\n",
      "time/preback_start (s)                  0.130523\n",
      "time/preback_zf (s)                     5.19903\n",
      "time/saving (s)                         0.00544039\n",
      "time/training (s)                       2.3264\n",
      "time/epoch (s)                         17.8703\n",
      "time/total (s)                       1793.01\n",
      "Epoch                                 104\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:40:42.982829 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 105 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 116000\n",
      "trainer/ZF1 Loss                       71.9126\n",
      "trainer/ZF2 Loss                       50.5714\n",
      "trainer/ZF Expert Reward               16.4466\n",
      "trainer/ZF Policy Reward               -0.672221\n",
      "trainer/ZF CHI2 Term                   98.5916\n",
      "trainer/Policy Loss                 -1361.85\n",
      "trainer/Bias Loss                     204.379\n",
      "trainer/Bias Value                     20.6791\n",
      "trainer/Policy Grad Norm              333.83\n",
      "trainer/Policy Param Norm              33.5553\n",
      "trainer/Zf1 Grad Norm                5358.82\n",
      "trainer/Zf1 Param Norm                 97.8532\n",
      "trainer/Zf2 Grad Norm                5847.93\n",
      "trainer/Zf2 Param Norm                 96.2796\n",
      "trainer/Z Expert Predictions Mean    1717.51\n",
      "trainer/Z Expert Predictions Std      173.312\n",
      "trainer/Z Expert Predictions Max     1943.05\n",
      "trainer/Z Expert Predictions Min      750.09\n",
      "trainer/Z Policy Predictions Mean    1350.08\n",
      "trainer/Z Policy Predictions Std      489.245\n",
      "trainer/Z Policy Predictions Max     1925.08\n",
      "trainer/Z Policy Predictions Min     -303.57\n",
      "trainer/Z Expert Targets Mean        1701.06\n",
      "trainer/Z Expert Targets Std          173.68\n",
      "trainer/Z Expert Targets Max         1925.58\n",
      "trainer/Z Expert Targets Min          726.507\n",
      "trainer/Z Policy Targets Mean        1350.75\n",
      "trainer/Z Policy Targets Std          477.339\n",
      "trainer/Z Policy Targets Max         1909.24\n",
      "trainer/Z Policy Targets Min         -231.154\n",
      "trainer/Log Pis Mean                   20.4351\n",
      "trainer/Log Pis Std                     5.48944\n",
      "trainer/Policy mu Mean                  1.22278\n",
      "trainer/Policy mu Std                   1.89446\n",
      "trainer/Policy log std Mean            -2.31896\n",
      "trainer/Policy log std Std              1.07624\n",
      "trainer/Alpha                           0.110778\n",
      "trainer/Alpha Loss                     -0.0481964\n",
      "exploration/num steps total        111197\n",
      "exploration/num paths total           690\n",
      "evaluation/num steps total         693017\n",
      "evaluation/num paths total           1063\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14807\n",
      "evaluation/Rewards Std                  1.30649\n",
      "evaluation/Rewards Max                  7.37052\n",
      "evaluation/Rewards Min                  0.124072\n",
      "evaluation/Returns Mean              5148.07\n",
      "evaluation/Returns Std                 41.7534\n",
      "evaluation/Returns Max               5218.02\n",
      "evaluation/Returns Min               5055.38\n",
      "evaluation/Estimation Bias Mean      1644.29\n",
      "evaluation/Estimation Bias Std        189.587\n",
      "evaluation/EB/Q_True Mean              48.288\n",
      "evaluation/EB/Q_True Std              149.018\n",
      "evaluation/EB/Q_Pred Mean            1692.58\n",
      "evaluation/EB/Q_Pred Std              118.017\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5148.07\n",
      "evaluation/Actions Mean                 0.536607\n",
      "evaluation/Actions Std                  0.628621\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999937\n",
      "time/backward_policy (s)                2.05914\n",
      "time/backward_zf1 (s)                   2.18842\n",
      "time/backward_zf2 (s)                   2.13309\n",
      "time/data sampling (s)                  0.279162\n",
      "time/data storing (s)                   0.0145743\n",
      "time/evaluation sampling (s)            1.44382\n",
      "time/exploration sampling (s)           0.193832\n",
      "time/logging (s)                        0.0121938\n",
      "time/preback_alpha (s)                  1.08855\n",
      "time/preback_policy (s)                 1.2441\n",
      "time/preback_start (s)                  0.128942\n",
      "time/preback_zf (s)                     5.23906\n",
      "time/saving (s)                         0.00580471\n",
      "time/training (s)                       2.13394\n",
      "time/epoch (s)                         18.1646\n",
      "time/total (s)                       1811.2\n",
      "Epoch                                 105\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:41:01.468213 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 106 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 117000\n",
      "trainer/ZF1 Loss                      133.822\n",
      "trainer/ZF2 Loss                      124.711\n",
      "trainer/ZF Expert Reward               15.006\n",
      "trainer/ZF Policy Reward                2.32804\n",
      "trainer/ZF CHI2 Term                  162.233\n",
      "trainer/Policy Loss                 -1375.34\n",
      "trainer/Bias Loss                     391.255\n",
      "trainer/Bias Value                     20.6863\n",
      "trainer/Policy Grad Norm              322.682\n",
      "trainer/Policy Param Norm              33.6236\n",
      "trainer/Zf1 Grad Norm               11383.7\n",
      "trainer/Zf1 Param Norm                 98.1571\n",
      "trainer/Zf2 Grad Norm               11153.9\n",
      "trainer/Zf2 Param Norm                 96.5725\n",
      "trainer/Z Expert Predictions Mean    1693.73\n",
      "trainer/Z Expert Predictions Std      181.647\n",
      "trainer/Z Expert Predictions Max     1941.19\n",
      "trainer/Z Expert Predictions Min      466.669\n",
      "trainer/Z Policy Predictions Mean    1355.74\n",
      "trainer/Z Policy Predictions Std      454.517\n",
      "trainer/Z Policy Predictions Max     1922.08\n",
      "trainer/Z Policy Predictions Min     -289.73\n",
      "trainer/Z Expert Targets Mean        1678.72\n",
      "trainer/Z Expert Targets Std          181.094\n",
      "trainer/Z Expert Targets Max         1935.84\n",
      "trainer/Z Expert Targets Min          448.112\n",
      "trainer/Z Policy Targets Mean        1353.41\n",
      "trainer/Z Policy Targets Std          452.455\n",
      "trainer/Z Policy Targets Max         1922.38\n",
      "trainer/Z Policy Targets Min         -280.448\n",
      "trainer/Log Pis Mean                   20.4931\n",
      "trainer/Log Pis Std                     5.04874\n",
      "trainer/Policy mu Mean                  1.23286\n",
      "trainer/Policy mu Std                   1.91792\n",
      "trainer/Policy log std Mean            -2.24454\n",
      "trainer/Policy log std Std              1.04377\n",
      "trainer/Alpha                           0.112086\n",
      "trainer/Alpha Loss                     -0.0552644\n",
      "exploration/num steps total        113197\n",
      "exploration/num paths total           692\n",
      "evaluation/num steps total         703017\n",
      "evaluation/num paths total           1073\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.05475\n",
      "evaluation/Rewards Std                  1.2635\n",
      "evaluation/Rewards Max                  7.00428\n",
      "evaluation/Rewards Min                  0.128718\n",
      "evaluation/Returns Mean              5054.75\n",
      "evaluation/Returns Std                 74.2261\n",
      "evaluation/Returns Max               5131.99\n",
      "evaluation/Returns Min               4901.91\n",
      "evaluation/Estimation Bias Mean      1698.62\n",
      "evaluation/Estimation Bias Std        215.283\n",
      "evaluation/EB/Q_True Mean              47.2566\n",
      "evaluation/EB/Q_True Std              145.943\n",
      "evaluation/EB/Q_Pred Mean            1745.88\n",
      "evaluation/EB/Q_Pred Std              178.392\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5054.75\n",
      "evaluation/Actions Mean                 0.494649\n",
      "evaluation/Actions Std                  0.649525\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999991\n",
      "time/backward_policy (s)                2.09386\n",
      "time/backward_zf1 (s)                   2.2612\n",
      "time/backward_zf2 (s)                   2.1855\n",
      "time/data sampling (s)                  0.276191\n",
      "time/data storing (s)                   0.0162826\n",
      "time/evaluation sampling (s)            1.52091\n",
      "time/exploration sampling (s)           0.210275\n",
      "time/logging (s)                        0.0119538\n",
      "time/preback_alpha (s)                  1.09165\n",
      "time/preback_policy (s)                 1.2494\n",
      "time/preback_start (s)                  0.127485\n",
      "time/preback_zf (s)                     5.24491\n",
      "time/saving (s)                         0.00548469\n",
      "time/training (s)                       2.12294\n",
      "time/epoch (s)                         18.418\n",
      "time/total (s)                       1829.63\n",
      "Epoch                                 106\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:41:19.480914 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 107 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 118000\n",
      "trainer/ZF1 Loss                       95.4214\n",
      "trainer/ZF2 Loss                       93.5281\n",
      "trainer/ZF Expert Reward               14.27\n",
      "trainer/ZF Policy Reward                2.14768\n",
      "trainer/ZF CHI2 Term                  125.947\n",
      "trainer/Policy Loss                 -1278.19\n",
      "trainer/Bias Loss                     498.034\n",
      "trainer/Bias Value                     20.6972\n",
      "trainer/Policy Grad Norm              347.629\n",
      "trainer/Policy Param Norm              33.6927\n",
      "trainer/Zf1 Grad Norm                7906.76\n",
      "trainer/Zf1 Param Norm                 98.4797\n",
      "trainer/Zf2 Grad Norm                7946.19\n",
      "trainer/Zf2 Param Norm                 96.8879\n",
      "trainer/Z Expert Predictions Mean    1688.88\n",
      "trainer/Z Expert Predictions Std      200.646\n",
      "trainer/Z Expert Predictions Max     1944.21\n",
      "trainer/Z Expert Predictions Min      513.822\n",
      "trainer/Z Policy Predictions Mean    1267.44\n",
      "trainer/Z Policy Predictions Std      555.667\n",
      "trainer/Z Policy Predictions Max     1867.69\n",
      "trainer/Z Policy Predictions Min     -212.93\n",
      "trainer/Z Expert Targets Mean        1674.61\n",
      "trainer/Z Expert Targets Std          201.722\n",
      "trainer/Z Expert Targets Max         1931.78\n",
      "trainer/Z Expert Targets Min          482.18\n",
      "trainer/Z Policy Targets Mean        1265.3\n",
      "trainer/Z Policy Targets Std          551.621\n",
      "trainer/Z Policy Targets Max         1859.81\n",
      "trainer/Z Policy Targets Min         -276.111\n",
      "trainer/Log Pis Mean                   19.5455\n",
      "trainer/Log Pis Std                     5.37955\n",
      "trainer/Policy mu Mean                  1.21478\n",
      "trainer/Policy mu Std                   2.03345\n",
      "trainer/Policy log std Mean            -2.08786\n",
      "trainer/Policy log std Std              1.09358\n",
      "trainer/Alpha                           0.112597\n",
      "trainer/Alpha Loss                      0.0511751\n",
      "exploration/num steps total        113197\n",
      "exploration/num paths total           692\n",
      "evaluation/num steps total         713017\n",
      "evaluation/num paths total           1083\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19254\n",
      "evaluation/Rewards Std                  1.29861\n",
      "evaluation/Rewards Max                  7.20406\n",
      "evaluation/Rewards Min                  0.142631\n",
      "evaluation/Returns Mean              5192.54\n",
      "evaluation/Returns Std                 31.1674\n",
      "evaluation/Returns Max               5243.61\n",
      "evaluation/Returns Min               5140.87\n",
      "evaluation/Estimation Bias Mean      1682.61\n",
      "evaluation/Estimation Bias Std        178.042\n",
      "evaluation/EB/Q_True Mean              49.1265\n",
      "evaluation/EB/Q_True Std              151.654\n",
      "evaluation/EB/Q_Pred Mean            1731.73\n",
      "evaluation/EB/Q_Pred Std              115.698\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5192.54\n",
      "evaluation/Actions Mean                 0.531429\n",
      "evaluation/Actions Std                  0.636217\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999922\n",
      "time/backward_policy (s)                2.02438\n",
      "time/backward_zf1 (s)                   2.19745\n",
      "time/backward_zf2 (s)                   2.12881\n",
      "time/data sampling (s)                  0.265077\n",
      "time/data storing (s)                   0.0150167\n",
      "time/evaluation sampling (s)            1.43571\n",
      "time/exploration sampling (s)           0.196846\n",
      "time/logging (s)                        0.0113779\n",
      "time/preback_alpha (s)                  1.0715\n",
      "time/preback_policy (s)                 1.2232\n",
      "time/preback_start (s)                  0.123293\n",
      "time/preback_zf (s)                     5.15894\n",
      "time/saving (s)                         0.00540512\n",
      "time/training (s)                       2.08694\n",
      "time/epoch (s)                         17.944\n",
      "time/total (s)                       1847.6\n",
      "Epoch                                 107\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:41:37.686639 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 108 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 119000\n",
      "trainer/ZF1 Loss                       46.2732\n",
      "trainer/ZF2 Loss                       48.1914\n",
      "trainer/ZF Expert Reward               27.16\n",
      "trainer/ZF Policy Reward                2.08952\n",
      "trainer/ZF CHI2 Term                   92.0699\n",
      "trainer/Policy Loss                 -1381.86\n",
      "trainer/Bias Loss                     273.268\n",
      "trainer/Bias Value                     20.7047\n",
      "trainer/Policy Grad Norm              384.39\n",
      "trainer/Policy Param Norm              33.7595\n",
      "trainer/Zf1 Grad Norm                6457.78\n",
      "trainer/Zf1 Param Norm                 98.7906\n",
      "trainer/Zf2 Grad Norm                5455.23\n",
      "trainer/Zf2 Param Norm                 97.1714\n",
      "trainer/Z Expert Predictions Mean    1708.94\n",
      "trainer/Z Expert Predictions Std      179.442\n",
      "trainer/Z Expert Predictions Max     1947.62\n",
      "trainer/Z Expert Predictions Min      937.477\n",
      "trainer/Z Policy Predictions Mean    1368.16\n",
      "trainer/Z Policy Predictions Std      464.34\n",
      "trainer/Z Policy Predictions Max     1896.13\n",
      "trainer/Z Policy Predictions Min     -188.46\n",
      "trainer/Z Expert Targets Mean        1681.78\n",
      "trainer/Z Expert Targets Std          179.003\n",
      "trainer/Z Expert Targets Max         1924.53\n",
      "trainer/Z Expert Targets Min          881.271\n",
      "trainer/Z Policy Targets Mean        1366.07\n",
      "trainer/Z Policy Targets Std          463.039\n",
      "trainer/Z Policy Targets Max         1892.59\n",
      "trainer/Z Policy Targets Min         -249.46\n",
      "trainer/Log Pis Mean                   19.9668\n",
      "trainer/Log Pis Std                     4.88916\n",
      "trainer/Policy mu Mean                  1.2837\n",
      "trainer/Policy mu Std                   1.87737\n",
      "trainer/Policy log std Mean            -2.23039\n",
      "trainer/Policy log std Std              1.05983\n",
      "trainer/Alpha                           0.112732\n",
      "trainer/Alpha Loss                      0.00374301\n",
      "exploration/num steps total        113197\n",
      "exploration/num paths total           692\n",
      "evaluation/num steps total         721542\n",
      "evaluation/num paths total           1093\n",
      "evaluation/path length Mean           852.5\n",
      "evaluation/path length Std            208.512\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            434\n",
      "evaluation/Rewards Mean                 5.02948\n",
      "evaluation/Rewards Std                  1.36665\n",
      "evaluation/Rewards Max                  7.17407\n",
      "evaluation/Rewards Min                  0.130965\n",
      "evaluation/Returns Mean              4287.63\n",
      "evaluation/Returns Std               1171.89\n",
      "evaluation/Returns Max               5183.27\n",
      "evaluation/Returns Min               1952.34\n",
      "evaluation/Estimation Bias Mean      1569.19\n",
      "evaluation/Estimation Bias Std        366.517\n",
      "evaluation/EB/Q_True Mean              56.9751\n",
      "evaluation/EB/Q_True Std              160.932\n",
      "evaluation/EB/Q_Pred Mean            1626.17\n",
      "evaluation/EB/Q_Pred Std              290.03\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4287.63\n",
      "evaluation/Actions Mean                 0.514566\n",
      "evaluation/Actions Std                  0.634359\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.04932\n",
      "time/backward_zf1 (s)                   2.21131\n",
      "time/backward_zf2 (s)                   2.16914\n",
      "time/data sampling (s)                  0.260265\n",
      "time/data storing (s)                   0.0163472\n",
      "time/evaluation sampling (s)            1.44421\n",
      "time/exploration sampling (s)           0.213093\n",
      "time/logging (s)                        0.00990069\n",
      "time/preback_alpha (s)                  1.08704\n",
      "time/preback_policy (s)                 1.24914\n",
      "time/preback_start (s)                  0.125134\n",
      "time/preback_zf (s)                     5.19996\n",
      "time/saving (s)                         0.00505249\n",
      "time/training (s)                       2.0956\n",
      "time/epoch (s)                         18.1355\n",
      "time/total (s)                       1865.75\n",
      "Epoch                                 108\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:41:55.962990 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 109 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 120000\n",
      "trainer/ZF1 Loss                      724.589\n",
      "trainer/ZF2 Loss                      689.885\n",
      "trainer/ZF Expert Reward               22.469\n",
      "trainer/ZF Policy Reward                2.15989\n",
      "trainer/ZF CHI2 Term                  746.905\n",
      "trainer/Policy Loss                 -1313.94\n",
      "trainer/Bias Loss                    6459.89\n",
      "trainer/Bias Value                     20.7141\n",
      "trainer/Policy Grad Norm              297.169\n",
      "trainer/Policy Param Norm              33.8268\n",
      "trainer/Zf1 Grad Norm                7382.82\n",
      "trainer/Zf1 Param Norm                 99.0969\n",
      "trainer/Zf2 Grad Norm                6465.17\n",
      "trainer/Zf2 Param Norm                 97.4671\n",
      "trainer/Z Expert Predictions Mean    1695.1\n",
      "trainer/Z Expert Predictions Std      163.702\n",
      "trainer/Z Expert Predictions Max     1945.72\n",
      "trainer/Z Expert Predictions Min      825.427\n",
      "trainer/Z Policy Predictions Mean    1301.99\n",
      "trainer/Z Policy Predictions Std      503.83\n",
      "trainer/Z Policy Predictions Max     1914.15\n",
      "trainer/Z Policy Predictions Min     -202.957\n",
      "trainer/Z Expert Targets Mean        1672.63\n",
      "trainer/Z Expert Targets Std          196.562\n",
      "trainer/Z Expert Targets Max         1915.63\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1299.83\n",
      "trainer/Z Policy Targets Std          501.466\n",
      "trainer/Z Policy Targets Max         1906.86\n",
      "trainer/Z Policy Targets Min         -231.485\n",
      "trainer/Log Pis Mean                   19.5545\n",
      "trainer/Log Pis Std                     4.92688\n",
      "trainer/Policy mu Mean                  1.20602\n",
      "trainer/Policy mu Std                   1.86417\n",
      "trainer/Policy log std Mean            -2.21908\n",
      "trainer/Policy log std Std              1.04254\n",
      "trainer/Alpha                           0.113368\n",
      "trainer/Alpha Loss                      0.0505052\n",
      "exploration/num steps total        114197\n",
      "exploration/num paths total           693\n",
      "evaluation/num steps total         731542\n",
      "evaluation/num paths total           1103\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25832\n",
      "evaluation/Rewards Std                  1.33769\n",
      "evaluation/Rewards Max                  7.38448\n",
      "evaluation/Rewards Min                  0.12431\n",
      "evaluation/Returns Mean              5258.32\n",
      "evaluation/Returns Std                 15.972\n",
      "evaluation/Returns Max               5279.62\n",
      "evaluation/Returns Min               5225.23\n",
      "evaluation/Estimation Bias Mean      1691.43\n",
      "evaluation/Estimation Bias Std        192.281\n",
      "evaluation/EB/Q_True Mean              49.8602\n",
      "evaluation/EB/Q_True Std              153.862\n",
      "evaluation/EB/Q_Pred Mean            1741.29\n",
      "evaluation/EB/Q_Pred Std              111.249\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5258.32\n",
      "evaluation/Actions Mean                 0.500912\n",
      "evaluation/Actions Std                  0.65873\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999843\n",
      "time/backward_policy (s)                1.96904\n",
      "time/backward_zf1 (s)                   2.15019\n",
      "time/backward_zf2 (s)                   2.0786\n",
      "time/data sampling (s)                  0.292654\n",
      "time/data storing (s)                   0.0149727\n",
      "time/evaluation sampling (s)            1.4848\n",
      "time/exploration sampling (s)           0.204713\n",
      "time/logging (s)                        0.0142769\n",
      "time/preback_alpha (s)                  0.995198\n",
      "time/preback_policy (s)                 1.14225\n",
      "time/preback_start (s)                  0.130987\n",
      "time/preback_zf (s)                     5.24842\n",
      "time/saving (s)                         0.00625648\n",
      "time/training (s)                       2.48102\n",
      "time/epoch (s)                         18.2134\n",
      "time/total (s)                       1883.98\n",
      "Epoch                                 109\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:42:13.375020 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 110 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 121000\n",
      "trainer/ZF1 Loss                       69.1026\n",
      "trainer/ZF2 Loss                       73.3876\n",
      "trainer/ZF Expert Reward               22.0014\n",
      "trainer/ZF Policy Reward                3.08547\n",
      "trainer/ZF CHI2 Term                  110.269\n",
      "trainer/Policy Loss                 -1343.3\n",
      "trainer/Bias Loss                     393.88\n",
      "trainer/Bias Value                     20.7206\n",
      "trainer/Policy Grad Norm              228.422\n",
      "trainer/Policy Param Norm              33.8897\n",
      "trainer/Zf1 Grad Norm                6112.32\n",
      "trainer/Zf1 Param Norm                 99.3865\n",
      "trainer/Zf2 Grad Norm                6430.96\n",
      "trainer/Zf2 Param Norm                 97.7316\n",
      "trainer/Z Expert Predictions Mean    1700.76\n",
      "trainer/Z Expert Predictions Std      177.186\n",
      "trainer/Z Expert Predictions Max     1942.39\n",
      "trainer/Z Expert Predictions Min      822.037\n",
      "trainer/Z Policy Predictions Mean    1326.09\n",
      "trainer/Z Policy Predictions Std      493.859\n",
      "trainer/Z Policy Predictions Max     1897.64\n",
      "trainer/Z Policy Predictions Min     -203.963\n",
      "trainer/Z Expert Targets Mean        1678.76\n",
      "trainer/Z Expert Targets Std          177.405\n",
      "trainer/Z Expert Targets Max         1926.53\n",
      "trainer/Z Expert Targets Min          779.241\n",
      "trainer/Z Policy Targets Mean        1323.01\n",
      "trainer/Z Policy Targets Std          486.303\n",
      "trainer/Z Policy Targets Max         1902.68\n",
      "trainer/Z Policy Targets Min         -157.601\n",
      "trainer/Log Pis Mean                   20.3112\n",
      "trainer/Log Pis Std                     4.73537\n",
      "trainer/Policy mu Mean                  1.314\n",
      "trainer/Policy mu Std                   1.85745\n",
      "trainer/Policy log std Mean            -2.22359\n",
      "trainer/Policy log std Std              1.0409\n",
      "trainer/Alpha                           0.113456\n",
      "trainer/Alpha Loss                     -0.035303\n",
      "exploration/num steps total        116197\n",
      "exploration/num paths total           695\n",
      "evaluation/num steps total         741542\n",
      "evaluation/num paths total           1113\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2237\n",
      "evaluation/Rewards Std                  1.32554\n",
      "evaluation/Rewards Max                  7.37339\n",
      "evaluation/Rewards Min                  0.115087\n",
      "evaluation/Returns Mean              5223.7\n",
      "evaluation/Returns Std                 18.1804\n",
      "evaluation/Returns Max               5253.99\n",
      "evaluation/Returns Min               5197.01\n",
      "evaluation/Estimation Bias Mean      1677.06\n",
      "evaluation/Estimation Bias Std        189.945\n",
      "evaluation/EB/Q_True Mean              49.2558\n",
      "evaluation/EB/Q_True Std              152.127\n",
      "evaluation/EB/Q_Pred Mean            1726.32\n",
      "evaluation/EB/Q_Pred Std              120.105\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5223.7\n",
      "evaluation/Actions Mean                 0.492401\n",
      "evaluation/Actions Std                  0.654224\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99985\n",
      "time/backward_policy (s)                1.83107\n",
      "time/backward_zf1 (s)                   1.96602\n",
      "time/backward_zf2 (s)                   1.87077\n",
      "time/data sampling (s)                  0.266255\n",
      "time/data storing (s)                   0.013822\n",
      "time/evaluation sampling (s)            1.53424\n",
      "time/exploration sampling (s)           0.198335\n",
      "time/logging (s)                        0.016649\n",
      "time/preback_alpha (s)                  0.937634\n",
      "time/preback_policy (s)                 1.03596\n",
      "time/preback_start (s)                  0.124218\n",
      "time/preback_zf (s)                     5.12024\n",
      "time/saving (s)                         0.0132471\n",
      "time/training (s)                       2.41642\n",
      "time/epoch (s)                         17.3449\n",
      "time/total (s)                       1901.35\n",
      "Epoch                                 110\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:42:30.898686 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 111 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 122000\n",
      "trainer/ZF1 Loss                       70.2063\n",
      "trainer/ZF2 Loss                       70.0398\n",
      "trainer/ZF Expert Reward               19.441\n",
      "trainer/ZF Policy Reward                3.01029\n",
      "trainer/ZF CHI2 Term                  107.345\n",
      "trainer/Policy Loss                 -1313.57\n",
      "trainer/Bias Loss                     268.32\n",
      "trainer/Bias Value                     20.7264\n",
      "trainer/Policy Grad Norm              235.018\n",
      "trainer/Policy Param Norm              33.9485\n",
      "trainer/Zf1 Grad Norm                4892.58\n",
      "trainer/Zf1 Param Norm                 99.7034\n",
      "trainer/Zf2 Grad Norm                6283.93\n",
      "trainer/Zf2 Param Norm                 98.03\n",
      "trainer/Z Expert Predictions Mean    1691.59\n",
      "trainer/Z Expert Predictions Std      156.448\n",
      "trainer/Z Expert Predictions Max     1936.12\n",
      "trainer/Z Expert Predictions Min      697.566\n",
      "trainer/Z Policy Predictions Mean    1305.13\n",
      "trainer/Z Policy Predictions Std      511.722\n",
      "trainer/Z Policy Predictions Max     1911.65\n",
      "trainer/Z Policy Predictions Min     -164.659\n",
      "trainer/Z Expert Targets Mean        1672.15\n",
      "trainer/Z Expert Targets Std          160.495\n",
      "trainer/Z Expert Targets Max         1927.07\n",
      "trainer/Z Expert Targets Min          680.009\n",
      "trainer/Z Policy Targets Mean        1302.12\n",
      "trainer/Z Policy Targets Std          509.271\n",
      "trainer/Z Policy Targets Max         1936.09\n",
      "trainer/Z Policy Targets Min         -158.755\n",
      "trainer/Log Pis Mean                   21.0015\n",
      "trainer/Log Pis Std                     5.54397\n",
      "trainer/Policy mu Mean                  1.30926\n",
      "trainer/Policy mu Std                   1.99611\n",
      "trainer/Policy log std Mean            -2.20471\n",
      "trainer/Policy log std Std              1.09428\n",
      "trainer/Alpha                           0.115813\n",
      "trainer/Alpha Loss                     -0.115973\n",
      "exploration/num steps total        117197\n",
      "exploration/num paths total           696\n",
      "evaluation/num steps total         751542\n",
      "evaluation/num paths total           1123\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09006\n",
      "evaluation/Rewards Std                  1.27932\n",
      "evaluation/Rewards Max                  7.15399\n",
      "evaluation/Rewards Min                  0.121258\n",
      "evaluation/Returns Mean              5090.06\n",
      "evaluation/Returns Std                 25.1384\n",
      "evaluation/Returns Max               5139.33\n",
      "evaluation/Returns Min               5052.89\n",
      "evaluation/Estimation Bias Mean      1680.88\n",
      "evaluation/Estimation Bias Std        194.142\n",
      "evaluation/EB/Q_True Mean              47.8462\n",
      "evaluation/EB/Q_True Std              147.801\n",
      "evaluation/EB/Q_Pred Mean            1728.72\n",
      "evaluation/EB/Q_Pred Std              130.432\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5090.06\n",
      "evaluation/Actions Mean                 0.51041\n",
      "evaluation/Actions Std                  0.643093\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999952\n",
      "time/backward_policy (s)                1.85772\n",
      "time/backward_zf1 (s)                   2.01206\n",
      "time/backward_zf2 (s)                   1.95365\n",
      "time/data sampling (s)                  0.279528\n",
      "time/data storing (s)                   0.0153817\n",
      "time/evaluation sampling (s)            1.38876\n",
      "time/exploration sampling (s)           0.204502\n",
      "time/logging (s)                        0.0128067\n",
      "time/preback_alpha (s)                  0.961746\n",
      "time/preback_policy (s)                 1.09882\n",
      "time/preback_start (s)                  0.128666\n",
      "time/preback_zf (s)                     5.17814\n",
      "time/saving (s)                         0.00602435\n",
      "time/training (s)                       2.35521\n",
      "time/epoch (s)                         17.453\n",
      "time/total (s)                       1918.82\n",
      "Epoch                                 111\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:42:48.163297 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 112 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 123000\n",
      "trainer/ZF1 Loss                       69.3927\n",
      "trainer/ZF2 Loss                       49.014\n",
      "trainer/ZF Expert Reward               21.1781\n",
      "trainer/ZF Policy Reward                0.345963\n",
      "trainer/ZF CHI2 Term                  101.272\n",
      "trainer/Policy Loss                 -1321.98\n",
      "trainer/Bias Loss                     217.952\n",
      "trainer/Bias Value                     20.7332\n",
      "trainer/Policy Grad Norm              210.53\n",
      "trainer/Policy Param Norm              34.0076\n",
      "trainer/Zf1 Grad Norm                5888.71\n",
      "trainer/Zf1 Param Norm                 99.9996\n",
      "trainer/Zf2 Grad Norm                5643.88\n",
      "trainer/Zf2 Param Norm                 98.3236\n",
      "trainer/Z Expert Predictions Mean    1698.19\n",
      "trainer/Z Expert Predictions Std      176.251\n",
      "trainer/Z Expert Predictions Max     1934.34\n",
      "trainer/Z Expert Predictions Min      613.688\n",
      "trainer/Z Policy Predictions Mean    1314.05\n",
      "trainer/Z Policy Predictions Std      478.023\n",
      "trainer/Z Policy Predictions Max     1923.97\n",
      "trainer/Z Policy Predictions Min     -387.54\n",
      "trainer/Z Expert Targets Mean        1677.01\n",
      "trainer/Z Expert Targets Std          177.281\n",
      "trainer/Z Expert Targets Max         1921.83\n",
      "trainer/Z Expert Targets Min          595.818\n",
      "trainer/Z Policy Targets Mean        1313.71\n",
      "trainer/Z Policy Targets Std          469.132\n",
      "trainer/Z Policy Targets Max         1912.96\n",
      "trainer/Z Policy Targets Min         -385.747\n",
      "trainer/Log Pis Mean                   21.4509\n",
      "trainer/Log Pis Std                     5.61793\n",
      "trainer/Policy mu Mean                  1.21611\n",
      "trainer/Policy mu Std                   1.9217\n",
      "trainer/Policy log std Mean            -2.43925\n",
      "trainer/Policy log std Std              1.01978\n",
      "trainer/Alpha                           0.118917\n",
      "trainer/Alpha Loss                     -0.172492\n",
      "exploration/num steps total        117197\n",
      "exploration/num paths total           696\n",
      "evaluation/num steps total         761542\n",
      "evaluation/num paths total           1133\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14406\n",
      "evaluation/Rewards Std                  1.29698\n",
      "evaluation/Rewards Max                  7.04987\n",
      "evaluation/Rewards Min                  0.122274\n",
      "evaluation/Returns Mean              5144.06\n",
      "evaluation/Returns Std                 15.865\n",
      "evaluation/Returns Max               5173.56\n",
      "evaluation/Returns Min               5122.18\n",
      "evaluation/Estimation Bias Mean      1713.89\n",
      "evaluation/Estimation Bias Std        185.438\n",
      "evaluation/EB/Q_True Mean              48.4562\n",
      "evaluation/EB/Q_True Std              149.537\n",
      "evaluation/EB/Q_Pred Mean            1762.35\n",
      "evaluation/EB/Q_Pred Std              109.74\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5144.06\n",
      "evaluation/Actions Mean                 0.519158\n",
      "evaluation/Actions Std                  0.634433\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999804\n",
      "time/backward_policy (s)                1.84457\n",
      "time/backward_zf1 (s)                   1.98315\n",
      "time/backward_zf2 (s)                   1.89138\n",
      "time/data sampling (s)                  0.267761\n",
      "time/data storing (s)                   0.0146569\n",
      "time/evaluation sampling (s)            1.40507\n",
      "time/exploration sampling (s)           0.195318\n",
      "time/logging (s)                        0.0139932\n",
      "time/preback_alpha (s)                  0.915117\n",
      "time/preback_policy (s)                 1.01204\n",
      "time/preback_start (s)                  0.122037\n",
      "time/preback_zf (s)                     5.10747\n",
      "time/saving (s)                         0.00498999\n",
      "time/training (s)                       2.41754\n",
      "time/epoch (s)                         17.1951\n",
      "time/total (s)                       1936.04\n",
      "Epoch                                 112\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:43:06.530669 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 113 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 124000\n",
      "trainer/ZF1 Loss                       47.1994\n",
      "trainer/ZF2 Loss                       55.4516\n",
      "trainer/ZF Expert Reward               23.634\n",
      "trainer/ZF Policy Reward                4.73833\n",
      "trainer/ZF CHI2 Term                   90.281\n",
      "trainer/Policy Loss                 -1372.51\n",
      "trainer/Bias Loss                     234.756\n",
      "trainer/Bias Value                     20.7408\n",
      "trainer/Policy Grad Norm              391.359\n",
      "trainer/Policy Param Norm              34.0628\n",
      "trainer/Zf1 Grad Norm                6619\n",
      "trainer/Zf1 Param Norm                100.297\n",
      "trainer/Zf2 Grad Norm                4365.07\n",
      "trainer/Zf2 Param Norm                 98.6052\n",
      "trainer/Z Expert Predictions Mean    1696.33\n",
      "trainer/Z Expert Predictions Std      207.988\n",
      "trainer/Z Expert Predictions Max     1951.35\n",
      "trainer/Z Expert Predictions Min        7.43485\n",
      "trainer/Z Policy Predictions Mean    1366.97\n",
      "trainer/Z Policy Predictions Std      500.51\n",
      "trainer/Z Policy Predictions Max     1922.82\n",
      "trainer/Z Policy Predictions Min     -335.985\n",
      "trainer/Z Expert Targets Mean        1672.69\n",
      "trainer/Z Expert Targets Std          206.539\n",
      "trainer/Z Expert Targets Max         1930.23\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1362.23\n",
      "trainer/Z Policy Targets Std          495.511\n",
      "trainer/Z Policy Targets Max         1887.29\n",
      "trainer/Z Policy Targets Min         -320.8\n",
      "trainer/Log Pis Mean                   20.2625\n",
      "trainer/Log Pis Std                     5.31499\n",
      "trainer/Policy mu Mean                  1.19083\n",
      "trainer/Policy mu Std                   1.96309\n",
      "trainer/Policy log std Mean            -2.24636\n",
      "trainer/Policy log std Std              1.04778\n",
      "trainer/Alpha                           0.121022\n",
      "trainer/Alpha Loss                     -0.0317675\n",
      "exploration/num steps total        119197\n",
      "exploration/num paths total           698\n",
      "evaluation/num steps total         771542\n",
      "evaluation/num paths total           1143\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.22511\n",
      "evaluation/Rewards Std                  1.32549\n",
      "evaluation/Rewards Max                  7.28477\n",
      "evaluation/Rewards Min                  0.0970158\n",
      "evaluation/Returns Mean              5225.11\n",
      "evaluation/Returns Std                 36.5648\n",
      "evaluation/Returns Max               5293.7\n",
      "evaluation/Returns Min               5161.84\n",
      "evaluation/Estimation Bias Mean      1653.01\n",
      "evaluation/Estimation Bias Std        189.681\n",
      "evaluation/EB/Q_True Mean              50.0767\n",
      "evaluation/EB/Q_True Std              154.802\n",
      "evaluation/EB/Q_Pred Mean            1703.08\n",
      "evaluation/EB/Q_Pred Std              118.313\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5225.11\n",
      "evaluation/Actions Mean                 0.506228\n",
      "evaluation/Actions Std                  0.650721\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999872\n",
      "time/backward_policy (s)                1.95521\n",
      "time/backward_zf1 (s)                   2.23151\n",
      "time/backward_zf2 (s)                   2.13864\n",
      "time/data sampling (s)                  0.28017\n",
      "time/data storing (s)                   0.0151459\n",
      "time/evaluation sampling (s)            1.48172\n",
      "time/exploration sampling (s)           0.210447\n",
      "time/logging (s)                        0.0126989\n",
      "time/preback_alpha (s)                  0.992117\n",
      "time/preback_policy (s)                 1.13799\n",
      "time/preback_start (s)                  0.130399\n",
      "time/preback_zf (s)                     5.29452\n",
      "time/saving (s)                         0.00914712\n",
      "time/training (s)                       2.40524\n",
      "time/epoch (s)                         18.295\n",
      "time/total (s)                       1954.35\n",
      "Epoch                                 113\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:43:24.234746 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 114 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 125000\n",
      "trainer/ZF1 Loss                      468.008\n",
      "trainer/ZF2 Loss                      482.801\n",
      "trainer/ZF Expert Reward               25.366\n",
      "trainer/ZF Policy Reward               11.6406\n",
      "trainer/ZF CHI2 Term                  509.048\n",
      "trainer/Policy Loss                 -1344.77\n",
      "trainer/Bias Loss                     309.856\n",
      "trainer/Bias Value                     20.7452\n",
      "trainer/Policy Grad Norm              357.408\n",
      "trainer/Policy Param Norm              34.1221\n",
      "trainer/Zf1 Grad Norm                7651.08\n",
      "trainer/Zf1 Param Norm                100.572\n",
      "trainer/Zf2 Grad Norm               10062.4\n",
      "trainer/Zf2 Param Norm                 98.8593\n",
      "trainer/Z Expert Predictions Mean    1694.65\n",
      "trainer/Z Expert Predictions Std      159.562\n",
      "trainer/Z Expert Predictions Max     1951.16\n",
      "trainer/Z Expert Predictions Min     1065.87\n",
      "trainer/Z Policy Predictions Mean    1340.59\n",
      "trainer/Z Policy Predictions Std      459.667\n",
      "trainer/Z Policy Predictions Max     1908.07\n",
      "trainer/Z Policy Predictions Min     -187.085\n",
      "trainer/Z Expert Targets Mean        1669.29\n",
      "trainer/Z Expert Targets Std          158.622\n",
      "trainer/Z Expert Targets Max         1919.93\n",
      "trainer/Z Expert Targets Min         1081.24\n",
      "trainer/Z Policy Targets Mean        1328.95\n",
      "trainer/Z Policy Targets Std          460.836\n",
      "trainer/Z Policy Targets Max         1914.21\n",
      "trainer/Z Policy Targets Min         -178.837\n",
      "trainer/Log Pis Mean                   20.1187\n",
      "trainer/Log Pis Std                     5.29673\n",
      "trainer/Policy mu Mean                  1.27114\n",
      "trainer/Policy mu Std                   1.98062\n",
      "trainer/Policy log std Mean            -2.15884\n",
      "trainer/Policy log std Std              1.06834\n",
      "trainer/Alpha                           0.118943\n",
      "trainer/Alpha Loss                     -0.0141178\n",
      "exploration/num steps total        121197\n",
      "exploration/num paths total           700\n",
      "evaluation/num steps total         781542\n",
      "evaluation/num paths total           1153\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.0997\n",
      "evaluation/Rewards Std                  1.28271\n",
      "evaluation/Rewards Max                  6.99344\n",
      "evaluation/Rewards Min                  0.124773\n",
      "evaluation/Returns Mean              5099.7\n",
      "evaluation/Returns Std                 29.6842\n",
      "evaluation/Returns Max               5133.89\n",
      "evaluation/Returns Min               5040.9\n",
      "evaluation/Estimation Bias Mean      1725.34\n",
      "evaluation/Estimation Bias Std        200.368\n",
      "evaluation/EB/Q_True Mean              48.0071\n",
      "evaluation/EB/Q_True Std              148.376\n",
      "evaluation/EB/Q_Pred Mean            1773.35\n",
      "evaluation/EB/Q_Pred Std              127.325\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5099.7\n",
      "evaluation/Actions Mean                 0.504113\n",
      "evaluation/Actions Std                  0.643385\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999834\n",
      "time/backward_policy (s)                1.92907\n",
      "time/backward_zf1 (s)                   2.10304\n",
      "time/backward_zf2 (s)                   2.00976\n",
      "time/data sampling (s)                  0.254664\n",
      "time/data storing (s)                   0.0148935\n",
      "time/evaluation sampling (s)            1.49845\n",
      "time/exploration sampling (s)           0.201624\n",
      "time/logging (s)                        0.0126595\n",
      "time/preback_alpha (s)                  1.00291\n",
      "time/preback_policy (s)                 1.11915\n",
      "time/preback_start (s)                  0.124757\n",
      "time/preback_zf (s)                     5.1213\n",
      "time/saving (s)                         0.00587791\n",
      "time/training (s)                       2.23547\n",
      "time/epoch (s)                         17.6336\n",
      "time/total (s)                       1972.01\n",
      "Epoch                                 114\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:43:41.481750 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 115 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 126000\n",
      "trainer/ZF1 Loss                      735.588\n",
      "trainer/ZF2 Loss                      724.259\n",
      "trainer/ZF Expert Reward               21.9268\n",
      "trainer/ZF Policy Reward                9.11403\n",
      "trainer/ZF CHI2 Term                  762.894\n",
      "trainer/Policy Loss                 -1332.86\n",
      "trainer/Bias Loss                     383.661\n",
      "trainer/Bias Value                     20.7485\n",
      "trainer/Policy Grad Norm              262.517\n",
      "trainer/Policy Param Norm              34.1766\n",
      "trainer/Zf1 Grad Norm               11634.6\n",
      "trainer/Zf1 Param Norm                100.846\n",
      "trainer/Zf2 Grad Norm                7618.41\n",
      "trainer/Zf2 Param Norm                 99.1026\n",
      "trainer/Z Expert Predictions Mean    1676.99\n",
      "trainer/Z Expert Predictions Std      196.535\n",
      "trainer/Z Expert Predictions Max     1941.35\n",
      "trainer/Z Expert Predictions Min      185.23\n",
      "trainer/Z Policy Predictions Mean    1324.94\n",
      "trainer/Z Policy Predictions Std      489.732\n",
      "trainer/Z Policy Predictions Max     1844.28\n",
      "trainer/Z Policy Predictions Min     -150.26\n",
      "trainer/Z Expert Targets Mean        1655.06\n",
      "trainer/Z Expert Targets Std          203.394\n",
      "trainer/Z Expert Targets Max         1931.02\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1315.83\n",
      "trainer/Z Policy Targets Std          491.23\n",
      "trainer/Z Policy Targets Max         1853.3\n",
      "trainer/Z Policy Targets Min         -144.969\n",
      "trainer/Log Pis Mean                   20.3611\n",
      "trainer/Log Pis Std                     5.13404\n",
      "trainer/Policy mu Mean                  1.30347\n",
      "trainer/Policy mu Std                   1.98741\n",
      "trainer/Policy log std Mean            -2.15489\n",
      "trainer/Policy log std Std              1.05073\n",
      "trainer/Alpha                           0.11908\n",
      "trainer/Alpha Loss                     -0.0429975\n",
      "exploration/num steps total        121197\n",
      "exploration/num paths total           700\n",
      "evaluation/num steps total         791542\n",
      "evaluation/num paths total           1163\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21546\n",
      "evaluation/Rewards Std                  1.32184\n",
      "evaluation/Rewards Max                  7.21234\n",
      "evaluation/Rewards Min                  0.111669\n",
      "evaluation/Returns Mean              5215.46\n",
      "evaluation/Returns Std                 32.689\n",
      "evaluation/Returns Max               5258.91\n",
      "evaluation/Returns Min               5157.81\n",
      "evaluation/Estimation Bias Mean      1642.93\n",
      "evaluation/Estimation Bias Std        185.211\n",
      "evaluation/EB/Q_True Mean              48.7185\n",
      "evaluation/EB/Q_True Std              150.394\n",
      "evaluation/EB/Q_Pred Mean            1691.64\n",
      "evaluation/EB/Q_Pred Std              116.84\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5215.46\n",
      "evaluation/Actions Mean                 0.515855\n",
      "evaluation/Actions Std                  0.638937\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999853\n",
      "time/backward_policy (s)                1.80725\n",
      "time/backward_zf1 (s)                   1.96658\n",
      "time/backward_zf2 (s)                   1.89623\n",
      "time/data sampling (s)                  0.259198\n",
      "time/data storing (s)                   0.015798\n",
      "time/evaluation sampling (s)            1.40634\n",
      "time/exploration sampling (s)           0.197702\n",
      "time/logging (s)                        0.0115002\n",
      "time/preback_alpha (s)                  0.949154\n",
      "time/preback_policy (s)                 1.05408\n",
      "time/preback_start (s)                  0.123165\n",
      "time/preback_zf (s)                     5.13773\n",
      "time/saving (s)                         0.00511311\n",
      "time/training (s)                       2.34969\n",
      "time/epoch (s)                         17.1795\n",
      "time/total (s)                       1989.21\n",
      "Epoch                                 115\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:43:58.746066 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 116 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 127000\n",
      "trainer/ZF1 Loss                       89.3052\n",
      "trainer/ZF2 Loss                       95.9848\n",
      "trainer/ZF Expert Reward               23.7439\n",
      "trainer/ZF Policy Reward                8.67987\n",
      "trainer/ZF CHI2 Term                  127.611\n",
      "trainer/Policy Loss                 -1365.31\n",
      "trainer/Bias Loss                     238.652\n",
      "trainer/Bias Value                     20.7538\n",
      "trainer/Policy Grad Norm              290.486\n",
      "trainer/Policy Param Norm              34.2284\n",
      "trainer/Zf1 Grad Norm                5690.4\n",
      "trainer/Zf1 Param Norm                101.149\n",
      "trainer/Zf2 Grad Norm                7110.3\n",
      "trainer/Zf2 Param Norm                 99.4057\n",
      "trainer/Z Expert Predictions Mean    1669.72\n",
      "trainer/Z Expert Predictions Std      190.067\n",
      "trainer/Z Expert Predictions Max     1946.02\n",
      "trainer/Z Expert Predictions Min      580.178\n",
      "trainer/Z Policy Predictions Mean    1358.86\n",
      "trainer/Z Policy Predictions Std      492.785\n",
      "trainer/Z Policy Predictions Max     1906.91\n",
      "trainer/Z Policy Predictions Min     -233.817\n",
      "trainer/Z Expert Targets Mean        1645.98\n",
      "trainer/Z Expert Targets Std          190.414\n",
      "trainer/Z Expert Targets Max         1911.88\n",
      "trainer/Z Expert Targets Min          555.961\n",
      "trainer/Z Policy Targets Mean        1350.18\n",
      "trainer/Z Policy Targets Std          485.898\n",
      "trainer/Z Policy Targets Max         1876.19\n",
      "trainer/Z Policy Targets Min         -233.331\n",
      "trainer/Log Pis Mean                   20.1031\n",
      "trainer/Log Pis Std                     5.38612\n",
      "trainer/Policy mu Mean                  1.25722\n",
      "trainer/Policy mu Std                   1.91683\n",
      "trainer/Policy log std Mean            -2.18823\n",
      "trainer/Policy log std Std              1.047\n",
      "trainer/Alpha                           0.120004\n",
      "trainer/Alpha Loss                     -0.0123786\n",
      "exploration/num steps total        123197\n",
      "exploration/num paths total           702\n",
      "evaluation/num steps total         801542\n",
      "evaluation/num paths total           1173\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21698\n",
      "evaluation/Rewards Std                  1.3219\n",
      "evaluation/Rewards Max                  7.13487\n",
      "evaluation/Rewards Min                  0.133576\n",
      "evaluation/Returns Mean              5216.98\n",
      "evaluation/Returns Std                 23.3519\n",
      "evaluation/Returns Max               5261.25\n",
      "evaluation/Returns Min               5186.3\n",
      "evaluation/Estimation Bias Mean      1692.42\n",
      "evaluation/Estimation Bias Std        186.656\n",
      "evaluation/EB/Q_True Mean              49.185\n",
      "evaluation/EB/Q_True Std              151.752\n",
      "evaluation/EB/Q_Pred Mean            1741.6\n",
      "evaluation/EB/Q_Pred Std              111.864\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5216.98\n",
      "evaluation/Actions Mean                 0.499124\n",
      "evaluation/Actions Std                  0.636527\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999789\n",
      "time/backward_policy (s)                1.82071\n",
      "time/backward_zf1 (s)                   1.98276\n",
      "time/backward_zf2 (s)                   1.87988\n",
      "time/data sampling (s)                  0.264198\n",
      "time/data storing (s)                   0.0140969\n",
      "time/evaluation sampling (s)            1.50476\n",
      "time/exploration sampling (s)           0.200205\n",
      "time/logging (s)                        0.0125773\n",
      "time/preback_alpha (s)                  0.925729\n",
      "time/preback_policy (s)                 1.02128\n",
      "time/preback_start (s)                  0.121317\n",
      "time/preback_zf (s)                     5.09371\n",
      "time/saving (s)                         0.00557734\n",
      "time/training (s)                       2.35328\n",
      "time/epoch (s)                         17.2001\n",
      "time/total (s)                       2006.43\n",
      "Epoch                                 116\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:44:17.027728 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 117 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 128000\n",
      "trainer/ZF1 Loss                      255.536\n",
      "trainer/ZF2 Loss                      219.65\n",
      "trainer/ZF Expert Reward               22.741\n",
      "trainer/ZF Policy Reward               -5.98397\n",
      "trainer/ZF CHI2 Term                  285.667\n",
      "trainer/Policy Loss                 -1300.71\n",
      "trainer/Bias Loss                    2107.19\n",
      "trainer/Bias Value                     20.7567\n",
      "trainer/Policy Grad Norm              274.048\n",
      "trainer/Policy Param Norm              34.2781\n",
      "trainer/Zf1 Grad Norm               12167\n",
      "trainer/Zf1 Param Norm                101.447\n",
      "trainer/Zf2 Grad Norm               12452.9\n",
      "trainer/Zf2 Param Norm                 99.6931\n",
      "trainer/Z Expert Predictions Mean    1658.18\n",
      "trainer/Z Expert Predictions Std      194.924\n",
      "trainer/Z Expert Predictions Max     1952.47\n",
      "trainer/Z Expert Predictions Min      775.589\n",
      "trainer/Z Policy Predictions Mean    1285.25\n",
      "trainer/Z Policy Predictions Std      481.696\n",
      "trainer/Z Policy Predictions Max     1850.67\n",
      "trainer/Z Policy Predictions Min     -127.74\n",
      "trainer/Z Expert Targets Mean        1635.44\n",
      "trainer/Z Expert Targets Std          216.292\n",
      "trainer/Z Expert Targets Max         1920.86\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1291.24\n",
      "trainer/Z Policy Targets Std          478.567\n",
      "trainer/Z Policy Targets Max         1856.35\n",
      "trainer/Z Policy Targets Min         -154.204\n",
      "trainer/Log Pis Mean                   19.5449\n",
      "trainer/Log Pis Std                     4.79735\n",
      "trainer/Policy mu Mean                  1.19918\n",
      "trainer/Policy mu Std                   1.89435\n",
      "trainer/Policy log std Mean            -2.25574\n",
      "trainer/Policy log std Std              1.07407\n",
      "trainer/Alpha                           0.119681\n",
      "trainer/Alpha Loss                      0.0544641\n",
      "exploration/num steps total        123197\n",
      "exploration/num paths total           702\n",
      "evaluation/num steps total         811542\n",
      "evaluation/num paths total           1183\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18167\n",
      "evaluation/Rewards Std                  1.31388\n",
      "evaluation/Rewards Max                  7.10787\n",
      "evaluation/Rewards Min                  0.127776\n",
      "evaluation/Returns Mean              5181.67\n",
      "evaluation/Returns Std                 33.007\n",
      "evaluation/Returns Max               5220.25\n",
      "evaluation/Returns Min               5109.74\n",
      "evaluation/Estimation Bias Mean      1677.43\n",
      "evaluation/Estimation Bias Std        184.962\n",
      "evaluation/EB/Q_True Mean              49.1236\n",
      "evaluation/EB/Q_True Std              151.61\n",
      "evaluation/EB/Q_Pred Mean            1726.55\n",
      "evaluation/EB/Q_Pred Std              106.912\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5181.67\n",
      "evaluation/Actions Mean                 0.502562\n",
      "evaluation/Actions Std                  0.637888\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999805\n",
      "time/backward_policy (s)                2.02105\n",
      "time/backward_zf1 (s)                   2.22146\n",
      "time/backward_zf2 (s)                   2.10112\n",
      "time/data sampling (s)                  0.278797\n",
      "time/data storing (s)                   0.0156093\n",
      "time/evaluation sampling (s)            1.44111\n",
      "time/exploration sampling (s)           0.203311\n",
      "time/logging (s)                        0.0120047\n",
      "time/preback_alpha (s)                  1.06261\n",
      "time/preback_policy (s)                 1.20136\n",
      "time/preback_start (s)                  0.129302\n",
      "time/preback_zf (s)                     5.26542\n",
      "time/saving (s)                         0.0056696\n",
      "time/training (s)                       2.25081\n",
      "time/epoch (s)                         18.2096\n",
      "time/total (s)                       2024.66\n",
      "Epoch                                 117\n",
      "---------------------------------  --------------\n",
      "2024-06-18 17:44:35.172620 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 118 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 129000\n",
      "trainer/ZF1 Loss                       63.4653\n",
      "trainer/ZF2 Loss                       63.819\n",
      "trainer/ZF Expert Reward               19.491\n",
      "trainer/ZF Policy Reward               -0.0534649\n",
      "trainer/ZF CHI2 Term                  103.079\n",
      "trainer/Policy Loss                 -1313.61\n",
      "trainer/Bias Loss                     256.052\n",
      "trainer/Bias Value                     20.7608\n",
      "trainer/Policy Grad Norm              306.251\n",
      "trainer/Policy Param Norm              34.3323\n",
      "trainer/Zf1 Grad Norm                5413.25\n",
      "trainer/Zf1 Param Norm                101.724\n",
      "trainer/Zf2 Grad Norm                4845.24\n",
      "trainer/Zf2 Param Norm                 99.9578\n",
      "trainer/Z Expert Predictions Mean    1690.61\n",
      "trainer/Z Expert Predictions Std      176.562\n",
      "trainer/Z Expert Predictions Max     1959.15\n",
      "trainer/Z Expert Predictions Min      578.877\n",
      "trainer/Z Policy Predictions Mean    1300.36\n",
      "trainer/Z Policy Predictions Std      498.779\n",
      "trainer/Z Policy Predictions Max     1917.19\n",
      "trainer/Z Policy Predictions Min     -265.215\n",
      "trainer/Z Expert Targets Mean        1671.12\n",
      "trainer/Z Expert Targets Std          175.207\n",
      "trainer/Z Expert Targets Max         1909.01\n",
      "trainer/Z Expert Targets Min          562.358\n",
      "trainer/Z Policy Targets Mean        1300.41\n",
      "trainer/Z Policy Targets Std          491.738\n",
      "trainer/Z Policy Targets Max         1867.72\n",
      "trainer/Z Policy Targets Min         -278.966\n",
      "trainer/Log Pis Mean                   20.0937\n",
      "trainer/Log Pis Std                     5.15709\n",
      "trainer/Policy mu Mean                  1.15897\n",
      "trainer/Policy mu Std                   2.02109\n",
      "trainer/Policy log std Mean            -2.2719\n",
      "trainer/Policy log std Std              1.06826\n",
      "trainer/Alpha                           0.120409\n",
      "trainer/Alpha Loss                     -0.0112803\n",
      "exploration/num steps total        123197\n",
      "exploration/num paths total           702\n",
      "evaluation/num steps total         821542\n",
      "evaluation/num paths total           1193\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2363\n",
      "evaluation/Rewards Std                  1.33325\n",
      "evaluation/Rewards Max                  7.13647\n",
      "evaluation/Rewards Min                  0.11716\n",
      "evaluation/Returns Mean              5236.3\n",
      "evaluation/Returns Std                 13.3741\n",
      "evaluation/Returns Max               5255.75\n",
      "evaluation/Returns Min               5208.91\n",
      "evaluation/Estimation Bias Mean      1702.44\n",
      "evaluation/Estimation Bias Std        187.685\n",
      "evaluation/EB/Q_True Mean              49.5752\n",
      "evaluation/EB/Q_True Std              153.207\n",
      "evaluation/EB/Q_Pred Mean            1752.01\n",
      "evaluation/EB/Q_Pred Std              111.378\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5236.3\n",
      "evaluation/Actions Mean                 0.502301\n",
      "evaluation/Actions Std                  0.642897\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999843\n",
      "time/backward_policy (s)                1.99794\n",
      "time/backward_zf1 (s)                   2.16597\n",
      "time/backward_zf2 (s)                   2.05483\n",
      "time/data sampling (s)                  0.276908\n",
      "time/data storing (s)                   0.0155415\n",
      "time/evaluation sampling (s)            1.53038\n",
      "time/exploration sampling (s)           0.206278\n",
      "time/logging (s)                        0.0121038\n",
      "time/preback_alpha (s)                  1.02824\n",
      "time/preback_policy (s)                 1.14927\n",
      "time/preback_start (s)                  0.128892\n",
      "time/preback_zf (s)                     5.22092\n",
      "time/saving (s)                         0.00514485\n",
      "time/training (s)                       2.27971\n",
      "time/epoch (s)                         18.0721\n",
      "time/total (s)                       2042.75\n",
      "Epoch                                 118\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:44:54.516919 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 119 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 130000\n",
      "trainer/ZF1 Loss                       70.5904\n",
      "trainer/ZF2 Loss                       86.8595\n",
      "trainer/ZF Expert Reward               12.5682\n",
      "trainer/ZF Policy Reward               -3.9539\n",
      "trainer/ZF CHI2 Term                  115.575\n",
      "trainer/Policy Loss                 -1306.25\n",
      "trainer/Bias Loss                     341.314\n",
      "trainer/Bias Value                     20.762\n",
      "trainer/Policy Grad Norm              247.03\n",
      "trainer/Policy Param Norm              34.3789\n",
      "trainer/Zf1 Grad Norm                7861.87\n",
      "trainer/Zf1 Param Norm                102.001\n",
      "trainer/Zf2 Grad Norm                9373.33\n",
      "trainer/Zf2 Param Norm                100.218\n",
      "trainer/Z Expert Predictions Mean    1678.23\n",
      "trainer/Z Expert Predictions Std      172.953\n",
      "trainer/Z Expert Predictions Max     1937.58\n",
      "trainer/Z Expert Predictions Min      597.78\n",
      "trainer/Z Policy Predictions Mean    1289.02\n",
      "trainer/Z Policy Predictions Std      496.243\n",
      "trainer/Z Policy Predictions Max     1898.08\n",
      "trainer/Z Policy Predictions Min     -261.085\n",
      "trainer/Z Expert Targets Mean        1665.66\n",
      "trainer/Z Expert Targets Std          175.7\n",
      "trainer/Z Expert Targets Max         1918.48\n",
      "trainer/Z Expert Targets Min          590.302\n",
      "trainer/Z Policy Targets Mean        1292.97\n",
      "trainer/Z Policy Targets Std          492.855\n",
      "trainer/Z Policy Targets Max         1910.12\n",
      "trainer/Z Policy Targets Min         -264.634\n",
      "trainer/Log Pis Mean                   20.5333\n",
      "trainer/Log Pis Std                     5.51337\n",
      "trainer/Policy mu Mean                  1.24726\n",
      "trainer/Policy mu Std                   1.9921\n",
      "trainer/Policy log std Mean            -2.16652\n",
      "trainer/Policy log std Std              1.09286\n",
      "trainer/Alpha                           0.122302\n",
      "trainer/Alpha Loss                     -0.0652166\n",
      "exploration/num steps total        124197\n",
      "exploration/num paths total           703\n",
      "evaluation/num steps total         831086\n",
      "evaluation/num paths total           1203\n",
      "evaluation/path length Mean           954.4\n",
      "evaluation/path length Std            136.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            544\n",
      "evaluation/Rewards Mean                 5.16962\n",
      "evaluation/Rewards Std                  1.33516\n",
      "evaluation/Rewards Max                  8.49234\n",
      "evaluation/Rewards Min                  0.127083\n",
      "evaluation/Returns Mean              4933.88\n",
      "evaluation/Returns Std                781.652\n",
      "evaluation/Returns Max               5252.18\n",
      "evaluation/Returns Min               2590.26\n",
      "evaluation/Estimation Bias Mean      1689.51\n",
      "evaluation/Estimation Bias Std        282.114\n",
      "evaluation/EB/Q_True Mean              51.3336\n",
      "evaluation/EB/Q_True Std              154.399\n",
      "evaluation/EB/Q_Pred Mean            1740.84\n",
      "evaluation/EB/Q_Pred Std              190.025\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4933.88\n",
      "evaluation/Actions Mean                 0.497296\n",
      "evaluation/Actions Std                  0.651833\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                2.12007\n",
      "time/backward_zf1 (s)                   2.42927\n",
      "time/backward_zf2 (s)                   2.26707\n",
      "time/data sampling (s)                  0.313281\n",
      "time/data storing (s)                   0.0163139\n",
      "time/evaluation sampling (s)            1.45774\n",
      "time/exploration sampling (s)           0.21465\n",
      "time/logging (s)                        0.0119105\n",
      "time/preback_alpha (s)                  1.08033\n",
      "time/preback_policy (s)                 1.23581\n",
      "time/preback_start (s)                  0.140416\n",
      "time/preback_zf (s)                     5.52332\n",
      "time/saving (s)                         0.00707822\n",
      "time/training (s)                       2.44606\n",
      "time/epoch (s)                         19.2633\n",
      "time/total (s)                       2062.04\n",
      "Epoch                                 119\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:45:14.742952 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 120 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 131000\n",
      "trainer/ZF1 Loss                     1123.67\n",
      "trainer/ZF2 Loss                     1121.87\n",
      "trainer/ZF Expert Reward               38.8748\n",
      "trainer/ZF Policy Reward                9.53612\n",
      "trainer/ZF CHI2 Term                 1171.17\n",
      "trainer/Policy Loss                 -1376.06\n",
      "trainer/Bias Loss                   11063.1\n",
      "trainer/Bias Value                     20.7651\n",
      "trainer/Policy Grad Norm              294.457\n",
      "trainer/Policy Param Norm              34.4269\n",
      "trainer/Zf1 Grad Norm               15764.4\n",
      "trainer/Zf1 Param Norm                102.298\n",
      "trainer/Zf2 Grad Norm               20532.2\n",
      "trainer/Zf2 Param Norm                100.506\n",
      "trainer/Z Expert Predictions Mean    1690.6\n",
      "trainer/Z Expert Predictions Std      194.486\n",
      "trainer/Z Expert Predictions Max     1951.91\n",
      "trainer/Z Expert Predictions Min      294.353\n",
      "trainer/Z Policy Predictions Mean    1377.44\n",
      "trainer/Z Policy Predictions Std      430.957\n",
      "trainer/Z Policy Predictions Max     1870.28\n",
      "trainer/Z Policy Predictions Min      -95.9012\n",
      "trainer/Z Expert Targets Mean        1651.72\n",
      "trainer/Z Expert Targets Std          243.018\n",
      "trainer/Z Expert Targets Max         1939.35\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1367.9\n",
      "trainer/Z Policy Targets Std          426.007\n",
      "trainer/Z Policy Targets Max         1836.38\n",
      "trainer/Z Policy Targets Min          -96.8474\n",
      "trainer/Log Pis Mean                   19.2534\n",
      "trainer/Log Pis Std                     5.04235\n",
      "trainer/Policy mu Mean                  1.14249\n",
      "trainer/Policy mu Std                   1.89806\n",
      "trainer/Policy log std Mean            -2.20316\n",
      "trainer/Policy log std Std              1.05956\n",
      "trainer/Alpha                           0.123063\n",
      "trainer/Alpha Loss                      0.091879\n",
      "exploration/num steps total        126197\n",
      "exploration/num paths total           705\n",
      "evaluation/num steps total         841086\n",
      "evaluation/num paths total           1213\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20182\n",
      "evaluation/Rewards Std                  1.34189\n",
      "evaluation/Rewards Max                  7.09377\n",
      "evaluation/Rewards Min                  0.0879111\n",
      "evaluation/Returns Mean              5201.82\n",
      "evaluation/Returns Std                 19.6451\n",
      "evaluation/Returns Max               5233.28\n",
      "evaluation/Returns Min               5169.03\n",
      "evaluation/Estimation Bias Mean      1731.57\n",
      "evaluation/Estimation Bias Std        189.846\n",
      "evaluation/EB/Q_True Mean              48.8681\n",
      "evaluation/EB/Q_True Std              150.868\n",
      "evaluation/EB/Q_Pred Mean            1780.44\n",
      "evaluation/EB/Q_Pred Std              122.471\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5201.82\n",
      "evaluation/Actions Mean                 0.497732\n",
      "evaluation/Actions Std                  0.648841\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -0.999818\n",
      "time/backward_policy (s)                2.30526\n",
      "time/backward_zf1 (s)                   2.59817\n",
      "time/backward_zf2 (s)                   2.40582\n",
      "time/data sampling (s)                  0.352878\n",
      "time/data storing (s)                   0.0182021\n",
      "time/evaluation sampling (s)            1.41899\n",
      "time/exploration sampling (s)           0.247036\n",
      "time/logging (s)                        0.0129178\n",
      "time/preback_alpha (s)                  1.16457\n",
      "time/preback_policy (s)                 1.35229\n",
      "time/preback_start (s)                  0.14917\n",
      "time/preback_zf (s)                     5.6587\n",
      "time/saving (s)                         0.00761643\n",
      "time/training (s)                       2.43666\n",
      "time/epoch (s)                         20.1283\n",
      "time/total (s)                       2082.21\n",
      "Epoch                                 120\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:45:33.196102 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 121 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 132000\n",
      "trainer/ZF1 Loss                     1066.18\n",
      "trainer/ZF2 Loss                     1093.45\n",
      "trainer/ZF Expert Reward               27.6929\n",
      "trainer/ZF Policy Reward               12.4019\n",
      "trainer/ZF CHI2 Term                 1114.56\n",
      "trainer/Policy Loss                 -1375.61\n",
      "trainer/Bias Loss                    6123.7\n",
      "trainer/Bias Value                     20.7667\n",
      "trainer/Policy Grad Norm              342.562\n",
      "trainer/Policy Param Norm              34.4737\n",
      "trainer/Zf1 Grad Norm                6707.22\n",
      "trainer/Zf1 Param Norm                102.564\n",
      "trainer/Zf2 Grad Norm                7654.77\n",
      "trainer/Zf2 Param Norm                100.748\n",
      "trainer/Z Expert Predictions Mean    1675.3\n",
      "trainer/Z Expert Predictions Std      177.749\n",
      "trainer/Z Expert Predictions Max     1957.86\n",
      "trainer/Z Expert Predictions Min      317.279\n",
      "trainer/Z Policy Predictions Mean    1374.65\n",
      "trainer/Z Policy Predictions Std      468.428\n",
      "trainer/Z Policy Predictions Max     1894.23\n",
      "trainer/Z Policy Predictions Min     -151.582\n",
      "trainer/Z Expert Targets Mean        1647.6\n",
      "trainer/Z Expert Targets Std          208.923\n",
      "trainer/Z Expert Targets Max         1937\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1362.25\n",
      "trainer/Z Policy Targets Std          470.307\n",
      "trainer/Z Policy Targets Max         1879.74\n",
      "trainer/Z Policy Targets Min         -146.348\n",
      "trainer/Log Pis Mean                   19.6493\n",
      "trainer/Log Pis Std                     4.46321\n",
      "trainer/Policy mu Mean                  1.19744\n",
      "trainer/Policy mu Std                   1.90312\n",
      "trainer/Policy log std Mean            -2.18999\n",
      "trainer/Policy log std Std              1.09832\n",
      "trainer/Alpha                           0.124204\n",
      "trainer/Alpha Loss                      0.0435608\n",
      "exploration/num steps total        127197\n",
      "exploration/num paths total           706\n",
      "evaluation/num steps total         851086\n",
      "evaluation/num paths total           1223\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18118\n",
      "evaluation/Rewards Std                  1.30902\n",
      "evaluation/Rewards Max                  7.20313\n",
      "evaluation/Rewards Min                  0.13229\n",
      "evaluation/Returns Mean              5181.18\n",
      "evaluation/Returns Std                 39.1309\n",
      "evaluation/Returns Max               5246.16\n",
      "evaluation/Returns Min               5129.44\n",
      "evaluation/Estimation Bias Mean      1712.2\n",
      "evaluation/Estimation Bias Std        211.865\n",
      "evaluation/EB/Q_True Mean              49.5731\n",
      "evaluation/EB/Q_True Std              153.031\n",
      "evaluation/EB/Q_Pred Mean            1761.77\n",
      "evaluation/EB/Q_Pred Std              142.327\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5181.18\n",
      "evaluation/Actions Mean                 0.502492\n",
      "evaluation/Actions Std                  0.646265\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999956\n",
      "time/backward_policy (s)                2.00458\n",
      "time/backward_zf1 (s)                   2.24443\n",
      "time/backward_zf2 (s)                   2.0924\n",
      "time/data sampling (s)                  0.304944\n",
      "time/data storing (s)                   0.0154662\n",
      "time/evaluation sampling (s)            1.43852\n",
      "time/exploration sampling (s)           0.205873\n",
      "time/logging (s)                        0.012269\n",
      "time/preback_alpha (s)                  1.00562\n",
      "time/preback_policy (s)                 1.12137\n",
      "time/preback_start (s)                  0.134426\n",
      "time/preback_zf (s)                     5.30774\n",
      "time/saving (s)                         0.00648076\n",
      "time/training (s)                       2.47974\n",
      "time/epoch (s)                         18.3739\n",
      "time/total (s)                       2100.61\n",
      "Epoch                                 121\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:45:51.796454 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 122 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 133000\n",
      "trainer/ZF1 Loss                      570.794\n",
      "trainer/ZF2 Loss                      497.527\n",
      "trainer/ZF Expert Reward               18.8601\n",
      "trainer/ZF Policy Reward                5.10709\n",
      "trainer/ZF CHI2 Term                  567.946\n",
      "trainer/Policy Loss                 -1308.72\n",
      "trainer/Bias Loss                     666.843\n",
      "trainer/Bias Value                     20.77\n",
      "trainer/Policy Grad Norm              235.75\n",
      "trainer/Policy Param Norm              34.5196\n",
      "trainer/Zf1 Grad Norm               12678.8\n",
      "trainer/Zf1 Param Norm                102.848\n",
      "trainer/Zf2 Grad Norm               13732.2\n",
      "trainer/Zf2 Param Norm                101.016\n",
      "trainer/Z Expert Predictions Mean    1684.78\n",
      "trainer/Z Expert Predictions Std      160.918\n",
      "trainer/Z Expert Predictions Max     1950.34\n",
      "trainer/Z Expert Predictions Min     1185.01\n",
      "trainer/Z Policy Predictions Mean    1297.89\n",
      "trainer/Z Policy Predictions Std      521.43\n",
      "trainer/Z Policy Predictions Max     1947.06\n",
      "trainer/Z Policy Predictions Min     -155.226\n",
      "trainer/Z Expert Targets Mean        1665.92\n",
      "trainer/Z Expert Targets Std          158.573\n",
      "trainer/Z Expert Targets Max         1931.83\n",
      "trainer/Z Expert Targets Min         1158.23\n",
      "trainer/Z Policy Targets Mean        1292.79\n",
      "trainer/Z Policy Targets Std          522.096\n",
      "trainer/Z Policy Targets Max         1925.15\n",
      "trainer/Z Policy Targets Min         -135.302\n",
      "trainer/Log Pis Mean                   20.2353\n",
      "trainer/Log Pis Std                     5.44711\n",
      "trainer/Policy mu Mean                  1.2429\n",
      "trainer/Policy mu Std                   1.99533\n",
      "trainer/Policy log std Mean            -2.21051\n",
      "trainer/Policy log std Std              1.10054\n",
      "trainer/Alpha                           0.12583\n",
      "trainer/Alpha Loss                     -0.0296051\n",
      "exploration/num steps total        127197\n",
      "exploration/num paths total           706\n",
      "evaluation/num steps total         861086\n",
      "evaluation/num paths total           1233\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13054\n",
      "evaluation/Rewards Std                  1.30202\n",
      "evaluation/Rewards Max                  7.13642\n",
      "evaluation/Rewards Min                  0.152205\n",
      "evaluation/Returns Mean              5130.54\n",
      "evaluation/Returns Std                 67.8563\n",
      "evaluation/Returns Max               5194.17\n",
      "evaluation/Returns Min               4958.07\n",
      "evaluation/Estimation Bias Mean      1685.21\n",
      "evaluation/Estimation Bias Std        253.515\n",
      "evaluation/EB/Q_True Mean              48.8942\n",
      "evaluation/EB/Q_True Std              151.065\n",
      "evaluation/EB/Q_Pred Mean            1734.1\n",
      "evaluation/EB/Q_Pred Std              163.4\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5130.54\n",
      "evaluation/Actions Mean                 0.490328\n",
      "evaluation/Actions Std                  0.64785\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999977\n",
      "time/backward_policy (s)                2.01019\n",
      "time/backward_zf1 (s)                   2.19751\n",
      "time/backward_zf2 (s)                   2.08989\n",
      "time/data sampling (s)                  0.312593\n",
      "time/data storing (s)                   0.0154944\n",
      "time/evaluation sampling (s)            1.48452\n",
      "time/exploration sampling (s)           0.209878\n",
      "time/logging (s)                        0.0115898\n",
      "time/preback_alpha (s)                  1.01965\n",
      "time/preback_policy (s)                 1.16205\n",
      "time/preback_start (s)                  0.133945\n",
      "time/preback_zf (s)                     5.36302\n",
      "time/saving (s)                         0.00536654\n",
      "time/training (s)                       2.50898\n",
      "time/epoch (s)                         18.5247\n",
      "time/total (s)                       2119.16\n",
      "Epoch                                 122\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:46:10.338241 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 123 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 134000\n",
      "trainer/ZF1 Loss                      115.219\n",
      "trainer/ZF2 Loss                      106.105\n",
      "trainer/ZF Expert Reward               35.0842\n",
      "trainer/ZF Policy Reward               19.86\n",
      "trainer/ZF CHI2 Term                  145.146\n",
      "trainer/Policy Loss                 -1378.48\n",
      "trainer/Bias Loss                     450.928\n",
      "trainer/Bias Value                     20.7732\n",
      "trainer/Policy Grad Norm              379.407\n",
      "trainer/Policy Param Norm              34.5691\n",
      "trainer/Zf1 Grad Norm               10100.1\n",
      "trainer/Zf1 Param Norm                103.117\n",
      "trainer/Zf2 Grad Norm                8659.84\n",
      "trainer/Zf2 Param Norm                101.284\n",
      "trainer/Z Expert Predictions Mean    1682.15\n",
      "trainer/Z Expert Predictions Std      202.509\n",
      "trainer/Z Expert Predictions Max     1978.04\n",
      "trainer/Z Expert Predictions Min      481.009\n",
      "trainer/Z Policy Predictions Mean    1366.59\n",
      "trainer/Z Policy Predictions Std      477.134\n",
      "trainer/Z Policy Predictions Max     1912.79\n",
      "trainer/Z Policy Predictions Min     -139.222\n",
      "trainer/Z Expert Targets Mean        1647.06\n",
      "trainer/Z Expert Targets Std          204.375\n",
      "trainer/Z Expert Targets Max         1929.85\n",
      "trainer/Z Expert Targets Min          437.574\n",
      "trainer/Z Policy Targets Mean        1346.73\n",
      "trainer/Z Policy Targets Std          473.485\n",
      "trainer/Z Policy Targets Max         1867.29\n",
      "trainer/Z Policy Targets Min         -118.248\n",
      "trainer/Log Pis Mean                   19.4541\n",
      "trainer/Log Pis Std                     4.8387\n",
      "trainer/Policy mu Mean                  1.15363\n",
      "trainer/Policy mu Std                   1.87812\n",
      "trainer/Policy log std Mean            -2.24726\n",
      "trainer/Policy log std Std              1.09032\n",
      "trainer/Alpha                           0.12843\n",
      "trainer/Alpha Loss                      0.0701141\n",
      "exploration/num steps total        129197\n",
      "exploration/num paths total           708\n",
      "evaluation/num steps total         871086\n",
      "evaluation/num paths total           1243\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19576\n",
      "evaluation/Rewards Std                  1.32868\n",
      "evaluation/Rewards Max                  7.10187\n",
      "evaluation/Rewards Min                  0.147043\n",
      "evaluation/Returns Mean              5195.76\n",
      "evaluation/Returns Std                 19.4277\n",
      "evaluation/Returns Max               5222.06\n",
      "evaluation/Returns Min               5169.74\n",
      "evaluation/Estimation Bias Mean      1647.35\n",
      "evaluation/Estimation Bias Std        187.022\n",
      "evaluation/EB/Q_True Mean              48.9237\n",
      "evaluation/EB/Q_True Std              151.036\n",
      "evaluation/EB/Q_Pred Mean            1696.28\n",
      "evaluation/EB/Q_Pred Std              104.441\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5195.76\n",
      "evaluation/Actions Mean                 0.523945\n",
      "evaluation/Actions Std                  0.636176\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.99986\n",
      "time/backward_policy (s)                2.09037\n",
      "time/backward_zf1 (s)                   2.26281\n",
      "time/backward_zf2 (s)                   2.17629\n",
      "time/data sampling (s)                  0.292125\n",
      "time/data storing (s)                   0.0144661\n",
      "time/evaluation sampling (s)            1.45646\n",
      "time/exploration sampling (s)           0.203202\n",
      "time/logging (s)                        0.0120814\n",
      "time/preback_alpha (s)                  1.0569\n",
      "time/preback_policy (s)                 1.19706\n",
      "time/preback_start (s)                  0.131794\n",
      "time/preback_zf (s)                     5.28456\n",
      "time/saving (s)                         0.00558334\n",
      "time/training (s)                       2.28721\n",
      "time/epoch (s)                         18.4709\n",
      "time/total (s)                       2137.65\n",
      "Epoch                                 123\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:46:29.125585 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 124 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 135000\n",
      "trainer/ZF1 Loss                      545.386\n",
      "trainer/ZF2 Loss                      546.837\n",
      "trainer/ZF Expert Reward               19.3355\n",
      "trainer/ZF Policy Reward                9.49932\n",
      "trainer/ZF CHI2 Term                  576.469\n",
      "trainer/Policy Loss                 -1386.24\n",
      "trainer/Bias Loss                     556.524\n",
      "trainer/Bias Value                     20.777\n",
      "trainer/Policy Grad Norm              325.563\n",
      "trainer/Policy Param Norm              34.6188\n",
      "trainer/Zf1 Grad Norm                8499.68\n",
      "trainer/Zf1 Param Norm                103.422\n",
      "trainer/Zf2 Grad Norm                8679.81\n",
      "trainer/Zf2 Param Norm                101.585\n",
      "trainer/Z Expert Predictions Mean    1690.37\n",
      "trainer/Z Expert Predictions Std      171.585\n",
      "trainer/Z Expert Predictions Max     1946.6\n",
      "trainer/Z Expert Predictions Min     1146.45\n",
      "trainer/Z Policy Predictions Mean    1377.5\n",
      "trainer/Z Policy Predictions Std      495.079\n",
      "trainer/Z Policy Predictions Max     1893.57\n",
      "trainer/Z Policy Predictions Min     -263.068\n",
      "trainer/Z Expert Targets Mean        1671.03\n",
      "trainer/Z Expert Targets Std          170.414\n",
      "trainer/Z Expert Targets Max         1926.38\n",
      "trainer/Z Expert Targets Min         1120.52\n",
      "trainer/Z Policy Targets Mean        1368\n",
      "trainer/Z Policy Targets Std          492.835\n",
      "trainer/Z Policy Targets Max         1918.75\n",
      "trainer/Z Policy Targets Min         -252.325\n",
      "trainer/Log Pis Mean                   20.7291\n",
      "trainer/Log Pis Std                     4.95261\n",
      "trainer/Policy mu Mean                  1.30701\n",
      "trainer/Policy mu Std                   1.96335\n",
      "trainer/Policy log std Mean            -2.23205\n",
      "trainer/Policy log std Std              1.10675\n",
      "trainer/Alpha                           0.129126\n",
      "trainer/Alpha Loss                     -0.0941365\n",
      "exploration/num steps total        131197\n",
      "exploration/num paths total           710\n",
      "evaluation/num steps total         881086\n",
      "evaluation/num paths total           1253\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13023\n",
      "evaluation/Rewards Std                  1.30091\n",
      "evaluation/Rewards Max                  6.90237\n",
      "evaluation/Rewards Min                  0.085596\n",
      "evaluation/Returns Mean              5130.23\n",
      "evaluation/Returns Std                 17.4743\n",
      "evaluation/Returns Max               5147.07\n",
      "evaluation/Returns Min               5086.94\n",
      "evaluation/Estimation Bias Mean      1720.61\n",
      "evaluation/Estimation Bias Std        181.811\n",
      "evaluation/EB/Q_True Mean              48.1052\n",
      "evaluation/EB/Q_True Std              148.548\n",
      "evaluation/EB/Q_Pred Mean            1768.72\n",
      "evaluation/EB/Q_Pred Std              109.645\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5130.23\n",
      "evaluation/Actions Mean                 0.499118\n",
      "evaluation/Actions Std                  0.637654\n",
      "evaluation/Actions Max                  0.999988\n",
      "evaluation/Actions Min                 -0.99974\n",
      "time/backward_policy (s)                2.03083\n",
      "time/backward_zf1 (s)                   2.2856\n",
      "time/backward_zf2 (s)                   2.1556\n",
      "time/data sampling (s)                  0.302058\n",
      "time/data storing (s)                   0.0162174\n",
      "time/evaluation sampling (s)            1.48784\n",
      "time/exploration sampling (s)           0.221021\n",
      "time/logging (s)                        0.0131305\n",
      "time/preback_alpha (s)                  1.03653\n",
      "time/preback_policy (s)                 1.16054\n",
      "time/preback_start (s)                  0.135281\n",
      "time/preback_zf (s)                     5.42094\n",
      "time/saving (s)                         0.00563389\n",
      "time/training (s)                       2.43898\n",
      "time/epoch (s)                         18.7102\n",
      "time/total (s)                       2156.38\n",
      "Epoch                                 124\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:46:47.663398 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 125 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 136000\n",
      "trainer/ZF1 Loss                       56.0146\n",
      "trainer/ZF2 Loss                       56.1919\n",
      "trainer/ZF Expert Reward               18.9562\n",
      "trainer/ZF Policy Reward                1.03283\n",
      "trainer/ZF CHI2 Term                   93.5943\n",
      "trainer/Policy Loss                 -1374.1\n",
      "trainer/Bias Loss                     253.511\n",
      "trainer/Bias Value                     20.7779\n",
      "trainer/Policy Grad Norm              326.325\n",
      "trainer/Policy Param Norm              34.6715\n",
      "trainer/Zf1 Grad Norm                5689.49\n",
      "trainer/Zf1 Param Norm                103.693\n",
      "trainer/Zf2 Grad Norm                6094.59\n",
      "trainer/Zf2 Param Norm                101.839\n",
      "trainer/Z Expert Predictions Mean    1666.3\n",
      "trainer/Z Expert Predictions Std      217.437\n",
      "trainer/Z Expert Predictions Max     1936.69\n",
      "trainer/Z Expert Predictions Min      123.828\n",
      "trainer/Z Policy Predictions Mean    1364.04\n",
      "trainer/Z Policy Predictions Std      437.699\n",
      "trainer/Z Policy Predictions Max     1913.84\n",
      "trainer/Z Policy Predictions Min     -203.772\n",
      "trainer/Z Expert Targets Mean        1647.34\n",
      "trainer/Z Expert Targets Std          223.402\n",
      "trainer/Z Expert Targets Max         1917.79\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1363.01\n",
      "trainer/Z Policy Targets Std          431.862\n",
      "trainer/Z Policy Targets Max         1908.67\n",
      "trainer/Z Policy Targets Min         -144.775\n",
      "trainer/Log Pis Mean                   19.7653\n",
      "trainer/Log Pis Std                     5.4615\n",
      "trainer/Policy mu Mean                  1.17994\n",
      "trainer/Policy mu Std                   1.9295\n",
      "trainer/Policy log std Mean            -2.17702\n",
      "trainer/Policy log std Std              1.08223\n",
      "trainer/Alpha                           0.131395\n",
      "trainer/Alpha Loss                      0.0308361\n",
      "exploration/num steps total        131197\n",
      "exploration/num paths total           710\n",
      "evaluation/num steps total         891086\n",
      "evaluation/num paths total           1263\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14301\n",
      "evaluation/Rewards Std                  1.32152\n",
      "evaluation/Rewards Max                  7.17522\n",
      "evaluation/Rewards Min                  0.0993087\n",
      "evaluation/Returns Mean              5143.01\n",
      "evaluation/Returns Std                 23.6929\n",
      "evaluation/Returns Max               5166.6\n",
      "evaluation/Returns Min               5077.01\n",
      "evaluation/Estimation Bias Mean      1722.12\n",
      "evaluation/Estimation Bias Std        199.68\n",
      "evaluation/EB/Q_True Mean              48.5195\n",
      "evaluation/EB/Q_True Std              149.885\n",
      "evaluation/EB/Q_Pred Mean            1770.64\n",
      "evaluation/EB/Q_Pred Std              139.199\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5143.01\n",
      "evaluation/Actions Mean                 0.501096\n",
      "evaluation/Actions Std                  0.64465\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999942\n",
      "time/backward_policy (s)                2.04397\n",
      "time/backward_zf1 (s)                   2.24741\n",
      "time/backward_zf2 (s)                   2.11603\n",
      "time/data sampling (s)                  0.30846\n",
      "time/data storing (s)                   0.0167917\n",
      "time/evaluation sampling (s)            1.45224\n",
      "time/exploration sampling (s)           0.207368\n",
      "time/logging (s)                        0.0158941\n",
      "time/preback_alpha (s)                  1.04047\n",
      "time/preback_policy (s)                 1.17315\n",
      "time/preback_start (s)                  0.136652\n",
      "time/preback_zf (s)                     5.30787\n",
      "time/saving (s)                         0.00507731\n",
      "time/training (s)                       2.39174\n",
      "time/epoch (s)                         18.4631\n",
      "time/total (s)                       2174.87\n",
      "Epoch                                 125\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:47:07.748265 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 126 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 137000\n",
      "trainer/ZF1 Loss                       57.3931\n",
      "trainer/ZF2 Loss                       50.5765\n",
      "trainer/ZF Expert Reward               19.3158\n",
      "trainer/ZF Policy Reward                2.71889\n",
      "trainer/ZF CHI2 Term                   90.1398\n",
      "trainer/Policy Loss                 -1355.27\n",
      "trainer/Bias Loss                     209.044\n",
      "trainer/Bias Value                     20.7795\n",
      "trainer/Policy Grad Norm              329.679\n",
      "trainer/Policy Param Norm              34.7249\n",
      "trainer/Zf1 Grad Norm                4735.07\n",
      "trainer/Zf1 Param Norm                103.982\n",
      "trainer/Zf2 Grad Norm                4135.2\n",
      "trainer/Zf2 Param Norm                102.107\n",
      "trainer/Z Expert Predictions Mean    1675.86\n",
      "trainer/Z Expert Predictions Std      174.829\n",
      "trainer/Z Expert Predictions Max     1912.3\n",
      "trainer/Z Expert Predictions Min      603.473\n",
      "trainer/Z Policy Predictions Mean    1341.7\n",
      "trainer/Z Policy Predictions Std      491.449\n",
      "trainer/Z Policy Predictions Max     1889.63\n",
      "trainer/Z Policy Predictions Min     -299.324\n",
      "trainer/Z Expert Targets Mean        1656.54\n",
      "trainer/Z Expert Targets Std          179.819\n",
      "trainer/Z Expert Targets Max         1905.33\n",
      "trainer/Z Expert Targets Min          542.684\n",
      "trainer/Z Policy Targets Mean        1338.98\n",
      "trainer/Z Policy Targets Std          486.373\n",
      "trainer/Z Policy Targets Max         1884.09\n",
      "trainer/Z Policy Targets Min         -327.515\n",
      "trainer/Log Pis Mean                   19.7556\n",
      "trainer/Log Pis Std                     5.09749\n",
      "trainer/Policy mu Mean                  1.21387\n",
      "trainer/Policy mu Std                   1.93343\n",
      "trainer/Policy log std Mean            -2.23594\n",
      "trainer/Policy log std Std              1.09657\n",
      "trainer/Alpha                           0.13141\n",
      "trainer/Alpha Loss                      0.0321088\n",
      "exploration/num steps total        133197\n",
      "exploration/num paths total           712\n",
      "evaluation/num steps total         901086\n",
      "evaluation/num paths total           1273\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16629\n",
      "evaluation/Rewards Std                  1.31299\n",
      "evaluation/Rewards Max                  7.06986\n",
      "evaluation/Rewards Min                  0.11874\n",
      "evaluation/Returns Mean              5166.29\n",
      "evaluation/Returns Std                 12.6745\n",
      "evaluation/Returns Max               5182.1\n",
      "evaluation/Returns Min               5136.45\n",
      "evaluation/Estimation Bias Mean      1722.66\n",
      "evaluation/Estimation Bias Std        180.674\n",
      "evaluation/EB/Q_True Mean              48.8316\n",
      "evaluation/EB/Q_True Std              150.744\n",
      "evaluation/EB/Q_Pred Mean            1771.49\n",
      "evaluation/EB/Q_Pred Std              105.048\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5166.29\n",
      "evaluation/Actions Mean                 0.510799\n",
      "evaluation/Actions Std                  0.635651\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999785\n",
      "time/backward_policy (s)                2.26509\n",
      "time/backward_zf1 (s)                   2.57626\n",
      "time/backward_zf2 (s)                   2.42512\n",
      "time/data sampling (s)                  0.346439\n",
      "time/data storing (s)                   0.0156792\n",
      "time/evaluation sampling (s)            1.46197\n",
      "time/exploration sampling (s)           0.219829\n",
      "time/logging (s)                        0.0125236\n",
      "time/preback_alpha (s)                  1.1601\n",
      "time/preback_policy (s)                 1.35193\n",
      "time/preback_start (s)                  0.141507\n",
      "time/preback_zf (s)                     5.64123\n",
      "time/saving (s)                         0.00556119\n",
      "time/training (s)                       2.37874\n",
      "time/epoch (s)                         20.002\n",
      "time/total (s)                       2194.89\n",
      "Epoch                                 126\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:47:26.499711 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 127 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 138000\n",
      "trainer/ZF1 Loss                       66.2069\n",
      "trainer/ZF2 Loss                       57.6328\n",
      "trainer/ZF Expert Reward               34.4566\n",
      "trainer/ZF Policy Reward               12.2969\n",
      "trainer/ZF CHI2 Term                  103.547\n",
      "trainer/Policy Loss                 -1351.32\n",
      "trainer/Bias Loss                     253.732\n",
      "trainer/Bias Value                     20.782\n",
      "trainer/Policy Grad Norm              213.309\n",
      "trainer/Policy Param Norm              34.7762\n",
      "trainer/Zf1 Grad Norm                4802.94\n",
      "trainer/Zf1 Param Norm                104.227\n",
      "trainer/Zf2 Grad Norm                4884.27\n",
      "trainer/Zf2 Param Norm                102.343\n",
      "trainer/Z Expert Predictions Mean    1690.58\n",
      "trainer/Z Expert Predictions Std      169.64\n",
      "trainer/Z Expert Predictions Max     1935.42\n",
      "trainer/Z Expert Predictions Min      595.179\n",
      "trainer/Z Policy Predictions Mean    1343.26\n",
      "trainer/Z Policy Predictions Std      528.082\n",
      "trainer/Z Policy Predictions Max     1956.59\n",
      "trainer/Z Policy Predictions Min     -194.55\n",
      "trainer/Z Expert Targets Mean        1656.12\n",
      "trainer/Z Expert Targets Std          171.703\n",
      "trainer/Z Expert Targets Max         1901.16\n",
      "trainer/Z Expert Targets Min          556.033\n",
      "trainer/Z Policy Targets Mean        1330.97\n",
      "trainer/Z Policy Targets Std          516.613\n",
      "trainer/Z Policy Targets Max         1915.15\n",
      "trainer/Z Policy Targets Min         -204.851\n",
      "trainer/Log Pis Mean                   19.6638\n",
      "trainer/Log Pis Std                     4.39381\n",
      "trainer/Policy mu Mean                  1.24744\n",
      "trainer/Policy mu Std                   1.93089\n",
      "trainer/Policy log std Mean            -2.13848\n",
      "trainer/Policy log std Std              1.11555\n",
      "trainer/Alpha                           0.133037\n",
      "trainer/Alpha Loss                      0.044727\n",
      "exploration/num steps total        133197\n",
      "exploration/num paths total           712\n",
      "evaluation/num steps total         911086\n",
      "evaluation/num paths total           1283\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12521\n",
      "evaluation/Rewards Std                  1.28043\n",
      "evaluation/Rewards Max                  6.91443\n",
      "evaluation/Rewards Min                  0.141405\n",
      "evaluation/Returns Mean              5125.21\n",
      "evaluation/Returns Std                  9.4464\n",
      "evaluation/Returns Max               5142.68\n",
      "evaluation/Returns Min               5107.01\n",
      "evaluation/Estimation Bias Mean      1723.51\n",
      "evaluation/Estimation Bias Std        182.678\n",
      "evaluation/EB/Q_True Mean              48.4307\n",
      "evaluation/EB/Q_True Std              149.515\n",
      "evaluation/EB/Q_Pred Mean            1771.94\n",
      "evaluation/EB/Q_Pred Std              104.073\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5125.21\n",
      "evaluation/Actions Mean                 0.508572\n",
      "evaluation/Actions Std                  0.63469\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999854\n",
      "time/backward_policy (s)                2.07261\n",
      "time/backward_zf1 (s)                   2.2687\n",
      "time/backward_zf2 (s)                   2.16321\n",
      "time/data sampling (s)                  0.30692\n",
      "time/data storing (s)                   0.0151932\n",
      "time/evaluation sampling (s)            1.48487\n",
      "time/exploration sampling (s)           0.206461\n",
      "time/logging (s)                        0.0126214\n",
      "time/preback_alpha (s)                  1.05898\n",
      "time/preback_policy (s)                 1.20818\n",
      "time/preback_start (s)                  0.135559\n",
      "time/preback_zf (s)                     5.33295\n",
      "time/saving (s)                         0.00565854\n",
      "time/training (s)                       2.40029\n",
      "time/epoch (s)                         18.6722\n",
      "time/total (s)                       2213.59\n",
      "Epoch                                 127\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:47:45.151711 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 128 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 139000\n",
      "trainer/ZF1 Loss                       61.8741\n",
      "trainer/ZF2 Loss                       60.594\n",
      "trainer/ZF Expert Reward               19.1195\n",
      "trainer/ZF Policy Reward                2.46052\n",
      "trainer/ZF CHI2 Term                   97.1316\n",
      "trainer/Policy Loss                 -1356\n",
      "trainer/Bias Loss                     333.323\n",
      "trainer/Bias Value                     20.786\n",
      "trainer/Policy Grad Norm              221.803\n",
      "trainer/Policy Param Norm              34.8243\n",
      "trainer/Zf1 Grad Norm                5683.54\n",
      "trainer/Zf1 Param Norm                104.496\n",
      "trainer/Zf2 Grad Norm                5445.43\n",
      "trainer/Zf2 Param Norm                102.59\n",
      "trainer/Z Expert Predictions Mean    1677.41\n",
      "trainer/Z Expert Predictions Std      173.564\n",
      "trainer/Z Expert Predictions Max     1914.83\n",
      "trainer/Z Expert Predictions Min      849.099\n",
      "trainer/Z Policy Predictions Mean    1344.27\n",
      "trainer/Z Policy Predictions Std      479.595\n",
      "trainer/Z Policy Predictions Max     1931.99\n",
      "trainer/Z Policy Predictions Min     -158.473\n",
      "trainer/Z Expert Targets Mean        1658.29\n",
      "trainer/Z Expert Targets Std          178.55\n",
      "trainer/Z Expert Targets Max         1895.29\n",
      "trainer/Z Expert Targets Min          823.888\n",
      "trainer/Z Policy Targets Mean        1341.81\n",
      "trainer/Z Policy Targets Std          475.372\n",
      "trainer/Z Policy Targets Max         1918.38\n",
      "trainer/Z Policy Targets Min         -124.083\n",
      "trainer/Log Pis Mean                   19.4329\n",
      "trainer/Log Pis Std                     4.54554\n",
      "trainer/Policy mu Mean                  1.19843\n",
      "trainer/Policy mu Std                   1.84628\n",
      "trainer/Policy log std Mean            -2.21055\n",
      "trainer/Policy log std Std              1.11557\n",
      "trainer/Alpha                           0.133433\n",
      "trainer/Alpha Loss                      0.0756626\n",
      "exploration/num steps total        133197\n",
      "exploration/num paths total           712\n",
      "evaluation/num steps total         921086\n",
      "evaluation/num paths total           1293\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20556\n",
      "evaluation/Rewards Std                  1.33741\n",
      "evaluation/Rewards Max                  7.13634\n",
      "evaluation/Rewards Min                  0.0856294\n",
      "evaluation/Returns Mean              5205.56\n",
      "evaluation/Returns Std                 12.531\n",
      "evaluation/Returns Max               5238.09\n",
      "evaluation/Returns Min               5191.64\n",
      "evaluation/Estimation Bias Mean      1722.75\n",
      "evaluation/Estimation Bias Std        186.801\n",
      "evaluation/EB/Q_True Mean              49.1397\n",
      "evaluation/EB/Q_True Std              151.927\n",
      "evaluation/EB/Q_Pred Mean            1771.88\n",
      "evaluation/EB/Q_Pred Std              107.958\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5205.56\n",
      "evaluation/Actions Mean                 0.495831\n",
      "evaluation/Actions Std                  0.644145\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999747\n",
      "time/backward_policy (s)                2.08025\n",
      "time/backward_zf1 (s)                   2.32524\n",
      "time/backward_zf2 (s)                   2.20375\n",
      "time/data sampling (s)                  0.294267\n",
      "time/data storing (s)                   0.0148591\n",
      "time/evaluation sampling (s)            1.40514\n",
      "time/exploration sampling (s)           0.200153\n",
      "time/logging (s)                        0.0146655\n",
      "time/preback_alpha (s)                  1.07609\n",
      "time/preback_policy (s)                 1.21249\n",
      "time/preback_start (s)                  0.131214\n",
      "time/preback_zf (s)                     5.35322\n",
      "time/saving (s)                         0.00525775\n",
      "time/training (s)                       2.26166\n",
      "time/epoch (s)                         18.5783\n",
      "time/total (s)                       2232.2\n",
      "Epoch                                 128\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:48:03.755539 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 129 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 140000\n",
      "trainer/ZF1 Loss                       51.9092\n",
      "trainer/ZF2 Loss                       67.395\n",
      "trainer/ZF Expert Reward               12.0609\n",
      "trainer/ZF Policy Reward               -5.91596\n",
      "trainer/ZF CHI2 Term                   97.5441\n",
      "trainer/Policy Loss                 -1360.56\n",
      "trainer/Bias Loss                     306.873\n",
      "trainer/Bias Value                     20.788\n",
      "trainer/Policy Grad Norm              320.188\n",
      "trainer/Policy Param Norm              34.8804\n",
      "trainer/Zf1 Grad Norm                6230.01\n",
      "trainer/Zf1 Param Norm                104.756\n",
      "trainer/Zf2 Grad Norm                7664.01\n",
      "trainer/Zf2 Param Norm                102.839\n",
      "trainer/Z Expert Predictions Mean    1665.49\n",
      "trainer/Z Expert Predictions Std      164.26\n",
      "trainer/Z Expert Predictions Max     1920.51\n",
      "trainer/Z Expert Predictions Min     1109.94\n",
      "trainer/Z Policy Predictions Mean    1344.21\n",
      "trainer/Z Policy Predictions Std      501.117\n",
      "trainer/Z Policy Predictions Max     1886.64\n",
      "trainer/Z Policy Predictions Min     -157.42\n",
      "trainer/Z Expert Targets Mean        1653.43\n",
      "trainer/Z Expert Targets Std          164.151\n",
      "trainer/Z Expert Targets Max         1898.47\n",
      "trainer/Z Expert Targets Min         1158.44\n",
      "trainer/Z Policy Targets Mean        1350.13\n",
      "trainer/Z Policy Targets Std          491.805\n",
      "trainer/Z Policy Targets Max         1902.78\n",
      "trainer/Z Policy Targets Min         -146.798\n",
      "trainer/Log Pis Mean                   20.1162\n",
      "trainer/Log Pis Std                     4.71694\n",
      "trainer/Policy mu Mean                  1.20038\n",
      "trainer/Policy mu Std                   1.99115\n",
      "trainer/Policy log std Mean            -2.21736\n",
      "trainer/Policy log std Std              1.09354\n",
      "trainer/Alpha                           0.133716\n",
      "trainer/Alpha Loss                     -0.0155396\n",
      "exploration/num steps total        134197\n",
      "exploration/num paths total           713\n",
      "evaluation/num steps total         931086\n",
      "evaluation/num paths total           1303\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15414\n",
      "evaluation/Rewards Std                  1.31207\n",
      "evaluation/Rewards Max                  7.01539\n",
      "evaluation/Rewards Min                  0.123316\n",
      "evaluation/Returns Mean              5154.14\n",
      "evaluation/Returns Std                 14.8464\n",
      "evaluation/Returns Max               5184.64\n",
      "evaluation/Returns Min               5132.02\n",
      "evaluation/Estimation Bias Mean      1674.45\n",
      "evaluation/Estimation Bias Std        186.404\n",
      "evaluation/EB/Q_True Mean              48.8113\n",
      "evaluation/EB/Q_True Std              150.73\n",
      "evaluation/EB/Q_Pred Mean            1723.26\n",
      "evaluation/EB/Q_Pred Std              107.537\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5154.14\n",
      "evaluation/Actions Mean                 0.512493\n",
      "evaluation/Actions Std                  0.640546\n",
      "evaluation/Actions Max                  0.999974\n",
      "evaluation/Actions Min                 -0.999884\n",
      "time/backward_policy (s)                2.07929\n",
      "time/backward_zf1 (s)                   2.28259\n",
      "time/backward_zf2 (s)                   2.19426\n",
      "time/data sampling (s)                  0.272177\n",
      "time/data storing (s)                   0.0159023\n",
      "time/evaluation sampling (s)            1.4899\n",
      "time/exploration sampling (s)           0.206967\n",
      "time/logging (s)                        0.0120878\n",
      "time/preback_alpha (s)                  1.09743\n",
      "time/preback_policy (s)                 1.25606\n",
      "time/preback_start (s)                  0.129877\n",
      "time/preback_zf (s)                     5.28824\n",
      "time/saving (s)                         0.00520421\n",
      "time/training (s)                       2.20148\n",
      "time/epoch (s)                         18.5315\n",
      "time/total (s)                       2250.75\n",
      "Epoch                                 129\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:48:21.723998 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 130 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 141000\n",
      "trainer/ZF1 Loss                      672.56\n",
      "trainer/ZF2 Loss                      642.076\n",
      "trainer/ZF Expert Reward               15.6898\n",
      "trainer/ZF Policy Reward                4.3219\n",
      "trainer/ZF CHI2 Term                  688.512\n",
      "trainer/Policy Loss                 -1425.27\n",
      "trainer/Bias Loss                     206.848\n",
      "trainer/Bias Value                     20.7881\n",
      "trainer/Policy Grad Norm              384.126\n",
      "trainer/Policy Param Norm              34.9346\n",
      "trainer/Zf1 Grad Norm                8096.21\n",
      "trainer/Zf1 Param Norm                105.017\n",
      "trainer/Zf2 Grad Norm                9118.32\n",
      "trainer/Zf2 Param Norm                103.071\n",
      "trainer/Z Expert Predictions Mean    1644.53\n",
      "trainer/Z Expert Predictions Std      174.003\n",
      "trainer/Z Expert Predictions Max     1943.87\n",
      "trainer/Z Expert Predictions Min      986.053\n",
      "trainer/Z Policy Predictions Mean    1416.93\n",
      "trainer/Z Policy Predictions Std      406.524\n",
      "trainer/Z Policy Predictions Max     1905\n",
      "trainer/Z Policy Predictions Min     -161.528\n",
      "trainer/Z Expert Targets Mean        1628.84\n",
      "trainer/Z Expert Targets Std          177.874\n",
      "trainer/Z Expert Targets Max         1904.67\n",
      "trainer/Z Expert Targets Min          920.544\n",
      "trainer/Z Policy Targets Mean        1412.61\n",
      "trainer/Z Policy Targets Std          410.236\n",
      "trainer/Z Policy Targets Max         1901.95\n",
      "trainer/Z Policy Targets Min         -177.104\n",
      "trainer/Log Pis Mean                   20.0261\n",
      "trainer/Log Pis Std                     4.52529\n",
      "trainer/Policy mu Mean                  1.29147\n",
      "trainer/Policy mu Std                   1.80996\n",
      "trainer/Policy log std Mean            -2.30503\n",
      "trainer/Policy log std Std              1.05615\n",
      "trainer/Alpha                           0.132878\n",
      "trainer/Alpha Loss                     -0.00347217\n",
      "exploration/num steps total        136197\n",
      "exploration/num paths total           715\n",
      "evaluation/num steps total         941086\n",
      "evaluation/num paths total           1313\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1293\n",
      "evaluation/Rewards Std                  1.27921\n",
      "evaluation/Rewards Max                  7.13913\n",
      "evaluation/Rewards Min                  0.147573\n",
      "evaluation/Returns Mean              5129.3\n",
      "evaluation/Returns Std                 44.5538\n",
      "evaluation/Returns Max               5177.49\n",
      "evaluation/Returns Min               5010.13\n",
      "evaluation/Estimation Bias Mean      1688.97\n",
      "evaluation/Estimation Bias Std        206.501\n",
      "evaluation/EB/Q_True Mean              48.496\n",
      "evaluation/EB/Q_True Std              149.778\n",
      "evaluation/EB/Q_Pred Mean            1737.46\n",
      "evaluation/EB/Q_Pred Std              141.74\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5129.3\n",
      "evaluation/Actions Mean                 0.506148\n",
      "evaluation/Actions Std                  0.644615\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999985\n",
      "time/backward_policy (s)                1.93974\n",
      "time/backward_zf1 (s)                   2.12853\n",
      "time/backward_zf2 (s)                   2.02856\n",
      "time/data sampling (s)                  0.287145\n",
      "time/data storing (s)                   0.0162822\n",
      "time/evaluation sampling (s)            1.43519\n",
      "time/exploration sampling (s)           0.211873\n",
      "time/logging (s)                        0.0120628\n",
      "time/preback_alpha (s)                  0.997274\n",
      "time/preback_policy (s)                 1.11567\n",
      "time/preback_start (s)                  0.131926\n",
      "time/preback_zf (s)                     5.20963\n",
      "time/saving (s)                         0.00533469\n",
      "time/training (s)                       2.37926\n",
      "time/epoch (s)                         17.8985\n",
      "time/total (s)                       2268.66\n",
      "Epoch                                 130\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:48:40.138543 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 131 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 142000\n",
      "trainer/ZF1 Loss                       61.1015\n",
      "trainer/ZF2 Loss                       49.6367\n",
      "trainer/ZF Expert Reward               25.8714\n",
      "trainer/ZF Policy Reward                9.04854\n",
      "trainer/ZF CHI2 Term                   92.0136\n",
      "trainer/Policy Loss                 -1425.95\n",
      "trainer/Bias Loss                     233.669\n",
      "trainer/Bias Value                     20.7893\n",
      "trainer/Policy Grad Norm              319.716\n",
      "trainer/Policy Param Norm              34.9928\n",
      "trainer/Zf1 Grad Norm                6426.33\n",
      "trainer/Zf1 Param Norm                105.274\n",
      "trainer/Zf2 Grad Norm                5458.58\n",
      "trainer/Zf2 Param Norm                103.323\n",
      "trainer/Z Expert Predictions Mean    1681.6\n",
      "trainer/Z Expert Predictions Std      163.624\n",
      "trainer/Z Expert Predictions Max     1935.4\n",
      "trainer/Z Expert Predictions Min     1118.81\n",
      "trainer/Z Policy Predictions Mean    1415.78\n",
      "trainer/Z Policy Predictions Std      469.392\n",
      "trainer/Z Policy Predictions Max     1873.89\n",
      "trainer/Z Policy Predictions Min     -232.076\n",
      "trainer/Z Expert Targets Mean        1655.73\n",
      "trainer/Z Expert Targets Std          164.356\n",
      "trainer/Z Expert Targets Max         1901.56\n",
      "trainer/Z Expert Targets Min         1046.72\n",
      "trainer/Z Policy Targets Mean        1406.73\n",
      "trainer/Z Policy Targets Std          465.999\n",
      "trainer/Z Policy Targets Max         1874.71\n",
      "trainer/Z Policy Targets Min         -229.518\n",
      "trainer/Log Pis Mean                   20.0219\n",
      "trainer/Log Pis Std                     4.62239\n",
      "trainer/Policy mu Mean                  1.26754\n",
      "trainer/Policy mu Std                   1.84541\n",
      "trainer/Policy log std Mean            -2.19096\n",
      "trainer/Policy log std Std              1.07906\n",
      "trainer/Alpha                           0.134902\n",
      "trainer/Alpha Loss                     -0.00294974\n",
      "exploration/num steps total        137197\n",
      "exploration/num paths total           716\n",
      "evaluation/num steps total         951086\n",
      "evaluation/num paths total           1323\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13162\n",
      "evaluation/Rewards Std                  1.30704\n",
      "evaluation/Rewards Max                  7.03567\n",
      "evaluation/Rewards Min                  0.122621\n",
      "evaluation/Returns Mean              5131.62\n",
      "evaluation/Returns Std                 12.4949\n",
      "evaluation/Returns Max               5150.12\n",
      "evaluation/Returns Min               5107.18\n",
      "evaluation/Estimation Bias Mean      1702\n",
      "evaluation/Estimation Bias Std        202.542\n",
      "evaluation/EB/Q_True Mean              48.6489\n",
      "evaluation/EB/Q_True Std              150.212\n",
      "evaluation/EB/Q_Pred Mean            1750.65\n",
      "evaluation/EB/Q_Pred Std              132.089\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5131.62\n",
      "evaluation/Actions Mean                 0.512933\n",
      "evaluation/Actions Std                  0.640266\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999786\n",
      "time/backward_policy (s)                1.99548\n",
      "time/backward_zf1 (s)                   2.2405\n",
      "time/backward_zf2 (s)                   2.09107\n",
      "time/data sampling (s)                  0.293387\n",
      "time/data storing (s)                   0.0156854\n",
      "time/evaluation sampling (s)            1.48552\n",
      "time/exploration sampling (s)           0.211935\n",
      "time/logging (s)                        0.0123208\n",
      "time/preback_alpha (s)                  1.00624\n",
      "time/preback_policy (s)                 1.11512\n",
      "time/preback_start (s)                  0.131515\n",
      "time/preback_zf (s)                     5.28363\n",
      "time/saving (s)                         0.00718254\n",
      "time/training (s)                       2.45333\n",
      "time/epoch (s)                         18.3429\n",
      "time/total (s)                       2287.03\n",
      "Epoch                                 131\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:48:59.315008 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 132 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 143000\n",
      "trainer/ZF1 Loss                       49.2865\n",
      "trainer/ZF2 Loss                       42.3785\n",
      "trainer/ZF Expert Reward               15.2811\n",
      "trainer/ZF Policy Reward               -4.14968\n",
      "trainer/ZF CHI2 Term                   85.6617\n",
      "trainer/Policy Loss                 -1420.08\n",
      "trainer/Bias Loss                     179.686\n",
      "trainer/Bias Value                     20.7897\n",
      "trainer/Policy Grad Norm              274.959\n",
      "trainer/Policy Param Norm              35.0485\n",
      "trainer/Zf1 Grad Norm                5979.02\n",
      "trainer/Zf1 Param Norm                105.533\n",
      "trainer/Zf2 Grad Norm                4497.01\n",
      "trainer/Zf2 Param Norm                103.588\n",
      "trainer/Z Expert Predictions Mean    1669.82\n",
      "trainer/Z Expert Predictions Std      169.128\n",
      "trainer/Z Expert Predictions Max     1900.9\n",
      "trainer/Z Expert Predictions Min      717.359\n",
      "trainer/Z Policy Predictions Mean    1403.81\n",
      "trainer/Z Policy Predictions Std      466.286\n",
      "trainer/Z Policy Predictions Max     1890.75\n",
      "trainer/Z Policy Predictions Min     -122.271\n",
      "trainer/Z Expert Targets Mean        1654.54\n",
      "trainer/Z Expert Targets Std          171.705\n",
      "trainer/Z Expert Targets Max         1882.53\n",
      "trainer/Z Expert Targets Min          693.989\n",
      "trainer/Z Policy Targets Mean        1407.96\n",
      "trainer/Z Policy Targets Std          459.295\n",
      "trainer/Z Policy Targets Max         1874.88\n",
      "trainer/Z Policy Targets Min         -174.098\n",
      "trainer/Log Pis Mean                   20.6045\n",
      "trainer/Log Pis Std                     4.89427\n",
      "trainer/Policy mu Mean                  1.32122\n",
      "trainer/Policy mu Std                   1.90211\n",
      "trainer/Policy log std Mean            -2.20548\n",
      "trainer/Policy log std Std              1.12065\n",
      "trainer/Alpha                           0.136047\n",
      "trainer/Alpha Loss                     -0.0822347\n",
      "exploration/num steps total        137197\n",
      "exploration/num paths total           716\n",
      "evaluation/num steps total         961086\n",
      "evaluation/num paths total           1333\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20277\n",
      "evaluation/Rewards Std                  1.3158\n",
      "evaluation/Rewards Max                  7.14003\n",
      "evaluation/Rewards Min                  0.157107\n",
      "evaluation/Returns Mean              5202.77\n",
      "evaluation/Returns Std                 24.3722\n",
      "evaluation/Returns Max               5241.8\n",
      "evaluation/Returns Min               5172.41\n",
      "evaluation/Estimation Bias Mean      1720.04\n",
      "evaluation/Estimation Bias Std        176.253\n",
      "evaluation/EB/Q_True Mean              48.8765\n",
      "evaluation/EB/Q_True Std              151.132\n",
      "evaluation/EB/Q_Pred Mean            1768.91\n",
      "evaluation/EB/Q_Pred Std              102.493\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5202.77\n",
      "evaluation/Actions Mean                 0.496555\n",
      "evaluation/Actions Std                  0.647793\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -0.999757\n",
      "time/backward_policy (s)                2.17222\n",
      "time/backward_zf1 (s)                   2.3904\n",
      "time/backward_zf2 (s)                   2.28447\n",
      "time/data sampling (s)                  0.318229\n",
      "time/data storing (s)                   0.0165703\n",
      "time/evaluation sampling (s)            1.48457\n",
      "time/exploration sampling (s)           0.21329\n",
      "time/logging (s)                        0.0119643\n",
      "time/preback_alpha (s)                  1.10723\n",
      "time/preback_policy (s)                 1.26099\n",
      "time/preback_start (s)                  0.137789\n",
      "time/preback_zf (s)                     5.3898\n",
      "time/saving (s)                         0.00628903\n",
      "time/training (s)                       2.30534\n",
      "time/epoch (s)                         19.0991\n",
      "time/total (s)                       2306.15\n",
      "Epoch                                 132\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:49:17.897804 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 133 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 144000\n",
      "trainer/ZF1 Loss                       37.9671\n",
      "trainer/ZF2 Loss                       48.3757\n",
      "trainer/ZF Expert Reward               16.8884\n",
      "trainer/ZF Policy Reward               -1.0286\n",
      "trainer/ZF CHI2 Term                   80.4638\n",
      "trainer/Policy Loss                 -1422.94\n",
      "trainer/Bias Loss                     248.146\n",
      "trainer/Bias Value                     20.7892\n",
      "trainer/Policy Grad Norm              293.728\n",
      "trainer/Policy Param Norm              35.0985\n",
      "trainer/Zf1 Grad Norm                4456.82\n",
      "trainer/Zf1 Param Norm                105.778\n",
      "trainer/Zf2 Grad Norm                5450.08\n",
      "trainer/Zf2 Param Norm                103.826\n",
      "trainer/Z Expert Predictions Mean    1666.56\n",
      "trainer/Z Expert Predictions Std      185.703\n",
      "trainer/Z Expert Predictions Max     1880.75\n",
      "trainer/Z Expert Predictions Min      527.347\n",
      "trainer/Z Policy Predictions Mean    1404.94\n",
      "trainer/Z Policy Predictions Std      436.679\n",
      "trainer/Z Policy Predictions Max     1886.98\n",
      "trainer/Z Policy Predictions Min     -175.746\n",
      "trainer/Z Expert Targets Mean        1649.67\n",
      "trainer/Z Expert Targets Std          190.22\n",
      "trainer/Z Expert Targets Max         1874.14\n",
      "trainer/Z Expert Targets Min          474.65\n",
      "trainer/Z Policy Targets Mean        1405.97\n",
      "trainer/Z Policy Targets Std          432.728\n",
      "trainer/Z Policy Targets Max         1871.92\n",
      "trainer/Z Policy Targets Min         -165.661\n",
      "trainer/Log Pis Mean                   19.571\n",
      "trainer/Log Pis Std                     4.39465\n",
      "trainer/Policy mu Mean                  1.24564\n",
      "trainer/Policy mu Std                   1.87244\n",
      "trainer/Policy log std Mean            -2.24599\n",
      "trainer/Policy log std Std              1.12469\n",
      "trainer/Alpha                           0.136738\n",
      "trainer/Alpha Loss                      0.0586586\n",
      "exploration/num steps total        139197\n",
      "exploration/num paths total           718\n",
      "evaluation/num steps total         971086\n",
      "evaluation/num paths total           1343\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18698\n",
      "evaluation/Rewards Std                  1.32299\n",
      "evaluation/Rewards Max                  7.06435\n",
      "evaluation/Rewards Min                  0.0985351\n",
      "evaluation/Returns Mean              5186.98\n",
      "evaluation/Returns Std                 21.1\n",
      "evaluation/Returns Max               5215.72\n",
      "evaluation/Returns Min               5157.07\n",
      "evaluation/Estimation Bias Mean      1709.76\n",
      "evaluation/Estimation Bias Std        179.605\n",
      "evaluation/EB/Q_True Mean              49.2056\n",
      "evaluation/EB/Q_True Std              151.999\n",
      "evaluation/EB/Q_Pred Mean            1758.97\n",
      "evaluation/EB/Q_Pred Std               97.9374\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5186.98\n",
      "evaluation/Actions Mean                 0.50936\n",
      "evaluation/Actions Std                  0.637929\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.99986\n",
      "time/backward_policy (s)                2.04051\n",
      "time/backward_zf1 (s)                   2.27584\n",
      "time/backward_zf2 (s)                   2.16389\n",
      "time/data sampling (s)                  0.301798\n",
      "time/data storing (s)                   0.0152344\n",
      "time/evaluation sampling (s)            1.46338\n",
      "time/exploration sampling (s)           0.206034\n",
      "time/logging (s)                        0.0122959\n",
      "time/preback_alpha (s)                  1.04304\n",
      "time/preback_policy (s)                 1.17199\n",
      "time/preback_start (s)                  0.1346\n",
      "time/preback_zf (s)                     5.31985\n",
      "time/saving (s)                         0.00562229\n",
      "time/training (s)                       2.3568\n",
      "time/epoch (s)                         18.5109\n",
      "time/total (s)                       2324.68\n",
      "Epoch                                 133\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:49:37.096453 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 134 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 145000\n",
      "trainer/ZF1 Loss                       51.5319\n",
      "trainer/ZF2 Loss                       50.8498\n",
      "trainer/ZF Expert Reward               15.2332\n",
      "trainer/ZF Policy Reward                0.715745\n",
      "trainer/ZF CHI2 Term                   85.4793\n",
      "trainer/Policy Loss                 -1410.85\n",
      "trainer/Bias Loss                     209.284\n",
      "trainer/Bias Value                     20.7886\n",
      "trainer/Policy Grad Norm              273.854\n",
      "trainer/Policy Param Norm              35.1455\n",
      "trainer/Zf1 Grad Norm                4381.69\n",
      "trainer/Zf1 Param Norm                106.021\n",
      "trainer/Zf2 Grad Norm                5269.17\n",
      "trainer/Zf2 Param Norm                104.06\n",
      "trainer/Z Expert Predictions Mean    1674.88\n",
      "trainer/Z Expert Predictions Std      152.609\n",
      "trainer/Z Expert Predictions Max     1889.98\n",
      "trainer/Z Expert Predictions Min     1082.31\n",
      "trainer/Z Policy Predictions Mean    1392.43\n",
      "trainer/Z Policy Predictions Std      468.521\n",
      "trainer/Z Policy Predictions Max     1873.43\n",
      "trainer/Z Policy Predictions Min     -180.58\n",
      "trainer/Z Expert Targets Mean        1659.64\n",
      "trainer/Z Expert Targets Std          156.217\n",
      "trainer/Z Expert Targets Max         1873.2\n",
      "trainer/Z Expert Targets Min         1059.69\n",
      "trainer/Z Policy Targets Mean        1391.71\n",
      "trainer/Z Policy Targets Std          460.803\n",
      "trainer/Z Policy Targets Max         1849.61\n",
      "trainer/Z Policy Targets Min         -189.246\n",
      "trainer/Log Pis Mean                   19.9706\n",
      "trainer/Log Pis Std                     4.55123\n",
      "trainer/Policy mu Mean                  1.23934\n",
      "trainer/Policy mu Std                   1.86656\n",
      "trainer/Policy log std Mean            -2.23541\n",
      "trainer/Policy log std Std              1.1311\n",
      "trainer/Alpha                           0.137303\n",
      "trainer/Alpha Loss                      0.00403425\n",
      "exploration/num steps total        141197\n",
      "exploration/num paths total           720\n",
      "evaluation/num steps total         981086\n",
      "evaluation/num paths total           1353\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13823\n",
      "evaluation/Rewards Std                  1.29043\n",
      "evaluation/Rewards Max                  6.95022\n",
      "evaluation/Rewards Min                  0.148509\n",
      "evaluation/Returns Mean              5138.23\n",
      "evaluation/Returns Std                 15.7496\n",
      "evaluation/Returns Max               5163.84\n",
      "evaluation/Returns Min               5107.4\n",
      "evaluation/Estimation Bias Mean      1727.98\n",
      "evaluation/Estimation Bias Std        181.464\n",
      "evaluation/EB/Q_True Mean              48.5187\n",
      "evaluation/EB/Q_True Std              149.955\n",
      "evaluation/EB/Q_Pred Mean            1776.5\n",
      "evaluation/EB/Q_Pred Std               97.8771\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5138.23\n",
      "evaluation/Actions Mean                 0.496033\n",
      "evaluation/Actions Std                  0.648877\n",
      "evaluation/Actions Max                  0.999982\n",
      "evaluation/Actions Min                 -0.999893\n",
      "time/backward_policy (s)                2.14546\n",
      "time/backward_zf1 (s)                   2.36284\n",
      "time/backward_zf2 (s)                   2.20619\n",
      "time/data sampling (s)                  0.321164\n",
      "time/data storing (s)                   0.0166417\n",
      "time/evaluation sampling (s)            1.57111\n",
      "time/exploration sampling (s)           0.222102\n",
      "time/logging (s)                        0.0117677\n",
      "time/preback_alpha (s)                  1.10714\n",
      "time/preback_policy (s)                 1.24865\n",
      "time/preback_start (s)                  0.138668\n",
      "time/preback_zf (s)                     5.41355\n",
      "time/saving (s)                         0.00551836\n",
      "time/training (s)                       2.35119\n",
      "time/epoch (s)                         19.122\n",
      "time/total (s)                       2343.82\n",
      "Epoch                                 134\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:49:55.461104 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 135 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 146000\n",
      "trainer/ZF1 Loss                       40.1136\n",
      "trainer/ZF2 Loss                       38.2451\n",
      "trainer/ZF Expert Reward               24.6535\n",
      "trainer/ZF Policy Reward                3.80522\n",
      "trainer/ZF CHI2 Term                   80.3691\n",
      "trainer/Policy Loss                 -1383.9\n",
      "trainer/Bias Loss                     251.569\n",
      "trainer/Bias Value                     20.7883\n",
      "trainer/Policy Grad Norm              352.507\n",
      "trainer/Policy Param Norm              35.1919\n",
      "trainer/Zf1 Grad Norm                3518.19\n",
      "trainer/Zf1 Param Norm                106.275\n",
      "trainer/Zf2 Grad Norm                4403.08\n",
      "trainer/Zf2 Param Norm                104.313\n",
      "trainer/Z Expert Predictions Mean    1679.01\n",
      "trainer/Z Expert Predictions Std      165.845\n",
      "trainer/Z Expert Predictions Max     1906.08\n",
      "trainer/Z Expert Predictions Min      803.038\n",
      "trainer/Z Policy Predictions Mean    1374.14\n",
      "trainer/Z Policy Predictions Std      477.45\n",
      "trainer/Z Policy Predictions Max     1879.45\n",
      "trainer/Z Policy Predictions Min     -156.364\n",
      "trainer/Z Expert Targets Mean        1654.36\n",
      "trainer/Z Expert Targets Std          167.45\n",
      "trainer/Z Expert Targets Max         1875.2\n",
      "trainer/Z Expert Targets Min          769.601\n",
      "trainer/Z Policy Targets Mean        1370.34\n",
      "trainer/Z Policy Targets Std          474.984\n",
      "trainer/Z Policy Targets Max         1863.6\n",
      "trainer/Z Policy Targets Min         -162.436\n",
      "trainer/Log Pis Mean                   20.547\n",
      "trainer/Log Pis Std                     5.04507\n",
      "trainer/Policy mu Mean                  1.22115\n",
      "trainer/Policy mu Std                   2.02555\n",
      "trainer/Policy log std Mean            -2.19965\n",
      "trainer/Policy log std Std              1.15717\n",
      "trainer/Alpha                           0.136898\n",
      "trainer/Alpha Loss                     -0.0748749\n",
      "exploration/num steps total        141197\n",
      "exploration/num paths total           720\n",
      "evaluation/num steps total         991086\n",
      "evaluation/num paths total           1363\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12269\n",
      "evaluation/Rewards Std                  1.31366\n",
      "evaluation/Rewards Max                  6.96928\n",
      "evaluation/Rewards Min                  0.095823\n",
      "evaluation/Returns Mean              5122.69\n",
      "evaluation/Returns Std                 12.0186\n",
      "evaluation/Returns Max               5146.53\n",
      "evaluation/Returns Min               5100.45\n",
      "evaluation/Estimation Bias Mean      1714.39\n",
      "evaluation/Estimation Bias Std        175.261\n",
      "evaluation/EB/Q_True Mean              48.4508\n",
      "evaluation/EB/Q_True Std              149.675\n",
      "evaluation/EB/Q_Pred Mean            1762.84\n",
      "evaluation/EB/Q_Pred Std               95.1099\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5122.69\n",
      "evaluation/Actions Mean                 0.49625\n",
      "evaluation/Actions Std                  0.640641\n",
      "evaluation/Actions Max                  0.999986\n",
      "evaluation/Actions Min                 -0.999926\n",
      "time/backward_policy (s)                1.97002\n",
      "time/backward_zf1 (s)                   2.20294\n",
      "time/backward_zf2 (s)                   2.06572\n",
      "time/data sampling (s)                  0.317996\n",
      "time/data storing (s)                   0.0144411\n",
      "time/evaluation sampling (s)            1.42536\n",
      "time/exploration sampling (s)           0.19772\n",
      "time/logging (s)                        0.0116806\n",
      "time/preback_alpha (s)                  1.00979\n",
      "time/preback_policy (s)                 1.12621\n",
      "time/preback_start (s)                  0.131936\n",
      "time/preback_zf (s)                     5.34589\n",
      "time/saving (s)                         0.00563256\n",
      "time/training (s)                       2.46435\n",
      "time/epoch (s)                         18.2897\n",
      "time/total (s)                       2362.14\n",
      "Epoch                                 135\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:50:13.772435 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 136 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 147000\n",
      "trainer/ZF1 Loss                       65.4778\n",
      "trainer/ZF2 Loss                       48.9677\n",
      "trainer/ZF Expert Reward               24.0053\n",
      "trainer/ZF Policy Reward               10.7541\n",
      "trainer/ZF CHI2 Term                   90.2197\n",
      "trainer/Policy Loss                 -1431.61\n",
      "trainer/Bias Loss                     260.767\n",
      "trainer/Bias Value                     20.7854\n",
      "trainer/Policy Grad Norm              466.56\n",
      "trainer/Policy Param Norm              35.2423\n",
      "trainer/Zf1 Grad Norm                3998.52\n",
      "trainer/Zf1 Param Norm                106.536\n",
      "trainer/Zf2 Grad Norm                4004.79\n",
      "trainer/Zf2 Param Norm                104.557\n",
      "trainer/Z Expert Predictions Mean    1681.07\n",
      "trainer/Z Expert Predictions Std      167.679\n",
      "trainer/Z Expert Predictions Max     1889.29\n",
      "trainer/Z Expert Predictions Min      558.078\n",
      "trainer/Z Policy Predictions Mean    1429.78\n",
      "trainer/Z Policy Predictions Std      420.965\n",
      "trainer/Z Policy Predictions Max     1864.17\n",
      "trainer/Z Policy Predictions Min     -222.002\n",
      "trainer/Z Expert Targets Mean        1657.07\n",
      "trainer/Z Expert Targets Std          173.128\n",
      "trainer/Z Expert Targets Max         1874.03\n",
      "trainer/Z Expert Targets Min          444.235\n",
      "trainer/Z Policy Targets Mean        1419.02\n",
      "trainer/Z Policy Targets Std          413.699\n",
      "trainer/Z Policy Targets Max         1868.14\n",
      "trainer/Z Policy Targets Min         -214.152\n",
      "trainer/Log Pis Mean                   19.9452\n",
      "trainer/Log Pis Std                     4.17003\n",
      "trainer/Policy mu Mean                  1.26264\n",
      "trainer/Policy mu Std                   1.8182\n",
      "trainer/Policy log std Mean            -2.28954\n",
      "trainer/Policy log std Std              1.0944\n",
      "trainer/Alpha                           0.138605\n",
      "trainer/Alpha Loss                      0.0076016\n",
      "exploration/num steps total        143197\n",
      "exploration/num paths total           722\n",
      "evaluation/num steps total              1.00109e+06\n",
      "evaluation/num paths total           1373\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08659\n",
      "evaluation/Rewards Std                  1.28315\n",
      "evaluation/Rewards Max                  6.93602\n",
      "evaluation/Rewards Min                  0.116946\n",
      "evaluation/Returns Mean              5086.59\n",
      "evaluation/Returns Std                 14.0939\n",
      "evaluation/Returns Max               5112.96\n",
      "evaluation/Returns Min               5067.73\n",
      "evaluation/Estimation Bias Mean      1685.54\n",
      "evaluation/Estimation Bias Std        186.078\n",
      "evaluation/EB/Q_True Mean              47.9019\n",
      "evaluation/EB/Q_True Std              147.77\n",
      "evaluation/EB/Q_Pred Mean            1733.44\n",
      "evaluation/EB/Q_Pred Std               97.0445\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5086.59\n",
      "evaluation/Actions Mean                 0.503861\n",
      "evaluation/Actions Std                  0.646939\n",
      "evaluation/Actions Max                  0.999987\n",
      "evaluation/Actions Min                 -0.999972\n",
      "time/backward_policy (s)                1.99861\n",
      "time/backward_zf1 (s)                   2.20577\n",
      "time/backward_zf2 (s)                   2.06428\n",
      "time/data sampling (s)                  0.313434\n",
      "time/data storing (s)                   0.0154291\n",
      "time/evaluation sampling (s)            1.45442\n",
      "time/exploration sampling (s)           0.211978\n",
      "time/logging (s)                        0.0123531\n",
      "time/preback_alpha (s)                  1.00462\n",
      "time/preback_policy (s)                 1.12583\n",
      "time/preback_start (s)                  0.133838\n",
      "time/preback_zf (s)                     5.27388\n",
      "time/saving (s)                         0.00551764\n",
      "time/training (s)                       2.4215\n",
      "time/epoch (s)                         18.2415\n",
      "time/total (s)                       2380.4\n",
      "Epoch                                 136\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:50:32.665640 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 137 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 148000\n",
      "trainer/ZF1 Loss                       42.1421\n",
      "trainer/ZF2 Loss                       38.1374\n",
      "trainer/ZF Expert Reward               16.1181\n",
      "trainer/ZF Policy Reward                1.66795\n",
      "trainer/ZF CHI2 Term                   74.5283\n",
      "trainer/Policy Loss                 -1443.36\n",
      "trainer/Bias Loss                     176.268\n",
      "trainer/Bias Value                     20.7837\n",
      "trainer/Policy Grad Norm              295.052\n",
      "trainer/Policy Param Norm              35.2938\n",
      "trainer/Zf1 Grad Norm                4622.3\n",
      "trainer/Zf1 Param Norm                106.783\n",
      "trainer/Zf2 Grad Norm                5300.52\n",
      "trainer/Zf2 Param Norm                104.8\n",
      "trainer/Z Expert Predictions Mean    1676.39\n",
      "trainer/Z Expert Predictions Std      155.399\n",
      "trainer/Z Expert Predictions Max     1874.89\n",
      "trainer/Z Expert Predictions Min      953.794\n",
      "trainer/Z Policy Predictions Mean    1435.59\n",
      "trainer/Z Policy Predictions Std      424.468\n",
      "trainer/Z Policy Predictions Max     1890.94\n",
      "trainer/Z Policy Predictions Min     -145.828\n",
      "trainer/Z Expert Targets Mean        1660.27\n",
      "trainer/Z Expert Targets Std          155.254\n",
      "trainer/Z Expert Targets Max         1868.69\n",
      "trainer/Z Expert Targets Min          932.769\n",
      "trainer/Z Policy Targets Mean        1433.92\n",
      "trainer/Z Policy Targets Std          417.132\n",
      "trainer/Z Policy Targets Max         1874.05\n",
      "trainer/Z Policy Targets Min         -155.339\n",
      "trainer/Log Pis Mean                   20.1399\n",
      "trainer/Log Pis Std                     4.627\n",
      "trainer/Policy mu Mean                  1.27964\n",
      "trainer/Policy mu Std                   1.88952\n",
      "trainer/Policy log std Mean            -2.16327\n",
      "trainer/Policy log std Std              1.10158\n",
      "trainer/Alpha                           0.137796\n",
      "trainer/Alpha Loss                     -0.0192752\n",
      "exploration/num steps total        143197\n",
      "exploration/num paths total           722\n",
      "evaluation/num steps total              1.01109e+06\n",
      "evaluation/num paths total           1383\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.22263\n",
      "evaluation/Rewards Std                  1.33983\n",
      "evaluation/Rewards Max                  7.2606\n",
      "evaluation/Rewards Min                  0.114129\n",
      "evaluation/Returns Mean              5222.63\n",
      "evaluation/Returns Std                 16.1837\n",
      "evaluation/Returns Max               5253.59\n",
      "evaluation/Returns Min               5196.79\n",
      "evaluation/Estimation Bias Mean      1695.83\n",
      "evaluation/Estimation Bias Std        172.152\n",
      "evaluation/EB/Q_True Mean              49.3206\n",
      "evaluation/EB/Q_True Std              152.308\n",
      "evaluation/EB/Q_Pred Mean            1745.15\n",
      "evaluation/EB/Q_Pred Std               86.6363\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5222.63\n",
      "evaluation/Actions Mean                 0.496452\n",
      "evaluation/Actions Std                  0.653339\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -0.99993\n",
      "time/backward_policy (s)                2.14887\n",
      "time/backward_zf1 (s)                   2.33124\n",
      "time/backward_zf2 (s)                   2.23412\n",
      "time/data sampling (s)                  0.317391\n",
      "time/data storing (s)                   0.0150566\n",
      "time/evaluation sampling (s)            1.42689\n",
      "time/exploration sampling (s)           0.201266\n",
      "time/logging (s)                        0.0116192\n",
      "time/preback_alpha (s)                  1.06346\n",
      "time/preback_policy (s)                 1.23195\n",
      "time/preback_start (s)                  0.133205\n",
      "time/preback_zf (s)                     5.31437\n",
      "time/saving (s)                         0.0177315\n",
      "time/training (s)                       2.36197\n",
      "time/epoch (s)                         18.8091\n",
      "time/total (s)                       2399.24\n",
      "Epoch                                 137\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:50:50.817493 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 138 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 149000\n",
      "trainer/ZF1 Loss                       46.0646\n",
      "trainer/ZF2 Loss                       47.8874\n",
      "trainer/ZF Expert Reward               22.4701\n",
      "trainer/ZF Policy Reward                2.83316\n",
      "trainer/ZF CHI2 Term                   86.3664\n",
      "trainer/Policy Loss                 -1347.63\n",
      "trainer/Bias Loss                     217.591\n",
      "trainer/Bias Value                     20.7799\n",
      "trainer/Policy Grad Norm              229.204\n",
      "trainer/Policy Param Norm              35.3493\n",
      "trainer/Zf1 Grad Norm                3054.46\n",
      "trainer/Zf1 Param Norm                107.031\n",
      "trainer/Zf2 Grad Norm                3422.39\n",
      "trainer/Zf2 Param Norm                105.04\n",
      "trainer/Z Expert Predictions Mean    1673.1\n",
      "trainer/Z Expert Predictions Std      154.351\n",
      "trainer/Z Expert Predictions Max     1894.2\n",
      "trainer/Z Expert Predictions Min      991.805\n",
      "trainer/Z Policy Predictions Mean    1337.59\n",
      "trainer/Z Policy Predictions Std      515.212\n",
      "trainer/Z Policy Predictions Max     1878.42\n",
      "trainer/Z Policy Predictions Min     -313.747\n",
      "trainer/Z Expert Targets Mean        1650.63\n",
      "trainer/Z Expert Targets Std          158.741\n",
      "trainer/Z Expert Targets Max         1873.07\n",
      "trainer/Z Expert Targets Min         1004.11\n",
      "trainer/Z Policy Targets Mean        1334.75\n",
      "trainer/Z Policy Targets Std          509.348\n",
      "trainer/Z Policy Targets Max         1867.98\n",
      "trainer/Z Policy Targets Min         -283.857\n",
      "trainer/Log Pis Mean                   19.953\n",
      "trainer/Log Pis Std                     4.96162\n",
      "trainer/Policy mu Mean                  1.29347\n",
      "trainer/Policy mu Std                   1.92732\n",
      "trainer/Policy log std Mean            -2.16125\n",
      "trainer/Policy log std Std              1.14086\n",
      "trainer/Alpha                           0.136156\n",
      "trainer/Alpha Loss                      0.00640312\n",
      "exploration/num steps total        143197\n",
      "exploration/num paths total           722\n",
      "evaluation/num steps total              1.02109e+06\n",
      "evaluation/num paths total           1393\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.0639\n",
      "evaluation/Rewards Std                  1.2626\n",
      "evaluation/Rewards Max                  7.04252\n",
      "evaluation/Rewards Min                  0.159522\n",
      "evaluation/Returns Mean              5063.9\n",
      "evaluation/Returns Std                 37.3974\n",
      "evaluation/Returns Max               5097.18\n",
      "evaluation/Returns Min               4968.7\n",
      "evaluation/Estimation Bias Mean      1683.79\n",
      "evaluation/Estimation Bias Std        180.075\n",
      "evaluation/EB/Q_True Mean              47.378\n",
      "evaluation/EB/Q_True Std              146.316\n",
      "evaluation/EB/Q_Pred Mean            1731.17\n",
      "evaluation/EB/Q_Pred Std              111.93\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5063.9\n",
      "evaluation/Actions Mean                 0.498804\n",
      "evaluation/Actions Std                  0.642826\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.95702\n",
      "time/backward_zf1 (s)                   2.184\n",
      "time/backward_zf2 (s)                   2.0439\n",
      "time/data sampling (s)                  0.293452\n",
      "time/data storing (s)                   0.0150863\n",
      "time/evaluation sampling (s)            1.45204\n",
      "time/exploration sampling (s)           0.202415\n",
      "time/logging (s)                        0.011444\n",
      "time/preback_alpha (s)                  0.999558\n",
      "time/preback_policy (s)                 1.10137\n",
      "time/preback_start (s)                  0.133431\n",
      "time/preback_zf (s)                     5.25542\n",
      "time/saving (s)                         0.00532694\n",
      "time/training (s)                       2.42752\n",
      "time/epoch (s)                         18.082\n",
      "time/total (s)                       2417.34\n",
      "Epoch                                 138\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:51:09.173058 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 139 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 150000\n",
      "trainer/ZF1 Loss                       26.2158\n",
      "trainer/ZF2 Loss                       30.8773\n",
      "trainer/ZF Expert Reward               19.9228\n",
      "trainer/ZF Policy Reward                5.24629\n",
      "trainer/ZF CHI2 Term                   62.8155\n",
      "trainer/Policy Loss                 -1405\n",
      "trainer/Bias Loss                     167.388\n",
      "trainer/Bias Value                     20.7748\n",
      "trainer/Policy Grad Norm              228.793\n",
      "trainer/Policy Param Norm              35.4009\n",
      "trainer/Zf1 Grad Norm                3349.76\n",
      "trainer/Zf1 Param Norm                107.251\n",
      "trainer/Zf2 Grad Norm                3980.02\n",
      "trainer/Zf2 Param Norm                105.254\n",
      "trainer/Z Expert Predictions Mean    1663.57\n",
      "trainer/Z Expert Predictions Std      147.369\n",
      "trainer/Z Expert Predictions Max     1895.52\n",
      "trainer/Z Expert Predictions Min     1014.21\n",
      "trainer/Z Policy Predictions Mean    1391.67\n",
      "trainer/Z Policy Predictions Std      460.865\n",
      "trainer/Z Policy Predictions Max     1895.68\n",
      "trainer/Z Policy Predictions Min      -83.0915\n",
      "trainer/Z Expert Targets Mean        1643.64\n",
      "trainer/Z Expert Targets Std          152.047\n",
      "trainer/Z Expert Targets Max         1879.2\n",
      "trainer/Z Expert Targets Min          962.03\n",
      "trainer/Z Policy Targets Mean        1386.43\n",
      "trainer/Z Policy Targets Std          457.939\n",
      "trainer/Z Policy Targets Max         1853.58\n",
      "trainer/Z Policy Targets Min         -134.456\n",
      "trainer/Log Pis Mean                   19.7903\n",
      "trainer/Log Pis Std                     4.54322\n",
      "trainer/Policy mu Mean                  1.27987\n",
      "trainer/Policy mu Std                   1.91037\n",
      "trainer/Policy log std Mean            -2.13443\n",
      "trainer/Policy log std Std              1.13747\n",
      "trainer/Alpha                           0.135017\n",
      "trainer/Alpha Loss                      0.0283169\n",
      "exploration/num steps total        144197\n",
      "exploration/num paths total           723\n",
      "evaluation/num steps total              1.03109e+06\n",
      "evaluation/num paths total           1403\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14676\n",
      "evaluation/Rewards Std                  1.3337\n",
      "evaluation/Rewards Max                  8.50375\n",
      "evaluation/Rewards Min                  0.124593\n",
      "evaluation/Returns Mean              5146.76\n",
      "evaluation/Returns Std                 47.1571\n",
      "evaluation/Returns Max               5191.52\n",
      "evaluation/Returns Min               5035.68\n",
      "evaluation/Estimation Bias Mean      1645.19\n",
      "evaluation/Estimation Bias Std        259.32\n",
      "evaluation/EB/Q_True Mean              48.9233\n",
      "evaluation/EB/Q_True Std              151.23\n",
      "evaluation/EB/Q_Pred Mean            1694.11\n",
      "evaluation/EB/Q_Pred Std              213.465\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5146.76\n",
      "evaluation/Actions Mean                 0.496442\n",
      "evaluation/Actions Std                  0.649851\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999991\n",
      "time/backward_policy (s)                1.98915\n",
      "time/backward_zf1 (s)                   2.252\n",
      "time/backward_zf2 (s)                   2.11\n",
      "time/data sampling (s)                  0.29141\n",
      "time/data storing (s)                   0.0164674\n",
      "time/evaluation sampling (s)            1.43763\n",
      "time/exploration sampling (s)           0.216127\n",
      "time/logging (s)                        0.0147092\n",
      "time/preback_alpha (s)                  0.994466\n",
      "time/preback_policy (s)                 1.11431\n",
      "time/preback_start (s)                  0.133626\n",
      "time/preback_zf (s)                     5.26554\n",
      "time/saving (s)                         0.00539225\n",
      "time/training (s)                       2.44691\n",
      "time/epoch (s)                         18.2877\n",
      "time/total (s)                       2435.64\n",
      "Epoch                                 139\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:51:28.650372 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 140 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 151000\n",
      "trainer/ZF1 Loss                       44.404\n",
      "trainer/ZF2 Loss                       46.5351\n",
      "trainer/ZF Expert Reward               18.9351\n",
      "trainer/ZF Policy Reward                1.13948\n",
      "trainer/ZF CHI2 Term                   82.7754\n",
      "trainer/Policy Loss                 -1397.61\n",
      "trainer/Bias Loss                     257.584\n",
      "trainer/Bias Value                     20.7706\n",
      "trainer/Policy Grad Norm              241.139\n",
      "trainer/Policy Param Norm              35.4496\n",
      "trainer/Zf1 Grad Norm                6894.58\n",
      "trainer/Zf1 Param Norm                107.488\n",
      "trainer/Zf2 Grad Norm                6677.74\n",
      "trainer/Zf2 Param Norm                105.48\n",
      "trainer/Z Expert Predictions Mean    1665.55\n",
      "trainer/Z Expert Predictions Std      159.703\n",
      "trainer/Z Expert Predictions Max     1893.86\n",
      "trainer/Z Expert Predictions Min      806.703\n",
      "trainer/Z Policy Predictions Mean    1383.32\n",
      "trainer/Z Policy Predictions Std      478.167\n",
      "trainer/Z Policy Predictions Max     1870.13\n",
      "trainer/Z Policy Predictions Min     -191.471\n",
      "trainer/Z Expert Targets Mean        1646.62\n",
      "trainer/Z Expert Targets Std          160.889\n",
      "trainer/Z Expert Targets Max         1857.46\n",
      "trainer/Z Expert Targets Min          797.519\n",
      "trainer/Z Policy Targets Mean        1382.18\n",
      "trainer/Z Policy Targets Std          472.635\n",
      "trainer/Z Policy Targets Max         1845.14\n",
      "trainer/Z Policy Targets Min         -206.872\n",
      "trainer/Log Pis Mean                   19.7072\n",
      "trainer/Log Pis Std                     4.80696\n",
      "trainer/Policy mu Mean                  1.19735\n",
      "trainer/Policy mu Std                   1.90259\n",
      "trainer/Policy log std Mean            -2.19396\n",
      "trainer/Policy log std Std              1.1261\n",
      "trainer/Alpha                           0.136924\n",
      "trainer/Alpha Loss                      0.0400881\n",
      "exploration/num steps total        146197\n",
      "exploration/num paths total           725\n",
      "evaluation/num steps total              1.04109e+06\n",
      "evaluation/num paths total           1413\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15716\n",
      "evaluation/Rewards Std                  1.311\n",
      "evaluation/Rewards Max                  7.05817\n",
      "evaluation/Rewards Min                  0.118565\n",
      "evaluation/Returns Mean              5157.16\n",
      "evaluation/Returns Std                 10.998\n",
      "evaluation/Returns Max               5176.92\n",
      "evaluation/Returns Min               5140.93\n",
      "evaluation/Estimation Bias Mean      1700.44\n",
      "evaluation/Estimation Bias Std        169.536\n",
      "evaluation/EB/Q_True Mean              48.8372\n",
      "evaluation/EB/Q_True Std              150.749\n",
      "evaluation/EB/Q_Pred Mean            1749.28\n",
      "evaluation/EB/Q_Pred Std               82.963\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5157.16\n",
      "evaluation/Actions Mean                 0.501646\n",
      "evaluation/Actions Std                  0.645423\n",
      "evaluation/Actions Max                  0.999959\n",
      "evaluation/Actions Min                 -0.999865\n",
      "time/backward_policy (s)                2.23972\n",
      "time/backward_zf1 (s)                   2.41912\n",
      "time/backward_zf2 (s)                   2.28287\n",
      "time/data sampling (s)                  0.320138\n",
      "time/data storing (s)                   0.0163293\n",
      "time/evaluation sampling (s)            1.46339\n",
      "time/exploration sampling (s)           0.222398\n",
      "time/logging (s)                        0.0118412\n",
      "time/preback_alpha (s)                  1.10823\n",
      "time/preback_policy (s)                 1.28935\n",
      "time/preback_start (s)                  0.141354\n",
      "time/preback_zf (s)                     5.38999\n",
      "time/saving (s)                         0.00531519\n",
      "time/training (s)                       2.47181\n",
      "time/epoch (s)                         19.3819\n",
      "time/total (s)                       2455.06\n",
      "Epoch                                 140\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:51:47.008425 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 141 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 152000\n",
      "trainer/ZF1 Loss                       38.1151\n",
      "trainer/ZF2 Loss                       53.2245\n",
      "trainer/ZF Expert Reward               19.561\n",
      "trainer/ZF Policy Reward                5.07292\n",
      "trainer/ZF CHI2 Term                   80.1724\n",
      "trainer/Policy Loss                 -1412.55\n",
      "trainer/Bias Loss                     143.301\n",
      "trainer/Bias Value                     20.7658\n",
      "trainer/Policy Grad Norm              264.084\n",
      "trainer/Policy Param Norm              35.5022\n",
      "trainer/Zf1 Grad Norm                3728.28\n",
      "trainer/Zf1 Param Norm                107.729\n",
      "trainer/Zf2 Grad Norm                5346.64\n",
      "trainer/Zf2 Param Norm                105.684\n",
      "trainer/Z Expert Predictions Mean    1679.22\n",
      "trainer/Z Expert Predictions Std      128.984\n",
      "trainer/Z Expert Predictions Max     1880.67\n",
      "trainer/Z Expert Predictions Min      596.058\n",
      "trainer/Z Policy Predictions Mean    1404.48\n",
      "trainer/Z Policy Predictions Std      451.811\n",
      "trainer/Z Policy Predictions Max     1881.37\n",
      "trainer/Z Policy Predictions Min     -235.593\n",
      "trainer/Z Expert Targets Mean        1659.66\n",
      "trainer/Z Expert Targets Std          132.402\n",
      "trainer/Z Expert Targets Max         1860.02\n",
      "trainer/Z Expert Targets Min          543.299\n",
      "trainer/Z Policy Targets Mean        1399.4\n",
      "trainer/Z Policy Targets Std          452.038\n",
      "trainer/Z Policy Targets Max         1870.41\n",
      "trainer/Z Policy Targets Min         -200.533\n",
      "trainer/Log Pis Mean                   20.2167\n",
      "trainer/Log Pis Std                     4.59305\n",
      "trainer/Policy mu Mean                  1.30303\n",
      "trainer/Policy mu Std                   1.88336\n",
      "trainer/Policy log std Mean            -2.18808\n",
      "trainer/Policy log std Std              1.13314\n",
      "trainer/Alpha                           0.1363\n",
      "trainer/Alpha Loss                     -0.0295323\n",
      "exploration/num steps total        147197\n",
      "exploration/num paths total           726\n",
      "evaluation/num steps total              1.05109e+06\n",
      "evaluation/num paths total           1423\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17585\n",
      "evaluation/Rewards Std                  1.31505\n",
      "evaluation/Rewards Max                  7.23507\n",
      "evaluation/Rewards Min                  0.129537\n",
      "evaluation/Returns Mean              5175.85\n",
      "evaluation/Returns Std                 15.8649\n",
      "evaluation/Returns Max               5201.66\n",
      "evaluation/Returns Min               5149.17\n",
      "evaluation/Estimation Bias Mean      1636.87\n",
      "evaluation/Estimation Bias Std        178.04\n",
      "evaluation/EB/Q_True Mean              49.1625\n",
      "evaluation/EB/Q_True Std              151.736\n",
      "evaluation/EB/Q_Pred Mean            1686.03\n",
      "evaluation/EB/Q_Pred Std               87.7866\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5175.85\n",
      "evaluation/Actions Mean                 0.516393\n",
      "evaluation/Actions Std                  0.634052\n",
      "evaluation/Actions Max                  0.999993\n",
      "evaluation/Actions Min                 -0.999709\n",
      "time/backward_policy (s)                1.98305\n",
      "time/backward_zf1 (s)                   2.17622\n",
      "time/backward_zf2 (s)                   2.06246\n",
      "time/data sampling (s)                  0.300265\n",
      "time/data storing (s)                   0.0167617\n",
      "time/evaluation sampling (s)            1.47436\n",
      "time/exploration sampling (s)           0.216904\n",
      "time/logging (s)                        0.0120723\n",
      "time/preback_alpha (s)                  0.9914\n",
      "time/preback_policy (s)                 1.10942\n",
      "time/preback_start (s)                  0.133001\n",
      "time/preback_zf (s)                     5.27876\n",
      "time/saving (s)                         0.00538168\n",
      "time/training (s)                       2.5269\n",
      "time/epoch (s)                         18.2869\n",
      "time/total (s)                       2473.37\n",
      "Epoch                                 141\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:52:05.736241 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 142 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 153000\n",
      "trainer/ZF1 Loss                       51.2911\n",
      "trainer/ZF2 Loss                       56.4002\n",
      "trainer/ZF Expert Reward               16.9909\n",
      "trainer/ZF Policy Reward                2.83307\n",
      "trainer/ZF CHI2 Term                   88.2003\n",
      "trainer/Policy Loss                 -1423.35\n",
      "trainer/Bias Loss                     205.18\n",
      "trainer/Bias Value                     20.7592\n",
      "trainer/Policy Grad Norm              324.29\n",
      "trainer/Policy Param Norm              35.5504\n",
      "trainer/Zf1 Grad Norm                4337.83\n",
      "trainer/Zf1 Param Norm                107.954\n",
      "trainer/Zf2 Grad Norm                4455.52\n",
      "trainer/Zf2 Param Norm                105.903\n",
      "trainer/Z Expert Predictions Mean    1675.33\n",
      "trainer/Z Expert Predictions Std      133.441\n",
      "trainer/Z Expert Predictions Max     1852.97\n",
      "trainer/Z Expert Predictions Min     1009.3\n",
      "trainer/Z Policy Predictions Mean    1416\n",
      "trainer/Z Policy Predictions Std      435.086\n",
      "trainer/Z Policy Predictions Max     1879.1\n",
      "trainer/Z Policy Predictions Min     -276.646\n",
      "trainer/Z Expert Targets Mean        1658.34\n",
      "trainer/Z Expert Targets Std          137.346\n",
      "trainer/Z Expert Targets Max         1837.44\n",
      "trainer/Z Expert Targets Min          986.549\n",
      "trainer/Z Policy Targets Mean        1413.16\n",
      "trainer/Z Policy Targets Std          429.728\n",
      "trainer/Z Policy Targets Max         1876.7\n",
      "trainer/Z Policy Targets Min         -237.828\n",
      "trainer/Log Pis Mean                   20.4008\n",
      "trainer/Log Pis Std                     4.80137\n",
      "trainer/Policy mu Mean                  1.21722\n",
      "trainer/Policy mu Std                   1.92787\n",
      "trainer/Policy log std Mean            -2.2459\n",
      "trainer/Policy log std Std              1.14401\n",
      "trainer/Alpha                           0.137188\n",
      "trainer/Alpha Loss                     -0.0549809\n",
      "exploration/num steps total        147197\n",
      "exploration/num paths total           726\n",
      "evaluation/num steps total              1.06105e+06\n",
      "evaluation/num paths total           1433\n",
      "evaluation/path length Mean           996.5\n",
      "evaluation/path length Std             10.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            965\n",
      "evaluation/Rewards Mean                 5.00224\n",
      "evaluation/Rewards Std                  1.30389\n",
      "evaluation/Rewards Max                  8.71661\n",
      "evaluation/Rewards Min                  0.120869\n",
      "evaluation/Returns Mean              4984.74\n",
      "evaluation/Returns Std                206.076\n",
      "evaluation/Returns Max               5152.88\n",
      "evaluation/Returns Min               4474.02\n",
      "evaluation/Estimation Bias Mean      1556.97\n",
      "evaluation/Estimation Bias Std        273.052\n",
      "evaluation/EB/Q_True Mean              42.1305\n",
      "evaluation/EB/Q_True Std              129.695\n",
      "evaluation/EB/Q_Pred Mean            1599.1\n",
      "evaluation/EB/Q_Pred Std              244.396\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4984.74\n",
      "evaluation/Actions Mean                 0.49696\n",
      "evaluation/Actions Std                  0.653547\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.07733\n",
      "time/backward_zf1 (s)                   2.29688\n",
      "time/backward_zf2 (s)                   2.18528\n",
      "time/data sampling (s)                  0.308054\n",
      "time/data storing (s)                   0.014609\n",
      "time/evaluation sampling (s)            1.41614\n",
      "time/exploration sampling (s)           0.198572\n",
      "time/logging (s)                        0.0115737\n",
      "time/preback_alpha (s)                  1.0381\n",
      "time/preback_policy (s)                 1.19328\n",
      "time/preback_start (s)                  0.130307\n",
      "time/preback_zf (s)                     5.35941\n",
      "time/saving (s)                         0.00512251\n",
      "time/training (s)                       2.40539\n",
      "time/epoch (s)                         18.64\n",
      "time/total (s)                       2492.04\n",
      "Epoch                                 142\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:52:24.060399 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 143 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 154000\n",
      "trainer/ZF1 Loss                       52.5588\n",
      "trainer/ZF2 Loss                       58.7172\n",
      "trainer/ZF Expert Reward               25.8522\n",
      "trainer/ZF Policy Reward                0.216962\n",
      "trainer/ZF CHI2 Term                  101.488\n",
      "trainer/Policy Loss                 -1341.77\n",
      "trainer/Bias Loss                     239.803\n",
      "trainer/Bias Value                     20.7534\n",
      "trainer/Policy Grad Norm              344.733\n",
      "trainer/Policy Param Norm              35.5993\n",
      "trainer/Zf1 Grad Norm                4884.86\n",
      "trainer/Zf1 Param Norm                108.207\n",
      "trainer/Zf2 Grad Norm                8140.69\n",
      "trainer/Zf2 Param Norm                106.174\n",
      "trainer/Z Expert Predictions Mean    1664.28\n",
      "trainer/Z Expert Predictions Std      164.927\n",
      "trainer/Z Expert Predictions Max     1881.74\n",
      "trainer/Z Expert Predictions Min       99.2557\n",
      "trainer/Z Policy Predictions Mean    1333.45\n",
      "trainer/Z Policy Predictions Std      507.453\n",
      "trainer/Z Policy Predictions Max     1862.56\n",
      "trainer/Z Policy Predictions Min     -223.154\n",
      "trainer/Z Expert Targets Mean        1638.43\n",
      "trainer/Z Expert Targets Std          172.378\n",
      "trainer/Z Expert Targets Max         1861.26\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1333.24\n",
      "trainer/Z Policy Targets Std          495.805\n",
      "trainer/Z Policy Targets Max         1828.96\n",
      "trainer/Z Policy Targets Min         -212.81\n",
      "trainer/Log Pis Mean                   20.4187\n",
      "trainer/Log Pis Std                     4.59077\n",
      "trainer/Policy mu Mean                  1.26399\n",
      "trainer/Policy mu Std                   1.98265\n",
      "trainer/Policy log std Mean            -2.12712\n",
      "trainer/Policy log std Std              1.13898\n",
      "trainer/Alpha                           0.14107\n",
      "trainer/Alpha Loss                     -0.0590645\n",
      "exploration/num steps total        149197\n",
      "exploration/num paths total           728\n",
      "evaluation/num steps total              1.0709e+06\n",
      "evaluation/num paths total           1443\n",
      "evaluation/path length Mean           984.4\n",
      "evaluation/path length Std             46.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            844\n",
      "evaluation/Rewards Mean                 5.03834\n",
      "evaluation/Rewards Std                  1.32115\n",
      "evaluation/Rewards Max                  7.00233\n",
      "evaluation/Rewards Min                  0.0922025\n",
      "evaluation/Returns Mean              4959.74\n",
      "evaluation/Returns Std                408.148\n",
      "evaluation/Returns Max               5137.66\n",
      "evaluation/Returns Min               3737.67\n",
      "evaluation/Estimation Bias Mean      1628.14\n",
      "evaluation/Estimation Bias Std        276.928\n",
      "evaluation/EB/Q_True Mean              48.6994\n",
      "evaluation/EB/Q_True Std              149.043\n",
      "evaluation/EB/Q_Pred Mean            1676.84\n",
      "evaluation/EB/Q_Pred Std              174.614\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4959.74\n",
      "evaluation/Actions Mean                 0.506496\n",
      "evaluation/Actions Std                  0.640712\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                2.01461\n",
      "time/backward_zf1 (s)                   2.17344\n",
      "time/backward_zf2 (s)                   2.12085\n",
      "time/data sampling (s)                  0.295955\n",
      "time/data storing (s)                   0.0138935\n",
      "time/evaluation sampling (s)            1.47801\n",
      "time/exploration sampling (s)           0.195737\n",
      "time/logging (s)                        0.0150046\n",
      "time/preback_alpha (s)                  1.03434\n",
      "time/preback_policy (s)                 1.16763\n",
      "time/preback_start (s)                  0.127817\n",
      "time/preback_zf (s)                     5.27275\n",
      "time/saving (s)                         0.00615113\n",
      "time/training (s)                       2.33847\n",
      "time/epoch (s)                         18.2547\n",
      "time/total (s)                       2510.32\n",
      "Epoch                                 143\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:52:42.546514 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 144 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 155000\n",
      "trainer/ZF1 Loss                      226.874\n",
      "trainer/ZF2 Loss                      151.608\n",
      "trainer/ZF Expert Reward               20.4147\n",
      "trainer/ZF Policy Reward                2.11452\n",
      "trainer/ZF CHI2 Term                  227.744\n",
      "trainer/Policy Loss                 -1433.75\n",
      "trainer/Bias Loss                    1590.56\n",
      "trainer/Bias Value                     20.7476\n",
      "trainer/Policy Grad Norm              442.992\n",
      "trainer/Policy Param Norm              35.6489\n",
      "trainer/Zf1 Grad Norm               10695.6\n",
      "trainer/Zf1 Param Norm                108.429\n",
      "trainer/Zf2 Grad Norm               13021\n",
      "trainer/Zf2 Param Norm                106.385\n",
      "trainer/Z Expert Predictions Mean    1652.56\n",
      "trainer/Z Expert Predictions Std      152.979\n",
      "trainer/Z Expert Predictions Max     1880.35\n",
      "trainer/Z Expert Predictions Min      660.224\n",
      "trainer/Z Policy Predictions Mean    1422.61\n",
      "trainer/Z Policy Predictions Std      411.518\n",
      "trainer/Z Policy Predictions Max     1870.86\n",
      "trainer/Z Policy Predictions Min      -57.7817\n",
      "trainer/Z Expert Targets Mean        1632.15\n",
      "trainer/Z Expert Targets Std          179.521\n",
      "trainer/Z Expert Targets Max         1847.42\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1420.5\n",
      "trainer/Z Policy Targets Std          402.976\n",
      "trainer/Z Policy Targets Max         1865.92\n",
      "trainer/Z Policy Targets Min         -123.418\n",
      "trainer/Log Pis Mean                   20.4065\n",
      "trainer/Log Pis Std                     4.96081\n",
      "trainer/Policy mu Mean                  1.2596\n",
      "trainer/Policy mu Std                   1.89922\n",
      "trainer/Policy log std Mean            -2.24339\n",
      "trainer/Policy log std Std              1.12611\n",
      "trainer/Alpha                           0.139352\n",
      "trainer/Alpha Loss                     -0.0566478\n",
      "exploration/num steps total        151197\n",
      "exploration/num paths total           730\n",
      "evaluation/num steps total              1.0809e+06\n",
      "evaluation/num paths total           1453\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.11924\n",
      "evaluation/Rewards Std                  1.29567\n",
      "evaluation/Rewards Max                  7.12079\n",
      "evaluation/Rewards Min                  0.143923\n",
      "evaluation/Returns Mean              5119.24\n",
      "evaluation/Returns Std                 16.3756\n",
      "evaluation/Returns Max               5143.71\n",
      "evaluation/Returns Min               5093.22\n",
      "evaluation/Estimation Bias Mean      1648.54\n",
      "evaluation/Estimation Bias Std        167.386\n",
      "evaluation/EB/Q_True Mean              48.5412\n",
      "evaluation/EB/Q_True Std              149.824\n",
      "evaluation/EB/Q_Pred Mean            1697.08\n",
      "evaluation/EB/Q_Pred Std               73.6788\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5119.24\n",
      "evaluation/Actions Mean                 0.51053\n",
      "evaluation/Actions Std                  0.640682\n",
      "evaluation/Actions Max                  0.999957\n",
      "evaluation/Actions Min                 -0.999863\n",
      "time/backward_policy (s)                2.00477\n",
      "time/backward_zf1 (s)                   2.18932\n",
      "time/backward_zf2 (s)                   2.09161\n",
      "time/data sampling (s)                  0.30325\n",
      "time/data storing (s)                   0.0165263\n",
      "time/evaluation sampling (s)            1.4707\n",
      "time/exploration sampling (s)           0.21418\n",
      "time/logging (s)                        0.0115694\n",
      "time/preback_alpha (s)                  1.0116\n",
      "time/preback_policy (s)                 1.13323\n",
      "time/preback_start (s)                  0.132989\n",
      "time/preback_zf (s)                     5.34958\n",
      "time/saving (s)                         0.00543978\n",
      "time/training (s)                       2.47728\n",
      "time/epoch (s)                         18.4121\n",
      "time/total (s)                       2528.75\n",
      "Epoch                                 144\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:52:59.952400 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 145 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 156000\n",
      "trainer/ZF1 Loss                       69.4945\n",
      "trainer/ZF2 Loss                       99.5048\n",
      "trainer/ZF Expert Reward               25.7111\n",
      "trainer/ZF Policy Reward                4.30781\n",
      "trainer/ZF CHI2 Term                  125.699\n",
      "trainer/Policy Loss                 -1433.05\n",
      "trainer/Bias Loss                     745.972\n",
      "trainer/Bias Value                     20.7403\n",
      "trainer/Policy Grad Norm              295.49\n",
      "trainer/Policy Param Norm              35.6949\n",
      "trainer/Zf1 Grad Norm               10697.2\n",
      "trainer/Zf1 Param Norm                108.638\n",
      "trainer/Zf2 Grad Norm               15574.6\n",
      "trainer/Zf2 Param Norm                106.577\n",
      "trainer/Z Expert Predictions Mean    1627.26\n",
      "trainer/Z Expert Predictions Std      193.02\n",
      "trainer/Z Expert Predictions Max     1844.47\n",
      "trainer/Z Expert Predictions Min      470.408\n",
      "trainer/Z Policy Predictions Mean    1426.3\n",
      "trainer/Z Policy Predictions Std      429.675\n",
      "trainer/Z Policy Predictions Max     1837.43\n",
      "trainer/Z Policy Predictions Min     -174.835\n",
      "trainer/Z Expert Targets Mean        1601.55\n",
      "trainer/Z Expert Targets Std          209.676\n",
      "trainer/Z Expert Targets Max         1842.25\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1422\n",
      "trainer/Z Policy Targets Std          424.778\n",
      "trainer/Z Policy Targets Max         1818.18\n",
      "trainer/Z Policy Targets Min         -190.012\n",
      "trainer/Log Pis Mean                   19.9959\n",
      "trainer/Log Pis Std                     4.53089\n",
      "trainer/Policy mu Mean                  1.25328\n",
      "trainer/Policy mu Std                   1.86978\n",
      "trainer/Policy log std Mean            -2.25316\n",
      "trainer/Policy log std Std              1.12425\n",
      "trainer/Alpha                           0.137109\n",
      "trainer/Alpha Loss                      0.000563439\n",
      "exploration/num steps total        151197\n",
      "exploration/num paths total           730\n",
      "evaluation/num steps total              1.0909e+06\n",
      "evaluation/num paths total           1463\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.97577\n",
      "evaluation/Rewards Std                  1.25184\n",
      "evaluation/Rewards Max                  6.98872\n",
      "evaluation/Rewards Min                  0.166366\n",
      "evaluation/Returns Mean              4975.77\n",
      "evaluation/Returns Std                104.072\n",
      "evaluation/Returns Max               5106.68\n",
      "evaluation/Returns Min               4703.78\n",
      "evaluation/Estimation Bias Mean      1612.41\n",
      "evaluation/Estimation Bias Std        201.012\n",
      "evaluation/EB/Q_True Mean              46.8047\n",
      "evaluation/EB/Q_True Std              144.787\n",
      "evaluation/EB/Q_Pred Mean            1659.21\n",
      "evaluation/EB/Q_Pred Std              147.284\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4975.77\n",
      "evaluation/Actions Mean                 0.503035\n",
      "evaluation/Actions Std                  0.641531\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999991\n",
      "time/backward_policy (s)                1.83139\n",
      "time/backward_zf1 (s)                   2.03543\n",
      "time/backward_zf2 (s)                   1.91239\n",
      "time/data sampling (s)                  0.298248\n",
      "time/data storing (s)                   0.0152051\n",
      "time/evaluation sampling (s)            1.4308\n",
      "time/exploration sampling (s)           0.201845\n",
      "time/logging (s)                        0.0120309\n",
      "time/preback_alpha (s)                  0.951016\n",
      "time/preback_policy (s)                 1.04437\n",
      "time/preback_start (s)                  0.12773\n",
      "time/preback_zf (s)                     5.12111\n",
      "time/saving (s)                         0.00530499\n",
      "time/training (s)                       2.35162\n",
      "time/epoch (s)                         17.3385\n",
      "time/total (s)                       2546.11\n",
      "Epoch                                 145\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:53:17.877486 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 146 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 157000\n",
      "trainer/ZF1 Loss                       41.0975\n",
      "trainer/ZF2 Loss                       44.7101\n",
      "trainer/ZF Expert Reward               26.7848\n",
      "trainer/ZF Policy Reward                7.66757\n",
      "trainer/ZF CHI2 Term                   81.6123\n",
      "trainer/Policy Loss                 -1419.97\n",
      "trainer/Bias Loss                     234.227\n",
      "trainer/Bias Value                     20.7299\n",
      "trainer/Policy Grad Norm              267.211\n",
      "trainer/Policy Param Norm              35.7417\n",
      "trainer/Zf1 Grad Norm                3515.41\n",
      "trainer/Zf1 Param Norm                108.861\n",
      "trainer/Zf2 Grad Norm                4497.77\n",
      "trainer/Zf2 Param Norm                106.79\n",
      "trainer/Z Expert Predictions Mean    1666.2\n",
      "trainer/Z Expert Predictions Std      140.107\n",
      "trainer/Z Expert Predictions Max     1866.65\n",
      "trainer/Z Expert Predictions Min      965.822\n",
      "trainer/Z Policy Predictions Mean    1411.05\n",
      "trainer/Z Policy Predictions Std      434.637\n",
      "trainer/Z Policy Predictions Max     1870.72\n",
      "trainer/Z Policy Predictions Min     -155.134\n",
      "trainer/Z Expert Targets Mean        1639.42\n",
      "trainer/Z Expert Targets Std          144.931\n",
      "trainer/Z Expert Targets Max         1841.38\n",
      "trainer/Z Expert Targets Min          931.034\n",
      "trainer/Z Policy Targets Mean        1403.38\n",
      "trainer/Z Policy Targets Std          429.424\n",
      "trainer/Z Policy Targets Max         1829.28\n",
      "trainer/Z Policy Targets Min         -154.12\n",
      "trainer/Log Pis Mean                   19.7891\n",
      "trainer/Log Pis Std                     4.40502\n",
      "trainer/Policy mu Mean                  1.20966\n",
      "trainer/Policy mu Std                   1.83346\n",
      "trainer/Policy log std Mean            -2.27384\n",
      "trainer/Policy log std Std              1.13235\n",
      "trainer/Alpha                           0.136514\n",
      "trainer/Alpha Loss                      0.0287912\n",
      "exploration/num steps total        153197\n",
      "exploration/num paths total           732\n",
      "evaluation/num steps total              1.1009e+06\n",
      "evaluation/num paths total           1473\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08106\n",
      "evaluation/Rewards Std                  1.28752\n",
      "evaluation/Rewards Max                  7.10613\n",
      "evaluation/Rewards Min                  0.113117\n",
      "evaluation/Returns Mean              5081.06\n",
      "evaluation/Returns Std                 38.2678\n",
      "evaluation/Returns Max               5122.24\n",
      "evaluation/Returns Min               5009.07\n",
      "evaluation/Estimation Bias Mean      1645.54\n",
      "evaluation/Estimation Bias Std        165.045\n",
      "evaluation/EB/Q_True Mean              47.8461\n",
      "evaluation/EB/Q_True Std              147.584\n",
      "evaluation/EB/Q_Pred Mean            1693.39\n",
      "evaluation/EB/Q_Pred Std               80.4274\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5081.06\n",
      "evaluation/Actions Mean                 0.510477\n",
      "evaluation/Actions Std                  0.639462\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.93156\n",
      "time/backward_zf1 (s)                   2.14277\n",
      "time/backward_zf2 (s)                   2.03822\n",
      "time/data sampling (s)                  0.29798\n",
      "time/data storing (s)                   0.0149696\n",
      "time/evaluation sampling (s)            1.48874\n",
      "time/exploration sampling (s)           0.208633\n",
      "time/logging (s)                        0.0125115\n",
      "time/preback_alpha (s)                  1.00081\n",
      "time/preback_policy (s)                 1.12237\n",
      "time/preback_start (s)                  0.128047\n",
      "time/preback_zf (s)                     5.18268\n",
      "time/saving (s)                         0.00554548\n",
      "time/training (s)                       2.28237\n",
      "time/epoch (s)                         17.8572\n",
      "time/total (s)                       2563.98\n",
      "Epoch                                 146\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:53:35.881200 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 147 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 158000\n",
      "trainer/ZF1 Loss                       27.5986\n",
      "trainer/ZF2 Loss                       34.4591\n",
      "trainer/ZF Expert Reward               23.576\n",
      "trainer/ZF Policy Reward                5.27661\n",
      "trainer/ZF CHI2 Term                   69.5679\n",
      "trainer/Policy Loss                 -1409.96\n",
      "trainer/Bias Loss                     126.617\n",
      "trainer/Bias Value                     20.7209\n",
      "trainer/Policy Grad Norm              232.879\n",
      "trainer/Policy Param Norm              35.7899\n",
      "trainer/Zf1 Grad Norm                3063.92\n",
      "trainer/Zf1 Param Norm                109.082\n",
      "trainer/Zf2 Grad Norm                4112.96\n",
      "trainer/Zf2 Param Norm                106.987\n",
      "trainer/Z Expert Predictions Mean    1661.04\n",
      "trainer/Z Expert Predictions Std      130.673\n",
      "trainer/Z Expert Predictions Max     1866.04\n",
      "trainer/Z Expert Predictions Min      762.326\n",
      "trainer/Z Policy Predictions Mean    1405.05\n",
      "trainer/Z Policy Predictions Std      460.507\n",
      "trainer/Z Policy Predictions Max     1868.8\n",
      "trainer/Z Policy Predictions Min     -219.753\n",
      "trainer/Z Expert Targets Mean        1637.46\n",
      "trainer/Z Expert Targets Std          133.313\n",
      "trainer/Z Expert Targets Max         1852.87\n",
      "trainer/Z Expert Targets Min          711.866\n",
      "trainer/Z Policy Targets Mean        1399.78\n",
      "trainer/Z Policy Targets Std          454.083\n",
      "trainer/Z Policy Targets Max         1838.47\n",
      "trainer/Z Policy Targets Min         -249.259\n",
      "trainer/Log Pis Mean                   20.4441\n",
      "trainer/Log Pis Std                     5.20296\n",
      "trainer/Policy mu Mean                  1.27818\n",
      "trainer/Policy mu Std                   2.00234\n",
      "trainer/Policy log std Mean            -2.13198\n",
      "trainer/Policy log std Std              1.13747\n",
      "trainer/Alpha                           0.139084\n",
      "trainer/Alpha Loss                     -0.0617648\n",
      "exploration/num steps total        153197\n",
      "exploration/num paths total           732\n",
      "evaluation/num steps total              1.1109e+06\n",
      "evaluation/num paths total           1483\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10872\n",
      "evaluation/Rewards Std                  1.2886\n",
      "evaluation/Rewards Max                  7.05351\n",
      "evaluation/Rewards Min                  0.132457\n",
      "evaluation/Returns Mean              5108.72\n",
      "evaluation/Returns Std                 33.0302\n",
      "evaluation/Returns Max               5144.03\n",
      "evaluation/Returns Min               5020.12\n",
      "evaluation/Estimation Bias Mean      1646.93\n",
      "evaluation/Estimation Bias Std        182.169\n",
      "evaluation/EB/Q_True Mean              48.1585\n",
      "evaluation/EB/Q_True Std              148.744\n",
      "evaluation/EB/Q_Pred Mean            1695.09\n",
      "evaluation/EB/Q_Pred Std              113.118\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5108.72\n",
      "evaluation/Actions Mean                 0.500159\n",
      "evaluation/Actions Std                  0.64162\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.00752\n",
      "time/backward_zf1 (s)                   2.1834\n",
      "time/backward_zf2 (s)                   2.09433\n",
      "time/data sampling (s)                  0.28098\n",
      "time/data storing (s)                   0.0143769\n",
      "time/evaluation sampling (s)            1.42962\n",
      "time/exploration sampling (s)           0.197658\n",
      "time/logging (s)                        0.0114213\n",
      "time/preback_alpha (s)                  1.00463\n",
      "time/preback_policy (s)                 1.12466\n",
      "time/preback_start (s)                  0.126484\n",
      "time/preback_zf (s)                     5.16117\n",
      "time/saving (s)                         0.00609433\n",
      "time/training (s)                       2.29278\n",
      "time/epoch (s)                         17.9351\n",
      "time/total (s)                       2581.94\n",
      "Epoch                                 147\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:53:53.420023 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 148 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 159000\n",
      "trainer/ZF1 Loss                      601.374\n",
      "trainer/ZF2 Loss                      593.558\n",
      "trainer/ZF Expert Reward               16.2127\n",
      "trainer/ZF Policy Reward               10.3014\n",
      "trainer/ZF CHI2 Term                  623.355\n",
      "trainer/Policy Loss                 -1422.39\n",
      "trainer/Bias Loss                     170.811\n",
      "trainer/Bias Value                     20.7124\n",
      "trainer/Policy Grad Norm              274.134\n",
      "trainer/Policy Param Norm              35.8348\n",
      "trainer/Zf1 Grad Norm                5032.54\n",
      "trainer/Zf1 Param Norm                109.289\n",
      "trainer/Zf2 Grad Norm                4074.35\n",
      "trainer/Zf2 Param Norm                107.191\n",
      "trainer/Z Expert Predictions Mean    1648.36\n",
      "trainer/Z Expert Predictions Std      141.415\n",
      "trainer/Z Expert Predictions Max     1833.1\n",
      "trainer/Z Expert Predictions Min      633.304\n",
      "trainer/Z Policy Predictions Mean    1418.74\n",
      "trainer/Z Policy Predictions Std      414.134\n",
      "trainer/Z Policy Predictions Max     1832.32\n",
      "trainer/Z Policy Predictions Min      -51.9032\n",
      "trainer/Z Expert Targets Mean        1632.15\n",
      "trainer/Z Expert Targets Std          145.547\n",
      "trainer/Z Expert Targets Max         1847.27\n",
      "trainer/Z Expert Targets Min          633.197\n",
      "trainer/Z Policy Targets Mean        1408.44\n",
      "trainer/Z Policy Targets Std          417.24\n",
      "trainer/Z Policy Targets Max         1829.62\n",
      "trainer/Z Policy Targets Min          -60.9582\n",
      "trainer/Log Pis Mean                   20.1793\n",
      "trainer/Log Pis Std                     4.05017\n",
      "trainer/Policy mu Mean                  1.23552\n",
      "trainer/Policy mu Std                   1.89629\n",
      "trainer/Policy log std Mean            -2.26186\n",
      "trainer/Policy log std Std              1.16516\n",
      "trainer/Alpha                           0.13788\n",
      "trainer/Alpha Loss                     -0.024725\n",
      "exploration/num steps total        153197\n",
      "exploration/num paths total           732\n",
      "evaluation/num steps total              1.1209e+06\n",
      "evaluation/num paths total           1493\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.05146\n",
      "evaluation/Rewards Std                  1.26978\n",
      "evaluation/Rewards Max                  7.10147\n",
      "evaluation/Rewards Min                  0.137513\n",
      "evaluation/Returns Mean              5051.46\n",
      "evaluation/Returns Std                 33.3975\n",
      "evaluation/Returns Max               5116.18\n",
      "evaluation/Returns Min               4995.32\n",
      "evaluation/Estimation Bias Mean      1619.35\n",
      "evaluation/Estimation Bias Std        173.277\n",
      "evaluation/EB/Q_True Mean              47.8524\n",
      "evaluation/EB/Q_True Std              147.6\n",
      "evaluation/EB/Q_Pred Mean            1667.2\n",
      "evaluation/EB/Q_Pred Std               83.3042\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5051.46\n",
      "evaluation/Actions Mean                 0.502081\n",
      "evaluation/Actions Std                  0.641943\n",
      "evaluation/Actions Max                  0.999993\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.91169\n",
      "time/backward_zf1 (s)                   2.05741\n",
      "time/backward_zf2 (s)                   1.99415\n",
      "time/data sampling (s)                  0.25692\n",
      "time/data storing (s)                   0.0152754\n",
      "time/evaluation sampling (s)            1.4253\n",
      "time/exploration sampling (s)           0.198467\n",
      "time/logging (s)                        0.0113838\n",
      "time/preback_alpha (s)                  0.991926\n",
      "time/preback_policy (s)                 1.12243\n",
      "time/preback_start (s)                  0.124971\n",
      "time/preback_zf (s)                     5.13127\n",
      "time/saving (s)                         0.00522799\n",
      "time/training (s)                       2.22562\n",
      "time/epoch (s)                         17.472\n",
      "time/total (s)                       2599.43\n",
      "Epoch                                 148\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:54:10.996064 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 149 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 160000\n",
      "trainer/ZF1 Loss                      984.41\n",
      "trainer/ZF2 Loss                      978.487\n",
      "trainer/ZF Expert Reward               17.6075\n",
      "trainer/ZF Policy Reward                7.05425\n",
      "trainer/ZF CHI2 Term                 1011.39\n",
      "trainer/Policy Loss                 -1418.77\n",
      "trainer/Bias Loss                    5021.28\n",
      "trainer/Bias Value                     20.7015\n",
      "trainer/Policy Grad Norm              401.621\n",
      "trainer/Policy Param Norm              35.8817\n",
      "trainer/Zf1 Grad Norm               11529.7\n",
      "trainer/Zf1 Param Norm                109.5\n",
      "trainer/Zf2 Grad Norm               13633.4\n",
      "trainer/Zf2 Param Norm                107.389\n",
      "trainer/Z Expert Predictions Mean    1653.09\n",
      "trainer/Z Expert Predictions Std      110.595\n",
      "trainer/Z Expert Predictions Max     1845.34\n",
      "trainer/Z Expert Predictions Min     1151.18\n",
      "trainer/Z Policy Predictions Mean    1406.07\n",
      "trainer/Z Policy Predictions Std      441.244\n",
      "trainer/Z Policy Predictions Max     1833.99\n",
      "trainer/Z Policy Predictions Min     -206.807\n",
      "trainer/Z Expert Targets Mean        1635.49\n",
      "trainer/Z Expert Targets Std          153.205\n",
      "trainer/Z Expert Targets Max         1826.25\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1399.02\n",
      "trainer/Z Policy Targets Std          445.028\n",
      "trainer/Z Policy Targets Max         1839.25\n",
      "trainer/Z Policy Targets Min         -217.893\n",
      "trainer/Log Pis Mean                   19.5853\n",
      "trainer/Log Pis Std                     4.54591\n",
      "trainer/Policy mu Mean                  1.16197\n",
      "trainer/Policy mu Std                   1.86347\n",
      "trainer/Policy log std Mean            -2.24948\n",
      "trainer/Policy log std Std              1.14003\n",
      "trainer/Alpha                           0.136803\n",
      "trainer/Alpha Loss                      0.0567294\n",
      "exploration/num steps total        155085\n",
      "exploration/num paths total           734\n",
      "evaluation/num steps total              1.1309e+06\n",
      "evaluation/num paths total           1503\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.02666\n",
      "evaluation/Rewards Std                  1.26548\n",
      "evaluation/Rewards Max                  7.02172\n",
      "evaluation/Rewards Min                  0.132001\n",
      "evaluation/Returns Mean              5026.66\n",
      "evaluation/Returns Std                 24.7621\n",
      "evaluation/Returns Max               5075.44\n",
      "evaluation/Returns Min               4995.48\n",
      "evaluation/Estimation Bias Mean      1609.71\n",
      "evaluation/Estimation Bias Std        172.873\n",
      "evaluation/EB/Q_True Mean              47.1919\n",
      "evaluation/EB/Q_True Std              145.56\n",
      "evaluation/EB/Q_Pred Mean            1656.9\n",
      "evaluation/EB/Q_Pred Std               96.6575\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5026.66\n",
      "evaluation/Actions Mean                 0.504071\n",
      "evaluation/Actions Std                  0.649192\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.87197\n",
      "time/backward_zf1 (s)                   2.03543\n",
      "time/backward_zf2 (s)                   1.94762\n",
      "time/data sampling (s)                  0.254402\n",
      "time/data storing (s)                   0.0144886\n",
      "time/evaluation sampling (s)            1.45488\n",
      "time/exploration sampling (s)           0.204534\n",
      "time/logging (s)                        0.0116794\n",
      "time/preback_alpha (s)                  0.974671\n",
      "time/preback_policy (s)                 1.09533\n",
      "time/preback_start (s)                  0.124889\n",
      "time/preback_zf (s)                     5.18471\n",
      "time/saving (s)                         0.00524004\n",
      "time/training (s)                       2.3251\n",
      "time/epoch (s)                         17.5049\n",
      "time/total (s)                       2616.96\n",
      "Epoch                                 149\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:54:28.488515 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 150 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 161000\n",
      "trainer/ZF1 Loss                      605.149\n",
      "trainer/ZF2 Loss                      600.098\n",
      "trainer/ZF Expert Reward               24.8198\n",
      "trainer/ZF Policy Reward               14.1726\n",
      "trainer/ZF CHI2 Term                  633.149\n",
      "trainer/Policy Loss                 -1379.07\n",
      "trainer/Bias Loss                     179.066\n",
      "trainer/Bias Value                     20.6886\n",
      "trainer/Policy Grad Norm              251.506\n",
      "trainer/Policy Param Norm              35.9265\n",
      "trainer/Zf1 Grad Norm                9548.52\n",
      "trainer/Zf1 Param Norm                109.724\n",
      "trainer/Zf2 Grad Norm                9547.04\n",
      "trainer/Zf2 Param Norm                107.623\n",
      "trainer/Z Expert Predictions Mean    1660.42\n",
      "trainer/Z Expert Predictions Std       99.508\n",
      "trainer/Z Expert Predictions Max     1847.28\n",
      "trainer/Z Expert Predictions Min     1325.79\n",
      "trainer/Z Policy Predictions Mean    1371.48\n",
      "trainer/Z Policy Predictions Std      448.383\n",
      "trainer/Z Policy Predictions Max     1803.97\n",
      "trainer/Z Policy Predictions Min     -162.407\n",
      "trainer/Z Expert Targets Mean        1635.6\n",
      "trainer/Z Expert Targets Std          105.395\n",
      "trainer/Z Expert Targets Max         1825.43\n",
      "trainer/Z Expert Targets Min         1287.65\n",
      "trainer/Z Policy Targets Mean        1357.31\n",
      "trainer/Z Policy Targets Std          450.587\n",
      "trainer/Z Policy Targets Max         1794.06\n",
      "trainer/Z Policy Targets Min         -127.083\n",
      "trainer/Log Pis Mean                   20.0789\n",
      "trainer/Log Pis Std                     4.96159\n",
      "trainer/Policy mu Mean                  1.24531\n",
      "trainer/Policy mu Std                   1.89717\n",
      "trainer/Policy log std Mean            -2.24486\n",
      "trainer/Policy log std Std              1.18981\n",
      "trainer/Alpha                           0.136548\n",
      "trainer/Alpha Loss                     -0.0107693\n",
      "exploration/num steps total        156085\n",
      "exploration/num paths total           735\n",
      "evaluation/num steps total              1.1409e+06\n",
      "evaluation/num paths total           1513\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12489\n",
      "evaluation/Rewards Std                  1.30591\n",
      "evaluation/Rewards Max                  7.16413\n",
      "evaluation/Rewards Min                  0.128474\n",
      "evaluation/Returns Mean              5124.89\n",
      "evaluation/Returns Std                 31.0698\n",
      "evaluation/Returns Max               5171.92\n",
      "evaluation/Returns Min               5065.1\n",
      "evaluation/Estimation Bias Mean      1621.64\n",
      "evaluation/Estimation Bias Std        171.128\n",
      "evaluation/EB/Q_True Mean              48.4129\n",
      "evaluation/EB/Q_True Std              149.418\n",
      "evaluation/EB/Q_Pred Mean            1670.05\n",
      "evaluation/EB/Q_Pred Std               78.6811\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5124.89\n",
      "evaluation/Actions Mean                 0.504711\n",
      "evaluation/Actions Std                  0.639374\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999895\n",
      "time/backward_policy (s)                1.90995\n",
      "time/backward_zf1 (s)                   2.06459\n",
      "time/backward_zf2 (s)                   2.00981\n",
      "time/data sampling (s)                  0.248622\n",
      "time/data storing (s)                   0.014991\n",
      "time/evaluation sampling (s)            1.45447\n",
      "time/exploration sampling (s)           0.198217\n",
      "time/logging (s)                        0.0120812\n",
      "time/preback_alpha (s)                  1.02716\n",
      "time/preback_policy (s)                 1.16759\n",
      "time/preback_start (s)                  0.121627\n",
      "time/preback_zf (s)                     5.12066\n",
      "time/saving (s)                         0.00533192\n",
      "time/training (s)                       2.07032\n",
      "time/epoch (s)                         17.4254\n",
      "time/total (s)                       2634.4\n",
      "Epoch                                 150\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:54:45.993601 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 151 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 162000\n",
      "trainer/ZF1 Loss                      561.29\n",
      "trainer/ZF2 Loss                      566.602\n",
      "trainer/ZF Expert Reward               30.4471\n",
      "trainer/ZF Policy Reward                8.21742\n",
      "trainer/ZF CHI2 Term                  606.228\n",
      "trainer/Policy Loss                 -1422.42\n",
      "trainer/Bias Loss                    5357.31\n",
      "trainer/Bias Value                     20.6783\n",
      "trainer/Policy Grad Norm              289.532\n",
      "trainer/Policy Param Norm              35.9692\n",
      "trainer/Zf1 Grad Norm                6247.39\n",
      "trainer/Zf1 Param Norm                109.943\n",
      "trainer/Zf2 Grad Norm                5651.18\n",
      "trainer/Zf2 Param Norm                107.835\n",
      "trainer/Z Expert Predictions Mean    1650.64\n",
      "trainer/Z Expert Predictions Std      156.271\n",
      "trainer/Z Expert Predictions Max     1824.29\n",
      "trainer/Z Expert Predictions Min      155.324\n",
      "trainer/Z Policy Predictions Mean    1410.22\n",
      "trainer/Z Policy Predictions Std      452.817\n",
      "trainer/Z Policy Predictions Max     1832.1\n",
      "trainer/Z Policy Predictions Min     -235.438\n",
      "trainer/Z Expert Targets Mean        1620.19\n",
      "trainer/Z Expert Targets Std          194.517\n",
      "trainer/Z Expert Targets Max         1807.08\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1402\n",
      "trainer/Z Policy Targets Std          445.263\n",
      "trainer/Z Policy Targets Max         1807.89\n",
      "trainer/Z Policy Targets Min         -238.75\n",
      "trainer/Log Pis Mean                   20.2555\n",
      "trainer/Log Pis Std                     4.6573\n",
      "trainer/Policy mu Mean                  1.23142\n",
      "trainer/Policy mu Std                   1.95228\n",
      "trainer/Policy log std Mean            -2.19035\n",
      "trainer/Policy log std Std              1.15441\n",
      "trainer/Alpha                           0.139102\n",
      "trainer/Alpha Loss                     -0.0355404\n",
      "exploration/num steps total        157085\n",
      "exploration/num paths total           736\n",
      "evaluation/num steps total              1.1509e+06\n",
      "evaluation/num paths total           1523\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20554\n",
      "evaluation/Rewards Std                  1.33167\n",
      "evaluation/Rewards Max                  7.34698\n",
      "evaluation/Rewards Min                  0.11577\n",
      "evaluation/Returns Mean              5205.54\n",
      "evaluation/Returns Std                 39.5701\n",
      "evaluation/Returns Max               5272.17\n",
      "evaluation/Returns Min               5136.8\n",
      "evaluation/Estimation Bias Mean      1586.28\n",
      "evaluation/Estimation Bias Std        179.405\n",
      "evaluation/EB/Q_True Mean              49.1561\n",
      "evaluation/EB/Q_True Std              152.004\n",
      "evaluation/EB/Q_Pred Mean            1635.44\n",
      "evaluation/EB/Q_Pred Std               91.7384\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5205.54\n",
      "evaluation/Actions Mean                 0.511306\n",
      "evaluation/Actions Std                  0.642122\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.92166\n",
      "time/backward_zf1 (s)                   2.07217\n",
      "time/backward_zf2 (s)                   2.0142\n",
      "time/data sampling (s)                  0.259727\n",
      "time/data storing (s)                   0.0146242\n",
      "time/evaluation sampling (s)            1.41247\n",
      "time/exploration sampling (s)           0.195981\n",
      "time/logging (s)                        0.0124458\n",
      "time/preback_alpha (s)                  0.982367\n",
      "time/preback_policy (s)                 1.11158\n",
      "time/preback_start (s)                  0.122429\n",
      "time/preback_zf (s)                     5.11072\n",
      "time/saving (s)                         0.00532754\n",
      "time/training (s)                       2.19853\n",
      "time/epoch (s)                         17.4342\n",
      "time/total (s)                       2651.86\n",
      "Epoch                                 151\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:55:03.470447 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 152 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 163000\n",
      "trainer/ZF1 Loss                      410.868\n",
      "trainer/ZF2 Loss                      342.877\n",
      "trainer/ZF Expert Reward                9.39756\n",
      "trainer/ZF Policy Reward                2.35164\n",
      "trainer/ZF CHI2 Term                  403.483\n",
      "trainer/Policy Loss                 -1428.17\n",
      "trainer/Bias Loss                     205.77\n",
      "trainer/Bias Value                     20.6665\n",
      "trainer/Policy Grad Norm              273.866\n",
      "trainer/Policy Param Norm              36.0141\n",
      "trainer/Zf1 Grad Norm                6464.5\n",
      "trainer/Zf1 Param Norm                110.152\n",
      "trainer/Zf2 Grad Norm                7086.25\n",
      "trainer/Zf2 Param Norm                108.029\n",
      "trainer/Z Expert Predictions Mean    1635.4\n",
      "trainer/Z Expert Predictions Std      130.142\n",
      "trainer/Z Expert Predictions Max     1818.72\n",
      "trainer/Z Expert Predictions Min      706.09\n",
      "trainer/Z Policy Predictions Mean    1412.84\n",
      "trainer/Z Policy Predictions Std      436.297\n",
      "trainer/Z Policy Predictions Max     1805.71\n",
      "trainer/Z Policy Predictions Min     -194.177\n",
      "trainer/Z Expert Targets Mean        1626.01\n",
      "trainer/Z Expert Targets Std          134.58\n",
      "trainer/Z Expert Targets Max         1806.5\n",
      "trainer/Z Expert Targets Min          674.387\n",
      "trainer/Z Policy Targets Mean        1410.49\n",
      "trainer/Z Policy Targets Std          438.639\n",
      "trainer/Z Policy Targets Max         1808.15\n",
      "trainer/Z Policy Targets Min         -218.421\n",
      "trainer/Log Pis Mean                   19.762\n",
      "trainer/Log Pis Std                     4.76135\n",
      "trainer/Policy mu Mean                  1.23145\n",
      "trainer/Policy mu Std                   1.90466\n",
      "trainer/Policy log std Mean            -2.22081\n",
      "trainer/Policy log std Std              1.15591\n",
      "trainer/Alpha                           0.139872\n",
      "trainer/Alpha Loss                      0.0332847\n",
      "exploration/num steps total        157085\n",
      "exploration/num paths total           736\n",
      "evaluation/num steps total              1.1609e+06\n",
      "evaluation/num paths total           1533\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.03078\n",
      "evaluation/Rewards Std                  1.276\n",
      "evaluation/Rewards Max                  7.26295\n",
      "evaluation/Rewards Min                  0.0933828\n",
      "evaluation/Returns Mean              5030.78\n",
      "evaluation/Returns Std                 65.928\n",
      "evaluation/Returns Max               5092.39\n",
      "evaluation/Returns Min               4860.12\n",
      "evaluation/Estimation Bias Mean      1588.82\n",
      "evaluation/Estimation Bias Std        205.92\n",
      "evaluation/EB/Q_True Mean              47.0966\n",
      "evaluation/EB/Q_True Std              145.531\n",
      "evaluation/EB/Q_Pred Mean            1635.92\n",
      "evaluation/EB/Q_Pred Std              134.693\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5030.78\n",
      "evaluation/Actions Mean                 0.503351\n",
      "evaluation/Actions Std                  0.646159\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.92517\n",
      "time/backward_zf1 (s)                   2.053\n",
      "time/backward_zf2 (s)                   1.98854\n",
      "time/data sampling (s)                  0.259523\n",
      "time/data storing (s)                   0.0138425\n",
      "time/evaluation sampling (s)            1.43112\n",
      "time/exploration sampling (s)           0.191674\n",
      "time/logging (s)                        0.012203\n",
      "time/preback_alpha (s)                  0.96468\n",
      "time/preback_policy (s)                 1.07443\n",
      "time/preback_start (s)                  0.120884\n",
      "time/preback_zf (s)                     5.0863\n",
      "time/saving (s)                         0.00527241\n",
      "time/training (s)                       2.27935\n",
      "time/epoch (s)                         17.406\n",
      "time/total (s)                       2669.29\n",
      "Epoch                                 152\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:55:20.980530 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 153 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 164000\n",
      "trainer/ZF1 Loss                       33.842\n",
      "trainer/ZF2 Loss                       37.7178\n",
      "trainer/ZF Expert Reward               14.4036\n",
      "trainer/ZF Policy Reward                1.53549\n",
      "trainer/ZF CHI2 Term                   68.7693\n",
      "trainer/Policy Loss                 -1394.7\n",
      "trainer/Bias Loss                     149.882\n",
      "trainer/Bias Value                     20.6523\n",
      "trainer/Policy Grad Norm              274.063\n",
      "trainer/Policy Param Norm              36.0586\n",
      "trainer/Zf1 Grad Norm                3328.52\n",
      "trainer/Zf1 Param Norm                110.357\n",
      "trainer/Zf2 Grad Norm                5749.86\n",
      "trainer/Zf2 Param Norm                108.203\n",
      "trainer/Z Expert Predictions Mean    1646.36\n",
      "trainer/Z Expert Predictions Std      125.526\n",
      "trainer/Z Expert Predictions Max     1817.04\n",
      "trainer/Z Expert Predictions Min      508.231\n",
      "trainer/Z Policy Predictions Mean    1387.9\n",
      "trainer/Z Policy Predictions Std      430.253\n",
      "trainer/Z Policy Predictions Max     1811.58\n",
      "trainer/Z Policy Predictions Min     -204.024\n",
      "trainer/Z Expert Targets Mean        1631.96\n",
      "trainer/Z Expert Targets Std          127.756\n",
      "trainer/Z Expert Targets Max         1805.86\n",
      "trainer/Z Expert Targets Min          490.353\n",
      "trainer/Z Policy Targets Mean        1386.36\n",
      "trainer/Z Policy Targets Std          424.898\n",
      "trainer/Z Policy Targets Max         1805\n",
      "trainer/Z Policy Targets Min         -207.597\n",
      "trainer/Log Pis Mean                   20.3245\n",
      "trainer/Log Pis Std                     4.94486\n",
      "trainer/Policy mu Mean                  1.2458\n",
      "trainer/Policy mu Std                   1.9695\n",
      "trainer/Policy log std Mean            -2.1749\n",
      "trainer/Policy log std Std              1.13033\n",
      "trainer/Alpha                           0.139997\n",
      "trainer/Alpha Loss                     -0.0454283\n",
      "exploration/num steps total        159085\n",
      "exploration/num paths total           738\n",
      "evaluation/num steps total              1.1709e+06\n",
      "evaluation/num paths total           1543\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.03378\n",
      "evaluation/Rewards Std                  1.26714\n",
      "evaluation/Rewards Max                  7.17242\n",
      "evaluation/Rewards Min                  0.126189\n",
      "evaluation/Returns Mean              5033.78\n",
      "evaluation/Returns Std                 54.2827\n",
      "evaluation/Returns Max               5108.09\n",
      "evaluation/Returns Min               4902.64\n",
      "evaluation/Estimation Bias Mean      1579\n",
      "evaluation/Estimation Bias Std        180.401\n",
      "evaluation/EB/Q_True Mean              46.1957\n",
      "evaluation/EB/Q_True Std              142.944\n",
      "evaluation/EB/Q_Pred Mean            1625.2\n",
      "evaluation/EB/Q_Pred Std              116.339\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5033.78\n",
      "evaluation/Actions Mean                 0.50113\n",
      "evaluation/Actions Std                  0.64658\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                1.94868\n",
      "time/backward_zf1 (s)                   2.07834\n",
      "time/backward_zf2 (s)                   2.03446\n",
      "time/data sampling (s)                  0.243993\n",
      "time/data storing (s)                   0.0148436\n",
      "time/evaluation sampling (s)            1.40027\n",
      "time/exploration sampling (s)           0.200127\n",
      "time/logging (s)                        0.0120037\n",
      "time/preback_alpha (s)                  1.03221\n",
      "time/preback_policy (s)                 1.17899\n",
      "time/preback_start (s)                  0.122703\n",
      "time/preback_zf (s)                     5.09915\n",
      "time/saving (s)                         0.00531432\n",
      "time/training (s)                       2.06602\n",
      "time/epoch (s)                         17.4371\n",
      "time/total (s)                       2686.75\n",
      "Epoch                                 153\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:55:38.663731 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 154 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 165000\n",
      "trainer/ZF1 Loss                       53.3885\n",
      "trainer/ZF2 Loss                       60.4555\n",
      "trainer/ZF Expert Reward               24.5035\n",
      "trainer/ZF Policy Reward               10.242\n",
      "trainer/ZF CHI2 Term                   90.7249\n",
      "trainer/Policy Loss                 -1395.78\n",
      "trainer/Bias Loss                     193.877\n",
      "trainer/Bias Value                     20.6385\n",
      "trainer/Policy Grad Norm              332.434\n",
      "trainer/Policy Param Norm              36.1012\n",
      "trainer/Zf1 Grad Norm                4091.95\n",
      "trainer/Zf1 Param Norm                110.572\n",
      "trainer/Zf2 Grad Norm                3979.57\n",
      "trainer/Zf2 Param Norm                108.405\n",
      "trainer/Z Expert Predictions Mean    1631.93\n",
      "trainer/Z Expert Predictions Std      169.83\n",
      "trainer/Z Expert Predictions Max     1810.26\n",
      "trainer/Z Expert Predictions Min       73.0174\n",
      "trainer/Z Policy Predictions Mean    1392.98\n",
      "trainer/Z Policy Predictions Std      435.657\n",
      "trainer/Z Policy Predictions Max     1816.37\n",
      "trainer/Z Policy Predictions Min     -231.698\n",
      "trainer/Z Expert Targets Mean        1607.43\n",
      "trainer/Z Expert Targets Std          175.526\n",
      "trainer/Z Expert Targets Max         1795.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1382.74\n",
      "trainer/Z Policy Targets Std          435.009\n",
      "trainer/Z Policy Targets Max         1799.3\n",
      "trainer/Z Policy Targets Min         -220.215\n",
      "trainer/Log Pis Mean                   19.7388\n",
      "trainer/Log Pis Std                     4.5623\n",
      "trainer/Policy mu Mean                  1.25878\n",
      "trainer/Policy mu Std                   1.86368\n",
      "trainer/Policy log std Mean            -2.1789\n",
      "trainer/Policy log std Std              1.14601\n",
      "trainer/Alpha                           0.140027\n",
      "trainer/Alpha Loss                      0.0365702\n",
      "exploration/num steps total        161085\n",
      "exploration/num paths total           740\n",
      "evaluation/num steps total              1.17869e+06\n",
      "evaluation/num paths total           1553\n",
      "evaluation/path length Mean           779.9\n",
      "evaluation/path length Std            200.746\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            400\n",
      "evaluation/Rewards Mean                 4.99359\n",
      "evaluation/Rewards Std                  1.3893\n",
      "evaluation/Rewards Max                  8.48346\n",
      "evaluation/Rewards Min                  0.137498\n",
      "evaluation/Returns Mean              3894.5\n",
      "evaluation/Returns Std               1132.03\n",
      "evaluation/Returns Max               5156.52\n",
      "evaluation/Returns Min               1770.79\n",
      "evaluation/Estimation Bias Mean      1420.77\n",
      "evaluation/Estimation Bias Std        448.278\n",
      "evaluation/EB/Q_True Mean              62.4369\n",
      "evaluation/EB/Q_True Std              167.894\n",
      "evaluation/EB/Q_Pred Mean            1483.21\n",
      "evaluation/EB/Q_Pred Std              406.464\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3894.5\n",
      "evaluation/Actions Mean                 0.475983\n",
      "evaluation/Actions Std                  0.66468\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97346\n",
      "time/backward_zf1 (s)                   2.1208\n",
      "time/backward_zf2 (s)                   2.06351\n",
      "time/data sampling (s)                  0.252797\n",
      "time/data storing (s)                   0.0139851\n",
      "time/evaluation sampling (s)            1.4735\n",
      "time/exploration sampling (s)           0.195895\n",
      "time/logging (s)                        0.00963933\n",
      "time/preback_alpha (s)                  1.03928\n",
      "time/preback_policy (s)                 1.19984\n",
      "time/preback_start (s)                  0.125821\n",
      "time/preback_zf (s)                     5.09775\n",
      "time/saving (s)                         0.00535608\n",
      "time/training (s)                       2.04366\n",
      "time/epoch (s)                         17.6153\n",
      "time/total (s)                       2704.39\n",
      "Epoch                                 154\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:55:56.283230 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 155 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 166000\n",
      "trainer/ZF1 Loss                       69.6176\n",
      "trainer/ZF2 Loss                       61.4554\n",
      "trainer/ZF Expert Reward               20.084\n",
      "trainer/ZF Policy Reward                8.26757\n",
      "trainer/ZF CHI2 Term                   97.1301\n",
      "trainer/Policy Loss                 -1445.95\n",
      "trainer/Bias Loss                     315.171\n",
      "trainer/Bias Value                     20.626\n",
      "trainer/Policy Grad Norm              247.575\n",
      "trainer/Policy Param Norm              36.1442\n",
      "trainer/Zf1 Grad Norm                7129.45\n",
      "trainer/Zf1 Param Norm                110.772\n",
      "trainer/Zf2 Grad Norm                8532.17\n",
      "trainer/Zf2 Param Norm                108.582\n",
      "trainer/Z Expert Predictions Mean    1632.27\n",
      "trainer/Z Expert Predictions Std      106.724\n",
      "trainer/Z Expert Predictions Max     1839.66\n",
      "trainer/Z Expert Predictions Min     1187.84\n",
      "trainer/Z Policy Predictions Mean    1438.69\n",
      "trainer/Z Policy Predictions Std      426.94\n",
      "trainer/Z Policy Predictions Max     1837.28\n",
      "trainer/Z Policy Predictions Min     -253.34\n",
      "trainer/Z Expert Targets Mean        1612.19\n",
      "trainer/Z Expert Targets Std          111.028\n",
      "trainer/Z Expert Targets Max         1809.37\n",
      "trainer/Z Expert Targets Min         1161.8\n",
      "trainer/Z Policy Targets Mean        1430.43\n",
      "trainer/Z Policy Targets Std          423.763\n",
      "trainer/Z Policy Targets Max         1810.4\n",
      "trainer/Z Policy Targets Min         -248.082\n",
      "trainer/Log Pis Mean                   19.9769\n",
      "trainer/Log Pis Std                     4.35373\n",
      "trainer/Policy mu Mean                  1.29332\n",
      "trainer/Policy mu Std                   1.89942\n",
      "trainer/Policy log std Mean            -2.16578\n",
      "trainer/Policy log std Std              1.14303\n",
      "trainer/Alpha                           0.138776\n",
      "trainer/Alpha Loss                      0.0032031\n",
      "exploration/num steps total        161551\n",
      "exploration/num paths total           741\n",
      "evaluation/num steps total              1.18869e+06\n",
      "evaluation/num paths total           1563\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08156\n",
      "evaluation/Rewards Std                  1.28273\n",
      "evaluation/Rewards Max                  7.13361\n",
      "evaluation/Rewards Min                  0.133799\n",
      "evaluation/Returns Mean              5081.56\n",
      "evaluation/Returns Std                 30.6812\n",
      "evaluation/Returns Max               5142.83\n",
      "evaluation/Returns Min               5032.97\n",
      "evaluation/Estimation Bias Mean      1587.95\n",
      "evaluation/Estimation Bias Std        169.776\n",
      "evaluation/EB/Q_True Mean              47.7472\n",
      "evaluation/EB/Q_True Std              147.346\n",
      "evaluation/EB/Q_Pred Mean            1635.69\n",
      "evaluation/EB/Q_Pred Std               74.9909\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5081.56\n",
      "evaluation/Actions Mean                 0.500402\n",
      "evaluation/Actions Std                  0.643497\n",
      "evaluation/Actions Max                  0.999972\n",
      "evaluation/Actions Min                 -0.999934\n",
      "time/backward_policy (s)                1.92064\n",
      "time/backward_zf1 (s)                   2.06772\n",
      "time/backward_zf2 (s)                   2.0077\n",
      "time/data sampling (s)                  0.26008\n",
      "time/data storing (s)                   0.0140877\n",
      "time/evaluation sampling (s)            1.48126\n",
      "time/exploration sampling (s)           0.192686\n",
      "time/logging (s)                        0.0120452\n",
      "time/preback_alpha (s)                  1.00711\n",
      "time/preback_policy (s)                 1.14016\n",
      "time/preback_start (s)                  0.122434\n",
      "time/preback_zf (s)                     5.13601\n",
      "time/saving (s)                         0.00524958\n",
      "time/training (s)                       2.18633\n",
      "time/epoch (s)                         17.5535\n",
      "time/total (s)                       2721.96\n",
      "Epoch                                 155\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:56:13.628929 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 156 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 167000\n",
      "trainer/ZF1 Loss                      566.857\n",
      "trainer/ZF2 Loss                      564.476\n",
      "trainer/ZF Expert Reward               15.962\n",
      "trainer/ZF Policy Reward                6.99159\n",
      "trainer/ZF CHI2 Term                  593.936\n",
      "trainer/Policy Loss                 -1421.79\n",
      "trainer/Bias Loss                     157.941\n",
      "trainer/Bias Value                     20.6105\n",
      "trainer/Policy Grad Norm              249.273\n",
      "trainer/Policy Param Norm              36.1859\n",
      "trainer/Zf1 Grad Norm                5906.27\n",
      "trainer/Zf1 Param Norm                110.971\n",
      "trainer/Zf2 Grad Norm                5762.8\n",
      "trainer/Zf2 Param Norm                108.774\n",
      "trainer/Z Expert Predictions Mean    1638.44\n",
      "trainer/Z Expert Predictions Std      105.153\n",
      "trainer/Z Expert Predictions Max     1821.19\n",
      "trainer/Z Expert Predictions Min     1208.15\n",
      "trainer/Z Policy Predictions Mean    1412.9\n",
      "trainer/Z Policy Predictions Std      416.41\n",
      "trainer/Z Policy Predictions Max     1804.52\n",
      "trainer/Z Policy Predictions Min     -206.477\n",
      "trainer/Z Expert Targets Mean        1622.48\n",
      "trainer/Z Expert Targets Std          109.206\n",
      "trainer/Z Expert Targets Max         1814.19\n",
      "trainer/Z Expert Targets Min         1199.68\n",
      "trainer/Z Policy Targets Mean        1405.91\n",
      "trainer/Z Policy Targets Std          420.809\n",
      "trainer/Z Policy Targets Max         1800.95\n",
      "trainer/Z Policy Targets Min         -229.532\n",
      "trainer/Log Pis Mean                   19.4936\n",
      "trainer/Log Pis Std                     4.69891\n",
      "trainer/Policy mu Mean                  1.22087\n",
      "trainer/Policy mu Std                   1.86005\n",
      "trainer/Policy log std Mean            -2.23533\n",
      "trainer/Policy log std Std              1.15378\n",
      "trainer/Alpha                           0.140794\n",
      "trainer/Alpha Loss                      0.0713083\n",
      "exploration/num steps total        164001\n",
      "exploration/num paths total           744\n",
      "evaluation/num steps total              1.19869e+06\n",
      "evaluation/num paths total           1573\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.0262\n",
      "evaluation/Rewards Std                  1.2656\n",
      "evaluation/Rewards Max                  7.02122\n",
      "evaluation/Rewards Min                  0.133105\n",
      "evaluation/Returns Mean              5026.2\n",
      "evaluation/Returns Std                 38.9145\n",
      "evaluation/Returns Max               5070.17\n",
      "evaluation/Returns Min               4927.77\n",
      "evaluation/Estimation Bias Mean      1577.51\n",
      "evaluation/Estimation Bias Std        172.496\n",
      "evaluation/EB/Q_True Mean              47.8371\n",
      "evaluation/EB/Q_True Std              147.56\n",
      "evaluation/EB/Q_Pred Mean            1625.35\n",
      "evaluation/EB/Q_Pred Std               82.7152\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5026.2\n",
      "evaluation/Actions Mean                 0.504281\n",
      "evaluation/Actions Std                  0.643332\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.87122\n",
      "time/backward_zf1 (s)                   2.01488\n",
      "time/backward_zf2 (s)                   1.93735\n",
      "time/data sampling (s)                  0.25222\n",
      "time/data storing (s)                   0.0152409\n",
      "time/evaluation sampling (s)            1.39638\n",
      "time/exploration sampling (s)           0.204227\n",
      "time/logging (s)                        0.0121879\n",
      "time/preback_alpha (s)                  0.962532\n",
      "time/preback_policy (s)                 1.07514\n",
      "time/preback_start (s)                  0.122939\n",
      "time/preback_zf (s)                     5.10841\n",
      "time/saving (s)                         0.00612768\n",
      "time/training (s)                       2.3\n",
      "time/epoch (s)                         17.2788\n",
      "time/total (s)                       2739.26\n",
      "Epoch                                 156\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:56:30.759659 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 157 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 168000\n",
      "trainer/ZF1 Loss                       33.3713\n",
      "trainer/ZF2 Loss                       29.2143\n",
      "trainer/ZF Expert Reward               20.3437\n",
      "trainer/ZF Policy Reward                3.42798\n",
      "trainer/ZF CHI2 Term                   68.3947\n",
      "trainer/Policy Loss                 -1430.54\n",
      "trainer/Bias Loss                     137.034\n",
      "trainer/Bias Value                     20.5959\n",
      "trainer/Policy Grad Norm              321.935\n",
      "trainer/Policy Param Norm              36.2263\n",
      "trainer/Zf1 Grad Norm                2996.87\n",
      "trainer/Zf1 Param Norm                111.189\n",
      "trainer/Zf2 Grad Norm                3531.41\n",
      "trainer/Zf2 Param Norm                108.965\n",
      "trainer/Z Expert Predictions Mean    1625.26\n",
      "trainer/Z Expert Predictions Std      122.126\n",
      "trainer/Z Expert Predictions Max     1813.02\n",
      "trainer/Z Expert Predictions Min      926.139\n",
      "trainer/Z Policy Predictions Mean    1412.77\n",
      "trainer/Z Policy Predictions Std      387.307\n",
      "trainer/Z Policy Predictions Max     1806.53\n",
      "trainer/Z Policy Predictions Min     -180.46\n",
      "trainer/Z Expert Targets Mean        1604.92\n",
      "trainer/Z Expert Targets Std          126.843\n",
      "trainer/Z Expert Targets Max         1800.42\n",
      "trainer/Z Expert Targets Min          913.375\n",
      "trainer/Z Policy Targets Mean        1409.35\n",
      "trainer/Z Policy Targets Std          382.421\n",
      "trainer/Z Policy Targets Max         1802.47\n",
      "trainer/Z Policy Targets Min         -203.391\n",
      "trainer/Log Pis Mean                   20.3901\n",
      "trainer/Log Pis Std                     4.67035\n",
      "trainer/Policy mu Mean                  1.30856\n",
      "trainer/Policy mu Std                   1.90863\n",
      "trainer/Policy log std Mean            -2.18027\n",
      "trainer/Policy log std Std              1.14962\n",
      "trainer/Alpha                           0.139861\n",
      "trainer/Alpha Loss                     -0.0545637\n",
      "exploration/num steps total        164001\n",
      "exploration/num paths total           744\n",
      "evaluation/num steps total              1.20869e+06\n",
      "evaluation/num paths total           1583\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09544\n",
      "evaluation/Rewards Std                  1.30733\n",
      "evaluation/Rewards Max                  7.0673\n",
      "evaluation/Rewards Min                  0.108019\n",
      "evaluation/Returns Mean              5095.44\n",
      "evaluation/Returns Std                 54.2693\n",
      "evaluation/Returns Max               5180.88\n",
      "evaluation/Returns Min               5021.05\n",
      "evaluation/Estimation Bias Mean      1573.24\n",
      "evaluation/Estimation Bias Std        164.597\n",
      "evaluation/EB/Q_True Mean              47.4347\n",
      "evaluation/EB/Q_True Std              146.203\n",
      "evaluation/EB/Q_Pred Mean            1620.68\n",
      "evaluation/EB/Q_Pred Std               89.0366\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5095.44\n",
      "evaluation/Actions Mean                 0.486972\n",
      "evaluation/Actions Std                  0.648091\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                1.8403\n",
      "time/backward_zf1 (s)                   1.97391\n",
      "time/backward_zf2 (s)                   1.922\n",
      "time/data sampling (s)                  0.254287\n",
      "time/data storing (s)                   0.0144902\n",
      "time/evaluation sampling (s)            1.4091\n",
      "time/exploration sampling (s)           0.192934\n",
      "time/logging (s)                        0.011815\n",
      "time/preback_alpha (s)                  0.992809\n",
      "time/preback_policy (s)                 1.10859\n",
      "time/preback_start (s)                  0.121809\n",
      "time/preback_zf (s)                     5.07919\n",
      "time/saving (s)                         0.00550483\n",
      "time/training (s)                       2.13494\n",
      "time/epoch (s)                         17.0617\n",
      "time/total (s)                       2756.35\n",
      "Epoch                                 157\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:56:48.655070 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 158 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 169000\n",
      "trainer/ZF1 Loss                       28.8775\n",
      "trainer/ZF2 Loss                       22.4844\n",
      "trainer/ZF Expert Reward               17.4106\n",
      "trainer/ZF Policy Reward               -2.10709\n",
      "trainer/ZF CHI2 Term                   64.9908\n",
      "trainer/Policy Loss                 -1405.16\n",
      "trainer/Bias Loss                     146.149\n",
      "trainer/Bias Value                     20.5813\n",
      "trainer/Policy Grad Norm              312.783\n",
      "trainer/Policy Param Norm              36.263\n",
      "trainer/Zf1 Grad Norm                4110.84\n",
      "trainer/Zf1 Param Norm                111.401\n",
      "trainer/Zf2 Grad Norm                3941.4\n",
      "trainer/Zf2 Param Norm                109.169\n",
      "trainer/Z Expert Predictions Mean    1617.8\n",
      "trainer/Z Expert Predictions Std      127.389\n",
      "trainer/Z Expert Predictions Max     1815.88\n",
      "trainer/Z Expert Predictions Min      531.143\n",
      "trainer/Z Policy Predictions Mean    1395.13\n",
      "trainer/Z Policy Predictions Std      431.029\n",
      "trainer/Z Policy Predictions Max     1810.55\n",
      "trainer/Z Policy Predictions Min     -181.303\n",
      "trainer/Z Expert Targets Mean        1600.39\n",
      "trainer/Z Expert Targets Std          128.985\n",
      "trainer/Z Expert Targets Max         1801.42\n",
      "trainer/Z Expert Targets Min          473.992\n",
      "trainer/Z Policy Targets Mean        1397.24\n",
      "trainer/Z Policy Targets Std          425.486\n",
      "trainer/Z Policy Targets Max         1802.34\n",
      "trainer/Z Policy Targets Min         -219.265\n",
      "trainer/Log Pis Mean                   19.9921\n",
      "trainer/Log Pis Std                     4.60421\n",
      "trainer/Policy mu Mean                  1.22867\n",
      "trainer/Policy mu Std                   1.94518\n",
      "trainer/Policy log std Mean            -2.22738\n",
      "trainer/Policy log std Std              1.18377\n",
      "trainer/Alpha                           0.138329\n",
      "trainer/Alpha Loss                      0.00109405\n",
      "exploration/num steps total        164001\n",
      "exploration/num paths total           744\n",
      "evaluation/num steps total              1.2181e+06\n",
      "evaluation/num paths total           1593\n",
      "evaluation/path length Mean           940.5\n",
      "evaluation/path length Std            176.84\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            410\n",
      "evaluation/Rewards Mean                 5.0911\n",
      "evaluation/Rewards Std                  1.32524\n",
      "evaluation/Rewards Max                  7.21113\n",
      "evaluation/Rewards Min                  0.110868\n",
      "evaluation/Returns Mean              4788.18\n",
      "evaluation/Returns Std               1001.71\n",
      "evaluation/Returns Max               5217.76\n",
      "evaluation/Returns Min               1795.97\n",
      "evaluation/Estimation Bias Mean      1520.66\n",
      "evaluation/Estimation Bias Std        351.69\n",
      "evaluation/EB/Q_True Mean              52.2227\n",
      "evaluation/EB/Q_True Std              155.78\n",
      "evaluation/EB/Q_Pred Mean            1572.89\n",
      "evaluation/EB/Q_Pred Std              261.105\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4788.18\n",
      "evaluation/Actions Mean                 0.497428\n",
      "evaluation/Actions Std                  0.64938\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97012\n",
      "time/backward_zf1 (s)                   2.12814\n",
      "time/backward_zf2 (s)                   2.07198\n",
      "time/data sampling (s)                  0.266311\n",
      "time/data storing (s)                   0.0138889\n",
      "time/evaluation sampling (s)            1.46267\n",
      "time/exploration sampling (s)           0.191096\n",
      "time/logging (s)                        0.0116032\n",
      "time/preback_alpha (s)                  1.04575\n",
      "time/preback_policy (s)                 1.21\n",
      "time/preback_start (s)                  0.125842\n",
      "time/preback_zf (s)                     5.17241\n",
      "time/saving (s)                         0.00531883\n",
      "time/training (s)                       2.15147\n",
      "time/epoch (s)                         17.8266\n",
      "time/total (s)                       2774.19\n",
      "Epoch                                 158\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 17:57:06.324543 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 159 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 170000\n",
      "trainer/ZF1 Loss                      607.24\n",
      "trainer/ZF2 Loss                      591.71\n",
      "trainer/ZF Expert Reward               19.9718\n",
      "trainer/ZF Policy Reward               13.4548\n",
      "trainer/ZF CHI2 Term                  625.159\n",
      "trainer/Policy Loss                 -1400.74\n",
      "trainer/Bias Loss                     286.967\n",
      "trainer/Bias Value                     20.5632\n",
      "trainer/Policy Grad Norm              314.549\n",
      "trainer/Policy Param Norm              36.3013\n",
      "trainer/Zf1 Grad Norm                5154.32\n",
      "trainer/Zf1 Param Norm                111.605\n",
      "trainer/Zf2 Grad Norm                5899.99\n",
      "trainer/Zf2 Param Norm                109.362\n",
      "trainer/Z Expert Predictions Mean    1623.28\n",
      "trainer/Z Expert Predictions Std      106.285\n",
      "trainer/Z Expert Predictions Max     1814.88\n",
      "trainer/Z Expert Predictions Min      744.651\n",
      "trainer/Z Policy Predictions Mean    1391.07\n",
      "trainer/Z Policy Predictions Std      457.394\n",
      "trainer/Z Policy Predictions Max     1812.6\n",
      "trainer/Z Policy Predictions Min     -232.385\n",
      "trainer/Z Expert Targets Mean        1603.31\n",
      "trainer/Z Expert Targets Std          111.568\n",
      "trainer/Z Expert Targets Max         1798.52\n",
      "trainer/Z Expert Targets Min          672.941\n",
      "trainer/Z Policy Targets Mean        1377.61\n",
      "trainer/Z Policy Targets Std          463.383\n",
      "trainer/Z Policy Targets Max         1793.07\n",
      "trainer/Z Policy Targets Min         -259.446\n",
      "trainer/Log Pis Mean                   19.3604\n",
      "trainer/Log Pis Std                     4.65834\n",
      "trainer/Policy mu Mean                  1.20194\n",
      "trainer/Policy mu Std                   1.8718\n",
      "trainer/Policy log std Mean            -2.2257\n",
      "trainer/Policy log std Std              1.1418\n",
      "trainer/Alpha                           0.137046\n",
      "trainer/Alpha Loss                      0.0876541\n",
      "exploration/num steps total        166001\n",
      "exploration/num paths total           746\n",
      "evaluation/num steps total              1.22751e+06\n",
      "evaluation/num paths total           1603\n",
      "evaluation/path length Mean           941\n",
      "evaluation/path length Std            134.215\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            562\n",
      "evaluation/Rewards Mean                 4.952\n",
      "evaluation/Rewards Std                  1.27243\n",
      "evaluation/Rewards Max                  7.22382\n",
      "evaluation/Rewards Min                  0.116402\n",
      "evaluation/Returns Mean              4659.83\n",
      "evaluation/Returns Std                699.911\n",
      "evaluation/Returns Max               5028.57\n",
      "evaluation/Returns Min               2655.53\n",
      "evaluation/Estimation Bias Mean      1449.26\n",
      "evaluation/Estimation Bias Std        324.277\n",
      "evaluation/EB/Q_True Mean              49.5961\n",
      "evaluation/EB/Q_True Std              148.071\n",
      "evaluation/EB/Q_Pred Mean            1498.85\n",
      "evaluation/EB/Q_Pred Std              284.797\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4659.83\n",
      "evaluation/Actions Mean                 0.499538\n",
      "evaluation/Actions Std                  0.652422\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94918\n",
      "time/backward_zf1 (s)                   2.11753\n",
      "time/backward_zf2 (s)                   2.05899\n",
      "time/data sampling (s)                  0.2674\n",
      "time/data storing (s)                   0.0151019\n",
      "time/evaluation sampling (s)            1.42681\n",
      "time/exploration sampling (s)           0.203592\n",
      "time/logging (s)                        0.0111453\n",
      "time/preback_alpha (s)                  1.01961\n",
      "time/preback_policy (s)                 1.16385\n",
      "time/preback_start (s)                  0.123798\n",
      "time/preback_zf (s)                     5.12001\n",
      "time/saving (s)                         0.00545078\n",
      "time/training (s)                       2.1156\n",
      "time/epoch (s)                         17.5981\n",
      "time/total (s)                       2791.81\n",
      "Epoch                                 159\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:57:24.030423 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 160 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 171000\n",
      "trainer/ZF1 Loss                       25.1833\n",
      "trainer/ZF2 Loss                       28.5651\n",
      "trainer/ZF Expert Reward               20.7414\n",
      "trainer/ZF Policy Reward                4.81911\n",
      "trainer/ZF CHI2 Term                   62.8751\n",
      "trainer/Policy Loss                 -1389.72\n",
      "trainer/Bias Loss                     135.684\n",
      "trainer/Bias Value                     20.5474\n",
      "trainer/Policy Grad Norm              259.921\n",
      "trainer/Policy Param Norm              36.3449\n",
      "trainer/Zf1 Grad Norm                2726.36\n",
      "trainer/Zf1 Param Norm                111.834\n",
      "trainer/Zf2 Grad Norm                3130.4\n",
      "trainer/Zf2 Param Norm                109.568\n",
      "trainer/Z Expert Predictions Mean    1616.6\n",
      "trainer/Z Expert Predictions Std      134.306\n",
      "trainer/Z Expert Predictions Max     1804.89\n",
      "trainer/Z Expert Predictions Min      581.224\n",
      "trainer/Z Policy Predictions Mean    1375.32\n",
      "trainer/Z Policy Predictions Std      467.714\n",
      "trainer/Z Policy Predictions Max     1790.05\n",
      "trainer/Z Policy Predictions Min     -314.666\n",
      "trainer/Z Expert Targets Mean        1595.86\n",
      "trainer/Z Expert Targets Std          136.692\n",
      "trainer/Z Expert Targets Max         1796.16\n",
      "trainer/Z Expert Targets Min          614.379\n",
      "trainer/Z Policy Targets Mean        1370.5\n",
      "trainer/Z Policy Targets Std          461.17\n",
      "trainer/Z Policy Targets Max         1783.92\n",
      "trainer/Z Policy Targets Min         -301.033\n",
      "trainer/Log Pis Mean                   20.2813\n",
      "trainer/Log Pis Std                     4.51182\n",
      "trainer/Policy mu Mean                  1.26546\n",
      "trainer/Policy mu Std                   1.90162\n",
      "trainer/Policy log std Mean            -2.24051\n",
      "trainer/Policy log std Std              1.17581\n",
      "trainer/Alpha                           0.136899\n",
      "trainer/Alpha Loss                     -0.0385167\n",
      "exploration/num steps total        166001\n",
      "exploration/num paths total           746\n",
      "evaluation/num steps total              1.23751e+06\n",
      "evaluation/num paths total           1613\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.01089\n",
      "evaluation/Rewards Std                  1.26751\n",
      "evaluation/Rewards Max                  7.00349\n",
      "evaluation/Rewards Min                  0.107672\n",
      "evaluation/Returns Mean              5010.89\n",
      "evaluation/Returns Std                 29.4702\n",
      "evaluation/Returns Max               5064.19\n",
      "evaluation/Returns Min               4966.07\n",
      "evaluation/Estimation Bias Mean      1550.49\n",
      "evaluation/Estimation Bias Std        163.841\n",
      "evaluation/EB/Q_True Mean              47.3235\n",
      "evaluation/EB/Q_True Std              146.213\n",
      "evaluation/EB/Q_Pred Mean            1597.82\n",
      "evaluation/EB/Q_Pred Std               82.2559\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5010.89\n",
      "evaluation/Actions Mean                 0.507814\n",
      "evaluation/Actions Std                  0.643263\n",
      "evaluation/Actions Max                  0.999982\n",
      "evaluation/Actions Min                 -0.999924\n",
      "time/backward_policy (s)                1.95201\n",
      "time/backward_zf1 (s)                   2.0959\n",
      "time/backward_zf2 (s)                   2.03915\n",
      "time/data sampling (s)                  0.263795\n",
      "time/data storing (s)                   0.0152799\n",
      "time/evaluation sampling (s)            1.48062\n",
      "time/exploration sampling (s)           0.200095\n",
      "time/logging (s)                        0.0124667\n",
      "time/preback_alpha (s)                  1.04445\n",
      "time/preback_policy (s)                 1.18549\n",
      "time/preback_start (s)                  0.125806\n",
      "time/preback_zf (s)                     5.12003\n",
      "time/saving (s)                         0.00592516\n",
      "time/training (s)                       2.09312\n",
      "time/epoch (s)                         17.6341\n",
      "time/total (s)                       2809.47\n",
      "Epoch                                 160\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:57:41.795427 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 161 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 172000\n",
      "trainer/ZF1 Loss                       90.0956\n",
      "trainer/ZF2 Loss                       69.5701\n",
      "trainer/ZF Expert Reward               15.212\n",
      "trainer/ZF Policy Reward                2.38247\n",
      "trainer/ZF CHI2 Term                  112.888\n",
      "trainer/Policy Loss                 -1402.1\n",
      "trainer/Bias Loss                     133.439\n",
      "trainer/Bias Value                     20.5297\n",
      "trainer/Policy Grad Norm              314.872\n",
      "trainer/Policy Param Norm              36.3901\n",
      "trainer/Zf1 Grad Norm                5903.84\n",
      "trainer/Zf1 Param Norm                112.055\n",
      "trainer/Zf2 Grad Norm                5521.29\n",
      "trainer/Zf2 Param Norm                109.771\n",
      "trainer/Z Expert Predictions Mean    1601.75\n",
      "trainer/Z Expert Predictions Std      117.331\n",
      "trainer/Z Expert Predictions Max     1810.48\n",
      "trainer/Z Expert Predictions Min     1043.19\n",
      "trainer/Z Policy Predictions Mean    1400.76\n",
      "trainer/Z Policy Predictions Std      391.921\n",
      "trainer/Z Policy Predictions Max     1794.27\n",
      "trainer/Z Policy Predictions Min     -198.061\n",
      "trainer/Z Expert Targets Mean        1586.54\n",
      "trainer/Z Expert Targets Std          119.675\n",
      "trainer/Z Expert Targets Max         1787.04\n",
      "trainer/Z Expert Targets Min         1019.4\n",
      "trainer/Z Policy Targets Mean        1398.38\n",
      "trainer/Z Policy Targets Std          388.503\n",
      "trainer/Z Policy Targets Max         1780.48\n",
      "trainer/Z Policy Targets Min         -183.708\n",
      "trainer/Log Pis Mean                   20.4298\n",
      "trainer/Log Pis Std                     4.35971\n",
      "trainer/Policy mu Mean                  1.26165\n",
      "trainer/Policy mu Std                   1.91975\n",
      "trainer/Policy log std Mean            -2.19206\n",
      "trainer/Policy log std Std              1.18261\n",
      "trainer/Alpha                           0.138796\n",
      "trainer/Alpha Loss                     -0.0596479\n",
      "exploration/num steps total        166001\n",
      "exploration/num paths total           746\n",
      "evaluation/num steps total              1.24751e+06\n",
      "evaluation/num paths total           1623\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13659\n",
      "evaluation/Rewards Std                  1.2996\n",
      "evaluation/Rewards Max                  7.14481\n",
      "evaluation/Rewards Min                  0.115057\n",
      "evaluation/Returns Mean              5136.59\n",
      "evaluation/Returns Std                 51.9833\n",
      "evaluation/Returns Max               5195.01\n",
      "evaluation/Returns Min               5022.73\n",
      "evaluation/Estimation Bias Mean      1583.26\n",
      "evaluation/Estimation Bias Std        173.201\n",
      "evaluation/EB/Q_True Mean              47.434\n",
      "evaluation/EB/Q_True Std              146.199\n",
      "evaluation/EB/Q_Pred Mean            1630.7\n",
      "evaluation/EB/Q_Pred Std               91.3209\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5136.59\n",
      "evaluation/Actions Mean                 0.492323\n",
      "evaluation/Actions Std                  0.651114\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.98639\n",
      "time/backward_zf1 (s)                   2.1188\n",
      "time/backward_zf2 (s)                   2.07284\n",
      "time/data sampling (s)                  0.261077\n",
      "time/data storing (s)                   0.015335\n",
      "time/evaluation sampling (s)            1.41417\n",
      "time/exploration sampling (s)           0.1993\n",
      "time/logging (s)                        0.0114675\n",
      "time/preback_alpha (s)                  1.02882\n",
      "time/preback_policy (s)                 1.18007\n",
      "time/preback_start (s)                  0.1245\n",
      "time/preback_zf (s)                     5.11922\n",
      "time/saving (s)                         0.00538031\n",
      "time/training (s)                       2.15644\n",
      "time/epoch (s)                         17.6938\n",
      "time/total (s)                       2827.19\n",
      "Epoch                                 161\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:57:58.908522 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 162 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 173000\n",
      "trainer/ZF1 Loss                       69.76\n",
      "trainer/ZF2 Loss                       51.4508\n",
      "trainer/ZF Expert Reward               17.3378\n",
      "trainer/ZF Policy Reward                1.37636\n",
      "trainer/ZF CHI2 Term                   96.4634\n",
      "trainer/Policy Loss                 -1399.11\n",
      "trainer/Bias Loss                     192.223\n",
      "trainer/Bias Value                     20.5158\n",
      "trainer/Policy Grad Norm              343.968\n",
      "trainer/Policy Param Norm              36.4208\n",
      "trainer/Zf1 Grad Norm                7033.5\n",
      "trainer/Zf1 Param Norm                112.273\n",
      "trainer/Zf2 Grad Norm                4761.42\n",
      "trainer/Zf2 Param Norm                109.98\n",
      "trainer/Z Expert Predictions Mean    1592.52\n",
      "trainer/Z Expert Predictions Std      134.967\n",
      "trainer/Z Expert Predictions Max     1810.33\n",
      "trainer/Z Expert Predictions Min      573.177\n",
      "trainer/Z Policy Predictions Mean    1391.29\n",
      "trainer/Z Policy Predictions Std      422.335\n",
      "trainer/Z Policy Predictions Max     1794.18\n",
      "trainer/Z Policy Predictions Min     -227.089\n",
      "trainer/Z Expert Targets Mean        1575.18\n",
      "trainer/Z Expert Targets Std          139.241\n",
      "trainer/Z Expert Targets Max         1792.13\n",
      "trainer/Z Expert Targets Min          536.872\n",
      "trainer/Z Policy Targets Mean        1389.91\n",
      "trainer/Z Policy Targets Std          419.524\n",
      "trainer/Z Policy Targets Max         1779.8\n",
      "trainer/Z Policy Targets Min         -321.398\n",
      "trainer/Log Pis Mean                   20.0975\n",
      "trainer/Log Pis Std                     4.73617\n",
      "trainer/Policy mu Mean                  1.27967\n",
      "trainer/Policy mu Std                   1.89784\n",
      "trainer/Policy log std Mean            -2.21498\n",
      "trainer/Policy log std Std              1.17996\n",
      "trainer/Alpha                           0.140469\n",
      "trainer/Alpha Loss                     -0.0137021\n",
      "exploration/num steps total        166001\n",
      "exploration/num paths total           746\n",
      "evaluation/num steps total              1.25751e+06\n",
      "evaluation/num paths total           1633\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.01453\n",
      "evaluation/Rewards Std                  1.25273\n",
      "evaluation/Rewards Max                  7.09426\n",
      "evaluation/Rewards Min                  0.158947\n",
      "evaluation/Returns Mean              5014.53\n",
      "evaluation/Returns Std                 80.0032\n",
      "evaluation/Returns Max               5088.59\n",
      "evaluation/Returns Min               4834.44\n",
      "evaluation/Estimation Bias Mean      1520.36\n",
      "evaluation/Estimation Bias Std        200.743\n",
      "evaluation/EB/Q_True Mean              47.2911\n",
      "evaluation/EB/Q_True Std              145.918\n",
      "evaluation/EB/Q_Pred Mean            1567.65\n",
      "evaluation/EB/Q_Pred Std              142.759\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5014.53\n",
      "evaluation/Actions Mean                 0.522089\n",
      "evaluation/Actions Std                  0.635059\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.82376\n",
      "time/backward_zf1 (s)                   1.97001\n",
      "time/backward_zf2 (s)                   1.89271\n",
      "time/data sampling (s)                  0.233775\n",
      "time/data storing (s)                   0.0142733\n",
      "time/evaluation sampling (s)            1.399\n",
      "time/exploration sampling (s)           0.190969\n",
      "time/logging (s)                        0.0114355\n",
      "time/preback_alpha (s)                  0.946305\n",
      "time/preback_policy (s)                 1.04751\n",
      "time/preback_start (s)                  0.120887\n",
      "time/preback_zf (s)                     5.07893\n",
      "time/saving (s)                         0.00476996\n",
      "time/training (s)                       2.31362\n",
      "time/epoch (s)                         17.048\n",
      "time/total (s)                       2844.26\n",
      "Epoch                                 162\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:58:16.056229 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 163 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 174000\n",
      "trainer/ZF1 Loss                       42.8206\n",
      "trainer/ZF2 Loss                       40.6682\n",
      "trainer/ZF Expert Reward               20.5494\n",
      "trainer/ZF Policy Reward                6.43711\n",
      "trainer/ZF CHI2 Term                   75.4498\n",
      "trainer/Policy Loss                 -1421.09\n",
      "trainer/Bias Loss                     312.268\n",
      "trainer/Bias Value                     20.4989\n",
      "trainer/Policy Grad Norm              255.767\n",
      "trainer/Policy Param Norm              36.4574\n",
      "trainer/Zf1 Grad Norm                5432.23\n",
      "trainer/Zf1 Param Norm                112.5\n",
      "trainer/Zf2 Grad Norm                6371.35\n",
      "trainer/Zf2 Param Norm                110.206\n",
      "trainer/Z Expert Predictions Mean    1593.11\n",
      "trainer/Z Expert Predictions Std      137.481\n",
      "trainer/Z Expert Predictions Max     1816.38\n",
      "trainer/Z Expert Predictions Min      189.9\n",
      "trainer/Z Policy Predictions Mean    1412.19\n",
      "trainer/Z Policy Predictions Std      396.428\n",
      "trainer/Z Policy Predictions Max     1798.27\n",
      "trainer/Z Policy Predictions Min     -237.823\n",
      "trainer/Z Expert Targets Mean        1572.56\n",
      "trainer/Z Expert Targets Std          148.485\n",
      "trainer/Z Expert Targets Max         1793.42\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1405.75\n",
      "trainer/Z Policy Targets Std          394.158\n",
      "trainer/Z Policy Targets Max         1791.26\n",
      "trainer/Z Policy Targets Min         -245.971\n",
      "trainer/Log Pis Mean                   19.791\n",
      "trainer/Log Pis Std                     4.37449\n",
      "trainer/Policy mu Mean                  1.28604\n",
      "trainer/Policy mu Std                   1.8569\n",
      "trainer/Policy log std Mean            -2.19297\n",
      "trainer/Policy log std Std              1.13903\n",
      "trainer/Alpha                           0.13961\n",
      "trainer/Alpha Loss                      0.0291746\n",
      "exploration/num steps total        168001\n",
      "exploration/num paths total           748\n",
      "evaluation/num steps total              1.26751e+06\n",
      "evaluation/num paths total           1643\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07086\n",
      "evaluation/Rewards Std                  1.28417\n",
      "evaluation/Rewards Max                  7.25723\n",
      "evaluation/Rewards Min                  0.0984116\n",
      "evaluation/Returns Mean              5070.86\n",
      "evaluation/Returns Std                 52.1702\n",
      "evaluation/Returns Max               5151.49\n",
      "evaluation/Returns Min               4968.23\n",
      "evaluation/Estimation Bias Mean      1524.8\n",
      "evaluation/Estimation Bias Std        194.034\n",
      "evaluation/EB/Q_True Mean              47.889\n",
      "evaluation/EB/Q_True Std              148.03\n",
      "evaluation/EB/Q_Pred Mean            1572.69\n",
      "evaluation/EB/Q_Pred Std              118.291\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5070.86\n",
      "evaluation/Actions Mean                 0.504075\n",
      "evaluation/Actions Std                  0.646361\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.8442\n",
      "time/backward_zf1 (s)                   1.96421\n",
      "time/backward_zf2 (s)                   1.91239\n",
      "time/data sampling (s)                  0.239537\n",
      "time/data storing (s)                   0.0144769\n",
      "time/evaluation sampling (s)            1.41305\n",
      "time/exploration sampling (s)           0.199025\n",
      "time/logging (s)                        0.0141863\n",
      "time/preback_alpha (s)                  0.947516\n",
      "time/preback_policy (s)                 1.05795\n",
      "time/preback_start (s)                  0.121851\n",
      "time/preback_zf (s)                     5.06364\n",
      "time/saving (s)                         0.00549994\n",
      "time/training (s)                       2.28761\n",
      "time/epoch (s)                         17.0852\n",
      "time/total (s)                       2861.36\n",
      "Epoch                                 163\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:58:34.009079 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 164 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 175000\n",
      "trainer/ZF1 Loss                       62.1459\n",
      "trainer/ZF2 Loss                       63.889\n",
      "trainer/ZF Expert Reward               22.0482\n",
      "trainer/ZF Policy Reward                1.8509\n",
      "trainer/ZF CHI2 Term                  103.206\n",
      "trainer/Policy Loss                 -1334.65\n",
      "trainer/Bias Loss                     144.918\n",
      "trainer/Bias Value                     20.4849\n",
      "trainer/Policy Grad Norm              283.879\n",
      "trainer/Policy Param Norm              36.4929\n",
      "trainer/Zf1 Grad Norm                3816.45\n",
      "trainer/Zf1 Param Norm                112.716\n",
      "trainer/Zf2 Grad Norm                6719.75\n",
      "trainer/Zf2 Param Norm                110.418\n",
      "trainer/Z Expert Predictions Mean    1592.24\n",
      "trainer/Z Expert Predictions Std      131.29\n",
      "trainer/Z Expert Predictions Max     1815.09\n",
      "trainer/Z Expert Predictions Min      604.547\n",
      "trainer/Z Policy Predictions Mean    1322.85\n",
      "trainer/Z Policy Predictions Std      458.074\n",
      "trainer/Z Policy Predictions Max     1793.04\n",
      "trainer/Z Policy Predictions Min     -280.428\n",
      "trainer/Z Expert Targets Mean        1570.19\n",
      "trainer/Z Expert Targets Std          135.392\n",
      "trainer/Z Expert Targets Max         1789.32\n",
      "trainer/Z Expert Targets Min          543.405\n",
      "trainer/Z Policy Targets Mean        1321\n",
      "trainer/Z Policy Targets Std          453.799\n",
      "trainer/Z Policy Targets Max         1769.82\n",
      "trainer/Z Policy Targets Min         -283.489\n",
      "trainer/Log Pis Mean                   20.1936\n",
      "trainer/Log Pis Std                     5.21966\n",
      "trainer/Policy mu Mean                  1.26265\n",
      "trainer/Policy mu Std                   1.94238\n",
      "trainer/Policy log std Mean            -2.18116\n",
      "trainer/Policy log std Std              1.18707\n",
      "trainer/Alpha                           0.13955\n",
      "trainer/Alpha Loss                     -0.0270127\n",
      "exploration/num steps total        170001\n",
      "exploration/num paths total           750\n",
      "evaluation/num steps total              1.27729e+06\n",
      "evaluation/num paths total           1653\n",
      "evaluation/path length Mean           978.4\n",
      "evaluation/path length Std             64.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            784\n",
      "evaluation/Rewards Mean                 5.21453\n",
      "evaluation/Rewards Std                  1.32157\n",
      "evaluation/Rewards Max                  8.06595\n",
      "evaluation/Rewards Min                  0.135223\n",
      "evaluation/Returns Mean              5101.9\n",
      "evaluation/Returns Std                359.252\n",
      "evaluation/Returns Max               5278.14\n",
      "evaluation/Returns Min               4029.62\n",
      "evaluation/Estimation Bias Mean      1503.55\n",
      "evaluation/Estimation Bias Std        213.497\n",
      "evaluation/EB/Q_True Mean              50.1142\n",
      "evaluation/EB/Q_True Std              152.889\n",
      "evaluation/EB/Q_Pred Mean            1553.67\n",
      "evaluation/EB/Q_Pred Std              133.17\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5101.9\n",
      "evaluation/Actions Mean                 0.492576\n",
      "evaluation/Actions Std                  0.651555\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.03338\n",
      "time/backward_zf1 (s)                   2.16772\n",
      "time/backward_zf2 (s)                   2.10254\n",
      "time/data sampling (s)                  0.26577\n",
      "time/data storing (s)                   0.0155575\n",
      "time/evaluation sampling (s)            1.37387\n",
      "time/exploration sampling (s)           0.209517\n",
      "time/logging (s)                        0.0128855\n",
      "time/preback_alpha (s)                  1.04426\n",
      "time/preback_policy (s)                 1.20484\n",
      "time/preback_start (s)                  0.12574\n",
      "time/preback_zf (s)                     5.14845\n",
      "time/saving (s)                         0.00656496\n",
      "time/training (s)                       2.17241\n",
      "time/epoch (s)                         17.8835\n",
      "time/total (s)                       2879.26\n",
      "Epoch                                 164\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:58:51.418215 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 165 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 176000\n",
      "trainer/ZF1 Loss                       50.6302\n",
      "trainer/ZF2 Loss                       46.8861\n",
      "trainer/ZF Expert Reward               18.4007\n",
      "trainer/ZF Policy Reward               -0.590878\n",
      "trainer/ZF CHI2 Term                   86.6818\n",
      "trainer/Policy Loss                 -1382.21\n",
      "trainer/Bias Loss                     193.978\n",
      "trainer/Bias Value                     20.4706\n",
      "trainer/Policy Grad Norm              250.143\n",
      "trainer/Policy Param Norm              36.53\n",
      "trainer/Zf1 Grad Norm                3997.95\n",
      "trainer/Zf1 Param Norm                112.956\n",
      "trainer/Zf2 Grad Norm                4584.55\n",
      "trainer/Zf2 Param Norm                110.648\n",
      "trainer/Z Expert Predictions Mean    1572.38\n",
      "trainer/Z Expert Predictions Std      140.2\n",
      "trainer/Z Expert Predictions Max     1801.58\n",
      "trainer/Z Expert Predictions Min      510.158\n",
      "trainer/Z Policy Predictions Mean    1369.82\n",
      "trainer/Z Policy Predictions Std      441.672\n",
      "trainer/Z Policy Predictions Max     1778.45\n",
      "trainer/Z Policy Predictions Min     -312.056\n",
      "trainer/Z Expert Targets Mean        1553.98\n",
      "trainer/Z Expert Targets Std          143.475\n",
      "trainer/Z Expert Targets Max         1786.23\n",
      "trainer/Z Expert Targets Min          481.541\n",
      "trainer/Z Policy Targets Mean        1370.41\n",
      "trainer/Z Policy Targets Std          431.593\n",
      "trainer/Z Policy Targets Max         1778.22\n",
      "trainer/Z Policy Targets Min         -238.705\n",
      "trainer/Log Pis Mean                   19.1234\n",
      "trainer/Log Pis Std                     4.15056\n",
      "trainer/Policy mu Mean                  1.28851\n",
      "trainer/Policy mu Std                   1.81057\n",
      "trainer/Policy log std Mean            -2.22749\n",
      "trainer/Policy log std Std              1.1838\n",
      "trainer/Alpha                           0.139347\n",
      "trainer/Alpha Loss                      0.122167\n",
      "exploration/num steps total        171001\n",
      "exploration/num paths total           751\n",
      "evaluation/num steps total              1.28707e+06\n",
      "evaluation/num paths total           1663\n",
      "evaluation/path length Mean           977.4\n",
      "evaluation/path length Std             67.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            774\n",
      "evaluation/Rewards Mean                 5.16899\n",
      "evaluation/Rewards Std                  1.32188\n",
      "evaluation/Rewards Max                  7.2417\n",
      "evaluation/Rewards Min                  0.130017\n",
      "evaluation/Returns Mean              5052.17\n",
      "evaluation/Returns Std                369.022\n",
      "evaluation/Returns Max               5209.6\n",
      "evaluation/Returns Min               3952.56\n",
      "evaluation/Estimation Bias Mean      1537.28\n",
      "evaluation/Estimation Bias Std        226.8\n",
      "evaluation/EB/Q_True Mean              50.4013\n",
      "evaluation/EB/Q_True Std              153.876\n",
      "evaluation/EB/Q_Pred Mean            1587.68\n",
      "evaluation/EB/Q_Pred Std              136.308\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5052.17\n",
      "evaluation/Actions Mean                 0.498779\n",
      "evaluation/Actions Std                  0.6443\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999986\n",
      "time/backward_policy (s)                1.89318\n",
      "time/backward_zf1 (s)                   2.02701\n",
      "time/backward_zf2 (s)                   1.97974\n",
      "time/data sampling (s)                  0.261033\n",
      "time/data storing (s)                   0.0152251\n",
      "time/evaluation sampling (s)            1.40968\n",
      "time/exploration sampling (s)           0.199532\n",
      "time/logging (s)                        0.0121301\n",
      "time/preback_alpha (s)                  1.00728\n",
      "time/preback_policy (s)                 1.1295\n",
      "time/preback_start (s)                  0.124602\n",
      "time/preback_zf (s)                     5.09668\n",
      "time/saving (s)                         0.00531437\n",
      "time/training (s)                       2.17474\n",
      "time/epoch (s)                         17.3356\n",
      "time/total (s)                       2896.63\n",
      "Epoch                                 165\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:59:08.783501 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 166 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 177000\n",
      "trainer/ZF1 Loss                      548.697\n",
      "trainer/ZF2 Loss                      551.665\n",
      "trainer/ZF Expert Reward               13.9011\n",
      "trainer/ZF Policy Reward                5.23208\n",
      "trainer/ZF CHI2 Term                  578.634\n",
      "trainer/Policy Loss                 -1378.85\n",
      "trainer/Bias Loss                     160.557\n",
      "trainer/Bias Value                     20.4566\n",
      "trainer/Policy Grad Norm              329.355\n",
      "trainer/Policy Param Norm              36.5674\n",
      "trainer/Zf1 Grad Norm                5990.05\n",
      "trainer/Zf1 Param Norm                113.185\n",
      "trainer/Zf2 Grad Norm                7568.09\n",
      "trainer/Zf2 Param Norm                110.872\n",
      "trainer/Z Expert Predictions Mean    1567.65\n",
      "trainer/Z Expert Predictions Std      126.113\n",
      "trainer/Z Expert Predictions Max     1783.79\n",
      "trainer/Z Expert Predictions Min      496.816\n",
      "trainer/Z Policy Predictions Mean    1376.3\n",
      "trainer/Z Policy Predictions Std      417.662\n",
      "trainer/Z Policy Predictions Max     1782.72\n",
      "trainer/Z Policy Predictions Min     -282.451\n",
      "trainer/Z Expert Targets Mean        1553.75\n",
      "trainer/Z Expert Targets Std          126.821\n",
      "trainer/Z Expert Targets Max         1762.92\n",
      "trainer/Z Expert Targets Min          568.113\n",
      "trainer/Z Policy Targets Mean        1371.07\n",
      "trainer/Z Policy Targets Std          418.197\n",
      "trainer/Z Policy Targets Max         1770.67\n",
      "trainer/Z Policy Targets Min         -251.474\n",
      "trainer/Log Pis Mean                   19.9843\n",
      "trainer/Log Pis Std                     4.18604\n",
      "trainer/Policy mu Mean                  1.2357\n",
      "trainer/Policy mu Std                   1.84115\n",
      "trainer/Policy log std Mean            -2.28634\n",
      "trainer/Policy log std Std              1.1731\n",
      "trainer/Alpha                           0.139174\n",
      "trainer/Alpha Loss                      0.0021867\n",
      "exploration/num steps total        174001\n",
      "exploration/num paths total           754\n",
      "evaluation/num steps total              1.29707e+06\n",
      "evaluation/num paths total           1673\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15135\n",
      "evaluation/Rewards Std                  1.29485\n",
      "evaluation/Rewards Max                  7.23826\n",
      "evaluation/Rewards Min                  0.136137\n",
      "evaluation/Returns Mean              5151.35\n",
      "evaluation/Returns Std                 22.9133\n",
      "evaluation/Returns Max               5193.01\n",
      "evaluation/Returns Min               5108.28\n",
      "evaluation/Estimation Bias Mean      1550.41\n",
      "evaluation/Estimation Bias Std        174.439\n",
      "evaluation/EB/Q_True Mean              48.8333\n",
      "evaluation/EB/Q_True Std              150.999\n",
      "evaluation/EB/Q_Pred Mean            1599.24\n",
      "evaluation/EB/Q_Pred Std               84.9578\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5151.35\n",
      "evaluation/Actions Mean                 0.499653\n",
      "evaluation/Actions Std                  0.645533\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.89671\n",
      "time/backward_zf1 (s)                   2.04515\n",
      "time/backward_zf2 (s)                   1.99229\n",
      "time/data sampling (s)                  0.258688\n",
      "time/data storing (s)                   0.0139361\n",
      "time/evaluation sampling (s)            1.39079\n",
      "time/exploration sampling (s)           0.198734\n",
      "time/logging (s)                        0.0121999\n",
      "time/preback_alpha (s)                  1.00748\n",
      "time/preback_policy (s)                 1.13576\n",
      "time/preback_start (s)                  0.122704\n",
      "time/preback_zf (s)                     5.09722\n",
      "time/saving (s)                         0.00497595\n",
      "time/training (s)                       2.11439\n",
      "time/epoch (s)                         17.291\n",
      "time/total (s)                       2913.94\n",
      "Epoch                                 166\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:59:25.921960 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 167 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 178000\n",
      "trainer/ZF1 Loss                       46.2303\n",
      "trainer/ZF2 Loss                       39.709\n",
      "trainer/ZF Expert Reward               14.0039\n",
      "trainer/ZF Policy Reward               -1.00411\n",
      "trainer/ZF CHI2 Term                   77.7521\n",
      "trainer/Policy Loss                 -1400.75\n",
      "trainer/Bias Loss                     158.006\n",
      "trainer/Bias Value                     20.4396\n",
      "trainer/Policy Grad Norm              246.479\n",
      "trainer/Policy Param Norm              36.604\n",
      "trainer/Zf1 Grad Norm                5241.6\n",
      "trainer/Zf1 Param Norm                113.412\n",
      "trainer/Zf2 Grad Norm                5080.86\n",
      "trainer/Zf2 Param Norm                111.099\n",
      "trainer/Z Expert Predictions Mean    1562.67\n",
      "trainer/Z Expert Predictions Std      118.325\n",
      "trainer/Z Expert Predictions Max     1764.23\n",
      "trainer/Z Expert Predictions Min      906.79\n",
      "trainer/Z Policy Predictions Mean    1387.83\n",
      "trainer/Z Policy Predictions Std      397.913\n",
      "trainer/Z Policy Predictions Max     1770.7\n",
      "trainer/Z Policy Predictions Min     -126.606\n",
      "trainer/Z Expert Targets Mean        1548.67\n",
      "trainer/Z Expert Targets Std          121.439\n",
      "trainer/Z Expert Targets Max         1756.69\n",
      "trainer/Z Expert Targets Min          879.194\n",
      "trainer/Z Policy Targets Mean        1388.84\n",
      "trainer/Z Policy Targets Std          393.084\n",
      "trainer/Z Policy Targets Max         1762.69\n",
      "trainer/Z Policy Targets Min         -105.419\n",
      "trainer/Log Pis Mean                   19.9742\n",
      "trainer/Log Pis Std                     3.99537\n",
      "trainer/Policy mu Mean                  1.28578\n",
      "trainer/Policy mu Std                   1.83905\n",
      "trainer/Policy log std Mean            -2.25627\n",
      "trainer/Policy log std Std              1.18212\n",
      "trainer/Alpha                           0.137548\n",
      "trainer/Alpha Loss                      0.00355358\n",
      "exploration/num steps total        174001\n",
      "exploration/num paths total           754\n",
      "evaluation/num steps total              1.30707e+06\n",
      "evaluation/num paths total           1683\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16626\n",
      "evaluation/Rewards Std                  1.31893\n",
      "evaluation/Rewards Max                  7.22687\n",
      "evaluation/Rewards Min                  0.142823\n",
      "evaluation/Returns Mean              5166.26\n",
      "evaluation/Returns Std                 31.2038\n",
      "evaluation/Returns Max               5197.72\n",
      "evaluation/Returns Min               5088.78\n",
      "evaluation/Estimation Bias Mean      1552.39\n",
      "evaluation/Estimation Bias Std        166.299\n",
      "evaluation/EB/Q_True Mean              49.0851\n",
      "evaluation/EB/Q_True Std              151.6\n",
      "evaluation/EB/Q_Pred Mean            1601.48\n",
      "evaluation/EB/Q_Pred Std               72.1788\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5166.26\n",
      "evaluation/Actions Mean                 0.508619\n",
      "evaluation/Actions Std                  0.638392\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.82693\n",
      "time/backward_zf1 (s)                   1.96354\n",
      "time/backward_zf2 (s)                   1.88976\n",
      "time/data sampling (s)                  0.262901\n",
      "time/data storing (s)                   0.0138748\n",
      "time/evaluation sampling (s)            1.396\n",
      "time/exploration sampling (s)           0.191862\n",
      "time/logging (s)                        0.0118564\n",
      "time/preback_alpha (s)                  0.948316\n",
      "time/preback_policy (s)                 1.05427\n",
      "time/preback_start (s)                  0.121822\n",
      "time/preback_zf (s)                     5.09363\n",
      "time/saving (s)                         0.0052466\n",
      "time/training (s)                       2.28933\n",
      "time/epoch (s)                         17.0693\n",
      "time/total (s)                       2931.04\n",
      "Epoch                                 167\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 17:59:43.108880 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 168 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 179000\n",
      "trainer/ZF1 Loss                       50.8904\n",
      "trainer/ZF2 Loss                       49.4369\n",
      "trainer/ZF Expert Reward               22.6367\n",
      "trainer/ZF Policy Reward                2.23294\n",
      "trainer/ZF CHI2 Term                   89.9024\n",
      "trainer/Policy Loss                 -1381.98\n",
      "trainer/Bias Loss                     438.645\n",
      "trainer/Bias Value                     20.4243\n",
      "trainer/Policy Grad Norm              302.548\n",
      "trainer/Policy Param Norm              36.6395\n",
      "trainer/Zf1 Grad Norm                4783.64\n",
      "trainer/Zf1 Param Norm                113.639\n",
      "trainer/Zf2 Grad Norm                4672.14\n",
      "trainer/Zf2 Param Norm                111.316\n",
      "trainer/Z Expert Predictions Mean    1550.08\n",
      "trainer/Z Expert Predictions Std      167.087\n",
      "trainer/Z Expert Predictions Max     1784.61\n",
      "trainer/Z Expert Predictions Min       79.0163\n",
      "trainer/Z Policy Predictions Mean    1373.7\n",
      "trainer/Z Policy Predictions Std      389.688\n",
      "trainer/Z Policy Predictions Max     1780.02\n",
      "trainer/Z Policy Predictions Min     -200.028\n",
      "trainer/Z Expert Targets Mean        1527.44\n",
      "trainer/Z Expert Targets Std          174.521\n",
      "trainer/Z Expert Targets Max         1775.07\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1371.46\n",
      "trainer/Z Policy Targets Std          381.355\n",
      "trainer/Z Policy Targets Max         1769.2\n",
      "trainer/Z Policy Targets Min         -225.035\n",
      "trainer/Log Pis Mean                   19.5302\n",
      "trainer/Log Pis Std                     3.91633\n",
      "trainer/Policy mu Mean                  1.17319\n",
      "trainer/Policy mu Std                   1.84431\n",
      "trainer/Policy log std Mean            -2.23629\n",
      "trainer/Policy log std Std              1.17043\n",
      "trainer/Alpha                           0.137565\n",
      "trainer/Alpha Loss                      0.0646269\n",
      "exploration/num steps total        174001\n",
      "exploration/num paths total           754\n",
      "evaluation/num steps total              1.31707e+06\n",
      "evaluation/num paths total           1693\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18771\n",
      "evaluation/Rewards Std                  1.30934\n",
      "evaluation/Rewards Max                  7.27431\n",
      "evaluation/Rewards Min                  0.134894\n",
      "evaluation/Returns Mean              5187.71\n",
      "evaluation/Returns Std                 20.6936\n",
      "evaluation/Returns Max               5223.41\n",
      "evaluation/Returns Min               5157.4\n",
      "evaluation/Estimation Bias Mean      1543.78\n",
      "evaluation/Estimation Bias Std        168.95\n",
      "evaluation/EB/Q_True Mean              48.9512\n",
      "evaluation/EB/Q_True Std              151.252\n",
      "evaluation/EB/Q_Pred Mean            1592.73\n",
      "evaluation/EB/Q_Pred Std               77.2943\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5187.71\n",
      "evaluation/Actions Mean                 0.509299\n",
      "evaluation/Actions Std                  0.634904\n",
      "evaluation/Actions Max                  0.999993\n",
      "evaluation/Actions Min                 -0.999981\n",
      "time/backward_policy (s)                1.86208\n",
      "time/backward_zf1 (s)                   1.98777\n",
      "time/backward_zf2 (s)                   1.93723\n",
      "time/data sampling (s)                  0.246517\n",
      "time/data storing (s)                   0.0142568\n",
      "time/evaluation sampling (s)            1.41016\n",
      "time/exploration sampling (s)           0.194617\n",
      "time/logging (s)                        0.0123112\n",
      "time/preback_alpha (s)                  0.994454\n",
      "time/preback_policy (s)                 1.11997\n",
      "time/preback_start (s)                  0.120632\n",
      "time/preback_zf (s)                     5.07201\n",
      "time/saving (s)                         0.00550727\n",
      "time/training (s)                       2.14028\n",
      "time/epoch (s)                         17.1178\n",
      "time/total (s)                       2948.18\n",
      "Epoch                                 168\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:00:00.933339 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 169 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 180000\n",
      "trainer/ZF1 Loss                       40.6732\n",
      "trainer/ZF2 Loss                       32.6854\n",
      "trainer/ZF Expert Reward               21.7404\n",
      "trainer/ZF Policy Reward                8.37175\n",
      "trainer/ZF CHI2 Term                   69.2711\n",
      "trainer/Policy Loss                 -1375.18\n",
      "trainer/Bias Loss                     163.707\n",
      "trainer/Bias Value                     20.4072\n",
      "trainer/Policy Grad Norm              209.382\n",
      "trainer/Policy Param Norm              36.6772\n",
      "trainer/Zf1 Grad Norm                2707.03\n",
      "trainer/Zf1 Param Norm                113.86\n",
      "trainer/Zf2 Grad Norm                2579.74\n",
      "trainer/Zf2 Param Norm                111.534\n",
      "trainer/Z Expert Predictions Mean    1576.1\n",
      "trainer/Z Expert Predictions Std      118.7\n",
      "trainer/Z Expert Predictions Max     1788.11\n",
      "trainer/Z Expert Predictions Min     1054.43\n",
      "trainer/Z Policy Predictions Mean    1366.27\n",
      "trainer/Z Policy Predictions Std      385.857\n",
      "trainer/Z Policy Predictions Max     1768.57\n",
      "trainer/Z Policy Predictions Min     -281.256\n",
      "trainer/Z Expert Targets Mean        1554.35\n",
      "trainer/Z Expert Targets Std          122.49\n",
      "trainer/Z Expert Targets Max         1767.44\n",
      "trainer/Z Expert Targets Min         1035.99\n",
      "trainer/Z Policy Targets Mean        1357.9\n",
      "trainer/Z Policy Targets Std          382.646\n",
      "trainer/Z Policy Targets Max         1757.07\n",
      "trainer/Z Policy Targets Min         -274.674\n",
      "trainer/Log Pis Mean                   19.4173\n",
      "trainer/Log Pis Std                     4.28606\n",
      "trainer/Policy mu Mean                  1.22948\n",
      "trainer/Policy mu Std                   1.8205\n",
      "trainer/Policy log std Mean            -2.23208\n",
      "trainer/Policy log std Std              1.12264\n",
      "trainer/Alpha                           0.140203\n",
      "trainer/Alpha Loss                      0.0816894\n",
      "exploration/num steps total        176001\n",
      "exploration/num paths total           756\n",
      "evaluation/num steps total              1.32707e+06\n",
      "evaluation/num paths total           1703\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25894\n",
      "evaluation/Rewards Std                  1.34714\n",
      "evaluation/Rewards Max                  7.40294\n",
      "evaluation/Rewards Min                  0.136702\n",
      "evaluation/Returns Mean              5258.94\n",
      "evaluation/Returns Std                 20.4359\n",
      "evaluation/Returns Max               5290.59\n",
      "evaluation/Returns Min               5212.37\n",
      "evaluation/Estimation Bias Mean      1521.14\n",
      "evaluation/Estimation Bias Std        172.414\n",
      "evaluation/EB/Q_True Mean              49.6789\n",
      "evaluation/EB/Q_True Std              153.2\n",
      "evaluation/EB/Q_Pred Mean            1570.82\n",
      "evaluation/EB/Q_Pred Std               76.7739\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5258.94\n",
      "evaluation/Actions Mean                 0.51671\n",
      "evaluation/Actions Std                  0.633367\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999885\n",
      "time/backward_policy (s)                2.02443\n",
      "time/backward_zf1 (s)                   2.16014\n",
      "time/backward_zf2 (s)                   2.10743\n",
      "time/data sampling (s)                  0.253241\n",
      "time/data storing (s)                   0.0138112\n",
      "time/evaluation sampling (s)            1.44715\n",
      "time/exploration sampling (s)           0.195036\n",
      "time/logging (s)                        0.0145861\n",
      "time/preback_alpha (s)                  1.05082\n",
      "time/preback_policy (s)                 1.20546\n",
      "time/preback_start (s)                  0.122652\n",
      "time/preback_zf (s)                     5.10444\n",
      "time/saving (s)                         0.00532449\n",
      "time/training (s)                       2.05079\n",
      "time/epoch (s)                         17.7553\n",
      "time/total (s)                       2965.96\n",
      "Epoch                                 169\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:00:18.449238 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 170 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 181000\n",
      "trainer/ZF1 Loss                       46.8004\n",
      "trainer/ZF2 Loss                       41.2126\n",
      "trainer/ZF Expert Reward               18.3573\n",
      "trainer/ZF Policy Reward                7.12436\n",
      "trainer/ZF CHI2 Term                   75.4407\n",
      "trainer/Policy Loss                 -1373.62\n",
      "trainer/Bias Loss                     176.726\n",
      "trainer/Bias Value                     20.3921\n",
      "trainer/Policy Grad Norm              336.07\n",
      "trainer/Policy Param Norm              36.7168\n",
      "trainer/Zf1 Grad Norm                4005.7\n",
      "trainer/Zf1 Param Norm                114.081\n",
      "trainer/Zf2 Grad Norm                4530.19\n",
      "trainer/Zf2 Param Norm                111.748\n",
      "trainer/Z Expert Predictions Mean    1559.96\n",
      "trainer/Z Expert Predictions Std      135.472\n",
      "trainer/Z Expert Predictions Max     1760.47\n",
      "trainer/Z Expert Predictions Min      533.99\n",
      "trainer/Z Policy Predictions Mean    1363.96\n",
      "trainer/Z Policy Predictions Std      432.988\n",
      "trainer/Z Policy Predictions Max     1762.81\n",
      "trainer/Z Policy Predictions Min     -216.141\n",
      "trainer/Z Expert Targets Mean        1541.6\n",
      "trainer/Z Expert Targets Std          136.426\n",
      "trainer/Z Expert Targets Max         1743.32\n",
      "trainer/Z Expert Targets Min          492.587\n",
      "trainer/Z Policy Targets Mean        1356.83\n",
      "trainer/Z Policy Targets Std          435.178\n",
      "trainer/Z Policy Targets Max         1760.09\n",
      "trainer/Z Policy Targets Min         -237.041\n",
      "trainer/Log Pis Mean                   20.4053\n",
      "trainer/Log Pis Std                     4.63151\n",
      "trainer/Policy mu Mean                  1.28761\n",
      "trainer/Policy mu Std                   1.87686\n",
      "trainer/Policy log std Mean            -2.20598\n",
      "trainer/Policy log std Std              1.19335\n",
      "trainer/Alpha                           0.144171\n",
      "trainer/Alpha Loss                     -0.0584287\n",
      "exploration/num steps total        176001\n",
      "exploration/num paths total           756\n",
      "evaluation/num steps total              1.33648e+06\n",
      "evaluation/num paths total           1713\n",
      "evaluation/path length Mean           941\n",
      "evaluation/path length Std            177\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            410\n",
      "evaluation/Rewards Mean                 5.21846\n",
      "evaluation/Rewards Std                  1.37513\n",
      "evaluation/Rewards Max                  7.46891\n",
      "evaluation/Rewards Min                  0.143549\n",
      "evaluation/Returns Mean              4910.57\n",
      "evaluation/Returns Std               1025.93\n",
      "evaluation/Returns Max               5276.01\n",
      "evaluation/Returns Min               1833.37\n",
      "evaluation/Estimation Bias Mean      1495.74\n",
      "evaluation/Estimation Bias Std        242.67\n",
      "evaluation/EB/Q_True Mean              52.9167\n",
      "evaluation/EB/Q_True Std              157.98\n",
      "evaluation/EB/Q_Pred Mean            1548.66\n",
      "evaluation/EB/Q_Pred Std              150.77\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4910.57\n",
      "evaluation/Actions Mean                 0.506045\n",
      "evaluation/Actions Std                  0.63943\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.89716\n",
      "time/backward_zf1 (s)                   2.0452\n",
      "time/backward_zf2 (s)                   1.98256\n",
      "time/data sampling (s)                  0.257156\n",
      "time/data storing (s)                   0.013765\n",
      "time/evaluation sampling (s)            1.48444\n",
      "time/exploration sampling (s)           0.187173\n",
      "time/logging (s)                        0.0118934\n",
      "time/preback_alpha (s)                  0.993183\n",
      "time/preback_policy (s)                 1.10865\n",
      "time/preback_start (s)                  0.124463\n",
      "time/preback_zf (s)                     5.12515\n",
      "time/saving (s)                         0.00501035\n",
      "time/training (s)                       2.21128\n",
      "time/epoch (s)                         17.4471\n",
      "time/total (s)                       2983.42\n",
      "Epoch                                 170\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:00:35.999966 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 171 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 182000\n",
      "trainer/ZF1 Loss                       67.1892\n",
      "trainer/ZF2 Loss                       73.725\n",
      "trainer/ZF Expert Reward               15.1424\n",
      "trainer/ZF Policy Reward                3.22317\n",
      "trainer/ZF CHI2 Term                  102.174\n",
      "trainer/Policy Loss                 -1328.29\n",
      "trainer/Bias Loss                     290.45\n",
      "trainer/Bias Value                     20.3779\n",
      "trainer/Policy Grad Norm              308.379\n",
      "trainer/Policy Param Norm              36.7577\n",
      "trainer/Zf1 Grad Norm                5059.97\n",
      "trainer/Zf1 Param Norm                114.304\n",
      "trainer/Zf2 Grad Norm                5476.8\n",
      "trainer/Zf2 Param Norm                111.957\n",
      "trainer/Z Expert Predictions Mean    1545.89\n",
      "trainer/Z Expert Predictions Std      112.817\n",
      "trainer/Z Expert Predictions Max     1754.31\n",
      "trainer/Z Expert Predictions Min     1081.7\n",
      "trainer/Z Policy Predictions Mean    1319.5\n",
      "trainer/Z Policy Predictions Std      442.051\n",
      "trainer/Z Policy Predictions Max     1758.38\n",
      "trainer/Z Policy Predictions Min     -240.015\n",
      "trainer/Z Expert Targets Mean        1530.75\n",
      "trainer/Z Expert Targets Std          119.005\n",
      "trainer/Z Expert Targets Max         1750.25\n",
      "trainer/Z Expert Targets Min          994.181\n",
      "trainer/Z Policy Targets Mean        1316.27\n",
      "trainer/Z Policy Targets Std          438.344\n",
      "trainer/Z Policy Targets Max         1740.03\n",
      "trainer/Z Policy Targets Min         -267.544\n",
      "trainer/Log Pis Mean                   19.9976\n",
      "trainer/Log Pis Std                     4.63677\n",
      "trainer/Policy mu Mean                  1.24635\n",
      "trainer/Policy mu Std                   1.89855\n",
      "trainer/Policy log std Mean            -2.21658\n",
      "trainer/Policy log std Std              1.16396\n",
      "trainer/Alpha                           0.143747\n",
      "trainer/Alpha Loss                      0.00034059\n",
      "exploration/num steps total        176001\n",
      "exploration/num paths total           756\n",
      "evaluation/num steps total              1.34648e+06\n",
      "evaluation/num paths total           1723\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2692\n",
      "evaluation/Rewards Std                  1.35224\n",
      "evaluation/Rewards Max                  7.46595\n",
      "evaluation/Rewards Min                  0.112232\n",
      "evaluation/Returns Mean              5269.2\n",
      "evaluation/Returns Std                 14.7748\n",
      "evaluation/Returns Max               5298.98\n",
      "evaluation/Returns Min               5247.07\n",
      "evaluation/Estimation Bias Mean      1521.01\n",
      "evaluation/Estimation Bias Std        169.763\n",
      "evaluation/EB/Q_True Mean              49.7482\n",
      "evaluation/EB/Q_True Std              153.638\n",
      "evaluation/EB/Q_Pred Mean            1570.75\n",
      "evaluation/EB/Q_Pred Std               81.4584\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5269.2\n",
      "evaluation/Actions Mean                 0.513151\n",
      "evaluation/Actions Std                  0.640627\n",
      "evaluation/Actions Max                  0.999994\n",
      "evaluation/Actions Min                 -0.999953\n",
      "time/backward_policy (s)                1.91413\n",
      "time/backward_zf1 (s)                   2.07458\n",
      "time/backward_zf2 (s)                   1.99287\n",
      "time/data sampling (s)                  0.259809\n",
      "time/data storing (s)                   0.0143284\n",
      "time/evaluation sampling (s)            1.40914\n",
      "time/exploration sampling (s)           0.192222\n",
      "time/logging (s)                        0.0116148\n",
      "time/preback_alpha (s)                  1.01459\n",
      "time/preback_policy (s)                 1.12145\n",
      "time/preback_start (s)                  0.125967\n",
      "time/preback_zf (s)                     5.1248\n",
      "time/saving (s)                         0.00549391\n",
      "time/training (s)                       2.223\n",
      "time/epoch (s)                         17.484\n",
      "time/total (s)                       3000.92\n",
      "Epoch                                 171\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:00:53.272650 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 172 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 183000\n",
      "trainer/ZF1 Loss                       38.3535\n",
      "trainer/ZF2 Loss                       46.3022\n",
      "trainer/ZF Expert Reward               18.7957\n",
      "trainer/ZF Policy Reward                1.74441\n",
      "trainer/ZF CHI2 Term                   79.0492\n",
      "trainer/Policy Loss                 -1312.18\n",
      "trainer/Bias Loss                     204.787\n",
      "trainer/Bias Value                     20.3634\n",
      "trainer/Policy Grad Norm              271.231\n",
      "trainer/Policy Param Norm              36.8019\n",
      "trainer/Zf1 Grad Norm                3256.14\n",
      "trainer/Zf1 Param Norm                114.514\n",
      "trainer/Zf2 Grad Norm                4992.27\n",
      "trainer/Zf2 Param Norm                112.175\n",
      "trainer/Z Expert Predictions Mean    1543.22\n",
      "trainer/Z Expert Predictions Std      127.4\n",
      "trainer/Z Expert Predictions Max     1768.91\n",
      "trainer/Z Expert Predictions Min      633.156\n",
      "trainer/Z Policy Predictions Mean    1304.64\n",
      "trainer/Z Policy Predictions Std      458.897\n",
      "trainer/Z Policy Predictions Max     1761.22\n",
      "trainer/Z Policy Predictions Min     -231.149\n",
      "trainer/Z Expert Targets Mean        1524.42\n",
      "trainer/Z Expert Targets Std          131.518\n",
      "trainer/Z Expert Targets Max         1757.62\n",
      "trainer/Z Expert Targets Min          581.446\n",
      "trainer/Z Policy Targets Mean        1302.9\n",
      "trainer/Z Policy Targets Std          454.518\n",
      "trainer/Z Policy Targets Max         1743.86\n",
      "trainer/Z Policy Targets Min         -197.686\n",
      "trainer/Log Pis Mean                   19.8688\n",
      "trainer/Log Pis Std                     4.34272\n",
      "trainer/Policy mu Mean                  1.2577\n",
      "trainer/Policy mu Std                   1.84198\n",
      "trainer/Policy log std Mean            -2.21336\n",
      "trainer/Policy log std Std              1.19644\n",
      "trainer/Alpha                           0.142857\n",
      "trainer/Alpha Loss                      0.0187466\n",
      "exploration/num steps total        176001\n",
      "exploration/num paths total           756\n",
      "evaluation/num steps total              1.35648e+06\n",
      "evaluation/num paths total           1733\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.23481\n",
      "evaluation/Rewards Std                  1.33752\n",
      "evaluation/Rewards Max                  7.36364\n",
      "evaluation/Rewards Min                  0.103574\n",
      "evaluation/Returns Mean              5234.81\n",
      "evaluation/Returns Std                 23.7876\n",
      "evaluation/Returns Max               5272.36\n",
      "evaluation/Returns Min               5208.31\n",
      "evaluation/Estimation Bias Mean      1518.7\n",
      "evaluation/Estimation Bias Std        170.675\n",
      "evaluation/EB/Q_True Mean              49.3036\n",
      "evaluation/EB/Q_True Std              152.445\n",
      "evaluation/EB/Q_Pred Mean            1568.01\n",
      "evaluation/EB/Q_Pred Std               87.599\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5234.81\n",
      "evaluation/Actions Mean                 0.5119\n",
      "evaluation/Actions Std                  0.646875\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999982\n",
      "time/backward_policy (s)                1.83539\n",
      "time/backward_zf1 (s)                   1.97674\n",
      "time/backward_zf2 (s)                   1.91091\n",
      "time/data sampling (s)                  0.239484\n",
      "time/data storing (s)                   0.0138945\n",
      "time/evaluation sampling (s)            1.42159\n",
      "time/exploration sampling (s)           0.188694\n",
      "time/logging (s)                        0.0116594\n",
      "time/preback_alpha (s)                  0.916054\n",
      "time/preback_policy (s)                 1.01472\n",
      "time/preback_start (s)                  0.121737\n",
      "time/preback_zf (s)                     5.09727\n",
      "time/saving (s)                         0.00538572\n",
      "time/training (s)                       2.45044\n",
      "time/epoch (s)                         17.204\n",
      "time/total (s)                       3018.15\n",
      "Epoch                                 172\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:01:10.463669 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 173 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 184000\n",
      "trainer/ZF1 Loss                       34.9036\n",
      "trainer/ZF2 Loss                       37.7922\n",
      "trainer/ZF Expert Reward               21.0904\n",
      "trainer/ZF Policy Reward                6.81407\n",
      "trainer/ZF CHI2 Term                   70.4936\n",
      "trainer/Policy Loss                 -1373.44\n",
      "trainer/Bias Loss                     242.791\n",
      "trainer/Bias Value                     20.3479\n",
      "trainer/Policy Grad Norm              240.681\n",
      "trainer/Policy Param Norm              36.8435\n",
      "trainer/Zf1 Grad Norm                6390.54\n",
      "trainer/Zf1 Param Norm                114.735\n",
      "trainer/Zf2 Grad Norm                7263.25\n",
      "trainer/Zf2 Param Norm                112.385\n",
      "trainer/Z Expert Predictions Mean    1539.34\n",
      "trainer/Z Expert Predictions Std      151.251\n",
      "trainer/Z Expert Predictions Max     1763.38\n",
      "trainer/Z Expert Predictions Min      228.468\n",
      "trainer/Z Policy Predictions Mean    1362.84\n",
      "trainer/Z Policy Predictions Std      381.809\n",
      "trainer/Z Policy Predictions Max     1749.82\n",
      "trainer/Z Policy Predictions Min     -305.376\n",
      "trainer/Z Expert Targets Mean        1518.25\n",
      "trainer/Z Expert Targets Std          162.324\n",
      "trainer/Z Expert Targets Max         1752.05\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1356.03\n",
      "trainer/Z Policy Targets Std          379.093\n",
      "trainer/Z Policy Targets Max         1742.01\n",
      "trainer/Z Policy Targets Min         -351.237\n",
      "trainer/Log Pis Mean                   20.0701\n",
      "trainer/Log Pis Std                     4.53333\n",
      "trainer/Policy mu Mean                  1.30323\n",
      "trainer/Policy mu Std                   1.87081\n",
      "trainer/Policy log std Mean            -2.19612\n",
      "trainer/Policy log std Std              1.15511\n",
      "trainer/Alpha                           0.145696\n",
      "trainer/Alpha Loss                     -0.010211\n",
      "exploration/num steps total        178001\n",
      "exploration/num paths total           758\n",
      "evaluation/num steps total              1.36648e+06\n",
      "evaluation/num paths total           1743\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15915\n",
      "evaluation/Rewards Std                  1.30369\n",
      "evaluation/Rewards Max                  7.33721\n",
      "evaluation/Rewards Min                  0.133026\n",
      "evaluation/Returns Mean              5159.15\n",
      "evaluation/Returns Std                 34.8956\n",
      "evaluation/Returns Max               5192.86\n",
      "evaluation/Returns Min               5067.18\n",
      "evaluation/Estimation Bias Mean      1518.74\n",
      "evaluation/Estimation Bias Std        176.685\n",
      "evaluation/EB/Q_True Mean              49.003\n",
      "evaluation/EB/Q_True Std              151.51\n",
      "evaluation/EB/Q_Pred Mean            1567.74\n",
      "evaluation/EB/Q_Pred Std               91.5242\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5159.15\n",
      "evaluation/Actions Mean                 0.500811\n",
      "evaluation/Actions Std                  0.644773\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.83039\n",
      "time/backward_zf1 (s)                   1.96346\n",
      "time/backward_zf2 (s)                   1.89757\n",
      "time/data sampling (s)                  0.241666\n",
      "time/data storing (s)                   0.013937\n",
      "time/evaluation sampling (s)            1.43648\n",
      "time/exploration sampling (s)           0.194424\n",
      "time/logging (s)                        0.0123456\n",
      "time/preback_alpha (s)                  0.958377\n",
      "time/preback_policy (s)                 1.06734\n",
      "time/preback_start (s)                  0.123733\n",
      "time/preback_zf (s)                     5.08095\n",
      "time/saving (s)                         0.00550369\n",
      "time/training (s)                       2.29983\n",
      "time/epoch (s)                         17.126\n",
      "time/total (s)                       3035.3\n",
      "Epoch                                 173\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:01:27.941037 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 174 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 185000\n",
      "trainer/ZF1 Loss                      435.785\n",
      "trainer/ZF2 Loss                      494.53\n",
      "trainer/ZF Expert Reward               14.7862\n",
      "trainer/ZF Policy Reward                0.163293\n",
      "trainer/ZF CHI2 Term                  499.619\n",
      "trainer/Policy Loss                 -1400.32\n",
      "trainer/Bias Loss                    4484.6\n",
      "trainer/Bias Value                     20.3315\n",
      "trainer/Policy Grad Norm              253.92\n",
      "trainer/Policy Param Norm              36.8837\n",
      "trainer/Zf1 Grad Norm                7611.89\n",
      "trainer/Zf1 Param Norm                114.944\n",
      "trainer/Zf2 Grad Norm                9067.55\n",
      "trainer/Zf2 Param Norm                112.59\n",
      "trainer/Z Expert Predictions Mean    1530.49\n",
      "trainer/Z Expert Predictions Std      147.278\n",
      "trainer/Z Expert Predictions Max     1766.54\n",
      "trainer/Z Expert Predictions Min      279.806\n",
      "trainer/Z Policy Predictions Mean    1384.73\n",
      "trainer/Z Policy Predictions Std      336.712\n",
      "trainer/Z Policy Predictions Max     1752.01\n",
      "trainer/Z Policy Predictions Min     -204.104\n",
      "trainer/Z Expert Targets Mean        1515.7\n",
      "trainer/Z Expert Targets Std          178.659\n",
      "trainer/Z Expert Targets Max         1753.59\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1384.57\n",
      "trainer/Z Policy Targets Std          337.483\n",
      "trainer/Z Policy Targets Max         1743.47\n",
      "trainer/Z Policy Targets Min         -227.851\n",
      "trainer/Log Pis Mean                   20.039\n",
      "trainer/Log Pis Std                     4.03679\n",
      "trainer/Policy mu Mean                  1.24132\n",
      "trainer/Policy mu Std                   1.81595\n",
      "trainer/Policy log std Mean            -2.30846\n",
      "trainer/Policy log std Std              1.19451\n",
      "trainer/Alpha                           0.1463\n",
      "trainer/Alpha Loss                     -0.00570501\n",
      "exploration/num steps total        180001\n",
      "exploration/num paths total           760\n",
      "evaluation/num steps total              1.37648e+06\n",
      "evaluation/num paths total           1753\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.28142\n",
      "evaluation/Rewards Std                  1.36772\n",
      "evaluation/Rewards Max                  7.47378\n",
      "evaluation/Rewards Min                  0.114929\n",
      "evaluation/Returns Mean              5281.42\n",
      "evaluation/Returns Std                 15.8253\n",
      "evaluation/Returns Max               5304.55\n",
      "evaluation/Returns Min               5258.01\n",
      "evaluation/Estimation Bias Mean      1489.32\n",
      "evaluation/Estimation Bias Std        176.8\n",
      "evaluation/EB/Q_True Mean              49.8182\n",
      "evaluation/EB/Q_True Std              153.741\n",
      "evaluation/EB/Q_Pred Mean            1539.14\n",
      "evaluation/EB/Q_Pred Std               88.2274\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5281.42\n",
      "evaluation/Actions Mean                 0.505563\n",
      "evaluation/Actions Std                  0.645041\n",
      "evaluation/Actions Max                  0.999981\n",
      "evaluation/Actions Min                 -0.999973\n",
      "time/backward_policy (s)                1.90245\n",
      "time/backward_zf1 (s)                   2.04202\n",
      "time/backward_zf2 (s)                   1.97976\n",
      "time/data sampling (s)                  0.256531\n",
      "time/data storing (s)                   0.0138997\n",
      "time/evaluation sampling (s)            1.48537\n",
      "time/exploration sampling (s)           0.195839\n",
      "time/logging (s)                        0.011768\n",
      "time/preback_alpha (s)                  0.987912\n",
      "time/preback_policy (s)                 1.09702\n",
      "time/preback_start (s)                  0.123102\n",
      "time/preback_zf (s)                     5.10156\n",
      "time/saving (s)                         0.00550178\n",
      "time/training (s)                       2.19405\n",
      "time/epoch (s)                         17.3968\n",
      "time/total (s)                       3052.73\n",
      "Epoch                                 174\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:01:45.575373 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 175 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 186000\n",
      "trainer/ZF1 Loss                      451.608\n",
      "trainer/ZF2 Loss                      459.482\n",
      "trainer/ZF Expert Reward               29.6117\n",
      "trainer/ZF Policy Reward                8.08405\n",
      "trainer/ZF CHI2 Term                  496.757\n",
      "trainer/Policy Loss                 -1372.69\n",
      "trainer/Bias Loss                    4425.15\n",
      "trainer/Bias Value                     20.3157\n",
      "trainer/Policy Grad Norm              327.04\n",
      "trainer/Policy Param Norm              36.9213\n",
      "trainer/Zf1 Grad Norm                5242.47\n",
      "trainer/Zf1 Param Norm                115.149\n",
      "trainer/Zf2 Grad Norm                5041.96\n",
      "trainer/Zf2 Param Norm                112.788\n",
      "trainer/Z Expert Predictions Mean    1538.73\n",
      "trainer/Z Expert Predictions Std      140.667\n",
      "trainer/Z Expert Predictions Max     1772.57\n",
      "trainer/Z Expert Predictions Min      378.334\n",
      "trainer/Z Policy Predictions Mean    1363.72\n",
      "trainer/Z Policy Predictions Std      352.344\n",
      "trainer/Z Policy Predictions Max     1752.97\n",
      "trainer/Z Policy Predictions Min     -340.859\n",
      "trainer/Z Expert Targets Mean        1509.12\n",
      "trainer/Z Expert Targets Std          172.474\n",
      "trainer/Z Expert Targets Max         1744.45\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1355.64\n",
      "trainer/Z Policy Targets Std          348.517\n",
      "trainer/Z Policy Targets Max         1739.54\n",
      "trainer/Z Policy Targets Min         -361.639\n",
      "trainer/Log Pis Mean                   19.8831\n",
      "trainer/Log Pis Std                     4.50008\n",
      "trainer/Policy mu Mean                  1.24881\n",
      "trainer/Policy mu Std                   1.84283\n",
      "trainer/Policy log std Mean            -2.21618\n",
      "trainer/Policy log std Std              1.17489\n",
      "trainer/Alpha                           0.147319\n",
      "trainer/Alpha Loss                      0.0172152\n",
      "exploration/num steps total        181001\n",
      "exploration/num paths total           761\n",
      "evaluation/num steps total              1.38648e+06\n",
      "evaluation/num paths total           1763\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.27224\n",
      "evaluation/Rewards Std                  1.37267\n",
      "evaluation/Rewards Max                  7.38653\n",
      "evaluation/Rewards Min                  0.126274\n",
      "evaluation/Returns Mean              5272.24\n",
      "evaluation/Returns Std                 11.4902\n",
      "evaluation/Returns Max               5295.36\n",
      "evaluation/Returns Min               5255.49\n",
      "evaluation/Estimation Bias Mean      1478.69\n",
      "evaluation/Estimation Bias Std        168.756\n",
      "evaluation/EB/Q_True Mean              49.8645\n",
      "evaluation/EB/Q_True Std              153.811\n",
      "evaluation/EB/Q_Pred Mean            1528.55\n",
      "evaluation/EB/Q_Pred Std               74.3791\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5272.24\n",
      "evaluation/Actions Mean                 0.506941\n",
      "evaluation/Actions Std                  0.644076\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999955\n",
      "time/backward_policy (s)                1.97393\n",
      "time/backward_zf1 (s)                   2.10006\n",
      "time/backward_zf2 (s)                   2.04922\n",
      "time/data sampling (s)                  0.255753\n",
      "time/data storing (s)                   0.0146635\n",
      "time/evaluation sampling (s)            1.43673\n",
      "time/exploration sampling (s)           0.194161\n",
      "time/logging (s)                        0.0149823\n",
      "time/preback_alpha (s)                  1.04067\n",
      "time/preback_policy (s)                 1.18727\n",
      "time/preback_start (s)                  0.123583\n",
      "time/preback_zf (s)                     5.10745\n",
      "time/saving (s)                         0.00579339\n",
      "time/training (s)                       2.06371\n",
      "time/epoch (s)                         17.568\n",
      "time/total (s)                       3070.32\n",
      "Epoch                                 175\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:02:02.775088 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 176 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 187000\n",
      "trainer/ZF1 Loss                       41.0546\n",
      "trainer/ZF2 Loss                       41.9545\n",
      "trainer/ZF Expert Reward               22.1986\n",
      "trainer/ZF Policy Reward                0.27594\n",
      "trainer/ZF CHI2 Term                   83.6102\n",
      "trainer/Policy Loss                 -1313.7\n",
      "trainer/Bias Loss                     259.919\n",
      "trainer/Bias Value                     20.3003\n",
      "trainer/Policy Grad Norm              318.966\n",
      "trainer/Policy Param Norm              36.9646\n",
      "trainer/Zf1 Grad Norm                4803.94\n",
      "trainer/Zf1 Param Norm                115.351\n",
      "trainer/Zf2 Grad Norm                6178.73\n",
      "trainer/Zf2 Param Norm                112.992\n",
      "trainer/Z Expert Predictions Mean    1517.78\n",
      "trainer/Z Expert Predictions Std      160.395\n",
      "trainer/Z Expert Predictions Max     1748.69\n",
      "trainer/Z Expert Predictions Min      144.323\n",
      "trainer/Z Policy Predictions Mean    1310.97\n",
      "trainer/Z Policy Predictions Std      402.581\n",
      "trainer/Z Policy Predictions Max     1728.86\n",
      "trainer/Z Policy Predictions Min     -270.597\n",
      "trainer/Z Expert Targets Mean        1495.58\n",
      "trainer/Z Expert Targets Std          169.939\n",
      "trainer/Z Expert Targets Max         1741.91\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1310.69\n",
      "trainer/Z Policy Targets Std          396.296\n",
      "trainer/Z Policy Targets Max         1731.56\n",
      "trainer/Z Policy Targets Min         -276.097\n",
      "trainer/Log Pis Mean                   20.3868\n",
      "trainer/Log Pis Std                     4.66738\n",
      "trainer/Policy mu Mean                  1.28469\n",
      "trainer/Policy mu Std                   1.92295\n",
      "trainer/Policy log std Mean            -2.17226\n",
      "trainer/Policy log std Std              1.1648\n",
      "trainer/Alpha                           0.145862\n",
      "trainer/Alpha Loss                     -0.056425\n",
      "exploration/num steps total        184001\n",
      "exploration/num paths total           764\n",
      "evaluation/num steps total              1.39648e+06\n",
      "evaluation/num paths total           1773\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18868\n",
      "evaluation/Rewards Std                  1.30621\n",
      "evaluation/Rewards Max                  7.28406\n",
      "evaluation/Rewards Min                  0.147688\n",
      "evaluation/Returns Mean              5188.68\n",
      "evaluation/Returns Std                 21.3157\n",
      "evaluation/Returns Max               5219.29\n",
      "evaluation/Returns Min               5150.22\n",
      "evaluation/Estimation Bias Mean      1528.43\n",
      "evaluation/Estimation Bias Std        163.538\n",
      "evaluation/EB/Q_True Mean              48.8223\n",
      "evaluation/EB/Q_True Std              150.725\n",
      "evaluation/EB/Q_Pred Mean            1577.25\n",
      "evaluation/EB/Q_Pred Std               65.0258\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5188.68\n",
      "evaluation/Actions Mean                 0.49621\n",
      "evaluation/Actions Std                  0.648349\n",
      "evaluation/Actions Max                  0.999985\n",
      "evaluation/Actions Min                 -0.999962\n",
      "time/backward_policy (s)                1.81839\n",
      "time/backward_zf1 (s)                   1.9603\n",
      "time/backward_zf2 (s)                   1.8896\n",
      "time/data sampling (s)                  0.27134\n",
      "time/data storing (s)                   0.014454\n",
      "time/evaluation sampling (s)            1.40838\n",
      "time/exploration sampling (s)           0.20141\n",
      "time/logging (s)                        0.0125659\n",
      "time/preback_alpha (s)                  0.934854\n",
      "time/preback_policy (s)                 1.0384\n",
      "time/preback_start (s)                  0.122807\n",
      "time/preback_zf (s)                     5.0978\n",
      "time/saving (s)                         0.0173856\n",
      "time/training (s)                       2.3432\n",
      "time/epoch (s)                         17.1309\n",
      "time/total (s)                       3087.47\n",
      "Epoch                                 176\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:02:20.383748 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 177 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 188000\n",
      "trainer/ZF1 Loss                      198.547\n",
      "trainer/ZF2 Loss                      159.77\n",
      "trainer/ZF Expert Reward               20.1267\n",
      "trainer/ZF Policy Reward                9.84588\n",
      "trainer/ZF CHI2 Term                  209.396\n",
      "trainer/Policy Loss                 -1336.8\n",
      "trainer/Bias Loss                     154.878\n",
      "trainer/Bias Value                     20.2865\n",
      "trainer/Policy Grad Norm              354.624\n",
      "trainer/Policy Param Norm              37.0044\n",
      "trainer/Zf1 Grad Norm                5341.6\n",
      "trainer/Zf1 Param Norm                115.572\n",
      "trainer/Zf2 Grad Norm                7360.77\n",
      "trainer/Zf2 Param Norm                113.207\n",
      "trainer/Z Expert Predictions Mean    1520.04\n",
      "trainer/Z Expert Predictions Std      127.642\n",
      "trainer/Z Expert Predictions Max     1739.98\n",
      "trainer/Z Expert Predictions Min      929.771\n",
      "trainer/Z Policy Predictions Mean    1334.19\n",
      "trainer/Z Policy Predictions Std      407.358\n",
      "trainer/Z Policy Predictions Max     1737.65\n",
      "trainer/Z Policy Predictions Min     -136.855\n",
      "trainer/Z Expert Targets Mean        1499.91\n",
      "trainer/Z Expert Targets Std          129.51\n",
      "trainer/Z Expert Targets Max         1721.97\n",
      "trainer/Z Expert Targets Min          905.431\n",
      "trainer/Z Policy Targets Mean        1324.35\n",
      "trainer/Z Policy Targets Std          407.141\n",
      "trainer/Z Policy Targets Max         1738.14\n",
      "trainer/Z Policy Targets Min         -131.068\n",
      "trainer/Log Pis Mean                   20.1582\n",
      "trainer/Log Pis Std                     4.29276\n",
      "trainer/Policy mu Mean                  1.22739\n",
      "trainer/Policy mu Std                   1.89663\n",
      "trainer/Policy log std Mean            -2.25017\n",
      "trainer/Policy log std Std              1.20195\n",
      "trainer/Alpha                           0.149723\n",
      "trainer/Alpha Loss                     -0.0236933\n",
      "exploration/num steps total        184001\n",
      "exploration/num paths total           764\n",
      "evaluation/num steps total              1.40648e+06\n",
      "evaluation/num paths total           1783\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25748\n",
      "evaluation/Rewards Std                  1.3485\n",
      "evaluation/Rewards Max                  7.37999\n",
      "evaluation/Rewards Min                  0.0903984\n",
      "evaluation/Returns Mean              5257.48\n",
      "evaluation/Returns Std                 39.4309\n",
      "evaluation/Returns Max               5303.54\n",
      "evaluation/Returns Min               5162.76\n",
      "evaluation/Estimation Bias Mean      1493.86\n",
      "evaluation/Estimation Bias Std        181.271\n",
      "evaluation/EB/Q_True Mean              50.1643\n",
      "evaluation/EB/Q_True Std              155.054\n",
      "evaluation/EB/Q_Pred Mean            1544.02\n",
      "evaluation/EB/Q_Pred Std               86.571\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5257.48\n",
      "evaluation/Actions Mean                 0.510387\n",
      "evaluation/Actions Std                  0.647814\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999988\n",
      "time/backward_policy (s)                1.96228\n",
      "time/backward_zf1 (s)                   2.11337\n",
      "time/backward_zf2 (s)                   2.06459\n",
      "time/data sampling (s)                  0.26348\n",
      "time/data storing (s)                   0.0147323\n",
      "time/evaluation sampling (s)            1.39639\n",
      "time/exploration sampling (s)           0.19328\n",
      "time/logging (s)                        0.0118438\n",
      "time/preback_alpha (s)                  1.03643\n",
      "time/preback_policy (s)                 1.18427\n",
      "time/preback_start (s)                  0.122969\n",
      "time/preback_zf (s)                     5.09198\n",
      "time/saving (s)                         0.00496074\n",
      "time/training (s)                       2.07127\n",
      "time/epoch (s)                         17.5318\n",
      "time/total (s)                       3105.03\n",
      "Epoch                                 177\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:02:37.871695 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 178 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 189000\n",
      "trainer/ZF1 Loss                      418.646\n",
      "trainer/ZF2 Loss                      410.832\n",
      "trainer/ZF Expert Reward               27.109\n",
      "trainer/ZF Policy Reward                5.3555\n",
      "trainer/ZF CHI2 Term                  456.663\n",
      "trainer/Policy Loss                 -1348.16\n",
      "trainer/Bias Loss                    4027.47\n",
      "trainer/Bias Value                     20.274\n",
      "trainer/Policy Grad Norm              360.024\n",
      "trainer/Policy Param Norm              37.0466\n",
      "trainer/Zf1 Grad Norm                8429.74\n",
      "trainer/Zf1 Param Norm                115.797\n",
      "trainer/Zf2 Grad Norm               11002\n",
      "trainer/Zf2 Param Norm                113.417\n",
      "trainer/Z Expert Predictions Mean    1529.27\n",
      "trainer/Z Expert Predictions Std      105.73\n",
      "trainer/Z Expert Predictions Max     1740.99\n",
      "trainer/Z Expert Predictions Min     1070.4\n",
      "trainer/Z Policy Predictions Mean    1338.65\n",
      "trainer/Z Policy Predictions Std      395.429\n",
      "trainer/Z Policy Predictions Max     1719.71\n",
      "trainer/Z Policy Predictions Min     -251.558\n",
      "trainer/Z Expert Targets Mean        1502.16\n",
      "trainer/Z Expert Targets Std          146.402\n",
      "trainer/Z Expert Targets Max         1725.39\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1333.3\n",
      "trainer/Z Policy Targets Std          393.555\n",
      "trainer/Z Policy Targets Max         1703.92\n",
      "trainer/Z Policy Targets Min         -288.484\n",
      "trainer/Log Pis Mean                   20.3749\n",
      "trainer/Log Pis Std                     4.30397\n",
      "trainer/Policy mu Mean                  1.27066\n",
      "trainer/Policy mu Std                   1.87585\n",
      "trainer/Policy log std Mean            -2.24823\n",
      "trainer/Policy log std Std              1.13157\n",
      "trainer/Alpha                           0.152738\n",
      "trainer/Alpha Loss                     -0.057264\n",
      "exploration/num steps total        184001\n",
      "exploration/num paths total           764\n",
      "evaluation/num steps total              1.41648e+06\n",
      "evaluation/num paths total           1793\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.28454\n",
      "evaluation/Rewards Std                  1.34939\n",
      "evaluation/Rewards Max                  7.43598\n",
      "evaluation/Rewards Min                  0.136959\n",
      "evaluation/Returns Mean              5284.54\n",
      "evaluation/Returns Std                 21.4524\n",
      "evaluation/Returns Max               5320.92\n",
      "evaluation/Returns Min               5247.1\n",
      "evaluation/Estimation Bias Mean      1480.41\n",
      "evaluation/Estimation Bias Std        177.485\n",
      "evaluation/EB/Q_True Mean              50.2877\n",
      "evaluation/EB/Q_True Std              155.443\n",
      "evaluation/EB/Q_Pred Mean            1530.7\n",
      "evaluation/EB/Q_Pred Std               90.3333\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5284.54\n",
      "evaluation/Actions Mean                 0.520123\n",
      "evaluation/Actions Std                  0.642685\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999981\n",
      "time/backward_policy (s)                1.93011\n",
      "time/backward_zf1 (s)                   2.05896\n",
      "time/backward_zf2 (s)                   2.01096\n",
      "time/data sampling (s)                  0.253669\n",
      "time/data storing (s)                   0.0143502\n",
      "time/evaluation sampling (s)            1.39253\n",
      "time/exploration sampling (s)           0.190835\n",
      "time/logging (s)                        0.0118452\n",
      "time/preback_alpha (s)                  1.01797\n",
      "time/preback_policy (s)                 1.16989\n",
      "time/preback_start (s)                  0.122991\n",
      "time/preback_zf (s)                     5.14508\n",
      "time/saving (s)                         0.00530965\n",
      "time/training (s)                       2.09437\n",
      "time/epoch (s)                         17.4189\n",
      "time/total (s)                       3122.47\n",
      "Epoch                                 178\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:02:55.278486 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 179 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 190000\n",
      "trainer/ZF1 Loss                      505.952\n",
      "trainer/ZF2 Loss                      499.099\n",
      "trainer/ZF Expert Reward               30.8396\n",
      "trainer/ZF Policy Reward               21.1245\n",
      "trainer/ZF CHI2 Term                  531.98\n",
      "trainer/Policy Loss                 -1326.14\n",
      "trainer/Bias Loss                     236.952\n",
      "trainer/Bias Value                     20.2608\n",
      "trainer/Policy Grad Norm              260.952\n",
      "trainer/Policy Param Norm              37.0903\n",
      "trainer/Zf1 Grad Norm                7193.26\n",
      "trainer/Zf1 Param Norm                116.002\n",
      "trainer/Zf2 Grad Norm                5490.49\n",
      "trainer/Zf2 Param Norm                113.601\n",
      "trainer/Z Expert Predictions Mean    1525.35\n",
      "trainer/Z Expert Predictions Std      125.18\n",
      "trainer/Z Expert Predictions Max     1754.79\n",
      "trainer/Z Expert Predictions Min      627.594\n",
      "trainer/Z Policy Predictions Mean    1323.61\n",
      "trainer/Z Policy Predictions Std      424.103\n",
      "trainer/Z Policy Predictions Max     1726.63\n",
      "trainer/Z Policy Predictions Min     -315.476\n",
      "trainer/Z Expert Targets Mean        1494.51\n",
      "trainer/Z Expert Targets Std          129.691\n",
      "trainer/Z Expert Targets Max         1723.84\n",
      "trainer/Z Expert Targets Min          616.66\n",
      "trainer/Z Policy Targets Mean        1302.49\n",
      "trainer/Z Policy Targets Std          428.443\n",
      "trainer/Z Policy Targets Max         1705.88\n",
      "trainer/Z Policy Targets Min         -354.704\n",
      "trainer/Log Pis Mean                   19.9389\n",
      "trainer/Log Pis Std                     4.33655\n",
      "trainer/Policy mu Mean                  1.28472\n",
      "trainer/Policy mu Std                   1.83395\n",
      "trainer/Policy log std Mean            -2.20332\n",
      "trainer/Policy log std Std              1.19845\n",
      "trainer/Alpha                           0.15397\n",
      "trainer/Alpha Loss                      0.00940986\n",
      "exploration/num steps total        186001\n",
      "exploration/num paths total           766\n",
      "evaluation/num steps total              1.42648e+06\n",
      "evaluation/num paths total           1803\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.27076\n",
      "evaluation/Rewards Std                  1.35542\n",
      "evaluation/Rewards Max                  7.4232\n",
      "evaluation/Rewards Min                  0.137648\n",
      "evaluation/Returns Mean              5270.76\n",
      "evaluation/Returns Std                 15.5227\n",
      "evaluation/Returns Max               5294.96\n",
      "evaluation/Returns Min               5248.42\n",
      "evaluation/Estimation Bias Mean      1485.27\n",
      "evaluation/Estimation Bias Std        173.42\n",
      "evaluation/EB/Q_True Mean              49.7995\n",
      "evaluation/EB/Q_True Std              153.846\n",
      "evaluation/EB/Q_Pred Mean            1535.07\n",
      "evaluation/EB/Q_Pred Std               70.6238\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5270.76\n",
      "evaluation/Actions Mean                 0.508623\n",
      "evaluation/Actions Std                  0.645461\n",
      "evaluation/Actions Max                  0.999987\n",
      "evaluation/Actions Min                 -0.99994\n",
      "time/backward_policy (s)                1.86165\n",
      "time/backward_zf1 (s)                   2.02528\n",
      "time/backward_zf2 (s)                   1.95596\n",
      "time/data sampling (s)                  0.257844\n",
      "time/data storing (s)                   0.014331\n",
      "time/evaluation sampling (s)            1.40862\n",
      "time/exploration sampling (s)           0.196621\n",
      "time/logging (s)                        0.0116579\n",
      "time/preback_alpha (s)                  0.945617\n",
      "time/preback_policy (s)                 1.05079\n",
      "time/preback_start (s)                  0.123786\n",
      "time/preback_zf (s)                     5.10972\n",
      "time/saving (s)                         0.0052385\n",
      "time/training (s)                       2.3629\n",
      "time/epoch (s)                         17.33\n",
      "time/total (s)                       3139.83\n",
      "Epoch                                 179\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:03:12.706600 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 180 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 191000\n",
      "trainer/ZF1 Loss                       41.7555\n",
      "trainer/ZF2 Loss                       38.6452\n",
      "trainer/ZF Expert Reward               21.7451\n",
      "trainer/ZF Policy Reward                6.05901\n",
      "trainer/ZF CHI2 Term                   75.7813\n",
      "trainer/Policy Loss                 -1321.23\n",
      "trainer/Bias Loss                     269.184\n",
      "trainer/Bias Value                     20.2489\n",
      "trainer/Policy Grad Norm              294.576\n",
      "trainer/Policy Param Norm              37.1318\n",
      "trainer/Zf1 Grad Norm                7726.88\n",
      "trainer/Zf1 Param Norm                116.187\n",
      "trainer/Zf2 Grad Norm                4532.41\n",
      "trainer/Zf2 Param Norm                113.79\n",
      "trainer/Z Expert Predictions Mean    1508.09\n",
      "trainer/Z Expert Predictions Std      157.599\n",
      "trainer/Z Expert Predictions Max     1726.88\n",
      "trainer/Z Expert Predictions Min      208.357\n",
      "trainer/Z Policy Predictions Mean    1313.85\n",
      "trainer/Z Policy Predictions Std      366.552\n",
      "trainer/Z Policy Predictions Max     1706.53\n",
      "trainer/Z Policy Predictions Min     -220.648\n",
      "trainer/Z Expert Targets Mean        1486.35\n",
      "trainer/Z Expert Targets Std          167.814\n",
      "trainer/Z Expert Targets Max         1718.64\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1307.79\n",
      "trainer/Z Policy Targets Std          358.667\n",
      "trainer/Z Policy Targets Max         1695.7\n",
      "trainer/Z Policy Targets Min         -193.692\n",
      "trainer/Log Pis Mean                   20.0958\n",
      "trainer/Log Pis Std                     4.06358\n",
      "trainer/Policy mu Mean                  1.33495\n",
      "trainer/Policy mu Std                   1.85721\n",
      "trainer/Policy log std Mean            -2.21806\n",
      "trainer/Policy log std Std              1.16618\n",
      "trainer/Alpha                           0.153599\n",
      "trainer/Alpha Loss                     -0.0147181\n",
      "exploration/num steps total        186001\n",
      "exploration/num paths total           766\n",
      "evaluation/num steps total              1.43648e+06\n",
      "evaluation/num paths total           1813\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25169\n",
      "evaluation/Rewards Std                  1.34129\n",
      "evaluation/Rewards Max                  7.31502\n",
      "evaluation/Rewards Min                  0.137379\n",
      "evaluation/Returns Mean              5251.69\n",
      "evaluation/Returns Std                 11.1085\n",
      "evaluation/Returns Max               5269.89\n",
      "evaluation/Returns Min               5236.51\n",
      "evaluation/Estimation Bias Mean      1463.26\n",
      "evaluation/Estimation Bias Std        173.143\n",
      "evaluation/EB/Q_True Mean              49.6939\n",
      "evaluation/EB/Q_True Std              153.423\n",
      "evaluation/EB/Q_Pred Mean            1512.95\n",
      "evaluation/EB/Q_Pred Std               80.4904\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5251.69\n",
      "evaluation/Actions Mean                 0.516325\n",
      "evaluation/Actions Std                  0.643127\n",
      "evaluation/Actions Max                  0.999981\n",
      "evaluation/Actions Min                 -0.999913\n",
      "time/backward_policy (s)                1.87818\n",
      "time/backward_zf1 (s)                   2.01855\n",
      "time/backward_zf2 (s)                   1.96199\n",
      "time/data sampling (s)                  0.254741\n",
      "time/data storing (s)                   0.0137166\n",
      "time/evaluation sampling (s)            1.42457\n",
      "time/exploration sampling (s)           0.18746\n",
      "time/logging (s)                        0.0115231\n",
      "time/preback_alpha (s)                  1.00163\n",
      "time/preback_policy (s)                 1.14192\n",
      "time/preback_start (s)                  0.122925\n",
      "time/preback_zf (s)                     5.13806\n",
      "time/saving (s)                         0.00523716\n",
      "time/training (s)                       2.20237\n",
      "time/epoch (s)                         17.3629\n",
      "time/total (s)                       3157.21\n",
      "Epoch                                 180\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:03:30.318007 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 181 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 192000\n",
      "trainer/ZF1 Loss                      459.424\n",
      "trainer/ZF2 Loss                      468.12\n",
      "trainer/ZF Expert Reward               17.1334\n",
      "trainer/ZF Policy Reward                7.13822\n",
      "trainer/ZF CHI2 Term                  494.225\n",
      "trainer/Policy Loss                 -1336.52\n",
      "trainer/Bias Loss                      90.2512\n",
      "trainer/Bias Value                     20.2365\n",
      "trainer/Policy Grad Norm              264.405\n",
      "trainer/Policy Param Norm              37.1755\n",
      "trainer/Zf1 Grad Norm                3789.14\n",
      "trainer/Zf1 Param Norm                116.386\n",
      "trainer/Zf2 Grad Norm                4723.82\n",
      "trainer/Zf2 Param Norm                113.98\n",
      "trainer/Z Expert Predictions Mean    1503.08\n",
      "trainer/Z Expert Predictions Std      126.616\n",
      "trainer/Z Expert Predictions Max     1725.06\n",
      "trainer/Z Expert Predictions Min      587.429\n",
      "trainer/Z Policy Predictions Mean    1328.01\n",
      "trainer/Z Policy Predictions Std      365.494\n",
      "trainer/Z Policy Predictions Max     1697.86\n",
      "trainer/Z Policy Predictions Min     -275.807\n",
      "trainer/Z Expert Targets Mean        1485.94\n",
      "trainer/Z Expert Targets Std          130.562\n",
      "trainer/Z Expert Targets Max         1716.1\n",
      "trainer/Z Expert Targets Min          553.349\n",
      "trainer/Z Policy Targets Mean        1320.87\n",
      "trainer/Z Policy Targets Std          368.173\n",
      "trainer/Z Policy Targets Max         1696.25\n",
      "trainer/Z Policy Targets Min         -291.504\n",
      "trainer/Log Pis Mean                   20.6641\n",
      "trainer/Log Pis Std                     3.85676\n",
      "trainer/Policy mu Mean                  1.3018\n",
      "trainer/Policy mu Std                   1.90545\n",
      "trainer/Policy log std Mean            -2.20772\n",
      "trainer/Policy log std Std              1.17941\n",
      "trainer/Alpha                           0.151476\n",
      "trainer/Alpha Loss                     -0.100587\n",
      "exploration/num steps total        186001\n",
      "exploration/num paths total           766\n",
      "evaluation/num steps total              1.445e+06\n",
      "evaluation/num paths total           1823\n",
      "evaluation/path length Mean           852.7\n",
      "evaluation/path length Std            194.902\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            439\n",
      "evaluation/Rewards Mean                 5.15442\n",
      "evaluation/Rewards Std                  1.41245\n",
      "evaluation/Rewards Max                  7.26388\n",
      "evaluation/Rewards Min                  0.112917\n",
      "evaluation/Returns Mean              4395.17\n",
      "evaluation/Returns Std               1132.13\n",
      "evaluation/Returns Max               5264.2\n",
      "evaluation/Returns Min               2009.71\n",
      "evaluation/Estimation Bias Mean      1396.27\n",
      "evaluation/Estimation Bias Std        335.915\n",
      "evaluation/EB/Q_True Mean              58.2104\n",
      "evaluation/EB/Q_True Std              164.467\n",
      "evaluation/EB/Q_Pred Mean            1454.48\n",
      "evaluation/EB/Q_Pred Std              278.876\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4395.17\n",
      "evaluation/Actions Mean                 0.495158\n",
      "evaluation/Actions Std                  0.65589\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.98355\n",
      "time/backward_zf1 (s)                   2.1078\n",
      "time/backward_zf2 (s)                   2.06359\n",
      "time/data sampling (s)                  0.242591\n",
      "time/data storing (s)                   0.0152282\n",
      "time/evaluation sampling (s)            1.38784\n",
      "time/exploration sampling (s)           0.196318\n",
      "time/logging (s)                        0.0104665\n",
      "time/preback_alpha (s)                  1.03158\n",
      "time/preback_policy (s)                 1.17306\n",
      "time/preback_start (s)                  0.123066\n",
      "time/preback_zf (s)                     5.09452\n",
      "time/saving (s)                         0.00536755\n",
      "time/training (s)                       2.1113\n",
      "time/epoch (s)                         17.5463\n",
      "time/total (s)                       3174.77\n",
      "Epoch                                 181\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:03:47.743515 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 182 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 193000\n",
      "trainer/ZF1 Loss                       41.7498\n",
      "trainer/ZF2 Loss                       37.3821\n",
      "trainer/ZF Expert Reward               16.8789\n",
      "trainer/ZF Policy Reward                0.5472\n",
      "trainer/ZF CHI2 Term                   75.5464\n",
      "trainer/Policy Loss                 -1358.9\n",
      "trainer/Bias Loss                     228.761\n",
      "trainer/Bias Value                     20.2208\n",
      "trainer/Policy Grad Norm              288.299\n",
      "trainer/Policy Param Norm              37.221\n",
      "trainer/Zf1 Grad Norm                6054.16\n",
      "trainer/Zf1 Param Norm                116.569\n",
      "trainer/Zf2 Grad Norm                5417.29\n",
      "trainer/Zf2 Param Norm                114.167\n",
      "trainer/Z Expert Predictions Mean    1491.82\n",
      "trainer/Z Expert Predictions Std      146.774\n",
      "trainer/Z Expert Predictions Max     1718.09\n",
      "trainer/Z Expert Predictions Min      137.729\n",
      "trainer/Z Policy Predictions Mean    1345.11\n",
      "trainer/Z Policy Predictions Std      327.699\n",
      "trainer/Z Policy Predictions Max     1705.37\n",
      "trainer/Z Policy Predictions Min     -205.79\n",
      "trainer/Z Expert Targets Mean        1474.94\n",
      "trainer/Z Expert Targets Std          154.991\n",
      "trainer/Z Expert Targets Max         1703.3\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1344.56\n",
      "trainer/Z Policy Targets Std          324.964\n",
      "trainer/Z Policy Targets Max         1698.87\n",
      "trainer/Z Policy Targets Min         -268.786\n",
      "trainer/Log Pis Mean                   19.8473\n",
      "trainer/Log Pis Std                     4.34832\n",
      "trainer/Policy mu Mean                  1.17764\n",
      "trainer/Policy mu Std                   1.85185\n",
      "trainer/Policy log std Mean            -2.26692\n",
      "trainer/Policy log std Std              1.15582\n",
      "trainer/Alpha                           0.15211\n",
      "trainer/Alpha Loss                      0.0232301\n",
      "exploration/num steps total        186001\n",
      "exploration/num paths total           766\n",
      "evaluation/num steps total              1.45405e+06\n",
      "evaluation/num paths total           1833\n",
      "evaluation/path length Mean           904.9\n",
      "evaluation/path length Std            190.216\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            519\n",
      "evaluation/Rewards Mean                 5.1784\n",
      "evaluation/Rewards Std                  1.39049\n",
      "evaluation/Rewards Max                  7.36319\n",
      "evaluation/Rewards Min                  0.129885\n",
      "evaluation/Returns Mean              4685.94\n",
      "evaluation/Returns Std               1098.12\n",
      "evaluation/Returns Max               5272.12\n",
      "evaluation/Returns Min               2454.05\n",
      "evaluation/Estimation Bias Mean      1439.23\n",
      "evaluation/Estimation Bias Std        257.404\n",
      "evaluation/EB/Q_True Mean              55.1359\n",
      "evaluation/EB/Q_True Std              161.068\n",
      "evaluation/EB/Q_Pred Mean            1494.36\n",
      "evaluation/EB/Q_Pred Std              170.934\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4685.94\n",
      "evaluation/Actions Mean                 0.508501\n",
      "evaluation/Actions Std                  0.64843\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.93189\n",
      "time/backward_zf1 (s)                   2.06284\n",
      "time/backward_zf2 (s)                   2.00805\n",
      "time/data sampling (s)                  0.262107\n",
      "time/data storing (s)                   0.0138461\n",
      "time/evaluation sampling (s)            1.42286\n",
      "time/exploration sampling (s)           0.191664\n",
      "time/logging (s)                        0.0122722\n",
      "time/preback_alpha (s)                  1.02362\n",
      "time/preback_policy (s)                 1.15542\n",
      "time/preback_start (s)                  0.121696\n",
      "time/preback_zf (s)                     5.06539\n",
      "time/saving (s)                         0.00525796\n",
      "time/training (s)                       2.08033\n",
      "time/epoch (s)                         17.3573\n",
      "time/total (s)                       3192.15\n",
      "Epoch                                 182\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:04:05.427126 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 183 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 194000\n",
      "trainer/ZF1 Loss                       10.5801\n",
      "trainer/ZF2 Loss                       17.8394\n",
      "trainer/ZF Expert Reward               17.6628\n",
      "trainer/ZF Policy Reward                0.684265\n",
      "trainer/ZF CHI2 Term                   51.1947\n",
      "trainer/Policy Loss                 -1316.34\n",
      "trainer/Bias Loss                     134.864\n",
      "trainer/Bias Value                     20.2086\n",
      "trainer/Policy Grad Norm              284.781\n",
      "trainer/Policy Param Norm              37.2644\n",
      "trainer/Zf1 Grad Norm                2431.98\n",
      "trainer/Zf1 Param Norm                116.771\n",
      "trainer/Zf2 Grad Norm                3429.73\n",
      "trainer/Zf2 Param Norm                114.369\n",
      "trainer/Z Expert Predictions Mean    1497.68\n",
      "trainer/Z Expert Predictions Std      120.465\n",
      "trainer/Z Expert Predictions Max     1704.14\n",
      "trainer/Z Expert Predictions Min      853.973\n",
      "trainer/Z Policy Predictions Mean    1305.93\n",
      "trainer/Z Policy Predictions Std      362.148\n",
      "trainer/Z Policy Predictions Max     1679.5\n",
      "trainer/Z Policy Predictions Min     -132.068\n",
      "trainer/Z Expert Targets Mean        1480.02\n",
      "trainer/Z Expert Targets Std          125.356\n",
      "trainer/Z Expert Targets Max         1690.05\n",
      "trainer/Z Expert Targets Min          789.639\n",
      "trainer/Z Policy Targets Mean        1305.25\n",
      "trainer/Z Policy Targets Std          356.664\n",
      "trainer/Z Policy Targets Max         1678.11\n",
      "trainer/Z Policy Targets Min         -144.743\n",
      "trainer/Log Pis Mean                   20.2086\n",
      "trainer/Log Pis Std                     4.39288\n",
      "trainer/Policy mu Mean                  1.30967\n",
      "trainer/Policy mu Std                   1.88744\n",
      "trainer/Policy log std Mean            -2.16221\n",
      "trainer/Policy log std Std              1.19194\n",
      "trainer/Alpha                           0.152839\n",
      "trainer/Alpha Loss                     -0.0318777\n",
      "exploration/num steps total        188001\n",
      "exploration/num paths total           768\n",
      "evaluation/num steps total              1.4628e+06\n",
      "evaluation/num paths total           1845\n",
      "evaluation/path length Mean           728.583\n",
      "evaluation/path length Std            213.595\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            397\n",
      "evaluation/Rewards Mean                 4.9444\n",
      "evaluation/Rewards Std                  1.42829\n",
      "evaluation/Rewards Max                  7.27384\n",
      "evaluation/Rewards Min                  0.133748\n",
      "evaluation/Returns Mean              3602.4\n",
      "evaluation/Returns Std               1189.74\n",
      "evaluation/Returns Max               5146.13\n",
      "evaluation/Returns Min               1711\n",
      "evaluation/Estimation Bias Mean      1338.37\n",
      "evaluation/Estimation Bias Std        419.323\n",
      "evaluation/EB/Q_True Mean              54.6877\n",
      "evaluation/EB/Q_True Std              156.562\n",
      "evaluation/EB/Q_Pred Mean            1393.06\n",
      "evaluation/EB/Q_Pred Std              365.318\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3602.4\n",
      "evaluation/Actions Mean                 0.484692\n",
      "evaluation/Actions Std                  0.653262\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.9683\n",
      "time/backward_zf1 (s)                   2.10636\n",
      "time/backward_zf2 (s)                   2.0581\n",
      "time/data sampling (s)                  0.268823\n",
      "time/data storing (s)                   0.0142359\n",
      "time/evaluation sampling (s)            1.43961\n",
      "time/exploration sampling (s)           0.201043\n",
      "time/logging (s)                        0.0104308\n",
      "time/preback_alpha (s)                  1.03493\n",
      "time/preback_policy (s)                 1.18418\n",
      "time/preback_start (s)                  0.123542\n",
      "time/preback_zf (s)                     5.10385\n",
      "time/saving (s)                         0.00524986\n",
      "time/training (s)                       2.08693\n",
      "time/epoch (s)                         17.6056\n",
      "time/total (s)                       3209.78\n",
      "Epoch                                 183\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:04:22.805299 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 184 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 195000\n",
      "trainer/ZF1 Loss                       27.6902\n",
      "trainer/ZF2 Loss                       37.0287\n",
      "trainer/ZF Expert Reward               19.8467\n",
      "trainer/ZF Policy Reward                4.05809\n",
      "trainer/ZF CHI2 Term                   67.9263\n",
      "trainer/Policy Loss                 -1315.25\n",
      "trainer/Bias Loss                     138.543\n",
      "trainer/Bias Value                     20.1946\n",
      "trainer/Policy Grad Norm              270.054\n",
      "trainer/Policy Param Norm              37.3073\n",
      "trainer/Zf1 Grad Norm                3060.63\n",
      "trainer/Zf1 Param Norm                116.976\n",
      "trainer/Zf2 Grad Norm                4022.71\n",
      "trainer/Zf2 Param Norm                114.562\n",
      "trainer/Z Expert Predictions Mean    1481.56\n",
      "trainer/Z Expert Predictions Std      127.796\n",
      "trainer/Z Expert Predictions Max     1688.16\n",
      "trainer/Z Expert Predictions Min      947.588\n",
      "trainer/Z Policy Predictions Mean    1308.96\n",
      "trainer/Z Policy Predictions Std      370.74\n",
      "trainer/Z Policy Predictions Max     1678.82\n",
      "trainer/Z Policy Predictions Min     -277.756\n",
      "trainer/Z Expert Targets Mean        1461.72\n",
      "trainer/Z Expert Targets Std          132.482\n",
      "trainer/Z Expert Targets Max         1677.48\n",
      "trainer/Z Expert Targets Min          829.117\n",
      "trainer/Z Policy Targets Mean        1304.9\n",
      "trainer/Z Policy Targets Std          367.338\n",
      "trainer/Z Policy Targets Max         1663.74\n",
      "trainer/Z Policy Targets Min         -283.516\n",
      "trainer/Log Pis Mean                   19.9781\n",
      "trainer/Log Pis Std                     4.54517\n",
      "trainer/Policy mu Mean                  1.31096\n",
      "trainer/Policy mu Std                   1.81199\n",
      "trainer/Policy log std Mean            -2.26293\n",
      "trainer/Policy log std Std              1.17358\n",
      "trainer/Alpha                           0.155548\n",
      "trainer/Alpha Loss                      0.0034074\n",
      "exploration/num steps total        190001\n",
      "exploration/num paths total           770\n",
      "evaluation/num steps total              1.47246e+06\n",
      "evaluation/num paths total           1855\n",
      "evaluation/path length Mean           966.2\n",
      "evaluation/path length Std            101.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            662\n",
      "evaluation/Rewards Mean                 5.10726\n",
      "evaluation/Rewards Std                  1.31842\n",
      "evaluation/Rewards Max                  7.10001\n",
      "evaluation/Rewards Min                  0.121418\n",
      "evaluation/Returns Mean              4934.63\n",
      "evaluation/Returns Std                563.718\n",
      "evaluation/Returns Max               5146.33\n",
      "evaluation/Returns Min               3244.02\n",
      "evaluation/Estimation Bias Mean      1462.85\n",
      "evaluation/Estimation Bias Std        213.634\n",
      "evaluation/EB/Q_True Mean              49.865\n",
      "evaluation/EB/Q_True Std              151.194\n",
      "evaluation/EB/Q_Pred Mean            1512.71\n",
      "evaluation/EB/Q_Pred Std              113.056\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4934.63\n",
      "evaluation/Actions Mean                 0.486991\n",
      "evaluation/Actions Std                  0.655793\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.8573\n",
      "time/backward_zf1 (s)                   2.01458\n",
      "time/backward_zf2 (s)                   1.9362\n",
      "time/data sampling (s)                  0.268248\n",
      "time/data storing (s)                   0.0141171\n",
      "time/evaluation sampling (s)            1.42988\n",
      "time/exploration sampling (s)           0.202387\n",
      "time/logging (s)                        0.0116863\n",
      "time/preback_alpha (s)                  0.975822\n",
      "time/preback_policy (s)                 1.08442\n",
      "time/preback_start (s)                  0.123469\n",
      "time/preback_zf (s)                     5.12051\n",
      "time/saving (s)                         0.00542305\n",
      "time/training (s)                       2.26932\n",
      "time/epoch (s)                         17.3134\n",
      "time/total (s)                       3227.12\n",
      "Epoch                                 184\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:04:40.035116 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 185 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 196000\n",
      "trainer/ZF1 Loss                       30.8402\n",
      "trainer/ZF2 Loss                       39.5016\n",
      "trainer/ZF Expert Reward               18.1305\n",
      "trainer/ZF Policy Reward                3.07928\n",
      "trainer/ZF CHI2 Term                   69.8621\n",
      "trainer/Policy Loss                 -1333.83\n",
      "trainer/Bias Loss                     220.411\n",
      "trainer/Bias Value                     20.1791\n",
      "trainer/Policy Grad Norm              263.53\n",
      "trainer/Policy Param Norm              37.3518\n",
      "trainer/Zf1 Grad Norm                3770.46\n",
      "trainer/Zf1 Param Norm                117.17\n",
      "trainer/Zf2 Grad Norm                4875.81\n",
      "trainer/Zf2 Param Norm                114.751\n",
      "trainer/Z Expert Predictions Mean    1474.06\n",
      "trainer/Z Expert Predictions Std      149.308\n",
      "trainer/Z Expert Predictions Max     1664.04\n",
      "trainer/Z Expert Predictions Min      284.89\n",
      "trainer/Z Policy Predictions Mean    1323.5\n",
      "trainer/Z Policy Predictions Std      338.304\n",
      "trainer/Z Policy Predictions Max     1662.7\n",
      "trainer/Z Policy Predictions Min     -226.085\n",
      "trainer/Z Expert Targets Mean        1455.93\n",
      "trainer/Z Expert Targets Std          157.587\n",
      "trainer/Z Expert Targets Max         1657.37\n",
      "trainer/Z Expert Targets Min          205.115\n",
      "trainer/Z Policy Targets Mean        1320.42\n",
      "trainer/Z Policy Targets Std          335.364\n",
      "trainer/Z Policy Targets Max         1652.62\n",
      "trainer/Z Policy Targets Min         -203.467\n",
      "trainer/Log Pis Mean                   19.8385\n",
      "trainer/Log Pis Std                     4.43754\n",
      "trainer/Policy mu Mean                  1.32397\n",
      "trainer/Policy mu Std                   1.83865\n",
      "trainer/Policy log std Mean            -2.18767\n",
      "trainer/Policy log std Std              1.17775\n",
      "trainer/Alpha                           0.15661\n",
      "trainer/Alpha Loss                      0.0253007\n",
      "exploration/num steps total        191001\n",
      "exploration/num paths total           771\n",
      "evaluation/num steps total              1.48195e+06\n",
      "evaluation/num paths total           1865\n",
      "evaluation/path length Mean           948.8\n",
      "evaluation/path length Std            114.994\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            627\n",
      "evaluation/Rewards Mean                 5.14575\n",
      "evaluation/Rewards Std                  1.3343\n",
      "evaluation/Rewards Max                  7.41849\n",
      "evaluation/Rewards Min                  0.110337\n",
      "evaluation/Returns Mean              4882.29\n",
      "evaluation/Returns Std                656.63\n",
      "evaluation/Returns Max               5287.14\n",
      "evaluation/Returns Min               3050.14\n",
      "evaluation/Estimation Bias Mean      1435.24\n",
      "evaluation/Estimation Bias Std        258.229\n",
      "evaluation/EB/Q_True Mean              52.7443\n",
      "evaluation/EB/Q_True Std              158.263\n",
      "evaluation/EB/Q_Pred Mean            1487.99\n",
      "evaluation/EB/Q_Pred Std              173.216\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4882.29\n",
      "evaluation/Actions Mean                 0.49503\n",
      "evaluation/Actions Std                  0.654253\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.79553\n",
      "time/backward_zf1 (s)                   1.94892\n",
      "time/backward_zf2 (s)                   1.88729\n",
      "time/data sampling (s)                  0.271652\n",
      "time/data storing (s)                   0.0153283\n",
      "time/evaluation sampling (s)            1.41626\n",
      "time/exploration sampling (s)           0.201699\n",
      "time/logging (s)                        0.0127529\n",
      "time/preback_alpha (s)                  0.927615\n",
      "time/preback_policy (s)                 1.0118\n",
      "time/preback_start (s)                  0.123715\n",
      "time/preback_zf (s)                     5.10866\n",
      "time/saving (s)                         0.0051733\n",
      "time/training (s)                       2.43807\n",
      "time/epoch (s)                         17.1645\n",
      "time/total (s)                       3244.3\n",
      "Epoch                                 185\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:04:57.571227 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 186 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 197000\n",
      "trainer/ZF1 Loss                       31.8358\n",
      "trainer/ZF2 Loss                       30.3194\n",
      "trainer/ZF Expert Reward               22.6156\n",
      "trainer/ZF Policy Reward                7.42184\n",
      "trainer/ZF CHI2 Term                   66.0799\n",
      "trainer/Policy Loss                 -1348.57\n",
      "trainer/Bias Loss                     185.648\n",
      "trainer/Bias Value                     20.1673\n",
      "trainer/Policy Grad Norm              257.392\n",
      "trainer/Policy Param Norm              37.3911\n",
      "trainer/Zf1 Grad Norm                3533.64\n",
      "trainer/Zf1 Param Norm                117.35\n",
      "trainer/Zf2 Grad Norm                4611.46\n",
      "trainer/Zf2 Param Norm                114.938\n",
      "trainer/Z Expert Predictions Mean    1473.38\n",
      "trainer/Z Expert Predictions Std      121.882\n",
      "trainer/Z Expert Predictions Max     1678.95\n",
      "trainer/Z Expert Predictions Min      967.331\n",
      "trainer/Z Policy Predictions Mean    1339.1\n",
      "trainer/Z Policy Predictions Std      313.664\n",
      "trainer/Z Policy Predictions Max     1661.67\n",
      "trainer/Z Policy Predictions Min      -85.8725\n",
      "trainer/Z Expert Targets Mean        1450.76\n",
      "trainer/Z Expert Targets Std          126.766\n",
      "trainer/Z Expert Targets Max         1649.62\n",
      "trainer/Z Expert Targets Min          946.836\n",
      "trainer/Z Policy Targets Mean        1331.67\n",
      "trainer/Z Policy Targets Std          308.746\n",
      "trainer/Z Policy Targets Max         1636.79\n",
      "trainer/Z Policy Targets Min         -139.769\n",
      "trainer/Log Pis Mean                   20.0087\n",
      "trainer/Log Pis Std                     4.42382\n",
      "trainer/Policy mu Mean                  1.3771\n",
      "trainer/Policy mu Std                   1.86178\n",
      "trainer/Policy log std Mean            -2.0952\n",
      "trainer/Policy log std Std              1.15133\n",
      "trainer/Alpha                           0.158676\n",
      "trainer/Alpha Loss                     -0.00137574\n",
      "exploration/num steps total        194001\n",
      "exploration/num paths total           774\n",
      "evaluation/num steps total              1.49056e+06\n",
      "evaluation/num paths total           1875\n",
      "evaluation/path length Mean           861.2\n",
      "evaluation/path length Std            199.134\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            406\n",
      "evaluation/Rewards Mean                 5.13043\n",
      "evaluation/Rewards Std                  1.38396\n",
      "evaluation/Rewards Max                  7.33961\n",
      "evaluation/Rewards Min                  0.13089\n",
      "evaluation/Returns Mean              4418.33\n",
      "evaluation/Returns Std               1132.22\n",
      "evaluation/Returns Max               5256.66\n",
      "evaluation/Returns Min               1796.72\n",
      "evaluation/Estimation Bias Mean      1356.71\n",
      "evaluation/Estimation Bias Std        329.631\n",
      "evaluation/EB/Q_True Mean              57.2382\n",
      "evaluation/EB/Q_True Std              162.627\n",
      "evaluation/EB/Q_Pred Mean            1413.95\n",
      "evaluation/EB/Q_Pred Std              263.251\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4418.33\n",
      "evaluation/Actions Mean                 0.50093\n",
      "evaluation/Actions Std                  0.652709\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90362\n",
      "time/backward_zf1 (s)                   2.04019\n",
      "time/backward_zf2 (s)                   1.99511\n",
      "time/data sampling (s)                  0.271251\n",
      "time/data storing (s)                   0.0142848\n",
      "time/evaluation sampling (s)            1.45105\n",
      "time/exploration sampling (s)           0.201662\n",
      "time/logging (s)                        0.0114406\n",
      "time/preback_alpha (s)                  1.00195\n",
      "time/preback_policy (s)                 1.11783\n",
      "time/preback_start (s)                  0.124443\n",
      "time/preback_zf (s)                     5.12826\n",
      "time/saving (s)                         0.00520917\n",
      "time/training (s)                       2.20045\n",
      "time/epoch (s)                         17.4667\n",
      "time/total (s)                       3261.79\n",
      "Epoch                                 186\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:05:15.125019 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 187 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 198000\n",
      "trainer/ZF1 Loss                      411.551\n",
      "trainer/ZF2 Loss                      426.835\n",
      "trainer/ZF Expert Reward               13.7822\n",
      "trainer/ZF Policy Reward                9.34684\n",
      "trainer/ZF CHI2 Term                  443.061\n",
      "trainer/Policy Loss                 -1323.99\n",
      "trainer/Bias Loss                     211.898\n",
      "trainer/Bias Value                     20.1556\n",
      "trainer/Policy Grad Norm              403.095\n",
      "trainer/Policy Param Norm              37.434\n",
      "trainer/Zf1 Grad Norm                7206.15\n",
      "trainer/Zf1 Param Norm                117.538\n",
      "trainer/Zf2 Grad Norm                8437.47\n",
      "trainer/Zf2 Param Norm                115.13\n",
      "trainer/Z Expert Predictions Mean    1453.88\n",
      "trainer/Z Expert Predictions Std      134.098\n",
      "trainer/Z Expert Predictions Max     1662.79\n",
      "trainer/Z Expert Predictions Min      274.679\n",
      "trainer/Z Policy Predictions Mean    1320.36\n",
      "trainer/Z Policy Predictions Std      340.483\n",
      "trainer/Z Policy Predictions Max     1647.86\n",
      "trainer/Z Policy Predictions Min     -146.439\n",
      "trainer/Z Expert Targets Mean        1440.09\n",
      "trainer/Z Expert Targets Std          137.786\n",
      "trainer/Z Expert Targets Max         1629.29\n",
      "trainer/Z Expert Targets Min          233.196\n",
      "trainer/Z Policy Targets Mean        1311.02\n",
      "trainer/Z Policy Targets Std          353.133\n",
      "trainer/Z Policy Targets Max         1636.09\n",
      "trainer/Z Policy Targets Min         -152.829\n",
      "trainer/Log Pis Mean                   19.6286\n",
      "trainer/Log Pis Std                     4.58078\n",
      "trainer/Policy mu Mean                  1.26934\n",
      "trainer/Policy mu Std                   1.82209\n",
      "trainer/Policy log std Mean            -2.25231\n",
      "trainer/Policy log std Std              1.20095\n",
      "trainer/Alpha                           0.159569\n",
      "trainer/Alpha Loss                      0.0592675\n",
      "exploration/num steps total        194001\n",
      "exploration/num paths total           774\n",
      "evaluation/num steps total              1.50056e+06\n",
      "evaluation/num paths total           1885\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21584\n",
      "evaluation/Rewards Std                  1.3325\n",
      "evaluation/Rewards Max                  7.34574\n",
      "evaluation/Rewards Min                  0.129839\n",
      "evaluation/Returns Mean              5215.84\n",
      "evaluation/Returns Std                 27.491\n",
      "evaluation/Returns Max               5251.2\n",
      "evaluation/Returns Min               5152.81\n",
      "evaluation/Estimation Bias Mean      1404\n",
      "evaluation/Estimation Bias Std        173.463\n",
      "evaluation/EB/Q_True Mean              49.4985\n",
      "evaluation/EB/Q_True Std              152.844\n",
      "evaluation/EB/Q_Pred Mean            1453.5\n",
      "evaluation/EB/Q_Pred Std               81.5571\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5215.84\n",
      "evaluation/Actions Mean                 0.507842\n",
      "evaluation/Actions Std                  0.650424\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999918\n",
      "time/backward_policy (s)                1.92793\n",
      "time/backward_zf1 (s)                   2.06743\n",
      "time/backward_zf2 (s)                   1.99655\n",
      "time/data sampling (s)                  0.269122\n",
      "time/data storing (s)                   0.0149212\n",
      "time/evaluation sampling (s)            1.41147\n",
      "time/exploration sampling (s)           0.194584\n",
      "time/logging (s)                        0.0120529\n",
      "time/preback_alpha (s)                  1.02811\n",
      "time/preback_policy (s)                 1.1545\n",
      "time/preback_start (s)                  0.124013\n",
      "time/preback_zf (s)                     5.12619\n",
      "time/saving (s)                         0.00541189\n",
      "time/training (s)                       2.15133\n",
      "time/epoch (s)                         17.4836\n",
      "time/total (s)                       3279.29\n",
      "Epoch                                 187\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:05:32.938517 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 188 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 199000\n",
      "trainer/ZF1 Loss                      474.845\n",
      "trainer/ZF2 Loss                      463.743\n",
      "trainer/ZF Expert Reward               23.8348\n",
      "trainer/ZF Policy Reward               12.4604\n",
      "trainer/ZF CHI2 Term                  500.822\n",
      "trainer/Policy Loss                 -1315.51\n",
      "trainer/Bias Loss                     140.393\n",
      "trainer/Bias Value                     20.1434\n",
      "trainer/Policy Grad Norm              306.201\n",
      "trainer/Policy Param Norm              37.4786\n",
      "trainer/Zf1 Grad Norm                3977.78\n",
      "trainer/Zf1 Param Norm                117.73\n",
      "trainer/Zf2 Grad Norm                4387.89\n",
      "trainer/Zf2 Param Norm                115.318\n",
      "trainer/Z Expert Predictions Mean    1466.28\n",
      "trainer/Z Expert Predictions Std      122.392\n",
      "trainer/Z Expert Predictions Max     1673.52\n",
      "trainer/Z Expert Predictions Min      956.315\n",
      "trainer/Z Policy Predictions Mean    1311.29\n",
      "trainer/Z Policy Predictions Std      347.663\n",
      "trainer/Z Policy Predictions Max     1655.17\n",
      "trainer/Z Policy Predictions Min     -152.406\n",
      "trainer/Z Expert Targets Mean        1442.45\n",
      "trainer/Z Expert Targets Std          126.085\n",
      "trainer/Z Expert Targets Max         1651.63\n",
      "trainer/Z Expert Targets Min          921.838\n",
      "trainer/Z Policy Targets Mean        1298.83\n",
      "trainer/Z Policy Targets Std          351.675\n",
      "trainer/Z Policy Targets Max         1641.03\n",
      "trainer/Z Policy Targets Min         -169.136\n",
      "trainer/Log Pis Mean                   20.3572\n",
      "trainer/Log Pis Std                     4.54486\n",
      "trainer/Policy mu Mean                  1.30058\n",
      "trainer/Policy mu Std                   1.92878\n",
      "trainer/Policy log std Mean            -2.22716\n",
      "trainer/Policy log std Std              1.20836\n",
      "trainer/Alpha                           0.15957\n",
      "trainer/Alpha Loss                     -0.0569923\n",
      "exploration/num steps total        194001\n",
      "exploration/num paths total           774\n",
      "evaluation/num steps total              1.51056e+06\n",
      "evaluation/num paths total           1895\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18965\n",
      "evaluation/Rewards Std                  1.3155\n",
      "evaluation/Rewards Max                  7.26282\n",
      "evaluation/Rewards Min                  0.114119\n",
      "evaluation/Returns Mean              5189.65\n",
      "evaluation/Returns Std                 20.2808\n",
      "evaluation/Returns Max               5230.19\n",
      "evaluation/Returns Min               5158.43\n",
      "evaluation/Estimation Bias Mean      1458.84\n",
      "evaluation/Estimation Bias Std        162.183\n",
      "evaluation/EB/Q_True Mean              49.4562\n",
      "evaluation/EB/Q_True Std              152.709\n",
      "evaluation/EB/Q_Pred Mean            1508.29\n",
      "evaluation/EB/Q_Pred Std               63.0433\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5189.65\n",
      "evaluation/Actions Mean                 0.496741\n",
      "evaluation/Actions Std                  0.646569\n",
      "evaluation/Actions Max                  0.999987\n",
      "evaluation/Actions Min                 -0.999861\n",
      "time/backward_policy (s)                1.97971\n",
      "time/backward_zf1 (s)                   2.13071\n",
      "time/backward_zf2 (s)                   2.06473\n",
      "time/data sampling (s)                  0.272711\n",
      "time/data storing (s)                   0.01503\n",
      "time/evaluation sampling (s)            1.3752\n",
      "time/exploration sampling (s)           0.197683\n",
      "time/logging (s)                        0.0114594\n",
      "time/preback_alpha (s)                  1.02081\n",
      "time/preback_policy (s)                 1.15699\n",
      "time/preback_start (s)                  0.12597\n",
      "time/preback_zf (s)                     5.14777\n",
      "time/saving (s)                         0.00534555\n",
      "time/training (s)                       2.2425\n",
      "time/epoch (s)                         17.7466\n",
      "time/total (s)                       3297.06\n",
      "Epoch                                 188\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:05:50.412618 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 189 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 200000\n",
      "trainer/ZF1 Loss                      371.089\n",
      "trainer/ZF2 Loss                      388.739\n",
      "trainer/ZF Expert Reward               23.5214\n",
      "trainer/ZF Policy Reward               -2.47506\n",
      "trainer/ZF CHI2 Term                  425.992\n",
      "trainer/Policy Loss                 -1254.24\n",
      "trainer/Bias Loss                    3760.46\n",
      "trainer/Bias Value                     20.1303\n",
      "trainer/Policy Grad Norm              359.006\n",
      "trainer/Policy Param Norm              37.5231\n",
      "trainer/Zf1 Grad Norm                9174.2\n",
      "trainer/Zf1 Param Norm                117.935\n",
      "trainer/Zf2 Grad Norm                6242.33\n",
      "trainer/Zf2 Param Norm                115.52\n",
      "trainer/Z Expert Predictions Mean    1456.23\n",
      "trainer/Z Expert Predictions Std      129.292\n",
      "trainer/Z Expert Predictions Max     1645.37\n",
      "trainer/Z Expert Predictions Min      458.109\n",
      "trainer/Z Policy Predictions Mean    1242.74\n",
      "trainer/Z Policy Predictions Std      408.681\n",
      "trainer/Z Policy Predictions Max     1639.25\n",
      "trainer/Z Policy Predictions Min     -184.397\n",
      "trainer/Z Expert Targets Mean        1432.71\n",
      "trainer/Z Expert Targets Std          161.738\n",
      "trainer/Z Expert Targets Max         1642.83\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1245.22\n",
      "trainer/Z Policy Targets Std          405.284\n",
      "trainer/Z Policy Targets Max         1638.58\n",
      "trainer/Z Policy Targets Min         -190.869\n",
      "trainer/Log Pis Mean                   20.2846\n",
      "trainer/Log Pis Std                     4.55936\n",
      "trainer/Policy mu Mean                  1.28611\n",
      "trainer/Policy mu Std                   1.91408\n",
      "trainer/Policy log std Mean            -2.22623\n",
      "trainer/Policy log std Std              1.16189\n",
      "trainer/Alpha                           0.159418\n",
      "trainer/Alpha Loss                     -0.0453593\n",
      "exploration/num steps total        196001\n",
      "exploration/num paths total           776\n",
      "evaluation/num steps total              1.52017e+06\n",
      "evaluation/num paths total           1905\n",
      "evaluation/path length Mean           961.2\n",
      "evaluation/path length Std             71.0828\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            770\n",
      "evaluation/Rewards Mean                 4.96056\n",
      "evaluation/Rewards Std                  1.2898\n",
      "evaluation/Rewards Max                  7.11876\n",
      "evaluation/Rewards Min                  0.105059\n",
      "evaluation/Returns Mean              4768.09\n",
      "evaluation/Returns Std                402.612\n",
      "evaluation/Returns Max               5067.87\n",
      "evaluation/Returns Min               3755.07\n",
      "evaluation/Estimation Bias Mean      1341.08\n",
      "evaluation/Estimation Bias Std        251.28\n",
      "evaluation/EB/Q_True Mean              43.077\n",
      "evaluation/EB/Q_True Std              130.447\n",
      "evaluation/EB/Q_Pred Mean            1384.16\n",
      "evaluation/EB/Q_Pred Std              214.62\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4768.09\n",
      "evaluation/Actions Mean                 0.48722\n",
      "evaluation/Actions Std                  0.655431\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.90099\n",
      "time/backward_zf1 (s)                   2.02769\n",
      "time/backward_zf2 (s)                   1.99199\n",
      "time/data sampling (s)                  0.25776\n",
      "time/data storing (s)                   0.0144267\n",
      "time/evaluation sampling (s)            1.46614\n",
      "time/exploration sampling (s)           0.202877\n",
      "time/logging (s)                        0.0134167\n",
      "time/preback_alpha (s)                  0.988322\n",
      "time/preback_policy (s)                 1.11781\n",
      "time/preback_start (s)                  0.123483\n",
      "time/preback_zf (s)                     5.07977\n",
      "time/saving (s)                         0.021496\n",
      "time/training (s)                       2.20075\n",
      "time/epoch (s)                         17.4069\n",
      "time/total (s)                       3314.49\n",
      "Epoch                                 189\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:06:07.710331 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 190 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 201000\n",
      "trainer/ZF1 Loss                       11.3529\n",
      "trainer/ZF2 Loss                       12.1932\n",
      "trainer/ZF Expert Reward               21.8924\n",
      "trainer/ZF Policy Reward                3.69407\n",
      "trainer/ZF CHI2 Term                   49.6782\n",
      "trainer/Policy Loss                 -1314.07\n",
      "trainer/Bias Loss                     146.692\n",
      "trainer/Bias Value                     20.1192\n",
      "trainer/Policy Grad Norm              240.34\n",
      "trainer/Policy Param Norm              37.568\n",
      "trainer/Zf1 Grad Norm                2802.46\n",
      "trainer/Zf1 Param Norm                118.132\n",
      "trainer/Zf2 Grad Norm                2377.88\n",
      "trainer/Zf2 Param Norm                115.714\n",
      "trainer/Z Expert Predictions Mean    1449.11\n",
      "trainer/Z Expert Predictions Std      132.499\n",
      "trainer/Z Expert Predictions Max     1663.32\n",
      "trainer/Z Expert Predictions Min      372.36\n",
      "trainer/Z Policy Predictions Mean    1302.74\n",
      "trainer/Z Policy Predictions Std      333.987\n",
      "trainer/Z Policy Predictions Max     1650.06\n",
      "trainer/Z Policy Predictions Min     -167.318\n",
      "trainer/Z Expert Targets Mean        1427.22\n",
      "trainer/Z Expert Targets Std          134.32\n",
      "trainer/Z Expert Targets Max         1642.25\n",
      "trainer/Z Expert Targets Min          421.039\n",
      "trainer/Z Policy Targets Mean        1299.05\n",
      "trainer/Z Policy Targets Std          328.047\n",
      "trainer/Z Policy Targets Max         1630.64\n",
      "trainer/Z Policy Targets Min         -160.317\n",
      "trainer/Log Pis Mean                   19.9058\n",
      "trainer/Log Pis Std                     4.31918\n",
      "trainer/Policy mu Mean                  1.25847\n",
      "trainer/Policy mu Std                   1.87004\n",
      "trainer/Policy log std Mean            -2.23259\n",
      "trainer/Policy log std Std              1.19998\n",
      "trainer/Alpha                           0.160608\n",
      "trainer/Alpha Loss                      0.0151233\n",
      "exploration/num steps total        196001\n",
      "exploration/num paths total           776\n",
      "evaluation/num steps total              1.53009e+06\n",
      "evaluation/num paths total           1915\n",
      "evaluation/path length Mean           992.3\n",
      "evaluation/path length Std             23.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            923\n",
      "evaluation/Rewards Mean                 5.12093\n",
      "evaluation/Rewards Std                  1.28851\n",
      "evaluation/Rewards Max                  7.36482\n",
      "evaluation/Rewards Min                  0.116649\n",
      "evaluation/Returns Mean              5081.49\n",
      "evaluation/Returns Std                137.313\n",
      "evaluation/Returns Max               5165.66\n",
      "evaluation/Returns Min               4679.78\n",
      "evaluation/Estimation Bias Mean      1399.76\n",
      "evaluation/Estimation Bias Std        231.081\n",
      "evaluation/EB/Q_True Mean              49.0959\n",
      "evaluation/EB/Q_True Std              151.164\n",
      "evaluation/EB/Q_Pred Mean            1448.86\n",
      "evaluation/EB/Q_Pred Std              152.567\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5081.49\n",
      "evaluation/Actions Mean                 0.502211\n",
      "evaluation/Actions Std                  0.643996\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.83093\n",
      "time/backward_zf1 (s)                   1.98656\n",
      "time/backward_zf2 (s)                   1.89726\n",
      "time/data sampling (s)                  0.269699\n",
      "time/data storing (s)                   0.0150489\n",
      "time/evaluation sampling (s)            1.40757\n",
      "time/exploration sampling (s)           0.199407\n",
      "time/logging (s)                        0.0124306\n",
      "time/preback_alpha (s)                  0.938265\n",
      "time/preback_policy (s)                 1.02803\n",
      "time/preback_start (s)                  0.124516\n",
      "time/preback_zf (s)                     5.1481\n",
      "time/saving (s)                         0.00590281\n",
      "time/training (s)                       2.36203\n",
      "time/epoch (s)                         17.2258\n",
      "time/total (s)                       3331.74\n",
      "Epoch                                 190\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:06:25.479899 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 191 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 202000\n",
      "trainer/ZF1 Loss                       19.3984\n",
      "trainer/ZF2 Loss                       24.7222\n",
      "trainer/ZF Expert Reward               19.0063\n",
      "trainer/ZF Policy Reward                3.20162\n",
      "trainer/ZF CHI2 Term                   57.6902\n",
      "trainer/Policy Loss                 -1269.81\n",
      "trainer/Bias Loss                     106.498\n",
      "trainer/Bias Value                     20.1057\n",
      "trainer/Policy Grad Norm              317.761\n",
      "trainer/Policy Param Norm              37.6124\n",
      "trainer/Zf1 Grad Norm                2767.36\n",
      "trainer/Zf1 Param Norm                118.324\n",
      "trainer/Zf2 Grad Norm                2684.87\n",
      "trainer/Zf2 Param Norm                115.899\n",
      "trainer/Z Expert Predictions Mean    1438.62\n",
      "trainer/Z Expert Predictions Std      114.772\n",
      "trainer/Z Expert Predictions Max     1633.63\n",
      "trainer/Z Expert Predictions Min      931.434\n",
      "trainer/Z Policy Predictions Mean    1268.41\n",
      "trainer/Z Policy Predictions Std      360.057\n",
      "trainer/Z Policy Predictions Max     1613.25\n",
      "trainer/Z Policy Predictions Min     -234.21\n",
      "trainer/Z Expert Targets Mean        1419.61\n",
      "trainer/Z Expert Targets Std          118.666\n",
      "trainer/Z Expert Targets Max         1619.19\n",
      "trainer/Z Expert Targets Min          893.859\n",
      "trainer/Z Policy Targets Mean        1265.21\n",
      "trainer/Z Policy Targets Std          354.327\n",
      "trainer/Z Policy Targets Max         1603.12\n",
      "trainer/Z Policy Targets Min         -213.16\n",
      "trainer/Log Pis Mean                   20.0254\n",
      "trainer/Log Pis Std                     3.89464\n",
      "trainer/Policy mu Mean                  1.27777\n",
      "trainer/Policy mu Std                   1.86522\n",
      "trainer/Policy log std Mean            -2.13377\n",
      "trainer/Policy log std Std              1.12785\n",
      "trainer/Alpha                           0.162621\n",
      "trainer/Alpha Loss                     -0.00413398\n",
      "exploration/num steps total        196001\n",
      "exploration/num paths total           776\n",
      "evaluation/num steps total              1.53968e+06\n",
      "evaluation/num paths total           1925\n",
      "evaluation/path length Mean           959.2\n",
      "evaluation/path length Std            122.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            592\n",
      "evaluation/Rewards Mean                 4.98394\n",
      "evaluation/Rewards Std                  1.28064\n",
      "evaluation/Rewards Max                  7.09143\n",
      "evaluation/Rewards Min                  0.152225\n",
      "evaluation/Returns Mean              4780.59\n",
      "evaluation/Returns Std                681.317\n",
      "evaluation/Returns Max               5110.49\n",
      "evaluation/Returns Min               2762.81\n",
      "evaluation/Estimation Bias Mean      1373.37\n",
      "evaluation/Estimation Bias Std        240.398\n",
      "evaluation/EB/Q_True Mean              50.1051\n",
      "evaluation/EB/Q_True Std              151.199\n",
      "evaluation/EB/Q_Pred Mean            1423.47\n",
      "evaluation/EB/Q_Pred Std              160.519\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4780.59\n",
      "evaluation/Actions Mean                 0.489281\n",
      "evaluation/Actions Std                  0.650763\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.97347\n",
      "time/backward_zf1 (s)                   2.11\n",
      "time/backward_zf2 (s)                   2.05328\n",
      "time/data sampling (s)                  0.262931\n",
      "time/data storing (s)                   0.0154721\n",
      "time/evaluation sampling (s)            1.42879\n",
      "time/exploration sampling (s)           0.199148\n",
      "time/logging (s)                        0.0114747\n",
      "time/preback_alpha (s)                  1.03665\n",
      "time/preback_policy (s)                 1.17151\n",
      "time/preback_start (s)                  0.125493\n",
      "time/preback_zf (s)                     5.14339\n",
      "time/saving (s)                         0.00520541\n",
      "time/training (s)                       2.16286\n",
      "time/epoch (s)                         17.6997\n",
      "time/total (s)                       3349.46\n",
      "Epoch                                 191\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:06:42.885717 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 192 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 203000\n",
      "trainer/ZF1 Loss                       36.123\n",
      "trainer/ZF2 Loss                       35.2849\n",
      "trainer/ZF Expert Reward               29.7333\n",
      "trainer/ZF Policy Reward               14.1275\n",
      "trainer/ZF CHI2 Term                   71.514\n",
      "trainer/Policy Loss                 -1341.73\n",
      "trainer/Bias Loss                     224.227\n",
      "trainer/Bias Value                     20.094\n",
      "trainer/Policy Grad Norm              306.467\n",
      "trainer/Policy Param Norm              37.654\n",
      "trainer/Zf1 Grad Norm                4793.84\n",
      "trainer/Zf1 Param Norm                118.503\n",
      "trainer/Zf2 Grad Norm                4795.75\n",
      "trainer/Zf2 Param Norm                116.08\n",
      "trainer/Z Expert Predictions Mean    1423.22\n",
      "trainer/Z Expert Predictions Std      158.234\n",
      "trainer/Z Expert Predictions Max     1650.06\n",
      "trainer/Z Expert Predictions Min      141.693\n",
      "trainer/Z Policy Predictions Mean    1339.03\n",
      "trainer/Z Policy Predictions Std      257.871\n",
      "trainer/Z Policy Predictions Max     1620.1\n",
      "trainer/Z Policy Predictions Min      141.507\n",
      "trainer/Z Expert Targets Mean        1393.48\n",
      "trainer/Z Expert Targets Std          166.289\n",
      "trainer/Z Expert Targets Max         1623.08\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1324.91\n",
      "trainer/Z Policy Targets Std          253.42\n",
      "trainer/Z Policy Targets Max         1619.64\n",
      "trainer/Z Policy Targets Min          127.472\n",
      "trainer/Log Pis Mean                   20.4083\n",
      "trainer/Log Pis Std                     4.01767\n",
      "trainer/Policy mu Mean                  1.31555\n",
      "trainer/Policy mu Std                   1.81622\n",
      "trainer/Policy log std Mean            -2.20582\n",
      "trainer/Policy log std Std              1.15085\n",
      "trainer/Alpha                           0.162835\n",
      "trainer/Alpha Loss                     -0.0664766\n",
      "exploration/num steps total        196652\n",
      "exploration/num paths total           777\n",
      "evaluation/num steps total              1.54894e+06\n",
      "evaluation/num paths total           1935\n",
      "evaluation/path length Mean           925.1\n",
      "evaluation/path length Std            161.094\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            493\n",
      "evaluation/Rewards Mean                 5.15476\n",
      "evaluation/Rewards Std                  1.35171\n",
      "evaluation/Rewards Max                  7.28469\n",
      "evaluation/Rewards Min                  0.133995\n",
      "evaluation/Returns Mean              4768.67\n",
      "evaluation/Returns Std                933.887\n",
      "evaluation/Returns Max               5243.35\n",
      "evaluation/Returns Min               2262.06\n",
      "evaluation/Estimation Bias Mean      1376.64\n",
      "evaluation/Estimation Bias Std        233.217\n",
      "evaluation/EB/Q_True Mean              52.2585\n",
      "evaluation/EB/Q_True Std              154.372\n",
      "evaluation/EB/Q_Pred Mean            1428.9\n",
      "evaluation/EB/Q_Pred Std              155.806\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4768.67\n",
      "evaluation/Actions Mean                 0.504653\n",
      "evaluation/Actions Std                  0.648275\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.86797\n",
      "time/backward_zf1 (s)                   1.99864\n",
      "time/backward_zf2 (s)                   1.9203\n",
      "time/data sampling (s)                  0.255351\n",
      "time/data storing (s)                   0.0141704\n",
      "time/evaluation sampling (s)            1.42863\n",
      "time/exploration sampling (s)           0.192897\n",
      "time/logging (s)                        0.0113811\n",
      "time/preback_alpha (s)                  0.955858\n",
      "time/preback_policy (s)                 1.06777\n",
      "time/preback_start (s)                  0.12326\n",
      "time/preback_zf (s)                     5.13412\n",
      "time/saving (s)                         0.00518899\n",
      "time/training (s)                       2.35461\n",
      "time/epoch (s)                         17.3301\n",
      "time/total (s)                       3366.82\n",
      "Epoch                                 192\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:07:00.484041 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 193 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 204000\n",
      "trainer/ZF1 Loss                       22.273\n",
      "trainer/ZF2 Loss                       36.7159\n",
      "trainer/ZF Expert Reward               18.336\n",
      "trainer/ZF Policy Reward                2.06392\n",
      "trainer/ZF CHI2 Term                   65.3061\n",
      "trainer/Policy Loss                 -1314.89\n",
      "trainer/Bias Loss                     129.163\n",
      "trainer/Bias Value                     20.0823\n",
      "trainer/Policy Grad Norm              350.972\n",
      "trainer/Policy Param Norm              37.7036\n",
      "trainer/Zf1 Grad Norm                3947.2\n",
      "trainer/Zf1 Param Norm                118.688\n",
      "trainer/Zf2 Grad Norm                5411.48\n",
      "trainer/Zf2 Param Norm                116.268\n",
      "trainer/Z Expert Predictions Mean    1430.84\n",
      "trainer/Z Expert Predictions Std      139.939\n",
      "trainer/Z Expert Predictions Max     1646.01\n",
      "trainer/Z Expert Predictions Min      -10.8179\n",
      "trainer/Z Policy Predictions Mean    1303.64\n",
      "trainer/Z Policy Predictions Std      306.923\n",
      "trainer/Z Policy Predictions Max     1648.7\n",
      "trainer/Z Policy Predictions Min     -255.375\n",
      "trainer/Z Expert Targets Mean        1412.5\n",
      "trainer/Z Expert Targets Std          140.064\n",
      "trainer/Z Expert Targets Max         1620.37\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1301.57\n",
      "trainer/Z Policy Targets Std          299.884\n",
      "trainer/Z Policy Targets Max         1619.23\n",
      "trainer/Z Policy Targets Min         -236.154\n",
      "trainer/Log Pis Mean                   19.7369\n",
      "trainer/Log Pis Std                     4.20725\n",
      "trainer/Policy mu Mean                  1.17825\n",
      "trainer/Policy mu Std                   1.88777\n",
      "trainer/Policy log std Mean            -2.25137\n",
      "trainer/Policy log std Std              1.1811\n",
      "trainer/Alpha                           0.162951\n",
      "trainer/Alpha Loss                      0.0428746\n",
      "exploration/num steps total        199623\n",
      "exploration/num paths total           780\n",
      "evaluation/num steps total              1.55894e+06\n",
      "evaluation/num paths total           1945\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18269\n",
      "evaluation/Rewards Std                  1.33251\n",
      "evaluation/Rewards Max                  7.35263\n",
      "evaluation/Rewards Min                  0.0827213\n",
      "evaluation/Returns Mean              5182.69\n",
      "evaluation/Returns Std                 17.6867\n",
      "evaluation/Returns Max               5213.73\n",
      "evaluation/Returns Min               5152.91\n",
      "evaluation/Estimation Bias Mean      1329.88\n",
      "evaluation/Estimation Bias Std        190.031\n",
      "evaluation/EB/Q_True Mean              49.0089\n",
      "evaluation/EB/Q_True Std              151.505\n",
      "evaluation/EB/Q_Pred Mean            1378.89\n",
      "evaluation/EB/Q_Pred Std              112.228\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5182.69\n",
      "evaluation/Actions Mean                 0.50428\n",
      "evaluation/Actions Std                  0.654212\n",
      "evaluation/Actions Max                  0.999991\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                1.95788\n",
      "time/backward_zf1 (s)                   2.10264\n",
      "time/backward_zf2 (s)                   2.0307\n",
      "time/data sampling (s)                  0.267541\n",
      "time/data storing (s)                   0.0147844\n",
      "time/evaluation sampling (s)            1.39594\n",
      "time/exploration sampling (s)           0.207532\n",
      "time/logging (s)                        0.0133196\n",
      "time/preback_alpha (s)                  1.03003\n",
      "time/preback_policy (s)                 1.1615\n",
      "time/preback_start (s)                  0.125283\n",
      "time/preback_zf (s)                     5.11138\n",
      "time/saving (s)                         0.00505843\n",
      "time/training (s)                       2.10732\n",
      "time/epoch (s)                         17.5309\n",
      "time/total (s)                       3384.37\n",
      "Epoch                                 193\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:07:18.078256 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 194 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 205000\n",
      "trainer/ZF1 Loss                      380.235\n",
      "trainer/ZF2 Loss                      390.245\n",
      "trainer/ZF Expert Reward               16.981\n",
      "trainer/ZF Policy Reward                9.18324\n",
      "trainer/ZF CHI2 Term                  412.947\n",
      "trainer/Policy Loss                 -1264.05\n",
      "trainer/Bias Loss                     129.669\n",
      "trainer/Bias Value                     20.0711\n",
      "trainer/Policy Grad Norm              271.168\n",
      "trainer/Policy Param Norm              37.7466\n",
      "trainer/Zf1 Grad Norm                8194.15\n",
      "trainer/Zf1 Param Norm                118.861\n",
      "trainer/Zf2 Grad Norm                6676.23\n",
      "trainer/Zf2 Param Norm                116.447\n",
      "trainer/Z Expert Predictions Mean    1433.55\n",
      "trainer/Z Expert Predictions Std      149.839\n",
      "trainer/Z Expert Predictions Max     1619.69\n",
      "trainer/Z Expert Predictions Min      -50.5515\n",
      "trainer/Z Policy Predictions Mean    1258.93\n",
      "trainer/Z Policy Predictions Std      365.311\n",
      "trainer/Z Policy Predictions Max     1607.99\n",
      "trainer/Z Policy Predictions Min     -165.245\n",
      "trainer/Z Expert Targets Mean        1416.57\n",
      "trainer/Z Expert Targets Std          151.137\n",
      "trainer/Z Expert Targets Max         1600.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1249.75\n",
      "trainer/Z Policy Targets Std          372.521\n",
      "trainer/Z Policy Targets Max         1592.35\n",
      "trainer/Z Policy Targets Min         -190.373\n",
      "trainer/Log Pis Mean                   20.1107\n",
      "trainer/Log Pis Std                     4.62876\n",
      "trainer/Policy mu Mean                  1.25182\n",
      "trainer/Policy mu Std                   1.91136\n",
      "trainer/Policy log std Mean            -2.14431\n",
      "trainer/Policy log std Std              1.18887\n",
      "trainer/Alpha                           0.161831\n",
      "trainer/Alpha Loss                     -0.0179141\n",
      "exploration/num steps total        201415\n",
      "exploration/num paths total           782\n",
      "evaluation/num steps total              1.56894e+06\n",
      "evaluation/num paths total           1955\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.05975\n",
      "evaluation/Rewards Std                  1.28132\n",
      "evaluation/Rewards Max                  7.23002\n",
      "evaluation/Rewards Min                  0.110385\n",
      "evaluation/Returns Mean              5059.75\n",
      "evaluation/Returns Std                 74.8234\n",
      "evaluation/Returns Max               5133.99\n",
      "evaluation/Returns Min               4908.02\n",
      "evaluation/Estimation Bias Mean      1359.42\n",
      "evaluation/Estimation Bias Std        239.825\n",
      "evaluation/EB/Q_True Mean              48.0969\n",
      "evaluation/EB/Q_True Std              148.668\n",
      "evaluation/EB/Q_Pred Mean            1407.52\n",
      "evaluation/EB/Q_Pred Std              172.255\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5059.75\n",
      "evaluation/Actions Mean                 0.490137\n",
      "evaluation/Actions Std                  0.654399\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.92879\n",
      "time/backward_zf1 (s)                   2.0451\n",
      "time/backward_zf2 (s)                   1.98643\n",
      "time/data sampling (s)                  0.261543\n",
      "time/data storing (s)                   0.0141067\n",
      "time/evaluation sampling (s)            1.4128\n",
      "time/exploration sampling (s)           0.19882\n",
      "time/logging (s)                        0.0115013\n",
      "time/preback_alpha (s)                  1.00486\n",
      "time/preback_policy (s)                 1.12738\n",
      "time/preback_start (s)                  0.125501\n",
      "time/preback_zf (s)                     5.16384\n",
      "time/saving (s)                         0.00537281\n",
      "time/training (s)                       2.23811\n",
      "time/epoch (s)                         17.5242\n",
      "time/total (s)                       3401.91\n",
      "Epoch                                 194\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:07:35.834671 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 195 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 206000\n",
      "trainer/ZF1 Loss                      409.026\n",
      "trainer/ZF2 Loss                      438.927\n",
      "trainer/ZF Expert Reward               23.5964\n",
      "trainer/ZF Policy Reward                2.90365\n",
      "trainer/ZF CHI2 Term                  464.626\n",
      "trainer/Policy Loss                 -1241.06\n",
      "trainer/Bias Loss                    3925.52\n",
      "trainer/Bias Value                     20.0597\n",
      "trainer/Policy Grad Norm              245.908\n",
      "trainer/Policy Param Norm              37.7898\n",
      "trainer/Zf1 Grad Norm                6620.61\n",
      "trainer/Zf1 Param Norm                119.058\n",
      "trainer/Zf2 Grad Norm                6859.13\n",
      "trainer/Zf2 Param Norm                116.633\n",
      "trainer/Z Expert Predictions Mean    1430.9\n",
      "trainer/Z Expert Predictions Std      116.7\n",
      "trainer/Z Expert Predictions Max     1620.01\n",
      "trainer/Z Expert Predictions Min      810.027\n",
      "trainer/Z Policy Predictions Mean    1231.67\n",
      "trainer/Z Policy Predictions Std      354.161\n",
      "trainer/Z Policy Predictions Max     1628.45\n",
      "trainer/Z Policy Predictions Min     -211.293\n",
      "trainer/Z Expert Targets Mean        1407.3\n",
      "trainer/Z Expert Targets Std          151.73\n",
      "trainer/Z Expert Targets Max         1602.34\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1228.77\n",
      "trainer/Z Policy Targets Std          351.912\n",
      "trainer/Z Policy Targets Max         1597.96\n",
      "trainer/Z Policy Targets Min         -202.306\n",
      "trainer/Log Pis Mean                   20.1587\n",
      "trainer/Log Pis Std                     4.58246\n",
      "trainer/Policy mu Mean                  1.27159\n",
      "trainer/Policy mu Std                   1.92124\n",
      "trainer/Policy log std Mean            -2.16693\n",
      "trainer/Policy log std Std              1.15072\n",
      "trainer/Alpha                           0.162417\n",
      "trainer/Alpha Loss                     -0.0257683\n",
      "exploration/num steps total        202415\n",
      "exploration/num paths total           783\n",
      "evaluation/num steps total              1.57837e+06\n",
      "evaluation/num paths total           1965\n",
      "evaluation/path length Mean           943\n",
      "evaluation/path length Std            171\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            430\n",
      "evaluation/Rewards Mean                 5.15317\n",
      "evaluation/Rewards Std                  1.35453\n",
      "evaluation/Rewards Max                  7.26632\n",
      "evaluation/Rewards Min                  0.0984971\n",
      "evaluation/Returns Mean              4859.44\n",
      "evaluation/Returns Std                967.991\n",
      "evaluation/Returns Max               5217.9\n",
      "evaluation/Returns Min               1956.33\n",
      "evaluation/Estimation Bias Mean      1335.59\n",
      "evaluation/Estimation Bias Std        216.599\n",
      "evaluation/EB/Q_True Mean              51.6611\n",
      "evaluation/EB/Q_True Std              154.556\n",
      "evaluation/EB/Q_Pred Mean            1387.25\n",
      "evaluation/EB/Q_Pred Std              143.583\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4859.44\n",
      "evaluation/Actions Mean                 0.509206\n",
      "evaluation/Actions Std                  0.643673\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.954\n",
      "time/backward_zf1 (s)                   2.08087\n",
      "time/backward_zf2 (s)                   2.03808\n",
      "time/data sampling (s)                  0.268316\n",
      "time/data storing (s)                   0.0149947\n",
      "time/evaluation sampling (s)            1.50026\n",
      "time/exploration sampling (s)           0.201521\n",
      "time/logging (s)                        0.0117417\n",
      "time/preback_alpha (s)                  1.03698\n",
      "time/preback_policy (s)                 1.16306\n",
      "time/preback_start (s)                  0.1263\n",
      "time/preback_zf (s)                     5.12423\n",
      "time/saving (s)                         0.0197793\n",
      "time/training (s)                       2.15031\n",
      "time/epoch (s)                         17.6904\n",
      "time/total (s)                       3419.62\n",
      "Epoch                                 195\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:07:53.243141 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 196 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 207000\n",
      "trainer/ZF1 Loss                      374.642\n",
      "trainer/ZF2 Loss                      315.317\n",
      "trainer/ZF Expert Reward               22.6148\n",
      "trainer/ZF Policy Reward               16.3347\n",
      "trainer/ZF CHI2 Term                  371.148\n",
      "trainer/Policy Loss                 -1241.33\n",
      "trainer/Bias Loss                     170.955\n",
      "trainer/Bias Value                     20.0505\n",
      "trainer/Policy Grad Norm              352.298\n",
      "trainer/Policy Param Norm              37.834\n",
      "trainer/Zf1 Grad Norm                8938.41\n",
      "trainer/Zf1 Param Norm                119.238\n",
      "trainer/Zf2 Grad Norm               10206.1\n",
      "trainer/Zf2 Param Norm                116.808\n",
      "trainer/Z Expert Predictions Mean    1419.77\n",
      "trainer/Z Expert Predictions Std      124.911\n",
      "trainer/Z Expert Predictions Max     1626.53\n",
      "trainer/Z Expert Predictions Min      240.919\n",
      "trainer/Z Policy Predictions Mean    1243.19\n",
      "trainer/Z Policy Predictions Std      352.24\n",
      "trainer/Z Policy Predictions Max     1614.71\n",
      "trainer/Z Policy Predictions Min     -206.387\n",
      "trainer/Z Expert Targets Mean        1397.16\n",
      "trainer/Z Expert Targets Std          125.423\n",
      "trainer/Z Expert Targets Max         1601.4\n",
      "trainer/Z Expert Targets Min          240.776\n",
      "trainer/Z Policy Targets Mean        1226.85\n",
      "trainer/Z Policy Targets Std          360.176\n",
      "trainer/Z Policy Targets Max         1596.31\n",
      "trainer/Z Policy Targets Min         -239.048\n",
      "trainer/Log Pis Mean                   20.0888\n",
      "trainer/Log Pis Std                     4.98924\n",
      "trainer/Policy mu Mean                  1.3756\n",
      "trainer/Policy mu Std                   1.91866\n",
      "trainer/Policy log std Mean            -2.06207\n",
      "trainer/Policy log std Std              1.17656\n",
      "trainer/Alpha                           0.162632\n",
      "trainer/Alpha Loss                     -0.0144426\n",
      "exploration/num steps total        203415\n",
      "exploration/num paths total           784\n",
      "evaluation/num steps total              1.58814e+06\n",
      "evaluation/num paths total           1975\n",
      "evaluation/path length Mean           976.9\n",
      "evaluation/path length Std             69.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            769\n",
      "evaluation/Rewards Mean                 4.97297\n",
      "evaluation/Rewards Std                  1.26264\n",
      "evaluation/Rewards Max                  7.06851\n",
      "evaluation/Rewards Min                  0.131396\n",
      "evaluation/Returns Mean              4858.09\n",
      "evaluation/Returns Std                394.535\n",
      "evaluation/Returns Max               5098.06\n",
      "evaluation/Returns Min               3706.16\n",
      "evaluation/Estimation Bias Mean      1314.61\n",
      "evaluation/Estimation Bias Std        253.086\n",
      "evaluation/EB/Q_True Mean              47.3927\n",
      "evaluation/EB/Q_True Std              144.03\n",
      "evaluation/EB/Q_Pred Mean            1362\n",
      "evaluation/EB/Q_Pred Std              191.345\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4858.09\n",
      "evaluation/Actions Mean                 0.499671\n",
      "evaluation/Actions Std                  0.653487\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.89938\n",
      "time/backward_zf1 (s)                   2.04079\n",
      "time/backward_zf2 (s)                   1.97661\n",
      "time/data sampling (s)                  0.274468\n",
      "time/data storing (s)                   0.0146128\n",
      "time/evaluation sampling (s)            1.40104\n",
      "time/exploration sampling (s)           0.19844\n",
      "time/logging (s)                        0.0115304\n",
      "time/preback_alpha (s)                  1.01427\n",
      "time/preback_policy (s)                 1.14961\n",
      "time/preback_start (s)                  0.124775\n",
      "time/preback_zf (s)                     5.09986\n",
      "time/saving (s)                         0.00514516\n",
      "time/training (s)                       2.12966\n",
      "time/epoch (s)                         17.3402\n",
      "time/total (s)                       3436.98\n",
      "Epoch                                 196\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:08:10.901386 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 197 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 208000\n",
      "trainer/ZF1 Loss                       31.0752\n",
      "trainer/ZF2 Loss                       34.6367\n",
      "trainer/ZF Expert Reward               21.3977\n",
      "trainer/ZF Policy Reward                4.41558\n",
      "trainer/ZF CHI2 Term                   69.6513\n",
      "trainer/Policy Loss                 -1238.76\n",
      "trainer/Bias Loss                     168.892\n",
      "trainer/Bias Value                     20.0401\n",
      "trainer/Policy Grad Norm              251.764\n",
      "trainer/Policy Param Norm              37.8751\n",
      "trainer/Zf1 Grad Norm                3443.22\n",
      "trainer/Zf1 Param Norm                119.433\n",
      "trainer/Zf2 Grad Norm                3994.77\n",
      "trainer/Zf2 Param Norm                116.999\n",
      "trainer/Z Expert Predictions Mean    1412.51\n",
      "trainer/Z Expert Predictions Std      149.356\n",
      "trainer/Z Expert Predictions Max     1616.29\n",
      "trainer/Z Expert Predictions Min       82.1734\n",
      "trainer/Z Policy Predictions Mean    1231.28\n",
      "trainer/Z Policy Predictions Std      375.514\n",
      "trainer/Z Policy Predictions Max     1594.64\n",
      "trainer/Z Policy Predictions Min     -332.096\n",
      "trainer/Z Expert Targets Mean        1391.11\n",
      "trainer/Z Expert Targets Std          157.596\n",
      "trainer/Z Expert Targets Max         1595.92\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1226.86\n",
      "trainer/Z Policy Targets Std          369.443\n",
      "trainer/Z Policy Targets Max         1590.51\n",
      "trainer/Z Policy Targets Min         -404.168\n",
      "trainer/Log Pis Mean                   20.0134\n",
      "trainer/Log Pis Std                     4.35238\n",
      "trainer/Policy mu Mean                  1.19831\n",
      "trainer/Policy mu Std                   1.87271\n",
      "trainer/Policy log std Mean            -2.238\n",
      "trainer/Policy log std Std              1.17109\n",
      "trainer/Alpha                           0.163137\n",
      "trainer/Alpha Loss                     -0.00218308\n",
      "exploration/num steps total        203415\n",
      "exploration/num paths total           784\n",
      "evaluation/num steps total              1.59762e+06\n",
      "evaluation/num paths total           1986\n",
      "evaluation/path length Mean           861.818\n",
      "evaluation/path length Std            211.107\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            354\n",
      "evaluation/Rewards Mean                 4.96349\n",
      "evaluation/Rewards Std                  1.35475\n",
      "evaluation/Rewards Max                  7.20543\n",
      "evaluation/Rewards Min                  0.0771036\n",
      "evaluation/Returns Mean              4277.62\n",
      "evaluation/Returns Std               1177.23\n",
      "evaluation/Returns Max               5151.84\n",
      "evaluation/Returns Min               1507.8\n",
      "evaluation/Estimation Bias Mean      1325.95\n",
      "evaluation/Estimation Bias Std        326.676\n",
      "evaluation/EB/Q_True Mean              51.433\n",
      "evaluation/EB/Q_True Std              154.29\n",
      "evaluation/EB/Q_Pred Mean            1377.38\n",
      "evaluation/EB/Q_Pred Std              245.834\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4277.62\n",
      "evaluation/Actions Mean                 0.492922\n",
      "evaluation/Actions Std                  0.652191\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.96492\n",
      "time/backward_zf1 (s)                   2.0967\n",
      "time/backward_zf2 (s)                   2.05238\n",
      "time/data sampling (s)                  0.264849\n",
      "time/data storing (s)                   0.0154814\n",
      "time/evaluation sampling (s)            1.39738\n",
      "time/exploration sampling (s)           0.198413\n",
      "time/logging (s)                        0.0115612\n",
      "time/preback_alpha (s)                  1.03672\n",
      "time/preback_policy (s)                 1.18752\n",
      "time/preback_start (s)                  0.122765\n",
      "time/preback_zf (s)                     5.11875\n",
      "time/saving (s)                         0.00518361\n",
      "time/training (s)                       2.11623\n",
      "time/epoch (s)                         17.5889\n",
      "time/total (s)                       3454.59\n",
      "Epoch                                 197\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:08:28.202998 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 198 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 209000\n",
      "trainer/ZF1 Loss                       24.2338\n",
      "trainer/ZF2 Loss                       23.6988\n",
      "trainer/ZF Expert Reward               21.1591\n",
      "trainer/ZF Policy Reward                3.60798\n",
      "trainer/ZF CHI2 Term                   61.6253\n",
      "trainer/Policy Loss                 -1201.48\n",
      "trainer/Bias Loss                     165.774\n",
      "trainer/Bias Value                     20.0304\n",
      "trainer/Policy Grad Norm              304.962\n",
      "trainer/Policy Param Norm              37.9133\n",
      "trainer/Zf1 Grad Norm                4850.12\n",
      "trainer/Zf1 Param Norm                119.616\n",
      "trainer/Zf2 Grad Norm                4772.96\n",
      "trainer/Zf2 Param Norm                117.173\n",
      "trainer/Z Expert Predictions Mean    1412.77\n",
      "trainer/Z Expert Predictions Std      106.382\n",
      "trainer/Z Expert Predictions Max     1600.94\n",
      "trainer/Z Expert Predictions Min     1071.29\n",
      "trainer/Z Policy Predictions Mean    1191.52\n",
      "trainer/Z Policy Predictions Std      408.383\n",
      "trainer/Z Policy Predictions Max     1590.99\n",
      "trainer/Z Policy Predictions Min     -192.83\n",
      "trainer/Z Expert Targets Mean        1391.61\n",
      "trainer/Z Expert Targets Std          109.641\n",
      "trainer/Z Expert Targets Max         1586.35\n",
      "trainer/Z Expert Targets Min         1031.27\n",
      "trainer/Z Policy Targets Mean        1187.91\n",
      "trainer/Z Policy Targets Std          405.899\n",
      "trainer/Z Policy Targets Max         1579.01\n",
      "trainer/Z Policy Targets Min         -200.993\n",
      "trainer/Log Pis Mean                   20.3109\n",
      "trainer/Log Pis Std                     4.4329\n",
      "trainer/Policy mu Mean                  1.26807\n",
      "trainer/Policy mu Std                   1.87433\n",
      "trainer/Policy log std Mean            -2.24462\n",
      "trainer/Policy log std Std              1.1941\n",
      "trainer/Alpha                           0.162156\n",
      "trainer/Alpha Loss                     -0.0504184\n",
      "exploration/num steps total        203415\n",
      "exploration/num paths total           784\n",
      "evaluation/num steps total              1.60762e+06\n",
      "evaluation/num paths total           1996\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07131\n",
      "evaluation/Rewards Std                  1.27466\n",
      "evaluation/Rewards Max                  7.04407\n",
      "evaluation/Rewards Min                  0.141083\n",
      "evaluation/Returns Mean              5071.31\n",
      "evaluation/Returns Std                 62.3001\n",
      "evaluation/Returns Max               5147.06\n",
      "evaluation/Returns Min               4950.35\n",
      "evaluation/Estimation Bias Mean      1341.67\n",
      "evaluation/Estimation Bias Std        184.628\n",
      "evaluation/EB/Q_True Mean              48.325\n",
      "evaluation/EB/Q_True Std              149.498\n",
      "evaluation/EB/Q_Pred Mean            1390\n",
      "evaluation/EB/Q_Pred Std              109.334\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5071.31\n",
      "evaluation/Actions Mean                 0.493066\n",
      "evaluation/Actions Std                  0.653283\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.87599\n",
      "time/backward_zf1 (s)                   2.01393\n",
      "time/backward_zf2 (s)                   1.95785\n",
      "time/data sampling (s)                  0.26444\n",
      "time/data storing (s)                   0.0146271\n",
      "time/evaluation sampling (s)            1.39217\n",
      "time/exploration sampling (s)           0.192411\n",
      "time/logging (s)                        0.0119566\n",
      "time/preback_alpha (s)                  0.981938\n",
      "time/preback_policy (s)                 1.10279\n",
      "time/preback_start (s)                  0.122866\n",
      "time/preback_zf (s)                     5.07885\n",
      "time/saving (s)                         0.00535464\n",
      "time/training (s)                       2.22182\n",
      "time/epoch (s)                         17.237\n",
      "time/total (s)                       3471.85\n",
      "Epoch                                 198\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:08:45.663403 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 199 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 210000\n",
      "trainer/ZF1 Loss                       44.7427\n",
      "trainer/ZF2 Loss                       46.296\n",
      "trainer/ZF Expert Reward               28.7969\n",
      "trainer/ZF Policy Reward               13.2316\n",
      "trainer/ZF CHI2 Term                   80.2968\n",
      "trainer/Policy Loss                 -1223.77\n",
      "trainer/Bias Loss                     246.48\n",
      "trainer/Bias Value                     20.0192\n",
      "trainer/Policy Grad Norm              226.91\n",
      "trainer/Policy Param Norm              37.9552\n",
      "trainer/Zf1 Grad Norm                5208.45\n",
      "trainer/Zf1 Param Norm                119.788\n",
      "trainer/Zf2 Grad Norm                5501.36\n",
      "trainer/Zf2 Param Norm                117.346\n",
      "trainer/Z Expert Predictions Mean    1406.71\n",
      "trainer/Z Expert Predictions Std      155.194\n",
      "trainer/Z Expert Predictions Max     1610.18\n",
      "trainer/Z Expert Predictions Min      318.728\n",
      "trainer/Z Policy Predictions Mean    1223.1\n",
      "trainer/Z Policy Predictions Std      382.62\n",
      "trainer/Z Policy Predictions Max     1577.13\n",
      "trainer/Z Policy Predictions Min     -206.083\n",
      "trainer/Z Expert Targets Mean        1377.91\n",
      "trainer/Z Expert Targets Std          160.944\n",
      "trainer/Z Expert Targets Max         1581.86\n",
      "trainer/Z Expert Targets Min          275.148\n",
      "trainer/Z Policy Targets Mean        1209.87\n",
      "trainer/Z Policy Targets Std          379.274\n",
      "trainer/Z Policy Targets Max         1554.4\n",
      "trainer/Z Policy Targets Min         -213.146\n",
      "trainer/Log Pis Mean                   19.4062\n",
      "trainer/Log Pis Std                     3.94788\n",
      "trainer/Policy mu Mean                  1.23238\n",
      "trainer/Policy mu Std                   1.8435\n",
      "trainer/Policy log std Mean            -2.16469\n",
      "trainer/Policy log std Std              1.17651\n",
      "trainer/Alpha                           0.159538\n",
      "trainer/Alpha Loss                      0.0947374\n",
      "exploration/num steps total        205415\n",
      "exploration/num paths total           786\n",
      "evaluation/num steps total              1.61702e+06\n",
      "evaluation/num paths total           2006\n",
      "evaluation/path length Mean           941\n",
      "evaluation/path length Std            101.529\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            690\n",
      "evaluation/Rewards Mean                 5.0376\n",
      "evaluation/Rewards Std                  1.30033\n",
      "evaluation/Rewards Max                  7.12217\n",
      "evaluation/Rewards Min                  0.125455\n",
      "evaluation/Returns Mean              4740.39\n",
      "evaluation/Returns Std                561.194\n",
      "evaluation/Returns Max               5128.68\n",
      "evaluation/Returns Min               3351.16\n",
      "evaluation/Estimation Bias Mean      1300.95\n",
      "evaluation/Estimation Bias Std        265.536\n",
      "evaluation/EB/Q_True Mean              50.36\n",
      "evaluation/EB/Q_True Std              150.367\n",
      "evaluation/EB/Q_Pred Mean            1351.31\n",
      "evaluation/EB/Q_Pred Std              207.171\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4740.39\n",
      "evaluation/Actions Mean                 0.491204\n",
      "evaluation/Actions Std                  0.655485\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.84433\n",
      "time/backward_zf1 (s)                   1.9842\n",
      "time/backward_zf2 (s)                   1.89481\n",
      "time/data sampling (s)                  0.26675\n",
      "time/data storing (s)                   0.0146273\n",
      "time/evaluation sampling (s)            1.51671\n",
      "time/exploration sampling (s)           0.205288\n",
      "time/logging (s)                        0.0114646\n",
      "time/preback_alpha (s)                  0.943246\n",
      "time/preback_policy (s)                 1.0429\n",
      "time/preback_start (s)                  0.125464\n",
      "time/preback_zf (s)                     5.12977\n",
      "time/saving (s)                         0.00544216\n",
      "time/training (s)                       2.40417\n",
      "time/epoch (s)                         17.3892\n",
      "time/total (s)                       3489.26\n",
      "Epoch                                 199\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:09:03.214182 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 200 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 211000\n",
      "trainer/ZF1 Loss                       51.0455\n",
      "trainer/ZF2 Loss                       64.2591\n",
      "trainer/ZF Expert Reward               21.1703\n",
      "trainer/ZF Policy Reward                6.37428\n",
      "trainer/ZF CHI2 Term                   92.6164\n",
      "trainer/Policy Loss                 -1287.22\n",
      "trainer/Bias Loss                     420.972\n",
      "trainer/Bias Value                     20.0101\n",
      "trainer/Policy Grad Norm              280.879\n",
      "trainer/Policy Param Norm              38.0002\n",
      "trainer/Zf1 Grad Norm                4392.76\n",
      "trainer/Zf1 Param Norm                119.986\n",
      "trainer/Zf2 Grad Norm                5979.31\n",
      "trainer/Zf2 Param Norm                117.542\n",
      "trainer/Z Expert Predictions Mean    1385.22\n",
      "trainer/Z Expert Predictions Std      138.021\n",
      "trainer/Z Expert Predictions Max     1570.45\n",
      "trainer/Z Expert Predictions Min      304.573\n",
      "trainer/Z Policy Predictions Mean    1283.61\n",
      "trainer/Z Policy Predictions Std      284.897\n",
      "trainer/Z Policy Predictions Max     1586.85\n",
      "trainer/Z Policy Predictions Min     -141.48\n",
      "trainer/Z Expert Targets Mean        1364.05\n",
      "trainer/Z Expert Targets Std          144.44\n",
      "trainer/Z Expert Targets Max         1565.24\n",
      "trainer/Z Expert Targets Min          278.324\n",
      "trainer/Z Policy Targets Mean        1277.24\n",
      "trainer/Z Policy Targets Std          278.611\n",
      "trainer/Z Policy Targets Max         1580.54\n",
      "trainer/Z Policy Targets Min          -89.2128\n",
      "trainer/Log Pis Mean                   20.3718\n",
      "trainer/Log Pis Std                     4.55204\n",
      "trainer/Policy mu Mean                  1.23772\n",
      "trainer/Policy mu Std                   1.93103\n",
      "trainer/Policy log std Mean            -2.23178\n",
      "trainer/Policy log std Std              1.17023\n",
      "trainer/Alpha                           0.159523\n",
      "trainer/Alpha Loss                     -0.0593106\n",
      "exploration/num steps total        205415\n",
      "exploration/num paths total           786\n",
      "evaluation/num steps total              1.62702e+06\n",
      "evaluation/num paths total           2016\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07454\n",
      "evaluation/Rewards Std                  1.28208\n",
      "evaluation/Rewards Max                  7.24507\n",
      "evaluation/Rewards Min                  0.109942\n",
      "evaluation/Returns Mean              5074.54\n",
      "evaluation/Returns Std                120.935\n",
      "evaluation/Returns Max               5225.68\n",
      "evaluation/Returns Min               4849.17\n",
      "evaluation/Estimation Bias Mean      1296.51\n",
      "evaluation/Estimation Bias Std        194.241\n",
      "evaluation/EB/Q_True Mean              45.8848\n",
      "evaluation/EB/Q_True Std              141.748\n",
      "evaluation/EB/Q_Pred Mean            1342.4\n",
      "evaluation/EB/Q_Pred Std              163.709\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5074.54\n",
      "evaluation/Actions Mean                 0.510248\n",
      "evaluation/Actions Std                  0.644969\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.91284\n",
      "time/backward_zf1 (s)                   2.05683\n",
      "time/backward_zf2 (s)                   1.96458\n",
      "time/data sampling (s)                  0.276393\n",
      "time/data storing (s)                   0.0142895\n",
      "time/evaluation sampling (s)            1.38525\n",
      "time/exploration sampling (s)           0.192458\n",
      "time/logging (s)                        0.0121546\n",
      "time/preback_alpha (s)                  0.994012\n",
      "time/preback_policy (s)                 1.1131\n",
      "time/preback_start (s)                  0.125121\n",
      "time/preback_zf (s)                     5.1305\n",
      "time/saving (s)                         0.00547421\n",
      "time/training (s)                       2.29061\n",
      "time/epoch (s)                         17.4736\n",
      "time/total (s)                       3506.76\n",
      "Epoch                                 200\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:09:20.747486 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 201 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 212000\n",
      "trainer/ZF1 Loss                       28.7602\n",
      "trainer/ZF2 Loss                       21.0363\n",
      "trainer/ZF Expert Reward               19.9911\n",
      "trainer/ZF Policy Reward                7.20345\n",
      "trainer/ZF CHI2 Term                   57.6281\n",
      "trainer/Policy Loss                 -1228.9\n",
      "trainer/Bias Loss                     122.38\n",
      "trainer/Bias Value                     19.9989\n",
      "trainer/Policy Grad Norm              289.379\n",
      "trainer/Policy Param Norm              38.0425\n",
      "trainer/Zf1 Grad Norm                3768.18\n",
      "trainer/Zf1 Param Norm                120.176\n",
      "trainer/Zf2 Grad Norm                3327.44\n",
      "trainer/Zf2 Param Norm                117.722\n",
      "trainer/Z Expert Predictions Mean    1405.59\n",
      "trainer/Z Expert Predictions Std      111.552\n",
      "trainer/Z Expert Predictions Max     1581.88\n",
      "trainer/Z Expert Predictions Min      926.025\n",
      "trainer/Z Policy Predictions Mean    1223.04\n",
      "trainer/Z Policy Predictions Std      348.118\n",
      "trainer/Z Policy Predictions Max     1599.95\n",
      "trainer/Z Policy Predictions Min     -373.928\n",
      "trainer/Z Expert Targets Mean        1385.6\n",
      "trainer/Z Expert Targets Std          113.144\n",
      "trainer/Z Expert Targets Max         1563.47\n",
      "trainer/Z Expert Targets Min          873.833\n",
      "trainer/Z Policy Targets Mean        1215.83\n",
      "trainer/Z Policy Targets Std          343.869\n",
      "trainer/Z Policy Targets Max         1578.26\n",
      "trainer/Z Policy Targets Min         -355.868\n",
      "trainer/Log Pis Mean                   20.1436\n",
      "trainer/Log Pis Std                     4.30212\n",
      "trainer/Policy mu Mean                  1.30768\n",
      "trainer/Policy mu Std                   1.86382\n",
      "trainer/Policy log std Mean            -2.17525\n",
      "trainer/Policy log std Std              1.19483\n",
      "trainer/Alpha                           0.162926\n",
      "trainer/Alpha Loss                     -0.0234017\n",
      "exploration/num steps total        205415\n",
      "exploration/num paths total           786\n",
      "evaluation/num steps total              1.63702e+06\n",
      "evaluation/num paths total           2026\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.01922\n",
      "evaluation/Rewards Std                  1.2552\n",
      "evaluation/Rewards Max                  6.95679\n",
      "evaluation/Rewards Min                  0.124899\n",
      "evaluation/Returns Mean              5019.22\n",
      "evaluation/Returns Std                 43.8232\n",
      "evaluation/Returns Max               5069.39\n",
      "evaluation/Returns Min               4939.21\n",
      "evaluation/Estimation Bias Mean      1303.44\n",
      "evaluation/Estimation Bias Std        202.999\n",
      "evaluation/EB/Q_True Mean              47.5834\n",
      "evaluation/EB/Q_True Std              147.058\n",
      "evaluation/EB/Q_Pred Mean            1351.03\n",
      "evaluation/EB/Q_Pred Std              123.484\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5019.22\n",
      "evaluation/Actions Mean                 0.492916\n",
      "evaluation/Actions Std                  0.651291\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.92857\n",
      "time/backward_zf1 (s)                   2.06538\n",
      "time/backward_zf2 (s)                   2.00519\n",
      "time/data sampling (s)                  0.257626\n",
      "time/data storing (s)                   0.014654\n",
      "time/evaluation sampling (s)            1.44456\n",
      "time/exploration sampling (s)           0.196103\n",
      "time/logging (s)                        0.012369\n",
      "time/preback_alpha (s)                  1.03622\n",
      "time/preback_policy (s)                 1.15283\n",
      "time/preback_start (s)                  0.124564\n",
      "time/preback_zf (s)                     5.12552\n",
      "time/saving (s)                         0.0177789\n",
      "time/training (s)                       2.08524\n",
      "time/epoch (s)                         17.4666\n",
      "time/total (s)                       3524.25\n",
      "Epoch                                 201\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:09:38.430899 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 202 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 213000\n",
      "trainer/ZF1 Loss                      347.053\n",
      "trainer/ZF2 Loss                      381.469\n",
      "trainer/ZF Expert Reward               18.5084\n",
      "trainer/ZF Policy Reward                9.0475\n",
      "trainer/ZF CHI2 Term                  393.335\n",
      "trainer/Policy Loss                 -1222.84\n",
      "trainer/Bias Loss                     132.171\n",
      "trainer/Bias Value                     19.989\n",
      "trainer/Policy Grad Norm              333.776\n",
      "trainer/Policy Param Norm              38.0839\n",
      "trainer/Zf1 Grad Norm                5556.91\n",
      "trainer/Zf1 Param Norm                120.369\n",
      "trainer/Zf2 Grad Norm                8077.05\n",
      "trainer/Zf2 Param Norm                117.907\n",
      "trainer/Z Expert Predictions Mean    1392.55\n",
      "trainer/Z Expert Predictions Std      109.816\n",
      "trainer/Z Expert Predictions Max     1577.53\n",
      "trainer/Z Expert Predictions Min      938.6\n",
      "trainer/Z Policy Predictions Mean    1213.93\n",
      "trainer/Z Policy Predictions Std      345.167\n",
      "trainer/Z Policy Predictions Max     1574.79\n",
      "trainer/Z Policy Predictions Min     -172.501\n",
      "trainer/Z Expert Targets Mean        1374.04\n",
      "trainer/Z Expert Targets Std          112.478\n",
      "trainer/Z Expert Targets Max         1558.36\n",
      "trainer/Z Expert Targets Min          913.312\n",
      "trainer/Z Policy Targets Mean        1204.88\n",
      "trainer/Z Policy Targets Std          348.879\n",
      "trainer/Z Policy Targets Max         1556.06\n",
      "trainer/Z Policy Targets Min         -144.567\n",
      "trainer/Log Pis Mean                   19.8114\n",
      "trainer/Log Pis Std                     4.01677\n",
      "trainer/Policy mu Mean                  1.19673\n",
      "trainer/Policy mu Std                   1.82576\n",
      "trainer/Policy log std Mean            -2.23083\n",
      "trainer/Policy log std Std              1.16909\n",
      "trainer/Alpha                           0.161477\n",
      "trainer/Alpha Loss                      0.0304615\n",
      "exploration/num steps total        206415\n",
      "exploration/num paths total           787\n",
      "evaluation/num steps total              1.64702e+06\n",
      "evaluation/num paths total           2036\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15998\n",
      "evaluation/Rewards Std                  1.30975\n",
      "evaluation/Rewards Max                  7.30435\n",
      "evaluation/Rewards Min                  0.106277\n",
      "evaluation/Returns Mean              5159.98\n",
      "evaluation/Returns Std                 31.7275\n",
      "evaluation/Returns Max               5195.82\n",
      "evaluation/Returns Min               5071.37\n",
      "evaluation/Estimation Bias Mean      1322.03\n",
      "evaluation/Estimation Bias Std        191.989\n",
      "evaluation/EB/Q_True Mean              49.1356\n",
      "evaluation/EB/Q_True Std              151.959\n",
      "evaluation/EB/Q_Pred Mean            1371.16\n",
      "evaluation/EB/Q_Pred Std              113.921\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5159.98\n",
      "evaluation/Actions Mean                 0.508536\n",
      "evaluation/Actions Std                  0.648379\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.98383\n",
      "time/backward_zf1 (s)                   2.09618\n",
      "time/backward_zf2 (s)                   2.02523\n",
      "time/data sampling (s)                  0.250851\n",
      "time/data storing (s)                   0.0147133\n",
      "time/evaluation sampling (s)            1.44506\n",
      "time/exploration sampling (s)           0.197584\n",
      "time/logging (s)                        0.012196\n",
      "time/preback_alpha (s)                  1.00606\n",
      "time/preback_policy (s)                 1.1285\n",
      "time/preback_start (s)                  0.125553\n",
      "time/preback_zf (s)                     5.11788\n",
      "time/saving (s)                         0.00537448\n",
      "time/training (s)                       2.20385\n",
      "time/epoch (s)                         17.6129\n",
      "time/total (s)                       3541.89\n",
      "Epoch                                 202\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:09:56.146946 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 203 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 214000\n",
      "trainer/ZF1 Loss                       42.3522\n",
      "trainer/ZF2 Loss                       48.8239\n",
      "trainer/ZF Expert Reward               29.2143\n",
      "trainer/ZF Policy Reward               13.0867\n",
      "trainer/ZF CHI2 Term                   81.2072\n",
      "trainer/Policy Loss                 -1246.42\n",
      "trainer/Bias Loss                     303.475\n",
      "trainer/Bias Value                     19.9786\n",
      "trainer/Policy Grad Norm              296.074\n",
      "trainer/Policy Param Norm              38.1287\n",
      "trainer/Zf1 Grad Norm                3931.7\n",
      "trainer/Zf1 Param Norm                120.553\n",
      "trainer/Zf2 Grad Norm                4358.35\n",
      "trainer/Zf2 Param Norm                118.075\n",
      "trainer/Z Expert Predictions Mean    1397.6\n",
      "trainer/Z Expert Predictions Std      128.071\n",
      "trainer/Z Expert Predictions Max     1590.29\n",
      "trainer/Z Expert Predictions Min      563.71\n",
      "trainer/Z Policy Predictions Mean    1236.53\n",
      "trainer/Z Policy Predictions Std      318.041\n",
      "trainer/Z Policy Predictions Max     1581.72\n",
      "trainer/Z Policy Predictions Min        1.76887\n",
      "trainer/Z Expert Targets Mean        1368.39\n",
      "trainer/Z Expert Targets Std          133.308\n",
      "trainer/Z Expert Targets Max         1563.97\n",
      "trainer/Z Expert Targets Min          538.819\n",
      "trainer/Z Policy Targets Mean        1223.44\n",
      "trainer/Z Policy Targets Std          310.101\n",
      "trainer/Z Policy Targets Max         1557.7\n",
      "trainer/Z Policy Targets Min           28.0064\n",
      "trainer/Log Pis Mean                   19.6884\n",
      "trainer/Log Pis Std                     4.53371\n",
      "trainer/Policy mu Mean                  1.29989\n",
      "trainer/Policy mu Std                   1.83553\n",
      "trainer/Policy log std Mean            -2.19602\n",
      "trainer/Policy log std Std              1.15284\n",
      "trainer/Alpha                           0.160862\n",
      "trainer/Alpha Loss                      0.050116\n",
      "exploration/num steps total        209415\n",
      "exploration/num paths total           790\n",
      "evaluation/num steps total              1.65702e+06\n",
      "evaluation/num paths total           2046\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.05097\n",
      "evaluation/Rewards Std                  1.2833\n",
      "evaluation/Rewards Max                  6.99387\n",
      "evaluation/Rewards Min                  0.104935\n",
      "evaluation/Returns Mean              5050.97\n",
      "evaluation/Returns Std                 68.8748\n",
      "evaluation/Returns Max               5125.51\n",
      "evaluation/Returns Min               4921.64\n",
      "evaluation/Estimation Bias Mean      1271.79\n",
      "evaluation/Estimation Bias Std        188.528\n",
      "evaluation/EB/Q_True Mean              48.2001\n",
      "evaluation/EB/Q_True Std              148.784\n",
      "evaluation/EB/Q_Pred Mean            1319.99\n",
      "evaluation/EB/Q_Pred Std              120.913\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5050.97\n",
      "evaluation/Actions Mean                 0.491045\n",
      "evaluation/Actions Std                  0.655405\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.93201\n",
      "time/backward_zf1 (s)                   2.10692\n",
      "time/backward_zf2 (s)                   2.04713\n",
      "time/data sampling (s)                  0.258894\n",
      "time/data storing (s)                   0.0139106\n",
      "time/evaluation sampling (s)            1.47197\n",
      "time/exploration sampling (s)           0.199681\n",
      "time/logging (s)                        0.0117636\n",
      "time/preback_alpha (s)                  1.01517\n",
      "time/preback_policy (s)                 1.16115\n",
      "time/preback_start (s)                  0.12444\n",
      "time/preback_zf (s)                     5.13103\n",
      "time/saving (s)                         0.00554658\n",
      "time/training (s)                       2.16594\n",
      "time/epoch (s)                         17.6455\n",
      "time/total (s)                       3559.55\n",
      "Epoch                                 203\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:10:13.600311 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 204 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 215000\n",
      "trainer/ZF1 Loss                       54.6397\n",
      "trainer/ZF2 Loss                       55.3262\n",
      "trainer/ZF Expert Reward               10.6308\n",
      "trainer/ZF Policy Reward               -1.48759\n",
      "trainer/ZF CHI2 Term                   86.6096\n",
      "trainer/Policy Loss                 -1249.19\n",
      "trainer/Bias Loss                     305.566\n",
      "trainer/Bias Value                     19.9682\n",
      "trainer/Policy Grad Norm              301.058\n",
      "trainer/Policy Param Norm              38.1668\n",
      "trainer/Zf1 Grad Norm                6189.81\n",
      "trainer/Zf1 Param Norm                120.733\n",
      "trainer/Zf2 Grad Norm                5349.83\n",
      "trainer/Zf2 Param Norm                118.256\n",
      "trainer/Z Expert Predictions Mean    1363.22\n",
      "trainer/Z Expert Predictions Std      148.284\n",
      "trainer/Z Expert Predictions Max     1583.81\n",
      "trainer/Z Expert Predictions Min      260.743\n",
      "trainer/Z Policy Predictions Mean    1241.3\n",
      "trainer/Z Policy Predictions Std      300.662\n",
      "trainer/Z Policy Predictions Max     1562.59\n",
      "trainer/Z Policy Predictions Min       -7.34433\n",
      "trainer/Z Expert Targets Mean        1352.59\n",
      "trainer/Z Expert Targets Std          152.335\n",
      "trainer/Z Expert Targets Max         1567.2\n",
      "trainer/Z Expert Targets Min          208.035\n",
      "trainer/Z Policy Targets Mean        1242.79\n",
      "trainer/Z Policy Targets Std          297.526\n",
      "trainer/Z Policy Targets Max         1558.79\n",
      "trainer/Z Policy Targets Min          -76.4103\n",
      "trainer/Log Pis Mean                   19.7052\n",
      "trainer/Log Pis Std                     4.37959\n",
      "trainer/Policy mu Mean                  1.22606\n",
      "trainer/Policy mu Std                   1.77827\n",
      "trainer/Policy log std Mean            -2.29505\n",
      "trainer/Policy log std Std              1.17256\n",
      "trainer/Alpha                           0.164453\n",
      "trainer/Alpha Loss                      0.0484723\n",
      "exploration/num steps total        211415\n",
      "exploration/num paths total           792\n",
      "evaluation/num steps total              1.66702e+06\n",
      "evaluation/num paths total           2056\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.11447\n",
      "evaluation/Rewards Std                  1.2807\n",
      "evaluation/Rewards Max                  7.08266\n",
      "evaluation/Rewards Min                  0.143917\n",
      "evaluation/Returns Mean              5114.47\n",
      "evaluation/Returns Std                 31.6221\n",
      "evaluation/Returns Max               5166.01\n",
      "evaluation/Returns Min               5064.51\n",
      "evaluation/Estimation Bias Mean      1334.94\n",
      "evaluation/Estimation Bias Std        173.997\n",
      "evaluation/EB/Q_True Mean              47.8419\n",
      "evaluation/EB/Q_True Std              147.592\n",
      "evaluation/EB/Q_Pred Mean            1382.78\n",
      "evaluation/EB/Q_Pred Std               94.9739\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5114.47\n",
      "evaluation/Actions Mean                 0.493162\n",
      "evaluation/Actions Std                  0.648831\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.86992\n",
      "time/backward_zf1 (s)                   2.00695\n",
      "time/backward_zf2 (s)                   1.94211\n",
      "time/data sampling (s)                  0.260041\n",
      "time/data storing (s)                   0.0140105\n",
      "time/evaluation sampling (s)            1.42255\n",
      "time/exploration sampling (s)           0.198304\n",
      "time/logging (s)                        0.0118511\n",
      "time/preback_alpha (s)                  0.940339\n",
      "time/preback_policy (s)                 1.05403\n",
      "time/preback_start (s)                  0.123964\n",
      "time/preback_zf (s)                     5.10857\n",
      "time/saving (s)                         0.00536195\n",
      "time/training (s)                       2.42929\n",
      "time/epoch (s)                         17.3873\n",
      "time/total (s)                       3576.96\n",
      "Epoch                                 204\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:10:31.002039 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 205 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 216000\n",
      "trainer/ZF1 Loss                       45.5822\n",
      "trainer/ZF2 Loss                       32.9472\n",
      "trainer/ZF Expert Reward               15.259\n",
      "trainer/ZF Policy Reward                1.8039\n",
      "trainer/ZF CHI2 Term                   72.0487\n",
      "trainer/Policy Loss                 -1205.38\n",
      "trainer/Bias Loss                     220.288\n",
      "trainer/Bias Value                     19.9594\n",
      "trainer/Policy Grad Norm              256.693\n",
      "trainer/Policy Param Norm              38.2016\n",
      "trainer/Zf1 Grad Norm                4441.05\n",
      "trainer/Zf1 Param Norm                120.912\n",
      "trainer/Zf2 Grad Norm                4974.05\n",
      "trainer/Zf2 Param Norm                118.424\n",
      "trainer/Z Expert Predictions Mean    1360.04\n",
      "trainer/Z Expert Predictions Std      156.809\n",
      "trainer/Z Expert Predictions Max     1588.45\n",
      "trainer/Z Expert Predictions Min      275.321\n",
      "trainer/Z Policy Predictions Mean    1190.79\n",
      "trainer/Z Policy Predictions Std      327.744\n",
      "trainer/Z Policy Predictions Max     1580.99\n",
      "trainer/Z Policy Predictions Min      -79.1339\n",
      "trainer/Z Expert Targets Mean        1344.78\n",
      "trainer/Z Expert Targets Std          159.356\n",
      "trainer/Z Expert Targets Max         1560.72\n",
      "trainer/Z Expert Targets Min          242.824\n",
      "trainer/Z Policy Targets Mean        1188.99\n",
      "trainer/Z Policy Targets Std          321.754\n",
      "trainer/Z Policy Targets Max         1557.44\n",
      "trainer/Z Policy Targets Min          -80.8891\n",
      "trainer/Log Pis Mean                   19.5242\n",
      "trainer/Log Pis Std                     3.94254\n",
      "trainer/Policy mu Mean                  1.22757\n",
      "trainer/Policy mu Std                   1.80038\n",
      "trainer/Policy log std Mean            -2.25733\n",
      "trainer/Policy log std Std              1.13431\n",
      "trainer/Alpha                           0.164549\n",
      "trainer/Alpha Loss                      0.0782925\n",
      "exploration/num steps total        212415\n",
      "exploration/num paths total           793\n",
      "evaluation/num steps total              1.67702e+06\n",
      "evaluation/num paths total           2066\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10444\n",
      "evaluation/Rewards Std                  1.27305\n",
      "evaluation/Rewards Max                  7.04175\n",
      "evaluation/Rewards Min                  0.138565\n",
      "evaluation/Returns Mean              5104.44\n",
      "evaluation/Returns Std                 26.6642\n",
      "evaluation/Returns Max               5163.43\n",
      "evaluation/Returns Min               5063.89\n",
      "evaluation/Estimation Bias Mean      1301.11\n",
      "evaluation/Estimation Bias Std        182.619\n",
      "evaluation/EB/Q_True Mean              48.1934\n",
      "evaluation/EB/Q_True Std              148.935\n",
      "evaluation/EB/Q_Pred Mean            1349.3\n",
      "evaluation/EB/Q_Pred Std              111.569\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5104.44\n",
      "evaluation/Actions Mean                 0.5035\n",
      "evaluation/Actions Std                  0.651579\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.87517\n",
      "time/backward_zf1 (s)                   2.01025\n",
      "time/backward_zf2 (s)                   1.93261\n",
      "time/data sampling (s)                  0.273671\n",
      "time/data storing (s)                   0.014727\n",
      "time/evaluation sampling (s)            1.43734\n",
      "time/exploration sampling (s)           0.201057\n",
      "time/logging (s)                        0.0120257\n",
      "time/preback_alpha (s)                  0.936855\n",
      "time/preback_policy (s)                 1.02879\n",
      "time/preback_start (s)                  0.125837\n",
      "time/preback_zf (s)                     5.10067\n",
      "time/saving (s)                         0.00542602\n",
      "time/training (s)                       2.38003\n",
      "time/epoch (s)                         17.3345\n",
      "time/total (s)                       3594.31\n",
      "Epoch                                 205\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:10:48.551573 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 206 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 217000\n",
      "trainer/ZF1 Loss                       16.5843\n",
      "trainer/ZF2 Loss                       21.5327\n",
      "trainer/ZF Expert Reward               22.2081\n",
      "trainer/ZF Policy Reward                7.59742\n",
      "trainer/ZF CHI2 Term                   53.9858\n",
      "trainer/Policy Loss                 -1183.31\n",
      "trainer/Bias Loss                      95.0233\n",
      "trainer/Bias Value                     19.9494\n",
      "trainer/Policy Grad Norm              400.643\n",
      "trainer/Policy Param Norm              38.237\n",
      "trainer/Zf1 Grad Norm                2391.29\n",
      "trainer/Zf1 Param Norm                121.094\n",
      "trainer/Zf2 Grad Norm                2860.55\n",
      "trainer/Zf2 Param Norm                118.61\n",
      "trainer/Z Expert Predictions Mean    1367.98\n",
      "trainer/Z Expert Predictions Std      157.977\n",
      "trainer/Z Expert Predictions Max     1584.3\n",
      "trainer/Z Expert Predictions Min       18.7075\n",
      "trainer/Z Policy Predictions Mean    1176.92\n",
      "trainer/Z Policy Predictions Std      376.91\n",
      "trainer/Z Policy Predictions Max     1569.62\n",
      "trainer/Z Policy Predictions Min     -147.057\n",
      "trainer/Z Expert Targets Mean        1345.77\n",
      "trainer/Z Expert Targets Std          159.817\n",
      "trainer/Z Expert Targets Max         1564.09\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1169.32\n",
      "trainer/Z Policy Targets Std          371.296\n",
      "trainer/Z Policy Targets Max         1554.35\n",
      "trainer/Z Policy Targets Min         -141.236\n",
      "trainer/Log Pis Mean                   20.5218\n",
      "trainer/Log Pis Std                     4.8166\n",
      "trainer/Policy mu Mean                  1.27853\n",
      "trainer/Policy mu Std                   1.93314\n",
      "trainer/Policy log std Mean            -2.1813\n",
      "trainer/Policy log std Std              1.19237\n",
      "trainer/Alpha                           0.165112\n",
      "trainer/Alpha Loss                     -0.0861497\n",
      "exploration/num steps total        213415\n",
      "exploration/num paths total           794\n",
      "evaluation/num steps total              1.68702e+06\n",
      "evaluation/num paths total           2076\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.01804\n",
      "evaluation/Rewards Std                  1.26874\n",
      "evaluation/Rewards Max                  6.87634\n",
      "evaluation/Rewards Min                  0.113111\n",
      "evaluation/Returns Mean              5018.04\n",
      "evaluation/Returns Std                 46.5291\n",
      "evaluation/Returns Max               5120.49\n",
      "evaluation/Returns Min               4940.85\n",
      "evaluation/Estimation Bias Mean      1270.35\n",
      "evaluation/Estimation Bias Std        195.396\n",
      "evaluation/EB/Q_True Mean              46.9558\n",
      "evaluation/EB/Q_True Std              145.112\n",
      "evaluation/EB/Q_Pred Mean            1317.31\n",
      "evaluation/EB/Q_Pred Std              134.465\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5018.04\n",
      "evaluation/Actions Mean                 0.499099\n",
      "evaluation/Actions Std                  0.654033\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.90056\n",
      "time/backward_zf1 (s)                   2.03874\n",
      "time/backward_zf2 (s)                   1.97525\n",
      "time/data sampling (s)                  0.272387\n",
      "time/data storing (s)                   0.0145925\n",
      "time/evaluation sampling (s)            1.41732\n",
      "time/exploration sampling (s)           0.19745\n",
      "time/logging (s)                        0.0120268\n",
      "time/preback_alpha (s)                  0.973952\n",
      "time/preback_policy (s)                 1.08202\n",
      "time/preback_start (s)                  0.123717\n",
      "time/preback_zf (s)                     5.12561\n",
      "time/saving (s)                         0.00528137\n",
      "time/training (s)                       2.34411\n",
      "time/epoch (s)                         17.483\n",
      "time/total (s)                       3611.81\n",
      "Epoch                                 206\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:11:06.459766 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 207 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 218000\n",
      "trainer/ZF1 Loss                      225.482\n",
      "trainer/ZF2 Loss                      227.417\n",
      "trainer/ZF Expert Reward               24.6156\n",
      "trainer/ZF Policy Reward                5.17386\n",
      "trainer/ZF CHI2 Term                  265.905\n",
      "trainer/Policy Loss                 -1163.9\n",
      "trainer/Bias Loss                    2155.65\n",
      "trainer/Bias Value                     19.9396\n",
      "trainer/Policy Grad Norm              345.505\n",
      "trainer/Policy Param Norm              38.2761\n",
      "trainer/Zf1 Grad Norm                7634.4\n",
      "trainer/Zf1 Param Norm                121.293\n",
      "trainer/Zf2 Grad Norm                8587.08\n",
      "trainer/Zf2 Param Norm                118.806\n",
      "trainer/Z Expert Predictions Mean    1365.78\n",
      "trainer/Z Expert Predictions Std      140.018\n",
      "trainer/Z Expert Predictions Max     1582.92\n",
      "trainer/Z Expert Predictions Min      328.432\n",
      "trainer/Z Policy Predictions Mean    1160.3\n",
      "trainer/Z Policy Predictions Std      382.243\n",
      "trainer/Z Policy Predictions Max     1574.86\n",
      "trainer/Z Policy Predictions Min      -63.8721\n",
      "trainer/Z Expert Targets Mean        1341.17\n",
      "trainer/Z Expert Targets Std          162.065\n",
      "trainer/Z Expert Targets Max         1565.45\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1155.12\n",
      "trainer/Z Policy Targets Std          378.148\n",
      "trainer/Z Policy Targets Max         1551.71\n",
      "trainer/Z Policy Targets Min          -99.6655\n",
      "trainer/Log Pis Mean                   20.2155\n",
      "trainer/Log Pis Std                     4.82776\n",
      "trainer/Policy mu Mean                  1.20373\n",
      "trainer/Policy mu Std                   1.93895\n",
      "trainer/Policy log std Mean            -2.20373\n",
      "trainer/Policy log std Std              1.22107\n",
      "trainer/Alpha                           0.165556\n",
      "trainer/Alpha Loss                     -0.0356833\n",
      "exploration/num steps total        213415\n",
      "exploration/num paths total           794\n",
      "evaluation/num steps total              1.69702e+06\n",
      "evaluation/num paths total           2086\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16865\n",
      "evaluation/Rewards Std                  1.29623\n",
      "evaluation/Rewards Max                  7.25996\n",
      "evaluation/Rewards Min                  0.134342\n",
      "evaluation/Returns Mean              5168.65\n",
      "evaluation/Returns Std                 26.606\n",
      "evaluation/Returns Max               5215.89\n",
      "evaluation/Returns Min               5116.3\n",
      "evaluation/Estimation Bias Mean      1299.28\n",
      "evaluation/Estimation Bias Std        180.641\n",
      "evaluation/EB/Q_True Mean              48.9246\n",
      "evaluation/EB/Q_True Std              150.916\n",
      "evaluation/EB/Q_Pred Mean            1348.2\n",
      "evaluation/EB/Q_Pred Std              115.791\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5168.65\n",
      "evaluation/Actions Mean                 0.496835\n",
      "evaluation/Actions Std                  0.647234\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.97114\n",
      "time/backward_zf1 (s)                   2.11763\n",
      "time/backward_zf2 (s)                   2.06462\n",
      "time/data sampling (s)                  0.263333\n",
      "time/data storing (s)                   0.0155561\n",
      "time/evaluation sampling (s)            1.51675\n",
      "time/exploration sampling (s)           0.201515\n",
      "time/logging (s)                        0.0118094\n",
      "time/preback_alpha (s)                  1.04484\n",
      "time/preback_policy (s)                 1.18513\n",
      "time/preback_start (s)                  0.126838\n",
      "time/preback_zf (s)                     5.16773\n",
      "time/saving (s)                         0.00535989\n",
      "time/training (s)                       2.1498\n",
      "time/epoch (s)                         17.842\n",
      "time/total (s)                       3629.67\n",
      "Epoch                                 207\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:11:23.667215 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 208 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 219000\n",
      "trainer/ZF1 Loss                       43.5945\n",
      "trainer/ZF2 Loss                       37.9763\n",
      "trainer/ZF Expert Reward               15.878\n",
      "trainer/ZF Policy Reward                1.8439\n",
      "trainer/ZF CHI2 Term                   74.6391\n",
      "trainer/Policy Loss                 -1206.82\n",
      "trainer/Bias Loss                     125.821\n",
      "trainer/Bias Value                     19.9269\n",
      "trainer/Policy Grad Norm              326.901\n",
      "trainer/Policy Param Norm              38.3161\n",
      "trainer/Zf1 Grad Norm                4605.34\n",
      "trainer/Zf1 Param Norm                121.496\n",
      "trainer/Zf2 Grad Norm                4753.49\n",
      "trainer/Zf2 Param Norm                118.998\n",
      "trainer/Z Expert Predictions Mean    1360.72\n",
      "trainer/Z Expert Predictions Std      143.022\n",
      "trainer/Z Expert Predictions Max     1575.61\n",
      "trainer/Z Expert Predictions Min      277.302\n",
      "trainer/Z Policy Predictions Mean    1198.1\n",
      "trainer/Z Policy Predictions Std      307.211\n",
      "trainer/Z Policy Predictions Max     1557.71\n",
      "trainer/Z Policy Predictions Min      -12.8448\n",
      "trainer/Z Expert Targets Mean        1344.84\n",
      "trainer/Z Expert Targets Std          146.611\n",
      "trainer/Z Expert Targets Max         1557.35\n",
      "trainer/Z Expert Targets Min          247.509\n",
      "trainer/Z Policy Targets Mean        1196.25\n",
      "trainer/Z Policy Targets Std          306.556\n",
      "trainer/Z Policy Targets Max         1545.2\n",
      "trainer/Z Policy Targets Min           15.1909\n",
      "trainer/Log Pis Mean                   20.0197\n",
      "trainer/Log Pis Std                     4.19054\n",
      "trainer/Policy mu Mean                  1.2329\n",
      "trainer/Policy mu Std                   1.87146\n",
      "trainer/Policy log std Mean            -2.23287\n",
      "trainer/Policy log std Std              1.18649\n",
      "trainer/Alpha                           0.164523\n",
      "trainer/Alpha Loss                     -0.00324473\n",
      "exploration/num steps total        213415\n",
      "exploration/num paths total           794\n",
      "evaluation/num steps total              1.70702e+06\n",
      "evaluation/num paths total           2096\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08266\n",
      "evaluation/Rewards Std                  1.28106\n",
      "evaluation/Rewards Max                  6.89789\n",
      "evaluation/Rewards Min                  0.125409\n",
      "evaluation/Returns Mean              5082.66\n",
      "evaluation/Returns Std                 16.2511\n",
      "evaluation/Returns Max               5120.59\n",
      "evaluation/Returns Min               5057.54\n",
      "evaluation/Estimation Bias Mean      1318.43\n",
      "evaluation/Estimation Bias Std        169.228\n",
      "evaluation/EB/Q_True Mean              48.0545\n",
      "evaluation/EB/Q_True Std              148.641\n",
      "evaluation/EB/Q_Pred Mean            1366.48\n",
      "evaluation/EB/Q_Pred Std               79.133\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5082.66\n",
      "evaluation/Actions Mean                 0.495826\n",
      "evaluation/Actions Std                  0.651302\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999979\n",
      "time/backward_policy (s)                1.83596\n",
      "time/backward_zf1 (s)                   1.97586\n",
      "time/backward_zf2 (s)                   1.89738\n",
      "time/data sampling (s)                  0.248038\n",
      "time/data storing (s)                   0.0149498\n",
      "time/evaluation sampling (s)            1.39913\n",
      "time/exploration sampling (s)           0.194434\n",
      "time/logging (s)                        0.0119468\n",
      "time/preback_alpha (s)                  0.940163\n",
      "time/preback_policy (s)                 1.0316\n",
      "time/preback_start (s)                  0.122305\n",
      "time/preback_zf (s)                     5.0904\n",
      "time/saving (s)                         0.00487859\n",
      "time/training (s)                       2.36994\n",
      "time/epoch (s)                         17.137\n",
      "time/total (s)                       3646.83\n",
      "Epoch                                 208\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:11:41.139005 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 209 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 220000\n",
      "trainer/ZF1 Loss                      251.031\n",
      "trainer/ZF2 Loss                      261.181\n",
      "trainer/ZF Expert Reward               15.2562\n",
      "trainer/ZF Policy Reward                4.78193\n",
      "trainer/ZF CHI2 Term                  286.699\n",
      "trainer/Policy Loss                 -1175.49\n",
      "trainer/Bias Loss                     438.954\n",
      "trainer/Bias Value                     19.9139\n",
      "trainer/Policy Grad Norm              332.725\n",
      "trainer/Policy Param Norm              38.3533\n",
      "trainer/Zf1 Grad Norm                8406.15\n",
      "trainer/Zf1 Param Norm                121.684\n",
      "trainer/Zf2 Grad Norm               10657.7\n",
      "trainer/Zf2 Param Norm                119.18\n",
      "trainer/Z Expert Predictions Mean    1353.07\n",
      "trainer/Z Expert Predictions Std      105.093\n",
      "trainer/Z Expert Predictions Max     1580.86\n",
      "trainer/Z Expert Predictions Min      952.194\n",
      "trainer/Z Policy Predictions Mean    1162.2\n",
      "trainer/Z Policy Predictions Std      380.575\n",
      "trainer/Z Policy Predictions Max     1562.66\n",
      "trainer/Z Policy Predictions Min     -128.487\n",
      "trainer/Z Expert Targets Mean        1337.81\n",
      "trainer/Z Expert Targets Std          109.405\n",
      "trainer/Z Expert Targets Max         1556.88\n",
      "trainer/Z Expert Targets Min          922.867\n",
      "trainer/Z Policy Targets Mean        1157.42\n",
      "trainer/Z Policy Targets Std          381.361\n",
      "trainer/Z Policy Targets Max         1542.09\n",
      "trainer/Z Policy Targets Min         -122.641\n",
      "trainer/Log Pis Mean                   20.3219\n",
      "trainer/Log Pis Std                     4.54479\n",
      "trainer/Policy mu Mean                  1.27231\n",
      "trainer/Policy mu Std                   1.92091\n",
      "trainer/Policy log std Mean            -2.16362\n",
      "trainer/Policy log std Std              1.22019\n",
      "trainer/Alpha                           0.165341\n",
      "trainer/Alpha Loss                     -0.0532256\n",
      "exploration/num steps total        215415\n",
      "exploration/num paths total           796\n",
      "evaluation/num steps total              1.71702e+06\n",
      "evaluation/num paths total           2106\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21782\n",
      "evaluation/Rewards Std                  1.30974\n",
      "evaluation/Rewards Max                  7.30634\n",
      "evaluation/Rewards Min                  0.152928\n",
      "evaluation/Returns Mean              5217.82\n",
      "evaluation/Returns Std                 42.4088\n",
      "evaluation/Returns Max               5285.56\n",
      "evaluation/Returns Min               5146.32\n",
      "evaluation/Estimation Bias Mean      1277.03\n",
      "evaluation/Estimation Bias Std        183.197\n",
      "evaluation/EB/Q_True Mean              49.6347\n",
      "evaluation/EB/Q_True Std              153.477\n",
      "evaluation/EB/Q_Pred Mean            1326.66\n",
      "evaluation/EB/Q_Pred Std              108.89\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5217.82\n",
      "evaluation/Actions Mean                 0.502831\n",
      "evaluation/Actions Std                  0.643154\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.87599\n",
      "time/backward_zf1 (s)                   2.01881\n",
      "time/backward_zf2 (s)                   1.94117\n",
      "time/data sampling (s)                  0.257126\n",
      "time/data storing (s)                   0.0152667\n",
      "time/evaluation sampling (s)            1.41036\n",
      "time/exploration sampling (s)           0.204567\n",
      "time/logging (s)                        0.0124414\n",
      "time/preback_alpha (s)                  0.962317\n",
      "time/preback_policy (s)                 1.06361\n",
      "time/preback_start (s)                  0.126842\n",
      "time/preback_zf (s)                     5.14494\n",
      "time/saving (s)                         0.00536296\n",
      "time/training (s)                       2.36117\n",
      "time/epoch (s)                         17.4\n",
      "time/total (s)                       3664.26\n",
      "Epoch                                 209\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:11:58.480406 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 210 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 221000\n",
      "trainer/ZF1 Loss                       38.9486\n",
      "trainer/ZF2 Loss                       43.3273\n",
      "trainer/ZF Expert Reward               16.6281\n",
      "trainer/ZF Policy Reward                4.06861\n",
      "trainer/ZF CHI2 Term                   73.5708\n",
      "trainer/Policy Loss                 -1147.28\n",
      "trainer/Bias Loss                     145.031\n",
      "trainer/Bias Value                     19.9023\n",
      "trainer/Policy Grad Norm              285.831\n",
      "trainer/Policy Param Norm              38.3863\n",
      "trainer/Zf1 Grad Norm                3837.77\n",
      "trainer/Zf1 Param Norm                121.868\n",
      "trainer/Zf2 Grad Norm                4170.92\n",
      "trainer/Zf2 Param Norm                119.37\n",
      "trainer/Z Expert Predictions Mean    1340.84\n",
      "trainer/Z Expert Predictions Std      183.053\n",
      "trainer/Z Expert Predictions Max     1567.2\n",
      "trainer/Z Expert Predictions Min      -64.4251\n",
      "trainer/Z Policy Predictions Mean    1146.51\n",
      "trainer/Z Policy Predictions Std      351.965\n",
      "trainer/Z Policy Predictions Max     1547.55\n",
      "trainer/Z Policy Predictions Min     -132.986\n",
      "trainer/Z Expert Targets Mean        1324.21\n",
      "trainer/Z Expert Targets Std          183.358\n",
      "trainer/Z Expert Targets Max         1554.47\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1142.44\n",
      "trainer/Z Policy Targets Std          346.52\n",
      "trainer/Z Policy Targets Max         1541.59\n",
      "trainer/Z Policy Targets Min         -114.682\n",
      "trainer/Log Pis Mean                   20.0742\n",
      "trainer/Log Pis Std                     4.49972\n",
      "trainer/Policy mu Mean                  1.3136\n",
      "trainer/Policy mu Std                   1.89051\n",
      "trainer/Policy log std Mean            -2.13165\n",
      "trainer/Policy log std Std              1.15056\n",
      "trainer/Alpha                           0.168766\n",
      "trainer/Alpha Loss                     -0.0125149\n",
      "exploration/num steps total        215415\n",
      "exploration/num paths total           796\n",
      "evaluation/num steps total              1.7268e+06\n",
      "evaluation/num paths total           2116\n",
      "evaluation/path length Mean           977.5\n",
      "evaluation/path length Std             67.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            775\n",
      "evaluation/Rewards Mean                 5.12724\n",
      "evaluation/Rewards Std                  1.31161\n",
      "evaluation/Rewards Max                  7.29996\n",
      "evaluation/Rewards Min                  0.122824\n",
      "evaluation/Returns Mean              5011.88\n",
      "evaluation/Returns Std                415.524\n",
      "evaluation/Returns Max               5197.03\n",
      "evaluation/Returns Min               3768.64\n",
      "evaluation/Estimation Bias Mean      1239.66\n",
      "evaluation/Estimation Bias Std        234.447\n",
      "evaluation/EB/Q_True Mean              49.7058\n",
      "evaluation/EB/Q_True Std              151.8\n",
      "evaluation/EB/Q_Pred Mean            1289.37\n",
      "evaluation/EB/Q_Pred Std              165.89\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5011.88\n",
      "evaluation/Actions Mean                 0.514315\n",
      "evaluation/Actions Std                  0.641902\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.88963\n",
      "time/backward_zf1 (s)                   2.03773\n",
      "time/backward_zf2 (s)                   1.96322\n",
      "time/data sampling (s)                  0.257646\n",
      "time/data storing (s)                   0.0142862\n",
      "time/evaluation sampling (s)            1.41718\n",
      "time/exploration sampling (s)           0.194874\n",
      "time/logging (s)                        0.0112452\n",
      "time/preback_alpha (s)                  0.985443\n",
      "time/preback_policy (s)                 1.10283\n",
      "time/preback_start (s)                  0.12391\n",
      "time/preback_zf (s)                     5.08121\n",
      "time/saving (s)                         0.00534468\n",
      "time/training (s)                       2.18485\n",
      "time/epoch (s)                         17.2694\n",
      "time/total (s)                       3681.55\n",
      "Epoch                                 210\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:12:16.441963 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 211 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 222000\n",
      "trainer/ZF1 Loss                       30.5314\n",
      "trainer/ZF2 Loss                       24.3779\n",
      "trainer/ZF Expert Reward               16.9207\n",
      "trainer/ZF Policy Reward                2.86153\n",
      "trainer/ZF CHI2 Term                   61.5603\n",
      "trainer/Policy Loss                 -1209.46\n",
      "trainer/Bias Loss                     164.879\n",
      "trainer/Bias Value                     19.8916\n",
      "trainer/Policy Grad Norm              385.74\n",
      "trainer/Policy Param Norm              38.4293\n",
      "trainer/Zf1 Grad Norm                4245.69\n",
      "trainer/Zf1 Param Norm                122.055\n",
      "trainer/Zf2 Grad Norm                3727.19\n",
      "trainer/Zf2 Param Norm                119.564\n",
      "trainer/Z Expert Predictions Mean    1335.41\n",
      "trainer/Z Expert Predictions Std      136.104\n",
      "trainer/Z Expert Predictions Max     1572.41\n",
      "trainer/Z Expert Predictions Min      358.851\n",
      "trainer/Z Policy Predictions Mean    1201.93\n",
      "trainer/Z Policy Predictions Std      306.147\n",
      "trainer/Z Policy Predictions Max     1552.63\n",
      "trainer/Z Policy Predictions Min      -68.7561\n",
      "trainer/Z Expert Targets Mean        1318.48\n",
      "trainer/Z Expert Targets Std          142.338\n",
      "trainer/Z Expert Targets Max         1555.51\n",
      "trainer/Z Expert Targets Min          303.563\n",
      "trainer/Z Policy Targets Mean        1199.07\n",
      "trainer/Z Policy Targets Std          301.201\n",
      "trainer/Z Policy Targets Max         1542.28\n",
      "trainer/Z Policy Targets Min          -41.6362\n",
      "trainer/Log Pis Mean                   20.249\n",
      "trainer/Log Pis Std                     4.22712\n",
      "trainer/Policy mu Mean                  1.27233\n",
      "trainer/Policy mu Std                   1.88721\n",
      "trainer/Policy log std Mean            -2.20873\n",
      "trainer/Policy log std Std              1.18342\n",
      "trainer/Alpha                           0.169474\n",
      "trainer/Alpha Loss                     -0.0421889\n",
      "exploration/num steps total        215415\n",
      "exploration/num paths total           796\n",
      "evaluation/num steps total              1.7368e+06\n",
      "evaluation/num paths total           2126\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13241\n",
      "evaluation/Rewards Std                  1.29571\n",
      "evaluation/Rewards Max                  7.22706\n",
      "evaluation/Rewards Min                  0.113512\n",
      "evaluation/Returns Mean              5132.41\n",
      "evaluation/Returns Std                 25.2371\n",
      "evaluation/Returns Max               5165.04\n",
      "evaluation/Returns Min               5084.96\n",
      "evaluation/Estimation Bias Mean      1306.64\n",
      "evaluation/Estimation Bias Std        186.524\n",
      "evaluation/EB/Q_True Mean              48.8147\n",
      "evaluation/EB/Q_True Std              151.067\n",
      "evaluation/EB/Q_Pred Mean            1355.46\n",
      "evaluation/EB/Q_Pred Std               90.1578\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5132.41\n",
      "evaluation/Actions Mean                 0.505415\n",
      "evaluation/Actions Std                  0.643213\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.9968\n",
      "time/backward_zf1 (s)                   2.15197\n",
      "time/backward_zf2 (s)                   2.10182\n",
      "time/data sampling (s)                  0.259522\n",
      "time/data storing (s)                   0.0156537\n",
      "time/evaluation sampling (s)            1.49609\n",
      "time/exploration sampling (s)           0.198368\n",
      "time/logging (s)                        0.0116973\n",
      "time/preback_alpha (s)                  1.03236\n",
      "time/preback_policy (s)                 1.19554\n",
      "time/preback_start (s)                  0.125803\n",
      "time/preback_zf (s)                     5.14903\n",
      "time/saving (s)                         0.00495989\n",
      "time/training (s)                       2.1547\n",
      "time/epoch (s)                         17.8943\n",
      "time/total (s)                       3699.46\n",
      "Epoch                                 211\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:12:34.589969 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 212 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 223000\n",
      "trainer/ZF1 Loss                       37.4808\n",
      "trainer/ZF2 Loss                       51.1034\n",
      "trainer/ZF Expert Reward               21.5448\n",
      "trainer/ZF Policy Reward                9.417\n",
      "trainer/ZF CHI2 Term                   76.6104\n",
      "trainer/Policy Loss                 -1160.46\n",
      "trainer/Bias Loss                     190.725\n",
      "trainer/Bias Value                     19.8791\n",
      "trainer/Policy Grad Norm              262.449\n",
      "trainer/Policy Param Norm              38.462\n",
      "trainer/Zf1 Grad Norm                5014.9\n",
      "trainer/Zf1 Param Norm                122.241\n",
      "trainer/Zf2 Grad Norm                4433.31\n",
      "trainer/Zf2 Param Norm                119.75\n",
      "trainer/Z Expert Predictions Mean    1334.55\n",
      "trainer/Z Expert Predictions Std      180.713\n",
      "trainer/Z Expert Predictions Max     1561.64\n",
      "trainer/Z Expert Predictions Min       62.5469\n",
      "trainer/Z Policy Predictions Mean    1157.71\n",
      "trainer/Z Policy Predictions Std      357.916\n",
      "trainer/Z Policy Predictions Max     1540.31\n",
      "trainer/Z Policy Predictions Min      -67.8676\n",
      "trainer/Z Expert Targets Mean        1313\n",
      "trainer/Z Expert Targets Std          185.893\n",
      "trainer/Z Expert Targets Max         1548.03\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1148.29\n",
      "trainer/Z Policy Targets Std          356.203\n",
      "trainer/Z Policy Targets Max         1537.66\n",
      "trainer/Z Policy Targets Min         -121.129\n",
      "trainer/Log Pis Mean                   20.3944\n",
      "trainer/Log Pis Std                     5.04352\n",
      "trainer/Policy mu Mean                  1.32702\n",
      "trainer/Policy mu Std                   1.93626\n",
      "trainer/Policy log std Mean            -2.10479\n",
      "trainer/Policy log std Std              1.18619\n",
      "trainer/Alpha                           0.172016\n",
      "trainer/Alpha Loss                     -0.0678399\n",
      "exploration/num steps total        216415\n",
      "exploration/num paths total           797\n",
      "evaluation/num steps total              1.7468e+06\n",
      "evaluation/num paths total           2136\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10768\n",
      "evaluation/Rewards Std                  1.2877\n",
      "evaluation/Rewards Max                  7.23824\n",
      "evaluation/Rewards Min                  0.131979\n",
      "evaluation/Returns Mean              5107.68\n",
      "evaluation/Returns Std                 28.4786\n",
      "evaluation/Returns Max               5169.7\n",
      "evaluation/Returns Min               5059.31\n",
      "evaluation/Estimation Bias Mean      1310.95\n",
      "evaluation/Estimation Bias Std        186.418\n",
      "evaluation/EB/Q_True Mean              48.1872\n",
      "evaluation/EB/Q_True Std              148.78\n",
      "evaluation/EB/Q_Pred Mean            1359.14\n",
      "evaluation/EB/Q_Pred Std               94.957\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5107.68\n",
      "evaluation/Actions Mean                 0.50035\n",
      "evaluation/Actions Std                  0.643265\n",
      "evaluation/Actions Max                  0.999975\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                2.06259\n",
      "time/backward_zf1 (s)                   2.19394\n",
      "time/backward_zf2 (s)                   2.14659\n",
      "time/data sampling (s)                  0.2573\n",
      "time/data storing (s)                   0.0153127\n",
      "time/evaluation sampling (s)            1.40541\n",
      "time/exploration sampling (s)           0.202205\n",
      "time/logging (s)                        0.016541\n",
      "time/preback_alpha (s)                  1.0587\n",
      "time/preback_policy (s)                 1.2157\n",
      "time/preback_start (s)                  0.127532\n",
      "time/preback_zf (s)                     5.17588\n",
      "time/saving (s)                         0.00603191\n",
      "time/training (s)                       2.19787\n",
      "time/epoch (s)                         18.0816\n",
      "time/total (s)                       3717.57\n",
      "Epoch                                 212\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:12:52.667429 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 213 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 224000\n",
      "trainer/ZF1 Loss                      328.577\n",
      "trainer/ZF2 Loss                      331.745\n",
      "trainer/ZF Expert Reward               24.3116\n",
      "trainer/ZF Policy Reward                4.17158\n",
      "trainer/ZF CHI2 Term                  369.936\n",
      "trainer/Policy Loss                 -1185.55\n",
      "trainer/Bias Loss                    3204.18\n",
      "trainer/Bias Value                     19.8664\n",
      "trainer/Policy Grad Norm              259.1\n",
      "trainer/Policy Param Norm              38.4982\n",
      "trainer/Zf1 Grad Norm                6393.78\n",
      "trainer/Zf1 Param Norm                122.43\n",
      "trainer/Zf2 Grad Norm                6854.36\n",
      "trainer/Zf2 Param Norm                119.95\n",
      "trainer/Z Expert Predictions Mean    1339.53\n",
      "trainer/Z Expert Predictions Std      112.461\n",
      "trainer/Z Expert Predictions Max     1563.32\n",
      "trainer/Z Expert Predictions Min      973.496\n",
      "trainer/Z Policy Predictions Mean    1180.91\n",
      "trainer/Z Policy Predictions Std      334.168\n",
      "trainer/Z Policy Predictions Max     1553.73\n",
      "trainer/Z Policy Predictions Min      -73.5452\n",
      "trainer/Z Expert Targets Mean        1315.22\n",
      "trainer/Z Expert Targets Std          141.009\n",
      "trainer/Z Expert Targets Max         1541.12\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1176.74\n",
      "trainer/Z Policy Targets Std          330.838\n",
      "trainer/Z Policy Targets Max         1544.86\n",
      "trainer/Z Policy Targets Min          -40.0951\n",
      "trainer/Log Pis Mean                   19.8334\n",
      "trainer/Log Pis Std                     4.15814\n",
      "trainer/Policy mu Mean                  1.18687\n",
      "trainer/Policy mu Std                   1.84872\n",
      "trainer/Policy log std Mean            -2.27721\n",
      "trainer/Policy log std Std              1.19044\n",
      "trainer/Alpha                           0.173759\n",
      "trainer/Alpha Loss                      0.0289564\n",
      "exploration/num steps total        219415\n",
      "exploration/num paths total           800\n",
      "evaluation/num steps total              1.7568e+06\n",
      "evaluation/num paths total           2146\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09229\n",
      "evaluation/Rewards Std                  1.28589\n",
      "evaluation/Rewards Max                  7.16987\n",
      "evaluation/Rewards Min                  0.123023\n",
      "evaluation/Returns Mean              5092.29\n",
      "evaluation/Returns Std                 41.108\n",
      "evaluation/Returns Max               5140.24\n",
      "evaluation/Returns Min               4991.4\n",
      "evaluation/Estimation Bias Mean      1264.04\n",
      "evaluation/Estimation Bias Std        179.583\n",
      "evaluation/EB/Q_True Mean              48.1447\n",
      "evaluation/EB/Q_True Std              148.598\n",
      "evaluation/EB/Q_Pred Mean            1312.19\n",
      "evaluation/EB/Q_Pred Std              105.089\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5092.29\n",
      "evaluation/Actions Mean                 0.513365\n",
      "evaluation/Actions Std                  0.642303\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                2.03729\n",
      "time/backward_zf1 (s)                   2.17241\n",
      "time/backward_zf2 (s)                   2.11548\n",
      "time/data sampling (s)                  0.264472\n",
      "time/data storing (s)                   0.0146024\n",
      "time/evaluation sampling (s)            1.44305\n",
      "time/exploration sampling (s)           0.205033\n",
      "time/logging (s)                        0.016017\n",
      "time/preback_alpha (s)                  1.06092\n",
      "time/preback_policy (s)                 1.20639\n",
      "time/preback_start (s)                  0.127218\n",
      "time/preback_zf (s)                     5.15972\n",
      "time/saving (s)                         0.00637964\n",
      "time/training (s)                       2.17689\n",
      "time/epoch (s)                         18.0059\n",
      "time/total (s)                       3735.59\n",
      "Epoch                                 213\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:13:10.350121 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 214 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 225000\n",
      "trainer/ZF1 Loss                       34.2339\n",
      "trainer/ZF2 Loss                       36.858\n",
      "trainer/ZF Expert Reward               11.6538\n",
      "trainer/ZF Policy Reward               -5.70115\n",
      "trainer/ZF CHI2 Term                   72.0067\n",
      "trainer/Policy Loss                 -1151.83\n",
      "trainer/Bias Loss                     158.212\n",
      "trainer/Bias Value                     19.8537\n",
      "trainer/Policy Grad Norm              292.738\n",
      "trainer/Policy Param Norm              38.5322\n",
      "trainer/Zf1 Grad Norm                6351.03\n",
      "trainer/Zf1 Param Norm                122.623\n",
      "trainer/Zf2 Grad Norm                6197.49\n",
      "trainer/Zf2 Param Norm                120.148\n",
      "trainer/Z Expert Predictions Mean    1318.12\n",
      "trainer/Z Expert Predictions Std      146.612\n",
      "trainer/Z Expert Predictions Max     1544.45\n",
      "trainer/Z Expert Predictions Min      369.283\n",
      "trainer/Z Policy Predictions Mean    1132.03\n",
      "trainer/Z Policy Predictions Std      330.077\n",
      "trainer/Z Policy Predictions Max     1534.36\n",
      "trainer/Z Policy Predictions Min      -24.0584\n",
      "trainer/Z Expert Targets Mean        1306.47\n",
      "trainer/Z Expert Targets Std          148.208\n",
      "trainer/Z Expert Targets Max         1541.09\n",
      "trainer/Z Expert Targets Min          369.038\n",
      "trainer/Z Policy Targets Mean        1137.74\n",
      "trainer/Z Policy Targets Std          329.256\n",
      "trainer/Z Policy Targets Max         1541.18\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   19.2987\n",
      "trainer/Log Pis Std                     4.17165\n",
      "trainer/Policy mu Mean                  1.28596\n",
      "trainer/Policy mu Std                   1.76594\n",
      "trainer/Policy log std Mean            -2.22458\n",
      "trainer/Policy log std Std              1.18163\n",
      "trainer/Alpha                           0.172999\n",
      "trainer/Alpha Loss                      0.121321\n",
      "exploration/num steps total        221415\n",
      "exploration/num paths total           802\n",
      "evaluation/num steps total              1.7668e+06\n",
      "evaluation/num paths total           2156\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1227\n",
      "evaluation/Rewards Std                  1.28804\n",
      "evaluation/Rewards Max                  7.00267\n",
      "evaluation/Rewards Min                  0.112916\n",
      "evaluation/Returns Mean              5122.7\n",
      "evaluation/Returns Std                 27.0586\n",
      "evaluation/Returns Max               5176.83\n",
      "evaluation/Returns Min               5083.27\n",
      "evaluation/Estimation Bias Mean      1279.61\n",
      "evaluation/Estimation Bias Std        176.368\n",
      "evaluation/EB/Q_True Mean              48.2853\n",
      "evaluation/EB/Q_True Std              149.135\n",
      "evaluation/EB/Q_Pred Mean            1327.9\n",
      "evaluation/EB/Q_Pred Std               86.6899\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5122.7\n",
      "evaluation/Actions Mean                 0.494504\n",
      "evaluation/Actions Std                  0.649723\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                1.97692\n",
      "time/backward_zf1 (s)                   2.10682\n",
      "time/backward_zf2 (s)                   2.05942\n",
      "time/data sampling (s)                  0.261758\n",
      "time/data storing (s)                   0.014323\n",
      "time/evaluation sampling (s)            1.41158\n",
      "time/exploration sampling (s)           0.202204\n",
      "time/logging (s)                        0.0145516\n",
      "time/preback_alpha (s)                  1.03615\n",
      "time/preback_policy (s)                 1.18466\n",
      "time/preback_start (s)                  0.125394\n",
      "time/preback_zf (s)                     5.1201\n",
      "time/saving (s)                         0.0060916\n",
      "time/training (s)                       2.09174\n",
      "time/epoch (s)                         17.6117\n",
      "time/total (s)                       3753.23\n",
      "Epoch                                 214\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:13:27.731431 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 215 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 226000\n",
      "trainer/ZF1 Loss                       34.3566\n",
      "trainer/ZF2 Loss                       33.3942\n",
      "trainer/ZF Expert Reward               13.4082\n",
      "trainer/ZF Policy Reward               -0.853496\n",
      "trainer/ZF CHI2 Term                   67.961\n",
      "trainer/Policy Loss                 -1167.69\n",
      "trainer/Bias Loss                     149.473\n",
      "trainer/Bias Value                     19.8448\n",
      "trainer/Policy Grad Norm              235.31\n",
      "trainer/Policy Param Norm              38.5732\n",
      "trainer/Zf1 Grad Norm                4913.04\n",
      "trainer/Zf1 Param Norm                122.805\n",
      "trainer/Zf2 Grad Norm                4915.4\n",
      "trainer/Zf2 Param Norm                120.344\n",
      "trainer/Z Expert Predictions Mean    1320.44\n",
      "trainer/Z Expert Predictions Std      133.684\n",
      "trainer/Z Expert Predictions Max     1561.31\n",
      "trainer/Z Expert Predictions Min      341.685\n",
      "trainer/Z Policy Predictions Mean    1155.26\n",
      "trainer/Z Policy Predictions Std      331.315\n",
      "trainer/Z Policy Predictions Max     1551.26\n",
      "trainer/Z Policy Predictions Min     -158.804\n",
      "trainer/Z Expert Targets Mean        1307.03\n",
      "trainer/Z Expert Targets Std          135.547\n",
      "trainer/Z Expert Targets Max         1541.55\n",
      "trainer/Z Expert Targets Min          294.976\n",
      "trainer/Z Policy Targets Mean        1156.12\n",
      "trainer/Z Policy Targets Std          327.436\n",
      "trainer/Z Policy Targets Max         1531.27\n",
      "trainer/Z Policy Targets Min           -1.9339\n",
      "trainer/Log Pis Mean                   20.0241\n",
      "trainer/Log Pis Std                     4.34302\n",
      "trainer/Policy mu Mean                  1.26902\n",
      "trainer/Policy mu Std                   1.90702\n",
      "trainer/Policy log std Mean            -2.1741\n",
      "trainer/Policy log std Std              1.19159\n",
      "trainer/Alpha                           0.175844\n",
      "trainer/Alpha Loss                     -0.00424029\n",
      "exploration/num steps total        222415\n",
      "exploration/num paths total           803\n",
      "evaluation/num steps total              1.7768e+06\n",
      "evaluation/num paths total           2166\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1871\n",
      "evaluation/Rewards Std                  1.30907\n",
      "evaluation/Rewards Max                  7.31988\n",
      "evaluation/Rewards Min                  0.138833\n",
      "evaluation/Returns Mean              5187.1\n",
      "evaluation/Returns Std                 20.3381\n",
      "evaluation/Returns Max               5218.11\n",
      "evaluation/Returns Min               5160.31\n",
      "evaluation/Estimation Bias Mean      1231.87\n",
      "evaluation/Estimation Bias Std        204.999\n",
      "evaluation/EB/Q_True Mean              49.0633\n",
      "evaluation/EB/Q_True Std              151.469\n",
      "evaluation/EB/Q_Pred Mean            1280.93\n",
      "evaluation/EB/Q_Pred Std              143.529\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5187.1\n",
      "evaluation/Actions Mean                 0.517305\n",
      "evaluation/Actions Std                  0.63983\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.83419\n",
      "time/backward_zf1 (s)                   1.98261\n",
      "time/backward_zf2 (s)                   1.91127\n",
      "time/data sampling (s)                  0.267226\n",
      "time/data storing (s)                   0.0148118\n",
      "time/evaluation sampling (s)            1.46791\n",
      "time/exploration sampling (s)           0.198536\n",
      "time/logging (s)                        0.0115655\n",
      "time/preback_alpha (s)                  0.942434\n",
      "time/preback_policy (s)                 1.04649\n",
      "time/preback_start (s)                  0.124172\n",
      "time/preback_zf (s)                     5.12738\n",
      "time/saving (s)                         0.00545362\n",
      "time/training (s)                       2.37425\n",
      "time/epoch (s)                         17.3083\n",
      "time/total (s)                       3770.56\n",
      "Epoch                                 215\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:13:44.912527 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 216 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 227000\n",
      "trainer/ZF1 Loss                      240.245\n",
      "trainer/ZF2 Loss                      180.711\n",
      "trainer/ZF Expert Reward               22.7907\n",
      "trainer/ZF Policy Reward                4.26525\n",
      "trainer/ZF CHI2 Term                  249.339\n",
      "trainer/Policy Loss                 -1117.13\n",
      "trainer/Bias Loss                    1923.59\n",
      "trainer/Bias Value                     19.8325\n",
      "trainer/Policy Grad Norm              279.239\n",
      "trainer/Policy Param Norm              38.6126\n",
      "trainer/Zf1 Grad Norm                9760.56\n",
      "trainer/Zf1 Param Norm                122.974\n",
      "trainer/Zf2 Grad Norm               10827.1\n",
      "trainer/Zf2 Param Norm                120.535\n",
      "trainer/Z Expert Predictions Mean    1334.82\n",
      "trainer/Z Expert Predictions Std      119.423\n",
      "trainer/Z Expert Predictions Max     1552.13\n",
      "trainer/Z Expert Predictions Min      931.714\n",
      "trainer/Z Policy Predictions Mean    1109.66\n",
      "trainer/Z Policy Predictions Std      370.125\n",
      "trainer/Z Policy Predictions Max     1540.8\n",
      "trainer/Z Policy Predictions Min     -121.053\n",
      "trainer/Z Expert Targets Mean        1312.03\n",
      "trainer/Z Expert Targets Std          144.915\n",
      "trainer/Z Expert Targets Max         1539.39\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1105.39\n",
      "trainer/Z Policy Targets Std          364.782\n",
      "trainer/Z Policy Targets Max         1525.95\n",
      "trainer/Z Policy Targets Min         -126.87\n",
      "trainer/Log Pis Mean                   20.5414\n",
      "trainer/Log Pis Std                     4.8356\n",
      "trainer/Policy mu Mean                  1.28192\n",
      "trainer/Policy mu Std                   1.97315\n",
      "trainer/Policy log std Mean            -2.10359\n",
      "trainer/Policy log std Std              1.18275\n",
      "trainer/Alpha                           0.175488\n",
      "trainer/Alpha Loss                     -0.0950145\n",
      "exploration/num steps total        223415\n",
      "exploration/num paths total           804\n",
      "evaluation/num steps total              1.7868e+06\n",
      "evaluation/num paths total           2176\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12425\n",
      "evaluation/Rewards Std                  1.2933\n",
      "evaluation/Rewards Max                  7.28726\n",
      "evaluation/Rewards Min                  0.0934281\n",
      "evaluation/Returns Mean              5124.25\n",
      "evaluation/Returns Std                 38.1162\n",
      "evaluation/Returns Max               5172.25\n",
      "evaluation/Returns Min               5044.14\n",
      "evaluation/Estimation Bias Mean      1299.18\n",
      "evaluation/Estimation Bias Std        185.66\n",
      "evaluation/EB/Q_True Mean              48.1964\n",
      "evaluation/EB/Q_True Std              148.686\n",
      "evaluation/EB/Q_Pred Mean            1347.38\n",
      "evaluation/EB/Q_Pred Std               93.5969\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5124.25\n",
      "evaluation/Actions Mean                 0.511069\n",
      "evaluation/Actions Std                  0.643891\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.81334\n",
      "time/backward_zf1 (s)                   1.94909\n",
      "time/backward_zf2 (s)                   1.86907\n",
      "time/data sampling (s)                  0.270347\n",
      "time/data storing (s)                   0.0146546\n",
      "time/evaluation sampling (s)            1.39487\n",
      "time/exploration sampling (s)           0.198661\n",
      "time/logging (s)                        0.0132824\n",
      "time/preback_alpha (s)                  0.927219\n",
      "time/preback_policy (s)                 1.01596\n",
      "time/preback_start (s)                  0.12323\n",
      "time/preback_zf (s)                     5.11262\n",
      "time/saving (s)                         0.0210816\n",
      "time/training (s)                       2.39169\n",
      "time/epoch (s)                         17.1151\n",
      "time/total (s)                       3787.69\n",
      "Epoch                                 216\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:14:02.635033 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 217 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 228000\n",
      "trainer/ZF1 Loss                       66.2612\n",
      "trainer/ZF2 Loss                       61.0212\n",
      "trainer/ZF Expert Reward               30.1769\n",
      "trainer/ZF Policy Reward               14.4742\n",
      "trainer/ZF CHI2 Term                   99.4369\n",
      "trainer/Policy Loss                 -1117.64\n",
      "trainer/Bias Loss                     286.9\n",
      "trainer/Bias Value                     19.82\n",
      "trainer/Policy Grad Norm              314.824\n",
      "trainer/Policy Param Norm              38.6545\n",
      "trainer/Zf1 Grad Norm                6078.12\n",
      "trainer/Zf1 Param Norm                123.149\n",
      "trainer/Zf2 Grad Norm                6246.76\n",
      "trainer/Zf2 Param Norm                120.715\n",
      "trainer/Z Expert Predictions Mean    1316.36\n",
      "trainer/Z Expert Predictions Std      146.573\n",
      "trainer/Z Expert Predictions Max     1564.76\n",
      "trainer/Z Expert Predictions Min      253.424\n",
      "trainer/Z Policy Predictions Mean    1117.65\n",
      "trainer/Z Policy Predictions Std      377.592\n",
      "trainer/Z Policy Predictions Max     1548.14\n",
      "trainer/Z Policy Predictions Min     -465.344\n",
      "trainer/Z Expert Targets Mean        1286.18\n",
      "trainer/Z Expert Targets Std          152.318\n",
      "trainer/Z Expert Targets Max         1528.18\n",
      "trainer/Z Expert Targets Min          204.169\n",
      "trainer/Z Policy Targets Mean        1103.17\n",
      "trainer/Z Policy Targets Std          367.955\n",
      "trainer/Z Policy Targets Max         1524.63\n",
      "trainer/Z Policy Targets Min         -432.142\n",
      "trainer/Log Pis Mean                   20.296\n",
      "trainer/Log Pis Std                     5.04963\n",
      "trainer/Policy mu Mean                  1.2738\n",
      "trainer/Policy mu Std                   1.94678\n",
      "trainer/Policy log std Mean            -2.16093\n",
      "trainer/Policy log std Std              1.19941\n",
      "trainer/Alpha                           0.179073\n",
      "trainer/Alpha Loss                     -0.0530016\n",
      "exploration/num steps total        223415\n",
      "exploration/num paths total           804\n",
      "evaluation/num steps total              1.7968e+06\n",
      "evaluation/num paths total           2186\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18707\n",
      "evaluation/Rewards Std                  1.32223\n",
      "evaluation/Rewards Max                  7.27876\n",
      "evaluation/Rewards Min                  0.109781\n",
      "evaluation/Returns Mean              5187.07\n",
      "evaluation/Returns Std                  8.12874\n",
      "evaluation/Returns Max               5197.53\n",
      "evaluation/Returns Min               5171.18\n",
      "evaluation/Estimation Bias Mean      1214.86\n",
      "evaluation/Estimation Bias Std        210.415\n",
      "evaluation/EB/Q_True Mean              49.0763\n",
      "evaluation/EB/Q_True Std              151.672\n",
      "evaluation/EB/Q_Pred Mean            1263.94\n",
      "evaluation/EB/Q_Pred Std              132.697\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5187.07\n",
      "evaluation/Actions Mean                 0.505285\n",
      "evaluation/Actions Std                  0.643808\n",
      "evaluation/Actions Max                  0.999981\n",
      "evaluation/Actions Min                 -0.999985\n",
      "time/backward_policy (s)                1.97631\n",
      "time/backward_zf1 (s)                   2.11201\n",
      "time/backward_zf2 (s)                   2.05793\n",
      "time/data sampling (s)                  0.260275\n",
      "time/data storing (s)                   0.0137204\n",
      "time/evaluation sampling (s)            1.44741\n",
      "time/exploration sampling (s)           0.189211\n",
      "time/logging (s)                        0.0118692\n",
      "time/preback_alpha (s)                  1.03681\n",
      "time/preback_policy (s)                 1.17544\n",
      "time/preback_start (s)                  0.122752\n",
      "time/preback_zf (s)                     5.11445\n",
      "time/saving (s)                         0.005495\n",
      "time/training (s)                       2.13143\n",
      "time/epoch (s)                         17.6551\n",
      "time/total (s)                       3805.37\n",
      "Epoch                                 217\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:14:20.138665 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 218 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 229000\n",
      "trainer/ZF1 Loss                       47.8788\n",
      "trainer/ZF2 Loss                       50.0903\n",
      "trainer/ZF Expert Reward               11.6172\n",
      "trainer/ZF Policy Reward               -4.90938\n",
      "trainer/ZF CHI2 Term                   84.9357\n",
      "trainer/Policy Loss                 -1189.39\n",
      "trainer/Bias Loss                     280.601\n",
      "trainer/Bias Value                     19.8063\n",
      "trainer/Policy Grad Norm              333.147\n",
      "trainer/Policy Param Norm              38.6901\n",
      "trainer/Zf1 Grad Norm                6163.73\n",
      "trainer/Zf1 Param Norm                123.319\n",
      "trainer/Zf2 Grad Norm                7058.67\n",
      "trainer/Zf2 Param Norm                120.886\n",
      "trainer/Z Expert Predictions Mean    1319.26\n",
      "trainer/Z Expert Predictions Std      109.018\n",
      "trainer/Z Expert Predictions Max     1531.2\n",
      "trainer/Z Expert Predictions Min      877.556\n",
      "trainer/Z Policy Predictions Mean    1174.29\n",
      "trainer/Z Policy Predictions Std      294.389\n",
      "trainer/Z Policy Predictions Max     1540.28\n",
      "trainer/Z Policy Predictions Min     -143.076\n",
      "trainer/Z Expert Targets Mean        1307.64\n",
      "trainer/Z Expert Targets Std          113.575\n",
      "trainer/Z Expert Targets Max         1532.79\n",
      "trainer/Z Expert Targets Min          856.095\n",
      "trainer/Z Policy Targets Mean        1179.2\n",
      "trainer/Z Policy Targets Std          289.713\n",
      "trainer/Z Policy Targets Max         1530.56\n",
      "trainer/Z Policy Targets Min         -109.866\n",
      "trainer/Log Pis Mean                   19.6207\n",
      "trainer/Log Pis Std                     4.16819\n",
      "trainer/Policy mu Mean                  1.29521\n",
      "trainer/Policy mu Std                   1.79398\n",
      "trainer/Policy log std Mean            -2.1774\n",
      "trainer/Policy log std Std              1.15829\n",
      "trainer/Alpha                           0.176116\n",
      "trainer/Alpha Loss                      0.0667984\n",
      "exploration/num steps total        223415\n",
      "exploration/num paths total           804\n",
      "evaluation/num steps total              1.8068e+06\n",
      "evaluation/num paths total           2196\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07854\n",
      "evaluation/Rewards Std                  1.29056\n",
      "evaluation/Rewards Max                  7.25003\n",
      "evaluation/Rewards Min                  0.0952219\n",
      "evaluation/Returns Mean              5078.54\n",
      "evaluation/Returns Std                 40.5142\n",
      "evaluation/Returns Max               5164.22\n",
      "evaluation/Returns Min               5021.99\n",
      "evaluation/Estimation Bias Mean      1243.05\n",
      "evaluation/Estimation Bias Std        184.428\n",
      "evaluation/EB/Q_True Mean              48.8139\n",
      "evaluation/EB/Q_True Std              151.043\n",
      "evaluation/EB/Q_Pred Mean            1291.86\n",
      "evaluation/EB/Q_Pred Std              109.022\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5078.54\n",
      "evaluation/Actions Mean                 0.507999\n",
      "evaluation/Actions Std                  0.649899\n",
      "evaluation/Actions Max                  0.99998\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.943\n",
      "time/backward_zf1 (s)                   2.07245\n",
      "time/backward_zf2 (s)                   1.99968\n",
      "time/data sampling (s)                  0.254166\n",
      "time/data storing (s)                   0.0143482\n",
      "time/evaluation sampling (s)            1.42923\n",
      "time/exploration sampling (s)           0.195059\n",
      "time/logging (s)                        0.0114763\n",
      "time/preback_alpha (s)                  1.01054\n",
      "time/preback_policy (s)                 1.1352\n",
      "time/preback_start (s)                  0.12378\n",
      "time/preback_zf (s)                     5.08616\n",
      "time/saving (s)                         0.00529594\n",
      "time/training (s)                       2.15277\n",
      "time/epoch (s)                         17.4332\n",
      "time/total (s)                       3822.82\n",
      "Epoch                                 218\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:14:37.783876 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 219 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 230000\n",
      "trainer/ZF1 Loss                       29.6779\n",
      "trainer/ZF2 Loss                       35.6503\n",
      "trainer/ZF Expert Reward               16.5269\n",
      "trainer/ZF Policy Reward                1.12369\n",
      "trainer/ZF CHI2 Term                   67.6285\n",
      "trainer/Policy Loss                 -1142.71\n",
      "trainer/Bias Loss                     184.298\n",
      "trainer/Bias Value                     19.798\n",
      "trainer/Policy Grad Norm              268.24\n",
      "trainer/Policy Param Norm              38.7304\n",
      "trainer/Zf1 Grad Norm                3556.57\n",
      "trainer/Zf1 Param Norm                123.501\n",
      "trainer/Zf2 Grad Norm                4715.58\n",
      "trainer/Zf2 Param Norm                121.065\n",
      "trainer/Z Expert Predictions Mean    1298.06\n",
      "trainer/Z Expert Predictions Std      166.878\n",
      "trainer/Z Expert Predictions Max     1547.69\n",
      "trainer/Z Expert Predictions Min      277.442\n",
      "trainer/Z Policy Predictions Mean    1132.77\n",
      "trainer/Z Policy Predictions Std      324.738\n",
      "trainer/Z Policy Predictions Max     1523.68\n",
      "trainer/Z Policy Predictions Min     -262.519\n",
      "trainer/Z Expert Targets Mean        1281.53\n",
      "trainer/Z Expert Targets Std          168.416\n",
      "trainer/Z Expert Targets Max         1526.38\n",
      "trainer/Z Expert Targets Min          256.31\n",
      "trainer/Z Policy Targets Mean        1131.64\n",
      "trainer/Z Policy Targets Std          320.474\n",
      "trainer/Z Policy Targets Max         1520.38\n",
      "trainer/Z Policy Targets Min         -227.494\n",
      "trainer/Log Pis Mean                   19.7587\n",
      "trainer/Log Pis Std                     4.70981\n",
      "trainer/Policy mu Mean                  1.27398\n",
      "trainer/Policy mu Std                   1.90163\n",
      "trainer/Policy log std Mean            -2.11814\n",
      "trainer/Policy log std Std              1.18484\n",
      "trainer/Alpha                           0.176446\n",
      "trainer/Alpha Loss                      0.0425683\n",
      "exploration/num steps total        225415\n",
      "exploration/num paths total           806\n",
      "evaluation/num steps total              1.8168e+06\n",
      "evaluation/num paths total           2206\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16273\n",
      "evaluation/Rewards Std                  1.31445\n",
      "evaluation/Rewards Max                  7.14711\n",
      "evaluation/Rewards Min                  0.0997293\n",
      "evaluation/Returns Mean              5162.73\n",
      "evaluation/Returns Std                 12.4548\n",
      "evaluation/Returns Max               5185.4\n",
      "evaluation/Returns Min               5142.95\n",
      "evaluation/Estimation Bias Mean      1315.64\n",
      "evaluation/Estimation Bias Std        163.163\n",
      "evaluation/EB/Q_True Mean              48.8573\n",
      "evaluation/EB/Q_True Std              150.869\n",
      "evaluation/EB/Q_Pred Mean            1364.49\n",
      "evaluation/EB/Q_Pred Std               69.2917\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5162.73\n",
      "evaluation/Actions Mean                 0.492182\n",
      "evaluation/Actions Std                  0.653475\n",
      "evaluation/Actions Max                  0.999972\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.9407\n",
      "time/backward_zf1 (s)                   2.11193\n",
      "time/backward_zf2 (s)                   2.03495\n",
      "time/data sampling (s)                  0.257946\n",
      "time/data storing (s)                   0.0149813\n",
      "time/evaluation sampling (s)            1.44883\n",
      "time/exploration sampling (s)           0.204449\n",
      "time/logging (s)                        0.0119931\n",
      "time/preback_alpha (s)                  1.0085\n",
      "time/preback_policy (s)                 1.1435\n",
      "time/preback_start (s)                  0.125883\n",
      "time/preback_zf (s)                     5.09762\n",
      "time/saving (s)                         0.00639707\n",
      "time/training (s)                       2.16844\n",
      "time/epoch (s)                         17.5761\n",
      "time/total (s)                       3840.42\n",
      "Epoch                                 219\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:14:55.814179 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 220 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 231000\n",
      "trainer/ZF1 Loss                       35.3977\n",
      "trainer/ZF2 Loss                       40.4694\n",
      "trainer/ZF Expert Reward               28.9314\n",
      "trainer/ZF Policy Reward               12.4792\n",
      "trainer/ZF CHI2 Term                   74.184\n",
      "trainer/Policy Loss                 -1123.86\n",
      "trainer/Bias Loss                     187.443\n",
      "trainer/Bias Value                     19.7854\n",
      "trainer/Policy Grad Norm              250.985\n",
      "trainer/Policy Param Norm              38.768\n",
      "trainer/Zf1 Grad Norm                4259.26\n",
      "trainer/Zf1 Param Norm                123.689\n",
      "trainer/Zf2 Grad Norm                5046.96\n",
      "trainer/Zf2 Param Norm                121.261\n",
      "trainer/Z Expert Predictions Mean    1294.61\n",
      "trainer/Z Expert Predictions Std      174.184\n",
      "trainer/Z Expert Predictions Max     1545.2\n",
      "trainer/Z Expert Predictions Min      298.335\n",
      "trainer/Z Policy Predictions Mean    1125.78\n",
      "trainer/Z Policy Predictions Std      331.578\n",
      "trainer/Z Policy Predictions Max     1537.6\n",
      "trainer/Z Policy Predictions Min      -61.6849\n",
      "trainer/Z Expert Targets Mean        1265.68\n",
      "trainer/Z Expert Targets Std          177.785\n",
      "trainer/Z Expert Targets Max         1527.23\n",
      "trainer/Z Expert Targets Min          244.446\n",
      "trainer/Z Policy Targets Mean        1113.3\n",
      "trainer/Z Policy Targets Std          326.008\n",
      "trainer/Z Policy Targets Max         1526.62\n",
      "trainer/Z Policy Targets Min          -57.4955\n",
      "trainer/Log Pis Mean                   19.9983\n",
      "trainer/Log Pis Std                     4.91541\n",
      "trainer/Policy mu Mean                  1.29306\n",
      "trainer/Policy mu Std                   1.8776\n",
      "trainer/Policy log std Mean            -2.18677\n",
      "trainer/Policy log std Std              1.20915\n",
      "trainer/Alpha                           0.174913\n",
      "trainer/Alpha Loss                      0.000295071\n",
      "exploration/num steps total        225415\n",
      "exploration/num paths total           806\n",
      "evaluation/num steps total              1.8268e+06\n",
      "evaluation/num paths total           2216\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19528\n",
      "evaluation/Rewards Std                  1.31243\n",
      "evaluation/Rewards Max                  7.14685\n",
      "evaluation/Rewards Min                  0.117286\n",
      "evaluation/Returns Mean              5195.28\n",
      "evaluation/Returns Std                 18.167\n",
      "evaluation/Returns Max               5226.06\n",
      "evaluation/Returns Min               5159.3\n",
      "evaluation/Estimation Bias Mean      1246.53\n",
      "evaluation/Estimation Bias Std        179.658\n",
      "evaluation/EB/Q_True Mean              49.1454\n",
      "evaluation/EB/Q_True Std              151.926\n",
      "evaluation/EB/Q_Pred Mean            1295.67\n",
      "evaluation/EB/Q_Pred Std               98.6395\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5195.28\n",
      "evaluation/Actions Mean                 0.505309\n",
      "evaluation/Actions Std                  0.647895\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.01812\n",
      "time/backward_zf1 (s)                   2.1734\n",
      "time/backward_zf2 (s)                   2.11727\n",
      "time/data sampling (s)                  0.28377\n",
      "time/data storing (s)                   0.0151048\n",
      "time/evaluation sampling (s)            1.43919\n",
      "time/exploration sampling (s)           0.199634\n",
      "time/logging (s)                        0.0118345\n",
      "time/preback_alpha (s)                  1.03118\n",
      "time/preback_policy (s)                 1.17573\n",
      "time/preback_start (s)                  0.128421\n",
      "time/preback_zf (s)                     5.16271\n",
      "time/saving (s)                         0.00522547\n",
      "time/training (s)                       2.19723\n",
      "time/epoch (s)                         17.9588\n",
      "time/total (s)                       3858.4\n",
      "Epoch                                 220\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:15:13.630477 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 221 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 232000\n",
      "trainer/ZF1 Loss                      183.987\n",
      "trainer/ZF2 Loss                      115.796\n",
      "trainer/ZF Expert Reward               16.0838\n",
      "trainer/ZF Policy Reward               -1.51652\n",
      "trainer/ZF CHI2 Term                  187.905\n",
      "trainer/Policy Loss                 -1119.44\n",
      "trainer/Bias Loss                    1337.59\n",
      "trainer/Bias Value                     19.7756\n",
      "trainer/Policy Grad Norm              322.798\n",
      "trainer/Policy Param Norm              38.8073\n",
      "trainer/Zf1 Grad Norm                9610.07\n",
      "trainer/Zf1 Param Norm                123.863\n",
      "trainer/Zf2 Grad Norm                9162.17\n",
      "trainer/Zf2 Param Norm                121.443\n",
      "trainer/Z Expert Predictions Mean    1297.89\n",
      "trainer/Z Expert Predictions Std      136.162\n",
      "trainer/Z Expert Predictions Max     1532.48\n",
      "trainer/Z Expert Predictions Min      464.04\n",
      "trainer/Z Policy Predictions Mean    1116.31\n",
      "trainer/Z Policy Predictions Std      351.288\n",
      "trainer/Z Policy Predictions Max     1545.56\n",
      "trainer/Z Policy Predictions Min      -29.1077\n",
      "trainer/Z Expert Targets Mean        1281.81\n",
      "trainer/Z Expert Targets Std          156.297\n",
      "trainer/Z Expert Targets Max         1525.57\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1117.82\n",
      "trainer/Z Policy Targets Std          347.943\n",
      "trainer/Z Policy Targets Max         1528.3\n",
      "trainer/Z Policy Targets Min          -27.6405\n",
      "trainer/Log Pis Mean                   20.6193\n",
      "trainer/Log Pis Std                     4.94858\n",
      "trainer/Policy mu Mean                  1.26092\n",
      "trainer/Policy mu Std                   1.98407\n",
      "trainer/Policy log std Mean            -2.21132\n",
      "trainer/Policy log std Std              1.23293\n",
      "trainer/Alpha                           0.172353\n",
      "trainer/Alpha Loss                     -0.106735\n",
      "exploration/num steps total        225415\n",
      "exploration/num paths total           806\n",
      "evaluation/num steps total              1.8368e+06\n",
      "evaluation/num paths total           2226\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15508\n",
      "evaluation/Rewards Std                  1.31613\n",
      "evaluation/Rewards Max                  7.13225\n",
      "evaluation/Rewards Min                  0.106405\n",
      "evaluation/Returns Mean              5155.08\n",
      "evaluation/Returns Std                 18.1863\n",
      "evaluation/Returns Max               5180.35\n",
      "evaluation/Returns Min               5126.29\n",
      "evaluation/Estimation Bias Mean      1295.44\n",
      "evaluation/Estimation Bias Std        160.967\n",
      "evaluation/EB/Q_True Mean              48.5082\n",
      "evaluation/EB/Q_True Std              149.973\n",
      "evaluation/EB/Q_Pred Mean            1343.94\n",
      "evaluation/EB/Q_Pred Std               77.5358\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5155.08\n",
      "evaluation/Actions Mean                 0.497847\n",
      "evaluation/Actions Std                  0.650025\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                1.93567\n",
      "time/backward_zf1 (s)                   2.1076\n",
      "time/backward_zf2 (s)                   2.01059\n",
      "time/data sampling (s)                  0.270301\n",
      "time/data storing (s)                   0.0149881\n",
      "time/evaluation sampling (s)            1.46223\n",
      "time/exploration sampling (s)           0.196184\n",
      "time/logging (s)                        0.0117547\n",
      "time/preback_alpha (s)                  0.998493\n",
      "time/preback_policy (s)                 1.10018\n",
      "time/preback_start (s)                  0.127696\n",
      "time/preback_zf (s)                     5.17572\n",
      "time/saving (s)                         0.00518893\n",
      "time/training (s)                       2.32963\n",
      "time/epoch (s)                         17.7462\n",
      "time/total (s)                       3876.17\n",
      "Epoch                                 221\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:15:31.667498 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 222 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 233000\n",
      "trainer/ZF1 Loss                       56.7129\n",
      "trainer/ZF2 Loss                       41.5378\n",
      "trainer/ZF Expert Reward               13.9776\n",
      "trainer/ZF Policy Reward                0.629387\n",
      "trainer/ZF CHI2 Term                   82.2075\n",
      "trainer/Policy Loss                 -1137.59\n",
      "trainer/Bias Loss                     280.578\n",
      "trainer/Bias Value                     19.7644\n",
      "trainer/Policy Grad Norm              310.182\n",
      "trainer/Policy Param Norm              38.8466\n",
      "trainer/Zf1 Grad Norm                7180.35\n",
      "trainer/Zf1 Param Norm                124.052\n",
      "trainer/Zf2 Grad Norm                5734.85\n",
      "trainer/Zf2 Param Norm                121.632\n",
      "trainer/Z Expert Predictions Mean    1290.23\n",
      "trainer/Z Expert Predictions Std      144.129\n",
      "trainer/Z Expert Predictions Max     1529.94\n",
      "trainer/Z Expert Predictions Min      474.03\n",
      "trainer/Z Policy Predictions Mean    1129.06\n",
      "trainer/Z Policy Predictions Std      324.21\n",
      "trainer/Z Policy Predictions Max     1523.44\n",
      "trainer/Z Policy Predictions Min      -38.1507\n",
      "trainer/Z Expert Targets Mean        1276.25\n",
      "trainer/Z Expert Targets Std          144.383\n",
      "trainer/Z Expert Targets Max         1522.86\n",
      "trainer/Z Expert Targets Min          423.69\n",
      "trainer/Z Policy Targets Mean        1128.43\n",
      "trainer/Z Policy Targets Std          319.474\n",
      "trainer/Z Policy Targets Max         1522.17\n",
      "trainer/Z Policy Targets Min          -15.013\n",
      "trainer/Log Pis Mean                   19.9333\n",
      "trainer/Log Pis Std                     4.75602\n",
      "trainer/Policy mu Mean                  1.21153\n",
      "trainer/Policy mu Std                   1.85902\n",
      "trainer/Policy log std Mean            -2.25707\n",
      "trainer/Policy log std Std              1.20464\n",
      "trainer/Alpha                           0.172144\n",
      "trainer/Alpha Loss                      0.0114815\n",
      "exploration/num steps total        226415\n",
      "exploration/num paths total           807\n",
      "evaluation/num steps total              1.84612e+06\n",
      "evaluation/num paths total           2236\n",
      "evaluation/path length Mean           932.2\n",
      "evaluation/path length Std            138.871\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            594\n",
      "evaluation/Rewards Mean                 5.1054\n",
      "evaluation/Rewards Std                  1.33636\n",
      "evaluation/Rewards Max                  7.84304\n",
      "evaluation/Rewards Min                  0.117255\n",
      "evaluation/Returns Mean              4759.25\n",
      "evaluation/Returns Std                802.311\n",
      "evaluation/Returns Max               5196.01\n",
      "evaluation/Returns Min               2815.09\n",
      "evaluation/Estimation Bias Mean      1219.44\n",
      "evaluation/Estimation Bias Std        244.681\n",
      "evaluation/EB/Q_True Mean              51.9135\n",
      "evaluation/EB/Q_True Std              154.01\n",
      "evaluation/EB/Q_Pred Mean            1271.35\n",
      "evaluation/EB/Q_Pred Std              168.444\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4759.25\n",
      "evaluation/Actions Mean                 0.518039\n",
      "evaluation/Actions Std                  0.641522\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97063\n",
      "time/backward_zf1 (s)                   2.12953\n",
      "time/backward_zf2 (s)                   2.02066\n",
      "time/data sampling (s)                  0.272517\n",
      "time/data storing (s)                   0.0149572\n",
      "time/evaluation sampling (s)            1.43233\n",
      "time/exploration sampling (s)           0.204537\n",
      "time/logging (s)                        0.0137675\n",
      "time/preback_alpha (s)                  1.01626\n",
      "time/preback_policy (s)                 1.14209\n",
      "time/preback_start (s)                  0.133488\n",
      "time/preback_zf (s)                     5.23624\n",
      "time/saving (s)                         0.00973947\n",
      "time/training (s)                       2.37201\n",
      "time/epoch (s)                         17.9688\n",
      "time/total (s)                       3894.16\n",
      "Epoch                                 222\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:15:49.596060 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 223 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 234000\n",
      "trainer/ZF1 Loss                      282.382\n",
      "trainer/ZF2 Loss                      271.962\n",
      "trainer/ZF Expert Reward               22.5293\n",
      "trainer/ZF Policy Reward               12.6664\n",
      "trainer/ZF CHI2 Term                  307.048\n",
      "trainer/Policy Loss                 -1157.54\n",
      "trainer/Bias Loss                     138.061\n",
      "trainer/Bias Value                     19.7528\n",
      "trainer/Policy Grad Norm              330.203\n",
      "trainer/Policy Param Norm              38.8829\n",
      "trainer/Zf1 Grad Norm                4360.76\n",
      "trainer/Zf1 Param Norm                124.235\n",
      "trainer/Zf2 Grad Norm                5580.89\n",
      "trainer/Zf2 Param Norm                121.821\n",
      "trainer/Z Expert Predictions Mean    1298.05\n",
      "trainer/Z Expert Predictions Std      139.207\n",
      "trainer/Z Expert Predictions Max     1546.42\n",
      "trainer/Z Expert Predictions Min      249.09\n",
      "trainer/Z Policy Predictions Mean    1158.43\n",
      "trainer/Z Policy Predictions Std      333.349\n",
      "trainer/Z Policy Predictions Max     1555.89\n",
      "trainer/Z Policy Predictions Min       33.1868\n",
      "trainer/Z Expert Targets Mean        1275.52\n",
      "trainer/Z Expert Targets Std          143.634\n",
      "trainer/Z Expert Targets Max         1523.38\n",
      "trainer/Z Expert Targets Min          219.052\n",
      "trainer/Z Policy Targets Mean        1145.76\n",
      "trainer/Z Policy Targets Std          335.005\n",
      "trainer/Z Policy Targets Max         1539.76\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   20.2151\n",
      "trainer/Log Pis Std                     4.17572\n",
      "trainer/Policy mu Mean                  1.26539\n",
      "trainer/Policy mu Std                   1.83642\n",
      "trainer/Policy log std Mean            -2.22291\n",
      "trainer/Policy log std Std              1.18536\n",
      "trainer/Alpha                           0.172142\n",
      "trainer/Alpha Loss                     -0.0370335\n",
      "exploration/num steps total        229415\n",
      "exploration/num paths total           810\n",
      "evaluation/num steps total              1.85612e+06\n",
      "evaluation/num paths total           2246\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09554\n",
      "evaluation/Rewards Std                  1.2846\n",
      "evaluation/Rewards Max                  6.98675\n",
      "evaluation/Rewards Min                  0.0970497\n",
      "evaluation/Returns Mean              5095.54\n",
      "evaluation/Returns Std                 20.3189\n",
      "evaluation/Returns Max               5127.42\n",
      "evaluation/Returns Min               5060.67\n",
      "evaluation/Estimation Bias Mean      1254.13\n",
      "evaluation/Estimation Bias Std        178.426\n",
      "evaluation/EB/Q_True Mean              47.8093\n",
      "evaluation/EB/Q_True Std              147.665\n",
      "evaluation/EB/Q_Pred Mean            1301.94\n",
      "evaluation/EB/Q_Pred Std               97.3131\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5095.54\n",
      "evaluation/Actions Mean                 0.504568\n",
      "evaluation/Actions Std                  0.642429\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.99277\n",
      "time/backward_zf1 (s)                   2.1496\n",
      "time/backward_zf2 (s)                   2.0701\n",
      "time/data sampling (s)                  0.286685\n",
      "time/data storing (s)                   0.0148071\n",
      "time/evaluation sampling (s)            1.43432\n",
      "time/exploration sampling (s)           0.205435\n",
      "time/logging (s)                        0.0142669\n",
      "time/preback_alpha (s)                  1.00746\n",
      "time/preback_policy (s)                 1.13077\n",
      "time/preback_start (s)                  0.128421\n",
      "time/preback_zf (s)                     5.14629\n",
      "time/saving (s)                         0.00554462\n",
      "time/training (s)                       2.27398\n",
      "time/epoch (s)                         17.8605\n",
      "time/total (s)                       3912.04\n",
      "Epoch                                 223\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:16:07.803027 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 224 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 235000\n",
      "trainer/ZF1 Loss                       32.0447\n",
      "trainer/ZF2 Loss                       32.8305\n",
      "trainer/ZF Expert Reward               20.9562\n",
      "trainer/ZF Policy Reward                4.25829\n",
      "trainer/ZF CHI2 Term                   68.8321\n",
      "trainer/Policy Loss                 -1114.72\n",
      "trainer/Bias Loss                     172.12\n",
      "trainer/Bias Value                     19.7412\n",
      "trainer/Policy Grad Norm              323.221\n",
      "trainer/Policy Param Norm              38.9239\n",
      "trainer/Zf1 Grad Norm                5370.06\n",
      "trainer/Zf1 Param Norm                124.409\n",
      "trainer/Zf2 Grad Norm                4571.24\n",
      "trainer/Zf2 Param Norm                121.995\n",
      "trainer/Z Expert Predictions Mean    1307.94\n",
      "trainer/Z Expert Predictions Std      118.235\n",
      "trainer/Z Expert Predictions Max     1545.77\n",
      "trainer/Z Expert Predictions Min      890.053\n",
      "trainer/Z Policy Predictions Mean    1116.51\n",
      "trainer/Z Policy Predictions Std      368.95\n",
      "trainer/Z Policy Predictions Max     1556.27\n",
      "trainer/Z Policy Predictions Min      -64.4825\n",
      "trainer/Z Expert Targets Mean        1286.99\n",
      "trainer/Z Expert Targets Std          119.51\n",
      "trainer/Z Expert Targets Max         1520.76\n",
      "trainer/Z Expert Targets Min          866.684\n",
      "trainer/Z Policy Targets Mean        1112.25\n",
      "trainer/Z Policy Targets Std          358.776\n",
      "trainer/Z Policy Targets Max         1523.39\n",
      "trainer/Z Policy Targets Min          -50.2288\n",
      "trainer/Log Pis Mean                   19.8955\n",
      "trainer/Log Pis Std                     4.3362\n",
      "trainer/Policy mu Mean                  1.26342\n",
      "trainer/Policy mu Std                   1.85215\n",
      "trainer/Policy log std Mean            -2.16794\n",
      "trainer/Policy log std Std              1.2211\n",
      "trainer/Alpha                           0.17133\n",
      "trainer/Alpha Loss                      0.0179028\n",
      "exploration/num steps total        231415\n",
      "exploration/num paths total           812\n",
      "evaluation/num steps total              1.86612e+06\n",
      "evaluation/num paths total           2256\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.0837\n",
      "evaluation/Rewards Std                  1.2774\n",
      "evaluation/Rewards Max                  7.09583\n",
      "evaluation/Rewards Min                  0.130584\n",
      "evaluation/Returns Mean              5083.7\n",
      "evaluation/Returns Std                 27.2781\n",
      "evaluation/Returns Max               5121.72\n",
      "evaluation/Returns Min               5032.2\n",
      "evaluation/Estimation Bias Mean      1199.04\n",
      "evaluation/Estimation Bias Std        208.193\n",
      "evaluation/EB/Q_True Mean              48.0137\n",
      "evaluation/EB/Q_True Std              148.999\n",
      "evaluation/EB/Q_Pred Mean            1247.06\n",
      "evaluation/EB/Q_Pred Std              154.999\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5083.7\n",
      "evaluation/Actions Mean                 0.507489\n",
      "evaluation/Actions Std                  0.645918\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                2.04464\n",
      "time/backward_zf1 (s)                   2.21323\n",
      "time/backward_zf2 (s)                   2.10504\n",
      "time/data sampling (s)                  0.293748\n",
      "time/data storing (s)                   0.0147795\n",
      "time/evaluation sampling (s)            1.44762\n",
      "time/exploration sampling (s)           0.204492\n",
      "time/logging (s)                        0.0120687\n",
      "time/preback_alpha (s)                  1.028\n",
      "time/preback_policy (s)                 1.16607\n",
      "time/preback_start (s)                  0.129581\n",
      "time/preback_zf (s)                     5.19471\n",
      "time/saving (s)                         0.00543693\n",
      "time/training (s)                       2.27388\n",
      "time/epoch (s)                         18.1333\n",
      "time/total (s)                       3930.19\n",
      "Epoch                                 224\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:16:25.065615 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 225 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 236000\n",
      "trainer/ZF1 Loss                       28.1162\n",
      "trainer/ZF2 Loss                       32.5296\n",
      "trainer/ZF Expert Reward               12.8703\n",
      "trainer/ZF Policy Reward               -2.79776\n",
      "trainer/ZF CHI2 Term                   65.9447\n",
      "trainer/Policy Loss                 -1131.65\n",
      "trainer/Bias Loss                     122.25\n",
      "trainer/Bias Value                     19.7293\n",
      "trainer/Policy Grad Norm              336.321\n",
      "trainer/Policy Param Norm              38.9673\n",
      "trainer/Zf1 Grad Norm                4312.73\n",
      "trainer/Zf1 Param Norm                124.594\n",
      "trainer/Zf2 Grad Norm                5862.08\n",
      "trainer/Zf2 Param Norm                122.178\n",
      "trainer/Z Expert Predictions Mean    1277.89\n",
      "trainer/Z Expert Predictions Std      134.526\n",
      "trainer/Z Expert Predictions Max     1508.37\n",
      "trainer/Z Expert Predictions Min      338.551\n",
      "trainer/Z Policy Predictions Mean    1122.69\n",
      "trainer/Z Policy Predictions Std      333.061\n",
      "trainer/Z Policy Predictions Max     1543.56\n",
      "trainer/Z Policy Predictions Min      -51.409\n",
      "trainer/Z Expert Targets Mean        1265.02\n",
      "trainer/Z Expert Targets Std          136.713\n",
      "trainer/Z Expert Targets Max         1501.78\n",
      "trainer/Z Expert Targets Min          325.845\n",
      "trainer/Z Policy Targets Mean        1125.49\n",
      "trainer/Z Policy Targets Std          327.296\n",
      "trainer/Z Policy Targets Max         1546.57\n",
      "trainer/Z Policy Targets Min          -13.4021\n",
      "trainer/Log Pis Mean                   20.1553\n",
      "trainer/Log Pis Std                     4.38153\n",
      "trainer/Policy mu Mean                  1.22167\n",
      "trainer/Policy mu Std                   1.81458\n",
      "trainer/Policy log std Mean            -2.327\n",
      "trainer/Policy log std Std              1.17075\n",
      "trainer/Alpha                           0.172298\n",
      "trainer/Alpha Loss                     -0.0267619\n",
      "exploration/num steps total        232415\n",
      "exploration/num paths total           813\n",
      "evaluation/num steps total              1.87612e+06\n",
      "evaluation/num paths total           2266\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16186\n",
      "evaluation/Rewards Std                  1.29879\n",
      "evaluation/Rewards Max                  7.13858\n",
      "evaluation/Rewards Min                  0.127828\n",
      "evaluation/Returns Mean              5161.86\n",
      "evaluation/Returns Std                 18.3314\n",
      "evaluation/Returns Max               5185.51\n",
      "evaluation/Returns Min               5134.02\n",
      "evaluation/Estimation Bias Mean      1269.78\n",
      "evaluation/Estimation Bias Std        173.721\n",
      "evaluation/EB/Q_True Mean              48.55\n",
      "evaluation/EB/Q_True Std              150.08\n",
      "evaluation/EB/Q_Pred Mean            1318.33\n",
      "evaluation/EB/Q_Pred Std               90.8739\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5161.86\n",
      "evaluation/Actions Mean                 0.503959\n",
      "evaluation/Actions Std                  0.645661\n",
      "evaluation/Actions Max                  0.999975\n",
      "evaluation/Actions Min                 -0.999982\n",
      "time/backward_policy (s)                1.88394\n",
      "time/backward_zf1 (s)                   1.98218\n",
      "time/backward_zf2 (s)                   1.95109\n",
      "time/data sampling (s)                  0.239519\n",
      "time/data storing (s)                   0.0141429\n",
      "time/evaluation sampling (s)            1.42919\n",
      "time/exploration sampling (s)           0.193983\n",
      "time/logging (s)                        0.0116243\n",
      "time/preback_alpha (s)                  1.00647\n",
      "time/preback_policy (s)                 1.14633\n",
      "time/preback_start (s)                  0.118673\n",
      "time/preback_zf (s)                     5.09071\n",
      "time/saving (s)                         0.00551369\n",
      "time/training (s)                       2.11744\n",
      "time/epoch (s)                         17.1908\n",
      "time/total (s)                       3947.41\n",
      "Epoch                                 225\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:16:42.482258 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 226 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 237000\n",
      "trainer/ZF1 Loss                       27.968\n",
      "trainer/ZF2 Loss                       27.5699\n",
      "trainer/ZF Expert Reward               18.5391\n",
      "trainer/ZF Policy Reward                4.55263\n",
      "trainer/ZF CHI2 Term                   62.171\n",
      "trainer/Policy Loss                 -1149.81\n",
      "trainer/Bias Loss                     130.673\n",
      "trainer/Bias Value                     19.7183\n",
      "trainer/Policy Grad Norm              354.202\n",
      "trainer/Policy Param Norm              39.011\n",
      "trainer/Zf1 Grad Norm                4743.7\n",
      "trainer/Zf1 Param Norm                124.766\n",
      "trainer/Zf2 Grad Norm                5964.18\n",
      "trainer/Zf2 Param Norm                122.368\n",
      "trainer/Z Expert Predictions Mean    1291.4\n",
      "trainer/Z Expert Predictions Std      121.007\n",
      "trainer/Z Expert Predictions Max     1544.29\n",
      "trainer/Z Expert Predictions Min      948.596\n",
      "trainer/Z Policy Predictions Mean    1147.07\n",
      "trainer/Z Policy Predictions Std      323.79\n",
      "trainer/Z Policy Predictions Max     1549.49\n",
      "trainer/Z Policy Predictions Min      -66.4971\n",
      "trainer/Z Expert Targets Mean        1272.86\n",
      "trainer/Z Expert Targets Std          124.124\n",
      "trainer/Z Expert Targets Max         1510.15\n",
      "trainer/Z Expert Targets Min          945.957\n",
      "trainer/Z Policy Targets Mean        1142.52\n",
      "trainer/Z Policy Targets Std          319.341\n",
      "trainer/Z Policy Targets Max         1525.33\n",
      "trainer/Z Policy Targets Min          -46.5046\n",
      "trainer/Log Pis Mean                   20.6218\n",
      "trainer/Log Pis Std                     4.67143\n",
      "trainer/Policy mu Mean                  1.26116\n",
      "trainer/Policy mu Std                   1.885\n",
      "trainer/Policy log std Mean            -2.24483\n",
      "trainer/Policy log std Std              1.24532\n",
      "trainer/Alpha                           0.173835\n",
      "trainer/Alpha Loss                     -0.108083\n",
      "exploration/num steps total        233415\n",
      "exploration/num paths total           814\n",
      "evaluation/num steps total              1.88612e+06\n",
      "evaluation/num paths total           2276\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17085\n",
      "evaluation/Rewards Std                  1.30833\n",
      "evaluation/Rewards Max                  7.11882\n",
      "evaluation/Rewards Min                  0.110403\n",
      "evaluation/Returns Mean              5170.85\n",
      "evaluation/Returns Std                 17.2742\n",
      "evaluation/Returns Max               5202.12\n",
      "evaluation/Returns Min               5145.52\n",
      "evaluation/Estimation Bias Mean      1237.43\n",
      "evaluation/Estimation Bias Std        181.816\n",
      "evaluation/EB/Q_True Mean              48.5777\n",
      "evaluation/EB/Q_True Std              150.067\n",
      "evaluation/EB/Q_Pred Mean            1286.01\n",
      "evaluation/EB/Q_Pred Std              105.965\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5170.85\n",
      "evaluation/Actions Mean                 0.516799\n",
      "evaluation/Actions Std                  0.644782\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.91112\n",
      "time/backward_zf1 (s)                   2.00398\n",
      "time/backward_zf2 (s)                   1.96607\n",
      "time/data sampling (s)                  0.247042\n",
      "time/data storing (s)                   0.0143149\n",
      "time/evaluation sampling (s)            1.48863\n",
      "time/exploration sampling (s)           0.196469\n",
      "time/logging (s)                        0.0125466\n",
      "time/preback_alpha (s)                  1.00404\n",
      "time/preback_policy (s)                 1.15178\n",
      "time/preback_start (s)                  0.119485\n",
      "time/preback_zf (s)                     5.12501\n",
      "time/saving (s)                         0.0053583\n",
      "time/training (s)                       2.09613\n",
      "time/epoch (s)                         17.342\n",
      "time/total (s)                       3964.78\n",
      "Epoch                                 226\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:16:58.749335 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 227 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 238000\n",
      "trainer/ZF1 Loss                       18.4336\n",
      "trainer/ZF2 Loss                       31.7794\n",
      "trainer/ZF Expert Reward               17.8745\n",
      "trainer/ZF Policy Reward               -1.19422\n",
      "trainer/ZF CHI2 Term                   63.4877\n",
      "trainer/Policy Loss                 -1112.17\n",
      "trainer/Bias Loss                     143.88\n",
      "trainer/Bias Value                     19.7072\n",
      "trainer/Policy Grad Norm              343.21\n",
      "trainer/Policy Param Norm              39.0528\n",
      "trainer/Zf1 Grad Norm                4272.76\n",
      "trainer/Zf1 Param Norm                124.947\n",
      "trainer/Zf2 Grad Norm                5779.28\n",
      "trainer/Zf2 Param Norm                122.554\n",
      "trainer/Z Expert Predictions Mean    1284.94\n",
      "trainer/Z Expert Predictions Std      145.193\n",
      "trainer/Z Expert Predictions Max     1522.43\n",
      "trainer/Z Expert Predictions Min      208.901\n",
      "trainer/Z Policy Predictions Mean    1102.38\n",
      "trainer/Z Policy Predictions Std      332.752\n",
      "trainer/Z Policy Predictions Max     1535.96\n",
      "trainer/Z Policy Predictions Min      -60.1354\n",
      "trainer/Z Expert Targets Mean        1267.07\n",
      "trainer/Z Expert Targets Std          150.487\n",
      "trainer/Z Expert Targets Max         1509.25\n",
      "trainer/Z Expert Targets Min          181.439\n",
      "trainer/Z Policy Targets Mean        1103.58\n",
      "trainer/Z Policy Targets Std          327.057\n",
      "trainer/Z Policy Targets Max         1532.48\n",
      "trainer/Z Policy Targets Min          -33.0868\n",
      "trainer/Log Pis Mean                   19.5075\n",
      "trainer/Log Pis Std                     4.11362\n",
      "trainer/Policy mu Mean                  1.24005\n",
      "trainer/Policy mu Std                   1.75397\n",
      "trainer/Policy log std Mean            -2.29466\n",
      "trainer/Policy log std Std              1.20464\n",
      "trainer/Alpha                           0.174658\n",
      "trainer/Alpha Loss                      0.0860163\n",
      "exploration/num steps total        233415\n",
      "exploration/num paths total           814\n",
      "evaluation/num steps total              1.89612e+06\n",
      "evaluation/num paths total           2286\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13019\n",
      "evaluation/Rewards Std                  1.29163\n",
      "evaluation/Rewards Max                  7.07636\n",
      "evaluation/Rewards Min                  0.100829\n",
      "evaluation/Returns Mean              5130.19\n",
      "evaluation/Returns Std                 24.7769\n",
      "evaluation/Returns Max               5167.78\n",
      "evaluation/Returns Min               5068.09\n",
      "evaluation/Estimation Bias Mean      1254.58\n",
      "evaluation/Estimation Bias Std        197.642\n",
      "evaluation/EB/Q_True Mean              48.8353\n",
      "evaluation/EB/Q_True Std              150.818\n",
      "evaluation/EB/Q_Pred Mean            1303.41\n",
      "evaluation/EB/Q_Pred Std              106.953\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5130.19\n",
      "evaluation/Actions Mean                 0.500502\n",
      "evaluation/Actions Std                  0.644771\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.62654\n",
      "time/backward_zf1 (s)                   1.73959\n",
      "time/backward_zf2 (s)                   1.66269\n",
      "time/data sampling (s)                  0.238317\n",
      "time/data storing (s)                   0.0135573\n",
      "time/evaluation sampling (s)            1.39465\n",
      "time/exploration sampling (s)           0.188094\n",
      "time/logging (s)                        0.0206252\n",
      "time/preback_alpha (s)                  0.838314\n",
      "time/preback_policy (s)                 0.896898\n",
      "time/preback_start (s)                  0.117904\n",
      "time/preback_zf (s)                     5.00549\n",
      "time/saving (s)                         0.0069849\n",
      "time/training (s)                       2.45419\n",
      "time/epoch (s)                         16.2038\n",
      "time/total (s)                       3981.01\n",
      "Epoch                                 227\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:17:15.654321 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 228 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 239000\n",
      "trainer/ZF1 Loss                       37.7954\n",
      "trainer/ZF2 Loss                       38.3635\n",
      "trainer/ZF Expert Reward               26.7013\n",
      "trainer/ZF Policy Reward               11.8951\n",
      "trainer/ZF CHI2 Term                   72.8887\n",
      "trainer/Policy Loss                 -1141.42\n",
      "trainer/Bias Loss                     198.678\n",
      "trainer/Bias Value                     19.6943\n",
      "trainer/Policy Grad Norm              295.991\n",
      "trainer/Policy Param Norm              39.094\n",
      "trainer/Zf1 Grad Norm                3910.34\n",
      "trainer/Zf1 Param Norm                125.112\n",
      "trainer/Zf2 Grad Norm                3739.6\n",
      "trainer/Zf2 Param Norm                122.722\n",
      "trainer/Z Expert Predictions Mean    1298.54\n",
      "trainer/Z Expert Predictions Std      128.021\n",
      "trainer/Z Expert Predictions Max     1543.78\n",
      "trainer/Z Expert Predictions Min      747.584\n",
      "trainer/Z Policy Predictions Mean    1141.19\n",
      "trainer/Z Policy Predictions Std      319.472\n",
      "trainer/Z Policy Predictions Max     1556.28\n",
      "trainer/Z Policy Predictions Min      -42.1184\n",
      "trainer/Z Expert Targets Mean        1271.84\n",
      "trainer/Z Expert Targets Std          133.048\n",
      "trainer/Z Expert Targets Max         1521.59\n",
      "trainer/Z Expert Targets Min          721.991\n",
      "trainer/Z Policy Targets Mean        1129.29\n",
      "trainer/Z Policy Targets Std          314.525\n",
      "trainer/Z Policy Targets Max         1542.41\n",
      "trainer/Z Policy Targets Min          -32.8373\n",
      "trainer/Log Pis Mean                   20.2051\n",
      "trainer/Log Pis Std                     4.07499\n",
      "trainer/Policy mu Mean                  1.23714\n",
      "trainer/Policy mu Std                   1.88336\n",
      "trainer/Policy log std Mean            -2.18951\n",
      "trainer/Policy log std Std              1.2209\n",
      "trainer/Alpha                           0.173818\n",
      "trainer/Alpha Loss                     -0.0356549\n",
      "exploration/num steps total        233415\n",
      "exploration/num paths total           814\n",
      "evaluation/num steps total              1.90612e+06\n",
      "evaluation/num paths total           2296\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12886\n",
      "evaluation/Rewards Std                  1.29087\n",
      "evaluation/Rewards Max                  6.98771\n",
      "evaluation/Rewards Min                  0.11028\n",
      "evaluation/Returns Mean              5128.86\n",
      "evaluation/Returns Std                 21.4729\n",
      "evaluation/Returns Max               5159.38\n",
      "evaluation/Returns Min               5089.69\n",
      "evaluation/Estimation Bias Mean      1243.29\n",
      "evaluation/Estimation Bias Std        179.241\n",
      "evaluation/EB/Q_True Mean              48.2286\n",
      "evaluation/EB/Q_True Std              149.035\n",
      "evaluation/EB/Q_Pred Mean            1291.52\n",
      "evaluation/EB/Q_Pred Std              103.053\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5128.86\n",
      "evaluation/Actions Mean                 0.502139\n",
      "evaluation/Actions Std                  0.641336\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.79466\n",
      "time/backward_zf1 (s)                   1.91973\n",
      "time/backward_zf2 (s)                   1.86899\n",
      "time/data sampling (s)                  0.229467\n",
      "time/data storing (s)                   0.0140809\n",
      "time/evaluation sampling (s)            1.37676\n",
      "time/exploration sampling (s)           0.192956\n",
      "time/logging (s)                        0.0119925\n",
      "time/preback_alpha (s)                  0.953222\n",
      "time/preback_policy (s)                 1.06189\n",
      "time/preback_start (s)                  0.119465\n",
      "time/preback_zf (s)                     5.05761\n",
      "time/saving (s)                         0.00525529\n",
      "time/training (s)                       2.22087\n",
      "time/epoch (s)                         16.8269\n",
      "time/total (s)                       3997.86\n",
      "Epoch                                 228\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:17:33.527582 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 229 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 240000\n",
      "trainer/ZF1 Loss                       51.059\n",
      "trainer/ZF2 Loss                       39.4482\n",
      "trainer/ZF Expert Reward               20.0642\n",
      "trainer/ZF Policy Reward                7.88493\n",
      "trainer/ZF CHI2 Term                   77.1041\n",
      "trainer/Policy Loss                 -1089.05\n",
      "trainer/Bias Loss                     164.876\n",
      "trainer/Bias Value                     19.6819\n",
      "trainer/Policy Grad Norm              405.996\n",
      "trainer/Policy Param Norm              39.1336\n",
      "trainer/Zf1 Grad Norm                3986.56\n",
      "trainer/Zf1 Param Norm                125.292\n",
      "trainer/Zf2 Grad Norm                4904.74\n",
      "trainer/Zf2 Param Norm                122.894\n",
      "trainer/Z Expert Predictions Mean    1279.94\n",
      "trainer/Z Expert Predictions Std      128.303\n",
      "trainer/Z Expert Predictions Max     1533.45\n",
      "trainer/Z Expert Predictions Min      775.745\n",
      "trainer/Z Policy Predictions Mean    1085.81\n",
      "trainer/Z Policy Predictions Std      351.629\n",
      "trainer/Z Policy Predictions Max     1519.61\n",
      "trainer/Z Policy Predictions Min      -51.5711\n",
      "trainer/Z Expert Targets Mean        1259.87\n",
      "trainer/Z Expert Targets Std          133.567\n",
      "trainer/Z Expert Targets Max         1516.19\n",
      "trainer/Z Expert Targets Min          710.717\n",
      "trainer/Z Policy Targets Mean        1077.92\n",
      "trainer/Z Policy Targets Std          348.024\n",
      "trainer/Z Policy Targets Max         1525.22\n",
      "trainer/Z Policy Targets Min          -60.5428\n",
      "trainer/Log Pis Mean                   19.87\n",
      "trainer/Log Pis Std                     4.34917\n",
      "trainer/Policy mu Mean                  1.21725\n",
      "trainer/Policy mu Std                   1.80026\n",
      "trainer/Policy log std Mean            -2.2607\n",
      "trainer/Policy log std Std              1.18137\n",
      "trainer/Alpha                           0.172846\n",
      "trainer/Alpha Loss                      0.0224762\n",
      "exploration/num steps total        235415\n",
      "exploration/num paths total           816\n",
      "evaluation/num steps total              1.91612e+06\n",
      "evaluation/num paths total           2306\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16636\n",
      "evaluation/Rewards Std                  1.32607\n",
      "evaluation/Rewards Max                  7.14677\n",
      "evaluation/Rewards Min                  0.0952759\n",
      "evaluation/Returns Mean              5166.36\n",
      "evaluation/Returns Std                 18.1296\n",
      "evaluation/Returns Max               5191.41\n",
      "evaluation/Returns Min               5129.18\n",
      "evaluation/Estimation Bias Mean      1232.67\n",
      "evaluation/Estimation Bias Std        189.77\n",
      "evaluation/EB/Q_True Mean              48.7633\n",
      "evaluation/EB/Q_True Std              150.568\n",
      "evaluation/EB/Q_Pred Mean            1281.43\n",
      "evaluation/EB/Q_Pred Std              110.605\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5166.36\n",
      "evaluation/Actions Mean                 0.51293\n",
      "evaluation/Actions Std                  0.643929\n",
      "evaluation/Actions Max                  0.999991\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.98376\n",
      "time/backward_zf1 (s)                   2.16161\n",
      "time/backward_zf2 (s)                   2.09715\n",
      "time/data sampling (s)                  0.245695\n",
      "time/data storing (s)                   0.0138781\n",
      "time/evaluation sampling (s)            1.45866\n",
      "time/exploration sampling (s)           0.196723\n",
      "time/logging (s)                        0.0117925\n",
      "time/preback_alpha (s)                  1.02978\n",
      "time/preback_policy (s)                 1.20494\n",
      "time/preback_start (s)                  0.121322\n",
      "time/preback_zf (s)                     5.15024\n",
      "time/saving (s)                         0.00537718\n",
      "time/training (s)                       2.10176\n",
      "time/epoch (s)                         17.7827\n",
      "time/total (s)                       4015.68\n",
      "Epoch                                 229\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:17:50.645784 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 230 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 241000\n",
      "trainer/ZF1 Loss                      634.853\n",
      "trainer/ZF2 Loss                      624.774\n",
      "trainer/ZF Expert Reward               26.4266\n",
      "trainer/ZF Policy Reward               11.8588\n",
      "trainer/ZF CHI2 Term                  663.95\n",
      "trainer/Policy Loss                 -1131.18\n",
      "trainer/Bias Loss                    3025.31\n",
      "trainer/Bias Value                     19.6695\n",
      "trainer/Policy Grad Norm              283.249\n",
      "trainer/Policy Param Norm              39.1778\n",
      "trainer/Zf1 Grad Norm               15539\n",
      "trainer/Zf1 Param Norm                125.455\n",
      "trainer/Zf2 Grad Norm               20029\n",
      "trainer/Zf2 Param Norm                123.072\n",
      "trainer/Z Expert Predictions Mean    1266.43\n",
      "trainer/Z Expert Predictions Std      148.693\n",
      "trainer/Z Expert Predictions Max     1529.92\n",
      "trainer/Z Expert Predictions Min       97.0665\n",
      "trainer/Z Policy Predictions Mean    1129.45\n",
      "trainer/Z Policy Predictions Std      324.095\n",
      "trainer/Z Policy Predictions Max     1571.28\n",
      "trainer/Z Policy Predictions Min      -16.861\n",
      "trainer/Z Expert Targets Mean        1240.01\n",
      "trainer/Z Expert Targets Std          171.886\n",
      "trainer/Z Expert Targets Max         1502.04\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1117.6\n",
      "trainer/Z Policy Targets Std          329.217\n",
      "trainer/Z Policy Targets Max         1534.74\n",
      "trainer/Z Policy Targets Min          -76.4114\n",
      "trainer/Log Pis Mean                   19.7658\n",
      "trainer/Log Pis Std                     3.99321\n",
      "trainer/Policy mu Mean                  1.21386\n",
      "trainer/Policy mu Std                   1.8507\n",
      "trainer/Policy log std Mean            -2.26169\n",
      "trainer/Policy log std Std              1.2155\n",
      "trainer/Alpha                           0.171839\n",
      "trainer/Alpha Loss                      0.0402398\n",
      "exploration/num steps total        235415\n",
      "exploration/num paths total           816\n",
      "evaluation/num steps total              1.92612e+06\n",
      "evaluation/num paths total           2316\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17924\n",
      "evaluation/Rewards Std                  1.32692\n",
      "evaluation/Rewards Max                  7.06731\n",
      "evaluation/Rewards Min                  0.084172\n",
      "evaluation/Returns Mean              5179.24\n",
      "evaluation/Returns Std                 14.1106\n",
      "evaluation/Returns Max               5204.19\n",
      "evaluation/Returns Min               5155.22\n",
      "evaluation/Estimation Bias Mean      1260.22\n",
      "evaluation/Estimation Bias Std        174.374\n",
      "evaluation/EB/Q_True Mean              49.0761\n",
      "evaluation/EB/Q_True Std              151.645\n",
      "evaluation/EB/Q_Pred Mean            1309.3\n",
      "evaluation/EB/Q_Pred Std               91.4406\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5179.24\n",
      "evaluation/Actions Mean                 0.497884\n",
      "evaluation/Actions Std                  0.64261\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.86502\n",
      "time/backward_zf1 (s)                   1.97025\n",
      "time/backward_zf2 (s)                   1.93356\n",
      "time/data sampling (s)                  0.22778\n",
      "time/data storing (s)                   0.0136791\n",
      "time/evaluation sampling (s)            1.52404\n",
      "time/exploration sampling (s)           0.187104\n",
      "time/logging (s)                        0.0124556\n",
      "time/preback_alpha (s)                  1.00814\n",
      "time/preback_policy (s)                 1.1403\n",
      "time/preback_start (s)                  0.117888\n",
      "time/preback_zf (s)                     5.03686\n",
      "time/saving (s)                         0.00880318\n",
      "time/training (s)                       2.0081\n",
      "time/epoch (s)                         17.054\n",
      "time/total (s)                       4032.75\n",
      "Epoch                                 230\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:18:10.049906 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 231 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 242000\n",
      "trainer/ZF1 Loss                      238.581\n",
      "trainer/ZF2 Loss                      276.423\n",
      "trainer/ZF Expert Reward               19.0786\n",
      "trainer/ZF Policy Reward                4.39322\n",
      "trainer/ZF CHI2 Term                  291.738\n",
      "trainer/Policy Loss                 -1143.88\n",
      "trainer/Bias Loss                    2392.45\n",
      "trainer/Bias Value                     19.6555\n",
      "trainer/Policy Grad Norm              401.905\n",
      "trainer/Policy Param Norm              39.225\n",
      "trainer/Zf1 Grad Norm               11327.5\n",
      "trainer/Zf1 Param Norm                125.637\n",
      "trainer/Zf2 Grad Norm                8496.65\n",
      "trainer/Zf2 Param Norm                123.257\n",
      "trainer/Z Expert Predictions Mean    1267.34\n",
      "trainer/Z Expert Predictions Std      150.883\n",
      "trainer/Z Expert Predictions Max     1555.54\n",
      "trainer/Z Expert Predictions Min      382.381\n",
      "trainer/Z Policy Predictions Mean    1141.51\n",
      "trainer/Z Policy Predictions Std      328.03\n",
      "trainer/Z Policy Predictions Max     1520.62\n",
      "trainer/Z Policy Predictions Min      -50.4168\n",
      "trainer/Z Expert Targets Mean        1248.26\n",
      "trainer/Z Expert Targets Std          171.284\n",
      "trainer/Z Expert Targets Max         1505.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1137.12\n",
      "trainer/Z Policy Targets Std          321.862\n",
      "trainer/Z Policy Targets Max         1529.05\n",
      "trainer/Z Policy Targets Min          -10.0314\n",
      "trainer/Log Pis Mean                   19.7475\n",
      "trainer/Log Pis Std                     4.2517\n",
      "trainer/Policy mu Mean                  1.24271\n",
      "trainer/Policy mu Std                   1.78849\n",
      "trainer/Policy log std Mean            -2.29777\n",
      "trainer/Policy log std Std              1.24301\n",
      "trainer/Alpha                           0.170894\n",
      "trainer/Alpha Loss                      0.0431459\n",
      "exploration/num steps total        235415\n",
      "exploration/num paths total           816\n",
      "evaluation/num steps total              1.93612e+06\n",
      "evaluation/num paths total           2326\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15554\n",
      "evaluation/Rewards Std                  1.32085\n",
      "evaluation/Rewards Max                  7.12715\n",
      "evaluation/Rewards Min                  0.0889908\n",
      "evaluation/Returns Mean              5155.54\n",
      "evaluation/Returns Std                 13.6448\n",
      "evaluation/Returns Max               5172.87\n",
      "evaluation/Returns Min               5136.06\n",
      "evaluation/Estimation Bias Mean      1263.52\n",
      "evaluation/Estimation Bias Std        170.006\n",
      "evaluation/EB/Q_True Mean              48.7042\n",
      "evaluation/EB/Q_True Std              150.375\n",
      "evaluation/EB/Q_Pred Mean            1312.23\n",
      "evaluation/EB/Q_Pred Std               88.5279\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5155.54\n",
      "evaluation/Actions Mean                 0.514778\n",
      "evaluation/Actions Std                  0.639371\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                2.20761\n",
      "time/backward_zf1 (s)                   2.39511\n",
      "time/backward_zf2 (s)                   2.34569\n",
      "time/data sampling (s)                  0.293161\n",
      "time/data storing (s)                   0.0159874\n",
      "time/evaluation sampling (s)            1.51296\n",
      "time/exploration sampling (s)           0.211619\n",
      "time/logging (s)                        0.0123396\n",
      "time/preback_alpha (s)                  1.07972\n",
      "time/preback_policy (s)                 1.28068\n",
      "time/preback_start (s)                  0.135887\n",
      "time/preback_zf (s)                     5.41006\n",
      "time/saving (s)                         0.00564236\n",
      "time/training (s)                       2.42103\n",
      "time/epoch (s)                         19.3275\n",
      "time/total (s)                       4052.1\n",
      "Epoch                                 231\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:18:27.653285 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 232 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 243000\n",
      "trainer/ZF1 Loss                       34.1342\n",
      "trainer/ZF2 Loss                       32.0254\n",
      "trainer/ZF Expert Reward               16.0492\n",
      "trainer/ZF Policy Reward                3.33516\n",
      "trainer/ZF CHI2 Term                   66.3273\n",
      "trainer/Policy Loss                 -1104.77\n",
      "trainer/Bias Loss                     158.252\n",
      "trainer/Bias Value                     19.6423\n",
      "trainer/Policy Grad Norm              307.907\n",
      "trainer/Policy Param Norm              39.2688\n",
      "trainer/Zf1 Grad Norm                4523.53\n",
      "trainer/Zf1 Param Norm                125.797\n",
      "trainer/Zf2 Grad Norm                5388.15\n",
      "trainer/Zf2 Param Norm                123.419\n",
      "trainer/Z Expert Predictions Mean    1268.65\n",
      "trainer/Z Expert Predictions Std      146.036\n",
      "trainer/Z Expert Predictions Max     1532.16\n",
      "trainer/Z Expert Predictions Min      150.015\n",
      "trainer/Z Policy Predictions Mean    1095.15\n",
      "trainer/Z Policy Predictions Std      324.066\n",
      "trainer/Z Policy Predictions Max     1501.52\n",
      "trainer/Z Policy Predictions Min      -34.6742\n",
      "trainer/Z Expert Targets Mean        1252.6\n",
      "trainer/Z Expert Targets Std          150.576\n",
      "trainer/Z Expert Targets Max         1519.75\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1091.82\n",
      "trainer/Z Policy Targets Std          321.137\n",
      "trainer/Z Policy Targets Max         1482.08\n",
      "trainer/Z Policy Targets Min          -55.3607\n",
      "trainer/Log Pis Mean                   20.7408\n",
      "trainer/Log Pis Std                     4.65449\n",
      "trainer/Policy mu Mean                  1.26141\n",
      "trainer/Policy mu Std                   1.98475\n",
      "trainer/Policy log std Mean            -2.15313\n",
      "trainer/Policy log std Std              1.23267\n",
      "trainer/Alpha                           0.173589\n",
      "trainer/Alpha Loss                     -0.128596\n",
      "exploration/num steps total        236415\n",
      "exploration/num paths total           817\n",
      "evaluation/num steps total              1.94612e+06\n",
      "evaluation/num paths total           2336\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15598\n",
      "evaluation/Rewards Std                  1.29645\n",
      "evaluation/Rewards Max                  7.01593\n",
      "evaluation/Rewards Min                  0.154158\n",
      "evaluation/Returns Mean              5155.98\n",
      "evaluation/Returns Std                 16.2529\n",
      "evaluation/Returns Max               5191.41\n",
      "evaluation/Returns Min               5134.4\n",
      "evaluation/Estimation Bias Mean      1234.88\n",
      "evaluation/Estimation Bias Std        185.245\n",
      "evaluation/EB/Q_True Mean              49.096\n",
      "evaluation/EB/Q_True Std              151.645\n",
      "evaluation/EB/Q_Pred Mean            1283.97\n",
      "evaluation/EB/Q_Pred Std               95.5411\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5155.98\n",
      "evaluation/Actions Mean                 0.507447\n",
      "evaluation/Actions Std                  0.643518\n",
      "evaluation/Actions Max                  0.999988\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.92123\n",
      "time/backward_zf1 (s)                   2.05819\n",
      "time/backward_zf2 (s)                   1.97849\n",
      "time/data sampling (s)                  0.242533\n",
      "time/data storing (s)                   0.0159931\n",
      "time/evaluation sampling (s)            1.45355\n",
      "time/exploration sampling (s)           0.205225\n",
      "time/logging (s)                        0.0124591\n",
      "time/preback_alpha (s)                  0.995169\n",
      "time/preback_policy (s)                 1.11987\n",
      "time/preback_start (s)                  0.127411\n",
      "time/preback_zf (s)                     5.13303\n",
      "time/saving (s)                         0.00533301\n",
      "time/training (s)                       2.25991\n",
      "time/epoch (s)                         17.5284\n",
      "time/total (s)                       4069.66\n",
      "Epoch                                 232\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:18:45.163605 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 233 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 244000\n",
      "trainer/ZF1 Loss                      186.259\n",
      "trainer/ZF2 Loss                      183.742\n",
      "trainer/ZF Expert Reward               15.6175\n",
      "trainer/ZF Policy Reward                9.35971\n",
      "trainer/ZF CHI2 Term                  211.031\n",
      "trainer/Policy Loss                 -1135.72\n",
      "trainer/Bias Loss                     136.907\n",
      "trainer/Bias Value                     19.6329\n",
      "trainer/Policy Grad Norm              389.168\n",
      "trainer/Policy Param Norm              39.3148\n",
      "trainer/Zf1 Grad Norm                7643.55\n",
      "trainer/Zf1 Param Norm                125.98\n",
      "trainer/Zf2 Grad Norm                8575.55\n",
      "trainer/Zf2 Param Norm                123.6\n",
      "trainer/Z Expert Predictions Mean    1273.69\n",
      "trainer/Z Expert Predictions Std      143.039\n",
      "trainer/Z Expert Predictions Max     1535.1\n",
      "trainer/Z Expert Predictions Min      206.708\n",
      "trainer/Z Policy Predictions Mean    1135.27\n",
      "trainer/Z Policy Predictions Std      331.908\n",
      "trainer/Z Policy Predictions Max     1554.19\n",
      "trainer/Z Policy Predictions Min     -362.256\n",
      "trainer/Z Expert Targets Mean        1258.07\n",
      "trainer/Z Expert Targets Std          144.951\n",
      "trainer/Z Expert Targets Max         1518.13\n",
      "trainer/Z Expert Targets Min          200.331\n",
      "trainer/Z Policy Targets Mean        1125.91\n",
      "trainer/Z Policy Targets Std          336.277\n",
      "trainer/Z Policy Targets Max         1527.35\n",
      "trainer/Z Policy Targets Min         -368.247\n",
      "trainer/Log Pis Mean                   19.9729\n",
      "trainer/Log Pis Std                     4.37844\n",
      "trainer/Policy mu Mean                  1.20052\n",
      "trainer/Policy mu Std                   1.8282\n",
      "trainer/Policy log std Mean            -2.26618\n",
      "trainer/Policy log std Std              1.19915\n",
      "trainer/Alpha                           0.171121\n",
      "trainer/Alpha Loss                      0.00463653\n",
      "exploration/num steps total        239415\n",
      "exploration/num paths total           820\n",
      "evaluation/num steps total              1.95612e+06\n",
      "evaluation/num paths total           2346\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17108\n",
      "evaluation/Rewards Std                  1.31436\n",
      "evaluation/Rewards Max                  7.13748\n",
      "evaluation/Rewards Min                  0.107508\n",
      "evaluation/Returns Mean              5171.08\n",
      "evaluation/Returns Std                 17.8828\n",
      "evaluation/Returns Max               5201.71\n",
      "evaluation/Returns Min               5145.91\n",
      "evaluation/Estimation Bias Mean      1234.72\n",
      "evaluation/Estimation Bias Std        176.265\n",
      "evaluation/EB/Q_True Mean              49.094\n",
      "evaluation/EB/Q_True Std              151.704\n",
      "evaluation/EB/Q_Pred Mean            1283.82\n",
      "evaluation/EB/Q_Pred Std               98.2793\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5171.08\n",
      "evaluation/Actions Mean                 0.508184\n",
      "evaluation/Actions Std                  0.641021\n",
      "evaluation/Actions Max                  0.999985\n",
      "evaluation/Actions Min                 -0.999974\n",
      "time/backward_policy (s)                1.92145\n",
      "time/backward_zf1 (s)                   2.04621\n",
      "time/backward_zf2 (s)                   1.95856\n",
      "time/data sampling (s)                  0.261492\n",
      "time/data storing (s)                   0.0138935\n",
      "time/evaluation sampling (s)            1.49207\n",
      "time/exploration sampling (s)           0.198526\n",
      "time/logging (s)                        0.011968\n",
      "time/preback_alpha (s)                  0.981574\n",
      "time/preback_policy (s)                 1.11193\n",
      "time/preback_start (s)                  0.126252\n",
      "time/preback_zf (s)                     5.09664\n",
      "time/saving (s)                         0.00638408\n",
      "time/training (s)                       2.21659\n",
      "time/epoch (s)                         17.4435\n",
      "time/total (s)                       4087.12\n",
      "Epoch                                 233\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:19:03.000367 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 234 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 245000\n",
      "trainer/ZF1 Loss                      362.825\n",
      "trainer/ZF2 Loss                      335.765\n",
      "trainer/ZF Expert Reward               18.1911\n",
      "trainer/ZF Policy Reward                8.24691\n",
      "trainer/ZF CHI2 Term                  379.269\n",
      "trainer/Policy Loss                 -1116.67\n",
      "trainer/Bias Loss                     159.463\n",
      "trainer/Bias Value                     19.6174\n",
      "trainer/Policy Grad Norm              305.251\n",
      "trainer/Policy Param Norm              39.3585\n",
      "trainer/Zf1 Grad Norm                9365.83\n",
      "trainer/Zf1 Param Norm                126.152\n",
      "trainer/Zf2 Grad Norm                8842.54\n",
      "trainer/Zf2 Param Norm                123.774\n",
      "trainer/Z Expert Predictions Mean    1249.63\n",
      "trainer/Z Expert Predictions Std      141.83\n",
      "trainer/Z Expert Predictions Max     1521.91\n",
      "trainer/Z Expert Predictions Min      783.162\n",
      "trainer/Z Policy Predictions Mean    1112.12\n",
      "trainer/Z Policy Predictions Std      330.756\n",
      "trainer/Z Policy Predictions Max     1535.64\n",
      "trainer/Z Policy Predictions Min     -363.384\n",
      "trainer/Z Expert Targets Mean        1231.44\n",
      "trainer/Z Expert Targets Std          146.134\n",
      "trainer/Z Expert Targets Max         1520.93\n",
      "trainer/Z Expert Targets Min          724.329\n",
      "trainer/Z Policy Targets Mean        1103.87\n",
      "trainer/Z Policy Targets Std          334.917\n",
      "trainer/Z Policy Targets Max         1517.38\n",
      "trainer/Z Policy Targets Min         -375.531\n",
      "trainer/Log Pis Mean                   20.2321\n",
      "trainer/Log Pis Std                     3.93934\n",
      "trainer/Policy mu Mean                  1.2131\n",
      "trainer/Policy mu Std                   1.83032\n",
      "trainer/Policy log std Mean            -2.34505\n",
      "trainer/Policy log std Std              1.24121\n",
      "trainer/Alpha                           0.173896\n",
      "trainer/Alpha Loss                     -0.0403688\n",
      "exploration/num steps total        241415\n",
      "exploration/num paths total           822\n",
      "evaluation/num steps total              1.96612e+06\n",
      "evaluation/num paths total           2356\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17939\n",
      "evaluation/Rewards Std                  1.33305\n",
      "evaluation/Rewards Max                  7.15731\n",
      "evaluation/Rewards Min                  0.109365\n",
      "evaluation/Returns Mean              5179.39\n",
      "evaluation/Returns Std                 16.5775\n",
      "evaluation/Returns Max               5199.76\n",
      "evaluation/Returns Min               5148.14\n",
      "evaluation/Estimation Bias Mean      1210.83\n",
      "evaluation/Estimation Bias Std        195.741\n",
      "evaluation/EB/Q_True Mean              48.9993\n",
      "evaluation/EB/Q_True Std              151.272\n",
      "evaluation/EB/Q_Pred Mean            1259.83\n",
      "evaluation/EB/Q_Pred Std              109.953\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5179.39\n",
      "evaluation/Actions Mean                 0.508185\n",
      "evaluation/Actions Std                  0.648528\n",
      "evaluation/Actions Max                  0.999993\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.91802\n",
      "time/backward_zf1 (s)                   2.11321\n",
      "time/backward_zf2 (s)                   1.99227\n",
      "time/data sampling (s)                  0.280937\n",
      "time/data storing (s)                   0.015937\n",
      "time/evaluation sampling (s)            1.40956\n",
      "time/exploration sampling (s)           0.212678\n",
      "time/logging (s)                        0.0118914\n",
      "time/preback_alpha (s)                  0.988983\n",
      "time/preback_policy (s)                 1.11764\n",
      "time/preback_start (s)                  0.131076\n",
      "time/preback_zf (s)                     5.2267\n",
      "time/saving (s)                         0.00550871\n",
      "time/training (s)                       2.34266\n",
      "time/epoch (s)                         17.7671\n",
      "time/total (s)                       4104.91\n",
      "Epoch                                 234\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:19:20.593277 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 235 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 246000\n",
      "trainer/ZF1 Loss                       24.1375\n",
      "trainer/ZF2 Loss                       20.2738\n",
      "trainer/ZF Expert Reward               20.0408\n",
      "trainer/ZF Policy Reward                2.76609\n",
      "trainer/ZF CHI2 Term                   59.3303\n",
      "trainer/Policy Loss                 -1109.18\n",
      "trainer/Bias Loss                     130.661\n",
      "trainer/Bias Value                     19.6054\n",
      "trainer/Policy Grad Norm              246.043\n",
      "trainer/Policy Param Norm              39.4047\n",
      "trainer/Zf1 Grad Norm                3698.07\n",
      "trainer/Zf1 Param Norm                126.306\n",
      "trainer/Zf2 Grad Norm                5020.24\n",
      "trainer/Zf2 Param Norm                123.95\n",
      "trainer/Z Expert Predictions Mean    1258.98\n",
      "trainer/Z Expert Predictions Std      156.2\n",
      "trainer/Z Expert Predictions Max     1537.34\n",
      "trainer/Z Expert Predictions Min      162.73\n",
      "trainer/Z Policy Predictions Mean    1101.2\n",
      "trainer/Z Policy Predictions Std      314.872\n",
      "trainer/Z Policy Predictions Max     1542.27\n",
      "trainer/Z Policy Predictions Min      -89.9869\n",
      "trainer/Z Expert Targets Mean        1238.94\n",
      "trainer/Z Expert Targets Std          157.145\n",
      "trainer/Z Expert Targets Max         1526.77\n",
      "trainer/Z Expert Targets Min          157.896\n",
      "trainer/Z Policy Targets Mean        1098.43\n",
      "trainer/Z Policy Targets Std          309.983\n",
      "trainer/Z Policy Targets Max         1513.66\n",
      "trainer/Z Policy Targets Min          -49.5525\n",
      "trainer/Log Pis Mean                   20.0505\n",
      "trainer/Log Pis Std                     4.51871\n",
      "trainer/Policy mu Mean                  1.16308\n",
      "trainer/Policy mu Std                   1.88349\n",
      "trainer/Policy log std Mean            -2.29199\n",
      "trainer/Policy log std Std              1.21111\n",
      "trainer/Alpha                           0.170295\n",
      "trainer/Alpha Loss                     -0.00859092\n",
      "exploration/num steps total        242415\n",
      "exploration/num paths total           823\n",
      "evaluation/num steps total              1.97612e+06\n",
      "evaluation/num paths total           2366\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15007\n",
      "evaluation/Rewards Std                  1.32381\n",
      "evaluation/Rewards Max                  7.08617\n",
      "evaluation/Rewards Min                  0.0942595\n",
      "evaluation/Returns Mean              5150.07\n",
      "evaluation/Returns Std                 20.1885\n",
      "evaluation/Returns Max               5179.97\n",
      "evaluation/Returns Min               5117.1\n",
      "evaluation/Estimation Bias Mean      1222.88\n",
      "evaluation/Estimation Bias Std        177.313\n",
      "evaluation/EB/Q_True Mean              48.379\n",
      "evaluation/EB/Q_True Std              149.473\n",
      "evaluation/EB/Q_Pred Mean            1271.26\n",
      "evaluation/EB/Q_Pred Std               98.7434\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5150.07\n",
      "evaluation/Actions Mean                 0.507132\n",
      "evaluation/Actions Std                  0.646582\n",
      "evaluation/Actions Max                  0.999991\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.90869\n",
      "time/backward_zf1 (s)                   2.06394\n",
      "time/backward_zf2 (s)                   1.97827\n",
      "time/data sampling (s)                  0.269549\n",
      "time/data storing (s)                   0.01423\n",
      "time/evaluation sampling (s)            1.4086\n",
      "time/exploration sampling (s)           0.194343\n",
      "time/logging (s)                        0.0119175\n",
      "time/preback_alpha (s)                  0.947227\n",
      "time/preback_policy (s)                 1.0464\n",
      "time/preback_start (s)                  0.127514\n",
      "time/preback_zf (s)                     5.13921\n",
      "time/saving (s)                         0.00578955\n",
      "time/training (s)                       2.40639\n",
      "time/epoch (s)                         17.5221\n",
      "time/total (s)                       4122.45\n",
      "Epoch                                 235\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:19:40.561902 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 236 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 247000\n",
      "trainer/ZF1 Loss                      239.253\n",
      "trainer/ZF2 Loss                      241.059\n",
      "trainer/ZF Expert Reward               16.6834\n",
      "trainer/ZF Policy Reward                2.20879\n",
      "trainer/ZF CHI2 Term                  274.237\n",
      "trainer/Policy Loss                 -1082.73\n",
      "trainer/Bias Loss                     137.906\n",
      "trainer/Bias Value                     19.5936\n",
      "trainer/Policy Grad Norm              286.913\n",
      "trainer/Policy Param Norm              39.4494\n",
      "trainer/Zf1 Grad Norm                6779.13\n",
      "trainer/Zf1 Param Norm                126.473\n",
      "trainer/Zf2 Grad Norm                7267.51\n",
      "trainer/Zf2 Param Norm                124.115\n",
      "trainer/Z Expert Predictions Mean    1241.02\n",
      "trainer/Z Expert Predictions Std      175.51\n",
      "trainer/Z Expert Predictions Max     1502.54\n",
      "trainer/Z Expert Predictions Min      186.675\n",
      "trainer/Z Policy Predictions Mean    1070.54\n",
      "trainer/Z Policy Predictions Std      343.781\n",
      "trainer/Z Policy Predictions Max     1519.39\n",
      "trainer/Z Policy Predictions Min      -23.5979\n",
      "trainer/Z Expert Targets Mean        1224.34\n",
      "trainer/Z Expert Targets Std          179.432\n",
      "trainer/Z Expert Targets Max         1491.72\n",
      "trainer/Z Expert Targets Min          151.135\n",
      "trainer/Z Policy Targets Mean        1068.33\n",
      "trainer/Z Policy Targets Std          344.168\n",
      "trainer/Z Policy Targets Max         1491.41\n",
      "trainer/Z Policy Targets Min          -53.3621\n",
      "trainer/Log Pis Mean                   19.8048\n",
      "trainer/Log Pis Std                     3.99116\n",
      "trainer/Policy mu Mean                  1.20672\n",
      "trainer/Policy mu Std                   1.80773\n",
      "trainer/Policy log std Mean            -2.28289\n",
      "trainer/Policy log std Std              1.22446\n",
      "trainer/Alpha                           0.171526\n",
      "trainer/Alpha Loss                      0.0334813\n",
      "exploration/num steps total        243415\n",
      "exploration/num paths total           824\n",
      "evaluation/num steps total              1.98612e+06\n",
      "evaluation/num paths total           2376\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21419\n",
      "evaluation/Rewards Std                  1.31146\n",
      "evaluation/Rewards Max                  7.15045\n",
      "evaluation/Rewards Min                  0.10635\n",
      "evaluation/Returns Mean              5214.19\n",
      "evaluation/Returns Std                 33.3472\n",
      "evaluation/Returns Max               5257.45\n",
      "evaluation/Returns Min               5142.66\n",
      "evaluation/Estimation Bias Mean      1167.52\n",
      "evaluation/Estimation Bias Std        208.227\n",
      "evaluation/EB/Q_True Mean              49.7013\n",
      "evaluation/EB/Q_True Std              153.491\n",
      "evaluation/EB/Q_Pred Mean            1217.22\n",
      "evaluation/EB/Q_Pred Std              132.985\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5214.19\n",
      "evaluation/Actions Mean                 0.493629\n",
      "evaluation/Actions Std                  0.653974\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.28792\n",
      "time/backward_zf1 (s)                   2.51648\n",
      "time/backward_zf2 (s)                   2.35592\n",
      "time/data sampling (s)                  0.385878\n",
      "time/data storing (s)                   0.0170156\n",
      "time/evaluation sampling (s)            1.55965\n",
      "time/exploration sampling (s)           0.220769\n",
      "time/logging (s)                        0.0124454\n",
      "time/preback_alpha (s)                  1.11114\n",
      "time/preback_policy (s)                 1.28667\n",
      "time/preback_start (s)                  0.147082\n",
      "time/preback_zf (s)                     5.53439\n",
      "time/saving (s)                         0.00651678\n",
      "time/training (s)                       2.44392\n",
      "time/epoch (s)                         19.8858\n",
      "time/total (s)                       4142.36\n",
      "Epoch                                 236\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:19:59.470201 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 237 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 248000\n",
      "trainer/ZF1 Loss                       52.6175\n",
      "trainer/ZF2 Loss                       59.3813\n",
      "trainer/ZF Expert Reward               16.651\n",
      "trainer/ZF Policy Reward                5.12059\n",
      "trainer/ZF CHI2 Term                   87.4739\n",
      "trainer/Policy Loss                 -1102.13\n",
      "trainer/Bias Loss                     309.772\n",
      "trainer/Bias Value                     19.5836\n",
      "trainer/Policy Grad Norm              383.523\n",
      "trainer/Policy Param Norm              39.4954\n",
      "trainer/Zf1 Grad Norm                5013.09\n",
      "trainer/Zf1 Param Norm                126.65\n",
      "trainer/Zf2 Grad Norm                5952.73\n",
      "trainer/Zf2 Param Norm                124.294\n",
      "trainer/Z Expert Predictions Mean    1257.99\n",
      "trainer/Z Expert Predictions Std      146.572\n",
      "trainer/Z Expert Predictions Max     1534.55\n",
      "trainer/Z Expert Predictions Min      171.81\n",
      "trainer/Z Policy Predictions Mean    1094.52\n",
      "trainer/Z Policy Predictions Std      335.005\n",
      "trainer/Z Policy Predictions Max     1523.65\n",
      "trainer/Z Policy Predictions Min      -22.2639\n",
      "trainer/Z Expert Targets Mean        1241.34\n",
      "trainer/Z Expert Targets Std          148.603\n",
      "trainer/Z Expert Targets Max         1523.61\n",
      "trainer/Z Expert Targets Min          143.504\n",
      "trainer/Z Policy Targets Mean        1089.4\n",
      "trainer/Z Policy Targets Std          330.283\n",
      "trainer/Z Policy Targets Max         1513.57\n",
      "trainer/Z Policy Targets Min           -2.568\n",
      "trainer/Log Pis Mean                   20.1455\n",
      "trainer/Log Pis Std                     4.62792\n",
      "trainer/Policy mu Mean                  1.18943\n",
      "trainer/Policy mu Std                   1.85172\n",
      "trainer/Policy log std Mean            -2.33382\n",
      "trainer/Policy log std Std              1.21225\n",
      "trainer/Alpha                           0.173561\n",
      "trainer/Alpha Loss                     -0.0252589\n",
      "exploration/num steps total        243415\n",
      "exploration/num paths total           824\n",
      "evaluation/num steps total              1.99612e+06\n",
      "evaluation/num paths total           2386\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19841\n",
      "evaluation/Rewards Std                  1.32695\n",
      "evaluation/Rewards Max                  7.15049\n",
      "evaluation/Rewards Min                  0.111518\n",
      "evaluation/Returns Mean              5198.41\n",
      "evaluation/Returns Std                 17.3424\n",
      "evaluation/Returns Max               5229.15\n",
      "evaluation/Returns Min               5173.09\n",
      "evaluation/Estimation Bias Mean      1226.81\n",
      "evaluation/Estimation Bias Std        196.708\n",
      "evaluation/EB/Q_True Mean              49.4528\n",
      "evaluation/EB/Q_True Std              152.813\n",
      "evaluation/EB/Q_Pred Mean            1276.26\n",
      "evaluation/EB/Q_Pred Std              110.343\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5198.41\n",
      "evaluation/Actions Mean                 0.504748\n",
      "evaluation/Actions Std                  0.647292\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                2.09953\n",
      "time/backward_zf1 (s)                   2.34792\n",
      "time/backward_zf2 (s)                   2.21503\n",
      "time/data sampling (s)                  0.324574\n",
      "time/data storing (s)                   0.0173377\n",
      "time/evaluation sampling (s)            1.38892\n",
      "time/exploration sampling (s)           0.219876\n",
      "time/logging (s)                        0.011404\n",
      "time/preback_alpha (s)                  1.05797\n",
      "time/preback_policy (s)                 1.20406\n",
      "time/preback_start (s)                  0.138342\n",
      "time/preback_zf (s)                     5.38907\n",
      "time/saving (s)                         0.00524416\n",
      "time/training (s)                       2.41227\n",
      "time/epoch (s)                         18.8315\n",
      "time/total (s)                       4161.21\n",
      "Epoch                                 237\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:20:19.497560 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 238 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 249000\n",
      "trainer/ZF1 Loss                       37.6601\n",
      "trainer/ZF2 Loss                       31.957\n",
      "trainer/ZF Expert Reward               23.5905\n",
      "trainer/ZF Policy Reward                7.31955\n",
      "trainer/ZF CHI2 Term                   71.0828\n",
      "trainer/Policy Loss                 -1138.81\n",
      "trainer/Bias Loss                     160.019\n",
      "trainer/Bias Value                     19.5709\n",
      "trainer/Policy Grad Norm              306.581\n",
      "trainer/Policy Param Norm              39.5366\n",
      "trainer/Zf1 Grad Norm                5018.69\n",
      "trainer/Zf1 Param Norm                126.833\n",
      "trainer/Zf2 Grad Norm                4897.08\n",
      "trainer/Zf2 Param Norm                124.47\n",
      "trainer/Z Expert Predictions Mean    1250.69\n",
      "trainer/Z Expert Predictions Std      132.231\n",
      "trainer/Z Expert Predictions Max     1536.32\n",
      "trainer/Z Expert Predictions Min      622.663\n",
      "trainer/Z Policy Predictions Mean    1139.72\n",
      "trainer/Z Policy Predictions Std      306.799\n",
      "trainer/Z Policy Predictions Max     1529.04\n",
      "trainer/Z Policy Predictions Min      -36.4316\n",
      "trainer/Z Expert Targets Mean        1227.1\n",
      "trainer/Z Expert Targets Std          133.657\n",
      "trainer/Z Expert Targets Max         1516.74\n",
      "trainer/Z Expert Targets Min          595.939\n",
      "trainer/Z Policy Targets Mean        1132.4\n",
      "trainer/Z Policy Targets Std          299.733\n",
      "trainer/Z Policy Targets Max         1524.78\n",
      "trainer/Z Policy Targets Min          -33.4684\n",
      "trainer/Log Pis Mean                   20.2053\n",
      "trainer/Log Pis Std                     4.34382\n",
      "trainer/Policy mu Mean                  1.1875\n",
      "trainer/Policy mu Std                   1.87901\n",
      "trainer/Policy log std Mean            -2.28115\n",
      "trainer/Policy log std Std              1.20883\n",
      "trainer/Alpha                           0.176648\n",
      "trainer/Alpha Loss                     -0.0362747\n",
      "exploration/num steps total        243415\n",
      "exploration/num paths total           824\n",
      "evaluation/num steps total              2.00612e+06\n",
      "evaluation/num paths total           2396\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19745\n",
      "evaluation/Rewards Std                  1.3058\n",
      "evaluation/Rewards Max                  7.07197\n",
      "evaluation/Rewards Min                  0.139739\n",
      "evaluation/Returns Mean              5197.45\n",
      "evaluation/Returns Std                 14.2552\n",
      "evaluation/Returns Max               5214.22\n",
      "evaluation/Returns Min               5175.11\n",
      "evaluation/Estimation Bias Mean      1271.54\n",
      "evaluation/Estimation Bias Std        184.348\n",
      "evaluation/EB/Q_True Mean              49.1105\n",
      "evaluation/EB/Q_True Std              151.708\n",
      "evaluation/EB/Q_Pred Mean            1320.65\n",
      "evaluation/EB/Q_Pred Std              108.882\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5197.45\n",
      "evaluation/Actions Mean                 0.504193\n",
      "evaluation/Actions Std                  0.644532\n",
      "evaluation/Actions Max                  0.999993\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.30974\n",
      "time/backward_zf1 (s)                   2.54639\n",
      "time/backward_zf2 (s)                   2.42214\n",
      "time/data sampling (s)                  0.320783\n",
      "time/data storing (s)                   0.0183588\n",
      "time/evaluation sampling (s)            1.41563\n",
      "time/exploration sampling (s)           0.227846\n",
      "time/logging (s)                        0.013898\n",
      "time/preback_alpha (s)                  1.12633\n",
      "time/preback_policy (s)                 1.30547\n",
      "time/preback_start (s)                  0.143677\n",
      "time/preback_zf (s)                     5.53683\n",
      "time/saving (s)                         0.00519595\n",
      "time/training (s)                       2.56196\n",
      "time/epoch (s)                         19.9543\n",
      "time/total (s)                       4181.19\n",
      "Epoch                                 238\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:20:39.272322 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 239 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 250000\n",
      "trainer/ZF1 Loss                       47.4643\n",
      "trainer/ZF2 Loss                       43.1814\n",
      "trainer/ZF Expert Reward               23.7247\n",
      "trainer/ZF Policy Reward               10.3355\n",
      "trainer/ZF CHI2 Term                   78.4137\n",
      "trainer/Policy Loss                 -1133.3\n",
      "trainer/Bias Loss                     321.9\n",
      "trainer/Bias Value                     19.5578\n",
      "trainer/Policy Grad Norm              373.774\n",
      "trainer/Policy Param Norm              39.5807\n",
      "trainer/Zf1 Grad Norm                4642.14\n",
      "trainer/Zf1 Param Norm                127.002\n",
      "trainer/Zf2 Grad Norm                3324.55\n",
      "trainer/Zf2 Param Norm                124.639\n",
      "trainer/Z Expert Predictions Mean    1267.83\n",
      "trainer/Z Expert Predictions Std      133.389\n",
      "trainer/Z Expert Predictions Max     1533.44\n",
      "trainer/Z Expert Predictions Min      852.433\n",
      "trainer/Z Policy Predictions Mean    1132.76\n",
      "trainer/Z Policy Predictions Std      287.808\n",
      "trainer/Z Policy Predictions Max     1542.28\n",
      "trainer/Z Policy Predictions Min     -531.206\n",
      "trainer/Z Expert Targets Mean        1244.1\n",
      "trainer/Z Expert Targets Std          139.569\n",
      "trainer/Z Expert Targets Max         1513.41\n",
      "trainer/Z Expert Targets Min          835.621\n",
      "trainer/Z Policy Targets Mean        1122.42\n",
      "trainer/Z Policy Targets Std          284.394\n",
      "trainer/Z Policy Targets Max         1515.78\n",
      "trainer/Z Policy Targets Min         -564.032\n",
      "trainer/Log Pis Mean                   19.9006\n",
      "trainer/Log Pis Std                     3.89289\n",
      "trainer/Policy mu Mean                  1.23517\n",
      "trainer/Policy mu Std                   1.79671\n",
      "trainer/Policy log std Mean            -2.3073\n",
      "trainer/Policy log std Std              1.2092\n",
      "trainer/Alpha                           0.17587\n",
      "trainer/Alpha Loss                      0.0174816\n",
      "exploration/num steps total        245415\n",
      "exploration/num paths total           826\n",
      "evaluation/num steps total              2.01612e+06\n",
      "evaluation/num paths total           2406\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20784\n",
      "evaluation/Rewards Std                  1.32147\n",
      "evaluation/Rewards Max                  7.14635\n",
      "evaluation/Rewards Min                  0.110326\n",
      "evaluation/Returns Mean              5207.84\n",
      "evaluation/Returns Std                 10.0028\n",
      "evaluation/Returns Max               5221.55\n",
      "evaluation/Returns Min               5189.53\n",
      "evaluation/Estimation Bias Mean      1224.64\n",
      "evaluation/Estimation Bias Std        185.433\n",
      "evaluation/EB/Q_True Mean              49.1592\n",
      "evaluation/EB/Q_True Std              151.869\n",
      "evaluation/EB/Q_Pred Mean            1273.8\n",
      "evaluation/EB/Q_Pred Std              109.124\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5207.84\n",
      "evaluation/Actions Mean                 0.503274\n",
      "evaluation/Actions Std                  0.650306\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.29848\n",
      "time/backward_zf1 (s)                   2.51476\n",
      "time/backward_zf2 (s)                   2.39714\n",
      "time/data sampling (s)                  0.339016\n",
      "time/data storing (s)                   0.017079\n",
      "time/evaluation sampling (s)            1.3785\n",
      "time/exploration sampling (s)           0.221584\n",
      "time/logging (s)                        0.011773\n",
      "time/preback_alpha (s)                  1.11539\n",
      "time/preback_policy (s)                 1.29502\n",
      "time/preback_start (s)                  0.143605\n",
      "time/preback_zf (s)                     5.47796\n",
      "time/saving (s)                         0.00537827\n",
      "time/training (s)                       2.4722\n",
      "time/epoch (s)                         19.6879\n",
      "time/total (s)                       4200.9\n",
      "Epoch                                 239\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:20:57.643609 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 240 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 251000\n",
      "trainer/ZF1 Loss                       38.4306\n",
      "trainer/ZF2 Loss                       32.7427\n",
      "trainer/ZF Expert Reward               14.8232\n",
      "trainer/ZF Policy Reward                3.13366\n",
      "trainer/ZF CHI2 Term                   67.2075\n",
      "trainer/Policy Loss                 -1133.88\n",
      "trainer/Bias Loss                     186.332\n",
      "trainer/Bias Value                     19.5478\n",
      "trainer/Policy Grad Norm              285.672\n",
      "trainer/Policy Param Norm              39.6242\n",
      "trainer/Zf1 Grad Norm                4951.93\n",
      "trainer/Zf1 Param Norm                127.176\n",
      "trainer/Zf2 Grad Norm                5428.1\n",
      "trainer/Zf2 Param Norm                124.81\n",
      "trainer/Z Expert Predictions Mean    1253.3\n",
      "trainer/Z Expert Predictions Std      151.338\n",
      "trainer/Z Expert Predictions Max     1521.29\n",
      "trainer/Z Expert Predictions Min      174.018\n",
      "trainer/Z Policy Predictions Mean    1127\n",
      "trainer/Z Policy Predictions Std      273.553\n",
      "trainer/Z Policy Predictions Max     1469.17\n",
      "trainer/Z Policy Predictions Min      -19.7475\n",
      "trainer/Z Expert Targets Mean        1238.47\n",
      "trainer/Z Expert Targets Std          154.71\n",
      "trainer/Z Expert Targets Max         1510.73\n",
      "trainer/Z Expert Targets Min          145.023\n",
      "trainer/Z Policy Targets Mean        1123.87\n",
      "trainer/Z Policy Targets Std          271.347\n",
      "trainer/Z Policy Targets Max         1500.92\n",
      "trainer/Z Policy Targets Min          -21.0429\n",
      "trainer/Log Pis Mean                   20.1326\n",
      "trainer/Log Pis Std                     4.11744\n",
      "trainer/Policy mu Mean                  1.22746\n",
      "trainer/Policy mu Std                   1.86965\n",
      "trainer/Policy log std Mean            -2.22622\n",
      "trainer/Policy log std Std              1.18378\n",
      "trainer/Alpha                           0.174556\n",
      "trainer/Alpha Loss                     -0.0231535\n",
      "exploration/num steps total        245415\n",
      "exploration/num paths total           826\n",
      "evaluation/num steps total              2.02612e+06\n",
      "evaluation/num paths total           2416\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18108\n",
      "evaluation/Rewards Std                  1.32543\n",
      "evaluation/Rewards Max                  7.1108\n",
      "evaluation/Rewards Min                  0.0917839\n",
      "evaluation/Returns Mean              5181.08\n",
      "evaluation/Returns Std                 11.2722\n",
      "evaluation/Returns Max               5200.29\n",
      "evaluation/Returns Min               5164.54\n",
      "evaluation/Estimation Bias Mean      1264.91\n",
      "evaluation/Estimation Bias Std        177.122\n",
      "evaluation/EB/Q_True Mean              48.8587\n",
      "evaluation/EB/Q_True Std              150.826\n",
      "evaluation/EB/Q_Pred Mean            1313.76\n",
      "evaluation/EB/Q_Pred Std               87.3343\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5181.08\n",
      "evaluation/Actions Mean                 0.498941\n",
      "evaluation/Actions Std                  0.642878\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.04804\n",
      "time/backward_zf1 (s)                   2.21481\n",
      "time/backward_zf2 (s)                   2.12613\n",
      "time/data sampling (s)                  0.310253\n",
      "time/data storing (s)                   0.0161274\n",
      "time/evaluation sampling (s)            1.44696\n",
      "time/exploration sampling (s)           0.207437\n",
      "time/logging (s)                        0.011584\n",
      "time/preback_alpha (s)                  1.02217\n",
      "time/preback_policy (s)                 1.14798\n",
      "time/preback_start (s)                  0.133647\n",
      "time/preback_zf (s)                     5.25376\n",
      "time/saving (s)                         0.00524806\n",
      "time/training (s)                       2.35419\n",
      "time/epoch (s)                         18.2983\n",
      "time/total (s)                       4219.22\n",
      "Epoch                                 240\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:21:17.509642 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 241 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 252000\n",
      "trainer/ZF1 Loss                       29.887\n",
      "trainer/ZF2 Loss                       24.4495\n",
      "trainer/ZF Expert Reward               14.8975\n",
      "trainer/ZF Policy Reward               -2.20483\n",
      "trainer/ZF CHI2 Term                   64.3653\n",
      "trainer/Policy Loss                 -1084.53\n",
      "trainer/Bias Loss                     146.348\n",
      "trainer/Bias Value                     19.5349\n",
      "trainer/Policy Grad Norm              272.371\n",
      "trainer/Policy Param Norm              39.6709\n",
      "trainer/Zf1 Grad Norm                5299.92\n",
      "trainer/Zf1 Param Norm                127.352\n",
      "trainer/Zf2 Grad Norm                4387.31\n",
      "trainer/Zf2 Param Norm                124.993\n",
      "trainer/Z Expert Predictions Mean    1234.57\n",
      "trainer/Z Expert Predictions Std      142.027\n",
      "trainer/Z Expert Predictions Max     1533.64\n",
      "trainer/Z Expert Predictions Min      696.932\n",
      "trainer/Z Policy Predictions Mean    1075.35\n",
      "trainer/Z Policy Predictions Std      372.41\n",
      "trainer/Z Policy Predictions Max     1523.38\n",
      "trainer/Z Policy Predictions Min     -190.654\n",
      "trainer/Z Expert Targets Mean        1219.67\n",
      "trainer/Z Expert Targets Std          142.629\n",
      "trainer/Z Expert Targets Max         1512.91\n",
      "trainer/Z Expert Targets Min          717.023\n",
      "trainer/Z Policy Targets Mean        1077.55\n",
      "trainer/Z Policy Targets Std          365.686\n",
      "trainer/Z Policy Targets Max         1519.85\n",
      "trainer/Z Policy Targets Min         -189.023\n",
      "trainer/Log Pis Mean                   20.2977\n",
      "trainer/Log Pis Std                     4.59904\n",
      "trainer/Policy mu Mean                  1.2919\n",
      "trainer/Policy mu Std                   1.84661\n",
      "trainer/Policy log std Mean            -2.20487\n",
      "trainer/Policy log std Std              1.25525\n",
      "trainer/Alpha                           0.176797\n",
      "trainer/Alpha Loss                     -0.0526332\n",
      "exploration/num steps total        245415\n",
      "exploration/num paths total           826\n",
      "evaluation/num steps total              2.03612e+06\n",
      "evaluation/num paths total           2426\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19943\n",
      "evaluation/Rewards Std                  1.31562\n",
      "evaluation/Rewards Max                  7.27709\n",
      "evaluation/Rewards Min                  0.113104\n",
      "evaluation/Returns Mean              5199.43\n",
      "evaluation/Returns Std                 34.6059\n",
      "evaluation/Returns Max               5264.45\n",
      "evaluation/Returns Min               5157.59\n",
      "evaluation/Estimation Bias Mean      1200.47\n",
      "evaluation/Estimation Bias Std        199.064\n",
      "evaluation/EB/Q_True Mean              49.5131\n",
      "evaluation/EB/Q_True Std              152.984\n",
      "evaluation/EB/Q_Pred Mean            1249.98\n",
      "evaluation/EB/Q_Pred Std              122.4\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5199.43\n",
      "evaluation/Actions Mean                 0.506042\n",
      "evaluation/Actions Std                  0.645277\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.31918\n",
      "time/backward_zf1 (s)                   2.5573\n",
      "time/backward_zf2 (s)                   2.45657\n",
      "time/data sampling (s)                  0.326239\n",
      "time/data storing (s)                   0.0166818\n",
      "time/evaluation sampling (s)            1.3971\n",
      "time/exploration sampling (s)           0.215628\n",
      "time/logging (s)                        0.0114628\n",
      "time/preback_alpha (s)                  1.15512\n",
      "time/preback_policy (s)                 1.33987\n",
      "time/preback_start (s)                  0.14152\n",
      "time/preback_zf (s)                     5.45258\n",
      "time/saving (s)                         0.0052722\n",
      "time/training (s)                       2.3931\n",
      "time/epoch (s)                         19.7876\n",
      "time/total (s)                       4239.03\n",
      "Epoch                                 241\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:21:37.583876 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 242 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 253000\n",
      "trainer/ZF1 Loss                       21.0708\n",
      "trainer/ZF2 Loss                       21.0807\n",
      "trainer/ZF Expert Reward               18.5751\n",
      "trainer/ZF Policy Reward                3.33308\n",
      "trainer/ZF CHI2 Term                   56.1757\n",
      "trainer/Policy Loss                 -1116.25\n",
      "trainer/Bias Loss                     110.222\n",
      "trainer/Bias Value                     19.5239\n",
      "trainer/Policy Grad Norm              403.901\n",
      "trainer/Policy Param Norm              39.7189\n",
      "trainer/Zf1 Grad Norm                4276.22\n",
      "trainer/Zf1 Param Norm                127.53\n",
      "trainer/Zf2 Grad Norm                4125.63\n",
      "trainer/Zf2 Param Norm                125.167\n",
      "trainer/Z Expert Predictions Mean    1257.39\n",
      "trainer/Z Expert Predictions Std      148.051\n",
      "trainer/Z Expert Predictions Max     1510.34\n",
      "trainer/Z Expert Predictions Min      189.343\n",
      "trainer/Z Policy Predictions Mean    1114.87\n",
      "trainer/Z Policy Predictions Std      310.014\n",
      "trainer/Z Policy Predictions Max     1539.58\n",
      "trainer/Z Policy Predictions Min       14.3725\n",
      "trainer/Z Expert Targets Mean        1238.82\n",
      "trainer/Z Expert Targets Std          150.706\n",
      "trainer/Z Expert Targets Max         1476.77\n",
      "trainer/Z Expert Targets Min          183.107\n",
      "trainer/Z Policy Targets Mean        1111.54\n",
      "trainer/Z Policy Targets Std          312.835\n",
      "trainer/Z Policy Targets Max         1505.5\n",
      "trainer/Z Policy Targets Min          -53.6092\n",
      "trainer/Log Pis Mean                   20.0586\n",
      "trainer/Log Pis Std                     3.65004\n",
      "trainer/Policy mu Mean                  1.26114\n",
      "trainer/Policy mu Std                   1.79055\n",
      "trainer/Policy log std Mean            -2.35749\n",
      "trainer/Policy log std Std              1.2497\n",
      "trainer/Alpha                           0.1752\n",
      "trainer/Alpha Loss                     -0.0102607\n",
      "exploration/num steps total        246415\n",
      "exploration/num paths total           827\n",
      "evaluation/num steps total              2.04564e+06\n",
      "evaluation/num paths total           2436\n",
      "evaluation/path length Mean           952.1\n",
      "evaluation/path length Std            143.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            521\n",
      "evaluation/Rewards Mean                 5.19274\n",
      "evaluation/Rewards Std                  1.3464\n",
      "evaluation/Rewards Max                  7.18748\n",
      "evaluation/Rewards Min                  0.0975003\n",
      "evaluation/Returns Mean              4944.01\n",
      "evaluation/Returns Std                808.038\n",
      "evaluation/Returns Max               5323.31\n",
      "evaluation/Returns Min               2523.32\n",
      "evaluation/Estimation Bias Mean      1180.57\n",
      "evaluation/Estimation Bias Std        264.204\n",
      "evaluation/EB/Q_True Mean              51.7655\n",
      "evaluation/EB/Q_True Std              155.586\n",
      "evaluation/EB/Q_Pred Mean            1232.34\n",
      "evaluation/EB/Q_Pred Std              182.393\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4944.01\n",
      "evaluation/Actions Mean                 0.501184\n",
      "evaluation/Actions Std                  0.644393\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.39131\n",
      "time/backward_zf1 (s)                   2.58299\n",
      "time/backward_zf2 (s)                   2.50291\n",
      "time/data sampling (s)                  0.308915\n",
      "time/data storing (s)                   0.017195\n",
      "time/evaluation sampling (s)            1.48381\n",
      "time/exploration sampling (s)           0.219504\n",
      "time/logging (s)                        0.0119226\n",
      "time/preback_alpha (s)                  1.15023\n",
      "time/preback_policy (s)                 1.33846\n",
      "time/preback_start (s)                  0.141491\n",
      "time/preback_zf (s)                     5.46679\n",
      "time/saving (s)                         0.00527496\n",
      "time/training (s)                       2.37309\n",
      "time/epoch (s)                         19.9939\n",
      "time/total (s)                       4259.05\n",
      "Epoch                                 242\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:21:56.751988 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 243 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 254000\n",
      "trainer/ZF1 Loss                       41.477\n",
      "trainer/ZF2 Loss                       56.8446\n",
      "trainer/ZF Expert Reward               16.3792\n",
      "trainer/ZF Policy Reward                5.68603\n",
      "trainer/ZF CHI2 Term                   79.3449\n",
      "trainer/Policy Loss                 -1085.4\n",
      "trainer/Bias Loss                     230.864\n",
      "trainer/Bias Value                     19.5128\n",
      "trainer/Policy Grad Norm              350.018\n",
      "trainer/Policy Param Norm              39.7612\n",
      "trainer/Zf1 Grad Norm                4435.87\n",
      "trainer/Zf1 Param Norm                127.703\n",
      "trainer/Zf2 Grad Norm                6205.78\n",
      "trainer/Zf2 Param Norm                125.344\n",
      "trainer/Z Expert Predictions Mean    1228.53\n",
      "trainer/Z Expert Predictions Std      169.697\n",
      "trainer/Z Expert Predictions Max     1504.26\n",
      "trainer/Z Expert Predictions Min      182.538\n",
      "trainer/Z Policy Predictions Mean    1079.05\n",
      "trainer/Z Policy Predictions Std      323.95\n",
      "trainer/Z Policy Predictions Max     1532.87\n",
      "trainer/Z Policy Predictions Min     -174.042\n",
      "trainer/Z Expert Targets Mean        1212.15\n",
      "trainer/Z Expert Targets Std          175.963\n",
      "trainer/Z Expert Targets Max         1490.88\n",
      "trainer/Z Expert Targets Min          151.394\n",
      "trainer/Z Policy Targets Mean        1073.37\n",
      "trainer/Z Policy Targets Std          317.51\n",
      "trainer/Z Policy Targets Max         1503.24\n",
      "trainer/Z Policy Targets Min         -127.466\n",
      "trainer/Log Pis Mean                   19.6879\n",
      "trainer/Log Pis Std                     4.234\n",
      "trainer/Policy mu Mean                  1.19675\n",
      "trainer/Policy mu Std                   1.80122\n",
      "trainer/Policy log std Mean            -2.30794\n",
      "trainer/Policy log std Std              1.211\n",
      "trainer/Alpha                           0.175652\n",
      "trainer/Alpha Loss                      0.054829\n",
      "exploration/num steps total        249415\n",
      "exploration/num paths total           830\n",
      "evaluation/num steps total              2.05564e+06\n",
      "evaluation/num paths total           2446\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18515\n",
      "evaluation/Rewards Std                  1.32283\n",
      "evaluation/Rewards Max                  7.1496\n",
      "evaluation/Rewards Min                  0.11665\n",
      "evaluation/Returns Mean              5185.15\n",
      "evaluation/Returns Std                 28.6436\n",
      "evaluation/Returns Max               5242.07\n",
      "evaluation/Returns Min               5140.22\n",
      "evaluation/Estimation Bias Mean      1205.89\n",
      "evaluation/Estimation Bias Std        187.355\n",
      "evaluation/EB/Q_True Mean              49.3349\n",
      "evaluation/EB/Q_True Std              152.366\n",
      "evaluation/EB/Q_Pred Mean            1255.23\n",
      "evaluation/EB/Q_Pred Std              101.497\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5185.15\n",
      "evaluation/Actions Mean                 0.500478\n",
      "evaluation/Actions Std                  0.653258\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.18228\n",
      "time/backward_zf1 (s)                   2.4091\n",
      "time/backward_zf2 (s)                   2.28728\n",
      "time/data sampling (s)                  0.325234\n",
      "time/data storing (s)                   0.0163859\n",
      "time/evaluation sampling (s)            1.3897\n",
      "time/exploration sampling (s)           0.218887\n",
      "time/logging (s)                        0.0120286\n",
      "time/preback_alpha (s)                  1.10924\n",
      "time/preback_policy (s)                 1.26845\n",
      "time/preback_start (s)                  0.136622\n",
      "time/preback_zf (s)                     5.4073\n",
      "time/saving (s)                         0.00550862\n",
      "time/training (s)                       2.3268\n",
      "time/epoch (s)                         19.0948\n",
      "time/total (s)                       4278.16\n",
      "Epoch                                 243\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:22:16.444525 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 244 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 255000\n",
      "trainer/ZF1 Loss                      578.263\n",
      "trainer/ZF2 Loss                      652.987\n",
      "trainer/ZF Expert Reward               27.9213\n",
      "trainer/ZF Policy Reward                9.15914\n",
      "trainer/ZF CHI2 Term                  654.43\n",
      "trainer/Policy Loss                 -1091.26\n",
      "trainer/Bias Loss                    4316.01\n",
      "trainer/Bias Value                     19.5019\n",
      "trainer/Policy Grad Norm              278.928\n",
      "trainer/Policy Param Norm              39.8003\n",
      "trainer/Zf1 Grad Norm               21783.5\n",
      "trainer/Zf1 Param Norm                127.858\n",
      "trainer/Zf2 Grad Norm               21705.5\n",
      "trainer/Zf2 Param Norm                125.511\n",
      "trainer/Z Expert Predictions Mean    1237.27\n",
      "trainer/Z Expert Predictions Std      168.759\n",
      "trainer/Z Expert Predictions Max     1513.02\n",
      "trainer/Z Expert Predictions Min      130.648\n",
      "trainer/Z Policy Predictions Mean    1093.28\n",
      "trainer/Z Policy Predictions Std      349.942\n",
      "trainer/Z Policy Predictions Max     1501.54\n",
      "trainer/Z Policy Predictions Min     -387.438\n",
      "trainer/Z Expert Targets Mean        1209.34\n",
      "trainer/Z Expert Targets Std          202.295\n",
      "trainer/Z Expert Targets Max         1489.97\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1084.12\n",
      "trainer/Z Policy Targets Std          354.783\n",
      "trainer/Z Policy Targets Max         1505.52\n",
      "trainer/Z Policy Targets Min         -447.031\n",
      "trainer/Log Pis Mean                   20.245\n",
      "trainer/Log Pis Std                     4.29217\n",
      "trainer/Policy mu Mean                  1.14455\n",
      "trainer/Policy mu Std                   1.90634\n",
      "trainer/Policy log std Mean            -2.25762\n",
      "trainer/Policy log std Std              1.20664\n",
      "trainer/Alpha                           0.174308\n",
      "trainer/Alpha Loss                     -0.0427096\n",
      "exploration/num steps total        251415\n",
      "exploration/num paths total           832\n",
      "evaluation/num steps total              2.06564e+06\n",
      "evaluation/num paths total           2456\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17715\n",
      "evaluation/Rewards Std                  1.31196\n",
      "evaluation/Rewards Max                  7.09157\n",
      "evaluation/Rewards Min                  0.101853\n",
      "evaluation/Returns Mean              5177.15\n",
      "evaluation/Returns Std                 30.0469\n",
      "evaluation/Returns Max               5198.77\n",
      "evaluation/Returns Min               5099.58\n",
      "evaluation/Estimation Bias Mean      1235.16\n",
      "evaluation/Estimation Bias Std        206.795\n",
      "evaluation/EB/Q_True Mean              49.08\n",
      "evaluation/EB/Q_True Std              151.788\n",
      "evaluation/EB/Q_Pred Mean            1284.24\n",
      "evaluation/EB/Q_Pred Std              136.635\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5177.15\n",
      "evaluation/Actions Mean                 0.495092\n",
      "evaluation/Actions Std                  0.648305\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.28487\n",
      "time/backward_zf1 (s)                   2.53717\n",
      "time/backward_zf2 (s)                   2.39308\n",
      "time/data sampling (s)                  0.327778\n",
      "time/data storing (s)                   0.0159904\n",
      "time/evaluation sampling (s)            1.42112\n",
      "time/exploration sampling (s)           0.216792\n",
      "time/logging (s)                        0.0117873\n",
      "time/preback_alpha (s)                  1.15084\n",
      "time/preback_policy (s)                 1.31676\n",
      "time/preback_start (s)                  0.139819\n",
      "time/preback_zf (s)                     5.45486\n",
      "time/saving (s)                         0.00548303\n",
      "time/training (s)                       2.3389\n",
      "time/epoch (s)                         19.6152\n",
      "time/total (s)                       4297.8\n",
      "Epoch                                 244\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:22:36.295427 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 245 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 256000\n",
      "trainer/ZF1 Loss                       46.6338\n",
      "trainer/ZF2 Loss                       57.0134\n",
      "trainer/ZF Expert Reward               17.4705\n",
      "trainer/ZF Policy Reward                2.7368\n",
      "trainer/ZF CHI2 Term                   86.6448\n",
      "trainer/Policy Loss                 -1085.01\n",
      "trainer/Bias Loss                     223.467\n",
      "trainer/Bias Value                     19.4907\n",
      "trainer/Policy Grad Norm              302.659\n",
      "trainer/Policy Param Norm              39.8448\n",
      "trainer/Zf1 Grad Norm                6676.6\n",
      "trainer/Zf1 Param Norm                128.022\n",
      "trainer/Zf2 Grad Norm                7642.4\n",
      "trainer/Zf2 Param Norm                125.672\n",
      "trainer/Z Expert Predictions Mean    1226.83\n",
      "trainer/Z Expert Predictions Std      156.131\n",
      "trainer/Z Expert Predictions Max     1521.19\n",
      "trainer/Z Expert Predictions Min      439.385\n",
      "trainer/Z Policy Predictions Mean    1075.2\n",
      "trainer/Z Policy Predictions Std      349.061\n",
      "trainer/Z Policy Predictions Max     1525.19\n",
      "trainer/Z Policy Predictions Min     -471.487\n",
      "trainer/Z Expert Targets Mean        1209.35\n",
      "trainer/Z Expert Targets Std          160.263\n",
      "trainer/Z Expert Targets Max         1496.8\n",
      "trainer/Z Expert Targets Min          413.196\n",
      "trainer/Z Policy Targets Mean        1072.46\n",
      "trainer/Z Policy Targets Std          346.783\n",
      "trainer/Z Policy Targets Max         1515.03\n",
      "trainer/Z Policy Targets Min         -461.903\n",
      "trainer/Log Pis Mean                   20.2903\n",
      "trainer/Log Pis Std                     4.38048\n",
      "trainer/Policy mu Mean                  1.17619\n",
      "trainer/Policy mu Std                   1.84254\n",
      "trainer/Policy log std Mean            -2.34956\n",
      "trainer/Policy log std Std              1.2176\n",
      "trainer/Alpha                           0.173527\n",
      "trainer/Alpha Loss                     -0.0503752\n",
      "exploration/num steps total        252415\n",
      "exploration/num paths total           833\n",
      "evaluation/num steps total              2.07564e+06\n",
      "evaluation/num paths total           2466\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18211\n",
      "evaluation/Rewards Std                  1.30108\n",
      "evaluation/Rewards Max                  7.13047\n",
      "evaluation/Rewards Min                  0.138169\n",
      "evaluation/Returns Mean              5182.11\n",
      "evaluation/Returns Std                 16.5426\n",
      "evaluation/Returns Max               5218.47\n",
      "evaluation/Returns Min               5162.5\n",
      "evaluation/Estimation Bias Mean      1160.62\n",
      "evaluation/Estimation Bias Std        198.575\n",
      "evaluation/EB/Q_True Mean              49.3294\n",
      "evaluation/EB/Q_True Std              152.39\n",
      "evaluation/EB/Q_Pred Mean            1209.95\n",
      "evaluation/EB/Q_Pred Std              124.548\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5182.11\n",
      "evaluation/Actions Mean                 0.491546\n",
      "evaluation/Actions Std                  0.652411\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.26196\n",
      "time/backward_zf1 (s)                   2.53132\n",
      "time/backward_zf2 (s)                   2.39009\n",
      "time/data sampling (s)                  0.344261\n",
      "time/data storing (s)                   0.017381\n",
      "time/evaluation sampling (s)            1.39103\n",
      "time/exploration sampling (s)           0.225251\n",
      "time/logging (s)                        0.0117212\n",
      "time/preback_alpha (s)                  1.13648\n",
      "time/preback_policy (s)                 1.33423\n",
      "time/preback_start (s)                  0.14319\n",
      "time/preback_zf (s)                     5.4959\n",
      "time/saving (s)                         0.00548716\n",
      "time/training (s)                       2.48019\n",
      "time/epoch (s)                         19.7685\n",
      "time/total (s)                       4317.59\n",
      "Epoch                                 245\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:22:56.196821 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 246 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 257000\n",
      "trainer/ZF1 Loss                      345.964\n",
      "trainer/ZF2 Loss                      331.755\n",
      "trainer/ZF Expert Reward               12.0474\n",
      "trainer/ZF Policy Reward               -0.590164\n",
      "trainer/ZF CHI2 Term                  371.16\n",
      "trainer/Policy Loss                 -1087.15\n",
      "trainer/Bias Loss                     143.809\n",
      "trainer/Bias Value                     19.48\n",
      "trainer/Policy Grad Norm              352.896\n",
      "trainer/Policy Param Norm              39.8842\n",
      "trainer/Zf1 Grad Norm                6988.17\n",
      "trainer/Zf1 Param Norm                128.183\n",
      "trainer/Zf2 Grad Norm                7546.12\n",
      "trainer/Zf2 Param Norm                125.835\n",
      "trainer/Z Expert Predictions Mean    1218.75\n",
      "trainer/Z Expert Predictions Std      155.754\n",
      "trainer/Z Expert Predictions Max     1485.08\n",
      "trainer/Z Expert Predictions Min      246.375\n",
      "trainer/Z Policy Predictions Mean    1081.14\n",
      "trainer/Z Policy Predictions Std      317.923\n",
      "trainer/Z Policy Predictions Max     1479.92\n",
      "trainer/Z Policy Predictions Min      -38.2082\n",
      "trainer/Z Expert Targets Mean        1206.7\n",
      "trainer/Z Expert Targets Std          160.534\n",
      "trainer/Z Expert Targets Max         1491.76\n",
      "trainer/Z Expert Targets Min          231.86\n",
      "trainer/Z Policy Targets Mean        1081.73\n",
      "trainer/Z Policy Targets Std          321.674\n",
      "trainer/Z Policy Targets Max         1485.25\n",
      "trainer/Z Policy Targets Min          -31.8691\n",
      "trainer/Log Pis Mean                   19.8611\n",
      "trainer/Log Pis Std                     4.12554\n",
      "trainer/Policy mu Mean                  1.16624\n",
      "trainer/Policy mu Std                   1.80898\n",
      "trainer/Policy log std Mean            -2.32915\n",
      "trainer/Policy log std Std              1.20876\n",
      "trainer/Alpha                           0.172367\n",
      "trainer/Alpha Loss                      0.023942\n",
      "exploration/num steps total        253415\n",
      "exploration/num paths total           834\n",
      "evaluation/num steps total              2.08552e+06\n",
      "evaluation/num paths total           2476\n",
      "evaluation/path length Mean           987.4\n",
      "evaluation/path length Std             37.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            874\n",
      "evaluation/Rewards Mean                 5.15071\n",
      "evaluation/Rewards Std                  1.29883\n",
      "evaluation/Rewards Max                  7.08092\n",
      "evaluation/Rewards Min                  0.128857\n",
      "evaluation/Returns Mean              5085.81\n",
      "evaluation/Returns Std                210.931\n",
      "evaluation/Returns Max               5240.31\n",
      "evaluation/Returns Min               4459.53\n",
      "evaluation/Estimation Bias Mean      1204.02\n",
      "evaluation/Estimation Bias Std        248.195\n",
      "evaluation/EB/Q_True Mean              50.1621\n",
      "evaluation/EB/Q_True Std              153.713\n",
      "evaluation/EB/Q_Pred Mean            1254.19\n",
      "evaluation/EB/Q_Pred Std              158.308\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5085.81\n",
      "evaluation/Actions Mean                 0.498509\n",
      "evaluation/Actions Std                  0.644132\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.32228\n",
      "time/backward_zf1 (s)                   2.5696\n",
      "time/backward_zf2 (s)                   2.48453\n",
      "time/data sampling (s)                  0.343837\n",
      "time/data storing (s)                   0.0164145\n",
      "time/evaluation sampling (s)            1.42973\n",
      "time/exploration sampling (s)           0.210609\n",
      "time/logging (s)                        0.0118113\n",
      "time/preback_alpha (s)                  1.15106\n",
      "time/preback_policy (s)                 1.36146\n",
      "time/preback_start (s)                  0.140053\n",
      "time/preback_zf (s)                     5.46867\n",
      "time/saving (s)                         0.00529362\n",
      "time/training (s)                       2.30943\n",
      "time/epoch (s)                         19.8248\n",
      "time/total (s)                       4337.44\n",
      "Epoch                                 246\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:23:15.838145 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 247 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 258000\n",
      "trainer/ZF1 Loss                       20.1484\n",
      "trainer/ZF2 Loss                       18.6632\n",
      "trainer/ZF Expert Reward               17.8755\n",
      "trainer/ZF Policy Reward                4.32674\n",
      "trainer/ZF CHI2 Term                   52.7802\n",
      "trainer/Policy Loss                 -1085.98\n",
      "trainer/Bias Loss                     100.016\n",
      "trainer/Bias Value                     19.4711\n",
      "trainer/Policy Grad Norm              353.588\n",
      "trainer/Policy Param Norm              39.9253\n",
      "trainer/Zf1 Grad Norm                3325.93\n",
      "trainer/Zf1 Param Norm                128.348\n",
      "trainer/Zf2 Grad Norm                3350.51\n",
      "trainer/Zf2 Param Norm                125.992\n",
      "trainer/Z Expert Predictions Mean    1223.44\n",
      "trainer/Z Expert Predictions Std      127.971\n",
      "trainer/Z Expert Predictions Max     1497.92\n",
      "trainer/Z Expert Predictions Min      761.058\n",
      "trainer/Z Policy Predictions Mean    1075.77\n",
      "trainer/Z Policy Predictions Std      324.61\n",
      "trainer/Z Policy Predictions Max     1496.27\n",
      "trainer/Z Policy Predictions Min      -39.7656\n",
      "trainer/Z Expert Targets Mean        1205.56\n",
      "trainer/Z Expert Targets Std          131.08\n",
      "trainer/Z Expert Targets Max         1476.93\n",
      "trainer/Z Expert Targets Min          716.715\n",
      "trainer/Z Policy Targets Mean        1071.45\n",
      "trainer/Z Policy Targets Std          322.926\n",
      "trainer/Z Policy Targets Max         1488.34\n",
      "trainer/Z Policy Targets Min          -52.7352\n",
      "trainer/Log Pis Mean                   20.0259\n",
      "trainer/Log Pis Std                     4.1358\n",
      "trainer/Policy mu Mean                  1.17401\n",
      "trainer/Policy mu Std                   1.87393\n",
      "trainer/Policy log std Mean            -2.25914\n",
      "trainer/Policy log std Std              1.22605\n",
      "trainer/Alpha                           0.172018\n",
      "trainer/Alpha Loss                     -0.00444983\n",
      "exploration/num steps total        253415\n",
      "exploration/num paths total           834\n",
      "evaluation/num steps total              2.09469e+06\n",
      "evaluation/num paths total           2486\n",
      "evaluation/path length Mean           917\n",
      "evaluation/path length Std            249\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            170\n",
      "evaluation/Rewards Mean                 5.19678\n",
      "evaluation/Rewards Std                  1.40429\n",
      "evaluation/Rewards Max                  7.26172\n",
      "evaluation/Rewards Min                  0.0736593\n",
      "evaluation/Returns Mean              4765.45\n",
      "evaluation/Returns Std               1436.05\n",
      "evaluation/Returns Max               5276.37\n",
      "evaluation/Returns Min                457.805\n",
      "evaluation/Estimation Bias Mean      1204.67\n",
      "evaluation/Estimation Bias Std        228.874\n",
      "evaluation/EB/Q_True Mean              54.4764\n",
      "evaluation/EB/Q_True Std              160.492\n",
      "evaluation/EB/Q_Pred Mean            1259.15\n",
      "evaluation/EB/Q_Pred Std              139.545\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4765.45\n",
      "evaluation/Actions Mean                 0.511556\n",
      "evaluation/Actions Std                  0.642988\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                2.30901\n",
      "time/backward_zf1 (s)                   2.51444\n",
      "time/backward_zf2 (s)                   2.38349\n",
      "time/data sampling (s)                  0.340305\n",
      "time/data storing (s)                   0.0167521\n",
      "time/evaluation sampling (s)            1.43254\n",
      "time/exploration sampling (s)           0.216057\n",
      "time/logging (s)                        0.0121295\n",
      "time/preback_alpha (s)                  1.13272\n",
      "time/preback_policy (s)                 1.32754\n",
      "time/preback_start (s)                  0.139731\n",
      "time/preback_zf (s)                     5.42104\n",
      "time/saving (s)                         0.00594355\n",
      "time/training (s)                       2.31371\n",
      "time/epoch (s)                         19.5654\n",
      "time/total (s)                       4357.02\n",
      "Epoch                                 247\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:23:35.873004 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 248 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 259000\n",
      "trainer/ZF1 Loss                      215.167\n",
      "trainer/ZF2 Loss                      267.196\n",
      "trainer/ZF Expert Reward               20.5433\n",
      "trainer/ZF Policy Reward                0.401069\n",
      "trainer/ZF CHI2 Term                  281.04\n",
      "trainer/Policy Loss                 -1096.16\n",
      "trainer/Bias Loss                    2309.65\n",
      "trainer/Bias Value                     19.4574\n",
      "trainer/Policy Grad Norm              395.132\n",
      "trainer/Policy Param Norm              39.968\n",
      "trainer/Zf1 Grad Norm               12508.2\n",
      "trainer/Zf1 Param Norm                128.487\n",
      "trainer/Zf2 Grad Norm               11046.2\n",
      "trainer/Zf2 Param Norm                126.146\n",
      "trainer/Z Expert Predictions Mean    1226.71\n",
      "trainer/Z Expert Predictions Std      178.018\n",
      "trainer/Z Expert Predictions Max     1509.23\n",
      "trainer/Z Expert Predictions Min      190.967\n",
      "trainer/Z Policy Predictions Mean    1084.85\n",
      "trainer/Z Policy Predictions Std      324.888\n",
      "trainer/Z Policy Predictions Max     1494.39\n",
      "trainer/Z Policy Predictions Min      -29.8687\n",
      "trainer/Z Expert Targets Mean        1206.17\n",
      "trainer/Z Expert Targets Std          196.541\n",
      "trainer/Z Expert Targets Max         1489.96\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1084.45\n",
      "trainer/Z Policy Targets Std          319.488\n",
      "trainer/Z Policy Targets Max         1488.68\n",
      "trainer/Z Policy Targets Min          -41.4979\n",
      "trainer/Log Pis Mean                   19.9154\n",
      "trainer/Log Pis Std                     3.99322\n",
      "trainer/Policy mu Mean                  1.23364\n",
      "trainer/Policy mu Std                   1.8316\n",
      "trainer/Policy log std Mean            -2.25028\n",
      "trainer/Policy log std Std              1.22801\n",
      "trainer/Alpha                           0.175198\n",
      "trainer/Alpha Loss                      0.0148289\n",
      "exploration/num steps total        253415\n",
      "exploration/num paths total           834\n",
      "evaluation/num steps total              2.10381e+06\n",
      "evaluation/num paths total           2496\n",
      "evaluation/path length Mean           912.6\n",
      "evaluation/path length Std            262.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            126\n",
      "evaluation/Rewards Mean                 5.2026\n",
      "evaluation/Rewards Std                  1.39133\n",
      "evaluation/Rewards Max                  7.20808\n",
      "evaluation/Rewards Min                  0.138409\n",
      "evaluation/Returns Mean              4747.89\n",
      "evaluation/Returns Std               1515.94\n",
      "evaluation/Returns Max               5275.8\n",
      "evaluation/Returns Min                200.35\n",
      "evaluation/Estimation Bias Mean      1187.93\n",
      "evaluation/Estimation Bias Std        222.493\n",
      "evaluation/EB/Q_True Mean              54.5347\n",
      "evaluation/EB/Q_True Std              159.932\n",
      "evaluation/EB/Q_Pred Mean            1242.46\n",
      "evaluation/EB/Q_Pred Std              129.392\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4747.89\n",
      "evaluation/Actions Mean                 0.513232\n",
      "evaluation/Actions Std                  0.641277\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.35926\n",
      "time/backward_zf1 (s)                   2.59673\n",
      "time/backward_zf2 (s)                   2.48751\n",
      "time/data sampling (s)                  0.344155\n",
      "time/data storing (s)                   0.0159573\n",
      "time/evaluation sampling (s)            1.43779\n",
      "time/exploration sampling (s)           0.213234\n",
      "time/logging (s)                        0.0123801\n",
      "time/preback_alpha (s)                  1.15524\n",
      "time/preback_policy (s)                 1.36801\n",
      "time/preback_start (s)                  0.14071\n",
      "time/preback_zf (s)                     5.49123\n",
      "time/saving (s)                         0.00523725\n",
      "time/training (s)                       2.33256\n",
      "time/epoch (s)                         19.96\n",
      "time/total (s)                       4377\n",
      "Epoch                                 248\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:23:55.514816 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 249 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 260000\n",
      "trainer/ZF1 Loss                       44.6059\n",
      "trainer/ZF2 Loss                       42.8577\n",
      "trainer/ZF Expert Reward               17.5954\n",
      "trainer/ZF Policy Reward                1.67984\n",
      "trainer/ZF CHI2 Term                   79.0454\n",
      "trainer/Policy Loss                 -1083.9\n",
      "trainer/Bias Loss                     244.949\n",
      "trainer/Bias Value                     19.4445\n",
      "trainer/Policy Grad Norm              370.021\n",
      "trainer/Policy Param Norm              40.0109\n",
      "trainer/Zf1 Grad Norm                5436.6\n",
      "trainer/Zf1 Param Norm                128.629\n",
      "trainer/Zf2 Grad Norm                4968.07\n",
      "trainer/Zf2 Param Norm                126.305\n",
      "trainer/Z Expert Predictions Mean    1234.68\n",
      "trainer/Z Expert Predictions Std      168.797\n",
      "trainer/Z Expert Predictions Max     1506.12\n",
      "trainer/Z Expert Predictions Min        9.40157\n",
      "trainer/Z Policy Predictions Mean    1074.71\n",
      "trainer/Z Policy Predictions Std      314.971\n",
      "trainer/Z Policy Predictions Max     1486.87\n",
      "trainer/Z Policy Predictions Min      -18.6014\n",
      "trainer/Z Expert Targets Mean        1217.08\n",
      "trainer/Z Expert Targets Std          174.326\n",
      "trainer/Z Expert Targets Max         1484.7\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1073.03\n",
      "trainer/Z Policy Targets Std          313.302\n",
      "trainer/Z Policy Targets Max         1491.05\n",
      "trainer/Z Policy Targets Min          -27.1483\n",
      "trainer/Log Pis Mean                   19.594\n",
      "trainer/Log Pis Std                     3.63781\n",
      "trainer/Policy mu Mean                  1.25989\n",
      "trainer/Policy mu Std                   1.72676\n",
      "trainer/Policy log std Mean            -2.28334\n",
      "trainer/Policy log std Std              1.19135\n",
      "trainer/Alpha                           0.176733\n",
      "trainer/Alpha Loss                      0.071761\n",
      "exploration/num steps total        255415\n",
      "exploration/num paths total           836\n",
      "evaluation/num steps total              2.1113e+06\n",
      "evaluation/num paths total           2507\n",
      "evaluation/path length Mean           680.455\n",
      "evaluation/path length Std            422.768\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            104\n",
      "evaluation/Rewards Mean                 4.95003\n",
      "evaluation/Rewards Std                  1.5452\n",
      "evaluation/Rewards Max                  6.99639\n",
      "evaluation/Rewards Min                 -0.22987\n",
      "evaluation/Returns Mean              3368.27\n",
      "evaluation/Returns Std               2382.23\n",
      "evaluation/Returns Max               5179.61\n",
      "evaluation/Returns Min                190.898\n",
      "evaluation/Estimation Bias Mean      1192.13\n",
      "evaluation/Estimation Bias Std        340.998\n",
      "evaluation/EB/Q_True Mean              65.3729\n",
      "evaluation/EB/Q_True Std              171.64\n",
      "evaluation/EB/Q_Pred Mean            1257.51\n",
      "evaluation/EB/Q_Pred Std              218.064\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3368.27\n",
      "evaluation/Actions Mean                 0.487693\n",
      "evaluation/Actions Std                  0.647373\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.24242\n",
      "time/backward_zf1 (s)                   2.50238\n",
      "time/backward_zf2 (s)                   2.35629\n",
      "time/data sampling (s)                  0.355408\n",
      "time/data storing (s)                   0.0167576\n",
      "time/evaluation sampling (s)            1.38819\n",
      "time/exploration sampling (s)           0.220788\n",
      "time/logging (s)                        0.00944861\n",
      "time/preback_alpha (s)                  1.12876\n",
      "time/preback_policy (s)                 1.29853\n",
      "time/preback_start (s)                  0.141493\n",
      "time/preback_zf (s)                     5.47686\n",
      "time/saving (s)                         0.00526742\n",
      "time/training (s)                       2.42088\n",
      "time/epoch (s)                         19.5635\n",
      "time/total (s)                       4396.58\n",
      "Epoch                                 249\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:24:15.212146 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 250 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 261000\n",
      "trainer/ZF1 Loss                      229.899\n",
      "trainer/ZF2 Loss                      253.794\n",
      "trainer/ZF Expert Reward               15.3489\n",
      "trainer/ZF Policy Reward                1.50568\n",
      "trainer/ZF CHI2 Term                  275.298\n",
      "trainer/Policy Loss                 -1053.91\n",
      "trainer/Bias Loss                    2288.9\n",
      "trainer/Bias Value                     19.4318\n",
      "trainer/Policy Grad Norm              285.913\n",
      "trainer/Policy Param Norm              40.0512\n",
      "trainer/Zf1 Grad Norm               14068.6\n",
      "trainer/Zf1 Param Norm                128.769\n",
      "trainer/Zf2 Grad Norm               13333.2\n",
      "trainer/Zf2 Param Norm                126.459\n",
      "trainer/Z Expert Predictions Mean    1216.59\n",
      "trainer/Z Expert Predictions Std      174.657\n",
      "trainer/Z Expert Predictions Max     1478.2\n",
      "trainer/Z Expert Predictions Min       32.5216\n",
      "trainer/Z Policy Predictions Mean    1042.71\n",
      "trainer/Z Policy Predictions Std      333.891\n",
      "trainer/Z Policy Predictions Max     1458.24\n",
      "trainer/Z Policy Predictions Min      -35.1675\n",
      "trainer/Z Expert Targets Mean        1201.24\n",
      "trainer/Z Expert Targets Std          193.065\n",
      "trainer/Z Expert Targets Max         1474.96\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1041.2\n",
      "trainer/Z Policy Targets Std          331.388\n",
      "trainer/Z Policy Targets Max         1456.98\n",
      "trainer/Z Policy Targets Min          -15.4541\n",
      "trainer/Log Pis Mean                   19.8063\n",
      "trainer/Log Pis Std                     4.51377\n",
      "trainer/Policy mu Mean                  1.14678\n",
      "trainer/Policy mu Std                   1.92447\n",
      "trainer/Policy log std Mean            -2.21822\n",
      "trainer/Policy log std Std              1.22945\n",
      "trainer/Alpha                           0.178899\n",
      "trainer/Alpha Loss                      0.0346478\n",
      "exploration/num steps total        255415\n",
      "exploration/num paths total           836\n",
      "evaluation/num steps total              2.1213e+06\n",
      "evaluation/num paths total           2517\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21194\n",
      "evaluation/Rewards Std                  1.31628\n",
      "evaluation/Rewards Max                  7.08183\n",
      "evaluation/Rewards Min                  0.0994947\n",
      "evaluation/Returns Mean              5211.94\n",
      "evaluation/Returns Std                 15.0525\n",
      "evaluation/Returns Max               5237.7\n",
      "evaluation/Returns Min               5180.82\n",
      "evaluation/Estimation Bias Mean      1238.04\n",
      "evaluation/Estimation Bias Std        169.693\n",
      "evaluation/EB/Q_True Mean              49.2949\n",
      "evaluation/EB/Q_True Std              152.092\n",
      "evaluation/EB/Q_Pred Mean            1287.34\n",
      "evaluation/EB/Q_Pred Std               84.8954\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5211.94\n",
      "evaluation/Actions Mean                 0.500748\n",
      "evaluation/Actions Std                  0.644419\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                2.25104\n",
      "time/backward_zf1 (s)                   2.51923\n",
      "time/backward_zf2 (s)                   2.39209\n",
      "time/data sampling (s)                  0.34897\n",
      "time/data storing (s)                   0.0192422\n",
      "time/evaluation sampling (s)            1.4548\n",
      "time/exploration sampling (s)           0.220728\n",
      "time/logging (s)                        0.0122939\n",
      "time/preback_alpha (s)                  1.13344\n",
      "time/preback_policy (s)                 1.32347\n",
      "time/preback_start (s)                  0.140343\n",
      "time/preback_zf (s)                     5.45203\n",
      "time/saving (s)                         0.00565171\n",
      "time/training (s)                       2.34886\n",
      "time/epoch (s)                         19.6222\n",
      "time/total (s)                       4416.23\n",
      "Epoch                                 250\n",
      "---------------------------------  ---------------\n",
      "2024-06-18 18:24:34.770821 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 251 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 262000\n",
      "trainer/ZF1 Loss                      358.413\n",
      "trainer/ZF2 Loss                      356.738\n",
      "trainer/ZF Expert Reward                9.38278\n",
      "trainer/ZF Policy Reward                3.4552\n",
      "trainer/ZF CHI2 Term                  383.352\n",
      "trainer/Policy Loss                 -1085\n",
      "trainer/Bias Loss                     186.547\n",
      "trainer/Bias Value                     19.421\n",
      "trainer/Policy Grad Norm              317.844\n",
      "trainer/Policy Param Norm              40.0878\n",
      "trainer/Zf1 Grad Norm                6051.81\n",
      "trainer/Zf1 Param Norm                128.916\n",
      "trainer/Zf2 Grad Norm                6532.88\n",
      "trainer/Zf2 Param Norm                126.603\n",
      "trainer/Z Expert Predictions Mean    1225.08\n",
      "trainer/Z Expert Predictions Std      137.059\n",
      "trainer/Z Expert Predictions Max     1484.67\n",
      "trainer/Z Expert Predictions Min      577.112\n",
      "trainer/Z Policy Predictions Mean    1083.26\n",
      "trainer/Z Policy Predictions Std      308.763\n",
      "trainer/Z Policy Predictions Max     1455.4\n",
      "trainer/Z Policy Predictions Min      -51.6459\n",
      "trainer/Z Expert Targets Mean        1215.7\n",
      "trainer/Z Expert Targets Std          138.731\n",
      "trainer/Z Expert Targets Max         1467.67\n",
      "trainer/Z Expert Targets Min          574.582\n",
      "trainer/Z Policy Targets Mean        1079.8\n",
      "trainer/Z Policy Targets Std          312.391\n",
      "trainer/Z Policy Targets Max         1446.73\n",
      "trainer/Z Policy Targets Min          -46.3716\n",
      "trainer/Log Pis Mean                   20.0498\n",
      "trainer/Log Pis Std                     3.86615\n",
      "trainer/Policy mu Mean                  1.21642\n",
      "trainer/Policy mu Std                   1.86118\n",
      "trainer/Policy log std Mean            -2.24421\n",
      "trainer/Policy log std Std              1.22046\n",
      "trainer/Alpha                           0.179516\n",
      "trainer/Alpha Loss                     -0.00894723\n",
      "exploration/num steps total        255415\n",
      "exploration/num paths total           836\n",
      "evaluation/num steps total              2.13042e+06\n",
      "evaluation/num paths total           2527\n",
      "evaluation/path length Mean           912\n",
      "evaluation/path length Std            264\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            120\n",
      "evaluation/Rewards Mean                 5.19099\n",
      "evaluation/Rewards Std                  1.40816\n",
      "evaluation/Rewards Max                  7.16082\n",
      "evaluation/Rewards Min                  0.0841675\n",
      "evaluation/Returns Mean              4734.18\n",
      "evaluation/Returns Std               1509.07\n",
      "evaluation/Returns Max               5260.84\n",
      "evaluation/Returns Min                207.272\n",
      "evaluation/Estimation Bias Mean      1192.46\n",
      "evaluation/Estimation Bias Std        217.298\n",
      "evaluation/EB/Q_True Mean              54.1934\n",
      "evaluation/EB/Q_True Std              159.086\n",
      "evaluation/EB/Q_Pred Mean            1246.65\n",
      "evaluation/EB/Q_Pred Std              131.696\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4734.18\n",
      "evaluation/Actions Mean                 0.503602\n",
      "evaluation/Actions Std                  0.64552\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.23404\n",
      "time/backward_zf1 (s)                   2.48093\n",
      "time/backward_zf2 (s)                   2.33415\n",
      "time/data sampling (s)                  0.352772\n",
      "time/data storing (s)                   0.0160753\n",
      "time/evaluation sampling (s)            1.41719\n",
      "time/exploration sampling (s)           0.208977\n",
      "time/logging (s)                        0.0132312\n",
      "time/preback_alpha (s)                  1.11354\n",
      "time/preback_policy (s)                 1.29922\n",
      "time/preback_start (s)                  0.138937\n",
      "time/preback_zf (s)                     5.45179\n",
      "time/saving (s)                         0.00536384\n",
      "time/training (s)                       2.41535\n",
      "time/epoch (s)                         19.4816\n",
      "time/total (s)                       4435.73\n",
      "Epoch                                 251\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:24:54.835097 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 252 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 263000\n",
      "trainer/ZF1 Loss                       42.9016\n",
      "trainer/ZF2 Loss                       59.4578\n",
      "trainer/ZF Expert Reward               28.7062\n",
      "trainer/ZF Policy Reward               13.7528\n",
      "trainer/ZF CHI2 Term                   85.5125\n",
      "trainer/Policy Loss                 -1099.06\n",
      "trainer/Bias Loss                     197.529\n",
      "trainer/Bias Value                     19.4095\n",
      "trainer/Policy Grad Norm              329.394\n",
      "trainer/Policy Param Norm              40.1305\n",
      "trainer/Zf1 Grad Norm                6257.01\n",
      "trainer/Zf1 Param Norm                129.052\n",
      "trainer/Zf2 Grad Norm                8200.7\n",
      "trainer/Zf2 Param Norm                126.743\n",
      "trainer/Z Expert Predictions Mean    1245.39\n",
      "trainer/Z Expert Predictions Std      126.711\n",
      "trainer/Z Expert Predictions Max     1511.54\n",
      "trainer/Z Expert Predictions Min      863.098\n",
      "trainer/Z Policy Predictions Mean    1100.2\n",
      "trainer/Z Policy Predictions Std      314.932\n",
      "trainer/Z Policy Predictions Max     1475.75\n",
      "trainer/Z Policy Predictions Min      -77.1625\n",
      "trainer/Z Expert Targets Mean        1216.69\n",
      "trainer/Z Expert Targets Std          128.067\n",
      "trainer/Z Expert Targets Max         1459.53\n",
      "trainer/Z Expert Targets Min          822.163\n",
      "trainer/Z Policy Targets Mean        1086.45\n",
      "trainer/Z Policy Targets Std          312.515\n",
      "trainer/Z Policy Targets Max         1456\n",
      "trainer/Z Policy Targets Min          -77.6494\n",
      "trainer/Log Pis Mean                   19.5752\n",
      "trainer/Log Pis Std                     4.01024\n",
      "trainer/Policy mu Mean                  1.22896\n",
      "trainer/Policy mu Std                   1.84014\n",
      "trainer/Policy log std Mean            -2.23854\n",
      "trainer/Policy log std Std              1.23097\n",
      "trainer/Alpha                           0.179137\n",
      "trainer/Alpha Loss                      0.0760986\n",
      "exploration/num steps total        256415\n",
      "exploration/num paths total           837\n",
      "evaluation/num steps total              2.13962e+06\n",
      "evaluation/num paths total           2538\n",
      "evaluation/path length Mean           836.636\n",
      "evaluation/path length Std            346.548\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             99\n",
      "evaluation/Rewards Mean                 5.10304\n",
      "evaluation/Rewards Std                  1.40121\n",
      "evaluation/Rewards Max                  7.04273\n",
      "evaluation/Rewards Min                  0.0947057\n",
      "evaluation/Returns Mean              4269.39\n",
      "evaluation/Returns Std               1925.99\n",
      "evaluation/Returns Max               5190.13\n",
      "evaluation/Returns Min                179.684\n",
      "evaluation/Estimation Bias Mean      1229.53\n",
      "evaluation/Estimation Bias Std        226.073\n",
      "evaluation/EB/Q_True Mean              53.108\n",
      "evaluation/EB/Q_True Std              156.675\n",
      "evaluation/EB/Q_Pred Mean            1282.64\n",
      "evaluation/EB/Q_Pred Std              128.64\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4269.39\n",
      "evaluation/Actions Mean                 0.503845\n",
      "evaluation/Actions Std                  0.647642\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                2.28562\n",
      "time/backward_zf1 (s)                   2.51982\n",
      "time/backward_zf2 (s)                   2.43188\n",
      "time/data sampling (s)                  0.357672\n",
      "time/data storing (s)                   0.0192873\n",
      "time/evaluation sampling (s)            1.38843\n",
      "time/exploration sampling (s)           0.232288\n",
      "time/logging (s)                        0.0113135\n",
      "time/preback_alpha (s)                  1.1382\n",
      "time/preback_policy (s)                 1.33288\n",
      "time/preback_start (s)                  0.144329\n",
      "time/preback_zf (s)                     5.58089\n",
      "time/saving (s)                         0.00543518\n",
      "time/training (s)                       2.53201\n",
      "time/epoch (s)                         19.9801\n",
      "time/total (s)                       4455.73\n",
      "Epoch                                 252\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:25:14.221176 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 253 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 264000\n",
      "trainer/ZF1 Loss                       29.3951\n",
      "trainer/ZF2 Loss                       39.9825\n",
      "trainer/ZF Expert Reward               18.3327\n",
      "trainer/ZF Policy Reward                3.25199\n",
      "trainer/ZF CHI2 Term                   70.084\n",
      "trainer/Policy Loss                 -1090.56\n",
      "trainer/Bias Loss                     148.765\n",
      "trainer/Bias Value                     19.3988\n",
      "trainer/Policy Grad Norm              405.601\n",
      "trainer/Policy Param Norm              40.1702\n",
      "trainer/Zf1 Grad Norm                4094.37\n",
      "trainer/Zf1 Param Norm                129.196\n",
      "trainer/Zf2 Grad Norm                4590.05\n",
      "trainer/Zf2 Param Norm                126.882\n",
      "trainer/Z Expert Predictions Mean    1221.11\n",
      "trainer/Z Expert Predictions Std      132.456\n",
      "trainer/Z Expert Predictions Max     1474.12\n",
      "trainer/Z Expert Predictions Min      637.623\n",
      "trainer/Z Policy Predictions Mean    1087.59\n",
      "trainer/Z Policy Predictions Std      301.57\n",
      "trainer/Z Policy Predictions Max     1500.67\n",
      "trainer/Z Policy Predictions Min      -58.4427\n",
      "trainer/Z Expert Targets Mean        1202.78\n",
      "trainer/Z Expert Targets Std          135.558\n",
      "trainer/Z Expert Targets Max         1461.21\n",
      "trainer/Z Expert Targets Min          617.514\n",
      "trainer/Z Policy Targets Mean        1084.34\n",
      "trainer/Z Policy Targets Std          298.341\n",
      "trainer/Z Policy Targets Max         1478.64\n",
      "trainer/Z Policy Targets Min          -52.9156\n",
      "trainer/Log Pis Mean                   20.5197\n",
      "trainer/Log Pis Std                     3.87467\n",
      "trainer/Policy mu Mean                  1.26927\n",
      "trainer/Policy mu Std                   1.90375\n",
      "trainer/Policy log std Mean            -2.26086\n",
      "trainer/Policy log std Std              1.22829\n",
      "trainer/Alpha                           0.182095\n",
      "trainer/Alpha Loss                     -0.094627\n",
      "exploration/num steps total        259415\n",
      "exploration/num paths total           840\n",
      "evaluation/num steps total              2.14788e+06\n",
      "evaluation/num paths total           2548\n",
      "evaluation/path length Mean           826.1\n",
      "evaluation/path length Std            347.838\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            119\n",
      "evaluation/Rewards Mean                 5.11715\n",
      "evaluation/Rewards Std                  1.46145\n",
      "evaluation/Rewards Max                  7.21686\n",
      "evaluation/Rewards Min                  0.0983718\n",
      "evaluation/Returns Mean              4227.28\n",
      "evaluation/Returns Std               1999.82\n",
      "evaluation/Returns Max               5248.04\n",
      "evaluation/Returns Min                203.416\n",
      "evaluation/Estimation Bias Mean      1199.95\n",
      "evaluation/Estimation Bias Std        264.39\n",
      "evaluation/EB/Q_True Mean              59.7964\n",
      "evaluation/EB/Q_True Std              166.014\n",
      "evaluation/EB/Q_Pred Mean            1259.74\n",
      "evaluation/EB/Q_Pred Std              159.853\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4227.28\n",
      "evaluation/Actions Mean                 0.509237\n",
      "evaluation/Actions Std                  0.644721\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.18746\n",
      "time/backward_zf1 (s)                   2.41597\n",
      "time/backward_zf2 (s)                   2.29333\n",
      "time/data sampling (s)                  0.358932\n",
      "time/data storing (s)                   0.0161897\n",
      "time/evaluation sampling (s)            1.41487\n",
      "time/exploration sampling (s)           0.218229\n",
      "time/logging (s)                        0.0103329\n",
      "time/preback_alpha (s)                  1.07527\n",
      "time/preback_policy (s)                 1.23692\n",
      "time/preback_start (s)                  0.140903\n",
      "time/preback_zf (s)                     5.43663\n",
      "time/saving (s)                         0.00499332\n",
      "time/training (s)                       2.49979\n",
      "time/epoch (s)                         19.3098\n",
      "time/total (s)                       4475.06\n",
      "Epoch                                 253\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:25:34.022003 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 254 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 265000\n",
      "trainer/ZF1 Loss                       73.7572\n",
      "trainer/ZF2 Loss                       65.8562\n",
      "trainer/ZF Expert Reward               20.0419\n",
      "trainer/ZF Policy Reward               13.6226\n",
      "trainer/ZF CHI2 Term                   96.0412\n",
      "trainer/Policy Loss                 -1088.52\n",
      "trainer/Bias Loss                     371.493\n",
      "trainer/Bias Value                     19.385\n",
      "trainer/Policy Grad Norm              454.905\n",
      "trainer/Policy Param Norm              40.2068\n",
      "trainer/Zf1 Grad Norm                6350.98\n",
      "trainer/Zf1 Param Norm                129.329\n",
      "trainer/Zf2 Grad Norm                7024.06\n",
      "trainer/Zf2 Param Norm                127.027\n",
      "trainer/Z Expert Predictions Mean    1246.4\n",
      "trainer/Z Expert Predictions Std      145.259\n",
      "trainer/Z Expert Predictions Max     1475.73\n",
      "trainer/Z Expert Predictions Min      220.061\n",
      "trainer/Z Policy Predictions Mean    1081.65\n",
      "trainer/Z Policy Predictions Std      315.44\n",
      "trainer/Z Policy Predictions Max     1441.56\n",
      "trainer/Z Policy Predictions Min     -134.168\n",
      "trainer/Z Expert Targets Mean        1226.35\n",
      "trainer/Z Expert Targets Std          147.688\n",
      "trainer/Z Expert Targets Max         1457.52\n",
      "trainer/Z Expert Targets Min          165.347\n",
      "trainer/Z Policy Targets Mean        1068.03\n",
      "trainer/Z Policy Targets Std          312.078\n",
      "trainer/Z Policy Targets Max         1444.08\n",
      "trainer/Z Policy Targets Min         -156.558\n",
      "trainer/Log Pis Mean                   20.0154\n",
      "trainer/Log Pis Std                     3.81438\n",
      "trainer/Policy mu Mean                  1.23969\n",
      "trainer/Policy mu Std                   1.85084\n",
      "trainer/Policy log std Mean            -2.21327\n",
      "trainer/Policy log std Std              1.19846\n",
      "trainer/Alpha                           0.184686\n",
      "trainer/Alpha Loss                     -0.00283817\n",
      "exploration/num steps total        261415\n",
      "exploration/num paths total           842\n",
      "evaluation/num steps total              2.15788e+06\n",
      "evaluation/num paths total           2558\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19614\n",
      "evaluation/Rewards Std                  1.32624\n",
      "evaluation/Rewards Max                  7.07726\n",
      "evaluation/Rewards Min                  0.108967\n",
      "evaluation/Returns Mean              5196.14\n",
      "evaluation/Returns Std                 15.6725\n",
      "evaluation/Returns Max               5218.85\n",
      "evaluation/Returns Min               5174.25\n",
      "evaluation/Estimation Bias Mean      1233.25\n",
      "evaluation/Estimation Bias Std        171.855\n",
      "evaluation/EB/Q_True Mean              49.1001\n",
      "evaluation/EB/Q_True Std              151.612\n",
      "evaluation/EB/Q_Pred Mean            1282.35\n",
      "evaluation/EB/Q_Pred Std               80.4767\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5196.14\n",
      "evaluation/Actions Mean                 0.499422\n",
      "evaluation/Actions Std                  0.646582\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999988\n",
      "time/backward_policy (s)                2.28649\n",
      "time/backward_zf1 (s)                   2.50485\n",
      "time/backward_zf2 (s)                   2.37514\n",
      "time/data sampling (s)                  0.359978\n",
      "time/data storing (s)                   0.0163221\n",
      "time/evaluation sampling (s)            1.46838\n",
      "time/exploration sampling (s)           0.218533\n",
      "time/logging (s)                        0.0122203\n",
      "time/preback_alpha (s)                  1.1325\n",
      "time/preback_policy (s)                 1.30987\n",
      "time/preback_start (s)                  0.142089\n",
      "time/preback_zf (s)                     5.46787\n",
      "time/saving (s)                         0.00519697\n",
      "time/training (s)                       2.42757\n",
      "time/epoch (s)                         19.727\n",
      "time/total (s)                       4494.81\n",
      "Epoch                                 254\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:25:53.666014 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 255 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 266000\n",
      "trainer/ZF1 Loss                       16.4557\n",
      "trainer/ZF2 Loss                       25.6456\n",
      "trainer/ZF Expert Reward               16.0098\n",
      "trainer/ZF Policy Reward                2.04956\n",
      "trainer/ZF CHI2 Term                   54.8198\n",
      "trainer/Policy Loss                 -1079.25\n",
      "trainer/Bias Loss                     117.846\n",
      "trainer/Bias Value                     19.3743\n",
      "trainer/Policy Grad Norm              350.709\n",
      "trainer/Policy Param Norm              40.2431\n",
      "trainer/Zf1 Grad Norm                4105.91\n",
      "trainer/Zf1 Param Norm                129.461\n",
      "trainer/Zf2 Grad Norm                4454.34\n",
      "trainer/Zf2 Param Norm                127.155\n",
      "trainer/Z Expert Predictions Mean    1215.56\n",
      "trainer/Z Expert Predictions Std      142.58\n",
      "trainer/Z Expert Predictions Max     1473.66\n",
      "trainer/Z Expert Predictions Min      155.295\n",
      "trainer/Z Policy Predictions Mean    1066.52\n",
      "trainer/Z Policy Predictions Std      306.589\n",
      "trainer/Z Policy Predictions Max     1447.13\n",
      "trainer/Z Policy Predictions Min      -78.6376\n",
      "trainer/Z Expert Targets Mean        1199.55\n",
      "trainer/Z Expert Targets Std          145.724\n",
      "trainer/Z Expert Targets Max         1445.42\n",
      "trainer/Z Expert Targets Min          115.15\n",
      "trainer/Z Policy Targets Mean        1064.47\n",
      "trainer/Z Policy Targets Std          302.78\n",
      "trainer/Z Policy Targets Max         1447.42\n",
      "trainer/Z Policy Targets Min          -96.2038\n",
      "trainer/Log Pis Mean                   20.009\n",
      "trainer/Log Pis Std                     4.31754\n",
      "trainer/Policy mu Mean                  1.19236\n",
      "trainer/Policy mu Std                   1.87274\n",
      "trainer/Policy log std Mean            -2.31211\n",
      "trainer/Policy log std Std              1.21424\n",
      "trainer/Alpha                           0.186435\n",
      "trainer/Alpha Loss                     -0.0016767\n",
      "exploration/num steps total        262415\n",
      "exploration/num paths total           843\n",
      "evaluation/num steps total              2.16615e+06\n",
      "evaluation/num paths total           2568\n",
      "evaluation/path length Mean           826.6\n",
      "evaluation/path length Std            346.857\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            119\n",
      "evaluation/Rewards Mean                 5.05307\n",
      "evaluation/Rewards Std                  1.4298\n",
      "evaluation/Rewards Max                  7.03089\n",
      "evaluation/Rewards Min                  0.0995761\n",
      "evaluation/Returns Mean              4176.87\n",
      "evaluation/Returns Std               1966.73\n",
      "evaluation/Returns Max               5191.1\n",
      "evaluation/Returns Min                221.772\n",
      "evaluation/Estimation Bias Mean      1202.67\n",
      "evaluation/Estimation Bias Std        274.842\n",
      "evaluation/EB/Q_True Mean              59.2241\n",
      "evaluation/EB/Q_True Std              164.576\n",
      "evaluation/EB/Q_Pred Mean            1261.89\n",
      "evaluation/EB/Q_Pred Std              170.829\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4176.87\n",
      "evaluation/Actions Mean                 0.487329\n",
      "evaluation/Actions Std                  0.654058\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.24875\n",
      "time/backward_zf1 (s)                   2.48829\n",
      "time/backward_zf2 (s)                   2.35857\n",
      "time/data sampling (s)                  0.356685\n",
      "time/data storing (s)                   0.0156594\n",
      "time/evaluation sampling (s)            1.42974\n",
      "time/exploration sampling (s)           0.214197\n",
      "time/logging (s)                        0.0100849\n",
      "time/preback_alpha (s)                  1.11265\n",
      "time/preback_policy (s)                 1.28762\n",
      "time/preback_start (s)                  0.140049\n",
      "time/preback_zf (s)                     5.42887\n",
      "time/saving (s)                         0.00537288\n",
      "time/training (s)                       2.46809\n",
      "time/epoch (s)                         19.5646\n",
      "time/total (s)                       4514.39\n",
      "Epoch                                 255\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:26:13.426475 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 256 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 267000\n",
      "trainer/ZF1 Loss                       41.859\n",
      "trainer/ZF2 Loss                       46.7718\n",
      "trainer/ZF Expert Reward               18.1852\n",
      "trainer/ZF Policy Reward                7.20344\n",
      "trainer/ZF CHI2 Term                   74.8772\n",
      "trainer/Policy Loss                 -1077\n",
      "trainer/Bias Loss                     135.704\n",
      "trainer/Bias Value                     19.3632\n",
      "trainer/Policy Grad Norm              300.88\n",
      "trainer/Policy Param Norm              40.2814\n",
      "trainer/Zf1 Grad Norm                4864\n",
      "trainer/Zf1 Param Norm                129.588\n",
      "trainer/Zf2 Grad Norm                4817.29\n",
      "trainer/Zf2 Param Norm                127.277\n",
      "trainer/Z Expert Predictions Mean    1206.47\n",
      "trainer/Z Expert Predictions Std      159.718\n",
      "trainer/Z Expert Predictions Max     1456.12\n",
      "trainer/Z Expert Predictions Min      163.044\n",
      "trainer/Z Policy Predictions Mean    1072.5\n",
      "trainer/Z Policy Predictions Std      294.849\n",
      "trainer/Z Policy Predictions Max     1447.33\n",
      "trainer/Z Policy Predictions Min     -100.078\n",
      "trainer/Z Expert Targets Mean        1188.28\n",
      "trainer/Z Expert Targets Std          164.383\n",
      "trainer/Z Expert Targets Max         1438.73\n",
      "trainer/Z Expert Targets Min          125.16\n",
      "trainer/Z Policy Targets Mean        1065.3\n",
      "trainer/Z Policy Targets Std          293.771\n",
      "trainer/Z Policy Targets Max         1435.27\n",
      "trainer/Z Policy Targets Min         -121.723\n",
      "trainer/Log Pis Mean                   19.7777\n",
      "trainer/Log Pis Std                     3.65436\n",
      "trainer/Policy mu Mean                  1.17047\n",
      "trainer/Policy mu Std                   1.75569\n",
      "trainer/Policy log std Mean            -2.37941\n",
      "trainer/Policy log std Std              1.17717\n",
      "trainer/Alpha                           0.184693\n",
      "trainer/Alpha Loss                      0.041057\n",
      "exploration/num steps total        263415\n",
      "exploration/num paths total           844\n",
      "evaluation/num steps total              2.17615e+06\n",
      "evaluation/num paths total           2578\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25539\n",
      "evaluation/Rewards Std                  1.3497\n",
      "evaluation/Rewards Max                  7.32409\n",
      "evaluation/Rewards Min                  0.11468\n",
      "evaluation/Returns Mean              5255.39\n",
      "evaluation/Returns Std                 16.4467\n",
      "evaluation/Returns Max               5276.88\n",
      "evaluation/Returns Min               5232.38\n",
      "evaluation/Estimation Bias Mean      1158.81\n",
      "evaluation/Estimation Bias Std        183.761\n",
      "evaluation/EB/Q_True Mean              49.6184\n",
      "evaluation/EB/Q_True Std              153.151\n",
      "evaluation/EB/Q_Pred Mean            1208.43\n",
      "evaluation/EB/Q_Pred Std              109.179\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5255.39\n",
      "evaluation/Actions Mean                 0.504702\n",
      "evaluation/Actions Std                  0.648666\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.24112\n",
      "time/backward_zf1 (s)                   2.57229\n",
      "time/backward_zf2 (s)                   2.38263\n",
      "time/data sampling (s)                  0.363449\n",
      "time/data storing (s)                   0.0162598\n",
      "time/evaluation sampling (s)            1.43981\n",
      "time/exploration sampling (s)           0.22186\n",
      "time/logging (s)                        0.0120898\n",
      "time/preback_alpha (s)                  1.0841\n",
      "time/preback_policy (s)                 1.26894\n",
      "time/preback_start (s)                  0.140366\n",
      "time/preback_zf (s)                     5.43462\n",
      "time/saving (s)                         0.00544603\n",
      "time/training (s)                       2.50383\n",
      "time/epoch (s)                         19.6868\n",
      "time/total (s)                       4534.1\n",
      "Epoch                                 256\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:26:33.120826 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 257 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 268000\n",
      "trainer/ZF1 Loss                       23.3495\n",
      "trainer/ZF2 Loss                       31.8169\n",
      "trainer/ZF Expert Reward               14.621\n",
      "trainer/ZF Policy Reward                1.38674\n",
      "trainer/ZF CHI2 Term                   60.518\n",
      "trainer/Policy Loss                 -1044.82\n",
      "trainer/Bias Loss                     165.027\n",
      "trainer/Bias Value                     19.3511\n",
      "trainer/Policy Grad Norm              288.541\n",
      "trainer/Policy Param Norm              40.3178\n",
      "trainer/Zf1 Grad Norm                4938.96\n",
      "trainer/Zf1 Param Norm                129.723\n",
      "trainer/Zf2 Grad Norm                4590.01\n",
      "trainer/Zf2 Param Norm                127.402\n",
      "trainer/Z Expert Predictions Mean    1199.55\n",
      "trainer/Z Expert Predictions Std      160.779\n",
      "trainer/Z Expert Predictions Max     1449.57\n",
      "trainer/Z Expert Predictions Min       46.1489\n",
      "trainer/Z Policy Predictions Mean    1037.37\n",
      "trainer/Z Policy Predictions Std      333.318\n",
      "trainer/Z Policy Predictions Max     1439.75\n",
      "trainer/Z Policy Predictions Min     -126.4\n",
      "trainer/Z Expert Targets Mean        1184.93\n",
      "trainer/Z Expert Targets Std          166.627\n",
      "trainer/Z Expert Targets Max         1436.35\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1035.98\n",
      "trainer/Z Policy Targets Std          331.912\n",
      "trainer/Z Policy Targets Max         1443.51\n",
      "trainer/Z Policy Targets Min         -120.591\n",
      "trainer/Log Pis Mean                   19.8994\n",
      "trainer/Log Pis Std                     4.35595\n",
      "trainer/Policy mu Mean                  1.23469\n",
      "trainer/Policy mu Std                   1.85767\n",
      "trainer/Policy log std Mean            -2.26179\n",
      "trainer/Policy log std Std              1.2339\n",
      "trainer/Alpha                           0.186466\n",
      "trainer/Alpha Loss                      0.0187513\n",
      "exploration/num steps total        263415\n",
      "exploration/num paths total           844\n",
      "evaluation/num steps total              2.18615e+06\n",
      "evaluation/num paths total           2588\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.23428\n",
      "evaluation/Rewards Std                  1.31953\n",
      "evaluation/Rewards Max                  7.21936\n",
      "evaluation/Rewards Min                  0.130008\n",
      "evaluation/Returns Mean              5234.28\n",
      "evaluation/Returns Std                 16.091\n",
      "evaluation/Returns Max               5260.81\n",
      "evaluation/Returns Min               5206.75\n",
      "evaluation/Estimation Bias Mean      1229.31\n",
      "evaluation/Estimation Bias Std        173.633\n",
      "evaluation/EB/Q_True Mean              49.4469\n",
      "evaluation/EB/Q_True Std              152.83\n",
      "evaluation/EB/Q_Pred Mean            1278.75\n",
      "evaluation/EB/Q_Pred Std               84.5494\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5234.28\n",
      "evaluation/Actions Mean                 0.494287\n",
      "evaluation/Actions Std                  0.646015\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.24197\n",
      "time/backward_zf1 (s)                   2.47029\n",
      "time/backward_zf2 (s)                   2.36473\n",
      "time/data sampling (s)                  0.348259\n",
      "time/data storing (s)                   0.0175659\n",
      "time/evaluation sampling (s)            1.41789\n",
      "time/exploration sampling (s)           0.218246\n",
      "time/logging (s)                        0.0115463\n",
      "time/preback_alpha (s)                  1.11928\n",
      "time/preback_policy (s)                 1.28418\n",
      "time/preback_start (s)                  0.141751\n",
      "time/preback_zf (s)                     5.45679\n",
      "time/saving (s)                         0.00558351\n",
      "time/training (s)                       2.51179\n",
      "time/epoch (s)                         19.6099\n",
      "time/total (s)                       4553.74\n",
      "Epoch                                 257\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:26:53.351210 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 258 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 269000\n",
      "trainer/ZF1 Loss                      234.775\n",
      "trainer/ZF2 Loss                      228.732\n",
      "trainer/ZF Expert Reward               22.1285\n",
      "trainer/ZF Policy Reward               13.0348\n",
      "trainer/ZF CHI2 Term                  260.614\n",
      "trainer/Policy Loss                 -1081.2\n",
      "trainer/Bias Loss                     127.581\n",
      "trainer/Bias Value                     19.3385\n",
      "trainer/Policy Grad Norm              287.959\n",
      "trainer/Policy Param Norm              40.3573\n",
      "trainer/Zf1 Grad Norm                6308.1\n",
      "trainer/Zf1 Param Norm                129.848\n",
      "trainer/Zf2 Grad Norm                7326.08\n",
      "trainer/Zf2 Param Norm                127.528\n",
      "trainer/Z Expert Predictions Mean    1209.17\n",
      "trainer/Z Expert Predictions Std      126.614\n",
      "trainer/Z Expert Predictions Max     1473.28\n",
      "trainer/Z Expert Predictions Min      827.52\n",
      "trainer/Z Policy Predictions Mean    1081.67\n",
      "trainer/Z Policy Predictions Std      307.449\n",
      "trainer/Z Policy Predictions Max     1430.29\n",
      "trainer/Z Policy Predictions Min     -316.786\n",
      "trainer/Z Expert Targets Mean        1187.04\n",
      "trainer/Z Expert Targets Std          129.97\n",
      "trainer/Z Expert Targets Max         1437.22\n",
      "trainer/Z Expert Targets Min          800.254\n",
      "trainer/Z Policy Targets Mean        1068.64\n",
      "trainer/Z Policy Targets Std          309.109\n",
      "trainer/Z Policy Targets Max         1422.48\n",
      "trainer/Z Policy Targets Min         -260.293\n",
      "trainer/Log Pis Mean                   19.9668\n",
      "trainer/Log Pis Std                     3.93386\n",
      "trainer/Policy mu Mean                  1.28081\n",
      "trainer/Policy mu Std                   1.84427\n",
      "trainer/Policy log std Mean            -2.20728\n",
      "trainer/Policy log std Std              1.21142\n",
      "trainer/Alpha                           0.187585\n",
      "trainer/Alpha Loss                      0.00622598\n",
      "exploration/num steps total        263415\n",
      "exploration/num paths total           844\n",
      "evaluation/num steps total              2.19443e+06\n",
      "evaluation/num paths total           2598\n",
      "evaluation/path length Mean           827.8\n",
      "evaluation/path length Std            344.435\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            128\n",
      "evaluation/Rewards Mean                 5.13168\n",
      "evaluation/Rewards Std                  1.47263\n",
      "evaluation/Rewards Max                  7.22294\n",
      "evaluation/Rewards Min                 -0.521036\n",
      "evaluation/Returns Mean              4248.01\n",
      "evaluation/Returns Std               2005.18\n",
      "evaluation/Returns Max               5268.49\n",
      "evaluation/Returns Min                210.652\n",
      "evaluation/Estimation Bias Mean      1139.73\n",
      "evaluation/Estimation Bias Std        281.853\n",
      "evaluation/EB/Q_True Mean              60.2023\n",
      "evaluation/EB/Q_True Std              167.326\n",
      "evaluation/EB/Q_Pred Mean            1199.93\n",
      "evaluation/EB/Q_Pred Std              172.266\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4248.01\n",
      "evaluation/Actions Mean                 0.500364\n",
      "evaluation/Actions Std                  0.644963\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.37888\n",
      "time/backward_zf1 (s)                   2.57283\n",
      "time/backward_zf2 (s)                   2.52209\n",
      "time/data sampling (s)                  0.358555\n",
      "time/data storing (s)                   0.0174084\n",
      "time/evaluation sampling (s)            1.39936\n",
      "time/exploration sampling (s)           0.223176\n",
      "time/logging (s)                        0.00985051\n",
      "time/preback_alpha (s)                  1.19733\n",
      "time/preback_policy (s)                 1.37915\n",
      "time/preback_start (s)                  0.144003\n",
      "time/preback_zf (s)                     5.4909\n",
      "time/saving (s)                         0.00509881\n",
      "time/training (s)                       2.45519\n",
      "time/epoch (s)                         20.1538\n",
      "time/total (s)                       4573.91\n",
      "Epoch                                 258\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:27:12.834332 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 259 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 270000\n",
      "trainer/ZF1 Loss                       26.1783\n",
      "trainer/ZF2 Loss                       24.8312\n",
      "trainer/ZF Expert Reward               14.3305\n",
      "trainer/ZF Policy Reward               -3.85293\n",
      "trainer/ZF CHI2 Term                   63.3206\n",
      "trainer/Policy Loss                 -1083.41\n",
      "trainer/Bias Loss                     163.088\n",
      "trainer/Bias Value                     19.3255\n",
      "trainer/Policy Grad Norm              227.689\n",
      "trainer/Policy Param Norm              40.3987\n",
      "trainer/Zf1 Grad Norm                7732.18\n",
      "trainer/Zf1 Param Norm                129.969\n",
      "trainer/Zf2 Grad Norm                4417.44\n",
      "trainer/Zf2 Param Norm                127.654\n",
      "trainer/Z Expert Predictions Mean    1209.08\n",
      "trainer/Z Expert Predictions Std      158.159\n",
      "trainer/Z Expert Predictions Max     1439.18\n",
      "trainer/Z Expert Predictions Min      124.011\n",
      "trainer/Z Policy Predictions Mean    1077.96\n",
      "trainer/Z Policy Predictions Std      299.826\n",
      "trainer/Z Policy Predictions Max     1423.62\n",
      "trainer/Z Policy Predictions Min     -171.549\n",
      "trainer/Z Expert Targets Mean        1194.75\n",
      "trainer/Z Expert Targets Std          166.802\n",
      "trainer/Z Expert Targets Max         1425.23\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1081.82\n",
      "trainer/Z Policy Targets Std          294.783\n",
      "trainer/Z Policy Targets Max         1421.48\n",
      "trainer/Z Policy Targets Min         -171.375\n",
      "trainer/Log Pis Mean                   19.8308\n",
      "trainer/Log Pis Std                     4.17844\n",
      "trainer/Policy mu Mean                  1.26869\n",
      "trainer/Policy mu Std                   1.84591\n",
      "trainer/Policy log std Mean            -2.17047\n",
      "trainer/Policy log std Std              1.19758\n",
      "trainer/Alpha                           0.189833\n",
      "trainer/Alpha Loss                      0.0321277\n",
      "exploration/num steps total        265415\n",
      "exploration/num paths total           846\n",
      "evaluation/num steps total              2.19622e+06\n",
      "evaluation/num paths total           2608\n",
      "evaluation/path length Mean           179\n",
      "evaluation/path length Std             82.4197\n",
      "evaluation/path length Max            365\n",
      "evaluation/path length Min             98\n",
      "evaluation/Rewards Mean                 1.46214\n",
      "evaluation/Rewards Std                  0.94973\n",
      "evaluation/Rewards Max                  5.50639\n",
      "evaluation/Rewards Min                 -1.63514\n",
      "evaluation/Returns Mean               261.724\n",
      "evaluation/Returns Std                 75.7629\n",
      "evaluation/Returns Max                376.546\n",
      "evaluation/Returns Min                178.332\n",
      "evaluation/Estimation Bias Mean       739.416\n",
      "evaluation/Estimation Bias Std        395.379\n",
      "evaluation/EB/Q_True Mean              14.1994\n",
      "evaluation/EB/Q_True Std               38.3198\n",
      "evaluation/EB/Q_Pred Mean             753.616\n",
      "evaluation/EB/Q_Pred Std              398.538\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            261.724\n",
      "evaluation/Actions Mean                 0.40354\n",
      "evaluation/Actions Std                  0.644536\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.39219\n",
      "time/backward_zf1 (s)                   2.633\n",
      "time/backward_zf2 (s)                   2.54994\n",
      "time/data sampling (s)                  0.357746\n",
      "time/data storing (s)                   0.016386\n",
      "time/evaluation sampling (s)            0.573726\n",
      "time/exploration sampling (s)           0.220443\n",
      "time/logging (s)                        0.00344346\n",
      "time/preback_alpha (s)                  1.16802\n",
      "time/preback_policy (s)                 1.36732\n",
      "time/preback_start (s)                  0.142629\n",
      "time/preback_zf (s)                     5.54146\n",
      "time/saving (s)                         0.00490034\n",
      "time/training (s)                       2.42902\n",
      "time/epoch (s)                         19.4002\n",
      "time/total (s)                       4593.33\n",
      "Epoch                                 259\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:27:32.885466 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 260 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 271000\n",
      "trainer/ZF1 Loss                       32.3916\n",
      "trainer/ZF2 Loss                       43.9248\n",
      "trainer/ZF Expert Reward               17.239\n",
      "trainer/ZF Policy Reward                1.4566\n",
      "trainer/ZF CHI2 Term                   74.072\n",
      "trainer/Policy Loss                 -1097.46\n",
      "trainer/Bias Loss                     162.852\n",
      "trainer/Bias Value                     19.3136\n",
      "trainer/Policy Grad Norm              367.464\n",
      "trainer/Policy Param Norm              40.4363\n",
      "trainer/Zf1 Grad Norm                4419.28\n",
      "trainer/Zf1 Param Norm                130.104\n",
      "trainer/Zf2 Grad Norm                7971.52\n",
      "trainer/Zf2 Param Norm                127.797\n",
      "trainer/Z Expert Predictions Mean    1198.32\n",
      "trainer/Z Expert Predictions Std      133.691\n",
      "trainer/Z Expert Predictions Max     1410.9\n",
      "trainer/Z Expert Predictions Min      658.135\n",
      "trainer/Z Policy Predictions Mean    1095.29\n",
      "trainer/Z Policy Predictions Std      270.225\n",
      "trainer/Z Policy Predictions Max     1433.81\n",
      "trainer/Z Policy Predictions Min      -18.0429\n",
      "trainer/Z Expert Targets Mean        1181.08\n",
      "trainer/Z Expert Targets Std          140.433\n",
      "trainer/Z Expert Targets Max         1398.72\n",
      "trainer/Z Expert Targets Min          602.964\n",
      "trainer/Z Policy Targets Mean        1093.84\n",
      "trainer/Z Policy Targets Std          268.316\n",
      "trainer/Z Policy Targets Max         1424.44\n",
      "trainer/Z Policy Targets Min          -17.5256\n",
      "trainer/Log Pis Mean                   20.3348\n",
      "trainer/Log Pis Std                     4.33676\n",
      "trainer/Policy mu Mean                  1.21519\n",
      "trainer/Policy mu Std                   1.90334\n",
      "trainer/Policy log std Mean            -2.20524\n",
      "trainer/Policy log std Std              1.21547\n",
      "trainer/Alpha                           0.19386\n",
      "trainer/Alpha Loss                     -0.0648936\n",
      "exploration/num steps total        265415\n",
      "exploration/num paths total           846\n",
      "evaluation/num steps total              2.20622e+06\n",
      "evaluation/num paths total           2618\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21742\n",
      "evaluation/Rewards Std                  1.3272\n",
      "evaluation/Rewards Max                  7.23824\n",
      "evaluation/Rewards Min                  0.0944477\n",
      "evaluation/Returns Mean              5217.42\n",
      "evaluation/Returns Std                 24.5522\n",
      "evaluation/Returns Max               5248.27\n",
      "evaluation/Returns Min               5163.43\n",
      "evaluation/Estimation Bias Mean      1170.24\n",
      "evaluation/Estimation Bias Std        182.115\n",
      "evaluation/EB/Q_True Mean              49.3983\n",
      "evaluation/EB/Q_True Std              152.647\n",
      "evaluation/EB/Q_Pred Mean            1219.64\n",
      "evaluation/EB/Q_Pred Std              102.391\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5217.42\n",
      "evaluation/Actions Mean                 0.493556\n",
      "evaluation/Actions Std                  0.645809\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.32379\n",
      "time/backward_zf1 (s)                   2.58359\n",
      "time/backward_zf2 (s)                   2.47243\n",
      "time/data sampling (s)                  0.314927\n",
      "time/data storing (s)                   0.0165672\n",
      "time/evaluation sampling (s)            1.48108\n",
      "time/exploration sampling (s)           0.209258\n",
      "time/logging (s)                        0.0139081\n",
      "time/preback_alpha (s)                  1.14662\n",
      "time/preback_policy (s)                 1.33119\n",
      "time/preback_start (s)                  0.140299\n",
      "time/preback_zf (s)                     5.50283\n",
      "time/saving (s)                         0.0097543\n",
      "time/training (s)                       2.43919\n",
      "time/epoch (s)                         19.9854\n",
      "time/total (s)                       4613.33\n",
      "Epoch                                 260\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:27:52.948329 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 261 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 272000\n",
      "trainer/ZF1 Loss                       44.6429\n",
      "trainer/ZF2 Loss                       28.6889\n",
      "trainer/ZF Expert Reward               12.3532\n",
      "trainer/ZF Policy Reward                3.72468\n",
      "trainer/ZF CHI2 Term                   64.7697\n",
      "trainer/Policy Loss                 -1054.43\n",
      "trainer/Bias Loss                     188.052\n",
      "trainer/Bias Value                     19.3025\n",
      "trainer/Policy Grad Norm              343.745\n",
      "trainer/Policy Param Norm              40.4755\n",
      "trainer/Zf1 Grad Norm                5717.42\n",
      "trainer/Zf1 Param Norm                130.23\n",
      "trainer/Zf2 Grad Norm                5027.24\n",
      "trainer/Zf2 Param Norm                127.925\n",
      "trainer/Z Expert Predictions Mean    1193.1\n",
      "trainer/Z Expert Predictions Std      141.774\n",
      "trainer/Z Expert Predictions Max     1433.88\n",
      "trainer/Z Expert Predictions Min       59.6257\n",
      "trainer/Z Policy Predictions Mean    1047.85\n",
      "trainer/Z Policy Predictions Std      333.377\n",
      "trainer/Z Policy Predictions Max     1428.52\n",
      "trainer/Z Policy Predictions Min      -10.9285\n",
      "trainer/Z Expert Targets Mean        1180.75\n",
      "trainer/Z Expert Targets Std          147.77\n",
      "trainer/Z Expert Targets Max         1410.26\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1044.12\n",
      "trainer/Z Policy Targets Std          334.274\n",
      "trainer/Z Policy Targets Max         1421.01\n",
      "trainer/Z Policy Targets Min           20.4057\n",
      "trainer/Log Pis Mean                   19.672\n",
      "trainer/Log Pis Std                     4.15909\n",
      "trainer/Policy mu Mean                  1.20853\n",
      "trainer/Policy mu Std                   1.8207\n",
      "trainer/Policy log std Mean            -2.2238\n",
      "trainer/Policy log std Std              1.22791\n",
      "trainer/Alpha                           0.192971\n",
      "trainer/Alpha Loss                      0.0632978\n",
      "exploration/num steps total        265415\n",
      "exploration/num paths total           846\n",
      "evaluation/num steps total              2.21622e+06\n",
      "evaluation/num paths total           2628\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18406\n",
      "evaluation/Rewards Std                  1.30799\n",
      "evaluation/Rewards Max                  7.0734\n",
      "evaluation/Rewards Min                  0.127381\n",
      "evaluation/Returns Mean              5184.06\n",
      "evaluation/Returns Std                 18.8418\n",
      "evaluation/Returns Max               5218.88\n",
      "evaluation/Returns Min               5155.94\n",
      "evaluation/Estimation Bias Mean      1215.28\n",
      "evaluation/Estimation Bias Std        182.237\n",
      "evaluation/EB/Q_True Mean              49.1099\n",
      "evaluation/EB/Q_True Std              151.529\n",
      "evaluation/EB/Q_Pred Mean            1264.39\n",
      "evaluation/EB/Q_Pred Std              101.977\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5184.06\n",
      "evaluation/Actions Mean                 0.497345\n",
      "evaluation/Actions Std                  0.649641\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.31066\n",
      "time/backward_zf1 (s)                   2.53189\n",
      "time/backward_zf2 (s)                   2.42179\n",
      "time/data sampling (s)                  0.356992\n",
      "time/data storing (s)                   0.0174793\n",
      "time/evaluation sampling (s)            1.43078\n",
      "time/exploration sampling (s)           0.21667\n",
      "time/logging (s)                        0.0120796\n",
      "time/preback_alpha (s)                  1.17675\n",
      "time/preback_policy (s)                 1.3374\n",
      "time/preback_start (s)                  0.143069\n",
      "time/preback_zf (s)                     5.59253\n",
      "time/saving (s)                         0.00581047\n",
      "time/training (s)                       2.43092\n",
      "time/epoch (s)                         19.9848\n",
      "time/total (s)                       4633.34\n",
      "Epoch                                 261\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:28:13.302306 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 262 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 273000\n",
      "trainer/ZF1 Loss                       26.4616\n",
      "trainer/ZF2 Loss                       19.5237\n",
      "trainer/ZF Expert Reward               23.5533\n",
      "trainer/ZF Policy Reward                7.46478\n",
      "trainer/ZF CHI2 Term                   58.3735\n",
      "trainer/Policy Loss                 -1053.78\n",
      "trainer/Bias Loss                     155.816\n",
      "trainer/Bias Value                     19.2917\n",
      "trainer/Policy Grad Norm              281.667\n",
      "trainer/Policy Param Norm              40.5092\n",
      "trainer/Zf1 Grad Norm                3360.11\n",
      "trainer/Zf1 Param Norm                130.354\n",
      "trainer/Zf2 Grad Norm                3615.08\n",
      "trainer/Zf2 Param Norm                128.044\n",
      "trainer/Z Expert Predictions Mean    1184.48\n",
      "trainer/Z Expert Predictions Std      160.499\n",
      "trainer/Z Expert Predictions Max     1467.43\n",
      "trainer/Z Expert Predictions Min      261.011\n",
      "trainer/Z Policy Predictions Mean    1053.77\n",
      "trainer/Z Policy Predictions Std      319.009\n",
      "trainer/Z Policy Predictions Max     1401.18\n",
      "trainer/Z Policy Predictions Min      -35.2236\n",
      "trainer/Z Expert Targets Mean        1160.93\n",
      "trainer/Z Expert Targets Std          165.723\n",
      "trainer/Z Expert Targets Max         1438.3\n",
      "trainer/Z Expert Targets Min          202.117\n",
      "trainer/Z Policy Targets Mean        1046.3\n",
      "trainer/Z Policy Targets Std          316.249\n",
      "trainer/Z Policy Targets Max         1404.45\n",
      "trainer/Z Policy Targets Min          -40.4147\n",
      "trainer/Log Pis Mean                   19.4872\n",
      "trainer/Log Pis Std                     4.34976\n",
      "trainer/Policy mu Mean                  1.21586\n",
      "trainer/Policy mu Std                   1.81843\n",
      "trainer/Policy log std Mean            -2.26732\n",
      "trainer/Policy log std Std              1.20382\n",
      "trainer/Alpha                           0.193214\n",
      "trainer/Alpha Loss                      0.0990895\n",
      "exploration/num steps total        266415\n",
      "exploration/num paths total           847\n",
      "evaluation/num steps total              2.22387e+06\n",
      "evaluation/num paths total           2639\n",
      "evaluation/path length Mean           695.909\n",
      "evaluation/path length Std            402.432\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            132\n",
      "evaluation/Rewards Mean                 4.90743\n",
      "evaluation/Rewards Std                  1.60156\n",
      "evaluation/Rewards Max                  7.16559\n",
      "evaluation/Rewards Min                  0.124505\n",
      "evaluation/Returns Mean              3415.12\n",
      "evaluation/Returns Std               2358.45\n",
      "evaluation/Returns Max               5211.66\n",
      "evaluation/Returns Min                212.45\n",
      "evaluation/Estimation Bias Mean      1134.23\n",
      "evaluation/Estimation Bias Std        354.258\n",
      "evaluation/EB/Q_True Mean              63.8338\n",
      "evaluation/EB/Q_True Std              169.51\n",
      "evaluation/EB/Q_Pred Mean            1198.07\n",
      "evaluation/EB/Q_Pred Std              221.893\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3415.12\n",
      "evaluation/Actions Mean                 0.501406\n",
      "evaluation/Actions Std                  0.644113\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.32934\n",
      "time/backward_zf1 (s)                   2.62471\n",
      "time/backward_zf2 (s)                   2.46761\n",
      "time/data sampling (s)                  0.38682\n",
      "time/data storing (s)                   0.0176581\n",
      "time/evaluation sampling (s)            1.47021\n",
      "time/exploration sampling (s)           0.225857\n",
      "time/logging (s)                        0.0110011\n",
      "time/preback_alpha (s)                  1.17361\n",
      "time/preback_policy (s)                 1.32264\n",
      "time/preback_start (s)                  0.150688\n",
      "time/preback_zf (s)                     5.59591\n",
      "time/saving (s)                         0.00556244\n",
      "time/training (s)                       2.48612\n",
      "time/epoch (s)                         20.2677\n",
      "time/total (s)                       4653.63\n",
      "Epoch                                 262\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:28:34.493895 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 263 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 274000\n",
      "trainer/ZF1 Loss                      288.853\n",
      "trainer/ZF2 Loss                      301.078\n",
      "trainer/ZF Expert Reward               23.1247\n",
      "trainer/ZF Policy Reward               12.3485\n",
      "trainer/ZF CHI2 Term                  325.297\n",
      "trainer/Policy Loss                 -1083.08\n",
      "trainer/Bias Loss                     132.674\n",
      "trainer/Bias Value                     19.2787\n",
      "trainer/Policy Grad Norm              261.417\n",
      "trainer/Policy Param Norm              40.5434\n",
      "trainer/Zf1 Grad Norm                6476.76\n",
      "trainer/Zf1 Param Norm                130.485\n",
      "trainer/Zf2 Grad Norm                5478.22\n",
      "trainer/Zf2 Param Norm                128.164\n",
      "trainer/Z Expert Predictions Mean    1187.9\n",
      "trainer/Z Expert Predictions Std      160.319\n",
      "trainer/Z Expert Predictions Max     1453.95\n",
      "trainer/Z Expert Predictions Min      379.657\n",
      "trainer/Z Policy Predictions Mean    1075.95\n",
      "trainer/Z Policy Predictions Std      292.869\n",
      "trainer/Z Policy Predictions Max     1420.72\n",
      "trainer/Z Policy Predictions Min      -61.0584\n",
      "trainer/Z Expert Targets Mean        1164.78\n",
      "trainer/Z Expert Targets Std          161.764\n",
      "trainer/Z Expert Targets Max         1435.87\n",
      "trainer/Z Expert Targets Min          349.692\n",
      "trainer/Z Policy Targets Mean        1063.6\n",
      "trainer/Z Policy Targets Std          293.595\n",
      "trainer/Z Policy Targets Max         1407.69\n",
      "trainer/Z Policy Targets Min          -37.3839\n",
      "trainer/Log Pis Mean                   19.7533\n",
      "trainer/Log Pis Std                     4.31193\n",
      "trainer/Policy mu Mean                  1.21256\n",
      "trainer/Policy mu Std                   1.85165\n",
      "trainer/Policy log std Mean            -2.26168\n",
      "trainer/Policy log std Std              1.23505\n",
      "trainer/Alpha                           0.194379\n",
      "trainer/Alpha Loss                      0.0479464\n",
      "exploration/num steps total        269415\n",
      "exploration/num paths total           850\n",
      "evaluation/num steps total              2.23304e+06\n",
      "evaluation/num paths total           2649\n",
      "evaluation/path length Mean           916.9\n",
      "evaluation/path length Std            249.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            169\n",
      "evaluation/Rewards Mean                 5.1472\n",
      "evaluation/Rewards Std                  1.39516\n",
      "evaluation/Rewards Max                  7.13603\n",
      "evaluation/Rewards Min                  0.119786\n",
      "evaluation/Returns Mean              4719.47\n",
      "evaluation/Returns Std               1476.75\n",
      "evaluation/Returns Max               5250.8\n",
      "evaluation/Returns Min                290.043\n",
      "evaluation/Estimation Bias Mean      1143.3\n",
      "evaluation/Estimation Bias Std        242.394\n",
      "evaluation/EB/Q_True Mean              53.9165\n",
      "evaluation/EB/Q_True Std              158.8\n",
      "evaluation/EB/Q_Pred Mean            1197.21\n",
      "evaluation/EB/Q_Pred Std              165.523\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4719.47\n",
      "evaluation/Actions Mean                 0.50285\n",
      "evaluation/Actions Std                  0.645727\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.45628\n",
      "time/backward_zf1 (s)                   2.85001\n",
      "time/backward_zf2 (s)                   2.61812\n",
      "time/data sampling (s)                  0.418595\n",
      "time/data storing (s)                   0.018891\n",
      "time/evaluation sampling (s)            1.46381\n",
      "time/exploration sampling (s)           0.236938\n",
      "time/logging (s)                        0.0128325\n",
      "time/preback_alpha (s)                  1.20373\n",
      "time/preback_policy (s)                 1.411\n",
      "time/preback_start (s)                  0.154517\n",
      "time/preback_zf (s)                     5.72097\n",
      "time/saving (s)                         0.00526212\n",
      "time/training (s)                       2.53789\n",
      "time/epoch (s)                         21.1089\n",
      "time/total (s)                       4674.76\n",
      "Epoch                                 263\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:28:54.350599 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 264 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 275000\n",
      "trainer/ZF1 Loss                      299.399\n",
      "trainer/ZF2 Loss                      284.196\n",
      "trainer/ZF Expert Reward               22.6217\n",
      "trainer/ZF Policy Reward               10.1462\n",
      "trainer/ZF CHI2 Term                  323.861\n",
      "trainer/Policy Loss                 -1064.37\n",
      "trainer/Bias Loss                     141.494\n",
      "trainer/Bias Value                     19.2648\n",
      "trainer/Policy Grad Norm              289.51\n",
      "trainer/Policy Param Norm              40.5798\n",
      "trainer/Zf1 Grad Norm                4894.04\n",
      "trainer/Zf1 Param Norm                130.612\n",
      "trainer/Zf2 Grad Norm                6614.82\n",
      "trainer/Zf2 Param Norm                128.289\n",
      "trainer/Z Expert Predictions Mean    1185.66\n",
      "trainer/Z Expert Predictions Std      156.933\n",
      "trainer/Z Expert Predictions Max     1431.14\n",
      "trainer/Z Expert Predictions Min      162.647\n",
      "trainer/Z Policy Predictions Mean    1057.74\n",
      "trainer/Z Policy Predictions Std      298.054\n",
      "trainer/Z Policy Predictions Max     1421.81\n",
      "trainer/Z Policy Predictions Min     -386.436\n",
      "trainer/Z Expert Targets Mean        1163.04\n",
      "trainer/Z Expert Targets Std          159.557\n",
      "trainer/Z Expert Targets Max         1418.96\n",
      "trainer/Z Expert Targets Min          141.449\n",
      "trainer/Z Policy Targets Mean        1047.59\n",
      "trainer/Z Policy Targets Std          299.64\n",
      "trainer/Z Policy Targets Max         1423.21\n",
      "trainer/Z Policy Targets Min         -366.106\n",
      "trainer/Log Pis Mean                   19.7856\n",
      "trainer/Log Pis Std                     3.91299\n",
      "trainer/Policy mu Mean                  1.22787\n",
      "trainer/Policy mu Std                   1.85897\n",
      "trainer/Policy log std Mean            -2.20752\n",
      "trainer/Policy log std Std              1.21711\n",
      "trainer/Alpha                           0.19432\n",
      "trainer/Alpha Loss                      0.0416619\n",
      "exploration/num steps total        271415\n",
      "exploration/num paths total           852\n",
      "evaluation/num steps total              2.24304e+06\n",
      "evaluation/num paths total           2659\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18099\n",
      "evaluation/Rewards Std                  1.31049\n",
      "evaluation/Rewards Max                  7.13016\n",
      "evaluation/Rewards Min                  0.118862\n",
      "evaluation/Returns Mean              5180.99\n",
      "evaluation/Returns Std                 23.3238\n",
      "evaluation/Returns Max               5212.38\n",
      "evaluation/Returns Min               5122.97\n",
      "evaluation/Estimation Bias Mean      1189.24\n",
      "evaluation/Estimation Bias Std        178.149\n",
      "evaluation/EB/Q_True Mean              48.9678\n",
      "evaluation/EB/Q_True Std              151.252\n",
      "evaluation/EB/Q_Pred Mean            1238.21\n",
      "evaluation/EB/Q_Pred Std               92.3344\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5180.99\n",
      "evaluation/Actions Mean                 0.499943\n",
      "evaluation/Actions Std                  0.649184\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999988\n",
      "time/backward_policy (s)                2.21272\n",
      "time/backward_zf1 (s)                   2.45986\n",
      "time/backward_zf2 (s)                   2.34617\n",
      "time/data sampling (s)                  0.368139\n",
      "time/data storing (s)                   0.0175475\n",
      "time/evaluation sampling (s)            1.40322\n",
      "time/exploration sampling (s)           0.234736\n",
      "time/logging (s)                        0.013609\n",
      "time/preback_alpha (s)                  1.15377\n",
      "time/preback_policy (s)                 1.32365\n",
      "time/preback_start (s)                  0.145905\n",
      "time/preback_zf (s)                     5.57962\n",
      "time/saving (s)                         0.00735857\n",
      "time/training (s)                       2.51462\n",
      "time/epoch (s)                         19.7809\n",
      "time/total (s)                       4694.56\n",
      "Epoch                                 264\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:29:14.368443 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 265 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 276000\n",
      "trainer/ZF1 Loss                       31.0783\n",
      "trainer/ZF2 Loss                       35.0266\n",
      "trainer/ZF Expert Reward               20.6274\n",
      "trainer/ZF Policy Reward                6.93416\n",
      "trainer/ZF CHI2 Term                   66.2982\n",
      "trainer/Policy Loss                 -1048.38\n",
      "trainer/Bias Loss                     134.905\n",
      "trainer/Bias Value                     19.2499\n",
      "trainer/Policy Grad Norm              285.515\n",
      "trainer/Policy Param Norm              40.617\n",
      "trainer/Zf1 Grad Norm                3329.16\n",
      "trainer/Zf1 Param Norm                130.739\n",
      "trainer/Zf2 Grad Norm                4308.56\n",
      "trainer/Zf2 Param Norm                128.421\n",
      "trainer/Z Expert Predictions Mean    1199.32\n",
      "trainer/Z Expert Predictions Std      125.988\n",
      "trainer/Z Expert Predictions Max     1421.42\n",
      "trainer/Z Expert Predictions Min      506.012\n",
      "trainer/Z Policy Predictions Mean    1042.54\n",
      "trainer/Z Policy Predictions Std      314.405\n",
      "trainer/Z Policy Predictions Max     1395.4\n",
      "trainer/Z Policy Predictions Min     -308.976\n",
      "trainer/Z Expert Targets Mean        1178.69\n",
      "trainer/Z Expert Targets Std          130.155\n",
      "trainer/Z Expert Targets Max         1410.87\n",
      "trainer/Z Expert Targets Min          475.906\n",
      "trainer/Z Policy Targets Mean        1035.61\n",
      "trainer/Z Policy Targets Std          309.331\n",
      "trainer/Z Policy Targets Max         1371.09\n",
      "trainer/Z Policy Targets Min         -313.82\n",
      "trainer/Log Pis Mean                   19.75\n",
      "trainer/Log Pis Std                     4.52854\n",
      "trainer/Policy mu Mean                  1.13987\n",
      "trainer/Policy mu Std                   1.86723\n",
      "trainer/Policy log std Mean            -2.25736\n",
      "trainer/Policy log std Std              1.20315\n",
      "trainer/Alpha                           0.196268\n",
      "trainer/Alpha Loss                      0.0490671\n",
      "exploration/num steps total        272415\n",
      "exploration/num paths total           853\n",
      "evaluation/num steps total              2.25218e+06\n",
      "evaluation/num paths total           2669\n",
      "evaluation/path length Mean           914\n",
      "evaluation/path length Std            258\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            140\n",
      "evaluation/Rewards Mean                 5.14478\n",
      "evaluation/Rewards Std                  1.38937\n",
      "evaluation/Rewards Max                  7.19495\n",
      "evaluation/Rewards Min                  0.114207\n",
      "evaluation/Returns Mean              4702.33\n",
      "evaluation/Returns Std               1483.84\n",
      "evaluation/Returns Max               5228.52\n",
      "evaluation/Returns Min                251.047\n",
      "evaluation/Estimation Bias Mean      1156.87\n",
      "evaluation/Estimation Bias Std        216.913\n",
      "evaluation/EB/Q_True Mean              53.6916\n",
      "evaluation/EB/Q_True Std              157.764\n",
      "evaluation/EB/Q_Pred Mean            1210.56\n",
      "evaluation/EB/Q_Pred Std              118.72\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4702.33\n",
      "evaluation/Actions Mean                 0.498911\n",
      "evaluation/Actions Std                  0.648672\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.33771\n",
      "time/backward_zf1 (s)                   2.59682\n",
      "time/backward_zf2 (s)                   2.50385\n",
      "time/data sampling (s)                  0.36125\n",
      "time/data storing (s)                   0.0169486\n",
      "time/evaluation sampling (s)            1.45251\n",
      "time/exploration sampling (s)           0.216218\n",
      "time/logging (s)                        0.0136201\n",
      "time/preback_alpha (s)                  1.15527\n",
      "time/preback_policy (s)                 1.34647\n",
      "time/preback_start (s)                  0.141113\n",
      "time/preback_zf (s)                     5.42702\n",
      "time/saving (s)                         0.00602812\n",
      "time/training (s)                       2.36451\n",
      "time/epoch (s)                         19.9393\n",
      "time/total (s)                       4714.52\n",
      "Epoch                                 265\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:29:34.479224 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 266 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 277000\n",
      "trainer/ZF1 Loss                      286.726\n",
      "trainer/ZF2 Loss                      312.237\n",
      "trainer/ZF Expert Reward                9.20423\n",
      "trainer/ZF Policy Reward               -0.581011\n",
      "trainer/ZF CHI2 Term                  329.212\n",
      "trainer/Policy Loss                 -1052.16\n",
      "trainer/Bias Loss                     156.38\n",
      "trainer/Bias Value                     19.2358\n",
      "trainer/Policy Grad Norm              278.643\n",
      "trainer/Policy Param Norm              40.6565\n",
      "trainer/Zf1 Grad Norm                7208.4\n",
      "trainer/Zf1 Param Norm                130.859\n",
      "trainer/Zf2 Grad Norm                8319.32\n",
      "trainer/Zf2 Param Norm                128.542\n",
      "trainer/Z Expert Predictions Mean    1178.03\n",
      "trainer/Z Expert Predictions Std      121.824\n",
      "trainer/Z Expert Predictions Max     1429.52\n",
      "trainer/Z Expert Predictions Min      762.97\n",
      "trainer/Z Policy Predictions Mean    1040.33\n",
      "trainer/Z Policy Predictions Std      292.978\n",
      "trainer/Z Policy Predictions Max     1397.28\n",
      "trainer/Z Policy Predictions Min     -231.327\n",
      "trainer/Z Expert Targets Mean        1168.83\n",
      "trainer/Z Expert Targets Std          124.075\n",
      "trainer/Z Expert Targets Max         1423.01\n",
      "trainer/Z Expert Targets Min          739.561\n",
      "trainer/Z Policy Targets Mean        1040.91\n",
      "trainer/Z Policy Targets Std          296.748\n",
      "trainer/Z Policy Targets Max         1417.54\n",
      "trainer/Z Policy Targets Min         -207.786\n",
      "trainer/Log Pis Mean                   20.1466\n",
      "trainer/Log Pis Std                     4.4855\n",
      "trainer/Policy mu Mean                  1.28489\n",
      "trainer/Policy mu Std                   1.91117\n",
      "trainer/Policy log std Mean            -2.1509\n",
      "trainer/Policy log std Std              1.18185\n",
      "trainer/Alpha                           0.197017\n",
      "trainer/Alpha Loss                     -0.0288891\n",
      "exploration/num steps total        273561\n",
      "exploration/num paths total           855\n",
      "evaluation/num steps total              2.26218e+06\n",
      "evaluation/num paths total           2679\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16655\n",
      "evaluation/Rewards Std                  1.30569\n",
      "evaluation/Rewards Max                  7.12613\n",
      "evaluation/Rewards Min                  0.128196\n",
      "evaluation/Returns Mean              5166.55\n",
      "evaluation/Returns Std                 14.3567\n",
      "evaluation/Returns Max               5196.96\n",
      "evaluation/Returns Min               5145.31\n",
      "evaluation/Estimation Bias Mean      1185.76\n",
      "evaluation/Estimation Bias Std        189.939\n",
      "evaluation/EB/Q_True Mean              49.0863\n",
      "evaluation/EB/Q_True Std              151.523\n",
      "evaluation/EB/Q_Pred Mean            1234.84\n",
      "evaluation/EB/Q_Pred Std              109.489\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5166.55\n",
      "evaluation/Actions Mean                 0.500265\n",
      "evaluation/Actions Std                  0.646672\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.32727\n",
      "time/backward_zf1 (s)                   2.51628\n",
      "time/backward_zf2 (s)                   2.38974\n",
      "time/data sampling (s)                  0.375798\n",
      "time/data storing (s)                   0.0178461\n",
      "time/evaluation sampling (s)            1.44575\n",
      "time/exploration sampling (s)           0.22425\n",
      "time/logging (s)                        0.0120979\n",
      "time/preback_alpha (s)                  1.13694\n",
      "time/preback_policy (s)                 1.30099\n",
      "time/preback_start (s)                  0.148595\n",
      "time/preback_zf (s)                     5.53877\n",
      "time/saving (s)                         0.00562234\n",
      "time/training (s)                       2.59205\n",
      "time/epoch (s)                         20.032\n",
      "time/total (s)                       4734.57\n",
      "Epoch                                 266\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:29:55.151764 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 267 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 278000\n",
      "trainer/ZF1 Loss                      391.767\n",
      "trainer/ZF2 Loss                      423.88\n",
      "trainer/ZF Expert Reward               27.3671\n",
      "trainer/ZF Policy Reward               14.484\n",
      "trainer/ZF CHI2 Term                  440.808\n",
      "trainer/Policy Loss                 -1082.43\n",
      "trainer/Bias Loss                    1683.85\n",
      "trainer/Bias Value                     19.2243\n",
      "trainer/Policy Grad Norm              279.833\n",
      "trainer/Policy Param Norm              40.6927\n",
      "trainer/Zf1 Grad Norm                9079.99\n",
      "trainer/Zf1 Param Norm                130.992\n",
      "trainer/Zf2 Grad Norm                9737.98\n",
      "trainer/Zf2 Param Norm                128.666\n",
      "trainer/Z Expert Predictions Mean    1188.59\n",
      "trainer/Z Expert Predictions Std      132.596\n",
      "trainer/Z Expert Predictions Max     1444.77\n",
      "trainer/Z Expert Predictions Min      707.449\n",
      "trainer/Z Policy Predictions Mean    1083.62\n",
      "trainer/Z Policy Predictions Std      273.081\n",
      "trainer/Z Policy Predictions Max     1394.5\n",
      "trainer/Z Policy Predictions Min     -334.145\n",
      "trainer/Z Expert Targets Mean        1161.22\n",
      "trainer/Z Expert Targets Std          152.799\n",
      "trainer/Z Expert Targets Max         1429.86\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1069.13\n",
      "trainer/Z Policy Targets Std          277.012\n",
      "trainer/Z Policy Targets Max         1399.68\n",
      "trainer/Z Policy Targets Min         -296.458\n",
      "trainer/Log Pis Mean                   20.3039\n",
      "trainer/Log Pis Std                     4.35373\n",
      "trainer/Policy mu Mean                  1.18503\n",
      "trainer/Policy mu Std                   1.87474\n",
      "trainer/Policy log std Mean            -2.29595\n",
      "trainer/Policy log std Std              1.21997\n",
      "trainer/Alpha                           0.196999\n",
      "trainer/Alpha Loss                     -0.059867\n",
      "exploration/num steps total        273561\n",
      "exploration/num paths total           855\n",
      "evaluation/num steps total              2.27166e+06\n",
      "evaluation/num paths total           2689\n",
      "evaluation/path length Mean           948.4\n",
      "evaluation/path length Std            154.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            484\n",
      "evaluation/Rewards Mean                 5.11733\n",
      "evaluation/Rewards Std                  1.32038\n",
      "evaluation/Rewards Max                  7.16638\n",
      "evaluation/Rewards Min                  0.103675\n",
      "evaluation/Returns Mean              4853.27\n",
      "evaluation/Returns Std                868.109\n",
      "evaluation/Returns Max               5180.32\n",
      "evaluation/Returns Min               2249.69\n",
      "evaluation/Estimation Bias Mean      1046.33\n",
      "evaluation/Estimation Bias Std        227.152\n",
      "evaluation/EB/Q_True Mean              51.3468\n",
      "evaluation/EB/Q_True Std              154.129\n",
      "evaluation/EB/Q_Pred Mean            1097.67\n",
      "evaluation/EB/Q_Pred Std              156.15\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4853.27\n",
      "evaluation/Actions Mean                 0.493004\n",
      "evaluation/Actions Std                  0.655881\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.34356\n",
      "time/backward_zf1 (s)                   2.64179\n",
      "time/backward_zf2 (s)                   2.53353\n",
      "time/data sampling (s)                  0.380597\n",
      "time/data storing (s)                   0.0201262\n",
      "time/evaluation sampling (s)            1.48247\n",
      "time/exploration sampling (s)           0.232412\n",
      "time/logging (s)                        0.0122663\n",
      "time/preback_alpha (s)                  1.17223\n",
      "time/preback_policy (s)                 1.37547\n",
      "time/preback_start (s)                  0.151975\n",
      "time/preback_zf (s)                     5.64006\n",
      "time/saving (s)                         0.00863724\n",
      "time/training (s)                       2.58769\n",
      "time/epoch (s)                         20.5828\n",
      "time/total (s)                       4755.18\n",
      "Epoch                                 267\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:30:15.582257 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 268 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 279000\n",
      "trainer/ZF1 Loss                       31.8236\n",
      "trainer/ZF2 Loss                       27.5963\n",
      "trainer/ZF Expert Reward               19.6997\n",
      "trainer/ZF Policy Reward                3.61299\n",
      "trainer/ZF CHI2 Term                   64.894\n",
      "trainer/Policy Loss                 -1042.68\n",
      "trainer/Bias Loss                     154.494\n",
      "trainer/Bias Value                     19.2097\n",
      "trainer/Policy Grad Norm              347.746\n",
      "trainer/Policy Param Norm              40.7273\n",
      "trainer/Zf1 Grad Norm                5099.96\n",
      "trainer/Zf1 Param Norm                131.126\n",
      "trainer/Zf2 Grad Norm                4652.49\n",
      "trainer/Zf2 Param Norm                128.803\n",
      "trainer/Z Expert Predictions Mean    1178.76\n",
      "trainer/Z Expert Predictions Std      145.657\n",
      "trainer/Z Expert Predictions Max     1440.75\n",
      "trainer/Z Expert Predictions Min      418.921\n",
      "trainer/Z Policy Predictions Mean    1040.49\n",
      "trainer/Z Policy Predictions Std      312.606\n",
      "trainer/Z Policy Predictions Max     1387.74\n",
      "trainer/Z Policy Predictions Min      -63.0707\n",
      "trainer/Z Expert Targets Mean        1159.06\n",
      "trainer/Z Expert Targets Std          150.301\n",
      "trainer/Z Expert Targets Max         1422.19\n",
      "trainer/Z Expert Targets Min          389.216\n",
      "trainer/Z Policy Targets Mean        1036.87\n",
      "trainer/Z Policy Targets Std          310.975\n",
      "trainer/Z Policy Targets Max         1380.15\n",
      "trainer/Z Policy Targets Min          -76.2346\n",
      "trainer/Log Pis Mean                   19.2902\n",
      "trainer/Log Pis Std                     4.26093\n",
      "trainer/Policy mu Mean                  1.18448\n",
      "trainer/Policy mu Std                   1.79906\n",
      "trainer/Policy log std Mean            -2.23316\n",
      "trainer/Policy log std Std              1.22585\n",
      "trainer/Alpha                           0.196701\n",
      "trainer/Alpha Loss                      0.139637\n",
      "exploration/num steps total        273561\n",
      "exploration/num paths total           855\n",
      "evaluation/num steps total              2.28166e+06\n",
      "evaluation/num paths total           2699\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15061\n",
      "evaluation/Rewards Std                  1.28862\n",
      "evaluation/Rewards Max                  7.12176\n",
      "evaluation/Rewards Min                  0.146261\n",
      "evaluation/Returns Mean              5150.61\n",
      "evaluation/Returns Std                 15.5674\n",
      "evaluation/Returns Max               5180.16\n",
      "evaluation/Returns Min               5124.79\n",
      "evaluation/Estimation Bias Mean      1086.35\n",
      "evaluation/Estimation Bias Std        204.407\n",
      "evaluation/EB/Q_True Mean              48.7473\n",
      "evaluation/EB/Q_True Std              150.419\n",
      "evaluation/EB/Q_Pred Mean            1135.09\n",
      "evaluation/EB/Q_Pred Std              122.223\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5150.61\n",
      "evaluation/Actions Mean                 0.489446\n",
      "evaluation/Actions Std                  0.654543\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.35754\n",
      "time/backward_zf1 (s)                   2.65166\n",
      "time/backward_zf2 (s)                   2.54323\n",
      "time/data sampling (s)                  0.383372\n",
      "time/data storing (s)                   0.0179337\n",
      "time/evaluation sampling (s)            1.4119\n",
      "time/exploration sampling (s)           0.220116\n",
      "time/logging (s)                        0.0120278\n",
      "time/preback_alpha (s)                  1.18417\n",
      "time/preback_policy (s)                 1.34722\n",
      "time/preback_start (s)                  0.148055\n",
      "time/preback_zf (s)                     5.62871\n",
      "time/saving (s)                         0.00557591\n",
      "time/training (s)                       2.43456\n",
      "time/epoch (s)                         20.3461\n",
      "time/total (s)                       4775.55\n",
      "Epoch                                 268\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:30:36.467701 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 269 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 280000\n",
      "trainer/ZF1 Loss                      417.784\n",
      "trainer/ZF2 Loss                      430.53\n",
      "trainer/ZF Expert Reward               10.4607\n",
      "trainer/ZF Policy Reward                3.54623\n",
      "trainer/ZF CHI2 Term                  451.163\n",
      "trainer/Policy Loss                 -1057.05\n",
      "trainer/Bias Loss                     824.562\n",
      "trainer/Bias Value                     19.1972\n",
      "trainer/Policy Grad Norm              445.924\n",
      "trainer/Policy Param Norm              40.7641\n",
      "trainer/Zf1 Grad Norm               12845.8\n",
      "trainer/Zf1 Param Norm                131.261\n",
      "trainer/Zf2 Grad Norm               12555\n",
      "trainer/Zf2 Param Norm                128.945\n",
      "trainer/Z Expert Predictions Mean    1173.2\n",
      "trainer/Z Expert Predictions Std      136.996\n",
      "trainer/Z Expert Predictions Max     1435.51\n",
      "trainer/Z Expert Predictions Min      354.153\n",
      "trainer/Z Policy Predictions Mean    1049.83\n",
      "trainer/Z Policy Predictions Std      292.446\n",
      "trainer/Z Policy Predictions Max     1397.92\n",
      "trainer/Z Policy Predictions Min     -115.407\n",
      "trainer/Z Expert Targets Mean        1162.74\n",
      "trainer/Z Expert Targets Std          138.663\n",
      "trainer/Z Expert Targets Max         1427.8\n",
      "trainer/Z Expert Targets Min          340.783\n",
      "trainer/Z Policy Targets Mean        1046.28\n",
      "trainer/Z Policy Targets Std          298.345\n",
      "trainer/Z Policy Targets Max         1397.54\n",
      "trainer/Z Policy Targets Min         -116.95\n",
      "trainer/Log Pis Mean                   20.2941\n",
      "trainer/Log Pis Std                     4.33839\n",
      "trainer/Policy mu Mean                  1.26993\n",
      "trainer/Policy mu Std                   1.84029\n",
      "trainer/Policy log std Mean            -2.25031\n",
      "trainer/Policy log std Std              1.21559\n",
      "trainer/Alpha                           0.199314\n",
      "trainer/Alpha Loss                     -0.05863\n",
      "exploration/num steps total        275561\n",
      "exploration/num paths total           857\n",
      "evaluation/num steps total              2.29166e+06\n",
      "evaluation/num paths total           2709\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17509\n",
      "evaluation/Rewards Std                  1.29939\n",
      "evaluation/Rewards Max                  7.16801\n",
      "evaluation/Rewards Min                  0.130865\n",
      "evaluation/Returns Mean              5175.09\n",
      "evaluation/Returns Std                 27.127\n",
      "evaluation/Returns Max               5215.77\n",
      "evaluation/Returns Min               5129.17\n",
      "evaluation/Estimation Bias Mean      1112.82\n",
      "evaluation/Estimation Bias Std        206.222\n",
      "evaluation/EB/Q_True Mean              49.0147\n",
      "evaluation/EB/Q_True Std              151.318\n",
      "evaluation/EB/Q_Pred Mean            1161.83\n",
      "evaluation/EB/Q_Pred Std              136.454\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5175.09\n",
      "evaluation/Actions Mean                 0.498618\n",
      "evaluation/Actions Std                  0.649932\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.38094\n",
      "time/backward_zf1 (s)                   2.74929\n",
      "time/backward_zf2 (s)                   2.58346\n",
      "time/data sampling (s)                  0.378058\n",
      "time/data storing (s)                   0.0163131\n",
      "time/evaluation sampling (s)            1.45467\n",
      "time/exploration sampling (s)           0.228367\n",
      "time/logging (s)                        0.0121665\n",
      "time/preback_alpha (s)                  1.18174\n",
      "time/preback_policy (s)                 1.38779\n",
      "time/preback_start (s)                  0.150434\n",
      "time/preback_zf (s)                     5.70234\n",
      "time/saving (s)                         0.00559555\n",
      "time/training (s)                       2.56908\n",
      "time/epoch (s)                         20.8002\n",
      "time/total (s)                       4796.37\n",
      "Epoch                                 269\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:30:57.267473 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 270 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 281000\n",
      "trainer/ZF1 Loss                       26.8078\n",
      "trainer/ZF2 Loss                       31.604\n",
      "trainer/ZF Expert Reward               12.9066\n",
      "trainer/ZF Policy Reward               -2.41016\n",
      "trainer/ZF CHI2 Term                   64.3632\n",
      "trainer/Policy Loss                 -1048.58\n",
      "trainer/Bias Loss                     218.201\n",
      "trainer/Bias Value                     19.1833\n",
      "trainer/Policy Grad Norm              240.413\n",
      "trainer/Policy Param Norm              40.8025\n",
      "trainer/Zf1 Grad Norm                5414.58\n",
      "trainer/Zf1 Param Norm                131.397\n",
      "trainer/Zf2 Grad Norm                7498.9\n",
      "trainer/Zf2 Param Norm                129.09\n",
      "trainer/Z Expert Predictions Mean    1188.69\n",
      "trainer/Z Expert Predictions Std      129.554\n",
      "trainer/Z Expert Predictions Max     1433.87\n",
      "trainer/Z Expert Predictions Min      780.559\n",
      "trainer/Z Policy Predictions Mean    1042.29\n",
      "trainer/Z Policy Predictions Std      298.459\n",
      "trainer/Z Policy Predictions Max     1379.26\n",
      "trainer/Z Policy Predictions Min     -113.041\n",
      "trainer/Z Expert Targets Mean        1175.79\n",
      "trainer/Z Expert Targets Std          132.666\n",
      "trainer/Z Expert Targets Max         1436.38\n",
      "trainer/Z Expert Targets Min          770.236\n",
      "trainer/Z Policy Targets Mean        1044.7\n",
      "trainer/Z Policy Targets Std          291.93\n",
      "trainer/Z Policy Targets Max         1398.27\n",
      "trainer/Z Policy Targets Min         -122.368\n",
      "trainer/Log Pis Mean                   20.041\n",
      "trainer/Log Pis Std                     4.46451\n",
      "trainer/Policy mu Mean                  1.25189\n",
      "trainer/Policy mu Std                   1.88908\n",
      "trainer/Policy log std Mean            -2.18865\n",
      "trainer/Policy log std Std              1.2404\n",
      "trainer/Alpha                           0.201852\n",
      "trainer/Alpha Loss                     -0.00826707\n",
      "exploration/num steps total        275561\n",
      "exploration/num paths total           857\n",
      "evaluation/num steps total              2.30166e+06\n",
      "evaluation/num paths total           2719\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20041\n",
      "evaluation/Rewards Std                  1.32265\n",
      "evaluation/Rewards Max                  7.20744\n",
      "evaluation/Rewards Min                  0.120392\n",
      "evaluation/Returns Mean              5200.41\n",
      "evaluation/Returns Std                 19.3536\n",
      "evaluation/Returns Max               5227.92\n",
      "evaluation/Returns Min               5166.72\n",
      "evaluation/Estimation Bias Mean      1136.28\n",
      "evaluation/Estimation Bias Std        183.102\n",
      "evaluation/EB/Q_True Mean              49.4446\n",
      "evaluation/EB/Q_True Std              152.643\n",
      "evaluation/EB/Q_Pred Mean            1185.72\n",
      "evaluation/EB/Q_Pred Std               93.0818\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5200.41\n",
      "evaluation/Actions Mean                 0.502198\n",
      "evaluation/Actions Std                  0.646693\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                2.40804\n",
      "time/backward_zf1 (s)                   2.72373\n",
      "time/backward_zf2 (s)                   2.56604\n",
      "time/data sampling (s)                  0.376551\n",
      "time/data storing (s)                   0.0182684\n",
      "time/evaluation sampling (s)            1.47777\n",
      "time/exploration sampling (s)           0.226552\n",
      "time/logging (s)                        0.0121843\n",
      "time/preback_alpha (s)                  1.17656\n",
      "time/preback_policy (s)                 1.39837\n",
      "time/preback_start (s)                  0.149175\n",
      "time/preback_zf (s)                     5.63906\n",
      "time/saving (s)                         0.00519853\n",
      "time/training (s)                       2.54056\n",
      "time/epoch (s)                         20.7181\n",
      "time/total (s)                       4817.11\n",
      "Epoch                                 270\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:31:17.451705 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 271 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 282000\n",
      "trainer/ZF1 Loss                       40.0818\n",
      "trainer/ZF2 Loss                       41.8531\n",
      "trainer/ZF Expert Reward               16.7133\n",
      "trainer/ZF Policy Reward               -0.629348\n",
      "trainer/ZF CHI2 Term                   77.8439\n",
      "trainer/Policy Loss                 -1053.34\n",
      "trainer/Bias Loss                     211.784\n",
      "trainer/Bias Value                     19.1716\n",
      "trainer/Policy Grad Norm              470.354\n",
      "trainer/Policy Param Norm              40.8375\n",
      "trainer/Zf1 Grad Norm                5570.55\n",
      "trainer/Zf1 Param Norm                131.55\n",
      "trainer/Zf2 Grad Norm                7018.28\n",
      "trainer/Zf2 Param Norm                129.228\n",
      "trainer/Z Expert Predictions Mean    1163.08\n",
      "trainer/Z Expert Predictions Std      142.29\n",
      "trainer/Z Expert Predictions Max     1418.89\n",
      "trainer/Z Expert Predictions Min      465.089\n",
      "trainer/Z Policy Predictions Mean    1048.08\n",
      "trainer/Z Policy Predictions Std      306.673\n",
      "trainer/Z Policy Predictions Max     1392.99\n",
      "trainer/Z Policy Predictions Min      -93.2337\n",
      "trainer/Z Expert Targets Mean        1146.37\n",
      "trainer/Z Expert Targets Std          145.646\n",
      "trainer/Z Expert Targets Max         1402.55\n",
      "trainer/Z Expert Targets Min          504.611\n",
      "trainer/Z Policy Targets Mean        1048.7\n",
      "trainer/Z Policy Targets Std          301.829\n",
      "trainer/Z Policy Targets Max         1385.75\n",
      "trainer/Z Policy Targets Min          -95.6784\n",
      "trainer/Log Pis Mean                   19.7311\n",
      "trainer/Log Pis Std                     3.91245\n",
      "trainer/Policy mu Mean                  1.25395\n",
      "trainer/Policy mu Std                   1.83462\n",
      "trainer/Policy log std Mean            -2.20619\n",
      "trainer/Policy log std Std              1.25599\n",
      "trainer/Alpha                           0.201318\n",
      "trainer/Alpha Loss                      0.0541385\n",
      "exploration/num steps total        275561\n",
      "exploration/num paths total           857\n",
      "evaluation/num steps total              2.31166e+06\n",
      "evaluation/num paths total           2729\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21536\n",
      "evaluation/Rewards Std                  1.33686\n",
      "evaluation/Rewards Max                  7.21544\n",
      "evaluation/Rewards Min                  0.0992413\n",
      "evaluation/Returns Mean              5215.36\n",
      "evaluation/Returns Std                 20.7759\n",
      "evaluation/Returns Max               5244.4\n",
      "evaluation/Returns Min               5167.3\n",
      "evaluation/Estimation Bias Mean      1151.72\n",
      "evaluation/Estimation Bias Std        176.737\n",
      "evaluation/EB/Q_True Mean              49.4225\n",
      "evaluation/EB/Q_True Std              152.732\n",
      "evaluation/EB/Q_Pred Mean            1201.14\n",
      "evaluation/EB/Q_Pred Std               91.0062\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5215.36\n",
      "evaluation/Actions Mean                 0.50558\n",
      "evaluation/Actions Std                  0.649966\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.3015\n",
      "time/backward_zf1 (s)                   2.62309\n",
      "time/backward_zf2 (s)                   2.42672\n",
      "time/data sampling (s)                  0.34585\n",
      "time/data storing (s)                   0.0183732\n",
      "time/evaluation sampling (s)            1.42101\n",
      "time/exploration sampling (s)           0.225226\n",
      "time/logging (s)                        0.012134\n",
      "time/preback_alpha (s)                  1.1544\n",
      "time/preback_policy (s)                 1.30449\n",
      "time/preback_start (s)                  0.148285\n",
      "time/preback_zf (s)                     5.60536\n",
      "time/saving (s)                         0.00679871\n",
      "time/training (s)                       2.51134\n",
      "time/epoch (s)                         20.1046\n",
      "time/total (s)                       4837.24\n",
      "Epoch                                 271\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:31:37.376036 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 272 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 283000\n",
      "trainer/ZF1 Loss                       39.8699\n",
      "trainer/ZF2 Loss                       26.2813\n",
      "trainer/ZF Expert Reward               17.4206\n",
      "trainer/ZF Policy Reward                5.08115\n",
      "trainer/ZF CHI2 Term                   65.1341\n",
      "trainer/Policy Loss                 -1020.37\n",
      "trainer/Bias Loss                     137.621\n",
      "trainer/Bias Value                     19.1598\n",
      "trainer/Policy Grad Norm              329.738\n",
      "trainer/Policy Param Norm              40.8742\n",
      "trainer/Zf1 Grad Norm                5835.68\n",
      "trainer/Zf1 Param Norm                131.708\n",
      "trainer/Zf2 Grad Norm                4663.77\n",
      "trainer/Zf2 Param Norm                129.375\n",
      "trainer/Z Expert Predictions Mean    1154.56\n",
      "trainer/Z Expert Predictions Std      153.885\n",
      "trainer/Z Expert Predictions Max     1421.8\n",
      "trainer/Z Expert Predictions Min        3.87978\n",
      "trainer/Z Policy Predictions Mean    1018.86\n",
      "trainer/Z Policy Predictions Std      308.409\n",
      "trainer/Z Policy Predictions Max     1391.45\n",
      "trainer/Z Policy Predictions Min     -143.013\n",
      "trainer/Z Expert Targets Mean        1137.14\n",
      "trainer/Z Expert Targets Std          157.578\n",
      "trainer/Z Expert Targets Max         1420.59\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1013.77\n",
      "trainer/Z Policy Targets Std          309.346\n",
      "trainer/Z Policy Targets Max         1401.42\n",
      "trainer/Z Policy Targets Min         -151.762\n",
      "trainer/Log Pis Mean                   19.9182\n",
      "trainer/Log Pis Std                     4.53176\n",
      "trainer/Policy mu Mean                  1.2318\n",
      "trainer/Policy mu Std                   1.85222\n",
      "trainer/Policy log std Mean            -2.2422\n",
      "trainer/Policy log std Std              1.23229\n",
      "trainer/Alpha                           0.201274\n",
      "trainer/Alpha Loss                      0.0164608\n",
      "exploration/num steps total        276561\n",
      "exploration/num paths total           858\n",
      "evaluation/num steps total              2.32166e+06\n",
      "evaluation/num paths total           2739\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14553\n",
      "evaluation/Rewards Std                  1.29428\n",
      "evaluation/Rewards Max                  7.11841\n",
      "evaluation/Rewards Min                  0.113671\n",
      "evaluation/Returns Mean              5145.53\n",
      "evaluation/Returns Std                 22.0129\n",
      "evaluation/Returns Max               5177.63\n",
      "evaluation/Returns Min               5112.75\n",
      "evaluation/Estimation Bias Mean      1104.09\n",
      "evaluation/Estimation Bias Std        218.989\n",
      "evaluation/EB/Q_True Mean              48.5795\n",
      "evaluation/EB/Q_True Std              150.11\n",
      "evaluation/EB/Q_Pred Mean            1152.67\n",
      "evaluation/EB/Q_Pred Std              130.405\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5145.53\n",
      "evaluation/Actions Mean                 0.496397\n",
      "evaluation/Actions Std                  0.653053\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.25873\n",
      "time/backward_zf1 (s)                   2.5305\n",
      "time/backward_zf2 (s)                   2.40127\n",
      "time/data sampling (s)                  0.339595\n",
      "time/data storing (s)                   0.0175756\n",
      "time/evaluation sampling (s)            1.43942\n",
      "time/exploration sampling (s)           0.223877\n",
      "time/logging (s)                        0.0131648\n",
      "time/preback_alpha (s)                  1.12474\n",
      "time/preback_policy (s)                 1.28614\n",
      "time/preback_start (s)                  0.145747\n",
      "time/preback_zf (s)                     5.51955\n",
      "time/saving (s)                         0.00525643\n",
      "time/training (s)                       2.53905\n",
      "time/epoch (s)                         19.8446\n",
      "time/total (s)                       4857.1\n",
      "Epoch                                 272\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:31:57.972261 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 273 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 284000\n",
      "trainer/ZF1 Loss                      285.435\n",
      "trainer/ZF2 Loss                      277.561\n",
      "trainer/ZF Expert Reward               17.4215\n",
      "trainer/ZF Policy Reward               10.964\n",
      "trainer/ZF CHI2 Term                  307.059\n",
      "trainer/Policy Loss                 -1023.99\n",
      "trainer/Bias Loss                     177.271\n",
      "trainer/Bias Value                     19.1459\n",
      "trainer/Policy Grad Norm              326.877\n",
      "trainer/Policy Param Norm              40.9152\n",
      "trainer/Zf1 Grad Norm                7763\n",
      "trainer/Zf1 Param Norm                131.876\n",
      "trainer/Zf2 Grad Norm                9388\n",
      "trainer/Zf2 Param Norm                129.536\n",
      "trainer/Z Expert Predictions Mean    1157.88\n",
      "trainer/Z Expert Predictions Std      153.578\n",
      "trainer/Z Expert Predictions Max     1449.94\n",
      "trainer/Z Expert Predictions Min      157.761\n",
      "trainer/Z Policy Predictions Mean    1025.17\n",
      "trainer/Z Policy Predictions Std      314.163\n",
      "trainer/Z Policy Predictions Max     1436.81\n",
      "trainer/Z Policy Predictions Min     -164.857\n",
      "trainer/Z Expert Targets Mean        1140.45\n",
      "trainer/Z Expert Targets Std          157.099\n",
      "trainer/Z Expert Targets Max         1409.68\n",
      "trainer/Z Expert Targets Min          137.062\n",
      "trainer/Z Policy Targets Mean        1014.2\n",
      "trainer/Z Policy Targets Std          315.024\n",
      "trainer/Z Policy Targets Max         1410.73\n",
      "trainer/Z Policy Targets Min         -132.639\n",
      "trainer/Log Pis Mean                   19.2972\n",
      "trainer/Log Pis Std                     4.37159\n",
      "trainer/Policy mu Mean                  1.22606\n",
      "trainer/Policy mu Std                   1.82565\n",
      "trainer/Policy log std Mean            -2.21176\n",
      "trainer/Policy log std Std              1.21915\n",
      "trainer/Alpha                           0.205378\n",
      "trainer/Alpha Loss                      0.144344\n",
      "exploration/num steps total        279561\n",
      "exploration/num paths total           861\n",
      "evaluation/num steps total              2.33166e+06\n",
      "evaluation/num paths total           2749\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20156\n",
      "evaluation/Rewards Std                  1.32679\n",
      "evaluation/Rewards Max                  7.2484\n",
      "evaluation/Rewards Min                  0.11603\n",
      "evaluation/Returns Mean              5201.56\n",
      "evaluation/Returns Std                 16.0702\n",
      "evaluation/Returns Max               5231.13\n",
      "evaluation/Returns Min               5172.25\n",
      "evaluation/Estimation Bias Mean      1160.68\n",
      "evaluation/Estimation Bias Std        175.998\n",
      "evaluation/EB/Q_True Mean              49.1502\n",
      "evaluation/EB/Q_True Std              151.768\n",
      "evaluation/EB/Q_Pred Mean            1209.83\n",
      "evaluation/EB/Q_Pred Std               88.7503\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5201.56\n",
      "evaluation/Actions Mean                 0.509563\n",
      "evaluation/Actions Std                  0.638547\n",
      "evaluation/Actions Max                  0.999991\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                2.3444\n",
      "time/backward_zf1 (s)                   2.68748\n",
      "time/backward_zf2 (s)                   2.50304\n",
      "time/data sampling (s)                  0.370931\n",
      "time/data storing (s)                   0.0194708\n",
      "time/evaluation sampling (s)            1.46983\n",
      "time/exploration sampling (s)           0.249886\n",
      "time/logging (s)                        0.0123551\n",
      "time/preback_alpha (s)                  1.17893\n",
      "time/preback_policy (s)                 1.34968\n",
      "time/preback_start (s)                  0.151783\n",
      "time/preback_zf (s)                     5.65653\n",
      "time/saving (s)                         0.00553547\n",
      "time/training (s)                       2.51268\n",
      "time/epoch (s)                         20.5125\n",
      "time/total (s)                       4877.64\n",
      "Epoch                                 273\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:32:17.470930 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 274 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 285000\n",
      "trainer/ZF1 Loss                       30.2386\n",
      "trainer/ZF2 Loss                       17.6665\n",
      "trainer/ZF Expert Reward               20.1297\n",
      "trainer/ZF Policy Reward                3.88817\n",
      "trainer/ZF CHI2 Term                   59.7365\n",
      "trainer/Policy Loss                 -1053.58\n",
      "trainer/Bias Loss                     122.209\n",
      "trainer/Bias Value                     19.1321\n",
      "trainer/Policy Grad Norm              304.689\n",
      "trainer/Policy Param Norm              40.9493\n",
      "trainer/Zf1 Grad Norm                4194.94\n",
      "trainer/Zf1 Param Norm                132.025\n",
      "trainer/Zf2 Grad Norm                3745.62\n",
      "trainer/Zf2 Param Norm                129.675\n",
      "trainer/Z Expert Predictions Mean    1159.31\n",
      "trainer/Z Expert Predictions Std      141.169\n",
      "trainer/Z Expert Predictions Max     1444.74\n",
      "trainer/Z Expert Predictions Min      314.554\n",
      "trainer/Z Policy Predictions Mean    1048.73\n",
      "trainer/Z Policy Predictions Std      279.502\n",
      "trainer/Z Policy Predictions Max     1430.96\n",
      "trainer/Z Policy Predictions Min      -70.9075\n",
      "trainer/Z Expert Targets Mean        1139.18\n",
      "trainer/Z Expert Targets Std          144.689\n",
      "trainer/Z Expert Targets Max         1422.61\n",
      "trainer/Z Expert Targets Min          279.123\n",
      "trainer/Z Policy Targets Mean        1044.84\n",
      "trainer/Z Policy Targets Std          275.831\n",
      "trainer/Z Policy Targets Max         1401.53\n",
      "trainer/Z Policy Targets Min          -39.6767\n",
      "trainer/Log Pis Mean                   19.7399\n",
      "trainer/Log Pis Std                     4.23574\n",
      "trainer/Policy mu Mean                  1.23329\n",
      "trainer/Policy mu Std                   1.82865\n",
      "trainer/Policy log std Mean            -2.19236\n",
      "trainer/Policy log std Std              1.20624\n",
      "trainer/Alpha                           0.207121\n",
      "trainer/Alpha Loss                      0.0538683\n",
      "exploration/num steps total        280561\n",
      "exploration/num paths total           862\n",
      "evaluation/num steps total              2.34166e+06\n",
      "evaluation/num paths total           2759\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15264\n",
      "evaluation/Rewards Std                  1.30608\n",
      "evaluation/Rewards Max                  7.06656\n",
      "evaluation/Rewards Min                  0.114441\n",
      "evaluation/Returns Mean              5152.64\n",
      "evaluation/Returns Std                 19.2176\n",
      "evaluation/Returns Max               5179.48\n",
      "evaluation/Returns Min               5116.46\n",
      "evaluation/Estimation Bias Mean      1130.07\n",
      "evaluation/Estimation Bias Std        181.019\n",
      "evaluation/EB/Q_True Mean              48.9569\n",
      "evaluation/EB/Q_True Std              151.239\n",
      "evaluation/EB/Q_Pred Mean            1179.03\n",
      "evaluation/EB/Q_Pred Std              125.25\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5152.64\n",
      "evaluation/Actions Mean                 0.504634\n",
      "evaluation/Actions Std                  0.65012\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.29367\n",
      "time/backward_zf1 (s)                   2.49432\n",
      "time/backward_zf2 (s)                   2.38953\n",
      "time/data sampling (s)                  0.341247\n",
      "time/data storing (s)                   0.0144792\n",
      "time/evaluation sampling (s)            1.4087\n",
      "time/exploration sampling (s)           0.205221\n",
      "time/logging (s)                        0.0118792\n",
      "time/preback_alpha (s)                  1.11959\n",
      "time/preback_policy (s)                 1.31592\n",
      "time/preback_start (s)                  0.136975\n",
      "time/preback_zf (s)                     5.36416\n",
      "time/saving (s)                         0.00548513\n",
      "time/training (s)                       2.3222\n",
      "time/epoch (s)                         19.4234\n",
      "time/total (s)                       4897.08\n",
      "Epoch                                 274\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:32:36.160098 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 275 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 286000\n",
      "trainer/ZF1 Loss                       37.8862\n",
      "trainer/ZF2 Loss                       39.5179\n",
      "trainer/ZF Expert Reward               14.6792\n",
      "trainer/ZF Policy Reward                3.83737\n",
      "trainer/ZF CHI2 Term                   69.7501\n",
      "trainer/Policy Loss                 -1022.83\n",
      "trainer/Bias Loss                     174.883\n",
      "trainer/Bias Value                     19.1169\n",
      "trainer/Policy Grad Norm              254.288\n",
      "trainer/Policy Param Norm              40.9901\n",
      "trainer/Zf1 Grad Norm                4983.83\n",
      "trainer/Zf1 Param Norm                132.175\n",
      "trainer/Zf2 Grad Norm                5256.34\n",
      "trainer/Zf2 Param Norm                129.815\n",
      "trainer/Z Expert Predictions Mean    1136.07\n",
      "trainer/Z Expert Predictions Std      184.98\n",
      "trainer/Z Expert Predictions Max     1459.06\n",
      "trainer/Z Expert Predictions Min      127.519\n",
      "trainer/Z Policy Predictions Mean    1020.07\n",
      "trainer/Z Policy Predictions Std      309.662\n",
      "trainer/Z Policy Predictions Max     1410.68\n",
      "trainer/Z Policy Predictions Min      -59.2426\n",
      "trainer/Z Expert Targets Mean        1121.39\n",
      "trainer/Z Expert Targets Std          190.241\n",
      "trainer/Z Expert Targets Max         1441.73\n",
      "trainer/Z Expert Targets Min          125.714\n",
      "trainer/Z Policy Targets Mean        1016.23\n",
      "trainer/Z Policy Targets Std          304.501\n",
      "trainer/Z Policy Targets Max         1413.58\n",
      "trainer/Z Policy Targets Min          -66.141\n",
      "trainer/Log Pis Mean                   20.4103\n",
      "trainer/Log Pis Std                     4.25767\n",
      "trainer/Policy mu Mean                  1.35439\n",
      "trainer/Policy mu Std                   1.84068\n",
      "trainer/Policy log std Mean            -2.16729\n",
      "trainer/Policy log std Std              1.2082\n",
      "trainer/Alpha                           0.207386\n",
      "trainer/Alpha Loss                     -0.0850878\n",
      "exploration/num steps total        281561\n",
      "exploration/num paths total           863\n",
      "evaluation/num steps total              2.35166e+06\n",
      "evaluation/num paths total           2769\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17354\n",
      "evaluation/Rewards Std                  1.3185\n",
      "evaluation/Rewards Max                  7.1587\n",
      "evaluation/Rewards Min                  0.109311\n",
      "evaluation/Returns Mean              5173.54\n",
      "evaluation/Returns Std                 11.3208\n",
      "evaluation/Returns Max               5194.96\n",
      "evaluation/Returns Min               5160.46\n",
      "evaluation/Estimation Bias Mean      1156.74\n",
      "evaluation/Estimation Bias Std        172.21\n",
      "evaluation/EB/Q_True Mean              48.8919\n",
      "evaluation/EB/Q_True Std              151.009\n",
      "evaluation/EB/Q_Pred Mean            1205.63\n",
      "evaluation/EB/Q_Pred Std               80.242\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5173.54\n",
      "evaluation/Actions Mean                 0.510157\n",
      "evaluation/Actions Std                  0.641138\n",
      "evaluation/Actions Max                  0.999994\n",
      "evaluation/Actions Min                 -0.99993\n",
      "time/backward_policy (s)                2.09578\n",
      "time/backward_zf1 (s)                   2.26962\n",
      "time/backward_zf2 (s)                   2.19697\n",
      "time/data sampling (s)                  0.327721\n",
      "time/data storing (s)                   0.0151491\n",
      "time/evaluation sampling (s)            1.41383\n",
      "time/exploration sampling (s)           0.207704\n",
      "time/logging (s)                        0.0116402\n",
      "time/preback_alpha (s)                  1.07832\n",
      "time/preback_policy (s)                 1.23446\n",
      "time/preback_start (s)                  0.13713\n",
      "time/preback_zf (s)                     5.30136\n",
      "time/saving (s)                         0.00526254\n",
      "time/training (s)                       2.31197\n",
      "time/epoch (s)                         18.6069\n",
      "time/total (s)                       4915.71\n",
      "Epoch                                 275\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:32:54.906693 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 276 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 287000\n",
      "trainer/ZF1 Loss                       44.774\n",
      "trainer/ZF2 Loss                       32.1402\n",
      "trainer/ZF Expert Reward               11.7353\n",
      "trainer/ZF Policy Reward               -1.37996\n",
      "trainer/ZF CHI2 Term                   71.9292\n",
      "trainer/Policy Loss                 -1040.26\n",
      "trainer/Bias Loss                     214.838\n",
      "trainer/Bias Value                     19.1043\n",
      "trainer/Policy Grad Norm              364.381\n",
      "trainer/Policy Param Norm              41.027\n",
      "trainer/Zf1 Grad Norm               10348.1\n",
      "trainer/Zf1 Param Norm                132.329\n",
      "trainer/Zf2 Grad Norm               10368.8\n",
      "trainer/Zf2 Param Norm                129.975\n",
      "trainer/Z Expert Predictions Mean    1159.28\n",
      "trainer/Z Expert Predictions Std      124.363\n",
      "trainer/Z Expert Predictions Max     1434.19\n",
      "trainer/Z Expert Predictions Min      736.118\n",
      "trainer/Z Policy Predictions Mean    1027.67\n",
      "trainer/Z Policy Predictions Std      273.174\n",
      "trainer/Z Policy Predictions Max     1403.32\n",
      "trainer/Z Policy Predictions Min       18.6137\n",
      "trainer/Z Expert Targets Mean        1147.54\n",
      "trainer/Z Expert Targets Std          128.475\n",
      "trainer/Z Expert Targets Max         1443.07\n",
      "trainer/Z Expert Targets Min          697.661\n",
      "trainer/Z Policy Targets Mean        1029.05\n",
      "trainer/Z Policy Targets Std          275.408\n",
      "trainer/Z Policy Targets Max         1425.37\n",
      "trainer/Z Policy Targets Min           18.7642\n",
      "trainer/Log Pis Mean                   20.5625\n",
      "trainer/Log Pis Std                     4.48553\n",
      "trainer/Policy mu Mean                  1.29214\n",
      "trainer/Policy mu Std                   1.86005\n",
      "trainer/Policy log std Mean            -2.25982\n",
      "trainer/Policy log std Std              1.20098\n",
      "trainer/Alpha                           0.209086\n",
      "trainer/Alpha Loss                     -0.1176\n",
      "exploration/num steps total        283561\n",
      "exploration/num paths total           865\n",
      "evaluation/num steps total              2.36166e+06\n",
      "evaluation/num paths total           2779\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.23579\n",
      "evaluation/Rewards Std                  1.34629\n",
      "evaluation/Rewards Max                  7.2949\n",
      "evaluation/Rewards Min                  0.0977109\n",
      "evaluation/Returns Mean              5235.79\n",
      "evaluation/Returns Std                 11.0746\n",
      "evaluation/Returns Max               5254.33\n",
      "evaluation/Returns Min               5220.04\n",
      "evaluation/Estimation Bias Mean      1102.17\n",
      "evaluation/Estimation Bias Std        179.781\n",
      "evaluation/EB/Q_True Mean              49.4493\n",
      "evaluation/EB/Q_True Std              152.708\n",
      "evaluation/EB/Q_Pred Mean            1151.62\n",
      "evaluation/EB/Q_Pred Std               98.0528\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5235.79\n",
      "evaluation/Actions Mean                 0.511173\n",
      "evaluation/Actions Std                  0.643353\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.09074\n",
      "time/backward_zf1 (s)                   2.31819\n",
      "time/backward_zf2 (s)                   2.23254\n",
      "time/data sampling (s)                  0.324377\n",
      "time/data storing (s)                   0.017094\n",
      "time/evaluation sampling (s)            1.41237\n",
      "time/exploration sampling (s)           0.218687\n",
      "time/logging (s)                        0.0119155\n",
      "time/preback_alpha (s)                  1.05108\n",
      "time/preback_policy (s)                 1.20069\n",
      "time/preback_start (s)                  0.136304\n",
      "time/preback_zf (s)                     5.27768\n",
      "time/saving (s)                         0.00542317\n",
      "time/training (s)                       2.3774\n",
      "time/epoch (s)                         18.6745\n",
      "time/total (s)                       4934.41\n",
      "Epoch                                 276\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:33:14.748098 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 277 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 288000\n",
      "trainer/ZF1 Loss                       24.4931\n",
      "trainer/ZF2 Loss                       23.7392\n",
      "trainer/ZF Expert Reward               20.0927\n",
      "trainer/ZF Policy Reward                6.34256\n",
      "trainer/ZF CHI2 Term                   57.5435\n",
      "trainer/Policy Loss                 -1044.3\n",
      "trainer/Bias Loss                     123.065\n",
      "trainer/Bias Value                     19.0875\n",
      "trainer/Policy Grad Norm              327.355\n",
      "trainer/Policy Param Norm              41.0677\n",
      "trainer/Zf1 Grad Norm                4589.71\n",
      "trainer/Zf1 Param Norm                132.474\n",
      "trainer/Zf2 Grad Norm                5564.95\n",
      "trainer/Zf2 Param Norm                130.117\n",
      "trainer/Z Expert Predictions Mean    1152.13\n",
      "trainer/Z Expert Predictions Std      147.988\n",
      "trainer/Z Expert Predictions Max     1449.22\n",
      "trainer/Z Expert Predictions Min      236.396\n",
      "trainer/Z Policy Predictions Mean    1040.09\n",
      "trainer/Z Policy Predictions Std      266.383\n",
      "trainer/Z Policy Predictions Max     1454.24\n",
      "trainer/Z Policy Predictions Min      -52.9804\n",
      "trainer/Z Expert Targets Mean        1132.03\n",
      "trainer/Z Expert Targets Std          151.383\n",
      "trainer/Z Expert Targets Max         1414.03\n",
      "trainer/Z Expert Targets Min          206.909\n",
      "trainer/Z Policy Targets Mean        1033.75\n",
      "trainer/Z Policy Targets Std          263.151\n",
      "trainer/Z Policy Targets Max         1436.55\n",
      "trainer/Z Policy Targets Min          -61.5691\n",
      "trainer/Log Pis Mean                   19.8759\n",
      "trainer/Log Pis Std                     4.22243\n",
      "trainer/Policy mu Mean                  1.22307\n",
      "trainer/Policy mu Std                   1.83552\n",
      "trainer/Policy log std Mean            -2.26437\n",
      "trainer/Policy log std Std              1.19481\n",
      "trainer/Alpha                           0.208084\n",
      "trainer/Alpha Loss                      0.0258133\n",
      "exploration/num steps total        283561\n",
      "exploration/num paths total           865\n",
      "evaluation/num steps total              2.37166e+06\n",
      "evaluation/num paths total           2789\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15052\n",
      "evaluation/Rewards Std                  1.29731\n",
      "evaluation/Rewards Max                  7.08553\n",
      "evaluation/Rewards Min                  0.133688\n",
      "evaluation/Returns Mean              5150.52\n",
      "evaluation/Returns Std                 18.711\n",
      "evaluation/Returns Max               5186.73\n",
      "evaluation/Returns Min               5123.4\n",
      "evaluation/Estimation Bias Mean      1155.87\n",
      "evaluation/Estimation Bias Std        177.603\n",
      "evaluation/EB/Q_True Mean              48.4624\n",
      "evaluation/EB/Q_True Std              149.785\n",
      "evaluation/EB/Q_Pred Mean            1204.33\n",
      "evaluation/EB/Q_Pred Std               98.2103\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5150.52\n",
      "evaluation/Actions Mean                 0.507877\n",
      "evaluation/Actions Std                  0.645429\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.21502\n",
      "time/backward_zf1 (s)                   2.51231\n",
      "time/backward_zf2 (s)                   2.38697\n",
      "time/data sampling (s)                  0.355532\n",
      "time/data storing (s)                   0.0170014\n",
      "time/evaluation sampling (s)            1.48305\n",
      "time/exploration sampling (s)           0.216305\n",
      "time/logging (s)                        0.0115578\n",
      "time/preback_alpha (s)                  1.10775\n",
      "time/preback_policy (s)                 1.27094\n",
      "time/preback_start (s)                  0.145228\n",
      "time/preback_zf (s)                     5.53358\n",
      "time/saving (s)                         0.00552322\n",
      "time/training (s)                       2.50065\n",
      "time/epoch (s)                         19.7614\n",
      "time/total (s)                       4954.19\n",
      "Epoch                                 277\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:33:34.015934 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 278 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 289000\n",
      "trainer/ZF1 Loss                       36.6445\n",
      "trainer/ZF2 Loss                       29.7502\n",
      "trainer/ZF Expert Reward               19.583\n",
      "trainer/ZF Policy Reward                3.23891\n",
      "trainer/ZF CHI2 Term                   68.9231\n",
      "trainer/Policy Loss                 -1014.04\n",
      "trainer/Bias Loss                     130.931\n",
      "trainer/Bias Value                     19.076\n",
      "trainer/Policy Grad Norm              377.092\n",
      "trainer/Policy Param Norm              41.1039\n",
      "trainer/Zf1 Grad Norm                3780.55\n",
      "trainer/Zf1 Param Norm                132.614\n",
      "trainer/Zf2 Grad Norm                4404.39\n",
      "trainer/Zf2 Param Norm                130.252\n",
      "trainer/Z Expert Predictions Mean    1129.7\n",
      "trainer/Z Expert Predictions Std      160.139\n",
      "trainer/Z Expert Predictions Max     1412.75\n",
      "trainer/Z Expert Predictions Min      -14.2565\n",
      "trainer/Z Policy Predictions Mean    1012.85\n",
      "trainer/Z Policy Predictions Std      300.089\n",
      "trainer/Z Policy Predictions Max     1366.24\n",
      "trainer/Z Policy Predictions Min     -207.038\n",
      "trainer/Z Expert Targets Mean        1110.12\n",
      "trainer/Z Expert Targets Std          162.614\n",
      "trainer/Z Expert Targets Max         1410.32\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1009.61\n",
      "trainer/Z Policy Targets Std          296.149\n",
      "trainer/Z Policy Targets Max         1411.71\n",
      "trainer/Z Policy Targets Min         -157.608\n",
      "trainer/Log Pis Mean                   19.5774\n",
      "trainer/Log Pis Std                     4.28977\n",
      "trainer/Policy mu Mean                  1.17587\n",
      "trainer/Policy mu Std                   1.80104\n",
      "trainer/Policy log std Mean            -2.28832\n",
      "trainer/Policy log std Std              1.22282\n",
      "trainer/Alpha                           0.208266\n",
      "trainer/Alpha Loss                      0.0880136\n",
      "exploration/num steps total        283561\n",
      "exploration/num paths total           865\n",
      "evaluation/num steps total              2.38166e+06\n",
      "evaluation/num paths total           2799\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1837\n",
      "evaluation/Rewards Std                  1.31332\n",
      "evaluation/Rewards Max                  7.216\n",
      "evaluation/Rewards Min                  0.125407\n",
      "evaluation/Returns Mean              5183.7\n",
      "evaluation/Returns Std                 22.9324\n",
      "evaluation/Returns Max               5220.15\n",
      "evaluation/Returns Min               5151.27\n",
      "evaluation/Estimation Bias Mean      1129.02\n",
      "evaluation/Estimation Bias Std        178.339\n",
      "evaluation/EB/Q_True Mean              48.9353\n",
      "evaluation/EB/Q_True Std              151.054\n",
      "evaluation/EB/Q_Pred Mean            1177.96\n",
      "evaluation/EB/Q_Pred Std               93.2342\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5183.7\n",
      "evaluation/Actions Mean                 0.506652\n",
      "evaluation/Actions Std                  0.643373\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                2.16131\n",
      "time/backward_zf1 (s)                   2.40051\n",
      "time/backward_zf2 (s)                   2.29086\n",
      "time/data sampling (s)                  0.328754\n",
      "time/data storing (s)                   0.0153538\n",
      "time/evaluation sampling (s)            1.46418\n",
      "time/exploration sampling (s)           0.204781\n",
      "time/logging (s)                        0.0119232\n",
      "time/preback_alpha (s)                  1.0736\n",
      "time/preback_policy (s)                 1.23804\n",
      "time/preback_start (s)                  0.139701\n",
      "time/preback_zf (s)                     5.40704\n",
      "time/saving (s)                         0.00519209\n",
      "time/training (s)                       2.45162\n",
      "time/epoch (s)                         19.1929\n",
      "time/total (s)                       4973.4\n",
      "Epoch                                 278\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:33:53.421887 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 279 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 290000\n",
      "trainer/ZF1 Loss                      480.918\n",
      "trainer/ZF2 Loss                      507.834\n",
      "trainer/ZF Expert Reward               14.2375\n",
      "trainer/ZF Policy Reward                7.74302\n",
      "trainer/ZF CHI2 Term                  520.431\n",
      "trainer/Policy Loss                 -1007.43\n",
      "trainer/Bias Loss                     101.939\n",
      "trainer/Bias Value                     19.0603\n",
      "trainer/Policy Grad Norm              287.983\n",
      "trainer/Policy Param Norm              41.1408\n",
      "trainer/Zf1 Grad Norm               10256.2\n",
      "trainer/Zf1 Param Norm                132.759\n",
      "trainer/Zf2 Grad Norm               10511.3\n",
      "trainer/Zf2 Param Norm                130.392\n",
      "trainer/Z Expert Predictions Mean    1142.52\n",
      "trainer/Z Expert Predictions Std      125.894\n",
      "trainer/Z Expert Predictions Max     1412.23\n",
      "trainer/Z Expert Predictions Min      554.921\n",
      "trainer/Z Policy Predictions Mean    1008.5\n",
      "trainer/Z Policy Predictions Std      316.961\n",
      "trainer/Z Policy Predictions Max     1401.39\n",
      "trainer/Z Policy Predictions Min     -196.502\n",
      "trainer/Z Expert Targets Mean        1128.28\n",
      "trainer/Z Expert Targets Std          128.769\n",
      "trainer/Z Expert Targets Max         1383.61\n",
      "trainer/Z Expert Targets Min          539.894\n",
      "trainer/Z Policy Targets Mean        1000.76\n",
      "trainer/Z Policy Targets Std          325.146\n",
      "trainer/Z Policy Targets Max         1381.47\n",
      "trainer/Z Policy Targets Min         -199.756\n",
      "trainer/Log Pis Mean                   19.7585\n",
      "trainer/Log Pis Std                     4.06352\n",
      "trainer/Policy mu Mean                  1.26218\n",
      "trainer/Policy mu Std                   1.86225\n",
      "trainer/Policy log std Mean            -2.14266\n",
      "trainer/Policy log std Std              1.20913\n",
      "trainer/Alpha                           0.208116\n",
      "trainer/Alpha Loss                      0.050273\n",
      "exploration/num steps total        285561\n",
      "exploration/num paths total           867\n",
      "evaluation/num steps total              2.39166e+06\n",
      "evaluation/num paths total           2809\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17798\n",
      "evaluation/Rewards Std                  1.31733\n",
      "evaluation/Rewards Max                  7.12863\n",
      "evaluation/Rewards Min                  0.102708\n",
      "evaluation/Returns Mean              5177.98\n",
      "evaluation/Returns Std                 22.4185\n",
      "evaluation/Returns Max               5214.73\n",
      "evaluation/Returns Min               5140.91\n",
      "evaluation/Estimation Bias Mean      1115.8\n",
      "evaluation/Estimation Bias Std        206.956\n",
      "evaluation/EB/Q_True Mean              48.8338\n",
      "evaluation/EB/Q_True Std              150.955\n",
      "evaluation/EB/Q_Pred Mean            1164.63\n",
      "evaluation/EB/Q_Pred Std              105.073\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5177.98\n",
      "evaluation/Actions Mean                 0.506801\n",
      "evaluation/Actions Std                  0.64506\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.21898\n",
      "time/backward_zf1 (s)                   2.48178\n",
      "time/backward_zf2 (s)                   2.35894\n",
      "time/data sampling (s)                  0.32241\n",
      "time/data storing (s)                   0.0152798\n",
      "time/evaluation sampling (s)            1.4483\n",
      "time/exploration sampling (s)           0.207312\n",
      "time/logging (s)                        0.0121447\n",
      "time/preback_alpha (s)                  1.09674\n",
      "time/preback_policy (s)                 1.2603\n",
      "time/preback_start (s)                  0.14109\n",
      "time/preback_zf (s)                     5.38808\n",
      "time/saving (s)                         0.00556233\n",
      "time/training (s)                       2.37069\n",
      "time/epoch (s)                         19.3276\n",
      "time/total (s)                       4992.75\n",
      "Epoch                                 279\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:34:13.037199 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 280 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 291000\n",
      "trainer/ZF1 Loss                      348.483\n",
      "trainer/ZF2 Loss                      378.013\n",
      "trainer/ZF Expert Reward               14.0056\n",
      "trainer/ZF Policy Reward               -1.49944\n",
      "trainer/ZF CHI2 Term                  398.89\n",
      "trainer/Policy Loss                  -990.234\n",
      "trainer/Bias Loss                    1617.79\n",
      "trainer/Bias Value                     19.0455\n",
      "trainer/Policy Grad Norm              277.397\n",
      "trainer/Policy Param Norm              41.1785\n",
      "trainer/Zf1 Grad Norm               11284.5\n",
      "trainer/Zf1 Param Norm                132.891\n",
      "trainer/Zf2 Grad Norm               15680.2\n",
      "trainer/Zf2 Param Norm                130.526\n",
      "trainer/Z Expert Predictions Mean    1131.83\n",
      "trainer/Z Expert Predictions Std      125.993\n",
      "trainer/Z Expert Predictions Max     1399.29\n",
      "trainer/Z Expert Predictions Min      770.111\n",
      "trainer/Z Policy Predictions Mean     986.059\n",
      "trainer/Z Policy Predictions Std      299.493\n",
      "trainer/Z Policy Predictions Max     1398.62\n",
      "trainer/Z Policy Predictions Min     -132.886\n",
      "trainer/Z Expert Targets Mean        1117.82\n",
      "trainer/Z Expert Targets Std          146.985\n",
      "trainer/Z Expert Targets Max         1404.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         987.558\n",
      "trainer/Z Policy Targets Std          301.175\n",
      "trainer/Z Policy Targets Max         1428.92\n",
      "trainer/Z Policy Targets Min         -127.719\n",
      "trainer/Log Pis Mean                   20.3402\n",
      "trainer/Log Pis Std                     4.84051\n",
      "trainer/Policy mu Mean                  1.23689\n",
      "trainer/Policy mu Std                   1.96282\n",
      "trainer/Policy log std Mean            -2.182\n",
      "trainer/Policy log std Std              1.22482\n",
      "trainer/Alpha                           0.207825\n",
      "trainer/Alpha Loss                     -0.0707044\n",
      "exploration/num steps total        285561\n",
      "exploration/num paths total           867\n",
      "evaluation/num steps total              2.40127e+06\n",
      "evaluation/num paths total           2819\n",
      "evaluation/path length Mean           960.6\n",
      "evaluation/path length Std            118.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            606\n",
      "evaluation/Rewards Mean                 5.17016\n",
      "evaluation/Rewards Std                  1.33123\n",
      "evaluation/Rewards Max                  7.18768\n",
      "evaluation/Rewards Min                  0.118045\n",
      "evaluation/Returns Mean              4966.46\n",
      "evaluation/Returns Std                672.83\n",
      "evaluation/Returns Max               5220.48\n",
      "evaluation/Returns Min               2948.66\n",
      "evaluation/Estimation Bias Mean      1123.97\n",
      "evaluation/Estimation Bias Std        243.948\n",
      "evaluation/EB/Q_True Mean              50.9711\n",
      "evaluation/EB/Q_True Std              154.023\n",
      "evaluation/EB/Q_Pred Mean            1174.95\n",
      "evaluation/EB/Q_Pred Std              144.571\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4966.46\n",
      "evaluation/Actions Mean                 0.507322\n",
      "evaluation/Actions Std                  0.645344\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.24986\n",
      "time/backward_zf1 (s)                   2.53194\n",
      "time/backward_zf2 (s)                   2.39317\n",
      "time/data sampling (s)                  0.341285\n",
      "time/data storing (s)                   0.0168314\n",
      "time/evaluation sampling (s)            1.37829\n",
      "time/exploration sampling (s)           0.212385\n",
      "time/logging (s)                        0.011506\n",
      "time/preback_alpha (s)                  1.11761\n",
      "time/preback_policy (s)                 1.26552\n",
      "time/preback_start (s)                  0.139537\n",
      "time/preback_zf (s)                     5.51033\n",
      "time/saving (s)                         0.00510205\n",
      "time/training (s)                       2.36621\n",
      "time/epoch (s)                         19.5396\n",
      "time/total (s)                       5012.31\n",
      "Epoch                                 280\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:34:32.465741 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 281 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 292000\n",
      "trainer/ZF1 Loss                      183.229\n",
      "trainer/ZF2 Loss                      208.506\n",
      "trainer/ZF Expert Reward               17.9428\n",
      "trainer/ZF Policy Reward                7.80709\n",
      "trainer/ZF CHI2 Term                  226.014\n",
      "trainer/Policy Loss                 -1027.29\n",
      "trainer/Bias Loss                     100.92\n",
      "trainer/Bias Value                     19.032\n",
      "trainer/Policy Grad Norm              350.005\n",
      "trainer/Policy Param Norm              41.2183\n",
      "trainer/Zf1 Grad Norm                3962.87\n",
      "trainer/Zf1 Param Norm                133.03\n",
      "trainer/Zf2 Grad Norm                5874.22\n",
      "trainer/Zf2 Param Norm                130.66\n",
      "trainer/Z Expert Predictions Mean    1133.42\n",
      "trainer/Z Expert Predictions Std      143.783\n",
      "trainer/Z Expert Predictions Max     1389.25\n",
      "trainer/Z Expert Predictions Min      258.852\n",
      "trainer/Z Policy Predictions Mean    1029.09\n",
      "trainer/Z Policy Predictions Std      283.185\n",
      "trainer/Z Policy Predictions Max     1364.14\n",
      "trainer/Z Policy Predictions Min      -84.2666\n",
      "trainer/Z Expert Targets Mean        1115.48\n",
      "trainer/Z Expert Targets Std          146.817\n",
      "trainer/Z Expert Targets Max         1382.77\n",
      "trainer/Z Expert Targets Min          232.134\n",
      "trainer/Z Policy Targets Mean        1021.28\n",
      "trainer/Z Policy Targets Std          289.78\n",
      "trainer/Z Policy Targets Max         1361.99\n",
      "trainer/Z Policy Targets Min         -106.455\n",
      "trainer/Log Pis Mean                   20.2129\n",
      "trainer/Log Pis Std                     4.41326\n",
      "trainer/Policy mu Mean                  1.28392\n",
      "trainer/Policy mu Std                   1.94164\n",
      "trainer/Policy log std Mean            -2.11115\n",
      "trainer/Policy log std Std              1.23113\n",
      "trainer/Alpha                           0.208691\n",
      "trainer/Alpha Loss                     -0.0444375\n",
      "exploration/num steps total        285561\n",
      "exploration/num paths total           867\n",
      "evaluation/num steps total              2.41127e+06\n",
      "evaluation/num paths total           2829\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15403\n",
      "evaluation/Rewards Std                  1.29957\n",
      "evaluation/Rewards Max                  7.16489\n",
      "evaluation/Rewards Min                  0.100792\n",
      "evaluation/Returns Mean              5154.03\n",
      "evaluation/Returns Std                 26.6768\n",
      "evaluation/Returns Max               5204.64\n",
      "evaluation/Returns Min               5122.15\n",
      "evaluation/Estimation Bias Mean      1072.28\n",
      "evaluation/Estimation Bias Std        228.695\n",
      "evaluation/EB/Q_True Mean              48.5374\n",
      "evaluation/EB/Q_True Std              149.861\n",
      "evaluation/EB/Q_Pred Mean            1120.81\n",
      "evaluation/EB/Q_Pred Std              149.44\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5154.03\n",
      "evaluation/Actions Mean                 0.500789\n",
      "evaluation/Actions Std                  0.64885\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.20184\n",
      "time/backward_zf1 (s)                   2.45002\n",
      "time/backward_zf2 (s)                   2.32872\n",
      "time/data sampling (s)                  0.328336\n",
      "time/data storing (s)                   0.0160722\n",
      "time/evaluation sampling (s)            1.40359\n",
      "time/exploration sampling (s)           0.208541\n",
      "time/logging (s)                        0.0120186\n",
      "time/preback_alpha (s)                  1.08293\n",
      "time/preback_policy (s)                 1.23972\n",
      "time/preback_start (s)                  0.138373\n",
      "time/preback_zf (s)                     5.41511\n",
      "time/saving (s)                         0.0169848\n",
      "time/training (s)                       2.5039\n",
      "time/epoch (s)                         19.3462\n",
      "time/total (s)                       5031.68\n",
      "Epoch                                 281\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:34:52.134098 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 282 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 293000\n",
      "trainer/ZF1 Loss                       34.877\n",
      "trainer/ZF2 Loss                       31.5001\n",
      "trainer/ZF Expert Reward               15.6241\n",
      "trainer/ZF Policy Reward                2.54339\n",
      "trainer/ZF CHI2 Term                   65.9957\n",
      "trainer/Policy Loss                 -1012.69\n",
      "trainer/Bias Loss                     133.23\n",
      "trainer/Bias Value                     19.0177\n",
      "trainer/Policy Grad Norm              312.484\n",
      "trainer/Policy Param Norm              41.2599\n",
      "trainer/Zf1 Grad Norm                5268.35\n",
      "trainer/Zf1 Param Norm                133.161\n",
      "trainer/Zf2 Grad Norm                5011.98\n",
      "trainer/Zf2 Param Norm                130.789\n",
      "trainer/Z Expert Predictions Mean    1115.11\n",
      "trainer/Z Expert Predictions Std      131.296\n",
      "trainer/Z Expert Predictions Max     1378.97\n",
      "trainer/Z Expert Predictions Min      498.238\n",
      "trainer/Z Policy Predictions Mean    1010.85\n",
      "trainer/Z Policy Predictions Std      306.572\n",
      "trainer/Z Policy Predictions Max     1375.18\n",
      "trainer/Z Policy Predictions Min     -220.716\n",
      "trainer/Z Expert Targets Mean        1099.49\n",
      "trainer/Z Expert Targets Std          135.242\n",
      "trainer/Z Expert Targets Max         1367.9\n",
      "trainer/Z Expert Targets Min          468.318\n",
      "trainer/Z Policy Targets Mean        1008.31\n",
      "trainer/Z Policy Targets Std          303.973\n",
      "trainer/Z Policy Targets Max         1361.72\n",
      "trainer/Z Policy Targets Min         -219.085\n",
      "trainer/Log Pis Mean                   19.9256\n",
      "trainer/Log Pis Std                     3.95834\n",
      "trainer/Policy mu Mean                  1.24847\n",
      "trainer/Policy mu Std                   1.80937\n",
      "trainer/Policy log std Mean            -2.23374\n",
      "trainer/Policy log std Std              1.23427\n",
      "trainer/Alpha                           0.207916\n",
      "trainer/Alpha Loss                      0.0154664\n",
      "exploration/num steps total        286561\n",
      "exploration/num paths total           868\n",
      "evaluation/num steps total              2.42127e+06\n",
      "evaluation/num paths total           2839\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14034\n",
      "evaluation/Rewards Std                  1.29767\n",
      "evaluation/Rewards Max                  7.00239\n",
      "evaluation/Rewards Min                  0.100165\n",
      "evaluation/Returns Mean              5140.34\n",
      "evaluation/Returns Std                  9.37125\n",
      "evaluation/Returns Max               5157.98\n",
      "evaluation/Returns Min               5124.42\n",
      "evaluation/Estimation Bias Mean      1127.47\n",
      "evaluation/Estimation Bias Std        202.535\n",
      "evaluation/EB/Q_True Mean              48.5549\n",
      "evaluation/EB/Q_True Std              150.09\n",
      "evaluation/EB/Q_Pred Mean            1176.03\n",
      "evaluation/EB/Q_Pred Std              119.506\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5140.34\n",
      "evaluation/Actions Mean                 0.49924\n",
      "evaluation/Actions Std                  0.644289\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.26984\n",
      "time/backward_zf1 (s)                   2.50155\n",
      "time/backward_zf2 (s)                   2.36593\n",
      "time/data sampling (s)                  0.321645\n",
      "time/data storing (s)                   0.0164537\n",
      "time/evaluation sampling (s)            1.44782\n",
      "time/exploration sampling (s)           0.221658\n",
      "time/logging (s)                        0.0126183\n",
      "time/preback_alpha (s)                  1.09107\n",
      "time/preback_policy (s)                 1.24974\n",
      "time/preback_start (s)                  0.140659\n",
      "time/preback_zf (s)                     5.41456\n",
      "time/saving (s)                         0.0054681\n",
      "time/training (s)                       2.53608\n",
      "time/epoch (s)                         19.5951\n",
      "time/total (s)                       5051.3\n",
      "Epoch                                 282\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:35:11.322384 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 283 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 294000\n",
      "trainer/ZF1 Loss                       54.4332\n",
      "trainer/ZF2 Loss                       43.492\n",
      "trainer/ZF Expert Reward               17.3354\n",
      "trainer/ZF Policy Reward                3.86356\n",
      "trainer/ZF CHI2 Term                   82.1167\n",
      "trainer/Policy Loss                 -1001.64\n",
      "trainer/Bias Loss                     378.306\n",
      "trainer/Bias Value                     19.0042\n",
      "trainer/Policy Grad Norm              289.29\n",
      "trainer/Policy Param Norm              41.3014\n",
      "trainer/Zf1 Grad Norm                7684.85\n",
      "trainer/Zf1 Param Norm                133.3\n",
      "trainer/Zf2 Grad Norm                7177.14\n",
      "trainer/Zf2 Param Norm                130.935\n",
      "trainer/Z Expert Predictions Mean    1143.53\n",
      "trainer/Z Expert Predictions Std      133.911\n",
      "trainer/Z Expert Predictions Max     1388.46\n",
      "trainer/Z Expert Predictions Min      248.124\n",
      "trainer/Z Policy Predictions Mean     992.962\n",
      "trainer/Z Policy Predictions Std      306.546\n",
      "trainer/Z Policy Predictions Max     1356.55\n",
      "trainer/Z Policy Predictions Min     -166.368\n",
      "trainer/Z Expert Targets Mean        1126.2\n",
      "trainer/Z Expert Targets Std          135.064\n",
      "trainer/Z Expert Targets Max         1376.19\n",
      "trainer/Z Expert Targets Min          229.5\n",
      "trainer/Z Policy Targets Mean         989.099\n",
      "trainer/Z Policy Targets Std          302.807\n",
      "trainer/Z Policy Targets Max         1372.8\n",
      "trainer/Z Policy Targets Min         -173.054\n",
      "trainer/Log Pis Mean                   19.881\n",
      "trainer/Log Pis Std                     4.3241\n",
      "trainer/Policy mu Mean                  1.24485\n",
      "trainer/Policy mu Std                   1.84738\n",
      "trainer/Policy log std Mean            -2.15193\n",
      "trainer/Policy log std Std              1.21181\n",
      "trainer/Alpha                           0.206932\n",
      "trainer/Alpha Loss                      0.0246221\n",
      "exploration/num steps total        289561\n",
      "exploration/num paths total           871\n",
      "evaluation/num steps total              2.43127e+06\n",
      "evaluation/num paths total           2849\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15889\n",
      "evaluation/Rewards Std                  1.30701\n",
      "evaluation/Rewards Max                  6.95698\n",
      "evaluation/Rewards Min                  0.0887861\n",
      "evaluation/Returns Mean              5158.89\n",
      "evaluation/Returns Std                 17.1119\n",
      "evaluation/Returns Max               5188.77\n",
      "evaluation/Returns Min               5119.64\n",
      "evaluation/Estimation Bias Mean      1099.5\n",
      "evaluation/Estimation Bias Std        219.02\n",
      "evaluation/EB/Q_True Mean              48.7799\n",
      "evaluation/EB/Q_True Std              150.767\n",
      "evaluation/EB/Q_Pred Mean            1148.28\n",
      "evaluation/EB/Q_Pred Std              125.601\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5158.89\n",
      "evaluation/Actions Mean                 0.498207\n",
      "evaluation/Actions Std                  0.648251\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.18712\n",
      "time/backward_zf1 (s)                   2.38685\n",
      "time/backward_zf2 (s)                   2.28397\n",
      "time/data sampling (s)                  0.325302\n",
      "time/data storing (s)                   0.0159713\n",
      "time/evaluation sampling (s)            1.45807\n",
      "time/exploration sampling (s)           0.214837\n",
      "time/logging (s)                        0.0134584\n",
      "time/preback_alpha (s)                  1.0771\n",
      "time/preback_policy (s)                 1.23191\n",
      "time/preback_start (s)                  0.140124\n",
      "time/preback_zf (s)                     5.358\n",
      "time/saving (s)                         0.00566609\n",
      "time/training (s)                       2.40729\n",
      "time/epoch (s)                         19.1057\n",
      "time/total (s)                       5070.43\n",
      "Epoch                                 283\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:35:30.547925 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 284 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 295000\n",
      "trainer/ZF1 Loss                       30.9872\n",
      "trainer/ZF2 Loss                       34.0571\n",
      "trainer/ZF Expert Reward               18.3153\n",
      "trainer/ZF Policy Reward                4.59762\n",
      "trainer/ZF CHI2 Term                   66.1237\n",
      "trainer/Policy Loss                  -966.247\n",
      "trainer/Bias Loss                     174.348\n",
      "trainer/Bias Value                     18.9911\n",
      "trainer/Policy Grad Norm              293.66\n",
      "trainer/Policy Param Norm              41.3388\n",
      "trainer/Zf1 Grad Norm                5800.4\n",
      "trainer/Zf1 Param Norm                133.433\n",
      "trainer/Zf2 Grad Norm                4335.33\n",
      "trainer/Zf2 Param Norm                131.076\n",
      "trainer/Z Expert Predictions Mean    1117.59\n",
      "trainer/Z Expert Predictions Std      150.171\n",
      "trainer/Z Expert Predictions Max     1378.22\n",
      "trainer/Z Expert Predictions Min      -99.2654\n",
      "trainer/Z Policy Predictions Mean     959.79\n",
      "trainer/Z Policy Predictions Std      320.393\n",
      "trainer/Z Policy Predictions Max     1375.12\n",
      "trainer/Z Policy Predictions Min     -113.584\n",
      "trainer/Z Expert Targets Mean        1099.27\n",
      "trainer/Z Expert Targets Std          150.984\n",
      "trainer/Z Expert Targets Max         1374.11\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         955.192\n",
      "trainer/Z Policy Targets Std          318.498\n",
      "trainer/Z Policy Targets Max         1375.78\n",
      "trainer/Z Policy Targets Min         -141.605\n",
      "trainer/Log Pis Mean                   20.0847\n",
      "trainer/Log Pis Std                     4.40163\n",
      "trainer/Policy mu Mean                  1.25618\n",
      "trainer/Policy mu Std                   1.90716\n",
      "trainer/Policy log std Mean            -2.16028\n",
      "trainer/Policy log std Std              1.2348\n",
      "trainer/Alpha                           0.205867\n",
      "trainer/Alpha Loss                     -0.0174448\n",
      "exploration/num steps total        290561\n",
      "exploration/num paths total           872\n",
      "evaluation/num steps total              2.44127e+06\n",
      "evaluation/num paths total           2859\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15158\n",
      "evaluation/Rewards Std                  1.30736\n",
      "evaluation/Rewards Max                  7.15207\n",
      "evaluation/Rewards Min                  0.101201\n",
      "evaluation/Returns Mean              5151.58\n",
      "evaluation/Returns Std                 25.4442\n",
      "evaluation/Returns Max               5201.95\n",
      "evaluation/Returns Min               5115.04\n",
      "evaluation/Estimation Bias Mean      1117.51\n",
      "evaluation/Estimation Bias Std        171.824\n",
      "evaluation/EB/Q_True Mean              48.5959\n",
      "evaluation/EB/Q_True Std              150.22\n",
      "evaluation/EB/Q_Pred Mean            1166.1\n",
      "evaluation/EB/Q_Pred Std              100.776\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5151.58\n",
      "evaluation/Actions Mean                 0.490475\n",
      "evaluation/Actions Std                  0.647505\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                2.1593\n",
      "time/backward_zf1 (s)                   2.3975\n",
      "time/backward_zf2 (s)                   2.28969\n",
      "time/data sampling (s)                  0.333303\n",
      "time/data storing (s)                   0.0151864\n",
      "time/evaluation sampling (s)            1.48503\n",
      "time/exploration sampling (s)           0.205059\n",
      "time/logging (s)                        0.0117201\n",
      "time/preback_alpha (s)                  1.06889\n",
      "time/preback_policy (s)                 1.21853\n",
      "time/preback_start (s)                  0.136553\n",
      "time/preback_zf (s)                     5.36224\n",
      "time/saving (s)                         0.00501301\n",
      "time/training (s)                       2.4481\n",
      "time/epoch (s)                         19.1361\n",
      "time/total (s)                       5089.6\n",
      "Epoch                                 284\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:35:49.606459 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 285 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 296000\n",
      "trainer/ZF1 Loss                       44.8189\n",
      "trainer/ZF2 Loss                       53.8285\n",
      "trainer/ZF Expert Reward               10.7439\n",
      "trainer/ZF Policy Reward               -6.83354\n",
      "trainer/ZF CHI2 Term                   86.7922\n",
      "trainer/Policy Loss                  -993.098\n",
      "trainer/Bias Loss                     199.612\n",
      "trainer/Bias Value                     18.9785\n",
      "trainer/Policy Grad Norm              266.035\n",
      "trainer/Policy Param Norm              41.3761\n",
      "trainer/Zf1 Grad Norm                7035.23\n",
      "trainer/Zf1 Param Norm                133.562\n",
      "trainer/Zf2 Grad Norm               10271.2\n",
      "trainer/Zf2 Param Norm                131.206\n",
      "trainer/Z Expert Predictions Mean    1126.28\n",
      "trainer/Z Expert Predictions Std      135.083\n",
      "trainer/Z Expert Predictions Max     1400.32\n",
      "trainer/Z Expert Predictions Min      477.096\n",
      "trainer/Z Policy Predictions Mean     979.085\n",
      "trainer/Z Policy Predictions Std      310.771\n",
      "trainer/Z Policy Predictions Max     1342.4\n",
      "trainer/Z Policy Predictions Min     -186.211\n",
      "trainer/Z Expert Targets Mean        1115.53\n",
      "trainer/Z Expert Targets Std          141.618\n",
      "trainer/Z Expert Targets Max         1392.81\n",
      "trainer/Z Expert Targets Min          437.948\n",
      "trainer/Z Policy Targets Mean         985.919\n",
      "trainer/Z Policy Targets Std          307.942\n",
      "trainer/Z Policy Targets Max         1344.73\n",
      "trainer/Z Policy Targets Min         -212.857\n",
      "trainer/Log Pis Mean                   20.092\n",
      "trainer/Log Pis Std                     4.33699\n",
      "trainer/Policy mu Mean                  1.27917\n",
      "trainer/Policy mu Std                   1.94326\n",
      "trainer/Policy log std Mean            -2.15365\n",
      "trainer/Policy log std Std              1.22885\n",
      "trainer/Alpha                           0.204794\n",
      "trainer/Alpha Loss                     -0.018846\n",
      "exploration/num steps total        291561\n",
      "exploration/num paths total           873\n",
      "evaluation/num steps total              2.45127e+06\n",
      "evaluation/num paths total           2869\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17673\n",
      "evaluation/Rewards Std                  1.33227\n",
      "evaluation/Rewards Max                  7.20796\n",
      "evaluation/Rewards Min                  0.0745209\n",
      "evaluation/Returns Mean              5176.73\n",
      "evaluation/Returns Std                 20.7575\n",
      "evaluation/Returns Max               5210.89\n",
      "evaluation/Returns Min               5144.15\n",
      "evaluation/Estimation Bias Mean      1137.41\n",
      "evaluation/Estimation Bias Std        174.533\n",
      "evaluation/EB/Q_True Mean              48.6737\n",
      "evaluation/EB/Q_True Std              150.222\n",
      "evaluation/EB/Q_Pred Mean            1186.08\n",
      "evaluation/EB/Q_Pred Std               82.6623\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5176.73\n",
      "evaluation/Actions Mean                 0.501533\n",
      "evaluation/Actions Std                  0.643093\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999983\n",
      "time/backward_policy (s)                2.15248\n",
      "time/backward_zf1 (s)                   2.39118\n",
      "time/backward_zf2 (s)                   2.2733\n",
      "time/data sampling (s)                  0.338962\n",
      "time/data storing (s)                   0.0162654\n",
      "time/evaluation sampling (s)            1.44146\n",
      "time/exploration sampling (s)           0.217521\n",
      "time/logging (s)                        0.012066\n",
      "time/preback_alpha (s)                  1.0733\n",
      "time/preback_policy (s)                 1.22063\n",
      "time/preback_start (s)                  0.137218\n",
      "time/preback_zf (s)                     5.35834\n",
      "time/saving (s)                         0.00572222\n",
      "time/training (s)                       2.34405\n",
      "time/epoch (s)                         18.9825\n",
      "time/total (s)                       5108.61\n",
      "Epoch                                 285\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:36:08.801900 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 286 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 297000\n",
      "trainer/ZF1 Loss                       26.3272\n",
      "trainer/ZF2 Loss                       15.2018\n",
      "trainer/ZF Expert Reward               19.4595\n",
      "trainer/ZF Policy Reward                6.27265\n",
      "trainer/ZF CHI2 Term                   53.2104\n",
      "trainer/Policy Loss                  -985.488\n",
      "trainer/Bias Loss                      86.3808\n",
      "trainer/Bias Value                     18.9622\n",
      "trainer/Policy Grad Norm              316.849\n",
      "trainer/Policy Param Norm              41.4115\n",
      "trainer/Zf1 Grad Norm                3913.11\n",
      "trainer/Zf1 Param Norm                133.69\n",
      "trainer/Zf2 Grad Norm                3940.46\n",
      "trainer/Zf2 Param Norm                131.339\n",
      "trainer/Z Expert Predictions Mean    1118.16\n",
      "trainer/Z Expert Predictions Std      160.348\n",
      "trainer/Z Expert Predictions Max     1405.5\n",
      "trainer/Z Expert Predictions Min      212.845\n",
      "trainer/Z Policy Predictions Mean     985.271\n",
      "trainer/Z Policy Predictions Std      300.507\n",
      "trainer/Z Policy Predictions Max     1369.05\n",
      "trainer/Z Policy Predictions Min      -73.2343\n",
      "trainer/Z Expert Targets Mean        1098.7\n",
      "trainer/Z Expert Targets Std          162.232\n",
      "trainer/Z Expert Targets Max         1390.27\n",
      "trainer/Z Expert Targets Min          179.46\n",
      "trainer/Z Policy Targets Mean         978.998\n",
      "trainer/Z Policy Targets Std          298.99\n",
      "trainer/Z Policy Targets Max         1353.9\n",
      "trainer/Z Policy Targets Min          -90.9901\n",
      "trainer/Log Pis Mean                   19.4535\n",
      "trainer/Log Pis Std                     4.17817\n",
      "trainer/Policy mu Mean                  1.18726\n",
      "trainer/Policy mu Std                   1.80055\n",
      "trainer/Policy log std Mean            -2.29966\n",
      "trainer/Policy log std Std              1.22068\n",
      "trainer/Alpha                           0.206094\n",
      "trainer/Alpha Loss                      0.112625\n",
      "exploration/num steps total        293561\n",
      "exploration/num paths total           875\n",
      "evaluation/num steps total              2.46127e+06\n",
      "evaluation/num paths total           2879\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1625\n",
      "evaluation/Rewards Std                  1.29889\n",
      "evaluation/Rewards Max                  7.02214\n",
      "evaluation/Rewards Min                  0.121874\n",
      "evaluation/Returns Mean              5162.5\n",
      "evaluation/Returns Std                 25.1369\n",
      "evaluation/Returns Max               5191.6\n",
      "evaluation/Returns Min               5111.51\n",
      "evaluation/Estimation Bias Mean      1114.61\n",
      "evaluation/Estimation Bias Std        216.411\n",
      "evaluation/EB/Q_True Mean              48.9637\n",
      "evaluation/EB/Q_True Std              151.123\n",
      "evaluation/EB/Q_Pred Mean            1163.57\n",
      "evaluation/EB/Q_Pred Std              110.077\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5162.5\n",
      "evaluation/Actions Mean                 0.504818\n",
      "evaluation/Actions Std                  0.64076\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.15838\n",
      "time/backward_zf1 (s)                   2.37937\n",
      "time/backward_zf2 (s)                   2.28722\n",
      "time/data sampling (s)                  0.341307\n",
      "time/data storing (s)                   0.0158126\n",
      "time/evaluation sampling (s)            1.43372\n",
      "time/exploration sampling (s)           0.213582\n",
      "time/logging (s)                        0.0123659\n",
      "time/preback_alpha (s)                  1.1044\n",
      "time/preback_policy (s)                 1.27841\n",
      "time/preback_start (s)                  0.138612\n",
      "time/preback_zf (s)                     5.40221\n",
      "time/saving (s)                         0.00543229\n",
      "time/training (s)                       2.34929\n",
      "time/epoch (s)                         19.1201\n",
      "time/total (s)                       5127.74\n",
      "Epoch                                 286\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:36:27.462542 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 287 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 298000\n",
      "trainer/ZF1 Loss                       26.4668\n",
      "trainer/ZF2 Loss                       25.5763\n",
      "trainer/ZF Expert Reward               15.9969\n",
      "trainer/ZF Policy Reward                4.54523\n",
      "trainer/ZF CHI2 Term                   57.6797\n",
      "trainer/Policy Loss                  -997.839\n",
      "trainer/Bias Loss                     112.813\n",
      "trainer/Bias Value                     18.9501\n",
      "trainer/Policy Grad Norm              260.572\n",
      "trainer/Policy Param Norm              41.4489\n",
      "trainer/Zf1 Grad Norm                3728.44\n",
      "trainer/Zf1 Param Norm                133.813\n",
      "trainer/Zf2 Grad Norm                6760.45\n",
      "trainer/Zf2 Param Norm                131.472\n",
      "trainer/Z Expert Predictions Mean    1121.33\n",
      "trainer/Z Expert Predictions Std      151.302\n",
      "trainer/Z Expert Predictions Max     1405.27\n",
      "trainer/Z Expert Predictions Min      103.079\n",
      "trainer/Z Policy Predictions Mean     990.306\n",
      "trainer/Z Policy Predictions Std      292.362\n",
      "trainer/Z Policy Predictions Max     1323.94\n",
      "trainer/Z Policy Predictions Min     -198.386\n",
      "trainer/Z Expert Targets Mean        1105.34\n",
      "trainer/Z Expert Targets Std          154.535\n",
      "trainer/Z Expert Targets Max         1383.09\n",
      "trainer/Z Expert Targets Min           70.5359\n",
      "trainer/Z Policy Targets Mean         985.761\n",
      "trainer/Z Policy Targets Std          286.401\n",
      "trainer/Z Policy Targets Max         1310.37\n",
      "trainer/Z Policy Targets Min         -160.69\n",
      "trainer/Log Pis Mean                   20.4105\n",
      "trainer/Log Pis Std                     4.3087\n",
      "trainer/Policy mu Mean                  1.29358\n",
      "trainer/Policy mu Std                   1.8298\n",
      "trainer/Policy log std Mean            -2.258\n",
      "trainer/Policy log std Std              1.245\n",
      "trainer/Alpha                           0.206407\n",
      "trainer/Alpha Loss                     -0.0847246\n",
      "exploration/num steps total        293561\n",
      "exploration/num paths total           875\n",
      "evaluation/num steps total              2.47127e+06\n",
      "evaluation/num paths total           2889\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.11493\n",
      "evaluation/Rewards Std                  1.2886\n",
      "evaluation/Rewards Max                  6.92279\n",
      "evaluation/Rewards Min                  0.105937\n",
      "evaluation/Returns Mean              5114.93\n",
      "evaluation/Returns Std                 22.3522\n",
      "evaluation/Returns Max               5154\n",
      "evaluation/Returns Min               5073.87\n",
      "evaluation/Estimation Bias Mean      1114.32\n",
      "evaluation/Estimation Bias Std        199.886\n",
      "evaluation/EB/Q_True Mean              48.4333\n",
      "evaluation/EB/Q_True Std              149.51\n",
      "evaluation/EB/Q_Pred Mean            1162.76\n",
      "evaluation/EB/Q_Pred Std              102.753\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5114.93\n",
      "evaluation/Actions Mean                 0.497989\n",
      "evaluation/Actions Std                  0.644725\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.08562\n",
      "time/backward_zf1 (s)                   2.27857\n",
      "time/backward_zf2 (s)                   2.18507\n",
      "time/data sampling (s)                  0.327847\n",
      "time/data storing (s)                   0.0159651\n",
      "time/evaluation sampling (s)            1.41224\n",
      "time/exploration sampling (s)           0.206873\n",
      "time/logging (s)                        0.0116854\n",
      "time/preback_alpha (s)                  1.04782\n",
      "time/preback_policy (s)                 1.15343\n",
      "time/preback_start (s)                  0.135983\n",
      "time/preback_zf (s)                     5.27948\n",
      "time/saving (s)                         0.00538389\n",
      "time/training (s)                       2.43337\n",
      "time/epoch (s)                         18.5793\n",
      "time/total (s)                       5146.35\n",
      "Epoch                                 287\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:36:46.350723 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 288 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 299000\n",
      "trainer/ZF1 Loss                       44.2566\n",
      "trainer/ZF2 Loss                       50.6711\n",
      "trainer/ZF Expert Reward               14.9435\n",
      "trainer/ZF Policy Reward                1.11717\n",
      "trainer/ZF CHI2 Term                   81.0207\n",
      "trainer/Policy Loss                  -972.649\n",
      "trainer/Bias Loss                     215.206\n",
      "trainer/Bias Value                     18.9363\n",
      "trainer/Policy Grad Norm              341.334\n",
      "trainer/Policy Param Norm              41.485\n",
      "trainer/Zf1 Grad Norm                5912.18\n",
      "trainer/Zf1 Param Norm                133.951\n",
      "trainer/Zf2 Grad Norm                6211.95\n",
      "trainer/Zf2 Param Norm                131.606\n",
      "trainer/Z Expert Predictions Mean    1120.87\n",
      "trainer/Z Expert Predictions Std      123.563\n",
      "trainer/Z Expert Predictions Max     1380.86\n",
      "trainer/Z Expert Predictions Min      422.188\n",
      "trainer/Z Policy Predictions Mean     968.362\n",
      "trainer/Z Policy Predictions Std      306.122\n",
      "trainer/Z Policy Predictions Max     1360.92\n",
      "trainer/Z Policy Predictions Min     -269.702\n",
      "trainer/Z Expert Targets Mean        1105.93\n",
      "trainer/Z Expert Targets Std          125.842\n",
      "trainer/Z Expert Targets Max         1379.18\n",
      "trainer/Z Expert Targets Min          394.562\n",
      "trainer/Z Policy Targets Mean         967.245\n",
      "trainer/Z Policy Targets Std          298.552\n",
      "trainer/Z Policy Targets Max         1357.37\n",
      "trainer/Z Policy Targets Min         -102.417\n",
      "trainer/Log Pis Mean                   19.9297\n",
      "trainer/Log Pis Std                     4.12895\n",
      "trainer/Policy mu Mean                  1.29715\n",
      "trainer/Policy mu Std                   1.79028\n",
      "trainer/Policy log std Mean            -2.21127\n",
      "trainer/Policy log std Std              1.21117\n",
      "trainer/Alpha                           0.204549\n",
      "trainer/Alpha Loss                      0.0143738\n",
      "exploration/num steps total        293561\n",
      "exploration/num paths total           875\n",
      "evaluation/num steps total              2.48127e+06\n",
      "evaluation/num paths total           2899\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12958\n",
      "evaluation/Rewards Std                  1.30168\n",
      "evaluation/Rewards Max                  7.06763\n",
      "evaluation/Rewards Min                  0.0833486\n",
      "evaluation/Returns Mean              5129.58\n",
      "evaluation/Returns Std                 14.8743\n",
      "evaluation/Returns Max               5149.96\n",
      "evaluation/Returns Min               5096.34\n",
      "evaluation/Estimation Bias Mean      1055.11\n",
      "evaluation/Estimation Bias Std        195.353\n",
      "evaluation/EB/Q_True Mean              48.5975\n",
      "evaluation/EB/Q_True Std              150.162\n",
      "evaluation/EB/Q_Pred Mean            1103.71\n",
      "evaluation/EB/Q_Pred Std              131.052\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5129.58\n",
      "evaluation/Actions Mean                 0.509579\n",
      "evaluation/Actions Std                  0.648671\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.12511\n",
      "time/backward_zf1 (s)                   2.33508\n",
      "time/backward_zf2 (s)                   2.21772\n",
      "time/data sampling (s)                  0.307364\n",
      "time/data storing (s)                   0.0172799\n",
      "time/evaluation sampling (s)            1.39537\n",
      "time/exploration sampling (s)           0.210399\n",
      "time/logging (s)                        0.0116811\n",
      "time/preback_alpha (s)                  1.06059\n",
      "time/preback_policy (s)                 1.18298\n",
      "time/preback_start (s)                  0.137671\n",
      "time/preback_zf (s)                     5.39085\n",
      "time/saving (s)                         0.00689705\n",
      "time/training (s)                       2.40271\n",
      "time/epoch (s)                         18.8017\n",
      "time/total (s)                       5165.19\n",
      "Epoch                                 288\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:37:05.547087 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 289 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 300000\n",
      "trainer/ZF1 Loss                       34.2491\n",
      "trainer/ZF2 Loss                       30.9756\n",
      "trainer/ZF Expert Reward               16.6108\n",
      "trainer/ZF Policy Reward                1.00852\n",
      "trainer/ZF CHI2 Term                   68.1183\n",
      "trainer/Policy Loss                  -969.897\n",
      "trainer/Bias Loss                     143.743\n",
      "trainer/Bias Value                     18.924\n",
      "trainer/Policy Grad Norm              304.622\n",
      "trainer/Policy Param Norm              41.5246\n",
      "trainer/Zf1 Grad Norm                9553.73\n",
      "trainer/Zf1 Param Norm                134.08\n",
      "trainer/Zf2 Grad Norm               16166.4\n",
      "trainer/Zf2 Param Norm                131.734\n",
      "trainer/Z Expert Predictions Mean    1114.93\n",
      "trainer/Z Expert Predictions Std      127.809\n",
      "trainer/Z Expert Predictions Max     1378.95\n",
      "trainer/Z Expert Predictions Min      137.549\n",
      "trainer/Z Policy Predictions Mean     968.569\n",
      "trainer/Z Policy Predictions Std      314.536\n",
      "trainer/Z Policy Predictions Max     1337.45\n",
      "trainer/Z Policy Predictions Min     -150.696\n",
      "trainer/Z Expert Targets Mean        1098.32\n",
      "trainer/Z Expert Targets Std          133.977\n",
      "trainer/Z Expert Targets Max         1378.85\n",
      "trainer/Z Expert Targets Min           78.3503\n",
      "trainer/Z Policy Targets Mean         967.561\n",
      "trainer/Z Policy Targets Std          314.067\n",
      "trainer/Z Policy Targets Max         1373.73\n",
      "trainer/Z Policy Targets Min         -158.348\n",
      "trainer/Log Pis Mean                   20.1047\n",
      "trainer/Log Pis Std                     3.86476\n",
      "trainer/Policy mu Mean                  1.26381\n",
      "trainer/Policy mu Std                   1.86048\n",
      "trainer/Policy log std Mean            -2.19551\n",
      "trainer/Policy log std Std              1.21455\n",
      "trainer/Alpha                           0.201205\n",
      "trainer/Alpha Loss                     -0.0210703\n",
      "exploration/num steps total        295561\n",
      "exploration/num paths total           877\n",
      "evaluation/num steps total              2.49127e+06\n",
      "evaluation/num paths total           2909\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1902\n",
      "evaluation/Rewards Std                  1.31342\n",
      "evaluation/Rewards Max                  7.1579\n",
      "evaluation/Rewards Min                  0.119434\n",
      "evaluation/Returns Mean              5190.2\n",
      "evaluation/Returns Std                 18.9747\n",
      "evaluation/Returns Max               5219.5\n",
      "evaluation/Returns Min               5159.79\n",
      "evaluation/Estimation Bias Mean      1102.28\n",
      "evaluation/Estimation Bias Std        175.179\n",
      "evaluation/EB/Q_True Mean              49.1085\n",
      "evaluation/EB/Q_True Std              151.777\n",
      "evaluation/EB/Q_Pred Mean            1151.39\n",
      "evaluation/EB/Q_Pred Std               91.7462\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5190.2\n",
      "evaluation/Actions Mean                 0.512397\n",
      "evaluation/Actions Std                  0.638611\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.17709\n",
      "time/backward_zf1 (s)                   2.40001\n",
      "time/backward_zf2 (s)                   2.27945\n",
      "time/data sampling (s)                  0.317327\n",
      "time/data storing (s)                   0.0165075\n",
      "time/evaluation sampling (s)            1.37691\n",
      "time/exploration sampling (s)           0.216217\n",
      "time/logging (s)                        0.0116736\n",
      "time/preback_alpha (s)                  1.0947\n",
      "time/preback_policy (s)                 1.26427\n",
      "time/preback_start (s)                  0.138631\n",
      "time/preback_zf (s)                     5.39314\n",
      "time/saving (s)                         0.00527314\n",
      "time/training (s)                       2.43238\n",
      "time/epoch (s)                         19.1236\n",
      "time/total (s)                       5184.33\n",
      "Epoch                                 289\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:37:24.731234 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 290 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 301000\n",
      "trainer/ZF1 Loss                       35.3538\n",
      "trainer/ZF2 Loss                       45.8618\n",
      "trainer/ZF Expert Reward               18.0775\n",
      "trainer/ZF Policy Reward                7.41542\n",
      "trainer/ZF CHI2 Term                   70.6721\n",
      "trainer/Policy Loss                  -991.712\n",
      "trainer/Bias Loss                     119.7\n",
      "trainer/Bias Value                     18.9067\n",
      "trainer/Policy Grad Norm              340.423\n",
      "trainer/Policy Param Norm              41.5615\n",
      "trainer/Zf1 Grad Norm                3833.4\n",
      "trainer/Zf1 Param Norm                134.207\n",
      "trainer/Zf2 Grad Norm                6388.62\n",
      "trainer/Zf2 Param Norm                131.858\n",
      "trainer/Z Expert Predictions Mean    1110.14\n",
      "trainer/Z Expert Predictions Std      147.233\n",
      "trainer/Z Expert Predictions Max     1353.71\n",
      "trainer/Z Expert Predictions Min       89.8167\n",
      "trainer/Z Policy Predictions Mean     991.435\n",
      "trainer/Z Policy Predictions Std      283.51\n",
      "trainer/Z Policy Predictions Max     1349.53\n",
      "trainer/Z Policy Predictions Min     -193.562\n",
      "trainer/Z Expert Targets Mean        1092.07\n",
      "trainer/Z Expert Targets Std          153.898\n",
      "trainer/Z Expert Targets Max         1343.42\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         984.02\n",
      "trainer/Z Policy Targets Std          281.746\n",
      "trainer/Z Policy Targets Max         1355.29\n",
      "trainer/Z Policy Targets Min         -212.66\n",
      "trainer/Log Pis Mean                   19.5983\n",
      "trainer/Log Pis Std                     4.39173\n",
      "trainer/Policy mu Mean                  1.29434\n",
      "trainer/Policy mu Std                   1.7832\n",
      "trainer/Policy log std Mean            -2.24494\n",
      "trainer/Policy log std Std              1.21795\n",
      "trainer/Alpha                           0.201269\n",
      "trainer/Alpha Loss                      0.0808623\n",
      "exploration/num steps total        295561\n",
      "exploration/num paths total           877\n",
      "evaluation/num steps total              2.50127e+06\n",
      "evaluation/num paths total           2919\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12206\n",
      "evaluation/Rewards Std                  1.3043\n",
      "evaluation/Rewards Max                  7.04275\n",
      "evaluation/Rewards Min                  0.0783528\n",
      "evaluation/Returns Mean              5122.06\n",
      "evaluation/Returns Std                 28.8463\n",
      "evaluation/Returns Max               5145.05\n",
      "evaluation/Returns Min               5064.72\n",
      "evaluation/Estimation Bias Mean      1102.02\n",
      "evaluation/Estimation Bias Std        181.847\n",
      "evaluation/EB/Q_True Mean              48.6513\n",
      "evaluation/EB/Q_True Std              150.289\n",
      "evaluation/EB/Q_Pred Mean            1150.67\n",
      "evaluation/EB/Q_Pred Std              104.187\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5122.06\n",
      "evaluation/Actions Mean                 0.504347\n",
      "evaluation/Actions Std                  0.644857\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.15257\n",
      "time/backward_zf1 (s)                   2.39233\n",
      "time/backward_zf2 (s)                   2.27785\n",
      "time/data sampling (s)                  0.32859\n",
      "time/data storing (s)                   0.0151497\n",
      "time/evaluation sampling (s)            1.38834\n",
      "time/exploration sampling (s)           0.203675\n",
      "time/logging (s)                        0.0122219\n",
      "time/preback_alpha (s)                  1.06976\n",
      "time/preback_policy (s)                 1.21778\n",
      "time/preback_start (s)                  0.138607\n",
      "time/preback_zf (s)                     5.40126\n",
      "time/saving (s)                         0.00540035\n",
      "time/training (s)                       2.50348\n",
      "time/epoch (s)                         19.107\n",
      "time/total (s)                       5203.46\n",
      "Epoch                                 290\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:37:43.917032 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 291 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 302000\n",
      "trainer/ZF1 Loss                       39.7172\n",
      "trainer/ZF2 Loss                       28.3214\n",
      "trainer/ZF Expert Reward               24.1461\n",
      "trainer/ZF Policy Reward               10.4668\n",
      "trainer/ZF CHI2 Term                   67.5578\n",
      "trainer/Policy Loss                 -1026.93\n",
      "trainer/Bias Loss                     151.993\n",
      "trainer/Bias Value                     18.8909\n",
      "trainer/Policy Grad Norm              275.161\n",
      "trainer/Policy Param Norm              41.5977\n",
      "trainer/Zf1 Grad Norm                4892.84\n",
      "trainer/Zf1 Param Norm                134.319\n",
      "trainer/Zf2 Grad Norm                4031.94\n",
      "trainer/Zf2 Param Norm                131.983\n",
      "trainer/Z Expert Predictions Mean    1129.32\n",
      "trainer/Z Expert Predictions Std      134.702\n",
      "trainer/Z Expert Predictions Max     1382.49\n",
      "trainer/Z Expert Predictions Min      318.111\n",
      "trainer/Z Policy Predictions Mean    1026.69\n",
      "trainer/Z Policy Predictions Std      255.442\n",
      "trainer/Z Policy Predictions Max     1335.81\n",
      "trainer/Z Policy Predictions Min      -69.3785\n",
      "trainer/Z Expert Targets Mean        1105.17\n",
      "trainer/Z Expert Targets Std          134.026\n",
      "trainer/Z Expert Targets Max         1357.45\n",
      "trainer/Z Expert Targets Min          297.294\n",
      "trainer/Z Policy Targets Mean        1016.22\n",
      "trainer/Z Policy Targets Std          249.786\n",
      "trainer/Z Policy Targets Max         1330.15\n",
      "trainer/Z Policy Targets Min          -51.5294\n",
      "trainer/Log Pis Mean                   20.0598\n",
      "trainer/Log Pis Std                     3.83984\n",
      "trainer/Policy mu Mean                  1.27198\n",
      "trainer/Policy mu Std                   1.81715\n",
      "trainer/Policy log std Mean            -2.24338\n",
      "trainer/Policy log std Std              1.22676\n",
      "trainer/Alpha                           0.199402\n",
      "trainer/Alpha Loss                     -0.0119264\n",
      "exploration/num steps total        295561\n",
      "exploration/num paths total           877\n",
      "evaluation/num steps total              2.51127e+06\n",
      "evaluation/num paths total           2929\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12541\n",
      "evaluation/Rewards Std                  1.29733\n",
      "evaluation/Rewards Max                  7.04359\n",
      "evaluation/Rewards Min                  0.096632\n",
      "evaluation/Returns Mean              5125.41\n",
      "evaluation/Returns Std                 17.5778\n",
      "evaluation/Returns Max               5167.28\n",
      "evaluation/Returns Min               5100.23\n",
      "evaluation/Estimation Bias Mean      1075.54\n",
      "evaluation/Estimation Bias Std        191.3\n",
      "evaluation/EB/Q_True Mean              48.4305\n",
      "evaluation/EB/Q_True Std              149.54\n",
      "evaluation/EB/Q_Pred Mean            1123.97\n",
      "evaluation/EB/Q_Pred Std              118.753\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5125.41\n",
      "evaluation/Actions Mean                 0.504986\n",
      "evaluation/Actions Std                  0.643482\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.20833\n",
      "time/backward_zf1 (s)                   2.47217\n",
      "time/backward_zf2 (s)                   2.334\n",
      "time/data sampling (s)                  0.303643\n",
      "time/data storing (s)                   0.0144841\n",
      "time/evaluation sampling (s)            1.45483\n",
      "time/exploration sampling (s)           0.197158\n",
      "time/logging (s)                        0.0123936\n",
      "time/preback_alpha (s)                  1.09117\n",
      "time/preback_policy (s)                 1.24638\n",
      "time/preback_start (s)                  0.134045\n",
      "time/preback_zf (s)                     5.33447\n",
      "time/saving (s)                         0.00537469\n",
      "time/training (s)                       2.30254\n",
      "time/epoch (s)                         19.111\n",
      "time/total (s)                       5222.59\n",
      "Epoch                                 291\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:38:03.011445 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 292 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 303000\n",
      "trainer/ZF1 Loss                       17.7263\n",
      "trainer/ZF2 Loss                       16.2025\n",
      "trainer/ZF Expert Reward               16.6401\n",
      "trainer/ZF Policy Reward                4.06165\n",
      "trainer/ZF CHI2 Term                   49.3052\n",
      "trainer/Policy Loss                 -1004.26\n",
      "trainer/Bias Loss                      85.5937\n",
      "trainer/Bias Value                     18.8757\n",
      "trainer/Policy Grad Norm              255.938\n",
      "trainer/Policy Param Norm              41.6363\n",
      "trainer/Zf1 Grad Norm                3350.19\n",
      "trainer/Zf1 Param Norm                134.446\n",
      "trainer/Zf2 Grad Norm                3622.31\n",
      "trainer/Zf2 Param Norm                132.105\n",
      "trainer/Z Expert Predictions Mean    1114.74\n",
      "trainer/Z Expert Predictions Std      135.816\n",
      "trainer/Z Expert Predictions Max     1361.11\n",
      "trainer/Z Expert Predictions Min      361.911\n",
      "trainer/Z Policy Predictions Mean    1003.15\n",
      "trainer/Z Policy Predictions Std      270.914\n",
      "trainer/Z Policy Predictions Max     1341.57\n",
      "trainer/Z Policy Predictions Min     -108.781\n",
      "trainer/Z Expert Targets Mean        1098.1\n",
      "trainer/Z Expert Targets Std          138.596\n",
      "trainer/Z Expert Targets Max         1342.45\n",
      "trainer/Z Expert Targets Min          331.948\n",
      "trainer/Z Policy Targets Mean         999.089\n",
      "trainer/Z Policy Targets Std          265.496\n",
      "trainer/Z Policy Targets Max         1315.26\n",
      "trainer/Z Policy Targets Min         -113.088\n",
      "trainer/Log Pis Mean                   19.9619\n",
      "trainer/Log Pis Std                     4.16292\n",
      "trainer/Policy mu Mean                  1.22422\n",
      "trainer/Policy mu Std                   1.81821\n",
      "trainer/Policy log std Mean            -2.2678\n",
      "trainer/Policy log std Std              1.19622\n",
      "trainer/Alpha                           0.198497\n",
      "trainer/Alpha Loss                      0.00755644\n",
      "exploration/num steps total        296561\n",
      "exploration/num paths total           878\n",
      "evaluation/num steps total              2.52127e+06\n",
      "evaluation/num paths total           2939\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12\n",
      "evaluation/Rewards Std                  1.29886\n",
      "evaluation/Rewards Max                  7.0192\n",
      "evaluation/Rewards Min                  0.104724\n",
      "evaluation/Returns Mean              5120\n",
      "evaluation/Returns Std                 21.3482\n",
      "evaluation/Returns Max               5152.23\n",
      "evaluation/Returns Min               5082.69\n",
      "evaluation/Estimation Bias Mean      1086.59\n",
      "evaluation/Estimation Bias Std        178.604\n",
      "evaluation/EB/Q_True Mean              48.7034\n",
      "evaluation/EB/Q_True Std              150.412\n",
      "evaluation/EB/Q_Pred Mean            1135.29\n",
      "evaluation/EB/Q_Pred Std               92.3982\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5120\n",
      "evaluation/Actions Mean                 0.505213\n",
      "evaluation/Actions Std                  0.643097\n",
      "evaluation/Actions Max                  0.999975\n",
      "evaluation/Actions Min                 -0.999902\n",
      "time/backward_policy (s)                2.23861\n",
      "time/backward_zf1 (s)                   2.44689\n",
      "time/backward_zf2 (s)                   2.32878\n",
      "time/data sampling (s)                  0.298049\n",
      "time/data storing (s)                   0.0148398\n",
      "time/evaluation sampling (s)            1.40755\n",
      "time/exploration sampling (s)           0.207008\n",
      "time/logging (s)                        0.0120736\n",
      "time/preback_alpha (s)                  1.09813\n",
      "time/preback_policy (s)                 1.25486\n",
      "time/preback_start (s)                  0.134374\n",
      "time/preback_zf (s)                     5.30216\n",
      "time/saving (s)                         0.00530786\n",
      "time/training (s)                       2.27019\n",
      "time/epoch (s)                         19.0188\n",
      "time/total (s)                       5241.63\n",
      "Epoch                                 292\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:38:23.435279 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 293 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 304000\n",
      "trainer/ZF1 Loss                       33.4016\n",
      "trainer/ZF2 Loss                       27.5571\n",
      "trainer/ZF Expert Reward               16.3801\n",
      "trainer/ZF Policy Reward                4.97716\n",
      "trainer/ZF CHI2 Term                   62.0537\n",
      "trainer/Policy Loss                  -998.777\n",
      "trainer/Bias Loss                     120.357\n",
      "trainer/Bias Value                     18.8638\n",
      "trainer/Policy Grad Norm              263.487\n",
      "trainer/Policy Param Norm              41.6745\n",
      "trainer/Zf1 Grad Norm                4873.15\n",
      "trainer/Zf1 Param Norm                134.579\n",
      "trainer/Zf2 Grad Norm                4915.88\n",
      "trainer/Zf2 Param Norm                132.23\n",
      "trainer/Z Expert Predictions Mean    1102.17\n",
      "trainer/Z Expert Predictions Std      145.84\n",
      "trainer/Z Expert Predictions Max     1368.32\n",
      "trainer/Z Expert Predictions Min      164.784\n",
      "trainer/Z Policy Predictions Mean     996.128\n",
      "trainer/Z Policy Predictions Std      274.747\n",
      "trainer/Z Policy Predictions Max     1332.81\n",
      "trainer/Z Policy Predictions Min      -16.2343\n",
      "trainer/Z Expert Targets Mean        1085.79\n",
      "trainer/Z Expert Targets Std          150.378\n",
      "trainer/Z Expert Targets Max         1363.99\n",
      "trainer/Z Expert Targets Min          128.498\n",
      "trainer/Z Policy Targets Mean         991.151\n",
      "trainer/Z Policy Targets Std          272.033\n",
      "trainer/Z Policy Targets Max         1329.74\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   20.3751\n",
      "trainer/Log Pis Std                     4.4297\n",
      "trainer/Policy mu Mean                  1.25813\n",
      "trainer/Policy mu Std                   1.83745\n",
      "trainer/Policy log std Mean            -2.27418\n",
      "trainer/Policy log std Std              1.24828\n",
      "trainer/Alpha                           0.201477\n",
      "trainer/Alpha Loss                     -0.0755765\n",
      "exploration/num steps total        299561\n",
      "exploration/num paths total           881\n",
      "evaluation/num steps total              2.53119e+06\n",
      "evaluation/num paths total           2949\n",
      "evaluation/path length Mean           991.9\n",
      "evaluation/path length Std             24.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            919\n",
      "evaluation/Rewards Mean                 5.12896\n",
      "evaluation/Rewards Std                  1.28659\n",
      "evaluation/Rewards Max                  7.30212\n",
      "evaluation/Rewards Min                  0.147102\n",
      "evaluation/Returns Mean              5087.41\n",
      "evaluation/Returns Std                122.248\n",
      "evaluation/Returns Max               5161.95\n",
      "evaluation/Returns Min               4725.48\n",
      "evaluation/Estimation Bias Mean      1004.59\n",
      "evaluation/Estimation Bias Std        229.348\n",
      "evaluation/EB/Q_True Mean              48.6389\n",
      "evaluation/EB/Q_True Std              149.437\n",
      "evaluation/EB/Q_Pred Mean            1053.23\n",
      "evaluation/EB/Q_Pred Std              162.68\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5087.41\n",
      "evaluation/Actions Mean                 0.498964\n",
      "evaluation/Actions Std                  0.650206\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.39944\n",
      "time/backward_zf1 (s)                   2.6674\n",
      "time/backward_zf2 (s)                   2.54619\n",
      "time/data sampling (s)                  0.346816\n",
      "time/data storing (s)                   0.0196787\n",
      "time/evaluation sampling (s)            1.42332\n",
      "time/exploration sampling (s)           0.242028\n",
      "time/logging (s)                        0.0119101\n",
      "time/preback_alpha (s)                  1.17441\n",
      "time/preback_policy (s)                 1.36565\n",
      "time/preback_start (s)                  0.147091\n",
      "time/preback_zf (s)                     5.58555\n",
      "time/saving (s)                         0.00547164\n",
      "time/training (s)                       2.4117\n",
      "time/epoch (s)                         20.3467\n",
      "time/total (s)                       5261.99\n",
      "Epoch                                 293\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:38:43.368606 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 294 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 305000\n",
      "trainer/ZF1 Loss                       26.4881\n",
      "trainer/ZF2 Loss                       20.0897\n",
      "trainer/ZF Expert Reward               18.2872\n",
      "trainer/ZF Policy Reward                7.34581\n",
      "trainer/ZF CHI2 Term                   54.761\n",
      "trainer/Policy Loss                  -979.512\n",
      "trainer/Bias Loss                     107.062\n",
      "trainer/Bias Value                     18.849\n",
      "trainer/Policy Grad Norm              293.147\n",
      "trainer/Policy Param Norm              41.7127\n",
      "trainer/Zf1 Grad Norm                4452.86\n",
      "trainer/Zf1 Param Norm                134.709\n",
      "trainer/Zf2 Grad Norm                3820.42\n",
      "trainer/Zf2 Param Norm                132.367\n",
      "trainer/Z Expert Predictions Mean    1115.33\n",
      "trainer/Z Expert Predictions Std      138.351\n",
      "trainer/Z Expert Predictions Max     1362.35\n",
      "trainer/Z Expert Predictions Min      378.165\n",
      "trainer/Z Policy Predictions Mean     977.603\n",
      "trainer/Z Policy Predictions Std      315.064\n",
      "trainer/Z Policy Predictions Max     1340.28\n",
      "trainer/Z Policy Predictions Min     -190.09\n",
      "trainer/Z Expert Targets Mean        1097.05\n",
      "trainer/Z Expert Targets Std          141.864\n",
      "trainer/Z Expert Targets Max         1359.42\n",
      "trainer/Z Expert Targets Min          337.251\n",
      "trainer/Z Policy Targets Mean         970.257\n",
      "trainer/Z Policy Targets Std          311.47\n",
      "trainer/Z Policy Targets Max         1341.37\n",
      "trainer/Z Policy Targets Min         -201.902\n",
      "trainer/Log Pis Mean                   20.7381\n",
      "trainer/Log Pis Std                     3.98386\n",
      "trainer/Policy mu Mean                  1.2612\n",
      "trainer/Policy mu Std                   1.89346\n",
      "trainer/Policy log std Mean            -2.25692\n",
      "trainer/Policy log std Std              1.23291\n",
      "trainer/Alpha                           0.20053\n",
      "trainer/Alpha Loss                     -0.148004\n",
      "exploration/num steps total        301312\n",
      "exploration/num paths total           883\n",
      "evaluation/num steps total              2.54093e+06\n",
      "evaluation/num paths total           2959\n",
      "evaluation/path length Mean           973.7\n",
      "evaluation/path length Std             52.8962\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            856\n",
      "evaluation/Rewards Mean                 5.10675\n",
      "evaluation/Rewards Std                  1.31086\n",
      "evaluation/Rewards Max                  7.03372\n",
      "evaluation/Rewards Min                  0.105765\n",
      "evaluation/Returns Mean              4972.44\n",
      "evaluation/Returns Std                323.727\n",
      "evaluation/Returns Max               5158.91\n",
      "evaluation/Returns Min               4268.66\n",
      "evaluation/Estimation Bias Mean      1053.54\n",
      "evaluation/Estimation Bias Std        289.503\n",
      "evaluation/EB/Q_True Mean              49.5977\n",
      "evaluation/EB/Q_True Std              151.03\n",
      "evaluation/EB/Q_Pred Mean            1103.14\n",
      "evaluation/EB/Q_Pred Std              200.112\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4972.44\n",
      "evaluation/Actions Mean                 0.49316\n",
      "evaluation/Actions Std                  0.647637\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.27137\n",
      "time/backward_zf1 (s)                   2.57468\n",
      "time/backward_zf2 (s)                   2.4049\n",
      "time/data sampling (s)                  0.352453\n",
      "time/data storing (s)                   0.0163343\n",
      "time/evaluation sampling (s)            1.4539\n",
      "time/exploration sampling (s)           0.215418\n",
      "time/logging (s)                        0.0123748\n",
      "time/preback_alpha (s)                  1.13092\n",
      "time/preback_policy (s)                 1.28674\n",
      "time/preback_start (s)                  0.14325\n",
      "time/preback_zf (s)                     5.49392\n",
      "time/saving (s)                         0.00529971\n",
      "time/training (s)                       2.49542\n",
      "time/epoch (s)                         19.857\n",
      "time/total (s)                       5281.87\n",
      "Epoch                                 294\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:39:03.256999 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 295 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 306000\n",
      "trainer/ZF1 Loss                       13.04\n",
      "trainer/ZF2 Loss                       23.9322\n",
      "trainer/ZF Expert Reward               16.6868\n",
      "trainer/ZF Policy Reward                4.13604\n",
      "trainer/ZF CHI2 Term                   51.1017\n",
      "trainer/Policy Loss                  -997.109\n",
      "trainer/Bias Loss                     119.204\n",
      "trainer/Bias Value                     18.8351\n",
      "trainer/Policy Grad Norm              301.96\n",
      "trainer/Policy Param Norm              41.7505\n",
      "trainer/Zf1 Grad Norm                4193.18\n",
      "trainer/Zf1 Param Norm                134.834\n",
      "trainer/Zf2 Grad Norm                5515.03\n",
      "trainer/Zf2 Param Norm                132.503\n",
      "trainer/Z Expert Predictions Mean    1101.27\n",
      "trainer/Z Expert Predictions Std      129.938\n",
      "trainer/Z Expert Predictions Max     1391.67\n",
      "trainer/Z Expert Predictions Min      601.373\n",
      "trainer/Z Policy Predictions Mean     992.913\n",
      "trainer/Z Policy Predictions Std      272.42\n",
      "trainer/Z Policy Predictions Max     1348.05\n",
      "trainer/Z Policy Predictions Min     -167.581\n",
      "trainer/Z Expert Targets Mean        1084.58\n",
      "trainer/Z Expert Targets Std          133.184\n",
      "trainer/Z Expert Targets Max         1377.1\n",
      "trainer/Z Expert Targets Min          575.463\n",
      "trainer/Z Policy Targets Mean         988.777\n",
      "trainer/Z Policy Targets Std          272.064\n",
      "trainer/Z Policy Targets Max         1353.34\n",
      "trainer/Z Policy Targets Min         -166.257\n",
      "trainer/Log Pis Mean                   20.2676\n",
      "trainer/Log Pis Std                     3.84585\n",
      "trainer/Policy mu Mean                  1.30703\n",
      "trainer/Policy mu Std                   1.82304\n",
      "trainer/Policy log std Mean            -2.22363\n",
      "trainer/Policy log std Std              1.20128\n",
      "trainer/Alpha                           0.201551\n",
      "trainer/Alpha Loss                     -0.0539251\n",
      "exploration/num steps total        302312\n",
      "exploration/num paths total           884\n",
      "evaluation/num steps total              2.55093e+06\n",
      "evaluation/num paths total           2969\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14098\n",
      "evaluation/Rewards Std                  1.27821\n",
      "evaluation/Rewards Max                  7.079\n",
      "evaluation/Rewards Min                  0.0981312\n",
      "evaluation/Returns Mean              5140.98\n",
      "evaluation/Returns Std                 15.851\n",
      "evaluation/Returns Max               5168.93\n",
      "evaluation/Returns Min               5113.42\n",
      "evaluation/Estimation Bias Mean      1024.05\n",
      "evaluation/Estimation Bias Std        205.839\n",
      "evaluation/EB/Q_True Mean              48.2991\n",
      "evaluation/EB/Q_True Std              149.12\n",
      "evaluation/EB/Q_Pred Mean            1072.35\n",
      "evaluation/EB/Q_Pred Std              148.338\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5140.98\n",
      "evaluation/Actions Mean                 0.493809\n",
      "evaluation/Actions Std                  0.653754\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.27348\n",
      "time/backward_zf1 (s)                   2.51465\n",
      "time/backward_zf2 (s)                   2.38133\n",
      "time/data sampling (s)                  0.356957\n",
      "time/data storing (s)                   0.0162327\n",
      "time/evaluation sampling (s)            1.45416\n",
      "time/exploration sampling (s)           0.211999\n",
      "time/logging (s)                        0.0121338\n",
      "time/preback_alpha (s)                  1.15154\n",
      "time/preback_policy (s)                 1.3135\n",
      "time/preback_start (s)                  0.14296\n",
      "time/preback_zf (s)                     5.51949\n",
      "time/saving (s)                         0.00533072\n",
      "time/training (s)                       2.45882\n",
      "time/epoch (s)                         19.8126\n",
      "time/total (s)                       5301.7\n",
      "Epoch                                 295\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:39:23.320472 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 296 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 307000\n",
      "trainer/ZF1 Loss                       49.4812\n",
      "trainer/ZF2 Loss                       39.2946\n",
      "trainer/ZF Expert Reward               19.2958\n",
      "trainer/ZF Policy Reward                6.20123\n",
      "trainer/ZF CHI2 Term                   76.956\n",
      "trainer/Policy Loss                  -997.857\n",
      "trainer/Bias Loss                     206.847\n",
      "trainer/Bias Value                     18.8214\n",
      "trainer/Policy Grad Norm              278.645\n",
      "trainer/Policy Param Norm              41.7891\n",
      "trainer/Zf1 Grad Norm                6176.54\n",
      "trainer/Zf1 Param Norm                134.98\n",
      "trainer/Zf2 Grad Norm                5847.47\n",
      "trainer/Zf2 Param Norm                132.645\n",
      "trainer/Z Expert Predictions Mean    1117.06\n",
      "trainer/Z Expert Predictions Std      124.308\n",
      "trainer/Z Expert Predictions Max     1373.83\n",
      "trainer/Z Expert Predictions Min      576.269\n",
      "trainer/Z Policy Predictions Mean     995.311\n",
      "trainer/Z Policy Predictions Std      286.539\n",
      "trainer/Z Policy Predictions Max     1365.5\n",
      "trainer/Z Policy Predictions Min     -116.421\n",
      "trainer/Z Expert Targets Mean        1097.76\n",
      "trainer/Z Expert Targets Std          127.834\n",
      "trainer/Z Expert Targets Max         1363.15\n",
      "trainer/Z Expert Targets Min          524.357\n",
      "trainer/Z Policy Targets Mean         989.109\n",
      "trainer/Z Policy Targets Std          281.239\n",
      "trainer/Z Policy Targets Max         1350.82\n",
      "trainer/Z Policy Targets Min         -118.635\n",
      "trainer/Log Pis Mean                   19.6702\n",
      "trainer/Log Pis Std                     4.07155\n",
      "trainer/Policy mu Mean                  1.24918\n",
      "trainer/Policy mu Std                   1.78034\n",
      "trainer/Policy log std Mean            -2.27141\n",
      "trainer/Policy log std Std              1.25635\n",
      "trainer/Alpha                           0.200223\n",
      "trainer/Alpha Loss                      0.0660412\n",
      "exploration/num steps total        303312\n",
      "exploration/num paths total           885\n",
      "evaluation/num steps total              2.56093e+06\n",
      "evaluation/num paths total           2979\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08532\n",
      "evaluation/Rewards Std                  1.28876\n",
      "evaluation/Rewards Max                  6.9452\n",
      "evaluation/Rewards Min                  0.091188\n",
      "evaluation/Returns Mean              5085.32\n",
      "evaluation/Returns Std                 34.2125\n",
      "evaluation/Returns Max               5127.9\n",
      "evaluation/Returns Min               5034.43\n",
      "evaluation/Estimation Bias Mean      1069.59\n",
      "evaluation/Estimation Bias Std        184.905\n",
      "evaluation/EB/Q_True Mean              48.4365\n",
      "evaluation/EB/Q_True Std              149.626\n",
      "evaluation/EB/Q_Pred Mean            1118.03\n",
      "evaluation/EB/Q_Pred Std              120.522\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5085.32\n",
      "evaluation/Actions Mean                 0.501781\n",
      "evaluation/Actions Std                  0.644173\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.34649\n",
      "time/backward_zf1 (s)                   2.59479\n",
      "time/backward_zf2 (s)                   2.47964\n",
      "time/data sampling (s)                  0.358748\n",
      "time/data storing (s)                   0.016804\n",
      "time/evaluation sampling (s)            1.3903\n",
      "time/exploration sampling (s)           0.217566\n",
      "time/logging (s)                        0.0115341\n",
      "time/preback_alpha (s)                  1.16729\n",
      "time/preback_policy (s)                 1.32587\n",
      "time/preback_start (s)                  0.14657\n",
      "time/preback_zf (s)                     5.49046\n",
      "time/saving (s)                         0.00535755\n",
      "time/training (s)                       2.42926\n",
      "time/epoch (s)                         19.9807\n",
      "time/total (s)                       5321.7\n",
      "Epoch                                 296\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:39:43.197939 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 297 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 308000\n",
      "trainer/ZF1 Loss                       32.1001\n",
      "trainer/ZF2 Loss                       33.7426\n",
      "trainer/ZF Expert Reward               15.1046\n",
      "trainer/ZF Policy Reward               -0.0130905\n",
      "trainer/ZF CHI2 Term                   67.975\n",
      "trainer/Policy Loss                  -976.919\n",
      "trainer/Bias Loss                     123.364\n",
      "trainer/Bias Value                     18.8078\n",
      "trainer/Policy Grad Norm              231.659\n",
      "trainer/Policy Param Norm              41.8249\n",
      "trainer/Zf1 Grad Norm                5184.38\n",
      "trainer/Zf1 Param Norm                135.126\n",
      "trainer/Zf2 Grad Norm                5303.88\n",
      "trainer/Zf2 Param Norm                132.785\n",
      "trainer/Z Expert Predictions Mean    1087.71\n",
      "trainer/Z Expert Predictions Std      136.286\n",
      "trainer/Z Expert Predictions Max     1378.26\n",
      "trainer/Z Expert Predictions Min      325.262\n",
      "trainer/Z Policy Predictions Mean     970.625\n",
      "trainer/Z Policy Predictions Std      301.978\n",
      "trainer/Z Policy Predictions Max     1370.83\n",
      "trainer/Z Policy Predictions Min     -269.27\n",
      "trainer/Z Expert Targets Mean        1072.61\n",
      "trainer/Z Expert Targets Std          140.722\n",
      "trainer/Z Expert Targets Max         1368.3\n",
      "trainer/Z Expert Targets Min          319.028\n",
      "trainer/Z Policy Targets Mean         970.638\n",
      "trainer/Z Policy Targets Std          296.853\n",
      "trainer/Z Policy Targets Max         1365.75\n",
      "trainer/Z Policy Targets Min         -284.782\n",
      "trainer/Log Pis Mean                   20.1373\n",
      "trainer/Log Pis Std                     4.05291\n",
      "trainer/Policy mu Mean                  1.25353\n",
      "trainer/Policy mu Std                   1.84089\n",
      "trainer/Policy log std Mean            -2.25273\n",
      "trainer/Policy log std Std              1.22731\n",
      "trainer/Alpha                           0.201974\n",
      "trainer/Alpha Loss                     -0.0277308\n",
      "exploration/num steps total        303312\n",
      "exploration/num paths total           885\n",
      "evaluation/num steps total              2.57093e+06\n",
      "evaluation/num paths total           2989\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13741\n",
      "evaluation/Rewards Std                  1.29144\n",
      "evaluation/Rewards Max                  7.04677\n",
      "evaluation/Rewards Min                  0.130362\n",
      "evaluation/Returns Mean              5137.41\n",
      "evaluation/Returns Std                 16.3595\n",
      "evaluation/Returns Max               5161.79\n",
      "evaluation/Returns Min               5115.21\n",
      "evaluation/Estimation Bias Mean      1098.54\n",
      "evaluation/Estimation Bias Std        178.204\n",
      "evaluation/EB/Q_True Mean              48.7406\n",
      "evaluation/EB/Q_True Std              150.457\n",
      "evaluation/EB/Q_Pred Mean            1147.28\n",
      "evaluation/EB/Q_Pred Std              101.416\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5137.41\n",
      "evaluation/Actions Mean                 0.499518\n",
      "evaluation/Actions Std                  0.645838\n",
      "evaluation/Actions Max                  0.999994\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.30762\n",
      "time/backward_zf1 (s)                   2.55723\n",
      "time/backward_zf2 (s)                   2.47411\n",
      "time/data sampling (s)                  0.339798\n",
      "time/data storing (s)                   0.0176414\n",
      "time/evaluation sampling (s)            1.43862\n",
      "time/exploration sampling (s)           0.217576\n",
      "time/logging (s)                        0.0117794\n",
      "time/preback_alpha (s)                  1.15567\n",
      "time/preback_policy (s)                 1.33555\n",
      "time/preback_start (s)                  0.142112\n",
      "time/preback_zf (s)                     5.45536\n",
      "time/saving (s)                         0.00544423\n",
      "time/training (s)                       2.33858\n",
      "time/epoch (s)                         19.7971\n",
      "time/total (s)                       5341.52\n",
      "Epoch                                 297\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:40:03.289610 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 298 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 309000\n",
      "trainer/ZF1 Loss                       95.2439\n",
      "trainer/ZF2 Loss                       99.157\n",
      "trainer/ZF Expert Reward               17.4279\n",
      "trainer/ZF Policy Reward                3.38569\n",
      "trainer/ZF CHI2 Term                  130.972\n",
      "trainer/Policy Loss                  -940.309\n",
      "trainer/Bias Loss                     711.968\n",
      "trainer/Bias Value                     18.7954\n",
      "trainer/Policy Grad Norm              284.935\n",
      "trainer/Policy Param Norm              41.8637\n",
      "trainer/Zf1 Grad Norm                9902.4\n",
      "trainer/Zf1 Param Norm                135.265\n",
      "trainer/Zf2 Grad Norm               10815.7\n",
      "trainer/Zf2 Param Norm                132.909\n",
      "trainer/Z Expert Predictions Mean    1099.99\n",
      "trainer/Z Expert Predictions Std      147.918\n",
      "trainer/Z Expert Predictions Max     1380.65\n",
      "trainer/Z Expert Predictions Min      154.177\n",
      "trainer/Z Policy Predictions Mean     933.745\n",
      "trainer/Z Policy Predictions Std      337.326\n",
      "trainer/Z Policy Predictions Max     1391.77\n",
      "trainer/Z Policy Predictions Min     -294.458\n",
      "trainer/Z Expert Targets Mean        1082.56\n",
      "trainer/Z Expert Targets Std          148.241\n",
      "trainer/Z Expert Targets Max         1366.48\n",
      "trainer/Z Expert Targets Min          171.623\n",
      "trainer/Z Policy Targets Mean         930.36\n",
      "trainer/Z Policy Targets Std          336.904\n",
      "trainer/Z Policy Targets Max         1377.85\n",
      "trainer/Z Policy Targets Min         -282.981\n",
      "trainer/Log Pis Mean                   19.9283\n",
      "trainer/Log Pis Std                     4.2622\n",
      "trainer/Policy mu Mean                  1.24572\n",
      "trainer/Policy mu Std                   1.85247\n",
      "trainer/Policy log std Mean            -2.22166\n",
      "trainer/Policy log std Std              1.26408\n",
      "trainer/Alpha                           0.201373\n",
      "trainer/Alpha Loss                      0.0144464\n",
      "exploration/num steps total        303312\n",
      "exploration/num paths total           885\n",
      "evaluation/num steps total              2.58002e+06\n",
      "evaluation/num paths total           2999\n",
      "evaluation/path length Mean           909.7\n",
      "evaluation/path length Std            185.479\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            454\n",
      "evaluation/Rewards Mean                 5.09036\n",
      "evaluation/Rewards Std                  1.34508\n",
      "evaluation/Rewards Max                  7.10317\n",
      "evaluation/Rewards Min                  0.0972593\n",
      "evaluation/Returns Mean              4630.7\n",
      "evaluation/Returns Std               1046.9\n",
      "evaluation/Returns Max               5183.33\n",
      "evaluation/Returns Min               2085.88\n",
      "evaluation/Estimation Bias Mean       998.215\n",
      "evaluation/Estimation Bias Std        284.695\n",
      "evaluation/EB/Q_True Mean              53.5579\n",
      "evaluation/EB/Q_True Std              156.9\n",
      "evaluation/EB/Q_Pred Mean            1051.77\n",
      "evaluation/EB/Q_Pred Std              208.495\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4630.7\n",
      "evaluation/Actions Mean                 0.496062\n",
      "evaluation/Actions Std                  0.647904\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.3258\n",
      "time/backward_zf1 (s)                   2.62513\n",
      "time/backward_zf2 (s)                   2.46639\n",
      "time/data sampling (s)                  0.332916\n",
      "time/data storing (s)                   0.0174166\n",
      "time/evaluation sampling (s)            1.41743\n",
      "time/exploration sampling (s)           0.220442\n",
      "time/logging (s)                        0.0108962\n",
      "time/preback_alpha (s)                  1.14084\n",
      "time/preback_policy (s)                 1.32373\n",
      "time/preback_start (s)                  0.144268\n",
      "time/preback_zf (s)                     5.53454\n",
      "time/saving (s)                         0.00534519\n",
      "time/training (s)                       2.4454\n",
      "time/epoch (s)                         20.0105\n",
      "time/total (s)                       5361.56\n",
      "Epoch                                 298\n",
      "---------------------------------  ----------------\n",
      "2024-06-18 18:40:23.277522 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_18_17_10_29_0000--s-0] Epoch 299 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 310000\n",
      "trainer/ZF1 Loss                       23.1252\n",
      "trainer/ZF2 Loss                       20.6276\n",
      "trainer/ZF Expert Reward               17.8115\n",
      "trainer/ZF Policy Reward                2.33151\n",
      "trainer/ZF CHI2 Term                   57.1595\n",
      "trainer/Policy Loss                  -958.645\n",
      "trainer/Bias Loss                      99.2718\n",
      "trainer/Bias Value                     18.7805\n",
      "trainer/Policy Grad Norm              274.6\n",
      "trainer/Policy Param Norm              41.9002\n",
      "trainer/Zf1 Grad Norm                2775.57\n",
      "trainer/Zf1 Param Norm                135.407\n",
      "trainer/Zf2 Grad Norm                3948.93\n",
      "trainer/Zf2 Param Norm                133.053\n",
      "trainer/Z Expert Predictions Mean    1086.84\n",
      "trainer/Z Expert Predictions Std      160.035\n",
      "trainer/Z Expert Predictions Max     1367.1\n",
      "trainer/Z Expert Predictions Min       75.0231\n",
      "trainer/Z Policy Predictions Mean     955.831\n",
      "trainer/Z Policy Predictions Std      324.762\n",
      "trainer/Z Policy Predictions Max     1372.81\n",
      "trainer/Z Policy Predictions Min     -238.303\n",
      "trainer/Z Expert Targets Mean        1069.03\n",
      "trainer/Z Expert Targets Std          163.742\n",
      "trainer/Z Expert Targets Max         1336.6\n",
      "trainer/Z Expert Targets Min           38.3303\n",
      "trainer/Z Policy Targets Mean         953.499\n",
      "trainer/Z Policy Targets Std          318.476\n",
      "trainer/Z Policy Targets Max         1364.73\n",
      "trainer/Z Policy Targets Min         -222.561\n",
      "trainer/Log Pis Mean                   20.0032\n",
      "trainer/Log Pis Std                     3.85123\n",
      "trainer/Policy mu Mean                  1.25929\n",
      "trainer/Policy mu Std                   1.8509\n",
      "trainer/Policy log std Mean            -2.24546\n",
      "trainer/Policy log std Std              1.25893\n",
      "trainer/Alpha                           0.201314\n",
      "trainer/Alpha Loss                     -0.000634508\n",
      "exploration/num steps total        305312\n",
      "exploration/num paths total           887\n",
      "evaluation/num steps total              2.59002e+06\n",
      "evaluation/num paths total           3009\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10744\n",
      "evaluation/Rewards Std                  1.28729\n",
      "evaluation/Rewards Max                  7.05609\n",
      "evaluation/Rewards Min                  0.0900361\n",
      "evaluation/Returns Mean              5107.44\n",
      "evaluation/Returns Std                 24.4938\n",
      "evaluation/Returns Max               5149.36\n",
      "evaluation/Returns Min               5072.72\n",
      "evaluation/Estimation Bias Mean      1000.79\n",
      "evaluation/Estimation Bias Std        198.09\n",
      "evaluation/EB/Q_True Mean              48.6728\n",
      "evaluation/EB/Q_True Std              150.47\n",
      "evaluation/EB/Q_Pred Mean            1049.46\n",
      "evaluation/EB/Q_Pred Std              124.58\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5107.44\n",
      "evaluation/Actions Mean                 0.500831\n",
      "evaluation/Actions Std                  0.649349\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.27261\n",
      "time/backward_zf1 (s)                   2.54266\n",
      "time/backward_zf2 (s)                   2.40394\n",
      "time/data sampling (s)                  0.376538\n",
      "time/data storing (s)                   0.0190902\n",
      "time/evaluation sampling (s)            1.40073\n",
      "time/exploration sampling (s)           0.235845\n",
      "time/logging (s)                        0.0118103\n",
      "time/preback_alpha (s)                  1.15844\n",
      "time/preback_policy (s)                 1.29349\n",
      "time/preback_start (s)                  0.148191\n",
      "time/preback_zf (s)                     5.54307\n",
      "time/saving (s)                         0.00568252\n",
      "time/training (s)                       2.49505\n",
      "time/epoch (s)                         19.9071\n",
      "time/total (s)                       5381.49\n",
      "Epoch                                 299\n",
      "---------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    experiment(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef637655-3ec8-463e-bb7c-cb684dedd835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

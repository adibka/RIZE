{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd095125-6be1-4c22-8760-d1fba60ab86d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## experiment (tqc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603bc9d-5ced-4410-9d8b-bc74345fd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_tqc(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant['layer_size']\n",
    "    num_quantiles = variant['num_quantiles']\n",
    "    n_nets = variant['n_nets']\n",
    "    \n",
    "    zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    target_zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = TruncIDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        zf=zf,\n",
    "        target_zf=target_zf,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b40f96-5af4-4fc9-8f5d-34bacdc440d8",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df783e4e-ddf6-45d9-8b26-6863e89107f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.data_management.torch_replay_buffer import TorchReplayBuffer\n",
    "from rlkit.envs import make_env\n",
    "from rlkit.envs.vecenv import SubprocVectorEnv, VectorEnv\n",
    "from rlkit.launchers.launcher_util import set_seed, setup_logger\n",
    "from rlkit.samplers.data_collector import (VecMdpPathCollector, VecMdpStepCollector)\n",
    "from rlkit.torch.idsac.idsac import IDSACTrainer\n",
    "from rlkit.torch.idsac.networks import QuantileMlp, Critic, softmax\n",
    "from rlkit.torch.networks import FlattenMlp\n",
    "from rlkit.torch.sac.policies import MakeDeterministic, TanhGaussianPolicy\n",
    "from rlkit.torch.torch_iq_algorithm import TorchVecOnlineIQAlgorithm\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba84c8-f8f8-4272-8885-83a6c028ee37",
   "metadata": {},
   "source": [
    "# experiment (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c847e24-53fa-4f9b-850b-c7b648d30304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant[\"layer_size\"]\n",
    "    num_quantiles = variant[\"num_quantiles\"]\n",
    "    tau_type = variant[\"trainer_kwargs\"][\"tau_type\"]\n",
    "    \n",
    "    zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M // 2],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    target_policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M // 2],\n",
    "    )\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "        zf1,\n",
    "        tau_type,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = IDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        target_policy=target_policy,\n",
    "        zf1=zf1,\n",
    "        zf2=zf2,\n",
    "        target_zf1=target_zf1,\n",
    "        target_zf2=target_zf2,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e380543-9ff2-4947-8cda-2f5b05957627",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fa2c3c-ae22-4830-bad1-8b99032cb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(dsac_cfg_path,\n",
    "               expert_path,\n",
    "               iq_cfg_path='configs/dsac-normal-iqn-neutral/iq.yaml',\n",
    "               cql_cfg_path='configs/dsac-normal-iqn-neutral/cql.yaml'\n",
    "              ):\n",
    "    \n",
    "    with open(dsac_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        variant = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    with open(iq_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        iq_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    with open(cql_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        cql_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    iq_cfg['expert_path'] = expert_path\n",
    "    variant['iq_kwargs'] = iq_cfg\n",
    "    variant['cql_kwargs'] = cql_cfg\n",
    "    return variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40faac3-2a8c-49fc-bece-f891df61d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = get_config(dsac_cfg_path='configs/dsac-normal-iqn-neutral/ant.yaml',\n",
    "                     expert_path='experts/Ant-v2_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00203431-e8bc-4e42-977f-298ec40d51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-10 20:36:09.647462 +0330 | Variant:\n",
      "2024-06-10 20:36:09.649086 +0330 | {\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"min_num_steps_before_training\": 10000,\n",
      "    \"num_epochs\": 300,\n",
      "    \"num_eval_paths_per_epoch\": 10,\n",
      "    \"num_expl_steps_per_train_loop\": 1000,\n",
      "    \"num_trains_per_train_loop\": 1000\n",
      "  },\n",
      "  \"env\": \"Ant-v2\",\n",
      "  \"seed\": 0,\n",
      "  \"expectation_z\": false,\n",
      "  \"eval_env_num\": 10,\n",
      "  \"expl_env_num\": 10,\n",
      "  \"layer_size\": 256,\n",
      "  \"num_quantiles\": 24,\n",
      "  \"replay_buffer_size\": 1000000,\n",
      "  \"trainer_kwargs\": {\n",
      "    \"alpha\": 0.01,\n",
      "    \"discount\": 0.99,\n",
      "    \"policy_lr\": 7.5e-05,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"tau_type\": \"iqn\",\n",
      "    \"use_automatic_entropy_tuning\": false,\n",
      "    \"zf_lr\": 0.0003,\n",
      "    \"bias\": 5,\n",
      "    \"bias_lr\": 0.001,\n",
      "    \"use_automatic_bias_tuning\": true\n",
      "  },\n",
      "  \"version\": \"normal-iqn-neutral\",\n",
      "  \"iq_kwargs\": {\n",
      "    \"expert_path\": \"experts/Ant-v2_25.pkl\",\n",
      "    \"subsample_freq\": 1,\n",
      "    \"demos\": 10,\n",
      "    \"regularize\": true,\n",
      "    \"div\": null,\n",
      "    \"loss\": \"value_policy\",\n",
      "    \"alpha\": 2.5\n",
      "  },\n",
      "  \"cql_kwargs\": {\n",
      "    \"use_cql\": false,\n",
      "    \"cql_weight\": 0.05,\n",
      "    \"num_random\": 10,\n",
      "    \"with_lagrange\": false,\n",
      "    \"lagrange_thresh\": 10.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    ptu.set_gpu_mode(True, 0)\n",
    "    # device = torch.device('cuda:0')\n",
    "seed = variant[\"seed\"]\n",
    "set_seed(seed)\n",
    "log_prefix = \"_\".join([\"idsac\", variant[\"env\"][:-3].lower(), str(variant[\"version\"])])\n",
    "setup_logger(log_prefix, variant=variant, seed=seed)\n",
    "variant[\"device\"] = ptu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9e0ac-93fd-4003-bfd1-29f851badba5",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa21b2b4-9bf0-4965-91a7-ff8ca706fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddie/venvs/IQ/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-10 20:36:32.060121 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 0 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 11000\n",
      "trainer/ZF1 Loss                       6.63922\n",
      "trainer/ZF2 Loss                       6.48249\n",
      "trainer/ZF Expert Reward               0.452431\n",
      "trainer/ZF Policy Reward               0.599272\n",
      "trainer/ZF CHI2 Term                   1.11882\n",
      "trainer/Policy Loss                   -0.00745451\n",
      "trainer/Bias Loss                     10.3762\n",
      "trainer/Bias Value                     4.999\n",
      "trainer/Policy Grad Norm               0.059052\n",
      "trainer/Policy Param Norm             14.6355\n",
      "trainer/Zf1 Grad Norm                 11.3205\n",
      "trainer/Zf1 Param Norm                32.0301\n",
      "trainer/Zf2 Grad Norm                 15.1294\n",
      "trainer/Zf2 Param Norm                32.0622\n",
      "trainer/Z Expert Predictions Mean      0.0583173\n",
      "trainer/Z Expert Predictions Std       0.16814\n",
      "trainer/Z Expert Predictions Max       0.775428\n",
      "trainer/Z Expert Predictions Min      -0.433509\n",
      "trainer/Z Policy Predictions Mean      0.183843\n",
      "trainer/Z Policy Predictions Std       0.247221\n",
      "trainer/Z Policy Predictions Max       1.0056\n",
      "trainer/Z Policy Predictions Min      -0.524552\n",
      "trainer/Z Expert Targets Mean         -0.394114\n",
      "trainer/Z Expert Targets Std           0.231924\n",
      "trainer/Z Expert Targets Max           0.34404\n",
      "trainer/Z Expert Targets Min          -1.17556\n",
      "trainer/Z Policy Targets Mean         -0.415429\n",
      "trainer/Z Policy Targets Std           0.263218\n",
      "trainer/Z Policy Targets Max           0.52437\n",
      "trainer/Z Policy Targets Min          -1.24537\n",
      "trainer/Log Pis Mean                  -5.34868\n",
      "trainer/Log Pis Std                    0.610679\n",
      "trainer/Policy mu Mean                -0.000322863\n",
      "trainer/Policy mu Std                  0.00143032\n",
      "trainer/Policy log std Mean            0.000234186\n",
      "trainer/Policy log std Std             0.00086459\n",
      "exploration/num steps total         7777\n",
      "exploration/num paths total           82\n",
      "evaluation/num steps total         10000\n",
      "evaluation/num paths total            10\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                0.461529\n",
      "evaluation/Rewards Std                 0.230243\n",
      "evaluation/Rewards Max                 1.93705\n",
      "evaluation/Rewards Min                -3.50476\n",
      "evaluation/Returns Mean              461.529\n",
      "evaluation/Returns Std                55.4054\n",
      "evaluation/Returns Max               520.56\n",
      "evaluation/Returns Min               328.329\n",
      "evaluation/Estimation Bias Mean      -46.6139\n",
      "evaluation/Estimation Bias Std        17.9456\n",
      "evaluation/EB/Q_True Mean              4.60475\n",
      "evaluation/EB/Q_True Std              14.2345\n",
      "evaluation/EB/Q_Pred Mean            -42.0091\n",
      "evaluation/EB/Q_Pred Std              11.1568\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           461.529\n",
      "evaluation/Actions Mean               -0.0544541\n",
      "evaluation/Actions Std                 0.372612\n",
      "evaluation/Actions Max                 0.998578\n",
      "evaluation/Actions Min                -0.999164\n",
      "time/backward_policy (s)               1.7085\n",
      "time/backward_zf1 (s)                  1.82703\n",
      "time/backward_zf2 (s)                  1.77109\n",
      "time/data sampling (s)                 0.210504\n",
      "time/data storing (s)                  0.0141786\n",
      "time/evaluation sampling (s)           1.861\n",
      "time/exploration sampling (s)          0.672659\n",
      "time/logging (s)                       0.0116775\n",
      "time/preback_alpha (s)                 0.542868\n",
      "time/preback_policy (s)                0.999864\n",
      "time/preback_start (s)                 0.139975\n",
      "time/preback_zf (s)                    5.02003\n",
      "time/saving (s)                        0.00507544\n",
      "time/training (s)                      2.34382\n",
      "time/epoch (s)                        17.1283\n",
      "time/total (s)                        24.8364\n",
      "Epoch                                  0\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:36:49.137917 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 1 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 12000\n",
      "trainer/ZF1 Loss                     -27.7775\n",
      "trainer/ZF2 Loss                     -27.7926\n",
      "trainer/ZF Expert Reward              13.6877\n",
      "trainer/ZF Policy Reward              -9.34162\n",
      "trainer/ZF CHI2 Term                   8.46995\n",
      "trainer/Policy Loss                   41.0424\n",
      "trainer/Bias Loss                     29.4468\n",
      "trainer/Bias Value                     6.16815\n",
      "trainer/Policy Grad Norm               2.96303\n",
      "trainer/Policy Param Norm             15.7821\n",
      "trainer/Zf1 Grad Norm                 26.7978\n",
      "trainer/Zf1 Param Norm                34.4946\n",
      "trainer/Zf2 Grad Norm                 22.7899\n",
      "trainer/Zf2 Param Norm                34.4768\n",
      "trainer/Z Expert Predictions Mean     60.8043\n",
      "trainer/Z Expert Predictions Std       4.74934\n",
      "trainer/Z Expert Predictions Max      61.3651\n",
      "trainer/Z Expert Predictions Min      -0.153634\n",
      "trainer/Z Policy Predictions Mean    -43.4353\n",
      "trainer/Z Policy Predictions Std       8.6836\n",
      "trainer/Z Policy Predictions Max      41.4372\n",
      "trainer/Z Policy Predictions Min     -46.1987\n",
      "trainer/Z Expert Targets Mean         47.1166\n",
      "trainer/Z Expert Targets Std           4.4607\n",
      "trainer/Z Expert Targets Max          47.7857\n",
      "trainer/Z Expert Targets Min         -16.1481\n",
      "trainer/Z Policy Targets Mean        -34.0936\n",
      "trainer/Z Policy Targets Std           9.16049\n",
      "trainer/Z Policy Targets Max          36.9811\n",
      "trainer/Z Policy Targets Min         -37.2485\n",
      "trainer/Log Pis Mean                  13.3593\n",
      "trainer/Log Pis Std                    9.0736\n",
      "trainer/Policy mu Mean                 0.115042\n",
      "trainer/Policy mu Std                  1.38299\n",
      "trainer/Policy log std Mean           -1.76736\n",
      "trainer/Policy log std Std             0.683083\n",
      "exploration/num steps total         9548\n",
      "exploration/num paths total           88\n",
      "evaluation/num steps total         18272\n",
      "evaluation/num paths total            22\n",
      "evaluation/path length Mean          689.333\n",
      "evaluation/path length Std           440.673\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            21\n",
      "evaluation/Rewards Mean                0.394641\n",
      "evaluation/Rewards Std                 0.476817\n",
      "evaluation/Rewards Max                 4.75499\n",
      "evaluation/Rewards Min                -3.1393\n",
      "evaluation/Returns Mean              272.039\n",
      "evaluation/Returns Std               202.116\n",
      "evaluation/Returns Max               596.903\n",
      "evaluation/Returns Min                12.1983\n",
      "evaluation/Estimation Bias Mean      -42.779\n",
      "evaluation/Estimation Bias Std        38.062\n",
      "evaluation/EB/Q_True Mean              5.3581\n",
      "evaluation/EB/Q_True Std              14.9073\n",
      "evaluation/EB/Q_Pred Mean            -37.4209\n",
      "evaluation/EB/Q_Pred Std              38.8017\n",
      "evaluation/Num Paths                  12\n",
      "evaluation/Average Returns           272.039\n",
      "evaluation/Actions Mean                0.0770381\n",
      "evaluation/Actions Std                 0.41663\n",
      "evaluation/Actions Max                 0.999638\n",
      "evaluation/Actions Min                -0.994255\n",
      "time/backward_policy (s)               1.79963\n",
      "time/backward_zf1 (s)                  1.90436\n",
      "time/backward_zf2 (s)                  1.83821\n",
      "time/data sampling (s)                 0.239541\n",
      "time/data storing (s)                  0.0137118\n",
      "time/evaluation sampling (s)           1.8266\n",
      "time/exploration sampling (s)          0.336164\n",
      "time/logging (s)                       0.00986581\n",
      "time/preback_alpha (s)                 0.546737\n",
      "time/preback_policy (s)                1.05627\n",
      "time/preback_start (s)                 0.140641\n",
      "time/preback_zf (s)                    5.02191\n",
      "time/saving (s)                        0.00741047\n",
      "time/training (s)                      2.26878\n",
      "time/epoch (s)                        17.0098\n",
      "time/total (s)                        41.867\n",
      "Epoch                                  1\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:37:06.910192 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 2 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 13000\n",
      "trainer/ZF1 Loss                     -34.5047\n",
      "trainer/ZF2 Loss                     -34.7025\n",
      "trainer/ZF Expert Reward              16.0927\n",
      "trainer/ZF Policy Reward             -10.5818\n",
      "trainer/ZF CHI2 Term                  14.4074\n",
      "trainer/Policy Loss                   54.6166\n",
      "trainer/Bias Loss                     39.6755\n",
      "trainer/Bias Value                     7.33535\n",
      "trainer/Policy Grad Norm               9.69159\n",
      "trainer/Policy Param Norm             16.9185\n",
      "trainer/Zf1 Grad Norm                111.014\n",
      "trainer/Zf1 Param Norm                37.3169\n",
      "trainer/Zf2 Grad Norm                103.728\n",
      "trainer/Zf2 Param Norm                37.2468\n",
      "trainer/Z Expert Predictions Mean    128.987\n",
      "trainer/Z Expert Predictions Std      11.2211\n",
      "trainer/Z Expert Predictions Max     130.864\n",
      "trainer/Z Expert Predictions Min      -5.75158\n",
      "trainer/Z Policy Predictions Mean    -64.5135\n",
      "trainer/Z Policy Predictions Std      29.5846\n",
      "trainer/Z Policy Predictions Max     120.067\n",
      "trainer/Z Policy Predictions Min     -86.2698\n",
      "trainer/Z Expert Targets Mean        112.894\n",
      "trainer/Z Expert Targets Std          11.1825\n",
      "trainer/Z Expert Targets Max         114.816\n",
      "trainer/Z Expert Targets Min         -35.4958\n",
      "trainer/Z Policy Targets Mean        -53.9317\n",
      "trainer/Z Policy Targets Std          29.9639\n",
      "trainer/Z Policy Targets Max         110.97\n",
      "trainer/Z Policy Targets Min         -77.9473\n",
      "trainer/Log Pis Mean                  22.5621\n",
      "trainer/Log Pis Std                    8.21314\n",
      "trainer/Policy mu Mean                 0.337079\n",
      "trainer/Policy mu Std                  1.91777\n",
      "trainer/Policy log std Mean           -2.18736\n",
      "trainer/Policy log std Std             0.881021\n",
      "exploration/num steps total        11039\n",
      "exploration/num paths total           94\n",
      "evaluation/num steps total         26323\n",
      "evaluation/num paths total            33\n",
      "evaluation/path length Mean          731.909\n",
      "evaluation/path length Std           437.836\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min             8\n",
      "evaluation/Rewards Mean                0.220621\n",
      "evaluation/Rewards Std                 0.643908\n",
      "evaluation/Rewards Max                 3.12337\n",
      "evaluation/Rewards Min                -2.71556\n",
      "evaluation/Returns Mean              161.475\n",
      "evaluation/Returns Std               482.84\n",
      "evaluation/Returns Max               604.782\n",
      "evaluation/Returns Min             -1111.21\n",
      "evaluation/Estimation Bias Mean      -30.4722\n",
      "evaluation/Estimation Bias Std        53.234\n",
      "evaluation/EB/Q_True Mean              5.68996\n",
      "evaluation/EB/Q_True Std              15.6926\n",
      "evaluation/EB/Q_Pred Mean            -24.7822\n",
      "evaluation/EB/Q_Pred Std              45.7533\n",
      "evaluation/Num Paths                  11\n",
      "evaluation/Average Returns           161.475\n",
      "evaluation/Actions Mean                0.102811\n",
      "evaluation/Actions Std                 0.439062\n",
      "evaluation/Actions Max                 0.998803\n",
      "evaluation/Actions Min                -0.997965\n",
      "time/backward_policy (s)               1.84763\n",
      "time/backward_zf1 (s)                  2.00098\n",
      "time/backward_zf2 (s)                  1.93628\n",
      "time/data sampling (s)                 0.286114\n",
      "time/data storing (s)                  0.0157049\n",
      "time/evaluation sampling (s)           1.81868\n",
      "time/exploration sampling (s)          0.375842\n",
      "time/logging (s)                       0.0124688\n",
      "time/preback_alpha (s)                 0.582422\n",
      "time/preback_policy (s)                1.07822\n",
      "time/preback_start (s)                 0.148933\n",
      "time/preback_zf (s)                    5.18604\n",
      "time/saving (s)                        0.00622477\n",
      "time/training (s)                      2.40484\n",
      "time/epoch (s)                        17.7004\n",
      "time/total (s)                        59.5948\n",
      "Epoch                                  2\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:37:22.574950 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 3 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 14000\n",
      "trainer/ZF1 Loss                     -31.0692\n",
      "trainer/ZF2 Loss                     -32.0068\n",
      "trainer/ZF Expert Reward              17.4112\n",
      "trainer/ZF Policy Reward             -10.9212\n",
      "trainer/ZF CHI2 Term                  17.5723\n",
      "trainer/Policy Loss                   42.4943\n",
      "trainer/Bias Loss                     43.8346\n",
      "trainer/Bias Value                     8.41516\n",
      "trainer/Policy Grad Norm              28.2598\n",
      "trainer/Policy Param Norm             17.6366\n",
      "trainer/Zf1 Grad Norm                221.372\n",
      "trainer/Zf1 Param Norm                39.9285\n",
      "trainer/Zf2 Grad Norm                186.691\n",
      "trainer/Zf2 Param Norm                39.8403\n",
      "trainer/Z Expert Predictions Mean    200.877\n",
      "trainer/Z Expert Predictions Std      11.8578\n",
      "trainer/Z Expert Predictions Max     204.163\n",
      "trainer/Z Expert Predictions Min      71.9759\n",
      "trainer/Z Policy Predictions Mean    -54.5649\n",
      "trainer/Z Policy Predictions Std      51.2314\n",
      "trainer/Z Policy Predictions Max     127.791\n",
      "trainer/Z Policy Predictions Min    -116.196\n",
      "trainer/Z Expert Targets Mean        183.465\n",
      "trainer/Z Expert Targets Std          11.2509\n",
      "trainer/Z Expert Targets Max         186.761\n",
      "trainer/Z Expert Targets Min          45.6552\n",
      "trainer/Z Policy Targets Mean        -43.6437\n",
      "trainer/Z Policy Targets Std          52.8877\n",
      "trainer/Z Policy Targets Max         130.188\n",
      "trainer/Z Policy Targets Min        -109.881\n",
      "trainer/Log Pis Mean                  20.9878\n",
      "trainer/Log Pis Std                    6.91164\n",
      "trainer/Policy mu Mean                 0.526513\n",
      "trainer/Policy mu Std                  1.41632\n",
      "trainer/Policy log std Mean           -2.61174\n",
      "trainer/Policy log std Std             0.97497\n",
      "exploration/num steps total        11068\n",
      "exploration/num paths total           95\n",
      "evaluation/num steps total         26435\n",
      "evaluation/num paths total            43\n",
      "evaluation/path length Mean           11.2\n",
      "evaluation/path length Std             3.45832\n",
      "evaluation/path length Max            18\n",
      "evaluation/path length Min             8\n",
      "evaluation/Rewards Mean                0.482423\n",
      "evaluation/Rewards Std                 1.14829\n",
      "evaluation/Rewards Max                 2.70754\n",
      "evaluation/Rewards Min                -1.69476\n",
      "evaluation/Returns Mean                5.40314\n",
      "evaluation/Returns Std                 6.40813\n",
      "evaluation/Returns Max                21.7217\n",
      "evaluation/Returns Min                -0.586864\n",
      "evaluation/Estimation Bias Mean      143.392\n",
      "evaluation/Estimation Bias Std        36.6945\n",
      "evaluation/EB/Q_True Mean              0.870016\n",
      "evaluation/EB/Q_True Std               2.7642\n",
      "evaluation/EB/Q_Pred Mean            144.262\n",
      "evaluation/EB/Q_Pred Std              37.022\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns             5.40314\n",
      "evaluation/Actions Mean                0.0721574\n",
      "evaluation/Actions Std                 0.588267\n",
      "evaluation/Actions Max                 0.974372\n",
      "evaluation/Actions Min                -0.981575\n",
      "time/backward_policy (s)               1.82247\n",
      "time/backward_zf1 (s)                  1.96214\n",
      "time/backward_zf2 (s)                  1.8706\n",
      "time/data sampling (s)                 0.286858\n",
      "time/data storing (s)                  0.0138961\n",
      "time/evaluation sampling (s)           0.114195\n",
      "time/exploration sampling (s)          0.345515\n",
      "time/logging (s)                       0.00147124\n",
      "time/preback_alpha (s)                 0.566234\n",
      "time/preback_policy (s)                1.05768\n",
      "time/preback_start (s)                 0.144289\n",
      "time/preback_zf (s)                    5.07825\n",
      "time/saving (s)                        0.00561302\n",
      "time/training (s)                      2.31625\n",
      "time/epoch (s)                        15.5855\n",
      "time/total (s)                        75.2025\n",
      "Epoch                                  3\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:37:39.660764 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 4 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 15000\n",
      "trainer/ZF1 Loss                     -30.4095\n",
      "trainer/ZF2 Loss                     -29.9283\n",
      "trainer/ZF Expert Reward              18.7671\n",
      "trainer/ZF Policy Reward             -10.062\n",
      "trainer/ZF CHI2 Term                  19.3377\n",
      "trainer/Policy Loss                   37.9322\n",
      "trainer/Bias Loss                     47.4022\n",
      "trainer/Bias Value                     9.45673\n",
      "trainer/Policy Grad Norm              23.4493\n",
      "trainer/Policy Param Norm             18.2421\n",
      "trainer/Zf1 Grad Norm                232.823\n",
      "trainer/Zf1 Param Norm                42.2631\n",
      "trainer/Zf2 Grad Norm                263.496\n",
      "trainer/Zf2 Param Norm                42.1277\n",
      "trainer/Z Expert Predictions Mean    273.123\n",
      "trainer/Z Expert Predictions Std      20.6617\n",
      "trainer/Z Expert Predictions Max     279.448\n",
      "trainer/Z Expert Predictions Min      49.851\n",
      "trainer/Z Policy Predictions Mean    -47.5334\n",
      "trainer/Z Policy Predictions Std      68.3017\n",
      "trainer/Z Policy Predictions Max     183.552\n",
      "trainer/Z Policy Predictions Min    -132.564\n",
      "trainer/Z Expert Targets Mean        254.356\n",
      "trainer/Z Expert Targets Std          20.9535\n",
      "trainer/Z Expert Targets Max         260.953\n",
      "trainer/Z Expert Targets Min          32.0656\n",
      "trainer/Z Policy Targets Mean        -37.4714\n",
      "trainer/Z Policy Targets Std          69.2931\n",
      "trainer/Z Policy Targets Max         195.225\n",
      "trainer/Z Policy Targets Min        -127.94\n",
      "trainer/Log Pis Mean                  20.8864\n",
      "trainer/Log Pis Std                    6.18339\n",
      "trainer/Policy mu Mean                 0.386846\n",
      "trainer/Policy mu Std                  1.47059\n",
      "trainer/Policy log std Mean           -2.6334\n",
      "trainer/Policy log std Std             1.29979\n",
      "exploration/num steps total        11276\n",
      "exploration/num paths total           97\n",
      "evaluation/num steps total         36435\n",
      "evaluation/num paths total            53\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean               -0.755622\n",
      "evaluation/Rewards Std                 0.0682321\n",
      "evaluation/Rewards Max                 0.785675\n",
      "evaluation/Rewards Min                -1.84603\n",
      "evaluation/Returns Mean             -755.622\n",
      "evaluation/Returns Std                24.7618\n",
      "evaluation/Returns Max              -707.499\n",
      "evaluation/Returns Min              -792.526\n",
      "evaluation/Estimation Bias Mean      188.366\n",
      "evaluation/Estimation Bias Std        21.3135\n",
      "evaluation/EB/Q_True Mean             -6.77706\n",
      "evaluation/EB/Q_True Std              20.8727\n",
      "evaluation/EB/Q_Pred Mean            181.589\n",
      "evaluation/EB/Q_Pred Std               8.60785\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          -755.622\n",
      "evaluation/Actions Mean                0.0732856\n",
      "evaluation/Actions Std                 0.658087\n",
      "evaluation/Actions Max                 0.9879\n",
      "evaluation/Actions Min                -0.951898\n",
      "time/backward_policy (s)               1.84217\n",
      "time/backward_zf1 (s)                  1.96342\n",
      "time/backward_zf2 (s)                  1.90255\n",
      "time/data sampling (s)                 0.248891\n",
      "time/data storing (s)                  0.0145752\n",
      "time/evaluation sampling (s)           1.77813\n",
      "time/exploration sampling (s)          0.33976\n",
      "time/logging (s)                       0.0122842\n",
      "time/preback_alpha (s)                 0.554515\n",
      "time/preback_policy (s)                1.12235\n",
      "time/preback_start (s)                 0.142759\n",
      "time/preback_zf (s)                    5.04116\n",
      "time/saving (s)                        0.00693502\n",
      "time/training (s)                      2.06154\n",
      "time/epoch (s)                        17.031\n",
      "time/total (s)                        92.2536\n",
      "Epoch                                  4\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:37:57.557718 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 5 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 16000\n",
      "trainer/ZF1 Loss                     -28.9388\n",
      "trainer/ZF2 Loss                     -27.3389\n",
      "trainer/ZF Expert Reward              18.7153\n",
      "trainer/ZF Policy Reward              -9.72832\n",
      "trainer/ZF CHI2 Term                  20.3367\n",
      "trainer/Policy Loss                   36.2363\n",
      "trainer/Bias Loss                     44.7281\n",
      "trainer/Bias Value                    10.4755\n",
      "trainer/Policy Grad Norm              28.1627\n",
      "trainer/Policy Param Norm             18.6186\n",
      "trainer/Zf1 Grad Norm                522.281\n",
      "trainer/Zf1 Param Norm                44.6092\n",
      "trainer/Zf2 Grad Norm                543.475\n",
      "trainer/Zf2 Param Norm                44.5155\n",
      "trainer/Z Expert Predictions Mean    345.05\n",
      "trainer/Z Expert Predictions Std      26.4477\n",
      "trainer/Z Expert Predictions Max     354.881\n",
      "trainer/Z Expert Predictions Min      82.9389\n",
      "trainer/Z Policy Predictions Mean    -48.8515\n",
      "trainer/Z Policy Predictions Std      98.2134\n",
      "trainer/Z Policy Predictions Max     220.136\n",
      "trainer/Z Policy Predictions Min    -156.126\n",
      "trainer/Z Expert Targets Mean        326.334\n",
      "trainer/Z Expert Targets Std          25.0123\n",
      "trainer/Z Expert Targets Max         335.623\n",
      "trainer/Z Expert Targets Min          62.9427\n",
      "trainer/Z Policy Targets Mean        -39.1232\n",
      "trainer/Z Policy Targets Std         100.91\n",
      "trainer/Z Policy Targets Max         222.776\n",
      "trainer/Z Policy Targets Min        -148.856\n",
      "trainer/Log Pis Mean                  20.2343\n",
      "trainer/Log Pis Std                    8.1323\n",
      "trainer/Policy mu Mean                 0.0139782\n",
      "trainer/Policy mu Std                  1.59645\n",
      "trainer/Policy log std Mean           -2.10162\n",
      "trainer/Policy log std Std             1.64488\n",
      "exploration/num steps total        11530\n",
      "exploration/num paths total           98\n",
      "evaluation/num steps total         44530\n",
      "evaluation/num paths total            63\n",
      "evaluation/path length Mean          809.5\n",
      "evaluation/path length Std           381.055\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            33\n",
      "evaluation/Rewards Mean                0.155025\n",
      "evaluation/Rewards Std                 0.231898\n",
      "evaluation/Rewards Max                 3.05242\n",
      "evaluation/Rewards Min                -2.79294\n",
      "evaluation/Returns Mean              125.493\n",
      "evaluation/Returns Std                64.2972\n",
      "evaluation/Returns Max               282.435\n",
      "evaluation/Returns Min                24.3171\n",
      "evaluation/Estimation Bias Mean      174.398\n",
      "evaluation/Estimation Bias Std        38.293\n",
      "evaluation/EB/Q_True Mean              1.14874\n",
      "evaluation/EB/Q_True Std               3.18638\n",
      "evaluation/EB/Q_Pred Mean            175.547\n",
      "evaluation/EB/Q_Pred Std              38.6235\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           125.493\n",
      "evaluation/Actions Mean                0.268879\n",
      "evaluation/Actions Std                 0.381971\n",
      "evaluation/Actions Max                 0.976607\n",
      "evaluation/Actions Min                -0.99827\n",
      "time/backward_policy (s)               1.98376\n",
      "time/backward_zf1 (s)                  2.08639\n",
      "time/backward_zf2 (s)                  2.0499\n",
      "time/data sampling (s)                 0.261602\n",
      "time/data storing (s)                  0.015064\n",
      "time/evaluation sampling (s)           1.88813\n",
      "time/exploration sampling (s)          0.362483\n",
      "time/logging (s)                       0.0101206\n",
      "time/preback_alpha (s)                 0.569204\n",
      "time/preback_policy (s)                1.21012\n",
      "time/preback_start (s)                 0.146544\n",
      "time/preback_zf (s)                    5.12577\n",
      "time/saving (s)                        0.00754117\n",
      "time/training (s)                      2.11011\n",
      "time/epoch (s)                        17.8267\n",
      "time/total (s)                       110.101\n",
      "Epoch                                  5\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:38:12.752688 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 6 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 17000\n",
      "trainer/ZF1 Loss                       2.09539\n",
      "trainer/ZF2 Loss                       1.11516\n",
      "trainer/ZF Expert Reward              21.9195\n",
      "trainer/ZF Policy Reward              -6.85657\n",
      "trainer/ZF CHI2 Term                  54.6353\n",
      "trainer/Policy Loss                   31.1789\n",
      "trainer/Bias Loss                    376.364\n",
      "trainer/Bias Value                    11.4814\n",
      "trainer/Policy Grad Norm              46.0475\n",
      "trainer/Policy Param Norm             19.0617\n",
      "trainer/Zf1 Grad Norm                593.924\n",
      "trainer/Zf1 Param Norm                46.8224\n",
      "trainer/Zf2 Grad Norm                495.514\n",
      "trainer/Zf2 Param Norm                46.798\n",
      "trainer/Z Expert Predictions Mean    418.917\n",
      "trainer/Z Expert Predictions Std      19.2893\n",
      "trainer/Z Expert Predictions Max     426.969\n",
      "trainer/Z Expert Predictions Min     196.617\n",
      "trainer/Z Policy Predictions Mean    -40.1323\n",
      "trainer/Z Policy Predictions Std     139.916\n",
      "trainer/Z Policy Predictions Max     347.014\n",
      "trainer/Z Policy Predictions Min    -189.891\n",
      "trainer/Z Expert Targets Mean        396.997\n",
      "trainer/Z Expert Targets Std          31.2487\n",
      "trainer/Z Expert Targets Max         407.404\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        -33.2757\n",
      "trainer/Z Policy Targets Std         138.437\n",
      "trainer/Z Policy Targets Max         350.844\n",
      "trainer/Z Policy Targets Min        -181.391\n",
      "trainer/Log Pis Mean                  24.499\n",
      "trainer/Log Pis Std                    8.4622\n",
      "trainer/Policy mu Mean                -0.623587\n",
      "trainer/Policy mu Std                  1.65834\n",
      "trainer/Policy log std Mean           -2.53678\n",
      "trainer/Policy log std Std             1.84808\n",
      "exploration/num steps total        12043\n",
      "exploration/num paths total           99\n",
      "evaluation/num steps total         44764\n",
      "evaluation/num paths total            73\n",
      "evaluation/path length Mean           23.4\n",
      "evaluation/path length Std             9.50999\n",
      "evaluation/path length Max            37\n",
      "evaluation/path length Min            10\n",
      "evaluation/Rewards Mean                0.980348\n",
      "evaluation/Rewards Std                 1.08445\n",
      "evaluation/Rewards Max                 4.17507\n",
      "evaluation/Rewards Min                -1.67319\n",
      "evaluation/Returns Mean               22.9402\n",
      "evaluation/Returns Std                11.1617\n",
      "evaluation/Returns Max                36.7363\n",
      "evaluation/Returns Min                 5.33291\n",
      "evaluation/Estimation Bias Mean      303.394\n",
      "evaluation/Estimation Bias Std        72.636\n",
      "evaluation/EB/Q_True Mean              2.75478\n",
      "evaluation/EB/Q_True Std               7.02385\n",
      "evaluation/EB/Q_Pred Mean            306.149\n",
      "evaluation/EB/Q_Pred Std              71.5523\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            22.9402\n",
      "evaluation/Actions Mean               -0.0198966\n",
      "evaluation/Actions Std                 0.562869\n",
      "evaluation/Actions Max                 0.986844\n",
      "evaluation/Actions Min                -0.997032\n",
      "time/backward_policy (s)               1.77587\n",
      "time/backward_zf1 (s)                  1.89519\n",
      "time/backward_zf2 (s)                  1.83503\n",
      "time/data sampling (s)                 0.26837\n",
      "time/data storing (s)                  0.0144803\n",
      "time/evaluation sampling (s)           0.11455\n",
      "time/exploration sampling (s)          0.340334\n",
      "time/logging (s)                       0.00184389\n",
      "time/preback_alpha (s)                 0.549115\n",
      "time/preback_policy (s)                1.08671\n",
      "time/preback_start (s)                 0.140398\n",
      "time/preback_zf (s)                    5.01213\n",
      "time/saving (s)                        0.00685383\n",
      "time/training (s)                      2.07668\n",
      "time/epoch (s)                        15.1176\n",
      "time/total (s)                       125.243\n",
      "Epoch                                  6\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:38:28.079666 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 7 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 18000\n",
      "trainer/ZF1 Loss                     -27.2805\n",
      "trainer/ZF2 Loss                     -27.6073\n",
      "trainer/ZF Expert Reward              21.2382\n",
      "trainer/ZF Policy Reward              -7.63453\n",
      "trainer/ZF CHI2 Term                  26.6359\n",
      "trainer/Policy Loss                   26.5917\n",
      "trainer/Bias Loss                     47.9134\n",
      "trainer/Bias Value                    12.4757\n",
      "trainer/Policy Grad Norm              48.471\n",
      "trainer/Policy Param Norm             19.572\n",
      "trainer/Zf1 Grad Norm                579.369\n",
      "trainer/Zf1 Param Norm                48.8237\n",
      "trainer/Zf2 Grad Norm                654.409\n",
      "trainer/Zf2 Param Norm                48.9073\n",
      "trainer/Z Expert Predictions Mean    487.588\n",
      "trainer/Z Expert Predictions Std      34.5751\n",
      "trainer/Z Expert Predictions Max     500.333\n",
      "trainer/Z Expert Predictions Min     180.127\n",
      "trainer/Z Policy Predictions Mean    -39.2028\n",
      "trainer/Z Policy Predictions Std     172.922\n",
      "trainer/Z Policy Predictions Max     372.911\n",
      "trainer/Z Policy Predictions Min    -218.816\n",
      "trainer/Z Expert Targets Mean        466.35\n",
      "trainer/Z Expert Targets Std          34.0971\n",
      "trainer/Z Expert Targets Max         480.603\n",
      "trainer/Z Expert Targets Min         171.49\n",
      "trainer/Z Policy Targets Mean        -31.5682\n",
      "trainer/Z Policy Targets Std         170.54\n",
      "trainer/Z Policy Targets Max         395.212\n",
      "trainer/Z Policy Targets Min        -209.199\n",
      "trainer/Log Pis Mean                  25.4617\n",
      "trainer/Log Pis Std                   10.3673\n",
      "trainer/Policy mu Mean                -0.396124\n",
      "trainer/Policy mu Std                  2.04943\n",
      "trainer/Policy log std Mean           -2.19481\n",
      "trainer/Policy log std Std             1.85949\n",
      "exploration/num steps total        13061\n",
      "exploration/num paths total          101\n",
      "evaluation/num steps total         45295\n",
      "evaluation/num paths total            83\n",
      "evaluation/path length Mean           53.1\n",
      "evaluation/path length Std            46.6743\n",
      "evaluation/path length Max           128\n",
      "evaluation/path length Min            10\n",
      "evaluation/Rewards Mean                1.38057\n",
      "evaluation/Rewards Std                 1.15706\n",
      "evaluation/Rewards Max                 4.09353\n",
      "evaluation/Rewards Min                -1.41929\n",
      "evaluation/Returns Mean               73.3085\n",
      "evaluation/Returns Std                69.8245\n",
      "evaluation/Returns Max               173.755\n",
      "evaluation/Returns Min                 3.42775\n",
      "evaluation/Estimation Bias Mean      255.281\n",
      "evaluation/Estimation Bias Std       135.581\n",
      "evaluation/EB/Q_True Mean              8.01607\n",
      "evaluation/EB/Q_True Std              16.3342\n",
      "evaluation/EB/Q_Pred Mean            263.297\n",
      "evaluation/EB/Q_Pred Std             136.989\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            73.3085\n",
      "evaluation/Actions Mean                0.0198156\n",
      "evaluation/Actions Std                 0.520811\n",
      "evaluation/Actions Max                 0.976415\n",
      "evaluation/Actions Min                -0.994146\n",
      "time/backward_policy (s)               1.78416\n",
      "time/backward_zf1 (s)                  1.88187\n",
      "time/backward_zf2 (s)                  1.84356\n",
      "time/data sampling (s)                 0.246666\n",
      "time/data storing (s)                  0.0135942\n",
      "time/evaluation sampling (s)           0.321246\n",
      "time/exploration sampling (s)          0.332351\n",
      "time/logging (s)                       0.00197993\n",
      "time/preback_alpha (s)                 0.534887\n",
      "time/preback_policy (s)                1.07675\n",
      "time/preback_start (s)                 0.138227\n",
      "time/preback_zf (s)                    4.99479\n",
      "time/saving (s)                        0.00701934\n",
      "time/training (s)                      2.0852\n",
      "time/epoch (s)                        15.2623\n",
      "time/total (s)                       140.526\n",
      "Epoch                                  7\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:38:43.476581 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 8 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 19000\n",
      "trainer/ZF1 Loss                     -29.7772\n",
      "trainer/ZF2 Loss                     -26.6063\n",
      "trainer/ZF Expert Reward              21.1834\n",
      "trainer/ZF Policy Reward             -14.3426\n",
      "trainer/ZF CHI2 Term                  29.4574\n",
      "trainer/Policy Loss                   24.5375\n",
      "trainer/Bias Loss                     43.7674\n",
      "trainer/Bias Value                    13.4608\n",
      "trainer/Policy Grad Norm              35.8394\n",
      "trainer/Policy Param Norm             20.1127\n",
      "trainer/Zf1 Grad Norm                767.2\n",
      "trainer/Zf1 Param Norm                50.6514\n",
      "trainer/Zf2 Grad Norm               1039.74\n",
      "trainer/Zf2 Param Norm                50.8001\n",
      "trainer/Z Expert Predictions Mean    557.939\n",
      "trainer/Z Expert Predictions Std      26.8275\n",
      "trainer/Z Expert Predictions Max     572.405\n",
      "trainer/Z Expert Predictions Min     289.788\n",
      "trainer/Z Policy Predictions Mean    -34.3493\n",
      "trainer/Z Policy Predictions Std     192.973\n",
      "trainer/Z Policy Predictions Max     449.344\n",
      "trainer/Z Policy Predictions Min    -249.459\n",
      "trainer/Z Expert Targets Mean        536.756\n",
      "trainer/Z Expert Targets Std          26.6568\n",
      "trainer/Z Expert Targets Max         551.338\n",
      "trainer/Z Expert Targets Min         250.563\n",
      "trainer/Z Policy Targets Mean        -20.0067\n",
      "trainer/Z Policy Targets Std         198.063\n",
      "trainer/Z Policy Targets Max         484.143\n",
      "trainer/Z Policy Targets Min        -241.156\n",
      "trainer/Log Pis Mean                  22.3467\n",
      "trainer/Log Pis Std                    6.26021\n",
      "trainer/Policy mu Mean                -0.0907019\n",
      "trainer/Policy mu Std                  1.71706\n",
      "trainer/Policy log std Mean           -2.37419\n",
      "trainer/Policy log std Std             1.70297\n",
      "exploration/num steps total        14694\n",
      "exploration/num paths total          107\n",
      "evaluation/num steps total         46088\n",
      "evaluation/num paths total            93\n",
      "evaluation/path length Mean           79.3\n",
      "evaluation/path length Std            29.833\n",
      "evaluation/path length Max           158\n",
      "evaluation/path length Min            57\n",
      "evaluation/Rewards Mean                1.73353\n",
      "evaluation/Rewards Std                 1.34578\n",
      "evaluation/Rewards Max                 5.13685\n",
      "evaluation/Rewards Min                -1.38175\n",
      "evaluation/Returns Mean              137.469\n",
      "evaluation/Returns Std                83.4363\n",
      "evaluation/Returns Max               356.628\n",
      "evaluation/Returns Min                52.4842\n",
      "evaluation/Estimation Bias Mean      407.83\n",
      "evaluation/Estimation Bias Std       124.054\n",
      "evaluation/EB/Q_True Mean             18.7302\n",
      "evaluation/EB/Q_True Std              41.4626\n",
      "evaluation/EB/Q_Pred Mean            426.56\n",
      "evaluation/EB/Q_Pred Std             116.712\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           137.469\n",
      "evaluation/Actions Mean                0.0313455\n",
      "evaluation/Actions Std                 0.537325\n",
      "evaluation/Actions Max                 0.979006\n",
      "evaluation/Actions Min                -0.991228\n",
      "time/backward_policy (s)               1.82646\n",
      "time/backward_zf1 (s)                  1.92257\n",
      "time/backward_zf2 (s)                  1.89766\n",
      "time/data sampling (s)                 0.231275\n",
      "time/data storing (s)                  0.0138611\n",
      "time/evaluation sampling (s)           0.405648\n",
      "time/exploration sampling (s)          0.334033\n",
      "time/logging (s)                       0.00287028\n",
      "time/preback_alpha (s)                 0.534608\n",
      "time/preback_policy (s)                1.15674\n",
      "time/preback_start (s)                 0.137832\n",
      "time/preback_zf (s)                    4.99014\n",
      "time/saving (s)                        0.00532521\n",
      "time/training (s)                      1.87526\n",
      "time/epoch (s)                        15.3343\n",
      "time/total (s)                       155.879\n",
      "Epoch                                  8\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:39:01.014007 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 9 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 20000\n",
      "trainer/ZF1 Loss                     -27.8765\n",
      "trainer/ZF2 Loss                     -25.1445\n",
      "trainer/ZF Expert Reward              21.1107\n",
      "trainer/ZF Policy Reward              -7.77559\n",
      "trainer/ZF CHI2 Term                  30.1427\n",
      "trainer/Policy Loss                   37.637\n",
      "trainer/Bias Loss                     66.1584\n",
      "trainer/Bias Value                    14.4366\n",
      "trainer/Policy Grad Norm              43.8241\n",
      "trainer/Policy Param Norm             20.6087\n",
      "trainer/Zf1 Grad Norm                700.717\n",
      "trainer/Zf1 Param Norm                52.219\n",
      "trainer/Zf2 Grad Norm               1125.12\n",
      "trainer/Zf2 Param Norm                52.4401\n",
      "trainer/Z Expert Predictions Mean    616.476\n",
      "trainer/Z Expert Predictions Std      38.6823\n",
      "trainer/Z Expert Predictions Max     639.476\n",
      "trainer/Z Expert Predictions Min     317.975\n",
      "trainer/Z Policy Predictions Mean    -46.8557\n",
      "trainer/Z Policy Predictions Std     216.886\n",
      "trainer/Z Policy Predictions Max     518.489\n",
      "trainer/Z Policy Predictions Min    -276.142\n",
      "trainer/Z Expert Targets Mean        595.365\n",
      "trainer/Z Expert Targets Std          39.3617\n",
      "trainer/Z Expert Targets Max         619.092\n",
      "trainer/Z Expert Targets Min         246.917\n",
      "trainer/Z Policy Targets Mean        -39.0801\n",
      "trainer/Z Policy Targets Std         216.542\n",
      "trainer/Z Policy Targets Max         553.68\n",
      "trainer/Z Policy Targets Min        -268.01\n",
      "trainer/Log Pis Mean                  28.0474\n",
      "trainer/Log Pis Std                    9.31821\n",
      "trainer/Policy mu Mean                -0.437088\n",
      "trainer/Policy mu Std                  2.23105\n",
      "trainer/Policy log std Mean           -2.63462\n",
      "trainer/Policy log std Std             1.52101\n",
      "exploration/num steps total        17516\n",
      "exploration/num paths total          110\n",
      "evaluation/num steps total         55392\n",
      "evaluation/num paths total           103\n",
      "evaluation/path length Mean          930.4\n",
      "evaluation/path length Std           208.8\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           304\n",
      "evaluation/Rewards Mean               -0.670651\n",
      "evaluation/Rewards Std                 0.8392\n",
      "evaluation/Rewards Max                 4.56988\n",
      "evaluation/Rewards Min                -4.20312\n",
      "evaluation/Returns Mean             -623.974\n",
      "evaluation/Returns Std               454.327\n",
      "evaluation/Returns Max                46.5131\n",
      "evaluation/Returns Min             -1759.12\n",
      "evaluation/Estimation Bias Mean      -91.7545\n",
      "evaluation/Estimation Bias Std       145.274\n",
      "evaluation/EB/Q_True Mean             -5.94296\n",
      "evaluation/EB/Q_True Std              17.6625\n",
      "evaluation/EB/Q_Pred Mean            -97.6974\n",
      "evaluation/EB/Q_Pred Std             141.907\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          -623.974\n",
      "evaluation/Actions Mean               -0.059424\n",
      "evaluation/Actions Std                 0.662488\n",
      "evaluation/Actions Max                 0.999919\n",
      "evaluation/Actions Min                -0.999857\n",
      "time/backward_policy (s)               1.89418\n",
      "time/backward_zf1 (s)                  1.99595\n",
      "time/backward_zf2 (s)                  1.96207\n",
      "time/data sampling (s)                 0.248245\n",
      "time/data storing (s)                  0.0140086\n",
      "time/evaluation sampling (s)           1.89086\n",
      "time/exploration sampling (s)          0.352273\n",
      "time/logging (s)                       0.0113375\n",
      "time/preback_alpha (s)                 0.562794\n",
      "time/preback_policy (s)                1.14833\n",
      "time/preback_start (s)                 0.144168\n",
      "time/preback_zf (s)                    5.08627\n",
      "time/saving (s)                        0.0062799\n",
      "time/training (s)                      2.16175\n",
      "time/epoch (s)                        17.4785\n",
      "time/total (s)                       173.379\n",
      "Epoch                                  9\n",
      "---------------------------------  -------------\n",
      "2024-06-10 20:39:16.945927 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 10 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 21000\n",
      "trainer/ZF1 Loss                     -16.9327\n",
      "trainer/ZF2 Loss                     -18.314\n",
      "trainer/ZF Expert Reward              20.8781\n",
      "trainer/ZF Policy Reward             -10.4271\n",
      "trainer/ZF CHI2 Term                  40.5834\n",
      "trainer/Policy Loss                   38.5361\n",
      "trainer/Bias Loss                     92.4594\n",
      "trainer/Bias Value                    15.4078\n",
      "trainer/Policy Grad Norm              70.4987\n",
      "trainer/Policy Param Norm             21.0276\n",
      "trainer/Zf1 Grad Norm               2320.82\n",
      "trainer/Zf1 Param Norm                53.7073\n",
      "trainer/Zf2 Grad Norm               2204.71\n",
      "trainer/Zf2 Param Norm                53.9904\n",
      "trainer/Z Expert Predictions Mean    678.21\n",
      "trainer/Z Expert Predictions Std      59.6187\n",
      "trainer/Z Expert Predictions Max     704.84\n",
      "trainer/Z Expert Predictions Min     252.327\n",
      "trainer/Z Policy Predictions Mean    -51.7472\n",
      "trainer/Z Policy Predictions Std     231.644\n",
      "trainer/Z Policy Predictions Max     664.908\n",
      "trainer/Z Policy Predictions Min    -299.469\n",
      "trainer/Z Expert Targets Mean        657.332\n",
      "trainer/Z Expert Targets Std          53.3468\n",
      "trainer/Z Expert Targets Max         683.388\n",
      "trainer/Z Expert Targets Min         250.383\n",
      "trainer/Z Policy Targets Mean        -41.3201\n",
      "trainer/Z Policy Targets Std         232.807\n",
      "trainer/Z Policy Targets Max         642.215\n",
      "trainer/Z Policy Targets Min        -291.83\n",
      "trainer/Log Pis Mean                  27.1733\n",
      "trainer/Log Pis Std                   10.4127\n",
      "trainer/Policy mu Mean                -0.707859\n",
      "trainer/Policy mu Std                  2.01673\n",
      "trainer/Policy log std Mean           -2.43191\n",
      "trainer/Policy log std Std             1.71935\n",
      "exploration/num steps total        17793\n",
      "exploration/num paths total          111\n",
      "evaluation/num steps total         56962\n",
      "evaluation/num paths total           113\n",
      "evaluation/path length Mean          157\n",
      "evaluation/path length Std            70.3918\n",
      "evaluation/path length Max           274\n",
      "evaluation/path length Min            45\n",
      "evaluation/Rewards Mean                1.47717\n",
      "evaluation/Rewards Std                 1.35806\n",
      "evaluation/Rewards Max                 4.18398\n",
      "evaluation/Rewards Min                -2.3335\n",
      "evaluation/Returns Mean              231.916\n",
      "evaluation/Returns Std                93.3815\n",
      "evaluation/Returns Max               362.342\n",
      "evaluation/Returns Min                88.6307\n",
      "evaluation/Estimation Bias Mean      354.206\n",
      "evaluation/Estimation Bias Std       248.752\n",
      "evaluation/EB/Q_True Mean             15.3156\n",
      "evaluation/EB/Q_True Std              38.6813\n",
      "evaluation/EB/Q_Pred Mean            369.521\n",
      "evaluation/EB/Q_Pred Std             250.979\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           231.916\n",
      "evaluation/Actions Mean                0.0437194\n",
      "evaluation/Actions Std                 0.511419\n",
      "evaluation/Actions Max                 0.999861\n",
      "evaluation/Actions Min                -0.998558\n",
      "time/backward_policy (s)               1.703\n",
      "time/backward_zf1 (s)                  1.82524\n",
      "time/backward_zf2 (s)                  1.7513\n",
      "time/data sampling (s)                 0.274285\n",
      "time/data storing (s)                  0.0145541\n",
      "time/evaluation sampling (s)           0.679268\n",
      "time/exploration sampling (s)          0.336862\n",
      "time/logging (s)                       0.00396807\n",
      "time/preback_alpha (s)                 0.557775\n",
      "time/preback_policy (s)                0.976674\n",
      "time/preback_start (s)                 0.143036\n",
      "time/preback_zf (s)                    5.07754\n",
      "time/saving (s)                        0.00695099\n",
      "time/training (s)                      2.5038\n",
      "time/epoch (s)                        15.8543\n",
      "time/total (s)                       189.258\n",
      "Epoch                                 10\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:39:32.421446 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 11 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 22000\n",
      "trainer/ZF1 Loss                      -9.11694\n",
      "trainer/ZF2 Loss                      -4.64778\n",
      "trainer/ZF Expert Reward              25.02\n",
      "trainer/ZF Policy Reward             -12.0232\n",
      "trainer/ZF CHI2 Term                  56.5208\n",
      "trainer/Policy Loss                    6.01933\n",
      "trainer/Bias Loss                     95.5877\n",
      "trainer/Bias Value                    16.365\n",
      "trainer/Policy Grad Norm              46.2577\n",
      "trainer/Policy Param Norm             21.5176\n",
      "trainer/Zf1 Grad Norm               1409.98\n",
      "trainer/Zf1 Param Norm                55.0907\n",
      "trainer/Zf2 Grad Norm               1465.18\n",
      "trainer/Zf2 Param Norm                55.4125\n",
      "trainer/Z Expert Predictions Mean    743.038\n",
      "trainer/Z Expert Predictions Std      59.618\n",
      "trainer/Z Expert Predictions Max     770.325\n",
      "trainer/Z Expert Predictions Min     375.817\n",
      "trainer/Z Policy Predictions Mean    -16.7265\n",
      "trainer/Z Policy Predictions Std     265.081\n",
      "trainer/Z Policy Predictions Max     733.173\n",
      "trainer/Z Policy Predictions Min    -326.421\n",
      "trainer/Z Expert Targets Mean        718.018\n",
      "trainer/Z Expert Targets Std          58.3625\n",
      "trainer/Z Expert Targets Max         749.541\n",
      "trainer/Z Expert Targets Min         346.584\n",
      "trainer/Z Policy Targets Mean         -4.70328\n",
      "trainer/Z Policy Targets Std         264.941\n",
      "trainer/Z Policy Targets Max         723.26\n",
      "trainer/Z Policy Targets Min        -317.577\n",
      "trainer/Log Pis Mean                  26.6262\n",
      "trainer/Log Pis Std                    9.00787\n",
      "trainer/Policy mu Mean                -0.471643\n",
      "trainer/Policy mu Std                  2.03838\n",
      "trainer/Policy log std Mean           -2.51392\n",
      "trainer/Policy log std Std             1.8321\n",
      "exploration/num steps total        19695\n",
      "exploration/num paths total          115\n",
      "evaluation/num steps total         57853\n",
      "evaluation/num paths total           123\n",
      "evaluation/path length Mean           89.1\n",
      "evaluation/path length Std            60.6604\n",
      "evaluation/path length Max           229\n",
      "evaluation/path length Min            19\n",
      "evaluation/Rewards Mean                1.09017\n",
      "evaluation/Rewards Std                 1.65117\n",
      "evaluation/Rewards Max                 5.10465\n",
      "evaluation/Rewards Min                -3.10529\n",
      "evaluation/Returns Mean               97.1338\n",
      "evaluation/Returns Std                53.8351\n",
      "evaluation/Returns Max               186.819\n",
      "evaluation/Returns Min               -11.3758\n",
      "evaluation/Estimation Bias Mean      247.209\n",
      "evaluation/Estimation Bias Std       275.99\n",
      "evaluation/EB/Q_True Mean              9.0193\n",
      "evaluation/EB/Q_True Std              18.6275\n",
      "evaluation/EB/Q_Pred Mean            256.229\n",
      "evaluation/EB/Q_Pred Std             280.451\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            97.1338\n",
      "evaluation/Actions Mean                0.0946851\n",
      "evaluation/Actions Std                 0.546149\n",
      "evaluation/Actions Max                 0.999991\n",
      "evaluation/Actions Min                -0.998538\n",
      "time/backward_policy (s)               1.75219\n",
      "time/backward_zf1 (s)                  1.84722\n",
      "time/backward_zf2 (s)                  1.8074\n",
      "time/data sampling (s)                 0.249851\n",
      "time/data storing (s)                  0.0140147\n",
      "time/evaluation sampling (s)           0.453599\n",
      "time/exploration sampling (s)          0.326696\n",
      "time/logging (s)                       0.00223955\n",
      "time/preback_alpha (s)                 0.541505\n",
      "time/preback_policy (s)                1.03285\n",
      "time/preback_start (s)                 0.14041\n",
      "time/preback_zf (s)                    5.0179\n",
      "time/saving (s)                        0.00582856\n",
      "time/training (s)                      2.21963\n",
      "time/epoch (s)                        15.4113\n",
      "time/total (s)                       204.688\n",
      "Epoch                                 11\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:39:49.405513 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 12 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 23000\n",
      "trainer/ZF1 Loss                     -13.4858\n",
      "trainer/ZF2 Loss                     -12.0632\n",
      "trainer/ZF Expert Reward              22.9482\n",
      "trainer/ZF Policy Reward             -11.8912\n",
      "trainer/ZF CHI2 Term                  53.5247\n",
      "trainer/Policy Loss                   20.0188\n",
      "trainer/Bias Loss                    111.852\n",
      "trainer/Bias Value                    17.3089\n",
      "trainer/Policy Grad Norm              94.7095\n",
      "trainer/Policy Param Norm             22.0478\n",
      "trainer/Zf1 Grad Norm               1378.64\n",
      "trainer/Zf1 Param Norm                56.352\n",
      "trainer/Zf2 Grad Norm               1559.64\n",
      "trainer/Zf2 Param Norm                56.7286\n",
      "trainer/Z Expert Predictions Mean    803.084\n",
      "trainer/Z Expert Predictions Std      63.1859\n",
      "trainer/Z Expert Predictions Max     841.266\n",
      "trainer/Z Expert Predictions Min     343.594\n",
      "trainer/Z Policy Predictions Mean    -34.4741\n",
      "trainer/Z Policy Predictions Std     281.559\n",
      "trainer/Z Policy Predictions Max     825.613\n",
      "trainer/Z Policy Predictions Min    -342.956\n",
      "trainer/Z Expert Targets Mean        780.136\n",
      "trainer/Z Expert Targets Std          62.7726\n",
      "trainer/Z Expert Targets Max         815.542\n",
      "trainer/Z Expert Targets Min         309.423\n",
      "trainer/Z Policy Targets Mean        -22.5829\n",
      "trainer/Z Policy Targets Std         281.769\n",
      "trainer/Z Policy Targets Max         794.276\n",
      "trainer/Z Policy Targets Min        -335.475\n",
      "trainer/Log Pis Mean                  31.7776\n",
      "trainer/Log Pis Std                   12.7706\n",
      "trainer/Policy mu Mean                -0.298623\n",
      "trainer/Policy mu Std                  2.7404\n",
      "trainer/Policy log std Mean           -2.83095\n",
      "trainer/Policy log std Std             1.51048\n",
      "exploration/num steps total        20634\n",
      "exploration/num paths total          119\n",
      "evaluation/num steps total         65008\n",
      "evaluation/num paths total           133\n",
      "evaluation/path length Mean          715.5\n",
      "evaluation/path length Std           347.942\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min            28\n",
      "evaluation/Rewards Mean                1.33705\n",
      "evaluation/Rewards Std                 2.11489\n",
      "evaluation/Rewards Max                 6.11248\n",
      "evaluation/Rewards Min                -4.08778\n",
      "evaluation/Returns Mean              956.659\n",
      "evaluation/Returns Std               878.142\n",
      "evaluation/Returns Max              1967.09\n",
      "evaluation/Returns Min              -878.062\n",
      "evaluation/Estimation Bias Mean      355.404\n",
      "evaluation/Estimation Bias Std       361.672\n",
      "evaluation/EB/Q_True Mean             17.269\n",
      "evaluation/EB/Q_True Std              48.2157\n",
      "evaluation/EB/Q_Pred Mean            372.673\n",
      "evaluation/EB/Q_Pred Std             367.432\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           956.659\n",
      "evaluation/Actions Mean                0.0122446\n",
      "evaluation/Actions Std                 0.567011\n",
      "evaluation/Actions Max                 0.999982\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.84287\n",
      "time/backward_zf1 (s)                  1.94356\n",
      "time/backward_zf2 (s)                  1.89795\n",
      "time/data sampling (s)                 0.250232\n",
      "time/data storing (s)                  0.0142739\n",
      "time/evaluation sampling (s)           1.73411\n",
      "time/exploration sampling (s)          0.330336\n",
      "time/logging (s)                       0.0101982\n",
      "time/preback_alpha (s)                 0.547237\n",
      "time/preback_policy (s)                1.10114\n",
      "time/preback_start (s)                 0.141992\n",
      "time/preback_zf (s)                    5.02999\n",
      "time/saving (s)                        0.00618715\n",
      "time/training (s)                      2.07437\n",
      "time/epoch (s)                        16.9244\n",
      "time/total (s)                       221.635\n",
      "Epoch                                 12\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:40:05.910039 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 13 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 24000\n",
      "trainer/ZF1 Loss                     153.226\n",
      "trainer/ZF2 Loss                     146.19\n",
      "trainer/ZF Expert Reward              28.0128\n",
      "trainer/ZF Policy Reward             -10.791\n",
      "trainer/ZF CHI2 Term                 214.551\n",
      "trainer/Policy Loss                  -50.7876\n",
      "trainer/Bias Loss                   1616.12\n",
      "trainer/Bias Value                    18.2259\n",
      "trainer/Policy Grad Norm              64.9241\n",
      "trainer/Policy Param Norm             22.4313\n",
      "trainer/Zf1 Grad Norm               1618.09\n",
      "trainer/Zf1 Param Norm                57.558\n",
      "trainer/Zf2 Grad Norm               2676.47\n",
      "trainer/Zf2 Param Norm                58.0075\n",
      "trainer/Z Expert Predictions Mean    875.551\n",
      "trainer/Z Expert Predictions Std      73.0591\n",
      "trainer/Z Expert Predictions Max     917.05\n",
      "trainer/Z Expert Predictions Min     430.529\n",
      "trainer/Z Policy Predictions Mean     41.6999\n",
      "trainer/Z Policy Predictions Std     325.54\n",
      "trainer/Z Policy Predictions Max     881.721\n",
      "trainer/Z Policy Predictions Min    -352.087\n",
      "trainer/Z Expert Targets Mean        847.539\n",
      "trainer/Z Expert Targets Std          87.6599\n",
      "trainer/Z Expert Targets Max         890.669\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         52.4909\n",
      "trainer/Z Policy Targets Std         323.694\n",
      "trainer/Z Policy Targets Max         851.68\n",
      "trainer/Z Policy Targets Min        -341.967\n",
      "trainer/Log Pis Mean                  26.3026\n",
      "trainer/Log Pis Std                    9.23144\n",
      "trainer/Policy mu Mean                -0.27575\n",
      "trainer/Policy mu Std                  2.09165\n",
      "trainer/Policy log std Mean           -2.79119\n",
      "trainer/Policy log std Std             1.46508\n",
      "exploration/num steps total        20634\n",
      "exploration/num paths total          119\n",
      "evaluation/num steps total         66444\n",
      "evaluation/num paths total           143\n",
      "evaluation/path length Mean          143.6\n",
      "evaluation/path length Std            59.3299\n",
      "evaluation/path length Max           275\n",
      "evaluation/path length Min            61\n",
      "evaluation/Rewards Mean                2.44506\n",
      "evaluation/Rewards Std                 1.85826\n",
      "evaluation/Rewards Max                 6.93671\n",
      "evaluation/Rewards Min                -2.25694\n",
      "evaluation/Returns Mean              351.111\n",
      "evaluation/Returns Std               206.921\n",
      "evaluation/Returns Max               897.863\n",
      "evaluation/Returns Min                85.0493\n",
      "evaluation/Estimation Bias Mean      606.031\n",
      "evaluation/Estimation Bias Std       290.354\n",
      "evaluation/EB/Q_True Mean             27.3414\n",
      "evaluation/EB/Q_True Std              70.3948\n",
      "evaluation/EB/Q_Pred Mean            633.373\n",
      "evaluation/EB/Q_Pred Std             274.894\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           351.111\n",
      "evaluation/Actions Mean                0.0040039\n",
      "evaluation/Actions Std                 0.50862\n",
      "evaluation/Actions Max                 0.999988\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.86525\n",
      "time/backward_zf1 (s)                  1.96321\n",
      "time/backward_zf2 (s)                  1.91141\n",
      "time/data sampling (s)                 0.260095\n",
      "time/data storing (s)                  0.0138185\n",
      "time/evaluation sampling (s)           1.12047\n",
      "time/exploration sampling (s)          0.325517\n",
      "time/logging (s)                       0.00269055\n",
      "time/preback_alpha (s)                 0.549239\n",
      "time/preback_policy (s)                1.11793\n",
      "time/preback_start (s)                 0.139954\n",
      "time/preback_zf (s)                    5.03221\n",
      "time/saving (s)                        0.0056433\n",
      "time/training (s)                      2.12507\n",
      "time/epoch (s)                        16.4325\n",
      "time/total (s)                       238.086\n",
      "Epoch                                 13\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:40:21.516136 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 14 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 25000\n",
      "trainer/ZF1 Loss                      29.2264\n",
      "trainer/ZF2 Loss                      10.5346\n",
      "trainer/ZF Expert Reward              26.0494\n",
      "trainer/ZF Policy Reward             -10.8176\n",
      "trainer/ZF CHI2 Term                  84.0717\n",
      "trainer/Policy Loss                  -77.0712\n",
      "trainer/Bias Loss                    283.338\n",
      "trainer/Bias Value                    19.1353\n",
      "trainer/Policy Grad Norm              91.3974\n",
      "trainer/Policy Param Norm             22.8452\n",
      "trainer/Zf1 Grad Norm               4363.23\n",
      "trainer/Zf1 Param Norm                58.7744\n",
      "trainer/Zf2 Grad Norm               2844.22\n",
      "trainer/Zf2 Param Norm                59.2899\n",
      "trainer/Z Expert Predictions Mean    956.459\n",
      "trainer/Z Expert Predictions Std      57.1235\n",
      "trainer/Z Expert Predictions Max     991.455\n",
      "trainer/Z Expert Predictions Min     618.807\n",
      "trainer/Z Policy Predictions Mean     58.946\n",
      "trainer/Z Policy Predictions Std     344.729\n",
      "trainer/Z Policy Predictions Max     947.525\n",
      "trainer/Z Policy Predictions Min    -362.982\n",
      "trainer/Z Expert Targets Mean        930.41\n",
      "trainer/Z Expert Targets Std          65.4752\n",
      "trainer/Z Expert Targets Max         965.703\n",
      "trainer/Z Expert Targets Min         516.17\n",
      "trainer/Z Policy Targets Mean         69.7635\n",
      "trainer/Z Policy Targets Std         344.387\n",
      "trainer/Z Policy Targets Max         918.48\n",
      "trainer/Z Policy Targets Min        -353.439\n",
      "trainer/Log Pis Mean                  27.6001\n",
      "trainer/Log Pis Std                   10.642\n",
      "trainer/Policy mu Mean                -0.292114\n",
      "trainer/Policy mu Std                  2.36916\n",
      "trainer/Policy log std Mean           -2.70669\n",
      "trainer/Policy log std Std             1.56554\n",
      "exploration/num steps total        20634\n",
      "exploration/num paths total          119\n",
      "evaluation/num steps total         67745\n",
      "evaluation/num paths total           153\n",
      "evaluation/path length Mean          130.1\n",
      "evaluation/path length Std            75.5823\n",
      "evaluation/path length Max           316\n",
      "evaluation/path length Min            47\n",
      "evaluation/Rewards Mean                2.60619\n",
      "evaluation/Rewards Std                 1.67765\n",
      "evaluation/Rewards Max                 5.9871\n",
      "evaluation/Rewards Min                -3.11082\n",
      "evaluation/Returns Mean              339.066\n",
      "evaluation/Returns Std               244.353\n",
      "evaluation/Returns Max               914.506\n",
      "evaluation/Returns Min                81.3139\n",
      "evaluation/Estimation Bias Mean      676.659\n",
      "evaluation/Estimation Bias Std       310.64\n",
      "evaluation/EB/Q_True Mean             32.2141\n",
      "evaluation/EB/Q_True Std              64.2313\n",
      "evaluation/EB/Q_Pred Mean            708.873\n",
      "evaluation/EB/Q_Pred Std             290.595\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           339.066\n",
      "evaluation/Actions Mean                0.0236098\n",
      "evaluation/Actions Std                 0.519481\n",
      "evaluation/Actions Max                 0.999989\n",
      "evaluation/Actions Min                -0.999986\n",
      "time/backward_policy (s)               1.66036\n",
      "time/backward_zf1 (s)                  1.76578\n",
      "time/backward_zf2 (s)                  1.70617\n",
      "time/data sampling (s)                 0.21559\n",
      "time/data storing (s)                  0.0135929\n",
      "time/evaluation sampling (s)           0.794687\n",
      "time/exploration sampling (s)          0.315891\n",
      "time/logging (s)                       0.00291541\n",
      "time/preback_alpha (s)                 0.535469\n",
      "time/preback_policy (s)                0.949717\n",
      "time/preback_start (s)                 0.135876\n",
      "time/preback_zf (s)                    5.00636\n",
      "time/saving (s)                        0.005678\n",
      "time/training (s)                      2.4369\n",
      "time/epoch (s)                        15.545\n",
      "time/total (s)                       253.649\n",
      "Epoch                                 14\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:40:38.008261 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 15 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 26000\n",
      "trainer/ZF1 Loss                       8.59093\n",
      "trainer/ZF2 Loss                       9.16667\n",
      "trainer/ZF Expert Reward              26.4275\n",
      "trainer/ZF Policy Reward              -6.56347\n",
      "trainer/ZF CHI2 Term                  69.5508\n",
      "trainer/Policy Loss                 -130.329\n",
      "trainer/Bias Loss                    154.671\n",
      "trainer/Bias Value                    20.0173\n",
      "trainer/Policy Grad Norm              93.6359\n",
      "trainer/Policy Param Norm             23.2206\n",
      "trainer/Zf1 Grad Norm               2159.17\n",
      "trainer/Zf1 Param Norm                59.9561\n",
      "trainer/Zf2 Grad Norm               2268.38\n",
      "trainer/Zf2 Param Norm                60.4948\n",
      "trainer/Z Expert Predictions Mean   1018.85\n",
      "trainer/Z Expert Predictions Std      87.7172\n",
      "trainer/Z Expert Predictions Max    1068.25\n",
      "trainer/Z Expert Predictions Min     313.559\n",
      "trainer/Z Policy Predictions Mean    115.284\n",
      "trainer/Z Policy Predictions Std     383.615\n",
      "trainer/Z Policy Predictions Max    1022.04\n",
      "trainer/Z Policy Predictions Min    -374.627\n",
      "trainer/Z Expert Targets Mean        992.424\n",
      "trainer/Z Expert Targets Std          87.9656\n",
      "trainer/Z Expert Targets Max        1042.68\n",
      "trainer/Z Expert Targets Min         270.692\n",
      "trainer/Z Policy Targets Mean        121.848\n",
      "trainer/Z Policy Targets Std         380.266\n",
      "trainer/Z Policy Targets Max         997.375\n",
      "trainer/Z Policy Targets Min        -363.09\n",
      "trainer/Log Pis Mean                  27.9607\n",
      "trainer/Log Pis Std                    9.02451\n",
      "trainer/Policy mu Mean                -0.189266\n",
      "trainer/Policy mu Std                  2.11363\n",
      "trainer/Policy log std Mean           -2.91326\n",
      "trainer/Policy log std Std             1.49259\n",
      "exploration/num steps total        22032\n",
      "exploration/num paths total          121\n",
      "evaluation/num steps total         71341\n",
      "evaluation/num paths total           163\n",
      "evaluation/path length Mean          359.6\n",
      "evaluation/path length Std           240.238\n",
      "evaluation/path length Max           792\n",
      "evaluation/path length Min            29\n",
      "evaluation/Rewards Mean                3.73329\n",
      "evaluation/Rewards Std                 1.42938\n",
      "evaluation/Rewards Max                 6.56932\n",
      "evaluation/Rewards Min                -1.89376\n",
      "evaluation/Returns Mean             1342.49\n",
      "evaluation/Returns Std               925.157\n",
      "evaluation/Returns Max              2942.07\n",
      "evaluation/Returns Min                 9.61586\n",
      "evaluation/Estimation Bias Mean      924.98\n",
      "evaluation/Estimation Bias Std       236.737\n",
      "evaluation/EB/Q_True Mean             72.3435\n",
      "evaluation/EB/Q_True Std             144.453\n",
      "evaluation/EB/Q_Pred Mean            997.324\n",
      "evaluation/EB/Q_Pred Std             177.119\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1342.49\n",
      "evaluation/Actions Mean                0.00484686\n",
      "evaluation/Actions Std                 0.499305\n",
      "evaluation/Actions Max                 0.99547\n",
      "evaluation/Actions Min                -0.999459\n",
      "time/backward_policy (s)               1.76491\n",
      "time/backward_zf1 (s)                  1.87213\n",
      "time/backward_zf2 (s)                  1.81887\n",
      "time/data sampling (s)                 0.247382\n",
      "time/data storing (s)                  0.0139643\n",
      "time/evaluation sampling (s)           1.40094\n",
      "time/exploration sampling (s)          0.320781\n",
      "time/logging (s)                       0.00522145\n",
      "time/preback_alpha (s)                 0.542689\n",
      "time/preback_policy (s)                1.04958\n",
      "time/preback_start (s)                 0.139064\n",
      "time/preback_zf (s)                    5.02161\n",
      "time/saving (s)                        0.00606568\n",
      "time/training (s)                      2.22487\n",
      "time/epoch (s)                        16.4281\n",
      "time/total (s)                       270.099\n",
      "Epoch                                 15\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:40:53.919934 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 16 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 27000\n",
      "trainer/ZF1 Loss                     235.149\n",
      "trainer/ZF2 Loss                     233.42\n",
      "trainer/ZF Expert Reward              29.5851\n",
      "trainer/ZF Policy Reward             -12.4741\n",
      "trainer/ZF CHI2 Term                 305.209\n",
      "trainer/Policy Loss                 -150.341\n",
      "trainer/Bias Loss                   2353.81\n",
      "trainer/Bias Value                    20.8726\n",
      "trainer/Policy Grad Norm              75.0843\n",
      "trainer/Policy Param Norm             23.5885\n",
      "trainer/Zf1 Grad Norm               4046.31\n",
      "trainer/Zf1 Param Norm                61.1179\n",
      "trainer/Zf2 Grad Norm               2529.53\n",
      "trainer/Zf2 Param Norm                61.6572\n",
      "trainer/Z Expert Predictions Mean   1085.67\n",
      "trainer/Z Expert Predictions Std      96.9607\n",
      "trainer/Z Expert Predictions Max    1140.7\n",
      "trainer/Z Expert Predictions Min     358.887\n",
      "trainer/Z Policy Predictions Mean    135.026\n",
      "trainer/Z Policy Predictions Std     433.696\n",
      "trainer/Z Policy Predictions Max    1132.08\n",
      "trainer/Z Policy Predictions Min    -389.967\n",
      "trainer/Z Expert Targets Mean       1056.09\n",
      "trainer/Z Expert Targets Std         115.572\n",
      "trainer/Z Expert Targets Max        1118.59\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        147.5\n",
      "trainer/Z Policy Targets Std         433.828\n",
      "trainer/Z Policy Targets Max        1111.1\n",
      "trainer/Z Policy Targets Min        -380.005\n",
      "trainer/Log Pis Mean                  29.1567\n",
      "trainer/Log Pis Std                    9.02511\n",
      "trainer/Policy mu Mean                -0.0414895\n",
      "trainer/Policy mu Std                  2.23616\n",
      "trainer/Policy log std Mean           -2.8679\n",
      "trainer/Policy log std Std             1.58762\n",
      "exploration/num steps total        22088\n",
      "exploration/num paths total          122\n",
      "evaluation/num steps total         72780\n",
      "evaluation/num paths total           173\n",
      "evaluation/path length Mean          143.9\n",
      "evaluation/path length Std            97.3596\n",
      "evaluation/path length Max           303\n",
      "evaluation/path length Min            11\n",
      "evaluation/Rewards Mean                3.31154\n",
      "evaluation/Rewards Std                 1.87711\n",
      "evaluation/Rewards Max                 6.63836\n",
      "evaluation/Rewards Min                -2.43422\n",
      "evaluation/Returns Mean              476.531\n",
      "evaluation/Returns Std               332.968\n",
      "evaluation/Returns Max              1019.04\n",
      "evaluation/Returns Min                -2.74473\n",
      "evaluation/Estimation Bias Mean      945.652\n",
      "evaluation/Estimation Bias Std       270.414\n",
      "evaluation/EB/Q_True Mean             31.9487\n",
      "evaluation/EB/Q_True Std              73.2725\n",
      "evaluation/EB/Q_Pred Mean            977.6\n",
      "evaluation/EB/Q_Pred Std             252.916\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           476.531\n",
      "evaluation/Actions Mean                0.0219818\n",
      "evaluation/Actions Std                 0.525046\n",
      "evaluation/Actions Max                 0.999983\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.73364\n",
      "time/backward_zf1 (s)                  1.85913\n",
      "time/backward_zf2 (s)                  1.7971\n",
      "time/data sampling (s)                 0.238577\n",
      "time/data storing (s)                  0.0140012\n",
      "time/evaluation sampling (s)           0.794969\n",
      "time/exploration sampling (s)          0.317974\n",
      "time/logging (s)                       0.00268961\n",
      "time/preback_alpha (s)                 0.544895\n",
      "time/preback_policy (s)                1.00922\n",
      "time/preback_start (s)                 0.13897\n",
      "time/preback_zf (s)                    5.01994\n",
      "time/saving (s)                        0.00560698\n",
      "time/training (s)                      2.36589\n",
      "time/epoch (s)                        15.8426\n",
      "time/total (s)                       285.964\n",
      "Epoch                                 16\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:41:09.858329 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 17 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 28000\n",
      "trainer/ZF1 Loss                      16.2319\n",
      "trainer/ZF2 Loss                      17.6247\n",
      "trainer/ZF Expert Reward              30.752\n",
      "trainer/ZF Policy Reward              -2.05507\n",
      "trainer/ZF CHI2 Term                  80.8776\n",
      "trainer/Policy Loss                 -203.542\n",
      "trainer/Bias Loss                    190.259\n",
      "trainer/Bias Value                    21.7028\n",
      "trainer/Policy Grad Norm              96.2628\n",
      "trainer/Policy Param Norm             23.9863\n",
      "trainer/Zf1 Grad Norm               2358.96\n",
      "trainer/Zf1 Param Norm                62.1845\n",
      "trainer/Zf2 Grad Norm               2662.93\n",
      "trainer/Zf2 Param Norm                62.7526\n",
      "trainer/Z Expert Predictions Mean   1159.26\n",
      "trainer/Z Expert Predictions Std     101.265\n",
      "trainer/Z Expert Predictions Max    1217.56\n",
      "trainer/Z Expert Predictions Min     467.546\n",
      "trainer/Z Policy Predictions Mean    186.813\n",
      "trainer/Z Policy Predictions Std     478.596\n",
      "trainer/Z Policy Predictions Max    1210.63\n",
      "trainer/Z Policy Predictions Min    -397.17\n",
      "trainer/Z Expert Targets Mean       1128.51\n",
      "trainer/Z Expert Targets Std         105.504\n",
      "trainer/Z Expert Targets Max        1189.36\n",
      "trainer/Z Expert Targets Min         431.371\n",
      "trainer/Z Policy Targets Mean        188.868\n",
      "trainer/Z Policy Targets Std         475.109\n",
      "trainer/Z Policy Targets Max        1176.2\n",
      "trainer/Z Policy Targets Min        -386.344\n",
      "trainer/Log Pis Mean                  31.4568\n",
      "trainer/Log Pis Std                   10.0345\n",
      "trainer/Policy mu Mean                 0.0753406\n",
      "trainer/Policy mu Std                  2.49203\n",
      "trainer/Policy log std Mean           -2.98149\n",
      "trainer/Policy log std Std             1.39434\n",
      "exploration/num steps total        23088\n",
      "exploration/num paths total          123\n",
      "evaluation/num steps total         74361\n",
      "evaluation/num paths total           183\n",
      "evaluation/path length Mean          158.1\n",
      "evaluation/path length Std            95.6666\n",
      "evaluation/path length Max           295\n",
      "evaluation/path length Min            11\n",
      "evaluation/Rewards Mean                3.4488\n",
      "evaluation/Rewards Std                 1.71153\n",
      "evaluation/Rewards Max                 6.32173\n",
      "evaluation/Rewards Min                -3.46601\n",
      "evaluation/Returns Mean              545.256\n",
      "evaluation/Returns Std               397.708\n",
      "evaluation/Returns Max              1185.94\n",
      "evaluation/Returns Min                 4.23416\n",
      "evaluation/Estimation Bias Mean     1059.27\n",
      "evaluation/Estimation Bias Std       260.866\n",
      "evaluation/EB/Q_True Mean             47.6118\n",
      "evaluation/EB/Q_True Std             110.293\n",
      "evaluation/EB/Q_Pred Mean           1106.88\n",
      "evaluation/EB/Q_Pred Std             191.185\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           545.256\n",
      "evaluation/Actions Mean                0.00950792\n",
      "evaluation/Actions Std                 0.536528\n",
      "evaluation/Actions Max                 0.995023\n",
      "evaluation/Actions Min                -0.99853\n",
      "time/backward_policy (s)               1.9035\n",
      "time/backward_zf1 (s)                  2.00585\n",
      "time/backward_zf2 (s)                  1.97177\n",
      "time/data sampling (s)                 0.243129\n",
      "time/data storing (s)                  0.0136815\n",
      "time/evaluation sampling (s)           0.614949\n",
      "time/exploration sampling (s)          0.320099\n",
      "time/logging (s)                       0.00293942\n",
      "time/preback_alpha (s)                 0.542587\n",
      "time/preback_policy (s)                1.16367\n",
      "time/preback_start (s)                 0.139345\n",
      "time/preback_zf (s)                    5.00949\n",
      "time/saving (s)                        0.00562864\n",
      "time/training (s)                      1.93596\n",
      "time/epoch (s)                        15.8726\n",
      "time/total (s)                       301.858\n",
      "Epoch                                 17\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:41:26.995647 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 18 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 29000\n",
      "trainer/ZF1 Loss                      54.9469\n",
      "trainer/ZF2 Loss                      40.2622\n",
      "trainer/ZF Expert Reward              29.3939\n",
      "trainer/ZF Policy Reward              -5.14999\n",
      "trainer/ZF CHI2 Term                 116.054\n",
      "trainer/Policy Loss                 -283.288\n",
      "trainer/Bias Loss                    174.68\n",
      "trainer/Bias Value                    22.4829\n",
      "trainer/Policy Grad Norm             107.64\n",
      "trainer/Policy Param Norm             24.3083\n",
      "trainer/Zf1 Grad Norm               3709.13\n",
      "trainer/Zf1 Param Norm                63.1685\n",
      "trainer/Zf2 Grad Norm               3870.43\n",
      "trainer/Zf2 Param Norm                63.726\n",
      "trainer/Z Expert Predictions Mean   1228.75\n",
      "trainer/Z Expert Predictions Std     104.307\n",
      "trainer/Z Expert Predictions Max    1283.18\n",
      "trainer/Z Expert Predictions Min     597.383\n",
      "trainer/Z Policy Predictions Mean    265.638\n",
      "trainer/Z Policy Predictions Std     530.244\n",
      "trainer/Z Policy Predictions Max    1260.38\n",
      "trainer/Z Policy Predictions Min    -408.254\n",
      "trainer/Z Expert Targets Mean       1199.36\n",
      "trainer/Z Expert Targets Std         105.629\n",
      "trainer/Z Expert Targets Max        1256.82\n",
      "trainer/Z Expert Targets Min         539.443\n",
      "trainer/Z Policy Targets Mean        270.788\n",
      "trainer/Z Policy Targets Std         520.991\n",
      "trainer/Z Policy Targets Max        1246.02\n",
      "trainer/Z Policy Targets Min        -397.253\n",
      "trainer/Log Pis Mean                  34.2479\n",
      "trainer/Log Pis Std                   14.8505\n",
      "trainer/Policy mu Mean                -0.0287363\n",
      "trainer/Policy mu Std                  3.10395\n",
      "trainer/Policy log std Mean           -3.10458\n",
      "trainer/Policy log std Std             1.29193\n",
      "exploration/num steps total        23088\n",
      "exploration/num paths total          123\n",
      "evaluation/num steps total         84361\n",
      "evaluation/num paths total           193\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                2.99556\n",
      "evaluation/Rewards Std                 2.30411\n",
      "evaluation/Rewards Max                 6.68493\n",
      "evaluation/Rewards Min                -3.05265\n",
      "evaluation/Returns Mean             2995.56\n",
      "evaluation/Returns Std              1642.54\n",
      "evaluation/Returns Max              3973.15\n",
      "evaluation/Returns Min             -1438.23\n",
      "evaluation/Estimation Bias Mean     1045.29\n",
      "evaluation/Estimation Bias Std       490.588\n",
      "evaluation/EB/Q_True Mean            -15.3088\n",
      "evaluation/EB/Q_True Std              53.9776\n",
      "evaluation/EB/Q_Pred Mean           1029.98\n",
      "evaluation/EB/Q_Pred Std             480.166\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          2995.56\n",
      "evaluation/Actions Mean               -0.0615771\n",
      "evaluation/Actions Std                 0.577017\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.85986\n",
      "time/backward_zf1 (s)                  1.9485\n",
      "time/backward_zf2 (s)                  1.9099\n",
      "time/data sampling (s)                 0.25133\n",
      "time/data storing (s)                  0.0143758\n",
      "time/evaluation sampling (s)           1.71873\n",
      "time/exploration sampling (s)          0.321763\n",
      "time/logging (s)                       0.0128238\n",
      "time/preback_alpha (s)                 0.552419\n",
      "time/preback_policy (s)                1.10948\n",
      "time/preback_start (s)                 0.140642\n",
      "time/preback_zf (s)                    5.05225\n",
      "time/saving (s)                        0.00595093\n",
      "time/training (s)                      2.18302\n",
      "time/epoch (s)                        17.081\n",
      "time/total (s)                       318.96\n",
      "Epoch                                 18\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:41:44.264269 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 19 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 30000\n",
      "trainer/ZF1 Loss                      46.9687\n",
      "trainer/ZF2 Loss                      43.7217\n",
      "trainer/ZF Expert Reward              27.4482\n",
      "trainer/ZF Policy Reward              -1.96662\n",
      "trainer/ZF CHI2 Term                 106.905\n",
      "trainer/Policy Loss                 -374.822\n",
      "trainer/Bias Loss                    198.982\n",
      "trainer/Bias Value                    23.2516\n",
      "trainer/Policy Grad Norm              81.9424\n",
      "trainer/Policy Param Norm             24.6053\n",
      "trainer/Zf1 Grad Norm               3323.52\n",
      "trainer/Zf1 Param Norm                64.11\n",
      "trainer/Zf2 Grad Norm               3774.34\n",
      "trainer/Zf2 Param Norm                64.666\n",
      "trainer/Z Expert Predictions Mean   1293.55\n",
      "trainer/Z Expert Predictions Std      92.4036\n",
      "trainer/Z Expert Predictions Max    1355.86\n",
      "trainer/Z Expert Predictions Min     795.723\n",
      "trainer/Z Policy Predictions Mean    352.782\n",
      "trainer/Z Policy Predictions Std     528.313\n",
      "trainer/Z Policy Predictions Max    1347.05\n",
      "trainer/Z Policy Predictions Min    -404.511\n",
      "trainer/Z Expert Targets Mean       1266.1\n",
      "trainer/Z Expert Targets Std          88.8809\n",
      "trainer/Z Expert Targets Max        1328.66\n",
      "trainer/Z Expert Targets Min         798.032\n",
      "trainer/Z Policy Targets Mean        354.748\n",
      "trainer/Z Policy Targets Std         520.621\n",
      "trainer/Z Policy Targets Max        1319.42\n",
      "trainer/Z Policy Targets Min        -393.511\n",
      "trainer/Log Pis Mean                  32.47\n",
      "trainer/Log Pis Std                   11.5732\n",
      "trainer/Policy mu Mean                -0.128197\n",
      "trainer/Policy mu Std                  2.88857\n",
      "trainer/Policy log std Mean           -3.14488\n",
      "trainer/Policy log std Std             1.22726\n",
      "exploration/num steps total        24088\n",
      "exploration/num paths total          124\n",
      "evaluation/num steps total         93525\n",
      "evaluation/num paths total           203\n",
      "evaluation/path length Mean          916.4\n",
      "evaluation/path length Std           250.8\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min           164\n",
      "evaluation/Rewards Mean                3.58374\n",
      "evaluation/Rewards Std                 1.17714\n",
      "evaluation/Rewards Max                 6.07626\n",
      "evaluation/Rewards Min                -3.95403\n",
      "evaluation/Returns Mean             3284.14\n",
      "evaluation/Returns Std              1081.31\n",
      "evaluation/Returns Max              3764.04\n",
      "evaluation/Returns Min                59.8467\n",
      "evaluation/Estimation Bias Mean     1247.04\n",
      "evaluation/Estimation Bias Std       229.383\n",
      "evaluation/EB/Q_True Mean             37.4443\n",
      "evaluation/EB/Q_True Std             109.933\n",
      "evaluation/EB/Q_Pred Mean           1284.49\n",
      "evaluation/EB/Q_Pred Std             177.244\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          3284.14\n",
      "evaluation/Actions Mean               -0.00442211\n",
      "evaluation/Actions Std                 0.554551\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.93291\n",
      "time/backward_zf1 (s)                  2.00274\n",
      "time/backward_zf2 (s)                  1.98931\n",
      "time/data sampling (s)                 0.270686\n",
      "time/data storing (s)                  0.014452\n",
      "time/evaluation sampling (s)           1.73929\n",
      "time/exploration sampling (s)          0.329596\n",
      "time/logging (s)                       0.0118596\n",
      "time/preback_alpha (s)                 0.553076\n",
      "time/preback_policy (s)                1.16923\n",
      "time/preback_start (s)                 0.141706\n",
      "time/preback_zf (s)                    5.04904\n",
      "time/saving (s)                        0.00616698\n",
      "time/training (s)                      1.98938\n",
      "time/epoch (s)                        17.1994\n",
      "time/total (s)                       336.182\n",
      "Epoch                                 19\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:42:00.941049 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 20 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  31000\n",
      "trainer/ZF1 Loss                       34.6375\n",
      "trainer/ZF2 Loss                       38.8443\n",
      "trainer/ZF Expert Reward               24.0666\n",
      "trainer/ZF Policy Reward               -5.6347\n",
      "trainer/ZF CHI2 Term                   99.7076\n",
      "trainer/Policy Loss                  -449.919\n",
      "trainer/Bias Loss                     191.107\n",
      "trainer/Bias Value                     23.989\n",
      "trainer/Policy Grad Norm               96.3054\n",
      "trainer/Policy Param Norm              24.8521\n",
      "trainer/Zf1 Grad Norm                3706.02\n",
      "trainer/Zf1 Param Norm                 65.0104\n",
      "trainer/Zf2 Grad Norm                4249.01\n",
      "trainer/Zf2 Param Norm                 65.5914\n",
      "trainer/Z Expert Predictions Mean    1365.52\n",
      "trainer/Z Expert Predictions Std       88.117\n",
      "trainer/Z Expert Predictions Max     1427.36\n",
      "trainer/Z Expert Predictions Min      776.508\n",
      "trainer/Z Policy Predictions Mean     431.129\n",
      "trainer/Z Policy Predictions Std      586.381\n",
      "trainer/Z Policy Predictions Max     1412.92\n",
      "trainer/Z Policy Predictions Min     -407.517\n",
      "trainer/Z Expert Targets Mean        1341.45\n",
      "trainer/Z Expert Targets Std           87.6079\n",
      "trainer/Z Expert Targets Max         1399.57\n",
      "trainer/Z Expert Targets Min          697.626\n",
      "trainer/Z Policy Targets Mean         436.764\n",
      "trainer/Z Policy Targets Std          583.689\n",
      "trainer/Z Policy Targets Max         1388.33\n",
      "trainer/Z Policy Targets Min         -395.819\n",
      "trainer/Log Pis Mean                   33.6014\n",
      "trainer/Log Pis Std                    11.6384\n",
      "trainer/Policy mu Mean                 -0.202945\n",
      "trainer/Policy mu Std                   3.09918\n",
      "trainer/Policy log std Mean            -3.17449\n",
      "trainer/Policy log std Std              1.44101\n",
      "exploration/num steps total         24088\n",
      "exploration/num paths total           124\n",
      "evaluation/num steps total         103525\n",
      "evaluation/num paths total            213\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.01037\n",
      "evaluation/Rewards Std                  1.01597\n",
      "evaluation/Rewards Max                  5.90851\n",
      "evaluation/Rewards Min                 -1.75428\n",
      "evaluation/Returns Mean              4010.37\n",
      "evaluation/Returns Std                127.251\n",
      "evaluation/Returns Max               4180.77\n",
      "evaluation/Returns Min               3746.88\n",
      "evaluation/Estimation Bias Mean      1363.1\n",
      "evaluation/Estimation Bias Std        159.241\n",
      "evaluation/EB/Q_True Mean              34.3873\n",
      "evaluation/EB/Q_True Std              106.628\n",
      "evaluation/EB/Q_Pred Mean            1397.48\n",
      "evaluation/EB/Q_Pred Std              123.617\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4010.37\n",
      "evaluation/Actions Mean                 0.0300096\n",
      "evaluation/Actions Std                  0.522514\n",
      "evaluation/Actions Max                  0.996262\n",
      "evaluation/Actions Min                 -0.99916\n",
      "time/backward_policy (s)                1.67973\n",
      "time/backward_zf1 (s)                   1.79793\n",
      "time/backward_zf2 (s)                   1.72617\n",
      "time/data sampling (s)                  0.268005\n",
      "time/data storing (s)                   0.0138428\n",
      "time/evaluation sampling (s)            1.73342\n",
      "time/exploration sampling (s)           0.31507\n",
      "time/logging (s)                        0.0167927\n",
      "time/preback_alpha (s)                  0.54186\n",
      "time/preback_policy (s)                 0.957111\n",
      "time/preback_start (s)                  0.138418\n",
      "time/preback_zf (s)                     5.00456\n",
      "time/saving (s)                         0.0105454\n",
      "time/training (s)                       2.41217\n",
      "time/epoch (s)                         16.6156\n",
      "time/total (s)                        352.82\n",
      "Epoch                                  20\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:42:17.693000 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 21 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  32000\n",
      "trainer/ZF1 Loss                      721.266\n",
      "trainer/ZF2 Loss                      658.436\n",
      "trainer/ZF Expert Reward               41.2274\n",
      "trainer/ZF Policy Reward                0.668726\n",
      "trainer/ZF CHI2 Term                  763.431\n",
      "trainer/Policy Loss                  -505.267\n",
      "trainer/Bias Loss                    6591.13\n",
      "trainer/Bias Value                     24.6764\n",
      "trainer/Policy Grad Norm              104.893\n",
      "trainer/Policy Param Norm              25.0857\n",
      "trainer/Zf1 Grad Norm                7130.14\n",
      "trainer/Zf1 Param Norm                 65.933\n",
      "trainer/Zf2 Grad Norm                8699.99\n",
      "trainer/Zf2 Param Norm                 66.5108\n",
      "trainer/Z Expert Predictions Mean    1432.75\n",
      "trainer/Z Expert Predictions Std       89.179\n",
      "trainer/Z Expert Predictions Max     1498.62\n",
      "trainer/Z Expert Predictions Min      920.217\n",
      "trainer/Z Policy Predictions Mean     490.803\n",
      "trainer/Z Policy Predictions Std      629.007\n",
      "trainer/Z Policy Predictions Max     1480.77\n",
      "trainer/Z Policy Predictions Min     -407.665\n",
      "trainer/Z Expert Targets Mean        1391.53\n",
      "trainer/Z Expert Targets Std          152.636\n",
      "trainer/Z Expert Targets Max         1469.11\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         490.134\n",
      "trainer/Z Policy Targets Std          619.641\n",
      "trainer/Z Policy Targets Max         1464.23\n",
      "trainer/Z Policy Targets Min         -396.007\n",
      "trainer/Log Pis Mean                   33.3552\n",
      "trainer/Log Pis Std                    12.8156\n",
      "trainer/Policy mu Mean                 -0.38966\n",
      "trainer/Policy mu Std                   3.37545\n",
      "trainer/Policy log std Mean            -2.99075\n",
      "trainer/Policy log std Std              1.46203\n",
      "exploration/num steps total         26088\n",
      "exploration/num paths total           126\n",
      "evaluation/num steps total         112616\n",
      "evaluation/num paths total            223\n",
      "evaluation/path length Mean           909.1\n",
      "evaluation/path length Std            272.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             91\n",
      "evaluation/Rewards Mean                 3.36864\n",
      "evaluation/Rewards Std                  1.98645\n",
      "evaluation/Rewards Max                  6.5145\n",
      "evaluation/Rewards Min                 -3.06966\n",
      "evaluation/Returns Mean              3062.43\n",
      "evaluation/Returns Std               1820.22\n",
      "evaluation/Returns Max               4250.37\n",
      "evaluation/Returns Min              -1024.94\n",
      "evaluation/Estimation Bias Mean      1309.52\n",
      "evaluation/Estimation Bias Std        364.507\n",
      "evaluation/EB/Q_True Mean              42.4641\n",
      "evaluation/EB/Q_True Std              123.8\n",
      "evaluation/EB/Q_Pred Mean            1351.99\n",
      "evaluation/EB/Q_Pred Std              346.216\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3062.43\n",
      "evaluation/Actions Mean                 0.0709835\n",
      "evaluation/Actions Std                  0.55642\n",
      "evaluation/Actions Max                  0.999985\n",
      "evaluation/Actions Min                 -0.999969\n",
      "time/backward_policy (s)                1.69716\n",
      "time/backward_zf1 (s)                   1.8128\n",
      "time/backward_zf2 (s)                   1.74979\n",
      "time/data sampling (s)                  0.264573\n",
      "time/data storing (s)                   0.0139111\n",
      "time/evaluation sampling (s)            1.70125\n",
      "time/exploration sampling (s)           0.316554\n",
      "time/logging (s)                        0.011701\n",
      "time/preback_alpha (s)                  0.544173\n",
      "time/preback_policy (s)                 0.957972\n",
      "time/preback_start (s)                  0.138952\n",
      "time/preback_zf (s)                     5.01507\n",
      "time/saving (s)                         0.00631949\n",
      "time/training (s)                       2.45213\n",
      "time/epoch (s)                         16.6824\n",
      "time/total (s)                        369.523\n",
      "Epoch                                  21\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:42:34.748063 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 22 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  33000\n",
      "trainer/ZF1 Loss                       27.9696\n",
      "trainer/ZF2 Loss                       39.0088\n",
      "trainer/ZF Expert Reward               31.8452\n",
      "trainer/ZF Policy Reward                1.4088\n",
      "trainer/ZF CHI2 Term                   97.4013\n",
      "trainer/Policy Loss                  -624.7\n",
      "trainer/Bias Loss                     154.562\n",
      "trainer/Bias Value                     25.3263\n",
      "trainer/Policy Grad Norm              137.192\n",
      "trainer/Policy Param Norm              25.317\n",
      "trainer/Zf1 Grad Norm                2402.19\n",
      "trainer/Zf1 Param Norm                 66.8979\n",
      "trainer/Zf2 Grad Norm                2584.34\n",
      "trainer/Zf2 Param Norm                 67.4353\n",
      "trainer/Z Expert Predictions Mean    1504.53\n",
      "trainer/Z Expert Predictions Std       92.3893\n",
      "trainer/Z Expert Predictions Max     1568.52\n",
      "trainer/Z Expert Predictions Min      809.67\n",
      "trainer/Z Policy Predictions Mean     602.858\n",
      "trainer/Z Policy Predictions Std      616.812\n",
      "trainer/Z Policy Predictions Max     1556.78\n",
      "trainer/Z Policy Predictions Min     -420.516\n",
      "trainer/Z Expert Targets Mean        1472.69\n",
      "trainer/Z Expert Targets Std           94.2313\n",
      "trainer/Z Expert Targets Max         1536.73\n",
      "trainer/Z Expert Targets Min          795.535\n",
      "trainer/Z Policy Targets Mean         601.449\n",
      "trainer/Z Policy Targets Std          602.913\n",
      "trainer/Z Policy Targets Max         1532.68\n",
      "trainer/Z Policy Targets Min         -412.148\n",
      "trainer/Log Pis Mean                   33.8139\n",
      "trainer/Log Pis Std                    11.733\n",
      "trainer/Policy mu Mean                 -0.15711\n",
      "trainer/Policy mu Std                   2.995\n",
      "trainer/Policy log std Mean            -3.36891\n",
      "trainer/Policy log std Std              1.41483\n",
      "exploration/num steps total         30088\n",
      "exploration/num paths total           130\n",
      "evaluation/num steps total         121662\n",
      "evaluation/num paths total            233\n",
      "evaluation/path length Mean           904.6\n",
      "evaluation/path length Std            286.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             46\n",
      "evaluation/Rewards Mean                 4.17591\n",
      "evaluation/Rewards Std                  0.978111\n",
      "evaluation/Rewards Max                  6.27841\n",
      "evaluation/Rewards Min                 -1.88922\n",
      "evaluation/Returns Mean              3777.53\n",
      "evaluation/Returns Std               1232.33\n",
      "evaluation/Returns Max               4394.04\n",
      "evaluation/Returns Min                 90.5004\n",
      "evaluation/Estimation Bias Mean      1520.22\n",
      "evaluation/Estimation Bias Std        158.877\n",
      "evaluation/EB/Q_True Mean              42.6247\n",
      "evaluation/EB/Q_True Std              124.178\n",
      "evaluation/EB/Q_Pred Mean            1562.84\n",
      "evaluation/EB/Q_Pred Std               94.7673\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3777.53\n",
      "evaluation/Actions Mean                 0.0431478\n",
      "evaluation/Actions Std                  0.523229\n",
      "evaluation/Actions Max                  0.997494\n",
      "evaluation/Actions Min                 -0.998356\n",
      "time/backward_policy (s)                1.83584\n",
      "time/backward_zf1 (s)                   1.94249\n",
      "time/backward_zf2 (s)                   1.88555\n",
      "time/data sampling (s)                  0.266384\n",
      "time/data storing (s)                   0.0137951\n",
      "time/evaluation sampling (s)            1.70408\n",
      "time/exploration sampling (s)           0.324011\n",
      "time/logging (s)                        0.0109606\n",
      "time/preback_alpha (s)                  0.548185\n",
      "time/preback_policy (s)                 1.08084\n",
      "time/preback_start (s)                  0.140949\n",
      "time/preback_zf (s)                     5.02426\n",
      "time/saving (s)                         0.00620787\n",
      "time/training (s)                       2.2071\n",
      "time/epoch (s)                         16.9906\n",
      "time/total (s)                        386.532\n",
      "Epoch                                  22\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:42:51.675193 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 23 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  34000\n",
      "trainer/ZF1 Loss                       93.3566\n",
      "trainer/ZF2 Loss                       95.2537\n",
      "trainer/ZF Expert Reward               27.2181\n",
      "trainer/ZF Policy Reward               -2.61364\n",
      "trainer/ZF CHI2 Term                  158.431\n",
      "trainer/Policy Loss                  -645.537\n",
      "trainer/Bias Loss                     205.007\n",
      "trainer/Bias Value                     25.9168\n",
      "trainer/Policy Grad Norm              118.436\n",
      "trainer/Policy Param Norm              25.5169\n",
      "trainer/Zf1 Grad Norm                3908.13\n",
      "trainer/Zf1 Param Norm                 67.7552\n",
      "trainer/Zf2 Grad Norm                3803.9\n",
      "trainer/Zf2 Param Norm                 68.2653\n",
      "trainer/Z Expert Predictions Mean    1563.03\n",
      "trainer/Z Expert Predictions Std      106.82\n",
      "trainer/Z Expert Predictions Max     1637.7\n",
      "trainer/Z Expert Predictions Min      997.803\n",
      "trainer/Z Policy Predictions Mean     621.089\n",
      "trainer/Z Policy Predictions Std      632.594\n",
      "trainer/Z Policy Predictions Max     1632.22\n",
      "trainer/Z Policy Predictions Min     -419.261\n",
      "trainer/Z Expert Targets Mean        1535.81\n",
      "trainer/Z Expert Targets Std          105.438\n",
      "trainer/Z Expert Targets Max         1605.94\n",
      "trainer/Z Expert Targets Min          956.21\n",
      "trainer/Z Policy Targets Mean         623.703\n",
      "trainer/Z Policy Targets Std          628.118\n",
      "trainer/Z Policy Targets Max         1608.16\n",
      "trainer/Z Policy Targets Min         -403.936\n",
      "trainer/Log Pis Mean                   34.6406\n",
      "trainer/Log Pis Std                    12.8177\n",
      "trainer/Policy mu Mean                 -0.0769039\n",
      "trainer/Policy mu Std                   2.99418\n",
      "trainer/Policy log std Mean            -3.30865\n",
      "trainer/Policy log std Std              1.41625\n",
      "exploration/num steps total         30088\n",
      "exploration/num paths total           130\n",
      "evaluation/num steps total         131662\n",
      "evaluation/num paths total            243\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.98264\n",
      "evaluation/Rewards Std                  1.14967\n",
      "evaluation/Rewards Max                  6.37788\n",
      "evaluation/Rewards Min                 -3.42263\n",
      "evaluation/Returns Mean              3982.64\n",
      "evaluation/Returns Std                108.801\n",
      "evaluation/Returns Max               4191.61\n",
      "evaluation/Returns Min               3803.88\n",
      "evaluation/Estimation Bias Mean      1567.44\n",
      "evaluation/Estimation Bias Std        165.583\n",
      "evaluation/EB/Q_True Mean              36.1302\n",
      "evaluation/EB/Q_True Std              111.22\n",
      "evaluation/EB/Q_Pred Mean            1603.57\n",
      "evaluation/EB/Q_Pred Std              130.438\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3982.64\n",
      "evaluation/Actions Mean                 0.0065004\n",
      "evaluation/Actions Std                  0.535756\n",
      "evaluation/Actions Max                  0.997033\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.74402\n",
      "time/backward_zf1 (s)                   1.86169\n",
      "time/backward_zf2 (s)                   1.79386\n",
      "time/data sampling (s)                  0.281344\n",
      "time/data storing (s)                   0.0144504\n",
      "time/evaluation sampling (s)            1.73025\n",
      "time/exploration sampling (s)           0.314602\n",
      "time/logging (s)                        0.0119764\n",
      "time/preback_alpha (s)                  0.552071\n",
      "time/preback_policy (s)                 1.00992\n",
      "time/preback_start (s)                  0.141127\n",
      "time/preback_zf (s)                     5.03474\n",
      "time/saving (s)                         0.0067247\n",
      "time/training (s)                       2.36443\n",
      "time/epoch (s)                         16.8612\n",
      "time/total (s)                        403.415\n",
      "Epoch                                  23\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:43:09.010166 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 24 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  35000\n",
      "trainer/ZF1 Loss                       69.5549\n",
      "trainer/ZF2 Loss                       62.2091\n",
      "trainer/ZF Expert Reward               31.1353\n",
      "trainer/ZF Policy Reward               -0.268581\n",
      "trainer/ZF CHI2 Term                  130.823\n",
      "trainer/Policy Loss                  -809.766\n",
      "trainer/Bias Loss                     280.102\n",
      "trainer/Bias Value                     26.3983\n",
      "trainer/Policy Grad Norm              133.896\n",
      "trainer/Policy Param Norm              25.7158\n",
      "trainer/Zf1 Grad Norm                6218.21\n",
      "trainer/Zf1 Param Norm                 68.5826\n",
      "trainer/Zf2 Grad Norm                4772.04\n",
      "trainer/Zf2 Param Norm                 69.0694\n",
      "trainer/Z Expert Predictions Mean    1637.11\n",
      "trainer/Z Expert Predictions Std       99.2607\n",
      "trainer/Z Expert Predictions Max     1708.17\n",
      "trainer/Z Expert Predictions Min      996.853\n",
      "trainer/Z Policy Predictions Mean     784.632\n",
      "trainer/Z Policy Predictions Std      641.538\n",
      "trainer/Z Policy Predictions Max     1697.56\n",
      "trainer/Z Policy Predictions Min     -385.64\n",
      "trainer/Z Expert Targets Mean        1605.98\n",
      "trainer/Z Expert Targets Std          100.019\n",
      "trainer/Z Expert Targets Max         1674.52\n",
      "trainer/Z Expert Targets Min          970.206\n",
      "trainer/Z Policy Targets Mean         784.901\n",
      "trainer/Z Policy Targets Std          630.322\n",
      "trainer/Z Policy Targets Max         1674.17\n",
      "trainer/Z Policy Targets Min         -373.787\n",
      "trainer/Log Pis Mean                   33.8758\n",
      "trainer/Log Pis Std                    13.2158\n",
      "trainer/Policy mu Mean                 -0.248343\n",
      "trainer/Policy mu Std                   2.73132\n",
      "trainer/Policy log std Mean            -3.49051\n",
      "trainer/Policy log std Std              1.26576\n",
      "exploration/num steps total         30088\n",
      "exploration/num paths total           130\n",
      "evaluation/num steps total         141657\n",
      "evaluation/num paths total            253\n",
      "evaluation/path length Mean           999.5\n",
      "evaluation/path length Std              1.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            995\n",
      "evaluation/Rewards Mean                 4.23719\n",
      "evaluation/Rewards Std                  1.14491\n",
      "evaluation/Rewards Max                  6.44543\n",
      "evaluation/Rewards Min                 -2.83747\n",
      "evaluation/Returns Mean              4235.07\n",
      "evaluation/Returns Std                139.616\n",
      "evaluation/Returns Max               4476.16\n",
      "evaluation/Returns Min               3967.98\n",
      "evaluation/Estimation Bias Mean      1620.07\n",
      "evaluation/Estimation Bias Std        189.489\n",
      "evaluation/EB/Q_True Mean              39.1872\n",
      "evaluation/EB/Q_True Std              120.843\n",
      "evaluation/EB/Q_Pred Mean            1659.26\n",
      "evaluation/EB/Q_Pred Std              139.749\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4235.07\n",
      "evaluation/Actions Mean                 0.0182955\n",
      "evaluation/Actions Std                  0.522312\n",
      "evaluation/Actions Max                  0.999692\n",
      "evaluation/Actions Min                 -0.999802\n",
      "time/backward_policy (s)                1.90599\n",
      "time/backward_zf1 (s)                   2.02376\n",
      "time/backward_zf2 (s)                   1.97834\n",
      "time/data sampling (s)                  0.270095\n",
      "time/data storing (s)                   0.0140355\n",
      "time/evaluation sampling (s)            1.74162\n",
      "time/exploration sampling (s)           0.314243\n",
      "time/logging (s)                        0.0119733\n",
      "time/preback_alpha (s)                  0.551678\n",
      "time/preback_policy (s)                 1.14011\n",
      "time/preback_start (s)                  0.140832\n",
      "time/preback_zf (s)                     5.06324\n",
      "time/saving (s)                         0.00647878\n",
      "time/training (s)                       2.10699\n",
      "time/epoch (s)                         17.2694\n",
      "time/total (s)                        420.705\n",
      "Epoch                                  24\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:43:26.016315 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 25 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  36000\n",
      "trainer/ZF1 Loss                       41.2501\n",
      "trainer/ZF2 Loss                       43.6404\n",
      "trainer/ZF Expert Reward               31.5605\n",
      "trainer/ZF Policy Reward                1.62547\n",
      "trainer/ZF CHI2 Term                  107.971\n",
      "trainer/Policy Loss                  -833.587\n",
      "trainer/Bias Loss                     277.597\n",
      "trainer/Bias Value                     26.8097\n",
      "trainer/Policy Grad Norm              132.815\n",
      "trainer/Policy Param Norm              25.9177\n",
      "trainer/Zf1 Grad Norm                3220.76\n",
      "trainer/Zf1 Param Norm                 69.3605\n",
      "trainer/Zf2 Grad Norm                3386.08\n",
      "trainer/Zf2 Param Norm                 69.809\n",
      "trainer/Z Expert Predictions Mean    1699.27\n",
      "trainer/Z Expert Predictions Std      109.227\n",
      "trainer/Z Expert Predictions Max     1774.91\n",
      "trainer/Z Expert Predictions Min      972.079\n",
      "trainer/Z Policy Predictions Mean     809.545\n",
      "trainer/Z Policy Predictions Std      688.374\n",
      "trainer/Z Policy Predictions Max     1756.73\n",
      "trainer/Z Policy Predictions Min     -354.818\n",
      "trainer/Z Expert Targets Mean        1667.71\n",
      "trainer/Z Expert Targets Std          112.962\n",
      "trainer/Z Expert Targets Max         1745.33\n",
      "trainer/Z Expert Targets Min          942.133\n",
      "trainer/Z Policy Targets Mean         807.92\n",
      "trainer/Z Policy Targets Std          679.328\n",
      "trainer/Z Policy Targets Max         1726.68\n",
      "trainer/Z Policy Targets Min         -339.441\n",
      "trainer/Log Pis Mean                   35.9507\n",
      "trainer/Log Pis Std                    18.3607\n",
      "trainer/Policy mu Mean                  0.0016989\n",
      "trainer/Policy mu Std                   3.1686\n",
      "trainer/Policy log std Mean            -3.41667\n",
      "trainer/Policy log std Std              1.36046\n",
      "exploration/num steps total         31088\n",
      "exploration/num paths total           131\n",
      "evaluation/num steps total         150863\n",
      "evaluation/num paths total            263\n",
      "evaluation/path length Mean           920.6\n",
      "evaluation/path length Std            144.624\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            619\n",
      "evaluation/Rewards Mean                 3.83336\n",
      "evaluation/Rewards Std                  1.49949\n",
      "evaluation/Rewards Max                  6.81438\n",
      "evaluation/Rewards Min                 -3.52798\n",
      "evaluation/Returns Mean              3528.99\n",
      "evaluation/Returns Std                618.683\n",
      "evaluation/Returns Max               4184.74\n",
      "evaluation/Returns Min               2342.39\n",
      "evaluation/Estimation Bias Mean      1573.73\n",
      "evaluation/Estimation Bias Std        245.833\n",
      "evaluation/EB/Q_True Mean              36.3929\n",
      "evaluation/EB/Q_True Std              107.649\n",
      "evaluation/EB/Q_Pred Mean            1610.12\n",
      "evaluation/EB/Q_Pred Std              217.811\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3528.99\n",
      "evaluation/Actions Mean                 0.0292044\n",
      "evaluation/Actions Std                  0.542764\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.84716\n",
      "time/backward_zf1 (s)                   1.92623\n",
      "time/backward_zf2 (s)                   1.91198\n",
      "time/data sampling (s)                  0.255834\n",
      "time/data storing (s)                   0.0139036\n",
      "time/evaluation sampling (s)            1.73816\n",
      "time/exploration sampling (s)           0.319861\n",
      "time/logging (s)                        0.0121512\n",
      "time/preback_alpha (s)                  0.543911\n",
      "time/preback_policy (s)                 1.12158\n",
      "time/preback_start (s)                  0.139843\n",
      "time/preback_zf (s)                     5.029\n",
      "time/saving (s)                         0.00647084\n",
      "time/training (s)                       2.06938\n",
      "time/epoch (s)                         16.9355\n",
      "time/total (s)                        437.666\n",
      "Epoch                                  25\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:43:42.566318 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 26 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  37000\n",
      "trainer/ZF1 Loss                       47.3415\n",
      "trainer/ZF2 Loss                       84.2229\n",
      "trainer/ZF Expert Reward               19.4165\n",
      "trainer/ZF Policy Reward               -7.75249\n",
      "trainer/ZF CHI2 Term                  127.223\n",
      "trainer/Policy Loss                  -949.288\n",
      "trainer/Bias Loss                     241.41\n",
      "trainer/Bias Value                     27.1598\n",
      "trainer/Policy Grad Norm              198.158\n",
      "trainer/Policy Param Norm              26.1204\n",
      "trainer/Zf1 Grad Norm                4894.33\n",
      "trainer/Zf1 Param Norm                 70.1186\n",
      "trainer/Zf2 Grad Norm                6229.01\n",
      "trainer/Zf2 Param Norm                 70.5581\n",
      "trainer/Z Expert Predictions Mean    1761.35\n",
      "trainer/Z Expert Predictions Std       77.2207\n",
      "trainer/Z Expert Predictions Max     1838.13\n",
      "trainer/Z Expert Predictions Min     1231.73\n",
      "trainer/Z Policy Predictions Mean     928.944\n",
      "trainer/Z Policy Predictions Std      708.628\n",
      "trainer/Z Policy Predictions Max     1825.22\n",
      "trainer/Z Policy Predictions Min     -285.589\n",
      "trainer/Z Expert Targets Mean        1741.93\n",
      "trainer/Z Expert Targets Std           73.1071\n",
      "trainer/Z Expert Targets Max         1812.65\n",
      "trainer/Z Expert Targets Min         1222.22\n",
      "trainer/Z Policy Targets Mean         936.697\n",
      "trainer/Z Policy Targets Std          705.522\n",
      "trainer/Z Policy Targets Max         1796.28\n",
      "trainer/Z Policy Targets Min         -308.121\n",
      "trainer/Log Pis Mean                   34.6178\n",
      "trainer/Log Pis Std                    15.7346\n",
      "trainer/Policy mu Mean                  0.0331178\n",
      "trainer/Policy mu Std                   2.79207\n",
      "trainer/Policy log std Mean            -3.45222\n",
      "trainer/Policy log std Std              1.31772\n",
      "exploration/num steps total         32088\n",
      "exploration/num paths total           132\n",
      "evaluation/num steps total         160863\n",
      "evaluation/num paths total            273\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.35078\n",
      "evaluation/Rewards Std                  1.08068\n",
      "evaluation/Rewards Max                  6.46841\n",
      "evaluation/Rewards Min                 -1.91808\n",
      "evaluation/Returns Mean              4350.78\n",
      "evaluation/Returns Std                112.246\n",
      "evaluation/Returns Max               4547.91\n",
      "evaluation/Returns Min               4163.56\n",
      "evaluation/Estimation Bias Mean      1762.34\n",
      "evaluation/Estimation Bias Std        175.82\n",
      "evaluation/EB/Q_True Mean              38.7899\n",
      "evaluation/EB/Q_True Std              120.13\n",
      "evaluation/EB/Q_Pred Mean            1801.13\n",
      "evaluation/EB/Q_Pred Std              131.324\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4350.78\n",
      "evaluation/Actions Mean                 0.0314481\n",
      "evaluation/Actions Std                  0.521639\n",
      "evaluation/Actions Max                  0.993152\n",
      "evaluation/Actions Min                 -0.998048\n",
      "time/backward_policy (s)                1.59514\n",
      "time/backward_zf1 (s)                   1.71118\n",
      "time/backward_zf2 (s)                   1.63258\n",
      "time/data sampling (s)                  0.265486\n",
      "time/data storing (s)                   0.0137797\n",
      "time/evaluation sampling (s)            1.73369\n",
      "time/exploration sampling (s)           0.316954\n",
      "time/logging (s)                        0.0122428\n",
      "time/preback_alpha (s)                  0.541329\n",
      "time/preback_policy (s)                 0.878104\n",
      "time/preback_start (s)                  0.138224\n",
      "time/preback_zf (s)                     5.01117\n",
      "time/saving (s)                         0.00646536\n",
      "time/training (s)                       2.62183\n",
      "time/epoch (s)                         16.4782\n",
      "time/total (s)                        454.172\n",
      "Epoch                                  26\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:43:59.904832 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 27 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  38000\n",
      "trainer/ZF1 Loss                       90.1689\n",
      "trainer/ZF2 Loss                       82.9218\n",
      "trainer/ZF Expert Reward               28.7669\n",
      "trainer/ZF Policy Reward                1.71199\n",
      "trainer/ZF CHI2 Term                  148.026\n",
      "trainer/Policy Loss                 -1043.15\n",
      "trainer/Bias Loss                     166.784\n",
      "trainer/Bias Value                     27.4139\n",
      "trainer/Policy Grad Norm              108.816\n",
      "trainer/Policy Param Norm              26.3118\n",
      "trainer/Zf1 Grad Norm                5057.83\n",
      "trainer/Zf1 Param Norm                 70.9028\n",
      "trainer/Zf2 Grad Norm                5018.53\n",
      "trainer/Zf2 Param Norm                 71.3074\n",
      "trainer/Z Expert Predictions Mean    1828.59\n",
      "trainer/Z Expert Predictions Std      104.694\n",
      "trainer/Z Expert Predictions Max     1902.46\n",
      "trainer/Z Expert Predictions Min     1087.3\n",
      "trainer/Z Policy Predictions Mean    1021.45\n",
      "trainer/Z Policy Predictions Std      682.511\n",
      "trainer/Z Policy Predictions Max     1887.5\n",
      "trainer/Z Policy Predictions Min     -286.121\n",
      "trainer/Z Expert Targets Mean        1799.82\n",
      "trainer/Z Expert Targets Std          102.77\n",
      "trainer/Z Expert Targets Max         1874.96\n",
      "trainer/Z Expert Targets Min         1055.75\n",
      "trainer/Z Policy Targets Mean        1019.74\n",
      "trainer/Z Policy Targets Std          677.131\n",
      "trainer/Z Policy Targets Max         1864.17\n",
      "trainer/Z Policy Targets Min         -274.119\n",
      "trainer/Log Pis Mean                   34.7735\n",
      "trainer/Log Pis Std                    14.1765\n",
      "trainer/Policy mu Mean                 -0.00292865\n",
      "trainer/Policy mu Std                   2.44747\n",
      "trainer/Policy log std Mean            -3.68507\n",
      "trainer/Policy log std Std              1.11583\n",
      "exploration/num steps total         33088\n",
      "exploration/num paths total           133\n",
      "evaluation/num steps total         170863\n",
      "evaluation/num paths total            283\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.31206\n",
      "evaluation/Rewards Std                  1.15764\n",
      "evaluation/Rewards Max                  6.50714\n",
      "evaluation/Rewards Min                 -1.87076\n",
      "evaluation/Returns Mean              4312.06\n",
      "evaluation/Returns Std                166.368\n",
      "evaluation/Returns Max               4592.31\n",
      "evaluation/Returns Min               4037.17\n",
      "evaluation/Estimation Bias Mean      1805.09\n",
      "evaluation/Estimation Bias Std        193.241\n",
      "evaluation/EB/Q_True Mean              38.0668\n",
      "evaluation/EB/Q_True Std              117.158\n",
      "evaluation/EB/Q_Pred Mean            1843.16\n",
      "evaluation/EB/Q_Pred Std              150.043\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4312.06\n",
      "evaluation/Actions Mean                 0.013942\n",
      "evaluation/Actions Std                  0.540761\n",
      "evaluation/Actions Max                  0.99601\n",
      "evaluation/Actions Min                 -0.999547\n",
      "time/backward_policy (s)                1.95123\n",
      "time/backward_zf1 (s)                   2.04503\n",
      "time/backward_zf2 (s)                   2.0052\n",
      "time/data sampling (s)                  0.259853\n",
      "time/data storing (s)                   0.0135833\n",
      "time/evaluation sampling (s)            1.79369\n",
      "time/exploration sampling (s)           0.314001\n",
      "time/logging (s)                        0.0140875\n",
      "time/preback_alpha (s)                  0.548066\n",
      "time/preback_policy (s)                 1.18497\n",
      "time/preback_start (s)                  0.140294\n",
      "time/preback_zf (s)                     5.0355\n",
      "time/saving (s)                         0.00729861\n",
      "time/training (s)                       1.96251\n",
      "time/epoch (s)                         17.2753\n",
      "time/total (s)                        471.467\n",
      "Epoch                                  27\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:44:16.717159 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 28 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  39000\n",
      "trainer/ZF1 Loss                       62.727\n",
      "trainer/ZF2 Loss                       96.7187\n",
      "trainer/ZF Expert Reward               23.9223\n",
      "trainer/ZF Policy Reward               -2.89299\n",
      "trainer/ZF CHI2 Term                  142.654\n",
      "trainer/Policy Loss                 -1073.02\n",
      "trainer/Bias Loss                     276.866\n",
      "trainer/Bias Value                     27.5922\n",
      "trainer/Policy Grad Norm              155.633\n",
      "trainer/Policy Param Norm              26.4979\n",
      "trainer/Zf1 Grad Norm                3777.4\n",
      "trainer/Zf1 Param Norm                 71.6465\n",
      "trainer/Zf2 Grad Norm                5903.93\n",
      "trainer/Zf2 Param Norm                 72.0256\n",
      "trainer/Z Expert Predictions Mean    1891.15\n",
      "trainer/Z Expert Predictions Std       90.457\n",
      "trainer/Z Expert Predictions Max     1964.12\n",
      "trainer/Z Expert Predictions Min     1320.5\n",
      "trainer/Z Policy Predictions Mean    1044.59\n",
      "trainer/Z Policy Predictions Std      698.707\n",
      "trainer/Z Policy Predictions Max     1960.26\n",
      "trainer/Z Policy Predictions Min     -236.662\n",
      "trainer/Z Expert Targets Mean        1867.23\n",
      "trainer/Z Expert Targets Std           86.4193\n",
      "trainer/Z Expert Targets Max         1939.14\n",
      "trainer/Z Expert Targets Min         1323.14\n",
      "trainer/Z Policy Targets Mean        1047.48\n",
      "trainer/Z Policy Targets Std          690.356\n",
      "trainer/Z Policy Targets Max         1938.47\n",
      "trainer/Z Policy Targets Min         -251.874\n",
      "trainer/Log Pis Mean                   36.4809\n",
      "trainer/Log Pis Std                    14.7554\n",
      "trainer/Policy mu Mean                 -0.100977\n",
      "trainer/Policy mu Std                   2.64776\n",
      "trainer/Policy log std Mean            -3.59647\n",
      "trainer/Policy log std Std              1.11726\n",
      "exploration/num steps total         33088\n",
      "exploration/num paths total           133\n",
      "evaluation/num steps total         180863\n",
      "evaluation/num paths total            293\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.45813\n",
      "evaluation/Rewards Std                  1.22584\n",
      "evaluation/Rewards Max                  6.75655\n",
      "evaluation/Rewards Min                 -2.3539\n",
      "evaluation/Returns Mean              4458.13\n",
      "evaluation/Returns Std                115.999\n",
      "evaluation/Returns Max               4633.4\n",
      "evaluation/Returns Min               4263.67\n",
      "evaluation/Estimation Bias Mean      1863.65\n",
      "evaluation/Estimation Bias Std        200.884\n",
      "evaluation/EB/Q_True Mean              39.7852\n",
      "evaluation/EB/Q_True Std              122.549\n",
      "evaluation/EB/Q_Pred Mean            1903.44\n",
      "evaluation/EB/Q_Pred Std              151.279\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4458.13\n",
      "evaluation/Actions Mean                 0.0364692\n",
      "evaluation/Actions Std                  0.52542\n",
      "evaluation/Actions Max                  0.997225\n",
      "evaluation/Actions Min                 -0.99661\n",
      "time/backward_policy (s)                1.72966\n",
      "time/backward_zf1 (s)                   1.83576\n",
      "time/backward_zf2 (s)                   1.77598\n",
      "time/data sampling (s)                  0.251793\n",
      "time/data storing (s)                   0.0141475\n",
      "time/evaluation sampling (s)            1.72744\n",
      "time/exploration sampling (s)           0.313438\n",
      "time/logging (s)                        0.0124119\n",
      "time/preback_alpha (s)                  0.547295\n",
      "time/preback_policy (s)                 1.01048\n",
      "time/preback_start (s)                  0.13973\n",
      "time/preback_zf (s)                     5.05041\n",
      "time/saving (s)                         0.00626997\n",
      "time/training (s)                       2.31909\n",
      "time/epoch (s)                         16.7339\n",
      "time/total (s)                        488.232\n",
      "Epoch                                  28\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:44:33.188269 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 29 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  40000\n",
      "trainer/ZF1 Loss                       88.2108\n",
      "trainer/ZF2 Loss                       76.9843\n",
      "trainer/ZF Expert Reward               20.7531\n",
      "trainer/ZF Policy Reward               -6.37111\n",
      "trainer/ZF CHI2 Term                  143.584\n",
      "trainer/Policy Loss                 -1199.76\n",
      "trainer/Bias Loss                     289.543\n",
      "trainer/Bias Value                     27.7006\n",
      "trainer/Policy Grad Norm              169.54\n",
      "trainer/Policy Param Norm              26.6804\n",
      "trainer/Zf1 Grad Norm                3670.76\n",
      "trainer/Zf1 Param Norm                 72.4238\n",
      "trainer/Zf2 Grad Norm                4382.6\n",
      "trainer/Zf2 Param Norm                 72.7855\n",
      "trainer/Z Expert Predictions Mean    1955.33\n",
      "trainer/Z Expert Predictions Std       74.63\n",
      "trainer/Z Expert Predictions Max     2028.75\n",
      "trainer/Z Expert Predictions Min     1396.98\n",
      "trainer/Z Policy Predictions Mean    1171.26\n",
      "trainer/Z Policy Predictions Std      684.379\n",
      "trainer/Z Policy Predictions Max     2020.19\n",
      "trainer/Z Policy Predictions Min     -190.205\n",
      "trainer/Z Expert Targets Mean        1934.57\n",
      "trainer/Z Expert Targets Std           69.8126\n",
      "trainer/Z Expert Targets Max         2003.48\n",
      "trainer/Z Expert Targets Min         1387.38\n",
      "trainer/Z Policy Targets Mean        1177.63\n",
      "trainer/Z Policy Targets Std          675.296\n",
      "trainer/Z Policy Targets Max         1991.42\n",
      "trainer/Z Policy Targets Min         -162.162\n",
      "trainer/Log Pis Mean                   34.2039\n",
      "trainer/Log Pis Std                    14.812\n",
      "trainer/Policy mu Mean                 -0.0384086\n",
      "trainer/Policy mu Std                   2.41774\n",
      "trainer/Policy log std Mean            -3.672\n",
      "trainer/Policy log std Std              1.04268\n",
      "exploration/num steps total         34088\n",
      "exploration/num paths total           134\n",
      "evaluation/num steps total         189997\n",
      "evaluation/num paths total            305\n",
      "evaluation/path length Mean           761.167\n",
      "evaluation/path length Std            359.877\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             97\n",
      "evaluation/Rewards Mean                 4.34792\n",
      "evaluation/Rewards Std                  1.25875\n",
      "evaluation/Rewards Max                  6.70334\n",
      "evaluation/Rewards Min                 -3.18832\n",
      "evaluation/Returns Mean              3309.49\n",
      "evaluation/Returns Std               1606.57\n",
      "evaluation/Returns Max               4628.1\n",
      "evaluation/Returns Min                348.718\n",
      "evaluation/Estimation Bias Mean      1898.67\n",
      "evaluation/Estimation Bias Std        204.36\n",
      "evaluation/EB/Q_True Mean              44.2983\n",
      "evaluation/EB/Q_True Std              129.722\n",
      "evaluation/EB/Q_Pred Mean            1942.97\n",
      "evaluation/EB/Q_Pred Std              153.19\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3309.49\n",
      "evaluation/Actions Mean                 0.00323974\n",
      "evaluation/Actions Std                  0.545868\n",
      "evaluation/Actions Max                  0.997545\n",
      "evaluation/Actions Min                 -0.999591\n",
      "time/backward_policy (s)                1.58459\n",
      "time/backward_zf1 (s)                   1.69436\n",
      "time/backward_zf2 (s)                   1.63042\n",
      "time/data sampling (s)                  0.236231\n",
      "time/data storing (s)                   0.0134646\n",
      "time/evaluation sampling (s)            1.72623\n",
      "time/exploration sampling (s)           0.310845\n",
      "time/logging (s)                        0.0160635\n",
      "time/preback_alpha (s)                  0.53772\n",
      "time/preback_policy (s)                 0.87698\n",
      "time/preback_start (s)                  0.136771\n",
      "time/preback_zf (s)                     5.00845\n",
      "time/saving (s)                         0.00643463\n",
      "time/training (s)                       2.63168\n",
      "time/epoch (s)                         16.4102\n",
      "time/total (s)                        504.663\n",
      "Epoch                                  29\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:44:49.933335 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 30 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  41000\n",
      "trainer/ZF1 Loss                       70.704\n",
      "trainer/ZF2 Loss                       88.3358\n",
      "trainer/ZF Expert Reward               24.968\n",
      "trainer/ZF Policy Reward               -1.90999\n",
      "trainer/ZF CHI2 Term                  142.669\n",
      "trainer/Policy Loss                 -1266.24\n",
      "trainer/Bias Loss                     229.02\n",
      "trainer/Bias Value                     27.7603\n",
      "trainer/Policy Grad Norm              169.473\n",
      "trainer/Policy Param Norm              26.847\n",
      "trainer/Zf1 Grad Norm                6024.1\n",
      "trainer/Zf1 Param Norm                 73.1539\n",
      "trainer/Zf2 Grad Norm                5257.47\n",
      "trainer/Zf2 Param Norm                 73.5136\n",
      "trainer/Z Expert Predictions Mean    1996.85\n",
      "trainer/Z Expert Predictions Std      116.145\n",
      "trainer/Z Expert Predictions Max     2081.3\n",
      "trainer/Z Expert Predictions Min     1289.26\n",
      "trainer/Z Policy Predictions Mean    1242.35\n",
      "trainer/Z Policy Predictions Std      696.526\n",
      "trainer/Z Policy Predictions Max     2066.52\n",
      "trainer/Z Policy Predictions Min     -186.559\n",
      "trainer/Z Expert Targets Mean        1971.88\n",
      "trainer/Z Expert Targets Std          114.037\n",
      "trainer/Z Expert Targets Max         2055.22\n",
      "trainer/Z Expert Targets Min         1256.79\n",
      "trainer/Z Policy Targets Mean        1244.26\n",
      "trainer/Z Policy Targets Std          687.946\n",
      "trainer/Z Policy Targets Max         2041.76\n",
      "trainer/Z Policy Targets Min         -202.878\n",
      "trainer/Log Pis Mean                   36.6372\n",
      "trainer/Log Pis Std                    15.7996\n",
      "trainer/Policy mu Mean                  0.0217783\n",
      "trainer/Policy mu Std                   2.71621\n",
      "trainer/Policy log std Mean            -3.75153\n",
      "trainer/Policy log std Std              1.17875\n",
      "exploration/num steps total         34088\n",
      "exploration/num paths total           134\n",
      "evaluation/num steps total         199997\n",
      "evaluation/num paths total            315\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.19595\n",
      "evaluation/Rewards Std                  0.843059\n",
      "evaluation/Rewards Max                  6.01978\n",
      "evaluation/Rewards Min                 -2.16254\n",
      "evaluation/Returns Mean              4195.95\n",
      "evaluation/Returns Std                 87.8623\n",
      "evaluation/Returns Max               4347.77\n",
      "evaluation/Returns Min               4036.52\n",
      "evaluation/Estimation Bias Mean      2001.91\n",
      "evaluation/Estimation Bias Std        145.493\n",
      "evaluation/EB/Q_True Mean              38.6604\n",
      "evaluation/EB/Q_True Std              118.753\n",
      "evaluation/EB/Q_Pred Mean            2040.58\n",
      "evaluation/EB/Q_Pred Std               84.7987\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4195.95\n",
      "evaluation/Actions Mean                 0.0310324\n",
      "evaluation/Actions Std                  0.521227\n",
      "evaluation/Actions Max                  0.99797\n",
      "evaluation/Actions Min                 -0.999157\n",
      "time/backward_policy (s)                1.67769\n",
      "time/backward_zf1 (s)                   1.78955\n",
      "time/backward_zf2 (s)                   1.72433\n",
      "time/data sampling (s)                  0.274168\n",
      "time/data storing (s)                   0.0143422\n",
      "time/evaluation sampling (s)            1.7506\n",
      "time/exploration sampling (s)           0.317319\n",
      "time/logging (s)                        0.0138391\n",
      "time/preback_alpha (s)                  0.547041\n",
      "time/preback_policy (s)                 0.954474\n",
      "time/preback_start (s)                  0.139286\n",
      "time/preback_zf (s)                     5.02553\n",
      "time/saving (s)                         0.0062117\n",
      "time/training (s)                       2.44051\n",
      "time/epoch (s)                         16.6749\n",
      "time/total (s)                        521.361\n",
      "Epoch                                  30\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:45:07.520326 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 31 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  42000\n",
      "trainer/ZF1 Loss                      119.687\n",
      "trainer/ZF2 Loss                      109.392\n",
      "trainer/ZF Expert Reward               29.2996\n",
      "trainer/ZF Policy Reward                2.22437\n",
      "trainer/ZF CHI2 Term                  175.907\n",
      "trainer/Policy Loss                 -1390.93\n",
      "trainer/Bias Loss                     448.335\n",
      "trainer/Bias Value                     27.7466\n",
      "trainer/Policy Grad Norm              226.817\n",
      "trainer/Policy Param Norm              27.0035\n",
      "trainer/Zf1 Grad Norm               11590.9\n",
      "trainer/Zf1 Param Norm                 73.9408\n",
      "trainer/Zf2 Grad Norm                7997.54\n",
      "trainer/Zf2 Param Norm                 74.2711\n",
      "trainer/Z Expert Predictions Mean    2061.93\n",
      "trainer/Z Expert Predictions Std       89.0512\n",
      "trainer/Z Expert Predictions Max     2152.16\n",
      "trainer/Z Expert Predictions Min     1461.37\n",
      "trainer/Z Policy Predictions Mean    1361.94\n",
      "trainer/Z Policy Predictions Std      681.65\n",
      "trainer/Z Policy Predictions Max     2130.15\n",
      "trainer/Z Policy Predictions Min     -167.369\n",
      "trainer/Z Expert Targets Mean        2032.63\n",
      "trainer/Z Expert Targets Std           92.3109\n",
      "trainer/Z Expert Targets Max         2121.35\n",
      "trainer/Z Expert Targets Min         1363.68\n",
      "trainer/Z Policy Targets Mean        1359.71\n",
      "trainer/Z Policy Targets Std          673.989\n",
      "trainer/Z Policy Targets Max         2110.58\n",
      "trainer/Z Policy Targets Min         -155.603\n",
      "trainer/Log Pis Mean                   34.6387\n",
      "trainer/Log Pis Std                    13.5052\n",
      "trainer/Policy mu Mean                  0.0106322\n",
      "trainer/Policy mu Std                   2.41921\n",
      "trainer/Policy log std Mean            -3.76285\n",
      "trainer/Policy log std Std              1.10526\n",
      "exploration/num steps total         36088\n",
      "exploration/num paths total           136\n",
      "evaluation/num steps total         209997\n",
      "evaluation/num paths total            325\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.9138\n",
      "evaluation/Rewards Std                  2.01637\n",
      "evaluation/Rewards Max                  6.64971\n",
      "evaluation/Rewards Min                 -2.6908\n",
      "evaluation/Returns Mean              3913.8\n",
      "evaluation/Returns Std               1252.05\n",
      "evaluation/Returns Max               4584.33\n",
      "evaluation/Returns Min                189.453\n",
      "evaluation/Estimation Bias Mean      1954.04\n",
      "evaluation/Estimation Bias Std        302.756\n",
      "evaluation/EB/Q_True Mean              40.1983\n",
      "evaluation/EB/Q_True Std              124.5\n",
      "evaluation/EB/Q_Pred Mean            1994.24\n",
      "evaluation/EB/Q_Pred Std              289.224\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3913.8\n",
      "evaluation/Actions Mean                -0.0042043\n",
      "evaluation/Actions Std                  0.560238\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                1.81397\n",
      "time/backward_zf1 (s)                   1.98094\n",
      "time/backward_zf2 (s)                   1.88999\n",
      "time/data sampling (s)                  0.299419\n",
      "time/data storing (s)                   0.0145695\n",
      "time/evaluation sampling (s)            1.86774\n",
      "time/exploration sampling (s)           0.332291\n",
      "time/logging (s)                        0.0123653\n",
      "time/preback_alpha (s)                  0.580611\n",
      "time/preback_policy (s)                 1.05291\n",
      "time/preback_start (s)                  0.14865\n",
      "time/preback_zf (s)                     5.14233\n",
      "time/saving (s)                         0.00656268\n",
      "time/training (s)                       2.3759\n",
      "time/epoch (s)                         17.5182\n",
      "time/total (s)                        538.898\n",
      "Epoch                                  31\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:45:24.817790 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 32 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  43000\n",
      "trainer/ZF1 Loss                      145.631\n",
      "trainer/ZF2 Loss                      108.649\n",
      "trainer/ZF Expert Reward               24.2314\n",
      "trainer/ZF Policy Reward                1.72901\n",
      "trainer/ZF CHI2 Term                  185.17\n",
      "trainer/Policy Loss                 -1450.23\n",
      "trainer/Bias Loss                     303.813\n",
      "trainer/Bias Value                     27.7024\n",
      "trainer/Policy Grad Norm              166.567\n",
      "trainer/Policy Param Norm              27.1461\n",
      "trainer/Zf1 Grad Norm                9016.03\n",
      "trainer/Zf1 Param Norm                 74.6946\n",
      "trainer/Zf2 Grad Norm                5312.65\n",
      "trainer/Zf2 Param Norm                 75.0395\n",
      "trainer/Z Expert Predictions Mean    2126.45\n",
      "trainer/Z Expert Predictions Std       71.8339\n",
      "trainer/Z Expert Predictions Max     2211.41\n",
      "trainer/Z Expert Predictions Min     1599.56\n",
      "trainer/Z Policy Predictions Mean    1427.13\n",
      "trainer/Z Policy Predictions Std      694.995\n",
      "trainer/Z Policy Predictions Max     2188.46\n",
      "trainer/Z Policy Predictions Min     -161.63\n",
      "trainer/Z Expert Targets Mean        2102.22\n",
      "trainer/Z Expert Targets Std           68.5181\n",
      "trainer/Z Expert Targets Max         2170.43\n",
      "trainer/Z Expert Targets Min         1580.08\n",
      "trainer/Z Policy Targets Mean        1425.4\n",
      "trainer/Z Policy Targets Std          685.732\n",
      "trainer/Z Policy Targets Max         2159.23\n",
      "trainer/Z Policy Targets Min         -147.075\n",
      "trainer/Log Pis Mean                   35.8869\n",
      "trainer/Log Pis Std                    15.1148\n",
      "trainer/Policy mu Mean                  0.0930931\n",
      "trainer/Policy mu Std                   2.7484\n",
      "trainer/Policy log std Mean            -3.76993\n",
      "trainer/Policy log std Std              1.15823\n",
      "exploration/num steps total         40041\n",
      "exploration/num paths total           140\n",
      "evaluation/num steps total         218780\n",
      "evaluation/num paths total            336\n",
      "evaluation/path length Mean           798.455\n",
      "evaluation/path length Std            257.686\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            228\n",
      "evaluation/Rewards Mean                 4.19545\n",
      "evaluation/Rewards Std                  0.9348\n",
      "evaluation/Rewards Max                  6.02312\n",
      "evaluation/Rewards Min                 -3.32751\n",
      "evaluation/Returns Mean              3349.88\n",
      "evaluation/Returns Std               1116.1\n",
      "evaluation/Returns Max               4319.62\n",
      "evaluation/Returns Min                934.967\n",
      "evaluation/Estimation Bias Mean      2058.72\n",
      "evaluation/Estimation Bias Std        168.371\n",
      "evaluation/EB/Q_True Mean              44.9354\n",
      "evaluation/EB/Q_True Std              128.898\n",
      "evaluation/EB/Q_Pred Mean            2103.65\n",
      "evaluation/EB/Q_Pred Std              103.627\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3349.88\n",
      "evaluation/Actions Mean                 0.0334257\n",
      "evaluation/Actions Std                  0.511246\n",
      "evaluation/Actions Max                  0.998187\n",
      "evaluation/Actions Min                 -0.998419\n",
      "time/backward_policy (s)                1.8905\n",
      "time/backward_zf1 (s)                   2.01415\n",
      "time/backward_zf2 (s)                   1.9625\n",
      "time/data sampling (s)                  0.277352\n",
      "time/data storing (s)                   0.0137887\n",
      "time/evaluation sampling (s)            1.79897\n",
      "time/exploration sampling (s)           0.32817\n",
      "time/logging (s)                        0.0116245\n",
      "time/preback_alpha (s)                  0.563403\n",
      "time/preback_policy (s)                 1.1855\n",
      "time/preback_start (s)                  0.14493\n",
      "time/preback_zf (s)                     5.06561\n",
      "time/saving (s)                         0.00909284\n",
      "time/training (s)                       1.96681\n",
      "time/epoch (s)                         17.2324\n",
      "time/total (s)                        556.148\n",
      "Epoch                                  32\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:45:41.935193 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 33 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  44000\n",
      "trainer/ZF1 Loss                      942.95\n",
      "trainer/ZF2 Loss                      916.625\n",
      "trainer/ZF Expert Reward               31.5278\n",
      "trainer/ZF Policy Reward                0.0343016\n",
      "trainer/ZF CHI2 Term                  997.31\n",
      "trainer/Policy Loss                 -1434.67\n",
      "trainer/Bias Loss                    8529.9\n",
      "trainer/Bias Value                     27.6014\n",
      "trainer/Policy Grad Norm              183.667\n",
      "trainer/Policy Param Norm              27.2781\n",
      "trainer/Zf1 Grad Norm                8387.28\n",
      "trainer/Zf1 Param Norm                 75.4746\n",
      "trainer/Zf2 Grad Norm                8646.06\n",
      "trainer/Zf2 Param Norm                 75.8233\n",
      "trainer/Z Expert Predictions Mean    2156.07\n",
      "trainer/Z Expert Predictions Std      108.495\n",
      "trainer/Z Expert Predictions Max     2253.1\n",
      "trainer/Z Expert Predictions Min     1410.55\n",
      "trainer/Z Policy Predictions Mean    1422.1\n",
      "trainer/Z Policy Predictions Std      716.548\n",
      "trainer/Z Policy Predictions Max     2237.16\n",
      "trainer/Z Policy Predictions Min     -197.778\n",
      "trainer/Z Expert Targets Mean        2124.54\n",
      "trainer/Z Expert Targets Std          171.611\n",
      "trainer/Z Expert Targets Max         2222.86\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1422.06\n",
      "trainer/Z Policy Targets Std          705.603\n",
      "trainer/Z Policy Targets Max         2211.07\n",
      "trainer/Z Policy Targets Min         -206.199\n",
      "trainer/Log Pis Mean                   36.3933\n",
      "trainer/Log Pis Std                    15.3857\n",
      "trainer/Policy mu Mean                 -0.0523151\n",
      "trainer/Policy mu Std                   2.76105\n",
      "trainer/Policy log std Mean            -3.78726\n",
      "trainer/Policy log std Std              1.14269\n",
      "exploration/num steps total         40173\n",
      "exploration/num paths total           141\n",
      "evaluation/num steps total         226691\n",
      "evaluation/num paths total            347\n",
      "evaluation/path length Mean           719.182\n",
      "evaluation/path length Std            343.244\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             21\n",
      "evaluation/Rewards Mean                 4.09513\n",
      "evaluation/Rewards Std                  1.39576\n",
      "evaluation/Rewards Max                  6.92337\n",
      "evaluation/Rewards Min                 -2.44848\n",
      "evaluation/Returns Mean              2945.14\n",
      "evaluation/Returns Std               1417.99\n",
      "evaluation/Returns Max               4161.88\n",
      "evaluation/Returns Min                 27.3928\n",
      "evaluation/Estimation Bias Mean      2027.82\n",
      "evaluation/Estimation Bias Std        228.063\n",
      "evaluation/EB/Q_True Mean              46.6435\n",
      "evaluation/EB/Q_True Std              126.25\n",
      "evaluation/EB/Q_Pred Mean            2074.47\n",
      "evaluation/EB/Q_Pred Std              186.852\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2945.14\n",
      "evaluation/Actions Mean                 0.014059\n",
      "evaluation/Actions Std                  0.534374\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84331\n",
      "time/backward_zf1 (s)                   1.96071\n",
      "time/backward_zf2 (s)                   1.92012\n",
      "time/data sampling (s)                  0.286585\n",
      "time/data storing (s)                   0.0139655\n",
      "time/evaluation sampling (s)            1.73686\n",
      "time/exploration sampling (s)           0.318965\n",
      "time/logging (s)                        0.00986115\n",
      "time/preback_alpha (s)                  0.558581\n",
      "time/preback_policy (s)                 1.13103\n",
      "time/preback_start (s)                  0.143228\n",
      "time/preback_zf (s)                     5.04266\n",
      "time/saving (s)                         0.00657267\n",
      "time/training (s)                       2.07672\n",
      "time/epoch (s)                         17.0492\n",
      "time/total (s)                        573.218\n",
      "Epoch                                  33\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:45:59.052701 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 34 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  45000\n",
      "trainer/ZF1 Loss                      929.552\n",
      "trainer/ZF2 Loss                      894.941\n",
      "trainer/ZF Expert Reward               32.4285\n",
      "trainer/ZF Policy Reward               -1.39926\n",
      "trainer/ZF CHI2 Term                  979.716\n",
      "trainer/Policy Loss                 -1529.8\n",
      "trainer/Bias Loss                    7918.4\n",
      "trainer/Bias Value                     27.4812\n",
      "trainer/Policy Grad Norm              166.266\n",
      "trainer/Policy Param Norm              27.4027\n",
      "trainer/Zf1 Grad Norm               14138.9\n",
      "trainer/Zf1 Param Norm                 76.1757\n",
      "trainer/Zf2 Grad Norm               13937.6\n",
      "trainer/Zf2 Param Norm                 76.5556\n",
      "trainer/Z Expert Predictions Mean    2200.76\n",
      "trainer/Z Expert Predictions Std      100.4\n",
      "trainer/Z Expert Predictions Max     2311.07\n",
      "trainer/Z Expert Predictions Min     1725.2\n",
      "trainer/Z Policy Predictions Mean    1508.15\n",
      "trainer/Z Policy Predictions Std      679.343\n",
      "trainer/Z Policy Predictions Max     2279.77\n",
      "trainer/Z Policy Predictions Min     -145.37\n",
      "trainer/Z Expert Targets Mean        2168.33\n",
      "trainer/Z Expert Targets Std          172.962\n",
      "trainer/Z Expert Targets Max         2278.38\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1509.55\n",
      "trainer/Z Policy Targets Std          669.281\n",
      "trainer/Z Policy Targets Max         2253.27\n",
      "trainer/Z Policy Targets Min         -116.796\n",
      "trainer/Log Pis Mean                   33.9816\n",
      "trainer/Log Pis Std                    14.0834\n",
      "trainer/Policy mu Mean                  0.134704\n",
      "trainer/Policy mu Std                   2.33934\n",
      "trainer/Policy log std Mean            -3.82403\n",
      "trainer/Policy log std Std              1.08809\n",
      "exploration/num steps total         40173\n",
      "exploration/num paths total           141\n",
      "evaluation/num steps total         236691\n",
      "evaluation/num paths total            357\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.21941\n",
      "evaluation/Rewards Std                  1.06032\n",
      "evaluation/Rewards Max                  6.65543\n",
      "evaluation/Rewards Min                 -2.58156\n",
      "evaluation/Returns Mean              4219.41\n",
      "evaluation/Returns Std                111.882\n",
      "evaluation/Returns Max               4354.53\n",
      "evaluation/Returns Min               3929.41\n",
      "evaluation/Estimation Bias Mean      2169.63\n",
      "evaluation/Estimation Bias Std        182.087\n",
      "evaluation/EB/Q_True Mean              39.0405\n",
      "evaluation/EB/Q_True Std              120.529\n",
      "evaluation/EB/Q_Pred Mean            2208.67\n",
      "evaluation/EB/Q_Pred Std              138.633\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4219.41\n",
      "evaluation/Actions Mean                 0.0116593\n",
      "evaluation/Actions Std                  0.538777\n",
      "evaluation/Actions Max                  0.997685\n",
      "evaluation/Actions Min                 -0.997773\n",
      "time/backward_policy (s)                1.73985\n",
      "time/backward_zf1 (s)                   1.83593\n",
      "time/backward_zf2 (s)                   1.77292\n",
      "time/data sampling (s)                  0.280254\n",
      "time/data storing (s)                   0.0149296\n",
      "time/evaluation sampling (s)            1.80228\n",
      "time/exploration sampling (s)           0.32527\n",
      "time/logging (s)                        0.0133184\n",
      "time/preback_alpha (s)                  0.555611\n",
      "time/preback_policy (s)                 0.970867\n",
      "time/preback_start (s)                  0.142413\n",
      "time/preback_zf (s)                     5.08086\n",
      "time/saving (s)                         0.00675172\n",
      "time/training (s)                       2.51279\n",
      "time/epoch (s)                         17.0541\n",
      "time/total (s)                        590.293\n",
      "Epoch                                  34\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:46:16.452530 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 35 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  46000\n",
      "trainer/ZF1 Loss                     1075.92\n",
      "trainer/ZF2 Loss                     1360.43\n",
      "trainer/ZF Expert Reward               41.8915\n",
      "trainer/ZF Policy Reward                7.44811\n",
      "trainer/ZF CHI2 Term                 1285.94\n",
      "trainer/Policy Loss                 -1590.32\n",
      "trainer/Bias Loss                   11034.6\n",
      "trainer/Bias Value                     27.3566\n",
      "trainer/Policy Grad Norm              218.904\n",
      "trainer/Policy Param Norm              27.5052\n",
      "trainer/Zf1 Grad Norm               39557.8\n",
      "trainer/Zf1 Param Norm                 76.9735\n",
      "trainer/Zf2 Grad Norm               31142.5\n",
      "trainer/Zf2 Param Norm                 77.3739\n",
      "trainer/Z Expert Predictions Mean    2244.59\n",
      "trainer/Z Expert Predictions Std      125.847\n",
      "trainer/Z Expert Predictions Max     2349.98\n",
      "trainer/Z Expert Predictions Min     1524.44\n",
      "trainer/Z Policy Predictions Mean    1575.17\n",
      "trainer/Z Policy Predictions Std      702.289\n",
      "trainer/Z Policy Predictions Max     2345.97\n",
      "trainer/Z Policy Predictions Min     -251.744\n",
      "trainer/Z Expert Targets Mean        2202.69\n",
      "trainer/Z Expert Targets Std          227.152\n",
      "trainer/Z Expert Targets Max         2327.03\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1567.72\n",
      "trainer/Z Policy Targets Std          693.262\n",
      "trainer/Z Policy Targets Max         2309.44\n",
      "trainer/Z Policy Targets Min         -233.918\n",
      "trainer/Log Pis Mean                   33.6604\n",
      "trainer/Log Pis Std                    14.4748\n",
      "trainer/Policy mu Mean                  0.118598\n",
      "trainer/Policy mu Std                   2.36189\n",
      "trainer/Policy log std Mean            -3.82681\n",
      "trainer/Policy log std Std              1.09353\n",
      "exploration/num steps total         41173\n",
      "exploration/num paths total           142\n",
      "evaluation/num steps total         239184\n",
      "evaluation/num paths total            367\n",
      "evaluation/path length Mean           249.3\n",
      "evaluation/path length Std            185.399\n",
      "evaluation/path length Max            631\n",
      "evaluation/path length Min             29\n",
      "evaluation/Rewards Mean                 3.91659\n",
      "evaluation/Rewards Std                  1.53379\n",
      "evaluation/Rewards Max                  6.37616\n",
      "evaluation/Rewards Min                 -2.78657\n",
      "evaluation/Returns Mean               976.407\n",
      "evaluation/Returns Std                807.179\n",
      "evaluation/Returns Max               2770.1\n",
      "evaluation/Returns Min                 51.7577\n",
      "evaluation/Estimation Bias Mean      2052.97\n",
      "evaluation/Estimation Bias Std        279.096\n",
      "evaluation/EB/Q_True Mean              91.7985\n",
      "evaluation/EB/Q_True Std              170.601\n",
      "evaluation/EB/Q_Pred Mean            2144.77\n",
      "evaluation/EB/Q_Pred Std              217.402\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            976.407\n",
      "evaluation/Actions Mean                 0.0100821\n",
      "evaluation/Actions Std                  0.522395\n",
      "evaluation/Actions Max                  0.999675\n",
      "evaluation/Actions Min                 -0.999741\n",
      "time/backward_policy (s)                1.98486\n",
      "time/backward_zf1 (s)                   2.09679\n",
      "time/backward_zf2 (s)                   2.04878\n",
      "time/data sampling (s)                  0.288287\n",
      "time/data storing (s)                   0.0139639\n",
      "time/evaluation sampling (s)            1.49988\n",
      "time/exploration sampling (s)           0.322407\n",
      "time/logging (s)                        0.00405466\n",
      "time/preback_alpha (s)                  0.571044\n",
      "time/preback_policy (s)                 1.17961\n",
      "time/preback_start (s)                  0.145958\n",
      "time/preback_zf (s)                     5.10244\n",
      "time/saving (s)                         0.00524199\n",
      "time/training (s)                       2.06057\n",
      "time/epoch (s)                         17.3239\n",
      "time/total (s)                        607.636\n",
      "Epoch                                  35\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:46:33.225470 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 36 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  47000\n",
      "trainer/ZF1 Loss                      151.734\n",
      "trainer/ZF2 Loss                      140.189\n",
      "trainer/ZF Expert Reward                9.38379\n",
      "trainer/ZF Policy Reward               -8.65406\n",
      "trainer/ZF CHI2 Term                  196.328\n",
      "trainer/Policy Loss                 -1684.52\n",
      "trainer/Bias Loss                     663.99\n",
      "trainer/Bias Value                     27.2311\n",
      "trainer/Policy Grad Norm              180.694\n",
      "trainer/Policy Param Norm              27.6314\n",
      "trainer/Zf1 Grad Norm               20564\n",
      "trainer/Zf1 Param Norm                 77.667\n",
      "trainer/Zf2 Grad Norm               15923.4\n",
      "trainer/Zf2 Param Norm                 78.1086\n",
      "trainer/Z Expert Predictions Mean    2277.99\n",
      "trainer/Z Expert Predictions Std       99.2686\n",
      "trainer/Z Expert Predictions Max     2398.39\n",
      "trainer/Z Expert Predictions Min     1696.58\n",
      "trainer/Z Policy Predictions Mean    1662.84\n",
      "trainer/Z Policy Predictions Std      649.601\n",
      "trainer/Z Policy Predictions Max     2395.55\n",
      "trainer/Z Policy Predictions Min     -253.557\n",
      "trainer/Z Expert Targets Mean        2268.6\n",
      "trainer/Z Expert Targets Std           93.6949\n",
      "trainer/Z Expert Targets Max         2371.28\n",
      "trainer/Z Expert Targets Min         1715.48\n",
      "trainer/Z Policy Targets Mean        1671.49\n",
      "trainer/Z Policy Targets Std          647.045\n",
      "trainer/Z Policy Targets Max         2357.21\n",
      "trainer/Z Policy Targets Min         -253.611\n",
      "trainer/Log Pis Mean                   32.6549\n",
      "trainer/Log Pis Std                    12.1513\n",
      "trainer/Policy mu Mean                  0.227857\n",
      "trainer/Policy mu Std                   1.96775\n",
      "trainer/Policy log std Mean            -4.00757\n",
      "trainer/Policy log std Std              0.950256\n",
      "exploration/num steps total         42173\n",
      "exploration/num paths total           143\n",
      "evaluation/num steps total         241742\n",
      "evaluation/num paths total            377\n",
      "evaluation/path length Mean           255.8\n",
      "evaluation/path length Std            226.153\n",
      "evaluation/path length Max            641\n",
      "evaluation/path length Min             10\n",
      "evaluation/Rewards Mean                 3.43495\n",
      "evaluation/Rewards Std                  1.82595\n",
      "evaluation/Rewards Max                  6.59099\n",
      "evaluation/Rewards Min                 -3.10994\n",
      "evaluation/Returns Mean               878.661\n",
      "evaluation/Returns Std                812.937\n",
      "evaluation/Returns Max               2267.29\n",
      "evaluation/Returns Min                 -2.47432\n",
      "evaluation/Estimation Bias Mean      1994.03\n",
      "evaluation/Estimation Bias Std        349.97\n",
      "evaluation/EB/Q_True Mean              79.2719\n",
      "evaluation/EB/Q_True Std              152.664\n",
      "evaluation/EB/Q_Pred Mean            2073.3\n",
      "evaluation/EB/Q_Pred Std              298.193\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            878.661\n",
      "evaluation/Actions Mean                 0.0366008\n",
      "evaluation/Actions Std                  0.561922\n",
      "evaluation/Actions Max                  0.999916\n",
      "evaluation/Actions Min                 -0.999982\n",
      "time/backward_policy (s)                1.90106\n",
      "time/backward_zf1 (s)                   2.0078\n",
      "time/backward_zf2 (s)                   1.95594\n",
      "time/data sampling (s)                  0.255585\n",
      "time/data storing (s)                   0.0139622\n",
      "time/evaluation sampling (s)            1.12684\n",
      "time/exploration sampling (s)           0.326335\n",
      "time/logging (s)                        0.00416573\n",
      "time/preback_alpha (s)                  0.556377\n",
      "time/preback_policy (s)                 1.10466\n",
      "time/preback_start (s)                  0.144203\n",
      "time/preback_zf (s)                     5.07264\n",
      "time/saving (s)                         0.00583302\n",
      "time/training (s)                       2.23277\n",
      "time/epoch (s)                         16.7082\n",
      "time/total (s)                        624.363\n",
      "Epoch                                  36\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:46:50.228412 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 37 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  48000\n",
      "trainer/ZF1 Loss                      423.987\n",
      "trainer/ZF2 Loss                      482.734\n",
      "trainer/ZF Expert Reward               19.2299\n",
      "trainer/ZF Policy Reward                1.66801\n",
      "trainer/ZF CHI2 Term                  506.152\n",
      "trainer/Policy Loss                 -1698.76\n",
      "trainer/Bias Loss                    3175.28\n",
      "trainer/Bias Value                     27.06\n",
      "trainer/Policy Grad Norm              215.21\n",
      "trainer/Policy Param Norm              27.7605\n",
      "trainer/Zf1 Grad Norm               12241\n",
      "trainer/Zf1 Param Norm                 78.362\n",
      "trainer/Zf2 Grad Norm               10103.2\n",
      "trainer/Zf2 Param Norm                 78.8157\n",
      "trainer/Z Expert Predictions Mean    2307.2\n",
      "trainer/Z Expert Predictions Std      108.197\n",
      "trainer/Z Expert Predictions Max     2419.04\n",
      "trainer/Z Expert Predictions Min     1768.7\n",
      "trainer/Z Policy Predictions Mean    1682.35\n",
      "trainer/Z Policy Predictions Std      719.157\n",
      "trainer/Z Policy Predictions Max     2420.73\n",
      "trainer/Z Policy Predictions Min     -257.827\n",
      "trainer/Z Expert Targets Mean        2287.97\n",
      "trainer/Z Expert Targets Std          130.7\n",
      "trainer/Z Expert Targets Max         2405.37\n",
      "trainer/Z Expert Targets Min         1056.88\n",
      "trainer/Z Policy Targets Mean        1680.68\n",
      "trainer/Z Policy Targets Std          714.343\n",
      "trainer/Z Policy Targets Max         2381.39\n",
      "trainer/Z Policy Targets Min         -223.401\n",
      "trainer/Log Pis Mean                   35.5856\n",
      "trainer/Log Pis Std                    13.4769\n",
      "trainer/Policy mu Mean                  0.243072\n",
      "trainer/Policy mu Std                   2.04924\n",
      "trainer/Policy log std Mean            -4.14955\n",
      "trainer/Policy log std Std              0.892845\n",
      "exploration/num steps total         43973\n",
      "exploration/num paths total           146\n",
      "evaluation/num steps total         251048\n",
      "evaluation/num paths total            387\n",
      "evaluation/path length Mean           930.6\n",
      "evaluation/path length Std            144.271\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            565\n",
      "evaluation/Rewards Mean                 4.44705\n",
      "evaluation/Rewards Std                  1.06551\n",
      "evaluation/Rewards Max                  6.66825\n",
      "evaluation/Rewards Min                 -2.67896\n",
      "evaluation/Returns Mean              4138.42\n",
      "evaluation/Returns Std                719.904\n",
      "evaluation/Returns Max               4603.46\n",
      "evaluation/Returns Min               2354.38\n",
      "evaluation/Estimation Bias Mean      2300.94\n",
      "evaluation/Estimation Bias Std        194.87\n",
      "evaluation/EB/Q_True Mean              44.6141\n",
      "evaluation/EB/Q_True Std              131.936\n",
      "evaluation/EB/Q_Pred Mean            2345.56\n",
      "evaluation/EB/Q_Pred Std              129.263\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4138.42\n",
      "evaluation/Actions Mean                 0.0258029\n",
      "evaluation/Actions Std                  0.521965\n",
      "evaluation/Actions Max                  0.998561\n",
      "evaluation/Actions Min                 -0.998916\n",
      "time/backward_policy (s)                1.76621\n",
      "time/backward_zf1 (s)                   1.87759\n",
      "time/backward_zf2 (s)                   1.81448\n",
      "time/data sampling (s)                  0.254574\n",
      "time/data storing (s)                   0.0136781\n",
      "time/evaluation sampling (s)            1.79239\n",
      "time/exploration sampling (s)           0.31796\n",
      "time/logging (s)                        0.011593\n",
      "time/preback_alpha (s)                  0.5514\n",
      "time/preback_policy (s)                 1.01277\n",
      "time/preback_start (s)                  0.140633\n",
      "time/preback_zf (s)                     5.06559\n",
      "time/saving (s)                         0.00656188\n",
      "time/training (s)                       2.31796\n",
      "time/epoch (s)                         16.9434\n",
      "time/total (s)                        641.328\n",
      "Epoch                                  37\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:47:07.494466 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 38 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  49000\n",
      "trainer/ZF1 Loss                     1110.8\n",
      "trainer/ZF2 Loss                     1133.37\n",
      "trainer/ZF Expert Reward               38.2166\n",
      "trainer/ZF Policy Reward                0.569851\n",
      "trainer/ZF CHI2 Term                 1194.81\n",
      "trainer/Policy Loss                 -1733.3\n",
      "trainer/Bias Loss                   10619.2\n",
      "trainer/Bias Value                     26.8822\n",
      "trainer/Policy Grad Norm              204.578\n",
      "trainer/Policy Param Norm              27.8862\n",
      "trainer/Zf1 Grad Norm               16082.3\n",
      "trainer/Zf1 Param Norm                 79.0726\n",
      "trainer/Zf2 Grad Norm               17912.8\n",
      "trainer/Zf2 Param Norm                 79.5984\n",
      "trainer/Z Expert Predictions Mean    2345.43\n",
      "trainer/Z Expert Predictions Std      162.481\n",
      "trainer/Z Expert Predictions Max     2481.45\n",
      "trainer/Z Expert Predictions Min      436.216\n",
      "trainer/Z Policy Predictions Mean    1711.7\n",
      "trainer/Z Policy Predictions Std      686.302\n",
      "trainer/Z Policy Predictions Max     2457.9\n",
      "trainer/Z Policy Predictions Min     -162.237\n",
      "trainer/Z Expert Targets Mean        2307.21\n",
      "trainer/Z Expert Targets Std          234.822\n",
      "trainer/Z Expert Targets Max         2449.41\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1711.13\n",
      "trainer/Z Policy Targets Std          677.709\n",
      "trainer/Z Policy Targets Max         2432.97\n",
      "trainer/Z Policy Targets Min         -152.996\n",
      "trainer/Log Pis Mean                   35.4341\n",
      "trainer/Log Pis Std                    14.7959\n",
      "trainer/Policy mu Mean                  0.202485\n",
      "trainer/Policy mu Std                   2.15927\n",
      "trainer/Policy log std Mean            -4.09358\n",
      "trainer/Policy log std Std              0.88769\n",
      "exploration/num steps total         43973\n",
      "exploration/num paths total           146\n",
      "evaluation/num steps total         257966\n",
      "evaluation/num paths total            398\n",
      "evaluation/path length Mean           628.909\n",
      "evaluation/path length Std            411.871\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             10\n",
      "evaluation/Rewards Mean                 4.36461\n",
      "evaluation/Rewards Std                  1.18376\n",
      "evaluation/Rewards Max                  6.40563\n",
      "evaluation/Rewards Min                 -2.70409\n",
      "evaluation/Returns Mean              2744.94\n",
      "evaluation/Returns Std               1850.06\n",
      "evaluation/Returns Max               4521.36\n",
      "evaluation/Returns Min                  1.94865\n",
      "evaluation/Estimation Bias Mean      2279.85\n",
      "evaluation/Estimation Bias Std        226.027\n",
      "evaluation/EB/Q_True Mean              57.003\n",
      "evaluation/EB/Q_True Std              142.678\n",
      "evaluation/EB/Q_Pred Mean            2336.85\n",
      "evaluation/EB/Q_Pred Std              170.481\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2744.94\n",
      "evaluation/Actions Mean                 0.025213\n",
      "evaluation/Actions Std                  0.525279\n",
      "evaluation/Actions Max                  0.999968\n",
      "evaluation/Actions Min                 -0.999982\n",
      "time/backward_policy (s)                1.88675\n",
      "time/backward_zf1 (s)                   1.99661\n",
      "time/backward_zf2 (s)                   1.95555\n",
      "time/data sampling (s)                  0.275757\n",
      "time/data storing (s)                   0.0137197\n",
      "time/evaluation sampling (s)            1.8415\n",
      "time/exploration sampling (s)           0.314761\n",
      "time/logging (s)                        0.00916769\n",
      "time/preback_alpha (s)                  0.552588\n",
      "time/preback_policy (s)                 1.17782\n",
      "time/preback_start (s)                  0.140819\n",
      "time/preback_zf (s)                     5.05394\n",
      "time/saving (s)                         0.00594556\n",
      "time/training (s)                       1.97403\n",
      "time/epoch (s)                         17.199\n",
      "time/total (s)                        658.546\n",
      "Epoch                                  38\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:47:24.777084 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 39 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  50000\n",
      "trainer/ZF1 Loss                      316.066\n",
      "trainer/ZF2 Loss                      224.541\n",
      "trainer/ZF Expert Reward               24.0156\n",
      "trainer/ZF Policy Reward                7.13439\n",
      "trainer/ZF CHI2 Term                  322.816\n",
      "trainer/Policy Loss                 -1716.13\n",
      "trainer/Bias Loss                     471.317\n",
      "trainer/Bias Value                     26.7098\n",
      "trainer/Policy Grad Norm              145.342\n",
      "trainer/Policy Param Norm              28.0184\n",
      "trainer/Zf1 Grad Norm                6549.74\n",
      "trainer/Zf1 Param Norm                 79.7404\n",
      "trainer/Zf2 Grad Norm                5159.67\n",
      "trainer/Zf2 Param Norm                 80.3638\n",
      "trainer/Z Expert Predictions Mean    2387.95\n",
      "trainer/Z Expert Predictions Std      106.03\n",
      "trainer/Z Expert Predictions Max     2506.06\n",
      "trainer/Z Expert Predictions Min     1713.78\n",
      "trainer/Z Policy Predictions Mean    1695.08\n",
      "trainer/Z Policy Predictions Std      735.935\n",
      "trainer/Z Policy Predictions Max     2472.64\n",
      "trainer/Z Policy Predictions Min      -14.4337\n",
      "trainer/Z Expert Targets Mean        2363.94\n",
      "trainer/Z Expert Targets Std          109.226\n",
      "trainer/Z Expert Targets Max         2489.77\n",
      "trainer/Z Expert Targets Min         1671.95\n",
      "trainer/Z Policy Targets Mean        1687.95\n",
      "trainer/Z Policy Targets Std          733.372\n",
      "trainer/Z Policy Targets Max         2485.6\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   35.9914\n",
      "trainer/Log Pis Std                    13.6977\n",
      "trainer/Policy mu Mean                  0.119529\n",
      "trainer/Policy mu Std                   2.24406\n",
      "trainer/Policy log std Mean            -3.96522\n",
      "trainer/Policy log std Std              0.992413\n",
      "exploration/num steps total         44973\n",
      "exploration/num paths total           147\n",
      "evaluation/num steps total         266700\n",
      "evaluation/num paths total            411\n",
      "evaluation/path length Mean           671.846\n",
      "evaluation/path length Std            431.919\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             21\n",
      "evaluation/Rewards Mean                 4.36063\n",
      "evaluation/Rewards Std                  1.18612\n",
      "evaluation/Rewards Max                  6.56073\n",
      "evaluation/Rewards Min                 -3.03729\n",
      "evaluation/Returns Mean              2929.67\n",
      "evaluation/Returns Std               1955.14\n",
      "evaluation/Returns Max               4658.8\n",
      "evaluation/Returns Min                 -9.6613\n",
      "evaluation/Estimation Bias Mean      2334.01\n",
      "evaluation/Estimation Bias Std        230.691\n",
      "evaluation/EB/Q_True Mean              42.8479\n",
      "evaluation/EB/Q_True Std              123.156\n",
      "evaluation/EB/Q_Pred Mean            2376.86\n",
      "evaluation/EB/Q_Pred Std              177.013\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2929.67\n",
      "evaluation/Actions Mean                 0.0256666\n",
      "evaluation/Actions Std                  0.536188\n",
      "evaluation/Actions Max                  0.999993\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86264\n",
      "time/backward_zf1 (s)                   1.96379\n",
      "time/backward_zf2 (s)                   1.93417\n",
      "time/data sampling (s)                  0.271078\n",
      "time/data storing (s)                   0.0140277\n",
      "time/evaluation sampling (s)            1.75059\n",
      "time/exploration sampling (s)           0.320523\n",
      "time/logging (s)                        0.0112274\n",
      "time/preback_alpha (s)                  0.554823\n",
      "time/preback_policy (s)                 1.11421\n",
      "time/preback_start (s)                  0.142507\n",
      "time/preback_zf (s)                     5.04713\n",
      "time/saving (s)                         0.00593492\n",
      "time/training (s)                       2.22754\n",
      "time/epoch (s)                         17.2202\n",
      "time/total (s)                        675.784\n",
      "Epoch                                  39\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:47:41.013961 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 40 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  51000\n",
      "trainer/ZF1 Loss                      116.358\n",
      "trainer/ZF2 Loss                       89.4892\n",
      "trainer/ZF Expert Reward               30.6921\n",
      "trainer/ZF Policy Reward                5.8746\n",
      "trainer/ZF CHI2 Term                  162.858\n",
      "trainer/Policy Loss                 -1802.26\n",
      "trainer/Bias Loss                     486.723\n",
      "trainer/Bias Value                     26.513\n",
      "trainer/Policy Grad Norm              145.017\n",
      "trainer/Policy Param Norm              28.1465\n",
      "trainer/Zf1 Grad Norm                5987.03\n",
      "trainer/Zf1 Param Norm                 80.3554\n",
      "trainer/Zf2 Grad Norm                4486.51\n",
      "trainer/Zf2 Param Norm                 81.0734\n",
      "trainer/Z Expert Predictions Mean    2422.59\n",
      "trainer/Z Expert Predictions Std       97.6712\n",
      "trainer/Z Expert Predictions Max     2542.02\n",
      "trainer/Z Expert Predictions Min     1970.37\n",
      "trainer/Z Policy Predictions Mean    1781.97\n",
      "trainer/Z Policy Predictions Std      700.596\n",
      "trainer/Z Policy Predictions Max     2542.68\n",
      "trainer/Z Policy Predictions Min       67.2071\n",
      "trainer/Z Expert Targets Mean        2391.9\n",
      "trainer/Z Expert Targets Std           99.8234\n",
      "trainer/Z Expert Targets Max         2520.38\n",
      "trainer/Z Expert Targets Min         1975.68\n",
      "trainer/Z Policy Targets Mean        1776.1\n",
      "trainer/Z Policy Targets Std          689.918\n",
      "trainer/Z Policy Targets Max         2512.56\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   35.4719\n",
      "trainer/Log Pis Std                    13.8289\n",
      "trainer/Policy mu Mean                  0.151423\n",
      "trainer/Policy mu Std                   2.22788\n",
      "trainer/Policy log std Mean            -3.99959\n",
      "trainer/Policy log std Std              0.969234\n",
      "exploration/num steps total         45378\n",
      "exploration/num paths total           149\n",
      "evaluation/num steps total         267826\n",
      "evaluation/num paths total            421\n",
      "evaluation/path length Mean           112.6\n",
      "evaluation/path length Std            126.23\n",
      "evaluation/path length Max            436\n",
      "evaluation/path length Min             10\n",
      "evaluation/Rewards Mean                 3.21948\n",
      "evaluation/Rewards Std                  1.90727\n",
      "evaluation/Rewards Max                  6.93956\n",
      "evaluation/Rewards Min                 -2.57685\n",
      "evaluation/Returns Mean               362.513\n",
      "evaluation/Returns Std                513.551\n",
      "evaluation/Returns Max               1749.97\n",
      "evaluation/Returns Min                 -0.013477\n",
      "evaluation/Estimation Bias Mean      2072.17\n",
      "evaluation/Estimation Bias Std        347.501\n",
      "evaluation/EB/Q_True Mean             123.512\n",
      "evaluation/EB/Q_True Std              171.188\n",
      "evaluation/EB/Q_Pred Mean            2195.68\n",
      "evaluation/EB/Q_Pred Std              272.668\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            362.513\n",
      "evaluation/Actions Mean                 0.0273121\n",
      "evaluation/Actions Std                  0.549421\n",
      "evaluation/Actions Max                  0.998755\n",
      "evaluation/Actions Min                 -0.999042\n",
      "time/backward_policy (s)                1.75889\n",
      "time/backward_zf1 (s)                   1.88853\n",
      "time/backward_zf2 (s)                   1.84267\n",
      "time/data sampling (s)                  0.273791\n",
      "time/data storing (s)                   0.0136403\n",
      "time/evaluation sampling (s)            0.969689\n",
      "time/exploration sampling (s)           0.316062\n",
      "time/logging (s)                        0.00240504\n",
      "time/preback_alpha (s)                  0.547817\n",
      "time/preback_policy (s)                 1.04203\n",
      "time/preback_start (s)                  0.140228\n",
      "time/preback_zf (s)                     5.03048\n",
      "time/saving (s)                         0.00568661\n",
      "time/training (s)                       2.33174\n",
      "time/epoch (s)                         16.1637\n",
      "time/total (s)                        691.967\n",
      "Epoch                                  40\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:47:57.849056 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 41 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  52000\n",
      "trainer/ZF1 Loss                      729.731\n",
      "trainer/ZF2 Loss                      487.205\n",
      "trainer/ZF Expert Reward               26.917\n",
      "trainer/ZF Policy Reward                5.51512\n",
      "trainer/ZF CHI2 Term                  665.431\n",
      "trainer/Policy Loss                 -1779.56\n",
      "trainer/Bias Loss                     335.769\n",
      "trainer/Bias Value                     26.3131\n",
      "trainer/Policy Grad Norm              165.537\n",
      "trainer/Policy Param Norm              28.2856\n",
      "trainer/Zf1 Grad Norm               10255.2\n",
      "trainer/Zf1 Param Norm                 80.9698\n",
      "trainer/Zf2 Grad Norm               15800\n",
      "trainer/Zf2 Param Norm                 81.7681\n",
      "trainer/Z Expert Predictions Mean    2450.95\n",
      "trainer/Z Expert Predictions Std      102.858\n",
      "trainer/Z Expert Predictions Max     2576.9\n",
      "trainer/Z Expert Predictions Min     1871.32\n",
      "trainer/Z Policy Predictions Mean    1760.69\n",
      "trainer/Z Policy Predictions Std      731.094\n",
      "trainer/Z Policy Predictions Max     2553.61\n",
      "trainer/Z Policy Predictions Min      115.633\n",
      "trainer/Z Expert Targets Mean        2424.03\n",
      "trainer/Z Expert Targets Std          103.085\n",
      "trainer/Z Expert Targets Max         2546.88\n",
      "trainer/Z Expert Targets Min         1860.4\n",
      "trainer/Z Policy Targets Mean        1755.17\n",
      "trainer/Z Policy Targets Std          725.977\n",
      "trainer/Z Policy Targets Max         2520.22\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   35.9199\n",
      "trainer/Log Pis Std                    14.0723\n",
      "trainer/Policy mu Mean                  0.168247\n",
      "trainer/Policy mu Std                   2.25559\n",
      "trainer/Policy log std Mean            -3.9612\n",
      "trainer/Policy log std Std              0.982835\n",
      "exploration/num steps total         47389\n",
      "exploration/num paths total           152\n",
      "evaluation/num steps total         277826\n",
      "evaluation/num paths total            431\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 2.61687\n",
      "evaluation/Rewards Std                  2.80256\n",
      "evaluation/Rewards Max                  6.67142\n",
      "evaluation/Rewards Min                 -3.78921\n",
      "evaluation/Returns Mean              2616.87\n",
      "evaluation/Returns Std               1887.28\n",
      "evaluation/Returns Max               4042.63\n",
      "evaluation/Returns Min              -1318.78\n",
      "evaluation/Estimation Bias Mean      1973.58\n",
      "evaluation/Estimation Bias Std        713.36\n",
      "evaluation/EB/Q_True Mean              35.2424\n",
      "evaluation/EB/Q_True Std              108.802\n",
      "evaluation/EB/Q_Pred Mean            2008.83\n",
      "evaluation/EB/Q_Pred Std              655.574\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2616.87\n",
      "evaluation/Actions Mean                 0.110346\n",
      "evaluation/Actions Std                  0.614672\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71947\n",
      "time/backward_zf1 (s)                   1.84154\n",
      "time/backward_zf2 (s)                   1.76385\n",
      "time/data sampling (s)                  0.256126\n",
      "time/data storing (s)                   0.01395\n",
      "time/evaluation sampling (s)            1.73347\n",
      "time/exploration sampling (s)           0.321148\n",
      "time/logging (s)                        0.011985\n",
      "time/preback_alpha (s)                  0.548329\n",
      "time/preback_policy (s)                 0.990427\n",
      "time/preback_start (s)                  0.140448\n",
      "time/preback_zf (s)                     5.03293\n",
      "time/saving (s)                         0.00655198\n",
      "time/training (s)                       2.39983\n",
      "time/epoch (s)                         16.7801\n",
      "time/total (s)                        708.767\n",
      "Epoch                                  41\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:48:14.889604 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 42 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  53000\n",
      "trainer/ZF1 Loss                      106.222\n",
      "trainer/ZF2 Loss                      130.59\n",
      "trainer/ZF Expert Reward               23.7733\n",
      "trainer/ZF Policy Reward               11.7067\n",
      "trainer/ZF CHI2 Term                  165.825\n",
      "trainer/Policy Loss                 -1831.35\n",
      "trainer/Bias Loss                     388.479\n",
      "trainer/Bias Value                     26.0887\n",
      "trainer/Policy Grad Norm              273.39\n",
      "trainer/Policy Param Norm              28.421\n",
      "trainer/Zf1 Grad Norm                6144.39\n",
      "trainer/Zf1 Param Norm                 81.606\n",
      "trainer/Zf2 Grad Norm                6349.7\n",
      "trainer/Zf2 Param Norm                 82.4803\n",
      "trainer/Z Expert Predictions Mean    2461.01\n",
      "trainer/Z Expert Predictions Std      126.593\n",
      "trainer/Z Expert Predictions Max     2625.78\n",
      "trainer/Z Expert Predictions Min     1869.72\n",
      "trainer/Z Policy Predictions Mean    1818.16\n",
      "trainer/Z Policy Predictions Std      700.547\n",
      "trainer/Z Policy Predictions Max     2584.54\n",
      "trainer/Z Policy Predictions Min      237.44\n",
      "trainer/Z Expert Targets Mean        2437.23\n",
      "trainer/Z Expert Targets Std          127.858\n",
      "trainer/Z Expert Targets Max         2574.73\n",
      "trainer/Z Expert Targets Min         1780.65\n",
      "trainer/Z Policy Targets Mean        1806.46\n",
      "trainer/Z Policy Targets Std          691.018\n",
      "trainer/Z Policy Targets Max         2552.51\n",
      "trainer/Z Policy Targets Min          242.262\n",
      "trainer/Log Pis Mean                   35.7086\n",
      "trainer/Log Pis Std                    14.3814\n",
      "trainer/Policy mu Mean                  0.116673\n",
      "trainer/Policy mu Std                   2.35491\n",
      "trainer/Policy log std Mean            -3.87326\n",
      "trainer/Policy log std Std              0.971157\n",
      "exploration/num steps total         49981\n",
      "exploration/num paths total           155\n",
      "evaluation/num steps total         285841\n",
      "evaluation/num paths total            442\n",
      "evaluation/path length Mean           728.636\n",
      "evaluation/path length Std            357.533\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             11\n",
      "evaluation/Rewards Mean                 3.50972\n",
      "evaluation/Rewards Std                  2.36532\n",
      "evaluation/Rewards Max                  6.74154\n",
      "evaluation/Rewards Min                 -3.44834\n",
      "evaluation/Returns Mean              2557.31\n",
      "evaluation/Returns Std               1897.85\n",
      "evaluation/Returns Max               4410.53\n",
      "evaluation/Returns Min              -1062.96\n",
      "evaluation/Estimation Bias Mean      2201.4\n",
      "evaluation/Estimation Bias Std        567.81\n",
      "evaluation/EB/Q_True Mean             -16.1241\n",
      "evaluation/EB/Q_True Std               73.6357\n",
      "evaluation/EB/Q_Pred Mean            2185.27\n",
      "evaluation/EB/Q_Pred Std              559.29\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2557.31\n",
      "evaluation/Actions Mean                 0.0711579\n",
      "evaluation/Actions Std                  0.592315\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78062\n",
      "time/backward_zf1 (s)                   1.88459\n",
      "time/backward_zf2 (s)                   1.83478\n",
      "time/data sampling (s)                  0.272497\n",
      "time/data storing (s)                   0.0138832\n",
      "time/evaluation sampling (s)            1.72176\n",
      "time/exploration sampling (s)           0.321399\n",
      "time/logging (s)                        0.00990306\n",
      "time/preback_alpha (s)                  0.551704\n",
      "time/preback_policy (s)                 1.02909\n",
      "time/preback_start (s)                  0.141049\n",
      "time/preback_zf (s)                     5.04349\n",
      "time/saving (s)                         0.00644079\n",
      "time/training (s)                       2.36081\n",
      "time/epoch (s)                         16.972\n",
      "time/total (s)                        725.76\n",
      "Epoch                                  42\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:48:31.696558 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 43 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  54000\n",
      "trainer/ZF1 Loss                      117.375\n",
      "trainer/ZF2 Loss                      145.79\n",
      "trainer/ZF Expert Reward               20.6162\n",
      "trainer/ZF Policy Reward                3.16355\n",
      "trainer/ZF CHI2 Term                  183.125\n",
      "trainer/Policy Loss                 -1941.45\n",
      "trainer/Bias Loss                     375.912\n",
      "trainer/Bias Value                     25.8365\n",
      "trainer/Policy Grad Norm              172.713\n",
      "trainer/Policy Param Norm              28.5495\n",
      "trainer/Zf1 Grad Norm                6462.34\n",
      "trainer/Zf1 Param Norm                 82.2002\n",
      "trainer/Zf2 Grad Norm               11192.1\n",
      "trainer/Zf2 Param Norm                 83.1052\n",
      "trainer/Z Expert Predictions Mean    2486.55\n",
      "trainer/Z Expert Predictions Std      118.094\n",
      "trainer/Z Expert Predictions Max     2636.15\n",
      "trainer/Z Expert Predictions Min     1820.63\n",
      "trainer/Z Policy Predictions Mean    1920.82\n",
      "trainer/Z Policy Predictions Std      667.667\n",
      "trainer/Z Policy Predictions Max     2607.59\n",
      "trainer/Z Policy Predictions Min       27.5472\n",
      "trainer/Z Expert Targets Mean        2465.94\n",
      "trainer/Z Expert Targets Std          118.853\n",
      "trainer/Z Expert Targets Max         2604.03\n",
      "trainer/Z Expert Targets Min         1850.15\n",
      "trainer/Z Policy Targets Mean        1917.66\n",
      "trainer/Z Policy Targets Std          662.83\n",
      "trainer/Z Policy Targets Max         2599.63\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   34.4346\n",
      "trainer/Log Pis Std                    12.7127\n",
      "trainer/Policy mu Mean                  0.0939488\n",
      "trainer/Policy mu Std                   2.05544\n",
      "trainer/Policy log std Mean            -4.07833\n",
      "trainer/Policy log std Std              0.960295\n",
      "exploration/num steps total         51083\n",
      "exploration/num paths total           157\n",
      "evaluation/num steps total         293321\n",
      "evaluation/num paths total            453\n",
      "evaluation/path length Mean           680\n",
      "evaluation/path length Std            399.415\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             11\n",
      "evaluation/Rewards Mean                 4.20219\n",
      "evaluation/Rewards Std                  1.47204\n",
      "evaluation/Rewards Max                  6.69753\n",
      "evaluation/Rewards Min                 -3.82354\n",
      "evaluation/Returns Mean              2857.49\n",
      "evaluation/Returns Std               1761.8\n",
      "evaluation/Returns Max               4541\n",
      "evaluation/Returns Min                  5.46376\n",
      "evaluation/Estimation Bias Mean      2399.37\n",
      "evaluation/Estimation Bias Std        285.378\n",
      "evaluation/EB/Q_True Mean              53.3323\n",
      "evaluation/EB/Q_True Std              139.327\n",
      "evaluation/EB/Q_Pred Mean            2452.7\n",
      "evaluation/EB/Q_Pred Std              220.195\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2857.49\n",
      "evaluation/Actions Mean                 0.0178878\n",
      "evaluation/Actions Std                  0.548786\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.75779\n",
      "time/backward_zf1 (s)                   1.86164\n",
      "time/backward_zf2 (s)                   1.81639\n",
      "time/data sampling (s)                  0.265906\n",
      "time/data storing (s)                   0.0138651\n",
      "time/evaluation sampling (s)            1.72938\n",
      "time/exploration sampling (s)           0.317577\n",
      "time/logging (s)                        0.00971352\n",
      "time/preback_alpha (s)                  0.542209\n",
      "time/preback_policy (s)                 1.03258\n",
      "time/preback_start (s)                  0.138647\n",
      "time/preback_zf (s)                     5.01537\n",
      "time/saving (s)                         0.0063555\n",
      "time/training (s)                       2.23507\n",
      "time/epoch (s)                         16.7425\n",
      "time/total (s)                        742.522\n",
      "Epoch                                  43\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:48:48.598080 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 44 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  55000\n",
      "trainer/ZF1 Loss                      159.46\n",
      "trainer/ZF2 Loss                      173.877\n",
      "trainer/ZF Expert Reward               34.2418\n",
      "trainer/ZF Policy Reward                6.45302\n",
      "trainer/ZF CHI2 Term                  229.291\n",
      "trainer/Policy Loss                 -1941.28\n",
      "trainer/Bias Loss                     840.07\n",
      "trainer/Bias Value                     25.5678\n",
      "trainer/Policy Grad Norm              299.164\n",
      "trainer/Policy Param Norm              28.6824\n",
      "trainer/Zf1 Grad Norm                7057.75\n",
      "trainer/Zf1 Param Norm                 82.8123\n",
      "trainer/Zf2 Grad Norm                6344.63\n",
      "trainer/Zf2 Param Norm                 83.7387\n",
      "trainer/Z Expert Predictions Mean    2520.69\n",
      "trainer/Z Expert Predictions Std      119.002\n",
      "trainer/Z Expert Predictions Max     2662.34\n",
      "trainer/Z Expert Predictions Min     1821.76\n",
      "trainer/Z Policy Predictions Mean    1920.35\n",
      "trainer/Z Policy Predictions Std      678.086\n",
      "trainer/Z Policy Predictions Max     2616.25\n",
      "trainer/Z Policy Predictions Min       89.8103\n",
      "trainer/Z Expert Targets Mean        2486.45\n",
      "trainer/Z Expert Targets Std          124.75\n",
      "trainer/Z Expert Targets Max         2635.44\n",
      "trainer/Z Expert Targets Min         1777.98\n",
      "trainer/Z Policy Targets Mean        1913.89\n",
      "trainer/Z Policy Targets Std          667.588\n",
      "trainer/Z Policy Targets Max         2625.87\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   35.185\n",
      "trainer/Log Pis Std                    12.283\n",
      "trainer/Policy mu Mean                 -0.0303928\n",
      "trainer/Policy mu Std                   2.18298\n",
      "trainer/Policy log std Mean            -3.98259\n",
      "trainer/Policy log std Std              0.978008\n",
      "exploration/num steps total         51083\n",
      "exploration/num paths total           157\n",
      "evaluation/num steps total         302107\n",
      "evaluation/num paths total            465\n",
      "evaluation/path length Mean           732.167\n",
      "evaluation/path length Std            398.324\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             10\n",
      "evaluation/Rewards Mean                 4.21827\n",
      "evaluation/Rewards Std                  1.3576\n",
      "evaluation/Rewards Max                  6.73446\n",
      "evaluation/Rewards Min                 -2.36925\n",
      "evaluation/Returns Mean              3088.48\n",
      "evaluation/Returns Std               1741.16\n",
      "evaluation/Returns Max               4444.01\n",
      "evaluation/Returns Min                 -0.312737\n",
      "evaluation/Estimation Bias Mean      2368.53\n",
      "evaluation/Estimation Bias Std        261.029\n",
      "evaluation/EB/Q_True Mean              46.4237\n",
      "evaluation/EB/Q_True Std              134.296\n",
      "evaluation/EB/Q_Pred Mean            2414.96\n",
      "evaluation/EB/Q_Pred Std              207.952\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3088.48\n",
      "evaluation/Actions Mean                 0.0340203\n",
      "evaluation/Actions Std                  0.542641\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -0.999978\n",
      "time/backward_policy (s)                1.73727\n",
      "time/backward_zf1 (s)                   1.85544\n",
      "time/backward_zf2 (s)                   1.79266\n",
      "time/data sampling (s)                  0.267799\n",
      "time/data storing (s)                   0.0141028\n",
      "time/evaluation sampling (s)            1.7281\n",
      "time/exploration sampling (s)           0.320231\n",
      "time/logging (s)                        0.0114008\n",
      "time/preback_alpha (s)                  0.547436\n",
      "time/preback_policy (s)                 1.01712\n",
      "time/preback_start (s)                  0.140998\n",
      "time/preback_zf (s)                     5.05582\n",
      "time/saving (s)                         0.0060998\n",
      "time/training (s)                       2.34607\n",
      "time/epoch (s)                         16.8405\n",
      "time/total (s)                        759.38\n",
      "Epoch                                  44\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:49:05.572920 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 45 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  56000\n",
      "trainer/ZF1 Loss                     2500.2\n",
      "trainer/ZF2 Loss                     2427.4\n",
      "trainer/ZF Expert Reward               14.3635\n",
      "trainer/ZF Policy Reward               12.9673\n",
      "trainer/ZF CHI2 Term                 2499.57\n",
      "trainer/Policy Loss                 -1944.83\n",
      "trainer/Bias Loss                     920.583\n",
      "trainer/Bias Value                     25.309\n",
      "trainer/Policy Grad Norm              145.357\n",
      "trainer/Policy Param Norm              28.8098\n",
      "trainer/Zf1 Grad Norm               12129.9\n",
      "trainer/Zf1 Param Norm                 83.3427\n",
      "trainer/Zf2 Grad Norm               19220.9\n",
      "trainer/Zf2 Param Norm                 84.3607\n",
      "trainer/Z Expert Predictions Mean    2512.55\n",
      "trainer/Z Expert Predictions Std      135.767\n",
      "trainer/Z Expert Predictions Max     2671.43\n",
      "trainer/Z Expert Predictions Min     1788.73\n",
      "trainer/Z Policy Predictions Mean    1924.86\n",
      "trainer/Z Policy Predictions Std      661.317\n",
      "trainer/Z Policy Predictions Max     2645.85\n",
      "trainer/Z Policy Predictions Min      367.126\n",
      "trainer/Z Expert Targets Mean        2498.19\n",
      "trainer/Z Expert Targets Std          146.455\n",
      "trainer/Z Expert Targets Max         2642.89\n",
      "trainer/Z Expert Targets Min         1430.14\n",
      "trainer/Z Policy Targets Mean        1911.89\n",
      "trainer/Z Policy Targets Std          680.575\n",
      "trainer/Z Policy Targets Max         2641.89\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   34.725\n",
      "trainer/Log Pis Std                    11.5275\n",
      "trainer/Policy mu Mean                  0.0434074\n",
      "trainer/Policy mu Std                   2.02515\n",
      "trainer/Policy log std Mean            -4.08162\n",
      "trainer/Policy log std Std              0.960905\n",
      "exploration/num steps total         51860\n",
      "exploration/num paths total           158\n",
      "evaluation/num steps total         309808\n",
      "evaluation/num paths total            478\n",
      "evaluation/path length Mean           592.385\n",
      "evaluation/path length Std            413.256\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 4.28097\n",
      "evaluation/Rewards Std                  1.41842\n",
      "evaluation/Rewards Max                  6.95057\n",
      "evaluation/Rewards Min                 -3.00213\n",
      "evaluation/Returns Mean              2535.98\n",
      "evaluation/Returns Std               1849.55\n",
      "evaluation/Returns Max               4564.13\n",
      "evaluation/Returns Min                  4.83547\n",
      "evaluation/Estimation Bias Mean      2406.85\n",
      "evaluation/Estimation Bias Std        274.427\n",
      "evaluation/EB/Q_True Mean              54.4818\n",
      "evaluation/EB/Q_True Std              144.49\n",
      "evaluation/EB/Q_Pred Mean            2461.33\n",
      "evaluation/EB/Q_Pred Std              213.677\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2535.98\n",
      "evaluation/Actions Mean                 0.0237711\n",
      "evaluation/Actions Std                  0.552289\n",
      "evaluation/Actions Max                  0.999994\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80494\n",
      "time/backward_zf1 (s)                   1.92651\n",
      "time/backward_zf2 (s)                   1.87844\n",
      "time/data sampling (s)                  0.271788\n",
      "time/data storing (s)                   0.0141793\n",
      "time/evaluation sampling (s)            1.75501\n",
      "time/exploration sampling (s)           0.319044\n",
      "time/logging (s)                        0.00965536\n",
      "time/preback_alpha (s)                  0.549426\n",
      "time/preback_policy (s)                 1.09615\n",
      "time/preback_start (s)                  0.140048\n",
      "time/preback_zf (s)                     5.02734\n",
      "time/saving (s)                         0.0059207\n",
      "time/training (s)                       2.10875\n",
      "time/epoch (s)                         16.9072\n",
      "time/total (s)                        776.308\n",
      "Epoch                                  45\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:49:22.616167 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 46 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  57000\n",
      "trainer/ZF1 Loss                      327.79\n",
      "trainer/ZF2 Loss                      311.952\n",
      "trainer/ZF Expert Reward               31.3436\n",
      "trainer/ZF Policy Reward                5.13007\n",
      "trainer/ZF CHI2 Term                  378.983\n",
      "trainer/Policy Loss                 -1994.27\n",
      "trainer/Bias Loss                     772.79\n",
      "trainer/Bias Value                     25.0328\n",
      "trainer/Policy Grad Norm              273.777\n",
      "trainer/Policy Param Norm              28.9393\n",
      "trainer/Zf1 Grad Norm               32913.4\n",
      "trainer/Zf1 Param Norm                 83.8934\n",
      "trainer/Zf2 Grad Norm               25810.6\n",
      "trainer/Zf2 Param Norm                 84.9703\n",
      "trainer/Z Expert Predictions Mean    2553.23\n",
      "trainer/Z Expert Predictions Std      176.883\n",
      "trainer/Z Expert Predictions Max     2698.42\n",
      "trainer/Z Expert Predictions Min      324.023\n",
      "trainer/Z Policy Predictions Mean    1963.43\n",
      "trainer/Z Policy Predictions Std      676.394\n",
      "trainer/Z Policy Predictions Max     2665.92\n",
      "trainer/Z Policy Predictions Min       38.4517\n",
      "trainer/Z Expert Targets Mean        2521.89\n",
      "trainer/Z Expert Targets Std          175.008\n",
      "trainer/Z Expert Targets Max         2677.82\n",
      "trainer/Z Expert Targets Min          339.055\n",
      "trainer/Z Policy Targets Mean        1958.3\n",
      "trainer/Z Policy Targets Std          667.408\n",
      "trainer/Z Policy Targets Max         2633.5\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   33.2307\n",
      "trainer/Log Pis Std                    10.1273\n",
      "trainer/Policy mu Mean                  0.0181605\n",
      "trainer/Policy mu Std                   1.89905\n",
      "trainer/Policy log std Mean            -3.96648\n",
      "trainer/Policy log std Std              0.9669\n",
      "exploration/num steps total         51860\n",
      "exploration/num paths total           158\n",
      "evaluation/num steps total         317078\n",
      "evaluation/num paths total            488\n",
      "evaluation/path length Mean           727\n",
      "evaluation/path length Std            358.222\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             55\n",
      "evaluation/Rewards Mean                 4.35415\n",
      "evaluation/Rewards Std                  1.11461\n",
      "evaluation/Rewards Max                  6.68465\n",
      "evaluation/Rewards Min                 -2.3522\n",
      "evaluation/Returns Mean              3165.47\n",
      "evaluation/Returns Std               1612.34\n",
      "evaluation/Returns Max               4517.94\n",
      "evaluation/Returns Min                135.678\n",
      "evaluation/Estimation Bias Mean      2480.27\n",
      "evaluation/Estimation Bias Std        215.042\n",
      "evaluation/EB/Q_True Mean              55.492\n",
      "evaluation/EB/Q_True Std              143.141\n",
      "evaluation/EB/Q_Pred Mean            2535.77\n",
      "evaluation/EB/Q_Pred Std              142.042\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3165.47\n",
      "evaluation/Actions Mean                 0.0314198\n",
      "evaluation/Actions Std                  0.545162\n",
      "evaluation/Actions Max                  0.999494\n",
      "evaluation/Actions Min                 -0.999306\n",
      "time/backward_policy (s)                1.76944\n",
      "time/backward_zf1 (s)                   1.88867\n",
      "time/backward_zf2 (s)                   1.84225\n",
      "time/data sampling (s)                  0.265678\n",
      "time/data storing (s)                   0.0140373\n",
      "time/evaluation sampling (s)            1.77397\n",
      "time/exploration sampling (s)           0.316977\n",
      "time/logging (s)                        0.00926869\n",
      "time/preback_alpha (s)                  0.549061\n",
      "time/preback_policy (s)                 1.06058\n",
      "time/preback_start (s)                  0.141151\n",
      "time/preback_zf (s)                     5.06543\n",
      "time/saving (s)                         0.00645992\n",
      "time/training (s)                       2.27511\n",
      "time/epoch (s)                         16.9781\n",
      "time/total (s)                        793.306\n",
      "Epoch                                  46\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:49:40.110771 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 47 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  58000\n",
      "trainer/ZF1 Loss                      210.226\n",
      "trainer/ZF2 Loss                      147.77\n",
      "trainer/ZF Expert Reward               26.6777\n",
      "trainer/ZF Policy Reward                6.4776\n",
      "trainer/ZF CHI2 Term                  233.943\n",
      "trainer/Policy Loss                 -1923.24\n",
      "trainer/Bias Loss                     550.972\n",
      "trainer/Bias Value                     24.7716\n",
      "trainer/Policy Grad Norm              214.242\n",
      "trainer/Policy Param Norm              29.0656\n",
      "trainer/Zf1 Grad Norm               29281.2\n",
      "trainer/Zf1 Param Norm                 84.3835\n",
      "trainer/Zf2 Grad Norm                6468.44\n",
      "trainer/Zf2 Param Norm                 85.5484\n",
      "trainer/Z Expert Predictions Mean    2560.29\n",
      "trainer/Z Expert Predictions Std      141.389\n",
      "trainer/Z Expert Predictions Max     2706.11\n",
      "trainer/Z Expert Predictions Min     1864.12\n",
      "trainer/Z Policy Predictions Mean    1910.35\n",
      "trainer/Z Policy Predictions Std      787.52\n",
      "trainer/Z Policy Predictions Max     2692.79\n",
      "trainer/Z Policy Predictions Min      328.408\n",
      "trainer/Z Expert Targets Mean        2533.61\n",
      "trainer/Z Expert Targets Std          149.126\n",
      "trainer/Z Expert Targets Max         2686.13\n",
      "trainer/Z Expert Targets Min         1800.67\n",
      "trainer/Z Policy Targets Mean        1903.87\n",
      "trainer/Z Policy Targets Std          773.291\n",
      "trainer/Z Policy Targets Max         2690.19\n",
      "trainer/Z Policy Targets Min          344.955\n",
      "trainer/Log Pis Mean                   35.0959\n",
      "trainer/Log Pis Std                    12.0476\n",
      "trainer/Policy mu Mean                  0.11369\n",
      "trainer/Policy mu Std                   2.24397\n",
      "trainer/Policy log std Mean            -3.91357\n",
      "trainer/Policy log std Std              1.07505\n",
      "exploration/num steps total         53465\n",
      "exploration/num paths total           160\n",
      "evaluation/num steps total         324213\n",
      "evaluation/num paths total            501\n",
      "evaluation/path length Mean           548.846\n",
      "evaluation/path length Std            405.819\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             37\n",
      "evaluation/Rewards Mean                 4.35893\n",
      "evaluation/Rewards Std                  1.23762\n",
      "evaluation/Rewards Max                  6.67163\n",
      "evaluation/Rewards Min                 -2.50396\n",
      "evaluation/Returns Mean              2392.38\n",
      "evaluation/Returns Std               1863.25\n",
      "evaluation/Returns Max               4658.83\n",
      "evaluation/Returns Min                 83.887\n",
      "evaluation/Estimation Bias Mean      2436.92\n",
      "evaluation/Estimation Bias Std        244.698\n",
      "evaluation/EB/Q_True Mean              59.473\n",
      "evaluation/EB/Q_True Std              151.117\n",
      "evaluation/EB/Q_Pred Mean            2496.39\n",
      "evaluation/EB/Q_Pred Std              167.431\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2392.38\n",
      "evaluation/Actions Mean                 0.0229136\n",
      "evaluation/Actions Std                  0.518055\n",
      "evaluation/Actions Max                  0.999675\n",
      "evaluation/Actions Min                 -0.999797\n",
      "time/backward_policy (s)                1.90414\n",
      "time/backward_zf1 (s)                   2.01438\n",
      "time/backward_zf2 (s)                   1.94476\n",
      "time/data sampling (s)                  0.281886\n",
      "time/data storing (s)                   0.0138302\n",
      "time/evaluation sampling (s)            1.72188\n",
      "time/exploration sampling (s)           0.324524\n",
      "time/logging (s)                        0.00965001\n",
      "time/preback_alpha (s)                  0.567771\n",
      "time/preback_policy (s)                 1.11369\n",
      "time/preback_start (s)                  0.145349\n",
      "time/preback_zf (s)                     5.09696\n",
      "time/saving (s)                         0.00679937\n",
      "time/training (s)                       2.28433\n",
      "time/epoch (s)                         17.4299\n",
      "time/total (s)                        810.754\n",
      "Epoch                                  47\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:49:57.224450 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 48 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  59000\n",
      "trainer/ZF1 Loss                      156.327\n",
      "trainer/ZF2 Loss                      189.959\n",
      "trainer/ZF Expert Reward                8.6882\n",
      "trainer/ZF Policy Reward               -3.71084\n",
      "trainer/ZF CHI2 Term                  219.334\n",
      "trainer/Policy Loss                 -2010.66\n",
      "trainer/Bias Loss                     581.309\n",
      "trainer/Bias Value                     24.5296\n",
      "trainer/Policy Grad Norm              220.823\n",
      "trainer/Policy Param Norm              29.1858\n",
      "trainer/Zf1 Grad Norm                8653.84\n",
      "trainer/Zf1 Param Norm                 84.844\n",
      "trainer/Zf2 Grad Norm                9416.5\n",
      "trainer/Zf2 Param Norm                 86.1084\n",
      "trainer/Z Expert Predictions Mean    2545.93\n",
      "trainer/Z Expert Predictions Std      133.069\n",
      "trainer/Z Expert Predictions Max     2696.74\n",
      "trainer/Z Expert Predictions Min     1963.35\n",
      "trainer/Z Policy Predictions Mean    2001.09\n",
      "trainer/Z Policy Predictions Std      681.705\n",
      "trainer/Z Policy Predictions Max     2668.73\n",
      "trainer/Z Policy Predictions Min      111.22\n",
      "trainer/Z Expert Targets Mean        2537.24\n",
      "trainer/Z Expert Targets Std          134.385\n",
      "trainer/Z Expert Targets Max         2699.88\n",
      "trainer/Z Expert Targets Min         1966.12\n",
      "trainer/Z Policy Targets Mean        2004.8\n",
      "trainer/Z Policy Targets Std          675.595\n",
      "trainer/Z Policy Targets Max         2696.28\n",
      "trainer/Z Policy Targets Min          145.459\n",
      "trainer/Log Pis Mean                   34.1334\n",
      "trainer/Log Pis Std                    10.8408\n",
      "trainer/Policy mu Mean                 -0.0112358\n",
      "trainer/Policy mu Std                   2.07183\n",
      "trainer/Policy log std Mean            -3.98161\n",
      "trainer/Policy log std Std              1.00332\n",
      "exploration/num steps total         53465\n",
      "exploration/num paths total           160\n",
      "evaluation/num steps total         331547\n",
      "evaluation/num paths total            511\n",
      "evaluation/path length Mean           733.4\n",
      "evaluation/path length Std            412.272\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 4.61128\n",
      "evaluation/Rewards Std                  1.07015\n",
      "evaluation/Rewards Max                  6.96173\n",
      "evaluation/Rewards Min                 -2.3134\n",
      "evaluation/Returns Mean              3381.91\n",
      "evaluation/Returns Std               1972.93\n",
      "evaluation/Returns Max               4778.31\n",
      "evaluation/Returns Min                  2.01548\n",
      "evaluation/Estimation Bias Mean      2521.96\n",
      "evaluation/Estimation Bias Std        226.928\n",
      "evaluation/EB/Q_True Mean              57.99\n",
      "evaluation/EB/Q_True Std              150.12\n",
      "evaluation/EB/Q_Pred Mean            2579.95\n",
      "evaluation/EB/Q_Pred Std              143.632\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3381.91\n",
      "evaluation/Actions Mean                 0.0241687\n",
      "evaluation/Actions Std                  0.53029\n",
      "evaluation/Actions Max                  0.998912\n",
      "evaluation/Actions Min                 -0.999607\n",
      "time/backward_policy (s)                1.7472\n",
      "time/backward_zf1 (s)                   1.89127\n",
      "time/backward_zf2 (s)                   1.79873\n",
      "time/data sampling (s)                  0.2674\n",
      "time/data storing (s)                   0.0139163\n",
      "time/evaluation sampling (s)            1.86162\n",
      "time/exploration sampling (s)           0.316826\n",
      "time/logging (s)                        0.0103964\n",
      "time/preback_alpha (s)                  0.557074\n",
      "time/preback_policy (s)                 1.01928\n",
      "time/preback_start (s)                  0.141584\n",
      "time/preback_zf (s)                     5.05215\n",
      "time/saving (s)                         0.0176751\n",
      "time/training (s)                       2.35282\n",
      "time/epoch (s)                         17.0479\n",
      "time/total (s)                        827.822\n",
      "Epoch                                  48\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:50:14.141824 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 49 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  60000\n",
      "trainer/ZF1 Loss                      138.384\n",
      "trainer/ZF2 Loss                      170.148\n",
      "trainer/ZF Expert Reward               18.7566\n",
      "trainer/ZF Policy Reward               -5.05422\n",
      "trainer/ZF CHI2 Term                  212.054\n",
      "trainer/Policy Loss                 -1938.32\n",
      "trainer/Bias Loss                     739.432\n",
      "trainer/Bias Value                     24.223\n",
      "trainer/Policy Grad Norm              126.733\n",
      "trainer/Policy Param Norm              29.3064\n",
      "trainer/Zf1 Grad Norm                9868.7\n",
      "trainer/Zf1 Param Norm                 85.3411\n",
      "trainer/Zf2 Grad Norm               10728\n",
      "trainer/Zf2 Param Norm                 86.7061\n",
      "trainer/Z Expert Predictions Mean    2572.56\n",
      "trainer/Z Expert Predictions Std      121.172\n",
      "trainer/Z Expert Predictions Max     2737.87\n",
      "trainer/Z Expert Predictions Min     2024.98\n",
      "trainer/Z Policy Predictions Mean    1920.15\n",
      "trainer/Z Policy Predictions Std      771.191\n",
      "trainer/Z Policy Predictions Max     2729.21\n",
      "trainer/Z Policy Predictions Min      306.042\n",
      "trainer/Z Expert Targets Mean        2553.81\n",
      "trainer/Z Expert Targets Std          118.169\n",
      "trainer/Z Expert Targets Max         2698.92\n",
      "trainer/Z Expert Targets Min         2046.17\n",
      "trainer/Z Policy Targets Mean        1925.21\n",
      "trainer/Z Policy Targets Std          760.234\n",
      "trainer/Z Policy Targets Max         2708.1\n",
      "trainer/Z Policy Targets Min          332.387\n",
      "trainer/Log Pis Mean                   34.32\n",
      "trainer/Log Pis Std                    11.0363\n",
      "trainer/Policy mu Mean                  0.0824283\n",
      "trainer/Policy mu Std                   2.20187\n",
      "trainer/Policy log std Mean            -3.82596\n",
      "trainer/Policy log std Std              1.11591\n",
      "exploration/num steps total         53465\n",
      "exploration/num paths total           160\n",
      "evaluation/num steps total         338832\n",
      "evaluation/num paths total            523\n",
      "evaluation/path length Mean           607.083\n",
      "evaluation/path length Std            387.771\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             56\n",
      "evaluation/Rewards Mean                 2.61142\n",
      "evaluation/Rewards Std                  2.967\n",
      "evaluation/Rewards Max                  6.92323\n",
      "evaluation/Rewards Min                 -4.77181\n",
      "evaluation/Returns Mean              1585.35\n",
      "evaluation/Returns Std               1742.96\n",
      "evaluation/Returns Max               3907.25\n",
      "evaluation/Returns Min              -2134.36\n",
      "evaluation/Estimation Bias Mean      2091.69\n",
      "evaluation/Estimation Bias Std        784.485\n",
      "evaluation/EB/Q_True Mean             -29.7669\n",
      "evaluation/EB/Q_True Std               80.9861\n",
      "evaluation/EB/Q_Pred Mean            2061.92\n",
      "evaluation/EB/Q_Pred Std              771.852\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           1585.35\n",
      "evaluation/Actions Mean                 0.0613623\n",
      "evaluation/Actions Std                  0.637363\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67634\n",
      "time/backward_zf1 (s)                   1.81099\n",
      "time/backward_zf2 (s)                   1.74228\n",
      "time/data sampling (s)                  0.270668\n",
      "time/data storing (s)                   0.0143233\n",
      "time/evaluation sampling (s)            1.76331\n",
      "time/exploration sampling (s)           0.320113\n",
      "time/logging (s)                        0.00959675\n",
      "time/preback_alpha (s)                  0.555863\n",
      "time/preback_policy (s)                 0.953672\n",
      "time/preback_start (s)                  0.142491\n",
      "time/preback_zf (s)                     5.07312\n",
      "time/saving (s)                         0.00630395\n",
      "time/training (s)                       2.51308\n",
      "time/epoch (s)                         16.8522\n",
      "time/total (s)                        844.694\n",
      "Epoch                                  49\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:50:31.107865 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 50 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  61000\n",
      "trainer/ZF1 Loss                      137.566\n",
      "trainer/ZF2 Loss                      147.101\n",
      "trainer/ZF Expert Reward               15.7801\n",
      "trainer/ZF Policy Reward                0.870736\n",
      "trainer/ZF CHI2 Term                  192.16\n",
      "trainer/Policy Loss                 -1979.58\n",
      "trainer/Bias Loss                     677.467\n",
      "trainer/Bias Value                     23.9532\n",
      "trainer/Policy Grad Norm              261.66\n",
      "trainer/Policy Param Norm              29.4306\n",
      "trainer/Zf1 Grad Norm               12289.8\n",
      "trainer/Zf1 Param Norm                 85.7854\n",
      "trainer/Zf2 Grad Norm               18342.5\n",
      "trainer/Zf2 Param Norm                 87.2289\n",
      "trainer/Z Expert Predictions Mean    2581.19\n",
      "trainer/Z Expert Predictions Std      122.006\n",
      "trainer/Z Expert Predictions Max     2732.63\n",
      "trainer/Z Expert Predictions Min     1986.21\n",
      "trainer/Z Policy Predictions Mean    1969.62\n",
      "trainer/Z Policy Predictions Std      743.839\n",
      "trainer/Z Policy Predictions Max     2706.1\n",
      "trainer/Z Policy Predictions Min      328.976\n",
      "trainer/Z Expert Targets Mean        2565.41\n",
      "trainer/Z Expert Targets Std          115.904\n",
      "trainer/Z Expert Targets Max         2725.1\n",
      "trainer/Z Expert Targets Min         1984.41\n",
      "trainer/Z Policy Targets Mean        1968.75\n",
      "trainer/Z Policy Targets Std          733.451\n",
      "trainer/Z Policy Targets Max         2700.39\n",
      "trainer/Z Policy Targets Min          362.581\n",
      "trainer/Log Pis Mean                   35.2704\n",
      "trainer/Log Pis Std                    12.475\n",
      "trainer/Policy mu Mean                  0.104178\n",
      "trainer/Policy mu Std                   2.23352\n",
      "trainer/Policy log std Mean            -3.92938\n",
      "trainer/Policy log std Std              1.00629\n",
      "exploration/num steps total         56348\n",
      "exploration/num paths total           163\n",
      "evaluation/num steps total         345572\n",
      "evaluation/num paths total            536\n",
      "evaluation/path length Mean           518.462\n",
      "evaluation/path length Std            426.941\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             27\n",
      "evaluation/Rewards Mean                 3.108\n",
      "evaluation/Rewards Std                  2.66635\n",
      "evaluation/Rewards Max                  6.46874\n",
      "evaluation/Rewards Min                 -3.75896\n",
      "evaluation/Returns Mean              1611.38\n",
      "evaluation/Returns Std               2097.08\n",
      "evaluation/Returns Max               4484.27\n",
      "evaluation/Returns Min              -2349.8\n",
      "evaluation/Estimation Bias Mean      2269.84\n",
      "evaluation/Estimation Bias Std        731.69\n",
      "evaluation/EB/Q_True Mean             -33.4257\n",
      "evaluation/EB/Q_True Std               82.8571\n",
      "evaluation/EB/Q_Pred Mean            2236.41\n",
      "evaluation/EB/Q_Pred Std              715.681\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           1611.38\n",
      "evaluation/Actions Mean                -0.0188877\n",
      "evaluation/Actions Std                  0.609496\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7839\n",
      "time/backward_zf1 (s)                   1.91015\n",
      "time/backward_zf2 (s)                   1.8529\n",
      "time/data sampling (s)                  0.265734\n",
      "time/data storing (s)                   0.0139128\n",
      "time/evaluation sampling (s)            1.71895\n",
      "time/exploration sampling (s)           0.325075\n",
      "time/logging (s)                        0.00957051\n",
      "time/preback_alpha (s)                  0.553906\n",
      "time/preback_policy (s)                 1.08084\n",
      "time/preback_start (s)                  0.142148\n",
      "time/preback_zf (s)                     5.05054\n",
      "time/saving (s)                         0.00632416\n",
      "time/training (s)                       2.18902\n",
      "time/epoch (s)                         16.903\n",
      "time/total (s)                        861.614\n",
      "Epoch                                  50\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:50:48.478986 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 51 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  62000\n",
      "trainer/ZF1 Loss                       92.2188\n",
      "trainer/ZF2 Loss                       80.0804\n",
      "trainer/ZF Expert Reward               27.308\n",
      "trainer/ZF Policy Reward                2.86504\n",
      "trainer/ZF CHI2 Term                  145.057\n",
      "trainer/Policy Loss                 -2053.5\n",
      "trainer/Bias Loss                     315.694\n",
      "trainer/Bias Value                     23.6994\n",
      "trainer/Policy Grad Norm              181.886\n",
      "trainer/Policy Param Norm              29.5437\n",
      "trainer/Zf1 Grad Norm                9684.98\n",
      "trainer/Zf1 Param Norm                 86.1708\n",
      "trainer/Zf2 Grad Norm                3723.41\n",
      "trainer/Zf2 Param Norm                 87.7218\n",
      "trainer/Z Expert Predictions Mean    2609.97\n",
      "trainer/Z Expert Predictions Std      118.681\n",
      "trainer/Z Expert Predictions Max     2758.91\n",
      "trainer/Z Expert Predictions Min     2005.34\n",
      "trainer/Z Policy Predictions Mean    2034.25\n",
      "trainer/Z Policy Predictions Std      720.71\n",
      "trainer/Z Policy Predictions Max     2766.31\n",
      "trainer/Z Policy Predictions Min      126.4\n",
      "trainer/Z Expert Targets Mean        2582.66\n",
      "trainer/Z Expert Targets Std          119.459\n",
      "trainer/Z Expert Targets Max         2718.5\n",
      "trainer/Z Expert Targets Min         2010.56\n",
      "trainer/Z Policy Targets Mean        2031.39\n",
      "trainer/Z Policy Targets Std          709.962\n",
      "trainer/Z Policy Targets Max         2723.7\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   34.8128\n",
      "trainer/Log Pis Std                    11.3886\n",
      "trainer/Policy mu Mean                 -0.00035652\n",
      "trainer/Policy mu Std                   2.15782\n",
      "trainer/Policy log std Mean            -4.00645\n",
      "trainer/Policy log std Std              1.06674\n",
      "exploration/num steps total         56461\n",
      "exploration/num paths total           164\n",
      "evaluation/num steps total         354858\n",
      "evaluation/num paths total            549\n",
      "evaluation/path length Mean           714.308\n",
      "evaluation/path length Std            323.363\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min              9\n",
      "evaluation/Rewards Mean                 3.26941\n",
      "evaluation/Rewards Std                  2.69596\n",
      "evaluation/Rewards Max                  6.7591\n",
      "evaluation/Rewards Min                 -4.78591\n",
      "evaluation/Returns Mean              2335.37\n",
      "evaluation/Returns Std               1876.74\n",
      "evaluation/Returns Max               4584.13\n",
      "evaluation/Returns Min              -1927.32\n",
      "evaluation/Estimation Bias Mean      2185.16\n",
      "evaluation/Estimation Bias Std        719.242\n",
      "evaluation/EB/Q_True Mean              45.4713\n",
      "evaluation/EB/Q_True Std              134.437\n",
      "evaluation/EB/Q_Pred Mean            2230.63\n",
      "evaluation/EB/Q_Pred Std              719.334\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2335.37\n",
      "evaluation/Actions Mean                 0.0255822\n",
      "evaluation/Actions Std                  0.607749\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9123\n",
      "time/backward_zf1 (s)                   2.03691\n",
      "time/backward_zf2 (s)                   1.97593\n",
      "time/data sampling (s)                  0.268039\n",
      "time/data storing (s)                   0.0142706\n",
      "time/evaluation sampling (s)            1.85629\n",
      "time/exploration sampling (s)           0.316025\n",
      "time/logging (s)                        0.0122198\n",
      "time/preback_alpha (s)                  0.557966\n",
      "time/preback_policy (s)                 1.18507\n",
      "time/preback_start (s)                  0.142532\n",
      "time/preback_zf (s)                     5.04313\n",
      "time/saving (s)                         0.00661897\n",
      "time/training (s)                       1.97461\n",
      "time/epoch (s)                         17.3019\n",
      "time/total (s)                        878.942\n",
      "Epoch                                  51\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:51:05.902788 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 52 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  63000\n",
      "trainer/ZF1 Loss                      157.187\n",
      "trainer/ZF2 Loss                      113.5\n",
      "trainer/ZF Expert Reward               22.1314\n",
      "trainer/ZF Policy Reward               -2.57232\n",
      "trainer/ZF CHI2 Term                  195.426\n",
      "trainer/Policy Loss                 -1967.5\n",
      "trainer/Bias Loss                     455.988\n",
      "trainer/Bias Value                     23.4183\n",
      "trainer/Policy Grad Norm              195.069\n",
      "trainer/Policy Param Norm              29.6557\n",
      "trainer/Zf1 Grad Norm               10216.5\n",
      "trainer/Zf1 Param Norm                 86.5242\n",
      "trainer/Zf2 Grad Norm                5538.47\n",
      "trainer/Zf2 Param Norm                 88.1925\n",
      "trainer/Z Expert Predictions Mean    2594.48\n",
      "trainer/Z Expert Predictions Std      132.127\n",
      "trainer/Z Expert Predictions Max     2745.17\n",
      "trainer/Z Expert Predictions Min     1931.49\n",
      "trainer/Z Policy Predictions Mean    1951.78\n",
      "trainer/Z Policy Predictions Std      784.291\n",
      "trainer/Z Policy Predictions Max     2749.69\n",
      "trainer/Z Policy Predictions Min     -168.558\n",
      "trainer/Z Expert Targets Mean        2572.35\n",
      "trainer/Z Expert Targets Std          133.178\n",
      "trainer/Z Expert Targets Max         2727.08\n",
      "trainer/Z Expert Targets Min         1945.82\n",
      "trainer/Z Policy Targets Mean        1954.35\n",
      "trainer/Z Policy Targets Std          769.049\n",
      "trainer/Z Policy Targets Max         2732.66\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   35.7362\n",
      "trainer/Log Pis Std                    12.0116\n",
      "trainer/Policy mu Mean                  0.0256901\n",
      "trainer/Policy mu Std                   2.32522\n",
      "trainer/Policy log std Mean            -3.8752\n",
      "trainer/Policy log std Std              1.10247\n",
      "exploration/num steps total         58520\n",
      "exploration/num paths total           167\n",
      "evaluation/num steps total         363888\n",
      "evaluation/num paths total            560\n",
      "evaluation/path length Mean           820.909\n",
      "evaluation/path length Std            281.866\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            185\n",
      "evaluation/Rewards Mean                 4.21456\n",
      "evaluation/Rewards Std                  1.54799\n",
      "evaluation/Rewards Max                  6.95425\n",
      "evaluation/Rewards Min                 -2.90625\n",
      "evaluation/Returns Mean              3459.77\n",
      "evaluation/Returns Std               1290.35\n",
      "evaluation/Returns Max               4643.03\n",
      "evaluation/Returns Min                756.142\n",
      "evaluation/Estimation Bias Mean      2494.49\n",
      "evaluation/Estimation Bias Std        248.181\n",
      "evaluation/EB/Q_True Mean              43.4583\n",
      "evaluation/EB/Q_True Std              127.063\n",
      "evaluation/EB/Q_Pred Mean            2537.95\n",
      "evaluation/EB/Q_Pred Std              209.603\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3459.77\n",
      "evaluation/Actions Mean                 0.0213215\n",
      "evaluation/Actions Std                  0.549862\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.93971\n",
      "time/backward_zf1 (s)                   2.07739\n",
      "time/backward_zf2 (s)                   2.01909\n",
      "time/data sampling (s)                  0.283139\n",
      "time/data storing (s)                   0.0147941\n",
      "time/evaluation sampling (s)            1.70186\n",
      "time/exploration sampling (s)           0.333045\n",
      "time/logging (s)                        0.0116602\n",
      "time/preback_alpha (s)                  0.560209\n",
      "time/preback_policy (s)                 1.19513\n",
      "time/preback_start (s)                  0.145657\n",
      "time/preback_zf (s)                     5.05801\n",
      "time/saving (s)                         0.00656559\n",
      "time/training (s)                       2.01222\n",
      "time/epoch (s)                         17.3585\n",
      "time/total (s)                        896.319\n",
      "Epoch                                  52\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:51:23.275798 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 53 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  64000\n",
      "trainer/ZF1 Loss                      261.57\n",
      "trainer/ZF2 Loss                      186.809\n",
      "trainer/ZF Expert Reward               31.5693\n",
      "trainer/ZF Policy Reward               10.2318\n",
      "trainer/ZF CHI2 Term                  279.492\n",
      "trainer/Policy Loss                 -2043.37\n",
      "trainer/Bias Loss                     411.95\n",
      "trainer/Bias Value                     23.136\n",
      "trainer/Policy Grad Norm              249.608\n",
      "trainer/Policy Param Norm              29.754\n",
      "trainer/Zf1 Grad Norm               25861.5\n",
      "trainer/Zf1 Param Norm                 86.8762\n",
      "trainer/Zf2 Grad Norm                8507.71\n",
      "trainer/Zf2 Param Norm                 88.6428\n",
      "trainer/Z Expert Predictions Mean    2607.94\n",
      "trainer/Z Expert Predictions Std      122.094\n",
      "trainer/Z Expert Predictions Max     2749.69\n",
      "trainer/Z Expert Predictions Min     1965.66\n",
      "trainer/Z Policy Predictions Mean    2036.31\n",
      "trainer/Z Policy Predictions Std      738.837\n",
      "trainer/Z Policy Predictions Max     2743.63\n",
      "trainer/Z Policy Predictions Min      303.986\n",
      "trainer/Z Expert Targets Mean        2576.37\n",
      "trainer/Z Expert Targets Std          125.333\n",
      "trainer/Z Expert Targets Max         2736.37\n",
      "trainer/Z Expert Targets Min         1942.86\n",
      "trainer/Z Policy Targets Mean        2026.08\n",
      "trainer/Z Policy Targets Std          726.405\n",
      "trainer/Z Policy Targets Max         2731.51\n",
      "trainer/Z Policy Targets Min          302.013\n",
      "trainer/Log Pis Mean                   34.3078\n",
      "trainer/Log Pis Std                    10.7068\n",
      "trainer/Policy mu Mean                  0.126963\n",
      "trainer/Policy mu Std                   2.0677\n",
      "trainer/Policy log std Mean            -3.94165\n",
      "trainer/Policy log std Std              1.02943\n",
      "exploration/num steps total         61131\n",
      "exploration/num paths total           171\n",
      "evaluation/num steps total         373477\n",
      "evaluation/num paths total            571\n",
      "evaluation/path length Mean           871.727\n",
      "evaluation/path length Std            291.702\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             48\n",
      "evaluation/Rewards Mean                 4.27486\n",
      "evaluation/Rewards Std                  1.60371\n",
      "evaluation/Rewards Max                  6.84158\n",
      "evaluation/Rewards Min                 -4.21034\n",
      "evaluation/Returns Mean              3726.51\n",
      "evaluation/Returns Std               1360.87\n",
      "evaluation/Returns Max               4673.2\n",
      "evaluation/Returns Min                136.478\n",
      "evaluation/Estimation Bias Mean      2481.3\n",
      "evaluation/Estimation Bias Std        355.54\n",
      "evaluation/EB/Q_True Mean              42.9333\n",
      "evaluation/EB/Q_True Std              129.19\n",
      "evaluation/EB/Q_Pred Mean            2524.23\n",
      "evaluation/EB/Q_Pred Std              323.902\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3726.51\n",
      "evaluation/Actions Mean                 0.0138273\n",
      "evaluation/Actions Std                  0.565322\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84008\n",
      "time/backward_zf1 (s)                   1.98275\n",
      "time/backward_zf2 (s)                   1.91753\n",
      "time/data sampling (s)                  0.281649\n",
      "time/data storing (s)                   0.0144279\n",
      "time/evaluation sampling (s)            1.75136\n",
      "time/exploration sampling (s)           0.328254\n",
      "time/logging (s)                        0.0119952\n",
      "time/preback_alpha (s)                  0.566536\n",
      "time/preback_policy (s)                 1.08115\n",
      "time/preback_start (s)                  0.145616\n",
      "time/preback_zf (s)                     5.11759\n",
      "time/saving (s)                         0.00656216\n",
      "time/training (s)                       2.26289\n",
      "time/epoch (s)                         17.3084\n",
      "time/total (s)                        913.646\n",
      "Epoch                                  53\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:51:40.011235 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 54 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  65000\n",
      "trainer/ZF1 Loss                      318.109\n",
      "trainer/ZF2 Loss                      236.23\n",
      "trainer/ZF Expert Reward               22.5914\n",
      "trainer/ZF Policy Reward                8.54231\n",
      "trainer/ZF CHI2 Term                  324.601\n",
      "trainer/Policy Loss                 -2078.81\n",
      "trainer/Bias Loss                    1270.02\n",
      "trainer/Bias Value                     22.845\n",
      "trainer/Policy Grad Norm              223.225\n",
      "trainer/Policy Param Norm              29.8573\n",
      "trainer/Zf1 Grad Norm               35755.7\n",
      "trainer/Zf1 Param Norm                 87.2319\n",
      "trainer/Zf2 Grad Norm               22934.1\n",
      "trainer/Zf2 Param Norm                 89.0949\n",
      "trainer/Z Expert Predictions Mean    2593.21\n",
      "trainer/Z Expert Predictions Std      178.49\n",
      "trainer/Z Expert Predictions Max     2760.03\n",
      "trainer/Z Expert Predictions Min      550.236\n",
      "trainer/Z Policy Predictions Mean    2075.09\n",
      "trainer/Z Policy Predictions Std      692.315\n",
      "trainer/Z Policy Predictions Max     2756.48\n",
      "trainer/Z Policy Predictions Min      298.133\n",
      "trainer/Z Expert Targets Mean        2570.62\n",
      "trainer/Z Expert Targets Std          207.662\n",
      "trainer/Z Expert Targets Max         2743.53\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        2066.55\n",
      "trainer/Z Policy Targets Std          682.046\n",
      "trainer/Z Policy Targets Max         2726.57\n",
      "trainer/Z Policy Targets Min          288.772\n",
      "trainer/Log Pis Mean                   33.7194\n",
      "trainer/Log Pis Std                    10.2508\n",
      "trainer/Policy mu Mean                 -0.0391433\n",
      "trainer/Policy mu Std                   2.07039\n",
      "trainer/Policy log std Mean            -3.94227\n",
      "trainer/Policy log std Std              1.09519\n",
      "exploration/num steps total         61131\n",
      "exploration/num paths total           171\n",
      "evaluation/num steps total         380759\n",
      "evaluation/num paths total            582\n",
      "evaluation/path length Mean           662\n",
      "evaluation/path length Std            371.514\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             11\n",
      "evaluation/Rewards Mean                 4.43862\n",
      "evaluation/Rewards Std                  1.14839\n",
      "evaluation/Rewards Max                  6.8117\n",
      "evaluation/Rewards Min                 -2.5442\n",
      "evaluation/Returns Mean              2938.36\n",
      "evaluation/Returns Std               1733.84\n",
      "evaluation/Returns Max               4632.7\n",
      "evaluation/Returns Min                 -4.8803\n",
      "evaluation/Estimation Bias Mean      2517.06\n",
      "evaluation/Estimation Bias Std        247.896\n",
      "evaluation/EB/Q_True Mean              58.3096\n",
      "evaluation/EB/Q_True Std              150.261\n",
      "evaluation/EB/Q_Pred Mean            2575.36\n",
      "evaluation/EB/Q_Pred Std              169.133\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2938.36\n",
      "evaluation/Actions Mean                 0.0225304\n",
      "evaluation/Actions Std                  0.550519\n",
      "evaluation/Actions Max                  0.999949\n",
      "evaluation/Actions Min                 -0.999894\n",
      "time/backward_policy (s)                1.71009\n",
      "time/backward_zf1 (s)                   1.82839\n",
      "time/backward_zf2 (s)                   1.76517\n",
      "time/data sampling (s)                  0.278534\n",
      "time/data storing (s)                   0.0141181\n",
      "time/evaluation sampling (s)            1.72143\n",
      "time/exploration sampling (s)           0.312789\n",
      "time/logging (s)                        0.00904048\n",
      "time/preback_alpha (s)                  0.546744\n",
      "time/preback_policy (s)                 0.980762\n",
      "time/preback_start (s)                  0.140417\n",
      "time/preback_zf (s)                     5.02865\n",
      "time/saving (s)                         0.00592132\n",
      "time/training (s)                       2.32689\n",
      "time/epoch (s)                         16.6689\n",
      "time/total (s)                        930.333\n",
      "Epoch                                  54\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:51:57.281513 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 55 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  66000\n",
      "trainer/ZF1 Loss                      470.736\n",
      "trainer/ZF2 Loss                      405.028\n",
      "trainer/ZF Expert Reward               32.7739\n",
      "trainer/ZF Policy Reward                7.29398\n",
      "trainer/ZF CHI2 Term                  498.064\n",
      "trainer/Policy Loss                 -2038.54\n",
      "trainer/Bias Loss                    3201.53\n",
      "trainer/Bias Value                     22.5484\n",
      "trainer/Policy Grad Norm              155.883\n",
      "trainer/Policy Param Norm              29.9531\n",
      "trainer/Zf1 Grad Norm               26140.1\n",
      "trainer/Zf1 Param Norm                 87.5648\n",
      "trainer/Zf2 Grad Norm               17072.7\n",
      "trainer/Zf2 Param Norm                 89.4761\n",
      "trainer/Z Expert Predictions Mean    2613.84\n",
      "trainer/Z Expert Predictions Std      169.133\n",
      "trainer/Z Expert Predictions Max     2778.95\n",
      "trainer/Z Expert Predictions Min      439.786\n",
      "trainer/Z Policy Predictions Mean    2029\n",
      "trainer/Z Policy Predictions Std      724.24\n",
      "trainer/Z Policy Predictions Max     2733.76\n",
      "trainer/Z Policy Predictions Min      237.823\n",
      "trainer/Z Expert Targets Mean        2581.06\n",
      "trainer/Z Expert Targets Std          206.583\n",
      "trainer/Z Expert Targets Max         2764.69\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        2021.71\n",
      "trainer/Z Policy Targets Std          707.583\n",
      "trainer/Z Policy Targets Max         2715.08\n",
      "trainer/Z Policy Targets Min          246.135\n",
      "trainer/Log Pis Mean                   35.0529\n",
      "trainer/Log Pis Std                    12.3637\n",
      "trainer/Policy mu Mean                  0.146193\n",
      "trainer/Policy mu Std                   2.25369\n",
      "trainer/Policy log std Mean            -4.01586\n",
      "trainer/Policy log std Std              1.01576\n",
      "exploration/num steps total         62131\n",
      "exploration/num paths total           172\n",
      "evaluation/num steps total         388329\n",
      "evaluation/num paths total            593\n",
      "evaluation/path length Mean           688.182\n",
      "evaluation/path length Std            392.52\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 3.8269\n",
      "evaluation/Rewards Std                  2.14865\n",
      "evaluation/Rewards Max                  6.7757\n",
      "evaluation/Rewards Min                 -4.28701\n",
      "evaluation/Returns Mean              2633.6\n",
      "evaluation/Returns Std               1683\n",
      "evaluation/Returns Max               4423.86\n",
      "evaluation/Returns Min                 -0.968904\n",
      "evaluation/Estimation Bias Mean      2330.54\n",
      "evaluation/Estimation Bias Std        590.212\n",
      "evaluation/EB/Q_True Mean              54.4142\n",
      "evaluation/EB/Q_True Std              144.075\n",
      "evaluation/EB/Q_Pred Mean            2384.95\n",
      "evaluation/EB/Q_Pred Std              579.289\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2633.6\n",
      "evaluation/Actions Mean                 0.0161934\n",
      "evaluation/Actions Std                  0.590808\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.87319\n",
      "time/backward_zf1 (s)                   1.98095\n",
      "time/backward_zf2 (s)                   1.9437\n",
      "time/data sampling (s)                  0.270763\n",
      "time/data storing (s)                   0.0139786\n",
      "time/evaluation sampling (s)            1.73913\n",
      "time/exploration sampling (s)           0.32088\n",
      "time/logging (s)                        0.00992285\n",
      "time/preback_alpha (s)                  0.553793\n",
      "time/preback_policy (s)                 1.14354\n",
      "time/preback_start (s)                  0.14308\n",
      "time/preback_zf (s)                     5.06438\n",
      "time/saving (s)                         0.00738317\n",
      "time/training (s)                       2.13942\n",
      "time/epoch (s)                         17.2041\n",
      "time/total (s)                        947.559\n",
      "Epoch                                  55\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:52:14.528408 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 56 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  67000\n",
      "trainer/ZF1 Loss                      293.76\n",
      "trainer/ZF2 Loss                      301.272\n",
      "trainer/ZF Expert Reward               22.0948\n",
      "trainer/ZF Policy Reward                2.23094\n",
      "trainer/ZF CHI2 Term                  351.107\n",
      "trainer/Policy Loss                 -2095.55\n",
      "trainer/Bias Loss                    1424.7\n",
      "trainer/Bias Value                     22.2338\n",
      "trainer/Policy Grad Norm              167.955\n",
      "trainer/Policy Param Norm              30.051\n",
      "trainer/Zf1 Grad Norm               16386.3\n",
      "trainer/Zf1 Param Norm                 87.8796\n",
      "trainer/Zf2 Grad Norm               22470.6\n",
      "trainer/Zf2 Param Norm                 89.9206\n",
      "trainer/Z Expert Predictions Mean    2582.18\n",
      "trainer/Z Expert Predictions Std      234.721\n",
      "trainer/Z Expert Predictions Max     2761.99\n",
      "trainer/Z Expert Predictions Min       70.9136\n",
      "trainer/Z Policy Predictions Mean    2079.22\n",
      "trainer/Z Policy Predictions Std      715.557\n",
      "trainer/Z Policy Predictions Max     2740.17\n",
      "trainer/Z Policy Predictions Min      -96.703\n",
      "trainer/Z Expert Targets Mean        2560.08\n",
      "trainer/Z Expert Targets Std          256.107\n",
      "trainer/Z Expert Targets Max         2747.17\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        2076.99\n",
      "trainer/Z Policy Targets Std          704.305\n",
      "trainer/Z Policy Targets Max         2716.6\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   34.0678\n",
      "trainer/Log Pis Std                    10.3526\n",
      "trainer/Policy mu Mean                  0.0558828\n",
      "trainer/Policy mu Std                   2.03733\n",
      "trainer/Policy log std Mean            -4.06281\n",
      "trainer/Policy log std Std              1.06346\n",
      "exploration/num steps total         62131\n",
      "exploration/num paths total           172\n",
      "evaluation/num steps total         397405\n",
      "evaluation/num paths total            603\n",
      "evaluation/path length Mean           907.6\n",
      "evaluation/path length Std            184.835\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            530\n",
      "evaluation/Rewards Mean                 4.43881\n",
      "evaluation/Rewards Std                  1.2361\n",
      "evaluation/Rewards Max                  7.02644\n",
      "evaluation/Rewards Min                 -3.23611\n",
      "evaluation/Returns Mean              4028.67\n",
      "evaluation/Returns Std                821.813\n",
      "evaluation/Returns Max               4668.81\n",
      "evaluation/Returns Min               2387.98\n",
      "evaluation/Estimation Bias Mean      2523.79\n",
      "evaluation/Estimation Bias Std        203.994\n",
      "evaluation/EB/Q_True Mean              44.8447\n",
      "evaluation/EB/Q_True Std              130.787\n",
      "evaluation/EB/Q_Pred Mean            2568.63\n",
      "evaluation/EB/Q_Pred Std              164.244\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4028.67\n",
      "evaluation/Actions Mean                 0.0205116\n",
      "evaluation/Actions Std                  0.544931\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999948\n",
      "time/backward_policy (s)                1.78499\n",
      "time/backward_zf1 (s)                   1.9257\n",
      "time/backward_zf2 (s)                   1.84157\n",
      "time/data sampling (s)                  0.285781\n",
      "time/data storing (s)                   0.0149297\n",
      "time/evaluation sampling (s)            1.80525\n",
      "time/exploration sampling (s)           0.322686\n",
      "time/logging (s)                        0.0129684\n",
      "time/preback_alpha (s)                  0.560576\n",
      "time/preback_policy (s)                 1.04367\n",
      "time/preback_start (s)                  0.143344\n",
      "time/preback_zf (s)                     5.09858\n",
      "time/saving (s)                         0.00745764\n",
      "time/training (s)                       2.33672\n",
      "time/epoch (s)                         17.1842\n",
      "time/total (s)                        964.762\n",
      "Epoch                                  56\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:52:33.067619 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 57 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  68000\n",
      "trainer/ZF1 Loss                      113.854\n",
      "trainer/ZF2 Loss                      109.726\n",
      "trainer/ZF Expert Reward               20.6941\n",
      "trainer/ZF Policy Reward                5.29392\n",
      "trainer/ZF CHI2 Term                  161.725\n",
      "trainer/Policy Loss                 -2024.88\n",
      "trainer/Bias Loss                     360.791\n",
      "trainer/Bias Value                     21.9626\n",
      "trainer/Policy Grad Norm              130.134\n",
      "trainer/Policy Param Norm              30.1383\n",
      "trainer/Zf1 Grad Norm                4544.84\n",
      "trainer/Zf1 Param Norm                 88.1637\n",
      "trainer/Zf2 Grad Norm                5408.2\n",
      "trainer/Zf2 Param Norm                 90.2658\n",
      "trainer/Z Expert Predictions Mean    2593.4\n",
      "trainer/Z Expert Predictions Std      118.796\n",
      "trainer/Z Expert Predictions Max     2746.88\n",
      "trainer/Z Expert Predictions Min     1921.7\n",
      "trainer/Z Policy Predictions Mean    2007.32\n",
      "trainer/Z Policy Predictions Std      743.142\n",
      "trainer/Z Policy Predictions Max     2737.99\n",
      "trainer/Z Policy Predictions Min      227.216\n",
      "trainer/Z Expert Targets Mean        2572.7\n",
      "trainer/Z Expert Targets Std          119.363\n",
      "trainer/Z Expert Targets Max         2735.73\n",
      "trainer/Z Expert Targets Min         1906.56\n",
      "trainer/Z Policy Targets Mean        2002.02\n",
      "trainer/Z Policy Targets Std          734.877\n",
      "trainer/Z Policy Targets Max         2736.46\n",
      "trainer/Z Policy Targets Min          225.268\n",
      "trainer/Log Pis Mean                   34.8835\n",
      "trainer/Log Pis Std                    11.1971\n",
      "trainer/Policy mu Mean                  0.152578\n",
      "trainer/Policy mu Std                   2.0642\n",
      "trainer/Policy log std Mean            -4.03968\n",
      "trainer/Policy log std Std              0.986626\n",
      "exploration/num steps total         63131\n",
      "exploration/num paths total           173\n",
      "evaluation/num steps total         405717\n",
      "evaluation/num paths total            613\n",
      "evaluation/path length Mean           831.2\n",
      "evaluation/path length Std            341.165\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             46\n",
      "evaluation/Rewards Mean                 3.09776\n",
      "evaluation/Rewards Std                  2.5213\n",
      "evaluation/Rewards Max                  7.00464\n",
      "evaluation/Rewards Min                 -3.67318\n",
      "evaluation/Returns Mean              2574.85\n",
      "evaluation/Returns Std               1515.34\n",
      "evaluation/Returns Max               4182.52\n",
      "evaluation/Returns Min                 61.9416\n",
      "evaluation/Estimation Bias Mean      2165.86\n",
      "evaluation/Estimation Bias Std        669.862\n",
      "evaluation/EB/Q_True Mean               5.79612\n",
      "evaluation/EB/Q_True Std               89.8282\n",
      "evaluation/EB/Q_Pred Mean            2171.66\n",
      "evaluation/EB/Q_Pred Std              661.128\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2574.85\n",
      "evaluation/Actions Mean                 0.0378463\n",
      "evaluation/Actions Std                  0.612832\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98718\n",
      "time/backward_zf1 (s)                   2.17921\n",
      "time/backward_zf2 (s)                   2.0916\n",
      "time/data sampling (s)                  0.336186\n",
      "time/data storing (s)                   0.0152862\n",
      "time/evaluation sampling (s)            1.89297\n",
      "time/exploration sampling (s)           0.334321\n",
      "time/logging (s)                        0.0102016\n",
      "time/preback_alpha (s)                  0.612453\n",
      "time/preback_policy (s)                 1.11801\n",
      "time/preback_start (s)                  0.154875\n",
      "time/preback_zf (s)                     5.30555\n",
      "time/saving (s)                         0.00616109\n",
      "time/training (s)                       2.42396\n",
      "time/epoch (s)                         18.468\n",
      "time/total (s)                        983.249\n",
      "Epoch                                  57\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:52:50.405751 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 58 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  69000\n",
      "trainer/ZF1 Loss                      168.215\n",
      "trainer/ZF2 Loss                      273.189\n",
      "trainer/ZF Expert Reward               16.8817\n",
      "trainer/ZF Policy Reward                1.25037\n",
      "trainer/ZF CHI2 Term                  270.064\n",
      "trainer/Policy Loss                 -1997.74\n",
      "trainer/Bias Loss                     712.271\n",
      "trainer/Bias Value                     21.6636\n",
      "trainer/Policy Grad Norm              180.223\n",
      "trainer/Policy Param Norm              30.2297\n",
      "trainer/Zf1 Grad Norm                9664.57\n",
      "trainer/Zf1 Param Norm                 88.4763\n",
      "trainer/Zf2 Grad Norm               18040.6\n",
      "trainer/Zf2 Param Norm                 90.6585\n",
      "trainer/Z Expert Predictions Mean    2586.69\n",
      "trainer/Z Expert Predictions Std      118.3\n",
      "trainer/Z Expert Predictions Max     2765.63\n",
      "trainer/Z Expert Predictions Min     1931.59\n",
      "trainer/Z Policy Predictions Mean    1987.29\n",
      "trainer/Z Policy Predictions Std      765.278\n",
      "trainer/Z Policy Predictions Max     2720.54\n",
      "trainer/Z Policy Predictions Min     -123.594\n",
      "trainer/Z Expert Targets Mean        2569.81\n",
      "trainer/Z Expert Targets Std          122.498\n",
      "trainer/Z Expert Targets Max         2746.93\n",
      "trainer/Z Expert Targets Min         1918.09\n",
      "trainer/Z Policy Targets Mean        1986.04\n",
      "trainer/Z Policy Targets Std          758.203\n",
      "trainer/Z Policy Targets Max         2710.25\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   34.0714\n",
      "trainer/Log Pis Std                    10.7257\n",
      "trainer/Policy mu Mean                  0.179782\n",
      "trainer/Policy mu Std                   2.09538\n",
      "trainer/Policy log std Mean            -3.97616\n",
      "trainer/Policy log std Std              1.07931\n",
      "exploration/num steps total         63131\n",
      "exploration/num paths total           173\n",
      "evaluation/num steps total         415164\n",
      "evaluation/num paths total            623\n",
      "evaluation/path length Mean           944.7\n",
      "evaluation/path length Std            165.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            447\n",
      "evaluation/Rewards Mean                 4.19193\n",
      "evaluation/Rewards Std                  1.78327\n",
      "evaluation/Rewards Max                  6.69494\n",
      "evaluation/Rewards Min                 -3.62507\n",
      "evaluation/Returns Mean              3960.11\n",
      "evaluation/Returns Std                999.672\n",
      "evaluation/Returns Max               4653.4\n",
      "evaluation/Returns Min               1960.32\n",
      "evaluation/Estimation Bias Mean      2398.37\n",
      "evaluation/Estimation Bias Std        423.564\n",
      "evaluation/EB/Q_True Mean              46.0449\n",
      "evaluation/EB/Q_True Std              137.689\n",
      "evaluation/EB/Q_Pred Mean            2444.42\n",
      "evaluation/EB/Q_Pred Std              404.615\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3960.11\n",
      "evaluation/Actions Mean                 0.0526498\n",
      "evaluation/Actions Std                  0.558577\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76619\n",
      "time/backward_zf1 (s)                   1.92727\n",
      "time/backward_zf2 (s)                   1.83357\n",
      "time/data sampling (s)                  0.315707\n",
      "time/data storing (s)                   0.0139677\n",
      "time/evaluation sampling (s)            1.77555\n",
      "time/exploration sampling (s)           0.319479\n",
      "time/logging (s)                        0.0127349\n",
      "time/preback_alpha (s)                  0.578186\n",
      "time/preback_policy (s)                 1.02228\n",
      "time/preback_start (s)                  0.145921\n",
      "time/preback_zf (s)                     5.11401\n",
      "time/saving (s)                         0.00611751\n",
      "time/training (s)                       2.44172\n",
      "time/epoch (s)                         17.2727\n",
      "time/total (s)                       1000.54\n",
      "Epoch                                  58\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:53:07.606825 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 59 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  70000\n",
      "trainer/ZF1 Loss                      160.169\n",
      "trainer/ZF2 Loss                      167.888\n",
      "trainer/ZF Expert Reward               17.2985\n",
      "trainer/ZF Policy Reward                0.230302\n",
      "trainer/ZF CHI2 Term                  214.274\n",
      "trainer/Policy Loss                 -2061.41\n",
      "trainer/Bias Loss                     408.691\n",
      "trainer/Bias Value                     21.3741\n",
      "trainer/Policy Grad Norm              219.79\n",
      "trainer/Policy Param Norm              30.3179\n",
      "trainer/Zf1 Grad Norm               12525.4\n",
      "trainer/Zf1 Param Norm                 88.7479\n",
      "trainer/Zf2 Grad Norm               11947.3\n",
      "trainer/Zf2 Param Norm                 90.9812\n",
      "trainer/Z Expert Predictions Mean    2598.95\n",
      "trainer/Z Expert Predictions Std      100.183\n",
      "trainer/Z Expert Predictions Max     2759.21\n",
      "trainer/Z Expert Predictions Min     2039.98\n",
      "trainer/Z Policy Predictions Mean    2054.88\n",
      "trainer/Z Policy Predictions Std      698.774\n",
      "trainer/Z Policy Predictions Max     2758.47\n",
      "trainer/Z Policy Predictions Min      222.356\n",
      "trainer/Z Expert Targets Mean        2581.65\n",
      "trainer/Z Expert Targets Std           99.8834\n",
      "trainer/Z Expert Targets Max         2773.44\n",
      "trainer/Z Expert Targets Min         2055.34\n",
      "trainer/Z Policy Targets Mean        2054.65\n",
      "trainer/Z Policy Targets Std          692.966\n",
      "trainer/Z Policy Targets Max         2744.22\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   33.5123\n",
      "trainer/Log Pis Std                     9.76523\n",
      "trainer/Policy mu Mean                  0.0579384\n",
      "trainer/Policy mu Std                   1.91445\n",
      "trainer/Policy log std Mean            -4.07679\n",
      "trainer/Policy log std Std              1.02545\n",
      "exploration/num steps total         63131\n",
      "exploration/num paths total           173\n",
      "evaluation/num steps total         423246\n",
      "evaluation/num paths total            633\n",
      "evaluation/path length Mean           808.2\n",
      "evaluation/path length Std            383.613\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             34\n",
      "evaluation/Rewards Mean                 4.33991\n",
      "evaluation/Rewards Std                  1.038\n",
      "evaluation/Rewards Max                  6.75631\n",
      "evaluation/Rewards Min                 -2.32067\n",
      "evaluation/Returns Mean              3507.52\n",
      "evaluation/Returns Std               1724.17\n",
      "evaluation/Returns Max               4434.24\n",
      "evaluation/Returns Min                 57.5733\n",
      "evaluation/Estimation Bias Mean      2488.23\n",
      "evaluation/Estimation Bias Std        199.32\n",
      "evaluation/EB/Q_True Mean              49.2992\n",
      "evaluation/EB/Q_True Std              135.216\n",
      "evaluation/EB/Q_Pred Mean            2537.53\n",
      "evaluation/EB/Q_Pred Std              131.998\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3507.52\n",
      "evaluation/Actions Mean                 0.0369713\n",
      "evaluation/Actions Std                  0.533836\n",
      "evaluation/Actions Max                  0.999768\n",
      "evaluation/Actions Min                 -0.998773\n",
      "time/backward_policy (s)                1.80897\n",
      "time/backward_zf1 (s)                   1.9409\n",
      "time/backward_zf2 (s)                   1.86449\n",
      "time/data sampling (s)                  0.298097\n",
      "time/data storing (s)                   0.0138591\n",
      "time/evaluation sampling (s)            1.80353\n",
      "time/exploration sampling (s)           0.312008\n",
      "time/logging (s)                        0.0103447\n",
      "time/preback_alpha (s)                  0.562628\n",
      "time/preback_policy (s)                 1.07328\n",
      "time/preback_start (s)                  0.143124\n",
      "time/preback_zf (s)                     5.07391\n",
      "time/saving (s)                         0.0070522\n",
      "time/training (s)                       2.21729\n",
      "time/epoch (s)                         17.1295\n",
      "time/total (s)                       1017.69\n",
      "Epoch                                  59\n",
      "---------------------------------  --------------\n",
      "2024-06-10 20:53:24.843524 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 60 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  71000\n",
      "trainer/ZF1 Loss                      123.661\n",
      "trainer/ZF2 Loss                      149.012\n",
      "trainer/ZF Expert Reward               19.0528\n",
      "trainer/ZF Policy Reward                2.39603\n",
      "trainer/ZF CHI2 Term                  186.753\n",
      "trainer/Policy Loss                 -2105.51\n",
      "trainer/Bias Loss                     697.973\n",
      "trainer/Bias Value                     21.0903\n",
      "trainer/Policy Grad Norm              120.461\n",
      "trainer/Policy Param Norm              30.4061\n",
      "trainer/Zf1 Grad Norm                6478.56\n",
      "trainer/Zf1 Param Norm                 89.0408\n",
      "trainer/Zf2 Grad Norm               11957.6\n",
      "trainer/Zf2 Param Norm                 91.3309\n",
      "trainer/Z Expert Predictions Mean    2592.2\n",
      "trainer/Z Expert Predictions Std       99.114\n",
      "trainer/Z Expert Predictions Max     2762.16\n",
      "trainer/Z Expert Predictions Min     2049.44\n",
      "trainer/Z Policy Predictions Mean    2096.27\n",
      "trainer/Z Policy Predictions Std      700.032\n",
      "trainer/Z Policy Predictions Max     2721.07\n",
      "trainer/Z Policy Predictions Min      167.107\n",
      "trainer/Z Expert Targets Mean        2573.15\n",
      "trainer/Z Expert Targets Std           98.7344\n",
      "trainer/Z Expert Targets Max         2708.17\n",
      "trainer/Z Expert Targets Min         2060.93\n",
      "trainer/Z Policy Targets Mean        2093.87\n",
      "trainer/Z Policy Targets Std          692.639\n",
      "trainer/Z Policy Targets Max         2700.52\n",
      "trainer/Z Policy Targets Min          179.419\n",
      "trainer/Log Pis Mean                   34.1011\n",
      "trainer/Log Pis Std                    11.4499\n",
      "trainer/Policy mu Mean                  0.0733019\n",
      "trainer/Policy mu Std                   2.0334\n",
      "trainer/Policy log std Mean            -4.14304\n",
      "trainer/Policy log std Std              0.990667\n",
      "exploration/num steps total         65131\n",
      "exploration/num paths total           175\n",
      "evaluation/num steps total         432025\n",
      "evaluation/num paths total            645\n",
      "evaluation/path length Mean           731.583\n",
      "evaluation/path length Std            402.35\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             13\n",
      "evaluation/Rewards Mean                 4.45215\n",
      "evaluation/Rewards Std                  1.1669\n",
      "evaluation/Rewards Max                  6.63819\n",
      "evaluation/Rewards Min                 -2.19117\n",
      "evaluation/Returns Mean              3257.12\n",
      "evaluation/Returns Std               1861.65\n",
      "evaluation/Returns Max               4638.35\n",
      "evaluation/Returns Min                  5.97445\n",
      "evaluation/Estimation Bias Mean      2493.43\n",
      "evaluation/Estimation Bias Std        217.193\n",
      "evaluation/EB/Q_True Mean              46.7367\n",
      "evaluation/EB/Q_True Std              133.642\n",
      "evaluation/EB/Q_Pred Mean            2540.17\n",
      "evaluation/EB/Q_Pred Std              159.002\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3257.12\n",
      "evaluation/Actions Mean                 0.049572\n",
      "evaluation/Actions Std                  0.550471\n",
      "evaluation/Actions Max                  0.999786\n",
      "evaluation/Actions Min                 -0.999064\n",
      "time/backward_policy (s)                1.7691\n",
      "time/backward_zf1 (s)                   1.89897\n",
      "time/backward_zf2 (s)                   1.82687\n",
      "time/data sampling (s)                  0.284231\n",
      "time/data storing (s)                   0.0138684\n",
      "time/evaluation sampling (s)            1.75898\n",
      "time/exploration sampling (s)           0.329256\n",
      "time/logging (s)                        0.0115565\n",
      "time/preback_alpha (s)                  0.56289\n",
      "time/preback_policy (s)                 1.02846\n",
      "time/preback_start (s)                  0.14395\n",
      "time/preback_zf (s)                     5.10427\n",
      "time/saving (s)                         0.00646243\n",
      "time/training (s)                       2.43215\n",
      "time/epoch (s)                         17.171\n",
      "time/total (s)                       1034.88\n",
      "Epoch                                  60\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:53:41.841278 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 61 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  72000\n",
      "trainer/ZF1 Loss                      136.968\n",
      "trainer/ZF2 Loss                      110.225\n",
      "trainer/ZF Expert Reward               18.5254\n",
      "trainer/ZF Policy Reward               -0.176208\n",
      "trainer/ZF CHI2 Term                  175.905\n",
      "trainer/Policy Loss                 -2090.92\n",
      "trainer/Bias Loss                     461.017\n",
      "trainer/Bias Value                     20.817\n",
      "trainer/Policy Grad Norm              141.681\n",
      "trainer/Policy Param Norm              30.4948\n",
      "trainer/Zf1 Grad Norm                9283.51\n",
      "trainer/Zf1 Param Norm                 89.2799\n",
      "trainer/Zf2 Grad Norm                8839.17\n",
      "trainer/Zf2 Param Norm                 91.6465\n",
      "trainer/Z Expert Predictions Mean    2567.56\n",
      "trainer/Z Expert Predictions Std      197.223\n",
      "trainer/Z Expert Predictions Max     2731.83\n",
      "trainer/Z Expert Predictions Min      -99.6396\n",
      "trainer/Z Policy Predictions Mean    2078.33\n",
      "trainer/Z Policy Predictions Std      684.941\n",
      "trainer/Z Policy Predictions Max     2711.9\n",
      "trainer/Z Policy Predictions Min       37.9218\n",
      "trainer/Z Expert Targets Mean        2549.03\n",
      "trainer/Z Expert Targets Std          193.435\n",
      "trainer/Z Expert Targets Max         2717.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        2078.5\n",
      "trainer/Z Policy Targets Std          678.231\n",
      "trainer/Z Policy Targets Max         2691.45\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   33.9466\n",
      "trainer/Log Pis Std                    11.3945\n",
      "trainer/Policy mu Mean                  0.154434\n",
      "trainer/Policy mu Std                   2.00336\n",
      "trainer/Policy log std Mean            -4.16691\n",
      "trainer/Policy log std Std              1.06996\n",
      "exploration/num steps total         65131\n",
      "exploration/num paths total           175\n",
      "evaluation/num steps total         440791\n",
      "evaluation/num paths total            655\n",
      "evaluation/path length Mean           876.6\n",
      "evaluation/path length Std            253.251\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            256\n",
      "evaluation/Rewards Mean                 4.39695\n",
      "evaluation/Rewards Std                  1.26684\n",
      "evaluation/Rewards Max                  6.90777\n",
      "evaluation/Rewards Min                 -2.64112\n",
      "evaluation/Returns Mean              3854.36\n",
      "evaluation/Returns Std               1207.73\n",
      "evaluation/Returns Max               4695.42\n",
      "evaluation/Returns Min                884.695\n",
      "evaluation/Estimation Bias Mean      2465.27\n",
      "evaluation/Estimation Bias Std        250.093\n",
      "evaluation/EB/Q_True Mean              48.9938\n",
      "evaluation/EB/Q_True Std              139.946\n",
      "evaluation/EB/Q_Pred Mean            2514.26\n",
      "evaluation/EB/Q_Pred Std              189.549\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3854.36\n",
      "evaluation/Actions Mean                 0.0196882\n",
      "evaluation/Actions Std                  0.543295\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.75947\n",
      "time/backward_zf1 (s)                   1.90707\n",
      "time/backward_zf2 (s)                   1.823\n",
      "time/data sampling (s)                  0.279518\n",
      "time/data storing (s)                   0.0138595\n",
      "time/evaluation sampling (s)            1.73594\n",
      "time/exploration sampling (s)           0.314528\n",
      "time/logging (s)                        0.0115024\n",
      "time/preback_alpha (s)                  0.549283\n",
      "time/preback_policy (s)                 1.02498\n",
      "time/preback_start (s)                  0.141839\n",
      "time/preback_zf (s)                     5.04786\n",
      "time/saving (s)                         0.00613034\n",
      "time/training (s)                       2.31906\n",
      "time/epoch (s)                         16.934\n",
      "time/total (s)                       1051.84\n",
      "Epoch                                  61\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:53:59.321018 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 62 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  73000\n",
      "trainer/ZF1 Loss                     1584.91\n",
      "trainer/ZF2 Loss                      837.607\n",
      "trainer/ZF Expert Reward               14.7218\n",
      "trainer/ZF Policy Reward               14.3906\n",
      "trainer/ZF CHI2 Term                 1244.05\n",
      "trainer/Policy Loss                 -2093.87\n",
      "trainer/Bias Loss                    1040.11\n",
      "trainer/Bias Value                     20.5545\n",
      "trainer/Policy Grad Norm              197.715\n",
      "trainer/Policy Param Norm              30.5762\n",
      "trainer/Zf1 Grad Norm               40404\n",
      "trainer/Zf1 Param Norm                 89.5464\n",
      "trainer/Zf2 Grad Norm               31387.4\n",
      "trainer/Zf2 Param Norm                 91.9432\n",
      "trainer/Z Expert Predictions Mean    2566.99\n",
      "trainer/Z Expert Predictions Std      114.658\n",
      "trainer/Z Expert Predictions Max     2718.37\n",
      "trainer/Z Expert Predictions Min     1984.91\n",
      "trainer/Z Policy Predictions Mean    2081.09\n",
      "trainer/Z Policy Predictions Std      665.832\n",
      "trainer/Z Policy Predictions Max     2700.02\n",
      "trainer/Z Policy Predictions Min      227.822\n",
      "trainer/Z Expert Targets Mean        2552.27\n",
      "trainer/Z Expert Targets Std          110.998\n",
      "trainer/Z Expert Targets Max         2717.01\n",
      "trainer/Z Expert Targets Min         1995.5\n",
      "trainer/Z Policy Targets Mean        2066.7\n",
      "trainer/Z Policy Targets Std          672.583\n",
      "trainer/Z Policy Targets Max         2711.72\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   32.7839\n",
      "trainer/Log Pis Std                    10.1791\n",
      "trainer/Policy mu Mean                  0.0982355\n",
      "trainer/Policy mu Std                   1.91222\n",
      "trainer/Policy log std Mean            -4.10954\n",
      "trainer/Policy log std Std              0.955358\n",
      "exploration/num steps total         68188\n",
      "exploration/num paths total           179\n",
      "evaluation/num steps total         449949\n",
      "evaluation/num paths total            665\n",
      "evaluation/path length Mean           915.8\n",
      "evaluation/path length Std            252.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            158\n",
      "evaluation/Rewards Mean                 3.98837\n",
      "evaluation/Rewards Std                  1.95309\n",
      "evaluation/Rewards Max                  6.75709\n",
      "evaluation/Rewards Min                 -3.54445\n",
      "evaluation/Returns Mean              3652.55\n",
      "evaluation/Returns Std               1472.33\n",
      "evaluation/Returns Max               4574.26\n",
      "evaluation/Returns Min                577.994\n",
      "evaluation/Estimation Bias Mean      2351.61\n",
      "evaluation/Estimation Bias Std        504.071\n",
      "evaluation/EB/Q_True Mean              43.5757\n",
      "evaluation/EB/Q_True Std              127.833\n",
      "evaluation/EB/Q_Pred Mean            2395.19\n",
      "evaluation/EB/Q_Pred Std              497.849\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3652.55\n",
      "evaluation/Actions Mean                 0.0114909\n",
      "evaluation/Actions Std                  0.557306\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88482\n",
      "time/backward_zf1 (s)                   2.00711\n",
      "time/backward_zf2 (s)                   1.94497\n",
      "time/data sampling (s)                  0.282821\n",
      "time/data storing (s)                   0.0141916\n",
      "time/evaluation sampling (s)            1.77981\n",
      "time/exploration sampling (s)           0.330937\n",
      "time/logging (s)                        0.0114779\n",
      "time/preback_alpha (s)                  0.563317\n",
      "time/preback_policy (s)                 1.10303\n",
      "time/preback_start (s)                  0.14463\n",
      "time/preback_zf (s)                     5.07322\n",
      "time/saving (s)                         0.00746686\n",
      "time/training (s)                       2.26295\n",
      "time/epoch (s)                         17.4108\n",
      "time/total (s)                       1069.27\n",
      "Epoch                                  62\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:54:17.842785 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 63 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  74000\n",
      "trainer/ZF1 Loss                      117.418\n",
      "trainer/ZF2 Loss                       82.5805\n",
      "trainer/ZF Expert Reward               19.6952\n",
      "trainer/ZF Policy Reward               12.0999\n",
      "trainer/ZF CHI2 Term                  138.264\n",
      "trainer/Policy Loss                 -2129.77\n",
      "trainer/Bias Loss                     383.892\n",
      "trainer/Bias Value                     20.2577\n",
      "trainer/Policy Grad Norm              147.87\n",
      "trainer/Policy Param Norm              30.6611\n",
      "trainer/Zf1 Grad Norm                5215.02\n",
      "trainer/Zf1 Param Norm                 89.7727\n",
      "trainer/Zf2 Grad Norm                3859.64\n",
      "trainer/Zf2 Param Norm                 92.2581\n",
      "trainer/Z Expert Predictions Mean    2559.5\n",
      "trainer/Z Expert Predictions Std      104.308\n",
      "trainer/Z Expert Predictions Max     2746.38\n",
      "trainer/Z Expert Predictions Min     2140.64\n",
      "trainer/Z Policy Predictions Mean    2127.04\n",
      "trainer/Z Policy Predictions Std      618.921\n",
      "trainer/Z Policy Predictions Max     2694.01\n",
      "trainer/Z Policy Predictions Min      222.704\n",
      "trainer/Z Expert Targets Mean        2539.81\n",
      "trainer/Z Expert Targets Std          107.306\n",
      "trainer/Z Expert Targets Max         2717.45\n",
      "trainer/Z Expert Targets Min         2119.55\n",
      "trainer/Z Policy Targets Mean        2114.94\n",
      "trainer/Z Policy Targets Std          612.383\n",
      "trainer/Z Policy Targets Max         2671.9\n",
      "trainer/Z Policy Targets Min          226.453\n",
      "trainer/Log Pis Mean                   30.9791\n",
      "trainer/Log Pis Std                     8.74151\n",
      "trainer/Policy mu Mean                  0.0912\n",
      "trainer/Policy mu Std                   1.6944\n",
      "trainer/Policy log std Mean            -4.04131\n",
      "trainer/Policy log std Std              0.900058\n",
      "exploration/num steps total         71188\n",
      "exploration/num paths total           182\n",
      "evaluation/num steps total         457221\n",
      "evaluation/num paths total            675\n",
      "evaluation/path length Mean           727.2\n",
      "evaluation/path length Std            363.107\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             18\n",
      "evaluation/Rewards Mean                 4.2688\n",
      "evaluation/Rewards Std                  1.3142\n",
      "evaluation/Rewards Max                  6.65113\n",
      "evaluation/Rewards Min                 -3.54594\n",
      "evaluation/Returns Mean              3104.27\n",
      "evaluation/Returns Std               1590.89\n",
      "evaluation/Returns Max               4524.99\n",
      "evaluation/Returns Min                  9.88764\n",
      "evaluation/Estimation Bias Mean      2373.35\n",
      "evaluation/Estimation Bias Std        250.414\n",
      "evaluation/EB/Q_True Mean              53.6389\n",
      "evaluation/EB/Q_True Std              139.269\n",
      "evaluation/EB/Q_Pred Mean            2426.98\n",
      "evaluation/EB/Q_Pred Std              194.737\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3104.27\n",
      "evaluation/Actions Mean                 0.0270554\n",
      "evaluation/Actions Std                  0.541785\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98733\n",
      "time/backward_zf1 (s)                   2.17121\n",
      "time/backward_zf2 (s)                   2.08448\n",
      "time/data sampling (s)                  0.319597\n",
      "time/data storing (s)                   0.0153264\n",
      "time/evaluation sampling (s)            2.03505\n",
      "time/exploration sampling (s)           0.337444\n",
      "time/logging (s)                        0.0101103\n",
      "time/preback_alpha (s)                  0.603918\n",
      "time/preback_policy (s)                 1.18383\n",
      "time/preback_start (s)                  0.152785\n",
      "time/preback_zf (s)                     5.21623\n",
      "time/saving (s)                         0.00667911\n",
      "time/training (s)                       2.32514\n",
      "time/epoch (s)                         18.4491\n",
      "time/total (s)                       1087.74\n",
      "Epoch                                  63\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:54:36.429095 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 64 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  75000\n",
      "trainer/ZF1 Loss                     1196.38\n",
      "trainer/ZF2 Loss                     1214.67\n",
      "trainer/ZF Expert Reward               13.8797\n",
      "trainer/ZF Policy Reward                1.7911\n",
      "trainer/ZF CHI2 Term                 1250.61\n",
      "trainer/Policy Loss                 -2046.93\n",
      "trainer/Bias Loss                     397.577\n",
      "trainer/Bias Value                     19.9639\n",
      "trainer/Policy Grad Norm              187.358\n",
      "trainer/Policy Param Norm              30.7414\n",
      "trainer/Zf1 Grad Norm               25451.4\n",
      "trainer/Zf1 Param Norm                 89.9885\n",
      "trainer/Zf2 Grad Norm               14639.4\n",
      "trainer/Zf2 Param Norm                 92.5306\n",
      "trainer/Z Expert Predictions Mean    2552.51\n",
      "trainer/Z Expert Predictions Std      105.271\n",
      "trainer/Z Expert Predictions Max     2734.44\n",
      "trainer/Z Expert Predictions Min     1864.25\n",
      "trainer/Z Policy Predictions Mean    2035.29\n",
      "trainer/Z Policy Predictions Std      701.563\n",
      "trainer/Z Policy Predictions Max     2659.58\n",
      "trainer/Z Policy Predictions Min       -2.88918\n",
      "trainer/Z Expert Targets Mean        2538.63\n",
      "trainer/Z Expert Targets Std          105.637\n",
      "trainer/Z Expert Targets Max         2699.58\n",
      "trainer/Z Expert Targets Min         1892.51\n",
      "trainer/Z Policy Targets Mean        2033.5\n",
      "trainer/Z Policy Targets Std          700.75\n",
      "trainer/Z Policy Targets Max         2673.98\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   33.3339\n",
      "trainer/Log Pis Std                    11.0226\n",
      "trainer/Policy mu Mean                  0.168031\n",
      "trainer/Policy mu Std                   2.05693\n",
      "trainer/Policy log std Mean            -4.06912\n",
      "trainer/Policy log std Std              1.04846\n",
      "exploration/num steps total         71188\n",
      "exploration/num paths total           182\n",
      "evaluation/num steps total         464912\n",
      "evaluation/num paths total            687\n",
      "evaluation/path length Mean           640.917\n",
      "evaluation/path length Std            353.006\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             35\n",
      "evaluation/Rewards Mean                 4.29899\n",
      "evaluation/Rewards Std                  1.55973\n",
      "evaluation/Rewards Max                  6.87174\n",
      "evaluation/Rewards Min                 -3.54111\n",
      "evaluation/Returns Mean              2755.29\n",
      "evaluation/Returns Std               1658.19\n",
      "evaluation/Returns Max               4691.91\n",
      "evaluation/Returns Min                 16.4536\n",
      "evaluation/Estimation Bias Mean      2388.31\n",
      "evaluation/Estimation Bias Std        298.253\n",
      "evaluation/EB/Q_True Mean              54.7367\n",
      "evaluation/EB/Q_True Std              145.849\n",
      "evaluation/EB/Q_Pred Mean            2443.04\n",
      "evaluation/EB/Q_Pred Std              238.97\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2755.29\n",
      "evaluation/Actions Mean                 0.0362131\n",
      "evaluation/Actions Std                  0.54887\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.0575\n",
      "time/backward_zf1 (s)                   2.19799\n",
      "time/backward_zf2 (s)                   2.11219\n",
      "time/data sampling (s)                  0.318329\n",
      "time/data storing (s)                   0.0165002\n",
      "time/evaluation sampling (s)            1.83387\n",
      "time/exploration sampling (s)           0.350097\n",
      "time/logging (s)                        0.00997296\n",
      "time/preback_alpha (s)                  0.613789\n",
      "time/preback_policy (s)                 1.19889\n",
      "time/preback_start (s)                  0.156586\n",
      "time/preback_zf (s)                     5.30615\n",
      "time/saving (s)                         0.00628576\n",
      "time/training (s)                       2.33512\n",
      "time/epoch (s)                         18.5133\n",
      "time/total (s)                       1106.27\n",
      "Epoch                                  64\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:54:54.821620 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 65 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  76000\n",
      "trainer/ZF1 Loss                      122.373\n",
      "trainer/ZF2 Loss                      101.723\n",
      "trainer/ZF Expert Reward               20.3696\n",
      "trainer/ZF Policy Reward                9.28444\n",
      "trainer/ZF CHI2 Term                  154.99\n",
      "trainer/Policy Loss                 -2109.73\n",
      "trainer/Bias Loss                     304.637\n",
      "trainer/Bias Value                     19.6786\n",
      "trainer/Policy Grad Norm              131.958\n",
      "trainer/Policy Param Norm              30.8283\n",
      "trainer/Zf1 Grad Norm                4456.52\n",
      "trainer/Zf1 Param Norm                 90.2379\n",
      "trainer/Zf2 Grad Norm                4781.38\n",
      "trainer/Zf2 Param Norm                 92.8427\n",
      "trainer/Z Expert Predictions Mean    2542.35\n",
      "trainer/Z Expert Predictions Std      104.747\n",
      "trainer/Z Expert Predictions Max     2702.52\n",
      "trainer/Z Expert Predictions Min     1905.89\n",
      "trainer/Z Policy Predictions Mean    2105.69\n",
      "trainer/Z Policy Predictions Std      620.809\n",
      "trainer/Z Policy Predictions Max     2666.9\n",
      "trainer/Z Policy Predictions Min      240.661\n",
      "trainer/Z Expert Targets Mean        2521.98\n",
      "trainer/Z Expert Targets Std          105.513\n",
      "trainer/Z Expert Targets Max         2673.98\n",
      "trainer/Z Expert Targets Min         1856.86\n",
      "trainer/Z Policy Targets Mean        2096.4\n",
      "trainer/Z Policy Targets Std          607.126\n",
      "trainer/Z Policy Targets Max         2668.77\n",
      "trainer/Z Policy Targets Min          229.552\n",
      "trainer/Log Pis Mean                   32.1783\n",
      "trainer/Log Pis Std                     9.78766\n",
      "trainer/Policy mu Mean                  0.128881\n",
      "trainer/Policy mu Std                   1.8275\n",
      "trainer/Policy log std Mean            -4.13958\n",
      "trainer/Policy log std Std              0.985955\n",
      "exploration/num steps total         72474\n",
      "exploration/num paths total           184\n",
      "evaluation/num steps total         474912\n",
      "evaluation/num paths total            697\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.79913\n",
      "evaluation/Rewards Std                  2.37073\n",
      "evaluation/Rewards Max                  6.61168\n",
      "evaluation/Rewards Min                 -3.91758\n",
      "evaluation/Returns Mean              3799.13\n",
      "evaluation/Returns Std               2149.35\n",
      "evaluation/Returns Max               4680.96\n",
      "evaluation/Returns Min              -2645.46\n",
      "evaluation/Estimation Bias Mean      2294.62\n",
      "evaluation/Estimation Bias Std        711.65\n",
      "evaluation/EB/Q_True Mean              41.509\n",
      "evaluation/EB/Q_True Std              128.288\n",
      "evaluation/EB/Q_Pred Mean            2336.13\n",
      "evaluation/EB/Q_Pred Std              588.773\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3799.13\n",
      "evaluation/Actions Mean                 0.0281145\n",
      "evaluation/Actions Std                  0.60306\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9491\n",
      "time/backward_zf1 (s)                   2.13559\n",
      "time/backward_zf2 (s)                   2.03366\n",
      "time/data sampling (s)                  0.321034\n",
      "time/data storing (s)                   0.0144837\n",
      "time/evaluation sampling (s)            1.84136\n",
      "time/exploration sampling (s)           0.334387\n",
      "time/logging (s)                        0.0127056\n",
      "time/preback_alpha (s)                  0.613645\n",
      "time/preback_policy (s)                 1.14584\n",
      "time/preback_start (s)                  0.155308\n",
      "time/preback_zf (s)                     5.27763\n",
      "time/saving (s)                         0.00715433\n",
      "time/training (s)                       2.48465\n",
      "time/epoch (s)                         18.3266\n",
      "time/total (s)                       1124.62\n",
      "Epoch                                  65\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:55:13.116164 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 66 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  77000\n",
      "trainer/ZF1 Loss                      169.581\n",
      "trainer/ZF2 Loss                      123.088\n",
      "trainer/ZF Expert Reward               27.2449\n",
      "trainer/ZF Policy Reward               11.3164\n",
      "trainer/ZF CHI2 Term                  195.342\n",
      "trainer/Policy Loss                 -2073.75\n",
      "trainer/Bias Loss                     617.021\n",
      "trainer/Bias Value                     19.4067\n",
      "trainer/Policy Grad Norm              235.116\n",
      "trainer/Policy Param Norm              30.907\n",
      "trainer/Zf1 Grad Norm                8031.36\n",
      "trainer/Zf1 Param Norm                 90.4847\n",
      "trainer/Zf2 Grad Norm               11413.6\n",
      "trainer/Zf2 Param Norm                 93.1329\n",
      "trainer/Z Expert Predictions Mean    2516.03\n",
      "trainer/Z Expert Predictions Std      116.978\n",
      "trainer/Z Expert Predictions Max     2696.08\n",
      "trainer/Z Expert Predictions Min     1929.74\n",
      "trainer/Z Policy Predictions Mean    2065.12\n",
      "trainer/Z Policy Predictions Std      650.645\n",
      "trainer/Z Policy Predictions Max     2677.63\n",
      "trainer/Z Policy Predictions Min      134.897\n",
      "trainer/Z Expert Targets Mean        2488.79\n",
      "trainer/Z Expert Targets Std          118.025\n",
      "trainer/Z Expert Targets Max         2650.82\n",
      "trainer/Z Expert Targets Min         1868.83\n",
      "trainer/Z Policy Targets Mean        2053.81\n",
      "trainer/Z Policy Targets Std          636.35\n",
      "trainer/Z Policy Targets Max         2664.11\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   33.4129\n",
      "trainer/Log Pis Std                     9.79338\n",
      "trainer/Policy mu Mean                  0.104424\n",
      "trainer/Policy mu Std                   1.90046\n",
      "trainer/Policy log std Mean            -4.16698\n",
      "trainer/Policy log std Std              0.963186\n",
      "exploration/num steps total         72474\n",
      "exploration/num paths total           184\n",
      "evaluation/num steps total         483766\n",
      "evaluation/num paths total            707\n",
      "evaluation/path length Mean           885.4\n",
      "evaluation/path length Std            178.078\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            500\n",
      "evaluation/Rewards Mean                 4.16208\n",
      "evaluation/Rewards Std                  1.31943\n",
      "evaluation/Rewards Max                  6.97803\n",
      "evaluation/Rewards Min                 -2.80719\n",
      "evaluation/Returns Mean              3685.11\n",
      "evaluation/Returns Std                742.185\n",
      "evaluation/Returns Max               4381.94\n",
      "evaluation/Returns Min               2034.14\n",
      "evaluation/Estimation Bias Mean      2336.39\n",
      "evaluation/Estimation Bias Std        215.344\n",
      "evaluation/EB/Q_True Mean              41.7694\n",
      "evaluation/EB/Q_True Std              120.738\n",
      "evaluation/EB/Q_Pred Mean            2378.16\n",
      "evaluation/EB/Q_Pred Std              178.514\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3685.11\n",
      "evaluation/Actions Mean                 0.0210753\n",
      "evaluation/Actions Std                  0.554073\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.94157\n",
      "time/backward_zf1 (s)                   2.11878\n",
      "time/backward_zf2 (s)                   2.0332\n",
      "time/data sampling (s)                  0.335182\n",
      "time/data storing (s)                   0.0149217\n",
      "time/evaluation sampling (s)            1.82371\n",
      "time/exploration sampling (s)           0.332835\n",
      "time/logging (s)                        0.0110744\n",
      "time/preback_alpha (s)                  0.603276\n",
      "time/preback_policy (s)                 1.10625\n",
      "time/preback_start (s)                  0.15321\n",
      "time/preback_zf (s)                     5.27152\n",
      "time/saving (s)                         0.00702422\n",
      "time/training (s)                       2.46809\n",
      "time/epoch (s)                         18.2206\n",
      "time/total (s)                       1142.86\n",
      "Epoch                                  66\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:55:31.179116 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 67 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  78000\n",
      "trainer/ZF1 Loss                       99.7696\n",
      "trainer/ZF2 Loss                      123.002\n",
      "trainer/ZF Expert Reward               17.5368\n",
      "trainer/ZF Policy Reward               -1.6797\n",
      "trainer/ZF CHI2 Term                  162.282\n",
      "trainer/Policy Loss                 -2049.64\n",
      "trainer/Bias Loss                     769.723\n",
      "trainer/Bias Value                     19.1186\n",
      "trainer/Policy Grad Norm              192.634\n",
      "trainer/Policy Param Norm              30.9777\n",
      "trainer/Zf1 Grad Norm                4135.5\n",
      "trainer/Zf1 Param Norm                 90.6827\n",
      "trainer/Zf2 Grad Norm                6378.18\n",
      "trainer/Zf2 Param Norm                 93.4446\n",
      "trainer/Z Expert Predictions Mean    2494.91\n",
      "trainer/Z Expert Predictions Std      109.657\n",
      "trainer/Z Expert Predictions Max     2618.5\n",
      "trainer/Z Expert Predictions Min     1953.95\n",
      "trainer/Z Policy Predictions Mean    2038.07\n",
      "trainer/Z Policy Predictions Std      657.37\n",
      "trainer/Z Policy Predictions Max     2642.73\n",
      "trainer/Z Policy Predictions Min      198.443\n",
      "trainer/Z Expert Targets Mean        2477.37\n",
      "trainer/Z Expert Targets Std          116.322\n",
      "trainer/Z Expert Targets Max         2653.85\n",
      "trainer/Z Expert Targets Min         1873.6\n",
      "trainer/Z Policy Targets Mean        2039.75\n",
      "trainer/Z Policy Targets Std          648.996\n",
      "trainer/Z Policy Targets Max         2615.88\n",
      "trainer/Z Policy Targets Min          197.519\n",
      "trainer/Log Pis Mean                   31.9999\n",
      "trainer/Log Pis Std                    10.0816\n",
      "trainer/Policy mu Mean                  0.100126\n",
      "trainer/Policy mu Std                   1.89087\n",
      "trainer/Policy log std Mean            -4.00316\n",
      "trainer/Policy log std Std              1.00809\n",
      "exploration/num steps total         73474\n",
      "exploration/num paths total           185\n",
      "evaluation/num steps total         493454\n",
      "evaluation/num paths total            717\n",
      "evaluation/path length Mean           968.8\n",
      "evaluation/path length Std             93.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            688\n",
      "evaluation/Rewards Mean                 4.23253\n",
      "evaluation/Rewards Std                  1.06427\n",
      "evaluation/Rewards Max                  6.37861\n",
      "evaluation/Rewards Min                 -2.16372\n",
      "evaluation/Returns Mean              4100.47\n",
      "evaluation/Returns Std                481.127\n",
      "evaluation/Returns Max               4365.6\n",
      "evaluation/Returns Min               2669.74\n",
      "evaluation/Estimation Bias Mean      2405.63\n",
      "evaluation/Estimation Bias Std        195.665\n",
      "evaluation/EB/Q_True Mean              41.0469\n",
      "evaluation/EB/Q_True Std              124.278\n",
      "evaluation/EB/Q_Pred Mean            2446.67\n",
      "evaluation/EB/Q_Pred Std              138.639\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4100.47\n",
      "evaluation/Actions Mean                 0.0270827\n",
      "evaluation/Actions Std                  0.52825\n",
      "evaluation/Actions Max                  0.999835\n",
      "evaluation/Actions Min                 -0.999926\n",
      "time/backward_policy (s)                1.95076\n",
      "time/backward_zf1 (s)                   2.11546\n",
      "time/backward_zf2 (s)                   2.03429\n",
      "time/data sampling (s)                  0.32864\n",
      "time/data storing (s)                   0.0157531\n",
      "time/evaluation sampling (s)            1.7808\n",
      "time/exploration sampling (s)           0.334036\n",
      "time/logging (s)                        0.0120394\n",
      "time/preback_alpha (s)                  0.597576\n",
      "time/preback_policy (s)                 1.17839\n",
      "time/preback_start (s)                  0.155383\n",
      "time/preback_zf (s)                     5.18782\n",
      "time/saving (s)                         0.00667278\n",
      "time/training (s)                       2.28295\n",
      "time/epoch (s)                         17.9806\n",
      "time/total (s)                       1160.88\n",
      "Epoch                                  67\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:55:49.634383 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 68 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  79000\n",
      "trainer/ZF1 Loss                       84.3884\n",
      "trainer/ZF2 Loss                       89.0239\n",
      "trainer/ZF Expert Reward               13.4336\n",
      "trainer/ZF Policy Reward                5.37272\n",
      "trainer/ZF CHI2 Term                  127.068\n",
      "trainer/Policy Loss                 -2048.42\n",
      "trainer/Bias Loss                     349.52\n",
      "trainer/Bias Value                     18.8647\n",
      "trainer/Policy Grad Norm              172.748\n",
      "trainer/Policy Param Norm              31.0507\n",
      "trainer/Zf1 Grad Norm                5717.7\n",
      "trainer/Zf1 Param Norm                 90.9034\n",
      "trainer/Zf2 Grad Norm                5359.13\n",
      "trainer/Zf2 Param Norm                 93.706\n",
      "trainer/Z Expert Predictions Mean    2473.24\n",
      "trainer/Z Expert Predictions Std      104.584\n",
      "trainer/Z Expert Predictions Max     2617.13\n",
      "trainer/Z Expert Predictions Min     1933.29\n",
      "trainer/Z Policy Predictions Mean    2041.11\n",
      "trainer/Z Policy Predictions Std      645.52\n",
      "trainer/Z Policy Predictions Max     2596.94\n",
      "trainer/Z Policy Predictions Min      170.827\n",
      "trainer/Z Expert Targets Mean        2459.8\n",
      "trainer/Z Expert Targets Std          107.776\n",
      "trainer/Z Expert Targets Max         2621.42\n",
      "trainer/Z Expert Targets Min         1893.29\n",
      "trainer/Z Policy Targets Mean        2035.73\n",
      "trainer/Z Policy Targets Std          640.37\n",
      "trainer/Z Policy Targets Max         2585.88\n",
      "trainer/Z Policy Targets Min          168.298\n",
      "trainer/Log Pis Mean                   32.6277\n",
      "trainer/Log Pis Std                     9.25393\n",
      "trainer/Policy mu Mean                  0.00507726\n",
      "trainer/Policy mu Std                   1.89642\n",
      "trainer/Policy log std Mean            -4.05157\n",
      "trainer/Policy log std Std              1.01425\n",
      "exploration/num steps total         73474\n",
      "exploration/num paths total           185\n",
      "evaluation/num steps total         502588\n",
      "evaluation/num paths total            727\n",
      "evaluation/path length Mean           913.4\n",
      "evaluation/path length Std            243.276\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            185\n",
      "evaluation/Rewards Mean                 4.53081\n",
      "evaluation/Rewards Std                  1.04177\n",
      "evaluation/Rewards Max                  6.6699\n",
      "evaluation/Rewards Min                 -2.44319\n",
      "evaluation/Returns Mean              4138.45\n",
      "evaluation/Returns Std               1180.15\n",
      "evaluation/Returns Max               4715.55\n",
      "evaluation/Returns Min                619.035\n",
      "evaluation/Estimation Bias Mean      2421.43\n",
      "evaluation/Estimation Bias Std        199.038\n",
      "evaluation/EB/Q_True Mean              46.5821\n",
      "evaluation/EB/Q_True Std              136.73\n",
      "evaluation/EB/Q_Pred Mean            2468.01\n",
      "evaluation/EB/Q_Pred Std              126.229\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4138.45\n",
      "evaluation/Actions Mean                 0.0230183\n",
      "evaluation/Actions Std                  0.553112\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999709\n",
      "time/backward_policy (s)                2.04158\n",
      "time/backward_zf1 (s)                   2.19992\n",
      "time/backward_zf2 (s)                   2.13577\n",
      "time/data sampling (s)                  0.322376\n",
      "time/data storing (s)                   0.0158511\n",
      "time/evaluation sampling (s)            1.79756\n",
      "time/exploration sampling (s)           0.351726\n",
      "time/logging (s)                        0.0127864\n",
      "time/preback_alpha (s)                  0.603209\n",
      "time/preback_policy (s)                 1.19666\n",
      "time/preback_start (s)                  0.153562\n",
      "time/preback_zf (s)                     5.24075\n",
      "time/saving (s)                         0.0068472\n",
      "time/training (s)                       2.29097\n",
      "time/epoch (s)                         18.3696\n",
      "time/total (s)                       1179.28\n",
      "Epoch                                  68\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:56:08.106964 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 69 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  80000\n",
      "trainer/ZF1 Loss                      145.288\n",
      "trainer/ZF2 Loss                       80.2882\n",
      "trainer/ZF Expert Reward               20.9441\n",
      "trainer/ZF Policy Reward                3.83554\n",
      "trainer/ZF CHI2 Term                  163.078\n",
      "trainer/Policy Loss                 -2061.52\n",
      "trainer/Bias Loss                     584.608\n",
      "trainer/Bias Value                     18.5816\n",
      "trainer/Policy Grad Norm              143.169\n",
      "trainer/Policy Param Norm              31.1301\n",
      "trainer/Zf1 Grad Norm               18451.1\n",
      "trainer/Zf1 Param Norm                 91.0909\n",
      "trainer/Zf2 Grad Norm                6479.88\n",
      "trainer/Zf2 Param Norm                 93.9652\n",
      "trainer/Z Expert Predictions Mean    2457.86\n",
      "trainer/Z Expert Predictions Std      169.51\n",
      "trainer/Z Expert Predictions Max     2636.43\n",
      "trainer/Z Expert Predictions Min      324.014\n",
      "trainer/Z Policy Predictions Mean    2052.23\n",
      "trainer/Z Policy Predictions Std      660.3\n",
      "trainer/Z Policy Predictions Max     2611.49\n",
      "trainer/Z Policy Predictions Min      -54.7098\n",
      "trainer/Z Expert Targets Mean        2436.92\n",
      "trainer/Z Expert Targets Std          189.992\n",
      "trainer/Z Expert Targets Max         2644.72\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        2048.39\n",
      "trainer/Z Policy Targets Std          652.485\n",
      "trainer/Z Policy Targets Max         2597.29\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   33.5166\n",
      "trainer/Log Pis Std                    10.6102\n",
      "trainer/Policy mu Mean                  0.152994\n",
      "trainer/Policy mu Std                   1.87966\n",
      "trainer/Policy log std Mean            -4.20249\n",
      "trainer/Policy log std Std              0.923017\n",
      "exploration/num steps total         73474\n",
      "exploration/num paths total           185\n",
      "evaluation/num steps total         510065\n",
      "evaluation/num paths total            737\n",
      "evaluation/path length Mean           747.7\n",
      "evaluation/path length Std            385.516\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            146\n",
      "evaluation/Rewards Mean                 3.77787\n",
      "evaluation/Rewards Std                  2.5159\n",
      "evaluation/Rewards Max                  6.903\n",
      "evaluation/Rewards Min                 -3.48164\n",
      "evaluation/Returns Mean              2824.72\n",
      "evaluation/Returns Std               2416.35\n",
      "evaluation/Returns Max               4867.35\n",
      "evaluation/Returns Min              -1911.8\n",
      "evaluation/Estimation Bias Mean      2119.94\n",
      "evaluation/Estimation Bias Std        679.784\n",
      "evaluation/EB/Q_True Mean              55.1872\n",
      "evaluation/EB/Q_True Std              144.003\n",
      "evaluation/EB/Q_Pred Mean            2175.12\n",
      "evaluation/EB/Q_Pred Std              682.025\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2824.72\n",
      "evaluation/Actions Mean                 0.0658889\n",
      "evaluation/Actions Std                  0.588426\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.02375\n",
      "time/backward_zf1 (s)                   2.19776\n",
      "time/backward_zf2 (s)                   2.10353\n",
      "time/data sampling (s)                  0.33178\n",
      "time/data storing (s)                   0.0150545\n",
      "time/evaluation sampling (s)            1.78741\n",
      "time/exploration sampling (s)           0.325329\n",
      "time/logging (s)                        0.0096234\n",
      "time/preback_alpha (s)                  0.621705\n",
      "time/preback_policy (s)                 1.19748\n",
      "time/preback_start (s)                  0.157457\n",
      "time/preback_zf (s)                     5.26952\n",
      "time/saving (s)                         0.00611299\n",
      "time/training (s)                       2.34998\n",
      "time/epoch (s)                         18.3965\n",
      "time/total (s)                       1197.7\n",
      "Epoch                                  69\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:56:26.867191 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 70 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  81000\n",
      "trainer/ZF1 Loss                       75.3539\n",
      "trainer/ZF2 Loss                       78.728\n",
      "trainer/ZF Expert Reward               19.6997\n",
      "trainer/ZF Policy Reward                9.16815\n",
      "trainer/ZF CHI2 Term                  119.374\n",
      "trainer/Policy Loss                 -2073.4\n",
      "trainer/Bias Loss                     303.299\n",
      "trainer/Bias Value                     18.3119\n",
      "trainer/Policy Grad Norm              159.74\n",
      "trainer/Policy Param Norm              31.2021\n",
      "trainer/Zf1 Grad Norm                4635.95\n",
      "trainer/Zf1 Param Norm                 91.2784\n",
      "trainer/Zf2 Grad Norm                5399.34\n",
      "trainer/Zf2 Param Norm                 94.2161\n",
      "trainer/Z Expert Predictions Mean    2446.67\n",
      "trainer/Z Expert Predictions Std      107.96\n",
      "trainer/Z Expert Predictions Max     2615.46\n",
      "trainer/Z Expert Predictions Min     1863.73\n",
      "trainer/Z Policy Predictions Mean    2065.68\n",
      "trainer/Z Policy Predictions Std      626.247\n",
      "trainer/Z Policy Predictions Max     2584.84\n",
      "trainer/Z Policy Predictions Min      126.135\n",
      "trainer/Z Expert Targets Mean        2426.97\n",
      "trainer/Z Expert Targets Std          109.993\n",
      "trainer/Z Expert Targets Max         2613.15\n",
      "trainer/Z Expert Targets Min         1804.78\n",
      "trainer/Z Policy Targets Mean        2056.51\n",
      "trainer/Z Policy Targets Std          617.648\n",
      "trainer/Z Policy Targets Max         2553.75\n",
      "trainer/Z Policy Targets Min          137.935\n",
      "trainer/Log Pis Mean                   32.1223\n",
      "trainer/Log Pis Std                    10.1737\n",
      "trainer/Policy mu Mean                  0.132482\n",
      "trainer/Policy mu Std                   1.83123\n",
      "trainer/Policy log std Mean            -4.16176\n",
      "trainer/Policy log std Std              0.907863\n",
      "exploration/num steps total         75749\n",
      "exploration/num paths total           188\n",
      "evaluation/num steps total         518547\n",
      "evaluation/num paths total            747\n",
      "evaluation/path length Mean           848.2\n",
      "evaluation/path length Std            255.078\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            223\n",
      "evaluation/Rewards Mean                 4.37225\n",
      "evaluation/Rewards Std                  1.40181\n",
      "evaluation/Rewards Max                  6.75333\n",
      "evaluation/Rewards Min                 -2.95783\n",
      "evaluation/Returns Mean              3708.54\n",
      "evaluation/Returns Std               1196.24\n",
      "evaluation/Returns Max               4713.23\n",
      "evaluation/Returns Min                922.281\n",
      "evaluation/Estimation Bias Mean      2300.75\n",
      "evaluation/Estimation Bias Std        295.493\n",
      "evaluation/EB/Q_True Mean              49.4037\n",
      "evaluation/EB/Q_True Std              139.743\n",
      "evaluation/EB/Q_Pred Mean            2350.15\n",
      "evaluation/EB/Q_Pred Std              255.28\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3708.54\n",
      "evaluation/Actions Mean                 0.0376201\n",
      "evaluation/Actions Std                  0.553138\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.10254\n",
      "time/backward_zf1 (s)                   2.297\n",
      "time/backward_zf2 (s)                   2.18205\n",
      "time/data sampling (s)                  0.333539\n",
      "time/data storing (s)                   0.014857\n",
      "time/evaluation sampling (s)            1.88686\n",
      "time/exploration sampling (s)           0.347072\n",
      "time/logging (s)                        0.0113227\n",
      "time/preback_alpha (s)                  0.614783\n",
      "time/preback_policy (s)                 1.23953\n",
      "time/preback_start (s)                  0.155955\n",
      "time/preback_zf (s)                     5.231\n",
      "time/saving (s)                         0.00634362\n",
      "time/training (s)                       2.26724\n",
      "time/epoch (s)                         18.6901\n",
      "time/total (s)                       1216.41\n",
      "Epoch                                  70\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:56:45.178745 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 71 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  82000\n",
      "trainer/ZF1 Loss                     1259.21\n",
      "trainer/ZF2 Loss                     1225.61\n",
      "trainer/ZF Expert Reward               18.8064\n",
      "trainer/ZF Policy Reward               11.987\n",
      "trainer/ZF CHI2 Term                 1281.45\n",
      "trainer/Policy Loss                 -2026.83\n",
      "trainer/Bias Loss                     339.349\n",
      "trainer/Bias Value                     18.0283\n",
      "trainer/Policy Grad Norm              105.159\n",
      "trainer/Policy Param Norm              31.2758\n",
      "trainer/Zf1 Grad Norm                4211.16\n",
      "trainer/Zf1 Param Norm                 91.4467\n",
      "trainer/Zf2 Grad Norm                7922.13\n",
      "trainer/Zf2 Param Norm                 94.4226\n",
      "trainer/Z Expert Predictions Mean    2426.72\n",
      "trainer/Z Expert Predictions Std       97.1953\n",
      "trainer/Z Expert Predictions Max     2570.06\n",
      "trainer/Z Expert Predictions Min     1778.82\n",
      "trainer/Z Policy Predictions Mean    2014.86\n",
      "trainer/Z Policy Predictions Std      643.966\n",
      "trainer/Z Policy Predictions Max     2573.54\n",
      "trainer/Z Policy Predictions Min      -92.4769\n",
      "trainer/Z Expert Targets Mean        2407.91\n",
      "trainer/Z Expert Targets Std           97.9055\n",
      "trainer/Z Expert Targets Max         2584.02\n",
      "trainer/Z Expert Targets Min         1817.74\n",
      "trainer/Z Policy Targets Mean        2002.87\n",
      "trainer/Z Policy Targets Std          646.299\n",
      "trainer/Z Policy Targets Max         2546.84\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   32.5491\n",
      "trainer/Log Pis Std                     8.95868\n",
      "trainer/Policy mu Mean                  0.167365\n",
      "trainer/Policy mu Std                   1.82773\n",
      "trainer/Policy log std Mean            -4.09911\n",
      "trainer/Policy log std Std              0.994387\n",
      "exploration/num steps total         76601\n",
      "exploration/num paths total           189\n",
      "evaluation/num steps total         527689\n",
      "evaluation/num paths total            757\n",
      "evaluation/path length Mean           914.2\n",
      "evaluation/path length Std            257.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            142\n",
      "evaluation/Rewards Mean                 2.9786\n",
      "evaluation/Rewards Std                  2.75106\n",
      "evaluation/Rewards Max                  6.37202\n",
      "evaluation/Rewards Min                 -4.39048\n",
      "evaluation/Returns Mean              2723.03\n",
      "evaluation/Returns Std               2597.39\n",
      "evaluation/Returns Max               4509.71\n",
      "evaluation/Returns Min              -1948.98\n",
      "evaluation/Estimation Bias Mean      1943.46\n",
      "evaluation/Estimation Bias Std        862.074\n",
      "evaluation/EB/Q_True Mean              45.1949\n",
      "evaluation/EB/Q_True Std              132.321\n",
      "evaluation/EB/Q_Pred Mean            1988.66\n",
      "evaluation/EB/Q_Pred Std              787.22\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2723.03\n",
      "evaluation/Actions Mean                 0.0726728\n",
      "evaluation/Actions Std                  0.615684\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99672\n",
      "time/backward_zf1 (s)                   2.18038\n",
      "time/backward_zf2 (s)                   2.09526\n",
      "time/data sampling (s)                  0.332121\n",
      "time/data storing (s)                   0.0147903\n",
      "time/evaluation sampling (s)            1.80706\n",
      "time/exploration sampling (s)           0.328965\n",
      "time/logging (s)                        0.0113681\n",
      "time/preback_alpha (s)                  0.606093\n",
      "time/preback_policy (s)                 1.18395\n",
      "time/preback_start (s)                  0.154149\n",
      "time/preback_zf (s)                     5.22668\n",
      "time/saving (s)                         0.00631329\n",
      "time/training (s)                       2.29366\n",
      "time/epoch (s)                         18.2375\n",
      "time/total (s)                       1234.67\n",
      "Epoch                                  71\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:57:03.095707 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 72 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  83000\n",
      "trainer/ZF1 Loss                      108.965\n",
      "trainer/ZF2 Loss                       97.3697\n",
      "trainer/ZF Expert Reward               16.6421\n",
      "trainer/ZF Policy Reward                2.80085\n",
      "trainer/ZF CHI2 Term                  150.12\n",
      "trainer/Policy Loss                 -2002.76\n",
      "trainer/Bias Loss                     286.556\n",
      "trainer/Bias Value                     17.7535\n",
      "trainer/Policy Grad Norm              145.739\n",
      "trainer/Policy Param Norm              31.3482\n",
      "trainer/Zf1 Grad Norm                4825.68\n",
      "trainer/Zf1 Param Norm                 91.6317\n",
      "trainer/Zf2 Grad Norm                4000.51\n",
      "trainer/Zf2 Param Norm                 94.6527\n",
      "trainer/Z Expert Predictions Mean    2403.7\n",
      "trainer/Z Expert Predictions Std       99.9876\n",
      "trainer/Z Expert Predictions Max     2567.38\n",
      "trainer/Z Expert Predictions Min     1937.04\n",
      "trainer/Z Policy Predictions Mean    1993.59\n",
      "trainer/Z Policy Predictions Std      624.142\n",
      "trainer/Z Policy Predictions Max     2508.06\n",
      "trainer/Z Policy Predictions Min       94.4761\n",
      "trainer/Z Expert Targets Mean        2387.06\n",
      "trainer/Z Expert Targets Std          103.803\n",
      "trainer/Z Expert Targets Max         2564.81\n",
      "trainer/Z Expert Targets Min         1913.03\n",
      "trainer/Z Policy Targets Mean        1990.79\n",
      "trainer/Z Policy Targets Std          614.563\n",
      "trainer/Z Policy Targets Max         2499.86\n",
      "trainer/Z Policy Targets Min           99.8704\n",
      "trainer/Log Pis Mean                   33.446\n",
      "trainer/Log Pis Std                     9.31884\n",
      "trainer/Policy mu Mean                  0.131318\n",
      "trainer/Policy mu Std                   1.85357\n",
      "trainer/Policy log std Mean            -4.20871\n",
      "trainer/Policy log std Std              0.905762\n",
      "exploration/num steps total         77792\n",
      "exploration/num paths total           191\n",
      "evaluation/num steps total         536719\n",
      "evaluation/num paths total            767\n",
      "evaluation/path length Mean           903\n",
      "evaluation/path length Std            291\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             30\n",
      "evaluation/Rewards Mean                 4.43343\n",
      "evaluation/Rewards Std                  1.10213\n",
      "evaluation/Rewards Max                  6.46638\n",
      "evaluation/Rewards Min                 -2.44935\n",
      "evaluation/Returns Mean              4003.39\n",
      "evaluation/Returns Std               1337.69\n",
      "evaluation/Returns Max               4597.63\n",
      "evaluation/Returns Min                  2.33203\n",
      "evaluation/Estimation Bias Mean      2321.38\n",
      "evaluation/Estimation Bias Std        185.68\n",
      "evaluation/EB/Q_True Mean              45.7342\n",
      "evaluation/EB/Q_True Std              133.413\n",
      "evaluation/EB/Q_Pred Mean            2367.11\n",
      "evaluation/EB/Q_Pred Std              121.087\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4003.39\n",
      "evaluation/Actions Mean                 0.02426\n",
      "evaluation/Actions Std                  0.538035\n",
      "evaluation/Actions Max                  0.999967\n",
      "evaluation/Actions Min                 -0.999961\n",
      "time/backward_policy (s)                1.90968\n",
      "time/backward_zf1 (s)                   2.03952\n",
      "time/backward_zf2 (s)                   1.96684\n",
      "time/data sampling (s)                  0.328402\n",
      "time/data storing (s)                   0.0155048\n",
      "time/evaluation sampling (s)            1.80678\n",
      "time/exploration sampling (s)           0.338968\n",
      "time/logging (s)                        0.0114726\n",
      "time/preback_alpha (s)                  0.60145\n",
      "time/preback_policy (s)                 1.1168\n",
      "time/preback_start (s)                  0.15302\n",
      "time/preback_zf (s)                     5.2074\n",
      "time/saving (s)                         0.00628004\n",
      "time/training (s)                       2.34646\n",
      "time/epoch (s)                         17.8486\n",
      "time/total (s)                       1252.54\n",
      "Epoch                                  72\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:57:20.959714 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 73 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  84000\n",
      "trainer/ZF1 Loss                      111.163\n",
      "trainer/ZF2 Loss                      170.356\n",
      "trainer/ZF Expert Reward                6.83749\n",
      "trainer/ZF Policy Reward               -5.0917\n",
      "trainer/ZF CHI2 Term                  185.669\n",
      "trainer/Policy Loss                 -1931.09\n",
      "trainer/Bias Loss                     399.452\n",
      "trainer/Bias Value                     17.494\n",
      "trainer/Policy Grad Norm              151.152\n",
      "trainer/Policy Param Norm              31.4149\n",
      "trainer/Zf1 Grad Norm                8668.73\n",
      "trainer/Zf1 Param Norm                 91.8046\n",
      "trainer/Zf2 Grad Norm               13309.8\n",
      "trainer/Zf2 Param Norm                 94.8827\n",
      "trainer/Z Expert Predictions Mean    2377.93\n",
      "trainer/Z Expert Predictions Std       86.1128\n",
      "trainer/Z Expert Predictions Max     2523.27\n",
      "trainer/Z Expert Predictions Min     1967.59\n",
      "trainer/Z Policy Predictions Mean    1909.17\n",
      "trainer/Z Policy Predictions Std      684.245\n",
      "trainer/Z Policy Predictions Max     2463.25\n",
      "trainer/Z Policy Predictions Min      -78.8424\n",
      "trainer/Z Expert Targets Mean        2371.1\n",
      "trainer/Z Expert Targets Std           86.1614\n",
      "trainer/Z Expert Targets Max         2505.97\n",
      "trainer/Z Expert Targets Min         1985.24\n",
      "trainer/Z Policy Targets Mean        1914.26\n",
      "trainer/Z Policy Targets Std          675.186\n",
      "trainer/Z Policy Targets Max         2485.42\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   33.3135\n",
      "trainer/Log Pis Std                    10.6956\n",
      "trainer/Policy mu Mean                  0.281636\n",
      "trainer/Policy mu Std                   2.05292\n",
      "trainer/Policy log std Mean            -4.01073\n",
      "trainer/Policy log std Std              1.06779\n",
      "exploration/num steps total         80792\n",
      "exploration/num paths total           194\n",
      "evaluation/num steps total         545274\n",
      "evaluation/num paths total            777\n",
      "evaluation/path length Mean           855.5\n",
      "evaluation/path length Std            229.303\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            386\n",
      "evaluation/Rewards Mean                 4.4806\n",
      "evaluation/Rewards Std                  1.12103\n",
      "evaluation/Rewards Max                  6.57002\n",
      "evaluation/Rewards Min                 -2.70093\n",
      "evaluation/Returns Mean              3833.15\n",
      "evaluation/Returns Std               1126.52\n",
      "evaluation/Returns Max               4657.78\n",
      "evaluation/Returns Min               1548.36\n",
      "evaluation/Estimation Bias Mean      2300.67\n",
      "evaluation/Estimation Bias Std        201.782\n",
      "evaluation/EB/Q_True Mean              49.7746\n",
      "evaluation/EB/Q_True Std              140.592\n",
      "evaluation/EB/Q_Pred Mean            2350.45\n",
      "evaluation/EB/Q_Pred Std              122.133\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3833.15\n",
      "evaluation/Actions Mean                 0.0211496\n",
      "evaluation/Actions Std                  0.531829\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89172\n",
      "time/backward_zf1 (s)                   2.0594\n",
      "time/backward_zf2 (s)                   1.94971\n",
      "time/data sampling (s)                  0.324435\n",
      "time/data storing (s)                   0.0145806\n",
      "time/evaluation sampling (s)            1.77023\n",
      "time/exploration sampling (s)           0.34162\n",
      "time/logging (s)                        0.011007\n",
      "time/preback_alpha (s)                  0.602571\n",
      "time/preback_policy (s)                 1.1135\n",
      "time/preback_start (s)                  0.152544\n",
      "time/preback_zf (s)                     5.2103\n",
      "time/saving (s)                         0.00698165\n",
      "time/training (s)                       2.34596\n",
      "time/epoch (s)                         17.7946\n",
      "time/total (s)                       1270.35\n",
      "Epoch                                  73\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:57:39.495719 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 74 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  85000\n",
      "trainer/ZF1 Loss                       51.1057\n",
      "trainer/ZF2 Loss                       87.6696\n",
      "trainer/ZF Expert Reward               16.6587\n",
      "trainer/ZF Policy Reward                5.46238\n",
      "trainer/ZF CHI2 Term                  112.082\n",
      "trainer/Policy Loss                 -1990.44\n",
      "trainer/Bias Loss                     353.382\n",
      "trainer/Bias Value                     17.2357\n",
      "trainer/Policy Grad Norm              144.264\n",
      "trainer/Policy Param Norm              31.4869\n",
      "trainer/Zf1 Grad Norm                7144.22\n",
      "trainer/Zf1 Param Norm                 91.9749\n",
      "trainer/Zf2 Grad Norm                5048.79\n",
      "trainer/Zf2 Param Norm                 95.0795\n",
      "trainer/Z Expert Predictions Mean    2352.94\n",
      "trainer/Z Expert Predictions Std       95.1412\n",
      "trainer/Z Expert Predictions Max     2483.68\n",
      "trainer/Z Expert Predictions Min     1741.17\n",
      "trainer/Z Policy Predictions Mean    1981.88\n",
      "trainer/Z Policy Predictions Std      645.261\n",
      "trainer/Z Policy Predictions Max     2507.9\n",
      "trainer/Z Policy Predictions Min       43.6679\n",
      "trainer/Z Expert Targets Mean        2336.28\n",
      "trainer/Z Expert Targets Std           98.1529\n",
      "trainer/Z Expert Targets Max         2477.08\n",
      "trainer/Z Expert Targets Min         1740.82\n",
      "trainer/Z Policy Targets Mean        1976.42\n",
      "trainer/Z Policy Targets Std          638.479\n",
      "trainer/Z Policy Targets Max         2471.81\n",
      "trainer/Z Policy Targets Min           49.5797\n",
      "trainer/Log Pis Mean                   31.8159\n",
      "trainer/Log Pis Std                     8.34963\n",
      "trainer/Policy mu Mean                  0.182944\n",
      "trainer/Policy mu Std                   1.77689\n",
      "trainer/Policy log std Mean            -4.10898\n",
      "trainer/Policy log std Std              1.00157\n",
      "exploration/num steps total         80792\n",
      "exploration/num paths total           194\n",
      "evaluation/num steps total         554343\n",
      "evaluation/num paths total            787\n",
      "evaluation/path length Mean           906.9\n",
      "evaluation/path length Std            279.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             69\n",
      "evaluation/Rewards Mean                 4.61597\n",
      "evaluation/Rewards Std                  1.08507\n",
      "evaluation/Rewards Max                  6.75363\n",
      "evaluation/Rewards Min                 -2.63597\n",
      "evaluation/Returns Mean              4186.22\n",
      "evaluation/Returns Std               1323\n",
      "evaluation/Returns Max               4734.79\n",
      "evaluation/Returns Min                220.627\n",
      "evaluation/Estimation Bias Mean      2289.76\n",
      "evaluation/Estimation Bias Std        184.239\n",
      "evaluation/EB/Q_True Mean              47.8301\n",
      "evaluation/EB/Q_True Std              139.165\n",
      "evaluation/EB/Q_Pred Mean            2337.59\n",
      "evaluation/EB/Q_Pred Std              113.202\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4186.22\n",
      "evaluation/Actions Mean                 0.0203559\n",
      "evaluation/Actions Std                  0.529401\n",
      "evaluation/Actions Max                  0.999646\n",
      "evaluation/Actions Min                 -0.999268\n",
      "time/backward_policy (s)                2.05484\n",
      "time/backward_zf1 (s)                   2.24432\n",
      "time/backward_zf2 (s)                   2.13377\n",
      "time/data sampling (s)                  0.342809\n",
      "time/data storing (s)                   0.0150546\n",
      "time/evaluation sampling (s)            1.91646\n",
      "time/exploration sampling (s)           0.331074\n",
      "time/logging (s)                        0.0117469\n",
      "time/preback_alpha (s)                  0.605319\n",
      "time/preback_policy (s)                 1.2173\n",
      "time/preback_start (s)                  0.154342\n",
      "time/preback_zf (s)                     5.21351\n",
      "time/saving (s)                         0.00656185\n",
      "time/training (s)                       2.21934\n",
      "time/epoch (s)                         18.4664\n",
      "time/total (s)                       1288.84\n",
      "Epoch                                  74\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:57:57.965999 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 75 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  86000\n",
      "trainer/ZF1 Loss                      107.195\n",
      "trainer/ZF2 Loss                       67.2483\n",
      "trainer/ZF Expert Reward               17.6574\n",
      "trainer/ZF Policy Reward                2.58912\n",
      "trainer/ZF CHI2 Term                  133.572\n",
      "trainer/Policy Loss                 -1944.21\n",
      "trainer/Bias Loss                     251.065\n",
      "trainer/Bias Value                     16.9765\n",
      "trainer/Policy Grad Norm              140.911\n",
      "trainer/Policy Param Norm              31.5569\n",
      "trainer/Zf1 Grad Norm                7105.8\n",
      "trainer/Zf1 Param Norm                 92.1488\n",
      "trainer/Zf2 Grad Norm                3075.84\n",
      "trainer/Zf2 Param Norm                 95.2896\n",
      "trainer/Z Expert Predictions Mean    2325.28\n",
      "trainer/Z Expert Predictions Std      179.903\n",
      "trainer/Z Expert Predictions Max     2498.78\n",
      "trainer/Z Expert Predictions Min      -57.091\n",
      "trainer/Z Policy Predictions Mean    1936.6\n",
      "trainer/Z Policy Predictions Std      637.209\n",
      "trainer/Z Policy Predictions Max     2464.42\n",
      "trainer/Z Policy Predictions Min       25.429\n",
      "trainer/Z Expert Targets Mean        2307.62\n",
      "trainer/Z Expert Targets Std          176.302\n",
      "trainer/Z Expert Targets Max         2470.66\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1934.01\n",
      "trainer/Z Policy Targets Std          631.87\n",
      "trainer/Z Policy Targets Max         2456.43\n",
      "trainer/Z Policy Targets Min           32.1822\n",
      "trainer/Log Pis Mean                   31.5983\n",
      "trainer/Log Pis Std                     8.89361\n",
      "trainer/Policy mu Mean                  0.216094\n",
      "trainer/Policy mu Std                   1.80922\n",
      "trainer/Policy log std Mean            -4.03918\n",
      "trainer/Policy log std Std              0.985311\n",
      "exploration/num steps total         83304\n",
      "exploration/num paths total           197\n",
      "evaluation/num steps total         560951\n",
      "evaluation/num paths total            798\n",
      "evaluation/path length Mean           600.727\n",
      "evaluation/path length Std            447.992\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             20\n",
      "evaluation/Rewards Mean                 4.38398\n",
      "evaluation/Rewards Std                  1.2978\n",
      "evaluation/Rewards Max                  6.79392\n",
      "evaluation/Rewards Min                 -2.86476\n",
      "evaluation/Returns Mean              2633.57\n",
      "evaluation/Returns Std               2084.02\n",
      "evaluation/Returns Max               4646.44\n",
      "evaluation/Returns Min                -18.5023\n",
      "evaluation/Estimation Bias Mean      2220.84\n",
      "evaluation/Estimation Bias Std        234.761\n",
      "evaluation/EB/Q_True Mean              64.0306\n",
      "evaluation/EB/Q_True Std              155.998\n",
      "evaluation/EB/Q_Pred Mean            2284.87\n",
      "evaluation/EB/Q_Pred Std              142.348\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2633.57\n",
      "evaluation/Actions Mean                 0.0306008\n",
      "evaluation/Actions Std                  0.530097\n",
      "evaluation/Actions Max                  0.999886\n",
      "evaluation/Actions Min                 -0.999613\n",
      "time/backward_policy (s)                2.02209\n",
      "time/backward_zf1 (s)                   2.20475\n",
      "time/backward_zf2 (s)                   2.12266\n",
      "time/data sampling (s)                  0.333676\n",
      "time/data storing (s)                   0.0163093\n",
      "time/evaluation sampling (s)            1.88643\n",
      "time/exploration sampling (s)           0.350703\n",
      "time/logging (s)                        0.00907952\n",
      "time/preback_alpha (s)                  0.606677\n",
      "time/preback_policy (s)                 1.18981\n",
      "time/preback_start (s)                  0.156001\n",
      "time/preback_zf (s)                     5.22556\n",
      "time/saving (s)                         0.00651263\n",
      "time/training (s)                       2.25836\n",
      "time/epoch (s)                         18.3886\n",
      "time/total (s)                       1307.25\n",
      "Epoch                                  75\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:58:15.910164 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 76 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  87000\n",
      "trainer/ZF1 Loss                       83.3038\n",
      "trainer/ZF2 Loss                       69.6973\n",
      "trainer/ZF Expert Reward               16.6862\n",
      "trainer/ZF Policy Reward                5.56081\n",
      "trainer/ZF CHI2 Term                  119.026\n",
      "trainer/Policy Loss                 -1954.2\n",
      "trainer/Bias Loss                     243.882\n",
      "trainer/Bias Value                     16.7237\n",
      "trainer/Policy Grad Norm              144.225\n",
      "trainer/Policy Param Norm              31.6203\n",
      "trainer/Zf1 Grad Norm                3999.12\n",
      "trainer/Zf1 Param Norm                 92.2832\n",
      "trainer/Zf2 Grad Norm                3381.4\n",
      "trainer/Zf2 Param Norm                 95.4788\n",
      "trainer/Z Expert Predictions Mean    2316.76\n",
      "trainer/Z Expert Predictions Std       98.5145\n",
      "trainer/Z Expert Predictions Max     2439.96\n",
      "trainer/Z Expert Predictions Min     1863.12\n",
      "trainer/Z Policy Predictions Mean    1941.39\n",
      "trainer/Z Policy Predictions Std      599.259\n",
      "trainer/Z Policy Predictions Max     2420.81\n",
      "trainer/Z Policy Predictions Min       12.3709\n",
      "trainer/Z Expert Targets Mean        2300.07\n",
      "trainer/Z Expert Targets Std           99.5126\n",
      "trainer/Z Expert Targets Max         2437.16\n",
      "trainer/Z Expert Targets Min         1827.95\n",
      "trainer/Z Policy Targets Mean        1935.83\n",
      "trainer/Z Policy Targets Std          586.7\n",
      "trainer/Z Policy Targets Max         2419.85\n",
      "trainer/Z Policy Targets Min           22.7998\n",
      "trainer/Log Pis Mean                   31.7176\n",
      "trainer/Log Pis Std                    10.1015\n",
      "trainer/Policy mu Mean                  0.248687\n",
      "trainer/Policy mu Std                   1.88875\n",
      "trainer/Policy log std Mean            -4.07482\n",
      "trainer/Policy log std Std              0.997176\n",
      "exploration/num steps total         83304\n",
      "exploration/num paths total           197\n",
      "evaluation/num steps total         568668\n",
      "evaluation/num paths total            809\n",
      "evaluation/path length Mean           701.545\n",
      "evaluation/path length Std            349.743\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             19\n",
      "evaluation/Rewards Mean                 3.97829\n",
      "evaluation/Rewards Std                  1.74667\n",
      "evaluation/Rewards Max                  6.64404\n",
      "evaluation/Rewards Min                 -4.06462\n",
      "evaluation/Returns Mean              2790.95\n",
      "evaluation/Returns Std               1528.46\n",
      "evaluation/Returns Max               4450.35\n",
      "evaluation/Returns Min                 -1.94938\n",
      "evaluation/Estimation Bias Mean      2129.22\n",
      "evaluation/Estimation Bias Std        344.207\n",
      "evaluation/EB/Q_True Mean              51.191\n",
      "evaluation/EB/Q_True Std              137.053\n",
      "evaluation/EB/Q_Pred Mean            2180.41\n",
      "evaluation/EB/Q_Pred Std              305.549\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2790.95\n",
      "evaluation/Actions Mean                 0.0184541\n",
      "evaluation/Actions Std                  0.557384\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88009\n",
      "time/backward_zf1 (s)                   2.04783\n",
      "time/backward_zf2 (s)                   1.9526\n",
      "time/data sampling (s)                  0.313957\n",
      "time/data storing (s)                   0.0154714\n",
      "time/evaluation sampling (s)            1.79568\n",
      "time/exploration sampling (s)           0.332927\n",
      "time/logging (s)                        0.0105108\n",
      "time/preback_alpha (s)                  0.6001\n",
      "time/preback_policy (s)                 1.06436\n",
      "time/preback_start (s)                  0.153162\n",
      "time/preback_zf (s)                     5.18965\n",
      "time/saving (s)                         0.00683024\n",
      "time/training (s)                       2.51425\n",
      "time/epoch (s)                         17.8774\n",
      "time/total (s)                       1325.15\n",
      "Epoch                                  76\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:58:34.257157 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 77 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  88000\n",
      "trainer/ZF1 Loss                     1169.44\n",
      "trainer/ZF2 Loss                     1193.9\n",
      "trainer/ZF Expert Reward               24.2707\n",
      "trainer/ZF Policy Reward               19.0465\n",
      "trainer/ZF CHI2 Term                 1219.01\n",
      "trainer/Policy Loss                 -1921.02\n",
      "trainer/Bias Loss                     318.29\n",
      "trainer/Bias Value                     16.5234\n",
      "trainer/Policy Grad Norm              143.77\n",
      "trainer/Policy Param Norm              31.6902\n",
      "trainer/Zf1 Grad Norm                3255.9\n",
      "trainer/Zf1 Param Norm                 92.4691\n",
      "trainer/Zf2 Grad Norm                6105.21\n",
      "trainer/Zf2 Param Norm                 95.6862\n",
      "trainer/Z Expert Predictions Mean    2301.81\n",
      "trainer/Z Expert Predictions Std       87.6186\n",
      "trainer/Z Expert Predictions Max     2411.82\n",
      "trainer/Z Expert Predictions Min     1801.98\n",
      "trainer/Z Policy Predictions Mean    1913.09\n",
      "trainer/Z Policy Predictions Std      602.444\n",
      "trainer/Z Policy Predictions Max     2383.44\n",
      "trainer/Z Policy Predictions Min       63.499\n",
      "trainer/Z Expert Targets Mean        2277.54\n",
      "trainer/Z Expert Targets Std           90.4675\n",
      "trainer/Z Expert Targets Max         2395.58\n",
      "trainer/Z Expert Targets Min         1795.15\n",
      "trainer/Z Policy Targets Mean        1894.04\n",
      "trainer/Z Policy Targets Std          602.204\n",
      "trainer/Z Policy Targets Max         2376.41\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   32.4398\n",
      "trainer/Log Pis Std                    10.1424\n",
      "trainer/Policy mu Mean                  0.200461\n",
      "trainer/Policy mu Std                   1.97346\n",
      "trainer/Policy log std Mean            -4.03427\n",
      "trainer/Policy log std Std              1.02493\n",
      "exploration/num steps total         83304\n",
      "exploration/num paths total           197\n",
      "evaluation/num steps total         577297\n",
      "evaluation/num paths total            824\n",
      "evaluation/path length Mean           575.267\n",
      "evaluation/path length Std            433.551\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             18\n",
      "evaluation/Rewards Mean                 4.49191\n",
      "evaluation/Rewards Std                  1.3337\n",
      "evaluation/Rewards Max                  7.0126\n",
      "evaluation/Rewards Min                 -4.54929\n",
      "evaluation/Returns Mean              2584.04\n",
      "evaluation/Returns Std               2027.11\n",
      "evaluation/Returns Max               4726.45\n",
      "evaluation/Returns Min                  3.53283\n",
      "evaluation/Estimation Bias Mean      2185.06\n",
      "evaluation/Estimation Bias Std        220.362\n",
      "evaluation/EB/Q_True Mean              48.36\n",
      "evaluation/EB/Q_True Std              137.378\n",
      "evaluation/EB/Q_Pred Mean            2233.42\n",
      "evaluation/EB/Q_Pred Std              151.509\n",
      "evaluation/Num Paths                   15\n",
      "evaluation/Average Returns           2584.04\n",
      "evaluation/Actions Mean                 0.0190436\n",
      "evaluation/Actions Std                  0.550797\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99237\n",
      "time/backward_zf1 (s)                   2.16857\n",
      "time/backward_zf2 (s)                   2.06415\n",
      "time/data sampling (s)                  0.331775\n",
      "time/data storing (s)                   0.0156406\n",
      "time/evaluation sampling (s)            1.8884\n",
      "time/exploration sampling (s)           0.339256\n",
      "time/logging (s)                        0.0139026\n",
      "time/preback_alpha (s)                  0.6034\n",
      "time/preback_policy (s)                 1.17005\n",
      "time/preback_start (s)                  0.153201\n",
      "time/preback_zf (s)                     5.21143\n",
      "time/saving (s)                         0.00636812\n",
      "time/training (s)                       2.32074\n",
      "time/epoch (s)                         18.2792\n",
      "time/total (s)                       1343.45\n",
      "Epoch                                  77\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:58:52.553102 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 78 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  89000\n",
      "trainer/ZF1 Loss                       86.2756\n",
      "trainer/ZF2 Loss                       67.9584\n",
      "trainer/ZF Expert Reward               14.2646\n",
      "trainer/ZF Policy Reward                6.49904\n",
      "trainer/ZF CHI2 Term                  117.36\n",
      "trainer/Policy Loss                 -1871.09\n",
      "trainer/Bias Loss                     247.776\n",
      "trainer/Bias Value                     16.2825\n",
      "trainer/Policy Grad Norm              116.191\n",
      "trainer/Policy Param Norm              31.7508\n",
      "trainer/Zf1 Grad Norm                3945.31\n",
      "trainer/Zf1 Param Norm                 92.6132\n",
      "trainer/Zf2 Grad Norm                3651.95\n",
      "trainer/Zf2 Param Norm                 95.8551\n",
      "trainer/Z Expert Predictions Mean    2261.36\n",
      "trainer/Z Expert Predictions Std      116.672\n",
      "trainer/Z Expert Predictions Max     2395.25\n",
      "trainer/Z Expert Predictions Min      861.149\n",
      "trainer/Z Policy Predictions Mean    1858.77\n",
      "trainer/Z Policy Predictions Std      657.635\n",
      "trainer/Z Policy Predictions Max     2367.65\n",
      "trainer/Z Policy Predictions Min      -57.2159\n",
      "trainer/Z Expert Targets Mean        2247.09\n",
      "trainer/Z Expert Targets Std          122.024\n",
      "trainer/Z Expert Targets Max         2406.28\n",
      "trainer/Z Expert Targets Min          772.253\n",
      "trainer/Z Policy Targets Mean        1852.27\n",
      "trainer/Z Policy Targets Std          653.569\n",
      "trainer/Z Policy Targets Max         2354.74\n",
      "trainer/Z Policy Targets Min          -44.3667\n",
      "trainer/Log Pis Mean                   32.8059\n",
      "trainer/Log Pis Std                    10.4658\n",
      "trainer/Policy mu Mean                  0.35005\n",
      "trainer/Policy mu Std                   2.04921\n",
      "trainer/Policy log std Mean            -4.00695\n",
      "trainer/Policy log std Std              1.04942\n",
      "exploration/num steps total         83304\n",
      "exploration/num paths total           197\n",
      "evaluation/num steps total         586317\n",
      "evaluation/num paths total            834\n",
      "evaluation/path length Mean           902\n",
      "evaluation/path length Std            294\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             20\n",
      "evaluation/Rewards Mean                 4.50857\n",
      "evaluation/Rewards Std                  1.29067\n",
      "evaluation/Rewards Max                  7.07073\n",
      "evaluation/Rewards Min                 -2.27834\n",
      "evaluation/Returns Mean              4066.73\n",
      "evaluation/Returns Std               1356.77\n",
      "evaluation/Returns Max               4699.02\n",
      "evaluation/Returns Min                 12.6805\n",
      "evaluation/Estimation Bias Mean      2156.73\n",
      "evaluation/Estimation Bias Std        190.822\n",
      "evaluation/EB/Q_True Mean              46.646\n",
      "evaluation/EB/Q_True Std              135.839\n",
      "evaluation/EB/Q_Pred Mean            2203.38\n",
      "evaluation/EB/Q_Pred Std              125.118\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4066.73\n",
      "evaluation/Actions Mean                 0.0170402\n",
      "evaluation/Actions Std                  0.550109\n",
      "evaluation/Actions Max                  0.999849\n",
      "evaluation/Actions Min                 -0.999752\n",
      "time/backward_policy (s)                1.98073\n",
      "time/backward_zf1 (s)                   2.19129\n",
      "time/backward_zf2 (s)                   2.08369\n",
      "time/data sampling (s)                  0.324242\n",
      "time/data storing (s)                   0.0151099\n",
      "time/evaluation sampling (s)            1.75904\n",
      "time/exploration sampling (s)           0.332458\n",
      "time/logging (s)                        0.011194\n",
      "time/preback_alpha (s)                  0.606942\n",
      "time/preback_policy (s)                 1.15567\n",
      "time/preback_start (s)                  0.153149\n",
      "time/preback_zf (s)                     5.25251\n",
      "time/saving (s)                         0.00635626\n",
      "time/training (s)                       2.35069\n",
      "time/epoch (s)                         18.2231\n",
      "time/total (s)                       1361.69\n",
      "Epoch                                  78\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:59:10.428667 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 79 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  90000\n",
      "trainer/ZF1 Loss                      953.114\n",
      "trainer/ZF2 Loss                       76.4067\n",
      "trainer/ZF Expert Reward               16.0264\n",
      "trainer/ZF Policy Reward                6.3023\n",
      "trainer/ZF CHI2 Term                  555.776\n",
      "trainer/Policy Loss                 -1940.32\n",
      "trainer/Bias Loss                    2580.58\n",
      "trainer/Bias Value                     16.0326\n",
      "trainer/Policy Grad Norm              122.12\n",
      "trainer/Policy Param Norm              31.8178\n",
      "trainer/Zf1 Grad Norm               24709.4\n",
      "trainer/Zf1 Param Norm                 92.7503\n",
      "trainer/Zf2 Grad Norm                6116.37\n",
      "trainer/Zf2 Param Norm                 96.0556\n",
      "trainer/Z Expert Predictions Mean    2237.91\n",
      "trainer/Z Expert Predictions Std      110.437\n",
      "trainer/Z Expert Predictions Max     2366.28\n",
      "trainer/Z Expert Predictions Min     1078.7\n",
      "trainer/Z Policy Predictions Mean    1935.92\n",
      "trainer/Z Policy Predictions Std      563.383\n",
      "trainer/Z Policy Predictions Max     2341.75\n",
      "trainer/Z Policy Predictions Min      -35.509\n",
      "trainer/Z Expert Targets Mean        2221.88\n",
      "trainer/Z Expert Targets Std          164.202\n",
      "trainer/Z Expert Targets Max         2391.61\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1929.61\n",
      "trainer/Z Policy Targets Std          559.007\n",
      "trainer/Z Policy Targets Max         2339.48\n",
      "trainer/Z Policy Targets Min          -26.1957\n",
      "trainer/Log Pis Mean                   31.6074\n",
      "trainer/Log Pis Std                    10.2434\n",
      "trainer/Policy mu Mean                  0.165842\n",
      "trainer/Policy mu Std                   1.82921\n",
      "trainer/Policy log std Mean            -4.11281\n",
      "trainer/Policy log std Std              0.921002\n",
      "exploration/num steps total         83304\n",
      "exploration/num paths total           197\n",
      "evaluation/num steps total         595054\n",
      "evaluation/num paths total            844\n",
      "evaluation/path length Mean           873.7\n",
      "evaluation/path length Std            290.653\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             47\n",
      "evaluation/Rewards Mean                 4.53514\n",
      "evaluation/Rewards Std                  1.20869\n",
      "evaluation/Rewards Max                  7.02855\n",
      "evaluation/Rewards Min                 -3.28886\n",
      "evaluation/Returns Mean              3962.35\n",
      "evaluation/Returns Std               1366.27\n",
      "evaluation/Returns Max               4768.03\n",
      "evaluation/Returns Min                103.875\n",
      "evaluation/Estimation Bias Mean      2161.76\n",
      "evaluation/Estimation Bias Std        201.871\n",
      "evaluation/EB/Q_True Mean              50.3034\n",
      "evaluation/EB/Q_True Std              143.32\n",
      "evaluation/EB/Q_Pred Mean            2212.06\n",
      "evaluation/EB/Q_Pred Std              121.753\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3962.35\n",
      "evaluation/Actions Mean                 0.0131795\n",
      "evaluation/Actions Std                  0.536621\n",
      "evaluation/Actions Max                  0.999949\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                1.86654\n",
      "time/backward_zf1 (s)                   2.04038\n",
      "time/backward_zf2 (s)                   1.92724\n",
      "time/data sampling (s)                  0.320807\n",
      "time/data storing (s)                   0.0165211\n",
      "time/evaluation sampling (s)            1.79746\n",
      "time/exploration sampling (s)           0.343231\n",
      "time/logging (s)                        0.0110447\n",
      "time/preback_alpha (s)                  0.599179\n",
      "time/preback_policy (s)                 1.06334\n",
      "time/preback_start (s)                  0.155752\n",
      "time/preback_zf (s)                     5.21597\n",
      "time/saving (s)                         0.00712135\n",
      "time/training (s)                       2.44425\n",
      "time/epoch (s)                         17.8088\n",
      "time/total (s)                       1379.52\n",
      "Epoch                                  79\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:59:28.658656 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 80 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  91000\n",
      "trainer/ZF1 Loss                       87.7049\n",
      "trainer/ZF2 Loss                       67.7704\n",
      "trainer/ZF Expert Reward               28.8428\n",
      "trainer/ZF Policy Reward               13.283\n",
      "trainer/ZF CHI2 Term                  125.835\n",
      "trainer/Policy Loss                 -1885.67\n",
      "trainer/Bias Loss                     278.163\n",
      "trainer/Bias Value                     15.8063\n",
      "trainer/Policy Grad Norm              132.724\n",
      "trainer/Policy Param Norm              31.8846\n",
      "trainer/Zf1 Grad Norm                5162.3\n",
      "trainer/Zf1 Param Norm                 92.9041\n",
      "trainer/Zf2 Grad Norm                3459.19\n",
      "trainer/Zf2 Param Norm                 96.2249\n",
      "trainer/Z Expert Predictions Mean    2228.2\n",
      "trainer/Z Expert Predictions Std      102.441\n",
      "trainer/Z Expert Predictions Max     2345.66\n",
      "trainer/Z Expert Predictions Min     1698.47\n",
      "trainer/Z Policy Predictions Mean    1877.87\n",
      "trainer/Z Policy Predictions Std      589.081\n",
      "trainer/Z Policy Predictions Max     2340.46\n",
      "trainer/Z Policy Predictions Min      -73.7862\n",
      "trainer/Z Expert Targets Mean        2199.36\n",
      "trainer/Z Expert Targets Std          100.238\n",
      "trainer/Z Expert Targets Max         2347.78\n",
      "trainer/Z Expert Targets Min         1655.04\n",
      "trainer/Z Policy Targets Mean        1864.59\n",
      "trainer/Z Policy Targets Std          576.809\n",
      "trainer/Z Policy Targets Max         2300.21\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   32.8664\n",
      "trainer/Log Pis Std                    10.96\n",
      "trainer/Policy mu Mean                  0.168891\n",
      "trainer/Policy mu Std                   2.01772\n",
      "trainer/Policy log std Mean            -4.08804\n",
      "trainer/Policy log std Std              0.945483\n",
      "exploration/num steps total         84328\n",
      "exploration/num paths total           199\n",
      "evaluation/num steps total         604923\n",
      "evaluation/num paths total            854\n",
      "evaluation/path length Mean           986.9\n",
      "evaluation/path length Std             39.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            869\n",
      "evaluation/Rewards Mean                 4.59393\n",
      "evaluation/Rewards Std                  1.18055\n",
      "evaluation/Rewards Max                  6.90914\n",
      "evaluation/Rewards Min                 -3.95235\n",
      "evaluation/Returns Mean              4533.74\n",
      "evaluation/Returns Std                239.565\n",
      "evaluation/Returns Max               4707.45\n",
      "evaluation/Returns Min               3832.66\n",
      "evaluation/Estimation Bias Mean      2126.96\n",
      "evaluation/Estimation Bias Std        188.177\n",
      "evaluation/EB/Q_True Mean              42.4777\n",
      "evaluation/EB/Q_True Std              130.895\n",
      "evaluation/EB/Q_Pred Mean            2169.44\n",
      "evaluation/EB/Q_Pred Std              125.174\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4533.74\n",
      "evaluation/Actions Mean                 0.0248365\n",
      "evaluation/Actions Std                  0.535672\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98363\n",
      "time/backward_zf1 (s)                   2.1382\n",
      "time/backward_zf2 (s)                   2.05742\n",
      "time/data sampling (s)                  0.338265\n",
      "time/data storing (s)                   0.0149782\n",
      "time/evaluation sampling (s)            1.78649\n",
      "time/exploration sampling (s)           0.332638\n",
      "time/logging (s)                        0.0125417\n",
      "time/preback_alpha (s)                  0.609337\n",
      "time/preback_policy (s)                 1.16342\n",
      "time/preback_start (s)                  0.153228\n",
      "time/preback_zf (s)                     5.23025\n",
      "time/saving (s)                         0.00683488\n",
      "time/training (s)                       2.33508\n",
      "time/epoch (s)                         18.1623\n",
      "time/total (s)                       1397.7\n",
      "Epoch                                  80\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 20:59:47.491036 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 81 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  92000\n",
      "trainer/ZF1 Loss                       60.2623\n",
      "trainer/ZF2 Loss                      104.586\n",
      "trainer/ZF Expert Reward               19.5155\n",
      "trainer/ZF Policy Reward               11.8598\n",
      "trainer/ZF CHI2 Term                  122.344\n",
      "trainer/Policy Loss                 -1856.2\n",
      "trainer/Bias Loss                     427.088\n",
      "trainer/Bias Value                     15.6091\n",
      "trainer/Policy Grad Norm              103.582\n",
      "trainer/Policy Param Norm              31.9498\n",
      "trainer/Zf1 Grad Norm                2539.99\n",
      "trainer/Zf1 Param Norm                 93.061\n",
      "trainer/Zf2 Grad Norm                4936.07\n",
      "trainer/Zf2 Param Norm                 96.3848\n",
      "trainer/Z Expert Predictions Mean    2192.33\n",
      "trainer/Z Expert Predictions Std       85.2964\n",
      "trainer/Z Expert Predictions Max     2319.27\n",
      "trainer/Z Expert Predictions Min     1655\n",
      "trainer/Z Policy Predictions Mean    1846.56\n",
      "trainer/Z Policy Predictions Std      552.718\n",
      "trainer/Z Policy Predictions Max     2310.89\n",
      "trainer/Z Policy Predictions Min      -43.4014\n",
      "trainer/Z Expert Targets Mean        2172.81\n",
      "trainer/Z Expert Targets Std           90.7778\n",
      "trainer/Z Expert Targets Max         2274.15\n",
      "trainer/Z Expert Targets Min         1617.58\n",
      "trainer/Z Policy Targets Mean        1834.7\n",
      "trainer/Z Policy Targets Std          545.631\n",
      "trainer/Z Policy Targets Max         2275.64\n",
      "trainer/Z Policy Targets Min          -22.681\n",
      "trainer/Log Pis Mean                   32.5899\n",
      "trainer/Log Pis Std                     9.83609\n",
      "trainer/Policy mu Mean                  0.287582\n",
      "trainer/Policy mu Std                   1.86846\n",
      "trainer/Policy log std Mean            -4.12244\n",
      "trainer/Policy log std Std              1.01003\n",
      "exploration/num steps total         85328\n",
      "exploration/num paths total           200\n",
      "evaluation/num steps total         610304\n",
      "evaluation/num paths total            866\n",
      "evaluation/path length Mean           448.417\n",
      "evaluation/path length Std            449.893\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             10\n",
      "evaluation/Rewards Mean                 4.52623\n",
      "evaluation/Rewards Std                  1.31662\n",
      "evaluation/Rewards Max                  6.8734\n",
      "evaluation/Rewards Min                 -2.98378\n",
      "evaluation/Returns Mean              2029.64\n",
      "evaluation/Returns Std               2166.4\n",
      "evaluation/Returns Max               4802.52\n",
      "evaluation/Returns Min                  1.85817\n",
      "evaluation/Estimation Bias Mean      2060.95\n",
      "evaluation/Estimation Bias Std        250.718\n",
      "evaluation/EB/Q_True Mean              81.6299\n",
      "evaluation/EB/Q_True Std              175.666\n",
      "evaluation/EB/Q_Pred Mean            2142.58\n",
      "evaluation/EB/Q_Pred Std              128.497\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2029.64\n",
      "evaluation/Actions Mean                 0.0289121\n",
      "evaluation/Actions Std                  0.539891\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999848\n",
      "time/backward_policy (s)                2.11574\n",
      "time/backward_zf1 (s)                   2.29683\n",
      "time/backward_zf2 (s)                   2.21729\n",
      "time/data sampling (s)                  0.343515\n",
      "time/data storing (s)                   0.0152004\n",
      "time/evaluation sampling (s)            1.72998\n",
      "time/exploration sampling (s)           0.335113\n",
      "time/logging (s)                        0.00741479\n",
      "time/preback_alpha (s)                  0.623075\n",
      "time/preback_policy (s)                 1.23534\n",
      "time/preback_start (s)                  0.155865\n",
      "time/preback_zf (s)                     5.29533\n",
      "time/saving (s)                         0.00796575\n",
      "time/training (s)                       2.37248\n",
      "time/epoch (s)                         18.7511\n",
      "time/total (s)                       1416.47\n",
      "Epoch                                  81\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:00:05.562071 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 82 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  93000\n",
      "trainer/ZF1 Loss                       47.2025\n",
      "trainer/ZF2 Loss                       38.3803\n",
      "trainer/ZF Expert Reward               13.3376\n",
      "trainer/ZF Policy Reward                4.22102\n",
      "trainer/ZF CHI2 Term                   85.1889\n",
      "trainer/Policy Loss                 -1780.69\n",
      "trainer/Bias Loss                     216.147\n",
      "trainer/Bias Value                     15.4116\n",
      "trainer/Policy Grad Norm              119.68\n",
      "trainer/Policy Param Norm              32.0203\n",
      "trainer/Zf1 Grad Norm                3536.98\n",
      "trainer/Zf1 Param Norm                 93.1897\n",
      "trainer/Zf2 Grad Norm                4095.62\n",
      "trainer/Zf2 Param Norm                 96.5293\n",
      "trainer/Z Expert Predictions Mean    2151.34\n",
      "trainer/Z Expert Predictions Std      167.287\n",
      "trainer/Z Expert Predictions Max     2278.09\n",
      "trainer/Z Expert Predictions Min      -86.4398\n",
      "trainer/Z Policy Predictions Mean    1770.18\n",
      "trainer/Z Policy Predictions Std      615.352\n",
      "trainer/Z Policy Predictions Max     2250.15\n",
      "trainer/Z Policy Predictions Min      -43.8177\n",
      "trainer/Z Expert Targets Mean        2138\n",
      "trainer/Z Expert Targets Std          164.443\n",
      "trainer/Z Expert Targets Max         2249.91\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1765.96\n",
      "trainer/Z Policy Targets Std          608.079\n",
      "trainer/Z Policy Targets Max         2238.39\n",
      "trainer/Z Policy Targets Min          -27.1222\n",
      "trainer/Log Pis Mean                   33.617\n",
      "trainer/Log Pis Std                    11.4812\n",
      "trainer/Policy mu Mean                  0.322148\n",
      "trainer/Policy mu Std                   2.19225\n",
      "trainer/Policy log std Mean            -4.04379\n",
      "trainer/Policy log std Std              1.12474\n",
      "exploration/num steps total         87348\n",
      "exploration/num paths total           203\n",
      "evaluation/num steps total         617331\n",
      "evaluation/num paths total            876\n",
      "evaluation/path length Mean           702.7\n",
      "evaluation/path length Std            400.636\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             34\n",
      "evaluation/Rewards Mean                 4.37771\n",
      "evaluation/Rewards Std                  1.44636\n",
      "evaluation/Rewards Max                  6.82573\n",
      "evaluation/Rewards Min                 -3.09337\n",
      "evaluation/Returns Mean              3076.22\n",
      "evaluation/Returns Std               1849.71\n",
      "evaluation/Returns Max               4638.84\n",
      "evaluation/Returns Min                 80.3779\n",
      "evaluation/Estimation Bias Mean      2008.41\n",
      "evaluation/Estimation Bias Std        220.23\n",
      "evaluation/EB/Q_True Mean              57.6746\n",
      "evaluation/EB/Q_True Std              145.052\n",
      "evaluation/EB/Q_Pred Mean            2066.09\n",
      "evaluation/EB/Q_Pred Std              133.79\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3076.22\n",
      "evaluation/Actions Mean                 0.0358149\n",
      "evaluation/Actions Std                  0.551203\n",
      "evaluation/Actions Max                  0.999989\n",
      "evaluation/Actions Min                 -0.999986\n",
      "time/backward_policy (s)                1.96481\n",
      "time/backward_zf1 (s)                   2.1395\n",
      "time/backward_zf2 (s)                   2.03729\n",
      "time/data sampling (s)                  0.311888\n",
      "time/data storing (s)                   0.0144728\n",
      "time/evaluation sampling (s)            1.77548\n",
      "time/exploration sampling (s)           0.330207\n",
      "time/logging (s)                        0.00927935\n",
      "time/preback_alpha (s)                  0.59773\n",
      "time/preback_policy (s)                 1.16103\n",
      "time/preback_start (s)                  0.15443\n",
      "time/preback_zf (s)                     5.19732\n",
      "time/saving (s)                         0.00618972\n",
      "time/training (s)                       2.30184\n",
      "time/epoch (s)                         18.0015\n",
      "time/total (s)                       1434.5\n",
      "Epoch                                  82\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:00:24.010095 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 83 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  94000\n",
      "trainer/ZF1 Loss                      221.238\n",
      "trainer/ZF2 Loss                       92.586\n",
      "trainer/ZF Expert Reward                0.399328\n",
      "trainer/ZF Policy Reward               -3.67115\n",
      "trainer/ZF CHI2 Term                  194.544\n",
      "trainer/Policy Loss                 -1799.39\n",
      "trainer/Bias Loss                     579.275\n",
      "trainer/Bias Value                     15.2269\n",
      "trainer/Policy Grad Norm              148.942\n",
      "trainer/Policy Param Norm              32.0885\n",
      "trainer/Zf1 Grad Norm               54473.8\n",
      "trainer/Zf1 Param Norm                 93.3282\n",
      "trainer/Zf2 Grad Norm                5491.52\n",
      "trainer/Zf2 Param Norm                 96.6763\n",
      "trainer/Z Expert Predictions Mean    2121.66\n",
      "trainer/Z Expert Predictions Std       76.1684\n",
      "trainer/Z Expert Predictions Max     2231.8\n",
      "trainer/Z Expert Predictions Min     1682.67\n",
      "trainer/Z Policy Predictions Mean    1776.5\n",
      "trainer/Z Policy Predictions Std      597.035\n",
      "trainer/Z Policy Predictions Max     2222.86\n",
      "trainer/Z Policy Predictions Min      -29.1965\n",
      "trainer/Z Expert Targets Mean        2121.26\n",
      "trainer/Z Expert Targets Std           76.8454\n",
      "trainer/Z Expert Targets Max         2228.69\n",
      "trainer/Z Expert Targets Min         1677.77\n",
      "trainer/Z Policy Targets Mean        1780.17\n",
      "trainer/Z Policy Targets Std          604.258\n",
      "trainer/Z Policy Targets Max         2203.62\n",
      "trainer/Z Policy Targets Min          -12.3826\n",
      "trainer/Log Pis Mean                   33.9006\n",
      "trainer/Log Pis Std                    11.8033\n",
      "trainer/Policy mu Mean                  0.326202\n",
      "trainer/Policy mu Std                   2.24311\n",
      "trainer/Policy log std Mean            -4.0713\n",
      "trainer/Policy log std Std              1.02739\n",
      "exploration/num steps total         90348\n",
      "exploration/num paths total           206\n",
      "evaluation/num steps total         625629\n",
      "evaluation/num paths total            886\n",
      "evaluation/path length Mean           829.8\n",
      "evaluation/path length Std            230.226\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            418\n",
      "evaluation/Rewards Mean                 4.59527\n",
      "evaluation/Rewards Std                  1.11773\n",
      "evaluation/Rewards Max                  6.72555\n",
      "evaluation/Rewards Min                 -1.98209\n",
      "evaluation/Returns Mean              3813.16\n",
      "evaluation/Returns Std               1082.73\n",
      "evaluation/Returns Max               4711.8\n",
      "evaluation/Returns Min               1911.04\n",
      "evaluation/Estimation Bias Mean      2048.11\n",
      "evaluation/Estimation Bias Std        175.068\n",
      "evaluation/EB/Q_True Mean              48.4886\n",
      "evaluation/EB/Q_True Std              134.766\n",
      "evaluation/EB/Q_Pred Mean            2096.6\n",
      "evaluation/EB/Q_Pred Std              104.704\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3813.16\n",
      "evaluation/Actions Mean                 0.0226422\n",
      "evaluation/Actions Std                  0.528585\n",
      "evaluation/Actions Max                  0.999611\n",
      "evaluation/Actions Min                 -0.999562\n",
      "time/backward_policy (s)                2.04175\n",
      "time/backward_zf1 (s)                   2.24238\n",
      "time/backward_zf2 (s)                   2.11669\n",
      "time/data sampling (s)                  0.326417\n",
      "time/data storing (s)                   0.0157168\n",
      "time/evaluation sampling (s)            1.80428\n",
      "time/exploration sampling (s)           0.350208\n",
      "time/logging (s)                        0.0107505\n",
      "time/preback_alpha (s)                  0.610461\n",
      "time/preback_policy (s)                 1.1749\n",
      "time/preback_start (s)                  0.155451\n",
      "time/preback_zf (s)                     5.21225\n",
      "time/saving (s)                         0.00684354\n",
      "time/training (s)                       2.30957\n",
      "time/epoch (s)                         18.3777\n",
      "time/total (s)                       1452.89\n",
      "Epoch                                  83\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:00:41.905577 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 84 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  95000\n",
      "trainer/ZF1 Loss                       37.2373\n",
      "trainer/ZF2 Loss                       54.1322\n",
      "trainer/ZF Expert Reward               14.4669\n",
      "trainer/ZF Policy Reward                2.52964\n",
      "trainer/ZF CHI2 Term                   89.278\n",
      "trainer/Policy Loss                 -1819.08\n",
      "trainer/Bias Loss                     240.518\n",
      "trainer/Bias Value                     15.028\n",
      "trainer/Policy Grad Norm              151.075\n",
      "trainer/Policy Param Norm              32.1578\n",
      "trainer/Zf1 Grad Norm                6585.58\n",
      "trainer/Zf1 Param Norm                 93.4777\n",
      "trainer/Zf2 Grad Norm                5861.99\n",
      "trainer/Zf2 Param Norm                 96.8159\n",
      "trainer/Z Expert Predictions Mean    2115.16\n",
      "trainer/Z Expert Predictions Std       71.9661\n",
      "trainer/Z Expert Predictions Max     2221.57\n",
      "trainer/Z Expert Predictions Min     1688.91\n",
      "trainer/Z Policy Predictions Mean    1803.36\n",
      "trainer/Z Policy Predictions Std      520.281\n",
      "trainer/Z Policy Predictions Max     2208.69\n",
      "trainer/Z Policy Predictions Min     -140.618\n",
      "trainer/Z Expert Targets Mean        2100.69\n",
      "trainer/Z Expert Targets Std           71.1324\n",
      "trainer/Z Expert Targets Max         2214.21\n",
      "trainer/Z Expert Targets Min         1680.15\n",
      "trainer/Z Policy Targets Mean        1800.83\n",
      "trainer/Z Policy Targets Std          507.55\n",
      "trainer/Z Policy Targets Max         2174.37\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   31.9757\n",
      "trainer/Log Pis Std                    11.105\n",
      "trainer/Policy mu Mean                  0.235332\n",
      "trainer/Policy mu Std                   1.93418\n",
      "trainer/Policy log std Mean            -4.08068\n",
      "trainer/Policy log std Std              0.972052\n",
      "exploration/num steps total         90348\n",
      "exploration/num paths total           206\n",
      "evaluation/num steps total         635276\n",
      "evaluation/num paths total            896\n",
      "evaluation/path length Mean           964.7\n",
      "evaluation/path length Std             96.9268\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            675\n",
      "evaluation/Rewards Mean                 4.67926\n",
      "evaluation/Rewards Std                  0.999001\n",
      "evaluation/Rewards Max                  6.7797\n",
      "evaluation/Rewards Min                 -2.47186\n",
      "evaluation/Returns Mean              4514.08\n",
      "evaluation/Returns Std                494.768\n",
      "evaluation/Returns Max               4841.18\n",
      "evaluation/Returns Min               3067.35\n",
      "evaluation/Estimation Bias Mean      2043.53\n",
      "evaluation/Estimation Bias Std        160.931\n",
      "evaluation/EB/Q_True Mean              44.715\n",
      "evaluation/EB/Q_True Std              134.795\n",
      "evaluation/EB/Q_Pred Mean            2088.24\n",
      "evaluation/EB/Q_Pred Std               76.7918\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4514.08\n",
      "evaluation/Actions Mean                 0.0340566\n",
      "evaluation/Actions Std                  0.542755\n",
      "evaluation/Actions Max                  0.999837\n",
      "evaluation/Actions Min                 -0.998156\n",
      "time/backward_policy (s)                1.90415\n",
      "time/backward_zf1 (s)                   2.06774\n",
      "time/backward_zf2 (s)                   1.96155\n",
      "time/data sampling (s)                  0.321816\n",
      "time/data storing (s)                   0.0156671\n",
      "time/evaluation sampling (s)            1.74943\n",
      "time/exploration sampling (s)           0.334766\n",
      "time/logging (s)                        0.0217345\n",
      "time/preback_alpha (s)                  0.601509\n",
      "time/preback_policy (s)                 1.10822\n",
      "time/preback_start (s)                  0.152901\n",
      "time/preback_zf (s)                     5.19286\n",
      "time/saving (s)                         0.0252597\n",
      "time/training (s)                       2.37596\n",
      "time/epoch (s)                         17.8336\n",
      "time/total (s)                       1470.75\n",
      "Epoch                                  84\n",
      "---------------------------------  --------------\n",
      "2024-06-10 21:01:00.383885 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 85 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  96000\n",
      "trainer/ZF1 Loss                      102.621\n",
      "trainer/ZF2 Loss                      105.09\n",
      "trainer/ZF Expert Reward               12.5923\n",
      "trainer/ZF Policy Reward                6.39485\n",
      "trainer/ZF CHI2 Term                  142.303\n",
      "trainer/Policy Loss                 -1785.08\n",
      "trainer/Bias Loss                     888.62\n",
      "trainer/Bias Value                     14.8432\n",
      "trainer/Policy Grad Norm              117.716\n",
      "trainer/Policy Param Norm              32.2252\n",
      "trainer/Zf1 Grad Norm                1916.24\n",
      "trainer/Zf1 Param Norm                 93.6374\n",
      "trainer/Zf2 Grad Norm                2510.12\n",
      "trainer/Zf2 Param Norm                 96.9755\n",
      "trainer/Z Expert Predictions Mean    2085.1\n",
      "trainer/Z Expert Predictions Std       72.4181\n",
      "trainer/Z Expert Predictions Max     2183.68\n",
      "trainer/Z Expert Predictions Min     1606.16\n",
      "trainer/Z Policy Predictions Mean    1784.6\n",
      "trainer/Z Policy Predictions Std      525.351\n",
      "trainer/Z Policy Predictions Max     2171.51\n",
      "trainer/Z Policy Predictions Min      -57.9521\n",
      "trainer/Z Expert Targets Mean        2072.5\n",
      "trainer/Z Expert Targets Std           80.5584\n",
      "trainer/Z Expert Targets Max         2176.82\n",
      "trainer/Z Expert Targets Min         1458.85\n",
      "trainer/Z Policy Targets Mean        1778.21\n",
      "trainer/Z Policy Targets Std          519.581\n",
      "trainer/Z Policy Targets Max         2152.29\n",
      "trainer/Z Policy Targets Min          -44.4468\n",
      "trainer/Log Pis Mean                   32.5756\n",
      "trainer/Log Pis Std                    11.6087\n",
      "trainer/Policy mu Mean                  0.225545\n",
      "trainer/Policy mu Std                   2.1621\n",
      "trainer/Policy log std Mean            -4.05132\n",
      "trainer/Policy log std Std              1.07921\n",
      "exploration/num steps total         93348\n",
      "exploration/num paths total           209\n",
      "evaluation/num steps total         644991\n",
      "evaluation/num paths total            906\n",
      "evaluation/path length Mean           971.5\n",
      "evaluation/path length Std             85.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            715\n",
      "evaluation/Rewards Mean                 4.69687\n",
      "evaluation/Rewards Std                  1.16737\n",
      "evaluation/Rewards Max                  6.93705\n",
      "evaluation/Rewards Min                 -2.47788\n",
      "evaluation/Returns Mean              4563\n",
      "evaluation/Returns Std                444.823\n",
      "evaluation/Returns Max               4943.98\n",
      "evaluation/Returns Min               3312.57\n",
      "evaluation/Estimation Bias Mean      1999.17\n",
      "evaluation/Estimation Bias Std        172.871\n",
      "evaluation/EB/Q_True Mean              43.4751\n",
      "evaluation/EB/Q_True Std              133.013\n",
      "evaluation/EB/Q_Pred Mean            2042.64\n",
      "evaluation/EB/Q_Pred Std              103.109\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4563\n",
      "evaluation/Actions Mean                 0.0239836\n",
      "evaluation/Actions Std                  0.530432\n",
      "evaluation/Actions Max                  0.999994\n",
      "evaluation/Actions Min                 -0.999988\n",
      "time/backward_policy (s)                2.08314\n",
      "time/backward_zf1 (s)                   2.2339\n",
      "time/backward_zf2 (s)                   2.16072\n",
      "time/data sampling (s)                  0.329847\n",
      "time/data storing (s)                   0.0154935\n",
      "time/evaluation sampling (s)            1.76277\n",
      "time/exploration sampling (s)           0.339506\n",
      "time/logging (s)                        0.0114931\n",
      "time/preback_alpha (s)                  0.609506\n",
      "time/preback_policy (s)                 1.21469\n",
      "time/preback_start (s)                  0.155327\n",
      "time/preback_zf (s)                     5.23704\n",
      "time/saving (s)                         0.00649574\n",
      "time/training (s)                       2.2367\n",
      "time/epoch (s)                         18.3966\n",
      "time/total (s)                       1489.17\n",
      "Epoch                                  85\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:01:18.666670 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 86 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  97000\n",
      "trainer/ZF1 Loss                       54.5569\n",
      "trainer/ZF2 Loss                       34.1802\n",
      "trainer/ZF Expert Reward               10.863\n",
      "trainer/ZF Policy Reward                0.388958\n",
      "trainer/ZF CHI2 Term                   86.7611\n",
      "trainer/Policy Loss                 -1738.79\n",
      "trainer/Bias Loss                     283.459\n",
      "trainer/Bias Value                     14.6543\n",
      "trainer/Policy Grad Norm               96.777\n",
      "trainer/Policy Param Norm              32.2892\n",
      "trainer/Zf1 Grad Norm                2899.74\n",
      "trainer/Zf1 Param Norm                 93.79\n",
      "trainer/Zf2 Grad Norm                2320.09\n",
      "trainer/Zf2 Param Norm                 97.1258\n",
      "trainer/Z Expert Predictions Mean    2060.26\n",
      "trainer/Z Expert Predictions Std       78.0931\n",
      "trainer/Z Expert Predictions Max     2147.33\n",
      "trainer/Z Expert Predictions Min     1615.34\n",
      "trainer/Z Policy Predictions Mean    1730.06\n",
      "trainer/Z Policy Predictions Std      533.518\n",
      "trainer/Z Policy Predictions Max     2151.18\n",
      "trainer/Z Policy Predictions Min      -56.0542\n",
      "trainer/Z Expert Targets Mean        2049.4\n",
      "trainer/Z Expert Targets Std           80.5217\n",
      "trainer/Z Expert Targets Max         2158.48\n",
      "trainer/Z Expert Targets Min         1598.69\n",
      "trainer/Z Policy Targets Mean        1729.67\n",
      "trainer/Z Policy Targets Std          528.289\n",
      "trainer/Z Policy Targets Max         2153.56\n",
      "trainer/Z Policy Targets Min          -43.2648\n",
      "trainer/Log Pis Mean                   32.2409\n",
      "trainer/Log Pis Std                    12.1028\n",
      "trainer/Policy mu Mean                  0.27909\n",
      "trainer/Policy mu Std                   2.14663\n",
      "trainer/Policy log std Mean            -3.93579\n",
      "trainer/Policy log std Std              1.0447\n",
      "exploration/num steps total         93348\n",
      "exploration/num paths total           209\n",
      "evaluation/num steps total         654047\n",
      "evaluation/num paths total            916\n",
      "evaluation/path length Mean           905.6\n",
      "evaluation/path length Std            283.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             56\n",
      "evaluation/Rewards Mean                 4.53976\n",
      "evaluation/Rewards Std                  1.17186\n",
      "evaluation/Rewards Max                  6.73749\n",
      "evaluation/Rewards Min                 -2.3565\n",
      "evaluation/Returns Mean              4111.21\n",
      "evaluation/Returns Std               1344.51\n",
      "evaluation/Returns Max               4673.64\n",
      "evaluation/Returns Min                 89.7487\n",
      "evaluation/Estimation Bias Mean      1979.18\n",
      "evaluation/Estimation Bias Std        174.01\n",
      "evaluation/EB/Q_True Mean              46.4424\n",
      "evaluation/EB/Q_True Std              136.346\n",
      "evaluation/EB/Q_Pred Mean            2025.62\n",
      "evaluation/EB/Q_Pred Std              109.27\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4111.21\n",
      "evaluation/Actions Mean                 0.0254719\n",
      "evaluation/Actions Std                  0.532724\n",
      "evaluation/Actions Max                  0.999982\n",
      "evaluation/Actions Min                 -0.999081\n",
      "time/backward_policy (s)                1.97529\n",
      "time/backward_zf1 (s)                   2.11033\n",
      "time/backward_zf2 (s)                   2.05018\n",
      "time/data sampling (s)                  0.332129\n",
      "time/data storing (s)                   0.0168559\n",
      "time/evaluation sampling (s)            1.70968\n",
      "time/exploration sampling (s)           0.351388\n",
      "time/logging (s)                        0.0112919\n",
      "time/preback_alpha (s)                  0.609351\n",
      "time/preback_policy (s)                 1.12167\n",
      "time/preback_start (s)                  0.156058\n",
      "time/preback_zf (s)                     5.24926\n",
      "time/saving (s)                         0.00614787\n",
      "time/training (s)                       2.51018\n",
      "time/epoch (s)                         18.2098\n",
      "time/total (s)                       1507.4\n",
      "Epoch                                  86\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:01:36.630805 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 87 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  98000\n",
      "trainer/ZF1 Loss                      120.109\n",
      "trainer/ZF2 Loss                       60.4093\n",
      "trainer/ZF Expert Reward                8.73686\n",
      "trainer/ZF Policy Reward                3.25796\n",
      "trainer/ZF CHI2 Term                  127.413\n",
      "trainer/Policy Loss                 -1744.73\n",
      "trainer/Bias Loss                     385.016\n",
      "trainer/Bias Value                     14.4508\n",
      "trainer/Policy Grad Norm              116.707\n",
      "trainer/Policy Param Norm              32.3505\n",
      "trainer/Zf1 Grad Norm                8404.08\n",
      "trainer/Zf1 Param Norm                 93.9148\n",
      "trainer/Zf2 Grad Norm                7403.16\n",
      "trainer/Zf2 Param Norm                 97.3119\n",
      "trainer/Z Expert Predictions Mean    2027.96\n",
      "trainer/Z Expert Predictions Std      157.151\n",
      "trainer/Z Expert Predictions Max     2124.43\n",
      "trainer/Z Expert Predictions Min     -195.435\n",
      "trainer/Z Policy Predictions Mean    1739.57\n",
      "trainer/Z Policy Predictions Std      493.438\n",
      "trainer/Z Policy Predictions Max     2116.09\n",
      "trainer/Z Policy Predictions Min      -62.0111\n",
      "trainer/Z Expert Targets Mean        2019.22\n",
      "trainer/Z Expert Targets Std          146.075\n",
      "trainer/Z Expert Targets Max         2129.36\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1736.31\n",
      "trainer/Z Policy Targets Std          486.437\n",
      "trainer/Z Policy Targets Max         2098.92\n",
      "trainer/Z Policy Targets Min          -48.3187\n",
      "trainer/Log Pis Mean                   31.9951\n",
      "trainer/Log Pis Std                    12.402\n",
      "trainer/Policy mu Mean                  0.339492\n",
      "trainer/Policy mu Std                   2.11622\n",
      "trainer/Policy log std Mean            -3.97405\n",
      "trainer/Policy log std Std              1.04692\n",
      "exploration/num steps total         93941\n",
      "exploration/num paths total           210\n",
      "evaluation/num steps total         663761\n",
      "evaluation/num paths total            927\n",
      "evaluation/path length Mean           883.091\n",
      "evaluation/path length Std            284.72\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             29\n",
      "evaluation/Rewards Mean                 4.52175\n",
      "evaluation/Rewards Std                  1.25915\n",
      "evaluation/Rewards Max                  6.71864\n",
      "evaluation/Rewards Min                 -3.5355\n",
      "evaluation/Returns Mean              3993.11\n",
      "evaluation/Returns Std               1314.65\n",
      "evaluation/Returns Max               4673.93\n",
      "evaluation/Returns Min                 50.9522\n",
      "evaluation/Estimation Bias Mean      1939.45\n",
      "evaluation/Estimation Bias Std        168.95\n",
      "evaluation/EB/Q_True Mean              42.1925\n",
      "evaluation/EB/Q_True Std              127.916\n",
      "evaluation/EB/Q_Pred Mean            1981.64\n",
      "evaluation/EB/Q_Pred Std              110.867\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3993.11\n",
      "evaluation/Actions Mean                 0.012768\n",
      "evaluation/Actions Std                  0.521739\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91049\n",
      "time/backward_zf1 (s)                   2.05785\n",
      "time/backward_zf2 (s)                   1.97148\n",
      "time/data sampling (s)                  0.326128\n",
      "time/data storing (s)                   0.0146176\n",
      "time/evaluation sampling (s)            1.76358\n",
      "time/exploration sampling (s)           0.325853\n",
      "time/logging (s)                        0.0124382\n",
      "time/preback_alpha (s)                  0.594479\n",
      "time/preback_policy (s)                 1.09086\n",
      "time/preback_start (s)                  0.149985\n",
      "time/preback_zf (s)                     5.19354\n",
      "time/saving (s)                         0.00649672\n",
      "time/training (s)                       2.47277\n",
      "time/epoch (s)                         17.8906\n",
      "time/total (s)                       1525.31\n",
      "Epoch                                  87\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:01:54.642456 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 88 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  99000\n",
      "trainer/ZF1 Loss                       41.1316\n",
      "trainer/ZF2 Loss                       41.9694\n",
      "trainer/ZF Expert Reward               15.0806\n",
      "trainer/ZF Policy Reward                7.25292\n",
      "trainer/ZF CHI2 Term                   80.6613\n",
      "trainer/Policy Loss                 -1768.34\n",
      "trainer/Bias Loss                     188.042\n",
      "trainer/Bias Value                     14.2718\n",
      "trainer/Policy Grad Norm              161.95\n",
      "trainer/Policy Param Norm              32.4122\n",
      "trainer/Zf1 Grad Norm                4361.87\n",
      "trainer/Zf1 Param Norm                 94.0806\n",
      "trainer/Zf2 Grad Norm                4466.11\n",
      "trainer/Zf2 Param Norm                 97.4629\n",
      "trainer/Z Expert Predictions Mean    2015.28\n",
      "trainer/Z Expert Predictions Std       62.7979\n",
      "trainer/Z Expert Predictions Max     2126.42\n",
      "trainer/Z Expert Predictions Min     1651.08\n",
      "trainer/Z Policy Predictions Mean    1757.29\n",
      "trainer/Z Policy Predictions Std      449.553\n",
      "trainer/Z Policy Predictions Max     2104.45\n",
      "trainer/Z Policy Predictions Min      -70.4344\n",
      "trainer/Z Expert Targets Mean        2000.2\n",
      "trainer/Z Expert Targets Std           62.1579\n",
      "trainer/Z Expert Targets Max         2102.03\n",
      "trainer/Z Expert Targets Min         1657.13\n",
      "trainer/Z Policy Targets Mean        1750.04\n",
      "trainer/Z Policy Targets Std          442.624\n",
      "trainer/Z Policy Targets Max         2091.4\n",
      "trainer/Z Policy Targets Min          -46.6995\n",
      "trainer/Log Pis Mean                   31.5991\n",
      "trainer/Log Pis Std                     9.54879\n",
      "trainer/Policy mu Mean                  0.153191\n",
      "trainer/Policy mu Std                   1.84846\n",
      "trainer/Policy log std Mean            -4.08283\n",
      "trainer/Policy log std Std              0.937856\n",
      "exploration/num steps total         93941\n",
      "exploration/num paths total           210\n",
      "evaluation/num steps total         671476\n",
      "evaluation/num paths total            938\n",
      "evaluation/path length Mean           701.364\n",
      "evaluation/path length Std            408.002\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             26\n",
      "evaluation/Rewards Mean                 4.58585\n",
      "evaluation/Rewards Std                  1.19451\n",
      "evaluation/Rewards Max                  6.70799\n",
      "evaluation/Rewards Min                 -2.81255\n",
      "evaluation/Returns Mean              3216.35\n",
      "evaluation/Returns Std               1972.53\n",
      "evaluation/Returns Max               4802.28\n",
      "evaluation/Returns Min                 19.2799\n",
      "evaluation/Estimation Bias Mean      1917.24\n",
      "evaluation/Estimation Bias Std        213.86\n",
      "evaluation/EB/Q_True Mean              56.5823\n",
      "evaluation/EB/Q_True Std              150.847\n",
      "evaluation/EB/Q_Pred Mean            1973.82\n",
      "evaluation/EB/Q_Pred Std              114.233\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3216.35\n",
      "evaluation/Actions Mean                 0.0293479\n",
      "evaluation/Actions Std                  0.54302\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92299\n",
      "time/backward_zf1 (s)                   2.07667\n",
      "time/backward_zf2 (s)                   1.97468\n",
      "time/data sampling (s)                  0.328283\n",
      "time/data storing (s)                   0.0160319\n",
      "time/evaluation sampling (s)            1.71991\n",
      "time/exploration sampling (s)           0.33919\n",
      "time/logging (s)                        0.0138328\n",
      "time/preback_alpha (s)                  0.607\n",
      "time/preback_policy (s)                 1.1028\n",
      "time/preback_start (s)                  0.154239\n",
      "time/preback_zf (s)                     5.22529\n",
      "time/saving (s)                         0.00606327\n",
      "time/training (s)                       2.45592\n",
      "time/epoch (s)                         17.9429\n",
      "time/total (s)                       1543.28\n",
      "Epoch                                  88\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:02:13.068080 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 89 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 100000\n",
      "trainer/ZF1 Loss                       56.1484\n",
      "trainer/ZF2 Loss                       59.3939\n",
      "trainer/ZF Expert Reward               21.334\n",
      "trainer/ZF Policy Reward                7.20867\n",
      "trainer/ZF CHI2 Term                  103.537\n",
      "trainer/Policy Loss                 -1707.03\n",
      "trainer/Bias Loss                     221.62\n",
      "trainer/Bias Value                     14.1127\n",
      "trainer/Policy Grad Norm              106.051\n",
      "trainer/Policy Param Norm              32.4786\n",
      "trainer/Zf1 Grad Norm                3810.35\n",
      "trainer/Zf1 Param Norm                 94.2199\n",
      "trainer/Zf2 Grad Norm                3451.23\n",
      "trainer/Zf2 Param Norm                 97.6173\n",
      "trainer/Z Expert Predictions Mean    1991.94\n",
      "trainer/Z Expert Predictions Std       68.3087\n",
      "trainer/Z Expert Predictions Max     2079.71\n",
      "trainer/Z Expert Predictions Min     1633.35\n",
      "trainer/Z Policy Predictions Mean    1697.12\n",
      "trainer/Z Policy Predictions Std      485.364\n",
      "trainer/Z Policy Predictions Max     2071.36\n",
      "trainer/Z Policy Predictions Min     -101.647\n",
      "trainer/Z Expert Targets Mean        1970.61\n",
      "trainer/Z Expert Targets Std           66.6738\n",
      "trainer/Z Expert Targets Max         2054.82\n",
      "trainer/Z Expert Targets Min         1614.52\n",
      "trainer/Z Policy Targets Mean        1689.91\n",
      "trainer/Z Policy Targets Std          480.915\n",
      "trainer/Z Policy Targets Max         2059.7\n",
      "trainer/Z Policy Targets Min          -72.2866\n",
      "trainer/Log Pis Mean                   31.9599\n",
      "trainer/Log Pis Std                    10.1894\n",
      "trainer/Policy mu Mean                  0.291921\n",
      "trainer/Policy mu Std                   2.01843\n",
      "trainer/Policy log std Mean            -3.96715\n",
      "trainer/Policy log std Std              1.11758\n",
      "exploration/num steps total         93941\n",
      "exploration/num paths total           210\n",
      "evaluation/num steps total         680437\n",
      "evaluation/num paths total            948\n",
      "evaluation/path length Mean           896.1\n",
      "evaluation/path length Std            273.463\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             83\n",
      "evaluation/Rewards Mean                 4.62769\n",
      "evaluation/Rewards Std                  1.15488\n",
      "evaluation/Rewards Max                  6.93819\n",
      "evaluation/Rewards Min                 -3.01383\n",
      "evaluation/Returns Mean              4146.87\n",
      "evaluation/Returns Std               1325.09\n",
      "evaluation/Returns Max               4867.6\n",
      "evaluation/Returns Min                230.197\n",
      "evaluation/Estimation Bias Mean      1896.86\n",
      "evaluation/Estimation Bias Std        183.085\n",
      "evaluation/EB/Q_True Mean              49.0224\n",
      "evaluation/EB/Q_True Std              141.883\n",
      "evaluation/EB/Q_Pred Mean            1945.88\n",
      "evaluation/EB/Q_Pred Std               99.024\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4146.87\n",
      "evaluation/Actions Mean                 0.0269329\n",
      "evaluation/Actions Std                  0.54275\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999949\n",
      "time/backward_policy (s)                2.0495\n",
      "time/backward_zf1 (s)                   2.21921\n",
      "time/backward_zf2 (s)                   2.15455\n",
      "time/data sampling (s)                  0.326327\n",
      "time/data storing (s)                   0.0156536\n",
      "time/evaluation sampling (s)            1.77229\n",
      "time/exploration sampling (s)           0.35137\n",
      "time/logging (s)                        0.0110625\n",
      "time/preback_alpha (s)                  0.605231\n",
      "time/preback_policy (s)                 1.23103\n",
      "time/preback_start (s)                  0.153972\n",
      "time/preback_zf (s)                     5.21828\n",
      "time/saving (s)                         0.00625257\n",
      "time/training (s)                       2.2359\n",
      "time/epoch (s)                         18.3506\n",
      "time/total (s)                       1561.65\n",
      "Epoch                                  89\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:02:31.275578 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 90 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 101000\n",
      "trainer/ZF1 Loss                       51.722\n",
      "trainer/ZF2 Loss                       40.96\n",
      "trainer/ZF Expert Reward               17.2244\n",
      "trainer/ZF Policy Reward                4.72479\n",
      "trainer/ZF CHI2 Term                   90.48\n",
      "trainer/Policy Loss                 -1706.19\n",
      "trainer/Bias Loss                     332.749\n",
      "trainer/Bias Value                     13.9731\n",
      "trainer/Policy Grad Norm              133.845\n",
      "trainer/Policy Param Norm              32.5367\n",
      "trainer/Zf1 Grad Norm                3910.91\n",
      "trainer/Zf1 Param Norm                 94.3617\n",
      "trainer/Zf2 Grad Norm                3011.12\n",
      "trainer/Zf2 Param Norm                 97.787\n",
      "trainer/Z Expert Predictions Mean    1960.68\n",
      "trainer/Z Expert Predictions Std       73.752\n",
      "trainer/Z Expert Predictions Max     2050.88\n",
      "trainer/Z Expert Predictions Min     1531.44\n",
      "trainer/Z Policy Predictions Mean    1697.97\n",
      "trainer/Z Policy Predictions Std      471.289\n",
      "trainer/Z Policy Predictions Max     2057.22\n",
      "trainer/Z Policy Predictions Min     -128.758\n",
      "trainer/Z Expert Targets Mean        1943.45\n",
      "trainer/Z Expert Targets Std           77.6468\n",
      "trainer/Z Expert Targets Max         2038.76\n",
      "trainer/Z Expert Targets Min         1487.26\n",
      "trainer/Z Policy Targets Mean        1693.25\n",
      "trainer/Z Policy Targets Std          460.525\n",
      "trainer/Z Policy Targets Max         2036.4\n",
      "trainer/Z Policy Targets Min          -68.5412\n",
      "trainer/Log Pis Mean                   31.959\n",
      "trainer/Log Pis Std                    10.5269\n",
      "trainer/Policy mu Mean                  0.196488\n",
      "trainer/Policy mu Std                   2.09707\n",
      "trainer/Policy log std Mean            -4.08087\n",
      "trainer/Policy log std Std              1.08084\n",
      "exploration/num steps total         94941\n",
      "exploration/num paths total           211\n",
      "evaluation/num steps total         687689\n",
      "evaluation/num paths total            961\n",
      "evaluation/path length Mean           557.846\n",
      "evaluation/path length Std            428.812\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 4.49429\n",
      "evaluation/Rewards Std                  1.18404\n",
      "evaluation/Rewards Max                  7.14981\n",
      "evaluation/Rewards Min                 -2.38354\n",
      "evaluation/Returns Mean              2507.12\n",
      "evaluation/Returns Std               2011.02\n",
      "evaluation/Returns Max               4724.72\n",
      "evaluation/Returns Min                  4.07395\n",
      "evaluation/Estimation Bias Mean      1846.66\n",
      "evaluation/Estimation Bias Std        208.216\n",
      "evaluation/EB/Q_True Mean              57.8707\n",
      "evaluation/EB/Q_True Std              149.236\n",
      "evaluation/EB/Q_Pred Mean            1904.53\n",
      "evaluation/EB/Q_Pred Std              110.319\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2507.12\n",
      "evaluation/Actions Mean                 0.0334717\n",
      "evaluation/Actions Std                  0.535448\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999921\n",
      "time/backward_policy (s)                1.95334\n",
      "time/backward_zf1 (s)                   2.09525\n",
      "time/backward_zf2 (s)                   2.00589\n",
      "time/data sampling (s)                  0.333418\n",
      "time/data storing (s)                   0.0148797\n",
      "time/evaluation sampling (s)            1.76621\n",
      "time/exploration sampling (s)           0.33089\n",
      "time/logging (s)                        0.0108107\n",
      "time/preback_alpha (s)                  0.606802\n",
      "time/preback_policy (s)                 1.11028\n",
      "time/preback_start (s)                  0.153378\n",
      "time/preback_zf (s)                     5.22114\n",
      "time/saving (s)                         0.0073743\n",
      "time/training (s)                       2.52835\n",
      "time/epoch (s)                         18.138\n",
      "time/total (s)                       1579.8\n",
      "Epoch                                  90\n",
      "---------------------------------  --------------\n",
      "2024-06-10 21:02:49.752940 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 91 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 102000\n",
      "trainer/ZF1 Loss                       25.5907\n",
      "trainer/ZF2 Loss                        8.61263\n",
      "trainer/ZF Expert Reward                9.81929\n",
      "trainer/ZF Policy Reward               -0.522793\n",
      "trainer/ZF CHI2 Term                   59.5002\n",
      "trainer/Policy Loss                 -1686.97\n",
      "trainer/Bias Loss                     156.64\n",
      "trainer/Bias Value                     13.828\n",
      "trainer/Policy Grad Norm              167.709\n",
      "trainer/Policy Param Norm              32.6007\n",
      "trainer/Zf1 Grad Norm                6680.78\n",
      "trainer/Zf1 Param Norm                 94.5094\n",
      "trainer/Zf2 Grad Norm                2381.83\n",
      "trainer/Zf2 Param Norm                 97.9249\n",
      "trainer/Z Expert Predictions Mean    1937.06\n",
      "trainer/Z Expert Predictions Std       58.1019\n",
      "trainer/Z Expert Predictions Max     2027.79\n",
      "trainer/Z Expert Predictions Min     1580.57\n",
      "trainer/Z Policy Predictions Mean    1678.33\n",
      "trainer/Z Policy Predictions Std      479.312\n",
      "trainer/Z Policy Predictions Max     2008.65\n",
      "trainer/Z Policy Predictions Min      -85.9458\n",
      "trainer/Z Expert Targets Mean        1927.24\n",
      "trainer/Z Expert Targets Std           56.2084\n",
      "trainer/Z Expert Targets Max         2019.68\n",
      "trainer/Z Expert Targets Min         1616.78\n",
      "trainer/Z Policy Targets Mean        1678.85\n",
      "trainer/Z Policy Targets Std          473.562\n",
      "trainer/Z Policy Targets Max         2005.01\n",
      "trainer/Z Policy Targets Min          -74.7894\n",
      "trainer/Log Pis Mean                   32.3803\n",
      "trainer/Log Pis Std                    10.9623\n",
      "trainer/Policy mu Mean                  0.3119\n",
      "trainer/Policy mu Std                   2.10605\n",
      "trainer/Policy log std Mean            -4.10086\n",
      "trainer/Policy log std Std              1.06543\n",
      "exploration/num steps total         95941\n",
      "exploration/num paths total           212\n",
      "evaluation/num steps total         697624\n",
      "evaluation/num paths total            971\n",
      "evaluation/path length Mean           993.5\n",
      "evaluation/path length Std             19.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            935\n",
      "evaluation/Rewards Mean                 4.69721\n",
      "evaluation/Rewards Std                  1.01422\n",
      "evaluation/Rewards Max                  6.7318\n",
      "evaluation/Rewards Min                 -2.0614\n",
      "evaluation/Returns Mean              4666.68\n",
      "evaluation/Returns Std                113.39\n",
      "evaluation/Returns Max               4774.13\n",
      "evaluation/Returns Min               4390.27\n",
      "evaluation/Estimation Bias Mean      1861.01\n",
      "evaluation/Estimation Bias Std        151.027\n",
      "evaluation/EB/Q_True Mean              43.5416\n",
      "evaluation/EB/Q_True Std              133.619\n",
      "evaluation/EB/Q_Pred Mean            1904.55\n",
      "evaluation/EB/Q_Pred Std               70.258\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4666.68\n",
      "evaluation/Actions Mean                 0.0177882\n",
      "evaluation/Actions Std                  0.530918\n",
      "evaluation/Actions Max                  0.999612\n",
      "evaluation/Actions Min                 -0.99957\n",
      "time/backward_policy (s)                2.02688\n",
      "time/backward_zf1 (s)                   2.21181\n",
      "time/backward_zf2 (s)                   2.09588\n",
      "time/data sampling (s)                  0.328962\n",
      "time/data storing (s)                   0.0146443\n",
      "time/evaluation sampling (s)            1.76941\n",
      "time/exploration sampling (s)           0.327958\n",
      "time/logging (s)                        0.013354\n",
      "time/preback_alpha (s)                  0.60626\n",
      "time/preback_policy (s)                 1.17378\n",
      "time/preback_start (s)                  0.15355\n",
      "time/preback_zf (s)                     5.27221\n",
      "time/saving (s)                         0.00672635\n",
      "time/training (s)                       2.40642\n",
      "time/epoch (s)                         18.4078\n",
      "time/total (s)                       1598.23\n",
      "Epoch                                  91\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:03:08.154208 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 92 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 103000\n",
      "trainer/ZF1 Loss                       97.102\n",
      "trainer/ZF2 Loss                       73.9152\n",
      "trainer/ZF Expert Reward               18.332\n",
      "trainer/ZF Policy Reward                3.4036\n",
      "trainer/ZF CHI2 Term                  131.235\n",
      "trainer/Policy Loss                 -1629.72\n",
      "trainer/Bias Loss                     748.909\n",
      "trainer/Bias Value                     13.698\n",
      "trainer/Policy Grad Norm              133.133\n",
      "trainer/Policy Param Norm              32.668\n",
      "trainer/Zf1 Grad Norm                7918.66\n",
      "trainer/Zf1 Param Norm                 94.6447\n",
      "trainer/Zf2 Grad Norm                2604.4\n",
      "trainer/Zf2 Param Norm                 98.0799\n",
      "trainer/Z Expert Predictions Mean    1908.87\n",
      "trainer/Z Expert Predictions Std      136.44\n",
      "trainer/Z Expert Predictions Max     2001.13\n",
      "trainer/Z Expert Predictions Min      -87.1396\n",
      "trainer/Z Policy Predictions Mean    1622.92\n",
      "trainer/Z Policy Predictions Std      493.659\n",
      "trainer/Z Policy Predictions Max     1982.02\n",
      "trainer/Z Policy Predictions Min      -87.4912\n",
      "trainer/Z Expert Targets Mean        1890.54\n",
      "trainer/Z Expert Targets Std          137.075\n",
      "trainer/Z Expert Targets Max         1981.62\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1619.52\n",
      "trainer/Z Policy Targets Std          485.513\n",
      "trainer/Z Policy Targets Max         1974.15\n",
      "trainer/Z Policy Targets Min          -66.0616\n",
      "trainer/Log Pis Mean                   31.1091\n",
      "trainer/Log Pis Std                     9.28178\n",
      "trainer/Policy mu Mean                  0.214769\n",
      "trainer/Policy mu Std                   2.15352\n",
      "trainer/Policy log std Mean            -3.88211\n",
      "trainer/Policy log std Std              1.2066\n",
      "exploration/num steps total         96941\n",
      "exploration/num paths total           213\n",
      "evaluation/num steps total         707624\n",
      "evaluation/num paths total            981\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.00423\n",
      "evaluation/Rewards Std                  2.19372\n",
      "evaluation/Rewards Max                  6.7468\n",
      "evaluation/Rewards Min                 -3.73264\n",
      "evaluation/Returns Mean              4004.23\n",
      "evaluation/Returns Std               1857.41\n",
      "evaluation/Returns Max               4812.97\n",
      "evaluation/Returns Min              -1551.56\n",
      "evaluation/Estimation Bias Mean      1738.52\n",
      "evaluation/Estimation Bias Std        346.873\n",
      "evaluation/EB/Q_True Mean              43.401\n",
      "evaluation/EB/Q_True Std              133.6\n",
      "evaluation/EB/Q_Pred Mean            1781.92\n",
      "evaluation/EB/Q_Pred Std              334.163\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4004.23\n",
      "evaluation/Actions Mean                 0.0274797\n",
      "evaluation/Actions Std                  0.570171\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98015\n",
      "time/backward_zf1 (s)                   2.16451\n",
      "time/backward_zf2 (s)                   2.06203\n",
      "time/data sampling (s)                  0.340238\n",
      "time/data storing (s)                   0.0158645\n",
      "time/evaluation sampling (s)            1.82864\n",
      "time/exploration sampling (s)           0.341509\n",
      "time/logging (s)                        0.0121461\n",
      "time/preback_alpha (s)                  0.611801\n",
      "time/preback_policy (s)                 1.13417\n",
      "time/preback_start (s)                  0.153994\n",
      "time/preback_zf (s)                     5.24151\n",
      "time/saving (s)                         0.00625694\n",
      "time/training (s)                       2.43389\n",
      "time/epoch (s)                         18.3267\n",
      "time/total (s)                       1616.58\n",
      "Epoch                                  92\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:03:26.914516 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 93 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 104000\n",
      "trainer/ZF1 Loss                       28.4865\n",
      "trainer/ZF2 Loss                       24.2941\n",
      "trainer/ZF Expert Reward               12.7939\n",
      "trainer/ZF Policy Reward                0.693197\n",
      "trainer/ZF CHI2 Term                   69.1052\n",
      "trainer/Policy Loss                 -1664.75\n",
      "trainer/Bias Loss                     213.803\n",
      "trainer/Bias Value                     13.5838\n",
      "trainer/Policy Grad Norm              102.714\n",
      "trainer/Policy Param Norm              32.7357\n",
      "trainer/Zf1 Grad Norm                5068.92\n",
      "trainer/Zf1 Param Norm                 94.8082\n",
      "trainer/Zf2 Grad Norm                3525.34\n",
      "trainer/Zf2 Param Norm                 98.2494\n",
      "trainer/Z Expert Predictions Mean    1898.05\n",
      "trainer/Z Expert Predictions Std       48.6124\n",
      "trainer/Z Expert Predictions Max     1979.62\n",
      "trainer/Z Expert Predictions Min     1644.3\n",
      "trainer/Z Policy Predictions Mean    1659.34\n",
      "trainer/Z Policy Predictions Std      401\n",
      "trainer/Z Policy Predictions Max     1970.68\n",
      "trainer/Z Policy Predictions Min      -47.6346\n",
      "trainer/Z Expert Targets Mean        1885.25\n",
      "trainer/Z Expert Targets Std           47.4985\n",
      "trainer/Z Expert Targets Max         1972.21\n",
      "trainer/Z Expert Targets Min         1654.45\n",
      "trainer/Z Policy Targets Mean        1658.65\n",
      "trainer/Z Policy Targets Std          394.688\n",
      "trainer/Z Policy Targets Max         1947.43\n",
      "trainer/Z Policy Targets Min          -43.7662\n",
      "trainer/Log Pis Mean                   30.9234\n",
      "trainer/Log Pis Std                     9.85518\n",
      "trainer/Policy mu Mean                  0.230473\n",
      "trainer/Policy mu Std                   1.92746\n",
      "trainer/Policy log std Mean            -4.02748\n",
      "trainer/Policy log std Std              1.04053\n",
      "exploration/num steps total         99941\n",
      "exploration/num paths total           216\n",
      "evaluation/num steps total         717294\n",
      "evaluation/num paths total            991\n",
      "evaluation/path length Mean           967\n",
      "evaluation/path length Std             80.2297\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            733\n",
      "evaluation/Rewards Mean                 4.6608\n",
      "evaluation/Rewards Std                  1.06534\n",
      "evaluation/Rewards Max                  6.9538\n",
      "evaluation/Rewards Min                 -2.11163\n",
      "evaluation/Returns Mean              4507\n",
      "evaluation/Returns Std                406.847\n",
      "evaluation/Returns Max               4798.66\n",
      "evaluation/Returns Min               3386.79\n",
      "evaluation/Estimation Bias Mean      1805.71\n",
      "evaluation/Estimation Bias Std        155.265\n",
      "evaluation/EB/Q_True Mean              44.5848\n",
      "evaluation/EB/Q_True Std              134.739\n",
      "evaluation/EB/Q_Pred Mean            1850.3\n",
      "evaluation/EB/Q_Pred Std               78.1056\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4507\n",
      "evaluation/Actions Mean                 0.0143958\n",
      "evaluation/Actions Std                  0.541643\n",
      "evaluation/Actions Max                  0.999802\n",
      "evaluation/Actions Min                 -0.99944\n",
      "time/backward_policy (s)                2.09166\n",
      "time/backward_zf1 (s)                   2.2611\n",
      "time/backward_zf2 (s)                   2.16144\n",
      "time/data sampling (s)                  0.352369\n",
      "time/data storing (s)                   0.015432\n",
      "time/evaluation sampling (s)            1.7617\n",
      "time/exploration sampling (s)           0.343491\n",
      "time/logging (s)                        0.0121561\n",
      "time/preback_alpha (s)                  0.624616\n",
      "time/preback_policy (s)                 1.17522\n",
      "time/preback_start (s)                  0.158005\n",
      "time/preback_zf (s)                     5.29758\n",
      "time/saving (s)                         0.00642371\n",
      "time/training (s)                       2.42493\n",
      "time/epoch (s)                         18.6861\n",
      "time/total (s)                       1635.29\n",
      "Epoch                                  93\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:03:45.356078 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 94 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 105000\n",
      "trainer/ZF1 Loss                       58.066\n",
      "trainer/ZF2 Loss                       33.6429\n",
      "trainer/ZF Expert Reward                5.77795\n",
      "trainer/ZF Policy Reward                0.332496\n",
      "trainer/ZF CHI2 Term                   82.8107\n",
      "trainer/Policy Loss                 -1611.35\n",
      "trainer/Bias Loss                     125.717\n",
      "trainer/Bias Value                     13.4555\n",
      "trainer/Policy Grad Norm              102.502\n",
      "trainer/Policy Param Norm              32.7991\n",
      "trainer/Zf1 Grad Norm                2868.51\n",
      "trainer/Zf1 Param Norm                 94.9593\n",
      "trainer/Zf2 Grad Norm                3366.47\n",
      "trainer/Zf2 Param Norm                 98.4098\n",
      "trainer/Z Expert Predictions Mean    1866.34\n",
      "trainer/Z Expert Predictions Std       49.1843\n",
      "trainer/Z Expert Predictions Max     1944.55\n",
      "trainer/Z Expert Predictions Min     1556.22\n",
      "trainer/Z Policy Predictions Mean    1605.96\n",
      "trainer/Z Policy Predictions Std      452.716\n",
      "trainer/Z Policy Predictions Max     1923.22\n",
      "trainer/Z Policy Predictions Min      -52.1242\n",
      "trainer/Z Expert Targets Mean        1860.56\n",
      "trainer/Z Expert Targets Std           49.314\n",
      "trainer/Z Expert Targets Max         1944.03\n",
      "trainer/Z Expert Targets Min         1513.27\n",
      "trainer/Z Policy Targets Mean        1605.63\n",
      "trainer/Z Policy Targets Std          453.254\n",
      "trainer/Z Policy Targets Max         1918.84\n",
      "trainer/Z Policy Targets Min          -34.1267\n",
      "trainer/Log Pis Mean                   31.8291\n",
      "trainer/Log Pis Std                    10.5308\n",
      "trainer/Policy mu Mean                  0.221617\n",
      "trainer/Policy mu Std                   2.15478\n",
      "trainer/Policy log std Mean            -3.9628\n",
      "trainer/Policy log std Std              1.11232\n",
      "exploration/num steps total         99941\n",
      "exploration/num paths total           216\n",
      "evaluation/num steps total         726905\n",
      "evaluation/num paths total           1001\n",
      "evaluation/path length Mean           961.1\n",
      "evaluation/path length Std            116.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            611\n",
      "evaluation/Rewards Mean                 4.60413\n",
      "evaluation/Rewards Std                  1.08945\n",
      "evaluation/Rewards Max                  6.84237\n",
      "evaluation/Rewards Min                 -2.1798\n",
      "evaluation/Returns Mean              4425.03\n",
      "evaluation/Returns Std                551.03\n",
      "evaluation/Returns Max               4882.9\n",
      "evaluation/Returns Min               2812.46\n",
      "evaluation/Estimation Bias Mean      1781.41\n",
      "evaluation/Estimation Bias Std        147.585\n",
      "evaluation/EB/Q_True Mean              42.5378\n",
      "evaluation/EB/Q_True Std              128.046\n",
      "evaluation/EB/Q_Pred Mean            1823.95\n",
      "evaluation/EB/Q_Pred Std               74.745\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4425.03\n",
      "evaluation/Actions Mean                 0.018255\n",
      "evaluation/Actions Std                  0.530994\n",
      "evaluation/Actions Max                  0.999778\n",
      "evaluation/Actions Min                 -0.999368\n",
      "time/backward_policy (s)                1.99995\n",
      "time/backward_zf1 (s)                   2.18238\n",
      "time/backward_zf2 (s)                   2.0625\n",
      "time/data sampling (s)                  0.348941\n",
      "time/data storing (s)                   0.0163226\n",
      "time/evaluation sampling (s)            1.81009\n",
      "time/exploration sampling (s)           0.340974\n",
      "time/logging (s)                        0.0117802\n",
      "time/preback_alpha (s)                  0.613366\n",
      "time/preback_policy (s)                 1.13754\n",
      "time/preback_start (s)                  0.154113\n",
      "time/preback_zf (s)                     5.24884\n",
      "time/saving (s)                         0.00651365\n",
      "time/training (s)                       2.43645\n",
      "time/epoch (s)                         18.3698\n",
      "time/total (s)                       1653.68\n",
      "Epoch                                  94\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:04:03.036936 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 95 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 106000\n",
      "trainer/ZF1 Loss                        6.49867\n",
      "trainer/ZF2 Loss                        8.7472\n",
      "trainer/ZF Expert Reward                7.98716\n",
      "trainer/ZF Policy Reward                0.48332\n",
      "trainer/ZF CHI2 Term                   46.358\n",
      "trainer/Policy Loss                 -1583.76\n",
      "trainer/Bias Loss                      96.1869\n",
      "trainer/Bias Value                     13.3728\n",
      "trainer/Policy Grad Norm               94.8075\n",
      "trainer/Policy Param Norm              32.867\n",
      "trainer/Zf1 Grad Norm                2402.36\n",
      "trainer/Zf1 Param Norm                 95.0748\n",
      "trainer/Zf2 Grad Norm                2572.13\n",
      "trainer/Zf2 Param Norm                 98.5388\n",
      "trainer/Z Expert Predictions Mean    1832.75\n",
      "trainer/Z Expert Predictions Std       69.2764\n",
      "trainer/Z Expert Predictions Max     1919.21\n",
      "trainer/Z Expert Predictions Min     1306.9\n",
      "trainer/Z Policy Predictions Mean    1580.97\n",
      "trainer/Z Policy Predictions Std      452.607\n",
      "trainer/Z Policy Predictions Max     1895.81\n",
      "trainer/Z Policy Predictions Min      -26.8144\n",
      "trainer/Z Expert Targets Mean        1824.76\n",
      "trainer/Z Expert Targets Std           69.9556\n",
      "trainer/Z Expert Targets Max         1903.62\n",
      "trainer/Z Expert Targets Min         1254.31\n",
      "trainer/Z Policy Targets Mean        1580.48\n",
      "trainer/Z Policy Targets Std          446.902\n",
      "trainer/Z Policy Targets Max         1884.31\n",
      "trainer/Z Policy Targets Min          -10.8971\n",
      "trainer/Log Pis Mean                   31.5467\n",
      "trainer/Log Pis Std                    10.8714\n",
      "trainer/Policy mu Mean                  0.222251\n",
      "trainer/Policy mu Std                   2.10598\n",
      "trainer/Policy log std Mean            -4.00722\n",
      "trainer/Policy log std Std              1.01618\n",
      "exploration/num steps total        102941\n",
      "exploration/num paths total           219\n",
      "evaluation/num steps total         736124\n",
      "evaluation/num paths total           1013\n",
      "evaluation/path length Mean           768.25\n",
      "evaluation/path length Std            361.611\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             12\n",
      "evaluation/Rewards Mean                 4.67603\n",
      "evaluation/Rewards Std                  1.13516\n",
      "evaluation/Rewards Max                  6.96452\n",
      "evaluation/Rewards Min                 -1.85029\n",
      "evaluation/Returns Mean              3592.36\n",
      "evaluation/Returns Std               1732\n",
      "evaluation/Returns Max               4870.95\n",
      "evaluation/Returns Min                  8.32243\n",
      "evaluation/Estimation Bias Mean      1758.1\n",
      "evaluation/Estimation Bias Std        159.586\n",
      "evaluation/EB/Q_True Mean              45.2685\n",
      "evaluation/EB/Q_True Std              132.757\n",
      "evaluation/EB/Q_Pred Mean            1803.37\n",
      "evaluation/EB/Q_Pred Std               79.8048\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3592.36\n",
      "evaluation/Actions Mean                 0.0218084\n",
      "evaluation/Actions Std                  0.544009\n",
      "evaluation/Actions Max                  0.999981\n",
      "evaluation/Actions Min                 -0.999503\n",
      "time/backward_policy (s)                1.8469\n",
      "time/backward_zf1 (s)                   2.00544\n",
      "time/backward_zf2 (s)                   1.96495\n",
      "time/data sampling (s)                  0.3111\n",
      "time/data storing (s)                   0.014442\n",
      "time/evaluation sampling (s)            1.91248\n",
      "time/exploration sampling (s)           0.331003\n",
      "time/logging (s)                        0.0110904\n",
      "time/preback_alpha (s)                  0.581214\n",
      "time/preback_policy (s)                 1.10671\n",
      "time/preback_start (s)                  0.150504\n",
      "time/preback_zf (s)                     5.12455\n",
      "time/saving (s)                         0.0179963\n",
      "time/training (s)                       2.23054\n",
      "time/epoch (s)                         17.6089\n",
      "time/total (s)                       1671.31\n",
      "Epoch                                  95\n",
      "---------------------------------  --------------\n",
      "2024-06-10 21:04:20.485497 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 96 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 107000\n",
      "trainer/ZF1 Loss                       25.0592\n",
      "trainer/ZF2 Loss                       15.4164\n",
      "trainer/ZF Expert Reward               10.1857\n",
      "trainer/ZF Policy Reward                2.77015\n",
      "trainer/ZF CHI2 Term                   61.5452\n",
      "trainer/Policy Loss                 -1495\n",
      "trainer/Bias Loss                      95.2761\n",
      "trainer/Bias Value                     13.2757\n",
      "trainer/Policy Grad Norm              102.214\n",
      "trainer/Policy Param Norm              32.9368\n",
      "trainer/Zf1 Grad Norm                2365.44\n",
      "trainer/Zf1 Param Norm                 95.2215\n",
      "trainer/Zf2 Grad Norm                2188.05\n",
      "trainer/Zf2 Param Norm                 98.6774\n",
      "trainer/Z Expert Predictions Mean    1816.81\n",
      "trainer/Z Expert Predictions Std       54.824\n",
      "trainer/Z Expert Predictions Max     1890.64\n",
      "trainer/Z Expert Predictions Min     1401.51\n",
      "trainer/Z Policy Predictions Mean    1485.06\n",
      "trainer/Z Policy Predictions Std      513.09\n",
      "trainer/Z Policy Predictions Max     1869.51\n",
      "trainer/Z Policy Predictions Min      -36.1877\n",
      "trainer/Z Expert Targets Mean        1806.63\n",
      "trainer/Z Expert Targets Std           54.571\n",
      "trainer/Z Expert Targets Max         1873.41\n",
      "trainer/Z Expert Targets Min         1378.23\n",
      "trainer/Z Policy Targets Mean        1482.29\n",
      "trainer/Z Policy Targets Std          507.754\n",
      "trainer/Z Policy Targets Max         1871.78\n",
      "trainer/Z Policy Targets Min          -23.875\n",
      "trainer/Log Pis Mean                   34.2342\n",
      "trainer/Log Pis Std                    12.8556\n",
      "trainer/Policy mu Mean                  0.375834\n",
      "trainer/Policy mu Std                   2.55196\n",
      "trainer/Policy log std Mean            -3.89442\n",
      "trainer/Policy log std Std              1.15001\n",
      "exploration/num steps total        102941\n",
      "exploration/num paths total           219\n",
      "evaluation/num steps total         742308\n",
      "evaluation/num paths total           1024\n",
      "evaluation/path length Mean           562.182\n",
      "evaluation/path length Std            379.778\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             39\n",
      "evaluation/Rewards Mean                 4.53568\n",
      "evaluation/Rewards Std                  1.28944\n",
      "evaluation/Rewards Max                  6.78144\n",
      "evaluation/Rewards Min                 -2.3962\n",
      "evaluation/Returns Mean              2549.88\n",
      "evaluation/Returns Std               1860\n",
      "evaluation/Returns Max               4797.67\n",
      "evaluation/Returns Min                 91.2311\n",
      "evaluation/Estimation Bias Mean      1691.78\n",
      "evaluation/Estimation Bias Std        208.327\n",
      "evaluation/EB/Q_True Mean              71.0658\n",
      "evaluation/EB/Q_True Std              166.33\n",
      "evaluation/EB/Q_Pred Mean            1762.85\n",
      "evaluation/EB/Q_Pred Std              103.776\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2549.88\n",
      "evaluation/Actions Mean                 0.0291267\n",
      "evaluation/Actions Std                  0.542887\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999974\n",
      "time/backward_policy (s)                1.80984\n",
      "time/backward_zf1 (s)                   1.96891\n",
      "time/backward_zf2 (s)                   1.8848\n",
      "time/data sampling (s)                  0.323326\n",
      "time/data storing (s)                   0.0149101\n",
      "time/evaluation sampling (s)            1.72571\n",
      "time/exploration sampling (s)           0.324555\n",
      "time/logging (s)                        0.00840525\n",
      "time/preback_alpha (s)                  0.584198\n",
      "time/preback_policy (s)                 1.03197\n",
      "time/preback_start (s)                  0.147959\n",
      "time/preback_zf (s)                     5.13463\n",
      "time/saving (s)                         0.00603555\n",
      "time/training (s)                       2.41365\n",
      "time/epoch (s)                         17.3789\n",
      "time/total (s)                       1688.71\n",
      "Epoch                                  96\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:04:38.201534 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 97 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 108000\n",
      "trainer/ZF1 Loss                       16.0374\n",
      "trainer/ZF2 Loss                       22.4111\n",
      "trainer/ZF Expert Reward               16.9075\n",
      "trainer/ZF Policy Reward                4.8479\n",
      "trainer/ZF CHI2 Term                   62.1742\n",
      "trainer/Policy Loss                 -1586.91\n",
      "trainer/Bias Loss                     179.299\n",
      "trainer/Bias Value                     13.1765\n",
      "trainer/Policy Grad Norm               83.5119\n",
      "trainer/Policy Param Norm              33.0032\n",
      "trainer/Zf1 Grad Norm                1559.07\n",
      "trainer/Zf1 Param Norm                 95.3603\n",
      "trainer/Zf2 Grad Norm                1684.85\n",
      "trainer/Zf2 Param Norm                 98.8099\n",
      "trainer/Z Expert Predictions Mean    1798.79\n",
      "trainer/Z Expert Predictions Std       46.647\n",
      "trainer/Z Expert Predictions Max     1866.81\n",
      "trainer/Z Expert Predictions Min     1580.97\n",
      "trainer/Z Policy Predictions Mean    1582.57\n",
      "trainer/Z Policy Predictions Std      394.767\n",
      "trainer/Z Policy Predictions Max     1848.54\n",
      "trainer/Z Policy Predictions Min      -42.8787\n",
      "trainer/Z Expert Targets Mean        1781.89\n",
      "trainer/Z Expert Targets Std           49.916\n",
      "trainer/Z Expert Targets Max         1863.18\n",
      "trainer/Z Expert Targets Min         1523.67\n",
      "trainer/Z Policy Targets Mean        1577.73\n",
      "trainer/Z Policy Targets Std          387.421\n",
      "trainer/Z Policy Targets Max         1848.3\n",
      "trainer/Z Policy Targets Min          -37.5749\n",
      "trainer/Log Pis Mean                   31.2023\n",
      "trainer/Log Pis Std                     9.4954\n",
      "trainer/Policy mu Mean                  0.257713\n",
      "trainer/Policy mu Std                   1.9901\n",
      "trainer/Policy log std Mean            -4.03443\n",
      "trainer/Policy log std Std              1.10732\n",
      "exploration/num steps total        104260\n",
      "exploration/num paths total           221\n",
      "evaluation/num steps total         750842\n",
      "evaluation/num paths total           1034\n",
      "evaluation/path length Mean           853.4\n",
      "evaluation/path length Std            309.41\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             46\n",
      "evaluation/Rewards Mean                 4.4028\n",
      "evaluation/Rewards Std                  1.03501\n",
      "evaluation/Rewards Max                  6.33979\n",
      "evaluation/Rewards Min                 -1.84249\n",
      "evaluation/Returns Mean              3757.35\n",
      "evaluation/Returns Std               1415.44\n",
      "evaluation/Returns Max               4622.9\n",
      "evaluation/Returns Min                 80.4313\n",
      "evaluation/Estimation Bias Mean      1716.22\n",
      "evaluation/Estimation Bias Std        155.48\n",
      "evaluation/EB/Q_True Mean              46.6247\n",
      "evaluation/EB/Q_True Std              131.368\n",
      "evaluation/EB/Q_Pred Mean            1762.85\n",
      "evaluation/EB/Q_Pred Std               69.9481\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3757.35\n",
      "evaluation/Actions Mean                 0.0143588\n",
      "evaluation/Actions Std                  0.527665\n",
      "evaluation/Actions Max                  0.999828\n",
      "evaluation/Actions Min                 -0.999317\n",
      "time/backward_policy (s)                1.83622\n",
      "time/backward_zf1 (s)                   2.0389\n",
      "time/backward_zf2 (s)                   1.92279\n",
      "time/data sampling (s)                  0.294125\n",
      "time/data storing (s)                   0.0143784\n",
      "time/evaluation sampling (s)            1.77452\n",
      "time/exploration sampling (s)           0.325453\n",
      "time/logging (s)                        0.0118225\n",
      "time/preback_alpha (s)                  0.577686\n",
      "time/preback_policy (s)                 1.04831\n",
      "time/preback_start (s)                  0.1473\n",
      "time/preback_zf (s)                     5.19256\n",
      "time/saving (s)                         0.00640072\n",
      "time/training (s)                       2.46099\n",
      "time/epoch (s)                         17.6515\n",
      "time/total (s)                       1706.38\n",
      "Epoch                                  97\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:04:56.897909 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 98 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 109000\n",
      "trainer/ZF1 Loss                       23.4924\n",
      "trainer/ZF2 Loss                       13.1177\n",
      "trainer/ZF Expert Reward               13.8257\n",
      "trainer/ZF Policy Reward                3.40843\n",
      "trainer/ZF CHI2 Term                   60.1719\n",
      "trainer/Policy Loss                 -1541.01\n",
      "trainer/Bias Loss                      79.2687\n",
      "trainer/Bias Value                     13.0804\n",
      "trainer/Policy Grad Norm              109.397\n",
      "trainer/Policy Param Norm              33.0647\n",
      "trainer/Zf1 Grad Norm                6105.88\n",
      "trainer/Zf1 Param Norm                 95.4926\n",
      "trainer/Zf2 Grad Norm                5151.16\n",
      "trainer/Zf2 Param Norm                 98.9622\n",
      "trainer/Z Expert Predictions Mean    1776.84\n",
      "trainer/Z Expert Predictions Std       54.283\n",
      "trainer/Z Expert Predictions Max     1847.15\n",
      "trainer/Z Expert Predictions Min     1481.47\n",
      "trainer/Z Policy Predictions Mean    1529.91\n",
      "trainer/Z Policy Predictions Std      439.768\n",
      "trainer/Z Policy Predictions Max     1846.36\n",
      "trainer/Z Policy Predictions Min       -7.07953\n",
      "trainer/Z Expert Targets Mean        1763.01\n",
      "trainer/Z Expert Targets Std           54.9744\n",
      "trainer/Z Expert Targets Max         1828.62\n",
      "trainer/Z Expert Targets Min         1460.51\n",
      "trainer/Z Policy Targets Mean        1526.5\n",
      "trainer/Z Policy Targets Std          434.444\n",
      "trainer/Z Policy Targets Max         1828.71\n",
      "trainer/Z Policy Targets Min           -1.75346\n",
      "trainer/Log Pis Mean                   31.7673\n",
      "trainer/Log Pis Std                     9.73306\n",
      "trainer/Policy mu Mean                  0.21804\n",
      "trainer/Policy mu Std                   2.15249\n",
      "trainer/Policy log std Mean            -3.95927\n",
      "trainer/Policy log std Std              1.14094\n",
      "exploration/num steps total        104307\n",
      "exploration/num paths total           222\n",
      "evaluation/num steps total         760842\n",
      "evaluation/num paths total           1044\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.44904\n",
      "evaluation/Rewards Std                  1.35475\n",
      "evaluation/Rewards Max                  6.79735\n",
      "evaluation/Rewards Min                 -4.20899\n",
      "evaluation/Returns Mean              4449.04\n",
      "evaluation/Returns Std                405.509\n",
      "evaluation/Returns Max               4760.71\n",
      "evaluation/Returns Min               3280.63\n",
      "evaluation/Estimation Bias Mean      1677.64\n",
      "evaluation/Estimation Bias Std        257.897\n",
      "evaluation/EB/Q_True Mean              43.5843\n",
      "evaluation/EB/Q_True Std              133.981\n",
      "evaluation/EB/Q_Pred Mean            1721.23\n",
      "evaluation/EB/Q_Pred Std              192.958\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4449.04\n",
      "evaluation/Actions Mean                 0.0292323\n",
      "evaluation/Actions Std                  0.550452\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.02941\n",
      "time/backward_zf1 (s)                   2.25207\n",
      "time/backward_zf2 (s)                   2.14857\n",
      "time/data sampling (s)                  0.324408\n",
      "time/data storing (s)                   0.0159585\n",
      "time/evaluation sampling (s)            1.96401\n",
      "time/exploration sampling (s)           0.332292\n",
      "time/logging (s)                        0.0126989\n",
      "time/preback_alpha (s)                  0.603497\n",
      "time/preback_policy (s)                 1.20983\n",
      "time/preback_start (s)                  0.152436\n",
      "time/preback_zf (s)                     5.30475\n",
      "time/saving (s)                         0.00646669\n",
      "time/training (s)                       2.2676\n",
      "time/epoch (s)                         18.624\n",
      "time/total (s)                       1725.02\n",
      "Epoch                                  98\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:05:14.070312 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 99 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 110000\n",
      "trainer/ZF1 Loss                       24.5443\n",
      "trainer/ZF2 Loss                       41.2193\n",
      "trainer/ZF Expert Reward               11.4302\n",
      "trainer/ZF Policy Reward                3.93573\n",
      "trainer/ZF CHI2 Term                   72.0062\n",
      "trainer/Policy Loss                 -1519.49\n",
      "trainer/Bias Loss                      75.3198\n",
      "trainer/Bias Value                     13.0167\n",
      "trainer/Policy Grad Norm              146.932\n",
      "trainer/Policy Param Norm              33.1249\n",
      "trainer/Zf1 Grad Norm               21433.8\n",
      "trainer/Zf1 Param Norm                 95.6243\n",
      "trainer/Zf2 Grad Norm               14380.5\n",
      "trainer/Zf2 Param Norm                 99.095\n",
      "trainer/Z Expert Predictions Mean    1750.72\n",
      "trainer/Z Expert Predictions Std       50.9387\n",
      "trainer/Z Expert Predictions Max     1814.72\n",
      "trainer/Z Expert Predictions Min     1448.4\n",
      "trainer/Z Policy Predictions Mean    1506.04\n",
      "trainer/Z Policy Predictions Std      410.188\n",
      "trainer/Z Policy Predictions Max     1809.38\n",
      "trainer/Z Policy Predictions Min      -12.7081\n",
      "trainer/Z Expert Targets Mean        1739.29\n",
      "trainer/Z Expert Targets Std           50.7419\n",
      "trainer/Z Expert Targets Max         1811.35\n",
      "trainer/Z Expert Targets Min         1437.02\n",
      "trainer/Z Policy Targets Mean        1502.11\n",
      "trainer/Z Policy Targets Std          411.079\n",
      "trainer/Z Policy Targets Max         1816.92\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   31.9494\n",
      "trainer/Log Pis Std                    10.0404\n",
      "trainer/Policy mu Mean                  0.178375\n",
      "trainer/Policy mu Std                   2.10998\n",
      "trainer/Policy log std Mean            -4.01991\n",
      "trainer/Policy log std Std              1.12078\n",
      "exploration/num steps total        104307\n",
      "exploration/num paths total           222\n",
      "evaluation/num steps total         768980\n",
      "evaluation/num paths total           1054\n",
      "evaluation/path length Mean           813.8\n",
      "evaluation/path length Std            299.087\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            184\n",
      "evaluation/Rewards Mean                 4.57872\n",
      "evaluation/Rewards Std                  1.05929\n",
      "evaluation/Rewards Max                  6.83822\n",
      "evaluation/Rewards Min                 -2.37697\n",
      "evaluation/Returns Mean              3726.17\n",
      "evaluation/Returns Std               1458.41\n",
      "evaluation/Returns Max               4829.17\n",
      "evaluation/Returns Min                749.038\n",
      "evaluation/Estimation Bias Mean      1668.94\n",
      "evaluation/Estimation Bias Std        156.154\n",
      "evaluation/EB/Q_True Mean              48.9686\n",
      "evaluation/EB/Q_True Std              134.546\n",
      "evaluation/EB/Q_Pred Mean            1717.91\n",
      "evaluation/EB/Q_Pred Std               69.3303\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3726.17\n",
      "evaluation/Actions Mean                 0.0201206\n",
      "evaluation/Actions Std                  0.545687\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77537\n",
      "time/backward_zf1 (s)                   1.93171\n",
      "time/backward_zf2 (s)                   1.84077\n",
      "time/data sampling (s)                  0.293855\n",
      "time/data storing (s)                   0.0142248\n",
      "time/evaluation sampling (s)            1.75887\n",
      "time/exploration sampling (s)           0.316465\n",
      "time/logging (s)                        0.00984273\n",
      "time/preback_alpha (s)                  0.562174\n",
      "time/preback_policy (s)                 1.03321\n",
      "time/preback_start (s)                  0.1417\n",
      "time/preback_zf (s)                     5.08286\n",
      "time/saving (s)                         0.00622893\n",
      "time/training (s)                       2.33211\n",
      "time/epoch (s)                         17.0994\n",
      "time/total (s)                       1742.15\n",
      "Epoch                                  99\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:05:31.029290 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 100 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 111000\n",
      "trainer/ZF1 Loss                       11.9671\n",
      "trainer/ZF2 Loss                       10.4296\n",
      "trainer/ZF Expert Reward                9.02723\n",
      "trainer/ZF Policy Reward               -0.983798\n",
      "trainer/ZF CHI2 Term                   53.1537\n",
      "trainer/Policy Loss                 -1502.38\n",
      "trainer/Bias Loss                      80.5706\n",
      "trainer/Bias Value                     12.9212\n",
      "trainer/Policy Grad Norm               74.871\n",
      "trainer/Policy Param Norm              33.1911\n",
      "trainer/Zf1 Grad Norm                2883.53\n",
      "trainer/Zf1 Param Norm                 95.7795\n",
      "trainer/Zf2 Grad Norm                2485.87\n",
      "trainer/Zf2 Param Norm                 99.2348\n",
      "trainer/Z Expert Predictions Mean    1724.45\n",
      "trainer/Z Expert Predictions Std       49.269\n",
      "trainer/Z Expert Predictions Max     1795.84\n",
      "trainer/Z Expert Predictions Min     1411.4\n",
      "trainer/Z Policy Predictions Mean    1491.01\n",
      "trainer/Z Policy Predictions Std      431.181\n",
      "trainer/Z Policy Predictions Max     1785.43\n",
      "trainer/Z Policy Predictions Min       -7.44798\n",
      "trainer/Z Expert Targets Mean        1715.43\n",
      "trainer/Z Expert Targets Std           48.4883\n",
      "trainer/Z Expert Targets Max         1781.47\n",
      "trainer/Z Expert Targets Min         1413.38\n",
      "trainer/Z Policy Targets Mean        1492\n",
      "trainer/Z Policy Targets Std          424.971\n",
      "trainer/Z Policy Targets Max         1782.08\n",
      "trainer/Z Policy Targets Min           10.0891\n",
      "trainer/Log Pis Mean                   32.267\n",
      "trainer/Log Pis Std                    10.5775\n",
      "trainer/Policy mu Mean                  0.257341\n",
      "trainer/Policy mu Std                   2.13875\n",
      "trainer/Policy log std Mean            -4.04545\n",
      "trainer/Policy log std Std              1.07691\n",
      "exploration/num steps total        105307\n",
      "exploration/num paths total           223\n",
      "evaluation/num steps total         778285\n",
      "evaluation/num paths total           1064\n",
      "evaluation/path length Mean           930.5\n",
      "evaluation/path length Std            208.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            305\n",
      "evaluation/Rewards Mean                 4.72561\n",
      "evaluation/Rewards Std                  1.00216\n",
      "evaluation/Rewards Max                  6.8436\n",
      "evaluation/Rewards Min                 -1.66678\n",
      "evaluation/Returns Mean              4397.18\n",
      "evaluation/Returns Std               1020.26\n",
      "evaluation/Returns Max               4812.73\n",
      "evaluation/Returns Min               1341.09\n",
      "evaluation/Estimation Bias Mean      1651.81\n",
      "evaluation/Estimation Bias Std        150.936\n",
      "evaluation/EB/Q_True Mean              47.2431\n",
      "evaluation/EB/Q_True Std              139.966\n",
      "evaluation/EB/Q_Pred Mean            1699.06\n",
      "evaluation/EB/Q_Pred Std               57.3411\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4397.18\n",
      "evaluation/Actions Mean                 0.0188202\n",
      "evaluation/Actions Std                  0.528663\n",
      "evaluation/Actions Max                  0.999835\n",
      "evaluation/Actions Min                 -0.999479\n",
      "time/backward_policy (s)                1.68667\n",
      "time/backward_zf1 (s)                   1.83062\n",
      "time/backward_zf2 (s)                   1.74065\n",
      "time/data sampling (s)                  0.296897\n",
      "time/data storing (s)                   0.0139837\n",
      "time/evaluation sampling (s)            1.7321\n",
      "time/exploration sampling (s)           0.316816\n",
      "time/logging (s)                        0.0131583\n",
      "time/preback_alpha (s)                  0.564827\n",
      "time/preback_policy (s)                 0.937497\n",
      "time/preback_start (s)                  0.14266\n",
      "time/preback_zf (s)                     5.06664\n",
      "time/saving (s)                         0.00685353\n",
      "time/training (s)                       2.54439\n",
      "time/epoch (s)                         16.8938\n",
      "time/total (s)                       1759.06\n",
      "Epoch                                 100\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:05:48.176453 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 101 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 112000\n",
      "trainer/ZF1 Loss                        5.41594\n",
      "trainer/ZF2 Loss                       42.4615\n",
      "trainer/ZF Expert Reward               14.2616\n",
      "trainer/ZF Policy Reward                2.89226\n",
      "trainer/ZF CHI2 Term                   67.106\n",
      "trainer/Policy Loss                 -1489.23\n",
      "trainer/Bias Loss                      88.3788\n",
      "trainer/Bias Value                     12.8219\n",
      "trainer/Policy Grad Norm              146.614\n",
      "trainer/Policy Param Norm              33.2505\n",
      "trainer/Zf1 Grad Norm                2516.61\n",
      "trainer/Zf1 Param Norm                 95.9099\n",
      "trainer/Zf2 Grad Norm                7011.68\n",
      "trainer/Zf2 Param Norm                 99.3848\n",
      "trainer/Z Expert Predictions Mean    1703.72\n",
      "trainer/Z Expert Predictions Std       62.8217\n",
      "trainer/Z Expert Predictions Max     1782.35\n",
      "trainer/Z Expert Predictions Min     1352.38\n",
      "trainer/Z Policy Predictions Mean    1480.63\n",
      "trainer/Z Policy Predictions Std      433.84\n",
      "trainer/Z Policy Predictions Max     1767.09\n",
      "trainer/Z Policy Predictions Min       -8.76606\n",
      "trainer/Z Expert Targets Mean        1689.46\n",
      "trainer/Z Expert Targets Std           62.3856\n",
      "trainer/Z Expert Targets Max         1773.47\n",
      "trainer/Z Expert Targets Min         1339.59\n",
      "trainer/Z Policy Targets Mean        1477.73\n",
      "trainer/Z Policy Targets Std          428.918\n",
      "trainer/Z Policy Targets Max         1762.26\n",
      "trainer/Z Policy Targets Min            6.02973\n",
      "trainer/Log Pis Mean                   32.1192\n",
      "trainer/Log Pis Std                    10.3585\n",
      "trainer/Policy mu Mean                  0.207672\n",
      "trainer/Policy mu Std                   2.20108\n",
      "trainer/Policy log std Mean            -4.06533\n",
      "trainer/Policy log std Std              1.10868\n",
      "exploration/num steps total        106307\n",
      "exploration/num paths total           224\n",
      "evaluation/num steps total         786444\n",
      "evaluation/num paths total           1074\n",
      "evaluation/path length Mean           815.9\n",
      "evaluation/path length Std            368.562\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             43\n",
      "evaluation/Rewards Mean                 4.52006\n",
      "evaluation/Rewards Std                  1.14649\n",
      "evaluation/Rewards Max                  6.86371\n",
      "evaluation/Rewards Min                 -2.35669\n",
      "evaluation/Returns Mean              3687.92\n",
      "evaluation/Returns Std               1722.51\n",
      "evaluation/Returns Max               4727.39\n",
      "evaluation/Returns Min                 53.5485\n",
      "evaluation/Estimation Bias Mean      1612.6\n",
      "evaluation/Estimation Bias Std        164.027\n",
      "evaluation/EB/Q_True Mean              51.2286\n",
      "evaluation/EB/Q_True Std              140.649\n",
      "evaluation/EB/Q_Pred Mean            1663.83\n",
      "evaluation/EB/Q_Pred Std               70.7738\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3687.92\n",
      "evaluation/Actions Mean                 0.0316264\n",
      "evaluation/Actions Std                  0.547171\n",
      "evaluation/Actions Max                  0.999874\n",
      "evaluation/Actions Min                 -0.999594\n",
      "time/backward_policy (s)                1.86528\n",
      "time/backward_zf1 (s)                   2.00424\n",
      "time/backward_zf2 (s)                   1.92377\n",
      "time/data sampling (s)                  0.284775\n",
      "time/data storing (s)                   0.0138534\n",
      "time/evaluation sampling (s)            1.69042\n",
      "time/exploration sampling (s)           0.316982\n",
      "time/logging (s)                        0.0130426\n",
      "time/preback_alpha (s)                  0.554458\n",
      "time/preback_policy (s)                 1.12461\n",
      "time/preback_start (s)                  0.14228\n",
      "time/preback_zf (s)                     5.03755\n",
      "time/saving (s)                         0.00682016\n",
      "time/training (s)                       2.10428\n",
      "time/epoch (s)                         17.0824\n",
      "time/total (s)                       1776.16\n",
      "Epoch                                 101\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:06:05.542025 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 102 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 113000\n",
      "trainer/ZF1 Loss                       37.9164\n",
      "trainer/ZF2 Loss                       64.1514\n",
      "trainer/ZF Expert Reward               10.9469\n",
      "trainer/ZF Policy Reward               -0.228905\n",
      "trainer/ZF CHI2 Term                   93.7021\n",
      "trainer/Policy Loss                 -1470.35\n",
      "trainer/Bias Loss                     483.812\n",
      "trainer/Bias Value                     12.7632\n",
      "trainer/Policy Grad Norm               98.2386\n",
      "trainer/Policy Param Norm              33.3092\n",
      "trainer/Zf1 Grad Norm                2229.9\n",
      "trainer/Zf1 Param Norm                 96.0561\n",
      "trainer/Zf2 Grad Norm                6748.78\n",
      "trainer/Zf2 Param Norm                 99.5516\n",
      "trainer/Z Expert Predictions Mean    1671.68\n",
      "trainer/Z Expert Predictions Std      127.21\n",
      "trainer/Z Expert Predictions Max     1739.49\n",
      "trainer/Z Expert Predictions Min     -128.312\n",
      "trainer/Z Policy Predictions Mean    1461.18\n",
      "trainer/Z Policy Predictions Std      417.22\n",
      "trainer/Z Policy Predictions Max     1740.15\n",
      "trainer/Z Policy Predictions Min       -4.93046\n",
      "trainer/Z Expert Targets Mean        1660.73\n",
      "trainer/Z Expert Targets Std          123.49\n",
      "trainer/Z Expert Targets Max         1739.85\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1461.41\n",
      "trainer/Z Policy Targets Std          411.377\n",
      "trainer/Z Policy Targets Max         1734.28\n",
      "trainer/Z Policy Targets Min            7.70499\n",
      "trainer/Log Pis Mean                   31.8105\n",
      "trainer/Log Pis Std                    10.0343\n",
      "trainer/Policy mu Mean                  0.252726\n",
      "trainer/Policy mu Std                   2.11106\n",
      "trainer/Policy log std Mean            -4.05214\n",
      "trainer/Policy log std Std              1.08038\n",
      "exploration/num steps total        108185\n",
      "exploration/num paths total           226\n",
      "evaluation/num steps total         796444\n",
      "evaluation/num paths total           1084\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.613\n",
      "evaluation/Rewards Std                  1.05952\n",
      "evaluation/Rewards Max                  6.70959\n",
      "evaluation/Rewards Min                 -2.35547\n",
      "evaluation/Returns Mean              4613\n",
      "evaluation/Returns Std                124.531\n",
      "evaluation/Returns Max               4862.3\n",
      "evaluation/Returns Min               4405.94\n",
      "evaluation/Estimation Bias Mean      1619.29\n",
      "evaluation/Estimation Bias Std        142.996\n",
      "evaluation/EB/Q_True Mean              42.2208\n",
      "evaluation/EB/Q_True Std              130.417\n",
      "evaluation/EB/Q_Pred Mean            1661.51\n",
      "evaluation/EB/Q_Pred Std               66.1496\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4613\n",
      "evaluation/Actions Mean                 0.015147\n",
      "evaluation/Actions Std                  0.536645\n",
      "evaluation/Actions Max                  0.999792\n",
      "evaluation/Actions Min                 -0.999759\n",
      "time/backward_policy (s)                1.81871\n",
      "time/backward_zf1 (s)                   1.9756\n",
      "time/backward_zf2 (s)                   1.9022\n",
      "time/data sampling (s)                  0.293318\n",
      "time/data storing (s)                   0.0145822\n",
      "time/evaluation sampling (s)            1.83639\n",
      "time/exploration sampling (s)           0.326454\n",
      "time/logging (s)                        0.0129699\n",
      "time/preback_alpha (s)                  0.56507\n",
      "time/preback_policy (s)                 1.06446\n",
      "time/preback_start (s)                  0.14389\n",
      "time/preback_zf (s)                     5.06978\n",
      "time/saving (s)                         0.00657158\n",
      "time/training (s)                       2.26602\n",
      "time/epoch (s)                         17.296\n",
      "time/total (s)                       1793.48\n",
      "Epoch                                 102\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:06:23.280577 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 103 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 114000\n",
      "trainer/ZF1 Loss                        3.37953\n",
      "trainer/ZF2 Loss                       -1.81696\n",
      "trainer/ZF Expert Reward               14.131\n",
      "trainer/ZF Policy Reward                7.4125\n",
      "trainer/ZF CHI2 Term                   38.7301\n",
      "trainer/Policy Loss                 -1475.01\n",
      "trainer/Bias Loss                      66.0618\n",
      "trainer/Bias Value                     12.7189\n",
      "trainer/Policy Grad Norm               84.0956\n",
      "trainer/Policy Param Norm              33.3655\n",
      "trainer/Zf1 Grad Norm                 894.583\n",
      "trainer/Zf1 Param Norm                 96.2022\n",
      "trainer/Zf2 Grad Norm                 995.148\n",
      "trainer/Zf2 Param Norm                 99.6822\n",
      "trainer/Z Expert Predictions Mean    1663.68\n",
      "trainer/Z Expert Predictions Std       60.2008\n",
      "trainer/Z Expert Predictions Max     1732.64\n",
      "trainer/Z Expert Predictions Min     1265.27\n",
      "trainer/Z Policy Predictions Mean    1472.23\n",
      "trainer/Z Policy Predictions Std      378.316\n",
      "trainer/Z Policy Predictions Max     1723.06\n",
      "trainer/Z Policy Predictions Min      -18.7135\n",
      "trainer/Z Expert Targets Mean        1649.55\n",
      "trainer/Z Expert Targets Std           59.199\n",
      "trainer/Z Expert Targets Max         1721.16\n",
      "trainer/Z Expert Targets Min         1258.43\n",
      "trainer/Z Policy Targets Mean        1464.81\n",
      "trainer/Z Policy Targets Std          371.077\n",
      "trainer/Z Policy Targets Max         1710.3\n",
      "trainer/Z Policy Targets Min            1.83867\n",
      "trainer/Log Pis Mean                   31.5458\n",
      "trainer/Log Pis Std                     8.20612\n",
      "trainer/Policy mu Mean                  0.166488\n",
      "trainer/Policy mu Std                   1.85534\n",
      "trainer/Policy log std Mean            -4.10127\n",
      "trainer/Policy log std Std              1.08876\n",
      "exploration/num steps total        109185\n",
      "exploration/num paths total           227\n",
      "evaluation/num steps total         804744\n",
      "evaluation/num paths total           1094\n",
      "evaluation/path length Mean           830\n",
      "evaluation/path length Std            308.759\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             31\n",
      "evaluation/Rewards Mean                 4.596\n",
      "evaluation/Rewards Std                  1.068\n",
      "evaluation/Rewards Max                  6.77688\n",
      "evaluation/Rewards Min                 -1.84481\n",
      "evaluation/Returns Mean              3814.68\n",
      "evaluation/Returns Std               1486.43\n",
      "evaluation/Returns Max               4717.02\n",
      "evaluation/Returns Min                 68.4358\n",
      "evaluation/Estimation Bias Mean      1585.06\n",
      "evaluation/Estimation Bias Std        172.618\n",
      "evaluation/EB/Q_True Mean              51.387\n",
      "evaluation/EB/Q_True Std              142.48\n",
      "evaluation/EB/Q_Pred Mean            1636.45\n",
      "evaluation/EB/Q_Pred Std               74.593\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3814.68\n",
      "evaluation/Actions Mean                 0.019703\n",
      "evaluation/Actions Std                  0.537737\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999925\n",
      "time/backward_policy (s)                1.91103\n",
      "time/backward_zf1 (s)                   2.08798\n",
      "time/backward_zf2 (s)                   2.00697\n",
      "time/data sampling (s)                  0.305582\n",
      "time/data storing (s)                   0.0153315\n",
      "time/evaluation sampling (s)            1.73618\n",
      "time/exploration sampling (s)           0.32698\n",
      "time/logging (s)                        0.0102435\n",
      "time/preback_alpha (s)                  0.570032\n",
      "time/preback_policy (s)                 1.11118\n",
      "time/preback_start (s)                  0.14491\n",
      "time/preback_zf (s)                     5.11454\n",
      "time/saving (s)                         0.0058425\n",
      "time/training (s)                       2.31463\n",
      "time/epoch (s)                         17.6614\n",
      "time/total (s)                       1811.17\n",
      "Epoch                                 103\n",
      "---------------------------------  --------------\n",
      "2024-06-10 21:06:41.102843 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 104 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 115000\n",
      "trainer/ZF1 Loss                       63.7286\n",
      "trainer/ZF2 Loss                       71.8107\n",
      "trainer/ZF Expert Reward               18.3536\n",
      "trainer/ZF Policy Reward                4.34948\n",
      "trainer/ZF CHI2 Term                  113.081\n",
      "trainer/Policy Loss                 -1439.71\n",
      "trainer/Bias Loss                     851.368\n",
      "trainer/Bias Value                     12.6829\n",
      "trainer/Policy Grad Norm              103.909\n",
      "trainer/Policy Param Norm              33.4266\n",
      "trainer/Zf1 Grad Norm                2133.92\n",
      "trainer/Zf1 Param Norm                 96.3641\n",
      "trainer/Zf2 Grad Norm                3745.46\n",
      "trainer/Zf2 Param Norm                 99.8268\n",
      "trainer/Z Expert Predictions Mean    1643.63\n",
      "trainer/Z Expert Predictions Std      103.382\n",
      "trainer/Z Expert Predictions Max     1714.73\n",
      "trainer/Z Expert Predictions Min      104.294\n",
      "trainer/Z Policy Predictions Mean    1434.44\n",
      "trainer/Z Policy Predictions Std      386.66\n",
      "trainer/Z Policy Predictions Max     1704.49\n",
      "trainer/Z Policy Predictions Min       21.4528\n",
      "trainer/Z Expert Targets Mean        1625.28\n",
      "trainer/Z Expert Targets Std          116.476\n",
      "trainer/Z Expert Targets Max         1714.29\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1430.09\n",
      "trainer/Z Policy Targets Std          381.006\n",
      "trainer/Z Policy Targets Max         1686.63\n",
      "trainer/Z Policy Targets Min           33.0198\n",
      "trainer/Log Pis Mean                   31.6233\n",
      "trainer/Log Pis Std                    10.47\n",
      "trainer/Policy mu Mean                  0.228817\n",
      "trainer/Policy mu Std                   2.10816\n",
      "trainer/Policy log std Mean            -3.94953\n",
      "trainer/Policy log std Std              1.12645\n",
      "exploration/num steps total        109185\n",
      "exploration/num paths total           227\n",
      "evaluation/num steps total         813075\n",
      "evaluation/num paths total           1104\n",
      "evaluation/path length Mean           833.1\n",
      "evaluation/path length Std            338.194\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             44\n",
      "evaluation/Rewards Mean                 4.59993\n",
      "evaluation/Rewards Std                  1.13656\n",
      "evaluation/Rewards Max                  6.68451\n",
      "evaluation/Rewards Min                 -2.10875\n",
      "evaluation/Returns Mean              3832.2\n",
      "evaluation/Returns Std               1627.3\n",
      "evaluation/Returns Max               4740.02\n",
      "evaluation/Returns Min                 29.5208\n",
      "evaluation/Estimation Bias Mean      1568.98\n",
      "evaluation/Estimation Bias Std        166.755\n",
      "evaluation/EB/Q_True Mean              51.5401\n",
      "evaluation/EB/Q_True Std              144.153\n",
      "evaluation/EB/Q_Pred Mean            1620.52\n",
      "evaluation/EB/Q_Pred Std               72.1282\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3832.2\n",
      "evaluation/Actions Mean                 0.024019\n",
      "evaluation/Actions Std                  0.536562\n",
      "evaluation/Actions Max                  0.999973\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.00682\n",
      "time/backward_zf1 (s)                   2.12625\n",
      "time/backward_zf2 (s)                   2.10027\n",
      "time/data sampling (s)                  0.293421\n",
      "time/data storing (s)                   0.0145845\n",
      "time/evaluation sampling (s)            1.73255\n",
      "time/exploration sampling (s)           0.320855\n",
      "time/logging (s)                        0.0106068\n",
      "time/preback_alpha (s)                  0.577248\n",
      "time/preback_policy (s)                 1.22892\n",
      "time/preback_start (s)                  0.14482\n",
      "time/preback_zf (s)                     5.12082\n",
      "time/saving (s)                         0.0175666\n",
      "time/training (s)                       2.06254\n",
      "time/epoch (s)                         17.7573\n",
      "time/total (s)                       1828.94\n",
      "Epoch                                 104\n",
      "---------------------------------  --------------\n",
      "2024-06-10 21:06:58.323715 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 105 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 116000\n",
      "trainer/ZF1 Loss                        1.82687\n",
      "trainer/ZF2 Loss                       20.5069\n",
      "trainer/ZF Expert Reward               15.3369\n",
      "trainer/ZF Policy Reward                4.61738\n",
      "trainer/ZF CHI2 Term                   52.8302\n",
      "trainer/Policy Loss                 -1440.43\n",
      "trainer/Bias Loss                     113.456\n",
      "trainer/Bias Value                     12.6377\n",
      "trainer/Policy Grad Norm               88.9462\n",
      "trainer/Policy Param Norm              33.4835\n",
      "trainer/Zf1 Grad Norm                1616.92\n",
      "trainer/Zf1 Param Norm                 96.5195\n",
      "trainer/Zf2 Grad Norm                8883.87\n",
      "trainer/Zf2 Param Norm                 99.9756\n",
      "trainer/Z Expert Predictions Mean    1630.32\n",
      "trainer/Z Expert Predictions Std       54.1063\n",
      "trainer/Z Expert Predictions Max     1704.56\n",
      "trainer/Z Expert Predictions Min     1344.93\n",
      "trainer/Z Policy Predictions Mean    1433.35\n",
      "trainer/Z Policy Predictions Std      389.036\n",
      "trainer/Z Policy Predictions Max     1691.01\n",
      "trainer/Z Policy Predictions Min       -7.36943\n",
      "trainer/Z Expert Targets Mean        1614.98\n",
      "trainer/Z Expert Targets Std           52.9073\n",
      "trainer/Z Expert Targets Max         1681.41\n",
      "trainer/Z Expert Targets Min         1325.18\n",
      "trainer/Z Policy Targets Mean        1428.73\n",
      "trainer/Z Policy Targets Std          382.485\n",
      "trainer/Z Policy Targets Max         1678.44\n",
      "trainer/Z Policy Targets Min            4.91292\n",
      "trainer/Log Pis Mean                   31.2563\n",
      "trainer/Log Pis Std                     9.61408\n",
      "trainer/Policy mu Mean                  0.175434\n",
      "trainer/Policy mu Std                   2.11909\n",
      "trainer/Policy log std Mean            -4.06885\n",
      "trainer/Policy log std Std              1.08026\n",
      "exploration/num steps total        112521\n",
      "exploration/num paths total           231\n",
      "evaluation/num steps total         822689\n",
      "evaluation/num paths total           1114\n",
      "evaluation/path length Mean           961.4\n",
      "evaluation/path length Std             77.6186\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            789\n",
      "evaluation/Rewards Mean                 4.67307\n",
      "evaluation/Rewards Std                  1.04277\n",
      "evaluation/Rewards Max                  6.86764\n",
      "evaluation/Rewards Min                 -1.91962\n",
      "evaluation/Returns Mean              4492.69\n",
      "evaluation/Returns Std                376.735\n",
      "evaluation/Returns Max               4877.98\n",
      "evaluation/Returns Min               3629.31\n",
      "evaluation/Estimation Bias Mean      1553.3\n",
      "evaluation/Estimation Bias Std        147.174\n",
      "evaluation/EB/Q_True Mean              44.7054\n",
      "evaluation/EB/Q_True Std              134.963\n",
      "evaluation/EB/Q_Pred Mean            1598.01\n",
      "evaluation/EB/Q_Pred Std               57.3742\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4492.69\n",
      "evaluation/Actions Mean                 0.018853\n",
      "evaluation/Actions Std                  0.541516\n",
      "evaluation/Actions Max                  0.999943\n",
      "evaluation/Actions Min                 -0.999702\n",
      "time/backward_policy (s)                1.75685\n",
      "time/backward_zf1 (s)                   1.93281\n",
      "time/backward_zf2 (s)                   1.85353\n",
      "time/data sampling (s)                  0.292434\n",
      "time/data storing (s)                   0.0147598\n",
      "time/evaluation sampling (s)            1.71972\n",
      "time/exploration sampling (s)           0.337717\n",
      "time/logging (s)                        0.0118598\n",
      "time/preback_alpha (s)                  0.566926\n",
      "time/preback_policy (s)                 1.03226\n",
      "time/preback_start (s)                  0.144873\n",
      "time/preback_zf (s)                     5.08396\n",
      "time/saving (s)                         0.00671312\n",
      "time/training (s)                       2.39174\n",
      "time/epoch (s)                         17.1462\n",
      "time/total (s)                       1846.12\n",
      "Epoch                                 105\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:07:16.474928 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 106 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 117000\n",
      "trainer/ZF1 Loss                        0.50169\n",
      "trainer/ZF2 Loss                       -0.802872\n",
      "trainer/ZF Expert Reward               12.6353\n",
      "trainer/ZF Policy Reward                3.18305\n",
      "trainer/ZF CHI2 Term                   38.9672\n",
      "trainer/Policy Loss                 -1456.12\n",
      "trainer/Bias Loss                      62.3237\n",
      "trainer/Bias Value                     12.6052\n",
      "trainer/Policy Grad Norm               84.901\n",
      "trainer/Policy Param Norm              33.536\n",
      "trainer/Zf1 Grad Norm                1612.01\n",
      "trainer/Zf1 Param Norm                 96.6782\n",
      "trainer/Zf2 Grad Norm                1178.44\n",
      "trainer/Zf2 Param Norm                100.133\n",
      "trainer/Z Expert Predictions Mean    1610.74\n",
      "trainer/Z Expert Predictions Std       40.9646\n",
      "trainer/Z Expert Predictions Max     1666.89\n",
      "trainer/Z Expert Predictions Min     1361.64\n",
      "trainer/Z Policy Predictions Mean    1448.56\n",
      "trainer/Z Policy Predictions Std      314.119\n",
      "trainer/Z Policy Predictions Max     1657.23\n",
      "trainer/Z Policy Predictions Min       -8.87418\n",
      "trainer/Z Expert Targets Mean        1598.11\n",
      "trainer/Z Expert Targets Std           42.8647\n",
      "trainer/Z Expert Targets Max         1656.18\n",
      "trainer/Z Expert Targets Min         1346.19\n",
      "trainer/Z Policy Targets Mean        1445.37\n",
      "trainer/Z Policy Targets Std          308.751\n",
      "trainer/Z Policy Targets Max         1654\n",
      "trainer/Z Policy Targets Min            3.75153\n",
      "trainer/Log Pis Mean                   29.9652\n",
      "trainer/Log Pis Std                     8.07413\n",
      "trainer/Policy mu Mean                  0.157975\n",
      "trainer/Policy mu Std                   1.71485\n",
      "trainer/Policy log std Mean            -4.11964\n",
      "trainer/Policy log std Std              0.973647\n",
      "exploration/num steps total        112521\n",
      "exploration/num paths total           231\n",
      "evaluation/num steps total         831953\n",
      "evaluation/num paths total           1124\n",
      "evaluation/path length Mean           926.4\n",
      "evaluation/path length Std            220.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            264\n",
      "evaluation/Rewards Mean                 4.57744\n",
      "evaluation/Rewards Std                  1.21832\n",
      "evaluation/Rewards Max                  6.84075\n",
      "evaluation/Rewards Min                 -3.18349\n",
      "evaluation/Returns Mean              4240.54\n",
      "evaluation/Returns Std               1215.98\n",
      "evaluation/Returns Max               4792.18\n",
      "evaluation/Returns Min                615.429\n",
      "evaluation/Estimation Bias Mean      1536.96\n",
      "evaluation/Estimation Bias Std        174.719\n",
      "evaluation/EB/Q_True Mean              46.0091\n",
      "evaluation/EB/Q_True Std              135.634\n",
      "evaluation/EB/Q_Pred Mean            1582.97\n",
      "evaluation/EB/Q_Pred Std               85.0967\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4240.54\n",
      "evaluation/Actions Mean                 0.00961481\n",
      "evaluation/Actions Std                  0.541167\n",
      "evaluation/Actions Max                  0.999901\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97738\n",
      "time/backward_zf1 (s)                   2.11749\n",
      "time/backward_zf2 (s)                   2.02355\n",
      "time/data sampling (s)                  0.352946\n",
      "time/data storing (s)                   0.0154441\n",
      "time/evaluation sampling (s)            1.85684\n",
      "time/exploration sampling (s)           0.330464\n",
      "time/logging (s)                        0.0113887\n",
      "time/preback_alpha (s)                  0.607769\n",
      "time/preback_policy (s)                 1.14467\n",
      "time/preback_start (s)                  0.1532\n",
      "time/preback_zf (s)                     5.16818\n",
      "time/saving (s)                         0.00745603\n",
      "time/training (s)                       2.31502\n",
      "time/epoch (s)                         18.0818\n",
      "time/total (s)                       1864.22\n",
      "Epoch                                 106\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:07:33.728615 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 107 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 118000\n",
      "trainer/ZF1 Loss                      312.592\n",
      "trainer/ZF2 Loss                       37.1819\n",
      "trainer/ZF Expert Reward               11.2107\n",
      "trainer/ZF Policy Reward                1.24066\n",
      "trainer/ZF CHI2 Term                  215.749\n",
      "trainer/Policy Loss                 -1379.72\n",
      "trainer/Bias Loss                     106.415\n",
      "trainer/Bias Value                     12.5261\n",
      "trainer/Policy Grad Norm              403.406\n",
      "trainer/Policy Param Norm              33.5947\n",
      "trainer/Zf1 Grad Norm               22441.9\n",
      "trainer/Zf1 Param Norm                 96.8352\n",
      "trainer/Zf2 Grad Norm               13015.5\n",
      "trainer/Zf2 Param Norm                100.264\n",
      "trainer/Z Expert Predictions Mean    1591.02\n",
      "trainer/Z Expert Predictions Std       55.6366\n",
      "trainer/Z Expert Predictions Max     1666.48\n",
      "trainer/Z Expert Predictions Min     1289.55\n",
      "trainer/Z Policy Predictions Mean    1366.35\n",
      "trainer/Z Policy Predictions Std      423.773\n",
      "trainer/Z Policy Predictions Max     1657.24\n",
      "trainer/Z Policy Predictions Min     -116.172\n",
      "trainer/Z Expert Targets Mean        1579.81\n",
      "trainer/Z Expert Targets Std           55.2344\n",
      "trainer/Z Expert Targets Max         1645.97\n",
      "trainer/Z Expert Targets Min         1292.61\n",
      "trainer/Z Policy Targets Mean        1365.11\n",
      "trainer/Z Policy Targets Std          421.75\n",
      "trainer/Z Policy Targets Max         1638.91\n",
      "trainer/Z Policy Targets Min           -7.54355\n",
      "trainer/Log Pis Mean                   31.2042\n",
      "trainer/Log Pis Std                     9.33984\n",
      "trainer/Policy mu Mean                  0.173436\n",
      "trainer/Policy mu Std                   2.01766\n",
      "trainer/Policy log std Mean            -4.04709\n",
      "trainer/Policy log std Std              1.09662\n",
      "exploration/num steps total        113521\n",
      "exploration/num paths total           232\n",
      "evaluation/num steps total         841953\n",
      "evaluation/num paths total           1134\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.57328\n",
      "evaluation/Rewards Std                  1.04262\n",
      "evaluation/Rewards Max                  6.8719\n",
      "evaluation/Rewards Min                 -2.1459\n",
      "evaluation/Returns Mean              4573.28\n",
      "evaluation/Returns Std                 83.8158\n",
      "evaluation/Returns Max               4702.33\n",
      "evaluation/Returns Min               4404.6\n",
      "evaluation/Estimation Bias Mean      1523.23\n",
      "evaluation/Estimation Bias Std        141.223\n",
      "evaluation/EB/Q_True Mean              42.4792\n",
      "evaluation/EB/Q_True Std              130.751\n",
      "evaluation/EB/Q_Pred Mean            1565.71\n",
      "evaluation/EB/Q_Pred Std               55.5568\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4573.28\n",
      "evaluation/Actions Mean                 0.0178925\n",
      "evaluation/Actions Std                  0.538938\n",
      "evaluation/Actions Max                  0.999717\n",
      "evaluation/Actions Min                 -0.999484\n",
      "time/backward_policy (s)                1.7428\n",
      "time/backward_zf1 (s)                   1.88028\n",
      "time/backward_zf2 (s)                   1.78846\n",
      "time/data sampling (s)                  0.31164\n",
      "time/data storing (s)                   0.0142296\n",
      "time/evaluation sampling (s)            1.83297\n",
      "time/exploration sampling (s)           0.321301\n",
      "time/logging (s)                        0.0131687\n",
      "time/preback_alpha (s)                  0.577072\n",
      "time/preback_policy (s)                 0.986996\n",
      "time/preback_start (s)                  0.146215\n",
      "time/preback_zf (s)                     5.11121\n",
      "time/saving (s)                         0.00644473\n",
      "time/training (s)                       2.45253\n",
      "time/epoch (s)                         17.1853\n",
      "time/total (s)                       1881.42\n",
      "Epoch                                 107\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:07:51.487380 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 108 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 119000\n",
      "trainer/ZF1 Loss                       11.6627\n",
      "trainer/ZF2 Loss                        8.06413\n",
      "trainer/ZF Expert Reward                6.74221\n",
      "trainer/ZF Policy Reward               -0.207248\n",
      "trainer/ZF CHI2 Term                   48.0473\n",
      "trainer/Policy Loss                 -1371.53\n",
      "trainer/Bias Loss                     121.214\n",
      "trainer/Bias Value                     12.5258\n",
      "trainer/Policy Grad Norm              111.91\n",
      "trainer/Policy Param Norm              33.6488\n",
      "trainer/Zf1 Grad Norm                2854.16\n",
      "trainer/Zf1 Param Norm                 96.9911\n",
      "trainer/Zf2 Grad Norm                2064.06\n",
      "trainer/Zf2 Param Norm                100.433\n",
      "trainer/Z Expert Predictions Mean    1562.69\n",
      "trainer/Z Expert Predictions Std       65.1187\n",
      "trainer/Z Expert Predictions Max     1642.3\n",
      "trainer/Z Expert Predictions Min     1199.98\n",
      "trainer/Z Policy Predictions Mean    1365.74\n",
      "trainer/Z Policy Predictions Std      382.954\n",
      "trainer/Z Policy Predictions Max     1648.34\n",
      "trainer/Z Policy Predictions Min       -5.22323\n",
      "trainer/Z Expert Targets Mean        1555.95\n",
      "trainer/Z Expert Targets Std           68.2751\n",
      "trainer/Z Expert Targets Max         1641.05\n",
      "trainer/Z Expert Targets Min         1183.19\n",
      "trainer/Z Policy Targets Mean        1365.95\n",
      "trainer/Z Policy Targets Std          381.351\n",
      "trainer/Z Policy Targets Max         1631.08\n",
      "trainer/Z Policy Targets Min            8.6262\n",
      "trainer/Log Pis Mean                   31.55\n",
      "trainer/Log Pis Std                    10.1781\n",
      "trainer/Policy mu Mean                  0.195576\n",
      "trainer/Policy mu Std                   2.05186\n",
      "trainer/Policy log std Mean            -4.05685\n",
      "trainer/Policy log std Std              1.16797\n",
      "exploration/num steps total        114521\n",
      "exploration/num paths total           233\n",
      "evaluation/num steps total         851756\n",
      "evaluation/num paths total           1144\n",
      "evaluation/path length Mean           980.3\n",
      "evaluation/path length Std             59.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            803\n",
      "evaluation/Rewards Mean                 4.53446\n",
      "evaluation/Rewards Std                  1.04585\n",
      "evaluation/Rewards Max                  6.64392\n",
      "evaluation/Rewards Min                 -1.87759\n",
      "evaluation/Returns Mean              4445.14\n",
      "evaluation/Returns Std                263.647\n",
      "evaluation/Returns Max               4601.75\n",
      "evaluation/Returns Min               3680.64\n",
      "evaluation/Estimation Bias Mean      1508.95\n",
      "evaluation/Estimation Bias Std        144.467\n",
      "evaluation/EB/Q_True Mean              42.0915\n",
      "evaluation/EB/Q_True Std              128.139\n",
      "evaluation/EB/Q_Pred Mean            1551.04\n",
      "evaluation/EB/Q_Pred Std               61.7991\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4445.14\n",
      "evaluation/Actions Mean                 0.0191155\n",
      "evaluation/Actions Std                  0.54681\n",
      "evaluation/Actions Max                  0.999913\n",
      "evaluation/Actions Min                 -0.999757\n",
      "time/backward_policy (s)                1.90014\n",
      "time/backward_zf1 (s)                   1.99583\n",
      "time/backward_zf2 (s)                   1.9317\n",
      "time/data sampling (s)                  0.314178\n",
      "time/data storing (s)                   0.015856\n",
      "time/evaluation sampling (s)            1.70808\n",
      "time/exploration sampling (s)           0.34666\n",
      "time/logging (s)                        0.0116114\n",
      "time/preback_alpha (s)                  0.585869\n",
      "time/preback_policy (s)                 1.06396\n",
      "time/preback_start (s)                  0.150569\n",
      "time/preback_zf (s)                     5.15242\n",
      "time/saving (s)                         0.00632915\n",
      "time/training (s)                       2.50523\n",
      "time/epoch (s)                         17.6884\n",
      "time/total (s)                       1899.13\n",
      "Epoch                                 108\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:08:08.519850 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 109 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 120000\n",
      "trainer/ZF1 Loss                      426.816\n",
      "trainer/ZF2 Loss                      442.251\n",
      "trainer/ZF Expert Reward               11.8943\n",
      "trainer/ZF Policy Reward                6.40821\n",
      "trainer/ZF CHI2 Term                  471.427\n",
      "trainer/Policy Loss                 -1369.51\n",
      "trainer/Bias Loss                     121.422\n",
      "trainer/Bias Value                     12.5155\n",
      "trainer/Policy Grad Norm              101.862\n",
      "trainer/Policy Param Norm              33.7022\n",
      "trainer/Zf1 Grad Norm                3883.87\n",
      "trainer/Zf1 Param Norm                 97.1337\n",
      "trainer/Zf2 Grad Norm                5148.92\n",
      "trainer/Zf2 Param Norm                100.589\n",
      "trainer/Z Expert Predictions Mean    1555.85\n",
      "trainer/Z Expert Predictions Std      113.613\n",
      "trainer/Z Expert Predictions Max     1634.87\n",
      "trainer/Z Expert Predictions Min     -135.581\n",
      "trainer/Z Policy Predictions Mean    1366.25\n",
      "trainer/Z Policy Predictions Std      378.383\n",
      "trainer/Z Policy Predictions Max     1619.8\n",
      "trainer/Z Policy Predictions Min      -19.5529\n",
      "trainer/Z Expert Targets Mean        1543.96\n",
      "trainer/Z Expert Targets Std          105.034\n",
      "trainer/Z Expert Targets Max         1616.74\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1359.84\n",
      "trainer/Z Policy Targets Std          381.662\n",
      "trainer/Z Policy Targets Max         1618.86\n",
      "trainer/Z Policy Targets Min           -7.46616\n",
      "trainer/Log Pis Mean                   31.7245\n",
      "trainer/Log Pis Std                     9.6369\n",
      "trainer/Policy mu Mean                  0.204587\n",
      "trainer/Policy mu Std                   2.13991\n",
      "trainer/Policy log std Mean            -4.05819\n",
      "trainer/Policy log std Std              1.1814\n",
      "exploration/num steps total        114919\n",
      "exploration/num paths total           234\n",
      "evaluation/num steps total         860860\n",
      "evaluation/num paths total           1154\n",
      "evaluation/path length Mean           910.4\n",
      "evaluation/path length Std            268.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            104\n",
      "evaluation/Rewards Mean                 4.60578\n",
      "evaluation/Rewards Std                  1.18721\n",
      "evaluation/Rewards Max                  6.73039\n",
      "evaluation/Rewards Min                 -4.19152\n",
      "evaluation/Returns Mean              4193.1\n",
      "evaluation/Returns Std               1355.16\n",
      "evaluation/Returns Max               4809.37\n",
      "evaluation/Returns Min                144.372\n",
      "evaluation/Estimation Bias Mean      1474.65\n",
      "evaluation/Estimation Bias Std        159.71\n",
      "evaluation/EB/Q_True Mean              46.1227\n",
      "evaluation/EB/Q_True Std              134.935\n",
      "evaluation/EB/Q_Pred Mean            1520.77\n",
      "evaluation/EB/Q_Pred Std               75.1963\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4193.1\n",
      "evaluation/Actions Mean                 0.0280308\n",
      "evaluation/Actions Std                  0.526465\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.68792\n",
      "time/backward_zf1 (s)                   1.82463\n",
      "time/backward_zf2 (s)                   1.74626\n",
      "time/data sampling (s)                  0.276381\n",
      "time/data storing (s)                   0.0144684\n",
      "time/evaluation sampling (s)            1.79849\n",
      "time/exploration sampling (s)           0.318636\n",
      "time/logging (s)                        0.011127\n",
      "time/preback_alpha (s)                  0.556115\n",
      "time/preback_policy (s)                 0.948586\n",
      "time/preback_start (s)                  0.141393\n",
      "time/preback_zf (s)                     5.06658\n",
      "time/saving (s)                         0.00621412\n",
      "time/training (s)                       2.56619\n",
      "time/epoch (s)                         16.963\n",
      "time/total (s)                       1916.12\n",
      "Epoch                                 109\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:08:25.528154 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 110 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 121000\n",
      "trainer/ZF1 Loss                        4.32448\n",
      "trainer/ZF2 Loss                        6.68089\n",
      "trainer/ZF Expert Reward                6.33206\n",
      "trainer/ZF Policy Reward               -2.49156\n",
      "trainer/ZF CHI2 Term                   44.2221\n",
      "trainer/Policy Loss                 -1388.95\n",
      "trainer/Bias Loss                     138.014\n",
      "trainer/Bias Value                     12.4699\n",
      "trainer/Policy Grad Norm              104.304\n",
      "trainer/Policy Param Norm              33.7526\n",
      "trainer/Zf1 Grad Norm                2929.62\n",
      "trainer/Zf1 Param Norm                 97.2991\n",
      "trainer/Zf2 Grad Norm                3305.19\n",
      "trainer/Zf2 Param Norm                100.741\n",
      "trainer/Z Expert Predictions Mean    1532.54\n",
      "trainer/Z Expert Predictions Std       64.0111\n",
      "trainer/Z Expert Predictions Max     1608.7\n",
      "trainer/Z Expert Predictions Min     1151.27\n",
      "trainer/Z Policy Predictions Mean    1376.94\n",
      "trainer/Z Policy Predictions Std      320.479\n",
      "trainer/Z Policy Predictions Max     1608.74\n",
      "trainer/Z Policy Predictions Min      -31.1578\n",
      "trainer/Z Expert Targets Mean        1526.2\n",
      "trainer/Z Expert Targets Std           61.9372\n",
      "trainer/Z Expert Targets Max         1587.24\n",
      "trainer/Z Expert Targets Min         1132.26\n",
      "trainer/Z Policy Targets Mean        1379.43\n",
      "trainer/Z Policy Targets Std          315.844\n",
      "trainer/Z Policy Targets Max         1590.09\n",
      "trainer/Z Policy Targets Min          -22.4508\n",
      "trainer/Log Pis Mean                   30.1977\n",
      "trainer/Log Pis Std                     8.77935\n",
      "trainer/Policy mu Mean                  0.115947\n",
      "trainer/Policy mu Std                   1.73124\n",
      "trainer/Policy log std Mean            -4.10957\n",
      "trainer/Policy log std Std              0.993307\n",
      "exploration/num steps total        115919\n",
      "exploration/num paths total           235\n",
      "evaluation/num steps total         870427\n",
      "evaluation/num paths total           1164\n",
      "evaluation/path length Mean           956.7\n",
      "evaluation/path length Std            129.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            567\n",
      "evaluation/Rewards Mean                 4.51197\n",
      "evaluation/Rewards Std                  1.00525\n",
      "evaluation/Rewards Max                  6.56854\n",
      "evaluation/Rewards Min                 -2.28405\n",
      "evaluation/Returns Mean              4316.6\n",
      "evaluation/Returns Std                610.332\n",
      "evaluation/Returns Max               4586.6\n",
      "evaluation/Returns Min               2489.89\n",
      "evaluation/Estimation Bias Mean      1478.45\n",
      "evaluation/Estimation Bias Std        142.852\n",
      "evaluation/EB/Q_True Mean              43.8551\n",
      "evaluation/EB/Q_True Std              132.058\n",
      "evaluation/EB/Q_Pred Mean            1522.3\n",
      "evaluation/EB/Q_Pred Std               51.4258\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4316.6\n",
      "evaluation/Actions Mean                 0.0249822\n",
      "evaluation/Actions Std                  0.547593\n",
      "evaluation/Actions Max                  0.999701\n",
      "evaluation/Actions Min                 -0.999246\n",
      "time/backward_policy (s)                1.68116\n",
      "time/backward_zf1 (s)                   1.8231\n",
      "time/backward_zf2 (s)                   1.73153\n",
      "time/data sampling (s)                  0.285237\n",
      "time/data storing (s)                   0.0138099\n",
      "time/evaluation sampling (s)            1.71841\n",
      "time/exploration sampling (s)           0.318965\n",
      "time/logging (s)                        0.0126607\n",
      "time/preback_alpha (s)                  0.562349\n",
      "time/preback_policy (s)                 0.938787\n",
      "time/preback_start (s)                  0.142468\n",
      "time/preback_zf (s)                     5.0836\n",
      "time/saving (s)                         0.0195159\n",
      "time/training (s)                       2.60765\n",
      "time/epoch (s)                         16.9392\n",
      "time/total (s)                       1933.08\n",
      "Epoch                                 110\n",
      "---------------------------------  --------------\n",
      "2024-06-10 21:08:43.132495 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 111 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 122000\n",
      "trainer/ZF1 Loss                       -4.94018\n",
      "trainer/ZF2 Loss                       -7.34354\n",
      "trainer/ZF Expert Reward                8.6107\n",
      "trainer/ZF Policy Reward               -0.434074\n",
      "trainer/ZF CHI2 Term                   34.0228\n",
      "trainer/Policy Loss                 -1358.05\n",
      "trainer/Bias Loss                      78.4689\n",
      "trainer/Bias Value                     12.4478\n",
      "trainer/Policy Grad Norm              108.896\n",
      "trainer/Policy Param Norm              33.8008\n",
      "trainer/Zf1 Grad Norm                1706.7\n",
      "trainer/Zf1 Param Norm                 97.4575\n",
      "trainer/Zf2 Grad Norm                1264.43\n",
      "trainer/Zf2 Param Norm                100.906\n",
      "trainer/Z Expert Predictions Mean    1528.62\n",
      "trainer/Z Expert Predictions Std       44.9622\n",
      "trainer/Z Expert Predictions Max     1592\n",
      "trainer/Z Expert Predictions Min     1203.33\n",
      "trainer/Z Policy Predictions Mean    1351.95\n",
      "trainer/Z Policy Predictions Std      350.303\n",
      "trainer/Z Policy Predictions Max     1587.75\n",
      "trainer/Z Policy Predictions Min      -34.8248\n",
      "trainer/Z Expert Targets Mean        1520.01\n",
      "trainer/Z Expert Targets Std           45.8915\n",
      "trainer/Z Expert Targets Max         1583.99\n",
      "trainer/Z Expert Targets Min         1197.12\n",
      "trainer/Z Policy Targets Mean        1352.39\n",
      "trainer/Z Policy Targets Std          343.711\n",
      "trainer/Z Policy Targets Max         1575.88\n",
      "trainer/Z Policy Targets Min          -31.0879\n",
      "trainer/Log Pis Mean                   31.4342\n",
      "trainer/Log Pis Std                     9.04062\n",
      "trainer/Policy mu Mean                  0.195924\n",
      "trainer/Policy mu Std                   1.91262\n",
      "trainer/Policy log std Mean            -4.08202\n",
      "trainer/Policy log std Std              1.10849\n",
      "exploration/num steps total        116919\n",
      "exploration/num paths total           236\n",
      "evaluation/num steps total         880427\n",
      "evaluation/num paths total           1174\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.50621\n",
      "evaluation/Rewards Std                  1.1333\n",
      "evaluation/Rewards Max                  6.74094\n",
      "evaluation/Rewards Min                 -2.26854\n",
      "evaluation/Returns Mean              4506.21\n",
      "evaluation/Returns Std                112.34\n",
      "evaluation/Returns Max               4642.45\n",
      "evaluation/Returns Min               4304.78\n",
      "evaluation/Estimation Bias Mean      1457.06\n",
      "evaluation/Estimation Bias Std        143.898\n",
      "evaluation/EB/Q_True Mean              42.4827\n",
      "evaluation/EB/Q_True Std              130.833\n",
      "evaluation/EB/Q_Pred Mean            1499.54\n",
      "evaluation/EB/Q_Pred Std               64.784\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4506.21\n",
      "evaluation/Actions Mean                 0.0281049\n",
      "evaluation/Actions Std                  0.546985\n",
      "evaluation/Actions Max                  0.99988\n",
      "evaluation/Actions Min                 -0.999663\n",
      "time/backward_policy (s)                1.851\n",
      "time/backward_zf1 (s)                   2.01644\n",
      "time/backward_zf2 (s)                   1.94337\n",
      "time/data sampling (s)                  0.293275\n",
      "time/data storing (s)                   0.014173\n",
      "time/evaluation sampling (s)            1.70172\n",
      "time/exploration sampling (s)           0.321552\n",
      "time/logging (s)                        0.01211\n",
      "time/preback_alpha (s)                  0.567255\n",
      "time/preback_policy (s)                 1.02683\n",
      "time/preback_start (s)                  0.144444\n",
      "time/preback_zf (s)                     5.1045\n",
      "time/saving (s)                         0.00670818\n",
      "time/training (s)                       2.53362\n",
      "time/epoch (s)                         17.537\n",
      "time/total (s)                       1950.64\n",
      "Epoch                                 111\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:09:00.950970 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 112 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 123000\n",
      "trainer/ZF1 Loss                       -0.355663\n",
      "trainer/ZF2 Loss                       20.1259\n",
      "trainer/ZF Expert Reward                7.38035\n",
      "trainer/ZF Policy Reward                1.72255\n",
      "trainer/ZF CHI2 Term                   46.248\n",
      "trainer/Policy Loss                 -1368.76\n",
      "trainer/Bias Loss                     116.96\n",
      "trainer/Bias Value                     12.4238\n",
      "trainer/Policy Grad Norm               83.165\n",
      "trainer/Policy Param Norm              33.8483\n",
      "trainer/Zf1 Grad Norm                2801.22\n",
      "trainer/Zf1 Param Norm                 97.6341\n",
      "trainer/Zf2 Grad Norm                4303.09\n",
      "trainer/Zf2 Param Norm                101.052\n",
      "trainer/Z Expert Predictions Mean    1508.92\n",
      "trainer/Z Expert Predictions Std       60.3797\n",
      "trainer/Z Expert Predictions Max     1574.85\n",
      "trainer/Z Expert Predictions Min      897.082\n",
      "trainer/Z Policy Predictions Mean    1364.42\n",
      "trainer/Z Policy Predictions Std      295.01\n",
      "trainer/Z Policy Predictions Max     1563.49\n",
      "trainer/Z Policy Predictions Min      -38.4981\n",
      "trainer/Z Expert Targets Mean        1501.54\n",
      "trainer/Z Expert Targets Std           65.9235\n",
      "trainer/Z Expert Targets Max         1565.32\n",
      "trainer/Z Expert Targets Min          720.777\n",
      "trainer/Z Policy Targets Mean        1362.7\n",
      "trainer/Z Policy Targets Std          292.993\n",
      "trainer/Z Policy Targets Max         1557.64\n",
      "trainer/Z Policy Targets Min          -23.6191\n",
      "trainer/Log Pis Mean                   31.0152\n",
      "trainer/Log Pis Std                     8.65631\n",
      "trainer/Policy mu Mean                  0.142841\n",
      "trainer/Policy mu Std                   1.65014\n",
      "trainer/Policy log std Mean            -4.22754\n",
      "trainer/Policy log std Std              0.922639\n",
      "exploration/num steps total        117919\n",
      "exploration/num paths total           237\n",
      "evaluation/num steps total         889607\n",
      "evaluation/num paths total           1185\n",
      "evaluation/path length Mean           834.545\n",
      "evaluation/path length Std            287.156\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            133\n",
      "evaluation/Rewards Mean                 3.85978\n",
      "evaluation/Rewards Std                  2.3777\n",
      "evaluation/Rewards Max                  6.85976\n",
      "evaluation/Rewards Min                 -4.33541\n",
      "evaluation/Returns Mean              3221.16\n",
      "evaluation/Returns Std               1960.19\n",
      "evaluation/Returns Max               4730.39\n",
      "evaluation/Returns Min              -1364.57\n",
      "evaluation/Estimation Bias Mean      1300.74\n",
      "evaluation/Estimation Bias Std        435.696\n",
      "evaluation/EB/Q_True Mean              45.4415\n",
      "evaluation/EB/Q_True Std              133.22\n",
      "evaluation/EB/Q_Pred Mean            1346.18\n",
      "evaluation/EB/Q_Pred Std              429.561\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3221.16\n",
      "evaluation/Actions Mean                 0.0490829\n",
      "evaluation/Actions Std                  0.590039\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85294\n",
      "time/backward_zf1 (s)                   1.99457\n",
      "time/backward_zf2 (s)                   1.93017\n",
      "time/data sampling (s)                  0.29509\n",
      "time/data storing (s)                   0.0146772\n",
      "time/evaluation sampling (s)            2.15109\n",
      "time/exploration sampling (s)           0.329399\n",
      "time/logging (s)                        0.012546\n",
      "time/preback_alpha (s)                  0.568869\n",
      "time/preback_policy (s)                 1.07704\n",
      "time/preback_start (s)                  0.144969\n",
      "time/preback_zf (s)                     5.09022\n",
      "time/saving (s)                         0.00722619\n",
      "time/training (s)                       2.2759\n",
      "time/epoch (s)                         17.7447\n",
      "time/total (s)                       1968.41\n",
      "Epoch                                 112\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:09:19.796263 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 113 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 124000\n",
      "trainer/ZF1 Loss                       -1.10911\n",
      "trainer/ZF2 Loss                       -2.36385\n",
      "trainer/ZF Expert Reward               14.0279\n",
      "trainer/ZF Policy Reward                2.04568\n",
      "trainer/ZF CHI2 Term                   40.0666\n",
      "trainer/Policy Loss                 -1354.87\n",
      "trainer/Bias Loss                      77.2576\n",
      "trainer/Bias Value                     12.4353\n",
      "trainer/Policy Grad Norm              103.651\n",
      "trainer/Policy Param Norm              33.9003\n",
      "trainer/Zf1 Grad Norm                2606.76\n",
      "trainer/Zf1 Param Norm                 97.7927\n",
      "trainer/Zf2 Grad Norm                3038.76\n",
      "trainer/Zf2 Param Norm                101.214\n",
      "trainer/Z Expert Predictions Mean    1491.42\n",
      "trainer/Z Expert Predictions Std      117.15\n",
      "trainer/Z Expert Predictions Max     1570.72\n",
      "trainer/Z Expert Predictions Min      -13.5886\n",
      "trainer/Z Policy Predictions Mean    1345.46\n",
      "trainer/Z Policy Predictions Std      310.012\n",
      "trainer/Z Policy Predictions Max     1556.08\n",
      "trainer/Z Policy Predictions Min      -55.3515\n",
      "trainer/Z Expert Targets Mean        1477.39\n",
      "trainer/Z Expert Targets Std          118.1\n",
      "trainer/Z Expert Targets Max         1550.42\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1343.42\n",
      "trainer/Z Policy Targets Std          302.352\n",
      "trainer/Z Policy Targets Max         1542.3\n",
      "trainer/Z Policy Targets Min          -32.8015\n",
      "trainer/Log Pis Mean                   30.122\n",
      "trainer/Log Pis Std                     7.73963\n",
      "trainer/Policy mu Mean                  0.0994765\n",
      "trainer/Policy mu Std                   1.58302\n",
      "trainer/Policy log std Mean            -4.15701\n",
      "trainer/Policy log std Std              0.926383\n",
      "exploration/num steps total        118919\n",
      "exploration/num paths total           238\n",
      "evaluation/num steps total         899607\n",
      "evaluation/num paths total           1195\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.43902\n",
      "evaluation/Rewards Std                  0.949371\n",
      "evaluation/Rewards Max                  6.39564\n",
      "evaluation/Rewards Min                 -2.08901\n",
      "evaluation/Returns Mean              4439.02\n",
      "evaluation/Returns Std                 65.4744\n",
      "evaluation/Returns Max               4515.39\n",
      "evaluation/Returns Min               4331.45\n",
      "evaluation/Estimation Bias Mean      1441.57\n",
      "evaluation/Estimation Bias Std        129.596\n",
      "evaluation/EB/Q_True Mean              39.6484\n",
      "evaluation/EB/Q_True Std              122.438\n",
      "evaluation/EB/Q_Pred Mean            1481.21\n",
      "evaluation/EB/Q_Pred Std               50.6415\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4439.02\n",
      "evaluation/Actions Mean                 0.0250039\n",
      "evaluation/Actions Std                  0.529234\n",
      "evaluation/Actions Max                  0.999234\n",
      "evaluation/Actions Min                 -0.999715\n",
      "time/backward_policy (s)                2.01775\n",
      "time/backward_zf1 (s)                   2.30431\n",
      "time/backward_zf2 (s)                   2.18554\n",
      "time/data sampling (s)                  0.346095\n",
      "time/data storing (s)                   0.0145499\n",
      "time/evaluation sampling (s)            1.78476\n",
      "time/exploration sampling (s)           0.331335\n",
      "time/logging (s)                        0.0119281\n",
      "time/preback_alpha (s)                  0.623931\n",
      "time/preback_policy (s)                 1.1836\n",
      "time/preback_start (s)                  0.155213\n",
      "time/preback_zf (s)                     5.36903\n",
      "time/saving (s)                         0.00664686\n",
      "time/training (s)                       2.43738\n",
      "time/epoch (s)                         18.7721\n",
      "time/total (s)                       1987.2\n",
      "Epoch                                 113\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:09:37.610257 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 114 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 125000\n",
      "trainer/ZF1 Loss                       17.6968\n",
      "trainer/ZF2 Loss                       -3.75229\n",
      "trainer/ZF Expert Reward               14.153\n",
      "trainer/ZF Policy Reward                6.64739\n",
      "trainer/ZF CHI2 Term                   45.71\n",
      "trainer/Policy Loss                 -1314.61\n",
      "trainer/Bias Loss                     108.291\n",
      "trainer/Bias Value                     12.4396\n",
      "trainer/Policy Grad Norm              109.511\n",
      "trainer/Policy Param Norm              33.9508\n",
      "trainer/Zf1 Grad Norm                5770.44\n",
      "trainer/Zf1 Param Norm                 97.9663\n",
      "trainer/Zf2 Grad Norm                 986.013\n",
      "trainer/Zf2 Param Norm                101.371\n",
      "trainer/Z Expert Predictions Mean    1487.56\n",
      "trainer/Z Expert Predictions Std       43.199\n",
      "trainer/Z Expert Predictions Max     1553.39\n",
      "trainer/Z Expert Predictions Min     1260.97\n",
      "trainer/Z Policy Predictions Mean    1312.14\n",
      "trainer/Z Policy Predictions Std      361.807\n",
      "trainer/Z Policy Predictions Max     1537.89\n",
      "trainer/Z Policy Predictions Min      -48.1152\n",
      "trainer/Z Expert Targets Mean        1473.41\n",
      "trainer/Z Expert Targets Std           43.4174\n",
      "trainer/Z Expert Targets Max         1542\n",
      "trainer/Z Expert Targets Min         1251.38\n",
      "trainer/Z Policy Targets Mean        1305.49\n",
      "trainer/Z Policy Targets Std          353.653\n",
      "trainer/Z Policy Targets Max         1529.28\n",
      "trainer/Z Policy Targets Min          -32.6962\n",
      "trainer/Log Pis Mean                   31.5476\n",
      "trainer/Log Pis Std                     9.03504\n",
      "trainer/Policy mu Mean                  0.0830911\n",
      "trainer/Policy mu Std                   1.99086\n",
      "trainer/Policy log std Mean            -4.15722\n",
      "trainer/Policy log std Std              1.06086\n",
      "exploration/num steps total        119528\n",
      "exploration/num paths total           239\n",
      "evaluation/num steps total         908100\n",
      "evaluation/num paths total           1205\n",
      "evaluation/path length Mean           849.3\n",
      "evaluation/path length Std            303.704\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            163\n",
      "evaluation/Rewards Mean                 4.63577\n",
      "evaluation/Rewards Std                  1.15676\n",
      "evaluation/Rewards Max                  6.96281\n",
      "evaluation/Rewards Min                 -1.6666\n",
      "evaluation/Returns Mean              3937.16\n",
      "evaluation/Returns Std               1463.43\n",
      "evaluation/Returns Max               4841.28\n",
      "evaluation/Returns Min                585.707\n",
      "evaluation/Estimation Bias Mean      1402.82\n",
      "evaluation/Estimation Bias Std        161.067\n",
      "evaluation/EB/Q_True Mean              48.6901\n",
      "evaluation/EB/Q_True Std              136.472\n",
      "evaluation/EB/Q_Pred Mean            1451.51\n",
      "evaluation/EB/Q_Pred Std               70.2843\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3937.16\n",
      "evaluation/Actions Mean                 0.0293469\n",
      "evaluation/Actions Std                  0.532235\n",
      "evaluation/Actions Max                  0.999798\n",
      "evaluation/Actions Min                 -0.999824\n",
      "time/backward_policy (s)                1.95413\n",
      "time/backward_zf1 (s)                   2.06938\n",
      "time/backward_zf2 (s)                   2.00566\n",
      "time/data sampling (s)                  0.302805\n",
      "time/data storing (s)                   0.015503\n",
      "time/evaluation sampling (s)            1.7708\n",
      "time/exploration sampling (s)           0.333467\n",
      "time/logging (s)                        0.0107389\n",
      "time/preback_alpha (s)                  0.58486\n",
      "time/preback_policy (s)                 1.14023\n",
      "time/preback_start (s)                  0.150568\n",
      "time/preback_zf (s)                     5.12496\n",
      "time/saving (s)                         0.00616448\n",
      "time/training (s)                       2.27643\n",
      "time/epoch (s)                         17.7457\n",
      "time/total (s)                       2004.96\n",
      "Epoch                                 114\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:09:55.159661 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 115 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 126000\n",
      "trainer/ZF1 Loss                        9.62029\n",
      "trainer/ZF2 Loss                       27.83\n",
      "trainer/ZF Expert Reward               10.0743\n",
      "trainer/ZF Policy Reward               -1.9508\n",
      "trainer/ZF CHI2 Term                   60.6187\n",
      "trainer/Policy Loss                 -1320.23\n",
      "trainer/Bias Loss                     129.266\n",
      "trainer/Bias Value                     12.4382\n",
      "trainer/Policy Grad Norm              154.25\n",
      "trainer/Policy Param Norm              34.0021\n",
      "trainer/Zf1 Grad Norm                6533.07\n",
      "trainer/Zf1 Param Norm                 98.1393\n",
      "trainer/Zf2 Grad Norm                6382.5\n",
      "trainer/Zf2 Param Norm                101.546\n",
      "trainer/Z Expert Predictions Mean    1462.58\n",
      "trainer/Z Expert Predictions Std      113.359\n",
      "trainer/Z Expert Predictions Max     1541.29\n",
      "trainer/Z Expert Predictions Min     -127.139\n",
      "trainer/Z Policy Predictions Mean    1310.2\n",
      "trainer/Z Policy Predictions Std      313.049\n",
      "trainer/Z Policy Predictions Max     1532.07\n",
      "trainer/Z Policy Predictions Min      -46.8818\n",
      "trainer/Z Expert Targets Mean        1452.5\n",
      "trainer/Z Expert Targets Std          106.119\n",
      "trainer/Z Expert Targets Max         1530.96\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1312.15\n",
      "trainer/Z Policy Targets Std          306.357\n",
      "trainer/Z Policy Targets Max         1523.59\n",
      "trainer/Z Policy Targets Min          -37.986\n",
      "trainer/Log Pis Mean                   30.1701\n",
      "trainer/Log Pis Std                     7.89816\n",
      "trainer/Policy mu Mean                  0.104225\n",
      "trainer/Policy mu Std                   1.7635\n",
      "trainer/Policy log std Mean            -4.12328\n",
      "trainer/Policy log std Std              1.01555\n",
      "exploration/num steps total        122528\n",
      "exploration/num paths total           242\n",
      "evaluation/num steps total         918100\n",
      "evaluation/num paths total           1215\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66459\n",
      "evaluation/Rewards Std                  1.09992\n",
      "evaluation/Rewards Max                  6.8471\n",
      "evaluation/Rewards Min                 -2.44077\n",
      "evaluation/Returns Mean              4664.59\n",
      "evaluation/Returns Std                 66.4227\n",
      "evaluation/Returns Max               4758\n",
      "evaluation/Returns Min               4550.14\n",
      "evaluation/Estimation Bias Mean      1410.94\n",
      "evaluation/Estimation Bias Std        145.08\n",
      "evaluation/EB/Q_True Mean              42.6971\n",
      "evaluation/EB/Q_True Std              132.171\n",
      "evaluation/EB/Q_Pred Mean            1453.64\n",
      "evaluation/EB/Q_Pred Std               60.5437\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4664.59\n",
      "evaluation/Actions Mean                 0.0120471\n",
      "evaluation/Actions Std                  0.533281\n",
      "evaluation/Actions Max                  0.999506\n",
      "evaluation/Actions Min                 -0.999023\n",
      "time/backward_policy (s)                1.80643\n",
      "time/backward_zf1 (s)                   1.9973\n",
      "time/backward_zf2 (s)                   1.90241\n",
      "time/data sampling (s)                  0.305054\n",
      "time/data storing (s)                   0.0150042\n",
      "time/evaluation sampling (s)            1.75309\n",
      "time/exploration sampling (s)           0.337537\n",
      "time/logging (s)                        0.0125383\n",
      "time/preback_alpha (s)                  0.578208\n",
      "time/preback_policy (s)                 1.047\n",
      "time/preback_start (s)                  0.148327\n",
      "time/preback_zf (s)                     5.14716\n",
      "time/saving (s)                         0.00647831\n",
      "time/training (s)                       2.42626\n",
      "time/epoch (s)                         17.4828\n",
      "time/total (s)                       2022.47\n",
      "Epoch                                 115\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:10:13.732412 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 116 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 127000\n",
      "trainer/ZF1 Loss                       10.7623\n",
      "trainer/ZF2 Loss                       30.9819\n",
      "trainer/ZF Expert Reward               15.3097\n",
      "trainer/ZF Policy Reward                8.00667\n",
      "trainer/ZF CHI2 Term                   57.7561\n",
      "trainer/Policy Loss                 -1293.61\n",
      "trainer/Bias Loss                     158.073\n",
      "trainer/Bias Value                     12.4624\n",
      "trainer/Policy Grad Norm              118.651\n",
      "trainer/Policy Param Norm              34.0475\n",
      "trainer/Zf1 Grad Norm                1868.59\n",
      "trainer/Zf1 Param Norm                 98.3054\n",
      "trainer/Zf2 Grad Norm                3645.4\n",
      "trainer/Zf2 Param Norm                101.714\n",
      "trainer/Z Expert Predictions Mean    1463.2\n",
      "trainer/Z Expert Predictions Std       45.835\n",
      "trainer/Z Expert Predictions Max     1539.46\n",
      "trainer/Z Expert Predictions Min     1229.39\n",
      "trainer/Z Policy Predictions Mean    1290.08\n",
      "trainer/Z Policy Predictions Std      365.657\n",
      "trainer/Z Policy Predictions Max     1530.72\n",
      "trainer/Z Policy Predictions Min      -58.9665\n",
      "trainer/Z Expert Targets Mean        1447.89\n",
      "trainer/Z Expert Targets Std           45.9059\n",
      "trainer/Z Expert Targets Max         1506.94\n",
      "trainer/Z Expert Targets Min         1199.41\n",
      "trainer/Z Policy Targets Mean        1282.08\n",
      "trainer/Z Policy Targets Std          359.923\n",
      "trainer/Z Policy Targets Max         1503.56\n",
      "trainer/Z Policy Targets Min          -42.534\n",
      "trainer/Log Pis Mean                   29.8798\n",
      "trainer/Log Pis Std                     8.06064\n",
      "trainer/Policy mu Mean                  0.122851\n",
      "trainer/Policy mu Std                   1.98323\n",
      "trainer/Policy log std Mean            -4.125\n",
      "trainer/Policy log std Std              1.07247\n",
      "exploration/num steps total        122528\n",
      "exploration/num paths total           242\n",
      "evaluation/num steps total         926514\n",
      "evaluation/num paths total           1225\n",
      "evaluation/path length Mean           841.4\n",
      "evaluation/path length Std            249.567\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            317\n",
      "evaluation/Rewards Mean                 4.61105\n",
      "evaluation/Rewards Std                  1.10407\n",
      "evaluation/Rewards Max                  6.74599\n",
      "evaluation/Rewards Min                 -1.85246\n",
      "evaluation/Returns Mean              3879.74\n",
      "evaluation/Returns Std               1210.82\n",
      "evaluation/Returns Max               4801.41\n",
      "evaluation/Returns Min               1469.24\n",
      "evaluation/Estimation Bias Mean      1385.73\n",
      "evaluation/Estimation Bias Std        163.647\n",
      "evaluation/EB/Q_True Mean              51.8313\n",
      "evaluation/EB/Q_True Std              144.567\n",
      "evaluation/EB/Q_Pred Mean            1437.56\n",
      "evaluation/EB/Q_Pred Std               65.1654\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3879.74\n",
      "evaluation/Actions Mean                 0.0243009\n",
      "evaluation/Actions Std                  0.536027\n",
      "evaluation/Actions Max                  0.999869\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.10585\n",
      "time/backward_zf1 (s)                   2.21828\n",
      "time/backward_zf2 (s)                   2.17589\n",
      "time/data sampling (s)                  0.334432\n",
      "time/data storing (s)                   0.0145811\n",
      "time/evaluation sampling (s)            1.75473\n",
      "time/exploration sampling (s)           0.323216\n",
      "time/logging (s)                        0.0100357\n",
      "time/preback_alpha (s)                  0.605495\n",
      "time/preback_policy (s)                 1.23556\n",
      "time/preback_start (s)                  0.154344\n",
      "time/preback_zf (s)                     5.25774\n",
      "time/saving (s)                         0.00655673\n",
      "time/training (s)                       2.30248\n",
      "time/epoch (s)                         18.4992\n",
      "time/total (s)                       2040.99\n",
      "Epoch                                 116\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:10:32.014877 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 117 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 128000\n",
      "trainer/ZF1 Loss                       -4.72055\n",
      "trainer/ZF2 Loss                        7.56189\n",
      "trainer/ZF Expert Reward               11.1114\n",
      "trainer/ZF Policy Reward                0.680548\n",
      "trainer/ZF CHI2 Term                   42.9473\n",
      "trainer/Policy Loss                 -1260.46\n",
      "trainer/Bias Loss                      70.271\n",
      "trainer/Bias Value                     12.4711\n",
      "trainer/Policy Grad Norm               90.1599\n",
      "trainer/Policy Param Norm              34.099\n",
      "trainer/Zf1 Grad Norm                1390.77\n",
      "trainer/Zf1 Param Norm                 98.497\n",
      "trainer/Zf2 Grad Norm                2031.84\n",
      "trainer/Zf2 Param Norm                101.878\n",
      "trainer/Z Expert Predictions Mean    1441.68\n",
      "trainer/Z Expert Predictions Std       97.9264\n",
      "trainer/Z Expert Predictions Max     1507.01\n",
      "trainer/Z Expert Predictions Min       57.4352\n",
      "trainer/Z Policy Predictions Mean    1245.89\n",
      "trainer/Z Policy Predictions Std      357.229\n",
      "trainer/Z Policy Predictions Max     1488.76\n",
      "trainer/Z Policy Predictions Min      -51.3827\n",
      "trainer/Z Expert Targets Mean        1430.57\n",
      "trainer/Z Expert Targets Std          101.741\n",
      "trainer/Z Expert Targets Max         1493.42\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1245.21\n",
      "trainer/Z Policy Targets Std          351.804\n",
      "trainer/Z Policy Targets Max         1482.91\n",
      "trainer/Z Policy Targets Min          -33.9419\n",
      "trainer/Log Pis Mean                   31.4099\n",
      "trainer/Log Pis Std                     9.35759\n",
      "trainer/Policy mu Mean                  0.0796082\n",
      "trainer/Policy mu Std                   1.98912\n",
      "trainer/Policy log std Mean            -4.03758\n",
      "trainer/Policy log std Std              1.10306\n",
      "exploration/num steps total        123528\n",
      "exploration/num paths total           243\n",
      "evaluation/num steps total         933164\n",
      "evaluation/num paths total           1235\n",
      "evaluation/path length Mean           665\n",
      "evaluation/path length Std            357.474\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             47\n",
      "evaluation/Rewards Mean                 4.50673\n",
      "evaluation/Rewards Std                  1.16307\n",
      "evaluation/Rewards Max                  6.64491\n",
      "evaluation/Rewards Min                 -2.04538\n",
      "evaluation/Returns Mean              2996.97\n",
      "evaluation/Returns Std               1738.68\n",
      "evaluation/Returns Max               4750.63\n",
      "evaluation/Returns Min                 93.2799\n",
      "evaluation/Estimation Bias Mean      1348.48\n",
      "evaluation/Estimation Bias Std        197.834\n",
      "evaluation/EB/Q_True Mean              66.0401\n",
      "evaluation/EB/Q_True Std              161.349\n",
      "evaluation/EB/Q_Pred Mean            1414.52\n",
      "evaluation/EB/Q_Pred Std               86.9297\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2996.97\n",
      "evaluation/Actions Mean                 0.0208696\n",
      "evaluation/Actions Std                  0.52352\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99445\n",
      "time/backward_zf1 (s)                   2.15188\n",
      "time/backward_zf2 (s)                   2.07831\n",
      "time/data sampling (s)                  0.327791\n",
      "time/data storing (s)                   0.0146794\n",
      "time/evaluation sampling (s)            1.82327\n",
      "time/exploration sampling (s)           0.333588\n",
      "time/logging (s)                        0.00913643\n",
      "time/preback_alpha (s)                  0.604324\n",
      "time/preback_policy (s)                 1.1723\n",
      "time/preback_start (s)                  0.153042\n",
      "time/preback_zf (s)                     5.19138\n",
      "time/saving (s)                         0.00688982\n",
      "time/training (s)                       2.34862\n",
      "time/epoch (s)                         18.2097\n",
      "time/total (s)                       2059.22\n",
      "Epoch                                 117\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:10:50.116579 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 118 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 129000\n",
      "trainer/ZF1 Loss                      421.068\n",
      "trainer/ZF2 Loss                      413.169\n",
      "trainer/ZF Expert Reward               13.7222\n",
      "trainer/ZF Policy Reward                7.20324\n",
      "trainer/ZF CHI2 Term                  454.476\n",
      "trainer/Policy Loss                 -1228.36\n",
      "trainer/Bias Loss                     551.25\n",
      "trainer/Bias Value                     12.5035\n",
      "trainer/Policy Grad Norm               82.7563\n",
      "trainer/Policy Param Norm              34.1431\n",
      "trainer/Zf1 Grad Norm                2632.45\n",
      "trainer/Zf1 Param Norm                 98.6664\n",
      "trainer/Zf2 Grad Norm                3325.85\n",
      "trainer/Zf2 Param Norm                102.049\n",
      "trainer/Z Expert Predictions Mean    1433.08\n",
      "trainer/Z Expert Predictions Std       45.0903\n",
      "trainer/Z Expert Predictions Max     1487.21\n",
      "trainer/Z Expert Predictions Min     1189.17\n",
      "trainer/Z Policy Predictions Mean    1225.44\n",
      "trainer/Z Policy Predictions Std      374.314\n",
      "trainer/Z Policy Predictions Max     1485.62\n",
      "trainer/Z Policy Predictions Min      -60.6996\n",
      "trainer/Z Expert Targets Mean        1419.36\n",
      "trainer/Z Expert Targets Std           55.6475\n",
      "trainer/Z Expert Targets Max         1488.28\n",
      "trainer/Z Expert Targets Min          911.81\n",
      "trainer/Z Policy Targets Mean        1218.24\n",
      "trainer/Z Policy Targets Std          377.136\n",
      "trainer/Z Policy Targets Max         1475.28\n",
      "trainer/Z Policy Targets Min          -47.8297\n",
      "trainer/Log Pis Mean                   31.15\n",
      "trainer/Log Pis Std                     9.22345\n",
      "trainer/Policy mu Mean                  0.162457\n",
      "trainer/Policy mu Std                   2.07954\n",
      "trainer/Policy log std Mean            -3.94327\n",
      "trainer/Policy log std Std              1.24418\n",
      "exploration/num steps total        123835\n",
      "exploration/num paths total           244\n",
      "evaluation/num steps total         941446\n",
      "evaluation/num paths total           1246\n",
      "evaluation/path length Mean           752.909\n",
      "evaluation/path length Std            344.842\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             72\n",
      "evaluation/Rewards Mean                 4.60947\n",
      "evaluation/Rewards Std                  1.14897\n",
      "evaluation/Rewards Max                  6.81399\n",
      "evaluation/Rewards Min                 -1.77527\n",
      "evaluation/Returns Mean              3470.51\n",
      "evaluation/Returns Std               1674.4\n",
      "evaluation/Returns Max               4803.49\n",
      "evaluation/Returns Min                183.36\n",
      "evaluation/Estimation Bias Mean      1357.69\n",
      "evaluation/Estimation Bias Std        170.195\n",
      "evaluation/EB/Q_True Mean              51.7799\n",
      "evaluation/EB/Q_True Std              143.807\n",
      "evaluation/EB/Q_Pred Mean            1409.47\n",
      "evaluation/EB/Q_Pred Std               69.12\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3470.51\n",
      "evaluation/Actions Mean                 0.0246866\n",
      "evaluation/Actions Std                  0.537966\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.00303\n",
      "time/backward_zf1 (s)                   2.15165\n",
      "time/backward_zf2 (s)                   2.06275\n",
      "time/data sampling (s)                  0.313036\n",
      "time/data storing (s)                   0.0140849\n",
      "time/evaluation sampling (s)            1.7688\n",
      "time/exploration sampling (s)           0.322311\n",
      "time/logging (s)                        0.0103745\n",
      "time/preback_alpha (s)                  0.589462\n",
      "time/preback_policy (s)                 1.16479\n",
      "time/preback_start (s)                  0.148435\n",
      "time/preback_zf (s)                     5.16984\n",
      "time/saving (s)                         0.00595264\n",
      "time/training (s)                       2.30987\n",
      "time/epoch (s)                         18.0344\n",
      "time/total (s)                       2077.27\n",
      "Epoch                                 118\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:11:07.553058 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 119 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 130000\n",
      "trainer/ZF1 Loss                       29.2615\n",
      "trainer/ZF2 Loss                       20.3832\n",
      "trainer/ZF Expert Reward               15.8309\n",
      "trainer/ZF Policy Reward                3.0484\n",
      "trainer/ZF CHI2 Term                   67.5108\n",
      "trainer/Policy Loss                 -1246.85\n",
      "trainer/Bias Loss                      80.7671\n",
      "trainer/Bias Value                     12.4867\n",
      "trainer/Policy Grad Norm              101.104\n",
      "trainer/Policy Param Norm              34.1896\n",
      "trainer/Zf1 Grad Norm                4681.78\n",
      "trainer/Zf1 Param Norm                 98.8623\n",
      "trainer/Zf2 Grad Norm                3629.32\n",
      "trainer/Zf2 Param Norm                102.225\n",
      "trainer/Z Expert Predictions Mean    1428.05\n",
      "trainer/Z Expert Predictions Std       51.2293\n",
      "trainer/Z Expert Predictions Max     1494.49\n",
      "trainer/Z Expert Predictions Min     1091.43\n",
      "trainer/Z Policy Predictions Mean    1240.66\n",
      "trainer/Z Policy Predictions Std      350.62\n",
      "trainer/Z Policy Predictions Max     1483.51\n",
      "trainer/Z Policy Predictions Min      -66.1185\n",
      "trainer/Z Expert Targets Mean        1412.22\n",
      "trainer/Z Expert Targets Std           51.0238\n",
      "trainer/Z Expert Targets Max         1474.97\n",
      "trainer/Z Expert Targets Min         1068.85\n",
      "trainer/Z Policy Targets Mean        1237.62\n",
      "trainer/Z Policy Targets Std          343.584\n",
      "trainer/Z Policy Targets Max         1471.31\n",
      "trainer/Z Policy Targets Min          -56.4264\n",
      "trainer/Log Pis Mean                   30.2081\n",
      "trainer/Log Pis Std                     8.12105\n",
      "trainer/Policy mu Mean                  0.121065\n",
      "trainer/Policy mu Std                   1.8269\n",
      "trainer/Policy log std Mean            -4.09477\n",
      "trainer/Policy log std Std              1.04112\n",
      "exploration/num steps total        124835\n",
      "exploration/num paths total           245\n",
      "evaluation/num steps total         951446\n",
      "evaluation/num paths total           1256\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.17108\n",
      "evaluation/Rewards Std                  1.85259\n",
      "evaluation/Rewards Max                  6.74233\n",
      "evaluation/Rewards Min                 -4.45256\n",
      "evaluation/Returns Mean              4171.08\n",
      "evaluation/Returns Std               1136.87\n",
      "evaluation/Returns Max               4687.95\n",
      "evaluation/Returns Min                785.637\n",
      "evaluation/Estimation Bias Mean      1305.39\n",
      "evaluation/Estimation Bias Std        298.176\n",
      "evaluation/EB/Q_True Mean              42.3604\n",
      "evaluation/EB/Q_True Std              130.549\n",
      "evaluation/EB/Q_Pred Mean            1347.75\n",
      "evaluation/EB/Q_Pred Std              208.947\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4171.08\n",
      "evaluation/Actions Mean                 0.00850231\n",
      "evaluation/Actions Std                  0.580856\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84147\n",
      "time/backward_zf1 (s)                   1.99677\n",
      "time/backward_zf2 (s)                   1.91798\n",
      "time/data sampling (s)                  0.295408\n",
      "time/data storing (s)                   0.014516\n",
      "time/evaluation sampling (s)            1.7595\n",
      "time/exploration sampling (s)           0.323967\n",
      "time/logging (s)                        0.0125734\n",
      "time/preback_alpha (s)                  0.571516\n",
      "time/preback_policy (s)                 1.08444\n",
      "time/preback_start (s)                  0.145765\n",
      "time/preback_zf (s)                     5.11133\n",
      "time/saving (s)                         0.00664942\n",
      "time/training (s)                       2.29119\n",
      "time/epoch (s)                         17.3731\n",
      "time/total (s)                       2094.66\n",
      "Epoch                                 119\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:11:25.192406 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 120 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 131000\n",
      "trainer/ZF1 Loss                      141.85\n",
      "trainer/ZF2 Loss                       27.2291\n",
      "trainer/ZF Expert Reward               14.6501\n",
      "trainer/ZF Policy Reward                2.45038\n",
      "trainer/ZF CHI2 Term                  126.787\n",
      "trainer/Policy Loss                 -1254.28\n",
      "trainer/Bias Loss                     764.743\n",
      "trainer/Bias Value                     12.5192\n",
      "trainer/Policy Grad Norm              106.83\n",
      "trainer/Policy Param Norm              34.2374\n",
      "trainer/Zf1 Grad Norm               27291.1\n",
      "trainer/Zf1 Param Norm                 99.0607\n",
      "trainer/Zf2 Grad Norm                8423.36\n",
      "trainer/Zf2 Param Norm                102.396\n",
      "trainer/Z Expert Predictions Mean    1407.93\n",
      "trainer/Z Expert Predictions Std       94.4384\n",
      "trainer/Z Expert Predictions Max     1475.28\n",
      "trainer/Z Expert Predictions Min      382.483\n",
      "trainer/Z Policy Predictions Mean    1251.55\n",
      "trainer/Z Policy Predictions Std      335.005\n",
      "trainer/Z Policy Predictions Max     1469.13\n",
      "trainer/Z Policy Predictions Min     -136.089\n",
      "trainer/Z Expert Targets Mean        1393.28\n",
      "trainer/Z Expert Targets Std          129.258\n",
      "trainer/Z Expert Targets Max         1452.48\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1249.1\n",
      "trainer/Z Policy Targets Std          329.339\n",
      "trainer/Z Policy Targets Max         1453.23\n",
      "trainer/Z Policy Targets Min          -47.4791\n",
      "trainer/Log Pis Mean                   30.3511\n",
      "trainer/Log Pis Std                     6.91746\n",
      "trainer/Policy mu Mean                  0.100837\n",
      "trainer/Policy mu Std                   1.6955\n",
      "trainer/Policy log std Mean            -4.17539\n",
      "trainer/Policy log std Std              1.07976\n",
      "exploration/num steps total        125835\n",
      "exploration/num paths total           246\n",
      "evaluation/num steps total         960864\n",
      "evaluation/num paths total           1266\n",
      "evaluation/path length Mean           941.8\n",
      "evaluation/path length Std            174.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            418\n",
      "evaluation/Rewards Mean                 4.59086\n",
      "evaluation/Rewards Std                  1.05192\n",
      "evaluation/Rewards Max                  6.62142\n",
      "evaluation/Rewards Min                 -2.62383\n",
      "evaluation/Returns Mean              4323.67\n",
      "evaluation/Returns Std                845.394\n",
      "evaluation/Returns Max               4792.26\n",
      "evaluation/Returns Min               1829.33\n",
      "evaluation/Estimation Bias Mean      1348.86\n",
      "evaluation/Estimation Bias Std        154.876\n",
      "evaluation/EB/Q_True Mean              46.5542\n",
      "evaluation/EB/Q_True Std              138.814\n",
      "evaluation/EB/Q_Pred Mean            1395.42\n",
      "evaluation/EB/Q_Pred Std               58.4016\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4323.67\n",
      "evaluation/Actions Mean                 0.0215631\n",
      "evaluation/Actions Std                  0.534513\n",
      "evaluation/Actions Max                  0.999874\n",
      "evaluation/Actions Min                 -0.999635\n",
      "time/backward_policy (s)                1.88639\n",
      "time/backward_zf1 (s)                   2.03288\n",
      "time/backward_zf2 (s)                   1.94237\n",
      "time/data sampling (s)                  0.325019\n",
      "time/data storing (s)                   0.0142511\n",
      "time/evaluation sampling (s)            1.75673\n",
      "time/exploration sampling (s)           0.319599\n",
      "time/logging (s)                        0.0121532\n",
      "time/preback_alpha (s)                  0.581975\n",
      "time/preback_policy (s)                 1.0961\n",
      "time/preback_start (s)                  0.150239\n",
      "time/preback_zf (s)                     5.12877\n",
      "time/saving (s)                         0.00652686\n",
      "time/training (s)                       2.31423\n",
      "time/epoch (s)                         17.5672\n",
      "time/total (s)                       2112.25\n",
      "Epoch                                 120\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:11:42.886475 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 121 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 132000\n",
      "trainer/ZF1 Loss                       -9.52976\n",
      "trainer/ZF2 Loss                       -2.0377\n",
      "trainer/ZF Expert Reward               13.6993\n",
      "trainer/ZF Policy Reward                3.74676\n",
      "trainer/ZF CHI2 Term                   34.7516\n",
      "trainer/Policy Loss                 -1248.21\n",
      "trainer/Bias Loss                      69.9632\n",
      "trainer/Bias Value                     12.551\n",
      "trainer/Policy Grad Norm               84.2145\n",
      "trainer/Policy Param Norm              34.2865\n",
      "trainer/Zf1 Grad Norm                1434.85\n",
      "trainer/Zf1 Param Norm                 99.2527\n",
      "trainer/Zf2 Grad Norm                2015.94\n",
      "trainer/Zf2 Param Norm                102.58\n",
      "trainer/Z Expert Predictions Mean    1395.94\n",
      "trainer/Z Expert Predictions Std       94.6187\n",
      "trainer/Z Expert Predictions Max     1464.53\n",
      "trainer/Z Expert Predictions Min       76.12\n",
      "trainer/Z Policy Predictions Mean    1243.28\n",
      "trainer/Z Policy Predictions Std      328.93\n",
      "trainer/Z Policy Predictions Max     1454.05\n",
      "trainer/Z Policy Predictions Min      -68.2254\n",
      "trainer/Z Expert Targets Mean        1382.24\n",
      "trainer/Z Expert Targets Std           99.592\n",
      "trainer/Z Expert Targets Max         1453.52\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1239.54\n",
      "trainer/Z Policy Targets Std          323.922\n",
      "trainer/Z Policy Targets Max         1432.43\n",
      "trainer/Z Policy Targets Min          -56.0133\n",
      "trainer/Log Pis Mean                   30.8917\n",
      "trainer/Log Pis Std                     8.78052\n",
      "trainer/Policy mu Mean                  0.0676881\n",
      "trainer/Policy mu Std                   1.81944\n",
      "trainer/Policy log std Mean            -4.21699\n",
      "trainer/Policy log std Std              1.03775\n",
      "exploration/num steps total        127495\n",
      "exploration/num paths total           248\n",
      "evaluation/num steps total         969815\n",
      "evaluation/num paths total           1276\n",
      "evaluation/path length Mean           895.1\n",
      "evaluation/path length Std            288.405\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             33\n",
      "evaluation/Rewards Mean                 3.62575\n",
      "evaluation/Rewards Std                  2.63992\n",
      "evaluation/Rewards Max                  6.54582\n",
      "evaluation/Rewards Min                 -5.74165\n",
      "evaluation/Returns Mean              3245.41\n",
      "evaluation/Returns Std               2256.02\n",
      "evaluation/Returns Max               4854.46\n",
      "evaluation/Returns Min              -1890.04\n",
      "evaluation/Estimation Bias Mean      1158.87\n",
      "evaluation/Estimation Bias Std        436.44\n",
      "evaluation/EB/Q_True Mean              43.2224\n",
      "evaluation/EB/Q_True Std              126.239\n",
      "evaluation/EB/Q_Pred Mean            1202.09\n",
      "evaluation/EB/Q_Pred Std              435.018\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3245.41\n",
      "evaluation/Actions Mean                 0.0621765\n",
      "evaluation/Actions Std                  0.593908\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95425\n",
      "time/backward_zf1 (s)                   2.10888\n",
      "time/backward_zf2 (s)                   2.04907\n",
      "time/data sampling (s)                  0.307535\n",
      "time/data storing (s)                   0.0142936\n",
      "time/evaluation sampling (s)            1.79803\n",
      "time/exploration sampling (s)           0.326029\n",
      "time/logging (s)                        0.0116272\n",
      "time/preback_alpha (s)                  0.57532\n",
      "time/preback_policy (s)                 1.18729\n",
      "time/preback_start (s)                  0.147992\n",
      "time/preback_zf (s)                     5.09873\n",
      "time/saving (s)                         0.00600446\n",
      "time/training (s)                       2.04091\n",
      "time/epoch (s)                         17.626\n",
      "time/total (s)                       2129.9\n",
      "Epoch                                 121\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:12:00.732269 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 122 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 133000\n",
      "trainer/ZF1 Loss                      348.451\n",
      "trainer/ZF2 Loss                      371.702\n",
      "trainer/ZF Expert Reward               10.0982\n",
      "trainer/ZF Policy Reward                9.52184\n",
      "trainer/ZF CHI2 Term                  391.725\n",
      "trainer/Policy Loss                 -1195.48\n",
      "trainer/Bias Loss                      58.1525\n",
      "trainer/Bias Value                     12.5545\n",
      "trainer/Policy Grad Norm               92.9284\n",
      "trainer/Policy Param Norm              34.3344\n",
      "trainer/Zf1 Grad Norm                1828.88\n",
      "trainer/Zf1 Param Norm                 99.4441\n",
      "trainer/Zf2 Grad Norm                2639.78\n",
      "trainer/Zf2 Param Norm                102.757\n",
      "trainer/Z Expert Predictions Mean    1388.22\n",
      "trainer/Z Expert Predictions Std       49.079\n",
      "trainer/Z Expert Predictions Max     1456.07\n",
      "trainer/Z Expert Predictions Min     1068.43\n",
      "trainer/Z Policy Predictions Mean    1191.9\n",
      "trainer/Z Policy Predictions Std      370.578\n",
      "trainer/Z Policy Predictions Max     1459.93\n",
      "trainer/Z Policy Predictions Min      -64.9673\n",
      "trainer/Z Expert Targets Mean        1378.13\n",
      "trainer/Z Expert Targets Std           49.1849\n",
      "trainer/Z Expert Targets Max         1442.11\n",
      "trainer/Z Expert Targets Min         1050.97\n",
      "trainer/Z Policy Targets Mean        1182.37\n",
      "trainer/Z Policy Targets Std          372.129\n",
      "trainer/Z Policy Targets Max         1434.85\n",
      "trainer/Z Policy Targets Min          -54.0492\n",
      "trainer/Log Pis Mean                   31.3862\n",
      "trainer/Log Pis Std                     9.29704\n",
      "trainer/Policy mu Mean                  0.175001\n",
      "trainer/Policy mu Std                   1.93481\n",
      "trainer/Policy log std Mean            -4.06436\n",
      "trainer/Policy log std Std              1.13901\n",
      "exploration/num steps total        128808\n",
      "exploration/num paths total           250\n",
      "evaluation/num steps total         978258\n",
      "evaluation/num paths total           1286\n",
      "evaluation/path length Mean           844.3\n",
      "evaluation/path length Std            319.869\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             58\n",
      "evaluation/Rewards Mean                 4.5243\n",
      "evaluation/Rewards Std                  1.04595\n",
      "evaluation/Rewards Max                  6.64785\n",
      "evaluation/Rewards Min                 -2.67346\n",
      "evaluation/Returns Mean              3819.86\n",
      "evaluation/Returns Std               1527.16\n",
      "evaluation/Returns Max               4697.38\n",
      "evaluation/Returns Min                167.178\n",
      "evaluation/Estimation Bias Mean      1321.17\n",
      "evaluation/Estimation Bias Std        168.317\n",
      "evaluation/EB/Q_True Mean              51.2223\n",
      "evaluation/EB/Q_True Std              143.783\n",
      "evaluation/EB/Q_Pred Mean            1372.39\n",
      "evaluation/EB/Q_Pred Std               65.3974\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3819.86\n",
      "evaluation/Actions Mean                 0.032618\n",
      "evaluation/Actions Std                  0.546195\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88851\n",
      "time/backward_zf1 (s)                   2.04688\n",
      "time/backward_zf2 (s)                   1.96077\n",
      "time/data sampling (s)                  0.304273\n",
      "time/data storing (s)                   0.0149836\n",
      "time/evaluation sampling (s)            1.89683\n",
      "time/exploration sampling (s)           0.327889\n",
      "time/logging (s)                        0.0110787\n",
      "time/preback_alpha (s)                  0.579494\n",
      "time/preback_policy (s)                 1.09434\n",
      "time/preback_start (s)                  0.148223\n",
      "time/preback_zf (s)                     5.14271\n",
      "time/saving (s)                         0.00705261\n",
      "time/training (s)                       2.35272\n",
      "time/epoch (s)                         17.7757\n",
      "time/total (s)                       2147.69\n",
      "Epoch                                 122\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:12:18.042912 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 123 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 134000\n",
      "trainer/ZF1 Loss                        2.15611\n",
      "trainer/ZF2 Loss                       44.6993\n",
      "trainer/ZF Expert Reward               12.3046\n",
      "trainer/ZF Policy Reward                0.849913\n",
      "trainer/ZF CHI2 Term                   66.7447\n",
      "trainer/Policy Loss                 -1226.66\n",
      "trainer/Bias Loss                     163.268\n",
      "trainer/Bias Value                     12.5502\n",
      "trainer/Policy Grad Norm              105.869\n",
      "trainer/Policy Param Norm              34.3852\n",
      "trainer/Zf1 Grad Norm                1639.54\n",
      "trainer/Zf1 Param Norm                 99.646\n",
      "trainer/Zf2 Grad Norm               12746.9\n",
      "trainer/Zf2 Param Norm                102.927\n",
      "trainer/Z Expert Predictions Mean    1385.7\n",
      "trainer/Z Expert Predictions Std       46.5129\n",
      "trainer/Z Expert Predictions Max     1447.6\n",
      "trainer/Z Expert Predictions Min     1142.87\n",
      "trainer/Z Policy Predictions Mean    1218.36\n",
      "trainer/Z Policy Predictions Std      353.951\n",
      "trainer/Z Policy Predictions Max     1441.07\n",
      "trainer/Z Policy Predictions Min      -77.0824\n",
      "trainer/Z Expert Targets Mean        1373.4\n",
      "trainer/Z Expert Targets Std           45.7281\n",
      "trainer/Z Expert Targets Max         1437.62\n",
      "trainer/Z Expert Targets Min         1119.32\n",
      "trainer/Z Policy Targets Mean        1217.51\n",
      "trainer/Z Policy Targets Std          344.13\n",
      "trainer/Z Policy Targets Max         1429.43\n",
      "trainer/Z Policy Targets Min          -58.7188\n",
      "trainer/Log Pis Mean                   32.1842\n",
      "trainer/Log Pis Std                     9.0855\n",
      "trainer/Policy mu Mean                  0.150203\n",
      "trainer/Policy mu Std                   2.10183\n",
      "trainer/Policy log std Mean            -4.18646\n",
      "trainer/Policy log std Std              1.12011\n",
      "exploration/num steps total        129808\n",
      "exploration/num paths total           251\n",
      "evaluation/num steps total         987265\n",
      "evaluation/num paths total           1296\n",
      "evaluation/path length Mean           900.7\n",
      "evaluation/path length Std            287.069\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             40\n",
      "evaluation/Rewards Mean                 4.60038\n",
      "evaluation/Rewards Std                  1.14019\n",
      "evaluation/Rewards Max                  6.77293\n",
      "evaluation/Rewards Min                 -2.28982\n",
      "evaluation/Returns Mean              4143.57\n",
      "evaluation/Returns Std               1363.1\n",
      "evaluation/Returns Max               4753.06\n",
      "evaluation/Returns Min                 68.9848\n",
      "evaluation/Estimation Bias Mean      1312.8\n",
      "evaluation/Estimation Bias Std        157.439\n",
      "evaluation/EB/Q_True Mean              46.8244\n",
      "evaluation/EB/Q_True Std              136.698\n",
      "evaluation/EB/Q_Pred Mean            1359.62\n",
      "evaluation/EB/Q_Pred Std               67.6009\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4143.57\n",
      "evaluation/Actions Mean                 0.0222519\n",
      "evaluation/Actions Std                  0.537428\n",
      "evaluation/Actions Max                  0.999765\n",
      "evaluation/Actions Min                 -0.999802\n",
      "time/backward_policy (s)                1.76932\n",
      "time/backward_zf1 (s)                   1.94646\n",
      "time/backward_zf2 (s)                   1.85762\n",
      "time/data sampling (s)                  0.311197\n",
      "time/data storing (s)                   0.0144673\n",
      "time/evaluation sampling (s)            1.7252\n",
      "time/exploration sampling (s)           0.321718\n",
      "time/logging (s)                        0.0112956\n",
      "time/preback_alpha (s)                  0.573301\n",
      "time/preback_policy (s)                 1.01582\n",
      "time/preback_start (s)                  0.144977\n",
      "time/preback_zf (s)                     5.09956\n",
      "time/saving (s)                         0.00740907\n",
      "time/training (s)                       2.4413\n",
      "time/epoch (s)                         17.2396\n",
      "time/total (s)                       2164.96\n",
      "Epoch                                 123\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:12:35.360761 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 124 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 135000\n",
      "trainer/ZF1 Loss                        3.06244\n",
      "trainer/ZF2 Loss                       -0.0373383\n",
      "trainer/ZF Expert Reward               16.7257\n",
      "trainer/ZF Policy Reward                6.00504\n",
      "trainer/ZF CHI2 Term                   42.7517\n",
      "trainer/Policy Loss                 -1230.91\n",
      "trainer/Bias Loss                     119.929\n",
      "trainer/Bias Value                     12.5895\n",
      "trainer/Policy Grad Norm              102.255\n",
      "trainer/Policy Param Norm              34.4337\n",
      "trainer/Zf1 Grad Norm                1058.57\n",
      "trainer/Zf1 Param Norm                 99.8497\n",
      "trainer/Zf2 Grad Norm                1238.39\n",
      "trainer/Zf2 Param Norm                103.092\n",
      "trainer/Z Expert Predictions Mean    1384.5\n",
      "trainer/Z Expert Predictions Std       40.4497\n",
      "trainer/Z Expert Predictions Max     1437.95\n",
      "trainer/Z Expert Predictions Min     1174.35\n",
      "trainer/Z Policy Predictions Mean    1227.21\n",
      "trainer/Z Policy Predictions Std      331.807\n",
      "trainer/Z Policy Predictions Max     1424.48\n",
      "trainer/Z Policy Predictions Min      -91.6809\n",
      "trainer/Z Expert Targets Mean        1367.77\n",
      "trainer/Z Expert Targets Std           42.295\n",
      "trainer/Z Expert Targets Max         1421.97\n",
      "trainer/Z Expert Targets Min         1093.54\n",
      "trainer/Z Policy Targets Mean        1221.21\n",
      "trainer/Z Policy Targets Std          325.271\n",
      "trainer/Z Policy Targets Max         1413.91\n",
      "trainer/Z Policy Targets Min          -79.4839\n",
      "trainer/Log Pis Mean                   30.8267\n",
      "trainer/Log Pis Std                     8.3075\n",
      "trainer/Policy mu Mean                  0.0795857\n",
      "trainer/Policy mu Std                   1.74114\n",
      "trainer/Policy log std Mean            -4.23477\n",
      "trainer/Policy log std Std              1.0286\n",
      "exploration/num steps total        130808\n",
      "exploration/num paths total           252\n",
      "evaluation/num steps total         996598\n",
      "evaluation/num paths total           1306\n",
      "evaluation/path length Mean           933.3\n",
      "evaluation/path length Std            200.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            333\n",
      "evaluation/Rewards Mean                 4.64305\n",
      "evaluation/Rewards Std                  1.04821\n",
      "evaluation/Rewards Max                  6.77713\n",
      "evaluation/Rewards Min                 -2.38351\n",
      "evaluation/Returns Mean              4333.36\n",
      "evaluation/Returns Std                994.656\n",
      "evaluation/Returns Max               4815.26\n",
      "evaluation/Returns Min               1366.33\n",
      "evaluation/Estimation Bias Mean      1303.07\n",
      "evaluation/Estimation Bias Std        162.205\n",
      "evaluation/EB/Q_True Mean              47.2274\n",
      "evaluation/EB/Q_True Std              140.306\n",
      "evaluation/EB/Q_Pred Mean            1350.29\n",
      "evaluation/EB/Q_Pred Std               66.0196\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4333.36\n",
      "evaluation/Actions Mean                 0.0194003\n",
      "evaluation/Actions Std                  0.530737\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79019\n",
      "time/backward_zf1 (s)                   1.94932\n",
      "time/backward_zf2 (s)                   1.85672\n",
      "time/data sampling (s)                  0.313645\n",
      "time/data storing (s)                   0.0146072\n",
      "time/evaluation sampling (s)            1.72401\n",
      "time/exploration sampling (s)           0.321489\n",
      "time/logging (s)                        0.0124408\n",
      "time/preback_alpha (s)                  0.576854\n",
      "time/preback_policy (s)                 1.0398\n",
      "time/preback_start (s)                  0.145467\n",
      "time/preback_zf (s)                     5.11456\n",
      "time/saving (s)                         0.00635293\n",
      "time/training (s)                       2.38756\n",
      "time/epoch (s)                         17.253\n",
      "time/total (s)                       2182.23\n",
      "Epoch                                 124\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:12:52.735845 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 125 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 136000\n",
      "trainer/ZF1 Loss                      337.839\n",
      "trainer/ZF2 Loss                      362.817\n",
      "trainer/ZF Expert Reward               11.1629\n",
      "trainer/ZF Policy Reward                7.10267\n",
      "trainer/ZF CHI2 Term                  385.486\n",
      "trainer/Policy Loss                 -1171.07\n",
      "trainer/Bias Loss                      93.5197\n",
      "trainer/Bias Value                     12.5974\n",
      "trainer/Policy Grad Norm              110.771\n",
      "trainer/Policy Param Norm              34.4788\n",
      "trainer/Zf1 Grad Norm                3470.77\n",
      "trainer/Zf1 Param Norm                100.03\n",
      "trainer/Zf2 Grad Norm                4058\n",
      "trainer/Zf2 Param Norm                103.264\n",
      "trainer/Z Expert Predictions Mean    1357.2\n",
      "trainer/Z Expert Predictions Std       91.6674\n",
      "trainer/Z Expert Predictions Max     1428.78\n",
      "trainer/Z Expert Predictions Min       97.4904\n",
      "trainer/Z Policy Predictions Mean    1166.91\n",
      "trainer/Z Policy Predictions Std      386.668\n",
      "trainer/Z Policy Predictions Max     1420.46\n",
      "trainer/Z Policy Predictions Min     -101.022\n",
      "trainer/Z Expert Targets Mean        1346.04\n",
      "trainer/Z Expert Targets Std           97.0238\n",
      "trainer/Z Expert Targets Max         1415.58\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1159.81\n",
      "trainer/Z Policy Targets Std          386.645\n",
      "trainer/Z Policy Targets Max         1409.25\n",
      "trainer/Z Policy Targets Min          -96.0517\n",
      "trainer/Log Pis Mean                   31.4123\n",
      "trainer/Log Pis Std                     8.70517\n",
      "trainer/Policy mu Mean                  0.076768\n",
      "trainer/Policy mu Std                   2.23695\n",
      "trainer/Policy log std Mean            -4.01332\n",
      "trainer/Policy log std Std              1.19262\n",
      "exploration/num steps total        131808\n",
      "exploration/num paths total           253\n",
      "evaluation/num steps total              1.00578e+06\n",
      "evaluation/num paths total           1316\n",
      "evaluation/path length Mean           917.8\n",
      "evaluation/path length Std            246.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            178\n",
      "evaluation/Rewards Mean                 4.60893\n",
      "evaluation/Rewards Std                  1.06081\n",
      "evaluation/Rewards Max                  6.66009\n",
      "evaluation/Rewards Min                 -2.08377\n",
      "evaluation/Returns Mean              4230.08\n",
      "evaluation/Returns Std               1194.11\n",
      "evaluation/Returns Max               4846.33\n",
      "evaluation/Returns Min                672.493\n",
      "evaluation/Estimation Bias Mean      1306.33\n",
      "evaluation/Estimation Bias Std        149.339\n",
      "evaluation/EB/Q_True Mean              45.1938\n",
      "evaluation/EB/Q_True Std              133.084\n",
      "evaluation/EB/Q_Pred Mean            1351.52\n",
      "evaluation/EB/Q_Pred Std               61.3832\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4230.08\n",
      "evaluation/Actions Mean                 0.0225187\n",
      "evaluation/Actions Std                  0.531019\n",
      "evaluation/Actions Max                  0.999922\n",
      "evaluation/Actions Min                 -0.999605\n",
      "time/backward_policy (s)                1.81385\n",
      "time/backward_zf1 (s)                   1.9721\n",
      "time/backward_zf2 (s)                   1.89177\n",
      "time/data sampling (s)                  0.319443\n",
      "time/data storing (s)                   0.0144095\n",
      "time/evaluation sampling (s)            1.78347\n",
      "time/exploration sampling (s)           0.318056\n",
      "time/logging (s)                        0.0116649\n",
      "time/preback_alpha (s)                  0.568506\n",
      "time/preback_policy (s)                 1.05939\n",
      "time/preback_start (s)                  0.145099\n",
      "time/preback_zf (s)                     5.08148\n",
      "time/saving (s)                         0.00638952\n",
      "time/training (s)                       2.31861\n",
      "time/epoch (s)                         17.3042\n",
      "time/total (s)                       2199.56\n",
      "Epoch                                 125\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:13:10.189253 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 126 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 137000\n",
      "trainer/ZF1 Loss                        2.38403\n",
      "trainer/ZF2 Loss                        1.0854\n",
      "trainer/ZF Expert Reward               17.9163\n",
      "trainer/ZF Policy Reward                9.74614\n",
      "trainer/ZF CHI2 Term                   39.9131\n",
      "trainer/Policy Loss                 -1206.98\n",
      "trainer/Bias Loss                      74.8519\n",
      "trainer/Bias Value                     12.6135\n",
      "trainer/Policy Grad Norm              137.608\n",
      "trainer/Policy Param Norm              34.5194\n",
      "trainer/Zf1 Grad Norm                2725.51\n",
      "trainer/Zf1 Param Norm                100.232\n",
      "trainer/Zf2 Grad Norm                1875.5\n",
      "trainer/Zf2 Param Norm                103.429\n",
      "trainer/Z Expert Predictions Mean    1366.77\n",
      "trainer/Z Expert Predictions Std       45.3082\n",
      "trainer/Z Expert Predictions Max     1432.05\n",
      "trainer/Z Expert Predictions Min     1073.01\n",
      "trainer/Z Policy Predictions Mean    1202.37\n",
      "trainer/Z Policy Predictions Std      331.964\n",
      "trainer/Z Policy Predictions Max     1414.87\n",
      "trainer/Z Policy Predictions Min     -110.782\n",
      "trainer/Z Expert Targets Mean        1348.85\n",
      "trainer/Z Expert Targets Std           46.3183\n",
      "trainer/Z Expert Targets Max         1409.11\n",
      "trainer/Z Expert Targets Min         1055.41\n",
      "trainer/Z Policy Targets Mean        1192.62\n",
      "trainer/Z Policy Targets Std          329.263\n",
      "trainer/Z Policy Targets Max         1400.17\n",
      "trainer/Z Policy Targets Min          -89.7861\n",
      "trainer/Log Pis Mean                   30.3113\n",
      "trainer/Log Pis Std                     6.93236\n",
      "trainer/Policy mu Mean                 -0.0137424\n",
      "trainer/Policy mu Std                   1.80324\n",
      "trainer/Policy log std Mean            -4.18237\n",
      "trainer/Policy log std Std              0.997446\n",
      "exploration/num steps total        131808\n",
      "exploration/num paths total           253\n",
      "evaluation/num steps total              1.01393e+06\n",
      "evaluation/num paths total           1326\n",
      "evaluation/path length Mean           815.8\n",
      "evaluation/path length Std            369.344\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             20\n",
      "evaluation/Rewards Mean                 4.47713\n",
      "evaluation/Rewards Std                  1.02638\n",
      "evaluation/Rewards Max                  6.36177\n",
      "evaluation/Rewards Min                 -2.04186\n",
      "evaluation/Returns Mean              3652.44\n",
      "evaluation/Returns Std               1694.77\n",
      "evaluation/Returns Max               4711.29\n",
      "evaluation/Returns Min                  5.45011\n",
      "evaluation/Estimation Bias Mean      1275.47\n",
      "evaluation/Estimation Bias Std        159.486\n",
      "evaluation/EB/Q_True Mean              53.0679\n",
      "evaluation/EB/Q_True Std              145.623\n",
      "evaluation/EB/Q_Pred Mean            1328.54\n",
      "evaluation/EB/Q_Pred Std               58.6308\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3652.44\n",
      "evaluation/Actions Mean                 0.0178487\n",
      "evaluation/Actions Std                  0.520343\n",
      "evaluation/Actions Max                  0.999477\n",
      "evaluation/Actions Min                 -0.999736\n",
      "time/backward_policy (s)                1.78752\n",
      "time/backward_zf1 (s)                   1.94464\n",
      "time/backward_zf2 (s)                   1.84838\n",
      "time/data sampling (s)                  0.32134\n",
      "time/data storing (s)                   0.014658\n",
      "time/evaluation sampling (s)            1.77161\n",
      "time/exploration sampling (s)           0.323724\n",
      "time/logging (s)                        0.0104195\n",
      "time/preback_alpha (s)                  0.574834\n",
      "time/preback_policy (s)                 0.993427\n",
      "time/preback_start (s)                  0.145125\n",
      "time/preback_zf (s)                     5.13262\n",
      "time/saving (s)                         0.0059634\n",
      "time/training (s)                       2.50666\n",
      "time/epoch (s)                         17.3809\n",
      "time/total (s)                       2216.96\n",
      "Epoch                                 126\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:13:27.943897 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 127 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 138000\n",
      "trainer/ZF1 Loss                       12.9072\n",
      "trainer/ZF2 Loss                        8.16258\n",
      "trainer/ZF Expert Reward               13.9332\n",
      "trainer/ZF Policy Reward                2.29921\n",
      "trainer/ZF CHI2 Term                   53.3124\n",
      "trainer/Policy Loss                 -1152.87\n",
      "trainer/Bias Loss                     112.127\n",
      "trainer/Bias Value                     12.6236\n",
      "trainer/Policy Grad Norm              123.801\n",
      "trainer/Policy Param Norm              34.5621\n",
      "trainer/Zf1 Grad Norm                2179.74\n",
      "trainer/Zf1 Param Norm                100.438\n",
      "trainer/Zf2 Grad Norm                2013.7\n",
      "trainer/Zf2 Param Norm                103.616\n",
      "trainer/Z Expert Predictions Mean    1354.92\n",
      "trainer/Z Expert Predictions Std       46.0312\n",
      "trainer/Z Expert Predictions Max     1416.06\n",
      "trainer/Z Expert Predictions Min      848.35\n",
      "trainer/Z Policy Predictions Mean    1147.41\n",
      "trainer/Z Policy Predictions Std      373.953\n",
      "trainer/Z Policy Predictions Max     1395.16\n",
      "trainer/Z Policy Predictions Min     -125.754\n",
      "trainer/Z Expert Targets Mean        1340.99\n",
      "trainer/Z Expert Targets Std           46.8491\n",
      "trainer/Z Expert Targets Max         1400.38\n",
      "trainer/Z Expert Targets Min          865.288\n",
      "trainer/Z Policy Targets Mean        1145.11\n",
      "trainer/Z Policy Targets Std          370.979\n",
      "trainer/Z Policy Targets Max         1391.51\n",
      "trainer/Z Policy Targets Min         -141.226\n",
      "trainer/Log Pis Mean                   31.4581\n",
      "trainer/Log Pis Std                     8.61776\n",
      "trainer/Policy mu Mean                  0.0832252\n",
      "trainer/Policy mu Std                   2.10004\n",
      "trainer/Policy log std Mean            -4.12336\n",
      "trainer/Policy log std Std              1.11575\n",
      "exploration/num steps total        132808\n",
      "exploration/num paths total           254\n",
      "evaluation/num steps total              1.02159e+06\n",
      "evaluation/num paths total           1336\n",
      "evaluation/path length Mean           765.3\n",
      "evaluation/path length Std            359.052\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            186\n",
      "evaluation/Rewards Mean                 4.1977\n",
      "evaluation/Rewards Std                  1.91769\n",
      "evaluation/Rewards Max                  6.78226\n",
      "evaluation/Rewards Min                 -3.06438\n",
      "evaluation/Returns Mean              3212.5\n",
      "evaluation/Returns Std               1801.3\n",
      "evaluation/Returns Max               4738.81\n",
      "evaluation/Returns Min                724.787\n",
      "evaluation/Estimation Bias Mean      1173.61\n",
      "evaluation/Estimation Bias Std        361.375\n",
      "evaluation/EB/Q_True Mean              55.8684\n",
      "evaluation/EB/Q_True Std              148.249\n",
      "evaluation/EB/Q_Pred Mean            1229.47\n",
      "evaluation/EB/Q_Pred Std              337.173\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3212.5\n",
      "evaluation/Actions Mean                 0.0308691\n",
      "evaluation/Actions Std                  0.557967\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90193\n",
      "time/backward_zf1 (s)                   2.05319\n",
      "time/backward_zf2 (s)                   1.95908\n",
      "time/data sampling (s)                  0.316723\n",
      "time/data storing (s)                   0.0143794\n",
      "time/evaluation sampling (s)            1.81433\n",
      "time/exploration sampling (s)           0.326712\n",
      "time/logging (s)                        0.00973275\n",
      "time/preback_alpha (s)                  0.58162\n",
      "time/preback_policy (s)                 1.1025\n",
      "time/preback_start (s)                  0.146984\n",
      "time/preback_zf (s)                     5.10578\n",
      "time/saving (s)                         0.00652295\n",
      "time/training (s)                       2.34424\n",
      "time/epoch (s)                         17.6837\n",
      "time/total (s)                       2234.66\n",
      "Epoch                                 127\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:13:45.782452 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 128 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 139000\n",
      "trainer/ZF1 Loss                       -6.71575\n",
      "trainer/ZF2 Loss                       -2.87121\n",
      "trainer/ZF Expert Reward                8.34838\n",
      "trainer/ZF Policy Reward                1.11107\n",
      "trainer/ZF CHI2 Term                   33.5057\n",
      "trainer/Policy Loss                 -1140.65\n",
      "trainer/Bias Loss                      60.3921\n",
      "trainer/Bias Value                     12.6724\n",
      "trainer/Policy Grad Norm              102.789\n",
      "trainer/Policy Param Norm              34.6089\n",
      "trainer/Zf1 Grad Norm                1256.03\n",
      "trainer/Zf1 Param Norm                100.63\n",
      "trainer/Zf2 Grad Norm                1626.26\n",
      "trainer/Zf2 Param Norm                103.798\n",
      "trainer/Z Expert Predictions Mean    1336.45\n",
      "trainer/Z Expert Predictions Std       56.2062\n",
      "trainer/Z Expert Predictions Max     1410.55\n",
      "trainer/Z Expert Predictions Min     1004.48\n",
      "trainer/Z Policy Predictions Mean    1137.22\n",
      "trainer/Z Policy Predictions Std      373.475\n",
      "trainer/Z Policy Predictions Max     1390.98\n",
      "trainer/Z Policy Predictions Min     -135.02\n",
      "trainer/Z Expert Targets Mean        1328.1\n",
      "trainer/Z Expert Targets Std           56.0156\n",
      "trainer/Z Expert Targets Max         1397.02\n",
      "trainer/Z Expert Targets Min          991.5\n",
      "trainer/Z Policy Targets Mean        1136.11\n",
      "trainer/Z Policy Targets Std          368.424\n",
      "trainer/Z Policy Targets Max         1396.24\n",
      "trainer/Z Policy Targets Min         -126.429\n",
      "trainer/Log Pis Mean                   31.3756\n",
      "trainer/Log Pis Std                     9.15456\n",
      "trainer/Policy mu Mean                  0.0180483\n",
      "trainer/Policy mu Std                   2.13555\n",
      "trainer/Policy log std Mean            -4.06585\n",
      "trainer/Policy log std Std              1.15506\n",
      "exploration/num steps total        133808\n",
      "exploration/num paths total           255\n",
      "evaluation/num steps total              1.02979e+06\n",
      "evaluation/num paths total           1346\n",
      "evaluation/path length Mean           820.7\n",
      "evaluation/path length Std            360.493\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             21\n",
      "evaluation/Rewards Mean                 3.70026\n",
      "evaluation/Rewards Std                  2.70226\n",
      "evaluation/Rewards Max                  7.0945\n",
      "evaluation/Rewards Min                 -4.13052\n",
      "evaluation/Returns Mean              3036.8\n",
      "evaluation/Returns Std               2610.29\n",
      "evaluation/Returns Max               4786.62\n",
      "evaluation/Returns Min              -2901.35\n",
      "evaluation/Estimation Bias Mean      1105.13\n",
      "evaluation/Estimation Bias Std        445.469\n",
      "evaluation/EB/Q_True Mean              52.6178\n",
      "evaluation/EB/Q_True Std              145.26\n",
      "evaluation/EB/Q_Pred Mean            1157.75\n",
      "evaluation/EB/Q_Pred Std              437.909\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3036.8\n",
      "evaluation/Actions Mean                 0.0763475\n",
      "evaluation/Actions Std                  0.607696\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89903\n",
      "time/backward_zf1 (s)                   2.07401\n",
      "time/backward_zf2 (s)                   1.98857\n",
      "time/data sampling (s)                  0.306282\n",
      "time/data storing (s)                   0.0141607\n",
      "time/evaluation sampling (s)            1.7829\n",
      "time/exploration sampling (s)           0.32066\n",
      "time/logging (s)                        0.0102864\n",
      "time/preback_alpha (s)                  0.582782\n",
      "time/preback_policy (s)                 1.11895\n",
      "time/preback_start (s)                  0.147795\n",
      "time/preback_zf (s)                     5.1333\n",
      "time/saving (s)                         0.00618947\n",
      "time/training (s)                       2.3862\n",
      "time/epoch (s)                         17.7711\n",
      "time/total (s)                       2252.46\n",
      "Epoch                                 128\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:14:03.606315 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 129 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 140000\n",
      "trainer/ZF1 Loss                       -0.278164\n",
      "trainer/ZF2 Loss                       18.8831\n",
      "trainer/ZF Expert Reward                9.55197\n",
      "trainer/ZF Policy Reward                0.688746\n",
      "trainer/ZF CHI2 Term                   48.8744\n",
      "trainer/Policy Loss                 -1181.78\n",
      "trainer/Bias Loss                      90.5576\n",
      "trainer/Bias Value                     12.7323\n",
      "trainer/Policy Grad Norm              100.874\n",
      "trainer/Policy Param Norm              34.6601\n",
      "trainer/Zf1 Grad Norm                2075.81\n",
      "trainer/Zf1 Param Norm                100.837\n",
      "trainer/Zf2 Grad Norm                5024.61\n",
      "trainer/Zf2 Param Norm                103.975\n",
      "trainer/Z Expert Predictions Mean    1328.61\n",
      "trainer/Z Expert Predictions Std       57.0332\n",
      "trainer/Z Expert Predictions Max     1397.19\n",
      "trainer/Z Expert Predictions Min     1017.77\n",
      "trainer/Z Policy Predictions Mean    1172.91\n",
      "trainer/Z Policy Predictions Std      358.452\n",
      "trainer/Z Policy Predictions Max     1388.02\n",
      "trainer/Z Policy Predictions Min     -144.377\n",
      "trainer/Z Expert Targets Mean        1319.06\n",
      "trainer/Z Expert Targets Std           55.8425\n",
      "trainer/Z Expert Targets Max         1386.3\n",
      "trainer/Z Expert Targets Min         1008.86\n",
      "trainer/Z Policy Targets Mean        1172.23\n",
      "trainer/Z Policy Targets Std          353.482\n",
      "trainer/Z Policy Targets Max         1375.7\n",
      "trainer/Z Policy Targets Min         -128.815\n",
      "trainer/Log Pis Mean                   31.0188\n",
      "trainer/Log Pis Std                     8.02551\n",
      "trainer/Policy mu Mean                 -0.022321\n",
      "trainer/Policy mu Std                   2.01218\n",
      "trainer/Policy log std Mean            -4.21771\n",
      "trainer/Policy log std Std              1.04749\n",
      "exploration/num steps total        133808\n",
      "exploration/num paths total           255\n",
      "evaluation/num steps total              1.03797e+06\n",
      "evaluation/num paths total           1356\n",
      "evaluation/path length Mean           817.9\n",
      "evaluation/path length Std            315.247\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             25\n",
      "evaluation/Rewards Mean                 4.53092\n",
      "evaluation/Rewards Std                  1.09622\n",
      "evaluation/Rewards Max                  6.56385\n",
      "evaluation/Rewards Min                 -2.21309\n",
      "evaluation/Returns Mean              3705.84\n",
      "evaluation/Returns Std               1502.32\n",
      "evaluation/Returns Max               4896.87\n",
      "evaluation/Returns Min                 -6.06816\n",
      "evaluation/Estimation Bias Mean      1265.35\n",
      "evaluation/Estimation Bias Std        160.665\n",
      "evaluation/EB/Q_True Mean              50.8223\n",
      "evaluation/EB/Q_True Std              139.437\n",
      "evaluation/EB/Q_Pred Mean            1316.17\n",
      "evaluation/EB/Q_Pred Std               66.3078\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3705.84\n",
      "evaluation/Actions Mean                 0.0225468\n",
      "evaluation/Actions Std                  0.542139\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98955\n",
      "time/backward_zf1 (s)                   2.1073\n",
      "time/backward_zf2 (s)                   2.07655\n",
      "time/data sampling (s)                  0.314236\n",
      "time/data storing (s)                   0.0152885\n",
      "time/evaluation sampling (s)            1.72551\n",
      "time/exploration sampling (s)           0.32724\n",
      "time/logging (s)                        0.0102331\n",
      "time/preback_alpha (s)                  0.583484\n",
      "time/preback_policy (s)                 1.20123\n",
      "time/preback_start (s)                  0.146846\n",
      "time/preback_zf (s)                     5.12384\n",
      "time/saving (s)                         0.00642454\n",
      "time/training (s)                       2.12569\n",
      "time/epoch (s)                         17.7534\n",
      "time/total (s)                       2270.23\n",
      "Epoch                                 129\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:14:20.984593 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 130 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 141000\n",
      "trainer/ZF1 Loss                      -13.5462\n",
      "trainer/ZF2 Loss                       -8.69439\n",
      "trainer/ZF Expert Reward               12.0727\n",
      "trainer/ZF Policy Reward                1.62175\n",
      "trainer/ZF CHI2 Term                   30.2285\n",
      "trainer/Policy Loss                 -1173.62\n",
      "trainer/Bias Loss                      68.6792\n",
      "trainer/Bias Value                     12.772\n",
      "trainer/Policy Grad Norm               82.6121\n",
      "trainer/Policy Param Norm              34.7105\n",
      "trainer/Zf1 Grad Norm                1027.37\n",
      "trainer/Zf1 Param Norm                101.047\n",
      "trainer/Zf2 Grad Norm                 961.077\n",
      "trainer/Zf2 Param Norm                104.164\n",
      "trainer/Z Expert Predictions Mean    1331.06\n",
      "trainer/Z Expert Predictions Std       43.043\n",
      "trainer/Z Expert Predictions Max     1395.5\n",
      "trainer/Z Expert Predictions Min     1065.67\n",
      "trainer/Z Policy Predictions Mean    1168.11\n",
      "trainer/Z Policy Predictions Std      335.203\n",
      "trainer/Z Policy Predictions Max     1366.45\n",
      "trainer/Z Policy Predictions Min     -156.416\n",
      "trainer/Z Expert Targets Mean        1318.98\n",
      "trainer/Z Expert Targets Std           42.8735\n",
      "trainer/Z Expert Targets Max         1379.03\n",
      "trainer/Z Expert Targets Min         1031.11\n",
      "trainer/Z Policy Targets Mean        1166.49\n",
      "trainer/Z Policy Targets Std          329.898\n",
      "trainer/Z Policy Targets Max         1369.06\n",
      "trainer/Z Policy Targets Min         -146.59\n",
      "trainer/Log Pis Mean                   31.2099\n",
      "trainer/Log Pis Std                     9.35846\n",
      "trainer/Policy mu Mean                  0.0200625\n",
      "trainer/Policy mu Std                   1.97063\n",
      "trainer/Policy log std Mean            -4.26928\n",
      "trainer/Policy log std Std              1.00893\n",
      "exploration/num steps total        134808\n",
      "exploration/num paths total           256\n",
      "evaluation/num steps total              1.04797e+06\n",
      "evaluation/num paths total           1366\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.61396\n",
      "evaluation/Rewards Std                  1.02355\n",
      "evaluation/Rewards Max                  6.78638\n",
      "evaluation/Rewards Min                 -2.3838\n",
      "evaluation/Returns Mean              4613.96\n",
      "evaluation/Returns Std                 93.2521\n",
      "evaluation/Returns Max               4789.08\n",
      "evaluation/Returns Min               4506.35\n",
      "evaluation/Estimation Bias Mean      1269.85\n",
      "evaluation/Estimation Bias Std        144.76\n",
      "evaluation/EB/Q_True Mean              44.3967\n",
      "evaluation/EB/Q_True Std              136.673\n",
      "evaluation/EB/Q_Pred Mean            1314.24\n",
      "evaluation/EB/Q_Pred Std               52.951\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4613.96\n",
      "evaluation/Actions Mean                 0.0169039\n",
      "evaluation/Actions Std                  0.531192\n",
      "evaluation/Actions Max                  0.99954\n",
      "evaluation/Actions Min                 -0.999097\n",
      "time/backward_policy (s)                1.82726\n",
      "time/backward_zf1 (s)                   1.96812\n",
      "time/backward_zf2 (s)                   1.89712\n",
      "time/data sampling (s)                  0.303126\n",
      "time/data storing (s)                   0.0149365\n",
      "time/evaluation sampling (s)            1.73283\n",
      "time/exploration sampling (s)           0.326594\n",
      "time/logging (s)                        0.0171844\n",
      "time/preback_alpha (s)                  0.572892\n",
      "time/preback_policy (s)                 1.04632\n",
      "time/preback_start (s)                  0.144146\n",
      "time/preback_zf (s)                     5.09654\n",
      "time/saving (s)                         0.00744869\n",
      "time/training (s)                       2.35044\n",
      "time/epoch (s)                         17.305\n",
      "time/total (s)                       2287.57\n",
      "Epoch                                 130\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:14:38.524454 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 131 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 142000\n",
      "trainer/ZF1 Loss                       -5.53154\n",
      "trainer/ZF2 Loss                        4.764\n",
      "trainer/ZF Expert Reward                9.10405\n",
      "trainer/ZF Policy Reward                0.634844\n",
      "trainer/ZF CHI2 Term                   38.7721\n",
      "trainer/Policy Loss                 -1146.79\n",
      "trainer/Bias Loss                      82.3351\n",
      "trainer/Bias Value                     12.824\n",
      "trainer/Policy Grad Norm               82.6551\n",
      "trainer/Policy Param Norm              34.7552\n",
      "trainer/Zf1 Grad Norm                1173.84\n",
      "trainer/Zf1 Param Norm                101.241\n",
      "trainer/Zf2 Grad Norm                2087.73\n",
      "trainer/Zf2 Param Norm                104.345\n",
      "trainer/Z Expert Predictions Mean    1312.8\n",
      "trainer/Z Expert Predictions Std       53.8984\n",
      "trainer/Z Expert Predictions Max     1387.14\n",
      "trainer/Z Expert Predictions Min      974.764\n",
      "trainer/Z Policy Predictions Mean    1139.7\n",
      "trainer/Z Policy Predictions Std      371.456\n",
      "trainer/Z Policy Predictions Max     1372.03\n",
      "trainer/Z Policy Predictions Min     -165.112\n",
      "trainer/Z Expert Targets Mean        1303.69\n",
      "trainer/Z Expert Targets Std           54.4534\n",
      "trainer/Z Expert Targets Max         1375.28\n",
      "trainer/Z Expert Targets Min          962.066\n",
      "trainer/Z Policy Targets Mean        1139.06\n",
      "trainer/Z Policy Targets Std          366.296\n",
      "trainer/Z Policy Targets Max         1369.59\n",
      "trainer/Z Policy Targets Min         -155.288\n",
      "trainer/Log Pis Mean                   30.9966\n",
      "trainer/Log Pis Std                     8.2469\n",
      "trainer/Policy mu Mean                  0.0196879\n",
      "trainer/Policy mu Std                   2.17748\n",
      "trainer/Policy log std Mean            -4.17853\n",
      "trainer/Policy log std Std              1.12082\n",
      "exploration/num steps total        136808\n",
      "exploration/num paths total           258\n",
      "evaluation/num steps total              1.05797e+06\n",
      "evaluation/num paths total           1376\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.48793\n",
      "evaluation/Rewards Std                  1.04292\n",
      "evaluation/Rewards Max                  6.66623\n",
      "evaluation/Rewards Min                 -2.56931\n",
      "evaluation/Returns Mean              4487.93\n",
      "evaluation/Returns Std                 58.7041\n",
      "evaluation/Returns Max               4605.24\n",
      "evaluation/Returns Min               4409.64\n",
      "evaluation/Estimation Bias Mean      1262\n",
      "evaluation/Estimation Bias Std        141.545\n",
      "evaluation/EB/Q_True Mean              41.8477\n",
      "evaluation/EB/Q_True Std              128.892\n",
      "evaluation/EB/Q_Pred Mean            1303.84\n",
      "evaluation/EB/Q_Pred Std               61.651\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4487.93\n",
      "evaluation/Actions Mean                 0.0160501\n",
      "evaluation/Actions Std                  0.53402\n",
      "evaluation/Actions Max                  0.999824\n",
      "evaluation/Actions Min                 -0.999597\n",
      "time/backward_policy (s)                1.90007\n",
      "time/backward_zf1 (s)                   2.0598\n",
      "time/backward_zf2 (s)                   1.95786\n",
      "time/data sampling (s)                  0.311651\n",
      "time/data storing (s)                   0.0146411\n",
      "time/evaluation sampling (s)            1.70765\n",
      "time/exploration sampling (s)           0.328778\n",
      "time/logging (s)                        0.0124544\n",
      "time/preback_alpha (s)                  0.576813\n",
      "time/preback_policy (s)                 1.0985\n",
      "time/preback_start (s)                  0.14617\n",
      "time/preback_zf (s)                     5.1184\n",
      "time/saving (s)                         0.0061262\n",
      "time/training (s)                       2.22626\n",
      "time/epoch (s)                         17.4652\n",
      "time/total (s)                       2305.05\n",
      "Epoch                                 131\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:14:56.460474 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 132 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 143000\n",
      "trainer/ZF1 Loss                       -5.2753\n",
      "trainer/ZF2 Loss                       -3.06604\n",
      "trainer/ZF Expert Reward               12.0588\n",
      "trainer/ZF Policy Reward                3.27873\n",
      "trainer/ZF CHI2 Term                   35.0925\n",
      "trainer/Policy Loss                 -1174.9\n",
      "trainer/Bias Loss                      72.8471\n",
      "trainer/Bias Value                     12.8807\n",
      "trainer/Policy Grad Norm              102.151\n",
      "trainer/Policy Param Norm              34.7996\n",
      "trainer/Zf1 Grad Norm                1651.06\n",
      "trainer/Zf1 Param Norm                101.441\n",
      "trainer/Zf2 Grad Norm                1086.61\n",
      "trainer/Zf2 Param Norm                104.527\n",
      "trainer/Z Expert Predictions Mean    1316.47\n",
      "trainer/Z Expert Predictions Std       40.4743\n",
      "trainer/Z Expert Predictions Max     1392.1\n",
      "trainer/Z Expert Predictions Min     1095.43\n",
      "trainer/Z Policy Predictions Mean    1170.13\n",
      "trainer/Z Policy Predictions Std      325.539\n",
      "trainer/Z Policy Predictions Max     1367.99\n",
      "trainer/Z Policy Predictions Min     -154.73\n",
      "trainer/Z Expert Targets Mean        1304.41\n",
      "trainer/Z Expert Targets Std           40.5153\n",
      "trainer/Z Expert Targets Max         1377.29\n",
      "trainer/Z Expert Targets Min         1089.27\n",
      "trainer/Z Policy Targets Mean        1166.85\n",
      "trainer/Z Policy Targets Std          322.069\n",
      "trainer/Z Policy Targets Max         1362.91\n",
      "trainer/Z Policy Targets Min         -157.337\n",
      "trainer/Log Pis Mean                   30.791\n",
      "trainer/Log Pis Std                     8.81367\n",
      "trainer/Policy mu Mean                  0.0229754\n",
      "trainer/Policy mu Std                   1.88646\n",
      "trainer/Policy log std Mean            -4.2857\n",
      "trainer/Policy log std Std              1.03162\n",
      "exploration/num steps total        139000\n",
      "exploration/num paths total           261\n",
      "evaluation/num steps total              1.06797e+06\n",
      "evaluation/num paths total           1386\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62055\n",
      "evaluation/Rewards Std                  0.979013\n",
      "evaluation/Rewards Max                  6.67857\n",
      "evaluation/Rewards Min                 -2.33521\n",
      "evaluation/Returns Mean              4620.55\n",
      "evaluation/Returns Std                104.194\n",
      "evaluation/Returns Max               4741.72\n",
      "evaluation/Returns Min               4402.41\n",
      "evaluation/Estimation Bias Mean      1261.14\n",
      "evaluation/Estimation Bias Std        144.254\n",
      "evaluation/EB/Q_True Mean              42.2735\n",
      "evaluation/EB/Q_True Std              130.577\n",
      "evaluation/EB/Q_Pred Mean            1303.41\n",
      "evaluation/EB/Q_Pred Std               52.4259\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4620.55\n",
      "evaluation/Actions Mean                 0.0336022\n",
      "evaluation/Actions Std                  0.537305\n",
      "evaluation/Actions Max                  0.999956\n",
      "evaluation/Actions Min                 -0.999675\n",
      "time/backward_policy (s)                1.90519\n",
      "time/backward_zf1 (s)                   2.03568\n",
      "time/backward_zf2 (s)                   1.97814\n",
      "time/data sampling (s)                  0.323454\n",
      "time/data storing (s)                   0.0156773\n",
      "time/evaluation sampling (s)            1.7725\n",
      "time/exploration sampling (s)           0.346306\n",
      "time/logging (s)                        0.0120239\n",
      "time/preback_alpha (s)                  0.59521\n",
      "time/preback_policy (s)                 1.09781\n",
      "time/preback_start (s)                  0.152392\n",
      "time/preback_zf (s)                     5.17047\n",
      "time/saving (s)                         0.00631606\n",
      "time/training (s)                       2.45299\n",
      "time/epoch (s)                         17.8642\n",
      "time/total (s)                       2322.94\n",
      "Epoch                                 132\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:15:14.351711 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 133 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 144000\n",
      "trainer/ZF1 Loss                       -2.77217\n",
      "trainer/ZF2 Loss                       14.6393\n",
      "trainer/ZF Expert Reward               11.6887\n",
      "trainer/ZF Policy Reward                2.53093\n",
      "trainer/ZF CHI2 Term                   46.4933\n",
      "trainer/Policy Loss                 -1139.58\n",
      "trainer/Bias Loss                      71.8016\n",
      "trainer/Bias Value                     12.8967\n",
      "trainer/Policy Grad Norm              185.132\n",
      "trainer/Policy Param Norm              34.8399\n",
      "trainer/Zf1 Grad Norm                2898.07\n",
      "trainer/Zf1 Param Norm                101.639\n",
      "trainer/Zf2 Grad Norm                1408.15\n",
      "trainer/Zf2 Param Norm                104.706\n",
      "trainer/Z Expert Predictions Mean    1306.13\n",
      "trainer/Z Expert Predictions Std       49.5048\n",
      "trainer/Z Expert Predictions Max     1370.47\n",
      "trainer/Z Expert Predictions Min     1015.9\n",
      "trainer/Z Policy Predictions Mean    1131.59\n",
      "trainer/Z Policy Predictions Std      366.813\n",
      "trainer/Z Policy Predictions Max     1371.66\n",
      "trainer/Z Policy Predictions Min     -199.512\n",
      "trainer/Z Expert Targets Mean        1294.45\n",
      "trainer/Z Expert Targets Std           51.0549\n",
      "trainer/Z Expert Targets Max         1376.3\n",
      "trainer/Z Expert Targets Min          989.368\n",
      "trainer/Z Policy Targets Mean        1129.06\n",
      "trainer/Z Policy Targets Std          362.635\n",
      "trainer/Z Policy Targets Max         1361.64\n",
      "trainer/Z Policy Targets Min         -180.713\n",
      "trainer/Log Pis Mean                   31.7192\n",
      "trainer/Log Pis Std                     9.5301\n",
      "trainer/Policy mu Mean                  0.0305506\n",
      "trainer/Policy mu Std                   2.26124\n",
      "trainer/Policy log std Mean            -4.10163\n",
      "trainer/Policy log std Std              1.14938\n",
      "exploration/num steps total        140000\n",
      "exploration/num paths total           262\n",
      "evaluation/num steps total              1.07729e+06\n",
      "evaluation/num paths total           1397\n",
      "evaluation/path length Mean           846.909\n",
      "evaluation/path length Std            303.312\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             22\n",
      "evaluation/Rewards Mean                 4.46356\n",
      "evaluation/Rewards Std                  0.959341\n",
      "evaluation/Rewards Max                  6.43921\n",
      "evaluation/Rewards Min                 -2.85496\n",
      "evaluation/Returns Mean              3780.23\n",
      "evaluation/Returns Std               1381.01\n",
      "evaluation/Returns Max               4595.44\n",
      "evaluation/Returns Min                 17.6029\n",
      "evaluation/Estimation Bias Mean      1247.51\n",
      "evaluation/Estimation Bias Std        144.758\n",
      "evaluation/EB/Q_True Mean              45.8069\n",
      "evaluation/EB/Q_True Std              135.528\n",
      "evaluation/EB/Q_Pred Mean            1293.32\n",
      "evaluation/EB/Q_Pred Std               49.1008\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3780.23\n",
      "evaluation/Actions Mean                 0.0192688\n",
      "evaluation/Actions Std                  0.524628\n",
      "evaluation/Actions Max                  0.999871\n",
      "evaluation/Actions Min                 -0.999517\n",
      "time/backward_policy (s)                1.97499\n",
      "time/backward_zf1 (s)                   2.11757\n",
      "time/backward_zf2 (s)                   2.0731\n",
      "time/data sampling (s)                  0.31613\n",
      "time/data storing (s)                   0.0148059\n",
      "time/evaluation sampling (s)            1.76992\n",
      "time/exploration sampling (s)           0.326196\n",
      "time/logging (s)                        0.0114782\n",
      "time/preback_alpha (s)                  0.584061\n",
      "time/preback_policy (s)                 1.17712\n",
      "time/preback_start (s)                  0.149883\n",
      "time/preback_zf (s)                     5.14798\n",
      "time/saving (s)                         0.00644182\n",
      "time/training (s)                       2.1505\n",
      "time/epoch (s)                         17.8202\n",
      "time/total (s)                       2340.78\n",
      "Epoch                                 133\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:15:31.928952 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 134 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 145000\n",
      "trainer/ZF1 Loss                       -7.73867\n",
      "trainer/ZF2 Loss                       -6.33884\n",
      "trainer/ZF Expert Reward               11.0657\n",
      "trainer/ZF Policy Reward               -1.54252\n",
      "trainer/ZF CHI2 Term                   36.6687\n",
      "trainer/Policy Loss                 -1151.26\n",
      "trainer/Bias Loss                      66.6968\n",
      "trainer/Bias Value                     12.9636\n",
      "trainer/Policy Grad Norm               93.3584\n",
      "trainer/Policy Param Norm              34.8822\n",
      "trainer/Zf1 Grad Norm                1421.48\n",
      "trainer/Zf1 Param Norm                101.838\n",
      "trainer/Zf2 Grad Norm                2378.86\n",
      "trainer/Zf2 Param Norm                104.902\n",
      "trainer/Z Expert Predictions Mean    1305.5\n",
      "trainer/Z Expert Predictions Std       52.4619\n",
      "trainer/Z Expert Predictions Max     1372.63\n",
      "trainer/Z Expert Predictions Min      997.209\n",
      "trainer/Z Policy Predictions Mean    1145.71\n",
      "trainer/Z Policy Predictions Std      331.597\n",
      "trainer/Z Policy Predictions Max     1352.47\n",
      "trainer/Z Policy Predictions Min     -174.666\n",
      "trainer/Z Expert Targets Mean        1294.43\n",
      "trainer/Z Expert Targets Std           51.4861\n",
      "trainer/Z Expert Targets Max         1363.82\n",
      "trainer/Z Expert Targets Min         1001.82\n",
      "trainer/Z Policy Targets Mean        1147.25\n",
      "trainer/Z Policy Targets Std          327.534\n",
      "trainer/Z Policy Targets Max         1349.94\n",
      "trainer/Z Policy Targets Min         -167.627\n",
      "trainer/Log Pis Mean                   31.4134\n",
      "trainer/Log Pis Std                     8.09612\n",
      "trainer/Policy mu Mean                  0.0144292\n",
      "trainer/Policy mu Std                   2.01568\n",
      "trainer/Policy log std Mean            -4.29919\n",
      "trainer/Policy log std Std              1.01497\n",
      "exploration/num steps total        141000\n",
      "exploration/num paths total           263\n",
      "evaluation/num steps total              1.08693e+06\n",
      "evaluation/num paths total           1407\n",
      "evaluation/path length Mean           964.4\n",
      "evaluation/path length Std            106.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            644\n",
      "evaluation/Rewards Mean                 4.6429\n",
      "evaluation/Rewards Std                  0.988918\n",
      "evaluation/Rewards Max                  6.73631\n",
      "evaluation/Rewards Min                 -1.67078\n",
      "evaluation/Returns Mean              4477.62\n",
      "evaluation/Returns Std                521.959\n",
      "evaluation/Returns Max               4774.75\n",
      "evaluation/Returns Min               2922.63\n",
      "evaluation/Estimation Bias Mean      1250.31\n",
      "evaluation/Estimation Bias Std        144.05\n",
      "evaluation/EB/Q_True Mean              43.5997\n",
      "evaluation/EB/Q_True Std              132.867\n",
      "evaluation/EB/Q_Pred Mean            1293.91\n",
      "evaluation/EB/Q_Pred Std               51.9122\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4477.62\n",
      "evaluation/Actions Mean                 0.0322913\n",
      "evaluation/Actions Std                  0.540229\n",
      "evaluation/Actions Max                  0.999532\n",
      "evaluation/Actions Min                 -0.999508\n",
      "time/backward_policy (s)                1.86328\n",
      "time/backward_zf1 (s)                   1.99516\n",
      "time/backward_zf2 (s)                   1.93328\n",
      "time/data sampling (s)                  0.311108\n",
      "time/data storing (s)                   0.0140273\n",
      "time/evaluation sampling (s)            1.71484\n",
      "time/exploration sampling (s)           0.319066\n",
      "time/logging (s)                        0.0118942\n",
      "time/preback_alpha (s)                  0.577422\n",
      "time/preback_policy (s)                 1.04611\n",
      "time/preback_start (s)                  0.146096\n",
      "time/preback_zf (s)                     5.11779\n",
      "time/saving (s)                         0.00633999\n",
      "time/training (s)                       2.45059\n",
      "time/epoch (s)                         17.507\n",
      "time/total (s)                       2358.31\n",
      "Epoch                                 134\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:15:49.614922 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 135 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 146000\n",
      "trainer/ZF1 Loss                       -9.37283\n",
      "trainer/ZF2 Loss                       -2.91511\n",
      "trainer/ZF Expert Reward               17.8104\n",
      "trainer/ZF Policy Reward                4.41835\n",
      "trainer/ZF CHI2 Term                   38.9903\n",
      "trainer/Policy Loss                 -1112.22\n",
      "trainer/Bias Loss                      71.6306\n",
      "trainer/Bias Value                     13.0163\n",
      "trainer/Policy Grad Norm              123.829\n",
      "trainer/Policy Param Norm              34.9248\n",
      "trainer/Zf1 Grad Norm                1192.16\n",
      "trainer/Zf1 Param Norm                102.063\n",
      "trainer/Zf2 Grad Norm                1214.13\n",
      "trainer/Zf2 Param Norm                105.101\n",
      "trainer/Z Expert Predictions Mean    1307.28\n",
      "trainer/Z Expert Predictions Std       40.6977\n",
      "trainer/Z Expert Predictions Max     1393.43\n",
      "trainer/Z Expert Predictions Min     1077.25\n",
      "trainer/Z Policy Predictions Mean    1110.81\n",
      "trainer/Z Policy Predictions Std      375.446\n",
      "trainer/Z Policy Predictions Max     1363.39\n",
      "trainer/Z Policy Predictions Min     -172.248\n",
      "trainer/Z Expert Targets Mean        1289.47\n",
      "trainer/Z Expert Targets Std           42.0785\n",
      "trainer/Z Expert Targets Max         1375.4\n",
      "trainer/Z Expert Targets Min         1047.01\n",
      "trainer/Z Policy Targets Mean        1106.4\n",
      "trainer/Z Policy Targets Std          371.881\n",
      "trainer/Z Policy Targets Max         1352.29\n",
      "trainer/Z Policy Targets Min         -176.102\n",
      "trainer/Log Pis Mean                   32.0628\n",
      "trainer/Log Pis Std                     9.02382\n",
      "trainer/Policy mu Mean                  0.00972419\n",
      "trainer/Policy mu Std                   2.20667\n",
      "trainer/Policy log std Mean            -4.12222\n",
      "trainer/Policy log std Std              1.18019\n",
      "exploration/num steps total        142000\n",
      "exploration/num paths total           264\n",
      "evaluation/num steps total              1.09693e+06\n",
      "evaluation/num paths total           1417\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.52689\n",
      "evaluation/Rewards Std                  0.945339\n",
      "evaluation/Rewards Max                  6.34216\n",
      "evaluation/Rewards Min                 -1.57584\n",
      "evaluation/Returns Mean              4526.89\n",
      "evaluation/Returns Std                 94.7553\n",
      "evaluation/Returns Max               4667.08\n",
      "evaluation/Returns Min               4385.43\n",
      "evaluation/Estimation Bias Mean      1247.87\n",
      "evaluation/Estimation Bias Std        136.381\n",
      "evaluation/EB/Q_True Mean              40.289\n",
      "evaluation/EB/Q_True Std              124.172\n",
      "evaluation/EB/Q_Pred Mean            1288.16\n",
      "evaluation/EB/Q_Pred Std               48.5543\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4526.89\n",
      "evaluation/Actions Mean                 0.0207052\n",
      "evaluation/Actions Std                  0.524636\n",
      "evaluation/Actions Max                  0.99952\n",
      "evaluation/Actions Min                 -0.999155\n",
      "time/backward_policy (s)                1.90681\n",
      "time/backward_zf1 (s)                   2.047\n",
      "time/backward_zf2 (s)                   1.96097\n",
      "time/data sampling (s)                  0.309932\n",
      "time/data storing (s)                   0.0144669\n",
      "time/evaluation sampling (s)            1.74176\n",
      "time/exploration sampling (s)           0.323869\n",
      "time/logging (s)                        0.0129803\n",
      "time/preback_alpha (s)                  0.581856\n",
      "time/preback_policy (s)                 1.13048\n",
      "time/preback_start (s)                  0.14717\n",
      "time/preback_zf (s)                     5.16394\n",
      "time/saving (s)                         0.00666177\n",
      "time/training (s)                       2.26466\n",
      "time/epoch (s)                         17.6126\n",
      "time/total (s)                       2375.95\n",
      "Epoch                                 135\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:16:07.069524 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 136 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 147000\n",
      "trainer/ZF1 Loss                       -0.865517\n",
      "trainer/ZF2 Loss                      -11.3117\n",
      "trainer/ZF Expert Reward               11.168\n",
      "trainer/ZF Policy Reward               -2.13789\n",
      "trainer/ZF CHI2 Term                   38.717\n",
      "trainer/Policy Loss                 -1131.83\n",
      "trainer/Bias Loss                      82.7945\n",
      "trainer/Bias Value                     13.0262\n",
      "trainer/Policy Grad Norm              137.397\n",
      "trainer/Policy Param Norm              34.9703\n",
      "trainer/Zf1 Grad Norm                4248.22\n",
      "trainer/Zf1 Param Norm                102.277\n",
      "trainer/Zf2 Grad Norm                1745.61\n",
      "trainer/Zf2 Param Norm                105.286\n",
      "trainer/Z Expert Predictions Mean    1294.07\n",
      "trainer/Z Expert Predictions Std       45.5195\n",
      "trainer/Z Expert Predictions Max     1385.06\n",
      "trainer/Z Expert Predictions Min     1040.78\n",
      "trainer/Z Policy Predictions Mean    1120.26\n",
      "trainer/Z Policy Predictions Std      361.328\n",
      "trainer/Z Policy Predictions Max     1346.95\n",
      "trainer/Z Policy Predictions Min     -199.182\n",
      "trainer/Z Expert Targets Mean        1282.91\n",
      "trainer/Z Expert Targets Std           45.7197\n",
      "trainer/Z Expert Targets Max         1356.5\n",
      "trainer/Z Expert Targets Min         1041.95\n",
      "trainer/Z Policy Targets Mean        1122.4\n",
      "trainer/Z Policy Targets Std          355.722\n",
      "trainer/Z Policy Targets Max         1339.35\n",
      "trainer/Z Policy Targets Min         -182.283\n",
      "trainer/Log Pis Mean                   31.8178\n",
      "trainer/Log Pis Std                     9.16736\n",
      "trainer/Policy mu Mean                  0.000477336\n",
      "trainer/Policy mu Std                   2.14103\n",
      "trainer/Policy log std Mean            -4.26192\n",
      "trainer/Policy log std Std              1.08686\n",
      "exploration/num steps total        142397\n",
      "exploration/num paths total           265\n",
      "evaluation/num steps total              1.10679e+06\n",
      "evaluation/num paths total           1427\n",
      "evaluation/path length Mean           985.9\n",
      "evaluation/path length Std             42.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            859\n",
      "evaluation/Rewards Mean                 4.59868\n",
      "evaluation/Rewards Std                  1.00766\n",
      "evaluation/Rewards Max                  6.71277\n",
      "evaluation/Rewards Min                 -1.52784\n",
      "evaluation/Returns Mean              4533.84\n",
      "evaluation/Returns Std                267.339\n",
      "evaluation/Returns Max               4853.4\n",
      "evaluation/Returns Min               3822.78\n",
      "evaluation/Estimation Bias Mean      1243.5\n",
      "evaluation/Estimation Bias Std        148.899\n",
      "evaluation/EB/Q_True Mean              44.1319\n",
      "evaluation/EB/Q_True Std              135.054\n",
      "evaluation/EB/Q_Pred Mean            1287.64\n",
      "evaluation/EB/Q_Pred Std               55.2426\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4533.84\n",
      "evaluation/Actions Mean                 0.0138797\n",
      "evaluation/Actions Std                  0.530026\n",
      "evaluation/Actions Max                  0.999816\n",
      "evaluation/Actions Min                 -0.999553\n",
      "time/backward_policy (s)                1.82373\n",
      "time/backward_zf1 (s)                   2.00092\n",
      "time/backward_zf2 (s)                   1.9001\n",
      "time/data sampling (s)                  0.28749\n",
      "time/data storing (s)                   0.0144507\n",
      "time/evaluation sampling (s)            1.804\n",
      "time/exploration sampling (s)           0.321425\n",
      "time/logging (s)                        0.0115722\n",
      "time/preback_alpha (s)                  0.569059\n",
      "time/preback_policy (s)                 1.0603\n",
      "time/preback_start (s)                  0.145963\n",
      "time/preback_zf (s)                     5.13644\n",
      "time/saving (s)                         0.00634639\n",
      "time/training (s)                       2.30118\n",
      "time/epoch (s)                         17.383\n",
      "time/total (s)                       2393.35\n",
      "Epoch                                 136\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:16:24.715684 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 137 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 148000\n",
      "trainer/ZF1 Loss                        2.28459\n",
      "trainer/ZF2 Loss                       46.6401\n",
      "trainer/ZF Expert Reward               17.6665\n",
      "trainer/ZF Policy Reward                9.49625\n",
      "trainer/ZF CHI2 Term                   63.1782\n",
      "trainer/Policy Loss                 -1156.78\n",
      "trainer/Bias Loss                     278.537\n",
      "trainer/Bias Value                     13.0918\n",
      "trainer/Policy Grad Norm              134.556\n",
      "trainer/Policy Param Norm              35.0147\n",
      "trainer/Zf1 Grad Norm                2237.84\n",
      "trainer/Zf1 Param Norm                102.461\n",
      "trainer/Zf2 Grad Norm                7394.77\n",
      "trainer/Zf2 Param Norm                105.463\n",
      "trainer/Z Expert Predictions Mean    1294.96\n",
      "trainer/Z Expert Predictions Std       66.6003\n",
      "trainer/Z Expert Predictions Max     1371.62\n",
      "trainer/Z Expert Predictions Min      508.984\n",
      "trainer/Z Policy Predictions Mean    1153.78\n",
      "trainer/Z Policy Predictions Std      311.341\n",
      "trainer/Z Policy Predictions Max     1361.22\n",
      "trainer/Z Policy Predictions Min     -186.614\n",
      "trainer/Z Expert Targets Mean        1277.3\n",
      "trainer/Z Expert Targets Std           53.7819\n",
      "trainer/Z Expert Targets Max         1353.07\n",
      "trainer/Z Expert Targets Min          823.319\n",
      "trainer/Z Policy Targets Mean        1144.28\n",
      "trainer/Z Policy Targets Std          303.966\n",
      "trainer/Z Policy Targets Max         1329.04\n",
      "trainer/Z Policy Targets Min         -186.54\n",
      "trainer/Log Pis Mean                   30.8542\n",
      "trainer/Log Pis Std                     7.59615\n",
      "trainer/Policy mu Mean                 -0.0245368\n",
      "trainer/Policy mu Std                   2.10738\n",
      "trainer/Policy log std Mean            -4.26437\n",
      "trainer/Policy log std Std              1.08121\n",
      "exploration/num steps total        143397\n",
      "exploration/num paths total           266\n",
      "evaluation/num steps total              1.11679e+06\n",
      "evaluation/num paths total           1437\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66235\n",
      "evaluation/Rewards Std                  1.02425\n",
      "evaluation/Rewards Max                  6.81179\n",
      "evaluation/Rewards Min                 -2.1164\n",
      "evaluation/Returns Mean              4662.35\n",
      "evaluation/Returns Std                 81.5544\n",
      "evaluation/Returns Max               4788\n",
      "evaluation/Returns Min               4543.08\n",
      "evaluation/Estimation Bias Mean      1223.75\n",
      "evaluation/Estimation Bias Std        139.879\n",
      "evaluation/EB/Q_True Mean              41.9439\n",
      "evaluation/EB/Q_True Std              129.486\n",
      "evaluation/EB/Q_Pred Mean            1265.69\n",
      "evaluation/EB/Q_Pred Std               53.6511\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4662.35\n",
      "evaluation/Actions Mean                 0.0280205\n",
      "evaluation/Actions Std                  0.530847\n",
      "evaluation/Actions Max                  0.999806\n",
      "evaluation/Actions Min                 -0.999647\n",
      "time/backward_policy (s)                1.9553\n",
      "time/backward_zf1 (s)                   2.10083\n",
      "time/backward_zf2 (s)                   2.04221\n",
      "time/data sampling (s)                  0.288406\n",
      "time/data storing (s)                   0.0152412\n",
      "time/evaluation sampling (s)            1.74438\n",
      "time/exploration sampling (s)           0.33662\n",
      "time/logging (s)                        0.011607\n",
      "time/preback_alpha (s)                  0.567968\n",
      "time/preback_policy (s)                 1.17914\n",
      "time/preback_start (s)                  0.148871\n",
      "time/preback_zf (s)                     5.12387\n",
      "time/saving (s)                         0.00642838\n",
      "time/training (s)                       2.05786\n",
      "time/epoch (s)                         17.5787\n",
      "time/total (s)                       2410.95\n",
      "Epoch                                 137\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:16:42.367437 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 138 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 149000\n",
      "trainer/ZF1 Loss                       27.0814\n",
      "trainer/ZF2 Loss                       10.0731\n",
      "trainer/ZF Expert Reward                8.79932\n",
      "trainer/ZF Policy Reward               -4.2097\n",
      "trainer/ZF CHI2 Term                   63.0433\n",
      "trainer/Policy Loss                 -1095.35\n",
      "trainer/Bias Loss                     284.349\n",
      "trainer/Bias Value                     13.1364\n",
      "trainer/Policy Grad Norm              107.589\n",
      "trainer/Policy Param Norm              35.059\n",
      "trainer/Zf1 Grad Norm                2536.34\n",
      "trainer/Zf1 Param Norm                102.675\n",
      "trainer/Zf2 Grad Norm                1857.6\n",
      "trainer/Zf2 Param Norm                105.654\n",
      "trainer/Z Expert Predictions Mean    1285.22\n",
      "trainer/Z Expert Predictions Std       34.5853\n",
      "trainer/Z Expert Predictions Max     1349.92\n",
      "trainer/Z Expert Predictions Min     1103.7\n",
      "trainer/Z Policy Predictions Mean    1086.11\n",
      "trainer/Z Policy Predictions Std      352.332\n",
      "trainer/Z Policy Predictions Max     1330.44\n",
      "trainer/Z Policy Predictions Min     -231.987\n",
      "trainer/Z Expert Targets Mean        1276.42\n",
      "trainer/Z Expert Targets Std           42.4999\n",
      "trainer/Z Expert Targets Max         1341.53\n",
      "trainer/Z Expert Targets Min          875.668\n",
      "trainer/Z Policy Targets Mean        1090.32\n",
      "trainer/Z Policy Targets Std          350.203\n",
      "trainer/Z Policy Targets Max         1325.16\n",
      "trainer/Z Policy Targets Min         -227.993\n",
      "trainer/Log Pis Mean                   31.7748\n",
      "trainer/Log Pis Std                     8.38291\n",
      "trainer/Policy mu Mean                 -0.00595291\n",
      "trainer/Policy mu Std                   2.08392\n",
      "trainer/Policy log std Mean            -4.19168\n",
      "trainer/Policy log std Std              1.18581\n",
      "exploration/num steps total        144397\n",
      "exploration/num paths total           267\n",
      "evaluation/num steps total              1.12632e+06\n",
      "evaluation/num paths total           1447\n",
      "evaluation/path length Mean           952.3\n",
      "evaluation/path length Std            122.688\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            589\n",
      "evaluation/Rewards Mean                 4.52924\n",
      "evaluation/Rewards Std                  1.09531\n",
      "evaluation/Rewards Max                  6.75451\n",
      "evaluation/Rewards Min                 -2.68769\n",
      "evaluation/Returns Mean              4313.2\n",
      "evaluation/Returns Std                631.994\n",
      "evaluation/Returns Max               4792.99\n",
      "evaluation/Returns Min               2522.18\n",
      "evaluation/Estimation Bias Mean      1228.69\n",
      "evaluation/Estimation Bias Std        153.215\n",
      "evaluation/EB/Q_True Mean              42.8194\n",
      "evaluation/EB/Q_True Std              128.626\n",
      "evaluation/EB/Q_Pred Mean            1271.51\n",
      "evaluation/EB/Q_Pred Std               67.8405\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4313.2\n",
      "evaluation/Actions Mean                 0.0174999\n",
      "evaluation/Actions Std                  0.534541\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.94952\n",
      "time/backward_zf1 (s)                   2.07872\n",
      "time/backward_zf2 (s)                   1.98892\n",
      "time/data sampling (s)                  0.284795\n",
      "time/data storing (s)                   0.0154538\n",
      "time/evaluation sampling (s)            1.7271\n",
      "time/exploration sampling (s)           0.323117\n",
      "time/logging (s)                        0.0118376\n",
      "time/preback_alpha (s)                  0.571291\n",
      "time/preback_policy (s)                 1.14755\n",
      "time/preback_start (s)                  0.148091\n",
      "time/preback_zf (s)                     5.14171\n",
      "time/saving (s)                         0.00619142\n",
      "time/training (s)                       2.18845\n",
      "time/epoch (s)                         17.5827\n",
      "time/total (s)                       2428.56\n",
      "Epoch                                 138\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:17:00.123363 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 139 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 150000\n",
      "trainer/ZF1 Loss                        1.67344\n",
      "trainer/ZF2 Loss                        2.31984\n",
      "trainer/ZF Expert Reward               14.6282\n",
      "trainer/ZF Policy Reward                3.98663\n",
      "trainer/ZF CHI2 Term                   43.652\n",
      "trainer/Policy Loss                 -1116.48\n",
      "trainer/Bias Loss                      46.6206\n",
      "trainer/Bias Value                     13.1863\n",
      "trainer/Policy Grad Norm              121.127\n",
      "trainer/Policy Param Norm              35.1004\n",
      "trainer/Zf1 Grad Norm                1752.89\n",
      "trainer/Zf1 Param Norm                102.884\n",
      "trainer/Zf2 Grad Norm                1688.69\n",
      "trainer/Zf2 Param Norm                105.856\n",
      "trainer/Z Expert Predictions Mean    1281.61\n",
      "trainer/Z Expert Predictions Std       47.1663\n",
      "trainer/Z Expert Predictions Max     1363.41\n",
      "trainer/Z Expert Predictions Min      970.266\n",
      "trainer/Z Policy Predictions Mean    1111\n",
      "trainer/Z Policy Predictions Std      346.899\n",
      "trainer/Z Policy Predictions Max     1339.73\n",
      "trainer/Z Policy Predictions Min     -247.566\n",
      "trainer/Z Expert Targets Mean        1266.99\n",
      "trainer/Z Expert Targets Std           47.4898\n",
      "trainer/Z Expert Targets Max         1351.58\n",
      "trainer/Z Expert Targets Min          941.135\n",
      "trainer/Z Policy Targets Mean        1107.01\n",
      "trainer/Z Policy Targets Std          339.803\n",
      "trainer/Z Policy Targets Max         1328.12\n",
      "trainer/Z Policy Targets Min         -246.294\n",
      "trainer/Log Pis Mean                   31.327\n",
      "trainer/Log Pis Std                     7.85533\n",
      "trainer/Policy mu Mean                 -0.0844175\n",
      "trainer/Policy mu Std                   1.85919\n",
      "trainer/Policy log std Mean            -4.24526\n",
      "trainer/Policy log std Std              1.08619\n",
      "exploration/num steps total        144397\n",
      "exploration/num paths total           267\n",
      "evaluation/num steps total              1.13535e+06\n",
      "evaluation/num paths total           1457\n",
      "evaluation/path length Mean           903.2\n",
      "evaluation/path length Std            290.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             32\n",
      "evaluation/Rewards Mean                 4.58382\n",
      "evaluation/Rewards Std                  1.07674\n",
      "evaluation/Rewards Max                  6.67298\n",
      "evaluation/Rewards Min                 -2.18664\n",
      "evaluation/Returns Mean              4140.11\n",
      "evaluation/Returns Std               1365.87\n",
      "evaluation/Returns Max               4897.74\n",
      "evaluation/Returns Min                 60.7414\n",
      "evaluation/Estimation Bias Mean      1224.21\n",
      "evaluation/Estimation Bias Std        147.63\n",
      "evaluation/EB/Q_True Mean              46.4047\n",
      "evaluation/EB/Q_True Std              135.345\n",
      "evaluation/EB/Q_Pred Mean            1270.62\n",
      "evaluation/EB/Q_Pred Std               62.2164\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4140.11\n",
      "evaluation/Actions Mean                 0.0277831\n",
      "evaluation/Actions Std                  0.531609\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.999268\n",
      "time/backward_policy (s)                1.97474\n",
      "time/backward_zf1 (s)                   2.11818\n",
      "time/backward_zf2 (s)                   2.0424\n",
      "time/data sampling (s)                  0.290428\n",
      "time/data storing (s)                   0.0147757\n",
      "time/evaluation sampling (s)            1.77243\n",
      "time/exploration sampling (s)           0.325327\n",
      "time/logging (s)                        0.0129322\n",
      "time/preback_alpha (s)                  0.565667\n",
      "time/preback_policy (s)                 1.1526\n",
      "time/preback_start (s)                  0.14392\n",
      "time/preback_zf (s)                     5.09638\n",
      "time/saving (s)                         0.00611737\n",
      "time/training (s)                       2.17366\n",
      "time/epoch (s)                         17.6895\n",
      "time/total (s)                       2446.27\n",
      "Epoch                                 139\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:17:17.440891 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 140 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 151000\n",
      "trainer/ZF1 Loss                        4.66022\n",
      "trainer/ZF2 Loss                        3.26482\n",
      "trainer/ZF Expert Reward               14.8557\n",
      "trainer/ZF Policy Reward                6.07305\n",
      "trainer/ZF CHI2 Term                   43.3106\n",
      "trainer/Policy Loss                 -1148.87\n",
      "trainer/Bias Loss                      97.7531\n",
      "trainer/Bias Value                     13.2278\n",
      "trainer/Policy Grad Norm               87.6313\n",
      "trainer/Policy Param Norm              35.1438\n",
      "trainer/Zf1 Grad Norm                1202.3\n",
      "trainer/Zf1 Param Norm                103.101\n",
      "trainer/Zf2 Grad Norm                1283.68\n",
      "trainer/Zf2 Param Norm                106.058\n",
      "trainer/Z Expert Predictions Mean    1279.29\n",
      "trainer/Z Expert Predictions Std       49.6571\n",
      "trainer/Z Expert Predictions Max     1354.94\n",
      "trainer/Z Expert Predictions Min     1041.75\n",
      "trainer/Z Policy Predictions Mean    1145.49\n",
      "trainer/Z Policy Predictions Std      319.072\n",
      "trainer/Z Policy Predictions Max     1328.76\n",
      "trainer/Z Policy Predictions Min     -317.49\n",
      "trainer/Z Expert Targets Mean        1264.43\n",
      "trainer/Z Expert Targets Std           50.7079\n",
      "trainer/Z Expert Targets Max         1342.12\n",
      "trainer/Z Expert Targets Min         1020.49\n",
      "trainer/Z Policy Targets Mean        1139.41\n",
      "trainer/Z Policy Targets Std          316.279\n",
      "trainer/Z Policy Targets Max         1317.33\n",
      "trainer/Z Policy Targets Min         -302.128\n",
      "trainer/Log Pis Mean                   30.8741\n",
      "trainer/Log Pis Std                     7.47533\n",
      "trainer/Policy mu Mean                 -0.0324544\n",
      "trainer/Policy mu Std                   1.86157\n",
      "trainer/Policy log std Mean            -4.37854\n",
      "trainer/Policy log std Std              1.01221\n",
      "exploration/num steps total        144397\n",
      "exploration/num paths total           267\n",
      "evaluation/num steps total              1.14449e+06\n",
      "evaluation/num paths total           1467\n",
      "evaluation/path length Mean           914.7\n",
      "evaluation/path length Std            255.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            147\n",
      "evaluation/Rewards Mean                 4.5975\n",
      "evaluation/Rewards Std                  1.04384\n",
      "evaluation/Rewards Max                  6.83791\n",
      "evaluation/Rewards Min                 -2.27643\n",
      "evaluation/Returns Mean              4205.33\n",
      "evaluation/Returns Std               1205.6\n",
      "evaluation/Returns Max               4701.37\n",
      "evaluation/Returns Min                594.587\n",
      "evaluation/Estimation Bias Mean      1217.55\n",
      "evaluation/Estimation Bias Std        153.859\n",
      "evaluation/EB/Q_True Mean              47.1448\n",
      "evaluation/EB/Q_True Std              138.414\n",
      "evaluation/EB/Q_Pred Mean            1264.69\n",
      "evaluation/EB/Q_Pred Std               61.0638\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4205.33\n",
      "evaluation/Actions Mean                 0.0237106\n",
      "evaluation/Actions Std                  0.53359\n",
      "evaluation/Actions Max                  0.999864\n",
      "evaluation/Actions Min                 -0.999827\n",
      "time/backward_policy (s)                1.85243\n",
      "time/backward_zf1 (s)                   1.97536\n",
      "time/backward_zf2 (s)                   1.9043\n",
      "time/data sampling (s)                  0.297458\n",
      "time/data storing (s)                   0.0138291\n",
      "time/evaluation sampling (s)            1.81015\n",
      "time/exploration sampling (s)           0.318091\n",
      "time/logging (s)                        0.0111012\n",
      "time/preback_alpha (s)                  0.562482\n",
      "time/preback_policy (s)                 1.10252\n",
      "time/preback_start (s)                  0.142407\n",
      "time/preback_zf (s)                     5.06347\n",
      "time/saving (s)                         0.00580945\n",
      "time/training (s)                       2.18077\n",
      "time/epoch (s)                         17.2402\n",
      "time/total (s)                       2463.53\n",
      "Epoch                                 140\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:17:34.929623 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 141 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 152000\n",
      "trainer/ZF1 Loss                       -9.94164\n",
      "trainer/ZF2 Loss                       -7.95089\n",
      "trainer/ZF Expert Reward               14.1101\n",
      "trainer/ZF Policy Reward                1.78425\n",
      "trainer/ZF CHI2 Term                   34.231\n",
      "trainer/Policy Loss                 -1098.06\n",
      "trainer/Bias Loss                      69.1801\n",
      "trainer/Bias Value                     13.268\n",
      "trainer/Policy Grad Norm              108.617\n",
      "trainer/Policy Param Norm              35.1879\n",
      "trainer/Zf1 Grad Norm                1332.68\n",
      "trainer/Zf1 Param Norm                103.309\n",
      "trainer/Zf2 Grad Norm                1490.27\n",
      "trainer/Zf2 Param Norm                106.256\n",
      "trainer/Z Expert Predictions Mean    1274.21\n",
      "trainer/Z Expert Predictions Std       44.7518\n",
      "trainer/Z Expert Predictions Max     1341.73\n",
      "trainer/Z Expert Predictions Min     1079.98\n",
      "trainer/Z Policy Predictions Mean    1092.7\n",
      "trainer/Z Policy Predictions Std      392.6\n",
      "trainer/Z Policy Predictions Max     1328.32\n",
      "trainer/Z Policy Predictions Min     -351.667\n",
      "trainer/Z Expert Targets Mean        1260.1\n",
      "trainer/Z Expert Targets Std           45.7801\n",
      "trainer/Z Expert Targets Max         1332.78\n",
      "trainer/Z Expert Targets Min         1059.65\n",
      "trainer/Z Policy Targets Mean        1090.92\n",
      "trainer/Z Policy Targets Std          386.84\n",
      "trainer/Z Policy Targets Max         1316.32\n",
      "trainer/Z Policy Targets Min         -338.685\n",
      "trainer/Log Pis Mean                   31.163\n",
      "trainer/Log Pis Std                     8.64913\n",
      "trainer/Policy mu Mean                 -0.072323\n",
      "trainer/Policy mu Std                   2.28736\n",
      "trainer/Policy log std Mean            -4.14433\n",
      "trainer/Policy log std Std              1.17188\n",
      "exploration/num steps total        146397\n",
      "exploration/num paths total           269\n",
      "evaluation/num steps total              1.15449e+06\n",
      "evaluation/num paths total           1477\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60507\n",
      "evaluation/Rewards Std                  0.998314\n",
      "evaluation/Rewards Max                  6.92004\n",
      "evaluation/Rewards Min                 -3.02439\n",
      "evaluation/Returns Mean              4605.07\n",
      "evaluation/Returns Std                 89.9345\n",
      "evaluation/Returns Max               4710.85\n",
      "evaluation/Returns Min               4479.9\n",
      "evaluation/Estimation Bias Mean      1227.03\n",
      "evaluation/Estimation Bias Std        141.39\n",
      "evaluation/EB/Q_True Mean              42.2261\n",
      "evaluation/EB/Q_True Std              129.878\n",
      "evaluation/EB/Q_Pred Mean            1269.25\n",
      "evaluation/EB/Q_Pred Std               51.4619\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4605.07\n",
      "evaluation/Actions Mean                 0.023458\n",
      "evaluation/Actions Std                  0.536531\n",
      "evaluation/Actions Max                  0.999798\n",
      "evaluation/Actions Min                 -0.999717\n",
      "time/backward_policy (s)                1.87653\n",
      "time/backward_zf1 (s)                   2.02148\n",
      "time/backward_zf2 (s)                   1.95191\n",
      "time/data sampling (s)                  0.302311\n",
      "time/data storing (s)                   0.0140862\n",
      "time/evaluation sampling (s)            1.82017\n",
      "time/exploration sampling (s)           0.32967\n",
      "time/logging (s)                        0.0130227\n",
      "time/preback_alpha (s)                  0.566354\n",
      "time/preback_policy (s)                 1.12882\n",
      "time/preback_start (s)                  0.14548\n",
      "time/preback_zf (s)                     5.11099\n",
      "time/saving (s)                         0.00661183\n",
      "time/training (s)                       2.13288\n",
      "time/epoch (s)                         17.4203\n",
      "time/total (s)                       2480.98\n",
      "Epoch                                 141\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:17:52.391822 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 142 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 153000\n",
      "trainer/ZF1 Loss                       -8.50657\n",
      "trainer/ZF2 Loss                       -5.60444\n",
      "trainer/ZF Expert Reward               15.2379\n",
      "trainer/ZF Policy Reward                3.56938\n",
      "trainer/ZF CHI2 Term                   35.4969\n",
      "trainer/Policy Loss                 -1119.87\n",
      "trainer/Bias Loss                      64.0127\n",
      "trainer/Bias Value                     13.3362\n",
      "trainer/Policy Grad Norm              177.88\n",
      "trainer/Policy Param Norm              35.2317\n",
      "trainer/Zf1 Grad Norm                1296.23\n",
      "trainer/Zf1 Param Norm                103.515\n",
      "trainer/Zf2 Grad Norm                1138.95\n",
      "trainer/Zf2 Param Norm                106.443\n",
      "trainer/Z Expert Predictions Mean    1275.26\n",
      "trainer/Z Expert Predictions Std       46.0625\n",
      "trainer/Z Expert Predictions Max     1350.76\n",
      "trainer/Z Expert Predictions Min      937.053\n",
      "trainer/Z Policy Predictions Mean    1113.18\n",
      "trainer/Z Policy Predictions Std      336.601\n",
      "trainer/Z Policy Predictions Max     1327.84\n",
      "trainer/Z Policy Predictions Min     -369.054\n",
      "trainer/Z Expert Targets Mean        1260.02\n",
      "trainer/Z Expert Targets Std           47.3847\n",
      "trainer/Z Expert Targets Max         1321.82\n",
      "trainer/Z Expert Targets Min          911.629\n",
      "trainer/Z Policy Targets Mean        1109.61\n",
      "trainer/Z Policy Targets Std          329.739\n",
      "trainer/Z Policy Targets Max         1316.2\n",
      "trainer/Z Policy Targets Min         -385.181\n",
      "trainer/Log Pis Mean                   31.1958\n",
      "trainer/Log Pis Std                     7.81995\n",
      "trainer/Policy mu Mean                 -0.0543493\n",
      "trainer/Policy mu Std                   1.9075\n",
      "trainer/Policy log std Mean            -4.32741\n",
      "trainer/Policy log std Std              1.04727\n",
      "exploration/num steps total        148397\n",
      "exploration/num paths total           271\n",
      "evaluation/num steps total              1.16445e+06\n",
      "evaluation/num paths total           1487\n",
      "evaluation/path length Mean           995.9\n",
      "evaluation/path length Std             12.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            959\n",
      "evaluation/Rewards Mean                 4.61953\n",
      "evaluation/Rewards Std                  1.03148\n",
      "evaluation/Rewards Max                  6.58896\n",
      "evaluation/Rewards Min                 -4.9453\n",
      "evaluation/Returns Mean              4600.59\n",
      "evaluation/Returns Std                142.511\n",
      "evaluation/Returns Max               4770.68\n",
      "evaluation/Returns Min               4268.2\n",
      "evaluation/Estimation Bias Mean      1216.7\n",
      "evaluation/Estimation Bias Std        143.927\n",
      "evaluation/EB/Q_True Mean              41.5093\n",
      "evaluation/EB/Q_True Std              127.108\n",
      "evaluation/EB/Q_Pred Mean            1258.21\n",
      "evaluation/EB/Q_Pred Std               60.6427\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4600.59\n",
      "evaluation/Actions Mean                 0.0212691\n",
      "evaluation/Actions Std                  0.537069\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81991\n",
      "time/backward_zf1 (s)                   1.97843\n",
      "time/backward_zf2 (s)                   1.89525\n",
      "time/data sampling (s)                  0.301872\n",
      "time/data storing (s)                   0.0142298\n",
      "time/evaluation sampling (s)            1.70969\n",
      "time/exploration sampling (s)           0.325589\n",
      "time/logging (s)                        0.0122068\n",
      "time/preback_alpha (s)                  0.575313\n",
      "time/preback_policy (s)                 1.04343\n",
      "time/preback_start (s)                  0.147355\n",
      "time/preback_zf (s)                     5.12127\n",
      "time/saving (s)                         0.00644184\n",
      "time/training (s)                       2.43941\n",
      "time/epoch (s)                         17.3904\n",
      "time/total (s)                       2498.39\n",
      "Epoch                                 142\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:18:10.880982 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 143 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 154000\n",
      "trainer/ZF1 Loss                      172.97\n",
      "trainer/ZF2 Loss                      276.99\n",
      "trainer/ZF Expert Reward               10.5433\n",
      "trainer/ZF Policy Reward                2.37784\n",
      "trainer/ZF CHI2 Term                  264.355\n",
      "trainer/Policy Loss                 -1088.57\n",
      "trainer/Bias Loss                     113.378\n",
      "trainer/Bias Value                     13.3887\n",
      "trainer/Policy Grad Norm              106.994\n",
      "trainer/Policy Param Norm              35.2732\n",
      "trainer/Zf1 Grad Norm                3195.48\n",
      "trainer/Zf1 Param Norm                103.718\n",
      "trainer/Zf2 Grad Norm                1873.75\n",
      "trainer/Zf2 Param Norm                106.651\n",
      "trainer/Z Expert Predictions Mean    1260.17\n",
      "trainer/Z Expert Predictions Std       83.6989\n",
      "trainer/Z Expert Predictions Max     1320.99\n",
      "trainer/Z Expert Predictions Min       54.7241\n",
      "trainer/Z Policy Predictions Mean    1082.58\n",
      "trainer/Z Policy Predictions Std      368.804\n",
      "trainer/Z Policy Predictions Max     1305.11\n",
      "trainer/Z Policy Predictions Min     -424.721\n",
      "trainer/Z Expert Targets Mean        1249.63\n",
      "trainer/Z Expert Targets Std           87.7017\n",
      "trainer/Z Expert Targets Max         1322.58\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1080.2\n",
      "trainer/Z Policy Targets Std          371.028\n",
      "trainer/Z Policy Targets Max         1303.78\n",
      "trainer/Z Policy Targets Min         -418.026\n",
      "trainer/Log Pis Mean                   31.5249\n",
      "trainer/Log Pis Std                     8.05055\n",
      "trainer/Policy mu Mean                 -0.0607605\n",
      "trainer/Policy mu Std                   2.13492\n",
      "trainer/Policy log std Mean            -4.17092\n",
      "trainer/Policy log std Std              1.14994\n",
      "exploration/num steps total        149397\n",
      "exploration/num paths total           272\n",
      "evaluation/num steps total              1.1735e+06\n",
      "evaluation/num paths total           1497\n",
      "evaluation/path length Mean           904.5\n",
      "evaluation/path length Std            286.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             45\n",
      "evaluation/Rewards Mean                 4.58235\n",
      "evaluation/Rewards Std                  1.04859\n",
      "evaluation/Rewards Max                  6.62279\n",
      "evaluation/Rewards Min                 -2.66575\n",
      "evaluation/Returns Mean              4144.74\n",
      "evaluation/Returns Std               1357.9\n",
      "evaluation/Returns Max               4789.56\n",
      "evaluation/Returns Min                 92.1548\n",
      "evaluation/Estimation Bias Mean      1202.17\n",
      "evaluation/Estimation Bias Std        152.579\n",
      "evaluation/EB/Q_True Mean              48.6564\n",
      "evaluation/EB/Q_True Std              142.127\n",
      "evaluation/EB/Q_Pred Mean            1250.82\n",
      "evaluation/EB/Q_Pred Std               61.1987\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4144.74\n",
      "evaluation/Actions Mean                 0.0247275\n",
      "evaluation/Actions Std                  0.532142\n",
      "evaluation/Actions Max                  0.999671\n",
      "evaluation/Actions Min                 -0.999749\n",
      "time/backward_policy (s)                1.95205\n",
      "time/backward_zf1 (s)                   2.19377\n",
      "time/backward_zf2 (s)                   2.06272\n",
      "time/data sampling (s)                  0.342009\n",
      "time/data storing (s)                   0.0152248\n",
      "time/evaluation sampling (s)            1.85394\n",
      "time/exploration sampling (s)           0.33069\n",
      "time/logging (s)                        0.0111416\n",
      "time/preback_alpha (s)                  0.621715\n",
      "time/preback_policy (s)                 1.1143\n",
      "time/preback_start (s)                  0.157462\n",
      "time/preback_zf (s)                     5.31251\n",
      "time/saving (s)                         0.00624019\n",
      "time/training (s)                       2.44267\n",
      "time/epoch (s)                         18.4165\n",
      "time/total (s)                       2516.83\n",
      "Epoch                                 143\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:18:28.503370 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 144 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 155000\n",
      "trainer/ZF1 Loss                       16.2308\n",
      "trainer/ZF2 Loss                        9.66322\n",
      "trainer/ZF Expert Reward               10.2686\n",
      "trainer/ZF Policy Reward                0.480336\n",
      "trainer/ZF CHI2 Term                   53.6504\n",
      "trainer/Policy Loss                 -1119.99\n",
      "trainer/Bias Loss                     102.725\n",
      "trainer/Bias Value                     13.4478\n",
      "trainer/Policy Grad Norm               96.4695\n",
      "trainer/Policy Param Norm              35.3234\n",
      "trainer/Zf1 Grad Norm                3187.39\n",
      "trainer/Zf1 Param Norm                103.923\n",
      "trainer/Zf2 Grad Norm                2031.34\n",
      "trainer/Zf2 Param Norm                106.861\n",
      "trainer/Z Expert Predictions Mean    1257.6\n",
      "trainer/Z Expert Predictions Std       90.2581\n",
      "trainer/Z Expert Predictions Max     1334.59\n",
      "trainer/Z Expert Predictions Min       20.2954\n",
      "trainer/Z Policy Predictions Mean    1110.09\n",
      "trainer/Z Policy Predictions Std      316.895\n",
      "trainer/Z Policy Predictions Max     1325.06\n",
      "trainer/Z Policy Predictions Min     -381.295\n",
      "trainer/Z Expert Targets Mean        1247.33\n",
      "trainer/Z Expert Targets Std           91.8324\n",
      "trainer/Z Expert Targets Max         1319.31\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1109.6\n",
      "trainer/Z Policy Targets Std          311.392\n",
      "trainer/Z Policy Targets Max         1307.31\n",
      "trainer/Z Policy Targets Min         -356.288\n",
      "trainer/Log Pis Mean                   31.2275\n",
      "trainer/Log Pis Std                     8.40193\n",
      "trainer/Policy mu Mean                  0.0142176\n",
      "trainer/Policy mu Std                   1.88225\n",
      "trainer/Policy log std Mean            -4.30427\n",
      "trainer/Policy log std Std              0.994659\n",
      "exploration/num steps total        150397\n",
      "exploration/num paths total           273\n",
      "evaluation/num steps total              1.18254e+06\n",
      "evaluation/num paths total           1507\n",
      "evaluation/path length Mean           904.5\n",
      "evaluation/path length Std            286.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             45\n",
      "evaluation/Rewards Mean                 4.60113\n",
      "evaluation/Rewards Std                  1.20303\n",
      "evaluation/Rewards Max                  6.83057\n",
      "evaluation/Rewards Min                 -3.21688\n",
      "evaluation/Returns Mean              4161.72\n",
      "evaluation/Returns Std               1374.86\n",
      "evaluation/Returns Max               4921.23\n",
      "evaluation/Returns Min                 73.9509\n",
      "evaluation/Estimation Bias Mean      1204.96\n",
      "evaluation/Estimation Bias Std        153.429\n",
      "evaluation/EB/Q_True Mean              44.3856\n",
      "evaluation/EB/Q_True Std              131.707\n",
      "evaluation/EB/Q_Pred Mean            1249.34\n",
      "evaluation/EB/Q_Pred Std               76.3438\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4161.72\n",
      "evaluation/Actions Mean                 0.0172773\n",
      "evaluation/Actions Std                  0.539303\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84344\n",
      "time/backward_zf1 (s)                   1.99623\n",
      "time/backward_zf2 (s)                   1.89759\n",
      "time/data sampling (s)                  0.320192\n",
      "time/data storing (s)                   0.0152701\n",
      "time/evaluation sampling (s)            1.80852\n",
      "time/exploration sampling (s)           0.333839\n",
      "time/logging (s)                        0.0117492\n",
      "time/preback_alpha (s)                  0.580442\n",
      "time/preback_policy (s)                 1.04954\n",
      "time/preback_start (s)                  0.149125\n",
      "time/preback_zf (s)                     5.11473\n",
      "time/saving (s)                         0.00609103\n",
      "time/training (s)                       2.42288\n",
      "time/epoch (s)                         17.5496\n",
      "time/total (s)                       2534.4\n",
      "Epoch                                 144\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:18:46.462269 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 145 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 156000\n",
      "trainer/ZF1 Loss                       -5.70273\n",
      "trainer/ZF2 Loss                       42.9784\n",
      "trainer/ZF Expert Reward               18.6855\n",
      "trainer/ZF Policy Reward                6.57394\n",
      "trainer/ZF CHI2 Term                   63.0683\n",
      "trainer/Policy Loss                 -1099.89\n",
      "trainer/Bias Loss                     257.61\n",
      "trainer/Bias Value                     13.5104\n",
      "trainer/Policy Grad Norm              132.514\n",
      "trainer/Policy Param Norm              35.3673\n",
      "trainer/Zf1 Grad Norm                3040.83\n",
      "trainer/Zf1 Param Norm                104.125\n",
      "trainer/Zf2 Grad Norm               15073.8\n",
      "trainer/Zf2 Param Norm                107.048\n",
      "trainer/Z Expert Predictions Mean    1264.23\n",
      "trainer/Z Expert Predictions Std       76.2386\n",
      "trainer/Z Expert Predictions Max     1336.29\n",
      "trainer/Z Expert Predictions Min      311.134\n",
      "trainer/Z Policy Predictions Mean    1094.81\n",
      "trainer/Z Policy Predictions Std      371.073\n",
      "trainer/Z Policy Predictions Max     1329.98\n",
      "trainer/Z Policy Predictions Min     -386.984\n",
      "trainer/Z Expert Targets Mean        1245.54\n",
      "trainer/Z Expert Targets Std           92.0828\n",
      "trainer/Z Expert Targets Max         1310.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1088.24\n",
      "trainer/Z Policy Targets Std          364.696\n",
      "trainer/Z Policy Targets Max         1299.54\n",
      "trainer/Z Policy Targets Min         -367.076\n",
      "trainer/Log Pis Mean                   32.6455\n",
      "trainer/Log Pis Std                     9.40082\n",
      "trainer/Policy mu Mean                 -0.0671639\n",
      "trainer/Policy mu Std                   2.08021\n",
      "trainer/Policy log std Mean            -4.30202\n",
      "trainer/Policy log std Std              1.08884\n",
      "exploration/num steps total        151397\n",
      "exploration/num paths total           274\n",
      "evaluation/num steps total              1.19116e+06\n",
      "evaluation/num paths total           1517\n",
      "evaluation/path length Mean           862.1\n",
      "evaluation/path length Std            259.015\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            329\n",
      "evaluation/Rewards Mean                 4.57165\n",
      "evaluation/Rewards Std                  1.11445\n",
      "evaluation/Rewards Max                  6.81315\n",
      "evaluation/Rewards Min                 -1.87019\n",
      "evaluation/Returns Mean              3941.22\n",
      "evaluation/Returns Std               1192.37\n",
      "evaluation/Returns Max               4787.63\n",
      "evaluation/Returns Min               1533.34\n",
      "evaluation/Estimation Bias Mean      1195.92\n",
      "evaluation/Estimation Bias Std        159.602\n",
      "evaluation/EB/Q_True Mean              48.6023\n",
      "evaluation/EB/Q_True Std              137.459\n",
      "evaluation/EB/Q_Pred Mean            1244.52\n",
      "evaluation/EB/Q_Pred Std               71.5343\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3941.22\n",
      "evaluation/Actions Mean                 0.0191624\n",
      "evaluation/Actions Std                  0.534035\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999935\n",
      "time/backward_policy (s)                1.9682\n",
      "time/backward_zf1 (s)                   2.11527\n",
      "time/backward_zf2 (s)                   2.06103\n",
      "time/data sampling (s)                  0.315251\n",
      "time/data storing (s)                   0.014861\n",
      "time/evaluation sampling (s)            1.81409\n",
      "time/exploration sampling (s)           0.326745\n",
      "time/logging (s)                        0.0127078\n",
      "time/preback_alpha (s)                  0.584341\n",
      "time/preback_policy (s)                 1.17984\n",
      "time/preback_start (s)                  0.148214\n",
      "time/preback_zf (s)                     5.13089\n",
      "time/saving (s)                         0.00821555\n",
      "time/training (s)                       2.20792\n",
      "time/epoch (s)                         17.8876\n",
      "time/total (s)                       2552.31\n",
      "Epoch                                 145\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:19:04.479526 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 146 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 157000\n",
      "trainer/ZF1 Loss                       -0.670944\n",
      "trainer/ZF2 Loss                       86.9666\n",
      "trainer/ZF Expert Reward               12.622\n",
      "trainer/ZF Policy Reward                2.76602\n",
      "trainer/ZF CHI2 Term                   84.275\n",
      "trainer/Policy Loss                 -1047.35\n",
      "trainer/Bias Loss                      72.8045\n",
      "trainer/Bias Value                     13.5501\n",
      "trainer/Policy Grad Norm              105.504\n",
      "trainer/Policy Param Norm              35.4091\n",
      "trainer/Zf1 Grad Norm                1738.07\n",
      "trainer/Zf1 Param Norm                104.33\n",
      "trainer/Zf2 Grad Norm                1847.03\n",
      "trainer/Zf2 Param Norm                107.229\n",
      "trainer/Z Expert Predictions Mean    1261.9\n",
      "trainer/Z Expert Predictions Std       42.8458\n",
      "trainer/Z Expert Predictions Max     1332.85\n",
      "trainer/Z Expert Predictions Min      993.712\n",
      "trainer/Z Policy Predictions Mean    1043.23\n",
      "trainer/Z Policy Predictions Std      415.007\n",
      "trainer/Z Policy Predictions Max     1317.88\n",
      "trainer/Z Policy Predictions Min     -465.709\n",
      "trainer/Z Expert Targets Mean        1249.28\n",
      "trainer/Z Expert Targets Std           45.5477\n",
      "trainer/Z Expert Targets Max         1330.3\n",
      "trainer/Z Expert Targets Min          970.385\n",
      "trainer/Z Policy Targets Mean        1040.47\n",
      "trainer/Z Policy Targets Std          410.666\n",
      "trainer/Z Policy Targets Max         1304.86\n",
      "trainer/Z Policy Targets Min         -470.19\n",
      "trainer/Log Pis Mean                   31.587\n",
      "trainer/Log Pis Std                     8.37519\n",
      "trainer/Policy mu Mean                 -0.0464983\n",
      "trainer/Policy mu Std                   2.11758\n",
      "trainer/Policy log std Mean            -4.08958\n",
      "trainer/Policy log std Std              1.27226\n",
      "exploration/num steps total        152397\n",
      "exploration/num paths total           275\n",
      "evaluation/num steps total              1.1992e+06\n",
      "evaluation/num paths total           1527\n",
      "evaluation/path length Mean           803.1\n",
      "evaluation/path length Std            325.174\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             29\n",
      "evaluation/Rewards Mean                 4.60558\n",
      "evaluation/Rewards Std                  1.118\n",
      "evaluation/Rewards Max                  6.75526\n",
      "evaluation/Rewards Min                 -3.35123\n",
      "evaluation/Returns Mean              3698.74\n",
      "evaluation/Returns Std               1534.56\n",
      "evaluation/Returns Max               4711.78\n",
      "evaluation/Returns Min                 39.9596\n",
      "evaluation/Estimation Bias Mean      1193.24\n",
      "evaluation/Estimation Bias Std        171.737\n",
      "evaluation/EB/Q_True Mean              53.8548\n",
      "evaluation/EB/Q_True Std              147.208\n",
      "evaluation/EB/Q_Pred Mean            1247.1\n",
      "evaluation/EB/Q_Pred Std               74.0637\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3698.74\n",
      "evaluation/Actions Mean                 0.0220353\n",
      "evaluation/Actions Std                  0.544931\n",
      "evaluation/Actions Max                  0.999961\n",
      "evaluation/Actions Min                 -0.999991\n",
      "time/backward_policy (s)                1.95702\n",
      "time/backward_zf1 (s)                   2.12947\n",
      "time/backward_zf2 (s)                   2.0438\n",
      "time/data sampling (s)                  0.327706\n",
      "time/data storing (s)                   0.0150874\n",
      "time/evaluation sampling (s)            1.75166\n",
      "time/exploration sampling (s)           0.32687\n",
      "time/logging (s)                        0.0117861\n",
      "time/preback_alpha (s)                  0.590675\n",
      "time/preback_policy (s)                 1.13711\n",
      "time/preback_start (s)                  0.149362\n",
      "time/preback_zf (s)                     5.18066\n",
      "time/saving (s)                         0.00638399\n",
      "time/training (s)                       2.3154\n",
      "time/epoch (s)                         17.943\n",
      "time/total (s)                       2570.28\n",
      "Epoch                                 146\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:19:22.134536 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 147 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 158000\n",
      "trainer/ZF1 Loss                      279.974\n",
      "trainer/ZF2 Loss                      282.221\n",
      "trainer/ZF Expert Reward               15.8726\n",
      "trainer/ZF Policy Reward                8.10995\n",
      "trainer/ZF CHI2 Term                  319.863\n",
      "trainer/Policy Loss                 -1128.6\n",
      "trainer/Bias Loss                      50.7927\n",
      "trainer/Bias Value                     13.5629\n",
      "trainer/Policy Grad Norm              110.187\n",
      "trainer/Policy Param Norm              35.4556\n",
      "trainer/Zf1 Grad Norm                2021.24\n",
      "trainer/Zf1 Param Norm                104.527\n",
      "trainer/Zf2 Grad Norm                2400.64\n",
      "trainer/Zf2 Param Norm                107.433\n",
      "trainer/Z Expert Predictions Mean    1263.36\n",
      "trainer/Z Expert Predictions Std       46.8051\n",
      "trainer/Z Expert Predictions Max     1334.01\n",
      "trainer/Z Expert Predictions Min     1034.28\n",
      "trainer/Z Policy Predictions Mean    1124.2\n",
      "trainer/Z Policy Predictions Std      318.958\n",
      "trainer/Z Policy Predictions Max     1329.26\n",
      "trainer/Z Policy Predictions Min     -489.471\n",
      "trainer/Z Expert Targets Mean        1247.49\n",
      "trainer/Z Expert Targets Std           49.0356\n",
      "trainer/Z Expert Targets Max         1313.36\n",
      "trainer/Z Expert Targets Min          993.584\n",
      "trainer/Z Policy Targets Mean        1116.09\n",
      "trainer/Z Policy Targets Std          319.716\n",
      "trainer/Z Policy Targets Max         1311.05\n",
      "trainer/Z Policy Targets Min         -471.346\n",
      "trainer/Log Pis Mean                   31.3155\n",
      "trainer/Log Pis Std                     7.01024\n",
      "trainer/Policy mu Mean                 -0.0106987\n",
      "trainer/Policy mu Std                   1.55465\n",
      "trainer/Policy log std Mean            -4.39069\n",
      "trainer/Policy log std Std              0.916909\n",
      "exploration/num steps total        153397\n",
      "exploration/num paths total           276\n",
      "evaluation/num steps total              1.2092e+06\n",
      "evaluation/num paths total           1537\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65937\n",
      "evaluation/Rewards Std                  0.963412\n",
      "evaluation/Rewards Max                  6.75861\n",
      "evaluation/Rewards Min                 -1.73231\n",
      "evaluation/Returns Mean              4659.37\n",
      "evaluation/Returns Std                 96.6611\n",
      "evaluation/Returns Max               4853.57\n",
      "evaluation/Returns Min               4515.21\n",
      "evaluation/Estimation Bias Mean      1205.82\n",
      "evaluation/Estimation Bias Std        145.249\n",
      "evaluation/EB/Q_True Mean              44.7046\n",
      "evaluation/EB/Q_True Std              137.809\n",
      "evaluation/EB/Q_Pred Mean            1250.53\n",
      "evaluation/EB/Q_Pred Std               48.9435\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4659.37\n",
      "evaluation/Actions Mean                 0.0252341\n",
      "evaluation/Actions Std                  0.532379\n",
      "evaluation/Actions Max                  0.999461\n",
      "evaluation/Actions Min                 -0.999335\n",
      "time/backward_policy (s)                1.81736\n",
      "time/backward_zf1 (s)                   2.00952\n",
      "time/backward_zf2 (s)                   1.89202\n",
      "time/data sampling (s)                  0.334003\n",
      "time/data storing (s)                   0.0143461\n",
      "time/evaluation sampling (s)            1.76306\n",
      "time/exploration sampling (s)           0.321847\n",
      "time/logging (s)                        0.012432\n",
      "time/preback_alpha (s)                  0.601299\n",
      "time/preback_policy (s)                 1.04088\n",
      "time/preback_start (s)                  0.152912\n",
      "time/preback_zf (s)                     5.19171\n",
      "time/saving (s)                         0.00676209\n",
      "time/training (s)                       2.42648\n",
      "time/epoch (s)                         17.5846\n",
      "time/total (s)                       2587.88\n",
      "Epoch                                 147\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:19:39.832030 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 148 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 159000\n",
      "trainer/ZF1 Loss                      -10.381\n",
      "trainer/ZF2 Loss                      -10.3495\n",
      "trainer/ZF Expert Reward               13.7618\n",
      "trainer/ZF Policy Reward                1.12986\n",
      "trainer/ZF CHI2 Term                   33.9239\n",
      "trainer/Policy Loss                 -1095.83\n",
      "trainer/Bias Loss                      60.7402\n",
      "trainer/Bias Value                     13.6465\n",
      "trainer/Policy Grad Norm              112.289\n",
      "trainer/Policy Param Norm              35.4934\n",
      "trainer/Zf1 Grad Norm                1236.6\n",
      "trainer/Zf1 Param Norm                104.733\n",
      "trainer/Zf2 Grad Norm                1188.04\n",
      "trainer/Zf2 Param Norm                107.626\n",
      "trainer/Z Expert Predictions Mean    1252.1\n",
      "trainer/Z Expert Predictions Std       56.206\n",
      "trainer/Z Expert Predictions Max     1335.71\n",
      "trainer/Z Expert Predictions Min      913.122\n",
      "trainer/Z Policy Predictions Mean    1088.79\n",
      "trainer/Z Policy Predictions Std      365.312\n",
      "trainer/Z Policy Predictions Max     1312.48\n",
      "trainer/Z Policy Predictions Min     -485.373\n",
      "trainer/Z Expert Targets Mean        1238.34\n",
      "trainer/Z Expert Targets Std           58.3715\n",
      "trainer/Z Expert Targets Max         1317.25\n",
      "trainer/Z Expert Targets Min          901.835\n",
      "trainer/Z Policy Targets Mean        1087.66\n",
      "trainer/Z Policy Targets Std          359.849\n",
      "trainer/Z Policy Targets Max         1296.99\n",
      "trainer/Z Policy Targets Min         -475.211\n",
      "trainer/Log Pis Mean                   31.9769\n",
      "trainer/Log Pis Std                     8.03219\n",
      "trainer/Policy mu Mean                 -0.0289422\n",
      "trainer/Policy mu Std                   1.90983\n",
      "trainer/Policy log std Mean            -4.30461\n",
      "trainer/Policy log std Std              1.07268\n",
      "exploration/num steps total        154397\n",
      "exploration/num paths total           277\n",
      "evaluation/num steps total              1.2192e+06\n",
      "evaluation/num paths total           1547\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67717\n",
      "evaluation/Rewards Std                  1.01895\n",
      "evaluation/Rewards Max                  6.88499\n",
      "evaluation/Rewards Min                 -2.08582\n",
      "evaluation/Returns Mean              4677.17\n",
      "evaluation/Returns Std                 78.5646\n",
      "evaluation/Returns Max               4783.32\n",
      "evaluation/Returns Min               4526.4\n",
      "evaluation/Estimation Bias Mean      1193.75\n",
      "evaluation/Estimation Bias Std        142.156\n",
      "evaluation/EB/Q_True Mean              43.4533\n",
      "evaluation/EB/Q_True Std              133.874\n",
      "evaluation/EB/Q_Pred Mean            1237.21\n",
      "evaluation/EB/Q_Pred Std               53.0833\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4677.17\n",
      "evaluation/Actions Mean                 0.021848\n",
      "evaluation/Actions Std                  0.536436\n",
      "evaluation/Actions Max                  0.999685\n",
      "evaluation/Actions Min                 -0.999537\n",
      "time/backward_policy (s)                1.88789\n",
      "time/backward_zf1 (s)                   2.03711\n",
      "time/backward_zf2 (s)                   1.95884\n",
      "time/data sampling (s)                  0.330406\n",
      "time/data storing (s)                   0.0148232\n",
      "time/evaluation sampling (s)            1.80434\n",
      "time/exploration sampling (s)           0.327044\n",
      "time/logging (s)                        0.0121563\n",
      "time/preback_alpha (s)                  0.588921\n",
      "time/preback_policy (s)                 1.08463\n",
      "time/preback_start (s)                  0.151889\n",
      "time/preback_zf (s)                     5.12691\n",
      "time/saving (s)                         0.00911039\n",
      "time/training (s)                       2.29502\n",
      "time/epoch (s)                         17.6291\n",
      "time/total (s)                       2605.53\n",
      "Epoch                                 148\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:19:58.468848 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 149 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 160000\n",
      "trainer/ZF1 Loss                       -4.2318\n",
      "trainer/ZF2 Loss                      -10.3424\n",
      "trainer/ZF Expert Reward               10.2724\n",
      "trainer/ZF Policy Reward               -0.729935\n",
      "trainer/ZF CHI2 Term                   35.4617\n",
      "trainer/Policy Loss                 -1088.42\n",
      "trainer/Bias Loss                      83.1411\n",
      "trainer/Bias Value                     13.6583\n",
      "trainer/Policy Grad Norm              122.282\n",
      "trainer/Policy Param Norm              35.5363\n",
      "trainer/Zf1 Grad Norm                2116.5\n",
      "trainer/Zf1 Param Norm                104.94\n",
      "trainer/Zf2 Grad Norm                1489.33\n",
      "trainer/Zf2 Param Norm                107.826\n",
      "trainer/Z Expert Predictions Mean    1250.12\n",
      "trainer/Z Expert Predictions Std       94.1374\n",
      "trainer/Z Expert Predictions Max     1323.09\n",
      "trainer/Z Expert Predictions Min      -93.011\n",
      "trainer/Z Policy Predictions Mean    1079.27\n",
      "trainer/Z Policy Predictions Std      376.738\n",
      "trainer/Z Policy Predictions Max     1305.41\n",
      "trainer/Z Policy Predictions Min     -476.254\n",
      "trainer/Z Expert Targets Mean        1239.85\n",
      "trainer/Z Expert Targets Std           89.1835\n",
      "trainer/Z Expert Targets Max         1307.62\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1080\n",
      "trainer/Z Policy Targets Std          375.189\n",
      "trainer/Z Policy Targets Max         1312.72\n",
      "trainer/Z Policy Targets Min         -462.73\n",
      "trainer/Log Pis Mean                   32.0671\n",
      "trainer/Log Pis Std                     8.623\n",
      "trainer/Policy mu Mean                 -0.0811818\n",
      "trainer/Policy mu Std                   2.19827\n",
      "trainer/Policy log std Mean            -4.32741\n",
      "trainer/Policy log std Std              1.15695\n",
      "exploration/num steps total        154397\n",
      "exploration/num paths total           277\n",
      "evaluation/num steps total              1.2292e+06\n",
      "evaluation/num paths total           1557\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62566\n",
      "evaluation/Rewards Std                  1.17739\n",
      "evaluation/Rewards Max                  7.05049\n",
      "evaluation/Rewards Min                 -2.91236\n",
      "evaluation/Returns Mean              4625.66\n",
      "evaluation/Returns Std                188.845\n",
      "evaluation/Returns Max               4904.04\n",
      "evaluation/Returns Min               4133.61\n",
      "evaluation/Estimation Bias Mean      1194.47\n",
      "evaluation/Estimation Bias Std        146.782\n",
      "evaluation/EB/Q_True Mean              37.9725\n",
      "evaluation/EB/Q_True Std              119.828\n",
      "evaluation/EB/Q_Pred Mean            1232.44\n",
      "evaluation/EB/Q_Pred Std               84.3655\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4625.66\n",
      "evaluation/Actions Mean                 0.0210928\n",
      "evaluation/Actions Std                  0.536993\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.01342\n",
      "time/backward_zf1 (s)                   2.18168\n",
      "time/backward_zf2 (s)                   2.10074\n",
      "time/data sampling (s)                  0.343431\n",
      "time/data storing (s)                   0.0157242\n",
      "time/evaluation sampling (s)            1.76529\n",
      "time/exploration sampling (s)           0.340714\n",
      "time/logging (s)                        0.0119863\n",
      "time/preback_alpha (s)                  0.626572\n",
      "time/preback_policy (s)                 1.16487\n",
      "time/preback_start (s)                  0.159573\n",
      "time/preback_zf (s)                     5.30783\n",
      "time/saving (s)                         0.00637443\n",
      "time/training (s)                       2.52325\n",
      "time/epoch (s)                         18.5615\n",
      "time/total (s)                       2624.11\n",
      "Epoch                                 149\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:20:17.858113 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 150 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 161000\n",
      "trainer/ZF1 Loss                       12.1671\n",
      "trainer/ZF2 Loss                       10.6097\n",
      "trainer/ZF Expert Reward               14.7163\n",
      "trainer/ZF Policy Reward                5.98952\n",
      "trainer/ZF CHI2 Term                   51.5199\n",
      "trainer/Policy Loss                 -1091.07\n",
      "trainer/Bias Loss                      55.1882\n",
      "trainer/Bias Value                     13.7349\n",
      "trainer/Policy Grad Norm              104.886\n",
      "trainer/Policy Param Norm              35.5779\n",
      "trainer/Zf1 Grad Norm                1583.12\n",
      "trainer/Zf1 Param Norm                105.134\n",
      "trainer/Zf2 Grad Norm                1424.95\n",
      "trainer/Zf2 Param Norm                108.013\n",
      "trainer/Z Expert Predictions Mean    1259.71\n",
      "trainer/Z Expert Predictions Std       41.8036\n",
      "trainer/Z Expert Predictions Max     1342.1\n",
      "trainer/Z Expert Predictions Min      867.772\n",
      "trainer/Z Policy Predictions Mean    1085.05\n",
      "trainer/Z Policy Predictions Std      342.864\n",
      "trainer/Z Policy Predictions Max     1297.79\n",
      "trainer/Z Policy Predictions Min     -415.271\n",
      "trainer/Z Expert Targets Mean        1244.99\n",
      "trainer/Z Expert Targets Std           42.3097\n",
      "trainer/Z Expert Targets Max         1317.53\n",
      "trainer/Z Expert Targets Min          865.078\n",
      "trainer/Z Policy Targets Mean        1079.06\n",
      "trainer/Z Policy Targets Std          339.443\n",
      "trainer/Z Policy Targets Max         1302.29\n",
      "trainer/Z Policy Targets Min         -411.312\n",
      "trainer/Log Pis Mean                   31.7219\n",
      "trainer/Log Pis Std                     8.11997\n",
      "trainer/Policy mu Mean                 -0.0570207\n",
      "trainer/Policy mu Std                   1.8822\n",
      "trainer/Policy log std Mean            -4.34005\n",
      "trainer/Policy log std Std              1.02194\n",
      "exploration/num steps total        154397\n",
      "exploration/num paths total           277\n",
      "evaluation/num steps total              1.2392e+06\n",
      "evaluation/num paths total           1567\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69117\n",
      "evaluation/Rewards Std                  1.09429\n",
      "evaluation/Rewards Max                  7.05197\n",
      "evaluation/Rewards Min                 -2.70606\n",
      "evaluation/Returns Mean              4691.17\n",
      "evaluation/Returns Std                168.209\n",
      "evaluation/Returns Max               5003.7\n",
      "evaluation/Returns Min               4327.02\n",
      "evaluation/Estimation Bias Mean      1190.48\n",
      "evaluation/Estimation Bias Std        153.762\n",
      "evaluation/EB/Q_True Mean              45.7684\n",
      "evaluation/EB/Q_True Std              141.181\n",
      "evaluation/EB/Q_Pred Mean            1236.24\n",
      "evaluation/EB/Q_Pred Std               62.8547\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4691.17\n",
      "evaluation/Actions Mean                 0.019719\n",
      "evaluation/Actions Std                  0.528768\n",
      "evaluation/Actions Max                  0.999967\n",
      "evaluation/Actions Min                 -0.999927\n",
      "time/backward_policy (s)                2.21038\n",
      "time/backward_zf1 (s)                   2.4108\n",
      "time/backward_zf2 (s)                   2.30182\n",
      "time/data sampling (s)                  0.348899\n",
      "time/data storing (s)                   0.0172741\n",
      "time/evaluation sampling (s)            1.82439\n",
      "time/exploration sampling (s)           0.351261\n",
      "time/logging (s)                        0.0121847\n",
      "time/preback_alpha (s)                  0.64918\n",
      "time/preback_policy (s)                 1.28741\n",
      "time/preback_start (s)                  0.164184\n",
      "time/preback_zf (s)                     5.35081\n",
      "time/saving (s)                         0.00618084\n",
      "time/training (s)                       2.37894\n",
      "time/epoch (s)                         19.3137\n",
      "time/total (s)                       2643.45\n",
      "Epoch                                 150\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:20:36.543801 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 151 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 162000\n",
      "trainer/ZF1 Loss                        0.34861\n",
      "trainer/ZF2 Loss                       -4.75188\n",
      "trainer/ZF Expert Reward               14.8032\n",
      "trainer/ZF Policy Reward                6.3537\n",
      "trainer/ZF CHI2 Term                   37.6816\n",
      "trainer/Policy Loss                 -1095.75\n",
      "trainer/Bias Loss                      59.5788\n",
      "trainer/Bias Value                     13.7591\n",
      "trainer/Policy Grad Norm              122.315\n",
      "trainer/Policy Param Norm              35.6166\n",
      "trainer/Zf1 Grad Norm                1261.94\n",
      "trainer/Zf1 Param Norm                105.331\n",
      "trainer/Zf2 Grad Norm                1442.19\n",
      "trainer/Zf2 Param Norm                108.195\n",
      "trainer/Z Expert Predictions Mean    1244.98\n",
      "trainer/Z Expert Predictions Std      122.506\n",
      "trainer/Z Expert Predictions Max     1341.91\n",
      "trainer/Z Expert Predictions Min      -50.9674\n",
      "trainer/Z Policy Predictions Mean    1089.37\n",
      "trainer/Z Policy Predictions Std      367.306\n",
      "trainer/Z Policy Predictions Max     1334.17\n",
      "trainer/Z Policy Predictions Min     -473.25\n",
      "trainer/Z Expert Targets Mean        1230.17\n",
      "trainer/Z Expert Targets Std          120.85\n",
      "trainer/Z Expert Targets Max         1323.01\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1083.01\n",
      "trainer/Z Policy Targets Std          362.66\n",
      "trainer/Z Policy Targets Max         1301.85\n",
      "trainer/Z Policy Targets Min         -449.201\n",
      "trainer/Log Pis Mean                   31.7512\n",
      "trainer/Log Pis Std                     7.27272\n",
      "trainer/Policy mu Mean                  0.0140761\n",
      "trainer/Policy mu Std                   2.0506\n",
      "trainer/Policy log std Mean            -4.23451\n",
      "trainer/Policy log std Std              1.13154\n",
      "exploration/num steps total        156397\n",
      "exploration/num paths total           279\n",
      "evaluation/num steps total              1.24824e+06\n",
      "evaluation/num paths total           1577\n",
      "evaluation/path length Mean           904.7\n",
      "evaluation/path length Std            285.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             47\n",
      "evaluation/Rewards Mean                 4.5097\n",
      "evaluation/Rewards Std                  1.04357\n",
      "evaluation/Rewards Max                  6.78479\n",
      "evaluation/Rewards Min                 -1.85102\n",
      "evaluation/Returns Mean              4079.92\n",
      "evaluation/Returns Std               1326.16\n",
      "evaluation/Returns Max               4794.57\n",
      "evaluation/Returns Min                119.749\n",
      "evaluation/Estimation Bias Mean      1199.21\n",
      "evaluation/Estimation Bias Std        150.595\n",
      "evaluation/EB/Q_True Mean              46.6634\n",
      "evaluation/EB/Q_True Std              135.868\n",
      "evaluation/EB/Q_Pred Mean            1245.88\n",
      "evaluation/EB/Q_Pred Std               61.9711\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4079.92\n",
      "evaluation/Actions Mean                 0.0210022\n",
      "evaluation/Actions Std                  0.536397\n",
      "evaluation/Actions Max                  0.999915\n",
      "evaluation/Actions Min                 -0.999767\n",
      "time/backward_policy (s)                2.05718\n",
      "time/backward_zf1 (s)                   2.24319\n",
      "time/backward_zf2 (s)                   2.12811\n",
      "time/data sampling (s)                  0.343192\n",
      "time/data storing (s)                   0.01536\n",
      "time/evaluation sampling (s)            1.83398\n",
      "time/exploration sampling (s)           0.341199\n",
      "time/logging (s)                        0.0113673\n",
      "time/preback_alpha (s)                  0.624608\n",
      "time/preback_policy (s)                 1.19533\n",
      "time/preback_start (s)                  0.159861\n",
      "time/preback_zf (s)                     5.29687\n",
      "time/saving (s)                         0.00619905\n",
      "time/training (s)                       2.35117\n",
      "time/epoch (s)                         18.6076\n",
      "time/total (s)                       2662.08\n",
      "Epoch                                 151\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:20:55.230632 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 152 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 163000\n",
      "trainer/ZF1 Loss                       -1.0624\n",
      "trainer/ZF2 Loss                       -8.14479\n",
      "trainer/ZF Expert Reward               13.837\n",
      "trainer/ZF Policy Reward                2.89541\n",
      "trainer/ZF CHI2 Term                   38.1419\n",
      "trainer/Policy Loss                 -1108.97\n",
      "trainer/Bias Loss                      88.5325\n",
      "trainer/Bias Value                     13.8172\n",
      "trainer/Policy Grad Norm              136.229\n",
      "trainer/Policy Param Norm              35.6603\n",
      "trainer/Zf1 Grad Norm                1178.34\n",
      "trainer/Zf1 Param Norm                105.533\n",
      "trainer/Zf2 Grad Norm                1238.99\n",
      "trainer/Zf2 Param Norm                108.395\n",
      "trainer/Z Expert Predictions Mean    1249.4\n",
      "trainer/Z Expert Predictions Std       44.4479\n",
      "trainer/Z Expert Predictions Max     1324.73\n",
      "trainer/Z Expert Predictions Min      992.776\n",
      "trainer/Z Policy Predictions Mean    1099.72\n",
      "trainer/Z Policy Predictions Std      360.892\n",
      "trainer/Z Policy Predictions Max     1294.67\n",
      "trainer/Z Policy Predictions Min     -460.214\n",
      "trainer/Z Expert Targets Mean        1235.57\n",
      "trainer/Z Expert Targets Std           47.4966\n",
      "trainer/Z Expert Targets Max         1312.9\n",
      "trainer/Z Expert Targets Min          996.493\n",
      "trainer/Z Policy Targets Mean        1096.83\n",
      "trainer/Z Policy Targets Std          357.456\n",
      "trainer/Z Policy Targets Max         1295.93\n",
      "trainer/Z Policy Targets Min         -456.98\n",
      "trainer/Log Pis Mean                   32.1252\n",
      "trainer/Log Pis Std                     8.34112\n",
      "trainer/Policy mu Mean                 -0.0147225\n",
      "trainer/Policy mu Std                   1.86878\n",
      "trainer/Policy log std Mean            -4.37478\n",
      "trainer/Policy log std Std              1.01726\n",
      "exploration/num steps total        158397\n",
      "exploration/num paths total           281\n",
      "evaluation/num steps total              1.2576e+06\n",
      "evaluation/num paths total           1587\n",
      "evaluation/path length Mean           935.9\n",
      "evaluation/path length Std            192.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            359\n",
      "evaluation/Rewards Mean                 4.68698\n",
      "evaluation/Rewards Std                  1.00191\n",
      "evaluation/Rewards Max                  6.68991\n",
      "evaluation/Rewards Min                 -1.36813\n",
      "evaluation/Returns Mean              4386.54\n",
      "evaluation/Returns Std                928.385\n",
      "evaluation/Returns Max               4826.87\n",
      "evaluation/Returns Min               1613\n",
      "evaluation/Estimation Bias Mean      1193.2\n",
      "evaluation/Estimation Bias Std        146.766\n",
      "evaluation/EB/Q_True Mean              44.6563\n",
      "evaluation/EB/Q_True Std              132.286\n",
      "evaluation/EB/Q_Pred Mean            1237.86\n",
      "evaluation/EB/Q_Pred Std               57.7025\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4386.54\n",
      "evaluation/Actions Mean                 0.0187509\n",
      "evaluation/Actions Std                  0.530845\n",
      "evaluation/Actions Max                  0.999666\n",
      "evaluation/Actions Min                 -0.999497\n",
      "time/backward_policy (s)                2.05877\n",
      "time/backward_zf1 (s)                   2.26634\n",
      "time/backward_zf2 (s)                   2.14044\n",
      "time/data sampling (s)                  0.372671\n",
      "time/data storing (s)                   0.0161719\n",
      "time/evaluation sampling (s)            1.75561\n",
      "time/exploration sampling (s)           0.353973\n",
      "time/logging (s)                        0.0125756\n",
      "time/preback_alpha (s)                  0.637157\n",
      "time/preback_policy (s)                 1.21053\n",
      "time/preback_start (s)                  0.158781\n",
      "time/preback_zf (s)                     5.29146\n",
      "time/saving (s)                         0.00692381\n",
      "time/training (s)                       2.33239\n",
      "time/epoch (s)                         18.6138\n",
      "time/total (s)                       2680.71\n",
      "Epoch                                 152\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:21:14.271606 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 153 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 164000\n",
      "trainer/ZF1 Loss                        4.39609\n",
      "trainer/ZF2 Loss                        1.06271\n",
      "trainer/ZF Expert Reward               10.8647\n",
      "trainer/ZF Policy Reward               -0.0120758\n",
      "trainer/ZF CHI2 Term                   43.8532\n",
      "trainer/Policy Loss                 -1083.23\n",
      "trainer/Bias Loss                     103.322\n",
      "trainer/Bias Value                     13.8119\n",
      "trainer/Policy Grad Norm               95.8967\n",
      "trainer/Policy Param Norm              35.7026\n",
      "trainer/Zf1 Grad Norm                1562.76\n",
      "trainer/Zf1 Param Norm                105.751\n",
      "trainer/Zf2 Grad Norm                1323.53\n",
      "trainer/Zf2 Param Norm                108.6\n",
      "trainer/Z Expert Predictions Mean    1253.11\n",
      "trainer/Z Expert Predictions Std       36.954\n",
      "trainer/Z Expert Predictions Max     1323.02\n",
      "trainer/Z Expert Predictions Min     1027.11\n",
      "trainer/Z Policy Predictions Mean    1074.01\n",
      "trainer/Z Policy Predictions Std      362.201\n",
      "trainer/Z Policy Predictions Max     1317.59\n",
      "trainer/Z Policy Predictions Min     -462.229\n",
      "trainer/Z Expert Targets Mean        1242.25\n",
      "trainer/Z Expert Targets Std           38.4865\n",
      "trainer/Z Expert Targets Max         1307.48\n",
      "trainer/Z Expert Targets Min         1024.05\n",
      "trainer/Z Policy Targets Mean        1074.02\n",
      "trainer/Z Policy Targets Std          358.637\n",
      "trainer/Z Policy Targets Max         1298.98\n",
      "trainer/Z Policy Targets Min         -452.397\n",
      "trainer/Log Pis Mean                   30.5525\n",
      "trainer/Log Pis Std                     6.64764\n",
      "trainer/Policy mu Mean                 -0.0151551\n",
      "trainer/Policy mu Std                   1.6226\n",
      "trainer/Policy log std Mean            -4.26621\n",
      "trainer/Policy log std Std              1.10197\n",
      "exploration/num steps total        159397\n",
      "exploration/num paths total           282\n",
      "evaluation/num steps total              1.2676e+06\n",
      "evaluation/num paths total           1597\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.665\n",
      "evaluation/Rewards Std                  0.997675\n",
      "evaluation/Rewards Max                  6.73251\n",
      "evaluation/Rewards Min                 -2.54929\n",
      "evaluation/Returns Mean              4665\n",
      "evaluation/Returns Std                108.951\n",
      "evaluation/Returns Max               4874.33\n",
      "evaluation/Returns Min               4523.73\n",
      "evaluation/Estimation Bias Mean      1199.33\n",
      "evaluation/Estimation Bias Std        144.6\n",
      "evaluation/EB/Q_True Mean              42.2947\n",
      "evaluation/EB/Q_True Std              130.986\n",
      "evaluation/EB/Q_Pred Mean            1241.62\n",
      "evaluation/EB/Q_Pred Std               52.2749\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4665\n",
      "evaluation/Actions Mean                 0.0181886\n",
      "evaluation/Actions Std                  0.535191\n",
      "evaluation/Actions Max                  0.999839\n",
      "evaluation/Actions Min                 -0.999774\n",
      "time/backward_policy (s)                2.11982\n",
      "time/backward_zf1 (s)                   2.35071\n",
      "time/backward_zf2 (s)                   2.24337\n",
      "time/data sampling (s)                  0.377851\n",
      "time/data storing (s)                   0.0154354\n",
      "time/evaluation sampling (s)            1.75543\n",
      "time/exploration sampling (s)           0.339635\n",
      "time/logging (s)                        0.0132124\n",
      "time/preback_alpha (s)                  0.64135\n",
      "time/preback_policy (s)                 1.23003\n",
      "time/preback_start (s)                  0.15907\n",
      "time/preback_zf (s)                     5.31126\n",
      "time/saving (s)                         0.00782682\n",
      "time/training (s)                       2.40265\n",
      "time/epoch (s)                         18.9677\n",
      "time/total (s)                       2699.7\n",
      "Epoch                                 153\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:21:32.811341 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 154 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 165000\n",
      "trainer/ZF1 Loss                      262.198\n",
      "trainer/ZF2 Loss                      243.828\n",
      "trainer/ZF Expert Reward               12.4905\n",
      "trainer/ZF Policy Reward                4.47398\n",
      "trainer/ZF CHI2 Term                  291.843\n",
      "trainer/Policy Loss                 -1102.28\n",
      "trainer/Bias Loss                      60.4738\n",
      "trainer/Bias Value                     13.8343\n",
      "trainer/Policy Grad Norm              118.613\n",
      "trainer/Policy Param Norm              35.7452\n",
      "trainer/Zf1 Grad Norm                1578.29\n",
      "trainer/Zf1 Param Norm                105.952\n",
      "trainer/Zf2 Grad Norm                2622.89\n",
      "trainer/Zf2 Param Norm                108.803\n",
      "trainer/Z Expert Predictions Mean    1245.96\n",
      "trainer/Z Expert Predictions Std       89.3396\n",
      "trainer/Z Expert Predictions Max     1326.19\n",
      "trainer/Z Expert Predictions Min       -4.11501\n",
      "trainer/Z Policy Predictions Mean    1097.9\n",
      "trainer/Z Policy Predictions Std      335.096\n",
      "trainer/Z Policy Predictions Max     1305.49\n",
      "trainer/Z Policy Predictions Min     -441.132\n",
      "trainer/Z Expert Targets Mean        1233.47\n",
      "trainer/Z Expert Targets Std           89.6378\n",
      "trainer/Z Expert Targets Max         1320.99\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1093.43\n",
      "trainer/Z Policy Targets Std          337.566\n",
      "trainer/Z Policy Targets Max         1290.62\n",
      "trainer/Z Policy Targets Min         -442.526\n",
      "trainer/Log Pis Mean                   31.1248\n",
      "trainer/Log Pis Std                     7.9821\n",
      "trainer/Policy mu Mean                 -0.00830784\n",
      "trainer/Policy mu Std                   2.16755\n",
      "trainer/Policy log std Mean            -4.28974\n",
      "trainer/Policy log std Std              1.16594\n",
      "exploration/num steps total        160397\n",
      "exploration/num paths total           283\n",
      "evaluation/num steps total              1.27418e+06\n",
      "evaluation/num paths total           1607\n",
      "evaluation/path length Mean           657.5\n",
      "evaluation/path length Std            350.744\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             28\n",
      "evaluation/Rewards Mean                 4.50775\n",
      "evaluation/Rewards Std                  1.14374\n",
      "evaluation/Rewards Max                  6.50427\n",
      "evaluation/Rewards Min                 -2.00762\n",
      "evaluation/Returns Mean              2963.85\n",
      "evaluation/Returns Std               1628.76\n",
      "evaluation/Returns Max               4668.58\n",
      "evaluation/Returns Min                 36.0943\n",
      "evaluation/Estimation Bias Mean      1155.05\n",
      "evaluation/Estimation Bias Std        172.297\n",
      "evaluation/EB/Q_True Mean              60.4904\n",
      "evaluation/EB/Q_True Std              148.536\n",
      "evaluation/EB/Q_Pred Mean            1215.54\n",
      "evaluation/EB/Q_Pred Std               69.0186\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2963.85\n",
      "evaluation/Actions Mean                 0.0257676\n",
      "evaluation/Actions Std                  0.523325\n",
      "evaluation/Actions Max                  0.999833\n",
      "evaluation/Actions Min                 -0.999669\n",
      "time/backward_policy (s)                2.04628\n",
      "time/backward_zf1 (s)                   2.26119\n",
      "time/backward_zf2 (s)                   2.13179\n",
      "time/data sampling (s)                  0.363556\n",
      "time/data storing (s)                   0.0165447\n",
      "time/evaluation sampling (s)            1.78693\n",
      "time/exploration sampling (s)           0.336757\n",
      "time/logging (s)                        0.00872629\n",
      "time/preback_alpha (s)                  0.616723\n",
      "time/preback_policy (s)                 1.1684\n",
      "time/preback_start (s)                  0.158619\n",
      "time/preback_zf (s)                     5.23858\n",
      "time/saving (s)                         0.00634188\n",
      "time/training (s)                       2.31986\n",
      "time/epoch (s)                         18.4603\n",
      "time/total (s)                       2718.18\n",
      "Epoch                                 154\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:21:52.483440 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 155 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 166000\n",
      "trainer/ZF1 Loss                        8.77111\n",
      "trainer/ZF2 Loss                       -3.93933\n",
      "trainer/ZF Expert Reward               11.9541\n",
      "trainer/ZF Policy Reward                2.98678\n",
      "trainer/ZF CHI2 Term                   43.5922\n",
      "trainer/Policy Loss                 -1042.25\n",
      "trainer/Bias Loss                     109.476\n",
      "trainer/Bias Value                     13.8374\n",
      "trainer/Policy Grad Norm              105.209\n",
      "trainer/Policy Param Norm              35.7863\n",
      "trainer/Zf1 Grad Norm                3180.94\n",
      "trainer/Zf1 Param Norm                106.161\n",
      "trainer/Zf2 Grad Norm                2175.63\n",
      "trainer/Zf2 Param Norm                109.016\n",
      "trainer/Z Expert Predictions Mean    1248.17\n",
      "trainer/Z Expert Predictions Std       67.1064\n",
      "trainer/Z Expert Predictions Max     1330.75\n",
      "trainer/Z Expert Predictions Min      386.553\n",
      "trainer/Z Policy Predictions Mean    1036.5\n",
      "trainer/Z Policy Predictions Std      430.491\n",
      "trainer/Z Policy Predictions Max     1325.75\n",
      "trainer/Z Policy Predictions Min     -441.172\n",
      "trainer/Z Expert Targets Mean        1236.21\n",
      "trainer/Z Expert Targets Std           74.4148\n",
      "trainer/Z Expert Targets Max         1313.43\n",
      "trainer/Z Expert Targets Min          251.868\n",
      "trainer/Z Policy Targets Mean        1033.51\n",
      "trainer/Z Policy Targets Std          424.818\n",
      "trainer/Z Policy Targets Max         1310.68\n",
      "trainer/Z Policy Targets Min         -412.602\n",
      "trainer/Log Pis Mean                   32.5343\n",
      "trainer/Log Pis Std                     8.70189\n",
      "trainer/Policy mu Mean                 -0.0533838\n",
      "trainer/Policy mu Std                   2.29516\n",
      "trainer/Policy log std Mean            -4.21398\n",
      "trainer/Policy log std Std              1.27482\n",
      "exploration/num steps total        161397\n",
      "exploration/num paths total           284\n",
      "evaluation/num steps total              1.28368e+06\n",
      "evaluation/num paths total           1617\n",
      "evaluation/path length Mean           950.1\n",
      "evaluation/path length Std            149.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            501\n",
      "evaluation/Rewards Mean                 4.5444\n",
      "evaluation/Rewards Std                  1.08466\n",
      "evaluation/Rewards Max                  6.94016\n",
      "evaluation/Rewards Min                 -2.00265\n",
      "evaluation/Returns Mean              4317.64\n",
      "evaluation/Returns Std                694.178\n",
      "evaluation/Returns Max               4666.26\n",
      "evaluation/Returns Min               2250.27\n",
      "evaluation/Estimation Bias Mean      1188\n",
      "evaluation/Estimation Bias Std        152.101\n",
      "evaluation/EB/Q_True Mean              43.011\n",
      "evaluation/EB/Q_True Std              129.304\n",
      "evaluation/EB/Q_Pred Mean            1231.02\n",
      "evaluation/EB/Q_Pred Std               71.0227\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4317.64\n",
      "evaluation/Actions Mean                 0.00855617\n",
      "evaluation/Actions Std                  0.534228\n",
      "evaluation/Actions Max                  0.999467\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                2.2175\n",
      "time/backward_zf1 (s)                   2.46872\n",
      "time/backward_zf2 (s)                   2.34931\n",
      "time/data sampling (s)                  0.371905\n",
      "time/data storing (s)                   0.0167592\n",
      "time/evaluation sampling (s)            1.77021\n",
      "time/exploration sampling (s)           0.349097\n",
      "time/logging (s)                        0.0124146\n",
      "time/preback_alpha (s)                  0.667841\n",
      "time/preback_policy (s)                 1.28617\n",
      "time/preback_start (s)                  0.163728\n",
      "time/preback_zf (s)                     5.46661\n",
      "time/saving (s)                         0.00644801\n",
      "time/training (s)                       2.4442\n",
      "time/epoch (s)                         19.5909\n",
      "time/total (s)                       2737.8\n",
      "Epoch                                 155\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:22:11.607994 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 156 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 167000\n",
      "trainer/ZF1 Loss                        1.25029\n",
      "trainer/ZF2 Loss                       11.744\n",
      "trainer/ZF Expert Reward               13.5861\n",
      "trainer/ZF Policy Reward               -0.747084\n",
      "trainer/ZF CHI2 Term                   51.9115\n",
      "trainer/Policy Loss                 -1108.94\n",
      "trainer/Bias Loss                      82.6006\n",
      "trainer/Bias Value                     13.8629\n",
      "trainer/Policy Grad Norm              150.037\n",
      "trainer/Policy Param Norm              35.8275\n",
      "trainer/Zf1 Grad Norm                1918.04\n",
      "trainer/Zf1 Param Norm                106.362\n",
      "trainer/Zf2 Grad Norm                2446.98\n",
      "trainer/Zf2 Param Norm                109.21\n",
      "trainer/Z Expert Predictions Mean    1249.57\n",
      "trainer/Z Expert Predictions Std       45.1954\n",
      "trainer/Z Expert Predictions Max     1325.75\n",
      "trainer/Z Expert Predictions Min      957.318\n",
      "trainer/Z Policy Predictions Mean    1101.02\n",
      "trainer/Z Policy Predictions Std      310.147\n",
      "trainer/Z Policy Predictions Max     1313.35\n",
      "trainer/Z Policy Predictions Min     -437.25\n",
      "trainer/Z Expert Targets Mean        1235.98\n",
      "trainer/Z Expert Targets Std           45.0882\n",
      "trainer/Z Expert Targets Max         1314.33\n",
      "trainer/Z Expert Targets Min          929.871\n",
      "trainer/Z Policy Targets Mean        1101.77\n",
      "trainer/Z Policy Targets Std          305.859\n",
      "trainer/Z Policy Targets Max         1298.64\n",
      "trainer/Z Policy Targets Min         -433.878\n",
      "trainer/Log Pis Mean                   31.3951\n",
      "trainer/Log Pis Std                     8.11821\n",
      "trainer/Policy mu Mean                 -0.0250249\n",
      "trainer/Policy mu Std                   1.89199\n",
      "trainer/Policy log std Mean            -4.30301\n",
      "trainer/Policy log std Std              1.05454\n",
      "exploration/num steps total        162397\n",
      "exploration/num paths total           285\n",
      "evaluation/num steps total              1.29298e+06\n",
      "evaluation/num paths total           1627\n",
      "evaluation/path length Mean           930.7\n",
      "evaluation/path length Std            207.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            307\n",
      "evaluation/Rewards Mean                 4.68386\n",
      "evaluation/Rewards Std                  0.985517\n",
      "evaluation/Rewards Max                  6.84427\n",
      "evaluation/Rewards Min                 -1.78631\n",
      "evaluation/Returns Mean              4359.27\n",
      "evaluation/Returns Std               1027.97\n",
      "evaluation/Returns Max               4808.58\n",
      "evaluation/Returns Min               1279.82\n",
      "evaluation/Estimation Bias Mean      1195.62\n",
      "evaluation/Estimation Bias Std        156.221\n",
      "evaluation/EB/Q_True Mean              47.3535\n",
      "evaluation/EB/Q_True Std              140.134\n",
      "evaluation/EB/Q_Pred Mean            1242.97\n",
      "evaluation/EB/Q_Pred Std               54.8104\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4359.27\n",
      "evaluation/Actions Mean                 0.0201596\n",
      "evaluation/Actions Std                  0.533052\n",
      "evaluation/Actions Max                  0.99964\n",
      "evaluation/Actions Min                 -0.999733\n",
      "time/backward_policy (s)                2.07415\n",
      "time/backward_zf1 (s)                   2.28196\n",
      "time/backward_zf2 (s)                   2.18949\n",
      "time/data sampling (s)                  0.3747\n",
      "time/data storing (s)                   0.0170395\n",
      "time/evaluation sampling (s)            1.75227\n",
      "time/exploration sampling (s)           0.346962\n",
      "time/logging (s)                        0.0118112\n",
      "time/preback_alpha (s)                  0.648772\n",
      "time/preback_policy (s)                 1.17567\n",
      "time/preback_start (s)                  0.160358\n",
      "time/preback_zf (s)                     5.38996\n",
      "time/saving (s)                         0.00657198\n",
      "time/training (s)                       2.61813\n",
      "time/epoch (s)                         19.0478\n",
      "time/total (s)                       2756.87\n",
      "Epoch                                 156\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:22:30.911415 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 157 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 168000\n",
      "trainer/ZF1 Loss                       -6.03748\n",
      "trainer/ZF2 Loss                       -2.82042\n",
      "trainer/ZF Expert Reward               11.6911\n",
      "trainer/ZF Policy Reward                0.0992545\n",
      "trainer/ZF CHI2 Term                   38.6265\n",
      "trainer/Policy Loss                 -1118.06\n",
      "trainer/Bias Loss                      63.3379\n",
      "trainer/Bias Value                     13.9208\n",
      "trainer/Policy Grad Norm              109.934\n",
      "trainer/Policy Param Norm              35.8757\n",
      "trainer/Zf1 Grad Norm                2386.19\n",
      "trainer/Zf1 Param Norm                106.563\n",
      "trainer/Zf2 Grad Norm                1784.26\n",
      "trainer/Zf2 Param Norm                109.397\n",
      "trainer/Z Expert Predictions Mean    1242.64\n",
      "trainer/Z Expert Predictions Std       46.5179\n",
      "trainer/Z Expert Predictions Max     1335.28\n",
      "trainer/Z Expert Predictions Min      945.556\n",
      "trainer/Z Policy Predictions Mean    1108.27\n",
      "trainer/Z Policy Predictions Std      303.803\n",
      "trainer/Z Policy Predictions Max     1312.47\n",
      "trainer/Z Policy Predictions Min     -312.493\n",
      "trainer/Z Expert Targets Mean        1230.95\n",
      "trainer/Z Expert Targets Std           49.0578\n",
      "trainer/Z Expert Targets Max         1318.54\n",
      "trainer/Z Expert Targets Min          918.074\n",
      "trainer/Z Policy Targets Mean        1108.18\n",
      "trainer/Z Policy Targets Std          299.578\n",
      "trainer/Z Policy Targets Max         1298.74\n",
      "trainer/Z Policy Targets Min         -304.105\n",
      "trainer/Log Pis Mean                   31.7814\n",
      "trainer/Log Pis Std                     8.99847\n",
      "trainer/Policy mu Mean                  0.00418459\n",
      "trainer/Policy mu Std                   2.03907\n",
      "trainer/Policy log std Mean            -4.43372\n",
      "trainer/Policy log std Std              1.03247\n",
      "exploration/num steps total        163397\n",
      "exploration/num paths total           286\n",
      "evaluation/num steps total              1.30298e+06\n",
      "evaluation/num paths total           1637\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66103\n",
      "evaluation/Rewards Std                  1.0207\n",
      "evaluation/Rewards Max                  6.71695\n",
      "evaluation/Rewards Min                 -2.1154\n",
      "evaluation/Returns Mean              4661.03\n",
      "evaluation/Returns Std                 91.2059\n",
      "evaluation/Returns Max               4767.42\n",
      "evaluation/Returns Min               4493.38\n",
      "evaluation/Estimation Bias Mean      1195.67\n",
      "evaluation/Estimation Bias Std        139.232\n",
      "evaluation/EB/Q_True Mean              42.6662\n",
      "evaluation/EB/Q_True Std              131.378\n",
      "evaluation/EB/Q_Pred Mean            1238.34\n",
      "evaluation/EB/Q_Pred Std               54.9283\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4661.03\n",
      "evaluation/Actions Mean                 0.0239574\n",
      "evaluation/Actions Std                  0.544927\n",
      "evaluation/Actions Max                  0.999807\n",
      "evaluation/Actions Min                 -0.999755\n",
      "time/backward_policy (s)                2.13448\n",
      "time/backward_zf1 (s)                   2.29638\n",
      "time/backward_zf2 (s)                   2.1735\n",
      "time/data sampling (s)                  0.397425\n",
      "time/data storing (s)                   0.0190643\n",
      "time/evaluation sampling (s)            1.80444\n",
      "time/exploration sampling (s)           0.371963\n",
      "time/logging (s)                        0.0134945\n",
      "time/preback_alpha (s)                  0.656292\n",
      "time/preback_policy (s)                 1.23239\n",
      "time/preback_start (s)                  0.166147\n",
      "time/preback_zf (s)                     5.39332\n",
      "time/saving (s)                         0.0111133\n",
      "time/training (s)                       2.55889\n",
      "time/epoch (s)                         19.2289\n",
      "time/total (s)                       2776.12\n",
      "Epoch                                 157\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:22:48.456624 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 158 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 169000\n",
      "trainer/ZF1 Loss                       -1.68065\n",
      "trainer/ZF2 Loss                        1.83879\n",
      "trainer/ZF Expert Reward               14.2515\n",
      "trainer/ZF Policy Reward                3.87786\n",
      "trainer/ZF CHI2 Term                   41.9616\n",
      "trainer/Policy Loss                 -1096.27\n",
      "trainer/Bias Loss                      51.8528\n",
      "trainer/Bias Value                     13.9396\n",
      "trainer/Policy Grad Norm              110.479\n",
      "trainer/Policy Param Norm              35.919\n",
      "trainer/Zf1 Grad Norm                1609.29\n",
      "trainer/Zf1 Param Norm                106.763\n",
      "trainer/Zf2 Grad Norm                1432.82\n",
      "trainer/Zf2 Param Norm                109.606\n",
      "trainer/Z Expert Predictions Mean    1243.32\n",
      "trainer/Z Expert Predictions Std       50.0191\n",
      "trainer/Z Expert Predictions Max     1329.28\n",
      "trainer/Z Expert Predictions Min     1007.26\n",
      "trainer/Z Policy Predictions Mean    1088.41\n",
      "trainer/Z Policy Predictions Std      353.964\n",
      "trainer/Z Policy Predictions Max     1298.21\n",
      "trainer/Z Policy Predictions Min     -445.684\n",
      "trainer/Z Expert Targets Mean        1229.07\n",
      "trainer/Z Expert Targets Std           50.9279\n",
      "trainer/Z Expert Targets Max         1327.33\n",
      "trainer/Z Expert Targets Min          995.053\n",
      "trainer/Z Policy Targets Mean        1084.53\n",
      "trainer/Z Policy Targets Std          348.955\n",
      "trainer/Z Policy Targets Max         1287.12\n",
      "trainer/Z Policy Targets Min         -425.852\n",
      "trainer/Log Pis Mean                   31.8271\n",
      "trainer/Log Pis Std                     7.91521\n",
      "trainer/Policy mu Mean                 -0.0139852\n",
      "trainer/Policy mu Std                   1.74011\n",
      "trainer/Policy log std Mean            -4.416\n",
      "trainer/Policy log std Std              1.08507\n",
      "exploration/num steps total        164694\n",
      "exploration/num paths total           288\n",
      "evaluation/num steps total              1.31074e+06\n",
      "evaluation/num paths total           1647\n",
      "evaluation/path length Mean           775.9\n",
      "evaluation/path length Std            375.926\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             43\n",
      "evaluation/Rewards Mean                 4.18443\n",
      "evaluation/Rewards Std                  2.08044\n",
      "evaluation/Rewards Max                  6.73991\n",
      "evaluation/Rewards Min                 -3.21919\n",
      "evaluation/Returns Mean              3246.7\n",
      "evaluation/Returns Std               1947.26\n",
      "evaluation/Returns Max               4816.24\n",
      "evaluation/Returns Min                 74.8768\n",
      "evaluation/Estimation Bias Mean      1078.49\n",
      "evaluation/Estimation Bias Std        391.494\n",
      "evaluation/EB/Q_True Mean              54.6979\n",
      "evaluation/EB/Q_True Std              146.887\n",
      "evaluation/EB/Q_Pred Mean            1133.19\n",
      "evaluation/EB/Q_Pred Std              373.458\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3246.7\n",
      "evaluation/Actions Mean                -0.00891736\n",
      "evaluation/Actions Std                  0.574703\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8002\n",
      "time/backward_zf1 (s)                   1.96064\n",
      "time/backward_zf2 (s)                   1.84924\n",
      "time/data sampling (s)                  0.332132\n",
      "time/data storing (s)                   0.01596\n",
      "time/evaluation sampling (s)            1.79919\n",
      "time/exploration sampling (s)           0.337629\n",
      "time/logging (s)                        0.00955095\n",
      "time/preback_alpha (s)                  0.60129\n",
      "time/preback_policy (s)                 1.01625\n",
      "time/preback_start (s)                  0.153171\n",
      "time/preback_zf (s)                     5.15447\n",
      "time/saving (s)                         0.00585363\n",
      "time/training (s)                       2.43091\n",
      "time/epoch (s)                         17.4665\n",
      "time/total (s)                       2793.61\n",
      "Epoch                                 158\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:23:06.423540 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 159 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 170000\n",
      "trainer/ZF1 Loss                        3.95958\n",
      "trainer/ZF2 Loss                        6.33453\n",
      "trainer/ZF Expert Reward               18.3381\n",
      "trainer/ZF Policy Reward                7.57839\n",
      "trainer/ZF CHI2 Term                   47.5046\n",
      "trainer/Policy Loss                 -1113.55\n",
      "trainer/Bias Loss                      96.2661\n",
      "trainer/Bias Value                     13.9787\n",
      "trainer/Policy Grad Norm              135.62\n",
      "trainer/Policy Param Norm              35.9644\n",
      "trainer/Zf1 Grad Norm                1522.75\n",
      "trainer/Zf1 Param Norm                106.959\n",
      "trainer/Zf2 Grad Norm                1493.73\n",
      "trainer/Zf2 Param Norm                109.797\n",
      "trainer/Z Expert Predictions Mean    1248.82\n",
      "trainer/Z Expert Predictions Std       43.5764\n",
      "trainer/Z Expert Predictions Max     1327.3\n",
      "trainer/Z Expert Predictions Min     1001.29\n",
      "trainer/Z Policy Predictions Mean    1109.13\n",
      "trainer/Z Policy Predictions Std      331.243\n",
      "trainer/Z Policy Predictions Max     1311.75\n",
      "trainer/Z Policy Predictions Min     -427.959\n",
      "trainer/Z Expert Targets Mean        1230.48\n",
      "trainer/Z Expert Targets Std           44.2859\n",
      "trainer/Z Expert Targets Max         1305.58\n",
      "trainer/Z Expert Targets Min          982.965\n",
      "trainer/Z Policy Targets Mean        1101.55\n",
      "trainer/Z Policy Targets Std          326.747\n",
      "trainer/Z Policy Targets Max         1300.51\n",
      "trainer/Z Policy Targets Min         -426.075\n",
      "trainer/Log Pis Mean                   31.917\n",
      "trainer/Log Pis Std                     9.05997\n",
      "trainer/Policy mu Mean                 -0.0135976\n",
      "trainer/Policy mu Std                   1.79751\n",
      "trainer/Policy log std Mean            -4.39116\n",
      "trainer/Policy log std Std              1.05319\n",
      "exploration/num steps total        164694\n",
      "exploration/num paths total           288\n",
      "evaluation/num steps total              1.32074e+06\n",
      "evaluation/num paths total           1657\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64593\n",
      "evaluation/Rewards Std                  1.03323\n",
      "evaluation/Rewards Max                  6.69739\n",
      "evaluation/Rewards Min                 -2.51752\n",
      "evaluation/Returns Mean              4645.93\n",
      "evaluation/Returns Std                107.678\n",
      "evaluation/Returns Max               4795.61\n",
      "evaluation/Returns Min               4404.82\n",
      "evaluation/Estimation Bias Mean      1190.4\n",
      "evaluation/Estimation Bias Std        151.623\n",
      "evaluation/EB/Q_True Mean              44.1535\n",
      "evaluation/EB/Q_True Std              135.85\n",
      "evaluation/EB/Q_Pred Mean            1234.55\n",
      "evaluation/EB/Q_Pred Std               54.049\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4645.93\n",
      "evaluation/Actions Mean                 0.021216\n",
      "evaluation/Actions Std                  0.543184\n",
      "evaluation/Actions Max                  0.999843\n",
      "evaluation/Actions Min                 -0.999892\n",
      "time/backward_policy (s)                2.00575\n",
      "time/backward_zf1 (s)                   2.11958\n",
      "time/backward_zf2 (s)                   2.05722\n",
      "time/data sampling (s)                  0.32566\n",
      "time/data storing (s)                   0.0156279\n",
      "time/evaluation sampling (s)            1.73463\n",
      "time/exploration sampling (s)           0.336832\n",
      "time/logging (s)                        0.0124694\n",
      "time/preback_alpha (s)                  0.584476\n",
      "time/preback_policy (s)                 1.16601\n",
      "time/preback_start (s)                  0.149802\n",
      "time/preback_zf (s)                     5.15656\n",
      "time/saving (s)                         0.018398\n",
      "time/training (s)                       2.21964\n",
      "time/epoch (s)                         17.9027\n",
      "time/total (s)                       2811.53\n",
      "Epoch                                 159\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:23:24.078828 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 160 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 171000\n",
      "trainer/ZF1 Loss                        2.68226\n",
      "trainer/ZF2 Loss                        2.88521\n",
      "trainer/ZF Expert Reward               13.3979\n",
      "trainer/ZF Policy Reward                3.99149\n",
      "trainer/ZF CHI2 Term                   44.009\n",
      "trainer/Policy Loss                 -1083.38\n",
      "trainer/Bias Loss                      80.6759\n",
      "trainer/Bias Value                     13.9523\n",
      "trainer/Policy Grad Norm               95.3273\n",
      "trainer/Policy Param Norm              36.0039\n",
      "trainer/Zf1 Grad Norm                 938.045\n",
      "trainer/Zf1 Param Norm                107.172\n",
      "trainer/Zf2 Grad Norm                1098.26\n",
      "trainer/Zf2 Param Norm                110.007\n",
      "trainer/Z Expert Predictions Mean    1245.52\n",
      "trainer/Z Expert Predictions Std       47.7058\n",
      "trainer/Z Expert Predictions Max     1328.31\n",
      "trainer/Z Expert Predictions Min     1011.23\n",
      "trainer/Z Policy Predictions Mean    1079.25\n",
      "trainer/Z Policy Predictions Std      352.462\n",
      "trainer/Z Policy Predictions Max     1294.63\n",
      "trainer/Z Policy Predictions Min     -403.283\n",
      "trainer/Z Expert Targets Mean        1232.12\n",
      "trainer/Z Expert Targets Std           49.9883\n",
      "trainer/Z Expert Targets Max         1311.68\n",
      "trainer/Z Expert Targets Min         1004.24\n",
      "trainer/Z Policy Targets Mean        1075.26\n",
      "trainer/Z Policy Targets Std          346.483\n",
      "trainer/Z Policy Targets Max         1288.06\n",
      "trainer/Z Policy Targets Min         -391.48\n",
      "trainer/Log Pis Mean                   32.1403\n",
      "trainer/Log Pis Std                     7.73717\n",
      "trainer/Policy mu Mean                  0.0101913\n",
      "trainer/Policy mu Std                   1.86984\n",
      "trainer/Policy log std Mean            -4.34996\n",
      "trainer/Policy log std Std              1.12291\n",
      "exploration/num steps total        164694\n",
      "exploration/num paths total           288\n",
      "evaluation/num steps total              1.33074e+06\n",
      "evaluation/num paths total           1667\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7079\n",
      "evaluation/Rewards Std                  1.02653\n",
      "evaluation/Rewards Max                  6.78138\n",
      "evaluation/Rewards Min                 -1.48524\n",
      "evaluation/Returns Mean              4707.9\n",
      "evaluation/Returns Std                121.615\n",
      "evaluation/Returns Max               4883.36\n",
      "evaluation/Returns Min               4416.65\n",
      "evaluation/Estimation Bias Mean      1195\n",
      "evaluation/Estimation Bias Std        142.94\n",
      "evaluation/EB/Q_True Mean              43.216\n",
      "evaluation/EB/Q_True Std              132.919\n",
      "evaluation/EB/Q_Pred Mean            1238.21\n",
      "evaluation/EB/Q_Pred Std               55.9607\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4707.9\n",
      "evaluation/Actions Mean                 0.021592\n",
      "evaluation/Actions Std                  0.534084\n",
      "evaluation/Actions Max                  0.999752\n",
      "evaluation/Actions Min                 -0.999274\n",
      "time/backward_policy (s)                1.92313\n",
      "time/backward_zf1 (s)                   2.0469\n",
      "time/backward_zf2 (s)                   1.99589\n",
      "time/data sampling (s)                  0.29855\n",
      "time/data storing (s)                   0.0140996\n",
      "time/evaluation sampling (s)            1.75417\n",
      "time/exploration sampling (s)           0.313544\n",
      "time/logging (s)                        0.0116201\n",
      "time/preback_alpha (s)                  0.575951\n",
      "time/preback_policy (s)                 1.11725\n",
      "time/preback_start (s)                  0.146324\n",
      "time/preback_zf (s)                     5.12764\n",
      "time/saving (s)                         0.00584496\n",
      "time/training (s)                       2.25159\n",
      "time/epoch (s)                         17.5825\n",
      "time/total (s)                       2829.13\n",
      "Epoch                                 160\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:23:42.193534 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 161 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 172000\n",
      "trainer/ZF1 Loss                       -8.36959\n",
      "trainer/ZF2 Loss                        4.43644\n",
      "trainer/ZF Expert Reward               17.5689\n",
      "trainer/ZF Policy Reward                8.1275\n",
      "trainer/ZF CHI2 Term                   38.356\n",
      "trainer/Policy Loss                 -1115.11\n",
      "trainer/Bias Loss                      70.7592\n",
      "trainer/Bias Value                     13.9561\n",
      "trainer/Policy Grad Norm              114.407\n",
      "trainer/Policy Param Norm              36.0403\n",
      "trainer/Zf1 Grad Norm                 937.288\n",
      "trainer/Zf1 Param Norm                107.353\n",
      "trainer/Zf2 Grad Norm                1743.79\n",
      "trainer/Zf2 Param Norm                110.186\n",
      "trainer/Z Expert Predictions Mean    1247.9\n",
      "trainer/Z Expert Predictions Std       49.8125\n",
      "trainer/Z Expert Predictions Max     1328.7\n",
      "trainer/Z Expert Predictions Min      998.781\n",
      "trainer/Z Policy Predictions Mean    1107.53\n",
      "trainer/Z Policy Predictions Std      334.842\n",
      "trainer/Z Policy Predictions Max     1319.88\n",
      "trainer/Z Policy Predictions Min     -434.398\n",
      "trainer/Z Expert Targets Mean        1230.33\n",
      "trainer/Z Expert Targets Std           48.4339\n",
      "trainer/Z Expert Targets Max         1317.91\n",
      "trainer/Z Expert Targets Min         1002.84\n",
      "trainer/Z Policy Targets Mean        1099.4\n",
      "trainer/Z Policy Targets Std          329.997\n",
      "trainer/Z Policy Targets Max         1299.29\n",
      "trainer/Z Policy Targets Min         -426.711\n",
      "trainer/Log Pis Mean                   31.193\n",
      "trainer/Log Pis Std                     6.62463\n",
      "trainer/Policy mu Mean                  0.00409135\n",
      "trainer/Policy mu Std                   1.69963\n",
      "trainer/Policy log std Mean            -4.41274\n",
      "trainer/Policy log std Std              1.09101\n",
      "exploration/num steps total        167033\n",
      "exploration/num paths total           291\n",
      "evaluation/num steps total              1.33917e+06\n",
      "evaluation/num paths total           1677\n",
      "evaluation/path length Mean           842.9\n",
      "evaluation/path length Std            325.545\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             24\n",
      "evaluation/Rewards Mean                 4.57053\n",
      "evaluation/Rewards Std                  1.05805\n",
      "evaluation/Rewards Max                  6.69744\n",
      "evaluation/Rewards Min                 -1.5273\n",
      "evaluation/Returns Mean              3852.5\n",
      "evaluation/Returns Std               1533.92\n",
      "evaluation/Returns Max               4747\n",
      "evaluation/Returns Min                 29.6439\n",
      "evaluation/Estimation Bias Mean      1165.33\n",
      "evaluation/Estimation Bias Std        155.217\n",
      "evaluation/EB/Q_True Mean              50.5019\n",
      "evaluation/EB/Q_True Std              141.234\n",
      "evaluation/EB/Q_Pred Mean            1215.83\n",
      "evaluation/EB/Q_Pred Std               58.6735\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3852.5\n",
      "evaluation/Actions Mean                 0.032391\n",
      "evaluation/Actions Std                  0.541075\n",
      "evaluation/Actions Max                  0.999985\n",
      "evaluation/Actions Min                 -0.999925\n",
      "time/backward_policy (s)                1.97011\n",
      "time/backward_zf1 (s)                   2.1301\n",
      "time/backward_zf2 (s)                   2.05093\n",
      "time/data sampling (s)                  0.325295\n",
      "time/data storing (s)                   0.014686\n",
      "time/evaluation sampling (s)            1.8101\n",
      "time/exploration sampling (s)           0.331991\n",
      "time/logging (s)                        0.0110787\n",
      "time/preback_alpha (s)                  0.597148\n",
      "time/preback_policy (s)                 1.124\n",
      "time/preback_start (s)                  0.154561\n",
      "time/preback_zf (s)                     5.19159\n",
      "time/saving (s)                         0.00592023\n",
      "time/training (s)                       2.32496\n",
      "time/epoch (s)                         18.0425\n",
      "time/total (s)                       2847.2\n",
      "Epoch                                 161\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:23:59.799366 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 162 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 173000\n",
      "trainer/ZF1 Loss                        8.9558\n",
      "trainer/ZF2 Loss                       -0.23457\n",
      "trainer/ZF Expert Reward                4.07419\n",
      "trainer/ZF Policy Reward               -4.08571\n",
      "trainer/ZF CHI2 Term                   45.066\n",
      "trainer/Policy Loss                 -1085.24\n",
      "trainer/Bias Loss                     119.949\n",
      "trainer/Bias Value                     13.9843\n",
      "trainer/Policy Grad Norm              106.737\n",
      "trainer/Policy Param Norm              36.0784\n",
      "trainer/Zf1 Grad Norm                2686\n",
      "trainer/Zf1 Param Norm                107.546\n",
      "trainer/Zf2 Grad Norm                1987.82\n",
      "trainer/Zf2 Param Norm                110.385\n",
      "trainer/Z Expert Predictions Mean    1237.8\n",
      "trainer/Z Expert Predictions Std       36.6064\n",
      "trainer/Z Expert Predictions Max     1300.32\n",
      "trainer/Z Expert Predictions Min     1053.89\n",
      "trainer/Z Policy Predictions Mean    1077.61\n",
      "trainer/Z Policy Predictions Std      348.83\n",
      "trainer/Z Policy Predictions Max     1299.28\n",
      "trainer/Z Policy Predictions Min     -395.01\n",
      "trainer/Z Expert Targets Mean        1233.72\n",
      "trainer/Z Expert Targets Std           38.3662\n",
      "trainer/Z Expert Targets Max         1297.58\n",
      "trainer/Z Expert Targets Min         1025.42\n",
      "trainer/Z Policy Targets Mean        1081.7\n",
      "trainer/Z Policy Targets Std          343.095\n",
      "trainer/Z Policy Targets Max         1309.79\n",
      "trainer/Z Policy Targets Min         -379.234\n",
      "trainer/Log Pis Mean                   32.8743\n",
      "trainer/Log Pis Std                     8.77827\n",
      "trainer/Policy mu Mean                 -0.0311988\n",
      "trainer/Policy mu Std                   2.47573\n",
      "trainer/Policy log std Mean            -4.37555\n",
      "trainer/Policy log std Std              1.20463\n",
      "exploration/num steps total        169033\n",
      "exploration/num paths total           293\n",
      "evaluation/num steps total              1.34891e+06\n",
      "evaluation/num paths total           1687\n",
      "evaluation/path length Mean           973.9\n",
      "evaluation/path length Std             78.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            739\n",
      "evaluation/Rewards Mean                 4.58396\n",
      "evaluation/Rewards Std                  0.950013\n",
      "evaluation/Rewards Max                  6.81785\n",
      "evaluation/Rewards Min                 -2.21668\n",
      "evaluation/Returns Mean              4464.31\n",
      "evaluation/Returns Std                387.281\n",
      "evaluation/Returns Max               4720.93\n",
      "evaluation/Returns Min               3324.22\n",
      "evaluation/Estimation Bias Mean      1195.65\n",
      "evaluation/Estimation Bias Std        138.874\n",
      "evaluation/EB/Q_True Mean              43.1763\n",
      "evaluation/EB/Q_True Std              130.934\n",
      "evaluation/EB/Q_Pred Mean            1238.83\n",
      "evaluation/EB/Q_Pred Std               44.8105\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4464.31\n",
      "evaluation/Actions Mean                 0.0224934\n",
      "evaluation/Actions Std                  0.534372\n",
      "evaluation/Actions Max                  0.999887\n",
      "evaluation/Actions Min                 -0.999644\n",
      "time/backward_policy (s)                1.83335\n",
      "time/backward_zf1 (s)                   1.99751\n",
      "time/backward_zf2 (s)                   1.88221\n",
      "time/data sampling (s)                  0.322697\n",
      "time/data storing (s)                   0.014408\n",
      "time/evaluation sampling (s)            1.75588\n",
      "time/exploration sampling (s)           0.327639\n",
      "time/logging (s)                        0.0126116\n",
      "time/preback_alpha (s)                  0.591307\n",
      "time/preback_policy (s)                 1.0333\n",
      "time/preback_start (s)                  0.149135\n",
      "time/preback_zf (s)                     5.16105\n",
      "time/saving (s)                         0.00654603\n",
      "time/training (s)                       2.44965\n",
      "time/epoch (s)                         17.5373\n",
      "time/total (s)                       2864.75\n",
      "Epoch                                 162\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:24:17.292533 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 163 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 174000\n",
      "trainer/ZF1 Loss                       -0.709858\n",
      "trainer/ZF2 Loss                       12.1918\n",
      "trainer/ZF Expert Reward               14.6466\n",
      "trainer/ZF Policy Reward                1.83889\n",
      "trainer/ZF CHI2 Term                   50.5953\n",
      "trainer/Policy Loss                 -1117.52\n",
      "trainer/Bias Loss                     150.322\n",
      "trainer/Bias Value                     13.9886\n",
      "trainer/Policy Grad Norm               95.3603\n",
      "trainer/Policy Param Norm              36.112\n",
      "trainer/Zf1 Grad Norm                1963.41\n",
      "trainer/Zf1 Param Norm                107.734\n",
      "trainer/Zf2 Grad Norm                3270.91\n",
      "trainer/Zf2 Param Norm                110.583\n",
      "trainer/Z Expert Predictions Mean    1238.28\n",
      "trainer/Z Expert Predictions Std       96.1225\n",
      "trainer/Z Expert Predictions Max     1326.85\n",
      "trainer/Z Expert Predictions Min     -134.869\n",
      "trainer/Z Policy Predictions Mean    1111.28\n",
      "trainer/Z Policy Predictions Std      322.97\n",
      "trainer/Z Policy Predictions Max     1299.24\n",
      "trainer/Z Policy Predictions Min     -391.683\n",
      "trainer/Z Expert Targets Mean        1223.63\n",
      "trainer/Z Expert Targets Std           90.8093\n",
      "trainer/Z Expert Targets Max         1317.36\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1109.44\n",
      "trainer/Z Policy Targets Std          316.686\n",
      "trainer/Z Policy Targets Max         1310.98\n",
      "trainer/Z Policy Targets Min         -417.399\n",
      "trainer/Log Pis Mean                   32.3703\n",
      "trainer/Log Pis Std                     8.74311\n",
      "trainer/Policy mu Mean                 -0.00299076\n",
      "trainer/Policy mu Std                   1.97021\n",
      "trainer/Policy log std Mean            -4.44135\n",
      "trainer/Policy log std Std              1.08602\n",
      "exploration/num steps total        170033\n",
      "exploration/num paths total           294\n",
      "evaluation/num steps total              1.35891e+06\n",
      "evaluation/num paths total           1697\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69896\n",
      "evaluation/Rewards Std                  0.967948\n",
      "evaluation/Rewards Max                  6.70624\n",
      "evaluation/Rewards Min                 -1.40289\n",
      "evaluation/Returns Mean              4698.96\n",
      "evaluation/Returns Std                 44.9364\n",
      "evaluation/Returns Max               4774.03\n",
      "evaluation/Returns Min               4613.77\n",
      "evaluation/Estimation Bias Mean      1185.96\n",
      "evaluation/Estimation Bias Std        140.495\n",
      "evaluation/EB/Q_True Mean              42.9737\n",
      "evaluation/EB/Q_True Std              132.558\n",
      "evaluation/EB/Q_Pred Mean            1228.93\n",
      "evaluation/EB/Q_Pred Std               50.2304\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4698.96\n",
      "evaluation/Actions Mean                 0.0141132\n",
      "evaluation/Actions Std                  0.525249\n",
      "evaluation/Actions Max                  0.999836\n",
      "evaluation/Actions Min                 -0.999741\n",
      "time/backward_policy (s)                1.79649\n",
      "time/backward_zf1 (s)                   1.95822\n",
      "time/backward_zf2 (s)                   1.84499\n",
      "time/data sampling (s)                  0.315751\n",
      "time/data storing (s)                   0.0148388\n",
      "time/evaluation sampling (s)            1.74452\n",
      "time/exploration sampling (s)           0.321665\n",
      "time/logging (s)                        0.012706\n",
      "time/preback_alpha (s)                  0.58357\n",
      "time/preback_policy (s)                 1.02649\n",
      "time/preback_start (s)                  0.147996\n",
      "time/preback_zf (s)                     5.1528\n",
      "time/saving (s)                         0.00660056\n",
      "time/training (s)                       2.49771\n",
      "time/epoch (s)                         17.4243\n",
      "time/total (s)                       2882.2\n",
      "Epoch                                 163\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:24:35.020094 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 164 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 175000\n",
      "trainer/ZF1 Loss                       14.634\n",
      "trainer/ZF2 Loss                        5.18839\n",
      "trainer/ZF Expert Reward               14.707\n",
      "trainer/ZF Policy Reward                3.46526\n",
      "trainer/ZF CHI2 Term                   53.0277\n",
      "trainer/Policy Loss                 -1074.13\n",
      "trainer/Bias Loss                      90.9394\n",
      "trainer/Bias Value                     14.0171\n",
      "trainer/Policy Grad Norm              107.761\n",
      "trainer/Policy Param Norm              36.1504\n",
      "trainer/Zf1 Grad Norm                2093.98\n",
      "trainer/Zf1 Param Norm                107.951\n",
      "trainer/Zf2 Grad Norm                1780.83\n",
      "trainer/Zf2 Param Norm                110.774\n",
      "trainer/Z Expert Predictions Mean    1241.51\n",
      "trainer/Z Expert Predictions Std       46.2293\n",
      "trainer/Z Expert Predictions Max     1315.59\n",
      "trainer/Z Expert Predictions Min      998.868\n",
      "trainer/Z Policy Predictions Mean    1066.2\n",
      "trainer/Z Policy Predictions Std      369.55\n",
      "trainer/Z Policy Predictions Max     1302.44\n",
      "trainer/Z Policy Predictions Min     -439.289\n",
      "trainer/Z Expert Targets Mean        1226.8\n",
      "trainer/Z Expert Targets Std           48.8833\n",
      "trainer/Z Expert Targets Max         1303.61\n",
      "trainer/Z Expert Targets Min          940.483\n",
      "trainer/Z Policy Targets Mean        1062.73\n",
      "trainer/Z Policy Targets Std          363.357\n",
      "trainer/Z Policy Targets Max         1286.82\n",
      "trainer/Z Policy Targets Min         -426.292\n",
      "trainer/Log Pis Mean                   32.1968\n",
      "trainer/Log Pis Std                    10.1832\n",
      "trainer/Policy mu Mean                 -0.0385965\n",
      "trainer/Policy mu Std                   2.29986\n",
      "trainer/Policy log std Mean            -4.2714\n",
      "trainer/Policy log std Std              1.16562\n",
      "exploration/num steps total        171790\n",
      "exploration/num paths total           296\n",
      "evaluation/num steps total              1.36794e+06\n",
      "evaluation/num paths total           1707\n",
      "evaluation/path length Mean           902.9\n",
      "evaluation/path length Std            291.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             29\n",
      "evaluation/Rewards Mean                 4.71121\n",
      "evaluation/Rewards Std                  1.01508\n",
      "evaluation/Rewards Max                  6.6624\n",
      "evaluation/Rewards Min                 -3.05959\n",
      "evaluation/Returns Mean              4253.75\n",
      "evaluation/Returns Std               1409.11\n",
      "evaluation/Returns Max               4896.37\n",
      "evaluation/Returns Min                 41.5336\n",
      "evaluation/Estimation Bias Mean      1180.63\n",
      "evaluation/Estimation Bias Std        152.772\n",
      "evaluation/EB/Q_True Mean              49.7584\n",
      "evaluation/EB/Q_True Std              144.993\n",
      "evaluation/EB/Q_Pred Mean            1230.39\n",
      "evaluation/EB/Q_Pred Std               53.9776\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4253.75\n",
      "evaluation/Actions Mean                 0.0204539\n",
      "evaluation/Actions Std                  0.537092\n",
      "evaluation/Actions Max                  0.999844\n",
      "evaluation/Actions Min                 -0.99977\n",
      "time/backward_policy (s)                1.86933\n",
      "time/backward_zf1 (s)                   2.02169\n",
      "time/backward_zf2 (s)                   1.92126\n",
      "time/data sampling (s)                  0.323803\n",
      "time/data storing (s)                   0.0167751\n",
      "time/evaluation sampling (s)            1.765\n",
      "time/exploration sampling (s)           0.336583\n",
      "time/logging (s)                        0.0108469\n",
      "time/preback_alpha (s)                  0.588352\n",
      "time/preback_policy (s)                 1.02662\n",
      "time/preback_start (s)                  0.151895\n",
      "time/preback_zf (s)                     5.14294\n",
      "time/saving (s)                         0.00613955\n",
      "time/training (s)                       2.47112\n",
      "time/epoch (s)                         17.6524\n",
      "time/total (s)                       2899.87\n",
      "Epoch                                 164\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:24:52.769525 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 165 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 176000\n",
      "trainer/ZF1 Loss                       66.6038\n",
      "trainer/ZF2 Loss                      103.363\n",
      "trainer/ZF Expert Reward               15.0225\n",
      "trainer/ZF Policy Reward                4.33743\n",
      "trainer/ZF CHI2 Term                  128.011\n",
      "trainer/Policy Loss                 -1066.89\n",
      "trainer/Bias Loss                      80.5417\n",
      "trainer/Bias Value                     14.0036\n",
      "trainer/Policy Grad Norm              202.43\n",
      "trainer/Policy Param Norm              36.1918\n",
      "trainer/Zf1 Grad Norm               15846.4\n",
      "trainer/Zf1 Param Norm                108.142\n",
      "trainer/Zf2 Grad Norm               14615.8\n",
      "trainer/Zf2 Param Norm                110.944\n",
      "trainer/Z Expert Predictions Mean    1242.87\n",
      "trainer/Z Expert Predictions Std       40.2845\n",
      "trainer/Z Expert Predictions Max     1313.49\n",
      "trainer/Z Expert Predictions Min     1014.04\n",
      "trainer/Z Policy Predictions Mean    1060.87\n",
      "trainer/Z Policy Predictions Std      388.179\n",
      "trainer/Z Policy Predictions Max     1310.4\n",
      "trainer/Z Policy Predictions Min     -444.362\n",
      "trainer/Z Expert Targets Mean        1227.85\n",
      "trainer/Z Expert Targets Std           41.0678\n",
      "trainer/Z Expert Targets Max         1301.94\n",
      "trainer/Z Expert Targets Min          997.821\n",
      "trainer/Z Policy Targets Mean        1056.53\n",
      "trainer/Z Policy Targets Std          387.84\n",
      "trainer/Z Policy Targets Max         1302.2\n",
      "trainer/Z Policy Targets Min         -444.175\n",
      "trainer/Log Pis Mean                   32.6685\n",
      "trainer/Log Pis Std                     9.65736\n",
      "trainer/Policy mu Mean                  0.0383598\n",
      "trainer/Policy mu Std                   2.11941\n",
      "trainer/Policy log std Mean            -4.31833\n",
      "trainer/Policy log std Std              1.20442\n",
      "exploration/num steps total        171790\n",
      "exploration/num paths total           296\n",
      "evaluation/num steps total              1.37678e+06\n",
      "evaluation/num paths total           1717\n",
      "evaluation/path length Mean           884.2\n",
      "evaluation/path length Std            261.602\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            149\n",
      "evaluation/Rewards Mean                 4.64494\n",
      "evaluation/Rewards Std                  1.01906\n",
      "evaluation/Rewards Max                  6.9714\n",
      "evaluation/Rewards Min                 -1.80789\n",
      "evaluation/Returns Mean              4107.06\n",
      "evaluation/Returns Std               1244.15\n",
      "evaluation/Returns Max               4829.36\n",
      "evaluation/Returns Min                642.261\n",
      "evaluation/Estimation Bias Mean      1175.41\n",
      "evaluation/Estimation Bias Std        159.64\n",
      "evaluation/EB/Q_True Mean              49.7755\n",
      "evaluation/EB/Q_True Std              143.206\n",
      "evaluation/EB/Q_Pred Mean            1225.19\n",
      "evaluation/EB/Q_Pred Std               55.315\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4107.06\n",
      "evaluation/Actions Mean                 0.0218262\n",
      "evaluation/Actions Std                  0.537087\n",
      "evaluation/Actions Max                  0.999923\n",
      "evaluation/Actions Min                 -0.999805\n",
      "time/backward_policy (s)                1.85342\n",
      "time/backward_zf1 (s)                   2.03213\n",
      "time/backward_zf2 (s)                   1.92746\n",
      "time/data sampling (s)                  0.321022\n",
      "time/data storing (s)                   0.0148986\n",
      "time/evaluation sampling (s)            1.74936\n",
      "time/exploration sampling (s)           0.329155\n",
      "time/logging (s)                        0.0110795\n",
      "time/preback_alpha (s)                  0.586622\n",
      "time/preback_policy (s)                 1.04676\n",
      "time/preback_start (s)                  0.149657\n",
      "time/preback_zf (s)                     5.16283\n",
      "time/saving (s)                         0.00757015\n",
      "time/training (s)                       2.489\n",
      "time/epoch (s)                         17.681\n",
      "time/total (s)                       2917.57\n",
      "Epoch                                 165\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:25:10.541861 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 166 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 177000\n",
      "trainer/ZF1 Loss                       -1.86098\n",
      "trainer/ZF2 Loss                       -2.43388\n",
      "trainer/ZF Expert Reward               13.107\n",
      "trainer/ZF Policy Reward                2.43864\n",
      "trainer/ZF CHI2 Term                   40.5142\n",
      "trainer/Policy Loss                 -1124.64\n",
      "trainer/Bias Loss                     107.406\n",
      "trainer/Bias Value                     14.0083\n",
      "trainer/Policy Grad Norm              119.358\n",
      "trainer/Policy Param Norm              36.2271\n",
      "trainer/Zf1 Grad Norm                1228.78\n",
      "trainer/Zf1 Param Norm                108.346\n",
      "trainer/Zf2 Grad Norm                1374.89\n",
      "trainer/Zf2 Param Norm                111.149\n",
      "trainer/Z Expert Predictions Mean    1240.25\n",
      "trainer/Z Expert Predictions Std       48.7424\n",
      "trainer/Z Expert Predictions Max     1335.84\n",
      "trainer/Z Expert Predictions Min      984.339\n",
      "trainer/Z Policy Predictions Mean    1118.47\n",
      "trainer/Z Policy Predictions Std      308.231\n",
      "trainer/Z Policy Predictions Max     1327.24\n",
      "trainer/Z Policy Predictions Min     -452.105\n",
      "trainer/Z Expert Targets Mean        1227.14\n",
      "trainer/Z Expert Targets Std           51.4475\n",
      "trainer/Z Expert Targets Max         1312.59\n",
      "trainer/Z Expert Targets Min          891.165\n",
      "trainer/Z Policy Targets Mean        1116.04\n",
      "trainer/Z Policy Targets Std          304.533\n",
      "trainer/Z Policy Targets Max         1311.11\n",
      "trainer/Z Policy Targets Min         -431.733\n",
      "trainer/Log Pis Mean                   32.3165\n",
      "trainer/Log Pis Std                     7.60399\n",
      "trainer/Policy mu Mean                 -0.016489\n",
      "trainer/Policy mu Std                   1.72686\n",
      "trainer/Policy log std Mean            -4.52555\n",
      "trainer/Policy log std Std              1.00578\n",
      "exploration/num steps total        171790\n",
      "exploration/num paths total           296\n",
      "evaluation/num steps total              1.38678e+06\n",
      "evaluation/num paths total           1727\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.23738\n",
      "evaluation/Rewards Std                  1.96101\n",
      "evaluation/Rewards Max                  6.83477\n",
      "evaluation/Rewards Min                 -3.82165\n",
      "evaluation/Returns Mean              4237.38\n",
      "evaluation/Returns Std               1330.74\n",
      "evaluation/Returns Max               4806.82\n",
      "evaluation/Returns Min                255.944\n",
      "evaluation/Estimation Bias Mean      1099.72\n",
      "evaluation/Estimation Bias Std        349.391\n",
      "evaluation/EB/Q_True Mean              43.7205\n",
      "evaluation/EB/Q_True Std              134.53\n",
      "evaluation/EB/Q_Pred Mean            1143.44\n",
      "evaluation/EB/Q_Pred Std              332.715\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4237.38\n",
      "evaluation/Actions Mean                 0.0211055\n",
      "evaluation/Actions Std                  0.5631\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9611\n",
      "time/backward_zf1 (s)                   2.12669\n",
      "time/backward_zf2 (s)                   2.04407\n",
      "time/data sampling (s)                  0.319236\n",
      "time/data storing (s)                   0.0146706\n",
      "time/evaluation sampling (s)            1.77574\n",
      "time/exploration sampling (s)           0.325155\n",
      "time/logging (s)                        0.0147145\n",
      "time/preback_alpha (s)                  0.579487\n",
      "time/preback_policy (s)                 1.16005\n",
      "time/preback_start (s)                  0.147471\n",
      "time/preback_zf (s)                     5.12346\n",
      "time/saving (s)                         0.00633822\n",
      "time/training (s)                       2.10603\n",
      "time/epoch (s)                         17.7042\n",
      "time/total (s)                       2935.3\n",
      "Epoch                                 166\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:25:27.966083 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 167 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 178000\n",
      "trainer/ZF1 Loss                       25.5327\n",
      "trainer/ZF2 Loss                        0.15464\n",
      "trainer/ZF Expert Reward               12.3085\n",
      "trainer/ZF Policy Reward               -0.0658415\n",
      "trainer/ZF CHI2 Term                   56.8974\n",
      "trainer/Policy Loss                 -1086.89\n",
      "trainer/Bias Loss                      83.8049\n",
      "trainer/Bias Value                     14.0314\n",
      "trainer/Policy Grad Norm              131.967\n",
      "trainer/Policy Param Norm              36.2565\n",
      "trainer/Zf1 Grad Norm               10239.4\n",
      "trainer/Zf1 Param Norm                108.544\n",
      "trainer/Zf2 Grad Norm                3421.76\n",
      "trainer/Zf2 Param Norm                111.338\n",
      "trainer/Z Expert Predictions Mean    1232.6\n",
      "trainer/Z Expert Predictions Std       48.829\n",
      "trainer/Z Expert Predictions Max     1321.78\n",
      "trainer/Z Expert Predictions Min      986.634\n",
      "trainer/Z Policy Predictions Mean    1077.95\n",
      "trainer/Z Policy Predictions Std      358.036\n",
      "trainer/Z Policy Predictions Max     1297.53\n",
      "trainer/Z Policy Predictions Min     -394.531\n",
      "trainer/Z Expert Targets Mean        1220.29\n",
      "trainer/Z Expert Targets Std           51.6008\n",
      "trainer/Z Expert Targets Max         1306.87\n",
      "trainer/Z Expert Targets Min          965.497\n",
      "trainer/Z Policy Targets Mean        1078.02\n",
      "trainer/Z Policy Targets Std          355.675\n",
      "trainer/Z Policy Targets Max         1290.36\n",
      "trainer/Z Policy Targets Min         -385.26\n",
      "trainer/Log Pis Mean                   31.9993\n",
      "trainer/Log Pis Std                     8.36082\n",
      "trainer/Policy mu Mean                 -0.0210339\n",
      "trainer/Policy mu Std                   1.99339\n",
      "trainer/Policy log std Mean            -4.3984\n",
      "trainer/Policy log std Std              1.0618\n",
      "exploration/num steps total        172790\n",
      "exploration/num paths total           297\n",
      "evaluation/num steps total              1.39678e+06\n",
      "evaluation/num paths total           1737\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60058\n",
      "evaluation/Rewards Std                  1.01066\n",
      "evaluation/Rewards Max                  7.12223\n",
      "evaluation/Rewards Min                 -1.53799\n",
      "evaluation/Returns Mean              4600.58\n",
      "evaluation/Returns Std                 87.5123\n",
      "evaluation/Returns Max               4718.32\n",
      "evaluation/Returns Min               4419.59\n",
      "evaluation/Estimation Bias Mean      1177.76\n",
      "evaluation/Estimation Bias Std        143.161\n",
      "evaluation/EB/Q_True Mean              43.1431\n",
      "evaluation/EB/Q_True Std              133.108\n",
      "evaluation/EB/Q_Pred Mean            1220.9\n",
      "evaluation/EB/Q_Pred Std               53.8755\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4600.58\n",
      "evaluation/Actions Mean                 0.0151231\n",
      "evaluation/Actions Std                  0.531383\n",
      "evaluation/Actions Max                  0.999774\n",
      "evaluation/Actions Min                 -0.99942\n",
      "time/backward_policy (s)                1.84587\n",
      "time/backward_zf1 (s)                   1.96607\n",
      "time/backward_zf2 (s)                   1.91942\n",
      "time/data sampling (s)                  0.306614\n",
      "time/data storing (s)                   0.0144097\n",
      "time/evaluation sampling (s)            1.72018\n",
      "time/exploration sampling (s)           0.316589\n",
      "time/logging (s)                        0.0120612\n",
      "time/preback_alpha (s)                  0.573301\n",
      "time/preback_policy (s)                 1.08541\n",
      "time/preback_start (s)                  0.145637\n",
      "time/preback_zf (s)                     5.09729\n",
      "time/saving (s)                         0.00641114\n",
      "time/training (s)                       2.34382\n",
      "time/epoch (s)                         17.3531\n",
      "time/total (s)                       2952.67\n",
      "Epoch                                 167\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:25:45.673532 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 168 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 179000\n",
      "trainer/ZF1 Loss                       -0.843056\n",
      "trainer/ZF2 Loss                        4.34382\n",
      "trainer/ZF Expert Reward               12.8811\n",
      "trainer/ZF Policy Reward               -0.806833\n",
      "trainer/ZF CHI2 Term                   46.9735\n",
      "trainer/Policy Loss                 -1087.96\n",
      "trainer/Bias Loss                     131.917\n",
      "trainer/Bias Value                     14.0075\n",
      "trainer/Policy Grad Norm              133.739\n",
      "trainer/Policy Param Norm              36.2884\n",
      "trainer/Zf1 Grad Norm                1802.56\n",
      "trainer/Zf1 Param Norm                108.745\n",
      "trainer/Zf2 Grad Norm                1924.13\n",
      "trainer/Zf2 Param Norm                111.54\n",
      "trainer/Z Expert Predictions Mean    1231.07\n",
      "trainer/Z Expert Predictions Std       92.0491\n",
      "trainer/Z Expert Predictions Max     1316.89\n",
      "trainer/Z Expert Predictions Min        4.95373\n",
      "trainer/Z Policy Predictions Mean    1080.69\n",
      "trainer/Z Policy Predictions Std      335.626\n",
      "trainer/Z Policy Predictions Max     1308.99\n",
      "trainer/Z Policy Predictions Min     -405.148\n",
      "trainer/Z Expert Targets Mean        1218.19\n",
      "trainer/Z Expert Targets Std           93.1996\n",
      "trainer/Z Expert Targets Max         1301.5\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1081.5\n",
      "trainer/Z Policy Targets Std          330.559\n",
      "trainer/Z Policy Targets Max         1287.79\n",
      "trainer/Z Policy Targets Min         -389.958\n",
      "trainer/Log Pis Mean                   31.8536\n",
      "trainer/Log Pis Std                     8.232\n",
      "trainer/Policy mu Mean                 -0.002912\n",
      "trainer/Policy mu Std                   1.86821\n",
      "trainer/Policy log std Mean            -4.39769\n",
      "trainer/Policy log std Std              1.01818\n",
      "exploration/num steps total        174376\n",
      "exploration/num paths total           299\n",
      "evaluation/num steps total              1.40678e+06\n",
      "evaluation/num paths total           1747\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.19281\n",
      "evaluation/Rewards Std                  2.06089\n",
      "evaluation/Rewards Max                  6.83584\n",
      "evaluation/Rewards Min                 -3.93283\n",
      "evaluation/Returns Mean              4192.81\n",
      "evaluation/Returns Std               1410.54\n",
      "evaluation/Returns Max               4813.01\n",
      "evaluation/Returns Min                -30.6655\n",
      "evaluation/Estimation Bias Mean      1082.67\n",
      "evaluation/Estimation Bias Std        359.722\n",
      "evaluation/EB/Q_True Mean              44.1341\n",
      "evaluation/EB/Q_True Std              136.322\n",
      "evaluation/EB/Q_Pred Mean            1126.8\n",
      "evaluation/EB/Q_Pred Std              344.006\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4192.81\n",
      "evaluation/Actions Mean                 0.0145958\n",
      "evaluation/Actions Std                  0.575218\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92217\n",
      "time/backward_zf1 (s)                   2.08612\n",
      "time/backward_zf2 (s)                   1.99525\n",
      "time/data sampling (s)                  0.294256\n",
      "time/data storing (s)                   0.01408\n",
      "time/evaluation sampling (s)            1.75573\n",
      "time/exploration sampling (s)           0.32351\n",
      "time/logging (s)                        0.0120237\n",
      "time/preback_alpha (s)                  0.577267\n",
      "time/preback_policy (s)                 1.12658\n",
      "time/preback_start (s)                  0.147673\n",
      "time/preback_zf (s)                     5.15118\n",
      "time/saving (s)                         0.00657013\n",
      "time/training (s)                       2.22399\n",
      "time/epoch (s)                         17.6364\n",
      "time/total (s)                       2970.33\n",
      "Epoch                                 168\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:26:03.616259 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 169 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 180000\n",
      "trainer/ZF1 Loss                       16.6672\n",
      "trainer/ZF2 Loss                       11.2637\n",
      "trainer/ZF Expert Reward                9.35985\n",
      "trainer/ZF Policy Reward                0.770418\n",
      "trainer/ZF CHI2 Term                   54.7131\n",
      "trainer/Policy Loss                 -1115.7\n",
      "trainer/Bias Loss                      73.0518\n",
      "trainer/Bias Value                     14.0038\n",
      "trainer/Policy Grad Norm              112.027\n",
      "trainer/Policy Param Norm              36.3247\n",
      "trainer/Zf1 Grad Norm                1594.7\n",
      "trainer/Zf1 Param Norm                108.944\n",
      "trainer/Zf2 Grad Norm                1742.59\n",
      "trainer/Zf2 Param Norm                111.744\n",
      "trainer/Z Expert Predictions Mean    1231.4\n",
      "trainer/Z Expert Predictions Std       47.414\n",
      "trainer/Z Expert Predictions Max     1316\n",
      "trainer/Z Expert Predictions Min      981.966\n",
      "trainer/Z Policy Predictions Mean    1106.46\n",
      "trainer/Z Policy Predictions Std      303.398\n",
      "trainer/Z Policy Predictions Max     1289.59\n",
      "trainer/Z Policy Predictions Min     -401.892\n",
      "trainer/Z Expert Targets Mean        1222.04\n",
      "trainer/Z Expert Targets Std           47.3229\n",
      "trainer/Z Expert Targets Max         1315.11\n",
      "trainer/Z Expert Targets Min          986.078\n",
      "trainer/Z Policy Targets Mean        1105.69\n",
      "trainer/Z Policy Targets Std          301.134\n",
      "trainer/Z Policy Targets Max         1286.27\n",
      "trainer/Z Policy Targets Min         -387.56\n",
      "trainer/Log Pis Mean                   32.483\n",
      "trainer/Log Pis Std                     7.70478\n",
      "trainer/Policy mu Mean                 -0.00306882\n",
      "trainer/Policy mu Std                   1.74216\n",
      "trainer/Policy log std Mean            -4.55805\n",
      "trainer/Policy log std Std              0.945179\n",
      "exploration/num steps total        174376\n",
      "exploration/num paths total           299\n",
      "evaluation/num steps total              1.41678e+06\n",
      "evaluation/num paths total           1757\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.71611\n",
      "evaluation/Rewards Std                  1.00716\n",
      "evaluation/Rewards Max                  6.79816\n",
      "evaluation/Rewards Min                 -1.79221\n",
      "evaluation/Returns Mean              4716.11\n",
      "evaluation/Returns Std                112.554\n",
      "evaluation/Returns Max               4894.3\n",
      "evaluation/Returns Min               4517.07\n",
      "evaluation/Estimation Bias Mean      1184.83\n",
      "evaluation/Estimation Bias Std        147.886\n",
      "evaluation/EB/Q_True Mean              44.1691\n",
      "evaluation/EB/Q_True Std              136.417\n",
      "evaluation/EB/Q_Pred Mean            1229\n",
      "evaluation/EB/Q_Pred Std               60.9358\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4716.11\n",
      "evaluation/Actions Mean                 0.0161021\n",
      "evaluation/Actions Std                  0.540559\n",
      "evaluation/Actions Max                  0.999772\n",
      "evaluation/Actions Min                 -0.999821\n",
      "time/backward_policy (s)                1.99563\n",
      "time/backward_zf1 (s)                   2.14147\n",
      "time/backward_zf2 (s)                   2.06281\n",
      "time/data sampling (s)                  0.299048\n",
      "time/data storing (s)                   0.0154495\n",
      "time/evaluation sampling (s)            1.74164\n",
      "time/exploration sampling (s)           0.329186\n",
      "time/logging (s)                        0.012178\n",
      "time/preback_alpha (s)                  0.583144\n",
      "time/preback_policy (s)                 1.17915\n",
      "time/preback_start (s)                  0.149616\n",
      "time/preback_zf (s)                     5.15424\n",
      "time/saving (s)                         0.0082377\n",
      "time/training (s)                       2.20237\n",
      "time/epoch (s)                         17.8742\n",
      "time/total (s)                       2988.22\n",
      "Epoch                                 169\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:26:21.907503 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 170 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 181000\n",
      "trainer/ZF1 Loss                       -2.25267\n",
      "trainer/ZF2 Loss                       -4.28139\n",
      "trainer/ZF Expert Reward               19.0355\n",
      "trainer/ZF Policy Reward                9.88179\n",
      "trainer/ZF CHI2 Term                   37.408\n",
      "trainer/Policy Loss                 -1103.82\n",
      "trainer/Bias Loss                      86.3007\n",
      "trainer/Bias Value                     14.0194\n",
      "trainer/Policy Grad Norm              105.159\n",
      "trainer/Policy Param Norm              36.3626\n",
      "trainer/Zf1 Grad Norm                 986.988\n",
      "trainer/Zf1 Param Norm                109.132\n",
      "trainer/Zf2 Grad Norm                1066.62\n",
      "trainer/Zf2 Param Norm                111.93\n",
      "trainer/Z Expert Predictions Mean    1240.39\n",
      "trainer/Z Expert Predictions Std       42.0859\n",
      "trainer/Z Expert Predictions Max     1324.08\n",
      "trainer/Z Expert Predictions Min     1022.93\n",
      "trainer/Z Policy Predictions Mean    1099.84\n",
      "trainer/Z Policy Predictions Std      311.304\n",
      "trainer/Z Policy Predictions Max     1299.76\n",
      "trainer/Z Policy Predictions Min     -401.174\n",
      "trainer/Z Expert Targets Mean        1221.35\n",
      "trainer/Z Expert Targets Std           42.3424\n",
      "trainer/Z Expert Targets Max         1304.04\n",
      "trainer/Z Expert Targets Min          992.309\n",
      "trainer/Z Policy Targets Mean        1089.95\n",
      "trainer/Z Policy Targets Std          305.248\n",
      "trainer/Z Policy Targets Max         1293.41\n",
      "trainer/Z Policy Targets Min         -385.355\n",
      "trainer/Log Pis Mean                   31.8397\n",
      "trainer/Log Pis Std                     7.25684\n",
      "trainer/Policy mu Mean                  0.085733\n",
      "trainer/Policy mu Std                   1.62647\n",
      "trainer/Policy log std Mean            -4.43437\n",
      "trainer/Policy log std Std              0.972036\n",
      "exploration/num steps total        174376\n",
      "exploration/num paths total           299\n",
      "evaluation/num steps total              1.42605e+06\n",
      "evaluation/num paths total           1767\n",
      "evaluation/path length Mean           927.1\n",
      "evaluation/path length Std            218.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            271\n",
      "evaluation/Rewards Mean                 4.69008\n",
      "evaluation/Rewards Std                  0.981721\n",
      "evaluation/Rewards Max                  6.6529\n",
      "evaluation/Rewards Min                 -2.65749\n",
      "evaluation/Returns Mean              4348.17\n",
      "evaluation/Returns Std               1087.24\n",
      "evaluation/Returns Max               4810.11\n",
      "evaluation/Returns Min               1098.94\n",
      "evaluation/Estimation Bias Mean      1177.32\n",
      "evaluation/Estimation Bias Std        161.527\n",
      "evaluation/EB/Q_True Mean              47.2567\n",
      "evaluation/EB/Q_True Std              139.898\n",
      "evaluation/EB/Q_Pred Mean            1224.58\n",
      "evaluation/EB/Q_Pred Std               62.1022\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4348.17\n",
      "evaluation/Actions Mean                 0.0249132\n",
      "evaluation/Actions Std                  0.536666\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999931\n",
      "time/backward_policy (s)                2.06644\n",
      "time/backward_zf1 (s)                   2.22048\n",
      "time/backward_zf2 (s)                   2.16181\n",
      "time/data sampling (s)                  0.29265\n",
      "time/data storing (s)                   0.0154347\n",
      "time/evaluation sampling (s)            1.73091\n",
      "time/exploration sampling (s)           0.339689\n",
      "time/logging (s)                        0.0111972\n",
      "time/preback_alpha (s)                  0.591018\n",
      "time/preback_policy (s)                 1.23944\n",
      "time/preback_start (s)                  0.149303\n",
      "time/preback_zf (s)                     5.19316\n",
      "time/saving (s)                         0.00614697\n",
      "time/training (s)                       2.20045\n",
      "time/epoch (s)                         18.2181\n",
      "time/total (s)                       3006.46\n",
      "Epoch                                 170\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:26:39.738353 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 171 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 182000\n",
      "trainer/ZF1 Loss                       94.7454\n",
      "trainer/ZF2 Loss                      102.9\n",
      "trainer/ZF Expert Reward               14.3726\n",
      "trainer/ZF Policy Reward                4.78578\n",
      "trainer/ZF CHI2 Term                  139.22\n",
      "trainer/Policy Loss                 -1101.33\n",
      "trainer/Bias Loss                      57.1744\n",
      "trainer/Bias Value                     14.0225\n",
      "trainer/Policy Grad Norm              198.524\n",
      "trainer/Policy Param Norm              36.4049\n",
      "trainer/Zf1 Grad Norm               13686.4\n",
      "trainer/Zf1 Param Norm                109.318\n",
      "trainer/Zf2 Grad Norm               10830.2\n",
      "trainer/Zf2 Param Norm                112.118\n",
      "trainer/Z Expert Predictions Mean    1229.67\n",
      "trainer/Z Expert Predictions Std       49.9318\n",
      "trainer/Z Expert Predictions Max     1318.49\n",
      "trainer/Z Expert Predictions Min      979.392\n",
      "trainer/Z Policy Predictions Mean    1093.39\n",
      "trainer/Z Policy Predictions Std      300.236\n",
      "trainer/Z Policy Predictions Max     1298.99\n",
      "trainer/Z Policy Predictions Min     -405.557\n",
      "trainer/Z Expert Targets Mean        1215.3\n",
      "trainer/Z Expert Targets Std           50.1938\n",
      "trainer/Z Expert Targets Max         1307.26\n",
      "trainer/Z Expert Targets Min          975.516\n",
      "trainer/Z Policy Targets Mean        1088.6\n",
      "trainer/Z Policy Targets Std          302.167\n",
      "trainer/Z Policy Targets Max         1290.57\n",
      "trainer/Z Policy Targets Min         -419.394\n",
      "trainer/Log Pis Mean                   31.1222\n",
      "trainer/Log Pis Std                     7.36299\n",
      "trainer/Policy mu Mean                 -0.0108179\n",
      "trainer/Policy mu Std                   1.52674\n",
      "trainer/Policy log std Mean            -4.48511\n",
      "trainer/Policy log std Std              0.873982\n",
      "exploration/num steps total        177414\n",
      "exploration/num paths total           303\n",
      "evaluation/num steps total              1.43605e+06\n",
      "evaluation/num paths total           1777\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.71952\n",
      "evaluation/Rewards Std                  0.958692\n",
      "evaluation/Rewards Max                  6.702\n",
      "evaluation/Rewards Min                 -1.59726\n",
      "evaluation/Returns Mean              4719.52\n",
      "evaluation/Returns Std                 69.1971\n",
      "evaluation/Returns Max               4845.4\n",
      "evaluation/Returns Min               4623.58\n",
      "evaluation/Estimation Bias Mean      1177.72\n",
      "evaluation/Estimation Bias Std        140.412\n",
      "evaluation/EB/Q_True Mean              42.5968\n",
      "evaluation/EB/Q_True Std              131.628\n",
      "evaluation/EB/Q_Pred Mean            1220.31\n",
      "evaluation/EB/Q_Pred Std               50.2076\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4719.52\n",
      "evaluation/Actions Mean                 0.0263496\n",
      "evaluation/Actions Std                  0.535376\n",
      "evaluation/Actions Max                  0.999914\n",
      "evaluation/Actions Min                 -0.999766\n",
      "time/backward_policy (s)                1.89804\n",
      "time/backward_zf1 (s)                   2.08313\n",
      "time/backward_zf2 (s)                   1.99647\n",
      "time/data sampling (s)                  0.312348\n",
      "time/data storing (s)                   0.015291\n",
      "time/evaluation sampling (s)            1.7901\n",
      "time/exploration sampling (s)           0.334434\n",
      "time/logging (s)                        0.0126774\n",
      "time/preback_alpha (s)                  0.587196\n",
      "time/preback_policy (s)                 1.12958\n",
      "time/preback_start (s)                  0.14912\n",
      "time/preback_zf (s)                     5.1684\n",
      "time/saving (s)                         0.00653877\n",
      "time/training (s)                       2.27946\n",
      "time/epoch (s)                         17.7628\n",
      "time/total (s)                       3024.25\n",
      "Epoch                                 171\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:26:57.334087 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 172 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 183000\n",
      "trainer/ZF1 Loss                       -2.09124\n",
      "trainer/ZF2 Loss                        4.54589\n",
      "trainer/ZF Expert Reward               14.5002\n",
      "trainer/ZF Policy Reward                2.74733\n",
      "trainer/ZF CHI2 Term                   44.5616\n",
      "trainer/Policy Loss                 -1056.99\n",
      "trainer/Bias Loss                     114.726\n",
      "trainer/Bias Value                     14.0481\n",
      "trainer/Policy Grad Norm              121.064\n",
      "trainer/Policy Param Norm              36.4494\n",
      "trainer/Zf1 Grad Norm                1362.21\n",
      "trainer/Zf1 Param Norm                109.498\n",
      "trainer/Zf2 Grad Norm                1355.24\n",
      "trainer/Zf2 Param Norm                112.287\n",
      "trainer/Z Expert Predictions Mean    1223.99\n",
      "trainer/Z Expert Predictions Std       51.1036\n",
      "trainer/Z Expert Predictions Max     1308.75\n",
      "trainer/Z Expert Predictions Min      977.814\n",
      "trainer/Z Policy Predictions Mean    1053.36\n",
      "trainer/Z Policy Predictions Std      370.066\n",
      "trainer/Z Policy Predictions Max     1295.71\n",
      "trainer/Z Policy Predictions Min     -428.935\n",
      "trainer/Z Expert Targets Mean        1209.49\n",
      "trainer/Z Expert Targets Std           56.1051\n",
      "trainer/Z Expert Targets Max         1293.59\n",
      "trainer/Z Expert Targets Min          819.21\n",
      "trainer/Z Policy Targets Mean        1050.61\n",
      "trainer/Z Policy Targets Std          363.932\n",
      "trainer/Z Policy Targets Max         1302.06\n",
      "trainer/Z Policy Targets Min         -420.748\n",
      "trainer/Log Pis Mean                   31.9004\n",
      "trainer/Log Pis Std                     8.41275\n",
      "trainer/Policy mu Mean                  0.0373354\n",
      "trainer/Policy mu Std                   1.85276\n",
      "trainer/Policy log std Mean            -4.3053\n",
      "trainer/Policy log std Std              1.09111\n",
      "exploration/num steps total        178444\n",
      "exploration/num paths total           305\n",
      "evaluation/num steps total              1.44605e+06\n",
      "evaluation/num paths total           1787\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7694\n",
      "evaluation/Rewards Std                  0.996629\n",
      "evaluation/Rewards Max                  6.71736\n",
      "evaluation/Rewards Min                 -1.7683\n",
      "evaluation/Returns Mean              4769.4\n",
      "evaluation/Returns Std                105.13\n",
      "evaluation/Returns Max               4877.89\n",
      "evaluation/Returns Min               4566.16\n",
      "evaluation/Estimation Bias Mean      1172.09\n",
      "evaluation/Estimation Bias Std        147.459\n",
      "evaluation/EB/Q_True Mean              44.4515\n",
      "evaluation/EB/Q_True Std              136.964\n",
      "evaluation/EB/Q_Pred Mean            1216.54\n",
      "evaluation/EB/Q_Pred Std               52.066\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4769.4\n",
      "evaluation/Actions Mean                 0.0202638\n",
      "evaluation/Actions Std                  0.536529\n",
      "evaluation/Actions Max                  0.999865\n",
      "evaluation/Actions Min                 -0.999774\n",
      "time/backward_policy (s)                1.82203\n",
      "time/backward_zf1 (s)                   1.9823\n",
      "time/backward_zf2 (s)                   1.90146\n",
      "time/data sampling (s)                  0.312279\n",
      "time/data storing (s)                   0.0140329\n",
      "time/evaluation sampling (s)            1.75415\n",
      "time/exploration sampling (s)           0.318907\n",
      "time/logging (s)                        0.012159\n",
      "time/preback_alpha (s)                  0.584392\n",
      "time/preback_policy (s)                 1.04127\n",
      "time/preback_start (s)                  0.148082\n",
      "time/preback_zf (s)                     5.15158\n",
      "time/saving (s)                         0.00646159\n",
      "time/training (s)                       2.47401\n",
      "time/epoch (s)                         17.5231\n",
      "time/total (s)                       3041.79\n",
      "Epoch                                 172\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:27:15.248410 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 173 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 184000\n",
      "trainer/ZF1 Loss                       -7.78181\n",
      "trainer/ZF2 Loss                        5.79747\n",
      "trainer/ZF Expert Reward               15.2976\n",
      "trainer/ZF Policy Reward                4.84678\n",
      "trainer/ZF CHI2 Term                   40.1297\n",
      "trainer/Policy Loss                 -1112.13\n",
      "trainer/Bias Loss                      52.8675\n",
      "trainer/Bias Value                     13.9958\n",
      "trainer/Policy Grad Norm              106.945\n",
      "trainer/Policy Param Norm              36.4887\n",
      "trainer/Zf1 Grad Norm                1165.14\n",
      "trainer/Zf1 Param Norm                109.716\n",
      "trainer/Zf2 Grad Norm                1607.63\n",
      "trainer/Zf2 Param Norm                112.482\n",
      "trainer/Z Expert Predictions Mean    1223.73\n",
      "trainer/Z Expert Predictions Std       92.4504\n",
      "trainer/Z Expert Predictions Max     1309.41\n",
      "trainer/Z Expert Predictions Min       32.4667\n",
      "trainer/Z Policy Predictions Mean    1105.33\n",
      "trainer/Z Policy Predictions Std      272.458\n",
      "trainer/Z Policy Predictions Max     1291.08\n",
      "trainer/Z Policy Predictions Min     -378.399\n",
      "trainer/Z Expert Targets Mean        1208.43\n",
      "trainer/Z Expert Targets Std           94.8698\n",
      "trainer/Z Expert Targets Max         1297.54\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1100.49\n",
      "trainer/Z Policy Targets Std          271.517\n",
      "trainer/Z Policy Targets Max         1284.87\n",
      "trainer/Z Policy Targets Min         -377.84\n",
      "trainer/Log Pis Mean                   30.9809\n",
      "trainer/Log Pis Std                     6.05937\n",
      "trainer/Policy mu Mean                  0.0295213\n",
      "trainer/Policy mu Std                   1.48317\n",
      "trainer/Policy log std Mean            -4.40265\n",
      "trainer/Policy log std Std              0.891374\n",
      "exploration/num steps total        179444\n",
      "exploration/num paths total           306\n",
      "evaluation/num steps total              1.45589e+06\n",
      "evaluation/num paths total           1797\n",
      "evaluation/path length Mean           983.3\n",
      "evaluation/path length Std             50.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            833\n",
      "evaluation/Rewards Mean                 4.57289\n",
      "evaluation/Rewards Std                  1.03032\n",
      "evaluation/Rewards Max                  6.79226\n",
      "evaluation/Rewards Min                 -2.12824\n",
      "evaluation/Returns Mean              4496.52\n",
      "evaluation/Returns Std                215.097\n",
      "evaluation/Returns Max               4717.05\n",
      "evaluation/Returns Min               3945.2\n",
      "evaluation/Estimation Bias Mean      1160.82\n",
      "evaluation/Estimation Bias Std        136.085\n",
      "evaluation/EB/Q_True Mean              40.1923\n",
      "evaluation/EB/Q_True Std              122.606\n",
      "evaluation/EB/Q_Pred Mean            1201.01\n",
      "evaluation/EB/Q_Pred Std               56.8183\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4496.52\n",
      "evaluation/Actions Mean                 0.0270428\n",
      "evaluation/Actions Std                  0.530047\n",
      "evaluation/Actions Max                  0.999946\n",
      "evaluation/Actions Min                 -0.999983\n",
      "time/backward_policy (s)                1.95762\n",
      "time/backward_zf1 (s)                   2.12268\n",
      "time/backward_zf2 (s)                   2.04181\n",
      "time/data sampling (s)                  0.318446\n",
      "time/data storing (s)                   0.015616\n",
      "time/evaluation sampling (s)            1.7236\n",
      "time/exploration sampling (s)           0.329509\n",
      "time/logging (s)                        0.0133682\n",
      "time/preback_alpha (s)                  0.58564\n",
      "time/preback_policy (s)                 1.15732\n",
      "time/preback_start (s)                  0.152296\n",
      "time/preback_zf (s)                     5.17189\n",
      "time/saving (s)                         0.00830732\n",
      "time/training (s)                       2.24685\n",
      "time/epoch (s)                         17.845\n",
      "time/total (s)                       3059.66\n",
      "Epoch                                 173\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:27:33.267565 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 174 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 185000\n",
      "trainer/ZF1 Loss                      -10.8072\n",
      "trainer/ZF2 Loss                       -6.20252\n",
      "trainer/ZF Expert Reward               11.7553\n",
      "trainer/ZF Policy Reward                0.0751422\n",
      "trainer/ZF CHI2 Term                   35.8794\n",
      "trainer/Policy Loss                 -1079.56\n",
      "trainer/Bias Loss                      59.2714\n",
      "trainer/Bias Value                     14.0161\n",
      "trainer/Policy Grad Norm              148.608\n",
      "trainer/Policy Param Norm              36.5257\n",
      "trainer/Zf1 Grad Norm                1178.4\n",
      "trainer/Zf1 Param Norm                109.9\n",
      "trainer/Zf2 Grad Norm                1431.82\n",
      "trainer/Zf2 Param Norm                112.663\n",
      "trainer/Z Expert Predictions Mean    1220.19\n",
      "trainer/Z Expert Predictions Std       83.2803\n",
      "trainer/Z Expert Predictions Max     1290.67\n",
      "trainer/Z Expert Predictions Min       75.3773\n",
      "trainer/Z Policy Predictions Mean    1073.96\n",
      "trainer/Z Policy Predictions Std      358.348\n",
      "trainer/Z Policy Predictions Max     1283.43\n",
      "trainer/Z Policy Predictions Min     -381.605\n",
      "trainer/Z Expert Targets Mean        1208.44\n",
      "trainer/Z Expert Targets Std           87.8495\n",
      "trainer/Z Expert Targets Max         1288.6\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1073.89\n",
      "trainer/Z Policy Targets Std          355.636\n",
      "trainer/Z Policy Targets Max         1291.65\n",
      "trainer/Z Policy Targets Min         -383.094\n",
      "trainer/Log Pis Mean                   33.0344\n",
      "trainer/Log Pis Std                     9.9017\n",
      "trainer/Policy mu Mean                  0.0681854\n",
      "trainer/Policy mu Std                   2.0044\n",
      "trainer/Policy log std Mean            -4.47051\n",
      "trainer/Policy log std Std              1.06282\n",
      "exploration/num steps total        181444\n",
      "exploration/num paths total           308\n",
      "evaluation/num steps total              1.46585e+06\n",
      "evaluation/num paths total           1807\n",
      "evaluation/path length Mean           996.3\n",
      "evaluation/path length Std             11.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            963\n",
      "evaluation/Rewards Mean                 4.71281\n",
      "evaluation/Rewards Std                  0.980292\n",
      "evaluation/Rewards Max                  6.98916\n",
      "evaluation/Rewards Min                 -3.17813\n",
      "evaluation/Returns Mean              4695.37\n",
      "evaluation/Returns Std                126.782\n",
      "evaluation/Returns Max               4859.01\n",
      "evaluation/Returns Min               4444.34\n",
      "evaluation/Estimation Bias Mean      1170.38\n",
      "evaluation/Estimation Bias Std        146.893\n",
      "evaluation/EB/Q_True Mean              43.8893\n",
      "evaluation/EB/Q_True Std              134.908\n",
      "evaluation/EB/Q_Pred Mean            1214.27\n",
      "evaluation/EB/Q_Pred Std               51.8652\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4695.37\n",
      "evaluation/Actions Mean                 0.029784\n",
      "evaluation/Actions Std                  0.539574\n",
      "evaluation/Actions Max                  0.999973\n",
      "evaluation/Actions Min                 -0.9999\n",
      "time/backward_policy (s)                1.97216\n",
      "time/backward_zf1 (s)                   2.11738\n",
      "time/backward_zf2 (s)                   2.05065\n",
      "time/data sampling (s)                  0.32953\n",
      "time/data storing (s)                   0.0151241\n",
      "time/evaluation sampling (s)            1.78418\n",
      "time/exploration sampling (s)           0.334307\n",
      "time/logging (s)                        0.0204579\n",
      "time/preback_alpha (s)                  0.595597\n",
      "time/preback_policy (s)                 1.15918\n",
      "time/preback_start (s)                  0.149861\n",
      "time/preback_zf (s)                     5.18658\n",
      "time/saving (s)                         0.0128115\n",
      "time/training (s)                       2.22764\n",
      "time/epoch (s)                         17.9555\n",
      "time/total (s)                       3077.63\n",
      "Epoch                                 174\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:27:51.150479 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 175 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 186000\n",
      "trainer/ZF1 Loss                       -0.434666\n",
      "trainer/ZF2 Loss                       -5.06667\n",
      "trainer/ZF Expert Reward               14.8375\n",
      "trainer/ZF Policy Reward                3.53641\n",
      "trainer/ZF CHI2 Term                   41.5683\n",
      "trainer/Policy Loss                 -1051.83\n",
      "trainer/Bias Loss                      58.1848\n",
      "trainer/Bias Value                     14.0027\n",
      "trainer/Policy Grad Norm               92.5233\n",
      "trainer/Policy Param Norm              36.5671\n",
      "trainer/Zf1 Grad Norm                1221.24\n",
      "trainer/Zf1 Param Norm                110.083\n",
      "trainer/Zf2 Grad Norm                1085.46\n",
      "trainer/Zf2 Param Norm                112.856\n",
      "trainer/Z Expert Predictions Mean    1219.84\n",
      "trainer/Z Expert Predictions Std       87.8739\n",
      "trainer/Z Expert Predictions Max     1308.07\n",
      "trainer/Z Expert Predictions Min       39.295\n",
      "trainer/Z Policy Predictions Mean    1047.01\n",
      "trainer/Z Policy Predictions Std      372.084\n",
      "trainer/Z Policy Predictions Max     1280.46\n",
      "trainer/Z Policy Predictions Min     -388.203\n",
      "trainer/Z Expert Targets Mean        1205\n",
      "trainer/Z Expert Targets Std           89.7234\n",
      "trainer/Z Expert Targets Max         1289.17\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1043.47\n",
      "trainer/Z Policy Targets Std          365.627\n",
      "trainer/Z Policy Targets Max         1278.18\n",
      "trainer/Z Policy Targets Min         -369.13\n",
      "trainer/Log Pis Mean                   33.3513\n",
      "trainer/Log Pis Std                     9.3573\n",
      "trainer/Policy mu Mean                  0.114095\n",
      "trainer/Policy mu Std                   1.89759\n",
      "trainer/Policy log std Mean            -4.40318\n",
      "trainer/Policy log std Std              1.08396\n",
      "exploration/num steps total        181444\n",
      "exploration/num paths total           308\n",
      "evaluation/num steps total              1.47585e+06\n",
      "evaluation/num paths total           1817\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67426\n",
      "evaluation/Rewards Std                  1.00229\n",
      "evaluation/Rewards Max                  6.93816\n",
      "evaluation/Rewards Min                 -1.66396\n",
      "evaluation/Returns Mean              4674.26\n",
      "evaluation/Returns Std                113.846\n",
      "evaluation/Returns Max               4881.06\n",
      "evaluation/Returns Min               4503.41\n",
      "evaluation/Estimation Bias Mean      1168.58\n",
      "evaluation/Estimation Bias Std        142.202\n",
      "evaluation/EB/Q_True Mean              42.7702\n",
      "evaluation/EB/Q_True Std              132.224\n",
      "evaluation/EB/Q_Pred Mean            1211.35\n",
      "evaluation/EB/Q_Pred Std               50.9455\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4674.26\n",
      "evaluation/Actions Mean                 0.0260813\n",
      "evaluation/Actions Std                  0.536705\n",
      "evaluation/Actions Max                  0.999813\n",
      "evaluation/Actions Min                 -0.999873\n",
      "time/backward_policy (s)                1.96838\n",
      "time/backward_zf1 (s)                   2.10316\n",
      "time/backward_zf2 (s)                   2.02811\n",
      "time/data sampling (s)                  0.312052\n",
      "time/data storing (s)                   0.0144485\n",
      "time/evaluation sampling (s)            1.68256\n",
      "time/exploration sampling (s)           0.325188\n",
      "time/logging (s)                        0.011566\n",
      "time/preback_alpha (s)                  0.587522\n",
      "time/preback_policy (s)                 1.15611\n",
      "time/preback_start (s)                  0.149559\n",
      "time/preback_zf (s)                     5.1625\n",
      "time/saving (s)                         0.00639468\n",
      "time/training (s)                       2.29074\n",
      "time/epoch (s)                         17.7983\n",
      "time/total (s)                       3095.46\n",
      "Epoch                                 175\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:28:08.749971 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 176 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 187000\n",
      "trainer/ZF1 Loss                        3.73832\n",
      "trainer/ZF2 Loss                        4.08631\n",
      "trainer/ZF Expert Reward               18.6215\n",
      "trainer/ZF Policy Reward                7.6136\n",
      "trainer/ZF CHI2 Term                   47.4646\n",
      "trainer/Policy Loss                 -1054.54\n",
      "trainer/Bias Loss                     115.762\n",
      "trainer/Bias Value                     13.9852\n",
      "trainer/Policy Grad Norm              152.154\n",
      "trainer/Policy Param Norm              36.6061\n",
      "trainer/Zf1 Grad Norm                1669.44\n",
      "trainer/Zf1 Param Norm                110.277\n",
      "trainer/Zf2 Grad Norm                1379.56\n",
      "trainer/Zf2 Param Norm                113.039\n",
      "trainer/Z Expert Predictions Mean    1224.44\n",
      "trainer/Z Expert Predictions Std       91.9041\n",
      "trainer/Z Expert Predictions Max     1298.87\n",
      "trainer/Z Expert Predictions Min      -58.3808\n",
      "trainer/Z Policy Predictions Mean    1051.86\n",
      "trainer/Z Policy Predictions Std      364.447\n",
      "trainer/Z Policy Predictions Max     1287.16\n",
      "trainer/Z Policy Predictions Min     -361.214\n",
      "trainer/Z Expert Targets Mean        1205.82\n",
      "trainer/Z Expert Targets Std           89.3952\n",
      "trainer/Z Expert Targets Max         1286.91\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1044.24\n",
      "trainer/Z Policy Targets Std          359.168\n",
      "trainer/Z Policy Targets Max         1289.82\n",
      "trainer/Z Policy Targets Min         -356.868\n",
      "trainer/Log Pis Mean                   32.8731\n",
      "trainer/Log Pis Std                     9.19763\n",
      "trainer/Policy mu Mean                  0.0423296\n",
      "trainer/Policy mu Std                   2.1516\n",
      "trainer/Policy log std Mean            -4.36615\n",
      "trainer/Policy log std Std              1.19439\n",
      "exploration/num steps total        181444\n",
      "exploration/num paths total           308\n",
      "evaluation/num steps total              1.48488e+06\n",
      "evaluation/num paths total           1827\n",
      "evaluation/path length Mean           903\n",
      "evaluation/path length Std            291\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             30\n",
      "evaluation/Rewards Mean                 4.70131\n",
      "evaluation/Rewards Std                  1.03564\n",
      "evaluation/Rewards Max                  7.05873\n",
      "evaluation/Rewards Min                 -2.21931\n",
      "evaluation/Returns Mean              4245.29\n",
      "evaluation/Returns Std               1411.02\n",
      "evaluation/Returns Max               4895.67\n",
      "evaluation/Returns Min                 22.4573\n",
      "evaluation/Estimation Bias Mean      1156.28\n",
      "evaluation/Estimation Bias Std        161.183\n",
      "evaluation/EB/Q_True Mean              49.9568\n",
      "evaluation/EB/Q_True Std              145.501\n",
      "evaluation/EB/Q_Pred Mean            1206.23\n",
      "evaluation/EB/Q_Pred Std               56.0938\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4245.29\n",
      "evaluation/Actions Mean                 0.0313597\n",
      "evaluation/Actions Std                  0.539812\n",
      "evaluation/Actions Max                  0.999976\n",
      "evaluation/Actions Min                 -0.999866\n",
      "time/backward_policy (s)                1.85838\n",
      "time/backward_zf1 (s)                   2.02334\n",
      "time/backward_zf2 (s)                   1.94294\n",
      "time/data sampling (s)                  0.287422\n",
      "time/data storing (s)                   0.016588\n",
      "time/evaluation sampling (s)            1.71368\n",
      "time/exploration sampling (s)           0.331528\n",
      "time/logging (s)                        0.011469\n",
      "time/preback_alpha (s)                  0.586372\n",
      "time/preback_policy (s)                 1.08168\n",
      "time/preback_start (s)                  0.149897\n",
      "time/preback_zf (s)                     5.15764\n",
      "time/saving (s)                         0.00616012\n",
      "time/training (s)                       2.36537\n",
      "time/epoch (s)                         17.5325\n",
      "time/total (s)                       3113.01\n",
      "Epoch                                 176\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:28:26.788141 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 177 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 188000\n",
      "trainer/ZF1 Loss                      -12.2186\n",
      "trainer/ZF2 Loss                       -2.92432\n",
      "trainer/ZF Expert Reward               11.696\n",
      "trainer/ZF Policy Reward               -1.40947\n",
      "trainer/ZF CHI2 Term                   37.5465\n",
      "trainer/Policy Loss                 -1085.77\n",
      "trainer/Bias Loss                      76.5394\n",
      "trainer/Bias Value                     14.0367\n",
      "trainer/Policy Grad Norm              137.994\n",
      "trainer/Policy Param Norm              36.6433\n",
      "trainer/Zf1 Grad Norm                1134.01\n",
      "trainer/Zf1 Param Norm                110.46\n",
      "trainer/Zf2 Grad Norm                1846.87\n",
      "trainer/Zf2 Param Norm                113.225\n",
      "trainer/Z Expert Predictions Mean    1210.83\n",
      "trainer/Z Expert Predictions Std       50.6108\n",
      "trainer/Z Expert Predictions Max     1294.74\n",
      "trainer/Z Expert Predictions Min      961.386\n",
      "trainer/Z Policy Predictions Mean    1077.81\n",
      "trainer/Z Policy Predictions Std      294.84\n",
      "trainer/Z Policy Predictions Max     1284.09\n",
      "trainer/Z Policy Predictions Min     -303.598\n",
      "trainer/Z Expert Targets Mean        1199.13\n",
      "trainer/Z Expert Targets Std           53.5496\n",
      "trainer/Z Expert Targets Max         1281.3\n",
      "trainer/Z Expert Targets Min          923.047\n",
      "trainer/Z Policy Targets Mean        1079.22\n",
      "trainer/Z Policy Targets Std          288.043\n",
      "trainer/Z Policy Targets Max         1257.81\n",
      "trainer/Z Policy Targets Min         -290.005\n",
      "trainer/Log Pis Mean                   32.3359\n",
      "trainer/Log Pis Std                     8.78347\n",
      "trainer/Policy mu Mean                  0.0647124\n",
      "trainer/Policy mu Std                   1.84342\n",
      "trainer/Policy log std Mean            -4.43087\n",
      "trainer/Policy log std Std              0.984716\n",
      "exploration/num steps total        182444\n",
      "exploration/num paths total           309\n",
      "evaluation/num steps total              1.49409e+06\n",
      "evaluation/num paths total           1837\n",
      "evaluation/path length Mean           920.7\n",
      "evaluation/path length Std            237.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            207\n",
      "evaluation/Rewards Mean                 4.67982\n",
      "evaluation/Rewards Std                  1.16799\n",
      "evaluation/Rewards Max                  6.99759\n",
      "evaluation/Rewards Min                 -3.26239\n",
      "evaluation/Returns Mean              4308.71\n",
      "evaluation/Returns Std               1269.43\n",
      "evaluation/Returns Max               4906.06\n",
      "evaluation/Returns Min                515.267\n",
      "evaluation/Estimation Bias Mean      1155.55\n",
      "evaluation/Estimation Bias Std        170.551\n",
      "evaluation/EB/Q_True Mean              46.8581\n",
      "evaluation/EB/Q_True Std              138.063\n",
      "evaluation/EB/Q_Pred Mean            1202.41\n",
      "evaluation/EB/Q_Pred Std               80.9586\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4308.71\n",
      "evaluation/Actions Mean                 0.0155915\n",
      "evaluation/Actions Std                  0.543883\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94164\n",
      "time/backward_zf1 (s)                   2.10303\n",
      "time/backward_zf2 (s)                   2.01585\n",
      "time/data sampling (s)                  0.329543\n",
      "time/data storing (s)                   0.0159109\n",
      "time/evaluation sampling (s)            1.76725\n",
      "time/exploration sampling (s)           0.33705\n",
      "time/logging (s)                        0.0114185\n",
      "time/preback_alpha (s)                  0.587315\n",
      "time/preback_policy (s)                 1.1134\n",
      "time/preback_start (s)                  0.149754\n",
      "time/preback_zf (s)                     5.18094\n",
      "time/saving (s)                         0.00615019\n",
      "time/training (s)                       2.39919\n",
      "time/epoch (s)                         17.9584\n",
      "time/total (s)                       3131\n",
      "Epoch                                 177\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:28:44.558190 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 178 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 189000\n",
      "trainer/ZF1 Loss                       -0.493042\n",
      "trainer/ZF2 Loss                        7.13268\n",
      "trainer/ZF Expert Reward               12.14\n",
      "trainer/ZF Policy Reward                0.97091\n",
      "trainer/ZF CHI2 Term                   46.4984\n",
      "trainer/Policy Loss                 -1082.47\n",
      "trainer/Bias Loss                     111.06\n",
      "trainer/Bias Value                     14.023\n",
      "trainer/Policy Grad Norm              140.387\n",
      "trainer/Policy Param Norm              36.6828\n",
      "trainer/Zf1 Grad Norm                1577.74\n",
      "trainer/Zf1 Param Norm                110.648\n",
      "trainer/Zf2 Grad Norm                1592.05\n",
      "trainer/Zf2 Param Norm                113.428\n",
      "trainer/Z Expert Predictions Mean    1216.51\n",
      "trainer/Z Expert Predictions Std       84.0197\n",
      "trainer/Z Expert Predictions Max     1317.2\n",
      "trainer/Z Expert Predictions Min       20.9659\n",
      "trainer/Z Policy Predictions Mean    1072.78\n",
      "trainer/Z Policy Predictions Std      325.611\n",
      "trainer/Z Policy Predictions Max     1283.98\n",
      "trainer/Z Policy Predictions Min     -363.959\n",
      "trainer/Z Expert Targets Mean        1204.37\n",
      "trainer/Z Expert Targets Std           85.1281\n",
      "trainer/Z Expert Targets Max         1296.3\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1071.81\n",
      "trainer/Z Policy Targets Std          322.543\n",
      "trainer/Z Policy Targets Max         1278.92\n",
      "trainer/Z Policy Targets Min         -374.414\n",
      "trainer/Log Pis Mean                   32.3327\n",
      "trainer/Log Pis Std                     7.77613\n",
      "trainer/Policy mu Mean                  0.0784633\n",
      "trainer/Policy mu Std                   1.67759\n",
      "trainer/Policy log std Mean            -4.4419\n",
      "trainer/Policy log std Std              0.986492\n",
      "exploration/num steps total        184444\n",
      "exploration/num paths total           311\n",
      "evaluation/num steps total              1.50389e+06\n",
      "evaluation/num paths total           1848\n",
      "evaluation/path length Mean           891.091\n",
      "evaluation/path length Std            257.938\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            132\n",
      "evaluation/Rewards Mean                 4.77022\n",
      "evaluation/Rewards Std                  0.947258\n",
      "evaluation/Rewards Max                  6.7431\n",
      "evaluation/Rewards Min                 -1.4824\n",
      "evaluation/Returns Mean              4250.7\n",
      "evaluation/Returns Std               1244.57\n",
      "evaluation/Returns Max               4912.88\n",
      "evaluation/Returns Min                551.902\n",
      "evaluation/Estimation Bias Mean      1164.33\n",
      "evaluation/Estimation Bias Std        141.891\n",
      "evaluation/EB/Q_True Mean              43.8878\n",
      "evaluation/EB/Q_True Std              134.554\n",
      "evaluation/EB/Q_Pred Mean            1208.22\n",
      "evaluation/EB/Q_Pred Std               47.8817\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4250.7\n",
      "evaluation/Actions Mean                 0.0288897\n",
      "evaluation/Actions Std                  0.538419\n",
      "evaluation/Actions Max                  0.999576\n",
      "evaluation/Actions Min                 -0.99992\n",
      "time/backward_policy (s)                1.89341\n",
      "time/backward_zf1 (s)                   2.07736\n",
      "time/backward_zf2 (s)                   1.97417\n",
      "time/data sampling (s)                  0.319361\n",
      "time/data storing (s)                   0.0144306\n",
      "time/evaluation sampling (s)            1.71688\n",
      "time/exploration sampling (s)           0.323273\n",
      "time/logging (s)                        0.0119519\n",
      "time/preback_alpha (s)                  0.589898\n",
      "time/preback_policy (s)                 1.10818\n",
      "time/preback_start (s)                  0.149399\n",
      "time/preback_zf (s)                     5.1748\n",
      "time/saving (s)                         0.00625602\n",
      "time/training (s)                       2.34146\n",
      "time/epoch (s)                         17.7008\n",
      "time/total (s)                       3148.72\n",
      "Epoch                                 178\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:29:02.389192 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 179 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 190000\n",
      "trainer/ZF1 Loss                       -3.24215\n",
      "trainer/ZF2 Loss                        8.80915\n",
      "trainer/ZF Expert Reward               11.1452\n",
      "trainer/ZF Policy Reward                2.36584\n",
      "trainer/ZF CHI2 Term                   42.9022\n",
      "trainer/Policy Loss                 -1095.08\n",
      "trainer/Bias Loss                     105.13\n",
      "trainer/Bias Value                     14.0199\n",
      "trainer/Policy Grad Norm              125.778\n",
      "trainer/Policy Param Norm              36.7175\n",
      "trainer/Zf1 Grad Norm                1102.61\n",
      "trainer/Zf1 Param Norm                110.854\n",
      "trainer/Zf2 Grad Norm                1552.86\n",
      "trainer/Zf2 Param Norm                113.609\n",
      "trainer/Z Expert Predictions Mean    1216.1\n",
      "trainer/Z Expert Predictions Std       44.0984\n",
      "trainer/Z Expert Predictions Max     1285.94\n",
      "trainer/Z Expert Predictions Min      962.731\n",
      "trainer/Z Policy Predictions Mean    1088.86\n",
      "trainer/Z Policy Predictions Std      288.713\n",
      "trainer/Z Policy Predictions Max     1290.02\n",
      "trainer/Z Policy Predictions Min     -299.779\n",
      "trainer/Z Expert Targets Mean        1204.95\n",
      "trainer/Z Expert Targets Std           46.1104\n",
      "trainer/Z Expert Targets Max         1288.68\n",
      "trainer/Z Expert Targets Min          961.025\n",
      "trainer/Z Policy Targets Mean        1086.49\n",
      "trainer/Z Policy Targets Std          284.011\n",
      "trainer/Z Policy Targets Max         1274.48\n",
      "trainer/Z Policy Targets Min         -286.265\n",
      "trainer/Log Pis Mean                   31.6559\n",
      "trainer/Log Pis Std                     7.8892\n",
      "trainer/Policy mu Mean                  0.0457681\n",
      "trainer/Policy mu Std                   1.88336\n",
      "trainer/Policy log std Mean            -4.46367\n",
      "trainer/Policy log std Std              1.09139\n",
      "exploration/num steps total        184444\n",
      "exploration/num paths total           311\n",
      "evaluation/num steps total              1.51389e+06\n",
      "evaluation/num paths total           1858\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.73753\n",
      "evaluation/Rewards Std                  1.04602\n",
      "evaluation/Rewards Max                  6.78687\n",
      "evaluation/Rewards Min                 -2.15151\n",
      "evaluation/Returns Mean              4737.53\n",
      "evaluation/Returns Std                109.137\n",
      "evaluation/Returns Max               4867.69\n",
      "evaluation/Returns Min               4528.72\n",
      "evaluation/Estimation Bias Mean      1153.93\n",
      "evaluation/Estimation Bias Std        150.292\n",
      "evaluation/EB/Q_True Mean              44.5766\n",
      "evaluation/EB/Q_True Std              137.484\n",
      "evaluation/EB/Q_Pred Mean            1198.51\n",
      "evaluation/EB/Q_Pred Std               58.5928\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4737.53\n",
      "evaluation/Actions Mean                 0.0183796\n",
      "evaluation/Actions Std                  0.527455\n",
      "evaluation/Actions Max                  0.999955\n",
      "evaluation/Actions Min                 -0.999945\n",
      "time/backward_policy (s)                2.01669\n",
      "time/backward_zf1 (s)                   2.14642\n",
      "time/backward_zf2 (s)                   2.08052\n",
      "time/data sampling (s)                  0.308978\n",
      "time/data storing (s)                   0.0146371\n",
      "time/evaluation sampling (s)            1.70061\n",
      "time/exploration sampling (s)           0.318346\n",
      "time/logging (s)                        0.0121154\n",
      "time/preback_alpha (s)                  0.57683\n",
      "time/preback_policy (s)                 1.17905\n",
      "time/preback_start (s)                  0.146952\n",
      "time/preback_zf (s)                     5.11362\n",
      "time/saving (s)                         0.00635147\n",
      "time/training (s)                       2.14143\n",
      "time/epoch (s)                         17.7626\n",
      "time/total (s)                       3166.5\n",
      "Epoch                                 179\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:29:20.333229 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 180 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 191000\n",
      "trainer/ZF1 Loss                       -6.51967\n",
      "trainer/ZF2 Loss                       -8.30828\n",
      "trainer/ZF Expert Reward               17.6345\n",
      "trainer/ZF Policy Reward                4.90917\n",
      "trainer/ZF CHI2 Term                   36.7311\n",
      "trainer/Policy Loss                 -1092.75\n",
      "trainer/Bias Loss                      82.4536\n",
      "trainer/Bias Value                     14.0283\n",
      "trainer/Policy Grad Norm              125.85\n",
      "trainer/Policy Param Norm              36.7528\n",
      "trainer/Zf1 Grad Norm                1280.23\n",
      "trainer/Zf1 Param Norm                111.04\n",
      "trainer/Zf2 Grad Norm                1017.77\n",
      "trainer/Zf2 Param Norm                113.789\n",
      "trainer/Z Expert Predictions Mean    1212.19\n",
      "trainer/Z Expert Predictions Std       87.4198\n",
      "trainer/Z Expert Predictions Max     1299.57\n",
      "trainer/Z Expert Predictions Min       43.217\n",
      "trainer/Z Policy Predictions Mean    1087.66\n",
      "trainer/Z Policy Predictions Std      296.007\n",
      "trainer/Z Policy Predictions Max     1283.41\n",
      "trainer/Z Policy Predictions Min     -370.882\n",
      "trainer/Z Expert Targets Mean        1194.56\n",
      "trainer/Z Expert Targets Std           89.4264\n",
      "trainer/Z Expert Targets Max         1277.19\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1082.75\n",
      "trainer/Z Policy Targets Std          291.313\n",
      "trainer/Z Policy Targets Max         1270.03\n",
      "trainer/Z Policy Targets Min         -367.052\n",
      "trainer/Log Pis Mean                   31.7372\n",
      "trainer/Log Pis Std                     9.12496\n",
      "trainer/Policy mu Mean                  0.0200959\n",
      "trainer/Policy mu Std                   1.83502\n",
      "trainer/Policy log std Mean            -4.46763\n",
      "trainer/Policy log std Std              0.953334\n",
      "exploration/num steps total        184444\n",
      "exploration/num paths total           311\n",
      "evaluation/num steps total              1.52318e+06\n",
      "evaluation/num paths total           1868\n",
      "evaluation/path length Mean           928.8\n",
      "evaluation/path length Std            209.959\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            299\n",
      "evaluation/Rewards Mean                 4.73257\n",
      "evaluation/Rewards Std                  0.999356\n",
      "evaluation/Rewards Max                  7.04684\n",
      "evaluation/Rewards Min                 -1.68149\n",
      "evaluation/Returns Mean              4395.61\n",
      "evaluation/Returns Std               1012.69\n",
      "evaluation/Returns Max               4864.6\n",
      "evaluation/Returns Min               1374.41\n",
      "evaluation/Estimation Bias Mean      1163.83\n",
      "evaluation/Estimation Bias Std        147.465\n",
      "evaluation/EB/Q_True Mean              44.8911\n",
      "evaluation/EB/Q_True Std              132.887\n",
      "evaluation/EB/Q_Pred Mean            1208.72\n",
      "evaluation/EB/Q_Pred Std               62.8623\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4395.61\n",
      "evaluation/Actions Mean                 0.0318345\n",
      "evaluation/Actions Std                  0.543131\n",
      "evaluation/Actions Max                  0.99988\n",
      "evaluation/Actions Min                 -0.999935\n",
      "time/backward_policy (s)                1.9486\n",
      "time/backward_zf1 (s)                   2.10111\n",
      "time/backward_zf2 (s)                   2.02935\n",
      "time/data sampling (s)                  0.303777\n",
      "time/data storing (s)                   0.0152412\n",
      "time/evaluation sampling (s)            1.72572\n",
      "time/exploration sampling (s)           0.323098\n",
      "time/logging (s)                        0.0109982\n",
      "time/preback_alpha (s)                  0.593529\n",
      "time/preback_policy (s)                 1.15287\n",
      "time/preback_start (s)                  0.149346\n",
      "time/preback_zf (s)                     5.23505\n",
      "time/saving (s)                         0.0061246\n",
      "time/training (s)                       2.27389\n",
      "time/epoch (s)                         17.8687\n",
      "time/total (s)                       3184.39\n",
      "Epoch                                 180\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:29:38.185253 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 181 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 192000\n",
      "trainer/ZF1 Loss                        3.28199\n",
      "trainer/ZF2 Loss                       -6.27665\n",
      "trainer/ZF Expert Reward               17.0428\n",
      "trainer/ZF Policy Reward                5.34671\n",
      "trainer/ZF CHI2 Term                   41.397\n",
      "trainer/Policy Loss                 -1107.61\n",
      "trainer/Bias Loss                      49.5937\n",
      "trainer/Bias Value                     14.0498\n",
      "trainer/Policy Grad Norm              147.515\n",
      "trainer/Policy Param Norm              36.7906\n",
      "trainer/Zf1 Grad Norm                3441.78\n",
      "trainer/Zf1 Param Norm                111.211\n",
      "trainer/Zf2 Grad Norm                1099.81\n",
      "trainer/Zf2 Param Norm                113.97\n",
      "trainer/Z Expert Predictions Mean    1220.32\n",
      "trainer/Z Expert Predictions Std       40.8908\n",
      "trainer/Z Expert Predictions Max     1297.43\n",
      "trainer/Z Expert Predictions Min      953.807\n",
      "trainer/Z Policy Predictions Mean    1101.11\n",
      "trainer/Z Policy Predictions Std      255.996\n",
      "trainer/Z Policy Predictions Max     1271.92\n",
      "trainer/Z Policy Predictions Min     -316.747\n",
      "trainer/Z Expert Targets Mean        1203.27\n",
      "trainer/Z Expert Targets Std           40.6598\n",
      "trainer/Z Expert Targets Max         1275.9\n",
      "trainer/Z Expert Targets Min          952.574\n",
      "trainer/Z Policy Targets Mean        1095.76\n",
      "trainer/Z Policy Targets Std          249.864\n",
      "trainer/Z Policy Targets Max         1271.42\n",
      "trainer/Z Policy Targets Min         -303.936\n",
      "trainer/Log Pis Mean                   31.5133\n",
      "trainer/Log Pis Std                     6.65916\n",
      "trainer/Policy mu Mean                  0.0519824\n",
      "trainer/Policy mu Std                   1.41011\n",
      "trainer/Policy log std Mean            -4.51082\n",
      "trainer/Policy log std Std              0.894699\n",
      "exploration/num steps total        186444\n",
      "exploration/num paths total           313\n",
      "evaluation/num steps total              1.53318e+06\n",
      "evaluation/num paths total           1878\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69865\n",
      "evaluation/Rewards Std                  0.962827\n",
      "evaluation/Rewards Max                  6.73996\n",
      "evaluation/Rewards Min                 -1.88579\n",
      "evaluation/Returns Mean              4698.65\n",
      "evaluation/Returns Std                127.175\n",
      "evaluation/Returns Max               4903.33\n",
      "evaluation/Returns Min               4417.36\n",
      "evaluation/Estimation Bias Mean      1157.02\n",
      "evaluation/Estimation Bias Std        146.753\n",
      "evaluation/EB/Q_True Mean              44.2076\n",
      "evaluation/EB/Q_True Std              136.01\n",
      "evaluation/EB/Q_Pred Mean            1201.23\n",
      "evaluation/EB/Q_Pred Std               50.9709\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4698.65\n",
      "evaluation/Actions Mean                 0.0248451\n",
      "evaluation/Actions Std                  0.536393\n",
      "evaluation/Actions Max                  0.999774\n",
      "evaluation/Actions Min                 -0.999847\n",
      "time/backward_policy (s)                1.89745\n",
      "time/backward_zf1 (s)                   2.04063\n",
      "time/backward_zf2 (s)                   1.93819\n",
      "time/data sampling (s)                  0.329234\n",
      "time/data storing (s)                   0.0152303\n",
      "time/evaluation sampling (s)            1.75054\n",
      "time/exploration sampling (s)           0.337567\n",
      "time/logging (s)                        0.0129401\n",
      "time/preback_alpha (s)                  0.588122\n",
      "time/preback_policy (s)                 1.05546\n",
      "time/preback_start (s)                  0.150065\n",
      "time/preback_zf (s)                     5.18842\n",
      "time/saving (s)                         0.00608981\n",
      "time/training (s)                       2.47195\n",
      "time/epoch (s)                         17.7819\n",
      "time/total (s)                       3202.2\n",
      "Epoch                                 181\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:29:56.003613 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 182 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 193000\n",
      "trainer/ZF1 Loss                        0.580608\n",
      "trainer/ZF2 Loss                        6.54738\n",
      "trainer/ZF Expert Reward               13.1616\n",
      "trainer/ZF Policy Reward                3.15483\n",
      "trainer/ZF CHI2 Term                   45.697\n",
      "trainer/Policy Loss                 -1068.95\n",
      "trainer/Bias Loss                      97.8492\n",
      "trainer/Bias Value                     14.0368\n",
      "trainer/Policy Grad Norm              120.317\n",
      "trainer/Policy Param Norm              36.8284\n",
      "trainer/Zf1 Grad Norm                1871.17\n",
      "trainer/Zf1 Param Norm                111.374\n",
      "trainer/Zf2 Grad Norm                1813.84\n",
      "trainer/Zf2 Param Norm                114.159\n",
      "trainer/Z Expert Predictions Mean    1202.52\n",
      "trainer/Z Expert Predictions Std       95.135\n",
      "trainer/Z Expert Predictions Max     1288.26\n",
      "trainer/Z Expert Predictions Min     -118.882\n",
      "trainer/Z Policy Predictions Mean    1064.36\n",
      "trainer/Z Policy Predictions Std      322.47\n",
      "trainer/Z Policy Predictions Max     1282.25\n",
      "trainer/Z Policy Predictions Min     -347.767\n",
      "trainer/Z Expert Targets Mean        1189.35\n",
      "trainer/Z Expert Targets Std           89.6639\n",
      "trainer/Z Expert Targets Max         1272.69\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1061.21\n",
      "trainer/Z Policy Targets Std          319.215\n",
      "trainer/Z Policy Targets Max         1260.65\n",
      "trainer/Z Policy Targets Min         -342.311\n",
      "trainer/Log Pis Mean                   32.4507\n",
      "trainer/Log Pis Std                     8.80439\n",
      "trainer/Policy mu Mean                  0.0616613\n",
      "trainer/Policy mu Std                   1.8297\n",
      "trainer/Policy log std Mean            -4.43501\n",
      "trainer/Policy log std Std              0.995707\n",
      "exploration/num steps total        188444\n",
      "exploration/num paths total           315\n",
      "evaluation/num steps total              1.54166e+06\n",
      "evaluation/num paths total           1889\n",
      "evaluation/path length Mean           771.091\n",
      "evaluation/path length Std            375.51\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             64\n",
      "evaluation/Rewards Mean                 4.71886\n",
      "evaluation/Rewards Std                  1.06583\n",
      "evaluation/Rewards Max                  6.9296\n",
      "evaluation/Rewards Min                 -1.57424\n",
      "evaluation/Returns Mean              3638.67\n",
      "evaluation/Returns Std               1858.03\n",
      "evaluation/Returns Max               4899.93\n",
      "evaluation/Returns Min                154.449\n",
      "evaluation/Estimation Bias Mean      1139.64\n",
      "evaluation/Estimation Bias Std        169.86\n",
      "evaluation/EB/Q_True Mean              51.8292\n",
      "evaluation/EB/Q_True Std              145.722\n",
      "evaluation/EB/Q_Pred Mean            1191.47\n",
      "evaluation/EB/Q_Pred Std               65.1183\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3638.67\n",
      "evaluation/Actions Mean                 0.0235429\n",
      "evaluation/Actions Std                  0.535062\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -0.999968\n",
      "time/backward_policy (s)                1.88137\n",
      "time/backward_zf1 (s)                   2.0526\n",
      "time/backward_zf2 (s)                   1.96084\n",
      "time/data sampling (s)                  0.300184\n",
      "time/data storing (s)                   0.0152463\n",
      "time/evaluation sampling (s)            1.75043\n",
      "time/exploration sampling (s)           0.334071\n",
      "time/logging (s)                        0.0101746\n",
      "time/preback_alpha (s)                  0.581092\n",
      "time/preback_policy (s)                 1.10246\n",
      "time/preback_start (s)                  0.149743\n",
      "time/preback_zf (s)                     5.16554\n",
      "time/saving (s)                         0.00651598\n",
      "time/training (s)                       2.43776\n",
      "time/epoch (s)                         17.748\n",
      "time/total (s)                       3219.96\n",
      "Epoch                                 182\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:30:13.753787 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 183 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 194000\n",
      "trainer/ZF1 Loss                      225.161\n",
      "trainer/ZF2 Loss                      238.169\n",
      "trainer/ZF Expert Reward               13.6516\n",
      "trainer/ZF Policy Reward                7.12298\n",
      "trainer/ZF CHI2 Term                  270.564\n",
      "trainer/Policy Loss                 -1086.64\n",
      "trainer/Bias Loss                      49.5838\n",
      "trainer/Bias Value                     14.0269\n",
      "trainer/Policy Grad Norm              107.971\n",
      "trainer/Policy Param Norm              36.8626\n",
      "trainer/Zf1 Grad Norm                2043.99\n",
      "trainer/Zf1 Param Norm                111.566\n",
      "trainer/Zf2 Grad Norm                2331.39\n",
      "trainer/Zf2 Param Norm                114.34\n",
      "trainer/Z Expert Predictions Mean    1211.59\n",
      "trainer/Z Expert Predictions Std       43.1424\n",
      "trainer/Z Expert Predictions Max     1295.65\n",
      "trainer/Z Expert Predictions Min      876.839\n",
      "trainer/Z Policy Predictions Mean    1083.21\n",
      "trainer/Z Policy Predictions Std      282.627\n",
      "trainer/Z Policy Predictions Max     1268.64\n",
      "trainer/Z Policy Predictions Min     -365.866\n",
      "trainer/Z Expert Targets Mean        1197.93\n",
      "trainer/Z Expert Targets Std           43.8355\n",
      "trainer/Z Expert Targets Max         1278.46\n",
      "trainer/Z Expert Targets Min          862.952\n",
      "trainer/Z Policy Targets Mean        1076.08\n",
      "trainer/Z Policy Targets Std          284.095\n",
      "trainer/Z Policy Targets Max         1270.07\n",
      "trainer/Z Policy Targets Min         -332.598\n",
      "trainer/Log Pis Mean                   32.6973\n",
      "trainer/Log Pis Std                     7.97576\n",
      "trainer/Policy mu Mean                  0.0971029\n",
      "trainer/Policy mu Std                   1.6556\n",
      "trainer/Policy log std Mean            -4.5633\n",
      "trainer/Policy log std Std              0.955925\n",
      "exploration/num steps total        189444\n",
      "exploration/num paths total           316\n",
      "evaluation/num steps total              1.55166e+06\n",
      "evaluation/num paths total           1899\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.56337\n",
      "evaluation/Rewards Std                  1.40263\n",
      "evaluation/Rewards Max                  7.10181\n",
      "evaluation/Rewards Min                 -3.94612\n",
      "evaluation/Returns Mean              4563.37\n",
      "evaluation/Returns Std                463.492\n",
      "evaluation/Returns Max               4970.39\n",
      "evaluation/Returns Min               3236.72\n",
      "evaluation/Estimation Bias Mean      1124.02\n",
      "evaluation/Estimation Bias Std        251.826\n",
      "evaluation/EB/Q_True Mean              42.3782\n",
      "evaluation/EB/Q_True Std              130.284\n",
      "evaluation/EB/Q_Pred Mean            1166.4\n",
      "evaluation/EB/Q_Pred Std              188.655\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4563.37\n",
      "evaluation/Actions Mean                 0.0245384\n",
      "evaluation/Actions Std                  0.549415\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91325\n",
      "time/backward_zf1 (s)                   2.05616\n",
      "time/backward_zf2 (s)                   1.98845\n",
      "time/data sampling (s)                  0.318526\n",
      "time/data storing (s)                   0.0156308\n",
      "time/evaluation sampling (s)            1.74367\n",
      "time/exploration sampling (s)           0.335672\n",
      "time/logging (s)                        0.0129832\n",
      "time/preback_alpha (s)                  0.576447\n",
      "time/preback_policy (s)                 1.1314\n",
      "time/preback_start (s)                  0.14788\n",
      "time/preback_zf (s)                     5.15102\n",
      "time/saving (s)                         0.00639876\n",
      "time/training (s)                       2.28844\n",
      "time/epoch (s)                         17.6859\n",
      "time/total (s)                       3237.67\n",
      "Epoch                                 183\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:30:31.583707 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 184 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 195000\n",
      "trainer/ZF1 Loss                        8.46356\n",
      "trainer/ZF2 Loss                        1.22927\n",
      "trainer/ZF Expert Reward                7.95792\n",
      "trainer/ZF Policy Reward               -2.06301\n",
      "trainer/ZF CHI2 Term                   47.2555\n",
      "trainer/Policy Loss                 -1036.56\n",
      "trainer/Bias Loss                      70.6152\n",
      "trainer/Bias Value                     14.0167\n",
      "trainer/Policy Grad Norm              134.445\n",
      "trainer/Policy Param Norm              36.8967\n",
      "trainer/Zf1 Grad Norm                2196.49\n",
      "trainer/Zf1 Param Norm                111.746\n",
      "trainer/Zf2 Grad Norm                2048.69\n",
      "trainer/Zf2 Param Norm                114.526\n",
      "trainer/Z Expert Predictions Mean    1202.22\n",
      "trainer/Z Expert Predictions Std       39.7373\n",
      "trainer/Z Expert Predictions Max     1278.26\n",
      "trainer/Z Expert Predictions Min      988.105\n",
      "trainer/Z Policy Predictions Mean    1030.28\n",
      "trainer/Z Policy Predictions Std      349.557\n",
      "trainer/Z Policy Predictions Max     1271.04\n",
      "trainer/Z Policy Predictions Min     -359.143\n",
      "trainer/Z Expert Targets Mean        1194.26\n",
      "trainer/Z Expert Targets Std           41.3892\n",
      "trainer/Z Expert Targets Max         1268.71\n",
      "trainer/Z Expert Targets Min          964.877\n",
      "trainer/Z Policy Targets Mean        1032.34\n",
      "trainer/Z Policy Targets Std          347.202\n",
      "trainer/Z Policy Targets Max         1264.42\n",
      "trainer/Z Policy Targets Min         -336.243\n",
      "trainer/Log Pis Mean                   32.7153\n",
      "trainer/Log Pis Std                     8.05705\n",
      "trainer/Policy mu Mean                  0.060967\n",
      "trainer/Policy mu Std                   2.0196\n",
      "trainer/Policy log std Mean            -4.39895\n",
      "trainer/Policy log std Std              1.12002\n",
      "exploration/num steps total        191777\n",
      "exploration/num paths total           319\n",
      "evaluation/num steps total              1.55988e+06\n",
      "evaluation/num paths total           1909\n",
      "evaluation/path length Mean           822.3\n",
      "evaluation/path length Std            356.175\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             59\n",
      "evaluation/Rewards Mean                 4.63824\n",
      "evaluation/Rewards Std                  1.04273\n",
      "evaluation/Rewards Max                  6.74175\n",
      "evaluation/Rewards Min                 -1.78807\n",
      "evaluation/Returns Mean              3814.03\n",
      "evaluation/Returns Std               1723.42\n",
      "evaluation/Returns Max               4863.01\n",
      "evaluation/Returns Min                188.855\n",
      "evaluation/Estimation Bias Mean      1139.41\n",
      "evaluation/Estimation Bias Std        167.266\n",
      "evaluation/EB/Q_True Mean              52.7559\n",
      "evaluation/EB/Q_True Std              146.257\n",
      "evaluation/EB/Q_Pred Mean            1192.16\n",
      "evaluation/EB/Q_Pred Std               64.9648\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3814.03\n",
      "evaluation/Actions Mean                 0.0165464\n",
      "evaluation/Actions Std                  0.535947\n",
      "evaluation/Actions Max                  0.999907\n",
      "evaluation/Actions Min                 -0.999873\n",
      "time/backward_policy (s)                1.93464\n",
      "time/backward_zf1 (s)                   2.08049\n",
      "time/backward_zf2 (s)                   2.01264\n",
      "time/data sampling (s)                  0.312349\n",
      "time/data storing (s)                   0.0156825\n",
      "time/evaluation sampling (s)            1.71339\n",
      "time/exploration sampling (s)           0.342673\n",
      "time/logging (s)                        0.0100243\n",
      "time/preback_alpha (s)                  0.578755\n",
      "time/preback_policy (s)                 1.09763\n",
      "time/preback_start (s)                  0.148978\n",
      "time/preback_zf (s)                     5.14901\n",
      "time/saving (s)                         0.00585768\n",
      "time/training (s)                       2.35515\n",
      "time/epoch (s)                         17.7573\n",
      "time/total (s)                       3255.44\n",
      "Epoch                                 184\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:30:49.279652 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 185 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 196000\n",
      "trainer/ZF1 Loss                       -7.84693\n",
      "trainer/ZF2 Loss                       -4.03173\n",
      "trainer/ZF Expert Reward               14.0541\n",
      "trainer/ZF Policy Reward                2.09966\n",
      "trainer/ZF CHI2 Term                   38.731\n",
      "trainer/Policy Loss                 -1048.71\n",
      "trainer/Bias Loss                      61.1477\n",
      "trainer/Bias Value                     14.0027\n",
      "trainer/Policy Grad Norm              113.778\n",
      "trainer/Policy Param Norm              36.935\n",
      "trainer/Zf1 Grad Norm                1648.55\n",
      "trainer/Zf1 Param Norm                111.936\n",
      "trainer/Zf2 Grad Norm                2043.53\n",
      "trainer/Zf2 Param Norm                114.713\n",
      "trainer/Z Expert Predictions Mean    1196.55\n",
      "trainer/Z Expert Predictions Std       66.214\n",
      "trainer/Z Expert Predictions Max     1277.05\n",
      "trainer/Z Expert Predictions Min      415.202\n",
      "trainer/Z Policy Predictions Mean    1040.79\n",
      "trainer/Z Policy Predictions Std      367.155\n",
      "trainer/Z Policy Predictions Max     1272.97\n",
      "trainer/Z Policy Predictions Min     -370.516\n",
      "trainer/Z Expert Targets Mean        1182.5\n",
      "trainer/Z Expert Targets Std           67.9038\n",
      "trainer/Z Expert Targets Max         1260.51\n",
      "trainer/Z Expert Targets Min          391.518\n",
      "trainer/Z Policy Targets Mean        1038.69\n",
      "trainer/Z Policy Targets Std          361.89\n",
      "trainer/Z Policy Targets Max         1266.68\n",
      "trainer/Z Policy Targets Min         -373.416\n",
      "trainer/Log Pis Mean                   33.0464\n",
      "trainer/Log Pis Std                     9.853\n",
      "trainer/Policy mu Mean                  0.0826521\n",
      "trainer/Policy mu Std                   2.03374\n",
      "trainer/Policy log std Mean            -4.39043\n",
      "trainer/Policy log std Std              1.13088\n",
      "exploration/num steps total        191777\n",
      "exploration/num paths total           319\n",
      "evaluation/num steps total              1.56988e+06\n",
      "evaluation/num paths total           1919\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69914\n",
      "evaluation/Rewards Std                  0.941778\n",
      "evaluation/Rewards Max                  6.78365\n",
      "evaluation/Rewards Min                 -1.77415\n",
      "evaluation/Returns Mean              4699.14\n",
      "evaluation/Returns Std                 74.1512\n",
      "evaluation/Returns Max               4822.39\n",
      "evaluation/Returns Min               4556.64\n",
      "evaluation/Estimation Bias Mean      1154.36\n",
      "evaluation/Estimation Bias Std        148.614\n",
      "evaluation/EB/Q_True Mean              44.0865\n",
      "evaluation/EB/Q_True Std              135.813\n",
      "evaluation/EB/Q_Pred Mean            1198.44\n",
      "evaluation/EB/Q_Pred Std               46.4285\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4699.14\n",
      "evaluation/Actions Mean                 0.0235186\n",
      "evaluation/Actions Std                  0.525265\n",
      "evaluation/Actions Max                  0.999546\n",
      "evaluation/Actions Min                 -0.999695\n",
      "time/backward_policy (s)                1.93707\n",
      "time/backward_zf1 (s)                   2.08635\n",
      "time/backward_zf2 (s)                   2.01276\n",
      "time/data sampling (s)                  0.31214\n",
      "time/data storing (s)                   0.0155921\n",
      "time/evaluation sampling (s)            1.69658\n",
      "time/exploration sampling (s)           0.33675\n",
      "time/logging (s)                        0.0130671\n",
      "time/preback_alpha (s)                  0.583497\n",
      "time/preback_policy (s)                 1.16266\n",
      "time/preback_start (s)                  0.150194\n",
      "time/preback_zf (s)                     5.13831\n",
      "time/saving (s)                         0.00653792\n",
      "time/training (s)                       2.17526\n",
      "time/epoch (s)                         17.6268\n",
      "time/total (s)                       3273.09\n",
      "Epoch                                 185\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:31:07.076507 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 186 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 197000\n",
      "trainer/ZF1 Loss                      301.833\n",
      "trainer/ZF2 Loss                      301.579\n",
      "trainer/ZF Expert Reward               17.385\n",
      "trainer/ZF Policy Reward               12.4986\n",
      "trainer/ZF CHI2 Term                  338.481\n",
      "trainer/Policy Loss                 -1109.87\n",
      "trainer/Bias Loss                      77.0981\n",
      "trainer/Bias Value                     13.997\n",
      "trainer/Policy Grad Norm              134.12\n",
      "trainer/Policy Param Norm              36.9712\n",
      "trainer/Zf1 Grad Norm                1924.79\n",
      "trainer/Zf1 Param Norm                112.127\n",
      "trainer/Zf2 Grad Norm                1843.46\n",
      "trainer/Zf2 Param Norm                114.909\n",
      "trainer/Z Expert Predictions Mean    1203.2\n",
      "trainer/Z Expert Predictions Std       49.7252\n",
      "trainer/Z Expert Predictions Max     1281.92\n",
      "trainer/Z Expert Predictions Min      972.313\n",
      "trainer/Z Policy Predictions Mean    1109.2\n",
      "trainer/Z Policy Predictions Std      268.331\n",
      "trainer/Z Policy Predictions Max     1272.45\n",
      "trainer/Z Policy Predictions Min     -410.534\n",
      "trainer/Z Expert Targets Mean        1185.82\n",
      "trainer/Z Expert Targets Std           50.2437\n",
      "trainer/Z Expert Targets Max         1266.91\n",
      "trainer/Z Expert Targets Min          955.348\n",
      "trainer/Z Policy Targets Mean        1096.7\n",
      "trainer/Z Policy Targets Std          274.01\n",
      "trainer/Z Policy Targets Max         1261.51\n",
      "trainer/Z Policy Targets Min         -408.481\n",
      "trainer/Log Pis Mean                   32.2099\n",
      "trainer/Log Pis Std                     6.67829\n",
      "trainer/Policy mu Mean                  0.0300528\n",
      "trainer/Policy mu Std                   1.58497\n",
      "trainer/Policy log std Mean            -4.60021\n",
      "trainer/Policy log std Std              0.958945\n",
      "exploration/num steps total        191777\n",
      "exploration/num paths total           319\n",
      "evaluation/num steps total              1.57988e+06\n",
      "evaluation/num paths total           1929\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.74721\n",
      "evaluation/Rewards Std                  0.970429\n",
      "evaluation/Rewards Max                  6.9021\n",
      "evaluation/Rewards Min                 -1.60848\n",
      "evaluation/Returns Mean              4747.21\n",
      "evaluation/Returns Std                 87.8126\n",
      "evaluation/Returns Max               4884.57\n",
      "evaluation/Returns Min               4560.52\n",
      "evaluation/Estimation Bias Mean      1153.75\n",
      "evaluation/Estimation Bias Std        143.278\n",
      "evaluation/EB/Q_True Mean              43.423\n",
      "evaluation/EB/Q_True Std              133.443\n",
      "evaluation/EB/Q_Pred Mean            1197.17\n",
      "evaluation/EB/Q_Pred Std               49.6641\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4747.21\n",
      "evaluation/Actions Mean                 0.0236115\n",
      "evaluation/Actions Std                  0.544708\n",
      "evaluation/Actions Max                  0.999859\n",
      "evaluation/Actions Min                 -0.999826\n",
      "time/backward_policy (s)                1.97314\n",
      "time/backward_zf1 (s)                   2.13577\n",
      "time/backward_zf2 (s)                   2.07605\n",
      "time/data sampling (s)                  0.303555\n",
      "time/data storing (s)                   0.0147944\n",
      "time/evaluation sampling (s)            1.75417\n",
      "time/exploration sampling (s)           0.328487\n",
      "time/logging (s)                        0.0121552\n",
      "time/preback_alpha (s)                  0.574508\n",
      "time/preback_policy (s)                 1.20188\n",
      "time/preback_start (s)                  0.147321\n",
      "time/preback_zf (s)                     5.12072\n",
      "time/saving (s)                         0.00644701\n",
      "time/training (s)                       2.07619\n",
      "time/epoch (s)                         17.7252\n",
      "time/total (s)                       3290.84\n",
      "Epoch                                 186\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:31:24.693501 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 187 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 198000\n",
      "trainer/ZF1 Loss                        1.83264\n",
      "trainer/ZF2 Loss                        0.430542\n",
      "trainer/ZF Expert Reward               15.741\n",
      "trainer/ZF Policy Reward                4.21384\n",
      "trainer/ZF CHI2 Term                   44.8092\n",
      "trainer/Policy Loss                 -1074.57\n",
      "trainer/Bias Loss                      59.696\n",
      "trainer/Bias Value                     13.9861\n",
      "trainer/Policy Grad Norm              117.849\n",
      "trainer/Policy Param Norm              37.0092\n",
      "trainer/Zf1 Grad Norm                1012.24\n",
      "trainer/Zf1 Param Norm                112.32\n",
      "trainer/Zf2 Grad Norm                1148.55\n",
      "trainer/Zf2 Param Norm                115.102\n",
      "trainer/Z Expert Predictions Mean    1206\n",
      "trainer/Z Expert Predictions Std       44.1947\n",
      "trainer/Z Expert Predictions Max     1295.89\n",
      "trainer/Z Expert Predictions Min      917.087\n",
      "trainer/Z Policy Predictions Mean    1071.68\n",
      "trainer/Z Policy Predictions Std      325.258\n",
      "trainer/Z Policy Predictions Max     1269.78\n",
      "trainer/Z Policy Predictions Min     -370.305\n",
      "trainer/Z Expert Targets Mean        1190.26\n",
      "trainer/Z Expert Targets Std           43.5863\n",
      "trainer/Z Expert Targets Max         1274.23\n",
      "trainer/Z Expert Targets Min          907.075\n",
      "trainer/Z Policy Targets Mean        1067.46\n",
      "trainer/Z Policy Targets Std          320.308\n",
      "trainer/Z Policy Targets Max         1253.73\n",
      "trainer/Z Policy Targets Min         -355.952\n",
      "trainer/Log Pis Mean                   32.4751\n",
      "trainer/Log Pis Std                     8.83448\n",
      "trainer/Policy mu Mean                  0.00102955\n",
      "trainer/Policy mu Std                   1.8906\n",
      "trainer/Policy log std Mean            -4.50229\n",
      "trainer/Policy log std Std              1.10329\n",
      "exploration/num steps total        192777\n",
      "exploration/num paths total           320\n",
      "evaluation/num steps total              1.58988e+06\n",
      "evaluation/num paths total           1939\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.73126\n",
      "evaluation/Rewards Std                  1.00472\n",
      "evaluation/Rewards Max                  6.8128\n",
      "evaluation/Rewards Min                 -2.97103\n",
      "evaluation/Returns Mean              4731.26\n",
      "evaluation/Returns Std                 68.9939\n",
      "evaluation/Returns Max               4830.07\n",
      "evaluation/Returns Min               4587.53\n",
      "evaluation/Estimation Bias Mean      1149.46\n",
      "evaluation/Estimation Bias Std        142.767\n",
      "evaluation/EB/Q_True Mean              43.1742\n",
      "evaluation/EB/Q_True Std              133.11\n",
      "evaluation/EB/Q_Pred Mean            1192.64\n",
      "evaluation/EB/Q_Pred Std               53.9506\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4731.26\n",
      "evaluation/Actions Mean                 0.0205121\n",
      "evaluation/Actions Std                  0.546617\n",
      "evaluation/Actions Max                  0.999944\n",
      "evaluation/Actions Min                 -0.999832\n",
      "time/backward_policy (s)                1.92341\n",
      "time/backward_zf1 (s)                   2.05432\n",
      "time/backward_zf2 (s)                   1.99952\n",
      "time/data sampling (s)                  0.301821\n",
      "time/data storing (s)                   0.0152763\n",
      "time/evaluation sampling (s)            1.76954\n",
      "time/exploration sampling (s)           0.334196\n",
      "time/logging (s)                        0.0118979\n",
      "time/preback_alpha (s)                  0.572515\n",
      "time/preback_policy (s)                 1.13619\n",
      "time/preback_start (s)                  0.147492\n",
      "time/preback_zf (s)                     5.10598\n",
      "time/saving (s)                         0.00638128\n",
      "time/training (s)                       2.15617\n",
      "time/epoch (s)                         17.5347\n",
      "time/total (s)                       3308.41\n",
      "Epoch                                 187\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:31:42.149205 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 188 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 199000\n",
      "trainer/ZF1 Loss                        0.304531\n",
      "trainer/ZF2 Loss                       -2.90584\n",
      "trainer/ZF Expert Reward               11.1402\n",
      "trainer/ZF Policy Reward                0.281125\n",
      "trainer/ZF CHI2 Term                   41.2099\n",
      "trainer/Policy Loss                 -1077.71\n",
      "trainer/Bias Loss                     110.456\n",
      "trainer/Bias Value                     13.9987\n",
      "trainer/Policy Grad Norm              158.725\n",
      "trainer/Policy Param Norm              37.0452\n",
      "trainer/Zf1 Grad Norm                5038.01\n",
      "trainer/Zf1 Param Norm                112.495\n",
      "trainer/Zf2 Grad Norm                1567.65\n",
      "trainer/Zf2 Param Norm                115.272\n",
      "trainer/Z Expert Predictions Mean    1196.5\n",
      "trainer/Z Expert Predictions Std       43.0569\n",
      "trainer/Z Expert Predictions Max     1274.48\n",
      "trainer/Z Expert Predictions Min      942.249\n",
      "trainer/Z Policy Predictions Mean    1073.93\n",
      "trainer/Z Policy Predictions Std      284.689\n",
      "trainer/Z Policy Predictions Max     1246.47\n",
      "trainer/Z Policy Predictions Min     -341.692\n",
      "trainer/Z Expert Targets Mean        1185.36\n",
      "trainer/Z Expert Targets Std           46.8947\n",
      "trainer/Z Expert Targets Max         1268.68\n",
      "trainer/Z Expert Targets Min          945.435\n",
      "trainer/Z Policy Targets Mean        1073.65\n",
      "trainer/Z Policy Targets Std          284.482\n",
      "trainer/Z Policy Targets Max         1242.47\n",
      "trainer/Z Policy Targets Min         -334.294\n",
      "trainer/Log Pis Mean                   31.9712\n",
      "trainer/Log Pis Std                     6.93613\n",
      "trainer/Policy mu Mean                  0.0847713\n",
      "trainer/Policy mu Std                   1.53669\n",
      "trainer/Policy log std Mean            -4.54208\n",
      "trainer/Policy log std Std              0.989258\n",
      "exploration/num steps total        194777\n",
      "exploration/num paths total           322\n",
      "evaluation/num steps total              1.59988e+06\n",
      "evaluation/num paths total           1949\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63071\n",
      "evaluation/Rewards Std                  0.942869\n",
      "evaluation/Rewards Max                  6.6717\n",
      "evaluation/Rewards Min                 -1.67973\n",
      "evaluation/Returns Mean              4630.71\n",
      "evaluation/Returns Std                 97.7988\n",
      "evaluation/Returns Max               4793.5\n",
      "evaluation/Returns Min               4479.02\n",
      "evaluation/Estimation Bias Mean      1147.07\n",
      "evaluation/Estimation Bias Std        137.61\n",
      "evaluation/EB/Q_True Mean              41.4021\n",
      "evaluation/EB/Q_True Std              127.971\n",
      "evaluation/EB/Q_Pred Mean            1188.47\n",
      "evaluation/EB/Q_Pred Std               48.6674\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4630.71\n",
      "evaluation/Actions Mean                 0.020791\n",
      "evaluation/Actions Std                  0.531964\n",
      "evaluation/Actions Max                  0.999509\n",
      "evaluation/Actions Min                 -0.999787\n",
      "time/backward_policy (s)                1.82984\n",
      "time/backward_zf1 (s)                   1.96639\n",
      "time/backward_zf2 (s)                   1.89506\n",
      "time/data sampling (s)                  0.281951\n",
      "time/data storing (s)                   0.014129\n",
      "time/evaluation sampling (s)            1.75238\n",
      "time/exploration sampling (s)           0.328142\n",
      "time/logging (s)                        0.0122426\n",
      "time/preback_alpha (s)                  0.567931\n",
      "time/preback_policy (s)                 1.0709\n",
      "time/preback_start (s)                  0.146834\n",
      "time/preback_zf (s)                     5.11614\n",
      "time/saving (s)                         0.00644566\n",
      "time/training (s)                       2.3964\n",
      "time/epoch (s)                         17.3848\n",
      "time/total (s)                       3325.82\n",
      "Epoch                                 188\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:31:59.892440 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 189 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 200000\n",
      "trainer/ZF1 Loss                        9.26459\n",
      "trainer/ZF2 Loss                        4.30272\n",
      "trainer/ZF Expert Reward               17.574\n",
      "trainer/ZF Policy Reward                5.55551\n",
      "trainer/ZF CHI2 Term                   51.9597\n",
      "trainer/Policy Loss                 -1022.55\n",
      "trainer/Bias Loss                     139.611\n",
      "trainer/Bias Value                     13.9925\n",
      "trainer/Policy Grad Norm              133.724\n",
      "trainer/Policy Param Norm              37.0821\n",
      "trainer/Zf1 Grad Norm                1611.5\n",
      "trainer/Zf1 Param Norm                112.685\n",
      "trainer/Zf2 Grad Norm                1304.92\n",
      "trainer/Zf2 Param Norm                115.473\n",
      "trainer/Z Expert Predictions Mean    1201.31\n",
      "trainer/Z Expert Predictions Std       86.5656\n",
      "trainer/Z Expert Predictions Max     1287.46\n",
      "trainer/Z Expert Predictions Min      -54.3689\n",
      "trainer/Z Policy Predictions Mean    1017.95\n",
      "trainer/Z Policy Predictions Std      378.923\n",
      "trainer/Z Policy Predictions Max     1253.35\n",
      "trainer/Z Policy Predictions Min     -467.173\n",
      "trainer/Z Expert Targets Mean        1183.73\n",
      "trainer/Z Expert Targets Std           83.8008\n",
      "trainer/Z Expert Targets Max         1279.87\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1012.39\n",
      "trainer/Z Policy Targets Std          370.476\n",
      "trainer/Z Policy Targets Max         1240.52\n",
      "trainer/Z Policy Targets Min         -447.366\n",
      "trainer/Log Pis Mean                   33.4924\n",
      "trainer/Log Pis Std                     9.76342\n",
      "trainer/Policy mu Mean                  0.1115\n",
      "trainer/Policy mu Std                   2.28195\n",
      "trainer/Policy log std Mean            -4.33932\n",
      "trainer/Policy log std Std              1.28916\n",
      "exploration/num steps total        194777\n",
      "exploration/num paths total           322\n",
      "evaluation/num steps total              1.60988e+06\n",
      "evaluation/num paths total           1959\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.8477\n",
      "evaluation/Rewards Std                  2.39161\n",
      "evaluation/Rewards Max                  6.69191\n",
      "evaluation/Rewards Min                 -3.88267\n",
      "evaluation/Returns Mean              3847.7\n",
      "evaluation/Returns Std               2182.75\n",
      "evaluation/Returns Max               4804.46\n",
      "evaluation/Returns Min              -2692.45\n",
      "evaluation/Estimation Bias Mean      1000.56\n",
      "evaluation/Estimation Bias Std        440.35\n",
      "evaluation/EB/Q_True Mean              42.226\n",
      "evaluation/EB/Q_True Std              129.976\n",
      "evaluation/EB/Q_Pred Mean            1042.79\n",
      "evaluation/EB/Q_Pred Std              434.585\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3847.7\n",
      "evaluation/Actions Mean                -0.00569834\n",
      "evaluation/Actions Std                  0.593117\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93206\n",
      "time/backward_zf1 (s)                   2.1069\n",
      "time/backward_zf2 (s)                   2.00835\n",
      "time/data sampling (s)                  0.303897\n",
      "time/data storing (s)                   0.0142855\n",
      "time/evaluation sampling (s)            1.75193\n",
      "time/exploration sampling (s)           0.319535\n",
      "time/logging (s)                        0.0118892\n",
      "time/preback_alpha (s)                  0.578347\n",
      "time/preback_policy (s)                 1.15799\n",
      "time/preback_start (s)                  0.14908\n",
      "time/preback_zf (s)                     5.15358\n",
      "time/saving (s)                         0.00640215\n",
      "time/training (s)                       2.17787\n",
      "time/epoch (s)                         17.6721\n",
      "time/total (s)                       3343.51\n",
      "Epoch                                 189\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:32:17.176121 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 190 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 201000\n",
      "trainer/ZF1 Loss                       -9.45267\n",
      "trainer/ZF2 Loss                        1.70599\n",
      "trainer/ZF Expert Reward               13.3185\n",
      "trainer/ZF Policy Reward                0.199797\n",
      "trainer/ZF CHI2 Term                   41.1433\n",
      "trainer/Policy Loss                 -1043.34\n",
      "trainer/Bias Loss                      63.5613\n",
      "trainer/Bias Value                     13.9897\n",
      "trainer/Policy Grad Norm              112.912\n",
      "trainer/Policy Param Norm              37.1157\n",
      "trainer/Zf1 Grad Norm                1325\n",
      "trainer/Zf1 Param Norm                112.871\n",
      "trainer/Zf2 Grad Norm                1822.22\n",
      "trainer/Zf2 Param Norm                115.639\n",
      "trainer/Z Expert Predictions Mean    1195.84\n",
      "trainer/Z Expert Predictions Std       45.0902\n",
      "trainer/Z Expert Predictions Max     1278.21\n",
      "trainer/Z Expert Predictions Min      982.947\n",
      "trainer/Z Policy Predictions Mean    1038.59\n",
      "trainer/Z Policy Predictions Std      333.269\n",
      "trainer/Z Policy Predictions Max     1266.02\n",
      "trainer/Z Policy Predictions Min     -455.648\n",
      "trainer/Z Expert Targets Mean        1182.53\n",
      "trainer/Z Expert Targets Std           45.9676\n",
      "trainer/Z Expert Targets Max         1258.11\n",
      "trainer/Z Expert Targets Min          959.875\n",
      "trainer/Z Policy Targets Mean        1038.39\n",
      "trainer/Z Policy Targets Std          330.689\n",
      "trainer/Z Policy Targets Max         1246.67\n",
      "trainer/Z Policy Targets Min         -447.807\n",
      "trainer/Log Pis Mean                   32.2202\n",
      "trainer/Log Pis Std                     7.0853\n",
      "trainer/Policy mu Mean                  0.0240202\n",
      "trainer/Policy mu Std                   1.7237\n",
      "trainer/Policy log std Mean            -4.50564\n",
      "trainer/Policy log std Std              1.0664\n",
      "exploration/num steps total        194777\n",
      "exploration/num paths total           322\n",
      "evaluation/num steps total              1.61988e+06\n",
      "evaluation/num paths total           1969\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.61952\n",
      "evaluation/Rewards Std                  0.950746\n",
      "evaluation/Rewards Max                  6.53297\n",
      "evaluation/Rewards Min                 -1.62725\n",
      "evaluation/Returns Mean              4619.52\n",
      "evaluation/Returns Std                101.65\n",
      "evaluation/Returns Max               4802.15\n",
      "evaluation/Returns Min               4479.02\n",
      "evaluation/Estimation Bias Mean      1132.4\n",
      "evaluation/Estimation Bias Std        136.823\n",
      "evaluation/EB/Q_True Mean              42.6897\n",
      "evaluation/EB/Q_True Std              131.401\n",
      "evaluation/EB/Q_Pred Mean            1175.09\n",
      "evaluation/EB/Q_Pred Std               48.0365\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4619.52\n",
      "evaluation/Actions Mean                 0.0286099\n",
      "evaluation/Actions Std                  0.526812\n",
      "evaluation/Actions Max                  0.999664\n",
      "evaluation/Actions Min                 -0.999784\n",
      "time/backward_policy (s)                1.7831\n",
      "time/backward_zf1 (s)                   1.92754\n",
      "time/backward_zf2 (s)                   1.85326\n",
      "time/data sampling (s)                  0.277407\n",
      "time/data storing (s)                   0.0154945\n",
      "time/evaluation sampling (s)            1.72818\n",
      "time/exploration sampling (s)           0.329696\n",
      "time/logging (s)                        0.0116322\n",
      "time/preback_alpha (s)                  0.567286\n",
      "time/preback_policy (s)                 1.0128\n",
      "time/preback_start (s)                  0.145549\n",
      "time/preback_zf (s)                     5.11196\n",
      "time/saving (s)                         0.00633933\n",
      "time/training (s)                       2.44687\n",
      "time/epoch (s)                         17.2171\n",
      "time/total (s)                       3360.75\n",
      "Epoch                                 190\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:32:34.421371 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 191 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 202000\n",
      "trainer/ZF1 Loss                       -2.14083\n",
      "trainer/ZF2 Loss                       -5.21959\n",
      "trainer/ZF Expert Reward               16.3232\n",
      "trainer/ZF Policy Reward                5.54277\n",
      "trainer/ZF CHI2 Term                   38.9857\n",
      "trainer/Policy Loss                 -1077.7\n",
      "trainer/Bias Loss                      64.1443\n",
      "trainer/Bias Value                     14.0306\n",
      "trainer/Policy Grad Norm              128.902\n",
      "trainer/Policy Param Norm              37.1528\n",
      "trainer/Zf1 Grad Norm                1682.46\n",
      "trainer/Zf1 Param Norm                113.065\n",
      "trainer/Zf2 Grad Norm                1215.75\n",
      "trainer/Zf2 Param Norm                115.826\n",
      "trainer/Z Expert Predictions Mean    1192.81\n",
      "trainer/Z Expert Predictions Std       44.0943\n",
      "trainer/Z Expert Predictions Max     1270.09\n",
      "trainer/Z Expert Predictions Min      924.479\n",
      "trainer/Z Policy Predictions Mean    1073.46\n",
      "trainer/Z Policy Predictions Std      268.477\n",
      "trainer/Z Policy Predictions Max     1261.55\n",
      "trainer/Z Policy Predictions Min     -381.099\n",
      "trainer/Z Expert Targets Mean        1176.49\n",
      "trainer/Z Expert Targets Std           45.376\n",
      "trainer/Z Expert Targets Max         1255.2\n",
      "trainer/Z Expert Targets Min          896.884\n",
      "trainer/Z Policy Targets Mean        1067.92\n",
      "trainer/Z Policy Targets Std          266.319\n",
      "trainer/Z Policy Targets Max         1254.89\n",
      "trainer/Z Policy Targets Min         -380.628\n",
      "trainer/Log Pis Mean                   32.2076\n",
      "trainer/Log Pis Std                     8.56575\n",
      "trainer/Policy mu Mean                  0.0756423\n",
      "trainer/Policy mu Std                   1.6647\n",
      "trainer/Policy log std Mean            -4.59022\n",
      "trainer/Policy log std Std              0.94791\n",
      "exploration/num steps total        195777\n",
      "exploration/num paths total           323\n",
      "evaluation/num steps total              1.62944e+06\n",
      "evaluation/num paths total           1979\n",
      "evaluation/path length Mean           956.1\n",
      "evaluation/path length Std            131.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            561\n",
      "evaluation/Rewards Mean                 4.72665\n",
      "evaluation/Rewards Std                  1.01219\n",
      "evaluation/Rewards Max                  6.94992\n",
      "evaluation/Rewards Min                 -2.71932\n",
      "evaluation/Returns Mean              4519.15\n",
      "evaluation/Returns Std                643.923\n",
      "evaluation/Returns Max               4886.98\n",
      "evaluation/Returns Min               2598.51\n",
      "evaluation/Estimation Bias Mean      1129.77\n",
      "evaluation/Estimation Bias Std        156.082\n",
      "evaluation/EB/Q_True Mean              46.8333\n",
      "evaluation/EB/Q_True Std              140.542\n",
      "evaluation/EB/Q_Pred Mean            1176.6\n",
      "evaluation/EB/Q_Pred Std               57.5771\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4519.15\n",
      "evaluation/Actions Mean                 0.0178427\n",
      "evaluation/Actions Std                  0.5372\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81188\n",
      "time/backward_zf1 (s)                   1.94556\n",
      "time/backward_zf2 (s)                   1.86855\n",
      "time/data sampling (s)                  0.266875\n",
      "time/data storing (s)                   0.0150016\n",
      "time/evaluation sampling (s)            1.70248\n",
      "time/exploration sampling (s)           0.324895\n",
      "time/logging (s)                        0.0120307\n",
      "time/preback_alpha (s)                  0.565122\n",
      "time/preback_policy (s)                 1.04463\n",
      "time/preback_start (s)                  0.146462\n",
      "time/preback_zf (s)                     5.11872\n",
      "time/saving (s)                         0.00634399\n",
      "time/training (s)                       2.35121\n",
      "time/epoch (s)                         17.1798\n",
      "time/total (s)                       3377.94\n",
      "Epoch                                 191\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:32:51.914534 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 192 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 203000\n",
      "trainer/ZF1 Loss                       -5.86108\n",
      "trainer/ZF2 Loss                       -6.82703\n",
      "trainer/ZF Expert Reward               15.1308\n",
      "trainer/ZF Policy Reward                2.29077\n",
      "trainer/ZF CHI2 Term                   37.9907\n",
      "trainer/Policy Loss                 -1049.74\n",
      "trainer/Bias Loss                      47.9998\n",
      "trainer/Bias Value                     14.0238\n",
      "trainer/Policy Grad Norm              132.103\n",
      "trainer/Policy Param Norm              37.1851\n",
      "trainer/Zf1 Grad Norm                1199.41\n",
      "trainer/Zf1 Param Norm                113.252\n",
      "trainer/Zf2 Grad Norm                1308.96\n",
      "trainer/Zf2 Param Norm                116.008\n",
      "trainer/Z Expert Predictions Mean    1187.55\n",
      "trainer/Z Expert Predictions Std       86.6938\n",
      "trainer/Z Expert Predictions Max     1265.36\n",
      "trainer/Z Expert Predictions Min       63.3393\n",
      "trainer/Z Policy Predictions Mean    1041.42\n",
      "trainer/Z Policy Predictions Std      326.464\n",
      "trainer/Z Policy Predictions Max     1237\n",
      "trainer/Z Policy Predictions Min     -532.259\n",
      "trainer/Z Expert Targets Mean        1172.42\n",
      "trainer/Z Expert Targets Std           90.0029\n",
      "trainer/Z Expert Targets Max         1248.06\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1039.13\n",
      "trainer/Z Policy Targets Std          319.856\n",
      "trainer/Z Policy Targets Max         1245.88\n",
      "trainer/Z Policy Targets Min         -521.14\n",
      "trainer/Log Pis Mean                   31.8128\n",
      "trainer/Log Pis Std                     7.80062\n",
      "trainer/Policy mu Mean                  0.0886775\n",
      "trainer/Policy mu Std                   1.89875\n",
      "trainer/Policy log std Mean            -4.38289\n",
      "trainer/Policy log std Std              1.19508\n",
      "exploration/num steps total        197777\n",
      "exploration/num paths total           325\n",
      "evaluation/num steps total              1.63944e+06\n",
      "evaluation/num paths total           1989\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.73914\n",
      "evaluation/Rewards Std                  0.952077\n",
      "evaluation/Rewards Max                  6.85016\n",
      "evaluation/Rewards Min                 -1.66903\n",
      "evaluation/Returns Mean              4739.14\n",
      "evaluation/Returns Std                118.897\n",
      "evaluation/Returns Max               4923.78\n",
      "evaluation/Returns Min               4604.57\n",
      "evaluation/Estimation Bias Mean      1136.73\n",
      "evaluation/Estimation Bias Std        146.594\n",
      "evaluation/EB/Q_True Mean              44.8755\n",
      "evaluation/EB/Q_True Std              138.121\n",
      "evaluation/EB/Q_Pred Mean            1181.61\n",
      "evaluation/EB/Q_Pred Std               50.3569\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4739.14\n",
      "evaluation/Actions Mean                 0.0220878\n",
      "evaluation/Actions Std                  0.537598\n",
      "evaluation/Actions Max                  0.999823\n",
      "evaluation/Actions Min                 -0.999921\n",
      "time/backward_policy (s)                1.92898\n",
      "time/backward_zf1 (s)                   2.08323\n",
      "time/backward_zf2 (s)                   2.00182\n",
      "time/data sampling (s)                  0.289797\n",
      "time/data storing (s)                   0.0143078\n",
      "time/evaluation sampling (s)            1.72777\n",
      "time/exploration sampling (s)           0.327598\n",
      "time/logging (s)                        0.0120735\n",
      "time/preback_alpha (s)                  0.564598\n",
      "time/preback_policy (s)                 1.1259\n",
      "time/preback_start (s)                  0.145691\n",
      "time/preback_zf (s)                     5.0706\n",
      "time/saving (s)                         0.00644344\n",
      "time/training (s)                       2.12431\n",
      "time/epoch (s)                         17.4231\n",
      "time/total (s)                       3395.39\n",
      "Epoch                                 192\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:33:09.014537 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 193 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 204000\n",
      "trainer/ZF1 Loss                        1.27321\n",
      "trainer/ZF2 Loss                        3.14868\n",
      "trainer/ZF Expert Reward               11.6231\n",
      "trainer/ZF Policy Reward                1.49167\n",
      "trainer/ZF CHI2 Term                   43.8774\n",
      "trainer/Policy Loss                 -1062.96\n",
      "trainer/Bias Loss                      64.8624\n",
      "trainer/Bias Value                     14.0445\n",
      "trainer/Policy Grad Norm              133.385\n",
      "trainer/Policy Param Norm              37.2189\n",
      "trainer/Zf1 Grad Norm                2052.01\n",
      "trainer/Zf1 Param Norm                113.438\n",
      "trainer/Zf2 Grad Norm                2158.47\n",
      "trainer/Zf2 Param Norm                116.205\n",
      "trainer/Z Expert Predictions Mean    1181.26\n",
      "trainer/Z Expert Predictions Std       84.1449\n",
      "trainer/Z Expert Predictions Max     1263.22\n",
      "trainer/Z Expert Predictions Min        4.46391\n",
      "trainer/Z Policy Predictions Mean    1060.03\n",
      "trainer/Z Policy Predictions Std      303.362\n",
      "trainer/Z Policy Predictions Max     1252.59\n",
      "trainer/Z Policy Predictions Min     -525.773\n",
      "trainer/Z Expert Targets Mean        1169.64\n",
      "trainer/Z Expert Targets Std           85.1047\n",
      "trainer/Z Expert Targets Max         1252.7\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1058.53\n",
      "trainer/Z Policy Targets Std          301.571\n",
      "trainer/Z Policy Targets Max         1238.82\n",
      "trainer/Z Policy Targets Min         -518.383\n",
      "trainer/Log Pis Mean                   31.8536\n",
      "trainer/Log Pis Std                     5.70358\n",
      "trainer/Policy mu Mean                  0.0742479\n",
      "trainer/Policy mu Std                   1.43173\n",
      "trainer/Policy log std Mean            -4.50292\n",
      "trainer/Policy log std Std              0.956565\n",
      "exploration/num steps total        198777\n",
      "exploration/num paths total           326\n",
      "evaluation/num steps total              1.64775e+06\n",
      "evaluation/num paths total           1999\n",
      "evaluation/path length Mean           830.6\n",
      "evaluation/path length Std            269.951\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            304\n",
      "evaluation/Rewards Mean                 4.74943\n",
      "evaluation/Rewards Std                  1.06591\n",
      "evaluation/Rewards Max                  7.11832\n",
      "evaluation/Rewards Min                 -2.17332\n",
      "evaluation/Returns Mean              3944.88\n",
      "evaluation/Returns Std               1326.33\n",
      "evaluation/Returns Max               4885.38\n",
      "evaluation/Returns Min               1355.47\n",
      "evaluation/Estimation Bias Mean      1110.93\n",
      "evaluation/Estimation Bias Std        163.028\n",
      "evaluation/EB/Q_True Mean              53.4283\n",
      "evaluation/EB/Q_True Std              148.435\n",
      "evaluation/EB/Q_Pred Mean            1164.36\n",
      "evaluation/EB/Q_Pred Std               60.7657\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3944.88\n",
      "evaluation/Actions Mean                 0.0195829\n",
      "evaluation/Actions Std                  0.532664\n",
      "evaluation/Actions Max                  0.999754\n",
      "evaluation/Actions Min                 -0.99985\n",
      "time/backward_policy (s)                1.71344\n",
      "time/backward_zf1 (s)                   1.87406\n",
      "time/backward_zf2 (s)                   1.78552\n",
      "time/data sampling (s)                  0.296513\n",
      "time/data storing (s)                   0.0144699\n",
      "time/evaluation sampling (s)            1.70687\n",
      "time/exploration sampling (s)           0.319028\n",
      "time/logging (s)                        0.0111186\n",
      "time/preback_alpha (s)                  0.565678\n",
      "time/preback_policy (s)                 0.967321\n",
      "time/preback_start (s)                  0.145434\n",
      "time/preback_zf (s)                     5.10098\n",
      "time/saving (s)                         0.00588172\n",
      "time/training (s)                       2.5262\n",
      "time/epoch (s)                         17.0325\n",
      "time/total (s)                       3412.44\n",
      "Epoch                                 193\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:33:26.445288 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 194 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 205000\n",
      "trainer/ZF1 Loss                        5.34391\n",
      "trainer/ZF2 Loss                       -5.64474\n",
      "trainer/ZF Expert Reward               11.7528\n",
      "trainer/ZF Policy Reward                3.0095\n",
      "trainer/ZF CHI2 Term                   39.9844\n",
      "trainer/Policy Loss                 -1087.04\n",
      "trainer/Bias Loss                      96.509\n",
      "trainer/Bias Value                     14.0418\n",
      "trainer/Policy Grad Norm              155.909\n",
      "trainer/Policy Param Norm              37.2496\n",
      "trainer/Zf1 Grad Norm                2745.77\n",
      "trainer/Zf1 Param Norm                113.625\n",
      "trainer/Zf2 Grad Norm                1344.88\n",
      "trainer/Zf2 Param Norm                116.359\n",
      "trainer/Z Expert Predictions Mean    1179.96\n",
      "trainer/Z Expert Predictions Std       91.186\n",
      "trainer/Z Expert Predictions Max     1256.83\n",
      "trainer/Z Expert Predictions Min     -106.985\n",
      "trainer/Z Policy Predictions Mean    1081.65\n",
      "trainer/Z Policy Predictions Std      262.594\n",
      "trainer/Z Policy Predictions Max     1263.44\n",
      "trainer/Z Policy Predictions Min     -550.55\n",
      "trainer/Z Expert Targets Mean        1168.21\n",
      "trainer/Z Expert Targets Std           85.5275\n",
      "trainer/Z Expert Targets Max         1246.33\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1078.64\n",
      "trainer/Z Policy Targets Std          257.365\n",
      "trainer/Z Policy Targets Max         1256.64\n",
      "trainer/Z Policy Targets Min         -537.506\n",
      "trainer/Log Pis Mean                   31.7087\n",
      "trainer/Log Pis Std                     5.67722\n",
      "trainer/Policy mu Mean                  0.0467269\n",
      "trainer/Policy mu Std                   1.34843\n",
      "trainer/Policy log std Mean            -4.60115\n",
      "trainer/Policy log std Std              0.844905\n",
      "exploration/num steps total        201777\n",
      "exploration/num paths total           329\n",
      "evaluation/num steps total              1.65733e+06\n",
      "evaluation/num paths total           2009\n",
      "evaluation/path length Mean           958.4\n",
      "evaluation/path length Std            124.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            584\n",
      "evaluation/Rewards Mean                 4.68222\n",
      "evaluation/Rewards Std                  0.972643\n",
      "evaluation/Rewards Max                  6.80001\n",
      "evaluation/Rewards Min                 -1.66642\n",
      "evaluation/Returns Mean              4487.44\n",
      "evaluation/Returns Std                547.675\n",
      "evaluation/Returns Max               4796.58\n",
      "evaluation/Returns Min               2859.38\n",
      "evaluation/Estimation Bias Mean      1130.58\n",
      "evaluation/Estimation Bias Std        146.656\n",
      "evaluation/EB/Q_True Mean              44.9147\n",
      "evaluation/EB/Q_True Std              135.562\n",
      "evaluation/EB/Q_Pred Mean            1175.5\n",
      "evaluation/EB/Q_Pred Std               50.3227\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4487.44\n",
      "evaluation/Actions Mean                 0.0212954\n",
      "evaluation/Actions Std                  0.536287\n",
      "evaluation/Actions Max                  0.999977\n",
      "evaluation/Actions Min                 -0.999854\n",
      "time/backward_policy (s)                1.85431\n",
      "time/backward_zf1 (s)                   1.99314\n",
      "time/backward_zf2 (s)                   1.9165\n",
      "time/data sampling (s)                  0.290423\n",
      "time/data storing (s)                   0.01457\n",
      "time/evaluation sampling (s)            1.73882\n",
      "time/exploration sampling (s)           0.335315\n",
      "time/logging (s)                        0.0117657\n",
      "time/preback_alpha (s)                  0.568478\n",
      "time/preback_policy (s)                 1.07426\n",
      "time/preback_start (s)                  0.148119\n",
      "time/preback_zf (s)                     5.08288\n",
      "time/saving (s)                         0.00655767\n",
      "time/training (s)                       2.32523\n",
      "time/epoch (s)                         17.3604\n",
      "time/total (s)                       3429.82\n",
      "Epoch                                 194\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:33:43.986511 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 195 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 206000\n",
      "trainer/ZF1 Loss                       15.6662\n",
      "trainer/ZF2 Loss                       20.2243\n",
      "trainer/ZF Expert Reward               16.5252\n",
      "trainer/ZF Policy Reward                7.62194\n",
      "trainer/ZF CHI2 Term                   58.8275\n",
      "trainer/Policy Loss                 -1041.44\n",
      "trainer/Bias Loss                     108.322\n",
      "trainer/Bias Value                     14.0668\n",
      "trainer/Policy Grad Norm              182.327\n",
      "trainer/Policy Param Norm              37.283\n",
      "trainer/Zf1 Grad Norm                8801.17\n",
      "trainer/Zf1 Param Norm                113.797\n",
      "trainer/Zf2 Grad Norm                9338.17\n",
      "trainer/Zf2 Param Norm                116.542\n",
      "trainer/Z Expert Predictions Mean    1178.07\n",
      "trainer/Z Expert Predictions Std       86.154\n",
      "trainer/Z Expert Predictions Max     1283.25\n",
      "trainer/Z Expert Predictions Min       80.8969\n",
      "trainer/Z Policy Predictions Mean    1035.11\n",
      "trainer/Z Policy Predictions Std      348.523\n",
      "trainer/Z Policy Predictions Max     1259.16\n",
      "trainer/Z Policy Predictions Min     -570.914\n",
      "trainer/Z Expert Targets Mean        1161.54\n",
      "trainer/Z Expert Targets Std           90.8326\n",
      "trainer/Z Expert Targets Max         1265.38\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1027.48\n",
      "trainer/Z Policy Targets Std          344.78\n",
      "trainer/Z Policy Targets Max         1269.28\n",
      "trainer/Z Policy Targets Min         -564.076\n",
      "trainer/Log Pis Mean                   32.302\n",
      "trainer/Log Pis Std                     7.8343\n",
      "trainer/Policy mu Mean                  0.0818596\n",
      "trainer/Policy mu Std                   1.74241\n",
      "trainer/Policy log std Mean            -4.49529\n",
      "trainer/Policy log std Std              1.04694\n",
      "exploration/num steps total        201777\n",
      "exploration/num paths total           329\n",
      "evaluation/num steps total              1.66733e+06\n",
      "evaluation/num paths total           2019\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.72251\n",
      "evaluation/Rewards Std                  0.966201\n",
      "evaluation/Rewards Max                  6.80079\n",
      "evaluation/Rewards Min                 -2.6793\n",
      "evaluation/Returns Mean              4722.51\n",
      "evaluation/Returns Std                 93.1215\n",
      "evaluation/Returns Max               4846.72\n",
      "evaluation/Returns Min               4548.29\n",
      "evaluation/Estimation Bias Mean      1127\n",
      "evaluation/Estimation Bias Std        145.671\n",
      "evaluation/EB/Q_True Mean              44.2199\n",
      "evaluation/EB/Q_True Std              136.163\n",
      "evaluation/EB/Q_Pred Mean            1171.22\n",
      "evaluation/EB/Q_Pred Std               50.4825\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4722.51\n",
      "evaluation/Actions Mean                 0.0220916\n",
      "evaluation/Actions Std                  0.539799\n",
      "evaluation/Actions Max                  0.999865\n",
      "evaluation/Actions Min                 -0.999882\n",
      "time/backward_policy (s)                1.83542\n",
      "time/backward_zf1 (s)                   1.97949\n",
      "time/backward_zf2 (s)                   1.91735\n",
      "time/data sampling (s)                  0.31467\n",
      "time/data storing (s)                   0.0155951\n",
      "time/evaluation sampling (s)            1.7519\n",
      "time/exploration sampling (s)           0.321788\n",
      "time/logging (s)                        0.0175783\n",
      "time/preback_alpha (s)                  0.577178\n",
      "time/preback_policy (s)                 1.07702\n",
      "time/preback_start (s)                  0.148758\n",
      "time/preback_zf (s)                     5.15391\n",
      "time/saving (s)                         0.0101931\n",
      "time/training (s)                       2.3597\n",
      "time/epoch (s)                         17.4805\n",
      "time/total (s)                       3447.32\n",
      "Epoch                                 195\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:34:01.513894 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 196 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 207000\n",
      "trainer/ZF1 Loss                       17.3714\n",
      "trainer/ZF2 Loss                        2.94257\n",
      "trainer/ZF Expert Reward               15.3611\n",
      "trainer/ZF Policy Reward                5.27598\n",
      "trainer/ZF CHI2 Term                   52.5236\n",
      "trainer/Policy Loss                 -1056.88\n",
      "trainer/Bias Loss                     180.946\n",
      "trainer/Bias Value                     14.0308\n",
      "trainer/Policy Grad Norm              107.482\n",
      "trainer/Policy Param Norm              37.314\n",
      "trainer/Zf1 Grad Norm                1825.35\n",
      "trainer/Zf1 Param Norm                113.973\n",
      "trainer/Zf2 Grad Norm                1747.31\n",
      "trainer/Zf2 Param Norm                116.723\n",
      "trainer/Z Expert Predictions Mean    1182.98\n",
      "trainer/Z Expert Predictions Std       45.0363\n",
      "trainer/Z Expert Predictions Max     1267.14\n",
      "trainer/Z Expert Predictions Min      906.974\n",
      "trainer/Z Policy Predictions Mean    1051.46\n",
      "trainer/Z Policy Predictions Std      302.44\n",
      "trainer/Z Policy Predictions Max     1256.26\n",
      "trainer/Z Policy Predictions Min     -540.423\n",
      "trainer/Z Expert Targets Mean        1167.62\n",
      "trainer/Z Expert Targets Std           52.9533\n",
      "trainer/Z Expert Targets Max         1257.08\n",
      "trainer/Z Expert Targets Min          684.282\n",
      "trainer/Z Policy Targets Mean        1046.18\n",
      "trainer/Z Policy Targets Std          298.454\n",
      "trainer/Z Policy Targets Max         1238.53\n",
      "trainer/Z Policy Targets Min         -536.206\n",
      "trainer/Log Pis Mean                   32.6077\n",
      "trainer/Log Pis Std                     9.42519\n",
      "trainer/Policy mu Mean                  0.0597137\n",
      "trainer/Policy mu Std                   1.81701\n",
      "trainer/Policy log std Mean            -4.54512\n",
      "trainer/Policy log std Std              0.99266\n",
      "exploration/num steps total        201777\n",
      "exploration/num paths total           329\n",
      "evaluation/num steps total              1.67705e+06\n",
      "evaluation/num paths total           2029\n",
      "evaluation/path length Mean           971.6\n",
      "evaluation/path length Std             85.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            716\n",
      "evaluation/Rewards Mean                 4.68049\n",
      "evaluation/Rewards Std                  0.980139\n",
      "evaluation/Rewards Max                  6.74773\n",
      "evaluation/Rewards Min                 -2.09976\n",
      "evaluation/Returns Mean              4547.56\n",
      "evaluation/Returns Std                416.682\n",
      "evaluation/Returns Max               4812.77\n",
      "evaluation/Returns Min               3330.53\n",
      "evaluation/Estimation Bias Mean      1117.95\n",
      "evaluation/Estimation Bias Std        149.607\n",
      "evaluation/EB/Q_True Mean              45.2275\n",
      "evaluation/EB/Q_True Std              137.455\n",
      "evaluation/EB/Q_Pred Mean            1163.18\n",
      "evaluation/EB/Q_Pred Std               50.1689\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4547.56\n",
      "evaluation/Actions Mean                 0.0276335\n",
      "evaluation/Actions Std                  0.530378\n",
      "evaluation/Actions Max                  0.999751\n",
      "evaluation/Actions Min                 -0.999751\n",
      "time/backward_policy (s)                1.82052\n",
      "time/backward_zf1 (s)                   1.96396\n",
      "time/backward_zf2 (s)                   1.87896\n",
      "time/data sampling (s)                  0.295564\n",
      "time/data storing (s)                   0.0146551\n",
      "time/evaluation sampling (s)            1.68938\n",
      "time/exploration sampling (s)           0.319316\n",
      "time/logging (s)                        0.0118726\n",
      "time/preback_alpha (s)                  0.580953\n",
      "time/preback_policy (s)                 1.01829\n",
      "time/preback_start (s)                  0.14961\n",
      "time/preback_zf (s)                     5.15404\n",
      "time/saving (s)                         0.00729495\n",
      "time/training (s)                       2.54305\n",
      "time/epoch (s)                         17.4475\n",
      "time/total (s)                       3464.79\n",
      "Epoch                                 196\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:34:19.798133 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 197 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 208000\n",
      "trainer/ZF1 Loss                      216.213\n",
      "trainer/ZF2 Loss                      229.84\n",
      "trainer/ZF Expert Reward               13.4598\n",
      "trainer/ZF Policy Reward                6.46462\n",
      "trainer/ZF CHI2 Term                  261.566\n",
      "trainer/Policy Loss                 -1058.52\n",
      "trainer/Bias Loss                      72.6426\n",
      "trainer/Bias Value                     14.0406\n",
      "trainer/Policy Grad Norm              146.297\n",
      "trainer/Policy Param Norm              37.3483\n",
      "trainer/Zf1 Grad Norm                1644.71\n",
      "trainer/Zf1 Param Norm                114.133\n",
      "trainer/Zf2 Grad Norm                1932.25\n",
      "trainer/Zf2 Param Norm                116.899\n",
      "trainer/Z Expert Predictions Mean    1169.12\n",
      "trainer/Z Expert Predictions Std       85.6402\n",
      "trainer/Z Expert Predictions Max     1260.8\n",
      "trainer/Z Expert Predictions Min       78.9896\n",
      "trainer/Z Policy Predictions Mean    1054.71\n",
      "trainer/Z Policy Predictions Std      298.582\n",
      "trainer/Z Policy Predictions Max     1261.82\n",
      "trainer/Z Policy Predictions Min     -524.563\n",
      "trainer/Z Expert Targets Mean        1155.66\n",
      "trainer/Z Expert Targets Std           89.9467\n",
      "trainer/Z Expert Targets Max         1246.52\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1048.24\n",
      "trainer/Z Policy Targets Std          303.558\n",
      "trainer/Z Policy Targets Max         1246.28\n",
      "trainer/Z Policy Targets Min         -529.669\n",
      "trainer/Log Pis Mean                   31.8634\n",
      "trainer/Log Pis Std                     6.38991\n",
      "trainer/Policy mu Mean                  0.0594446\n",
      "trainer/Policy mu Std                   1.49095\n",
      "trainer/Policy log std Mean            -4.58785\n",
      "trainer/Policy log std Std              0.858385\n",
      "exploration/num steps total        202777\n",
      "exploration/num paths total           330\n",
      "evaluation/num steps total              1.68701e+06\n",
      "evaluation/num paths total           2039\n",
      "evaluation/path length Mean           996.4\n",
      "evaluation/path length Std             10.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            964\n",
      "evaluation/Rewards Mean                 4.68769\n",
      "evaluation/Rewards Std                  1.00805\n",
      "evaluation/Rewards Max                  7.02243\n",
      "evaluation/Rewards Min                 -1.70651\n",
      "evaluation/Returns Mean              4670.82\n",
      "evaluation/Returns Std                112.009\n",
      "evaluation/Returns Max               4840.38\n",
      "evaluation/Returns Min               4459.88\n",
      "evaluation/Estimation Bias Mean      1119.81\n",
      "evaluation/Estimation Bias Std        145.733\n",
      "evaluation/EB/Q_True Mean              44.1239\n",
      "evaluation/EB/Q_True Std              135.351\n",
      "evaluation/EB/Q_Pred Mean            1163.93\n",
      "evaluation/EB/Q_Pred Std               57.5799\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4670.82\n",
      "evaluation/Actions Mean                 0.0183189\n",
      "evaluation/Actions Std                  0.532764\n",
      "evaluation/Actions Max                  0.999962\n",
      "evaluation/Actions Min                 -0.999909\n",
      "time/backward_policy (s)                2.05364\n",
      "time/backward_zf1 (s)                   2.2154\n",
      "time/backward_zf2 (s)                   2.16354\n",
      "time/data sampling (s)                  0.317369\n",
      "time/data storing (s)                   0.0154927\n",
      "time/evaluation sampling (s)            1.74256\n",
      "time/exploration sampling (s)           0.333361\n",
      "time/logging (s)                        0.011912\n",
      "time/preback_alpha (s)                  0.59122\n",
      "time/preback_policy (s)                 1.21949\n",
      "time/preback_start (s)                  0.150986\n",
      "time/preback_zf (s)                     5.19975\n",
      "time/saving (s)                         0.00652536\n",
      "time/training (s)                       2.18599\n",
      "time/epoch (s)                         18.2072\n",
      "time/total (s)                       3483.03\n",
      "Epoch                                 197\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:34:37.231827 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 198 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 209000\n",
      "trainer/ZF1 Loss                        5.47633\n",
      "trainer/ZF2 Loss                        4.42717\n",
      "trainer/ZF Expert Reward               19.0843\n",
      "trainer/ZF Policy Reward                8.31912\n",
      "trainer/ZF CHI2 Term                   47.6253\n",
      "trainer/Policy Loss                 -1048.22\n",
      "trainer/Bias Loss                     104.064\n",
      "trainer/Bias Value                     14.058\n",
      "trainer/Policy Grad Norm              125.649\n",
      "trainer/Policy Param Norm              37.3827\n",
      "trainer/Zf1 Grad Norm                1404.82\n",
      "trainer/Zf1 Param Norm                114.293\n",
      "trainer/Zf2 Grad Norm                1711.93\n",
      "trainer/Zf2 Param Norm                117.054\n",
      "trainer/Z Expert Predictions Mean    1177.4\n",
      "trainer/Z Expert Predictions Std       59.3053\n",
      "trainer/Z Expert Predictions Max     1258.3\n",
      "trainer/Z Expert Predictions Min      704.3\n",
      "trainer/Z Policy Predictions Mean    1046.38\n",
      "trainer/Z Policy Predictions Std      313.229\n",
      "trainer/Z Policy Predictions Max     1254.16\n",
      "trainer/Z Policy Predictions Min     -511.119\n",
      "trainer/Z Expert Targets Mean        1158.32\n",
      "trainer/Z Expert Targets Std           62.3325\n",
      "trainer/Z Expert Targets Max         1236.56\n",
      "trainer/Z Expert Targets Min          675.738\n",
      "trainer/Z Policy Targets Mean        1038.06\n",
      "trainer/Z Policy Targets Std          307.797\n",
      "trainer/Z Policy Targets Max         1233.59\n",
      "trainer/Z Policy Targets Min         -488.223\n",
      "trainer/Log Pis Mean                   32.2306\n",
      "trainer/Log Pis Std                     7.82194\n",
      "trainer/Policy mu Mean                  0.0391233\n",
      "trainer/Policy mu Std                   1.67773\n",
      "trainer/Policy log std Mean            -4.4778\n",
      "trainer/Policy log std Std              0.993358\n",
      "exploration/num steps total        204777\n",
      "exploration/num paths total           332\n",
      "evaluation/num steps total              1.69701e+06\n",
      "evaluation/num paths total           2049\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60937\n",
      "evaluation/Rewards Std                  0.976439\n",
      "evaluation/Rewards Max                  6.80806\n",
      "evaluation/Rewards Min                 -1.52291\n",
      "evaluation/Returns Mean              4609.37\n",
      "evaluation/Returns Std                 64.4882\n",
      "evaluation/Returns Max               4721.8\n",
      "evaluation/Returns Min               4523.9\n",
      "evaluation/Estimation Bias Mean      1118.37\n",
      "evaluation/Estimation Bias Std        142.639\n",
      "evaluation/EB/Q_True Mean              43.1186\n",
      "evaluation/EB/Q_True Std              132.385\n",
      "evaluation/EB/Q_Pred Mean            1161.49\n",
      "evaluation/EB/Q_Pred Std               50.3375\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4609.37\n",
      "evaluation/Actions Mean                 0.0195134\n",
      "evaluation/Actions Std                  0.532941\n",
      "evaluation/Actions Max                  0.999334\n",
      "evaluation/Actions Min                 -0.999441\n",
      "time/backward_policy (s)                1.77887\n",
      "time/backward_zf1 (s)                   1.92322\n",
      "time/backward_zf2 (s)                   1.84584\n",
      "time/data sampling (s)                  0.289683\n",
      "time/data storing (s)                   0.0149944\n",
      "time/evaluation sampling (s)            1.76143\n",
      "time/exploration sampling (s)           0.329576\n",
      "time/logging (s)                        0.0122996\n",
      "time/preback_alpha (s)                  0.576009\n",
      "time/preback_policy (s)                 1.01511\n",
      "time/preback_start (s)                  0.148522\n",
      "time/preback_zf (s)                     5.15095\n",
      "time/saving (s)                         0.00661674\n",
      "time/training (s)                       2.51363\n",
      "time/epoch (s)                         17.3667\n",
      "time/total (s)                       3500.41\n",
      "Epoch                                 198\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:34:54.406083 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 199 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 210000\n",
      "trainer/ZF1 Loss                      101.956\n",
      "trainer/ZF2 Loss                      188.902\n",
      "trainer/ZF Expert Reward               12.9739\n",
      "trainer/ZF Policy Reward                3.04335\n",
      "trainer/ZF CHI2 Term                  186.561\n",
      "trainer/Policy Loss                 -1048.37\n",
      "trainer/Bias Loss                      84.6671\n",
      "trainer/Bias Value                     14.0707\n",
      "trainer/Policy Grad Norm              216.199\n",
      "trainer/Policy Param Norm              37.4211\n",
      "trainer/Zf1 Grad Norm                2994.8\n",
      "trainer/Zf1 Param Norm                114.461\n",
      "trainer/Zf2 Grad Norm                2305.15\n",
      "trainer/Zf2 Param Norm                117.204\n",
      "trainer/Z Expert Predictions Mean    1178.64\n",
      "trainer/Z Expert Predictions Std       39.6005\n",
      "trainer/Z Expert Predictions Max     1270.62\n",
      "trainer/Z Expert Predictions Min      935.933\n",
      "trainer/Z Policy Predictions Mean    1045.59\n",
      "trainer/Z Policy Predictions Std      303.003\n",
      "trainer/Z Policy Predictions Max     1243.8\n",
      "trainer/Z Policy Predictions Min     -559.668\n",
      "trainer/Z Expert Targets Mean        1165.67\n",
      "trainer/Z Expert Targets Std           42.2544\n",
      "trainer/Z Expert Targets Max         1258.43\n",
      "trainer/Z Expert Targets Min          931.746\n",
      "trainer/Z Policy Targets Mean        1042.55\n",
      "trainer/Z Policy Targets Std          303.803\n",
      "trainer/Z Policy Targets Max         1236.29\n",
      "trainer/Z Policy Targets Min         -539.405\n",
      "trainer/Log Pis Mean                   31.5166\n",
      "trainer/Log Pis Std                     7.46895\n",
      "trainer/Policy mu Mean                  0.041374\n",
      "trainer/Policy mu Std                   1.49461\n",
      "trainer/Policy log std Mean            -4.51601\n",
      "trainer/Policy log std Std              0.935157\n",
      "exploration/num steps total        204777\n",
      "exploration/num paths total           332\n",
      "evaluation/num steps total              1.70701e+06\n",
      "evaluation/num paths total           2059\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.62071\n",
      "evaluation/Rewards Std                  0.971023\n",
      "evaluation/Rewards Max                  6.89001\n",
      "evaluation/Rewards Min                 -1.94637\n",
      "evaluation/Returns Mean              4620.71\n",
      "evaluation/Returns Std                106.391\n",
      "evaluation/Returns Max               4783.29\n",
      "evaluation/Returns Min               4372.79\n",
      "evaluation/Estimation Bias Mean      1117.41\n",
      "evaluation/Estimation Bias Std        134.552\n",
      "evaluation/EB/Q_True Mean              41.9627\n",
      "evaluation/EB/Q_True Std              129.941\n",
      "evaluation/EB/Q_Pred Mean            1159.38\n",
      "evaluation/EB/Q_Pred Std               49.6912\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4620.71\n",
      "evaluation/Actions Mean                 0.0138794\n",
      "evaluation/Actions Std                  0.52809\n",
      "evaluation/Actions Max                  0.999933\n",
      "evaluation/Actions Min                 -0.999724\n",
      "time/backward_policy (s)                1.79997\n",
      "time/backward_zf1 (s)                   1.94798\n",
      "time/backward_zf2 (s)                   1.85631\n",
      "time/data sampling (s)                  0.298117\n",
      "time/data storing (s)                   0.0140364\n",
      "time/evaluation sampling (s)            1.67565\n",
      "time/exploration sampling (s)           0.310416\n",
      "time/logging (s)                        0.0119665\n",
      "time/preback_alpha (s)                  0.567759\n",
      "time/preback_policy (s)                 1.02453\n",
      "time/preback_start (s)                  0.146138\n",
      "time/preback_zf (s)                     5.08819\n",
      "time/saving (s)                         0.00637167\n",
      "time/training (s)                       2.36017\n",
      "time/epoch (s)                         17.1076\n",
      "time/total (s)                       3517.54\n",
      "Epoch                                 199\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:35:12.390598 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 200 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 211000\n",
      "trainer/ZF1 Loss                       -6.07637\n",
      "trainer/ZF2 Loss                       -4.21146\n",
      "trainer/ZF Expert Reward               17.0845\n",
      "trainer/ZF Policy Reward                3.53973\n",
      "trainer/ZF CHI2 Term                   41.2694\n",
      "trainer/Policy Loss                 -1059.39\n",
      "trainer/Bias Loss                      55.7172\n",
      "trainer/Bias Value                     14.0452\n",
      "trainer/Policy Grad Norm              127.403\n",
      "trainer/Policy Param Norm              37.4534\n",
      "trainer/Zf1 Grad Norm                1496.9\n",
      "trainer/Zf1 Param Norm                114.642\n",
      "trainer/Zf2 Grad Norm                1272.77\n",
      "trainer/Zf2 Param Norm                117.395\n",
      "trainer/Z Expert Predictions Mean    1178.95\n",
      "trainer/Z Expert Predictions Std       43.6357\n",
      "trainer/Z Expert Predictions Max     1258.25\n",
      "trainer/Z Expert Predictions Min      948.661\n",
      "trainer/Z Policy Predictions Mean    1054.72\n",
      "trainer/Z Policy Predictions Std      314.981\n",
      "trainer/Z Policy Predictions Max     1250.31\n",
      "trainer/Z Policy Predictions Min     -534.338\n",
      "trainer/Z Expert Targets Mean        1161.87\n",
      "trainer/Z Expert Targets Std           44.9091\n",
      "trainer/Z Expert Targets Max         1241.97\n",
      "trainer/Z Expert Targets Min          916.712\n",
      "trainer/Z Policy Targets Mean        1051.18\n",
      "trainer/Z Policy Targets Std          310.971\n",
      "trainer/Z Policy Targets Max         1233.33\n",
      "trainer/Z Policy Targets Min         -533.249\n",
      "trainer/Log Pis Mean                   33.2006\n",
      "trainer/Log Pis Std                     9.14903\n",
      "trainer/Policy mu Mean                  0.0619795\n",
      "trainer/Policy mu Std                   1.9195\n",
      "trainer/Policy log std Mean            -4.52798\n",
      "trainer/Policy log std Std              1.0344\n",
      "exploration/num steps total        204777\n",
      "exploration/num paths total           332\n",
      "evaluation/num steps total              1.71612e+06\n",
      "evaluation/num paths total           2069\n",
      "evaluation/path length Mean           910.9\n",
      "evaluation/path length Std            267.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            109\n",
      "evaluation/Rewards Mean                 4.70065\n",
      "evaluation/Rewards Std                  0.995999\n",
      "evaluation/Rewards Max                  6.86166\n",
      "evaluation/Rewards Min                 -1.74791\n",
      "evaluation/Returns Mean              4281.83\n",
      "evaluation/Returns Std               1298.6\n",
      "evaluation/Returns Max               4909.44\n",
      "evaluation/Returns Min                398.079\n",
      "evaluation/Estimation Bias Mean      1116.24\n",
      "evaluation/Estimation Bias Std        150.581\n",
      "evaluation/EB/Q_True Mean              47.5939\n",
      "evaluation/EB/Q_True Std              139.509\n",
      "evaluation/EB/Q_Pred Mean            1163.83\n",
      "evaluation/EB/Q_Pred Std               53.3574\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4281.83\n",
      "evaluation/Actions Mean                 0.021309\n",
      "evaluation/Actions Std                  0.534459\n",
      "evaluation/Actions Max                  0.999985\n",
      "evaluation/Actions Min                 -0.999677\n",
      "time/backward_policy (s)                1.98933\n",
      "time/backward_zf1 (s)                   2.13972\n",
      "time/backward_zf2 (s)                   2.0686\n",
      "time/data sampling (s)                  0.284502\n",
      "time/data storing (s)                   0.0159095\n",
      "time/evaluation sampling (s)            1.72567\n",
      "time/exploration sampling (s)           0.334964\n",
      "time/logging (s)                        0.0169606\n",
      "time/preback_alpha (s)                  0.58466\n",
      "time/preback_policy (s)                 1.15155\n",
      "time/preback_start (s)                  0.15184\n",
      "time/preback_zf (s)                     5.17016\n",
      "time/saving (s)                         0.00664964\n",
      "time/training (s)                       2.27583\n",
      "time/epoch (s)                         17.9164\n",
      "time/total (s)                       3535.48\n",
      "Epoch                                 200\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:35:29.850037 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 201 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 212000\n",
      "trainer/ZF1 Loss                      -12.3909\n",
      "trainer/ZF2 Loss                       -8.44599\n",
      "trainer/ZF Expert Reward               16.9999\n",
      "trainer/ZF Policy Reward                6.26682\n",
      "trainer/ZF CHI2 Term                   33.0556\n",
      "trainer/Policy Loss                 -1028.33\n",
      "trainer/Bias Loss                      58.6834\n",
      "trainer/Bias Value                     14.0515\n",
      "trainer/Policy Grad Norm              126.195\n",
      "trainer/Policy Param Norm              37.4886\n",
      "trainer/Zf1 Grad Norm                 788.176\n",
      "trainer/Zf1 Param Norm                114.804\n",
      "trainer/Zf2 Grad Norm                 873.388\n",
      "trainer/Zf2 Param Norm                117.548\n",
      "trainer/Z Expert Predictions Mean    1175.63\n",
      "trainer/Z Expert Predictions Std       47.2544\n",
      "trainer/Z Expert Predictions Max     1267.62\n",
      "trainer/Z Expert Predictions Min      902.401\n",
      "trainer/Z Policy Predictions Mean    1024.02\n",
      "trainer/Z Policy Predictions Std      347.711\n",
      "trainer/Z Policy Predictions Max     1234.65\n",
      "trainer/Z Policy Predictions Min     -530.73\n",
      "trainer/Z Expert Targets Mean        1158.63\n",
      "trainer/Z Expert Targets Std           47.9217\n",
      "trainer/Z Expert Targets Max         1254.84\n",
      "trainer/Z Expert Targets Min          883.201\n",
      "trainer/Z Policy Targets Mean        1017.76\n",
      "trainer/Z Policy Targets Std          344.225\n",
      "trainer/Z Policy Targets Max         1233.21\n",
      "trainer/Z Policy Targets Min         -542.594\n",
      "trainer/Log Pis Mean                   33.0717\n",
      "trainer/Log Pis Std                     8.70868\n",
      "trainer/Policy mu Mean                  0.0772244\n",
      "trainer/Policy mu Std                   1.80284\n",
      "trainer/Policy log std Mean            -4.5117\n",
      "trainer/Policy log std Std              1.05471\n",
      "exploration/num steps total        205777\n",
      "exploration/num paths total           333\n",
      "evaluation/num steps total              1.72532e+06\n",
      "evaluation/num paths total           2079\n",
      "evaluation/path length Mean           920.2\n",
      "evaluation/path length Std            181.02\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            410\n",
      "evaluation/Rewards Mean                 4.64936\n",
      "evaluation/Rewards Std                  1.11495\n",
      "evaluation/Rewards Max                  6.95715\n",
      "evaluation/Rewards Min                 -3.87006\n",
      "evaluation/Returns Mean              4278.34\n",
      "evaluation/Returns Std                868.289\n",
      "evaluation/Returns Max               4812.62\n",
      "evaluation/Returns Min               1859.35\n",
      "evaluation/Estimation Bias Mean      1108.09\n",
      "evaluation/Estimation Bias Std        150.098\n",
      "evaluation/EB/Q_True Mean              46.192\n",
      "evaluation/EB/Q_True Std              136.538\n",
      "evaluation/EB/Q_Pred Mean            1154.29\n",
      "evaluation/EB/Q_Pred Std               65.1928\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4278.34\n",
      "evaluation/Actions Mean                 0.0103357\n",
      "evaluation/Actions Std                  0.525597\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.87746\n",
      "time/backward_zf1 (s)                   2.02498\n",
      "time/backward_zf2 (s)                   1.95437\n",
      "time/data sampling (s)                  0.296662\n",
      "time/data storing (s)                   0.014493\n",
      "time/evaluation sampling (s)            1.75002\n",
      "time/exploration sampling (s)           0.323228\n",
      "time/logging (s)                        0.0117903\n",
      "time/preback_alpha (s)                  0.565391\n",
      "time/preback_policy (s)                 1.10443\n",
      "time/preback_start (s)                  0.144736\n",
      "time/preback_zf (s)                     5.09101\n",
      "time/saving (s)                         0.00657275\n",
      "time/training (s)                       2.21664\n",
      "time/epoch (s)                         17.3818\n",
      "time/total (s)                       3552.89\n",
      "Epoch                                 201\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:35:47.312408 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 202 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 213000\n",
      "trainer/ZF1 Loss                      160.52\n",
      "trainer/ZF2 Loss                       12.5708\n",
      "trainer/ZF Expert Reward               17.3959\n",
      "trainer/ZF Policy Reward               10.4308\n",
      "trainer/ZF CHI2 Term                  126.112\n",
      "trainer/Policy Loss                 -1017.53\n",
      "trainer/Bias Loss                     102.542\n",
      "trainer/Bias Value                     14.0461\n",
      "trainer/Policy Grad Norm              155.396\n",
      "trainer/Policy Param Norm              37.5254\n",
      "trainer/Zf1 Grad Norm                4234.55\n",
      "trainer/Zf1 Param Norm                114.959\n",
      "trainer/Zf2 Grad Norm                2703.37\n",
      "trainer/Zf2 Param Norm                117.69\n",
      "trainer/Z Expert Predictions Mean    1175.67\n",
      "trainer/Z Expert Predictions Std       36.5413\n",
      "trainer/Z Expert Predictions Max     1251.55\n",
      "trainer/Z Expert Predictions Min      950.782\n",
      "trainer/Z Policy Predictions Mean    1014.04\n",
      "trainer/Z Policy Predictions Std      349.923\n",
      "trainer/Z Policy Predictions Max     1261.51\n",
      "trainer/Z Policy Predictions Min     -484.665\n",
      "trainer/Z Expert Targets Mean        1158.27\n",
      "trainer/Z Expert Targets Std           37.5895\n",
      "trainer/Z Expert Targets Max         1233.11\n",
      "trainer/Z Expert Targets Min          924.747\n",
      "trainer/Z Policy Targets Mean        1003.61\n",
      "trainer/Z Policy Targets Std          350.785\n",
      "trainer/Z Policy Targets Max         1233.76\n",
      "trainer/Z Policy Targets Min         -486.526\n",
      "trainer/Log Pis Mean                   32.9313\n",
      "trainer/Log Pis Std                     9.17831\n",
      "trainer/Policy mu Mean                  0.0264739\n",
      "trainer/Policy mu Std                   1.87207\n",
      "trainer/Policy log std Mean            -4.40599\n",
      "trainer/Policy log std Std              1.05898\n",
      "exploration/num steps total        207777\n",
      "exploration/num paths total           335\n",
      "evaluation/num steps total              1.73532e+06\n",
      "evaluation/num paths total           2089\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.73749\n",
      "evaluation/Rewards Std                  0.972907\n",
      "evaluation/Rewards Max                  6.78494\n",
      "evaluation/Rewards Min                 -1.46555\n",
      "evaluation/Returns Mean              4737.49\n",
      "evaluation/Returns Std                 75.2735\n",
      "evaluation/Returns Max               4828.97\n",
      "evaluation/Returns Min               4623.62\n",
      "evaluation/Estimation Bias Mean      1106.7\n",
      "evaluation/Estimation Bias Std        144.026\n",
      "evaluation/EB/Q_True Mean              44.8021\n",
      "evaluation/EB/Q_True Std              138.25\n",
      "evaluation/EB/Q_Pred Mean            1151.51\n",
      "evaluation/EB/Q_Pred Std               46.7952\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4737.49\n",
      "evaluation/Actions Mean                 0.0194383\n",
      "evaluation/Actions Std                  0.537086\n",
      "evaluation/Actions Max                  0.999424\n",
      "evaluation/Actions Min                 -0.999858\n",
      "time/backward_policy (s)                1.86006\n",
      "time/backward_zf1 (s)                   1.99012\n",
      "time/backward_zf2 (s)                   1.89986\n",
      "time/data sampling (s)                  0.306293\n",
      "time/data storing (s)                   0.0151235\n",
      "time/evaluation sampling (s)            1.74115\n",
      "time/exploration sampling (s)           0.331897\n",
      "time/logging (s)                        0.0124848\n",
      "time/preback_alpha (s)                  0.574926\n",
      "time/preback_policy (s)                 1.07289\n",
      "time/preback_start (s)                  0.146982\n",
      "time/preback_zf (s)                     5.11009\n",
      "time/saving (s)                         0.00649515\n",
      "time/training (s)                       2.3254\n",
      "time/epoch (s)                         17.3938\n",
      "time/total (s)                       3570.3\n",
      "Epoch                                 202\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:36:05.393281 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 203 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 214000\n",
      "trainer/ZF1 Loss                      162.318\n",
      "trainer/ZF2 Loss                      170.07\n",
      "trainer/ZF Expert Reward               14.2874\n",
      "trainer/ZF Policy Reward                5.20875\n",
      "trainer/ZF CHI2 Term                  206.888\n",
      "trainer/Policy Loss                 -1038.75\n",
      "trainer/Bias Loss                      55.8321\n",
      "trainer/Bias Value                     14.0391\n",
      "trainer/Policy Grad Norm              103.286\n",
      "trainer/Policy Param Norm              37.5596\n",
      "trainer/Zf1 Grad Norm                2308.35\n",
      "trainer/Zf1 Param Norm                115.119\n",
      "trainer/Zf2 Grad Norm                3539.25\n",
      "trainer/Zf2 Param Norm                117.844\n",
      "trainer/Z Expert Predictions Mean    1166.08\n",
      "trainer/Z Expert Predictions Std       41.8229\n",
      "trainer/Z Expert Predictions Max     1240.5\n",
      "trainer/Z Expert Predictions Min      939.917\n",
      "trainer/Z Policy Predictions Mean    1033.43\n",
      "trainer/Z Policy Predictions Std      289.765\n",
      "trainer/Z Policy Predictions Max     1212.34\n",
      "trainer/Z Policy Predictions Min     -503.968\n",
      "trainer/Z Expert Targets Mean        1151.8\n",
      "trainer/Z Expert Targets Std           43.0857\n",
      "trainer/Z Expert Targets Max         1236.68\n",
      "trainer/Z Expert Targets Min          936.364\n",
      "trainer/Z Policy Targets Mean        1028.22\n",
      "trainer/Z Policy Targets Std          292.649\n",
      "trainer/Z Policy Targets Max         1231.8\n",
      "trainer/Z Policy Targets Min         -507.73\n",
      "trainer/Log Pis Mean                   31.934\n",
      "trainer/Log Pis Std                     7.56285\n",
      "trainer/Policy mu Mean                  0.0696204\n",
      "trainer/Policy mu Std                   1.62027\n",
      "trainer/Policy log std Mean            -4.51551\n",
      "trainer/Policy log std Std              0.979845\n",
      "exploration/num steps total        208777\n",
      "exploration/num paths total           336\n",
      "evaluation/num steps total              1.74532e+06\n",
      "evaluation/num paths total           2099\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7329\n",
      "evaluation/Rewards Std                  0.961289\n",
      "evaluation/Rewards Max                  6.75559\n",
      "evaluation/Rewards Min                 -1.23371\n",
      "evaluation/Returns Mean              4732.9\n",
      "evaluation/Returns Std                117.228\n",
      "evaluation/Returns Max               4928.84\n",
      "evaluation/Returns Min               4530.51\n",
      "evaluation/Estimation Bias Mean      1112.7\n",
      "evaluation/Estimation Bias Std        144.531\n",
      "evaluation/EB/Q_True Mean              43.9689\n",
      "evaluation/EB/Q_True Std              135.356\n",
      "evaluation/EB/Q_Pred Mean            1156.67\n",
      "evaluation/EB/Q_Pred Std               50.5721\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4732.9\n",
      "evaluation/Actions Mean                 0.0192998\n",
      "evaluation/Actions Std                  0.537304\n",
      "evaluation/Actions Max                  0.999742\n",
      "evaluation/Actions Min                 -0.999891\n",
      "time/backward_policy (s)                1.99326\n",
      "time/backward_zf1 (s)                   2.16337\n",
      "time/backward_zf2 (s)                   2.06652\n",
      "time/data sampling (s)                  0.318005\n",
      "time/data storing (s)                   0.0162586\n",
      "time/evaluation sampling (s)            1.82649\n",
      "time/exploration sampling (s)           0.338257\n",
      "time/logging (s)                        0.0125766\n",
      "time/preback_alpha (s)                  0.586162\n",
      "time/preback_policy (s)                 1.17988\n",
      "time/preback_start (s)                  0.149264\n",
      "time/preback_zf (s)                     5.17382\n",
      "time/saving (s)                         0.00648676\n",
      "time/training (s)                       2.17911\n",
      "time/epoch (s)                         18.0095\n",
      "time/total (s)                       3588.33\n",
      "Epoch                                 203\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:36:24.421581 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 204 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 215000\n",
      "trainer/ZF1 Loss                       -6.35788\n",
      "trainer/ZF2 Loss                       -2.71256\n",
      "trainer/ZF Expert Reward               16.6946\n",
      "trainer/ZF Policy Reward                4.30814\n",
      "trainer/ZF CHI2 Term                   39.2837\n",
      "trainer/Policy Loss                 -1061.07\n",
      "trainer/Bias Loss                      71.2698\n",
      "trainer/Bias Value                     14.0377\n",
      "trainer/Policy Grad Norm              131.562\n",
      "trainer/Policy Param Norm              37.593\n",
      "trainer/Zf1 Grad Norm                1038.23\n",
      "trainer/Zf1 Param Norm                115.276\n",
      "trainer/Zf2 Grad Norm                 919.216\n",
      "trainer/Zf2 Param Norm                118.001\n",
      "trainer/Z Expert Predictions Mean    1167.13\n",
      "trainer/Z Expert Predictions Std       44.2735\n",
      "trainer/Z Expert Predictions Max     1252.19\n",
      "trainer/Z Expert Predictions Min      954.3\n",
      "trainer/Z Policy Predictions Mean    1056.53\n",
      "trainer/Z Policy Predictions Std      260.891\n",
      "trainer/Z Policy Predictions Max     1231.38\n",
      "trainer/Z Policy Predictions Min     -558.407\n",
      "trainer/Z Expert Targets Mean        1150.44\n",
      "trainer/Z Expert Targets Std           45.1574\n",
      "trainer/Z Expert Targets Max         1229.48\n",
      "trainer/Z Expert Targets Min          923.091\n",
      "trainer/Z Policy Targets Mean        1052.22\n",
      "trainer/Z Policy Targets Std          255.885\n",
      "trainer/Z Policy Targets Max         1208.1\n",
      "trainer/Z Policy Targets Min         -533.687\n",
      "trainer/Log Pis Mean                   31.75\n",
      "trainer/Log Pis Std                     6.33819\n",
      "trainer/Policy mu Mean                  0.0749703\n",
      "trainer/Policy mu Std                   1.3825\n",
      "trainer/Policy log std Mean            -4.60234\n",
      "trainer/Policy log std Std              0.932001\n",
      "exploration/num steps total        211777\n",
      "exploration/num paths total           339\n",
      "evaluation/num steps total              1.75532e+06\n",
      "evaluation/num paths total           2109\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66696\n",
      "evaluation/Rewards Std                  0.999114\n",
      "evaluation/Rewards Max                  6.98549\n",
      "evaluation/Rewards Min                 -2.56362\n",
      "evaluation/Returns Mean              4666.96\n",
      "evaluation/Returns Std                106.683\n",
      "evaluation/Returns Max               4854.29\n",
      "evaluation/Returns Min               4477.21\n",
      "evaluation/Estimation Bias Mean      1104.36\n",
      "evaluation/Estimation Bias Std        139.852\n",
      "evaluation/EB/Q_True Mean              43.0746\n",
      "evaluation/EB/Q_True Std              133.006\n",
      "evaluation/EB/Q_Pred Mean            1147.44\n",
      "evaluation/EB/Q_Pred Std               49.5703\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4666.96\n",
      "evaluation/Actions Mean                 0.024333\n",
      "evaluation/Actions Std                  0.537741\n",
      "evaluation/Actions Max                  0.999783\n",
      "evaluation/Actions Min                 -0.999841\n",
      "time/backward_policy (s)                2.08222\n",
      "time/backward_zf1 (s)                   2.29032\n",
      "time/backward_zf2 (s)                   2.23808\n",
      "time/data sampling (s)                  0.346856\n",
      "time/data storing (s)                   0.0180677\n",
      "time/evaluation sampling (s)            1.75544\n",
      "time/exploration sampling (s)           0.367826\n",
      "time/logging (s)                        0.0123077\n",
      "time/preback_alpha (s)                  0.631687\n",
      "time/preback_policy (s)                 1.25378\n",
      "time/preback_start (s)                  0.163582\n",
      "time/preback_zf (s)                     5.38492\n",
      "time/saving (s)                         0.00649581\n",
      "time/training (s)                       2.40475\n",
      "time/epoch (s)                         18.9563\n",
      "time/total (s)                       3607.3\n",
      "Epoch                                 204\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:36:42.116138 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 205 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 216000\n",
      "trainer/ZF1 Loss                       -1.20557\n",
      "trainer/ZF2 Loss                       -3.07493\n",
      "trainer/ZF Expert Reward               13.8066\n",
      "trainer/ZF Policy Reward                4.72929\n",
      "trainer/ZF CHI2 Term                   38.6456\n",
      "trainer/Policy Loss                 -1042.4\n",
      "trainer/Bias Loss                      55.7235\n",
      "trainer/Bias Value                     14.0223\n",
      "trainer/Policy Grad Norm              130.407\n",
      "trainer/Policy Param Norm              37.625\n",
      "trainer/Zf1 Grad Norm                1419.37\n",
      "trainer/Zf1 Param Norm                115.431\n",
      "trainer/Zf2 Grad Norm                1453.09\n",
      "trainer/Zf2 Param Norm                118.161\n",
      "trainer/Z Expert Predictions Mean    1164.16\n",
      "trainer/Z Expert Predictions Std       48.8905\n",
      "trainer/Z Expert Predictions Max     1251.11\n",
      "trainer/Z Expert Predictions Min      838.657\n",
      "trainer/Z Policy Predictions Mean    1037.69\n",
      "trainer/Z Policy Predictions Std      285.431\n",
      "trainer/Z Policy Predictions Max     1240.28\n",
      "trainer/Z Policy Predictions Min     -496.265\n",
      "trainer/Z Expert Targets Mean        1150.35\n",
      "trainer/Z Expert Targets Std           48.3712\n",
      "trainer/Z Expert Targets Max         1228.36\n",
      "trainer/Z Expert Targets Min          847.591\n",
      "trainer/Z Policy Targets Mean        1032.96\n",
      "trainer/Z Policy Targets Std          280.597\n",
      "trainer/Z Policy Targets Max         1207.75\n",
      "trainer/Z Policy Targets Min         -500.943\n",
      "trainer/Log Pis Mean                   32.0289\n",
      "trainer/Log Pis Std                     6.58178\n",
      "trainer/Policy mu Mean                  0.0493577\n",
      "trainer/Policy mu Std                   1.49599\n",
      "trainer/Policy log std Mean            -4.54892\n",
      "trainer/Policy log std Std              0.966082\n",
      "exploration/num steps total        211777\n",
      "exploration/num paths total           339\n",
      "evaluation/num steps total              1.76532e+06\n",
      "evaluation/num paths total           2119\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.81944\n",
      "evaluation/Rewards Std                  0.970234\n",
      "evaluation/Rewards Max                  6.77537\n",
      "evaluation/Rewards Min                 -1.6551\n",
      "evaluation/Returns Mean              4819.44\n",
      "evaluation/Returns Std                 70.6594\n",
      "evaluation/Returns Max               4949.22\n",
      "evaluation/Returns Min               4733.16\n",
      "evaluation/Estimation Bias Mean      1100.88\n",
      "evaluation/Estimation Bias Std        142.007\n",
      "evaluation/EB/Q_True Mean              43.8443\n",
      "evaluation/EB/Q_True Std              134.89\n",
      "evaluation/EB/Q_Pred Mean            1144.72\n",
      "evaluation/EB/Q_Pred Std               48.7984\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4819.44\n",
      "evaluation/Actions Mean                 0.0278719\n",
      "evaluation/Actions Std                  0.538683\n",
      "evaluation/Actions Max                  0.999817\n",
      "evaluation/Actions Min                 -0.99991\n",
      "time/backward_policy (s)                1.85216\n",
      "time/backward_zf1 (s)                   2.01169\n",
      "time/backward_zf2 (s)                   1.91647\n",
      "time/data sampling (s)                  0.324092\n",
      "time/data storing (s)                   0.0147914\n",
      "time/evaluation sampling (s)            1.73484\n",
      "time/exploration sampling (s)           0.321104\n",
      "time/logging (s)                        0.0127187\n",
      "time/preback_alpha (s)                  0.589326\n",
      "time/preback_policy (s)                 1.05903\n",
      "time/preback_start (s)                  0.15211\n",
      "time/preback_zf (s)                     5.18333\n",
      "time/saving (s)                         0.00651398\n",
      "time/training (s)                       2.44854\n",
      "time/epoch (s)                         17.6267\n",
      "time/total (s)                       3624.95\n",
      "Epoch                                 205\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:37:00.456528 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 206 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 217000\n",
      "trainer/ZF1 Loss                        3.32863\n",
      "trainer/ZF2 Loss                       -4.48642\n",
      "trainer/ZF Expert Reward               14.9847\n",
      "trainer/ZF Policy Reward                4.80997\n",
      "trainer/ZF CHI2 Term                   42.2531\n",
      "trainer/Policy Loss                 -1009.65\n",
      "trainer/Bias Loss                     142.434\n",
      "trainer/Bias Value                     14.0313\n",
      "trainer/Policy Grad Norm              129.529\n",
      "trainer/Policy Param Norm              37.6544\n",
      "trainer/Zf1 Grad Norm                1661.38\n",
      "trainer/Zf1 Param Norm                115.586\n",
      "trainer/Zf2 Grad Norm                1399.08\n",
      "trainer/Zf2 Param Norm                118.316\n",
      "trainer/Z Expert Predictions Mean    1157.63\n",
      "trainer/Z Expert Predictions Std       86.396\n",
      "trainer/Z Expert Predictions Max     1232.83\n",
      "trainer/Z Expert Predictions Min       -1.24716\n",
      "trainer/Z Policy Predictions Mean    1007.16\n",
      "trainer/Z Policy Predictions Std      337.312\n",
      "trainer/Z Policy Predictions Max     1232.23\n",
      "trainer/Z Policy Predictions Min     -511.236\n",
      "trainer/Z Expert Targets Mean        1142.64\n",
      "trainer/Z Expert Targets Std           89.8539\n",
      "trainer/Z Expert Targets Max         1231.99\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1002.35\n",
      "trainer/Z Policy Targets Std          331.254\n",
      "trainer/Z Policy Targets Max         1222.55\n",
      "trainer/Z Policy Targets Min         -495.361\n",
      "trainer/Log Pis Mean                   32.9871\n",
      "trainer/Log Pis Std                     9.27119\n",
      "trainer/Policy mu Mean                  0.0631398\n",
      "trainer/Policy mu Std                   1.89104\n",
      "trainer/Policy log std Mean            -4.49215\n",
      "trainer/Policy log std Std              1.14994\n",
      "exploration/num steps total        211777\n",
      "exploration/num paths total           339\n",
      "evaluation/num steps total              1.77532e+06\n",
      "evaluation/num paths total           2129\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.74064\n",
      "evaluation/Rewards Std                  0.973299\n",
      "evaluation/Rewards Max                  6.82245\n",
      "evaluation/Rewards Min                 -1.92329\n",
      "evaluation/Returns Mean              4740.64\n",
      "evaluation/Returns Std                 96.2215\n",
      "evaluation/Returns Max               4834.14\n",
      "evaluation/Returns Min               4514.27\n",
      "evaluation/Estimation Bias Mean      1097.16\n",
      "evaluation/Estimation Bias Std        144.656\n",
      "evaluation/EB/Q_True Mean              44.0658\n",
      "evaluation/EB/Q_True Std              136.106\n",
      "evaluation/EB/Q_Pred Mean            1141.22\n",
      "evaluation/EB/Q_Pred Std               50.686\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4740.64\n",
      "evaluation/Actions Mean                 0.0278398\n",
      "evaluation/Actions Std                  0.538522\n",
      "evaluation/Actions Max                  0.999742\n",
      "evaluation/Actions Min                 -0.999862\n",
      "time/backward_policy (s)                1.98741\n",
      "time/backward_zf1 (s)                   2.20322\n",
      "time/backward_zf2 (s)                   2.06601\n",
      "time/data sampling (s)                  0.318498\n",
      "time/data storing (s)                   0.0162615\n",
      "time/evaluation sampling (s)            1.72136\n",
      "time/exploration sampling (s)           0.341481\n",
      "time/logging (s)                        0.0122951\n",
      "time/preback_alpha (s)                  0.60974\n",
      "time/preback_policy (s)                 1.12701\n",
      "time/preback_start (s)                  0.154467\n",
      "time/preback_zf (s)                     5.27109\n",
      "time/saving (s)                         0.00656999\n",
      "time/training (s)                       2.43331\n",
      "time/epoch (s)                         18.2687\n",
      "time/total (s)                       3643.24\n",
      "Epoch                                 206\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:37:18.219246 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 207 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 218000\n",
      "trainer/ZF1 Loss                       -4.66206\n",
      "trainer/ZF2 Loss                       -4.67189\n",
      "trainer/ZF Expert Reward               14.2743\n",
      "trainer/ZF Policy Reward                2.2744\n",
      "trainer/ZF CHI2 Term                   39.3005\n",
      "trainer/Policy Loss                 -1036.15\n",
      "trainer/Bias Loss                      89.0105\n",
      "trainer/Bias Value                     14.0187\n",
      "trainer/Policy Grad Norm              154.64\n",
      "trainer/Policy Param Norm              37.6907\n",
      "trainer/Zf1 Grad Norm                1227.84\n",
      "trainer/Zf1 Param Norm                115.759\n",
      "trainer/Zf2 Grad Norm                1182.91\n",
      "trainer/Zf2 Param Norm                118.472\n",
      "trainer/Z Expert Predictions Mean    1150.08\n",
      "trainer/Z Expert Predictions Std       82.8559\n",
      "trainer/Z Expert Predictions Max     1234.2\n",
      "trainer/Z Expert Predictions Min       -0.0701056\n",
      "trainer/Z Policy Predictions Mean    1032.04\n",
      "trainer/Z Policy Predictions Std      275.516\n",
      "trainer/Z Policy Predictions Max     1202.15\n",
      "trainer/Z Policy Predictions Min     -511.065\n",
      "trainer/Z Expert Targets Mean        1135.8\n",
      "trainer/Z Expert Targets Std           83.1919\n",
      "trainer/Z Expert Targets Max         1230.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1029.77\n",
      "trainer/Z Policy Targets Std          272.592\n",
      "trainer/Z Policy Targets Max         1195.39\n",
      "trainer/Z Policy Targets Min         -478.743\n",
      "trainer/Log Pis Mean                   32.2905\n",
      "trainer/Log Pis Std                     7.19156\n",
      "trainer/Policy mu Mean                  0.0142366\n",
      "trainer/Policy mu Std                   1.50502\n",
      "trainer/Policy log std Mean            -4.59125\n",
      "trainer/Policy log std Std              0.926138\n",
      "exploration/num steps total        212777\n",
      "exploration/num paths total           340\n",
      "evaluation/num steps total              1.78532e+06\n",
      "evaluation/num paths total           2139\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.72996\n",
      "evaluation/Rewards Std                  1.04395\n",
      "evaluation/Rewards Max                  6.78872\n",
      "evaluation/Rewards Min                 -2.46357\n",
      "evaluation/Returns Mean              4729.96\n",
      "evaluation/Returns Std                104.394\n",
      "evaluation/Returns Max               4923.13\n",
      "evaluation/Returns Min               4569.75\n",
      "evaluation/Estimation Bias Mean      1092.7\n",
      "evaluation/Estimation Bias Std        148.329\n",
      "evaluation/EB/Q_True Mean              43.4616\n",
      "evaluation/EB/Q_True Std              133.577\n",
      "evaluation/EB/Q_Pred Mean            1136.16\n",
      "evaluation/EB/Q_Pred Std               56.51\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4729.96\n",
      "evaluation/Actions Mean                 0.0202266\n",
      "evaluation/Actions Std                  0.528967\n",
      "evaluation/Actions Max                  0.999663\n",
      "evaluation/Actions Min                 -0.999883\n",
      "time/backward_policy (s)                1.89717\n",
      "time/backward_zf1 (s)                   2.02598\n",
      "time/backward_zf2 (s)                   1.94203\n",
      "time/data sampling (s)                  0.309725\n",
      "time/data storing (s)                   0.0149059\n",
      "time/evaluation sampling (s)            1.73324\n",
      "time/exploration sampling (s)           0.333369\n",
      "time/logging (s)                        0.0117323\n",
      "time/preback_alpha (s)                  0.581576\n",
      "time/preback_policy (s)                 1.05586\n",
      "time/preback_start (s)                  0.148613\n",
      "time/preback_zf (s)                     5.14081\n",
      "time/saving (s)                         0.0065082\n",
      "time/training (s)                       2.49109\n",
      "time/epoch (s)                         17.6926\n",
      "time/total (s)                       3660.95\n",
      "Epoch                                 207\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:37:36.123241 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 208 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 219000\n",
      "trainer/ZF1 Loss                       -0.0606918\n",
      "trainer/ZF2 Loss                        0.252052\n",
      "trainer/ZF Expert Reward               11.1012\n",
      "trainer/ZF Policy Reward               -1.41635\n",
      "trainer/ZF CHI2 Term                   44.3908\n",
      "trainer/Policy Loss                 -1030.18\n",
      "trainer/Bias Loss                      66.4446\n",
      "trainer/Bias Value                     14.0648\n",
      "trainer/Policy Grad Norm              133.164\n",
      "trainer/Policy Param Norm              37.724\n",
      "trainer/Zf1 Grad Norm                1659.36\n",
      "trainer/Zf1 Param Norm                115.916\n",
      "trainer/Zf2 Grad Norm                1869.32\n",
      "trainer/Zf2 Param Norm                118.619\n",
      "trainer/Z Expert Predictions Mean    1150.13\n",
      "trainer/Z Expert Predictions Std       41.2121\n",
      "trainer/Z Expert Predictions Max     1234.24\n",
      "trainer/Z Expert Predictions Min      865.614\n",
      "trainer/Z Policy Predictions Mean    1024.45\n",
      "trainer/Z Policy Predictions Std      281.802\n",
      "trainer/Z Policy Predictions Max     1215.99\n",
      "trainer/Z Policy Predictions Min     -475.522\n",
      "trainer/Z Expert Targets Mean        1139.03\n",
      "trainer/Z Expert Targets Std           44.0681\n",
      "trainer/Z Expert Targets Max         1221.08\n",
      "trainer/Z Expert Targets Min          822.625\n",
      "trainer/Z Policy Targets Mean        1025.87\n",
      "trainer/Z Policy Targets Std          278.711\n",
      "trainer/Z Policy Targets Max         1215.62\n",
      "trainer/Z Policy Targets Min         -459.341\n",
      "trainer/Log Pis Mean                   32.0985\n",
      "trainer/Log Pis Std                     7.3304\n",
      "trainer/Policy mu Mean                  0.0526017\n",
      "trainer/Policy mu Std                   1.53919\n",
      "trainer/Policy log std Mean            -4.56024\n",
      "trainer/Policy log std Std              0.936523\n",
      "exploration/num steps total        214777\n",
      "exploration/num paths total           342\n",
      "evaluation/num steps total              1.79508e+06\n",
      "evaluation/num paths total           2149\n",
      "evaluation/path length Mean           975.7\n",
      "evaluation/path length Std             72.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            757\n",
      "evaluation/Rewards Mean                 4.67116\n",
      "evaluation/Rewards Std                  1.1124\n",
      "evaluation/Rewards Max                  7.15538\n",
      "evaluation/Rewards Min                 -2.60439\n",
      "evaluation/Returns Mean              4557.66\n",
      "evaluation/Returns Std                332.873\n",
      "evaluation/Returns Max               4868.44\n",
      "evaluation/Returns Min               3657.01\n",
      "evaluation/Estimation Bias Mean      1091.66\n",
      "evaluation/Estimation Bias Std        140.788\n",
      "evaluation/EB/Q_True Mean              41.3783\n",
      "evaluation/EB/Q_True Std              126.172\n",
      "evaluation/EB/Q_Pred Mean            1133.04\n",
      "evaluation/EB/Q_Pred Std               68.3201\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4557.66\n",
      "evaluation/Actions Mean                 0.0197453\n",
      "evaluation/Actions Std                  0.537792\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99984\n",
      "time/backward_policy (s)                1.82743\n",
      "time/backward_zf1 (s)                   2.06017\n",
      "time/backward_zf2 (s)                   1.93247\n",
      "time/data sampling (s)                  0.30772\n",
      "time/data storing (s)                   0.0145415\n",
      "time/evaluation sampling (s)            1.69077\n",
      "time/exploration sampling (s)           0.337069\n",
      "time/logging (s)                        0.0122048\n",
      "time/preback_alpha (s)                  0.605185\n",
      "time/preback_policy (s)                 1.06933\n",
      "time/preback_start (s)                  0.15296\n",
      "time/preback_zf (s)                     5.27919\n",
      "time/saving (s)                         0.00647832\n",
      "time/training (s)                       2.53616\n",
      "time/epoch (s)                         17.8317\n",
      "time/total (s)                       3678.8\n",
      "Epoch                                 208\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:37:53.332456 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 209 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 220000\n",
      "trainer/ZF1 Loss                       -6.16961\n",
      "trainer/ZF2 Loss                       -1.14624\n",
      "trainer/ZF Expert Reward               18.2593\n",
      "trainer/ZF Policy Reward                5.93892\n",
      "trainer/ZF CHI2 Term                   41.0213\n",
      "trainer/Policy Loss                  -980.298\n",
      "trainer/Bias Loss                      65.7565\n",
      "trainer/Bias Value                     14.1054\n",
      "trainer/Policy Grad Norm              121.776\n",
      "trainer/Policy Param Norm              37.7576\n",
      "trainer/Zf1 Grad Norm                1052.1\n",
      "trainer/Zf1 Param Norm                116.075\n",
      "trainer/Zf2 Grad Norm                1178.23\n",
      "trainer/Zf2 Param Norm                118.777\n",
      "trainer/Z Expert Predictions Mean    1152.89\n",
      "trainer/Z Expert Predictions Std       50.5984\n",
      "trainer/Z Expert Predictions Max     1246.45\n",
      "trainer/Z Expert Predictions Min      914.644\n",
      "trainer/Z Policy Predictions Mean     975.554\n",
      "trainer/Z Policy Predictions Std      373.251\n",
      "trainer/Z Policy Predictions Max     1224.14\n",
      "trainer/Z Policy Predictions Min     -502.586\n",
      "trainer/Z Expert Targets Mean        1134.63\n",
      "trainer/Z Expert Targets Std           53.0149\n",
      "trainer/Z Expert Targets Max         1226.2\n",
      "trainer/Z Expert Targets Min          880.043\n",
      "trainer/Z Policy Targets Mean         969.615\n",
      "trainer/Z Policy Targets Std          365.805\n",
      "trainer/Z Policy Targets Max         1210.27\n",
      "trainer/Z Policy Targets Min         -507.14\n",
      "trainer/Log Pis Mean                   32.6857\n",
      "trainer/Log Pis Std                     8.29739\n",
      "trainer/Policy mu Mean                  0.0911323\n",
      "trainer/Policy mu Std                   1.76612\n",
      "trainer/Policy log std Mean            -4.38312\n",
      "trainer/Policy log std Std              1.15319\n",
      "exploration/num steps total        214777\n",
      "exploration/num paths total           342\n",
      "evaluation/num steps total              1.80508e+06\n",
      "evaluation/num paths total           2159\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67564\n",
      "evaluation/Rewards Std                  1.06985\n",
      "evaluation/Rewards Max                  6.9173\n",
      "evaluation/Rewards Min                 -3.13743\n",
      "evaluation/Returns Mean              4675.64\n",
      "evaluation/Returns Std                119.35\n",
      "evaluation/Returns Max               4896.25\n",
      "evaluation/Returns Min               4524.15\n",
      "evaluation/Estimation Bias Mean      1092.74\n",
      "evaluation/Estimation Bias Std        138.033\n",
      "evaluation/EB/Q_True Mean              42.1313\n",
      "evaluation/EB/Q_True Std              129.783\n",
      "evaluation/EB/Q_Pred Mean            1134.87\n",
      "evaluation/EB/Q_Pred Std               54.9844\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4675.64\n",
      "evaluation/Actions Mean                 0.0225768\n",
      "evaluation/Actions Std                  0.531488\n",
      "evaluation/Actions Max                  0.999956\n",
      "evaluation/Actions Min                 -0.999903\n",
      "time/backward_policy (s)                1.86693\n",
      "time/backward_zf1 (s)                   1.98991\n",
      "time/backward_zf2 (s)                   1.94832\n",
      "time/data sampling (s)                  0.268996\n",
      "time/data storing (s)                   0.0140226\n",
      "time/evaluation sampling (s)            1.7223\n",
      "time/exploration sampling (s)           0.319677\n",
      "time/logging (s)                        0.0119196\n",
      "time/preback_alpha (s)                  0.550866\n",
      "time/preback_policy (s)                 1.12762\n",
      "time/preback_start (s)                  0.141214\n",
      "time/preback_zf (s)                     5.05612\n",
      "time/saving (s)                         0.00633353\n",
      "time/training (s)                       2.11836\n",
      "time/epoch (s)                         17.1426\n",
      "time/total (s)                       3695.96\n",
      "Epoch                                 209\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:38:10.228384 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 210 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 221000\n",
      "trainer/ZF1 Loss                       -4.68899\n",
      "trainer/ZF2 Loss                       -1.34541\n",
      "trainer/ZF Expert Reward               12.106\n",
      "trainer/ZF Policy Reward                2.69426\n",
      "trainer/ZF CHI2 Term                   39.5972\n",
      "trainer/Policy Loss                 -1016.74\n",
      "trainer/Bias Loss                      58.2719\n",
      "trainer/Bias Value                     14.086\n",
      "trainer/Policy Grad Norm              114.896\n",
      "trainer/Policy Param Norm              37.791\n",
      "trainer/Zf1 Grad Norm                 999.827\n",
      "trainer/Zf1 Param Norm                116.235\n",
      "trainer/Zf2 Grad Norm                1721.83\n",
      "trainer/Zf2 Param Norm                118.932\n",
      "trainer/Z Expert Predictions Mean    1142.4\n",
      "trainer/Z Expert Predictions Std       86.5475\n",
      "trainer/Z Expert Predictions Max     1239.93\n",
      "trainer/Z Expert Predictions Min      -30.6818\n",
      "trainer/Z Policy Predictions Mean    1010.46\n",
      "trainer/Z Policy Predictions Std      354.126\n",
      "trainer/Z Policy Predictions Max     1225.37\n",
      "trainer/Z Policy Predictions Min     -516.449\n",
      "trainer/Z Expert Targets Mean        1130.3\n",
      "trainer/Z Expert Targets Std           85.467\n",
      "trainer/Z Expert Targets Max         1224.87\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1007.77\n",
      "trainer/Z Policy Targets Std          348.432\n",
      "trainer/Z Policy Targets Max         1207.91\n",
      "trainer/Z Policy Targets Min         -498.123\n",
      "trainer/Log Pis Mean                   33.5381\n",
      "trainer/Log Pis Std                     8.12797\n",
      "trainer/Policy mu Mean                  0.0926794\n",
      "trainer/Policy mu Std                   1.63063\n",
      "trainer/Policy log std Mean            -4.60844\n",
      "trainer/Policy log std Std              0.944711\n",
      "exploration/num steps total        214777\n",
      "exploration/num paths total           342\n",
      "evaluation/num steps total              1.81348e+06\n",
      "evaluation/num paths total           2170\n",
      "evaluation/path length Mean           764\n",
      "evaluation/path length Std            392.775\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             32\n",
      "evaluation/Rewards Mean                 4.716\n",
      "evaluation/Rewards Std                  1.02735\n",
      "evaluation/Rewards Max                  6.81697\n",
      "evaluation/Rewards Min                 -1.40783\n",
      "evaluation/Returns Mean              3603.02\n",
      "evaluation/Returns Std               1912.02\n",
      "evaluation/Returns Max               4856.35\n",
      "evaluation/Returns Min                 43.6812\n",
      "evaluation/Estimation Bias Mean      1083.11\n",
      "evaluation/Estimation Bias Std        157.856\n",
      "evaluation/EB/Q_True Mean              50.8601\n",
      "evaluation/EB/Q_True Std              143.042\n",
      "evaluation/EB/Q_Pred Mean            1133.97\n",
      "evaluation/EB/Q_Pred Std               51.9646\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3603.02\n",
      "evaluation/Actions Mean                 0.0213207\n",
      "evaluation/Actions Std                  0.533211\n",
      "evaluation/Actions Max                  0.999827\n",
      "evaluation/Actions Min                 -0.999907\n",
      "time/backward_policy (s)                1.68743\n",
      "time/backward_zf1 (s)                   1.83307\n",
      "time/backward_zf2 (s)                   1.73915\n",
      "time/data sampling (s)                  0.274082\n",
      "time/data storing (s)                   0.014606\n",
      "time/evaluation sampling (s)            1.72486\n",
      "time/exploration sampling (s)           0.318217\n",
      "time/logging (s)                        0.0102404\n",
      "time/preback_alpha (s)                  0.564378\n",
      "time/preback_policy (s)                 0.963355\n",
      "time/preback_start (s)                  0.14506\n",
      "time/preback_zf (s)                     5.07825\n",
      "time/saving (s)                         0.00580607\n",
      "time/training (s)                       2.4655\n",
      "time/epoch (s)                         16.824\n",
      "time/total (s)                       3712.81\n",
      "Epoch                                 210\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:38:28.062814 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 211 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 222000\n",
      "trainer/ZF1 Loss                       -0.62204\n",
      "trainer/ZF2 Loss                       -6.08127\n",
      "trainer/ZF Expert Reward               18.1342\n",
      "trainer/ZF Policy Reward                8.99241\n",
      "trainer/ZF CHI2 Term                   37.9474\n",
      "trainer/Policy Loss                 -1031.26\n",
      "trainer/Bias Loss                      73.2832\n",
      "trainer/Bias Value                     14.1258\n",
      "trainer/Policy Grad Norm              134.297\n",
      "trainer/Policy Param Norm              37.8231\n",
      "trainer/Zf1 Grad Norm                1229.76\n",
      "trainer/Zf1 Param Norm                116.393\n",
      "trainer/Zf2 Grad Norm                 961.449\n",
      "trainer/Zf2 Param Norm                119.104\n",
      "trainer/Z Expert Predictions Mean    1145.64\n",
      "trainer/Z Expert Predictions Std       51.9681\n",
      "trainer/Z Expert Predictions Max     1245.4\n",
      "trainer/Z Expert Predictions Min      864.097\n",
      "trainer/Z Policy Predictions Mean    1028.99\n",
      "trainer/Z Policy Predictions Std      291.077\n",
      "trainer/Z Policy Predictions Max     1202.82\n",
      "trainer/Z Policy Predictions Min     -518.736\n",
      "trainer/Z Expert Targets Mean        1127.5\n",
      "trainer/Z Expert Targets Std           55.2097\n",
      "trainer/Z Expert Targets Max         1227.8\n",
      "trainer/Z Expert Targets Min          815.063\n",
      "trainer/Z Policy Targets Mean        1020\n",
      "trainer/Z Policy Targets Std          286.796\n",
      "trainer/Z Policy Targets Max         1201.75\n",
      "trainer/Z Policy Targets Min         -515.361\n",
      "trainer/Log Pis Mean                   32.4821\n",
      "trainer/Log Pis Std                     6.83014\n",
      "trainer/Policy mu Mean                  0.0354632\n",
      "trainer/Policy mu Std                   1.5308\n",
      "trainer/Policy log std Mean            -4.57273\n",
      "trainer/Policy log std Std              0.940231\n",
      "exploration/num steps total        215777\n",
      "exploration/num paths total           343\n",
      "evaluation/num steps total              1.82323e+06\n",
      "evaluation/num paths total           2180\n",
      "evaluation/path length Mean           974.3\n",
      "evaluation/path length Std             77.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            743\n",
      "evaluation/Rewards Mean                 4.05595\n",
      "evaluation/Rewards Std                  2.36357\n",
      "evaluation/Rewards Max                  6.94281\n",
      "evaluation/Rewards Min                 -3.34718\n",
      "evaluation/Returns Mean              3951.71\n",
      "evaluation/Returns Std               1943.86\n",
      "evaluation/Returns Max               4834.29\n",
      "evaluation/Returns Min              -1756.77\n",
      "evaluation/Estimation Bias Mean       978.285\n",
      "evaluation/Estimation Bias Std        373.041\n",
      "evaluation/EB/Q_True Mean              42.9572\n",
      "evaluation/EB/Q_True Std              130.441\n",
      "evaluation/EB/Q_Pred Mean            1021.24\n",
      "evaluation/EB/Q_Pred Std              361.867\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3951.71\n",
      "evaluation/Actions Mean                 0.0598248\n",
      "evaluation/Actions Std                  0.590069\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.89785\n",
      "time/backward_zf1 (s)                   2.02474\n",
      "time/backward_zf2 (s)                   1.93336\n",
      "time/data sampling (s)                  0.30713\n",
      "time/data storing (s)                   0.0153453\n",
      "time/evaluation sampling (s)            1.83208\n",
      "time/exploration sampling (s)           0.340188\n",
      "time/logging (s)                        0.012034\n",
      "time/preback_alpha (s)                  0.585259\n",
      "time/preback_policy (s)                 1.1287\n",
      "time/preback_start (s)                  0.149031\n",
      "time/preback_zf (s)                     5.18282\n",
      "time/saving (s)                         0.00612893\n",
      "time/training (s)                       2.35026\n",
      "time/epoch (s)                         17.7649\n",
      "time/total (s)                       3730.59\n",
      "Epoch                                 211\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:38:45.880895 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 212 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 223000\n",
      "trainer/ZF1 Loss                       -1.96618\n",
      "trainer/ZF2 Loss                        4.60866\n",
      "trainer/ZF Expert Reward               13.9472\n",
      "trainer/ZF Policy Reward                5.28465\n",
      "trainer/ZF CHI2 Term                   41.9412\n",
      "trainer/Policy Loss                 -1028.42\n",
      "trainer/Bias Loss                      47.3869\n",
      "trainer/Bias Value                     14.139\n",
      "trainer/Policy Grad Norm              140.688\n",
      "trainer/Policy Param Norm              37.8543\n",
      "trainer/Zf1 Grad Norm                1303.85\n",
      "trainer/Zf1 Param Norm                116.565\n",
      "trainer/Zf2 Grad Norm                1475.11\n",
      "trainer/Zf2 Param Norm                119.257\n",
      "trainer/Z Expert Predictions Mean    1136.9\n",
      "trainer/Z Expert Predictions Std       85.4391\n",
      "trainer/Z Expert Predictions Max     1232.76\n",
      "trainer/Z Expert Predictions Min       31.8303\n",
      "trainer/Z Policy Predictions Mean    1023.51\n",
      "trainer/Z Policy Predictions Std      257.367\n",
      "trainer/Z Policy Predictions Max     1221.54\n",
      "trainer/Z Policy Predictions Min     -223.675\n",
      "trainer/Z Expert Targets Mean        1122.95\n",
      "trainer/Z Expert Targets Std           87.6158\n",
      "trainer/Z Expert Targets Max         1229.68\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1018.22\n",
      "trainer/Z Policy Targets Std          252.842\n",
      "trainer/Z Policy Targets Max         1207.2\n",
      "trainer/Z Policy Targets Min         -213.399\n",
      "trainer/Log Pis Mean                   32.2802\n",
      "trainer/Log Pis Std                     7.22134\n",
      "trainer/Policy mu Mean                  0.0174672\n",
      "trainer/Policy mu Std                   1.56863\n",
      "trainer/Policy log std Mean            -4.51474\n",
      "trainer/Policy log std Std              0.979688\n",
      "exploration/num steps total        217777\n",
      "exploration/num paths total           345\n",
      "evaluation/num steps total              1.83293e+06\n",
      "evaluation/num paths total           2190\n",
      "evaluation/path length Mean           970.5\n",
      "evaluation/path length Std             88.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            705\n",
      "evaluation/Rewards Mean                 4.68807\n",
      "evaluation/Rewards Std                  1.05015\n",
      "evaluation/Rewards Max                  6.8806\n",
      "evaluation/Rewards Min                 -3.22994\n",
      "evaluation/Returns Mean              4549.77\n",
      "evaluation/Returns Std                425.377\n",
      "evaluation/Returns Max               4812.03\n",
      "evaluation/Returns Min               3297.95\n",
      "evaluation/Estimation Bias Mean      1087.56\n",
      "evaluation/Estimation Bias Std        146.118\n",
      "evaluation/EB/Q_True Mean              43.7644\n",
      "evaluation/EB/Q_True Std              133.077\n",
      "evaluation/EB/Q_Pred Mean            1131.32\n",
      "evaluation/EB/Q_Pred Std               58.3513\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4549.77\n",
      "evaluation/Actions Mean                 0.017745\n",
      "evaluation/Actions Std                  0.546792\n",
      "evaluation/Actions Max                  0.999959\n",
      "evaluation/Actions Min                 -0.999985\n",
      "time/backward_policy (s)                1.85077\n",
      "time/backward_zf1 (s)                   2.05452\n",
      "time/backward_zf2 (s)                   1.92881\n",
      "time/data sampling (s)                  0.307619\n",
      "time/data storing (s)                   0.0151262\n",
      "time/evaluation sampling (s)            1.80706\n",
      "time/exploration sampling (s)           0.337612\n",
      "time/logging (s)                        0.0119824\n",
      "time/preback_alpha (s)                  0.588527\n",
      "time/preback_policy (s)                 1.05829\n",
      "time/preback_start (s)                  0.150329\n",
      "time/preback_zf (s)                     5.18975\n",
      "time/saving (s)                         0.00986252\n",
      "time/training (s)                       2.43747\n",
      "time/epoch (s)                         17.7477\n",
      "time/total (s)                       3748.36\n",
      "Epoch                                 212\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:39:03.743448 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 213 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 224000\n",
      "trainer/ZF1 Loss                        9.45143\n",
      "trainer/ZF2 Loss                       -2.89665\n",
      "trainer/ZF Expert Reward               15.9413\n",
      "trainer/ZF Policy Reward                5.91739\n",
      "trainer/ZF CHI2 Term                   44.8784\n",
      "trainer/Policy Loss                 -1033.05\n",
      "trainer/Bias Loss                      80.7129\n",
      "trainer/Bias Value                     14.111\n",
      "trainer/Policy Grad Norm              134.441\n",
      "trainer/Policy Param Norm              37.8838\n",
      "trainer/Zf1 Grad Norm                1536.04\n",
      "trainer/Zf1 Param Norm                116.733\n",
      "trainer/Zf2 Grad Norm                1175.46\n",
      "trainer/Zf2 Param Norm                119.4\n",
      "trainer/Z Expert Predictions Mean    1139.66\n",
      "trainer/Z Expert Predictions Std       84.0985\n",
      "trainer/Z Expert Predictions Max     1232.53\n",
      "trainer/Z Expert Predictions Min       24.2955\n",
      "trainer/Z Policy Predictions Mean    1030.62\n",
      "trainer/Z Policy Predictions Std      252.568\n",
      "trainer/Z Policy Predictions Max     1201.97\n",
      "trainer/Z Policy Predictions Min     -388.43\n",
      "trainer/Z Expert Targets Mean        1123.72\n",
      "trainer/Z Expert Targets Std           87.0007\n",
      "trainer/Z Expert Targets Max         1215.24\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1024.7\n",
      "trainer/Z Policy Targets Std          250.255\n",
      "trainer/Z Policy Targets Max         1194.62\n",
      "trainer/Z Policy Targets Min         -386.896\n",
      "trainer/Log Pis Mean                   31.8961\n",
      "trainer/Log Pis Std                     6.17926\n",
      "trainer/Policy mu Mean                  0.0320969\n",
      "trainer/Policy mu Std                   1.433\n",
      "trainer/Policy log std Mean            -4.54013\n",
      "trainer/Policy log std Std              0.91606\n",
      "exploration/num steps total        218777\n",
      "exploration/num paths total           346\n",
      "evaluation/num steps total              1.84293e+06\n",
      "evaluation/num paths total           2200\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68942\n",
      "evaluation/Rewards Std                  1.08173\n",
      "evaluation/Rewards Max                  6.82616\n",
      "evaluation/Rewards Min                 -2.36681\n",
      "evaluation/Returns Mean              4689.42\n",
      "evaluation/Returns Std                118.957\n",
      "evaluation/Returns Max               4914.76\n",
      "evaluation/Returns Min               4456.19\n",
      "evaluation/Estimation Bias Mean      1077.74\n",
      "evaluation/Estimation Bias Std        143.678\n",
      "evaluation/EB/Q_True Mean              43.2577\n",
      "evaluation/EB/Q_True Std              133.063\n",
      "evaluation/EB/Q_Pred Mean            1121\n",
      "evaluation/EB/Q_Pred Std               61.1127\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4689.42\n",
      "evaluation/Actions Mean                 0.0213678\n",
      "evaluation/Actions Std                  0.532213\n",
      "evaluation/Actions Max                  0.999734\n",
      "evaluation/Actions Min                 -0.999945\n",
      "time/backward_policy (s)                1.87372\n",
      "time/backward_zf1 (s)                   2.06391\n",
      "time/backward_zf2 (s)                   1.9383\n",
      "time/data sampling (s)                  0.336246\n",
      "time/data storing (s)                   0.0159287\n",
      "time/evaluation sampling (s)            1.7908\n",
      "time/exploration sampling (s)           0.332999\n",
      "time/logging (s)                        0.0124612\n",
      "time/preback_alpha (s)                  0.602078\n",
      "time/preback_policy (s)                 1.07124\n",
      "time/preback_start (s)                  0.152296\n",
      "time/preback_zf (s)                     5.17904\n",
      "time/saving (s)                         0.00674849\n",
      "time/training (s)                       2.4164\n",
      "time/epoch (s)                         17.7922\n",
      "time/total (s)                       3766.17\n",
      "Epoch                                 213\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:39:21.296619 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 214 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 225000\n",
      "trainer/ZF1 Loss                       -4.741\n",
      "trainer/ZF2 Loss                       -1.94426\n",
      "trainer/ZF Expert Reward               14.2965\n",
      "trainer/ZF Policy Reward                1.65912\n",
      "trainer/ZF CHI2 Term                   42.3736\n",
      "trainer/Policy Loss                  -992.774\n",
      "trainer/Bias Loss                      75.0778\n",
      "trainer/Bias Value                     14.0892\n",
      "trainer/Policy Grad Norm              132.597\n",
      "trainer/Policy Param Norm              37.919\n",
      "trainer/Zf1 Grad Norm                1359.69\n",
      "trainer/Zf1 Param Norm                116.893\n",
      "trainer/Zf2 Grad Norm                1184.6\n",
      "trainer/Zf2 Param Norm                119.546\n",
      "trainer/Z Expert Predictions Mean    1143.55\n",
      "trainer/Z Expert Predictions Std       41.4927\n",
      "trainer/Z Expert Predictions Max     1242.48\n",
      "trainer/Z Expert Predictions Min      945.961\n",
      "trainer/Z Policy Predictions Mean     987.299\n",
      "trainer/Z Policy Predictions Std      328.499\n",
      "trainer/Z Policy Predictions Max     1205.5\n",
      "trainer/Z Policy Predictions Min     -502.341\n",
      "trainer/Z Expert Targets Mean        1129.25\n",
      "trainer/Z Expert Targets Std           43.656\n",
      "trainer/Z Expert Targets Max         1216.53\n",
      "trainer/Z Expert Targets Min          904.533\n",
      "trainer/Z Policy Targets Mean         985.64\n",
      "trainer/Z Policy Targets Std          323.686\n",
      "trainer/Z Policy Targets Max         1194.31\n",
      "trainer/Z Policy Targets Min         -481.46\n",
      "trainer/Log Pis Mean                   33.413\n",
      "trainer/Log Pis Std                     9.18234\n",
      "trainer/Policy mu Mean                  0.142171\n",
      "trainer/Policy mu Std                   1.74796\n",
      "trainer/Policy log std Mean            -4.49207\n",
      "trainer/Policy log std Std              1.04133\n",
      "exploration/num steps total        221777\n",
      "exploration/num paths total           349\n",
      "evaluation/num steps total              1.85293e+06\n",
      "evaluation/num paths total           2210\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6883\n",
      "evaluation/Rewards Std                  0.969778\n",
      "evaluation/Rewards Max                  7.03339\n",
      "evaluation/Rewards Min                 -2.83228\n",
      "evaluation/Returns Mean              4688.3\n",
      "evaluation/Returns Std                137.88\n",
      "evaluation/Returns Max               4883.63\n",
      "evaluation/Returns Min               4339.39\n",
      "evaluation/Estimation Bias Mean      1084.19\n",
      "evaluation/Estimation Bias Std        139.309\n",
      "evaluation/EB/Q_True Mean              42.6384\n",
      "evaluation/EB/Q_True Std              131.575\n",
      "evaluation/EB/Q_Pred Mean            1126.83\n",
      "evaluation/EB/Q_Pred Std               52.6684\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4688.3\n",
      "evaluation/Actions Mean                 0.0230095\n",
      "evaluation/Actions Std                  0.531786\n",
      "evaluation/Actions Max                  0.999847\n",
      "evaluation/Actions Min                 -0.999802\n",
      "time/backward_policy (s)                1.8278\n",
      "time/backward_zf1 (s)                   2.02862\n",
      "time/backward_zf2 (s)                   1.88716\n",
      "time/data sampling (s)                  0.321477\n",
      "time/data storing (s)                   0.0154169\n",
      "time/evaluation sampling (s)            1.71032\n",
      "time/exploration sampling (s)           0.340771\n",
      "time/logging (s)                        0.0126022\n",
      "time/preback_alpha (s)                  0.584975\n",
      "time/preback_policy (s)                 1.04039\n",
      "time/preback_start (s)                  0.149672\n",
      "time/preback_zf (s)                     5.13541\n",
      "time/saving (s)                         0.00656004\n",
      "time/training (s)                       2.42006\n",
      "time/epoch (s)                         17.4812\n",
      "time/total (s)                       3783.68\n",
      "Epoch                                 214\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:39:39.299328 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 215 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 226000\n",
      "trainer/ZF1 Loss                       -7.2165\n",
      "trainer/ZF2 Loss                        2.82618\n",
      "trainer/ZF Expert Reward               11.0155\n",
      "trainer/ZF Policy Reward                1.63314\n",
      "trainer/ZF CHI2 Term                   39.9596\n",
      "trainer/Policy Loss                 -1015.4\n",
      "trainer/Bias Loss                      54.1671\n",
      "trainer/Bias Value                     14.0682\n",
      "trainer/Policy Grad Norm              124.145\n",
      "trainer/Policy Param Norm              37.9511\n",
      "trainer/Zf1 Grad Norm                1300.02\n",
      "trainer/Zf1 Param Norm                117.04\n",
      "trainer/Zf2 Grad Norm                1586.79\n",
      "trainer/Zf2 Param Norm                119.689\n",
      "trainer/Z Expert Predictions Mean    1136.9\n",
      "trainer/Z Expert Predictions Std       45.5349\n",
      "trainer/Z Expert Predictions Max     1219.25\n",
      "trainer/Z Expert Predictions Min      894.569\n",
      "trainer/Z Policy Predictions Mean    1009.75\n",
      "trainer/Z Policy Predictions Std      310.74\n",
      "trainer/Z Policy Predictions Max     1216.2\n",
      "trainer/Z Policy Predictions Min     -426.555\n",
      "trainer/Z Expert Targets Mean        1125.88\n",
      "trainer/Z Expert Targets Std           45.5611\n",
      "trainer/Z Expert Targets Max         1205.24\n",
      "trainer/Z Expert Targets Min          894.725\n",
      "trainer/Z Policy Targets Mean        1008.12\n",
      "trainer/Z Policy Targets Std          307.599\n",
      "trainer/Z Policy Targets Max         1198.97\n",
      "trainer/Z Policy Targets Min         -416.3\n",
      "trainer/Log Pis Mean                   33.1035\n",
      "trainer/Log Pis Std                     9.74113\n",
      "trainer/Policy mu Mean                  0.0353793\n",
      "trainer/Policy mu Std                   1.67692\n",
      "trainer/Policy log std Mean            -4.58432\n",
      "trainer/Policy log std Std              0.937609\n",
      "exploration/num steps total        221777\n",
      "exploration/num paths total           349\n",
      "evaluation/num steps total              1.86293e+06\n",
      "evaluation/num paths total           2220\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64071\n",
      "evaluation/Rewards Std                  0.980647\n",
      "evaluation/Rewards Max                  6.98544\n",
      "evaluation/Rewards Min                 -1.80173\n",
      "evaluation/Returns Mean              4640.71\n",
      "evaluation/Returns Std                 81.4115\n",
      "evaluation/Returns Max               4788.87\n",
      "evaluation/Returns Min               4535.67\n",
      "evaluation/Estimation Bias Mean      1063.86\n",
      "evaluation/Estimation Bias Std        141.771\n",
      "evaluation/EB/Q_True Mean              42.208\n",
      "evaluation/EB/Q_True Std              130.15\n",
      "evaluation/EB/Q_Pred Mean            1106.07\n",
      "evaluation/EB/Q_Pred Std               46.9393\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4640.71\n",
      "evaluation/Actions Mean                 0.0250993\n",
      "evaluation/Actions Std                  0.5339\n",
      "evaluation/Actions Max                  0.999825\n",
      "evaluation/Actions Min                 -0.999811\n",
      "time/backward_policy (s)                1.96418\n",
      "time/backward_zf1 (s)                   2.13083\n",
      "time/backward_zf2 (s)                   2.05738\n",
      "time/data sampling (s)                  0.315829\n",
      "time/data storing (s)                   0.0156257\n",
      "time/evaluation sampling (s)            1.78883\n",
      "time/exploration sampling (s)           0.323092\n",
      "time/logging (s)                        0.013644\n",
      "time/preback_alpha (s)                  0.589338\n",
      "time/preback_policy (s)                 1.14746\n",
      "time/preback_start (s)                  0.149036\n",
      "time/preback_zf (s)                     5.16957\n",
      "time/saving (s)                         0.0107112\n",
      "time/training (s)                       2.25281\n",
      "time/epoch (s)                         17.9283\n",
      "time/total (s)                       3801.63\n",
      "Epoch                                 215\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:39:56.790374 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 216 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 227000\n",
      "trainer/ZF1 Loss                      -10.2085\n",
      "trainer/ZF2 Loss                       -0.729172\n",
      "trainer/ZF Expert Reward               11.263\n",
      "trainer/ZF Policy Reward                0.412034\n",
      "trainer/ZF CHI2 Term                   37.0192\n",
      "trainer/Policy Loss                 -1009.28\n",
      "trainer/Bias Loss                      62.5244\n",
      "trainer/Bias Value                     14.0676\n",
      "trainer/Policy Grad Norm               99.1437\n",
      "trainer/Policy Param Norm              37.9839\n",
      "trainer/Zf1 Grad Norm                1316.51\n",
      "trainer/Zf1 Param Norm                117.199\n",
      "trainer/Zf2 Grad Norm                1289.97\n",
      "trainer/Zf2 Param Norm                119.859\n",
      "trainer/Z Expert Predictions Mean    1126.75\n",
      "trainer/Z Expert Predictions Std       78.7536\n",
      "trainer/Z Expert Predictions Max     1224.29\n",
      "trainer/Z Expert Predictions Min       59.2537\n",
      "trainer/Z Policy Predictions Mean    1003.97\n",
      "trainer/Z Policy Predictions Std      262.667\n",
      "trainer/Z Policy Predictions Max     1196.2\n",
      "trainer/Z Policy Predictions Min     -380.014\n",
      "trainer/Z Expert Targets Mean        1115.49\n",
      "trainer/Z Expert Targets Std           82.3985\n",
      "trainer/Z Expert Targets Max         1210.14\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1003.56\n",
      "trainer/Z Policy Targets Std          256.219\n",
      "trainer/Z Policy Targets Max         1195.51\n",
      "trainer/Z Policy Targets Min         -360.122\n",
      "trainer/Log Pis Mean                   31.9566\n",
      "trainer/Log Pis Std                     7.07556\n",
      "trainer/Policy mu Mean                  0.0883698\n",
      "trainer/Policy mu Std                   1.46874\n",
      "trainer/Policy log std Mean            -4.52446\n",
      "trainer/Policy log std Std              0.868199\n",
      "exploration/num steps total        221777\n",
      "exploration/num paths total           349\n",
      "evaluation/num steps total              1.87293e+06\n",
      "evaluation/num paths total           2230\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.01283\n",
      "evaluation/Rewards Std                  2.38104\n",
      "evaluation/Rewards Max                  6.83961\n",
      "evaluation/Rewards Min                 -3.09917\n",
      "evaluation/Returns Mean              4012.83\n",
      "evaluation/Returns Std               2188.09\n",
      "evaluation/Returns Max               4844.42\n",
      "evaluation/Returns Min              -2548.63\n",
      "evaluation/Estimation Bias Mean      1005.89\n",
      "evaluation/Estimation Bias Std        217.291\n",
      "evaluation/EB/Q_True Mean              43.6579\n",
      "evaluation/EB/Q_True Std              134.511\n",
      "evaluation/EB/Q_Pred Mean            1049.55\n",
      "evaluation/EB/Q_Pred Std              184.216\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4012.83\n",
      "evaluation/Actions Mean                 0.0406661\n",
      "evaluation/Actions Std                  0.582196\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.86049\n",
      "time/backward_zf1 (s)                   2.0075\n",
      "time/backward_zf2 (s)                   1.91377\n",
      "time/data sampling (s)                  0.29969\n",
      "time/data storing (s)                   0.0150261\n",
      "time/evaluation sampling (s)            1.69913\n",
      "time/exploration sampling (s)           0.324386\n",
      "time/logging (s)                        0.0120657\n",
      "time/preback_alpha (s)                  0.583181\n",
      "time/preback_policy (s)                 1.08831\n",
      "time/preback_start (s)                  0.150213\n",
      "time/preback_zf (s)                     5.12804\n",
      "time/saving (s)                         0.00646225\n",
      "time/training (s)                       2.32676\n",
      "time/epoch (s)                         17.415\n",
      "time/total (s)                       3819.07\n",
      "Epoch                                 216\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:40:14.444962 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 217 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 228000\n",
      "trainer/ZF1 Loss                      448.821\n",
      "trainer/ZF2 Loss                      459.408\n",
      "trainer/ZF Expert Reward               11.5497\n",
      "trainer/ZF Policy Reward                7.56943\n",
      "trainer/ZF CHI2 Term                  489.87\n",
      "trainer/Policy Loss                 -1014.31\n",
      "trainer/Bias Loss                     151.109\n",
      "trainer/Bias Value                     14.0576\n",
      "trainer/Policy Grad Norm              129.958\n",
      "trainer/Policy Param Norm              38.0209\n",
      "trainer/Zf1 Grad Norm                3615.31\n",
      "trainer/Zf1 Param Norm                117.347\n",
      "trainer/Zf2 Grad Norm                3192.17\n",
      "trainer/Zf2 Param Norm                119.995\n",
      "trainer/Z Expert Predictions Mean    1131.06\n",
      "trainer/Z Expert Predictions Std       45.1516\n",
      "trainer/Z Expert Predictions Max     1215.37\n",
      "trainer/Z Expert Predictions Min      829.174\n",
      "trainer/Z Policy Predictions Mean    1011.37\n",
      "trainer/Z Policy Predictions Std      259.573\n",
      "trainer/Z Policy Predictions Max     1193.33\n",
      "trainer/Z Policy Predictions Min     -397.113\n",
      "trainer/Z Expert Targets Mean        1119.51\n",
      "trainer/Z Expert Targets Std           49.6895\n",
      "trainer/Z Expert Targets Max         1205.26\n",
      "trainer/Z Expert Targets Min          805.442\n",
      "trainer/Z Policy Targets Mean        1003.8\n",
      "trainer/Z Policy Targets Std          269.186\n",
      "trainer/Z Policy Targets Max         1191.82\n",
      "trainer/Z Policy Targets Min         -380.799\n",
      "trainer/Log Pis Mean                   32.0965\n",
      "trainer/Log Pis Std                     7.99081\n",
      "trainer/Policy mu Mean                  0.10769\n",
      "trainer/Policy mu Std                   1.47458\n",
      "trainer/Policy log std Mean            -4.59572\n",
      "trainer/Policy log std Std              0.866919\n",
      "exploration/num steps total        222777\n",
      "exploration/num paths total           350\n",
      "evaluation/num steps total              1.88293e+06\n",
      "evaluation/num paths total           2240\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.72564\n",
      "evaluation/Rewards Std                  1.00527\n",
      "evaluation/Rewards Max                  7.10918\n",
      "evaluation/Rewards Min                 -2.68503\n",
      "evaluation/Returns Mean              4725.64\n",
      "evaluation/Returns Std                114.116\n",
      "evaluation/Returns Max               4921.45\n",
      "evaluation/Returns Min               4486.81\n",
      "evaluation/Estimation Bias Mean      1071.23\n",
      "evaluation/Estimation Bias Std        137.896\n",
      "evaluation/EB/Q_True Mean              42.8768\n",
      "evaluation/EB/Q_True Std              132.128\n",
      "evaluation/EB/Q_Pred Mean            1114.1\n",
      "evaluation/EB/Q_Pred Std               52.3474\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4725.64\n",
      "evaluation/Actions Mean                 0.0199151\n",
      "evaluation/Actions Std                  0.538814\n",
      "evaluation/Actions Max                  0.999636\n",
      "evaluation/Actions Min                 -0.999954\n",
      "time/backward_policy (s)                1.85433\n",
      "time/backward_zf1 (s)                   2.0222\n",
      "time/backward_zf2 (s)                   1.91562\n",
      "time/data sampling (s)                  0.303481\n",
      "time/data storing (s)                   0.0147309\n",
      "time/evaluation sampling (s)            1.75686\n",
      "time/exploration sampling (s)           0.328773\n",
      "time/logging (s)                        0.0119992\n",
      "time/preback_alpha (s)                  0.580063\n",
      "time/preback_policy (s)                 1.03347\n",
      "time/preback_start (s)                  0.149778\n",
      "time/preback_zf (s)                     5.13657\n",
      "time/saving (s)                         0.00631308\n",
      "time/training (s)                       2.46938\n",
      "time/epoch (s)                         17.5836\n",
      "time/total (s)                       3836.67\n",
      "Epoch                                 217\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:40:32.084636 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 218 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 229000\n",
      "trainer/ZF1 Loss                       -1.26454\n",
      "trainer/ZF2 Loss                        2.5764\n",
      "trainer/ZF Expert Reward                9.04499\n",
      "trainer/ZF Policy Reward                0.314046\n",
      "trainer/ZF CHI2 Term                   41.8065\n",
      "trainer/Policy Loss                  -994.979\n",
      "trainer/Bias Loss                      76.9816\n",
      "trainer/Bias Value                     14.0425\n",
      "trainer/Policy Grad Norm              140.825\n",
      "trainer/Policy Param Norm              38.0498\n",
      "trainer/Zf1 Grad Norm                1454.32\n",
      "trainer/Zf1 Param Norm                117.499\n",
      "trainer/Zf2 Grad Norm                2237.76\n",
      "trainer/Zf2 Param Norm                120.147\n",
      "trainer/Z Expert Predictions Mean    1123.6\n",
      "trainer/Z Expert Predictions Std       48.9016\n",
      "trainer/Z Expert Predictions Max     1213.57\n",
      "trainer/Z Expert Predictions Min      864.65\n",
      "trainer/Z Policy Predictions Mean     987.361\n",
      "trainer/Z Policy Predictions Std      302.737\n",
      "trainer/Z Policy Predictions Max     1180.66\n",
      "trainer/Z Policy Predictions Min     -356.367\n",
      "trainer/Z Expert Targets Mean        1114.55\n",
      "trainer/Z Expert Targets Std           50.6406\n",
      "trainer/Z Expert Targets Max         1210.61\n",
      "trainer/Z Expert Targets Min          831.964\n",
      "trainer/Z Policy Targets Mean         987.047\n",
      "trainer/Z Policy Targets Std          300.214\n",
      "trainer/Z Policy Targets Max         1187.2\n",
      "trainer/Z Policy Targets Min         -349.674\n",
      "trainer/Log Pis Mean                   32.7471\n",
      "trainer/Log Pis Std                     8.00493\n",
      "trainer/Policy mu Mean                  0.0413049\n",
      "trainer/Policy mu Std                   1.76793\n",
      "trainer/Policy log std Mean            -4.52869\n",
      "trainer/Policy log std Std              1.05466\n",
      "exploration/num steps total        224777\n",
      "exploration/num paths total           352\n",
      "evaluation/num steps total              1.89293e+06\n",
      "evaluation/num paths total           2250\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67851\n",
      "evaluation/Rewards Std                  1.06984\n",
      "evaluation/Rewards Max                  6.92144\n",
      "evaluation/Rewards Min                 -2.18757\n",
      "evaluation/Returns Mean              4678.51\n",
      "evaluation/Returns Std                136.276\n",
      "evaluation/Returns Max               4873.92\n",
      "evaluation/Returns Min               4395.63\n",
      "evaluation/Estimation Bias Mean      1067.26\n",
      "evaluation/Estimation Bias Std        154.894\n",
      "evaluation/EB/Q_True Mean              45.0809\n",
      "evaluation/EB/Q_True Std              139.033\n",
      "evaluation/EB/Q_Pred Mean            1112.34\n",
      "evaluation/EB/Q_Pred Std               64.2876\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4678.51\n",
      "evaluation/Actions Mean                 0.0139815\n",
      "evaluation/Actions Std                  0.538633\n",
      "evaluation/Actions Max                  0.99994\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.82649\n",
      "time/backward_zf1 (s)                   1.9984\n",
      "time/backward_zf2 (s)                   1.89157\n",
      "time/data sampling (s)                  0.298953\n",
      "time/data storing (s)                   0.0166372\n",
      "time/evaluation sampling (s)            1.71593\n",
      "time/exploration sampling (s)           0.33912\n",
      "time/logging (s)                        0.011927\n",
      "time/preback_alpha (s)                  0.592896\n",
      "time/preback_policy (s)                 1.04081\n",
      "time/preback_start (s)                  0.153358\n",
      "time/preback_zf (s)                     5.17182\n",
      "time/saving (s)                         0.00638282\n",
      "time/training (s)                       2.50629\n",
      "time/epoch (s)                         17.5706\n",
      "time/total (s)                       3854.26\n",
      "Epoch                                 218\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:40:49.578781 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 219 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 230000\n",
      "trainer/ZF1 Loss                       -6.18019\n",
      "trainer/ZF2 Loss                       -5.70356\n",
      "trainer/ZF Expert Reward               14.9643\n",
      "trainer/ZF Policy Reward                3.47576\n",
      "trainer/ZF CHI2 Term                   37.1647\n",
      "trainer/Policy Loss                 -1018.68\n",
      "trainer/Bias Loss                      57.124\n",
      "trainer/Bias Value                     14.0505\n",
      "trainer/Policy Grad Norm              116.266\n",
      "trainer/Policy Param Norm              38.0799\n",
      "trainer/Zf1 Grad Norm                 974.33\n",
      "trainer/Zf1 Param Norm                117.667\n",
      "trainer/Zf2 Grad Norm                 922.423\n",
      "trainer/Zf2 Param Norm                120.326\n",
      "trainer/Z Expert Predictions Mean    1130.38\n",
      "trainer/Z Expert Predictions Std       40.5832\n",
      "trainer/Z Expert Predictions Max     1219.38\n",
      "trainer/Z Expert Predictions Min      901.11\n",
      "trainer/Z Policy Predictions Mean    1012.74\n",
      "trainer/Z Policy Predictions Std      261.279\n",
      "trainer/Z Policy Predictions Max     1198.36\n",
      "trainer/Z Policy Predictions Min     -345.255\n",
      "trainer/Z Expert Targets Mean        1115.41\n",
      "trainer/Z Expert Targets Std           40.9289\n",
      "trainer/Z Expert Targets Max         1199\n",
      "trainer/Z Expert Targets Min          902.758\n",
      "trainer/Z Policy Targets Mean        1009.26\n",
      "trainer/Z Policy Targets Std          256.713\n",
      "trainer/Z Policy Targets Max         1193.62\n",
      "trainer/Z Policy Targets Min         -323.364\n",
      "trainer/Log Pis Mean                   31.9374\n",
      "trainer/Log Pis Std                     6.53462\n",
      "trainer/Policy mu Mean                  0.0742617\n",
      "trainer/Policy mu Std                   1.52685\n",
      "trainer/Policy log std Mean            -4.52739\n",
      "trainer/Policy log std Std              0.951456\n",
      "exploration/num steps total        224777\n",
      "exploration/num paths total           352\n",
      "evaluation/num steps total              1.90198e+06\n",
      "evaluation/num paths total           2260\n",
      "evaluation/path length Mean           905.2\n",
      "evaluation/path length Std            261.591\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            123\n",
      "evaluation/Rewards Mean                 4.68277\n",
      "evaluation/Rewards Std                  1.13141\n",
      "evaluation/Rewards Max                  6.95649\n",
      "evaluation/Rewards Min                 -2.70095\n",
      "evaluation/Returns Mean              4238.85\n",
      "evaluation/Returns Std               1299.32\n",
      "evaluation/Returns Max               4848.04\n",
      "evaluation/Returns Min                367.693\n",
      "evaluation/Estimation Bias Mean      1055.63\n",
      "evaluation/Estimation Bias Std        157.483\n",
      "evaluation/EB/Q_True Mean              47.9196\n",
      "evaluation/EB/Q_True Std              139.458\n",
      "evaluation/EB/Q_Pred Mean            1103.55\n",
      "evaluation/EB/Q_Pred Std               64.1275\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4238.85\n",
      "evaluation/Actions Mean                 0.0260027\n",
      "evaluation/Actions Std                  0.542752\n",
      "evaluation/Actions Max                  0.99993\n",
      "evaluation/Actions Min                 -0.999968\n",
      "time/backward_policy (s)                1.82862\n",
      "time/backward_zf1 (s)                   1.9561\n",
      "time/backward_zf2 (s)                   1.87128\n",
      "time/data sampling (s)                  0.304466\n",
      "time/data storing (s)                   0.0155545\n",
      "time/evaluation sampling (s)            1.75041\n",
      "time/exploration sampling (s)           0.329107\n",
      "time/logging (s)                        0.0112694\n",
      "time/preback_alpha (s)                  0.586249\n",
      "time/preback_policy (s)                 1.04637\n",
      "time/preback_start (s)                  0.15294\n",
      "time/preback_zf (s)                     5.14681\n",
      "time/saving (s)                         0.00609407\n",
      "time/training (s)                       2.41618\n",
      "time/epoch (s)                         17.4214\n",
      "time/total (s)                       3871.71\n",
      "Epoch                                 219\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:41:07.048189 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 220 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 231000\n",
      "trainer/ZF1 Loss                       -7.48805\n",
      "trainer/ZF2 Loss                       -6.68705\n",
      "trainer/ZF Expert Reward               13.6176\n",
      "trainer/ZF Policy Reward                2.31076\n",
      "trainer/ZF CHI2 Term                   36.214\n",
      "trainer/Policy Loss                 -1020.46\n",
      "trainer/Bias Loss                      57.1258\n",
      "trainer/Bias Value                     14.0465\n",
      "trainer/Policy Grad Norm              144.653\n",
      "trainer/Policy Param Norm              38.114\n",
      "trainer/Zf1 Grad Norm                1094.6\n",
      "trainer/Zf1 Param Norm                117.82\n",
      "trainer/Zf2 Grad Norm                1235.6\n",
      "trainer/Zf2 Param Norm                120.466\n",
      "trainer/Z Expert Predictions Mean    1125.83\n",
      "trainer/Z Expert Predictions Std       43.9244\n",
      "trainer/Z Expert Predictions Max     1212.98\n",
      "trainer/Z Expert Predictions Min      908.685\n",
      "trainer/Z Policy Predictions Mean    1015.61\n",
      "trainer/Z Policy Predictions Std      252.195\n",
      "trainer/Z Policy Predictions Max     1219.82\n",
      "trainer/Z Policy Predictions Min     -403.441\n",
      "trainer/Z Expert Targets Mean        1112.21\n",
      "trainer/Z Expert Targets Std           45.0967\n",
      "trainer/Z Expert Targets Max         1200.78\n",
      "trainer/Z Expert Targets Min          892.349\n",
      "trainer/Z Policy Targets Mean        1013.3\n",
      "trainer/Z Policy Targets Std          247.069\n",
      "trainer/Z Policy Targets Max         1194.08\n",
      "trainer/Z Policy Targets Min         -388.844\n",
      "trainer/Log Pis Mean                   32.3179\n",
      "trainer/Log Pis Std                     6.44628\n",
      "trainer/Policy mu Mean                  0.109535\n",
      "trainer/Policy mu Std                   1.46749\n",
      "trainer/Policy log std Mean            -4.61505\n",
      "trainer/Policy log std Std              0.929248\n",
      "exploration/num steps total        224777\n",
      "exploration/num paths total           352\n",
      "evaluation/num steps total              1.91168e+06\n",
      "evaluation/num paths total           2271\n",
      "evaluation/path length Mean           881\n",
      "evaluation/path length Std            270.588\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            117\n",
      "evaluation/Rewards Mean                 4.71926\n",
      "evaluation/Rewards Std                  0.964505\n",
      "evaluation/Rewards Max                  6.89918\n",
      "evaluation/Rewards Min                 -1.87164\n",
      "evaluation/Returns Mean              4157.67\n",
      "evaluation/Returns Std               1307.22\n",
      "evaluation/Returns Max               4823.99\n",
      "evaluation/Returns Min                473.086\n",
      "evaluation/Estimation Bias Mean      1059.73\n",
      "evaluation/Estimation Bias Std        152.316\n",
      "evaluation/EB/Q_True Mean              44.1521\n",
      "evaluation/EB/Q_True Std              134.748\n",
      "evaluation/EB/Q_Pred Mean            1103.88\n",
      "evaluation/EB/Q_Pred Std               58.0706\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4157.67\n",
      "evaluation/Actions Mean                 0.0165899\n",
      "evaluation/Actions Std                  0.534403\n",
      "evaluation/Actions Max                  0.999928\n",
      "evaluation/Actions Min                 -0.999882\n",
      "time/backward_policy (s)                1.82537\n",
      "time/backward_zf1 (s)                   1.99515\n",
      "time/backward_zf2 (s)                   1.89008\n",
      "time/data sampling (s)                  0.314699\n",
      "time/data storing (s)                   0.014114\n",
      "time/evaluation sampling (s)            1.69707\n",
      "time/exploration sampling (s)           0.320482\n",
      "time/logging (s)                        0.0115961\n",
      "time/preback_alpha (s)                  0.581888\n",
      "time/preback_policy (s)                 1.04089\n",
      "time/preback_start (s)                  0.146863\n",
      "time/preback_zf (s)                     5.12229\n",
      "time/saving (s)                         0.00629315\n",
      "time/training (s)                       2.43156\n",
      "time/epoch (s)                         17.3984\n",
      "time/total (s)                       3889.13\n",
      "Epoch                                 220\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:41:24.836221 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 221 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 232000\n",
      "trainer/ZF1 Loss                       -1.11797\n",
      "trainer/ZF2 Loss                       -1.76534\n",
      "trainer/ZF Expert Reward               11.532\n",
      "trainer/ZF Policy Reward                1.71696\n",
      "trainer/ZF CHI2 Term                   40.3845\n",
      "trainer/Policy Loss                 -1028.54\n",
      "trainer/Bias Loss                      64.292\n",
      "trainer/Bias Value                     14.0589\n",
      "trainer/Policy Grad Norm              150.181\n",
      "trainer/Policy Param Norm              38.1433\n",
      "trainer/Zf1 Grad Norm                1760.88\n",
      "trainer/Zf1 Param Norm                117.98\n",
      "trainer/Zf2 Grad Norm                1562.64\n",
      "trainer/Zf2 Param Norm                120.622\n",
      "trainer/Z Expert Predictions Mean    1115.98\n",
      "trainer/Z Expert Predictions Std       86.0369\n",
      "trainer/Z Expert Predictions Max     1198.52\n",
      "trainer/Z Expert Predictions Min       16.1833\n",
      "trainer/Z Policy Predictions Mean    1019.82\n",
      "trainer/Z Policy Predictions Std      230.813\n",
      "trainer/Z Policy Predictions Max     1168.12\n",
      "trainer/Z Policy Predictions Min     -417.717\n",
      "trainer/Z Expert Targets Mean        1104.45\n",
      "trainer/Z Expert Targets Std           86.8662\n",
      "trainer/Z Expert Targets Max         1193.95\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1018.1\n",
      "trainer/Z Policy Targets Std          227.445\n",
      "trainer/Z Policy Targets Max         1185.27\n",
      "trainer/Z Policy Targets Min         -406.577\n",
      "trainer/Log Pis Mean                   32.3345\n",
      "trainer/Log Pis Std                     6.04561\n",
      "trainer/Policy mu Mean                 -0.0245949\n",
      "trainer/Policy mu Std                   1.47395\n",
      "trainer/Policy log std Mean            -4.59998\n",
      "trainer/Policy log std Std              0.928195\n",
      "exploration/num steps total        225777\n",
      "exploration/num paths total           353\n",
      "evaluation/num steps total              1.92168e+06\n",
      "evaluation/num paths total           2281\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.74141\n",
      "evaluation/Rewards Std                  0.952463\n",
      "evaluation/Rewards Max                  6.703\n",
      "evaluation/Rewards Min                 -1.45952\n",
      "evaluation/Returns Mean              4741.41\n",
      "evaluation/Returns Std                 71.7006\n",
      "evaluation/Returns Max               4846.18\n",
      "evaluation/Returns Min               4614.28\n",
      "evaluation/Estimation Bias Mean      1068.04\n",
      "evaluation/Estimation Bias Std        141.84\n",
      "evaluation/EB/Q_True Mean              42.4326\n",
      "evaluation/EB/Q_True Std              131.032\n",
      "evaluation/EB/Q_Pred Mean            1110.47\n",
      "evaluation/EB/Q_Pred Std               51.1696\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4741.41\n",
      "evaluation/Actions Mean                 0.0188114\n",
      "evaluation/Actions Std                  0.535372\n",
      "evaluation/Actions Max                  0.999684\n",
      "evaluation/Actions Min                 -0.999942\n",
      "time/backward_policy (s)                1.93987\n",
      "time/backward_zf1 (s)                   2.10024\n",
      "time/backward_zf2 (s)                   2.02912\n",
      "time/data sampling (s)                  0.294688\n",
      "time/data storing (s)                   0.0145829\n",
      "time/evaluation sampling (s)            1.69402\n",
      "time/exploration sampling (s)           0.323531\n",
      "time/logging (s)                        0.0125019\n",
      "time/preback_alpha (s)                  0.583417\n",
      "time/preback_policy (s)                 1.13994\n",
      "time/preback_start (s)                  0.149105\n",
      "time/preback_zf (s)                     5.14298\n",
      "time/saving (s)                         0.00577474\n",
      "time/training (s)                       2.28829\n",
      "time/epoch (s)                         17.7181\n",
      "time/total (s)                       3906.87\n",
      "Epoch                                 221\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:41:42.704203 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 222 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 233000\n",
      "trainer/ZF1 Loss                       -8.77622\n",
      "trainer/ZF2 Loss                       -8.92767\n",
      "trainer/ZF Expert Reward               17.0474\n",
      "trainer/ZF Policy Reward                7.63113\n",
      "trainer/ZF CHI2 Term                   32.7693\n",
      "trainer/Policy Loss                 -1024.17\n",
      "trainer/Bias Loss                      46.7501\n",
      "trainer/Bias Value                     14.0736\n",
      "trainer/Policy Grad Norm              137.25\n",
      "trainer/Policy Param Norm              38.1727\n",
      "trainer/Zf1 Grad Norm                 837.485\n",
      "trainer/Zf1 Param Norm                118.14\n",
      "trainer/Zf2 Grad Norm                 842.214\n",
      "trainer/Zf2 Param Norm                120.786\n",
      "trainer/Z Expert Predictions Mean    1126.03\n",
      "trainer/Z Expert Predictions Std       44.7039\n",
      "trainer/Z Expert Predictions Max     1207.68\n",
      "trainer/Z Expert Predictions Min      788.308\n",
      "trainer/Z Policy Predictions Mean    1021.21\n",
      "trainer/Z Policy Predictions Std      244.788\n",
      "trainer/Z Policy Predictions Max     1190.43\n",
      "trainer/Z Policy Predictions Min     -435.108\n",
      "trainer/Z Expert Targets Mean        1108.98\n",
      "trainer/Z Expert Targets Std           45.7439\n",
      "trainer/Z Expert Targets Max         1195.7\n",
      "trainer/Z Expert Targets Min          762.338\n",
      "trainer/Z Policy Targets Mean        1013.58\n",
      "trainer/Z Policy Targets Std          240.564\n",
      "trainer/Z Policy Targets Max         1163.26\n",
      "trainer/Z Policy Targets Min         -420.095\n",
      "trainer/Log Pis Mean                   32.5303\n",
      "trainer/Log Pis Std                     6.42747\n",
      "trainer/Policy mu Mean                  0.120936\n",
      "trainer/Policy mu Std                   1.39584\n",
      "trainer/Policy log std Mean            -4.61234\n",
      "trainer/Policy log std Std              0.88949\n",
      "exploration/num steps total        227777\n",
      "exploration/num paths total           355\n",
      "evaluation/num steps total              1.93168e+06\n",
      "evaluation/num paths total           2291\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.94343\n",
      "evaluation/Rewards Std                  2.37762\n",
      "evaluation/Rewards Max                  6.95237\n",
      "evaluation/Rewards Min                 -3.87448\n",
      "evaluation/Returns Mean              3943.43\n",
      "evaluation/Returns Std               2144.19\n",
      "evaluation/Returns Max               4860.39\n",
      "evaluation/Returns Min              -2480.62\n",
      "evaluation/Estimation Bias Mean      1015.15\n",
      "evaluation/Estimation Bias Std        197.39\n",
      "evaluation/EB/Q_True Mean              44.2856\n",
      "evaluation/EB/Q_True Std              136.334\n",
      "evaluation/EB/Q_Pred Mean            1059.44\n",
      "evaluation/EB/Q_Pred Std              159.521\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3943.43\n",
      "evaluation/Actions Mean                 0.0482605\n",
      "evaluation/Actions Std                  0.59155\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.89349\n",
      "time/backward_zf1 (s)                   2.08559\n",
      "time/backward_zf2 (s)                   1.99479\n",
      "time/data sampling (s)                  0.317235\n",
      "time/data storing (s)                   0.0147026\n",
      "time/evaluation sampling (s)            1.74624\n",
      "time/exploration sampling (s)           0.328045\n",
      "time/logging (s)                        0.0122034\n",
      "time/preback_alpha (s)                  0.586788\n",
      "time/preback_policy (s)                 1.07814\n",
      "time/preback_start (s)                  0.151604\n",
      "time/preback_zf (s)                     5.15971\n",
      "time/saving (s)                         0.00643034\n",
      "time/training (s)                       2.42149\n",
      "time/epoch (s)                         17.7965\n",
      "time/total (s)                       3924.69\n",
      "Epoch                                 222\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:42:01.219275 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 223 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 234000\n",
      "trainer/ZF1 Loss                       79.0254\n",
      "trainer/ZF2 Loss                      167.857\n",
      "trainer/ZF Expert Reward               16.9327\n",
      "trainer/ZF Policy Reward                9.94691\n",
      "trainer/ZF CHI2 Term                  163.236\n",
      "trainer/Policy Loss                  -985.718\n",
      "trainer/Bias Loss                      60.2075\n",
      "trainer/Bias Value                     14.0942\n",
      "trainer/Policy Grad Norm              132.239\n",
      "trainer/Policy Param Norm              38.205\n",
      "trainer/Zf1 Grad Norm                3270.89\n",
      "trainer/Zf1 Param Norm                118.283\n",
      "trainer/Zf2 Grad Norm                1936.73\n",
      "trainer/Zf2 Param Norm                120.941\n",
      "trainer/Z Expert Predictions Mean    1119.21\n",
      "trainer/Z Expert Predictions Std       38.3138\n",
      "trainer/Z Expert Predictions Max     1200.91\n",
      "trainer/Z Expert Predictions Min      959.092\n",
      "trainer/Z Policy Predictions Mean     985.32\n",
      "trainer/Z Policy Predictions Std      315.368\n",
      "trainer/Z Policy Predictions Max     1183.71\n",
      "trainer/Z Policy Predictions Min     -418.895\n",
      "trainer/Z Expert Targets Mean        1102.28\n",
      "trainer/Z Expert Targets Std           40.0764\n",
      "trainer/Z Expert Targets Max         1190.58\n",
      "trainer/Z Expert Targets Min          940.31\n",
      "trainer/Z Policy Targets Mean         975.373\n",
      "trainer/Z Policy Targets Std          314.943\n",
      "trainer/Z Policy Targets Max         1171.03\n",
      "trainer/Z Policy Targets Min         -428.606\n",
      "trainer/Log Pis Mean                   33.1403\n",
      "trainer/Log Pis Std                     7.36667\n",
      "trainer/Policy mu Mean                  0.0519968\n",
      "trainer/Policy mu Std                   1.61905\n",
      "trainer/Policy log std Mean            -4.62337\n",
      "trainer/Policy log std Std              1.0087\n",
      "exploration/num steps total        228777\n",
      "exploration/num paths total           356\n",
      "evaluation/num steps total              1.94168e+06\n",
      "evaluation/num paths total           2301\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66841\n",
      "evaluation/Rewards Std                  0.987475\n",
      "evaluation/Rewards Max                  6.71099\n",
      "evaluation/Rewards Min                 -1.80708\n",
      "evaluation/Returns Mean              4668.41\n",
      "evaluation/Returns Std                 98.1379\n",
      "evaluation/Returns Max               4782.14\n",
      "evaluation/Returns Min               4452.67\n",
      "evaluation/Estimation Bias Mean      1066.47\n",
      "evaluation/Estimation Bias Std        146.209\n",
      "evaluation/EB/Q_True Mean              43.7751\n",
      "evaluation/EB/Q_True Std              135.218\n",
      "evaluation/EB/Q_Pred Mean            1110.24\n",
      "evaluation/EB/Q_Pred Std               53.8022\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4668.41\n",
      "evaluation/Actions Mean                 0.0217939\n",
      "evaluation/Actions Std                  0.536376\n",
      "evaluation/Actions Max                  0.999627\n",
      "evaluation/Actions Min                 -0.999893\n",
      "time/backward_policy (s)                2.08998\n",
      "time/backward_zf1 (s)                   2.2607\n",
      "time/backward_zf2 (s)                   2.1839\n",
      "time/data sampling (s)                  0.327905\n",
      "time/data storing (s)                   0.0156928\n",
      "time/evaluation sampling (s)            1.78129\n",
      "time/exploration sampling (s)           0.336754\n",
      "time/logging (s)                        0.0126536\n",
      "time/preback_alpha (s)                  0.599127\n",
      "time/preback_policy (s)                 1.2188\n",
      "time/preback_start (s)                  0.152486\n",
      "time/preback_zf (s)                     5.18271\n",
      "time/saving (s)                         0.00687744\n",
      "time/training (s)                       2.27678\n",
      "time/epoch (s)                         18.4457\n",
      "time/total (s)                       3943.15\n",
      "Epoch                                 223\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:42:18.682219 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 224 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 235000\n",
      "trainer/ZF1 Loss                       -0.586655\n",
      "trainer/ZF2 Loss                       10.4831\n",
      "trainer/ZF Expert Reward               16.4737\n",
      "trainer/ZF Policy Reward                9.00239\n",
      "trainer/ZF CHI2 Term                   45.1587\n",
      "trainer/Policy Loss                  -996.715\n",
      "trainer/Bias Loss                      54.32\n",
      "trainer/Bias Value                     14.0752\n",
      "trainer/Policy Grad Norm              139.212\n",
      "trainer/Policy Param Norm              38.2355\n",
      "trainer/Zf1 Grad Norm                 957.675\n",
      "trainer/Zf1 Param Norm                118.439\n",
      "trainer/Zf2 Grad Norm                1052.61\n",
      "trainer/Zf2 Param Norm                121.103\n",
      "trainer/Z Expert Predictions Mean    1117.53\n",
      "trainer/Z Expert Predictions Std       46.588\n",
      "trainer/Z Expert Predictions Max     1212.87\n",
      "trainer/Z Expert Predictions Min      831.599\n",
      "trainer/Z Policy Predictions Mean     993.964\n",
      "trainer/Z Policy Predictions Std      272.662\n",
      "trainer/Z Policy Predictions Max     1193.28\n",
      "trainer/Z Policy Predictions Min     -393.692\n",
      "trainer/Z Expert Targets Mean        1101.06\n",
      "trainer/Z Expert Targets Std           48.0614\n",
      "trainer/Z Expert Targets Max         1193.73\n",
      "trainer/Z Expert Targets Min          804.99\n",
      "trainer/Z Policy Targets Mean         984.962\n",
      "trainer/Z Policy Targets Std          266.576\n",
      "trainer/Z Policy Targets Max         1175.11\n",
      "trainer/Z Policy Targets Min         -376.662\n",
      "trainer/Log Pis Mean                   33.0699\n",
      "trainer/Log Pis Std                     7.81977\n",
      "trainer/Policy mu Mean                  0.00241195\n",
      "trainer/Policy mu Std                   1.70076\n",
      "trainer/Policy log std Mean            -4.5483\n",
      "trainer/Policy log std Std              1.06787\n",
      "exploration/num steps total        231777\n",
      "exploration/num paths total           359\n",
      "evaluation/num steps total              1.95124e+06\n",
      "evaluation/num paths total           2311\n",
      "evaluation/path length Mean           956\n",
      "evaluation/path length Std            132\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            560\n",
      "evaluation/Rewards Mean                 3.97469\n",
      "evaluation/Rewards Std                  2.3635\n",
      "evaluation/Rewards Max                  6.93486\n",
      "evaluation/Rewards Min                 -4.15419\n",
      "evaluation/Returns Mean              3799.81\n",
      "evaluation/Returns Std               2106.75\n",
      "evaluation/Returns Max               4813.79\n",
      "evaluation/Returns Min              -2188.67\n",
      "evaluation/Estimation Bias Mean       908.24\n",
      "evaluation/Estimation Bias Std        487.501\n",
      "evaluation/EB/Q_True Mean              44.2351\n",
      "evaluation/EB/Q_True Std              132.359\n",
      "evaluation/EB/Q_Pred Mean             952.475\n",
      "evaluation/EB/Q_Pred Std              434.064\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3799.81\n",
      "evaluation/Actions Mean                 0.107474\n",
      "evaluation/Actions Std                  0.578076\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.81391\n",
      "time/backward_zf1 (s)                   1.98148\n",
      "time/backward_zf2 (s)                   1.88263\n",
      "time/data sampling (s)                  0.316376\n",
      "time/data storing (s)                   0.0146254\n",
      "time/evaluation sampling (s)            1.6688\n",
      "time/exploration sampling (s)           0.33246\n",
      "time/logging (s)                        0.011443\n",
      "time/preback_alpha (s)                  0.581123\n",
      "time/preback_policy (s)                 1.0282\n",
      "time/preback_start (s)                  0.149852\n",
      "time/preback_zf (s)                     5.13599\n",
      "time/saving (s)                         0.00713992\n",
      "time/training (s)                       2.46868\n",
      "time/epoch (s)                         17.3927\n",
      "time/total (s)                       3960.56\n",
      "Epoch                                 224\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:42:36.622380 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 225 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 236000\n",
      "trainer/ZF1 Loss                       -4.7402\n",
      "trainer/ZF2 Loss                      -10.1996\n",
      "trainer/ZF Expert Reward               12.1822\n",
      "trainer/ZF Policy Reward                1.92475\n",
      "trainer/ZF CHI2 Term                   35.5732\n",
      "trainer/Policy Loss                  -977.487\n",
      "trainer/Bias Loss                      54.9409\n",
      "trainer/Bias Value                     14.1219\n",
      "trainer/Policy Grad Norm              134.931\n",
      "trainer/Policy Param Norm              38.2689\n",
      "trainer/Zf1 Grad Norm                1292.35\n",
      "trainer/Zf1 Param Norm                118.568\n",
      "trainer/Zf2 Grad Norm                1157\n",
      "trainer/Zf2 Param Norm                121.247\n",
      "trainer/Z Expert Predictions Mean    1111.32\n",
      "trainer/Z Expert Predictions Std       40.051\n",
      "trainer/Z Expert Predictions Max     1198.49\n",
      "trainer/Z Expert Predictions Min      931.337\n",
      "trainer/Z Policy Predictions Mean     970.723\n",
      "trainer/Z Policy Predictions Std      300.668\n",
      "trainer/Z Policy Predictions Max     1200.44\n",
      "trainer/Z Policy Predictions Min     -379.236\n",
      "trainer/Z Expert Targets Mean        1099.14\n",
      "trainer/Z Expert Targets Std           41.4632\n",
      "trainer/Z Expert Targets Max         1190.11\n",
      "trainer/Z Expert Targets Min          905.549\n",
      "trainer/Z Policy Targets Mean         968.799\n",
      "trainer/Z Policy Targets Std          294.387\n",
      "trainer/Z Policy Targets Max         1186.6\n",
      "trainer/Z Policy Targets Min         -383.409\n",
      "trainer/Log Pis Mean                   33.1167\n",
      "trainer/Log Pis Std                     7.79885\n",
      "trainer/Policy mu Mean                  0.055217\n",
      "trainer/Policy mu Std                   1.65193\n",
      "trainer/Policy log std Mean            -4.51598\n",
      "trainer/Policy log std Std              1.02045\n",
      "exploration/num steps total        231777\n",
      "exploration/num paths total           359\n",
      "evaluation/num steps total              1.96124e+06\n",
      "evaluation/num paths total           2321\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.56452\n",
      "evaluation/Rewards Std                  0.926904\n",
      "evaluation/Rewards Max                  6.53836\n",
      "evaluation/Rewards Min                 -1.67293\n",
      "evaluation/Returns Mean              4564.52\n",
      "evaluation/Returns Std                 78.1726\n",
      "evaluation/Returns Max               4681.86\n",
      "evaluation/Returns Min               4417.59\n",
      "evaluation/Estimation Bias Mean      1049.03\n",
      "evaluation/Estimation Bias Std        136.165\n",
      "evaluation/EB/Q_True Mean              41.9656\n",
      "evaluation/EB/Q_True Std              129.975\n",
      "evaluation/EB/Q_Pred Mean            1090.99\n",
      "evaluation/EB/Q_Pred Std               46.2647\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4564.52\n",
      "evaluation/Actions Mean                 0.0246782\n",
      "evaluation/Actions Std                  0.536694\n",
      "evaluation/Actions Max                  0.999783\n",
      "evaluation/Actions Min                 -0.999845\n",
      "time/backward_policy (s)                1.91962\n",
      "time/backward_zf1 (s)                   2.06176\n",
      "time/backward_zf2 (s)                   1.95577\n",
      "time/data sampling (s)                  0.34059\n",
      "time/data storing (s)                   0.0161686\n",
      "time/evaluation sampling (s)            1.7589\n",
      "time/exploration sampling (s)           0.327626\n",
      "time/logging (s)                        0.0122254\n",
      "time/preback_alpha (s)                  0.596113\n",
      "time/preback_policy (s)                 1.08882\n",
      "time/preback_start (s)                  0.151995\n",
      "time/preback_zf (s)                     5.20044\n",
      "time/saving (s)                         0.0064329\n",
      "time/training (s)                       2.43617\n",
      "time/epoch (s)                         17.8726\n",
      "time/total (s)                       3978.45\n",
      "Epoch                                 225\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:42:54.273582 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 226 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 237000\n",
      "trainer/ZF1 Loss                       -2.66656\n",
      "trainer/ZF2 Loss                       -1.02382\n",
      "trainer/ZF Expert Reward               11.6892\n",
      "trainer/ZF Policy Reward                2.71684\n",
      "trainer/ZF CHI2 Term                   39.9689\n",
      "trainer/Policy Loss                  -973.962\n",
      "trainer/Bias Loss                      65.6396\n",
      "trainer/Bias Value                     14.1206\n",
      "trainer/Policy Grad Norm              123.331\n",
      "trainer/Policy Param Norm              38.2973\n",
      "trainer/Zf1 Grad Norm                1434.14\n",
      "trainer/Zf1 Param Norm                118.724\n",
      "trainer/Zf2 Grad Norm                 928.355\n",
      "trainer/Zf2 Param Norm                121.409\n",
      "trainer/Z Expert Predictions Mean    1110.72\n",
      "trainer/Z Expert Predictions Std       44.0062\n",
      "trainer/Z Expert Predictions Max     1188.89\n",
      "trainer/Z Expert Predictions Min      875.915\n",
      "trainer/Z Policy Predictions Mean     968.048\n",
      "trainer/Z Policy Predictions Std      311.696\n",
      "trainer/Z Policy Predictions Max     1167.64\n",
      "trainer/Z Policy Predictions Min     -436.677\n",
      "trainer/Z Expert Targets Mean        1099.03\n",
      "trainer/Z Expert Targets Std           44.8772\n",
      "trainer/Z Expert Targets Max         1184.58\n",
      "trainer/Z Expert Targets Min          854.066\n",
      "trainer/Z Policy Targets Mean         965.331\n",
      "trainer/Z Policy Targets Std          307.277\n",
      "trainer/Z Policy Targets Max         1161.24\n",
      "trainer/Z Policy Targets Min         -438.604\n",
      "trainer/Log Pis Mean                   33.1734\n",
      "trainer/Log Pis Std                     7.33786\n",
      "trainer/Policy mu Mean                  0.064525\n",
      "trainer/Policy mu Std                   1.77368\n",
      "trainer/Policy log std Mean            -4.53216\n",
      "trainer/Policy log std Std              1.05883\n",
      "exploration/num steps total        231777\n",
      "exploration/num paths total           359\n",
      "evaluation/num steps total              1.97124e+06\n",
      "evaluation/num paths total           2331\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68782\n",
      "evaluation/Rewards Std                  0.995462\n",
      "evaluation/Rewards Max                  6.89515\n",
      "evaluation/Rewards Min                 -1.75602\n",
      "evaluation/Returns Mean              4687.82\n",
      "evaluation/Returns Std                 97.9748\n",
      "evaluation/Returns Max               4900.26\n",
      "evaluation/Returns Min               4505.17\n",
      "evaluation/Estimation Bias Mean      1046.1\n",
      "evaluation/Estimation Bias Std        142.819\n",
      "evaluation/EB/Q_True Mean              42.9924\n",
      "evaluation/EB/Q_True Std              132.688\n",
      "evaluation/EB/Q_Pred Mean            1089.09\n",
      "evaluation/EB/Q_Pred Std               53.4543\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4687.82\n",
      "evaluation/Actions Mean                 0.021691\n",
      "evaluation/Actions Std                  0.534567\n",
      "evaluation/Actions Max                  0.999771\n",
      "evaluation/Actions Min                 -0.999958\n",
      "time/backward_policy (s)                1.91128\n",
      "time/backward_zf1 (s)                   2.04825\n",
      "time/backward_zf2 (s)                   1.99346\n",
      "time/data sampling (s)                  0.300539\n",
      "time/data storing (s)                   0.0143971\n",
      "time/evaluation sampling (s)            1.7425\n",
      "time/exploration sampling (s)           0.31921\n",
      "time/logging (s)                        0.011881\n",
      "time/preback_alpha (s)                  0.57977\n",
      "time/preback_policy (s)                 1.11627\n",
      "time/preback_start (s)                  0.148532\n",
      "time/preback_zf (s)                     5.13228\n",
      "time/saving (s)                         0.0176776\n",
      "time/training (s)                       2.24837\n",
      "time/epoch (s)                         17.5844\n",
      "time/total (s)                       3996.05\n",
      "Epoch                                 226\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:43:11.803079 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 227 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 238000\n",
      "trainer/ZF1 Loss                       -2.01265\n",
      "trainer/ZF2 Loss                       -3.08538\n",
      "trainer/ZF Expert Reward               14.2434\n",
      "trainer/ZF Policy Reward                3.00509\n",
      "trainer/ZF CHI2 Term                   40.3929\n",
      "trainer/Policy Loss                 -1007.28\n",
      "trainer/Bias Loss                      45.6915\n",
      "trainer/Bias Value                     14.1196\n",
      "trainer/Policy Grad Norm              125.448\n",
      "trainer/Policy Param Norm              38.332\n",
      "trainer/Zf1 Grad Norm                 936.394\n",
      "trainer/Zf1 Param Norm                118.868\n",
      "trainer/Zf2 Grad Norm                1194.11\n",
      "trainer/Zf2 Param Norm                121.562\n",
      "trainer/Z Expert Predictions Mean    1103.79\n",
      "trainer/Z Expert Predictions Std       48.6164\n",
      "trainer/Z Expert Predictions Max     1199.63\n",
      "trainer/Z Expert Predictions Min      849.08\n",
      "trainer/Z Policy Predictions Mean    1004.16\n",
      "trainer/Z Policy Predictions Std      246.457\n",
      "trainer/Z Policy Predictions Max     1178.19\n",
      "trainer/Z Policy Predictions Min     -418.089\n",
      "trainer/Z Expert Targets Mean        1089.54\n",
      "trainer/Z Expert Targets Std           50.3892\n",
      "trainer/Z Expert Targets Max         1189.54\n",
      "trainer/Z Expert Targets Min          846.36\n",
      "trainer/Z Policy Targets Mean        1001.16\n",
      "trainer/Z Policy Targets Std          243.242\n",
      "trainer/Z Policy Targets Max         1167.81\n",
      "trainer/Z Policy Targets Min         -402.959\n",
      "trainer/Log Pis Mean                   32.0238\n",
      "trainer/Log Pis Std                     6.38753\n",
      "trainer/Policy mu Mean                  0.0338119\n",
      "trainer/Policy mu Std                   1.37925\n",
      "trainer/Policy log std Mean            -4.65035\n",
      "trainer/Policy log std Std              0.860692\n",
      "exploration/num steps total        232777\n",
      "exploration/num paths total           360\n",
      "evaluation/num steps total              1.98124e+06\n",
      "evaluation/num paths total           2341\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.93074\n",
      "evaluation/Rewards Std                  2.32661\n",
      "evaluation/Rewards Max                  6.93051\n",
      "evaluation/Rewards Min                 -3.31044\n",
      "evaluation/Returns Mean              3930.74\n",
      "evaluation/Returns Std               2112.04\n",
      "evaluation/Returns Max               4692.5\n",
      "evaluation/Returns Min              -2403.23\n",
      "evaluation/Estimation Bias Mean       893.691\n",
      "evaluation/Estimation Bias Std        446.747\n",
      "evaluation/EB/Q_True Mean              43.2446\n",
      "evaluation/EB/Q_True Std              133.045\n",
      "evaluation/EB/Q_Pred Mean             936.935\n",
      "evaluation/EB/Q_Pred Std              440.949\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3930.74\n",
      "evaluation/Actions Mean                 0.0163751\n",
      "evaluation/Actions Std                  0.584826\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86476\n",
      "time/backward_zf1 (s)                   2.00467\n",
      "time/backward_zf2 (s)                   1.92858\n",
      "time/data sampling (s)                  0.308753\n",
      "time/data storing (s)                   0.0140622\n",
      "time/evaluation sampling (s)            1.73175\n",
      "time/exploration sampling (s)           0.316471\n",
      "time/logging (s)                        0.0126504\n",
      "time/preback_alpha (s)                  0.584395\n",
      "time/preback_policy (s)                 1.07285\n",
      "time/preback_start (s)                  0.151268\n",
      "time/preback_zf (s)                     5.12837\n",
      "time/saving (s)                         0.00678365\n",
      "time/training (s)                       2.33631\n",
      "time/epoch (s)                         17.4617\n",
      "time/total (s)                       4013.53\n",
      "Epoch                                 227\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:43:30.353806 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 228 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 239000\n",
      "trainer/ZF1 Loss                        1.49977\n",
      "trainer/ZF2 Loss                       -2.25521\n",
      "trainer/ZF Expert Reward                9.33334\n",
      "trainer/ZF Policy Reward               -0.0720398\n",
      "trainer/ZF CHI2 Term                   40.5639\n",
      "trainer/Policy Loss                 -1012.28\n",
      "trainer/Bias Loss                      63.1616\n",
      "trainer/Bias Value                     14.1239\n",
      "trainer/Policy Grad Norm              151.075\n",
      "trainer/Policy Param Norm              38.3666\n",
      "trainer/Zf1 Grad Norm                1628.52\n",
      "trainer/Zf1 Param Norm                119.021\n",
      "trainer/Zf2 Grad Norm                1631.69\n",
      "trainer/Zf2 Param Norm                121.716\n",
      "trainer/Z Expert Predictions Mean    1095.62\n",
      "trainer/Z Expert Predictions Std       51.6904\n",
      "trainer/Z Expert Predictions Max     1204.85\n",
      "trainer/Z Expert Predictions Min      818.09\n",
      "trainer/Z Policy Predictions Mean    1003.1\n",
      "trainer/Z Policy Predictions Std      214.958\n",
      "trainer/Z Policy Predictions Max     1161.3\n",
      "trainer/Z Policy Predictions Min     -343.377\n",
      "trainer/Z Expert Targets Mean        1086.29\n",
      "trainer/Z Expert Targets Std           51.7048\n",
      "trainer/Z Expert Targets Max         1184.94\n",
      "trainer/Z Expert Targets Min          808.955\n",
      "trainer/Z Policy Targets Mean        1003.18\n",
      "trainer/Z Policy Targets Std          211.865\n",
      "trainer/Z Policy Targets Max         1159.12\n",
      "trainer/Z Policy Targets Min         -317.513\n",
      "trainer/Log Pis Mean                   31.8548\n",
      "trainer/Log Pis Std                     6.53681\n",
      "trainer/Policy mu Mean                  0.061254\n",
      "trainer/Policy mu Std                   1.40265\n",
      "trainer/Policy log std Mean            -4.6261\n",
      "trainer/Policy log std Std              0.874774\n",
      "exploration/num steps total        234777\n",
      "exploration/num paths total           362\n",
      "evaluation/num steps total              1.99031e+06\n",
      "evaluation/num paths total           2352\n",
      "evaluation/path length Mean           825.273\n",
      "evaluation/path length Std            370.656\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             35\n",
      "evaluation/Rewards Mean                 4.62924\n",
      "evaluation/Rewards Std                  0.963563\n",
      "evaluation/Rewards Max                  6.82033\n",
      "evaluation/Rewards Min                 -2.77951\n",
      "evaluation/Returns Mean              3820.39\n",
      "evaluation/Returns Std               1771.25\n",
      "evaluation/Returns Max               4753.57\n",
      "evaluation/Returns Min                 52.8188\n",
      "evaluation/Estimation Bias Mean      1028.93\n",
      "evaluation/Estimation Bias Std        153.622\n",
      "evaluation/EB/Q_True Mean              46.8719\n",
      "evaluation/EB/Q_True Std              136.615\n",
      "evaluation/EB/Q_Pred Mean            1075.8\n",
      "evaluation/EB/Q_Pred Std               51.8572\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3820.39\n",
      "evaluation/Actions Mean                 0.0190152\n",
      "evaluation/Actions Std                  0.530443\n",
      "evaluation/Actions Max                  0.999881\n",
      "evaluation/Actions Min                 -0.999968\n",
      "time/backward_policy (s)                2.07348\n",
      "time/backward_zf1 (s)                   2.25836\n",
      "time/backward_zf2 (s)                   2.15007\n",
      "time/data sampling (s)                  0.316436\n",
      "time/data storing (s)                   0.0150301\n",
      "time/evaluation sampling (s)            1.75271\n",
      "time/exploration sampling (s)           0.33399\n",
      "time/logging (s)                        0.011097\n",
      "time/preback_alpha (s)                  0.608314\n",
      "time/preback_policy (s)                 1.17169\n",
      "time/preback_start (s)                  0.154326\n",
      "time/preback_zf (s)                     5.22431\n",
      "time/saving (s)                         0.00669068\n",
      "time/training (s)                       2.39659\n",
      "time/epoch (s)                         18.4731\n",
      "time/total (s)                       4032.03\n",
      "Epoch                                 228\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:43:48.571729 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 229 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 240000\n",
      "trainer/ZF1 Loss                        4.61971\n",
      "trainer/ZF2 Loss                        4.5697\n",
      "trainer/ZF Expert Reward                7.19471\n",
      "trainer/ZF Policy Reward               -1.06\n",
      "trainer/ZF CHI2 Term                   45.5078\n",
      "trainer/Policy Loss                  -948.741\n",
      "trainer/Bias Loss                      78.1622\n",
      "trainer/Bias Value                     14.0846\n",
      "trainer/Policy Grad Norm              117.317\n",
      "trainer/Policy Param Norm              38.4009\n",
      "trainer/Zf1 Grad Norm                1792.03\n",
      "trainer/Zf1 Param Norm                119.186\n",
      "trainer/Zf2 Grad Norm                1719.61\n",
      "trainer/Zf2 Param Norm                121.843\n",
      "trainer/Z Expert Predictions Mean    1096.35\n",
      "trainer/Z Expert Predictions Std       47.8839\n",
      "trainer/Z Expert Predictions Max     1191.69\n",
      "trainer/Z Expert Predictions Min      800.675\n",
      "trainer/Z Policy Predictions Mean     941.961\n",
      "trainer/Z Policy Predictions Std      322.161\n",
      "trainer/Z Policy Predictions Max     1162.87\n",
      "trainer/Z Policy Predictions Min     -435.94\n",
      "trainer/Z Expert Targets Mean        1089.16\n",
      "trainer/Z Expert Targets Std           48.8494\n",
      "trainer/Z Expert Targets Max         1191.52\n",
      "trainer/Z Expert Targets Min          793.612\n",
      "trainer/Z Policy Targets Mean         943.021\n",
      "trainer/Z Policy Targets Std          319.853\n",
      "trainer/Z Policy Targets Max         1164.61\n",
      "trainer/Z Policy Targets Min         -450.358\n",
      "trainer/Log Pis Mean                   32.9883\n",
      "trainer/Log Pis Std                     7.91124\n",
      "trainer/Policy mu Mean                  0.0407013\n",
      "trainer/Policy mu Std                   1.70685\n",
      "trainer/Policy log std Mean            -4.5317\n",
      "trainer/Policy log std Std              1.01703\n",
      "exploration/num steps total        234777\n",
      "exploration/num paths total           362\n",
      "evaluation/num steps total              2.00031e+06\n",
      "evaluation/num paths total           2362\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70483\n",
      "evaluation/Rewards Std                  1.03941\n",
      "evaluation/Rewards Max                  6.86269\n",
      "evaluation/Rewards Min                 -2.33421\n",
      "evaluation/Returns Mean              4704.83\n",
      "evaluation/Returns Std                 95.7733\n",
      "evaluation/Returns Max               4854.89\n",
      "evaluation/Returns Min               4579.67\n",
      "evaluation/Estimation Bias Mean      1040.15\n",
      "evaluation/Estimation Bias Std        150.857\n",
      "evaluation/EB/Q_True Mean              44.7511\n",
      "evaluation/EB/Q_True Std              137.809\n",
      "evaluation/EB/Q_Pred Mean            1084.9\n",
      "evaluation/EB/Q_Pred Std               58.293\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4704.83\n",
      "evaluation/Actions Mean                 0.0190962\n",
      "evaluation/Actions Std                  0.530927\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999901\n",
      "time/backward_policy (s)                1.99065\n",
      "time/backward_zf1 (s)                   2.14547\n",
      "time/backward_zf2 (s)                   2.04583\n",
      "time/data sampling (s)                  0.334882\n",
      "time/data storing (s)                   0.0151425\n",
      "time/evaluation sampling (s)            1.73827\n",
      "time/exploration sampling (s)           0.325167\n",
      "time/logging (s)                        0.0124219\n",
      "time/preback_alpha (s)                  0.602565\n",
      "time/preback_policy (s)                 1.11533\n",
      "time/preback_start (s)                  0.150618\n",
      "time/preback_zf (s)                     5.22222\n",
      "time/saving (s)                         0.00645937\n",
      "time/training (s)                       2.44268\n",
      "time/epoch (s)                         18.1477\n",
      "time/total (s)                       4050.2\n",
      "Epoch                                 229\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:44:06.864420 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 230 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 241000\n",
      "trainer/ZF1 Loss                        5.86031\n",
      "trainer/ZF2 Loss                        7.49753\n",
      "trainer/ZF Expert Reward               19.8893\n",
      "trainer/ZF Policy Reward                8.28208\n",
      "trainer/ZF CHI2 Term                   50.9644\n",
      "trainer/Policy Loss                  -991.433\n",
      "trainer/Bias Loss                      80.6436\n",
      "trainer/Bias Value                     14.0966\n",
      "trainer/Policy Grad Norm              193.846\n",
      "trainer/Policy Param Norm              38.4307\n",
      "trainer/Zf1 Grad Norm                1440.51\n",
      "trainer/Zf1 Param Norm                119.349\n",
      "trainer/Zf2 Grad Norm                1757.36\n",
      "trainer/Zf2 Param Norm                121.988\n",
      "trainer/Z Expert Predictions Mean    1098.74\n",
      "trainer/Z Expert Predictions Std      106.065\n",
      "trainer/Z Expert Predictions Max     1212.43\n",
      "trainer/Z Expert Predictions Min      -15.3727\n",
      "trainer/Z Policy Predictions Mean     988.656\n",
      "trainer/Z Policy Predictions Std      278.737\n",
      "trainer/Z Policy Predictions Max     1157.03\n",
      "trainer/Z Policy Predictions Min     -405.615\n",
      "trainer/Z Expert Targets Mean        1078.85\n",
      "trainer/Z Expert Targets Std          105.213\n",
      "trainer/Z Expert Targets Max         1179.38\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         980.374\n",
      "trainer/Z Policy Targets Std          269.442\n",
      "trainer/Z Policy Targets Max         1159.71\n",
      "trainer/Z Policy Targets Min         -390.867\n",
      "trainer/Log Pis Mean                   33.0083\n",
      "trainer/Log Pis Std                     7.32997\n",
      "trainer/Policy mu Mean                  0.0334774\n",
      "trainer/Policy mu Std                   1.67057\n",
      "trainer/Policy log std Mean            -4.58696\n",
      "trainer/Policy log std Std              0.984565\n",
      "exploration/num steps total        234777\n",
      "exploration/num paths total           362\n",
      "evaluation/num steps total              2.01031e+06\n",
      "evaluation/num paths total           2372\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.58942\n",
      "evaluation/Rewards Std                  0.92509\n",
      "evaluation/Rewards Max                  6.81711\n",
      "evaluation/Rewards Min                 -1.68539\n",
      "evaluation/Returns Mean              4589.42\n",
      "evaluation/Returns Std                 76.4116\n",
      "evaluation/Returns Max               4716.74\n",
      "evaluation/Returns Min               4472.31\n",
      "evaluation/Estimation Bias Mean      1039.67\n",
      "evaluation/Estimation Bias Std        135.47\n",
      "evaluation/EB/Q_True Mean              41.2731\n",
      "evaluation/EB/Q_True Std              127.399\n",
      "evaluation/EB/Q_Pred Mean            1080.95\n",
      "evaluation/EB/Q_Pred Std               47.6685\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4589.42\n",
      "evaluation/Actions Mean                 0.0243353\n",
      "evaluation/Actions Std                  0.531785\n",
      "evaluation/Actions Max                  0.999612\n",
      "evaluation/Actions Min                 -0.999884\n",
      "time/backward_policy (s)                1.95616\n",
      "time/backward_zf1 (s)                   2.1482\n",
      "time/backward_zf2 (s)                   2.06315\n",
      "time/data sampling (s)                  0.326144\n",
      "time/data storing (s)                   0.0151513\n",
      "time/evaluation sampling (s)            1.76866\n",
      "time/exploration sampling (s)           0.321712\n",
      "time/logging (s)                        0.0117939\n",
      "time/preback_alpha (s)                  0.607244\n",
      "time/preback_policy (s)                 1.14494\n",
      "time/preback_start (s)                  0.153551\n",
      "time/preback_zf (s)                     5.25876\n",
      "time/saving (s)                         0.00605068\n",
      "time/training (s)                       2.43359\n",
      "time/epoch (s)                         18.2151\n",
      "time/total (s)                       4068.44\n",
      "Epoch                                 230\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:44:24.475637 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 231 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 242000\n",
      "trainer/ZF1 Loss                      157.25\n",
      "trainer/ZF2 Loss                      133.039\n",
      "trainer/ZF Expert Reward               13.1312\n",
      "trainer/ZF Policy Reward                6.11904\n",
      "trainer/ZF CHI2 Term                  183.841\n",
      "trainer/Policy Loss                  -987.309\n",
      "trainer/Bias Loss                      61.0122\n",
      "trainer/Bias Value                     14.0982\n",
      "trainer/Policy Grad Norm              149.133\n",
      "trainer/Policy Param Norm              38.4593\n",
      "trainer/Zf1 Grad Norm                5236.67\n",
      "trainer/Zf1 Param Norm                119.501\n",
      "trainer/Zf2 Grad Norm                5009.8\n",
      "trainer/Zf2 Param Norm                122.144\n",
      "trainer/Z Expert Predictions Mean    1094.19\n",
      "trainer/Z Expert Predictions Std       77.0654\n",
      "trainer/Z Expert Predictions Max     1178.04\n",
      "trainer/Z Expert Predictions Min       35.0005\n",
      "trainer/Z Policy Predictions Mean     982.12\n",
      "trainer/Z Policy Predictions Std      252.172\n",
      "trainer/Z Policy Predictions Max     1159.53\n",
      "trainer/Z Policy Predictions Min     -348.379\n",
      "trainer/Z Expert Targets Mean        1081.06\n",
      "trainer/Z Expert Targets Std           79.752\n",
      "trainer/Z Expert Targets Max         1171.62\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         976.001\n",
      "trainer/Z Policy Targets Std          255.715\n",
      "trainer/Z Policy Targets Max         1133.02\n",
      "trainer/Z Policy Targets Min         -307.643\n",
      "trainer/Log Pis Mean                   32.0047\n",
      "trainer/Log Pis Std                     5.51888\n",
      "trainer/Policy mu Mean                  0.147194\n",
      "trainer/Policy mu Std                   1.47443\n",
      "trainer/Policy log std Mean            -4.63086\n",
      "trainer/Policy log std Std              0.940571\n",
      "exploration/num steps total        235777\n",
      "exploration/num paths total           363\n",
      "evaluation/num steps total              2.02025e+06\n",
      "evaluation/num paths total           2382\n",
      "evaluation/path length Mean           993.5\n",
      "evaluation/path length Std             19.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            935\n",
      "evaluation/Rewards Mean                 4.7099\n",
      "evaluation/Rewards Std                  0.995817\n",
      "evaluation/Rewards Max                  7.29228\n",
      "evaluation/Rewards Min                 -2.05257\n",
      "evaluation/Returns Mean              4679.29\n",
      "evaluation/Returns Std                113.731\n",
      "evaluation/Returns Max               4849.37\n",
      "evaluation/Returns Min               4390.14\n",
      "evaluation/Estimation Bias Mean      1033.71\n",
      "evaluation/Estimation Bias Std        146.642\n",
      "evaluation/EB/Q_True Mean              43.328\n",
      "evaluation/EB/Q_True Std              133.206\n",
      "evaluation/EB/Q_Pred Mean            1077.04\n",
      "evaluation/EB/Q_Pred Std               53.6731\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4679.29\n",
      "evaluation/Actions Mean                 0.0251557\n",
      "evaluation/Actions Std                  0.537872\n",
      "evaluation/Actions Max                  0.999739\n",
      "evaluation/Actions Min                 -0.999991\n",
      "time/backward_policy (s)                1.87023\n",
      "time/backward_zf1 (s)                   2.04954\n",
      "time/backward_zf2 (s)                   1.95441\n",
      "time/data sampling (s)                  0.289792\n",
      "time/data storing (s)                   0.0154504\n",
      "time/evaluation sampling (s)            1.67739\n",
      "time/exploration sampling (s)           0.332774\n",
      "time/logging (s)                        0.012767\n",
      "time/preback_alpha (s)                  0.588202\n",
      "time/preback_policy (s)                 1.10741\n",
      "time/preback_start (s)                  0.151769\n",
      "time/preback_zf (s)                     5.15297\n",
      "time/saving (s)                         0.00604686\n",
      "time/training (s)                       2.33543\n",
      "time/epoch (s)                         17.5442\n",
      "time/total (s)                       4086\n",
      "Epoch                                 231\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:44:42.589738 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 232 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 243000\n",
      "trainer/ZF1 Loss                        1.04557\n",
      "trainer/ZF2 Loss                        2.70403\n",
      "trainer/ZF Expert Reward               10.7125\n",
      "trainer/ZF Policy Reward               -3.13729\n",
      "trainer/ZF CHI2 Term                   47.5245\n",
      "trainer/Policy Loss                  -982.041\n",
      "trainer/Bias Loss                      65.4095\n",
      "trainer/Bias Value                     14.1179\n",
      "trainer/Policy Grad Norm              131.694\n",
      "trainer/Policy Param Norm              38.4886\n",
      "trainer/Zf1 Grad Norm                2119.79\n",
      "trainer/Zf1 Param Norm                119.64\n",
      "trainer/Zf2 Grad Norm                2703.6\n",
      "trainer/Zf2 Param Norm                122.296\n",
      "trainer/Z Expert Predictions Mean    1083.72\n",
      "trainer/Z Expert Predictions Std       77.7947\n",
      "trainer/Z Expert Predictions Max     1188.31\n",
      "trainer/Z Expert Predictions Min       52.8937\n",
      "trainer/Z Policy Predictions Mean     980.271\n",
      "trainer/Z Policy Predictions Std      247.156\n",
      "trainer/Z Policy Predictions Max     1134.66\n",
      "trainer/Z Policy Predictions Min     -397.66\n",
      "trainer/Z Expert Targets Mean        1073.01\n",
      "trainer/Z Expert Targets Std           80.7719\n",
      "trainer/Z Expert Targets Max         1168.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         983.408\n",
      "trainer/Z Policy Targets Std          240.626\n",
      "trainer/Z Policy Targets Max         1137.39\n",
      "trainer/Z Policy Targets Min         -387.099\n",
      "trainer/Log Pis Mean                   32.1212\n",
      "trainer/Log Pis Std                     6.47551\n",
      "trainer/Policy mu Mean                  0.0657141\n",
      "trainer/Policy mu Std                   1.41946\n",
      "trainer/Policy log std Mean            -4.64948\n",
      "trainer/Policy log std Std              0.86433\n",
      "exploration/num steps total        237777\n",
      "exploration/num paths total           365\n",
      "evaluation/num steps total              2.03025e+06\n",
      "evaluation/num paths total           2392\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66231\n",
      "evaluation/Rewards Std                  0.985123\n",
      "evaluation/Rewards Max                  7.00573\n",
      "evaluation/Rewards Min                 -1.70133\n",
      "evaluation/Returns Mean              4662.31\n",
      "evaluation/Returns Std                113.671\n",
      "evaluation/Returns Max               4912.48\n",
      "evaluation/Returns Min               4503.11\n",
      "evaluation/Estimation Bias Mean      1023.23\n",
      "evaluation/Estimation Bias Std        140.851\n",
      "evaluation/EB/Q_True Mean              42.2356\n",
      "evaluation/EB/Q_True Std              129.744\n",
      "evaluation/EB/Q_Pred Mean            1065.47\n",
      "evaluation/EB/Q_Pred Std               54.6089\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4662.31\n",
      "evaluation/Actions Mean                 0.0212869\n",
      "evaluation/Actions Std                  0.530874\n",
      "evaluation/Actions Max                  0.999532\n",
      "evaluation/Actions Min                 -0.999933\n",
      "time/backward_policy (s)                1.9781\n",
      "time/backward_zf1 (s)                   2.1779\n",
      "time/backward_zf2 (s)                   2.06016\n",
      "time/data sampling (s)                  0.314684\n",
      "time/data storing (s)                   0.0149418\n",
      "time/evaluation sampling (s)            1.74082\n",
      "time/exploration sampling (s)           0.333364\n",
      "time/logging (s)                        0.0128236\n",
      "time/preback_alpha (s)                  0.598274\n",
      "time/preback_policy (s)                 1.16115\n",
      "time/preback_start (s)                  0.153429\n",
      "time/preback_zf (s)                     5.19694\n",
      "time/saving (s)                         0.00688734\n",
      "time/training (s)                       2.29204\n",
      "time/epoch (s)                         18.0415\n",
      "time/total (s)                       4104.07\n",
      "Epoch                                 232\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:45:00.360767 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 233 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 244000\n",
      "trainer/ZF1 Loss                        0.487411\n",
      "trainer/ZF2 Loss                       -2.4639\n",
      "trainer/ZF Expert Reward               12.8287\n",
      "trainer/ZF Policy Reward                1.36377\n",
      "trainer/ZF CHI2 Term                   43.1351\n",
      "trainer/Policy Loss                  -961.246\n",
      "trainer/Bias Loss                      65.1568\n",
      "trainer/Bias Value                     14.1179\n",
      "trainer/Policy Grad Norm              121.016\n",
      "trainer/Policy Param Norm              38.5188\n",
      "trainer/Zf1 Grad Norm                1792.88\n",
      "trainer/Zf1 Param Norm                119.801\n",
      "trainer/Zf2 Grad Norm                1589.39\n",
      "trainer/Zf2 Param Norm                122.448\n",
      "trainer/Z Expert Predictions Mean    1080.72\n",
      "trainer/Z Expert Predictions Std       60.0935\n",
      "trainer/Z Expert Predictions Max     1186.78\n",
      "trainer/Z Expert Predictions Min      743.607\n",
      "trainer/Z Policy Predictions Mean     954.697\n",
      "trainer/Z Policy Predictions Std      298.692\n",
      "trainer/Z Policy Predictions Max     1150.24\n",
      "trainer/Z Policy Predictions Min     -410.31\n",
      "trainer/Z Expert Targets Mean        1067.89\n",
      "trainer/Z Expert Targets Std           63.2403\n",
      "trainer/Z Expert Targets Max         1162.6\n",
      "trainer/Z Expert Targets Min          699.667\n",
      "trainer/Z Policy Targets Mean         953.333\n",
      "trainer/Z Policy Targets Std          294.436\n",
      "trainer/Z Policy Targets Max         1145.89\n",
      "trainer/Z Policy Targets Min         -413.472\n",
      "trainer/Log Pis Mean                   32.9883\n",
      "trainer/Log Pis Std                     6.74831\n",
      "trainer/Policy mu Mean                 -0.0111661\n",
      "trainer/Policy mu Std                   1.57177\n",
      "trainer/Policy log std Mean            -4.5627\n",
      "trainer/Policy log std Std              0.981984\n",
      "exploration/num steps total        238777\n",
      "exploration/num paths total           366\n",
      "evaluation/num steps total              2.03987e+06\n",
      "evaluation/num paths total           2402\n",
      "evaluation/path length Mean           961.8\n",
      "evaluation/path length Std            114.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            618\n",
      "evaluation/Rewards Mean                 4.65267\n",
      "evaluation/Rewards Std                  0.969242\n",
      "evaluation/Rewards Max                  6.68695\n",
      "evaluation/Rewards Min                 -1.54758\n",
      "evaluation/Returns Mean              4474.94\n",
      "evaluation/Returns Std                549.724\n",
      "evaluation/Returns Max               4802.86\n",
      "evaluation/Returns Min               2854.98\n",
      "evaluation/Estimation Bias Mean      1029.81\n",
      "evaluation/Estimation Bias Std        149.601\n",
      "evaluation/EB/Q_True Mean              44.9369\n",
      "evaluation/EB/Q_True Std              135.28\n",
      "evaluation/EB/Q_Pred Mean            1074.74\n",
      "evaluation/EB/Q_Pred Std               59.0677\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4474.94\n",
      "evaluation/Actions Mean                 0.0197756\n",
      "evaluation/Actions Std                  0.539138\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86806\n",
      "time/backward_zf1 (s)                   2.04611\n",
      "time/backward_zf2 (s)                   1.93925\n",
      "time/data sampling (s)                  0.327219\n",
      "time/data storing (s)                   0.0157769\n",
      "time/evaluation sampling (s)            1.7506\n",
      "time/exploration sampling (s)           0.335769\n",
      "time/logging (s)                        0.012411\n",
      "time/preback_alpha (s)                  0.594327\n",
      "time/preback_policy (s)                 1.06267\n",
      "time/preback_start (s)                  0.153206\n",
      "time/preback_zf (s)                     5.14892\n",
      "time/saving (s)                         0.00727656\n",
      "time/training (s)                       2.43557\n",
      "time/epoch (s)                         17.6972\n",
      "time/total (s)                       4121.78\n",
      "Epoch                                 233\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:45:18.159942 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 234 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 245000\n",
      "trainer/ZF1 Loss                       -5.07243\n",
      "trainer/ZF2 Loss                       -2.7197\n",
      "trainer/ZF Expert Reward               14.261\n",
      "trainer/ZF Policy Reward                3.00576\n",
      "trainer/ZF CHI2 Term                   38.9282\n",
      "trainer/Policy Loss                 -1004.08\n",
      "trainer/Bias Loss                      55.0513\n",
      "trainer/Bias Value                     14.1581\n",
      "trainer/Policy Grad Norm              137.553\n",
      "trainer/Policy Param Norm              38.5501\n",
      "trainer/Zf1 Grad Norm                1161.01\n",
      "trainer/Zf1 Param Norm                119.945\n",
      "trainer/Zf2 Grad Norm                 951.949\n",
      "trainer/Zf2 Param Norm                122.591\n",
      "trainer/Z Expert Predictions Mean    1087.96\n",
      "trainer/Z Expert Predictions Std       51.028\n",
      "trainer/Z Expert Predictions Max     1168.24\n",
      "trainer/Z Expert Predictions Min      774.84\n",
      "trainer/Z Policy Predictions Mean     996.807\n",
      "trainer/Z Policy Predictions Std      214.367\n",
      "trainer/Z Policy Predictions Max     1141.04\n",
      "trainer/Z Policy Predictions Min     -312.113\n",
      "trainer/Z Expert Targets Mean        1073.7\n",
      "trainer/Z Expert Targets Std           52.9625\n",
      "trainer/Z Expert Targets Max         1157.35\n",
      "trainer/Z Expert Targets Min          768.205\n",
      "trainer/Z Policy Targets Mean         993.802\n",
      "trainer/Z Policy Targets Std          209.012\n",
      "trainer/Z Policy Targets Max         1135.26\n",
      "trainer/Z Policy Targets Min         -279.425\n",
      "trainer/Log Pis Mean                   31.8879\n",
      "trainer/Log Pis Std                     5.26945\n",
      "trainer/Policy mu Mean                  0.102022\n",
      "trainer/Policy mu Std                   1.34123\n",
      "trainer/Policy log std Mean            -4.70016\n",
      "trainer/Policy log std Std              0.854133\n",
      "exploration/num steps total        241777\n",
      "exploration/num paths total           369\n",
      "evaluation/num steps total              2.04987e+06\n",
      "evaluation/num paths total           2412\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65844\n",
      "evaluation/Rewards Std                  0.975373\n",
      "evaluation/Rewards Max                  6.75271\n",
      "evaluation/Rewards Min                 -2.19432\n",
      "evaluation/Returns Mean              4658.44\n",
      "evaluation/Returns Std                 95.5193\n",
      "evaluation/Returns Max               4808.83\n",
      "evaluation/Returns Min               4437.81\n",
      "evaluation/Estimation Bias Mean      1024.13\n",
      "evaluation/Estimation Bias Std        150.383\n",
      "evaluation/EB/Q_True Mean              44.1582\n",
      "evaluation/EB/Q_True Std              136.442\n",
      "evaluation/EB/Q_Pred Mean            1068.28\n",
      "evaluation/EB/Q_Pred Std               53.8691\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4658.44\n",
      "evaluation/Actions Mean                 0.0284344\n",
      "evaluation/Actions Std                  0.544415\n",
      "evaluation/Actions Max                  0.999897\n",
      "evaluation/Actions Min                 -0.999918\n",
      "time/backward_policy (s)                1.84741\n",
      "time/backward_zf1 (s)                   2.01278\n",
      "time/backward_zf2 (s)                   1.9056\n",
      "time/data sampling (s)                  0.318349\n",
      "time/data storing (s)                   0.0145128\n",
      "time/evaluation sampling (s)            1.8083\n",
      "time/exploration sampling (s)           0.335385\n",
      "time/logging (s)                        0.0120123\n",
      "time/preback_alpha (s)                  0.588105\n",
      "time/preback_policy (s)                 1.02628\n",
      "time/preback_start (s)                  0.15115\n",
      "time/preback_zf (s)                     5.15435\n",
      "time/saving (s)                         0.00669924\n",
      "time/training (s)                       2.54736\n",
      "time/epoch (s)                         17.7283\n",
      "time/total (s)                       4139.53\n",
      "Epoch                                 234\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:45:36.519817 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 235 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 246000\n",
      "trainer/ZF1 Loss                        9.33769\n",
      "trainer/ZF2 Loss                        5.86372\n",
      "trainer/ZF Expert Reward               10.8608\n",
      "trainer/ZF Policy Reward                1.33584\n",
      "trainer/ZF CHI2 Term                   49.7177\n",
      "trainer/Policy Loss                  -969.322\n",
      "trainer/Bias Loss                      74.3483\n",
      "trainer/Bias Value                     14.1478\n",
      "trainer/Policy Grad Norm              155.893\n",
      "trainer/Policy Param Norm              38.5775\n",
      "trainer/Zf1 Grad Norm                1832.37\n",
      "trainer/Zf1 Param Norm                120.099\n",
      "trainer/Zf2 Grad Norm                1291.29\n",
      "trainer/Zf2 Param Norm                122.75\n",
      "trainer/Z Expert Predictions Mean    1081.77\n",
      "trainer/Z Expert Predictions Std       53.8492\n",
      "trainer/Z Expert Predictions Max     1172.32\n",
      "trainer/Z Expert Predictions Min      740.561\n",
      "trainer/Z Policy Predictions Mean     966.645\n",
      "trainer/Z Policy Predictions Std      252.869\n",
      "trainer/Z Policy Predictions Max     1143.81\n",
      "trainer/Z Policy Predictions Min     -440.056\n",
      "trainer/Z Expert Targets Mean        1070.91\n",
      "trainer/Z Expert Targets Std           56.6988\n",
      "trainer/Z Expert Targets Max         1162.03\n",
      "trainer/Z Expert Targets Min          704.943\n",
      "trainer/Z Policy Targets Mean         965.309\n",
      "trainer/Z Policy Targets Std          247.191\n",
      "trainer/Z Policy Targets Max         1151.33\n",
      "trainer/Z Policy Targets Min         -428.376\n",
      "trainer/Log Pis Mean                   32.9212\n",
      "trainer/Log Pis Std                     6.34911\n",
      "trainer/Policy mu Mean                  0.0613293\n",
      "trainer/Policy mu Std                   1.50828\n",
      "trainer/Policy log std Mean            -4.6404\n",
      "trainer/Policy log std Std              1.01211\n",
      "exploration/num steps total        241777\n",
      "exploration/num paths total           369\n",
      "evaluation/num steps total              2.05953e+06\n",
      "evaluation/num paths total           2422\n",
      "evaluation/path length Mean           966.7\n",
      "evaluation/path length Std             99.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            667\n",
      "evaluation/Rewards Mean                 4.6705\n",
      "evaluation/Rewards Std                  0.94396\n",
      "evaluation/Rewards Max                  6.66795\n",
      "evaluation/Rewards Min                 -2.0888\n",
      "evaluation/Returns Mean              4514.97\n",
      "evaluation/Returns Std                476.348\n",
      "evaluation/Returns Max               4751.04\n",
      "evaluation/Returns Min               3091.61\n",
      "evaluation/Estimation Bias Mean      1019.82\n",
      "evaluation/Estimation Bias Std        147.066\n",
      "evaluation/EB/Q_True Mean              44.7159\n",
      "evaluation/EB/Q_True Std              135.375\n",
      "evaluation/EB/Q_Pred Mean            1064.54\n",
      "evaluation/EB/Q_Pred Std               49.0025\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4514.97\n",
      "evaluation/Actions Mean                 0.0288459\n",
      "evaluation/Actions Std                  0.533604\n",
      "evaluation/Actions Max                  0.999963\n",
      "evaluation/Actions Min                 -0.999966\n",
      "time/backward_policy (s)                2.00722\n",
      "time/backward_zf1 (s)                   2.19166\n",
      "time/backward_zf2 (s)                   2.10008\n",
      "time/data sampling (s)                  0.338491\n",
      "time/data storing (s)                   0.0171096\n",
      "time/evaluation sampling (s)            1.69622\n",
      "time/exploration sampling (s)           0.329463\n",
      "time/logging (s)                        0.0121294\n",
      "time/preback_alpha (s)                  0.611845\n",
      "time/preback_policy (s)                 1.16489\n",
      "time/preback_start (s)                  0.155555\n",
      "time/preback_zf (s)                     5.24779\n",
      "time/saving (s)                         0.0090297\n",
      "time/training (s)                       2.40565\n",
      "time/epoch (s)                         18.2871\n",
      "time/total (s)                       4157.84\n",
      "Epoch                                 235\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:45:54.779325 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 236 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 247000\n",
      "trainer/ZF1 Loss                      125.042\n",
      "trainer/ZF2 Loss                      129.869\n",
      "trainer/ZF Expert Reward                7.61141\n",
      "trainer/ZF Policy Reward                1.76828\n",
      "trainer/ZF CHI2 Term                  165.693\n",
      "trainer/Policy Loss                  -973.814\n",
      "trainer/Bias Loss                      88.9721\n",
      "trainer/Bias Value                     14.1506\n",
      "trainer/Policy Grad Norm              142.131\n",
      "trainer/Policy Param Norm              38.6059\n",
      "trainer/Zf1 Grad Norm                3000.29\n",
      "trainer/Zf1 Param Norm                120.255\n",
      "trainer/Zf2 Grad Norm                2675.76\n",
      "trainer/Zf2 Param Norm                122.899\n",
      "trainer/Z Expert Predictions Mean    1075.09\n",
      "trainer/Z Expert Predictions Std       50.0939\n",
      "trainer/Z Expert Predictions Max     1177.02\n",
      "trainer/Z Expert Predictions Min      736.785\n",
      "trainer/Z Policy Predictions Mean     969.347\n",
      "trainer/Z Policy Predictions Std      245.067\n",
      "trainer/Z Policy Predictions Max     1160.34\n",
      "trainer/Z Policy Predictions Min     -441.017\n",
      "trainer/Z Expert Targets Mean        1067.48\n",
      "trainer/Z Expert Targets Std           51.4331\n",
      "trainer/Z Expert Targets Max         1158.29\n",
      "trainer/Z Expert Targets Min          704.481\n",
      "trainer/Z Policy Targets Mean         967.579\n",
      "trainer/Z Policy Targets Std          248.604\n",
      "trainer/Z Policy Targets Max         1165.09\n",
      "trainer/Z Policy Targets Min         -422.459\n",
      "trainer/Log Pis Mean                   32.7221\n",
      "trainer/Log Pis Std                     7.06206\n",
      "trainer/Policy mu Mean                  0.0919934\n",
      "trainer/Policy mu Std                   1.39861\n",
      "trainer/Policy log std Mean            -4.6546\n",
      "trainer/Policy log std Std              0.89734\n",
      "exploration/num steps total        241777\n",
      "exploration/num paths total           369\n",
      "evaluation/num steps total              2.06953e+06\n",
      "evaluation/num paths total           2432\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70774\n",
      "evaluation/Rewards Std                  1.07058\n",
      "evaluation/Rewards Max                  6.80634\n",
      "evaluation/Rewards Min                 -3.17242\n",
      "evaluation/Returns Mean              4707.74\n",
      "evaluation/Returns Std                 86.5688\n",
      "evaluation/Returns Max               4840.82\n",
      "evaluation/Returns Min               4521.39\n",
      "evaluation/Estimation Bias Mean      1017.2\n",
      "evaluation/Estimation Bias Std        144.899\n",
      "evaluation/EB/Q_True Mean              43.0064\n",
      "evaluation/EB/Q_True Std              132.353\n",
      "evaluation/EB/Q_Pred Mean            1060.21\n",
      "evaluation/EB/Q_Pred Std               60.7407\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4707.74\n",
      "evaluation/Actions Mean                 0.0230651\n",
      "evaluation/Actions Std                  0.53101\n",
      "evaluation/Actions Max                  0.999918\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.94121\n",
      "time/backward_zf1 (s)                   2.12801\n",
      "time/backward_zf2 (s)                   2.03723\n",
      "time/data sampling (s)                  0.327762\n",
      "time/data storing (s)                   0.0166152\n",
      "time/evaluation sampling (s)            1.76478\n",
      "time/exploration sampling (s)           0.340774\n",
      "time/logging (s)                        0.0116852\n",
      "time/preback_alpha (s)                  0.604036\n",
      "time/preback_policy (s)                 1.1251\n",
      "time/preback_start (s)                  0.152967\n",
      "time/preback_zf (s)                     5.23333\n",
      "time/saving (s)                         0.00746726\n",
      "time/training (s)                       2.49622\n",
      "time/epoch (s)                         18.1872\n",
      "time/total (s)                       4176.05\n",
      "Epoch                                 236\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:46:12.844370 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 237 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 248000\n",
      "trainer/ZF1 Loss                       -8.75044\n",
      "trainer/ZF2 Loss                       -7.56239\n",
      "trainer/ZF Expert Reward               13.7753\n",
      "trainer/ZF Policy Reward                2.50908\n",
      "trainer/ZF CHI2 Term                   34.3931\n",
      "trainer/Policy Loss                  -993.716\n",
      "trainer/Bias Loss                      47.3994\n",
      "trainer/Bias Value                     14.144\n",
      "trainer/Policy Grad Norm              213.956\n",
      "trainer/Policy Param Norm              38.6349\n",
      "trainer/Zf1 Grad Norm                1351.94\n",
      "trainer/Zf1 Param Norm                120.393\n",
      "trainer/Zf2 Grad Norm                1093.56\n",
      "trainer/Zf2 Param Norm                123.042\n",
      "trainer/Z Expert Predictions Mean    1075.85\n",
      "trainer/Z Expert Predictions Std       51.4579\n",
      "trainer/Z Expert Predictions Max     1176.92\n",
      "trainer/Z Expert Predictions Min      853.014\n",
      "trainer/Z Policy Predictions Mean     988.884\n",
      "trainer/Z Policy Predictions Std      215.143\n",
      "trainer/Z Policy Predictions Max     1152.61\n",
      "trainer/Z Policy Predictions Min     -389.36\n",
      "trainer/Z Expert Targets Mean        1062.08\n",
      "trainer/Z Expert Targets Std           52.5267\n",
      "trainer/Z Expert Targets Max         1157.33\n",
      "trainer/Z Expert Targets Min          828.715\n",
      "trainer/Z Policy Targets Mean         986.375\n",
      "trainer/Z Policy Targets Std          210.727\n",
      "trainer/Z Policy Targets Max         1131.15\n",
      "trainer/Z Policy Targets Min         -390.072\n",
      "trainer/Log Pis Mean                   31.5993\n",
      "trainer/Log Pis Std                     6.04527\n",
      "trainer/Policy mu Mean                  0.027624\n",
      "trainer/Policy mu Std                   1.2708\n",
      "trainer/Policy log std Mean            -4.67279\n",
      "trainer/Policy log std Std              0.824124\n",
      "exploration/num steps total        242777\n",
      "exploration/num paths total           370\n",
      "evaluation/num steps total              2.07953e+06\n",
      "evaluation/num paths total           2442\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60042\n",
      "evaluation/Rewards Std                  1.13969\n",
      "evaluation/Rewards Max                  6.88557\n",
      "evaluation/Rewards Min                 -3.87801\n",
      "evaluation/Returns Mean              4600.42\n",
      "evaluation/Returns Std                135.882\n",
      "evaluation/Returns Max               4761.59\n",
      "evaluation/Returns Min               4296.26\n",
      "evaluation/Estimation Bias Mean      1004\n",
      "evaluation/Estimation Bias Std        189.946\n",
      "evaluation/EB/Q_True Mean              43.6152\n",
      "evaluation/EB/Q_True Std              134.761\n",
      "evaluation/EB/Q_Pred Mean            1047.61\n",
      "evaluation/EB/Q_Pred Std              128.208\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4600.42\n",
      "evaluation/Actions Mean                 0.0265126\n",
      "evaluation/Actions Std                  0.53891\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95589\n",
      "time/backward_zf1 (s)                   2.16116\n",
      "time/backward_zf2 (s)                   2.06938\n",
      "time/data sampling (s)                  0.329645\n",
      "time/data storing (s)                   0.0150314\n",
      "time/evaluation sampling (s)            1.79856\n",
      "time/exploration sampling (s)           0.33432\n",
      "time/logging (s)                        0.015404\n",
      "time/preback_alpha (s)                  0.596776\n",
      "time/preback_policy (s)                 1.12443\n",
      "time/preback_start (s)                  0.151839\n",
      "time/preback_zf (s)                     5.16692\n",
      "time/saving (s)                         0.0080747\n",
      "time/training (s)                       2.27259\n",
      "time/epoch (s)                         18\n",
      "time/total (s)                       4194.07\n",
      "Epoch                                 237\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:46:30.670794 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 238 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 249000\n",
      "trainer/ZF1 Loss                        0.845802\n",
      "trainer/ZF2 Loss                       -5.28425\n",
      "trainer/ZF Expert Reward               11.3182\n",
      "trainer/ZF Policy Reward                1.80728\n",
      "trainer/ZF CHI2 Term                   39.8815\n",
      "trainer/Policy Loss                  -977.505\n",
      "trainer/Bias Loss                      53.8838\n",
      "trainer/Bias Value                     14.1691\n",
      "trainer/Policy Grad Norm              111.394\n",
      "trainer/Policy Param Norm              38.665\n",
      "trainer/Zf1 Grad Norm                1584.28\n",
      "trainer/Zf1 Param Norm                120.541\n",
      "trainer/Zf2 Grad Norm                 986.304\n",
      "trainer/Zf2 Param Norm                123.174\n",
      "trainer/Z Expert Predictions Mean    1079.45\n",
      "trainer/Z Expert Predictions Std       39.6222\n",
      "trainer/Z Expert Predictions Max     1163.47\n",
      "trainer/Z Expert Predictions Min      888.01\n",
      "trainer/Z Policy Predictions Mean     973.808\n",
      "trainer/Z Policy Predictions Std      244.923\n",
      "trainer/Z Policy Predictions Max     1135.02\n",
      "trainer/Z Policy Predictions Min     -406.376\n",
      "trainer/Z Expert Targets Mean        1068.14\n",
      "trainer/Z Expert Targets Std           41.0935\n",
      "trainer/Z Expert Targets Max         1146.82\n",
      "trainer/Z Expert Targets Min          874.003\n",
      "trainer/Z Policy Targets Mean         972.001\n",
      "trainer/Z Policy Targets Std          240.925\n",
      "trainer/Z Policy Targets Max         1127.83\n",
      "trainer/Z Policy Targets Min         -397.843\n",
      "trainer/Log Pis Mean                   32.919\n",
      "trainer/Log Pis Std                     7.17316\n",
      "trainer/Policy mu Mean                  0.024534\n",
      "trainer/Policy mu Std                   1.58429\n",
      "trainer/Policy log std Mean            -4.60455\n",
      "trainer/Policy log std Std              1.00421\n",
      "exploration/num steps total        245454\n",
      "exploration/num paths total           373\n",
      "evaluation/num steps total              2.08879e+06\n",
      "evaluation/num paths total           2452\n",
      "evaluation/path length Mean           925.6\n",
      "evaluation/path length Std            223.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            256\n",
      "evaluation/Rewards Mean                 4.68069\n",
      "evaluation/Rewards Std                  1.00707\n",
      "evaluation/Rewards Max                  6.48806\n",
      "evaluation/Rewards Min                 -2.18614\n",
      "evaluation/Returns Mean              4332.45\n",
      "evaluation/Returns Std               1124.04\n",
      "evaluation/Returns Max               4814.02\n",
      "evaluation/Returns Min                969.708\n",
      "evaluation/Estimation Bias Mean      1014.21\n",
      "evaluation/Estimation Bias Std        156.055\n",
      "evaluation/EB/Q_True Mean              47.2709\n",
      "evaluation/EB/Q_True Std              139.585\n",
      "evaluation/EB/Q_Pred Mean            1061.48\n",
      "evaluation/EB/Q_Pred Std               60.1541\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4332.45\n",
      "evaluation/Actions Mean                 0.0215211\n",
      "evaluation/Actions Std                  0.537872\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.90296\n",
      "time/backward_zf1 (s)                   2.08512\n",
      "time/backward_zf2 (s)                   1.9577\n",
      "time/data sampling (s)                  0.302398\n",
      "time/data storing (s)                   0.0151769\n",
      "time/evaluation sampling (s)            1.74837\n",
      "time/exploration sampling (s)           0.337666\n",
      "time/logging (s)                        0.0115713\n",
      "time/preback_alpha (s)                  0.584191\n",
      "time/preback_policy (s)                 1.08553\n",
      "time/preback_start (s)                  0.150249\n",
      "time/preback_zf (s)                     5.16989\n",
      "time/saving (s)                         0.00655178\n",
      "time/training (s)                       2.39659\n",
      "time/epoch (s)                         17.754\n",
      "time/total (s)                       4211.84\n",
      "Epoch                                 238\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:46:48.411132 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 239 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 250000\n",
      "trainer/ZF1 Loss                      189.662\n",
      "trainer/ZF2 Loss                      209.426\n",
      "trainer/ZF Expert Reward               15.3546\n",
      "trainer/ZF Policy Reward                8.17534\n",
      "trainer/ZF CHI2 Term                  238.574\n",
      "trainer/Policy Loss                  -969.444\n",
      "trainer/Bias Loss                      74.8993\n",
      "trainer/Bias Value                     14.1716\n",
      "trainer/Policy Grad Norm              127.111\n",
      "trainer/Policy Param Norm              38.6956\n",
      "trainer/Zf1 Grad Norm                1446.46\n",
      "trainer/Zf1 Param Norm                120.668\n",
      "trainer/Zf2 Grad Norm                1251.38\n",
      "trainer/Zf2 Param Norm                123.317\n",
      "trainer/Z Expert Predictions Mean    1076.14\n",
      "trainer/Z Expert Predictions Std       43.1892\n",
      "trainer/Z Expert Predictions Max     1178.2\n",
      "trainer/Z Expert Predictions Min      841.291\n",
      "trainer/Z Policy Predictions Mean     967.226\n",
      "trainer/Z Policy Predictions Std      265.695\n",
      "trainer/Z Policy Predictions Max     1152.34\n",
      "trainer/Z Policy Predictions Min     -443.304\n",
      "trainer/Z Expert Targets Mean        1060.78\n",
      "trainer/Z Expert Targets Std           45.3973\n",
      "trainer/Z Expert Targets Max         1162.77\n",
      "trainer/Z Expert Targets Min          819.506\n",
      "trainer/Z Policy Targets Mean         959.051\n",
      "trainer/Z Policy Targets Std          266.235\n",
      "trainer/Z Policy Targets Max         1125.66\n",
      "trainer/Z Policy Targets Min         -424.806\n",
      "trainer/Log Pis Mean                   32.1726\n",
      "trainer/Log Pis Std                     5.68856\n",
      "trainer/Policy mu Mean                  0.0579805\n",
      "trainer/Policy mu Std                   1.37706\n",
      "trainer/Policy log std Mean            -4.60734\n",
      "trainer/Policy log std Std              0.914408\n",
      "exploration/num steps total        245454\n",
      "exploration/num paths total           373\n",
      "evaluation/num steps total              2.09879e+06\n",
      "evaluation/num paths total           2462\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.73067\n",
      "evaluation/Rewards Std                  0.944327\n",
      "evaluation/Rewards Max                  6.90904\n",
      "evaluation/Rewards Min                 -1.77075\n",
      "evaluation/Returns Mean              4730.67\n",
      "evaluation/Returns Std                105.66\n",
      "evaluation/Returns Max               4924.14\n",
      "evaluation/Returns Min               4485.44\n",
      "evaluation/Estimation Bias Mean      1014.54\n",
      "evaluation/Estimation Bias Std        145.769\n",
      "evaluation/EB/Q_True Mean              44.3166\n",
      "evaluation/EB/Q_True Std              136.638\n",
      "evaluation/EB/Q_Pred Mean            1058.86\n",
      "evaluation/EB/Q_Pred Std               48.8681\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4730.67\n",
      "evaluation/Actions Mean                 0.0183646\n",
      "evaluation/Actions Std                  0.538904\n",
      "evaluation/Actions Max                  0.999846\n",
      "evaluation/Actions Min                 -0.999865\n",
      "time/backward_policy (s)                1.87789\n",
      "time/backward_zf1 (s)                   2.0176\n",
      "time/backward_zf2 (s)                   1.92909\n",
      "time/data sampling (s)                  0.340396\n",
      "time/data storing (s)                   0.0147049\n",
      "time/evaluation sampling (s)            1.71754\n",
      "time/exploration sampling (s)           0.331285\n",
      "time/logging (s)                        0.012542\n",
      "time/preback_alpha (s)                  0.594244\n",
      "time/preback_policy (s)                 1.0578\n",
      "time/preback_start (s)                  0.151839\n",
      "time/preback_zf (s)                     5.16064\n",
      "time/saving (s)                         0.00638366\n",
      "time/training (s)                       2.46121\n",
      "time/epoch (s)                         17.6732\n",
      "time/total (s)                       4229.53\n",
      "Epoch                                 239\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:47:06.322105 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 240 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 251000\n",
      "trainer/ZF1 Loss                       -7.73501\n",
      "trainer/ZF2 Loss                       -3.07751\n",
      "trainer/ZF Expert Reward               15.3611\n",
      "trainer/ZF Policy Reward                5.7115\n",
      "trainer/ZF CHI2 Term                   36.188\n",
      "trainer/Policy Loss                 -1004.48\n",
      "trainer/Bias Loss                      43.0483\n",
      "trainer/Bias Value                     14.1476\n",
      "trainer/Policy Grad Norm              146.224\n",
      "trainer/Policy Param Norm              38.7253\n",
      "trainer/Zf1 Grad Norm                1283.02\n",
      "trainer/Zf1 Param Norm                120.818\n",
      "trainer/Zf2 Grad Norm                1002.04\n",
      "trainer/Zf2 Param Norm                123.489\n",
      "trainer/Z Expert Predictions Mean    1074.99\n",
      "trainer/Z Expert Predictions Std       51.6311\n",
      "trainer/Z Expert Predictions Max     1173.24\n",
      "trainer/Z Expert Predictions Min      840.939\n",
      "trainer/Z Policy Predictions Mean     999.753\n",
      "trainer/Z Policy Predictions Std      189.701\n",
      "trainer/Z Policy Predictions Max     1172.81\n",
      "trainer/Z Policy Predictions Min     -411.457\n",
      "trainer/Z Expert Targets Mean        1059.63\n",
      "trainer/Z Expert Targets Std           52.5788\n",
      "trainer/Z Expert Targets Max         1160.35\n",
      "trainer/Z Expert Targets Min          837.539\n",
      "trainer/Z Policy Targets Mean         994.041\n",
      "trainer/Z Policy Targets Std          186.912\n",
      "trainer/Z Policy Targets Max         1158.24\n",
      "trainer/Z Policy Targets Min         -410.748\n",
      "trainer/Log Pis Mean                   32.2674\n",
      "trainer/Log Pis Std                     5.4528\n",
      "trainer/Policy mu Mean                  0.0836855\n",
      "trainer/Policy mu Std                   1.24442\n",
      "trainer/Policy log std Mean            -4.70702\n",
      "trainer/Policy log std Std              0.836153\n",
      "exploration/num steps total        245454\n",
      "exploration/num paths total           373\n",
      "evaluation/num steps total              2.10879e+06\n",
      "evaluation/num paths total           2472\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67494\n",
      "evaluation/Rewards Std                  1.00164\n",
      "evaluation/Rewards Max                  6.83107\n",
      "evaluation/Rewards Min                 -1.64695\n",
      "evaluation/Returns Mean              4674.94\n",
      "evaluation/Returns Std                174.669\n",
      "evaluation/Returns Max               4873.53\n",
      "evaluation/Returns Min               4217.41\n",
      "evaluation/Estimation Bias Mean      1024.21\n",
      "evaluation/Estimation Bias Std        131.433\n",
      "evaluation/EB/Q_True Mean              38.5819\n",
      "evaluation/EB/Q_True Std              119.695\n",
      "evaluation/EB/Q_Pred Mean            1062.79\n",
      "evaluation/EB/Q_Pred Std               57.3183\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4674.94\n",
      "evaluation/Actions Mean                 0.029465\n",
      "evaluation/Actions Std                  0.538064\n",
      "evaluation/Actions Max                  0.999776\n",
      "evaluation/Actions Min                 -0.999974\n",
      "time/backward_policy (s)                1.86335\n",
      "time/backward_zf1 (s)                   2.02859\n",
      "time/backward_zf2 (s)                   1.9159\n",
      "time/data sampling (s)                  0.3277\n",
      "time/data storing (s)                   0.0159395\n",
      "time/evaluation sampling (s)            1.83619\n",
      "time/exploration sampling (s)           0.333414\n",
      "time/logging (s)                        0.0115275\n",
      "time/preback_alpha (s)                  0.590757\n",
      "time/preback_policy (s)                 1.07894\n",
      "time/preback_start (s)                  0.150677\n",
      "time/preback_zf (s)                     5.1794\n",
      "time/saving (s)                         0.00635388\n",
      "time/training (s)                       2.49672\n",
      "time/epoch (s)                         17.8355\n",
      "time/total (s)                       4247.39\n",
      "Epoch                                 240\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:47:24.403207 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 241 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 252000\n",
      "trainer/ZF1 Loss                       -8.25977\n",
      "trainer/ZF2 Loss                       -0.594791\n",
      "trainer/ZF Expert Reward               20.5575\n",
      "trainer/ZF Policy Reward                8.28785\n",
      "trainer/ZF CHI2 Term                   41.1545\n",
      "trainer/Policy Loss                  -960.437\n",
      "trainer/Bias Loss                      75.9403\n",
      "trainer/Bias Value                     14.1397\n",
      "trainer/Policy Grad Norm              153.302\n",
      "trainer/Policy Param Norm              38.7528\n",
      "trainer/Zf1 Grad Norm                1067.61\n",
      "trainer/Zf1 Param Norm                120.962\n",
      "trainer/Zf2 Grad Norm                1105.04\n",
      "trainer/Zf2 Param Norm                123.637\n",
      "trainer/Z Expert Predictions Mean    1073.07\n",
      "trainer/Z Expert Predictions Std       59.4593\n",
      "trainer/Z Expert Predictions Max     1163.33\n",
      "trainer/Z Expert Predictions Min      548.489\n",
      "trainer/Z Policy Predictions Mean     957.126\n",
      "trainer/Z Policy Predictions Std      282.156\n",
      "trainer/Z Policy Predictions Max     1154.26\n",
      "trainer/Z Policy Predictions Min     -458.305\n",
      "trainer/Z Expert Targets Mean        1052.52\n",
      "trainer/Z Expert Targets Std           60.3521\n",
      "trainer/Z Expert Targets Max         1140.88\n",
      "trainer/Z Expert Targets Min          533.006\n",
      "trainer/Z Policy Targets Mean         948.838\n",
      "trainer/Z Policy Targets Std          275.886\n",
      "trainer/Z Policy Targets Max         1131.61\n",
      "trainer/Z Policy Targets Min         -442.571\n",
      "trainer/Log Pis Mean                   33.6486\n",
      "trainer/Log Pis Std                     7.32553\n",
      "trainer/Policy mu Mean                  0.0537103\n",
      "trainer/Policy mu Std                   1.59776\n",
      "trainer/Policy log std Mean            -4.64619\n",
      "trainer/Policy log std Std              0.997665\n",
      "exploration/num steps total        246454\n",
      "exploration/num paths total           374\n",
      "evaluation/num steps total              2.11879e+06\n",
      "evaluation/num paths total           2482\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67848\n",
      "evaluation/Rewards Std                  0.937766\n",
      "evaluation/Rewards Max                  6.76589\n",
      "evaluation/Rewards Min                 -2.03709\n",
      "evaluation/Returns Mean              4678.48\n",
      "evaluation/Returns Std                 57.5866\n",
      "evaluation/Returns Max               4753.57\n",
      "evaluation/Returns Min               4575.79\n",
      "evaluation/Estimation Bias Mean       998.619\n",
      "evaluation/Estimation Bias Std        143.227\n",
      "evaluation/EB/Q_True Mean              43.5812\n",
      "evaluation/EB/Q_True Std              134.394\n",
      "evaluation/EB/Q_Pred Mean            1042.2\n",
      "evaluation/EB/Q_Pred Std               49.643\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4678.48\n",
      "evaluation/Actions Mean                 0.0221959\n",
      "evaluation/Actions Std                  0.532884\n",
      "evaluation/Actions Max                  0.999942\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                2.00704\n",
      "time/backward_zf1 (s)                   2.14809\n",
      "time/backward_zf2 (s)                   2.0732\n",
      "time/data sampling (s)                  0.297255\n",
      "time/data storing (s)                   0.0168435\n",
      "time/evaluation sampling (s)            1.72882\n",
      "time/exploration sampling (s)           0.344161\n",
      "time/logging (s)                        0.0128488\n",
      "time/preback_alpha (s)                  0.601315\n",
      "time/preback_policy (s)                 1.15242\n",
      "time/preback_start (s)                  0.152733\n",
      "time/preback_zf (s)                     5.20276\n",
      "time/saving (s)                         0.00603023\n",
      "time/training (s)                       2.26927\n",
      "time/epoch (s)                         18.0128\n",
      "time/total (s)                       4265.42\n",
      "Epoch                                 241\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:47:42.656327 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 242 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 253000\n",
      "trainer/ZF1 Loss                      203.699\n",
      "trainer/ZF2 Loss                      199.252\n",
      "trainer/ZF Expert Reward               11.0066\n",
      "trainer/ZF Policy Reward                3.62502\n",
      "trainer/ZF CHI2 Term                  240.833\n",
      "trainer/Policy Loss                  -963.573\n",
      "trainer/Bias Loss                      57.8038\n",
      "trainer/Bias Value                     14.1733\n",
      "trainer/Policy Grad Norm              106.604\n",
      "trainer/Policy Param Norm              38.7834\n",
      "trainer/Zf1 Grad Norm                1744.47\n",
      "trainer/Zf1 Param Norm                121.116\n",
      "trainer/Zf2 Grad Norm                1494.6\n",
      "trainer/Zf2 Param Norm                123.768\n",
      "trainer/Z Expert Predictions Mean    1067.49\n",
      "trainer/Z Expert Predictions Std       50.8382\n",
      "trainer/Z Expert Predictions Max     1147.31\n",
      "trainer/Z Expert Predictions Min      692.028\n",
      "trainer/Z Policy Predictions Mean     957.826\n",
      "trainer/Z Policy Predictions Std      237.46\n",
      "trainer/Z Policy Predictions Max     1135.92\n",
      "trainer/Z Policy Predictions Min     -436.157\n",
      "trainer/Z Expert Targets Mean        1056.48\n",
      "trainer/Z Expert Targets Std           52.996\n",
      "trainer/Z Expert Targets Max         1145.15\n",
      "trainer/Z Expert Targets Min          646.684\n",
      "trainer/Z Policy Targets Mean         954.201\n",
      "trainer/Z Policy Targets Std          242.386\n",
      "trainer/Z Policy Targets Max         1138.6\n",
      "trainer/Z Policy Targets Min         -423.809\n",
      "trainer/Log Pis Mean                   32.2984\n",
      "trainer/Log Pis Std                     6.50354\n",
      "trainer/Policy mu Mean                 -0.0246485\n",
      "trainer/Policy mu Std                   1.47967\n",
      "trainer/Policy log std Mean            -4.64544\n",
      "trainer/Policy log std Std              0.931923\n",
      "exploration/num steps total        247454\n",
      "exploration/num paths total           375\n",
      "evaluation/num steps total              2.12879e+06\n",
      "evaluation/num paths total           2492\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.17991\n",
      "evaluation/Rewards Std                  1.94317\n",
      "evaluation/Rewards Max                  6.71035\n",
      "evaluation/Rewards Min                 -3.06078\n",
      "evaluation/Returns Mean              4179.91\n",
      "evaluation/Returns Std               1295.02\n",
      "evaluation/Returns Max               4733.15\n",
      "evaluation/Returns Min                302.1\n",
      "evaluation/Estimation Bias Mean      1018.98\n",
      "evaluation/Estimation Bias Std        157.267\n",
      "evaluation/EB/Q_True Mean              -0.47403\n",
      "evaluation/EB/Q_True Std               87.7554\n",
      "evaluation/EB/Q_Pred Mean            1018.5\n",
      "evaluation/EB/Q_Pred Std              128.476\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4179.91\n",
      "evaluation/Actions Mean                 0.0310268\n",
      "evaluation/Actions Std                  0.569786\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999982\n",
      "time/backward_policy (s)                2.00505\n",
      "time/backward_zf1 (s)                   2.18518\n",
      "time/backward_zf2 (s)                   2.11321\n",
      "time/data sampling (s)                  0.319184\n",
      "time/data storing (s)                   0.0151596\n",
      "time/evaluation sampling (s)            1.76886\n",
      "time/exploration sampling (s)           0.330787\n",
      "time/logging (s)                        0.017213\n",
      "time/preback_alpha (s)                  0.601186\n",
      "time/preback_policy (s)                 1.16528\n",
      "time/preback_start (s)                  0.160281\n",
      "time/preback_zf (s)                     5.19704\n",
      "time/saving (s)                         0.0119404\n",
      "time/training (s)                       2.29296\n",
      "time/epoch (s)                         18.1833\n",
      "time/total (s)                       4283.63\n",
      "Epoch                                 242\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:48:00.554956 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 243 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 254000\n",
      "trainer/ZF1 Loss                        1.59687\n",
      "trainer/ZF2 Loss                       12.4754\n",
      "trainer/ZF Expert Reward               15.1014\n",
      "trainer/ZF Policy Reward                4.21869\n",
      "trainer/ZF CHI2 Term                   50.0199\n",
      "trainer/Policy Loss                  -966.537\n",
      "trainer/Bias Loss                      94.8279\n",
      "trainer/Bias Value                     14.1395\n",
      "trainer/Policy Grad Norm              107.587\n",
      "trainer/Policy Param Norm              38.8095\n",
      "trainer/Zf1 Grad Norm                1081.46\n",
      "trainer/Zf1 Param Norm                121.289\n",
      "trainer/Zf2 Grad Norm                1625.62\n",
      "trainer/Zf2 Param Norm                123.938\n",
      "trainer/Z Expert Predictions Mean    1067.19\n",
      "trainer/Z Expert Predictions Std       45.4359\n",
      "trainer/Z Expert Predictions Max     1151.73\n",
      "trainer/Z Expert Predictions Min      736.545\n",
      "trainer/Z Policy Predictions Mean     963.037\n",
      "trainer/Z Policy Predictions Std      235.602\n",
      "trainer/Z Policy Predictions Max     1126.51\n",
      "trainer/Z Policy Predictions Min     -446.186\n",
      "trainer/Z Expert Targets Mean        1052.09\n",
      "trainer/Z Expert Targets Std           49.2551\n",
      "trainer/Z Expert Targets Max         1147.21\n",
      "trainer/Z Expert Targets Min          729.064\n",
      "trainer/Z Policy Targets Mean         958.818\n",
      "trainer/Z Policy Targets Std          227.389\n",
      "trainer/Z Policy Targets Max         1126.46\n",
      "trainer/Z Policy Targets Min         -427.592\n",
      "trainer/Log Pis Mean                   32.4252\n",
      "trainer/Log Pis Std                     6.47762\n",
      "trainer/Policy mu Mean                 -0.00535506\n",
      "trainer/Policy mu Std                   1.43539\n",
      "trainer/Policy log std Mean            -4.61357\n",
      "trainer/Policy log std Std              0.956726\n",
      "exploration/num steps total        248454\n",
      "exploration/num paths total           376\n",
      "evaluation/num steps total              2.13879e+06\n",
      "evaluation/num paths total           2502\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.59128\n",
      "evaluation/Rewards Std                  1.03908\n",
      "evaluation/Rewards Max                  6.59468\n",
      "evaluation/Rewards Min                 -2.63766\n",
      "evaluation/Returns Mean              4591.28\n",
      "evaluation/Returns Std                 64.9527\n",
      "evaluation/Returns Max               4696.13\n",
      "evaluation/Returns Min               4466.06\n",
      "evaluation/Estimation Bias Mean       998.125\n",
      "evaluation/Estimation Bias Std        144.248\n",
      "evaluation/EB/Q_True Mean              42.6716\n",
      "evaluation/EB/Q_True Std              131.835\n",
      "evaluation/EB/Q_Pred Mean            1040.8\n",
      "evaluation/EB/Q_Pred Std               59.2445\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4591.28\n",
      "evaluation/Actions Mean                 0.0248592\n",
      "evaluation/Actions Std                  0.537048\n",
      "evaluation/Actions Max                  0.999869\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                1.90884\n",
      "time/backward_zf1 (s)                   2.07283\n",
      "time/backward_zf2 (s)                   1.99037\n",
      "time/data sampling (s)                  0.330446\n",
      "time/data storing (s)                   0.0148887\n",
      "time/evaluation sampling (s)            1.67783\n",
      "time/exploration sampling (s)           0.324785\n",
      "time/logging (s)                        0.0120017\n",
      "time/preback_alpha (s)                  0.603628\n",
      "time/preback_policy (s)                 1.08712\n",
      "time/preback_start (s)                  0.156757\n",
      "time/preback_zf (s)                     5.17639\n",
      "time/saving (s)                         0.00577939\n",
      "time/training (s)                       2.45996\n",
      "time/epoch (s)                         17.8216\n",
      "time/total (s)                       4301.47\n",
      "Epoch                                 243\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:48:18.622555 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 244 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 255000\n",
      "trainer/ZF1 Loss                        3.48097\n",
      "trainer/ZF2 Loss                       10.2269\n",
      "trainer/ZF Expert Reward               14.2514\n",
      "trainer/ZF Policy Reward                5.93277\n",
      "trainer/ZF CHI2 Term                   47.727\n",
      "trainer/Policy Loss                  -943.532\n",
      "trainer/Bias Loss                      69.9892\n",
      "trainer/Bias Value                     14.1493\n",
      "trainer/Policy Grad Norm              115.928\n",
      "trainer/Policy Param Norm              38.8377\n",
      "trainer/Zf1 Grad Norm                1183.44\n",
      "trainer/Zf1 Param Norm                121.422\n",
      "trainer/Zf2 Grad Norm                2204.14\n",
      "trainer/Zf2 Param Norm                124.089\n",
      "trainer/Z Expert Predictions Mean    1055.68\n",
      "trainer/Z Expert Predictions Std       98.0899\n",
      "trainer/Z Expert Predictions Max     1152.68\n",
      "trainer/Z Expert Predictions Min       77.9471\n",
      "trainer/Z Policy Predictions Mean     939.779\n",
      "trainer/Z Policy Predictions Std      284.533\n",
      "trainer/Z Policy Predictions Max     1133.52\n",
      "trainer/Z Policy Predictions Min     -447.32\n",
      "trainer/Z Expert Targets Mean        1041.43\n",
      "trainer/Z Expert Targets Std          103.784\n",
      "trainer/Z Expert Targets Max         1136.85\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         933.846\n",
      "trainer/Z Policy Targets Std          279.435\n",
      "trainer/Z Policy Targets Max         1130.45\n",
      "trainer/Z Policy Targets Min         -435.463\n",
      "trainer/Log Pis Mean                   32.8832\n",
      "trainer/Log Pis Std                     6.7942\n",
      "trainer/Policy mu Mean                  0.0358945\n",
      "trainer/Policy mu Std                   1.67538\n",
      "trainer/Policy log std Mean            -4.58326\n",
      "trainer/Policy log std Std              1.06332\n",
      "exploration/num steps total        251454\n",
      "exploration/num paths total           379\n",
      "evaluation/num steps total              2.14879e+06\n",
      "evaluation/num paths total           2512\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64595\n",
      "evaluation/Rewards Std                  0.986516\n",
      "evaluation/Rewards Max                  6.77146\n",
      "evaluation/Rewards Min                 -2.32267\n",
      "evaluation/Returns Mean              4645.95\n",
      "evaluation/Returns Std                 55.2381\n",
      "evaluation/Returns Max               4716.16\n",
      "evaluation/Returns Min               4557.31\n",
      "evaluation/Estimation Bias Mean       995.645\n",
      "evaluation/Estimation Bias Std        143.827\n",
      "evaluation/EB/Q_True Mean              42.6121\n",
      "evaluation/EB/Q_True Std              131.614\n",
      "evaluation/EB/Q_Pred Mean            1038.26\n",
      "evaluation/EB/Q_Pred Std               57.3644\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4645.95\n",
      "evaluation/Actions Mean                 0.0153707\n",
      "evaluation/Actions Std                  0.533922\n",
      "evaluation/Actions Max                  0.999966\n",
      "evaluation/Actions Min                 -0.999936\n",
      "time/backward_policy (s)                1.99267\n",
      "time/backward_zf1 (s)                   2.14984\n",
      "time/backward_zf2 (s)                   2.05366\n",
      "time/data sampling (s)                  0.314178\n",
      "time/data storing (s)                   0.0151558\n",
      "time/evaluation sampling (s)            1.74036\n",
      "time/exploration sampling (s)           0.336221\n",
      "time/logging (s)                        0.0121384\n",
      "time/preback_alpha (s)                  0.592701\n",
      "time/preback_policy (s)                 1.16363\n",
      "time/preback_start (s)                  0.153859\n",
      "time/preback_zf (s)                     5.17911\n",
      "time/saving (s)                         0.00653271\n",
      "time/training (s)                       2.28746\n",
      "time/epoch (s)                         17.9975\n",
      "time/total (s)                       4319.49\n",
      "Epoch                                 244\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:48:36.886951 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 245 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 256000\n",
      "trainer/ZF1 Loss                        4.20615\n",
      "trainer/ZF2 Loss                        1.88448\n",
      "trainer/ZF Expert Reward               10.6761\n",
      "trainer/ZF Policy Reward               -1.05653\n",
      "trainer/ZF CHI2 Term                   47.1015\n",
      "trainer/Policy Loss                  -971.509\n",
      "trainer/Bias Loss                      81.0868\n",
      "trainer/Bias Value                     14.1608\n",
      "trainer/Policy Grad Norm              151.901\n",
      "trainer/Policy Param Norm              38.8696\n",
      "trainer/Zf1 Grad Norm                2546.95\n",
      "trainer/Zf1 Param Norm                121.57\n",
      "trainer/Zf2 Grad Norm                1795.26\n",
      "trainer/Zf2 Param Norm                124.238\n",
      "trainer/Z Expert Predictions Mean    1059.61\n",
      "trainer/Z Expert Predictions Std       48.0647\n",
      "trainer/Z Expert Predictions Max     1161.76\n",
      "trainer/Z Expert Predictions Min      792.299\n",
      "trainer/Z Policy Predictions Mean     965.415\n",
      "trainer/Z Policy Predictions Std      213.425\n",
      "trainer/Z Policy Predictions Max     1152.12\n",
      "trainer/Z Policy Predictions Min     -259.172\n",
      "trainer/Z Expert Targets Mean        1048.93\n",
      "trainer/Z Expert Targets Std           47.3643\n",
      "trainer/Z Expert Targets Max         1137.69\n",
      "trainer/Z Expert Targets Min          797.744\n",
      "trainer/Z Policy Targets Mean         966.472\n",
      "trainer/Z Policy Targets Std          206.3\n",
      "trainer/Z Policy Targets Max         1134.97\n",
      "trainer/Z Policy Targets Min         -240.988\n",
      "trainer/Log Pis Mean                   32.65\n",
      "trainer/Log Pis Std                     7.41717\n",
      "trainer/Policy mu Mean                  0.00745706\n",
      "trainer/Policy mu Std                   1.47428\n",
      "trainer/Policy log std Mean            -4.61769\n",
      "trainer/Policy log std Std              0.934124\n",
      "exploration/num steps total        251454\n",
      "exploration/num paths total           379\n",
      "evaluation/num steps total              2.15799e+06\n",
      "evaluation/num paths total           2523\n",
      "evaluation/path length Mean           836.364\n",
      "evaluation/path length Std            348.674\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             23\n",
      "evaluation/Rewards Mean                 4.61074\n",
      "evaluation/Rewards Std                  1.14943\n",
      "evaluation/Rewards Max                  7.03464\n",
      "evaluation/Rewards Min                 -3.63955\n",
      "evaluation/Returns Mean              3856.25\n",
      "evaluation/Returns Std               1645.67\n",
      "evaluation/Returns Max               4865.45\n",
      "evaluation/Returns Min                 30.5959\n",
      "evaluation/Estimation Bias Mean       980.428\n",
      "evaluation/Estimation Bias Std        165.389\n",
      "evaluation/EB/Q_True Mean              47.2009\n",
      "evaluation/EB/Q_True Std              138.205\n",
      "evaluation/EB/Q_Pred Mean            1027.63\n",
      "evaluation/EB/Q_Pred Std               70.3652\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3856.25\n",
      "evaluation/Actions Mean                 0.0187026\n",
      "evaluation/Actions Std                  0.536758\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93336\n",
      "time/backward_zf1 (s)                   2.15982\n",
      "time/backward_zf2 (s)                   2.06368\n",
      "time/data sampling (s)                  0.34264\n",
      "time/data storing (s)                   0.0160734\n",
      "time/evaluation sampling (s)            1.85736\n",
      "time/exploration sampling (s)           0.332327\n",
      "time/logging (s)                        0.0108011\n",
      "time/preback_alpha (s)                  0.605622\n",
      "time/preback_policy (s)                 1.08068\n",
      "time/preback_start (s)                  0.153329\n",
      "time/preback_zf (s)                     5.17846\n",
      "time/saving (s)                         0.00627667\n",
      "time/training (s)                       2.44852\n",
      "time/epoch (s)                         18.189\n",
      "time/total (s)                       4337.7\n",
      "Epoch                                 245\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:48:54.832070 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 246 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 257000\n",
      "trainer/ZF1 Loss                        1.54744\n",
      "trainer/ZF2 Loss                       -6.33097\n",
      "trainer/ZF Expert Reward               17.7722\n",
      "trainer/ZF Policy Reward                1.56732\n",
      "trainer/ZF CHI2 Term                   46.3881\n",
      "trainer/Policy Loss                  -953.018\n",
      "trainer/Bias Loss                      60.4143\n",
      "trainer/Bias Value                     14.1751\n",
      "trainer/Policy Grad Norm              148.631\n",
      "trainer/Policy Param Norm              38.8979\n",
      "trainer/Zf1 Grad Norm                1453.72\n",
      "trainer/Zf1 Param Norm                121.732\n",
      "trainer/Zf2 Grad Norm                1091.21\n",
      "trainer/Zf2 Param Norm                124.386\n",
      "trainer/Z Expert Predictions Mean    1063.58\n",
      "trainer/Z Expert Predictions Std       44.0737\n",
      "trainer/Z Expert Predictions Max     1148.18\n",
      "trainer/Z Expert Predictions Min      765.391\n",
      "trainer/Z Policy Predictions Mean     946.137\n",
      "trainer/Z Policy Predictions Std      254.001\n",
      "trainer/Z Policy Predictions Max     1140.32\n",
      "trainer/Z Policy Predictions Min     -451.679\n",
      "trainer/Z Expert Targets Mean        1045.81\n",
      "trainer/Z Expert Targets Std           46.0232\n",
      "trainer/Z Expert Targets Max         1140.09\n",
      "trainer/Z Expert Targets Min          750.768\n",
      "trainer/Z Policy Targets Mean         944.57\n",
      "trainer/Z Policy Targets Std          249.097\n",
      "trainer/Z Policy Targets Max         1127.71\n",
      "trainer/Z Policy Targets Min         -445.971\n",
      "trainer/Log Pis Mean                   32.9041\n",
      "trainer/Log Pis Std                     7.58587\n",
      "trainer/Policy mu Mean                 -0.0289963\n",
      "trainer/Policy mu Std                   1.57477\n",
      "trainer/Policy log std Mean            -4.5864\n",
      "trainer/Policy log std Std              1.04742\n",
      "exploration/num steps total        251454\n",
      "exploration/num paths total           379\n",
      "evaluation/num steps total              2.16799e+06\n",
      "evaluation/num paths total           2533\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68535\n",
      "evaluation/Rewards Std                  0.955871\n",
      "evaluation/Rewards Max                  7.00206\n",
      "evaluation/Rewards Min                 -1.63333\n",
      "evaluation/Returns Mean              4685.35\n",
      "evaluation/Returns Std                 59.826\n",
      "evaluation/Returns Max               4766.93\n",
      "evaluation/Returns Min               4579.59\n",
      "evaluation/Estimation Bias Mean       996.183\n",
      "evaluation/Estimation Bias Std        138.957\n",
      "evaluation/EB/Q_True Mean              42.2577\n",
      "evaluation/EB/Q_True Std              130.465\n",
      "evaluation/EB/Q_Pred Mean            1038.44\n",
      "evaluation/EB/Q_Pred Std               48.2439\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4685.35\n",
      "evaluation/Actions Mean                 0.0192285\n",
      "evaluation/Actions Std                  0.533058\n",
      "evaluation/Actions Max                  0.999665\n",
      "evaluation/Actions Min                 -0.999979\n",
      "time/backward_policy (s)                1.9552\n",
      "time/backward_zf1 (s)                   2.10358\n",
      "time/backward_zf2 (s)                   2.01711\n",
      "time/data sampling (s)                  0.355448\n",
      "time/data storing (s)                   0.0161541\n",
      "time/evaluation sampling (s)            1.7087\n",
      "time/exploration sampling (s)           0.340297\n",
      "time/logging (s)                        0.0121442\n",
      "time/preback_alpha (s)                  0.606426\n",
      "time/preback_policy (s)                 1.12349\n",
      "time/preback_start (s)                  0.153462\n",
      "time/preback_zf (s)                     5.18596\n",
      "time/saving (s)                         0.00591323\n",
      "time/training (s)                       2.29204\n",
      "time/epoch (s)                         17.8759\n",
      "time/total (s)                       4355.59\n",
      "Epoch                                 246\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:49:12.963672 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 247 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 258000\n",
      "trainer/ZF1 Loss                        0.228031\n",
      "trainer/ZF2 Loss                       -2.8346\n",
      "trainer/ZF Expert Reward               10.9226\n",
      "trainer/ZF Policy Reward               -1.22088\n",
      "trainer/ZF CHI2 Term                   42.8923\n",
      "trainer/Policy Loss                  -926.391\n",
      "trainer/Bias Loss                      73.2342\n",
      "trainer/Bias Value                     14.1712\n",
      "trainer/Policy Grad Norm              152.185\n",
      "trainer/Policy Param Norm              38.925\n",
      "trainer/Zf1 Grad Norm                1569.19\n",
      "trainer/Zf1 Param Norm                121.885\n",
      "trainer/Zf2 Grad Norm                1416.79\n",
      "trainer/Zf2 Param Norm                124.551\n",
      "trainer/Z Expert Predictions Mean    1051.84\n",
      "trainer/Z Expert Predictions Std       48.534\n",
      "trainer/Z Expert Predictions Max     1147.52\n",
      "trainer/Z Expert Predictions Min      799.528\n",
      "trainer/Z Policy Predictions Mean     919.768\n",
      "trainer/Z Policy Predictions Std      290.501\n",
      "trainer/Z Policy Predictions Max     1108.36\n",
      "trainer/Z Policy Predictions Min     -493.55\n",
      "trainer/Z Expert Targets Mean        1040.91\n",
      "trainer/Z Expert Targets Std           49.8651\n",
      "trainer/Z Expert Targets Max         1139.81\n",
      "trainer/Z Expert Targets Min          783.485\n",
      "trainer/Z Policy Targets Mean         920.989\n",
      "trainer/Z Policy Targets Std          285.515\n",
      "trainer/Z Policy Targets Max         1106.9\n",
      "trainer/Z Policy Targets Min         -478.898\n",
      "trainer/Log Pis Mean                   32.3758\n",
      "trainer/Log Pis Std                     5.81027\n",
      "trainer/Policy mu Mean                  0.0419265\n",
      "trainer/Policy mu Std                   1.47657\n",
      "trainer/Policy log std Mean            -4.62153\n",
      "trainer/Policy log std Std              0.999059\n",
      "exploration/num steps total        252454\n",
      "exploration/num paths total           380\n",
      "evaluation/num steps total              2.17799e+06\n",
      "evaluation/num paths total           2543\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.12158\n",
      "evaluation/Rewards Std                  2.03848\n",
      "evaluation/Rewards Max                  6.87926\n",
      "evaluation/Rewards Min                 -2.17099\n",
      "evaluation/Returns Mean              4121.58\n",
      "evaluation/Returns Std               1779.15\n",
      "evaluation/Returns Max               4905.09\n",
      "evaluation/Returns Min              -1196.87\n",
      "evaluation/Estimation Bias Mean       946.068\n",
      "evaluation/Estimation Bias Std        167.175\n",
      "evaluation/EB/Q_True Mean              43.4144\n",
      "evaluation/EB/Q_True Std              133.716\n",
      "evaluation/EB/Q_Pred Mean             989.483\n",
      "evaluation/EB/Q_Pred Std              115.991\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4121.58\n",
      "evaluation/Actions Mean                 0.0275942\n",
      "evaluation/Actions Std                  0.559818\n",
      "evaluation/Actions Max                  0.999991\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.99676\n",
      "time/backward_zf1 (s)                   2.17411\n",
      "time/backward_zf2 (s)                   2.08955\n",
      "time/data sampling (s)                  0.334453\n",
      "time/data storing (s)                   0.0154532\n",
      "time/evaluation sampling (s)            1.75141\n",
      "time/exploration sampling (s)           0.330701\n",
      "time/logging (s)                        0.0119944\n",
      "time/preback_alpha (s)                  0.604748\n",
      "time/preback_policy (s)                 1.15847\n",
      "time/preback_start (s)                  0.154815\n",
      "time/preback_zf (s)                     5.18138\n",
      "time/saving (s)                         0.00593284\n",
      "time/training (s)                       2.25056\n",
      "time/epoch (s)                         18.0603\n",
      "time/total (s)                       4373.67\n",
      "Epoch                                 247\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:49:31.054064 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 248 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 259000\n",
      "trainer/ZF1 Loss                      139.116\n",
      "trainer/ZF2 Loss                      173.78\n",
      "trainer/ZF Expert Reward               13.9329\n",
      "trainer/ZF Policy Reward                4.19204\n",
      "trainer/ZF CHI2 Term                  197.973\n",
      "trainer/Policy Loss                  -930.583\n",
      "trainer/Bias Loss                      65.8422\n",
      "trainer/Bias Value                     14.1628\n",
      "trainer/Policy Grad Norm              152.285\n",
      "trainer/Policy Param Norm              38.9546\n",
      "trainer/Zf1 Grad Norm                2527.89\n",
      "trainer/Zf1 Param Norm                122.042\n",
      "trainer/Zf2 Grad Norm                1837.64\n",
      "trainer/Zf2 Param Norm                124.699\n",
      "trainer/Z Expert Predictions Mean    1053.31\n",
      "trainer/Z Expert Predictions Std       72.3525\n",
      "trainer/Z Expert Predictions Max     1142.31\n",
      "trainer/Z Expert Predictions Min       67.7181\n",
      "trainer/Z Policy Predictions Mean     928.726\n",
      "trainer/Z Policy Predictions Std      280.917\n",
      "trainer/Z Policy Predictions Max     1108.43\n",
      "trainer/Z Policy Predictions Min     -489.045\n",
      "trainer/Z Expert Targets Mean        1039.38\n",
      "trainer/Z Expert Targets Std           76.9126\n",
      "trainer/Z Expert Targets Max         1120.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         924.534\n",
      "trainer/Z Policy Targets Std          284.887\n",
      "trainer/Z Policy Targets Max         1108.76\n",
      "trainer/Z Policy Targets Min         -478.327\n",
      "trainer/Log Pis Mean                   32.1049\n",
      "trainer/Log Pis Std                     6.06299\n",
      "trainer/Policy mu Mean                  0.0466347\n",
      "trainer/Policy mu Std                   1.45343\n",
      "trainer/Policy log std Mean            -4.56359\n",
      "trainer/Policy log std Std              1.06536\n",
      "exploration/num steps total        255454\n",
      "exploration/num paths total           383\n",
      "evaluation/num steps total              2.18799e+06\n",
      "evaluation/num paths total           2553\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.56175\n",
      "evaluation/Rewards Std                  0.927797\n",
      "evaluation/Rewards Max                  6.69836\n",
      "evaluation/Rewards Min                 -1.85443\n",
      "evaluation/Returns Mean              4561.75\n",
      "evaluation/Returns Std                 34.356\n",
      "evaluation/Returns Max               4629.75\n",
      "evaluation/Returns Min               4501.52\n",
      "evaluation/Estimation Bias Mean       986.486\n",
      "evaluation/Estimation Bias Std        137.783\n",
      "evaluation/EB/Q_True Mean              42.0393\n",
      "evaluation/EB/Q_True Std              129.43\n",
      "evaluation/EB/Q_Pred Mean            1028.53\n",
      "evaluation/EB/Q_Pred Std               48.5988\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4561.75\n",
      "evaluation/Actions Mean                 0.0295714\n",
      "evaluation/Actions Std                  0.533435\n",
      "evaluation/Actions Max                  0.999888\n",
      "evaluation/Actions Min                 -0.999884\n",
      "time/backward_policy (s)                1.94574\n",
      "time/backward_zf1 (s)                   2.1522\n",
      "time/backward_zf2 (s)                   2.0281\n",
      "time/data sampling (s)                  0.314632\n",
      "time/data storing (s)                   0.0151072\n",
      "time/evaluation sampling (s)            1.80532\n",
      "time/exploration sampling (s)           0.337848\n",
      "time/logging (s)                        0.0126286\n",
      "time/preback_alpha (s)                  0.596158\n",
      "time/preback_policy (s)                 1.10513\n",
      "time/preback_start (s)                  0.15124\n",
      "time/preback_zf (s)                     5.17023\n",
      "time/saving (s)                         0.00813826\n",
      "time/training (s)                       2.37014\n",
      "time/epoch (s)                         18.0126\n",
      "time/total (s)                       4391.71\n",
      "Epoch                                 248\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:49:49.106371 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 249 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 260000\n",
      "trainer/ZF1 Loss                       37.8778\n",
      "trainer/ZF2 Loss                       -1.98969\n",
      "trainer/ZF Expert Reward               10.5103\n",
      "trainer/ZF Policy Reward               -0.416144\n",
      "trainer/ZF CHI2 Term                   61.2174\n",
      "trainer/Policy Loss                  -930.58\n",
      "trainer/Bias Loss                      77.9781\n",
      "trainer/Bias Value                     14.1568\n",
      "trainer/Policy Grad Norm              133.846\n",
      "trainer/Policy Param Norm              38.9821\n",
      "trainer/Zf1 Grad Norm                5101.12\n",
      "trainer/Zf1 Param Norm                122.212\n",
      "trainer/Zf2 Grad Norm                1985.16\n",
      "trainer/Zf2 Param Norm                124.856\n",
      "trainer/Z Expert Predictions Mean    1040.54\n",
      "trainer/Z Expert Predictions Std       77.7628\n",
      "trainer/Z Expert Predictions Max     1141.55\n",
      "trainer/Z Expert Predictions Min       43.4648\n",
      "trainer/Z Policy Predictions Mean     921.797\n",
      "trainer/Z Policy Predictions Std      269.713\n",
      "trainer/Z Policy Predictions Max     1145.94\n",
      "trainer/Z Policy Predictions Min     -454.622\n",
      "trainer/Z Expert Targets Mean        1030.03\n",
      "trainer/Z Expert Targets Std           81.4741\n",
      "trainer/Z Expert Targets Max         1133.38\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         922.213\n",
      "trainer/Z Policy Targets Std          265.32\n",
      "trainer/Z Policy Targets Max         1128.62\n",
      "trainer/Z Policy Targets Min         -438.663\n",
      "trainer/Log Pis Mean                   32.6736\n",
      "trainer/Log Pis Std                     6.88315\n",
      "trainer/Policy mu Mean                  0.0218326\n",
      "trainer/Policy mu Std                   1.49379\n",
      "trainer/Policy log std Mean            -4.65133\n",
      "trainer/Policy log std Std              0.978815\n",
      "exploration/num steps total        255454\n",
      "exploration/num paths total           383\n",
      "evaluation/num steps total              2.19765e+06\n",
      "evaluation/num paths total           2564\n",
      "evaluation/path length Mean           878.364\n",
      "evaluation/path length Std            265.635\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            183\n",
      "evaluation/Rewards Mean                 3.93708\n",
      "evaluation/Rewards Std                  2.47529\n",
      "evaluation/Rewards Max                  6.71783\n",
      "evaluation/Rewards Min                 -3.41987\n",
      "evaluation/Returns Mean              3458.19\n",
      "evaluation/Returns Std               2356.38\n",
      "evaluation/Returns Max               4919.12\n",
      "evaluation/Returns Min              -2703.12\n",
      "evaluation/Estimation Bias Mean       861.332\n",
      "evaluation/Estimation Bias Std        363.697\n",
      "evaluation/EB/Q_True Mean              45.1179\n",
      "evaluation/EB/Q_True Std              136.236\n",
      "evaluation/EB/Q_Pred Mean             906.449\n",
      "evaluation/EB/Q_Pred Std              349.79\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3458.19\n",
      "evaluation/Actions Mean                -0.0297307\n",
      "evaluation/Actions Std                  0.591125\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9106\n",
      "time/backward_zf1 (s)                   2.06746\n",
      "time/backward_zf2 (s)                   1.9741\n",
      "time/data sampling (s)                  0.322694\n",
      "time/data storing (s)                   0.0164265\n",
      "time/evaluation sampling (s)            1.82581\n",
      "time/exploration sampling (s)           0.340288\n",
      "time/logging (s)                        0.0119058\n",
      "time/preback_alpha (s)                  0.602519\n",
      "time/preback_policy (s)                 1.11143\n",
      "time/preback_start (s)                  0.153219\n",
      "time/preback_zf (s)                     5.22324\n",
      "time/saving (s)                         0.00644494\n",
      "time/training (s)                       2.41469\n",
      "time/epoch (s)                         17.9808\n",
      "time/total (s)                       4409.71\n",
      "Epoch                                 249\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:50:06.884148 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 250 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 261000\n",
      "trainer/ZF1 Loss                      143.728\n",
      "trainer/ZF2 Loss                      158.854\n",
      "trainer/ZF Expert Reward               13.4327\n",
      "trainer/ZF Policy Reward                3.35448\n",
      "trainer/ZF CHI2 Term                  194.418\n",
      "trainer/Policy Loss                  -901.49\n",
      "trainer/Bias Loss                      77.6506\n",
      "trainer/Bias Value                     14.1439\n",
      "trainer/Policy Grad Norm              172.773\n",
      "trainer/Policy Param Norm              39.0129\n",
      "trainer/Zf1 Grad Norm                2849.28\n",
      "trainer/Zf1 Param Norm                122.335\n",
      "trainer/Zf2 Grad Norm                2809.59\n",
      "trainer/Zf2 Param Norm                124.995\n",
      "trainer/Z Expert Predictions Mean    1042.07\n",
      "trainer/Z Expert Predictions Std      104.843\n",
      "trainer/Z Expert Predictions Max     1147.08\n",
      "trainer/Z Expert Predictions Min      -89.8895\n",
      "trainer/Z Policy Predictions Mean     893.622\n",
      "trainer/Z Policy Predictions Std      299.566\n",
      "trainer/Z Policy Predictions Max     1109.06\n",
      "trainer/Z Policy Predictions Min     -467.302\n",
      "trainer/Z Expert Targets Mean        1028.63\n",
      "trainer/Z Expert Targets Std          100.181\n",
      "trainer/Z Expert Targets Max         1124.6\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         890.268\n",
      "trainer/Z Policy Targets Std          299.694\n",
      "trainer/Z Policy Targets Max         1097.97\n",
      "trainer/Z Policy Targets Min         -452.898\n",
      "trainer/Log Pis Mean                   33.3827\n",
      "trainer/Log Pis Std                     6.79508\n",
      "trainer/Policy mu Mean                  0.0305019\n",
      "trainer/Policy mu Std                   1.5948\n",
      "trainer/Policy log std Mean            -4.54274\n",
      "trainer/Policy log std Std              1.08384\n",
      "exploration/num steps total        255454\n",
      "exploration/num paths total           383\n",
      "evaluation/num steps total              2.20765e+06\n",
      "evaluation/num paths total           2574\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7613\n",
      "evaluation/Rewards Std                  0.983729\n",
      "evaluation/Rewards Max                  6.98344\n",
      "evaluation/Rewards Min                 -1.70491\n",
      "evaluation/Returns Mean              4761.3\n",
      "evaluation/Returns Std                105.916\n",
      "evaluation/Returns Max               4908.97\n",
      "evaluation/Returns Min               4584.97\n",
      "evaluation/Estimation Bias Mean       975.641\n",
      "evaluation/Estimation Bias Std        145.109\n",
      "evaluation/EB/Q_True Mean              44.2095\n",
      "evaluation/EB/Q_True Std              136.482\n",
      "evaluation/EB/Q_Pred Mean            1019.85\n",
      "evaluation/EB/Q_Pred Std               50.3179\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4761.3\n",
      "evaluation/Actions Mean                 0.0230151\n",
      "evaluation/Actions Std                  0.536424\n",
      "evaluation/Actions Max                  0.999902\n",
      "evaluation/Actions Min                 -0.999977\n",
      "time/backward_policy (s)                1.85499\n",
      "time/backward_zf1 (s)                   2.01801\n",
      "time/backward_zf2 (s)                   1.91885\n",
      "time/data sampling (s)                  0.334808\n",
      "time/data storing (s)                   0.0149869\n",
      "time/evaluation sampling (s)            1.79234\n",
      "time/exploration sampling (s)           0.32384\n",
      "time/logging (s)                        0.0117303\n",
      "time/preback_alpha (s)                  0.594129\n",
      "time/preback_policy (s)                 1.05202\n",
      "time/preback_start (s)                  0.148258\n",
      "time/preback_zf (s)                     5.17854\n",
      "time/saving (s)                         0.00637602\n",
      "time/training (s)                       2.45725\n",
      "time/epoch (s)                         17.7061\n",
      "time/total (s)                       4427.44\n",
      "Epoch                                 250\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:50:25.622100 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 251 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 262000\n",
      "trainer/ZF1 Loss                       -3.19879\n",
      "trainer/ZF2 Loss                       -2.68142\n",
      "trainer/ZF Expert Reward               12.9553\n",
      "trainer/ZF Policy Reward                2.95137\n",
      "trainer/ZF CHI2 Term                   39.4566\n",
      "trainer/Policy Loss                  -938.809\n",
      "trainer/Bias Loss                      65.8865\n",
      "trainer/Bias Value                     14.1328\n",
      "trainer/Policy Grad Norm              137.249\n",
      "trainer/Policy Param Norm              39.0436\n",
      "trainer/Zf1 Grad Norm                1194.68\n",
      "trainer/Zf1 Param Norm                122.499\n",
      "trainer/Zf2 Grad Norm                1406.54\n",
      "trainer/Zf2 Param Norm                125.16\n",
      "trainer/Z Expert Predictions Mean    1038.36\n",
      "trainer/Z Expert Predictions Std       52.2128\n",
      "trainer/Z Expert Predictions Max     1138.57\n",
      "trainer/Z Expert Predictions Min      785.878\n",
      "trainer/Z Policy Predictions Mean     932.562\n",
      "trainer/Z Policy Predictions Std      253.082\n",
      "trainer/Z Policy Predictions Max     1100.35\n",
      "trainer/Z Policy Predictions Min     -487.077\n",
      "trainer/Z Expert Targets Mean        1025.4\n",
      "trainer/Z Expert Targets Std           54.3875\n",
      "trainer/Z Expert Targets Max         1120.43\n",
      "trainer/Z Expert Targets Min          763.997\n",
      "trainer/Z Policy Targets Mean         929.611\n",
      "trainer/Z Policy Targets Std          252.237\n",
      "trainer/Z Policy Targets Max         1102.15\n",
      "trainer/Z Policy Targets Min         -482.593\n",
      "trainer/Log Pis Mean                   32.72\n",
      "trainer/Log Pis Std                     6.1327\n",
      "trainer/Policy mu Mean                  0.0386005\n",
      "trainer/Policy mu Std                   1.50977\n",
      "trainer/Policy log std Mean            -4.62213\n",
      "trainer/Policy log std Std              0.983996\n",
      "exploration/num steps total        256454\n",
      "exploration/num paths total           384\n",
      "evaluation/num steps total              2.21705e+06\n",
      "evaluation/num paths total           2584\n",
      "evaluation/path length Mean           939.6\n",
      "evaluation/path length Std            181.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            396\n",
      "evaluation/Rewards Mean                 4.60137\n",
      "evaluation/Rewards Std                  0.977536\n",
      "evaluation/Rewards Max                  6.87826\n",
      "evaluation/Rewards Min                 -1.99301\n",
      "evaluation/Returns Mean              4323.44\n",
      "evaluation/Returns Std                869.388\n",
      "evaluation/Returns Max               4767.28\n",
      "evaluation/Returns Min               1727.52\n",
      "evaluation/Estimation Bias Mean       977.119\n",
      "evaluation/Estimation Bias Std        145.134\n",
      "evaluation/EB/Q_True Mean              44.5461\n",
      "evaluation/EB/Q_True Std              132.462\n",
      "evaluation/EB/Q_Pred Mean            1021.66\n",
      "evaluation/EB/Q_Pred Std               51.2544\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4323.44\n",
      "evaluation/Actions Mean                 0.0189527\n",
      "evaluation/Actions Std                  0.532959\n",
      "evaluation/Actions Max                  0.999849\n",
      "evaluation/Actions Min                 -0.99986\n",
      "time/backward_policy (s)                2.0684\n",
      "time/backward_zf1 (s)                   2.25097\n",
      "time/backward_zf2 (s)                   2.17729\n",
      "time/data sampling (s)                  0.321624\n",
      "time/data storing (s)                   0.0159662\n",
      "time/evaluation sampling (s)            1.80573\n",
      "time/exploration sampling (s)           0.347019\n",
      "time/logging (s)                        0.0187933\n",
      "time/preback_alpha (s)                  0.619882\n",
      "time/preback_policy (s)                 1.15479\n",
      "time/preback_start (s)                  0.156958\n",
      "time/preback_zf (s)                     5.27444\n",
      "time/saving (s)                         0.00646099\n",
      "time/training (s)                       2.45547\n",
      "time/epoch (s)                         18.6738\n",
      "time/total (s)                       4446.13\n",
      "Epoch                                 251\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:50:43.908201 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 252 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 263000\n",
      "trainer/ZF1 Loss                        0.828266\n",
      "trainer/ZF2 Loss                        0.0809174\n",
      "trainer/ZF Expert Reward               13.6449\n",
      "trainer/ZF Policy Reward                4.72308\n",
      "trainer/ZF CHI2 Term                   42.8247\n",
      "trainer/Policy Loss                  -915.294\n",
      "trainer/Bias Loss                      52.3596\n",
      "trainer/Bias Value                     14.1391\n",
      "trainer/Policy Grad Norm              123.994\n",
      "trainer/Policy Param Norm              39.0693\n",
      "trainer/Zf1 Grad Norm                1379.15\n",
      "trainer/Zf1 Param Norm                122.622\n",
      "trainer/Zf2 Grad Norm                1143.22\n",
      "trainer/Zf2 Param Norm                125.283\n",
      "trainer/Z Expert Predictions Mean    1046.85\n",
      "trainer/Z Expert Predictions Std       39.9363\n",
      "trainer/Z Expert Predictions Max     1140.12\n",
      "trainer/Z Expert Predictions Min      872.255\n",
      "trainer/Z Policy Predictions Mean     914.003\n",
      "trainer/Z Policy Predictions Std      299.063\n",
      "trainer/Z Policy Predictions Max     1107.86\n",
      "trainer/Z Policy Predictions Min     -465.735\n",
      "trainer/Z Expert Targets Mean        1033.2\n",
      "trainer/Z Expert Targets Std           42.2083\n",
      "trainer/Z Expert Targets Max         1113.29\n",
      "trainer/Z Expert Targets Min          844.337\n",
      "trainer/Z Policy Targets Mean         909.28\n",
      "trainer/Z Policy Targets Std          295.887\n",
      "trainer/Z Policy Targets Max         1103.48\n",
      "trainer/Z Policy Targets Min         -459.431\n",
      "trainer/Log Pis Mean                   33.7861\n",
      "trainer/Log Pis Std                     7.37696\n",
      "trainer/Policy mu Mean                  0.101691\n",
      "trainer/Policy mu Std                   1.82282\n",
      "trainer/Policy log std Mean            -4.5849\n",
      "trainer/Policy log std Std              1.13245\n",
      "exploration/num steps total        257454\n",
      "exploration/num paths total           385\n",
      "evaluation/num steps total              2.22568e+06\n",
      "evaluation/num paths total           2594\n",
      "evaluation/path length Mean           863.2\n",
      "evaluation/path length Std            302.02\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             30\n",
      "evaluation/Rewards Mean                 4.58882\n",
      "evaluation/Rewards Std                  1.02025\n",
      "evaluation/Rewards Max                  6.61665\n",
      "evaluation/Rewards Min                 -1.81041\n",
      "evaluation/Returns Mean              3961.07\n",
      "evaluation/Returns Std               1431.94\n",
      "evaluation/Returns Max               4710\n",
      "evaluation/Returns Min                 -8.65421\n",
      "evaluation/Estimation Bias Mean       975.678\n",
      "evaluation/Estimation Bias Std        151.415\n",
      "evaluation/EB/Q_True Mean              47.9508\n",
      "evaluation/EB/Q_True Std              135.586\n",
      "evaluation/EB/Q_Pred Mean            1023.63\n",
      "evaluation/EB/Q_Pred Std               57.8949\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3961.07\n",
      "evaluation/Actions Mean                 0.0245117\n",
      "evaluation/Actions Std                  0.530714\n",
      "evaluation/Actions Max                  0.999862\n",
      "evaluation/Actions Min                 -0.999935\n",
      "time/backward_policy (s)                1.99388\n",
      "time/backward_zf1 (s)                   2.15815\n",
      "time/backward_zf2 (s)                   2.08786\n",
      "time/data sampling (s)                  0.333315\n",
      "time/data storing (s)                   0.0145296\n",
      "time/evaluation sampling (s)            1.84186\n",
      "time/exploration sampling (s)           0.323793\n",
      "time/logging (s)                        0.0107178\n",
      "time/preback_alpha (s)                  0.599725\n",
      "time/preback_policy (s)                 1.18051\n",
      "time/preback_start (s)                  0.151195\n",
      "time/preback_zf (s)                     5.2273\n",
      "time/saving (s)                         0.0063779\n",
      "time/training (s)                       2.27399\n",
      "time/epoch (s)                         18.2032\n",
      "time/total (s)                       4464.35\n",
      "Epoch                                 252\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:51:02.141612 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 253 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 264000\n",
      "trainer/ZF1 Loss                       -8.18808\n",
      "trainer/ZF2 Loss                       -5.90015\n",
      "trainer/ZF Expert Reward               19.4409\n",
      "trainer/ZF Policy Reward                9.0224\n",
      "trainer/ZF CHI2 Term                   36.1594\n",
      "trainer/Policy Loss                  -900.244\n",
      "trainer/Bias Loss                      79.3514\n",
      "trainer/Bias Value                     14.1119\n",
      "trainer/Policy Grad Norm              132.682\n",
      "trainer/Policy Param Norm              39.0992\n",
      "trainer/Zf1 Grad Norm                1159.49\n",
      "trainer/Zf1 Param Norm                122.784\n",
      "trainer/Zf2 Grad Norm                1112.05\n",
      "trainer/Zf2 Param Norm                125.445\n",
      "trainer/Z Expert Predictions Mean    1048.55\n",
      "trainer/Z Expert Predictions Std       42.1023\n",
      "trainer/Z Expert Predictions Max     1151.09\n",
      "trainer/Z Expert Predictions Min      830.02\n",
      "trainer/Z Policy Predictions Mean     898.991\n",
      "trainer/Z Policy Predictions Std      336.841\n",
      "trainer/Z Policy Predictions Max     1133.53\n",
      "trainer/Z Policy Predictions Min     -509.714\n",
      "trainer/Z Expert Targets Mean        1029.11\n",
      "trainer/Z Expert Targets Std           42.0468\n",
      "trainer/Z Expert Targets Max         1112.37\n",
      "trainer/Z Expert Targets Min          808.396\n",
      "trainer/Z Policy Targets Mean         889.969\n",
      "trainer/Z Policy Targets Std          330.954\n",
      "trainer/Z Policy Targets Max         1114.54\n",
      "trainer/Z Policy Targets Min         -495.498\n",
      "trainer/Log Pis Mean                   33.1161\n",
      "trainer/Log Pis Std                     7.58313\n",
      "trainer/Policy mu Mean                  0.0598229\n",
      "trainer/Policy mu Std                   1.75027\n",
      "trainer/Policy log std Mean            -4.50538\n",
      "trainer/Policy log std Std              1.14922\n",
      "exploration/num steps total        258454\n",
      "exploration/num paths total           386\n",
      "evaluation/num steps total              2.23568e+06\n",
      "evaluation/num paths total           2604\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.71811\n",
      "evaluation/Rewards Std                  1.03287\n",
      "evaluation/Rewards Max                  7.0093\n",
      "evaluation/Rewards Min                 -2.10194\n",
      "evaluation/Returns Mean              4718.11\n",
      "evaluation/Returns Std                 63.5423\n",
      "evaluation/Returns Max               4831.91\n",
      "evaluation/Returns Min               4615.81\n",
      "evaluation/Estimation Bias Mean       972.493\n",
      "evaluation/Estimation Bias Std        149.765\n",
      "evaluation/EB/Q_True Mean              43.9631\n",
      "evaluation/EB/Q_True Std              135.056\n",
      "evaluation/EB/Q_Pred Mean            1016.46\n",
      "evaluation/EB/Q_Pred Std               57.712\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4718.11\n",
      "evaluation/Actions Mean                 0.0231823\n",
      "evaluation/Actions Std                  0.536524\n",
      "evaluation/Actions Max                  0.999824\n",
      "evaluation/Actions Min                 -0.999875\n",
      "time/backward_policy (s)                2.0346\n",
      "time/backward_zf1 (s)                   2.20913\n",
      "time/backward_zf2 (s)                   2.09628\n",
      "time/data sampling (s)                  0.345134\n",
      "time/data storing (s)                   0.0146848\n",
      "time/evaluation sampling (s)            1.72959\n",
      "time/exploration sampling (s)           0.329001\n",
      "time/logging (s)                        0.0127081\n",
      "time/preback_alpha (s)                  0.601625\n",
      "time/preback_policy (s)                 1.20753\n",
      "time/preback_start (s)                  0.152247\n",
      "time/preback_zf (s)                     5.19088\n",
      "time/saving (s)                         0.0188254\n",
      "time/training (s)                       2.2194\n",
      "time/epoch (s)                         18.1616\n",
      "time/total (s)                       4482.54\n",
      "Epoch                                 253\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:51:20.897548 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 254 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 265000\n",
      "trainer/ZF1 Loss                       -4.71977\n",
      "trainer/ZF2 Loss                       -5.77365\n",
      "trainer/ZF Expert Reward               16.3529\n",
      "trainer/ZF Policy Reward                5.59224\n",
      "trainer/ZF CHI2 Term                   37.9089\n",
      "trainer/Policy Loss                  -946.036\n",
      "trainer/Bias Loss                      62.0971\n",
      "trainer/Bias Value                     14.1308\n",
      "trainer/Policy Grad Norm              128.507\n",
      "trainer/Policy Param Norm              39.1278\n",
      "trainer/Zf1 Grad Norm                 882.411\n",
      "trainer/Zf1 Param Norm                122.928\n",
      "trainer/Zf2 Grad Norm                 945.165\n",
      "trainer/Zf2 Param Norm                125.599\n",
      "trainer/Z Expert Predictions Mean    1034.84\n",
      "trainer/Z Expert Predictions Std       50.9468\n",
      "trainer/Z Expert Predictions Max     1118.15\n",
      "trainer/Z Expert Predictions Min      758.719\n",
      "trainer/Z Policy Predictions Mean     938.179\n",
      "trainer/Z Policy Predictions Std      229.311\n",
      "trainer/Z Policy Predictions Max     1105.1\n",
      "trainer/Z Policy Predictions Min     -458.438\n",
      "trainer/Z Expert Targets Mean        1018.49\n",
      "trainer/Z Expert Targets Std           54.0051\n",
      "trainer/Z Expert Targets Max         1116.25\n",
      "trainer/Z Expert Targets Min          731.311\n",
      "trainer/Z Policy Targets Mean         932.586\n",
      "trainer/Z Policy Targets Std          226.317\n",
      "trainer/Z Policy Targets Max         1110.73\n",
      "trainer/Z Policy Targets Min         -447.871\n",
      "trainer/Log Pis Mean                   32.7221\n",
      "trainer/Log Pis Std                     7.64944\n",
      "trainer/Policy mu Mean                  0.0667018\n",
      "trainer/Policy mu Std                   1.42912\n",
      "trainer/Policy log std Mean            -4.66152\n",
      "trainer/Policy log std Std              0.910433\n",
      "exploration/num steps total        261454\n",
      "exploration/num paths total           389\n",
      "evaluation/num steps total              2.24568e+06\n",
      "evaluation/num paths total           2614\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.61032\n",
      "evaluation/Rewards Std                  0.99824\n",
      "evaluation/Rewards Max                  6.78406\n",
      "evaluation/Rewards Min                 -2.33345\n",
      "evaluation/Returns Mean              4610.32\n",
      "evaluation/Returns Std                 72.0044\n",
      "evaluation/Returns Max               4738.55\n",
      "evaluation/Returns Min               4458.55\n",
      "evaluation/Estimation Bias Mean       974.019\n",
      "evaluation/Estimation Bias Std        144.811\n",
      "evaluation/EB/Q_True Mean              42.7778\n",
      "evaluation/EB/Q_True Std              131.657\n",
      "evaluation/EB/Q_Pred Mean            1016.8\n",
      "evaluation/EB/Q_Pred Std               57.443\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4610.32\n",
      "evaluation/Actions Mean                 0.0242716\n",
      "evaluation/Actions Std                  0.528348\n",
      "evaluation/Actions Max                  0.999761\n",
      "evaluation/Actions Min                 -0.999925\n",
      "time/backward_policy (s)                2.12919\n",
      "time/backward_zf1 (s)                   2.33245\n",
      "time/backward_zf2 (s)                   2.21786\n",
      "time/data sampling (s)                  0.339326\n",
      "time/data storing (s)                   0.0151\n",
      "time/evaluation sampling (s)            1.74464\n",
      "time/exploration sampling (s)           0.34106\n",
      "time/logging (s)                        0.0134318\n",
      "time/preback_alpha (s)                  0.616402\n",
      "time/preback_policy (s)                 1.22541\n",
      "time/preback_start (s)                  0.155634\n",
      "time/preback_zf (s)                     5.2487\n",
      "time/saving (s)                         0.0214402\n",
      "time/training (s)                       2.28453\n",
      "time/epoch (s)                         18.6852\n",
      "time/total (s)                       4501.24\n",
      "Epoch                                 254\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:51:39.102114 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 255 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 266000\n",
      "trainer/ZF1 Loss                        5.68331\n",
      "trainer/ZF2 Loss                        5.75295\n",
      "trainer/ZF Expert Reward               15.3928\n",
      "trainer/ZF Policy Reward                7.8032\n",
      "trainer/ZF CHI2 Term                   45.9049\n",
      "trainer/Policy Loss                  -928.859\n",
      "trainer/Bias Loss                      67.693\n",
      "trainer/Bias Value                     14.1332\n",
      "trainer/Policy Grad Norm              120.886\n",
      "trainer/Policy Param Norm              39.1579\n",
      "trainer/Zf1 Grad Norm                1372.47\n",
      "trainer/Zf1 Param Norm                123.059\n",
      "trainer/Zf2 Grad Norm                1318.53\n",
      "trainer/Zf2 Param Norm                125.742\n",
      "trainer/Z Expert Predictions Mean    1034.88\n",
      "trainer/Z Expert Predictions Std       47.0123\n",
      "trainer/Z Expert Predictions Max     1132.58\n",
      "trainer/Z Expert Predictions Min      810.978\n",
      "trainer/Z Policy Predictions Mean     927.139\n",
      "trainer/Z Policy Predictions Std      271.458\n",
      "trainer/Z Policy Predictions Max     1127.6\n",
      "trainer/Z Policy Predictions Min     -466.521\n",
      "trainer/Z Expert Targets Mean        1019.49\n",
      "trainer/Z Expert Targets Std           47.3931\n",
      "trainer/Z Expert Targets Max         1108.24\n",
      "trainer/Z Expert Targets Min          790.397\n",
      "trainer/Z Policy Targets Mean         919.336\n",
      "trainer/Z Policy Targets Std          267.195\n",
      "trainer/Z Policy Targets Max         1112.41\n",
      "trainer/Z Policy Targets Min         -473.358\n",
      "trainer/Log Pis Mean                   32.9264\n",
      "trainer/Log Pis Std                     6.75323\n",
      "trainer/Policy mu Mean                  0.072297\n",
      "trainer/Policy mu Std                   1.43913\n",
      "trainer/Policy log std Mean            -4.69523\n",
      "trainer/Policy log std Std              0.941897\n",
      "exploration/num steps total        261454\n",
      "exploration/num paths total           389\n",
      "evaluation/num steps total              2.25568e+06\n",
      "evaluation/num paths total           2624\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.61611\n",
      "evaluation/Rewards Std                  0.960477\n",
      "evaluation/Rewards Max                  6.62725\n",
      "evaluation/Rewards Min                 -2.86185\n",
      "evaluation/Returns Mean              4616.11\n",
      "evaluation/Returns Std                102.618\n",
      "evaluation/Returns Max               4756.57\n",
      "evaluation/Returns Min               4379.27\n",
      "evaluation/Estimation Bias Mean       971.778\n",
      "evaluation/Estimation Bias Std        150.511\n",
      "evaluation/EB/Q_True Mean              42.9527\n",
      "evaluation/EB/Q_True Std              132.725\n",
      "evaluation/EB/Q_Pred Mean            1014.73\n",
      "evaluation/EB/Q_Pred Std               54.5222\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4616.11\n",
      "evaluation/Actions Mean                 0.0256358\n",
      "evaluation/Actions Std                  0.53051\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999909\n",
      "time/backward_policy (s)                1.96464\n",
      "time/backward_zf1 (s)                   2.15377\n",
      "time/backward_zf2 (s)                   2.05434\n",
      "time/data sampling (s)                  0.349271\n",
      "time/data storing (s)                   0.0155081\n",
      "time/evaluation sampling (s)            1.70378\n",
      "time/exploration sampling (s)           0.3283\n",
      "time/logging (s)                        0.0120191\n",
      "time/preback_alpha (s)                  0.604551\n",
      "time/preback_policy (s)                 1.11626\n",
      "time/preback_start (s)                  0.153014\n",
      "time/preback_zf (s)                     5.22658\n",
      "time/saving (s)                         0.00654233\n",
      "time/training (s)                       2.44183\n",
      "time/epoch (s)                         18.1304\n",
      "time/total (s)                       4519.39\n",
      "Epoch                                 255\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:51:57.327458 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 256 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 267000\n",
      "trainer/ZF1 Loss                      177.23\n",
      "trainer/ZF2 Loss                      177.345\n",
      "trainer/ZF Expert Reward               16.2776\n",
      "trainer/ZF Policy Reward                8.28645\n",
      "trainer/ZF CHI2 Term                  217.644\n",
      "trainer/Policy Loss                  -916.704\n",
      "trainer/Bias Loss                      54.6337\n",
      "trainer/Bias Value                     14.1291\n",
      "trainer/Policy Grad Norm              142.367\n",
      "trainer/Policy Param Norm              39.1849\n",
      "trainer/Zf1 Grad Norm                1572.09\n",
      "trainer/Zf1 Param Norm                123.192\n",
      "trainer/Zf2 Grad Norm                1830.49\n",
      "trainer/Zf2 Param Norm                125.873\n",
      "trainer/Z Expert Predictions Mean    1035.82\n",
      "trainer/Z Expert Predictions Std       45.7557\n",
      "trainer/Z Expert Predictions Max     1124.32\n",
      "trainer/Z Expert Predictions Min      796.947\n",
      "trainer/Z Policy Predictions Mean     919.301\n",
      "trainer/Z Policy Predictions Std      257.854\n",
      "trainer/Z Policy Predictions Max     1090\n",
      "trainer/Z Policy Predictions Min     -433.493\n",
      "trainer/Z Expert Targets Mean        1019.54\n",
      "trainer/Z Expert Targets Std           46.5752\n",
      "trainer/Z Expert Targets Max         1116.26\n",
      "trainer/Z Expert Targets Min          779.645\n",
      "trainer/Z Policy Targets Mean         911.015\n",
      "trainer/Z Policy Targets Std          260.691\n",
      "trainer/Z Policy Targets Max         1070.55\n",
      "trainer/Z Policy Targets Min         -431.726\n",
      "trainer/Log Pis Mean                   32.6913\n",
      "trainer/Log Pis Std                     7.15173\n",
      "trainer/Policy mu Mean                  0.0573352\n",
      "trainer/Policy mu Std                   1.61355\n",
      "trainer/Policy log std Mean            -4.64433\n",
      "trainer/Policy log std Std              0.958463\n",
      "exploration/num steps total        261454\n",
      "exploration/num paths total           389\n",
      "evaluation/num steps total              2.26568e+06\n",
      "evaluation/num paths total           2634\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.59481\n",
      "evaluation/Rewards Std                  0.96634\n",
      "evaluation/Rewards Max                  6.52584\n",
      "evaluation/Rewards Min                 -1.95993\n",
      "evaluation/Returns Mean              4594.81\n",
      "evaluation/Returns Std                106.017\n",
      "evaluation/Returns Max               4775.64\n",
      "evaluation/Returns Min               4351.74\n",
      "evaluation/Estimation Bias Mean       964.831\n",
      "evaluation/Estimation Bias Std        142.831\n",
      "evaluation/EB/Q_True Mean              42.8169\n",
      "evaluation/EB/Q_True Std              131.9\n",
      "evaluation/EB/Q_Pred Mean            1007.65\n",
      "evaluation/EB/Q_Pred Std               51.6794\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4594.81\n",
      "evaluation/Actions Mean                 0.0222677\n",
      "evaluation/Actions Std                  0.534056\n",
      "evaluation/Actions Max                  0.999956\n",
      "evaluation/Actions Min                 -0.999801\n",
      "time/backward_policy (s)                2.03727\n",
      "time/backward_zf1 (s)                   2.21102\n",
      "time/backward_zf2 (s)                   2.14049\n",
      "time/data sampling (s)                  0.320281\n",
      "time/data storing (s)                   0.016051\n",
      "time/evaluation sampling (s)            1.69882\n",
      "time/exploration sampling (s)           0.33422\n",
      "time/logging (s)                        0.0115381\n",
      "time/preback_alpha (s)                  0.597514\n",
      "time/preback_policy (s)                 1.18979\n",
      "time/preback_start (s)                  0.15101\n",
      "time/preback_zf (s)                     5.18146\n",
      "time/saving (s)                         0.00598765\n",
      "time/training (s)                       2.25696\n",
      "time/epoch (s)                         18.1524\n",
      "time/total (s)                       4537.56\n",
      "Epoch                                 256\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:52:15.130694 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 257 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 268000\n",
      "trainer/ZF1 Loss                      -15.2425\n",
      "trainer/ZF2 Loss                      -12.3299\n",
      "trainer/ZF Expert Reward               11.8907\n",
      "trainer/ZF Policy Reward               -1.15037\n",
      "trainer/ZF CHI2 Term                   32.2038\n",
      "trainer/Policy Loss                  -905.757\n",
      "trainer/Bias Loss                      47.2357\n",
      "trainer/Bias Value                     14.1198\n",
      "trainer/Policy Grad Norm              125.609\n",
      "trainer/Policy Param Norm              39.2118\n",
      "trainer/Zf1 Grad Norm                1436.44\n",
      "trainer/Zf1 Param Norm                123.339\n",
      "trainer/Zf2 Grad Norm                1525.2\n",
      "trainer/Zf2 Param Norm                126.027\n",
      "trainer/Z Expert Predictions Mean    1028.13\n",
      "trainer/Z Expert Predictions Std       72.0242\n",
      "trainer/Z Expert Predictions Max     1109.13\n",
      "trainer/Z Expert Predictions Min       26.5481\n",
      "trainer/Z Policy Predictions Mean     900.265\n",
      "trainer/Z Policy Predictions Std      264.805\n",
      "trainer/Z Policy Predictions Max     1117.81\n",
      "trainer/Z Policy Predictions Min     -431.856\n",
      "trainer/Z Expert Targets Mean        1016.24\n",
      "trainer/Z Expert Targets Std           74.1824\n",
      "trainer/Z Expert Targets Max         1103.51\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         901.415\n",
      "trainer/Z Policy Targets Std          262.811\n",
      "trainer/Z Policy Targets Max         1091.85\n",
      "trainer/Z Policy Targets Min         -435.821\n",
      "trainer/Log Pis Mean                   33.2818\n",
      "trainer/Log Pis Std                     7.50005\n",
      "trainer/Policy mu Mean                  0.0673926\n",
      "trainer/Policy mu Std                   1.72434\n",
      "trainer/Policy log std Mean            -4.56001\n",
      "trainer/Policy log std Std              1.04764\n",
      "exploration/num steps total        262454\n",
      "exploration/num paths total           390\n",
      "evaluation/num steps total              2.27568e+06\n",
      "evaluation/num paths total           2644\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65123\n",
      "evaluation/Rewards Std                  1.07804\n",
      "evaluation/Rewards Max                  7.03305\n",
      "evaluation/Rewards Min                 -2.13105\n",
      "evaluation/Returns Mean              4651.23\n",
      "evaluation/Returns Std                125.859\n",
      "evaluation/Returns Max               4854.87\n",
      "evaluation/Returns Min               4511.42\n",
      "evaluation/Estimation Bias Mean       961.967\n",
      "evaluation/Estimation Bias Std        139.694\n",
      "evaluation/EB/Q_True Mean              41.4175\n",
      "evaluation/EB/Q_True Std              128.057\n",
      "evaluation/EB/Q_Pred Mean            1003.38\n",
      "evaluation/EB/Q_Pred Std               64.0146\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4651.23\n",
      "evaluation/Actions Mean                 0.0194172\n",
      "evaluation/Actions Std                  0.53761\n",
      "evaluation/Actions Max                  0.999974\n",
      "evaluation/Actions Min                 -0.999983\n",
      "time/backward_policy (s)                1.88793\n",
      "time/backward_zf1 (s)                   2.07656\n",
      "time/backward_zf2 (s)                   1.97783\n",
      "time/data sampling (s)                  0.324035\n",
      "time/data storing (s)                   0.0150774\n",
      "time/evaluation sampling (s)            1.71896\n",
      "time/exploration sampling (s)           0.327116\n",
      "time/logging (s)                        0.0119355\n",
      "time/preback_alpha (s)                  0.595459\n",
      "time/preback_policy (s)                 1.08185\n",
      "time/preback_start (s)                  0.149956\n",
      "time/preback_zf (s)                     5.17627\n",
      "time/saving (s)                         0.00590058\n",
      "time/training (s)                       2.38197\n",
      "time/epoch (s)                         17.7308\n",
      "time/total (s)                       4555.32\n",
      "Epoch                                 257\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:52:33.512997 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 258 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 269000\n",
      "trainer/ZF1 Loss                      173.484\n",
      "trainer/ZF2 Loss                      179.038\n",
      "trainer/ZF Expert Reward               15.555\n",
      "trainer/ZF Policy Reward                8.8341\n",
      "trainer/ZF CHI2 Term                  215.888\n",
      "trainer/Policy Loss                  -913.785\n",
      "trainer/Bias Loss                      59.7258\n",
      "trainer/Bias Value                     14.1379\n",
      "trainer/Policy Grad Norm              140.273\n",
      "trainer/Policy Param Norm              39.2395\n",
      "trainer/Zf1 Grad Norm                1206.02\n",
      "trainer/Zf1 Param Norm                123.49\n",
      "trainer/Zf2 Grad Norm                1623.16\n",
      "trainer/Zf2 Param Norm                126.171\n",
      "trainer/Z Expert Predictions Mean    1030.42\n",
      "trainer/Z Expert Predictions Std       44.2601\n",
      "trainer/Z Expert Predictions Max     1110.27\n",
      "trainer/Z Expert Predictions Min      703.998\n",
      "trainer/Z Policy Predictions Mean     910.495\n",
      "trainer/Z Policy Predictions Std      261.663\n",
      "trainer/Z Policy Predictions Max     1097.66\n",
      "trainer/Z Policy Predictions Min     -467.224\n",
      "trainer/Z Expert Targets Mean        1014.86\n",
      "trainer/Z Expert Targets Std           44.9111\n",
      "trainer/Z Expert Targets Max         1097.1\n",
      "trainer/Z Expert Targets Min          689.141\n",
      "trainer/Z Policy Targets Mean         901.661\n",
      "trainer/Z Policy Targets Std          261.935\n",
      "trainer/Z Policy Targets Max         1058.84\n",
      "trainer/Z Policy Targets Min         -455.63\n",
      "trainer/Log Pis Mean                   33.2389\n",
      "trainer/Log Pis Std                     8.64119\n",
      "trainer/Policy mu Mean                  0.000419017\n",
      "trainer/Policy mu Std                   1.63817\n",
      "trainer/Policy log std Mean            -4.58538\n",
      "trainer/Policy log std Std              1.00428\n",
      "exploration/num steps total        265454\n",
      "exploration/num paths total           393\n",
      "evaluation/num steps total              2.2847e+06\n",
      "evaluation/num paths total           2654\n",
      "evaluation/path length Mean           901.9\n",
      "evaluation/path length Std            294.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             19\n",
      "evaluation/Rewards Mean                 4.68403\n",
      "evaluation/Rewards Std                  0.989331\n",
      "evaluation/Rewards Max                  6.84957\n",
      "evaluation/Rewards Min                 -2.12827\n",
      "evaluation/Returns Mean              4224.53\n",
      "evaluation/Returns Std               1398.34\n",
      "evaluation/Returns Max               4792.82\n",
      "evaluation/Returns Min                 32.8491\n",
      "evaluation/Estimation Bias Mean       951.04\n",
      "evaluation/Estimation Bias Std        151.046\n",
      "evaluation/EB/Q_True Mean              47.3954\n",
      "evaluation/EB/Q_True Std              137.84\n",
      "evaluation/EB/Q_Pred Mean             998.436\n",
      "evaluation/EB/Q_Pred Std               56.0604\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4224.53\n",
      "evaluation/Actions Mean                 0.0224666\n",
      "evaluation/Actions Std                  0.537132\n",
      "evaluation/Actions Max                  0.999805\n",
      "evaluation/Actions Min                 -0.999942\n",
      "time/backward_policy (s)                2.00932\n",
      "time/backward_zf1 (s)                   2.23177\n",
      "time/backward_zf2 (s)                   2.1136\n",
      "time/data sampling (s)                  0.324641\n",
      "time/data storing (s)                   0.0175017\n",
      "time/evaluation sampling (s)            1.75858\n",
      "time/exploration sampling (s)           0.358093\n",
      "time/logging (s)                        0.0114721\n",
      "time/preback_alpha (s)                  0.615947\n",
      "time/preback_policy (s)                 1.17342\n",
      "time/preback_start (s)                  0.159373\n",
      "time/preback_zf (s)                     5.21784\n",
      "time/saving (s)                         0.0061395\n",
      "time/training (s)                       2.30894\n",
      "time/epoch (s)                         18.3066\n",
      "time/total (s)                       4573.65\n",
      "Epoch                                 258\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:52:51.616037 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 259 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 270000\n",
      "trainer/ZF1 Loss                       -6.74214\n",
      "trainer/ZF2 Loss                       -5.53412\n",
      "trainer/ZF Expert Reward                9.98702\n",
      "trainer/ZF Policy Reward                0.733713\n",
      "trainer/ZF CHI2 Term                   35.7213\n",
      "trainer/Policy Loss                  -942.036\n",
      "trainer/Bias Loss                      59.5196\n",
      "trainer/Bias Value                     14.1312\n",
      "trainer/Policy Grad Norm              133.069\n",
      "trainer/Policy Param Norm              39.2732\n",
      "trainer/Zf1 Grad Norm                1473.51\n",
      "trainer/Zf1 Param Norm                123.626\n",
      "trainer/Zf2 Grad Norm                1197.59\n",
      "trainer/Zf2 Param Norm                126.3\n",
      "trainer/Z Expert Predictions Mean    1008.65\n",
      "trainer/Z Expert Predictions Std       86.3167\n",
      "trainer/Z Expert Predictions Max     1109.9\n",
      "trainer/Z Expert Predictions Min       12.6626\n",
      "trainer/Z Policy Predictions Mean     937.34\n",
      "trainer/Z Policy Predictions Std      200.254\n",
      "trainer/Z Policy Predictions Max     1099.09\n",
      "trainer/Z Policy Predictions Min     -464.147\n",
      "trainer/Z Expert Targets Mean         998.662\n",
      "trainer/Z Expert Targets Std           87.9486\n",
      "trainer/Z Expert Targets Max         1108.82\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         936.606\n",
      "trainer/Z Policy Targets Std          196.748\n",
      "trainer/Z Policy Targets Max         1087.78\n",
      "trainer/Z Policy Targets Min         -459.987\n",
      "trainer/Log Pis Mean                   32.9355\n",
      "trainer/Log Pis Std                     6.544\n",
      "trainer/Policy mu Mean                  0.0170441\n",
      "trainer/Policy mu Std                   1.33742\n",
      "trainer/Policy log std Mean            -4.72635\n",
      "trainer/Policy log std Std              0.916742\n",
      "exploration/num steps total        265454\n",
      "exploration/num paths total           393\n",
      "evaluation/num steps total              2.2947e+06\n",
      "evaluation/num paths total           2664\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6579\n",
      "evaluation/Rewards Std                  1.06813\n",
      "evaluation/Rewards Max                  6.93896\n",
      "evaluation/Rewards Min                 -3.17535\n",
      "evaluation/Returns Mean              4657.9\n",
      "evaluation/Returns Std                114.491\n",
      "evaluation/Returns Max               4865.77\n",
      "evaluation/Returns Min               4489.71\n",
      "evaluation/Estimation Bias Mean       940.781\n",
      "evaluation/Estimation Bias Std        150.626\n",
      "evaluation/EB/Q_True Mean              44.1282\n",
      "evaluation/EB/Q_True Std              136.069\n",
      "evaluation/EB/Q_Pred Mean             984.909\n",
      "evaluation/EB/Q_Pred Std               63.5029\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4657.9\n",
      "evaluation/Actions Mean                 0.0298108\n",
      "evaluation/Actions Std                  0.534595\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.93678\n",
      "time/backward_zf1 (s)                   2.13421\n",
      "time/backward_zf2 (s)                   2.01789\n",
      "time/data sampling (s)                  0.349603\n",
      "time/data storing (s)                   0.0154588\n",
      "time/evaluation sampling (s)            1.87094\n",
      "time/exploration sampling (s)           0.33264\n",
      "time/logging (s)                        0.012229\n",
      "time/preback_alpha (s)                  0.600647\n",
      "time/preback_policy (s)                 1.07865\n",
      "time/preback_start (s)                  0.153979\n",
      "time/preback_zf (s)                     5.14217\n",
      "time/saving (s)                         0.00650407\n",
      "time/training (s)                       2.37808\n",
      "time/epoch (s)                         18.0298\n",
      "time/total (s)                       4591.7\n",
      "Epoch                                 259\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 21:53:09.777141 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 260 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 271000\n",
      "trainer/ZF1 Loss                       -2.29308\n",
      "trainer/ZF2 Loss                       -6.90616\n",
      "trainer/ZF Expert Reward               11.6938\n",
      "trainer/ZF Policy Reward                0.115925\n",
      "trainer/ZF CHI2 Term                   39.3252\n",
      "trainer/Policy Loss                  -924.634\n",
      "trainer/Bias Loss                      54.7379\n",
      "trainer/Bias Value                     14.1618\n",
      "trainer/Policy Grad Norm              165.9\n",
      "trainer/Policy Param Norm              39.3011\n",
      "trainer/Zf1 Grad Norm                1429.49\n",
      "trainer/Zf1 Param Norm                123.776\n",
      "trainer/Zf2 Grad Norm                1289.84\n",
      "trainer/Zf2 Param Norm                126.459\n",
      "trainer/Z Expert Predictions Mean    1017.21\n",
      "trainer/Z Expert Predictions Std       57.2175\n",
      "trainer/Z Expert Predictions Max     1096.19\n",
      "trainer/Z Expert Predictions Min      677.171\n",
      "trainer/Z Policy Predictions Mean     919.999\n",
      "trainer/Z Policy Predictions Std      237.146\n",
      "trainer/Z Policy Predictions Max     1083.59\n",
      "trainer/Z Policy Predictions Min     -440.03\n",
      "trainer/Z Expert Targets Mean        1005.51\n",
      "trainer/Z Expert Targets Std           58.5262\n",
      "trainer/Z Expert Targets Max         1105.37\n",
      "trainer/Z Expert Targets Min          664.439\n",
      "trainer/Z Policy Targets Mean         919.883\n",
      "trainer/Z Policy Targets Std          235.872\n",
      "trainer/Z Policy Targets Max         1087.32\n",
      "trainer/Z Policy Targets Min         -452.168\n",
      "trainer/Log Pis Mean                   32.6737\n",
      "trainer/Log Pis Std                     6.14247\n",
      "trainer/Policy mu Mean                 -0.0118154\n",
      "trainer/Policy mu Std                   1.43866\n",
      "trainer/Policy log std Mean            -4.64576\n",
      "trainer/Policy log std Std              0.9243\n",
      "exploration/num steps total        265454\n",
      "exploration/num paths total           393\n",
      "evaluation/num steps total              2.30345e+06\n",
      "evaluation/num paths total           2675\n",
      "evaluation/path length Mean           795.818\n",
      "evaluation/path length Std            373.671\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             13\n",
      "evaluation/Rewards Mean                 4.66414\n",
      "evaluation/Rewards Std                  1.07633\n",
      "evaluation/Rewards Max                  6.75588\n",
      "evaluation/Rewards Min                 -2.12935\n",
      "evaluation/Returns Mean              3711.81\n",
      "evaluation/Returns Std               1791.53\n",
      "evaluation/Returns Max               4871.37\n",
      "evaluation/Returns Min                 -4.87814\n",
      "evaluation/Estimation Bias Mean       945.786\n",
      "evaluation/Estimation Bias Std        154.467\n",
      "evaluation/EB/Q_True Mean              47.426\n",
      "evaluation/EB/Q_True Std              136.037\n",
      "evaluation/EB/Q_Pred Mean             993.212\n",
      "evaluation/EB/Q_Pred Std               64.4108\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3711.81\n",
      "evaluation/Actions Mean                 0.0223412\n",
      "evaluation/Actions Std                  0.537801\n",
      "evaluation/Actions Max                  0.999975\n",
      "evaluation/Actions Min                 -0.999968\n",
      "time/backward_policy (s)                1.89868\n",
      "time/backward_zf1 (s)                   2.07311\n",
      "time/backward_zf2 (s)                   1.99107\n",
      "time/data sampling (s)                  0.337053\n",
      "time/data storing (s)                   0.0151686\n",
      "time/evaluation sampling (s)            1.89767\n",
      "time/exploration sampling (s)           0.329667\n",
      "time/logging (s)                        0.0103403\n",
      "time/preback_alpha (s)                  0.607801\n",
      "time/preback_policy (s)                 1.12713\n",
      "time/preback_start (s)                  0.15402\n",
      "time/preback_zf (s)                     5.23877\n",
      "time/saving (s)                         0.00634107\n",
      "time/training (s)                       2.39731\n",
      "time/epoch (s)                         18.0841\n",
      "time/total (s)                       4609.8\n",
      "Epoch                                 260\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:53:28.321773 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 261 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 272000\n",
      "trainer/ZF1 Loss                      180\n",
      "trainer/ZF2 Loss                      174.274\n",
      "trainer/ZF Expert Reward               14.1845\n",
      "trainer/ZF Policy Reward                6.41588\n",
      "trainer/ZF CHI2 Term                  218.127\n",
      "trainer/Policy Loss                  -902.097\n",
      "trainer/Bias Loss                      81.5192\n",
      "trainer/Bias Value                     14.1656\n",
      "trainer/Policy Grad Norm              118.853\n",
      "trainer/Policy Param Norm              39.3248\n",
      "trainer/Zf1 Grad Norm                1688.99\n",
      "trainer/Zf1 Param Norm                123.898\n",
      "trainer/Zf2 Grad Norm                1636.39\n",
      "trainer/Zf2 Param Norm                126.581\n",
      "trainer/Z Expert Predictions Mean    1020.71\n",
      "trainer/Z Expert Predictions Std       72.6524\n",
      "trainer/Z Expert Predictions Max     1114.58\n",
      "trainer/Z Expert Predictions Min       70.0796\n",
      "trainer/Z Policy Predictions Mean     897.572\n",
      "trainer/Z Policy Predictions Std      258.578\n",
      "trainer/Z Policy Predictions Max     1079.33\n",
      "trainer/Z Policy Predictions Min     -330.153\n",
      "trainer/Z Expert Targets Mean        1006.53\n",
      "trainer/Z Expert Targets Std           76.768\n",
      "trainer/Z Expert Targets Max         1100.2\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         891.156\n",
      "trainer/Z Policy Targets Std          261.603\n",
      "trainer/Z Policy Targets Max         1073.16\n",
      "trainer/Z Policy Targets Min         -337.199\n",
      "trainer/Log Pis Mean                   33.557\n",
      "trainer/Log Pis Std                     8.22222\n",
      "trainer/Policy mu Mean                 -0.00039739\n",
      "trainer/Policy mu Std                   1.67935\n",
      "trainer/Policy log std Mean            -4.59556\n",
      "trainer/Policy log std Std              1.01563\n",
      "exploration/num steps total        266454\n",
      "exploration/num paths total           394\n",
      "evaluation/num steps total              2.31154e+06\n",
      "evaluation/num paths total           2685\n",
      "evaluation/path length Mean           809.2\n",
      "evaluation/path length Std            381.659\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             31\n",
      "evaluation/Rewards Mean                 4.56659\n",
      "evaluation/Rewards Std                  1.0218\n",
      "evaluation/Rewards Max                  6.6183\n",
      "evaluation/Rewards Min                 -1.92772\n",
      "evaluation/Returns Mean              3695.28\n",
      "evaluation/Returns Std               1814.88\n",
      "evaluation/Returns Max               4706.99\n",
      "evaluation/Returns Min                 33.5995\n",
      "evaluation/Estimation Bias Mean       940.119\n",
      "evaluation/Estimation Bias Std        154.499\n",
      "evaluation/EB/Q_True Mean              51.6926\n",
      "evaluation/EB/Q_True Std              141.9\n",
      "evaluation/EB/Q_Pred Mean             991.811\n",
      "evaluation/EB/Q_Pred Std               54.8934\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3695.28\n",
      "evaluation/Actions Mean                 0.025781\n",
      "evaluation/Actions Std                  0.534464\n",
      "evaluation/Actions Max                  0.999863\n",
      "evaluation/Actions Min                 -0.999911\n",
      "time/backward_policy (s)                2.09689\n",
      "time/backward_zf1 (s)                   2.28399\n",
      "time/backward_zf2 (s)                   2.22626\n",
      "time/data sampling (s)                  0.312163\n",
      "time/data storing (s)                   0.0152641\n",
      "time/evaluation sampling (s)            1.80734\n",
      "time/exploration sampling (s)           0.337012\n",
      "time/logging (s)                        0.0105308\n",
      "time/preback_alpha (s)                  0.586339\n",
      "time/preback_policy (s)                 1.25056\n",
      "time/preback_start (s)                  0.149279\n",
      "time/preback_zf (s)                     5.22829\n",
      "time/saving (s)                         0.00604112\n",
      "time/training (s)                       2.16433\n",
      "time/epoch (s)                         18.4743\n",
      "time/total (s)                       4628.3\n",
      "Epoch                                 261\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:53:45.974549 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 262 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 273000\n",
      "trainer/ZF1 Loss                       -6.87939\n",
      "trainer/ZF2 Loss                       -2.28668\n",
      "trainer/ZF Expert Reward               16.2524\n",
      "trainer/ZF Policy Reward                4.13073\n",
      "trainer/ZF CHI2 Term                   40.84\n",
      "trainer/Policy Loss                  -893.268\n",
      "trainer/Bias Loss                      61.7862\n",
      "trainer/Bias Value                     14.1731\n",
      "trainer/Policy Grad Norm              142.592\n",
      "trainer/Policy Param Norm              39.3513\n",
      "trainer/Zf1 Grad Norm                1072.07\n",
      "trainer/Zf1 Param Norm                124.035\n",
      "trainer/Zf2 Grad Norm                1046.67\n",
      "trainer/Zf2 Param Norm                126.729\n",
      "trainer/Z Expert Predictions Mean    1024.36\n",
      "trainer/Z Expert Predictions Std       41.1827\n",
      "trainer/Z Expert Predictions Max     1103.05\n",
      "trainer/Z Expert Predictions Min      836.098\n",
      "trainer/Z Policy Predictions Mean     892.49\n",
      "trainer/Z Policy Predictions Std      275.009\n",
      "trainer/Z Policy Predictions Max     1092.7\n",
      "trainer/Z Policy Predictions Min     -398.033\n",
      "trainer/Z Expert Targets Mean        1008.1\n",
      "trainer/Z Expert Targets Std           43.1755\n",
      "trainer/Z Expert Targets Max         1096.37\n",
      "trainer/Z Expert Targets Min          803.742\n",
      "trainer/Z Policy Targets Mean         888.359\n",
      "trainer/Z Policy Targets Std          269.231\n",
      "trainer/Z Policy Targets Max         1056.22\n",
      "trainer/Z Policy Targets Min         -413.035\n",
      "trainer/Log Pis Mean                   33.6377\n",
      "trainer/Log Pis Std                     8.61883\n",
      "trainer/Policy mu Mean                 -0.0379981\n",
      "trainer/Policy mu Std                   1.76819\n",
      "trainer/Policy log std Mean            -4.59251\n",
      "trainer/Policy log std Std              1.04597\n",
      "exploration/num steps total        267454\n",
      "exploration/num paths total           395\n",
      "evaluation/num steps total              2.32056e+06\n",
      "evaluation/num paths total           2695\n",
      "evaluation/path length Mean           901.3\n",
      "evaluation/path length Std            296.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             13\n",
      "evaluation/Rewards Mean                 4.64682\n",
      "evaluation/Rewards Std                  0.960811\n",
      "evaluation/Rewards Max                  6.80188\n",
      "evaluation/Rewards Min                 -1.7876\n",
      "evaluation/Returns Mean              4188.18\n",
      "evaluation/Returns Std               1396.51\n",
      "evaluation/Returns Max               4830.83\n",
      "evaluation/Returns Min                  7.82067\n",
      "evaluation/Estimation Bias Mean       941.686\n",
      "evaluation/Estimation Bias Std        153.003\n",
      "evaluation/EB/Q_True Mean              48.1953\n",
      "evaluation/EB/Q_True Std              139.664\n",
      "evaluation/EB/Q_Pred Mean             989.882\n",
      "evaluation/EB/Q_Pred Std               53.5938\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4188.18\n",
      "evaluation/Actions Mean                 0.0157363\n",
      "evaluation/Actions Std                  0.531728\n",
      "evaluation/Actions Max                  0.999894\n",
      "evaluation/Actions Min                 -0.999763\n",
      "time/backward_policy (s)                1.88136\n",
      "time/backward_zf1 (s)                   2.04171\n",
      "time/backward_zf2 (s)                   1.96146\n",
      "time/data sampling (s)                  0.302441\n",
      "time/data storing (s)                   0.0149359\n",
      "time/evaluation sampling (s)            1.84318\n",
      "time/exploration sampling (s)           0.334701\n",
      "time/logging (s)                        0.0111545\n",
      "time/preback_alpha (s)                  0.580305\n",
      "time/preback_policy (s)                 1.1147\n",
      "time/preback_start (s)                  0.147276\n",
      "time/preback_zf (s)                     5.13946\n",
      "time/saving (s)                         0.00600591\n",
      "time/training (s)                       2.20566\n",
      "time/epoch (s)                         17.5844\n",
      "time/total (s)                       4645.9\n",
      "Epoch                                 262\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:54:02.638396 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 263 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 274000\n",
      "trainer/ZF1 Loss                      172.695\n",
      "trainer/ZF2 Loss                      189.139\n",
      "trainer/ZF Expert Reward               12.1185\n",
      "trainer/ZF Policy Reward                4.7682\n",
      "trainer/ZF CHI2 Term                  220.539\n",
      "trainer/Policy Loss                  -922.846\n",
      "trainer/Bias Loss                      57.6485\n",
      "trainer/Bias Value                     14.1887\n",
      "trainer/Policy Grad Norm              151.868\n",
      "trainer/Policy Param Norm              39.3771\n",
      "trainer/Zf1 Grad Norm                1951.34\n",
      "trainer/Zf1 Param Norm                124.175\n",
      "trainer/Zf2 Grad Norm                2337.77\n",
      "trainer/Zf2 Param Norm                126.851\n",
      "trainer/Z Expert Predictions Mean    1016.13\n",
      "trainer/Z Expert Predictions Std       44.5848\n",
      "trainer/Z Expert Predictions Max     1101.34\n",
      "trainer/Z Expert Predictions Min      770.337\n",
      "trainer/Z Policy Predictions Mean     920.988\n",
      "trainer/Z Policy Predictions Std      200.812\n",
      "trainer/Z Policy Predictions Max     1083.41\n",
      "trainer/Z Policy Predictions Min     -363.861\n",
      "trainer/Z Expert Targets Mean        1004.01\n",
      "trainer/Z Expert Targets Std           45.7015\n",
      "trainer/Z Expert Targets Max         1081.69\n",
      "trainer/Z Expert Targets Min          752.599\n",
      "trainer/Z Policy Targets Mean         916.22\n",
      "trainer/Z Policy Targets Std          203.581\n",
      "trainer/Z Policy Targets Max         1071.84\n",
      "trainer/Z Policy Targets Min         -347.358\n",
      "trainer/Log Pis Mean                   32.5977\n",
      "trainer/Log Pis Std                     6.27169\n",
      "trainer/Policy mu Mean                  0.0242884\n",
      "trainer/Policy mu Std                   1.32851\n",
      "trainer/Policy log std Mean            -4.6842\n",
      "trainer/Policy log std Std              0.862182\n",
      "exploration/num steps total        268454\n",
      "exploration/num paths total           396\n",
      "evaluation/num steps total              2.33056e+06\n",
      "evaluation/num paths total           2705\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.72291\n",
      "evaluation/Rewards Std                  0.958467\n",
      "evaluation/Rewards Max                  6.73637\n",
      "evaluation/Rewards Min                 -2.13669\n",
      "evaluation/Returns Mean              4722.91\n",
      "evaluation/Returns Std                 45.1991\n",
      "evaluation/Returns Max               4823.04\n",
      "evaluation/Returns Min               4648.73\n",
      "evaluation/Estimation Bias Mean       953.982\n",
      "evaluation/Estimation Bias Std        140.095\n",
      "evaluation/EB/Q_True Mean              43.0214\n",
      "evaluation/EB/Q_True Std              132.716\n",
      "evaluation/EB/Q_Pred Mean             997.004\n",
      "evaluation/EB/Q_Pred Std               49.2332\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4722.91\n",
      "evaluation/Actions Mean                 0.0261567\n",
      "evaluation/Actions Std                  0.537542\n",
      "evaluation/Actions Max                  0.999825\n",
      "evaluation/Actions Min                 -0.99998\n",
      "time/backward_policy (s)                1.61262\n",
      "time/backward_zf1 (s)                   1.7604\n",
      "time/backward_zf2 (s)                   1.65458\n",
      "time/data sampling (s)                  0.306185\n",
      "time/data storing (s)                   0.0138309\n",
      "time/evaluation sampling (s)            1.79246\n",
      "time/exploration sampling (s)           0.31346\n",
      "time/logging (s)                        0.0121385\n",
      "time/preback_alpha (s)                  0.560923\n",
      "time/preback_policy (s)                 0.901133\n",
      "time/preback_start (s)                  0.141958\n",
      "time/preback_zf (s)                     5.02109\n",
      "time/saving (s)                         0.00599573\n",
      "time/training (s)                       2.50094\n",
      "time/epoch (s)                         16.5977\n",
      "time/total (s)                       4662.52\n",
      "Epoch                                 263\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:54:21.177651 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 264 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 275000\n",
      "trainer/ZF1 Loss                       -9.24299\n",
      "trainer/ZF2 Loss                       -8.021\n",
      "trainer/ZF Expert Reward               17.0405\n",
      "trainer/ZF Policy Reward                4.02629\n",
      "trainer/ZF CHI2 Term                   37.169\n",
      "trainer/Policy Loss                  -916.483\n",
      "trainer/Bias Loss                      59.5772\n",
      "trainer/Bias Value                     14.1922\n",
      "trainer/Policy Grad Norm              124.969\n",
      "trainer/Policy Param Norm              39.4047\n",
      "trainer/Zf1 Grad Norm                 968.402\n",
      "trainer/Zf1 Param Norm                124.299\n",
      "trainer/Zf2 Grad Norm                1241.6\n",
      "trainer/Zf2 Param Norm                126.985\n",
      "trainer/Z Expert Predictions Mean    1021.22\n",
      "trainer/Z Expert Predictions Std       41.9116\n",
      "trainer/Z Expert Predictions Max     1100.94\n",
      "trainer/Z Expert Predictions Min      755.248\n",
      "trainer/Z Policy Predictions Mean     916.594\n",
      "trainer/Z Policy Predictions Std      218.909\n",
      "trainer/Z Policy Predictions Max     1064.91\n",
      "trainer/Z Policy Predictions Min     -381.994\n",
      "trainer/Z Expert Targets Mean        1004.18\n",
      "trainer/Z Expert Targets Std           42.5562\n",
      "trainer/Z Expert Targets Max         1088.37\n",
      "trainer/Z Expert Targets Min          742.81\n",
      "trainer/Z Policy Targets Mean         912.568\n",
      "trainer/Z Policy Targets Std          214.45\n",
      "trainer/Z Policy Targets Max         1074.06\n",
      "trainer/Z Policy Targets Min         -370.453\n",
      "trainer/Log Pis Mean                   33.118\n",
      "trainer/Log Pis Std                     7.63015\n",
      "trainer/Policy mu Mean                  0.0673004\n",
      "trainer/Policy mu Std                   1.46677\n",
      "trainer/Policy log std Mean            -4.7373\n",
      "trainer/Policy log std Std              0.909093\n",
      "exploration/num steps total        271454\n",
      "exploration/num paths total           399\n",
      "evaluation/num steps total              2.34056e+06\n",
      "evaluation/num paths total           2715\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70304\n",
      "evaluation/Rewards Std                  1.03101\n",
      "evaluation/Rewards Max                  6.91258\n",
      "evaluation/Rewards Min                 -1.97002\n",
      "evaluation/Returns Mean              4703.04\n",
      "evaluation/Returns Std                100.856\n",
      "evaluation/Returns Max               4873.08\n",
      "evaluation/Returns Min               4496.14\n",
      "evaluation/Estimation Bias Mean       942.107\n",
      "evaluation/Estimation Bias Std        152.059\n",
      "evaluation/EB/Q_True Mean              44.2915\n",
      "evaluation/EB/Q_True Std              136.681\n",
      "evaluation/EB/Q_Pred Mean             986.398\n",
      "evaluation/EB/Q_Pred Std               60.0673\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4703.04\n",
      "evaluation/Actions Mean                 0.0263019\n",
      "evaluation/Actions Std                  0.543683\n",
      "evaluation/Actions Max                  0.999944\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                2.05809\n",
      "time/backward_zf1 (s)                   2.27517\n",
      "time/backward_zf2 (s)                   2.12728\n",
      "time/data sampling (s)                  0.353132\n",
      "time/data storing (s)                   0.0152544\n",
      "time/evaluation sampling (s)            1.79452\n",
      "time/exploration sampling (s)           0.337801\n",
      "time/logging (s)                        0.0176867\n",
      "time/preback_alpha (s)                  0.619037\n",
      "time/preback_policy (s)                 1.15826\n",
      "time/preback_start (s)                  0.154039\n",
      "time/preback_zf (s)                     5.22384\n",
      "time/saving (s)                         0.0111512\n",
      "time/training (s)                       2.32656\n",
      "time/epoch (s)                         18.4718\n",
      "time/total (s)                       4681.01\n",
      "Epoch                                 264\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:54:39.242199 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 265 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 276000\n",
      "trainer/ZF1 Loss                        8.65233\n",
      "trainer/ZF2 Loss                       15.5132\n",
      "trainer/ZF Expert Reward               17.478\n",
      "trainer/ZF Policy Reward                9.10559\n",
      "trainer/ZF CHI2 Term                   53.0216\n",
      "trainer/Policy Loss                  -904.201\n",
      "trainer/Bias Loss                     175.607\n",
      "trainer/Bias Value                     14.1861\n",
      "trainer/Policy Grad Norm              154.423\n",
      "trainer/Policy Param Norm              39.4304\n",
      "trainer/Zf1 Grad Norm                1397.74\n",
      "trainer/Zf1 Param Norm                124.441\n",
      "trainer/Zf2 Grad Norm                1585.74\n",
      "trainer/Zf2 Param Norm                127.136\n",
      "trainer/Z Expert Predictions Mean    1014.96\n",
      "trainer/Z Expert Predictions Std       54.6593\n",
      "trainer/Z Expert Predictions Max     1108.04\n",
      "trainer/Z Expert Predictions Min      540.907\n",
      "trainer/Z Policy Predictions Mean     899.732\n",
      "trainer/Z Policy Predictions Std      232.338\n",
      "trainer/Z Policy Predictions Max     1076.38\n",
      "trainer/Z Policy Predictions Min     -386.77\n",
      "trainer/Z Expert Targets Mean         997.485\n",
      "trainer/Z Expert Targets Std           58.41\n",
      "trainer/Z Expert Targets Max         1093.1\n",
      "trainer/Z Expert Targets Min          535.242\n",
      "trainer/Z Policy Targets Mean         890.626\n",
      "trainer/Z Policy Targets Std          227.501\n",
      "trainer/Z Policy Targets Max         1056.97\n",
      "trainer/Z Policy Targets Min         -367.438\n",
      "trainer/Log Pis Mean                   32.8954\n",
      "trainer/Log Pis Std                     7.63187\n",
      "trainer/Policy mu Mean                  0.077806\n",
      "trainer/Policy mu Std                   1.6025\n",
      "trainer/Policy log std Mean            -4.56851\n",
      "trainer/Policy log std Std              1.04761\n",
      "exploration/num steps total        271454\n",
      "exploration/num paths total           399\n",
      "evaluation/num steps total              2.35056e+06\n",
      "evaluation/num paths total           2725\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66714\n",
      "evaluation/Rewards Std                  0.991938\n",
      "evaluation/Rewards Max                  6.65208\n",
      "evaluation/Rewards Min                 -1.74563\n",
      "evaluation/Returns Mean              4667.14\n",
      "evaluation/Returns Std                 74.5686\n",
      "evaluation/Returns Max               4788.22\n",
      "evaluation/Returns Min               4587.94\n",
      "evaluation/Estimation Bias Mean       938.667\n",
      "evaluation/Estimation Bias Std        139.909\n",
      "evaluation/EB/Q_True Mean              42.209\n",
      "evaluation/EB/Q_True Std              130.384\n",
      "evaluation/EB/Q_Pred Mean             980.876\n",
      "evaluation/EB/Q_Pred Std               53.6815\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4667.14\n",
      "evaluation/Actions Mean                 0.0308589\n",
      "evaluation/Actions Std                  0.53562\n",
      "evaluation/Actions Max                  0.99995\n",
      "evaluation/Actions Min                 -0.999949\n",
      "time/backward_policy (s)                1.96411\n",
      "time/backward_zf1 (s)                   2.12148\n",
      "time/backward_zf2 (s)                   2.04489\n",
      "time/data sampling (s)                  0.344772\n",
      "time/data storing (s)                   0.0162064\n",
      "time/evaluation sampling (s)            1.76651\n",
      "time/exploration sampling (s)           0.333232\n",
      "time/logging (s)                        0.0120624\n",
      "time/preback_alpha (s)                  0.598507\n",
      "time/preback_policy (s)                 1.13983\n",
      "time/preback_start (s)                  0.151404\n",
      "time/preback_zf (s)                     5.17744\n",
      "time/saving (s)                         0.00669531\n",
      "time/training (s)                       2.31065\n",
      "time/epoch (s)                         17.9878\n",
      "time/total (s)                       4699.02\n",
      "Epoch                                 265\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:54:58.167290 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 266 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 277000\n",
      "trainer/ZF1 Loss                      289.674\n",
      "trainer/ZF2 Loss                      329.471\n",
      "trainer/ZF Expert Reward               14.7404\n",
      "trainer/ZF Policy Reward               10.4233\n",
      "trainer/ZF CHI2 Term                  346.332\n",
      "trainer/Policy Loss                  -901.277\n",
      "trainer/Bias Loss                      49.9355\n",
      "trainer/Bias Value                     14.1817\n",
      "trainer/Policy Grad Norm              121.793\n",
      "trainer/Policy Param Norm              39.4534\n",
      "trainer/Zf1 Grad Norm                2292.84\n",
      "trainer/Zf1 Param Norm                124.578\n",
      "trainer/Zf2 Grad Norm                1880.31\n",
      "trainer/Zf2 Param Norm                127.28\n",
      "trainer/Z Expert Predictions Mean    1009.44\n",
      "trainer/Z Expert Predictions Std       47.9983\n",
      "trainer/Z Expert Predictions Max     1086.42\n",
      "trainer/Z Expert Predictions Min      755.128\n",
      "trainer/Z Policy Predictions Mean     901.88\n",
      "trainer/Z Policy Predictions Std      244.943\n",
      "trainer/Z Policy Predictions Max     1065.41\n",
      "trainer/Z Policy Predictions Min     -386.566\n",
      "trainer/Z Expert Targets Mean         994.698\n",
      "trainer/Z Expert Targets Std           50.6556\n",
      "trainer/Z Expert Targets Max         1073\n",
      "trainer/Z Expert Targets Min          727.855\n",
      "trainer/Z Policy Targets Mean         891.457\n",
      "trainer/Z Policy Targets Std          251.386\n",
      "trainer/Z Policy Targets Max         1057.98\n",
      "trainer/Z Policy Targets Min         -378.41\n",
      "trainer/Log Pis Mean                   32.7698\n",
      "trainer/Log Pis Std                     6.22275\n",
      "trainer/Policy mu Mean                  0.0557081\n",
      "trainer/Policy mu Std                   1.41933\n",
      "trainer/Policy log std Mean            -4.65271\n",
      "trainer/Policy log std Std              0.951087\n",
      "exploration/num steps total        271454\n",
      "exploration/num paths total           399\n",
      "evaluation/num steps total              2.36056e+06\n",
      "evaluation/num paths total           2735\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.56665\n",
      "evaluation/Rewards Std                  1.0579\n",
      "evaluation/Rewards Max                  6.79652\n",
      "evaluation/Rewards Min                 -1.86893\n",
      "evaluation/Returns Mean              4566.65\n",
      "evaluation/Returns Std                 77.1721\n",
      "evaluation/Returns Max               4679.45\n",
      "evaluation/Returns Min               4456.48\n",
      "evaluation/Estimation Bias Mean       937.543\n",
      "evaluation/Estimation Bias Std        147.276\n",
      "evaluation/EB/Q_True Mean              42.157\n",
      "evaluation/EB/Q_True Std              130.407\n",
      "evaluation/EB/Q_Pred Mean             979.7\n",
      "evaluation/EB/Q_Pred Std               60.2552\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4566.65\n",
      "evaluation/Actions Mean                 0.0221756\n",
      "evaluation/Actions Std                  0.538367\n",
      "evaluation/Actions Max                  0.999922\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.09012\n",
      "time/backward_zf1 (s)                   2.30708\n",
      "time/backward_zf2 (s)                   2.16318\n",
      "time/data sampling (s)                  0.358684\n",
      "time/data storing (s)                   0.0174884\n",
      "time/evaluation sampling (s)            1.71197\n",
      "time/exploration sampling (s)           0.350378\n",
      "time/logging (s)                        0.0120284\n",
      "time/preback_alpha (s)                  0.646759\n",
      "time/preback_policy (s)                 1.20174\n",
      "time/preback_start (s)                  0.161647\n",
      "time/preback_zf (s)                     5.35153\n",
      "time/saving (s)                         0.00610174\n",
      "time/training (s)                       2.47057\n",
      "time/epoch (s)                         18.8493\n",
      "time/total (s)                       4717.89\n",
      "Epoch                                 266\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:55:17.797025 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 267 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 278000\n",
      "trainer/ZF1 Loss                      171.488\n",
      "trainer/ZF2 Loss                      132.787\n",
      "trainer/ZF Expert Reward               17.8377\n",
      "trainer/ZF Policy Reward               10.6146\n",
      "trainer/ZF CHI2 Term                  192.188\n",
      "trainer/Policy Loss                  -914.79\n",
      "trainer/Bias Loss                      73.6307\n",
      "trainer/Bias Value                     14.1824\n",
      "trainer/Policy Grad Norm              138.647\n",
      "trainer/Policy Param Norm              39.4831\n",
      "trainer/Zf1 Grad Norm                1468.21\n",
      "trainer/Zf1 Param Norm                124.727\n",
      "trainer/Zf2 Grad Norm                2291.64\n",
      "trainer/Zf2 Param Norm                127.415\n",
      "trainer/Z Expert Predictions Mean    1002.77\n",
      "trainer/Z Expert Predictions Std       82.2546\n",
      "trainer/Z Expert Predictions Max     1082.59\n",
      "trainer/Z Expert Predictions Min       75.7587\n",
      "trainer/Z Policy Predictions Mean     914.953\n",
      "trainer/Z Policy Predictions Std      192.059\n",
      "trainer/Z Policy Predictions Max     1070.95\n",
      "trainer/Z Policy Predictions Min     -173.052\n",
      "trainer/Z Expert Targets Mean         984.928\n",
      "trainer/Z Expert Targets Std           85.6581\n",
      "trainer/Z Expert Targets Max         1070.54\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         904.338\n",
      "trainer/Z Policy Targets Std          195.073\n",
      "trainer/Z Policy Targets Max         1047.54\n",
      "trainer/Z Policy Targets Min         -231.042\n",
      "trainer/Log Pis Mean                   33.1593\n",
      "trainer/Log Pis Std                     7.6474\n",
      "trainer/Policy mu Mean                  0.0305161\n",
      "trainer/Policy mu Std                   1.50696\n",
      "trainer/Policy log std Mean            -4.74013\n",
      "trainer/Policy log std Std              0.840771\n",
      "exploration/num steps total        272454\n",
      "exploration/num paths total           400\n",
      "evaluation/num steps total              2.37056e+06\n",
      "evaluation/num paths total           2745\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.72424\n",
      "evaluation/Rewards Std                  1.01112\n",
      "evaluation/Rewards Max                  7.0096\n",
      "evaluation/Rewards Min                 -1.61026\n",
      "evaluation/Returns Mean              4724.24\n",
      "evaluation/Returns Std                 88.0364\n",
      "evaluation/Returns Max               4863.2\n",
      "evaluation/Returns Min               4598\n",
      "evaluation/Estimation Bias Mean       929.687\n",
      "evaluation/Estimation Bias Std        143.191\n",
      "evaluation/EB/Q_True Mean              43.8402\n",
      "evaluation/EB/Q_True Std              135.06\n",
      "evaluation/EB/Q_Pred Mean             973.527\n",
      "evaluation/EB/Q_Pred Std               55.6819\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4724.24\n",
      "evaluation/Actions Mean                 0.0235551\n",
      "evaluation/Actions Std                  0.537677\n",
      "evaluation/Actions Max                  0.999959\n",
      "evaluation/Actions Min                 -0.999989\n",
      "time/backward_policy (s)                2.30874\n",
      "time/backward_zf1 (s)                   2.50579\n",
      "time/backward_zf2 (s)                   2.35552\n",
      "time/data sampling (s)                  0.386843\n",
      "time/data storing (s)                   0.0161883\n",
      "time/evaluation sampling (s)            1.73473\n",
      "time/exploration sampling (s)           0.350301\n",
      "time/logging (s)                        0.0116909\n",
      "time/preback_alpha (s)                  0.657956\n",
      "time/preback_policy (s)                 1.2828\n",
      "time/preback_start (s)                  0.162805\n",
      "time/preback_zf (s)                     5.37578\n",
      "time/saving (s)                         0.00642388\n",
      "time/training (s)                       2.39372\n",
      "time/epoch (s)                         19.5493\n",
      "time/total (s)                       4737.46\n",
      "Epoch                                 267\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:55:36.994152 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 268 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 279000\n",
      "trainer/ZF1 Loss                       93.0284\n",
      "trainer/ZF2 Loss                       94.9767\n",
      "trainer/ZF Expert Reward                9.46831\n",
      "trainer/ZF Policy Reward                1.03207\n",
      "trainer/ZF CHI2 Term                  134.396\n",
      "trainer/Policy Loss                  -902.278\n",
      "trainer/Bias Loss                      68.9172\n",
      "trainer/Bias Value                     14.236\n",
      "trainer/Policy Grad Norm              159.447\n",
      "trainer/Policy Param Norm              39.5093\n",
      "trainer/Zf1 Grad Norm                2165.21\n",
      "trainer/Zf1 Param Norm                124.851\n",
      "trainer/Zf2 Grad Norm                1666.4\n",
      "trainer/Zf2 Param Norm                127.536\n",
      "trainer/Z Expert Predictions Mean     996.189\n",
      "trainer/Z Expert Predictions Std       52.5256\n",
      "trainer/Z Expert Predictions Max     1085.91\n",
      "trainer/Z Expert Predictions Min      652.236\n",
      "trainer/Z Policy Predictions Mean     896.38\n",
      "trainer/Z Policy Predictions Std      220.365\n",
      "trainer/Z Policy Predictions Max     1072.91\n",
      "trainer/Z Policy Predictions Min     -402.591\n",
      "trainer/Z Expert Targets Mean         986.72\n",
      "trainer/Z Expert Targets Std           55.2852\n",
      "trainer/Z Expert Targets Max         1082.69\n",
      "trainer/Z Expert Targets Min          639.398\n",
      "trainer/Z Policy Targets Mean         895.348\n",
      "trainer/Z Policy Targets Std          223.129\n",
      "trainer/Z Policy Targets Max         1062.17\n",
      "trainer/Z Policy Targets Min         -383.794\n",
      "trainer/Log Pis Mean                   32.2796\n",
      "trainer/Log Pis Std                     6.27211\n",
      "trainer/Policy mu Mean                  0.0482588\n",
      "trainer/Policy mu Std                   1.34041\n",
      "trainer/Policy log std Mean            -4.66385\n",
      "trainer/Policy log std Std              0.867931\n",
      "exploration/num steps total        275454\n",
      "exploration/num paths total           403\n",
      "evaluation/num steps total              2.38056e+06\n",
      "evaluation/num paths total           2755\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70815\n",
      "evaluation/Rewards Std                  0.984087\n",
      "evaluation/Rewards Max                  6.76313\n",
      "evaluation/Rewards Min                 -2.13003\n",
      "evaluation/Returns Mean              4708.15\n",
      "evaluation/Returns Std                 70.374\n",
      "evaluation/Returns Max               4851.15\n",
      "evaluation/Returns Min               4616.95\n",
      "evaluation/Estimation Bias Mean       936.34\n",
      "evaluation/Estimation Bias Std        141.379\n",
      "evaluation/EB/Q_True Mean              43.0965\n",
      "evaluation/EB/Q_True Std              132.817\n",
      "evaluation/EB/Q_Pred Mean             979.437\n",
      "evaluation/EB/Q_Pred Std               52.8371\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4708.15\n",
      "evaluation/Actions Mean                 0.0240827\n",
      "evaluation/Actions Std                  0.538271\n",
      "evaluation/Actions Max                  0.999536\n",
      "evaluation/Actions Min                 -0.999932\n",
      "time/backward_policy (s)                2.15762\n",
      "time/backward_zf1 (s)                   2.36146\n",
      "time/backward_zf2 (s)                   2.25813\n",
      "time/data sampling (s)                  0.358879\n",
      "time/data storing (s)                   0.0167602\n",
      "time/evaluation sampling (s)            1.80216\n",
      "time/exploration sampling (s)           0.348374\n",
      "time/logging (s)                        0.0123332\n",
      "time/preback_alpha (s)                  0.644179\n",
      "time/preback_policy (s)                 1.22946\n",
      "time/preback_start (s)                  0.162851\n",
      "time/preback_zf (s)                     5.3493\n",
      "time/saving (s)                         0.00677733\n",
      "time/training (s)                       2.41521\n",
      "time/epoch (s)                         19.1235\n",
      "time/total (s)                       4756.6\n",
      "Epoch                                 268\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:55:56.440801 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 269 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 280000\n",
      "trainer/ZF1 Loss                       -2.38017\n",
      "trainer/ZF2 Loss                       -5.06929\n",
      "trainer/ZF Expert Reward               13.8615\n",
      "trainer/ZF Policy Reward                4.18012\n",
      "trainer/ZF CHI2 Term                   38.0718\n",
      "trainer/Policy Loss                  -918.821\n",
      "trainer/Bias Loss                      45.0298\n",
      "trainer/Bias Value                     14.2852\n",
      "trainer/Policy Grad Norm              155.758\n",
      "trainer/Policy Param Norm              39.5379\n",
      "trainer/Zf1 Grad Norm                1014.1\n",
      "trainer/Zf1 Param Norm                125.002\n",
      "trainer/Zf2 Grad Norm                1085.22\n",
      "trainer/Zf2 Param Norm                127.674\n",
      "trainer/Z Expert Predictions Mean    1002.61\n",
      "trainer/Z Expert Predictions Std       46.9523\n",
      "trainer/Z Expert Predictions Max     1072.46\n",
      "trainer/Z Expert Predictions Min      665.09\n",
      "trainer/Z Policy Predictions Mean     913.749\n",
      "trainer/Z Policy Predictions Std      211.014\n",
      "trainer/Z Policy Predictions Max     1061.59\n",
      "trainer/Z Policy Predictions Min     -423.261\n",
      "trainer/Z Expert Targets Mean         988.748\n",
      "trainer/Z Expert Targets Std           48.1774\n",
      "trainer/Z Expert Targets Max         1062.5\n",
      "trainer/Z Expert Targets Min          638.383\n",
      "trainer/Z Policy Targets Mean         909.569\n",
      "trainer/Z Policy Targets Std          208.829\n",
      "trainer/Z Policy Targets Max         1043.27\n",
      "trainer/Z Policy Targets Min         -414.845\n",
      "trainer/Log Pis Mean                   32.4395\n",
      "trainer/Log Pis Std                     4.9712\n",
      "trainer/Policy mu Mean                  0.0866381\n",
      "trainer/Policy mu Std                   1.23167\n",
      "trainer/Policy log std Mean            -4.71768\n",
      "trainer/Policy log std Std              0.857257\n",
      "exploration/num steps total        275454\n",
      "exploration/num paths total           403\n",
      "evaluation/num steps total              2.39006e+06\n",
      "evaluation/num paths total           2765\n",
      "evaluation/path length Mean           950.2\n",
      "evaluation/path length Std            149.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            502\n",
      "evaluation/Rewards Mean                 4.67084\n",
      "evaluation/Rewards Std                  0.977375\n",
      "evaluation/Rewards Max                  6.74294\n",
      "evaluation/Rewards Min                 -2.12717\n",
      "evaluation/Returns Mean              4438.23\n",
      "evaluation/Returns Std                738.249\n",
      "evaluation/Returns Max               4782.57\n",
      "evaluation/Returns Min               2229.64\n",
      "evaluation/Estimation Bias Mean       936.666\n",
      "evaluation/Estimation Bias Std        150.423\n",
      "evaluation/EB/Q_True Mean              45.177\n",
      "evaluation/EB/Q_True Std              135.993\n",
      "evaluation/EB/Q_Pred Mean             981.843\n",
      "evaluation/EB/Q_Pred Std               55.7289\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4438.23\n",
      "evaluation/Actions Mean                 0.0237529\n",
      "evaluation/Actions Std                  0.538096\n",
      "evaluation/Actions Max                  0.999776\n",
      "evaluation/Actions Min                 -0.999945\n",
      "time/backward_policy (s)                2.17279\n",
      "time/backward_zf1 (s)                   2.4498\n",
      "time/backward_zf2 (s)                   2.32273\n",
      "time/data sampling (s)                  0.378904\n",
      "time/data storing (s)                   0.0168058\n",
      "time/evaluation sampling (s)            1.78754\n",
      "time/exploration sampling (s)           0.348453\n",
      "time/logging (s)                        0.0170324\n",
      "time/preback_alpha (s)                  0.655952\n",
      "time/preback_policy (s)                 1.2575\n",
      "time/preback_start (s)                  0.163532\n",
      "time/preback_zf (s)                     5.38856\n",
      "time/saving (s)                         0.0125535\n",
      "time/training (s)                       2.39974\n",
      "time/epoch (s)                         19.3719\n",
      "time/total (s)                       4775.99\n",
      "Epoch                                 269\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:56:15.651878 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 270 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 281000\n",
      "trainer/ZF1 Loss                       -0.0194016\n",
      "trainer/ZF2 Loss                        3.98862\n",
      "trainer/ZF Expert Reward               15.3912\n",
      "trainer/ZF Policy Reward                6.72232\n",
      "trainer/ZF CHI2 Term                   42.5471\n",
      "trainer/Policy Loss                  -914.846\n",
      "trainer/Bias Loss                      51.1308\n",
      "trainer/Bias Value                     14.2554\n",
      "trainer/Policy Grad Norm              165.896\n",
      "trainer/Policy Param Norm              39.5657\n",
      "trainer/Zf1 Grad Norm                1083.87\n",
      "trainer/Zf1 Param Norm                125.141\n",
      "trainer/Zf2 Grad Norm                 998.111\n",
      "trainer/Zf2 Param Norm                127.817\n",
      "trainer/Z Expert Predictions Mean     999.401\n",
      "trainer/Z Expert Predictions Std       44.3787\n",
      "trainer/Z Expert Predictions Max     1078.49\n",
      "trainer/Z Expert Predictions Min      665.796\n",
      "trainer/Z Policy Predictions Mean     912.833\n",
      "trainer/Z Policy Predictions Std      194.969\n",
      "trainer/Z Policy Predictions Max     1065.84\n",
      "trainer/Z Policy Predictions Min     -315.452\n",
      "trainer/Z Expert Targets Mean         984.01\n",
      "trainer/Z Expert Targets Std           46.3968\n",
      "trainer/Z Expert Targets Max         1074.84\n",
      "trainer/Z Expert Targets Min          639.978\n",
      "trainer/Z Policy Targets Mean         906.11\n",
      "trainer/Z Policy Targets Std          192.476\n",
      "trainer/Z Policy Targets Max         1054.54\n",
      "trainer/Z Policy Targets Min         -335.438\n",
      "trainer/Log Pis Mean                   32.2157\n",
      "trainer/Log Pis Std                     5.60441\n",
      "trainer/Policy mu Mean                  0.0306008\n",
      "trainer/Policy mu Std                   1.29014\n",
      "trainer/Policy log std Mean            -4.70439\n",
      "trainer/Policy log std Std              0.867121\n",
      "exploration/num steps total        275454\n",
      "exploration/num paths total           403\n",
      "evaluation/num steps total              2.39952e+06\n",
      "evaluation/num paths total           2775\n",
      "evaluation/path length Mean           946.3\n",
      "evaluation/path length Std            161.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            463\n",
      "evaluation/Rewards Mean                 3.87661\n",
      "evaluation/Rewards Std                  2.47758\n",
      "evaluation/Rewards Max                  7.0699\n",
      "evaluation/Rewards Min                 -3.68278\n",
      "evaluation/Returns Mean              3668.43\n",
      "evaluation/Returns Std               2248.33\n",
      "evaluation/Returns Max               4834.66\n",
      "evaluation/Returns Min              -2687.23\n",
      "evaluation/Estimation Bias Mean       877.819\n",
      "evaluation/Estimation Bias Std        194.664\n",
      "evaluation/EB/Q_True Mean              46.6084\n",
      "evaluation/EB/Q_True Std              140.01\n",
      "evaluation/EB/Q_Pred Mean             924.428\n",
      "evaluation/EB/Q_Pred Std              150.367\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3668.43\n",
      "evaluation/Actions Mean                 0.0419152\n",
      "evaluation/Actions Std                  0.592287\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.12044\n",
      "time/backward_zf1 (s)                   2.36697\n",
      "time/backward_zf2 (s)                   2.25285\n",
      "time/data sampling (s)                  0.379827\n",
      "time/data storing (s)                   0.0165842\n",
      "time/evaluation sampling (s)            1.72956\n",
      "time/exploration sampling (s)           0.350106\n",
      "time/logging (s)                        0.0113962\n",
      "time/preback_alpha (s)                  0.648144\n",
      "time/preback_policy (s)                 1.22923\n",
      "time/preback_start (s)                  0.16079\n",
      "time/preback_zf (s)                     5.39407\n",
      "time/saving (s)                         0.00624414\n",
      "time/training (s)                       2.46359\n",
      "time/epoch (s)                         19.1298\n",
      "time/total (s)                       4795.14\n",
      "Epoch                                 270\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:56:34.811179 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 271 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 282000\n",
      "trainer/ZF1 Loss                        5.08388\n",
      "trainer/ZF2 Loss                       -1.5368\n",
      "trainer/ZF Expert Reward               13.9659\n",
      "trainer/ZF Policy Reward                3.40144\n",
      "trainer/ZF CHI2 Term                   44.8786\n",
      "trainer/Policy Loss                  -890.162\n",
      "trainer/Bias Loss                      56.7603\n",
      "trainer/Bias Value                     14.2631\n",
      "trainer/Policy Grad Norm              190.607\n",
      "trainer/Policy Param Norm              39.5958\n",
      "trainer/Zf1 Grad Norm                3302.07\n",
      "trainer/Zf1 Param Norm                125.27\n",
      "trainer/Zf2 Grad Norm                2486.34\n",
      "trainer/Zf2 Param Norm                127.978\n",
      "trainer/Z Expert Predictions Mean     997.197\n",
      "trainer/Z Expert Predictions Std       48.1123\n",
      "trainer/Z Expert Predictions Max     1086.7\n",
      "trainer/Z Expert Predictions Min      749.505\n",
      "trainer/Z Policy Predictions Mean     884.619\n",
      "trainer/Z Policy Predictions Std      228.736\n",
      "trainer/Z Policy Predictions Max     1061.28\n",
      "trainer/Z Policy Predictions Min     -433.2\n",
      "trainer/Z Expert Targets Mean         983.231\n",
      "trainer/Z Expert Targets Std           50.1308\n",
      "trainer/Z Expert Targets Max         1076.65\n",
      "trainer/Z Expert Targets Min          727.04\n",
      "trainer/Z Policy Targets Mean         881.218\n",
      "trainer/Z Policy Targets Std          225.838\n",
      "trainer/Z Policy Targets Max         1054.56\n",
      "trainer/Z Policy Targets Min         -416.377\n",
      "trainer/Log Pis Mean                   32.8693\n",
      "trainer/Log Pis Std                     6.99359\n",
      "trainer/Policy mu Mean                  0.0578828\n",
      "trainer/Policy mu Std                   1.47573\n",
      "trainer/Policy log std Mean            -4.61599\n",
      "trainer/Policy log std Std              0.936963\n",
      "exploration/num steps total        276454\n",
      "exploration/num paths total           404\n",
      "evaluation/num steps total              2.40854e+06\n",
      "evaluation/num paths total           2785\n",
      "evaluation/path length Mean           901.7\n",
      "evaluation/path length Std            294.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             17\n",
      "evaluation/Rewards Mean                 4.53514\n",
      "evaluation/Rewards Std                  1.03088\n",
      "evaluation/Rewards Max                  6.58153\n",
      "evaluation/Rewards Min                 -3.7926\n",
      "evaluation/Returns Mean              4089.33\n",
      "evaluation/Returns Std               1363.89\n",
      "evaluation/Returns Max               4644.15\n",
      "evaluation/Returns Min                  0.956702\n",
      "evaluation/Estimation Bias Mean       913.324\n",
      "evaluation/Estimation Bias Std        148.104\n",
      "evaluation/EB/Q_True Mean              46.1767\n",
      "evaluation/EB/Q_True Std              134.521\n",
      "evaluation/EB/Q_Pred Mean             959.501\n",
      "evaluation/EB/Q_Pred Std               60.9263\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4089.33\n",
      "evaluation/Actions Mean                 0.02637\n",
      "evaluation/Actions Std                  0.532429\n",
      "evaluation/Actions Max                  0.99961\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                2.19493\n",
      "time/backward_zf1 (s)                   2.3855\n",
      "time/backward_zf2 (s)                   2.28187\n",
      "time/data sampling (s)                  0.370187\n",
      "time/data storing (s)                   0.016001\n",
      "time/evaluation sampling (s)            1.75658\n",
      "time/exploration sampling (s)           0.338882\n",
      "time/logging (s)                        0.011381\n",
      "time/preback_alpha (s)                  0.636787\n",
      "time/preback_policy (s)                 1.23902\n",
      "time/preback_start (s)                  0.15794\n",
      "time/preback_zf (s)                     5.33341\n",
      "time/saving (s)                         0.00603016\n",
      "time/training (s)                       2.35311\n",
      "time/epoch (s)                         19.0816\n",
      "time/total (s)                       4814.25\n",
      "Epoch                                 271\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:56:54.324910 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 272 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 283000\n",
      "trainer/ZF1 Loss                      187.977\n",
      "trainer/ZF2 Loss                      182.348\n",
      "trainer/ZF Expert Reward               11.2684\n",
      "trainer/ZF Policy Reward                1.02616\n",
      "trainer/ZF CHI2 Term                  227.913\n",
      "trainer/Policy Loss                  -867.561\n",
      "trainer/Bias Loss                      81.7559\n",
      "trainer/Bias Value                     14.2692\n",
      "trainer/Policy Grad Norm              172.478\n",
      "trainer/Policy Param Norm              39.6206\n",
      "trainer/Zf1 Grad Norm                2524.03\n",
      "trainer/Zf1 Param Norm                125.398\n",
      "trainer/Zf2 Grad Norm                3054.39\n",
      "trainer/Zf2 Param Norm                128.119\n",
      "trainer/Z Expert Predictions Mean     985.73\n",
      "trainer/Z Expert Predictions Std       76.1748\n",
      "trainer/Z Expert Predictions Max     1070.87\n",
      "trainer/Z Expert Predictions Min       33.0617\n",
      "trainer/Z Policy Predictions Mean     864.697\n",
      "trainer/Z Policy Predictions Std      252.628\n",
      "trainer/Z Policy Predictions Max     1058.17\n",
      "trainer/Z Policy Predictions Min     -407.62\n",
      "trainer/Z Expert Targets Mean         974.461\n",
      "trainer/Z Expert Targets Std           79.844\n",
      "trainer/Z Expert Targets Max         1063.09\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         863.671\n",
      "trainer/Z Policy Targets Std          256.595\n",
      "trainer/Z Policy Targets Max         1046.72\n",
      "trainer/Z Policy Targets Min         -381.609\n",
      "trainer/Log Pis Mean                   32.8369\n",
      "trainer/Log Pis Std                     6.78566\n",
      "trainer/Policy mu Mean                  0.0291759\n",
      "trainer/Policy mu Std                   1.56307\n",
      "trainer/Policy log std Mean            -4.55918\n",
      "trainer/Policy log std Std              1.03346\n",
      "exploration/num steps total        277454\n",
      "exploration/num paths total           405\n",
      "evaluation/num steps total              2.41854e+06\n",
      "evaluation/num paths total           2795\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.7058\n",
      "evaluation/Rewards Std                  1.00942\n",
      "evaluation/Rewards Max                  6.82344\n",
      "evaluation/Rewards Min                 -2.52878\n",
      "evaluation/Returns Mean              4705.8\n",
      "evaluation/Returns Std                 79.5024\n",
      "evaluation/Returns Max               4844.44\n",
      "evaluation/Returns Min               4611.09\n",
      "evaluation/Estimation Bias Mean       921.968\n",
      "evaluation/Estimation Bias Std        146.187\n",
      "evaluation/EB/Q_True Mean              43.67\n",
      "evaluation/EB/Q_True Std              134.769\n",
      "evaluation/EB/Q_Pred Mean             965.638\n",
      "evaluation/EB/Q_Pred Std               58.4985\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4705.8\n",
      "evaluation/Actions Mean                 0.021686\n",
      "evaluation/Actions Std                  0.540052\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -0.999939\n",
      "time/backward_policy (s)                2.21329\n",
      "time/backward_zf1 (s)                   2.46143\n",
      "time/backward_zf2 (s)                   2.32684\n",
      "time/data sampling (s)                  0.390653\n",
      "time/data storing (s)                   0.0181461\n",
      "time/evaluation sampling (s)            1.73569\n",
      "time/exploration sampling (s)           0.363861\n",
      "time/logging (s)                        0.0124177\n",
      "time/preback_alpha (s)                  0.659914\n",
      "time/preback_policy (s)                 1.24685\n",
      "time/preback_start (s)                  0.164725\n",
      "time/preback_zf (s)                     5.39286\n",
      "time/saving (s)                         0.00648392\n",
      "time/training (s)                       2.44245\n",
      "time/epoch (s)                         19.4356\n",
      "time/total (s)                       4833.7\n",
      "Epoch                                 272\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:57:14.002740 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 273 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 284000\n",
      "trainer/ZF1 Loss                       -3.79113\n",
      "trainer/ZF2 Loss                       -3.00513\n",
      "trainer/ZF Expert Reward               10.6599\n",
      "trainer/ZF Policy Reward               -2.60579\n",
      "trainer/ZF CHI2 Term                   42.0942\n",
      "trainer/Policy Loss                  -890.015\n",
      "trainer/Bias Loss                      57.4361\n",
      "trainer/Bias Value                     14.2839\n",
      "trainer/Policy Grad Norm              131.719\n",
      "trainer/Policy Param Norm              39.6455\n",
      "trainer/Zf1 Grad Norm                1945.81\n",
      "trainer/Zf1 Param Norm                125.529\n",
      "trainer/Zf2 Grad Norm                1417.84\n",
      "trainer/Zf2 Param Norm                128.258\n",
      "trainer/Z Expert Predictions Mean     989.53\n",
      "trainer/Z Expert Predictions Std       46.4612\n",
      "trainer/Z Expert Predictions Max     1069.94\n",
      "trainer/Z Expert Predictions Min      766.47\n",
      "trainer/Z Policy Predictions Mean     885.644\n",
      "trainer/Z Policy Predictions Std      219.875\n",
      "trainer/Z Policy Predictions Max     1031.11\n",
      "trainer/Z Policy Predictions Min     -271.335\n",
      "trainer/Z Expert Targets Mean         978.871\n",
      "trainer/Z Expert Targets Std           48.4857\n",
      "trainer/Z Expert Targets Max         1057.31\n",
      "trainer/Z Expert Targets Min          746.81\n",
      "trainer/Z Policy Targets Mean         888.25\n",
      "trainer/Z Policy Targets Std          215.465\n",
      "trainer/Z Policy Targets Max         1045.53\n",
      "trainer/Z Policy Targets Min         -233.278\n",
      "trainer/Log Pis Mean                   32.5522\n",
      "trainer/Log Pis Std                     5.9288\n",
      "trainer/Policy mu Mean                  0.0906776\n",
      "trainer/Policy mu Std                   1.46242\n",
      "trainer/Policy log std Mean            -4.651\n",
      "trainer/Policy log std Std              0.966292\n",
      "exploration/num steps total        279344\n",
      "exploration/num paths total           407\n",
      "evaluation/num steps total              2.42781e+06\n",
      "evaluation/num paths total           2806\n",
      "evaluation/path length Mean           842.727\n",
      "evaluation/path length Std            335.498\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             52\n",
      "evaluation/Rewards Mean                 4.72075\n",
      "evaluation/Rewards Std                  1.01568\n",
      "evaluation/Rewards Max                  6.69375\n",
      "evaluation/Rewards Min                 -2.65368\n",
      "evaluation/Returns Mean              3978.31\n",
      "evaluation/Returns Std               1620.93\n",
      "evaluation/Returns Max               4866.73\n",
      "evaluation/Returns Min                137.868\n",
      "evaluation/Estimation Bias Mean       917.336\n",
      "evaluation/Estimation Bias Std        156.449\n",
      "evaluation/EB/Q_True Mean              48.4063\n",
      "evaluation/EB/Q_True Std              142.853\n",
      "evaluation/EB/Q_Pred Mean             965.742\n",
      "evaluation/EB/Q_Pred Std               55.6578\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3978.31\n",
      "evaluation/Actions Mean                 0.0255627\n",
      "evaluation/Actions Std                  0.538566\n",
      "evaluation/Actions Max                  0.999886\n",
      "evaluation/Actions Min                 -0.99997\n",
      "time/backward_policy (s)                2.21572\n",
      "time/backward_zf1 (s)                   2.42142\n",
      "time/backward_zf2 (s)                   2.29835\n",
      "time/data sampling (s)                  0.389949\n",
      "time/data storing (s)                   0.0180115\n",
      "time/evaluation sampling (s)            1.76787\n",
      "time/exploration sampling (s)           0.354851\n",
      "time/logging (s)                        0.011467\n",
      "time/preback_alpha (s)                  0.680005\n",
      "time/preback_policy (s)                 1.28522\n",
      "time/preback_start (s)                  0.169006\n",
      "time/preback_zf (s)                     5.51565\n",
      "time/saving (s)                         0.00657333\n",
      "time/training (s)                       2.46334\n",
      "time/epoch (s)                         19.5974\n",
      "time/total (s)                       4853.32\n",
      "Epoch                                 273\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:57:33.223998 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 274 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 285000\n",
      "trainer/ZF1 Loss                      -13.3601\n",
      "trainer/ZF2 Loss                       -5.54145\n",
      "trainer/ZF Expert Reward               16.1972\n",
      "trainer/ZF Policy Reward                3.46724\n",
      "trainer/ZF CHI2 Term                   35.0948\n",
      "trainer/Policy Loss                  -907.437\n",
      "trainer/Bias Loss                      56.4955\n",
      "trainer/Bias Value                     14.2575\n",
      "trainer/Policy Grad Norm              143.976\n",
      "trainer/Policy Param Norm              39.6714\n",
      "trainer/Zf1 Grad Norm                 960.501\n",
      "trainer/Zf1 Param Norm                125.67\n",
      "trainer/Zf2 Grad Norm                1298.09\n",
      "trainer/Zf2 Param Norm                128.393\n",
      "trainer/Z Expert Predictions Mean     993.74\n",
      "trainer/Z Expert Predictions Std       40.4915\n",
      "trainer/Z Expert Predictions Max     1084.53\n",
      "trainer/Z Expert Predictions Min      732.275\n",
      "trainer/Z Policy Predictions Mean     905.59\n",
      "trainer/Z Policy Predictions Std      196.802\n",
      "trainer/Z Policy Predictions Max     1042.41\n",
      "trainer/Z Policy Predictions Min     -414.744\n",
      "trainer/Z Expert Targets Mean         977.543\n",
      "trainer/Z Expert Targets Std           42.2478\n",
      "trainer/Z Expert Targets Max         1058.75\n",
      "trainer/Z Expert Targets Min          722.297\n",
      "trainer/Z Policy Targets Mean         902.122\n",
      "trainer/Z Policy Targets Std          193.728\n",
      "trainer/Z Policy Targets Max         1053.61\n",
      "trainer/Z Policy Targets Min         -398.737\n",
      "trainer/Log Pis Mean                   32.1371\n",
      "trainer/Log Pis Std                     5.55817\n",
      "trainer/Policy mu Mean                  0.0355311\n",
      "trainer/Policy mu Std                   1.22218\n",
      "trainer/Policy log std Mean            -4.67895\n",
      "trainer/Policy log std Std              0.862925\n",
      "exploration/num steps total        281344\n",
      "exploration/num paths total           409\n",
      "evaluation/num steps total              2.43781e+06\n",
      "evaluation/num paths total           2816\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.63832\n",
      "evaluation/Rewards Std                  0.972631\n",
      "evaluation/Rewards Max                  6.84252\n",
      "evaluation/Rewards Min                 -2.57828\n",
      "evaluation/Returns Mean              4638.32\n",
      "evaluation/Returns Std                 99.1405\n",
      "evaluation/Returns Max               4793.29\n",
      "evaluation/Returns Min               4468.78\n",
      "evaluation/Estimation Bias Mean       915.875\n",
      "evaluation/Estimation Bias Std        149.309\n",
      "evaluation/EB/Q_True Mean              43.8903\n",
      "evaluation/EB/Q_True Std              135.347\n",
      "evaluation/EB/Q_Pred Mean             959.765\n",
      "evaluation/EB/Q_Pred Std               57.3309\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4638.32\n",
      "evaluation/Actions Mean                 0.025118\n",
      "evaluation/Actions Std                  0.538081\n",
      "evaluation/Actions Max                  0.999794\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.13234\n",
      "time/backward_zf1 (s)                   2.32626\n",
      "time/backward_zf2 (s)                   2.19821\n",
      "time/data sampling (s)                  0.395886\n",
      "time/data storing (s)                   0.016444\n",
      "time/evaluation sampling (s)            1.85456\n",
      "time/exploration sampling (s)           0.34747\n",
      "time/logging (s)                        0.0127743\n",
      "time/preback_alpha (s)                  0.646411\n",
      "time/preback_policy (s)                 1.20152\n",
      "time/preback_start (s)                  0.16233\n",
      "time/preback_zf (s)                     5.329\n",
      "time/saving (s)                         0.00693146\n",
      "time/training (s)                       2.51599\n",
      "time/epoch (s)                         19.1461\n",
      "time/total (s)                       4872.49\n",
      "Epoch                                 274\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:57:52.970564 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 275 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 286000\n",
      "trainer/ZF1 Loss                       -3.9334\n",
      "trainer/ZF2 Loss                        1.81403\n",
      "trainer/ZF Expert Reward               12.7163\n",
      "trainer/ZF Policy Reward                0.309656\n",
      "trainer/ZF CHI2 Term                   43.7776\n",
      "trainer/Policy Loss                  -914.563\n",
      "trainer/Bias Loss                      68.3292\n",
      "trainer/Bias Value                     14.2777\n",
      "trainer/Policy Grad Norm              136.354\n",
      "trainer/Policy Param Norm              39.6981\n",
      "trainer/Zf1 Grad Norm                1400.28\n",
      "trainer/Zf1 Param Norm                125.8\n",
      "trainer/Zf2 Grad Norm                1708.61\n",
      "trainer/Zf2 Param Norm                128.522\n",
      "trainer/Z Expert Predictions Mean     982.314\n",
      "trainer/Z Expert Predictions Std       45.5341\n",
      "trainer/Z Expert Predictions Max     1082.9\n",
      "trainer/Z Expert Predictions Min      739.094\n",
      "trainer/Z Policy Predictions Mean     912.19\n",
      "trainer/Z Policy Predictions Std      165.345\n",
      "trainer/Z Policy Predictions Max     1076.87\n",
      "trainer/Z Policy Predictions Min     -272.006\n",
      "trainer/Z Expert Targets Mean         969.597\n",
      "trainer/Z Expert Targets Std           47.9633\n",
      "trainer/Z Expert Targets Max         1069.22\n",
      "trainer/Z Expert Targets Min          724.068\n",
      "trainer/Z Policy Targets Mean         911.88\n",
      "trainer/Z Policy Targets Std          161.635\n",
      "trainer/Z Policy Targets Max         1065.49\n",
      "trainer/Z Policy Targets Min         -249.923\n",
      "trainer/Log Pis Mean                   32.7582\n",
      "trainer/Log Pis Std                     5.85501\n",
      "trainer/Policy mu Mean                  0.036848\n",
      "trainer/Policy mu Std                   1.19597\n",
      "trainer/Policy log std Mean            -4.79745\n",
      "trainer/Policy log std Std              0.823396\n",
      "exploration/num steps total        281344\n",
      "exploration/num paths total           409\n",
      "evaluation/num steps total              2.44781e+06\n",
      "evaluation/num paths total           2826\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.67505\n",
      "evaluation/Rewards Std                  0.987707\n",
      "evaluation/Rewards Max                  6.72198\n",
      "evaluation/Rewards Min                 -1.95699\n",
      "evaluation/Returns Mean              4675.05\n",
      "evaluation/Returns Std                 79.7633\n",
      "evaluation/Returns Max               4785.47\n",
      "evaluation/Returns Min               4547.36\n",
      "evaluation/Estimation Bias Mean       921.748\n",
      "evaluation/Estimation Bias Std        143.251\n",
      "evaluation/EB/Q_True Mean              43.7611\n",
      "evaluation/EB/Q_True Std              134.52\n",
      "evaluation/EB/Q_Pred Mean             965.509\n",
      "evaluation/EB/Q_Pred Std               53.4391\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4675.05\n",
      "evaluation/Actions Mean                 0.0269926\n",
      "evaluation/Actions Std                  0.540497\n",
      "evaluation/Actions Max                  0.999985\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                2.26637\n",
      "time/backward_zf1 (s)                   2.51386\n",
      "time/backward_zf2 (s)                   2.43666\n",
      "time/data sampling (s)                  0.392793\n",
      "time/data storing (s)                   0.0163761\n",
      "time/evaluation sampling (s)            1.7271\n",
      "time/exploration sampling (s)           0.347978\n",
      "time/logging (s)                        0.0116734\n",
      "time/preback_alpha (s)                  0.664662\n",
      "time/preback_policy (s)                 1.30788\n",
      "time/preback_start (s)                  0.163637\n",
      "time/preback_zf (s)                     5.41205\n",
      "time/saving (s)                         0.00632438\n",
      "time/training (s)                       2.39607\n",
      "time/epoch (s)                         19.6634\n",
      "time/total (s)                       4892.17\n",
      "Epoch                                 275\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:58:12.091530 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 276 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 287000\n",
      "trainer/ZF1 Loss                       -6.50433\n",
      "trainer/ZF2 Loss                       -2.02831\n",
      "trainer/ZF Expert Reward               13.2368\n",
      "trainer/ZF Policy Reward                3.94908\n",
      "trainer/ZF CHI2 Term                   37.5498\n",
      "trainer/Policy Loss                  -894.667\n",
      "trainer/Bias Loss                      51.9818\n",
      "trainer/Bias Value                     14.2862\n",
      "trainer/Policy Grad Norm              160.107\n",
      "trainer/Policy Param Norm              39.7241\n",
      "trainer/Zf1 Grad Norm                1138.07\n",
      "trainer/Zf1 Param Norm                125.941\n",
      "trainer/Zf2 Grad Norm                 977.439\n",
      "trainer/Zf2 Param Norm                128.656\n",
      "trainer/Z Expert Predictions Mean     985.201\n",
      "trainer/Z Expert Predictions Std       45.6061\n",
      "trainer/Z Expert Predictions Max     1080.56\n",
      "trainer/Z Expert Predictions Min      757.032\n",
      "trainer/Z Policy Predictions Mean     891.87\n",
      "trainer/Z Policy Predictions Std      193.292\n",
      "trainer/Z Policy Predictions Max     1044.51\n",
      "trainer/Z Policy Predictions Min     -381.108\n",
      "trainer/Z Expert Targets Mean         971.964\n",
      "trainer/Z Expert Targets Std           47.3388\n",
      "trainer/Z Expert Targets Max         1061.23\n",
      "trainer/Z Expert Targets Min          759.845\n",
      "trainer/Z Policy Targets Mean         887.921\n",
      "trainer/Z Policy Targets Std          187.66\n",
      "trainer/Z Policy Targets Max         1048.62\n",
      "trainer/Z Policy Targets Min         -366.425\n",
      "trainer/Log Pis Mean                   32.857\n",
      "trainer/Log Pis Std                     6.48654\n",
      "trainer/Policy mu Mean                  0.030346\n",
      "trainer/Policy mu Std                   1.28219\n",
      "trainer/Policy log std Mean            -4.75866\n",
      "trainer/Policy log std Std              0.819183\n",
      "exploration/num steps total        281344\n",
      "exploration/num paths total           409\n",
      "evaluation/num steps total              2.45781e+06\n",
      "evaluation/num paths total           2836\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65444\n",
      "evaluation/Rewards Std                  1.03877\n",
      "evaluation/Rewards Max                  6.82725\n",
      "evaluation/Rewards Min                 -2.30541\n",
      "evaluation/Returns Mean              4654.44\n",
      "evaluation/Returns Std                 76.2256\n",
      "evaluation/Returns Max               4816.75\n",
      "evaluation/Returns Min               4536.44\n",
      "evaluation/Estimation Bias Mean       925.643\n",
      "evaluation/Estimation Bias Std        147.75\n",
      "evaluation/EB/Q_True Mean              43.3957\n",
      "evaluation/EB/Q_True Std              133.596\n",
      "evaluation/EB/Q_Pred Mean             969.039\n",
      "evaluation/EB/Q_Pred Std               58.2754\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4654.44\n",
      "evaluation/Actions Mean                 0.0218905\n",
      "evaluation/Actions Std                  0.53942\n",
      "evaluation/Actions Max                  0.999683\n",
      "evaluation/Actions Min                 -0.999765\n",
      "time/backward_policy (s)                2.09665\n",
      "time/backward_zf1 (s)                   2.35807\n",
      "time/backward_zf2 (s)                   2.21494\n",
      "time/data sampling (s)                  0.36392\n",
      "time/data storing (s)                   0.0171942\n",
      "time/evaluation sampling (s)            1.71334\n",
      "time/exploration sampling (s)           0.362899\n",
      "time/logging (s)                        0.0121924\n",
      "time/preback_alpha (s)                  0.648852\n",
      "time/preback_policy (s)                 1.21173\n",
      "time/preback_start (s)                  0.161586\n",
      "time/preback_zf (s)                     5.37768\n",
      "time/saving (s)                         0.00607809\n",
      "time/training (s)                       2.50128\n",
      "time/epoch (s)                         19.0464\n",
      "time/total (s)                       4911.24\n",
      "Epoch                                 276\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:58:31.892344 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 277 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 288000\n",
      "trainer/ZF1 Loss                       -6.94299\n",
      "trainer/ZF2 Loss                       -9.46488\n",
      "trainer/ZF Expert Reward               14.1525\n",
      "trainer/ZF Policy Reward                4.30138\n",
      "trainer/ZF CHI2 Term                   33.717\n",
      "trainer/Policy Loss                  -904.509\n",
      "trainer/Bias Loss                      47.8065\n",
      "trainer/Bias Value                     14.2924\n",
      "trainer/Policy Grad Norm              191.534\n",
      "trainer/Policy Param Norm              39.7499\n",
      "trainer/Zf1 Grad Norm                1127.21\n",
      "trainer/Zf1 Param Norm                126.084\n",
      "trainer/Zf2 Grad Norm                1575.38\n",
      "trainer/Zf2 Param Norm                128.806\n",
      "trainer/Z Expert Predictions Mean     985.506\n",
      "trainer/Z Expert Predictions Std       38.7767\n",
      "trainer/Z Expert Predictions Max     1076.35\n",
      "trainer/Z Expert Predictions Min      799.463\n",
      "trainer/Z Policy Predictions Mean     904.26\n",
      "trainer/Z Policy Predictions Std      176.156\n",
      "trainer/Z Policy Predictions Max     1051.85\n",
      "trainer/Z Policy Predictions Min     -258.853\n",
      "trainer/Z Expert Targets Mean         971.354\n",
      "trainer/Z Expert Targets Std           40.991\n",
      "trainer/Z Expert Targets Max         1063.06\n",
      "trainer/Z Expert Targets Min          771.913\n",
      "trainer/Z Policy Targets Mean         899.959\n",
      "trainer/Z Policy Targets Std          173.88\n",
      "trainer/Z Policy Targets Max         1045.33\n",
      "trainer/Z Policy Targets Min         -252.52\n",
      "trainer/Log Pis Mean                   32.3938\n",
      "trainer/Log Pis Std                     6.08116\n",
      "trainer/Policy mu Mean                  0.00947095\n",
      "trainer/Policy mu Std                   1.35899\n",
      "trainer/Policy log std Mean            -4.70673\n",
      "trainer/Policy log std Std              0.873906\n",
      "exploration/num steps total        282344\n",
      "exploration/num paths total           410\n",
      "evaluation/num steps total              2.46781e+06\n",
      "evaluation/num paths total           2846\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.69798\n",
      "evaluation/Rewards Std                  0.968543\n",
      "evaluation/Rewards Max                  6.70199\n",
      "evaluation/Rewards Min                 -2.63087\n",
      "evaluation/Returns Mean              4697.98\n",
      "evaluation/Returns Std                 65.396\n",
      "evaluation/Returns Max               4785.7\n",
      "evaluation/Returns Min               4562.93\n",
      "evaluation/Estimation Bias Mean       920.754\n",
      "evaluation/Estimation Bias Std        141.358\n",
      "evaluation/EB/Q_True Mean              42.3196\n",
      "evaluation/EB/Q_True Std              130.06\n",
      "evaluation/EB/Q_Pred Mean             963.073\n",
      "evaluation/EB/Q_Pred Std               56.2404\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4697.98\n",
      "evaluation/Actions Mean                 0.0167725\n",
      "evaluation/Actions Std                  0.538487\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999964\n",
      "time/backward_policy (s)                2.2772\n",
      "time/backward_zf1 (s)                   2.55751\n",
      "time/backward_zf2 (s)                   2.42551\n",
      "time/data sampling (s)                  0.390021\n",
      "time/data storing (s)                   0.0161708\n",
      "time/evaluation sampling (s)            1.70618\n",
      "time/exploration sampling (s)           0.338439\n",
      "time/logging (s)                        0.0119129\n",
      "time/preback_alpha (s)                  0.65794\n",
      "time/preback_policy (s)                 1.30119\n",
      "time/preback_start (s)                  0.165781\n",
      "time/preback_zf (s)                     5.43864\n",
      "time/saving (s)                         0.00638626\n",
      "time/training (s)                       2.41292\n",
      "time/epoch (s)                         19.7058\n",
      "time/total (s)                       4930.98\n",
      "Epoch                                 277\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:58:51.216284 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 278 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 289000\n",
      "trainer/ZF1 Loss                       -2.47982\n",
      "trainer/ZF2 Loss                        7.11949\n",
      "trainer/ZF Expert Reward               14.2483\n",
      "trainer/ZF Policy Reward                3.09398\n",
      "trainer/ZF CHI2 Term                   45.6494\n",
      "trainer/Policy Loss                  -875.443\n",
      "trainer/Bias Loss                      60.4411\n",
      "trainer/Bias Value                     14.3092\n",
      "trainer/Policy Grad Norm              145.607\n",
      "trainer/Policy Param Norm              39.7733\n",
      "trainer/Zf1 Grad Norm                1138.78\n",
      "trainer/Zf1 Param Norm                126.215\n",
      "trainer/Zf2 Grad Norm                1483.43\n",
      "trainer/Zf2 Param Norm                128.94\n",
      "trainer/Z Expert Predictions Mean     978.655\n",
      "trainer/Z Expert Predictions Std       73.9496\n",
      "trainer/Z Expert Predictions Max     1058.68\n",
      "trainer/Z Expert Predictions Min       -5.09415\n",
      "trainer/Z Policy Predictions Mean     874.718\n",
      "trainer/Z Policy Predictions Std      205.247\n",
      "trainer/Z Policy Predictions Max     1056.85\n",
      "trainer/Z Policy Predictions Min     -395.456\n",
      "trainer/Z Expert Targets Mean         964.406\n",
      "trainer/Z Expert Targets Std           75.1681\n",
      "trainer/Z Expert Targets Max         1051.78\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         871.625\n",
      "trainer/Z Policy Targets Std          201.067\n",
      "trainer/Z Policy Targets Max         1038.17\n",
      "trainer/Z Policy Targets Min         -380.368\n",
      "trainer/Log Pis Mean                   32.5003\n",
      "trainer/Log Pis Std                     5.35212\n",
      "trainer/Policy mu Mean                  0.0633333\n",
      "trainer/Policy mu Std                   1.25017\n",
      "trainer/Policy log std Mean            -4.68451\n",
      "trainer/Policy log std Std              0.912466\n",
      "exploration/num steps total        285344\n",
      "exploration/num paths total           413\n",
      "evaluation/num steps total              2.47781e+06\n",
      "evaluation/num paths total           2856\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.65105\n",
      "evaluation/Rewards Std                  1.16931\n",
      "evaluation/Rewards Max                  7.01881\n",
      "evaluation/Rewards Min                 -3.5525\n",
      "evaluation/Returns Mean              4651.05\n",
      "evaluation/Returns Std                160.155\n",
      "evaluation/Returns Max               4894.32\n",
      "evaluation/Returns Min               4392.61\n",
      "evaluation/Estimation Bias Mean       898.929\n",
      "evaluation/Estimation Bias Std        172.872\n",
      "evaluation/EB/Q_True Mean              44.9234\n",
      "evaluation/EB/Q_True Std              138.381\n",
      "evaluation/EB/Q_Pred Mean             943.852\n",
      "evaluation/EB/Q_Pred Std              110.219\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4651.05\n",
      "evaluation/Actions Mean                 0.0210727\n",
      "evaluation/Actions Std                  0.542259\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                2.18531\n",
      "time/backward_zf1 (s)                   2.41269\n",
      "time/backward_zf2 (s)                   2.27347\n",
      "time/data sampling (s)                  0.35471\n",
      "time/data storing (s)                   0.015319\n",
      "time/evaluation sampling (s)            1.79149\n",
      "time/exploration sampling (s)           0.348218\n",
      "time/logging (s)                        0.0136372\n",
      "time/preback_alpha (s)                  0.643159\n",
      "time/preback_policy (s)                 1.21561\n",
      "time/preback_start (s)                  0.163547\n",
      "time/preback_zf (s)                     5.34779\n",
      "time/saving (s)                         0.00646885\n",
      "time/training (s)                       2.47715\n",
      "time/epoch (s)                         19.2486\n",
      "time/total (s)                       4950.25\n",
      "Epoch                                 278\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:59:10.578838 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 279 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 290000\n",
      "trainer/ZF1 Loss                       -2.01352\n",
      "trainer/ZF2 Loss                       -2.32563\n",
      "trainer/ZF Expert Reward               14.1078\n",
      "trainer/ZF Policy Reward                3.2567\n",
      "trainer/ZF CHI2 Term                   41.0613\n",
      "trainer/Policy Loss                  -885.847\n",
      "trainer/Bias Loss                      62.3598\n",
      "trainer/Bias Value                     14.3007\n",
      "trainer/Policy Grad Norm              147.249\n",
      "trainer/Policy Param Norm              39.8041\n",
      "trainer/Zf1 Grad Norm                 964.909\n",
      "trainer/Zf1 Param Norm                126.36\n",
      "trainer/Zf2 Grad Norm                1343.39\n",
      "trainer/Zf2 Param Norm                129.094\n",
      "trainer/Z Expert Predictions Mean     982.594\n",
      "trainer/Z Expert Predictions Std       47.2197\n",
      "trainer/Z Expert Predictions Max     1064.97\n",
      "trainer/Z Expert Predictions Min      755.096\n",
      "trainer/Z Policy Predictions Mean     883.819\n",
      "trainer/Z Policy Predictions Std      220.659\n",
      "trainer/Z Policy Predictions Max     1037.61\n",
      "trainer/Z Policy Predictions Min     -365.354\n",
      "trainer/Z Expert Targets Mean         968.486\n",
      "trainer/Z Expert Targets Std           49.1279\n",
      "trainer/Z Expert Targets Max         1061.7\n",
      "trainer/Z Expert Targets Min          726.665\n",
      "trainer/Z Policy Targets Mean         880.562\n",
      "trainer/Z Policy Targets Std          217.361\n",
      "trainer/Z Policy Targets Max         1037.97\n",
      "trainer/Z Policy Targets Min         -352.047\n",
      "trainer/Log Pis Mean                   32.7069\n",
      "trainer/Log Pis Std                     6.38791\n",
      "trainer/Policy mu Mean                  0.0125587\n",
      "trainer/Policy mu Std                   1.45894\n",
      "trainer/Policy log std Mean            -4.70106\n",
      "trainer/Policy log std Std              0.946173\n",
      "exploration/num steps total        285344\n",
      "exploration/num paths total           413\n",
      "evaluation/num steps total              2.48781e+06\n",
      "evaluation/num paths total           2866\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.47928\n",
      "evaluation/Rewards Std                  1.62894\n",
      "evaluation/Rewards Max                  6.83081\n",
      "evaluation/Rewards Min                 -3.32784\n",
      "evaluation/Returns Mean              4479.28\n",
      "evaluation/Returns Std                788.337\n",
      "evaluation/Returns Max               4893.58\n",
      "evaluation/Returns Min               2129.32\n",
      "evaluation/Estimation Bias Mean       893.825\n",
      "evaluation/Estimation Bias Std        164.636\n",
      "evaluation/EB/Q_True Mean              43.4759\n",
      "evaluation/EB/Q_True Std              134.52\n",
      "evaluation/EB/Q_Pred Mean             937.301\n",
      "evaluation/EB/Q_Pred Std              103.869\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4479.28\n",
      "evaluation/Actions Mean                 0.0355751\n",
      "evaluation/Actions Std                  0.556271\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999982\n",
      "time/backward_policy (s)                2.16751\n",
      "time/backward_zf1 (s)                   2.40943\n",
      "time/backward_zf2 (s)                   2.27855\n",
      "time/data sampling (s)                  0.375382\n",
      "time/data storing (s)                   0.0179385\n",
      "time/evaluation sampling (s)            1.75242\n",
      "time/exploration sampling (s)           0.354603\n",
      "time/logging (s)                        0.0119762\n",
      "time/preback_alpha (s)                  0.651778\n",
      "time/preback_policy (s)                 1.22246\n",
      "time/preback_start (s)                  0.168274\n",
      "time/preback_zf (s)                     5.42565\n",
      "time/saving (s)                         0.00655308\n",
      "time/training (s)                       2.43165\n",
      "time/epoch (s)                         19.2742\n",
      "time/total (s)                       4969.55\n",
      "Epoch                                 279\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:59:29.212346 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 280 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 291000\n",
      "trainer/ZF1 Loss                       -1.36821\n",
      "trainer/ZF2 Loss                        6.22278\n",
      "trainer/ZF Expert Reward                9.92215\n",
      "trainer/ZF Policy Reward                0.0384815\n",
      "trainer/ZF CHI2 Term                   44.4223\n",
      "trainer/Policy Loss                  -859.776\n",
      "trainer/Bias Loss                      58.0234\n",
      "trainer/Bias Value                     14.2815\n",
      "trainer/Policy Grad Norm              146.573\n",
      "trainer/Policy Param Norm              39.8322\n",
      "trainer/Zf1 Grad Norm                1620.99\n",
      "trainer/Zf1 Param Norm                126.504\n",
      "trainer/Zf2 Grad Norm                1711.29\n",
      "trainer/Zf2 Param Norm                129.217\n",
      "trainer/Z Expert Predictions Mean     973.29\n",
      "trainer/Z Expert Predictions Std       76.8841\n",
      "trainer/Z Expert Predictions Max     1075\n",
      "trainer/Z Expert Predictions Min        9.39506\n",
      "trainer/Z Policy Predictions Mean     855.537\n",
      "trainer/Z Policy Predictions Std      247.232\n",
      "trainer/Z Policy Predictions Max     1033.55\n",
      "trainer/Z Policy Predictions Min     -355.68\n",
      "trainer/Z Expert Targets Mean         963.367\n",
      "trainer/Z Expert Targets Std           76.9805\n",
      "trainer/Z Expert Targets Max         1048.28\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         855.498\n",
      "trainer/Z Policy Targets Std          242.047\n",
      "trainer/Z Policy Targets Max         1027.44\n",
      "trainer/Z Policy Targets Min         -345.9\n",
      "trainer/Log Pis Mean                   32.4357\n",
      "trainer/Log Pis Std                     6.02238\n",
      "trainer/Policy mu Mean                  0.0569641\n",
      "trainer/Policy mu Std                   1.53071\n",
      "trainer/Policy log std Mean            -4.61151\n",
      "trainer/Policy log std Std              0.975091\n",
      "exploration/num steps total        285344\n",
      "exploration/num paths total           413\n",
      "evaluation/num steps total              2.49781e+06\n",
      "evaluation/num paths total           2876\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.60536\n",
      "evaluation/Rewards Std                  1.15199\n",
      "evaluation/Rewards Max                  6.92335\n",
      "evaluation/Rewards Min                 -2.82742\n",
      "evaluation/Returns Mean              4605.36\n",
      "evaluation/Returns Std                138.752\n",
      "evaluation/Returns Max               4745.93\n",
      "evaluation/Returns Min               4321.48\n",
      "evaluation/Estimation Bias Mean       903.071\n",
      "evaluation/Estimation Bias Std        149.982\n",
      "evaluation/EB/Q_True Mean              43.7708\n",
      "evaluation/EB/Q_True Std              134.223\n",
      "evaluation/EB/Q_Pred Mean             946.841\n",
      "evaluation/EB/Q_Pred Std               69.276\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4605.36\n",
      "evaluation/Actions Mean                 0.0172683\n",
      "evaluation/Actions Std                  0.540508\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                2.0699\n",
      "time/backward_zf1 (s)                   2.28704\n",
      "time/backward_zf2 (s)                   2.14603\n",
      "time/data sampling (s)                  0.363119\n",
      "time/data storing (s)                   0.015059\n",
      "time/evaluation sampling (s)            1.7727\n",
      "time/exploration sampling (s)           0.326544\n",
      "time/logging (s)                        0.011673\n",
      "time/preback_alpha (s)                  0.631492\n",
      "time/preback_policy (s)                 1.17031\n",
      "time/preback_start (s)                  0.156861\n",
      "time/preback_zf (s)                     5.25201\n",
      "time/saving (s)                         0.00620923\n",
      "time/training (s)                       2.34596\n",
      "time/epoch (s)                         18.5549\n",
      "time/total (s)                       4988.13\n",
      "Epoch                                 280\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 21:59:48.765307 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 281 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 292000\n",
      "trainer/ZF1 Loss                       -7.57393\n",
      "trainer/ZF2 Loss                       -1.79033\n",
      "trainer/ZF Expert Reward               14.8642\n",
      "trainer/ZF Policy Reward                3.72644\n",
      "trainer/ZF CHI2 Term                   38.9096\n",
      "trainer/Policy Loss                  -892.521\n",
      "trainer/Bias Loss                      40.335\n",
      "trainer/Bias Value                     14.3006\n",
      "trainer/Policy Grad Norm              143.477\n",
      "trainer/Policy Param Norm              39.8583\n",
      "trainer/Zf1 Grad Norm                1083\n",
      "trainer/Zf1 Param Norm                126.637\n",
      "trainer/Zf2 Grad Norm                1124.16\n",
      "trainer/Zf2 Param Norm                129.353\n",
      "trainer/Z Expert Predictions Mean     976.854\n",
      "trainer/Z Expert Predictions Std       44.5044\n",
      "trainer/Z Expert Predictions Max     1076.78\n",
      "trainer/Z Expert Predictions Min      735.562\n",
      "trainer/Z Policy Predictions Mean     889.809\n",
      "trainer/Z Policy Predictions Std      191.716\n",
      "trainer/Z Policy Predictions Max     1033.62\n",
      "trainer/Z Policy Predictions Min     -390.898\n",
      "trainer/Z Expert Targets Mean         961.99\n",
      "trainer/Z Expert Targets Std           46.4254\n",
      "trainer/Z Expert Targets Max         1059.5\n",
      "trainer/Z Expert Targets Min          702.14\n",
      "trainer/Z Policy Targets Mean         886.083\n",
      "trainer/Z Policy Targets Std          188.444\n",
      "trainer/Z Policy Targets Max         1036.42\n",
      "trainer/Z Policy Targets Min         -381.169\n",
      "trainer/Log Pis Mean                   32.7817\n",
      "trainer/Log Pis Std                     4.42696\n",
      "trainer/Policy mu Mean                  0.00959783\n",
      "trainer/Policy mu Std                   1.20183\n",
      "trainer/Policy log std Mean            -4.80601\n",
      "trainer/Policy log std Std              0.852777\n",
      "exploration/num steps total        286344\n",
      "exploration/num paths total           414\n",
      "evaluation/num steps total              2.50684e+06\n",
      "evaluation/num paths total           2886\n",
      "evaluation/path length Mean           902.7\n",
      "evaluation/path length Std            291.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             27\n",
      "evaluation/Rewards Mean                 4.60095\n",
      "evaluation/Rewards Std                  1.12455\n",
      "evaluation/Rewards Max                  6.61241\n",
      "evaluation/Rewards Min                 -3.05575\n",
      "evaluation/Returns Mean              4153.28\n",
      "evaluation/Returns Std               1395.32\n",
      "evaluation/Returns Max               4854.87\n",
      "evaluation/Returns Min                 -7.53178\n",
      "evaluation/Estimation Bias Mean       894.997\n",
      "evaluation/Estimation Bias Std        159.537\n",
      "evaluation/EB/Q_True Mean              47.7471\n",
      "evaluation/EB/Q_True Std              139.309\n",
      "evaluation/EB/Q_Pred Mean             942.744\n",
      "evaluation/EB/Q_Pred Std               72.71\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4153.28\n",
      "evaluation/Actions Mean                 0.0251578\n",
      "evaluation/Actions Std                  0.538141\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.20716\n",
      "time/backward_zf1 (s)                   2.46993\n",
      "time/backward_zf2 (s)                   2.32832\n",
      "time/data sampling (s)                  0.339913\n",
      "time/data storing (s)                   0.0188594\n",
      "time/evaluation sampling (s)            1.77104\n",
      "time/exploration sampling (s)           0.374137\n",
      "time/logging (s)                        0.0118892\n",
      "time/preback_alpha (s)                  0.655136\n",
      "time/preback_policy (s)                 1.26214\n",
      "time/preback_start (s)                  0.166308\n",
      "time/preback_zf (s)                     5.39797\n",
      "time/saving (s)                         0.00659487\n",
      "time/training (s)                       2.46893\n",
      "time/epoch (s)                         19.4783\n",
      "time/total (s)                       5007.62\n",
      "Epoch                                 281\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:00:08.036539 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 282 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 293000\n",
      "trainer/ZF1 Loss                        8.75554\n",
      "trainer/ZF2 Loss                        0.984978\n",
      "trainer/ZF Expert Reward               14.0527\n",
      "trainer/ZF Policy Reward                3.30892\n",
      "trainer/ZF CHI2 Term                   47.7881\n",
      "trainer/Policy Loss                  -884.586\n",
      "trainer/Bias Loss                      60.5061\n",
      "trainer/Bias Value                     14.3236\n",
      "trainer/Policy Grad Norm              162.031\n",
      "trainer/Policy Param Norm              39.8849\n",
      "trainer/Zf1 Grad Norm                1760.85\n",
      "trainer/Zf1 Param Norm                126.765\n",
      "trainer/Zf2 Grad Norm                1131.25\n",
      "trainer/Zf2 Param Norm                129.504\n",
      "trainer/Z Expert Predictions Mean     969.217\n",
      "trainer/Z Expert Predictions Std       48.8399\n",
      "trainer/Z Expert Predictions Max     1050.08\n",
      "trainer/Z Expert Predictions Min      696.45\n",
      "trainer/Z Policy Predictions Mean     882.373\n",
      "trainer/Z Policy Predictions Std      191.508\n",
      "trainer/Z Policy Predictions Max     1030.29\n",
      "trainer/Z Policy Predictions Min     -350.616\n",
      "trainer/Z Expert Targets Mean         955.164\n",
      "trainer/Z Expert Targets Std           49.8042\n",
      "trainer/Z Expert Targets Max         1040.12\n",
      "trainer/Z Expert Targets Min          681.529\n",
      "trainer/Z Policy Targets Mean         879.064\n",
      "trainer/Z Policy Targets Std          188.87\n",
      "trainer/Z Policy Targets Max         1024.33\n",
      "trainer/Z Policy Targets Min         -335.175\n",
      "trainer/Log Pis Mean                   32.4991\n",
      "trainer/Log Pis Std                     5.85406\n",
      "trainer/Policy mu Mean                  0.0337534\n",
      "trainer/Policy mu Std                   1.36667\n",
      "trainer/Policy log std Mean            -4.70756\n",
      "trainer/Policy log std Std              0.904564\n",
      "exploration/num steps total        287344\n",
      "exploration/num paths total           415\n",
      "evaluation/num steps total              2.51684e+06\n",
      "evaluation/num paths total           2896\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6559\n",
      "evaluation/Rewards Std                  0.927999\n",
      "evaluation/Rewards Max                  6.81702\n",
      "evaluation/Rewards Min                 -1.87303\n",
      "evaluation/Returns Mean              4655.9\n",
      "evaluation/Returns Std                 58.4214\n",
      "evaluation/Returns Max               4757.71\n",
      "evaluation/Returns Min               4581.41\n",
      "evaluation/Estimation Bias Mean       904.805\n",
      "evaluation/Estimation Bias Std        142.495\n",
      "evaluation/EB/Q_True Mean              42.7488\n",
      "evaluation/EB/Q_True Std              131.924\n",
      "evaluation/EB/Q_Pred Mean             947.554\n",
      "evaluation/EB/Q_Pred Std               47.1876\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4655.9\n",
      "evaluation/Actions Mean                 0.025724\n",
      "evaluation/Actions Std                  0.531038\n",
      "evaluation/Actions Max                  0.999875\n",
      "evaluation/Actions Min                 -0.999971\n",
      "time/backward_policy (s)                2.19452\n",
      "time/backward_zf1 (s)                   2.4498\n",
      "time/backward_zf2 (s)                   2.29882\n",
      "time/data sampling (s)                  0.379497\n",
      "time/data storing (s)                   0.0152252\n",
      "time/evaluation sampling (s)            1.71901\n",
      "time/exploration sampling (s)           0.327154\n",
      "time/logging (s)                        0.0153975\n",
      "time/preback_alpha (s)                  0.647307\n",
      "time/preback_policy (s)                 1.25393\n",
      "time/preback_start (s)                  0.160316\n",
      "time/preback_zf (s)                     5.39015\n",
      "time/saving (s)                         0.00608521\n",
      "time/training (s)                       2.34246\n",
      "time/epoch (s)                         19.1997\n",
      "time/total (s)                       5026.84\n",
      "Epoch                                 282\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:00:27.282727 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 283 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 294000\n",
      "trainer/ZF1 Loss                       -3.72991\n",
      "trainer/ZF2 Loss                       -1.2234\n",
      "trainer/ZF Expert Reward               12.4818\n",
      "trainer/ZF Policy Reward               -0.822499\n",
      "trainer/ZF CHI2 Term                   44.1714\n",
      "trainer/Policy Loss                  -827.094\n",
      "trainer/Bias Loss                      57.4798\n",
      "trainer/Bias Value                     14.3273\n",
      "trainer/Policy Grad Norm              125.301\n",
      "trainer/Policy Param Norm              39.9093\n",
      "trainer/Zf1 Grad Norm                1513.05\n",
      "trainer/Zf1 Param Norm                126.887\n",
      "trainer/Zf2 Grad Norm                1332.11\n",
      "trainer/Zf2 Param Norm                129.66\n",
      "trainer/Z Expert Predictions Mean     967.458\n",
      "trainer/Z Expert Predictions Std       48.6568\n",
      "trainer/Z Expert Predictions Max     1060.41\n",
      "trainer/Z Expert Predictions Min      642.46\n",
      "trainer/Z Policy Predictions Mean     820.79\n",
      "trainer/Z Policy Predictions Std      297.471\n",
      "trainer/Z Policy Predictions Max     1062.41\n",
      "trainer/Z Policy Predictions Min     -395.248\n",
      "trainer/Z Expert Targets Mean         954.976\n",
      "trainer/Z Expert Targets Std           51.405\n",
      "trainer/Z Expert Targets Max         1046.39\n",
      "trainer/Z Expert Targets Min          621.008\n",
      "trainer/Z Policy Targets Mean         821.613\n",
      "trainer/Z Policy Targets Std          293.032\n",
      "trainer/Z Policy Targets Max         1046.25\n",
      "trainer/Z Policy Targets Min         -379.863\n",
      "trainer/Log Pis Mean                   33.6805\n",
      "trainer/Log Pis Std                     7.64729\n",
      "trainer/Policy mu Mean                  0.0879032\n",
      "trainer/Policy mu Std                   1.77712\n",
      "trainer/Policy log std Mean            -4.57234\n",
      "trainer/Policy log std Std              1.08682\n",
      "exploration/num steps total        289344\n",
      "exploration/num paths total           417\n",
      "evaluation/num steps total              2.52585e+06\n",
      "evaluation/num paths total           2906\n",
      "evaluation/path length Mean           901.7\n",
      "evaluation/path length Std            294.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             17\n",
      "evaluation/Rewards Mean                 4.6938\n",
      "evaluation/Rewards Std                  1.04951\n",
      "evaluation/Rewards Max                  7.02688\n",
      "evaluation/Rewards Min                 -4.3269\n",
      "evaluation/Returns Mean              4232.4\n",
      "evaluation/Returns Std               1423.5\n",
      "evaluation/Returns Max               4789.84\n",
      "evaluation/Returns Min                -32.8936\n",
      "evaluation/Estimation Bias Mean       904.106\n",
      "evaluation/Estimation Bias Std        151.712\n",
      "evaluation/EB/Q_True Mean              47.8905\n",
      "evaluation/EB/Q_True Std              139.07\n",
      "evaluation/EB/Q_Pred Mean             951.997\n",
      "evaluation/EB/Q_Pred Std               59.5121\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4232.4\n",
      "evaluation/Actions Mean                 0.0214559\n",
      "evaluation/Actions Std                  0.542728\n",
      "evaluation/Actions Max                  0.999931\n",
      "evaluation/Actions Min                 -0.999979\n",
      "time/backward_policy (s)                2.1368\n",
      "time/backward_zf1 (s)                   2.38018\n",
      "time/backward_zf2 (s)                   2.24766\n",
      "time/data sampling (s)                  0.365342\n",
      "time/data storing (s)                   0.0182821\n",
      "time/evaluation sampling (s)            1.73692\n",
      "time/exploration sampling (s)           0.356064\n",
      "time/logging (s)                        0.010714\n",
      "time/preback_alpha (s)                  0.654305\n",
      "time/preback_policy (s)                 1.20453\n",
      "time/preback_start (s)                  0.164732\n",
      "time/preback_zf (s)                     5.38009\n",
      "time/saving (s)                         0.0061899\n",
      "time/training (s)                       2.50446\n",
      "time/epoch (s)                         19.1663\n",
      "time/total (s)                       5046.03\n",
      "Epoch                                 283\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:00:46.365718 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 284 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 295000\n",
      "trainer/ZF1 Loss                       -2.30313\n",
      "trainer/ZF2 Loss                       -5.31437\n",
      "trainer/ZF Expert Reward               13.3298\n",
      "trainer/ZF Policy Reward                1.07492\n",
      "trainer/ZF CHI2 Term                   41.4183\n",
      "trainer/Policy Loss                  -854.421\n",
      "trainer/Bias Loss                      57.7852\n",
      "trainer/Bias Value                     14.3588\n",
      "trainer/Policy Grad Norm              163.944\n",
      "trainer/Policy Param Norm              39.9357\n",
      "trainer/Zf1 Grad Norm                1201.47\n",
      "trainer/Zf1 Param Norm                127.002\n",
      "trainer/Zf2 Grad Norm                1360.1\n",
      "trainer/Zf2 Param Norm                129.786\n",
      "trainer/Z Expert Predictions Mean     962.649\n",
      "trainer/Z Expert Predictions Std       75.7708\n",
      "trainer/Z Expert Predictions Max     1067\n",
      "trainer/Z Expert Predictions Min       -8.10015\n",
      "trainer/Z Policy Predictions Mean     850.057\n",
      "trainer/Z Policy Predictions Std      256.394\n",
      "trainer/Z Policy Predictions Max     1021.32\n",
      "trainer/Z Policy Predictions Min     -384.431\n",
      "trainer/Z Expert Targets Mean         949.319\n",
      "trainer/Z Expert Targets Std           75.6958\n",
      "trainer/Z Expert Targets Max         1054.81\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         848.982\n",
      "trainer/Z Policy Targets Std          252.235\n",
      "trainer/Z Policy Targets Max         1023.54\n",
      "trainer/Z Policy Targets Min         -381.625\n",
      "trainer/Log Pis Mean                   33.3052\n",
      "trainer/Log Pis Std                     6.90258\n",
      "trainer/Policy mu Mean                  0.00507908\n",
      "trainer/Policy mu Std                   1.63769\n",
      "trainer/Policy log std Mean            -4.63325\n",
      "trainer/Policy log std Std              1.03945\n",
      "exploration/num steps total        291344\n",
      "exploration/num paths total           419\n",
      "evaluation/num steps total              2.53585e+06\n",
      "evaluation/num paths total           2916\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66505\n",
      "evaluation/Rewards Std                  0.923468\n",
      "evaluation/Rewards Max                  6.56364\n",
      "evaluation/Rewards Min                 -1.73738\n",
      "evaluation/Returns Mean              4665.05\n",
      "evaluation/Returns Std                 44.7525\n",
      "evaluation/Returns Max               4723.82\n",
      "evaluation/Returns Min               4572.39\n",
      "evaluation/Estimation Bias Mean       905.096\n",
      "evaluation/Estimation Bias Std        142.59\n",
      "evaluation/EB/Q_True Mean              42.5064\n",
      "evaluation/EB/Q_True Std              130.962\n",
      "evaluation/EB/Q_Pred Mean             947.602\n",
      "evaluation/EB/Q_Pred Std               51.2269\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4665.05\n",
      "evaluation/Actions Mean                 0.0306888\n",
      "evaluation/Actions Std                  0.532182\n",
      "evaluation/Actions Max                  0.999718\n",
      "evaluation/Actions Min                 -0.999948\n",
      "time/backward_policy (s)                2.1128\n",
      "time/backward_zf1 (s)                   2.30841\n",
      "time/backward_zf2 (s)                   2.1863\n",
      "time/data sampling (s)                  0.385591\n",
      "time/data storing (s)                   0.0163736\n",
      "time/evaluation sampling (s)            1.75382\n",
      "time/exploration sampling (s)           0.34494\n",
      "time/logging (s)                        0.0167459\n",
      "time/preback_alpha (s)                  0.646544\n",
      "time/preback_policy (s)                 1.19526\n",
      "time/preback_start (s)                  0.160737\n",
      "time/preback_zf (s)                     5.37416\n",
      "time/saving (s)                         0.00640857\n",
      "time/training (s)                       2.50288\n",
      "time/epoch (s)                         19.011\n",
      "time/total (s)                       5065.06\n",
      "Epoch                                 284\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:01:05.322781 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 285 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 296000\n",
      "trainer/ZF1 Loss                        4.3693\n",
      "trainer/ZF2 Loss                        1.5373\n",
      "trainer/ZF Expert Reward               16.3358\n",
      "trainer/ZF Policy Reward                9.61042\n",
      "trainer/ZF CHI2 Term                   42.4306\n",
      "trainer/Policy Loss                  -858.611\n",
      "trainer/Bias Loss                      53.4203\n",
      "trainer/Bias Value                     14.3515\n",
      "trainer/Policy Grad Norm              134.627\n",
      "trainer/Policy Param Norm              39.9627\n",
      "trainer/Zf1 Grad Norm                1112.96\n",
      "trainer/Zf1 Param Norm                127.146\n",
      "trainer/Zf2 Grad Norm                 953.658\n",
      "trainer/Zf2 Param Norm                129.909\n",
      "trainer/Z Expert Predictions Mean     966.264\n",
      "trainer/Z Expert Predictions Std       47.3369\n",
      "trainer/Z Expert Predictions Max     1062.75\n",
      "trainer/Z Expert Predictions Min      729.164\n",
      "trainer/Z Policy Predictions Mean     858.706\n",
      "trainer/Z Policy Predictions Std      243.146\n",
      "trainer/Z Policy Predictions Max     1031.28\n",
      "trainer/Z Policy Predictions Min     -387.767\n",
      "trainer/Z Expert Targets Mean         949.928\n",
      "trainer/Z Expert Targets Std           47.9737\n",
      "trainer/Z Expert Targets Max         1043.8\n",
      "trainer/Z Expert Targets Min          707.542\n",
      "trainer/Z Policy Targets Mean         849.096\n",
      "trainer/Z Policy Targets Std          235.598\n",
      "trainer/Z Policy Targets Max         1007.13\n",
      "trainer/Z Policy Targets Min         -381.939\n",
      "trainer/Log Pis Mean                   33.0828\n",
      "trainer/Log Pis Std                     5.77061\n",
      "trainer/Policy mu Mean                  0.0794801\n",
      "trainer/Policy mu Std                   1.46578\n",
      "trainer/Policy log std Mean            -4.64758\n",
      "trainer/Policy log std Std              0.968792\n",
      "exploration/num steps total        291344\n",
      "exploration/num paths total           419\n",
      "evaluation/num steps total              2.54585e+06\n",
      "evaluation/num paths total           2926\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.64825\n",
      "evaluation/Rewards Std                  1.00743\n",
      "evaluation/Rewards Max                  6.83985\n",
      "evaluation/Rewards Min                 -2.00124\n",
      "evaluation/Returns Mean              4648.25\n",
      "evaluation/Returns Std                 87.7057\n",
      "evaluation/Returns Max               4826.28\n",
      "evaluation/Returns Min               4499.73\n",
      "evaluation/Estimation Bias Mean       897.969\n",
      "evaluation/Estimation Bias Std        142.467\n",
      "evaluation/EB/Q_True Mean              43.0481\n",
      "evaluation/EB/Q_True Std              132.429\n",
      "evaluation/EB/Q_Pred Mean             941.017\n",
      "evaluation/EB/Q_Pred Std               60.1825\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4648.25\n",
      "evaluation/Actions Mean                 0.023254\n",
      "evaluation/Actions Std                  0.539095\n",
      "evaluation/Actions Max                  0.999779\n",
      "evaluation/Actions Min                 -0.999981\n",
      "time/backward_policy (s)                2.08428\n",
      "time/backward_zf1 (s)                   2.3113\n",
      "time/backward_zf2 (s)                   2.17669\n",
      "time/data sampling (s)                  0.394206\n",
      "time/data storing (s)                   0.0166096\n",
      "time/evaluation sampling (s)            1.73722\n",
      "time/exploration sampling (s)           0.338018\n",
      "time/logging (s)                        0.0151365\n",
      "time/preback_alpha (s)                  0.654974\n",
      "time/preback_policy (s)                 1.21937\n",
      "time/preback_start (s)                  0.162956\n",
      "time/preback_zf (s)                     5.3752\n",
      "time/saving (s)                         0.006437\n",
      "time/training (s)                       2.38422\n",
      "time/epoch (s)                         18.8766\n",
      "time/total (s)                       5083.96\n",
      "Epoch                                 285\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:01:24.649296 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 286 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 297000\n",
      "trainer/ZF1 Loss                        1.21322\n",
      "trainer/ZF2 Loss                        4.09116\n",
      "trainer/ZF Expert Reward               15.5369\n",
      "trainer/ZF Policy Reward                3.28144\n",
      "trainer/ZF CHI2 Term                   46.8304\n",
      "trainer/Policy Loss                  -848.947\n",
      "trainer/Bias Loss                      54.4636\n",
      "trainer/Bias Value                     14.3695\n",
      "trainer/Policy Grad Norm              154.546\n",
      "trainer/Policy Param Norm              39.9897\n",
      "trainer/Zf1 Grad Norm                2200.08\n",
      "trainer/Zf1 Param Norm                127.281\n",
      "trainer/Zf2 Grad Norm                1508.42\n",
      "trainer/Zf2 Param Norm                130.059\n",
      "trainer/Z Expert Predictions Mean     969.896\n",
      "trainer/Z Expert Predictions Std       37.2823\n",
      "trainer/Z Expert Predictions Max     1058.94\n",
      "trainer/Z Expert Predictions Min      778.058\n",
      "trainer/Z Policy Predictions Mean     846.881\n",
      "trainer/Z Policy Predictions Std      262.383\n",
      "trainer/Z Policy Predictions Max     1037.41\n",
      "trainer/Z Policy Predictions Min     -395.344\n",
      "trainer/Z Expert Targets Mean         954.359\n",
      "trainer/Z Expert Targets Std           38.0405\n",
      "trainer/Z Expert Targets Max         1049.39\n",
      "trainer/Z Expert Targets Min          756.082\n",
      "trainer/Z Policy Targets Mean         843.599\n",
      "trainer/Z Policy Targets Std          257.385\n",
      "trainer/Z Policy Targets Max         1013.36\n",
      "trainer/Z Policy Targets Min         -374.541\n",
      "trainer/Log Pis Mean                   32.2452\n",
      "trainer/Log Pis Std                     6.63396\n",
      "trainer/Policy mu Mean                  0.0856453\n",
      "trainer/Policy mu Std                   1.43615\n",
      "trainer/Policy log std Mean            -4.62638\n",
      "trainer/Policy log std Std              0.960224\n",
      "exploration/num steps total        291344\n",
      "exploration/num paths total           419\n",
      "evaluation/num steps total              2.55537e+06\n",
      "evaluation/num paths total           2936\n",
      "evaluation/path length Mean           952.1\n",
      "evaluation/path length Std            143.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            521\n",
      "evaluation/Rewards Mean                 4.67886\n",
      "evaluation/Rewards Std                  1.09578\n",
      "evaluation/Rewards Max                  7.03694\n",
      "evaluation/Rewards Min                 -3.03826\n",
      "evaluation/Returns Mean              4454.74\n",
      "evaluation/Returns Std                713.735\n",
      "evaluation/Returns Max               4824.8\n",
      "evaluation/Returns Min               2361.21\n",
      "evaluation/Estimation Bias Mean       893.782\n",
      "evaluation/Estimation Bias Std        143.793\n",
      "evaluation/EB/Q_True Mean              42.8331\n",
      "evaluation/EB/Q_True Std              128.622\n",
      "evaluation/EB/Q_Pred Mean             936.615\n",
      "evaluation/EB/Q_Pred Std               62.4902\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4454.74\n",
      "evaluation/Actions Mean                 0.0260095\n",
      "evaluation/Actions Std                  0.541447\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99997\n",
      "time/backward_policy (s)                2.17114\n",
      "time/backward_zf1 (s)                   2.38883\n",
      "time/backward_zf2 (s)                   2.27932\n",
      "time/data sampling (s)                  0.370796\n",
      "time/data storing (s)                   0.0177539\n",
      "time/evaluation sampling (s)            1.74687\n",
      "time/exploration sampling (s)           0.348334\n",
      "time/logging (s)                        0.0111411\n",
      "time/preback_alpha (s)                  0.651991\n",
      "time/preback_policy (s)                 1.23463\n",
      "time/preback_start (s)                  0.163985\n",
      "time/preback_zf (s)                     5.3912\n",
      "time/saving (s)                         0.00723686\n",
      "time/training (s)                       2.45789\n",
      "time/epoch (s)                         19.2411\n",
      "time/total (s)                       5103.22\n",
      "Epoch                                 286\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:01:43.980415 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 287 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 298000\n",
      "trainer/ZF1 Loss                       -1.00674\n",
      "trainer/ZF2 Loss                        5.12122\n",
      "trainer/ZF Expert Reward               11.3021\n",
      "trainer/ZF Policy Reward                3.01573\n",
      "trainer/ZF CHI2 Term                   43.2562\n",
      "trainer/Policy Loss                  -835.89\n",
      "trainer/Bias Loss                      65.4751\n",
      "trainer/Bias Value                     14.4109\n",
      "trainer/Policy Grad Norm              125.036\n",
      "trainer/Policy Param Norm              40.0211\n",
      "trainer/Zf1 Grad Norm                1218.49\n",
      "trainer/Zf1 Param Norm                127.408\n",
      "trainer/Zf2 Grad Norm                1316.05\n",
      "trainer/Zf2 Param Norm                130.195\n",
      "trainer/Z Expert Predictions Mean     953.512\n",
      "trainer/Z Expert Predictions Std       52.8769\n",
      "trainer/Z Expert Predictions Max     1048.24\n",
      "trainer/Z Expert Predictions Min      724.152\n",
      "trainer/Z Policy Predictions Mean     835.085\n",
      "trainer/Z Policy Predictions Std      275.114\n",
      "trainer/Z Policy Predictions Max     1028.06\n",
      "trainer/Z Policy Predictions Min     -378.778\n",
      "trainer/Z Expert Targets Mean         942.21\n",
      "trainer/Z Expert Targets Std           55.6387\n",
      "trainer/Z Expert Targets Max         1036.74\n",
      "trainer/Z Expert Targets Min          698.481\n",
      "trainer/Z Policy Targets Mean         832.07\n",
      "trainer/Z Policy Targets Std          270.567\n",
      "trainer/Z Policy Targets Max         1008.64\n",
      "trainer/Z Policy Targets Min         -364.087\n",
      "trainer/Log Pis Mean                   33.2451\n",
      "trainer/Log Pis Std                     6.47156\n",
      "trainer/Policy mu Mean                  0.0825379\n",
      "trainer/Policy mu Std                   1.65639\n",
      "trainer/Policy log std Mean            -4.64352\n",
      "trainer/Policy log std Std              1.10744\n",
      "exploration/num steps total        292344\n",
      "exploration/num paths total           420\n",
      "evaluation/num steps total              2.56537e+06\n",
      "evaluation/num paths total           2946\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.68739\n",
      "evaluation/Rewards Std                  1.01308\n",
      "evaluation/Rewards Max                  6.98402\n",
      "evaluation/Rewards Min                 -2.00464\n",
      "evaluation/Returns Mean              4687.39\n",
      "evaluation/Returns Std                136.707\n",
      "evaluation/Returns Max               4875.53\n",
      "evaluation/Returns Min               4394.3\n",
      "evaluation/Estimation Bias Mean       898.412\n",
      "evaluation/Estimation Bias Std        140.833\n",
      "evaluation/EB/Q_True Mean              41.9193\n",
      "evaluation/EB/Q_True Std              129.779\n",
      "evaluation/EB/Q_Pred Mean             940.331\n",
      "evaluation/EB/Q_Pred Std               58.1977\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4687.39\n",
      "evaluation/Actions Mean                 0.0200331\n",
      "evaluation/Actions Std                  0.539717\n",
      "evaluation/Actions Max                  0.999884\n",
      "evaluation/Actions Min                 -0.999928\n",
      "time/backward_policy (s)                2.19156\n",
      "time/backward_zf1 (s)                   2.41058\n",
      "time/backward_zf2 (s)                   2.31038\n",
      "time/data sampling (s)                  0.380812\n",
      "time/data storing (s)                   0.0174657\n",
      "time/evaluation sampling (s)            1.78196\n",
      "time/exploration sampling (s)           0.355268\n",
      "time/logging (s)                        0.0179258\n",
      "time/preback_alpha (s)                  0.641588\n",
      "time/preback_policy (s)                 1.26421\n",
      "time/preback_start (s)                  0.160049\n",
      "time/preback_zf (s)                     5.34053\n",
      "time/saving (s)                         0.00587514\n",
      "time/training (s)                       2.38611\n",
      "time/epoch (s)                         19.2643\n",
      "time/total (s)                       5122.51\n",
      "Epoch                                 287\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:02:03.237476 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 288 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 299000\n",
      "trainer/ZF1 Loss                       -4.3805\n",
      "trainer/ZF2 Loss                       -4.28118\n",
      "trainer/ZF Expert Reward               16.9836\n",
      "trainer/ZF Policy Reward                4.3664\n",
      "trainer/ZF CHI2 Term                   41.3184\n",
      "trainer/Policy Loss                  -857.011\n",
      "trainer/Bias Loss                      53.7914\n",
      "trainer/Bias Value                     14.4395\n",
      "trainer/Policy Grad Norm              161.619\n",
      "trainer/Policy Param Norm              40.0439\n",
      "trainer/Zf1 Grad Norm                 891.628\n",
      "trainer/Zf1 Param Norm                127.549\n",
      "trainer/Zf2 Grad Norm                1065.43\n",
      "trainer/Zf2 Param Norm                130.333\n",
      "trainer/Z Expert Predictions Mean     962.941\n",
      "trainer/Z Expert Predictions Std       55.5507\n",
      "trainer/Z Expert Predictions Max     1057.36\n",
      "trainer/Z Expert Predictions Min      529.154\n",
      "trainer/Z Policy Predictions Mean     851.603\n",
      "trainer/Z Policy Predictions Std      229.338\n",
      "trainer/Z Policy Predictions Max     1032.22\n",
      "trainer/Z Policy Predictions Min     -370.554\n",
      "trainer/Z Expert Targets Mean         945.957\n",
      "trainer/Z Expert Targets Std           58.0463\n",
      "trainer/Z Expert Targets Max         1049.96\n",
      "trainer/Z Expert Targets Min          459.375\n",
      "trainer/Z Policy Targets Mean         847.237\n",
      "trainer/Z Policy Targets Std          226.624\n",
      "trainer/Z Policy Targets Max         1010.59\n",
      "trainer/Z Policy Targets Min         -388.973\n",
      "trainer/Log Pis Mean                   33.3656\n",
      "trainer/Log Pis Std                     6.49369\n",
      "trainer/Policy mu Mean                  0.044022\n",
      "trainer/Policy mu Std                   1.47651\n",
      "trainer/Policy log std Mean            -4.69279\n",
      "trainer/Policy log std Std              0.886866\n",
      "exploration/num steps total        295344\n",
      "exploration/num paths total           423\n",
      "evaluation/num steps total              2.57439e+06\n",
      "evaluation/num paths total           2956\n",
      "evaluation/path length Mean           901.7\n",
      "evaluation/path length Std            294.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             17\n",
      "evaluation/Rewards Mean                 4.61239\n",
      "evaluation/Rewards Std                  1.01469\n",
      "evaluation/Rewards Max                  6.83364\n",
      "evaluation/Rewards Min                 -2.40506\n",
      "evaluation/Returns Mean              4158.99\n",
      "evaluation/Returns Std               1393.65\n",
      "evaluation/Returns Max               4760.09\n",
      "evaluation/Returns Min                 -8.56045\n",
      "evaluation/Estimation Bias Mean       889.564\n",
      "evaluation/Estimation Bias Std        143.573\n",
      "evaluation/EB/Q_True Mean              44.6825\n",
      "evaluation/EB/Q_True Std              129.488\n",
      "evaluation/EB/Q_Pred Mean             934.247\n",
      "evaluation/EB/Q_Pred Std               58.2518\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4158.99\n",
      "evaluation/Actions Mean                 0.0110977\n",
      "evaluation/Actions Std                  0.532605\n",
      "evaluation/Actions Max                  0.999725\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                2.14813\n",
      "time/backward_zf1 (s)                   2.42602\n",
      "time/backward_zf2 (s)                   2.29533\n",
      "time/data sampling (s)                  0.359201\n",
      "time/data storing (s)                   0.0185991\n",
      "time/evaluation sampling (s)            1.74642\n",
      "time/exploration sampling (s)           0.366677\n",
      "time/logging (s)                        0.0124637\n",
      "time/preback_alpha (s)                  0.641687\n",
      "time/preback_policy (s)                 1.26101\n",
      "time/preback_start (s)                  0.167257\n",
      "time/preback_zf (s)                     5.36745\n",
      "time/saving (s)                         0.00620936\n",
      "time/training (s)                       2.35266\n",
      "time/epoch (s)                         19.1691\n",
      "time/total (s)                       5141.7\n",
      "Epoch                                 288\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:02:22.745614 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 289 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 300000\n",
      "trainer/ZF1 Loss                        2.01945\n",
      "trainer/ZF2 Loss                        6.23478\n",
      "trainer/ZF Expert Reward               15.8452\n",
      "trainer/ZF Policy Reward                3.47144\n",
      "trainer/ZF CHI2 Term                   49.3268\n",
      "trainer/Policy Loss                  -839.698\n",
      "trainer/Bias Loss                      73.3385\n",
      "trainer/Bias Value                     14.451\n",
      "trainer/Policy Grad Norm              147.085\n",
      "trainer/Policy Param Norm              40.0687\n",
      "trainer/Zf1 Grad Norm                1320.07\n",
      "trainer/Zf1 Param Norm                127.683\n",
      "trainer/Zf2 Grad Norm                1320.69\n",
      "trainer/Zf2 Param Norm                130.462\n",
      "trainer/Z Expert Predictions Mean     965.105\n",
      "trainer/Z Expert Predictions Std       47.7137\n",
      "trainer/Z Expert Predictions Max     1062.82\n",
      "trainer/Z Expert Predictions Min      678.089\n",
      "trainer/Z Policy Predictions Mean     836.186\n",
      "trainer/Z Policy Predictions Std      268.282\n",
      "trainer/Z Policy Predictions Max     1030.81\n",
      "trainer/Z Policy Predictions Min     -409.021\n",
      "trainer/Z Expert Targets Mean         949.259\n",
      "trainer/Z Expert Targets Std           48.3477\n",
      "trainer/Z Expert Targets Max         1039.91\n",
      "trainer/Z Expert Targets Min          650.482\n",
      "trainer/Z Policy Targets Mean         832.715\n",
      "trainer/Z Policy Targets Std          260.683\n",
      "trainer/Z Policy Targets Max         1012.65\n",
      "trainer/Z Policy Targets Min         -400.185\n",
      "trainer/Log Pis Mean                   33.1576\n",
      "trainer/Log Pis Std                     6.6486\n",
      "trainer/Policy mu Mean                 -0.0067896\n",
      "trainer/Policy mu Std                   1.55839\n",
      "trainer/Policy log std Mean            -4.67413\n",
      "trainer/Policy log std Std              0.973393\n",
      "exploration/num steps total        295344\n",
      "exploration/num paths total           423\n",
      "evaluation/num steps total              2.58278e+06\n",
      "evaluation/num paths total           2966\n",
      "evaluation/path length Mean           838.8\n",
      "evaluation/path length Std            327.68\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             63\n",
      "evaluation/Rewards Mean                 4.70728\n",
      "evaluation/Rewards Std                  1.06874\n",
      "evaluation/Rewards Max                  7.16756\n",
      "evaluation/Rewards Min                 -1.86166\n",
      "evaluation/Returns Mean              3948.47\n",
      "evaluation/Returns Std               1598.9\n",
      "evaluation/Returns Max               4893.62\n",
      "evaluation/Returns Min                132.527\n",
      "evaluation/Estimation Bias Mean       875.715\n",
      "evaluation/Estimation Bias Std        170.219\n",
      "evaluation/EB/Q_True Mean              53.1401\n",
      "evaluation/EB/Q_True Std              148.181\n",
      "evaluation/EB/Q_Pred Mean             928.855\n",
      "evaluation/EB/Q_Pred Std               67.0235\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3948.47\n",
      "evaluation/Actions Mean                 0.024028\n",
      "evaluation/Actions Std                  0.537593\n",
      "evaluation/Actions Max                  0.999969\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.17992\n",
      "time/backward_zf1 (s)                   2.4225\n",
      "time/backward_zf2 (s)                   2.27894\n",
      "time/data sampling (s)                  0.402503\n",
      "time/data storing (s)                   0.0160071\n",
      "time/evaluation sampling (s)            1.75955\n",
      "time/exploration sampling (s)           0.347546\n",
      "time/logging (s)                        0.0105561\n",
      "time/preback_alpha (s)                  0.664258\n",
      "time/preback_policy (s)                 1.29065\n",
      "time/preback_start (s)                  0.164135\n",
      "time/preback_zf (s)                     5.44518\n",
      "time/saving (s)                         0.00610265\n",
      "time/training (s)                       2.43706\n",
      "time/epoch (s)                         19.4249\n",
      "time/total (s)                       5161.15\n",
      "Epoch                                 289\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:02:42.255035 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 290 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 301000\n",
      "trainer/ZF1 Loss                       -7.61604\n",
      "trainer/ZF2 Loss                        0.157383\n",
      "trainer/ZF Expert Reward               14.3379\n",
      "trainer/ZF Policy Reward                0.76399\n",
      "trainer/ZF CHI2 Term                   42.5673\n",
      "trainer/Policy Loss                  -866.023\n",
      "trainer/Bias Loss                      60.8893\n",
      "trainer/Bias Value                     14.4213\n",
      "trainer/Policy Grad Norm              183.899\n",
      "trainer/Policy Param Norm              40.0957\n",
      "trainer/Zf1 Grad Norm                1118.74\n",
      "trainer/Zf1 Param Norm                127.799\n",
      "trainer/Zf2 Grad Norm                1586.71\n",
      "trainer/Zf2 Param Norm                130.619\n",
      "trainer/Z Expert Predictions Mean     950.951\n",
      "trainer/Z Expert Predictions Std       78.2292\n",
      "trainer/Z Expert Predictions Max     1048.94\n",
      "trainer/Z Expert Predictions Min       34.9458\n",
      "trainer/Z Policy Predictions Mean     858.335\n",
      "trainer/Z Policy Predictions Std      209.882\n",
      "trainer/Z Policy Predictions Max     1028.64\n",
      "trainer/Z Policy Predictions Min     -385.582\n",
      "trainer/Z Expert Targets Mean         936.613\n",
      "trainer/Z Expert Targets Std           80.9367\n",
      "trainer/Z Expert Targets Max         1036.95\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         857.571\n",
      "trainer/Z Policy Targets Std          207.653\n",
      "trainer/Z Policy Targets Max         1029.91\n",
      "trainer/Z Policy Targets Min         -387.594\n",
      "trainer/Log Pis Mean                   33.0532\n",
      "trainer/Log Pis Std                     5.64607\n",
      "trainer/Policy mu Mean                  0.0840277\n",
      "trainer/Policy mu Std                   1.25832\n",
      "trainer/Policy log std Mean            -4.76008\n",
      "trainer/Policy log std Std              0.885676\n",
      "exploration/num steps total        295344\n",
      "exploration/num paths total           423\n",
      "evaluation/num steps total              2.59278e+06\n",
      "evaluation/num paths total           2976\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.57594\n",
      "evaluation/Rewards Std                  1.14127\n",
      "evaluation/Rewards Max                  6.9158\n",
      "evaluation/Rewards Min                 -3.15183\n",
      "evaluation/Returns Mean              4575.94\n",
      "evaluation/Returns Std                146.011\n",
      "evaluation/Returns Max               4735.82\n",
      "evaluation/Returns Min               4205.05\n",
      "evaluation/Estimation Bias Mean       892.263\n",
      "evaluation/Estimation Bias Std        152.144\n",
      "evaluation/EB/Q_True Mean              41.8198\n",
      "evaluation/EB/Q_True Std              129.599\n",
      "evaluation/EB/Q_Pred Mean             934.083\n",
      "evaluation/EB/Q_Pred Std               76.8302\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4575.94\n",
      "evaluation/Actions Mean                 0.0198189\n",
      "evaluation/Actions Std                  0.53784\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.21658\n",
      "time/backward_zf1 (s)                   2.45862\n",
      "time/backward_zf2 (s)                   2.33179\n",
      "time/data sampling (s)                  0.410206\n",
      "time/data storing (s)                   0.0159334\n",
      "time/evaluation sampling (s)            1.7543\n",
      "time/exploration sampling (s)           0.337756\n",
      "time/logging (s)                        0.0127923\n",
      "time/preback_alpha (s)                  0.663604\n",
      "time/preback_policy (s)                 1.26969\n",
      "time/preback_start (s)                  0.160341\n",
      "time/preback_zf (s)                     5.37804\n",
      "time/saving (s)                         0.0064558\n",
      "time/training (s)                       2.41304\n",
      "time/epoch (s)                         19.4292\n",
      "time/total (s)                       5180.6\n",
      "Epoch                                 290\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:03:01.669695 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 291 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 302000\n",
      "trainer/ZF1 Loss                      201.446\n",
      "trainer/ZF2 Loss                      182.16\n",
      "trainer/ZF Expert Reward               18.3252\n",
      "trainer/ZF Policy Reward               11.917\n",
      "trainer/ZF CHI2 Term                  230.57\n",
      "trainer/Policy Loss                  -876.039\n",
      "trainer/Bias Loss                     120.155\n",
      "trainer/Bias Value                     14.4482\n",
      "trainer/Policy Grad Norm              132.27\n",
      "trainer/Policy Param Norm              40.122\n",
      "trainer/Zf1 Grad Norm                1521.23\n",
      "trainer/Zf1 Param Norm                127.944\n",
      "trainer/Zf2 Grad Norm                2273.79\n",
      "trainer/Zf2 Param Norm                130.75\n",
      "trainer/Z Expert Predictions Mean     957.211\n",
      "trainer/Z Expert Predictions Std       51.3511\n",
      "trainer/Z Expert Predictions Max     1045.46\n",
      "trainer/Z Expert Predictions Min      722.534\n",
      "trainer/Z Policy Predictions Mean     876.975\n",
      "trainer/Z Policy Predictions Std      207.953\n",
      "trainer/Z Policy Predictions Max     1025.99\n",
      "trainer/Z Policy Predictions Min     -407.67\n",
      "trainer/Z Expert Targets Mean         938.885\n",
      "trainer/Z Expert Targets Std           57.5554\n",
      "trainer/Z Expert Targets Max         1050.16\n",
      "trainer/Z Expert Targets Min          554.706\n",
      "trainer/Z Policy Targets Mean         865.058\n",
      "trainer/Z Policy Targets Std          211.163\n",
      "trainer/Z Policy Targets Max         1015.67\n",
      "trainer/Z Policy Targets Min         -397.403\n",
      "trainer/Log Pis Mean                   32.6861\n",
      "trainer/Log Pis Std                     5.84785\n",
      "trainer/Policy mu Mean                  0.0540838\n",
      "trainer/Policy mu Std                   1.3088\n",
      "trainer/Policy log std Mean            -4.77587\n",
      "trainer/Policy log std Std              0.832631\n",
      "exploration/num steps total        296344\n",
      "exploration/num paths total           424\n",
      "evaluation/num steps total              2.60202e+06\n",
      "evaluation/num paths total           2986\n",
      "evaluation/path length Mean           923.9\n",
      "evaluation/path length Std            228.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            239\n",
      "evaluation/Rewards Mean                 4.62854\n",
      "evaluation/Rewards Std                  0.95811\n",
      "evaluation/Rewards Max                  6.74881\n",
      "evaluation/Rewards Min                 -3.0135\n",
      "evaluation/Returns Mean              4276.31\n",
      "evaluation/Returns Std               1123.36\n",
      "evaluation/Returns Max               4733.31\n",
      "evaluation/Returns Min                911.045\n",
      "evaluation/Estimation Bias Mean       883.833\n",
      "evaluation/Estimation Bias Std        152.788\n",
      "evaluation/EB/Q_True Mean              46.6682\n",
      "evaluation/EB/Q_True Std              138.214\n",
      "evaluation/EB/Q_Pred Mean             930.501\n",
      "evaluation/EB/Q_Pred Std               52.5537\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4276.31\n",
      "evaluation/Actions Mean                 0.0225708\n",
      "evaluation/Actions Std                  0.53471\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999949\n",
      "time/backward_policy (s)                2.18087\n",
      "time/backward_zf1 (s)                   2.40906\n",
      "time/backward_zf2 (s)                   2.29819\n",
      "time/data sampling (s)                  0.391212\n",
      "time/data storing (s)                   0.0170585\n",
      "time/evaluation sampling (s)            1.78018\n",
      "time/exploration sampling (s)           0.351838\n",
      "time/logging (s)                        0.0117306\n",
      "time/preback_alpha (s)                  0.649738\n",
      "time/preback_policy (s)                 1.24016\n",
      "time/preback_start (s)                  0.163125\n",
      "time/preback_zf (s)                     5.38721\n",
      "time/saving (s)                         0.00619814\n",
      "time/training (s)                       2.45156\n",
      "time/epoch (s)                         19.3381\n",
      "time/total (s)                       5199.96\n",
      "Epoch                                 291\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:03:21.025475 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 292 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 303000\n",
      "trainer/ZF1 Loss                        2.71596\n",
      "trainer/ZF2 Loss                       -0.675194\n",
      "trainer/ZF Expert Reward               15.5542\n",
      "trainer/ZF Policy Reward                6.72397\n",
      "trainer/ZF CHI2 Term                   42.1017\n",
      "trainer/Policy Loss                  -852.571\n",
      "trainer/Bias Loss                      87.2477\n",
      "trainer/Bias Value                     14.4307\n",
      "trainer/Policy Grad Norm              129.621\n",
      "trainer/Policy Param Norm              40.1485\n",
      "trainer/Zf1 Grad Norm                1675.65\n",
      "trainer/Zf1 Param Norm                128.09\n",
      "trainer/Zf2 Grad Norm                1129.91\n",
      "trainer/Zf2 Param Norm                130.905\n",
      "trainer/Z Expert Predictions Mean     954.079\n",
      "trainer/Z Expert Predictions Std       45.4385\n",
      "trainer/Z Expert Predictions Max     1049.76\n",
      "trainer/Z Expert Predictions Min      714.265\n",
      "trainer/Z Policy Predictions Mean     851.411\n",
      "trainer/Z Policy Predictions Std      247.387\n",
      "trainer/Z Policy Predictions Max     1038.2\n",
      "trainer/Z Policy Predictions Min     -411.215\n",
      "trainer/Z Expert Targets Mean         938.525\n",
      "trainer/Z Expert Targets Std           47.8837\n",
      "trainer/Z Expert Targets Max         1028.13\n",
      "trainer/Z Expert Targets Min          688.851\n",
      "trainer/Z Policy Targets Mean         844.687\n",
      "trainer/Z Policy Targets Std          244.978\n",
      "trainer/Z Policy Targets Max         1023.63\n",
      "trainer/Z Policy Targets Min         -413.388\n",
      "trainer/Log Pis Mean                   32.5769\n",
      "trainer/Log Pis Std                     5.23619\n",
      "trainer/Policy mu Mean                  0.0313436\n",
      "trainer/Policy mu Std                   1.48155\n",
      "trainer/Policy log std Mean            -4.71333\n",
      "trainer/Policy log std Std              1.02397\n",
      "exploration/num steps total        297344\n",
      "exploration/num paths total           425\n",
      "evaluation/num steps total              2.61202e+06\n",
      "evaluation/num paths total           2996\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.66074\n",
      "evaluation/Rewards Std                  0.947134\n",
      "evaluation/Rewards Max                  6.93984\n",
      "evaluation/Rewards Min                 -1.59845\n",
      "evaluation/Returns Mean              4660.74\n",
      "evaluation/Returns Std                 81.3041\n",
      "evaluation/Returns Max               4762.05\n",
      "evaluation/Returns Min               4508.21\n",
      "evaluation/Estimation Bias Mean       889.355\n",
      "evaluation/Estimation Bias Std        143.314\n",
      "evaluation/EB/Q_True Mean              42.8757\n",
      "evaluation/EB/Q_True Std              132.032\n",
      "evaluation/EB/Q_Pred Mean             932.231\n",
      "evaluation/EB/Q_Pred Std               53.484\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4660.74\n",
      "evaluation/Actions Mean                 0.0225864\n",
      "evaluation/Actions Std                  0.534661\n",
      "evaluation/Actions Max                  0.999961\n",
      "evaluation/Actions Min                 -0.999968\n",
      "time/backward_policy (s)                2.13397\n",
      "time/backward_zf1 (s)                   2.41931\n",
      "time/backward_zf2 (s)                   2.27357\n",
      "time/data sampling (s)                  0.394152\n",
      "time/data storing (s)                   0.0169167\n",
      "time/evaluation sampling (s)            1.7519\n",
      "time/exploration sampling (s)           0.348602\n",
      "time/logging (s)                        0.0135079\n",
      "time/preback_alpha (s)                  0.660304\n",
      "time/preback_policy (s)                 1.27593\n",
      "time/preback_start (s)                  0.164885\n",
      "time/preback_zf (s)                     5.37296\n",
      "time/saving (s)                         0.0062052\n",
      "time/training (s)                       2.43511\n",
      "time/epoch (s)                         19.2673\n",
      "time/total (s)                       5219.26\n",
      "Epoch                                 292\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:03:40.352694 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 293 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 304000\n",
      "trainer/ZF1 Loss                       -8.538\n",
      "trainer/ZF2 Loss                        0.0434303\n",
      "trainer/ZF Expert Reward               14.6022\n",
      "trainer/ZF Policy Reward                3.2048\n",
      "trainer/ZF CHI2 Term                   38.87\n",
      "trainer/Policy Loss                  -874.676\n",
      "trainer/Bias Loss                      67.3191\n",
      "trainer/Bias Value                     14.4589\n",
      "trainer/Policy Grad Norm              149.797\n",
      "trainer/Policy Param Norm              40.1707\n",
      "trainer/Zf1 Grad Norm                1567.36\n",
      "trainer/Zf1 Param Norm                128.216\n",
      "trainer/Zf2 Grad Norm                1313.23\n",
      "trainer/Zf2 Param Norm                131.027\n",
      "trainer/Z Expert Predictions Mean     952.036\n",
      "trainer/Z Expert Predictions Std       50.0294\n",
      "trainer/Z Expert Predictions Max     1043.86\n",
      "trainer/Z Expert Predictions Min      652.916\n",
      "trainer/Z Policy Predictions Mean     868.138\n",
      "trainer/Z Policy Predictions Std      199.116\n",
      "trainer/Z Policy Predictions Max     1029.93\n",
      "trainer/Z Policy Predictions Min     -446.054\n",
      "trainer/Z Expert Targets Mean         937.434\n",
      "trainer/Z Expert Targets Std           52.6054\n",
      "trainer/Z Expert Targets Max         1029.79\n",
      "trainer/Z Expert Targets Min          636.155\n",
      "trainer/Z Policy Targets Mean         864.933\n",
      "trainer/Z Policy Targets Std          195.208\n",
      "trainer/Z Policy Targets Max         1014.05\n",
      "trainer/Z Policy Targets Min         -439.931\n",
      "trainer/Log Pis Mean                   32.0402\n",
      "trainer/Log Pis Std                     4.90396\n",
      "trainer/Policy mu Mean                  0.0218601\n",
      "trainer/Policy mu Std                   1.22918\n",
      "trainer/Policy log std Mean            -4.76934\n",
      "trainer/Policy log std Std              0.823779\n",
      "exploration/num steps total        299344\n",
      "exploration/num paths total           427\n",
      "evaluation/num steps total              2.62202e+06\n",
      "evaluation/num paths total           3006\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.70917\n",
      "evaluation/Rewards Std                  0.976391\n",
      "evaluation/Rewards Max                  6.84001\n",
      "evaluation/Rewards Min                 -1.86865\n",
      "evaluation/Returns Mean              4709.17\n",
      "evaluation/Returns Std                 89.7148\n",
      "evaluation/Returns Max               4884.55\n",
      "evaluation/Returns Min               4553.35\n",
      "evaluation/Estimation Bias Mean       891.414\n",
      "evaluation/Estimation Bias Std        142.671\n",
      "evaluation/EB/Q_True Mean              42.607\n",
      "evaluation/EB/Q_True Std              131.704\n",
      "evaluation/EB/Q_Pred Mean             934.021\n",
      "evaluation/EB/Q_Pred Std               55.2196\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4709.17\n",
      "evaluation/Actions Mean                 0.0228564\n",
      "evaluation/Actions Std                  0.544438\n",
      "evaluation/Actions Max                  0.999754\n",
      "evaluation/Actions Min                 -0.999991\n",
      "time/backward_policy (s)                2.127\n",
      "time/backward_zf1 (s)                   2.4077\n",
      "time/backward_zf2 (s)                   2.23242\n",
      "time/data sampling (s)                  0.393679\n",
      "time/data storing (s)                   0.0170604\n",
      "time/evaluation sampling (s)            1.72507\n",
      "time/exploration sampling (s)           0.355223\n",
      "time/logging (s)                        0.0120911\n",
      "time/preback_alpha (s)                  0.667186\n",
      "time/preback_policy (s)                 1.2374\n",
      "time/preback_start (s)                  0.165775\n",
      "time/preback_zf (s)                     5.43747\n",
      "time/saving (s)                         0.00642378\n",
      "time/training (s)                       2.46451\n",
      "time/epoch (s)                         19.249\n",
      "time/total (s)                       5238.53\n",
      "Epoch                                 293\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:03:59.696995 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 294 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 305000\n",
      "trainer/ZF1 Loss                        0.630165\n",
      "trainer/ZF2 Loss                        0.689049\n",
      "trainer/ZF Expert Reward               14.7698\n",
      "trainer/ZF Policy Reward                7.00861\n",
      "trainer/ZF CHI2 Term                   41.1335\n",
      "trainer/Policy Loss                  -848.926\n",
      "trainer/Bias Loss                      64.8936\n",
      "trainer/Bias Value                     14.4586\n",
      "trainer/Policy Grad Norm              160.177\n",
      "trainer/Policy Param Norm              40.1972\n",
      "trainer/Zf1 Grad Norm                1639.96\n",
      "trainer/Zf1 Param Norm                128.346\n",
      "trainer/Zf2 Grad Norm                1232.79\n",
      "trainer/Zf2 Param Norm                131.182\n",
      "trainer/Z Expert Predictions Mean     954.536\n",
      "trainer/Z Expert Predictions Std       45.8757\n",
      "trainer/Z Expert Predictions Max     1031.13\n",
      "trainer/Z Expert Predictions Min      708.472\n",
      "trainer/Z Policy Predictions Mean     846.804\n",
      "trainer/Z Policy Predictions Std      222.863\n",
      "trainer/Z Policy Predictions Max      996.48\n",
      "trainer/Z Policy Predictions Min     -455.893\n",
      "trainer/Z Expert Targets Mean         939.766\n",
      "trainer/Z Expert Targets Std           47.7913\n",
      "trainer/Z Expert Targets Max         1020.87\n",
      "trainer/Z Expert Targets Min          695.178\n",
      "trainer/Z Policy Targets Mean         839.795\n",
      "trainer/Z Policy Targets Std          219.583\n",
      "trainer/Z Policy Targets Max          983.655\n",
      "trainer/Z Policy Targets Min         -429.506\n",
      "trainer/Log Pis Mean                   33.0431\n",
      "trainer/Log Pis Std                     6.06279\n",
      "trainer/Policy mu Mean                  0.0382268\n",
      "trainer/Policy mu Std                   1.33391\n",
      "trainer/Policy log std Mean            -4.76272\n",
      "trainer/Policy log std Std              0.923798\n",
      "exploration/num steps total        301368\n",
      "exploration/num paths total           430\n",
      "evaluation/num steps total              2.6307e+06\n",
      "evaluation/num paths total           3016\n",
      "evaluation/path length Mean           867.7\n",
      "evaluation/path length Std            298.615\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             29\n",
      "evaluation/Rewards Mean                 4.74385\n",
      "evaluation/Rewards Std                  0.999268\n",
      "evaluation/Rewards Max                  6.81937\n",
      "evaluation/Rewards Min                 -1.88661\n",
      "evaluation/Returns Mean              4116.24\n",
      "evaluation/Returns Std               1456.2\n",
      "evaluation/Returns Max               4861.95\n",
      "evaluation/Returns Min                 22.1967\n",
      "evaluation/Estimation Bias Mean       871.009\n",
      "evaluation/Estimation Bias Std        159.038\n",
      "evaluation/EB/Q_True Mean              50.2258\n",
      "evaluation/EB/Q_True Std              142.669\n",
      "evaluation/EB/Q_Pred Mean             921.234\n",
      "evaluation/EB/Q_Pred Std               59.3792\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4116.24\n",
      "evaluation/Actions Mean                 0.0248043\n",
      "evaluation/Actions Std                  0.539398\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.14964\n",
      "time/backward_zf1 (s)                   2.39114\n",
      "time/backward_zf2 (s)                   2.27587\n",
      "time/data sampling (s)                  0.393536\n",
      "time/data storing (s)                   0.0167249\n",
      "time/evaluation sampling (s)            1.70715\n",
      "time/exploration sampling (s)           0.358969\n",
      "time/logging (s)                        0.0107684\n",
      "time/preback_alpha (s)                  0.66132\n",
      "time/preback_policy (s)                 1.24416\n",
      "time/preback_start (s)                  0.166825\n",
      "time/preback_zf (s)                     5.40271\n",
      "time/saving (s)                         0.0058575\n",
      "time/training (s)                       2.48089\n",
      "time/epoch (s)                         19.2656\n",
      "time/total (s)                       5257.81\n",
      "Epoch                                 294\n",
      "---------------------------------  ---------------\n",
      "2024-06-10 22:04:19.355852 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 295 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 306000\n",
      "trainer/ZF1 Loss                        5.91434\n",
      "trainer/ZF2 Loss                        4.54195\n",
      "trainer/ZF Expert Reward               10.1375\n",
      "trainer/ZF Policy Reward               -0.203551\n",
      "trainer/ZF CHI2 Term                   48.0391\n",
      "trainer/Policy Loss                  -848.503\n",
      "trainer/Bias Loss                      67.9228\n",
      "trainer/Bias Value                     14.4698\n",
      "trainer/Policy Grad Norm              168.93\n",
      "trainer/Policy Param Norm              40.2241\n",
      "trainer/Zf1 Grad Norm                1864.74\n",
      "trainer/Zf1 Param Norm                128.491\n",
      "trainer/Zf2 Grad Norm                1658.23\n",
      "trainer/Zf2 Param Norm                131.328\n",
      "trainer/Z Expert Predictions Mean     944.621\n",
      "trainer/Z Expert Predictions Std       49.7215\n",
      "trainer/Z Expert Predictions Max     1035.06\n",
      "trainer/Z Expert Predictions Min      614.891\n",
      "trainer/Z Policy Predictions Mean     844.271\n",
      "trainer/Z Policy Predictions Std      233.071\n",
      "trainer/Z Policy Predictions Max     1000.24\n",
      "trainer/Z Policy Predictions Min     -431.865\n",
      "trainer/Z Expert Targets Mean         934.484\n",
      "trainer/Z Expert Targets Std           51.1914\n",
      "trainer/Z Expert Targets Max         1023.32\n",
      "trainer/Z Expert Targets Min          588.003\n",
      "trainer/Z Policy Targets Mean         844.475\n",
      "trainer/Z Policy Targets Std          229.715\n",
      "trainer/Z Policy Targets Max         1001.25\n",
      "trainer/Z Policy Targets Min         -419.512\n",
      "trainer/Log Pis Mean                   32.798\n",
      "trainer/Log Pis Std                     5.90561\n",
      "trainer/Policy mu Mean                  0.0573606\n",
      "trainer/Policy mu Std                   1.39235\n",
      "trainer/Policy log std Mean            -4.72468\n",
      "trainer/Policy log std Std              0.918791\n",
      "exploration/num steps total        301368\n",
      "exploration/num paths total           430\n",
      "evaluation/num steps total              2.63973e+06\n",
      "evaluation/num paths total           3026\n",
      "evaluation/path length Mean           903.9\n",
      "evaluation/path length Std            288.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             39\n",
      "evaluation/Rewards Mean                 4.57097\n",
      "evaluation/Rewards Std                  1.05636\n",
      "evaluation/Rewards Max                  6.67154\n",
      "evaluation/Rewards Min                 -2.42608\n",
      "evaluation/Returns Mean              4131.7\n",
      "evaluation/Returns Std               1356.45\n",
      "evaluation/Returns Max               4768.45\n",
      "evaluation/Returns Min                 74.5606\n",
      "evaluation/Estimation Bias Mean       867.597\n",
      "evaluation/Estimation Bias Std        154.771\n",
      "evaluation/EB/Q_True Mean              46.7577\n",
      "evaluation/EB/Q_True Std              136.183\n",
      "evaluation/EB/Q_Pred Mean             914.355\n",
      "evaluation/EB/Q_Pred Std               65.969\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4131.7\n",
      "evaluation/Actions Mean                 0.0274063\n",
      "evaluation/Actions Std                  0.536232\n",
      "evaluation/Actions Max                  0.999948\n",
      "evaluation/Actions Min                 -0.999953\n",
      "time/backward_policy (s)                2.21043\n",
      "time/backward_zf1 (s)                   2.45927\n",
      "time/backward_zf2 (s)                   2.33136\n",
      "time/data sampling (s)                  0.423665\n",
      "time/data storing (s)                   0.019265\n",
      "time/evaluation sampling (s)            1.68097\n",
      "time/exploration sampling (s)           0.36867\n",
      "time/logging (s)                        0.0112368\n",
      "time/preback_alpha (s)                  0.673062\n",
      "time/preback_policy (s)                 1.28057\n",
      "time/preback_start (s)                  0.167676\n",
      "time/preback_zf (s)                     5.44407\n",
      "time/saving (s)                         0.00597028\n",
      "time/training (s)                       2.49587\n",
      "time/epoch (s)                         19.5721\n",
      "time/total (s)                       5277.41\n",
      "Epoch                                 295\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:04:38.090042 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 296 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 307000\n",
      "trainer/ZF1 Loss                       -5.40529\n",
      "trainer/ZF2 Loss                       -1.76412\n",
      "trainer/ZF Expert Reward               15.7721\n",
      "trainer/ZF Policy Reward                3.48439\n",
      "trainer/ZF CHI2 Term                   41.3702\n",
      "trainer/Policy Loss                  -839.364\n",
      "trainer/Bias Loss                      51.3807\n",
      "trainer/Bias Value                     14.4887\n",
      "trainer/Policy Grad Norm              135\n",
      "trainer/Policy Param Norm              40.2525\n",
      "trainer/Zf1 Grad Norm                1058.43\n",
      "trainer/Zf1 Param Norm                128.598\n",
      "trainer/Zf2 Grad Norm                 988.104\n",
      "trainer/Zf2 Param Norm                131.459\n",
      "trainer/Z Expert Predictions Mean     948.193\n",
      "trainer/Z Expert Predictions Std       50.8084\n",
      "trainer/Z Expert Predictions Max     1042.51\n",
      "trainer/Z Expert Predictions Min      655.424\n",
      "trainer/Z Policy Predictions Mean     837.697\n",
      "trainer/Z Policy Predictions Std      240.819\n",
      "trainer/Z Policy Predictions Max     1016.05\n",
      "trainer/Z Policy Predictions Min     -445.61\n",
      "trainer/Z Expert Targets Mean         932.421\n",
      "trainer/Z Expert Targets Std           53.3295\n",
      "trainer/Z Expert Targets Max         1027.69\n",
      "trainer/Z Expert Targets Min          611.918\n",
      "trainer/Z Policy Targets Mean         834.213\n",
      "trainer/Z Policy Targets Std          238.334\n",
      "trainer/Z Policy Targets Max         1005.93\n",
      "trainer/Z Policy Targets Min         -441.603\n",
      "trainer/Log Pis Mean                   32.9972\n",
      "trainer/Log Pis Std                     5.91168\n",
      "trainer/Policy mu Mean                  0.0726936\n",
      "trainer/Policy mu Std                   1.36341\n",
      "trainer/Policy log std Mean            -4.69622\n",
      "trainer/Policy log std Std              0.940076\n",
      "exploration/num steps total        301368\n",
      "exploration/num paths total           430\n",
      "evaluation/num steps total              2.64973e+06\n",
      "evaluation/num paths total           3036\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.6738\n",
      "evaluation/Rewards Std                  1.03041\n",
      "evaluation/Rewards Max                  6.89391\n",
      "evaluation/Rewards Min                 -2.51519\n",
      "evaluation/Returns Mean              4673.8\n",
      "evaluation/Returns Std                109.886\n",
      "evaluation/Returns Max               4785.28\n",
      "evaluation/Returns Min               4459.81\n",
      "evaluation/Estimation Bias Mean       869.27\n",
      "evaluation/Estimation Bias Std        149.503\n",
      "evaluation/EB/Q_True Mean              43.8733\n",
      "evaluation/EB/Q_True Std              135.384\n",
      "evaluation/EB/Q_Pred Mean             913.144\n",
      "evaluation/EB/Q_Pred Std               58.6932\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4673.8\n",
      "evaluation/Actions Mean                 0.0255694\n",
      "evaluation/Actions Std                  0.535866\n",
      "evaluation/Actions Max                  0.999974\n",
      "evaluation/Actions Min                 -0.999974\n",
      "time/backward_policy (s)                2.04679\n",
      "time/backward_zf1 (s)                   2.2492\n",
      "time/backward_zf2 (s)                   2.13123\n",
      "time/data sampling (s)                  0.391858\n",
      "time/data storing (s)                   0.0153443\n",
      "time/evaluation sampling (s)            1.71113\n",
      "time/exploration sampling (s)           0.329847\n",
      "time/logging (s)                        0.0120233\n",
      "time/preback_alpha (s)                  0.639152\n",
      "time/preback_policy (s)                 1.1738\n",
      "time/preback_start (s)                  0.158747\n",
      "time/preback_zf (s)                     5.31684\n",
      "time/saving (s)                         0.00631536\n",
      "time/training (s)                       2.47623\n",
      "time/epoch (s)                         18.6585\n",
      "time/total (s)                       5296.09\n",
      "Epoch                                 296\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:04:57.516089 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 297 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 308000\n",
      "trainer/ZF1 Loss                        4.52666\n",
      "trainer/ZF2 Loss                       10.7615\n",
      "trainer/ZF Expert Reward               12.7251\n",
      "trainer/ZF Policy Reward                1.37366\n",
      "trainer/ZF CHI2 Term                   51.499\n",
      "trainer/Policy Loss                  -848.665\n",
      "trainer/Bias Loss                      69.2458\n",
      "trainer/Bias Value                     14.4549\n",
      "trainer/Policy Grad Norm              128.347\n",
      "trainer/Policy Param Norm              40.2786\n",
      "trainer/Zf1 Grad Norm                1474.43\n",
      "trainer/Zf1 Param Norm                128.752\n",
      "trainer/Zf2 Grad Norm                1341.72\n",
      "trainer/Zf2 Param Norm                131.602\n",
      "trainer/Z Expert Predictions Mean     937.265\n",
      "trainer/Z Expert Predictions Std       55.2338\n",
      "trainer/Z Expert Predictions Max     1025.2\n",
      "trainer/Z Expert Predictions Min      631.72\n",
      "trainer/Z Policy Predictions Mean     843.841\n",
      "trainer/Z Policy Predictions Std      233.564\n",
      "trainer/Z Policy Predictions Max     1009.05\n",
      "trainer/Z Policy Predictions Min     -473.784\n",
      "trainer/Z Expert Targets Mean         924.539\n",
      "trainer/Z Expert Targets Std           56.736\n",
      "trainer/Z Expert Targets Max         1011.82\n",
      "trainer/Z Expert Targets Min          608.816\n",
      "trainer/Z Policy Targets Mean         842.467\n",
      "trainer/Z Policy Targets Std          229.278\n",
      "trainer/Z Policy Targets Max         1009.18\n",
      "trainer/Z Policy Targets Min         -445.057\n",
      "trainer/Log Pis Mean                   32.8319\n",
      "trainer/Log Pis Std                     5.82597\n",
      "trainer/Policy mu Mean                  0.034725\n",
      "trainer/Policy mu Std                   1.44823\n",
      "trainer/Policy log std Mean            -4.74357\n",
      "trainer/Policy log std Std              0.915781\n",
      "exploration/num steps total        302368\n",
      "exploration/num paths total           431\n",
      "evaluation/num steps total              2.65973e+06\n",
      "evaluation/num paths total           3046\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.62384\n",
      "evaluation/Rewards Std                  2.72852\n",
      "evaluation/Rewards Max                  7.05011\n",
      "evaluation/Rewards Min                 -3.67158\n",
      "evaluation/Returns Mean              3623.84\n",
      "evaluation/Returns Std               2240.53\n",
      "evaluation/Returns Max               4750.1\n",
      "evaluation/Returns Min              -2461.76\n",
      "evaluation/Estimation Bias Mean       793.669\n",
      "evaluation/Estimation Bias Std        233.218\n",
      "evaluation/EB/Q_True Mean              41.574\n",
      "evaluation/EB/Q_True Std              128.319\n",
      "evaluation/EB/Q_Pred Mean             835.243\n",
      "evaluation/EB/Q_Pred Std              211.485\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3623.84\n",
      "evaluation/Actions Mean                 0.0163579\n",
      "evaluation/Actions Std                  0.619616\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.1957\n",
      "time/backward_zf1 (s)                   2.42764\n",
      "time/backward_zf2 (s)                   2.30578\n",
      "time/data sampling (s)                  0.401324\n",
      "time/data storing (s)                   0.0174127\n",
      "time/evaluation sampling (s)            1.6949\n",
      "time/exploration sampling (s)           0.350993\n",
      "time/logging (s)                        0.0131015\n",
      "time/preback_alpha (s)                  0.663231\n",
      "time/preback_policy (s)                 1.24979\n",
      "time/preback_start (s)                  0.16453\n",
      "time/preback_zf (s)                     5.40284\n",
      "time/saving (s)                         0.00643864\n",
      "time/training (s)                       2.45563\n",
      "time/epoch (s)                         19.3493\n",
      "time/total (s)                       5315.46\n",
      "Epoch                                 297\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:05:16.640742 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 298 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 309000\n",
      "trainer/ZF1 Loss                       -0.939125\n",
      "trainer/ZF2 Loss                       -3.4371\n",
      "trainer/ZF Expert Reward               11.4878\n",
      "trainer/ZF Policy Reward               -1.81093\n",
      "trainer/ZF CHI2 Term                   44.1765\n",
      "trainer/Policy Loss                  -808.575\n",
      "trainer/Bias Loss                      62.356\n",
      "trainer/Bias Value                     14.4675\n",
      "trainer/Policy Grad Norm              162.879\n",
      "trainer/Policy Param Norm              40.3052\n",
      "trainer/Zf1 Grad Norm                1948.94\n",
      "trainer/Zf1 Param Norm                128.892\n",
      "trainer/Zf2 Grad Norm                1290.05\n",
      "trainer/Zf2 Param Norm                131.748\n",
      "trainer/Z Expert Predictions Mean     940.272\n",
      "trainer/Z Expert Predictions Std       45.4485\n",
      "trainer/Z Expert Predictions Max     1024.44\n",
      "trainer/Z Expert Predictions Min      727.072\n",
      "trainer/Z Policy Predictions Mean     802.554\n",
      "trainer/Z Policy Predictions Std      287.467\n",
      "trainer/Z Policy Predictions Max     1039.73\n",
      "trainer/Z Policy Predictions Min     -465.769\n",
      "trainer/Z Expert Targets Mean         928.784\n",
      "trainer/Z Expert Targets Std           46.8857\n",
      "trainer/Z Expert Targets Max         1014.39\n",
      "trainer/Z Expert Targets Min          724.913\n",
      "trainer/Z Policy Targets Mean         804.365\n",
      "trainer/Z Policy Targets Std          283.101\n",
      "trainer/Z Policy Targets Max         1024.72\n",
      "trainer/Z Policy Targets Min         -464.767\n",
      "trainer/Log Pis Mean                   33.3999\n",
      "trainer/Log Pis Std                     7.55289\n",
      "trainer/Policy mu Mean                  0.0018876\n",
      "trainer/Policy mu Std                   1.70389\n",
      "trainer/Policy log std Mean            -4.54859\n",
      "trainer/Policy log std Std              1.08791\n",
      "exploration/num steps total        305368\n",
      "exploration/num paths total           434\n",
      "evaluation/num steps total              2.66973e+06\n",
      "evaluation/num paths total           3056\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.52275\n",
      "evaluation/Rewards Std                  1.01398\n",
      "evaluation/Rewards Max                  6.86403\n",
      "evaluation/Rewards Min                 -2.59114\n",
      "evaluation/Returns Mean              4522.75\n",
      "evaluation/Returns Std                 93.1225\n",
      "evaluation/Returns Max               4622.37\n",
      "evaluation/Returns Min               4357.02\n",
      "evaluation/Estimation Bias Mean       867.635\n",
      "evaluation/Estimation Bias Std        146.031\n",
      "evaluation/EB/Q_True Mean              42.4584\n",
      "evaluation/EB/Q_True Std              130.918\n",
      "evaluation/EB/Q_Pred Mean             910.093\n",
      "evaluation/EB/Q_Pred Std               61.4185\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4522.75\n",
      "evaluation/Actions Mean                 0.0196474\n",
      "evaluation/Actions Std                  0.540323\n",
      "evaluation/Actions Max                  0.999975\n",
      "evaluation/Actions Min                 -0.999979\n",
      "time/backward_policy (s)                2.19695\n",
      "time/backward_zf1 (s)                   2.38457\n",
      "time/backward_zf2 (s)                   2.26174\n",
      "time/data sampling (s)                  0.364961\n",
      "time/data storing (s)                   0.0152932\n",
      "time/evaluation sampling (s)            1.69486\n",
      "time/exploration sampling (s)           0.341035\n",
      "time/logging (s)                        0.0127467\n",
      "time/preback_alpha (s)                  0.639712\n",
      "time/preback_policy (s)                 1.22313\n",
      "time/preback_start (s)                  0.160304\n",
      "time/preback_zf (s)                     5.33287\n",
      "time/saving (s)                         0.00651672\n",
      "time/training (s)                       2.39598\n",
      "time/epoch (s)                         19.0307\n",
      "time/total (s)                       5334.53\n",
      "Epoch                                 298\n",
      "---------------------------------  ----------------\n",
      "2024-06-10 22:05:35.937603 +0330 | [idsac_ant_normal-iqn-neutral_2024_06_10_20_36_09_0000--s-0] Epoch 299 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 310000\n",
      "trainer/ZF1 Loss                       -1.49961\n",
      "trainer/ZF2 Loss                       -4.86156\n",
      "trainer/ZF Expert Reward               10.3031\n",
      "trainer/ZF Policy Reward               -0.803421\n",
      "trainer/ZF CHI2 Term                   40.7936\n",
      "trainer/Policy Loss                  -822.089\n",
      "trainer/Bias Loss                      64.6409\n",
      "trainer/Bias Value                     14.4621\n",
      "trainer/Policy Grad Norm              184.954\n",
      "trainer/Policy Param Norm              40.3326\n",
      "trainer/Zf1 Grad Norm                1649.23\n",
      "trainer/Zf1 Param Norm                129.01\n",
      "trainer/Zf2 Grad Norm                1589.84\n",
      "trainer/Zf2 Param Norm                131.879\n",
      "trainer/Z Expert Predictions Mean     938.812\n",
      "trainer/Z Expert Predictions Std       47.5332\n",
      "trainer/Z Expert Predictions Max     1031.13\n",
      "trainer/Z Expert Predictions Min      635.314\n",
      "trainer/Z Policy Predictions Mean     816.85\n",
      "trainer/Z Policy Predictions Std      274.55\n",
      "trainer/Z Policy Predictions Max      999.915\n",
      "trainer/Z Policy Predictions Min     -454.608\n",
      "trainer/Z Expert Targets Mean         928.509\n",
      "trainer/Z Expert Targets Std           49.6703\n",
      "trainer/Z Expert Targets Max         1026.29\n",
      "trainer/Z Expert Targets Min          619.63\n",
      "trainer/Z Policy Targets Mean         817.654\n",
      "trainer/Z Policy Targets Std          271.611\n",
      "trainer/Z Policy Targets Max         1006.56\n",
      "trainer/Z Policy Targets Min         -437.537\n",
      "trainer/Log Pis Mean                   33.1997\n",
      "trainer/Log Pis Std                     6.81717\n",
      "trainer/Policy mu Mean                  0.0438676\n",
      "trainer/Policy mu Std                   1.58293\n",
      "trainer/Policy log std Mean            -4.67895\n",
      "trainer/Policy log std Std              0.96782\n",
      "exploration/num steps total        305368\n",
      "exploration/num paths total           434\n",
      "evaluation/num steps total              2.67973e+06\n",
      "evaluation/num paths total           3066\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 3.9309\n",
      "evaluation/Rewards Std                  2.38831\n",
      "evaluation/Rewards Max                  7.10471\n",
      "evaluation/Rewards Min                 -3.28787\n",
      "evaluation/Returns Mean              3930.9\n",
      "evaluation/Returns Std               2175.23\n",
      "evaluation/Returns Max               4871.53\n",
      "evaluation/Returns Min              -2587.19\n",
      "evaluation/Estimation Bias Mean       813.615\n",
      "evaluation/Estimation Bias Std        199.527\n",
      "evaluation/EB/Q_True Mean              41.9833\n",
      "evaluation/EB/Q_True Std              129.883\n",
      "evaluation/EB/Q_Pred Mean             855.599\n",
      "evaluation/EB/Q_Pred Std              165.189\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3930.9\n",
      "evaluation/Actions Mean                 0.0274717\n",
      "evaluation/Actions Std                  0.594846\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.18602\n",
      "time/backward_zf1 (s)                   2.43447\n",
      "time/backward_zf2 (s)                   2.29739\n",
      "time/data sampling (s)                  0.387685\n",
      "time/data storing (s)                   0.0164711\n",
      "time/evaluation sampling (s)            1.73217\n",
      "time/exploration sampling (s)           0.33729\n",
      "time/logging (s)                        0.0117611\n",
      "time/preback_alpha (s)                  0.645579\n",
      "time/preback_policy (s)                 1.22763\n",
      "time/preback_start (s)                  0.162616\n",
      "time/preback_zf (s)                     5.3716\n",
      "time/saving (s)                         0.00626604\n",
      "time/training (s)                       2.39195\n",
      "time/epoch (s)                         19.2089\n",
      "time/total (s)                       5353.77\n",
      "Epoch                                 299\n",
      "---------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    experiment(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6679a-5037-44ff-a459-897c0ee8c8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

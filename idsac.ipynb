{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd095125-6be1-4c22-8760-d1fba60ab86d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## experiment (tqc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603bc9d-5ced-4410-9d8b-bc74345fd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_tqc(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant['layer_size']\n",
    "    num_quantiles = variant['num_quantiles']\n",
    "    n_nets = variant['n_nets']\n",
    "    \n",
    "    zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    target_zf = Critic(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "        n_nets=n_nets,\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = TruncIDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        zf=zf,\n",
    "        target_zf=target_zf,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b40f96-5af4-4fc9-8f5d-34bacdc440d8",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df783e4e-ddf6-45d9-8b26-6863e89107f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.data_management.torch_replay_buffer import TorchReplayBuffer\n",
    "from rlkit.envs import make_env\n",
    "from rlkit.envs.vecenv import SubprocVectorEnv, VectorEnv\n",
    "from rlkit.launchers.launcher_util import set_seed, setup_logger\n",
    "from rlkit.samplers.data_collector import (VecMdpPathCollector, VecMdpStepCollector)\n",
    "from rlkit.torch.idsac.idsac import IDSACTrainer\n",
    "from rlkit.torch.idsac.networks import QuantileMlp, Critic, softmax\n",
    "from rlkit.torch.networks import FlattenMlp\n",
    "from rlkit.torch.sac.policies import MakeDeterministic, TanhGaussianPolicy\n",
    "from rlkit.torch.torch_iq_algorithm import TorchVecOnlineIQAlgorithm\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba84c8-f8f8-4272-8885-83a6c028ee37",
   "metadata": {},
   "source": [
    "# experiment (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c847e24-53fa-4f9b-850b-c7b648d30304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant[\"layer_size\"]\n",
    "    num_quantiles = variant[\"num_quantiles\"]\n",
    "    tau_type = variant[\"trainer_kwargs\"][\"tau_type\"]\n",
    "    \n",
    "    zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    target_policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M],\n",
    "    )\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "        zf1,\n",
    "        tau_type,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = IDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        target_policy=target_policy,\n",
    "        zf1=zf1,\n",
    "        zf2=zf2,\n",
    "        target_zf1=target_zf1,\n",
    "        target_zf2=target_zf2,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e380543-9ff2-4947-8cda-2f5b05957627",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fa2c3c-ae22-4830-bad1-8b99032cb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(dsac_cfg_path,\n",
    "               expert_path,\n",
    "               iq_cfg_path='configs/dsac-normal-iqn-neutral/iq.yaml',\n",
    "               cql_cfg_path='configs/dsac-normal-iqn-neutral/cql.yaml'\n",
    "              ):\n",
    "    \n",
    "    with open(dsac_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        variant = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    with open(iq_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        iq_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    with open(cql_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        cql_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    iq_cfg['expert_path'] = expert_path\n",
    "    variant['iq_kwargs'] = iq_cfg\n",
    "    variant['cql_kwargs'] = cql_cfg\n",
    "    return variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40faac3-2a8c-49fc-bece-f891df61d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = get_config(dsac_cfg_path='configs/dsac-normal-iqn-neutral/walker2d.yaml',\n",
    "                     expert_path='experts/Walker2d-v2_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00203431-e8bc-4e42-977f-298ec40d51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-25 17:52:08.166971 +0330 | Variant:\n",
      "2024-06-25 17:52:08.168613 +0330 | {\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"min_num_steps_before_training\": 10000,\n",
      "    \"num_epochs\": 300,\n",
      "    \"num_eval_paths_per_epoch\": 10,\n",
      "    \"num_expl_steps_per_train_loop\": 1000,\n",
      "    \"num_trains_per_train_loop\": 1000\n",
      "  },\n",
      "  \"env\": \"Walker2d-v2\",\n",
      "  \"seed\": 1,\n",
      "  \"expectation_z\": false,\n",
      "  \"eval_env_num\": 10,\n",
      "  \"expl_env_num\": 10,\n",
      "  \"layer_size\": 256,\n",
      "  \"num_quantiles\": 24,\n",
      "  \"replay_buffer_size\": 1000000,\n",
      "  \"trainer_kwargs\": {\n",
      "    \"alpha\": 0.01,\n",
      "    \"discount\": 0.99,\n",
      "    \"policy_lr\": 5e-05,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"tau_type\": \"iqn\",\n",
      "    \"use_automatic_entropy_tuning\": false,\n",
      "    \"zf_lr\": 0.0003,\n",
      "    \"bias\": 10,\n",
      "    \"bias_lr\": 1e-05,\n",
      "    \"use_automatic_bias_tuning\": true\n",
      "  },\n",
      "  \"version\": \"normal-iqn-neutral\",\n",
      "  \"iq_kwargs\": {\n",
      "    \"expert_path\": \"experts/Walker2d-v2_25.pkl\",\n",
      "    \"subsample_freq\": 1,\n",
      "    \"demos\": 10,\n",
      "    \"regularize\": true,\n",
      "    \"div\": null,\n",
      "    \"loss\": \"value_policy\",\n",
      "    \"alpha\": 2.5\n",
      "  },\n",
      "  \"cql_kwargs\": {\n",
      "    \"use_cql\": false,\n",
      "    \"cql_weight\": 0.05,\n",
      "    \"num_random\": 10,\n",
      "    \"with_lagrange\": false,\n",
      "    \"lagrange_thresh\": 10.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    ptu.set_gpu_mode(True, 0)\n",
    "    # device = torch.device('cuda:0')\n",
    "seed = variant[\"seed\"]\n",
    "set_seed(seed)\n",
    "log_prefix = \"_\".join([\"idsac\", variant[\"env\"][:-3].lower(), str(variant[\"version\"])])\n",
    "setup_logger(log_prefix, variant=variant, seed=seed)\n",
    "variant[\"device\"] = ptu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9e0ac-93fd-4003-bfd1-29f851badba5",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa21b2b4-9bf0-4965-91a7-ff8ca706fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddie/venvs/IQ/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-25 17:52:26.479390 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 0 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 11000\n",
      "trainer/ZF1 Loss                       5.12026\n",
      "trainer/ZF2 Loss                       5.16746\n",
      "trainer/ZF Expert Reward              -0.0369947\n",
      "trainer/ZF Policy Reward              -0.00487712\n",
      "trainer/ZF CHI2 Term                   5.07079\n",
      "trainer/Policy Loss                    0.298124\n",
      "trainer/Bias Loss                     50.4596\n",
      "trainer/Bias Value                     9.99999\n",
      "trainer/Policy Grad Norm               0.0497191\n",
      "trainer/Policy Param Norm             13.5685\n",
      "trainer/Zf1 Grad Norm                 17.6143\n",
      "trainer/Zf1 Param Norm                32.0882\n",
      "trainer/Zf2 Grad Norm                 16.6687\n",
      "trainer/Zf2 Param Norm                32.0647\n",
      "trainer/Z Expert Predictions Mean     -0.282249\n",
      "trainer/Z Expert Predictions Std       0.158273\n",
      "trainer/Z Expert Predictions Max       0.220318\n",
      "trainer/Z Expert Predictions Min      -0.835251\n",
      "trainer/Z Policy Predictions Mean     -0.305537\n",
      "trainer/Z Policy Predictions Std       0.14995\n",
      "trainer/Z Policy Predictions Max       0.259233\n",
      "trainer/Z Policy Predictions Min      -0.838001\n",
      "trainer/Z Expert Targets Mean         -0.245254\n",
      "trainer/Z Expert Targets Std           0.329694\n",
      "trainer/Z Expert Targets Max           0.588299\n",
      "trainer/Z Expert Targets Min          -1.1432\n",
      "trainer/Z Policy Targets Mean         -0.30066\n",
      "trainer/Z Policy Targets Std           0.38099\n",
      "trainer/Z Policy Targets Max           0.531405\n",
      "trainer/Z Policy Targets Min          -1.37592\n",
      "trainer/Log Pis Mean                  -4.09457\n",
      "trainer/Log Pis Std                    0.558732\n",
      "trainer/Policy mu Mean                 0.00033057\n",
      "trainer/Policy mu Std                  0.00101015\n",
      "trainer/Policy log std Mean           -0.000606922\n",
      "trainer/Policy log std Std             0.00156444\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        10529\n",
      "exploration/num paths total          507\n",
      "evaluation/num steps total           955\n",
      "evaluation/num paths total            10\n",
      "evaluation/path length Mean           95.5\n",
      "evaluation/path length Std             4.45533\n",
      "evaluation/path length Max           105\n",
      "evaluation/path length Min            89\n",
      "evaluation/Rewards Mean                0.528944\n",
      "evaluation/Rewards Std                 0.254282\n",
      "evaluation/Rewards Max                 1.32669\n",
      "evaluation/Rewards Min                -0.0553886\n",
      "evaluation/Returns Mean               50.5141\n",
      "evaluation/Returns Std                 4.81104\n",
      "evaluation/Returns Max                55.8988\n",
      "evaluation/Returns Min                41.272\n",
      "evaluation/Estimation Bias Mean       -5.41626\n",
      "evaluation/Estimation Bias Std        34.7606\n",
      "evaluation/EB/Q_True Mean              1.21764\n",
      "evaluation/EB/Q_True Std               4.88483\n",
      "evaluation/EB/Q_Pred Mean             -4.19862\n",
      "evaluation/EB/Q_Pred Std              33.8569\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            50.5141\n",
      "evaluation/Actions Mean                0.654479\n",
      "evaluation/Actions Std                 0.564926\n",
      "evaluation/Actions Max                 0.999879\n",
      "evaluation/Actions Min                -0.998545\n",
      "time/backward_policy (s)               1.91016\n",
      "time/backward_zf1 (s)                  2.01189\n",
      "time/backward_zf2 (s)                  1.95775\n",
      "time/data sampling (s)                 0.189918\n",
      "time/data storing (s)                  0.0138746\n",
      "time/evaluation sampling (s)           0.17844\n",
      "time/exploration sampling (s)          0.535858\n",
      "time/logging (s)                       0.00302192\n",
      "time/preback_alpha (s)                 0.547709\n",
      "time/preback_policy (s)                1.15504\n",
      "time/preback_start (s)                 0.118906\n",
      "time/preback_zf (s)                    4.98453\n",
      "time/saving (s)                        0.00533765\n",
      "time/training (s)                      2.00371\n",
      "time/epoch (s)                        15.6161\n",
      "time/total (s)                        22.21\n",
      "Epoch                                  0\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 17:52:41.176749 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 1 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 12000\n",
      "trainer/ZF1 Loss                     -17.2026\n",
      "trainer/ZF2 Loss                     -17.5266\n",
      "trainer/ZF Expert Reward              15.2468\n",
      "trainer/ZF Policy Reward              -9.57431\n",
      "trainer/ZF CHI2 Term                   7.75711\n",
      "trainer/Policy Loss                   25.8297\n",
      "trainer/Bias Loss                     14.8386\n",
      "trainer/Bias Value                    10.0074\n",
      "trainer/Policy Grad Norm               9.61511\n",
      "trainer/Policy Param Norm             14.7538\n",
      "trainer/Zf1 Grad Norm                 39.2911\n",
      "trainer/Zf1 Param Norm                34.3923\n",
      "trainer/Zf2 Grad Norm                 57.897\n",
      "trainer/Zf2 Param Norm                34.4104\n",
      "trainer/Z Expert Predictions Mean     64.4074\n",
      "trainer/Z Expert Predictions Std       5.49417\n",
      "trainer/Z Expert Predictions Max      65.3691\n",
      "trainer/Z Expert Predictions Min      15.3561\n",
      "trainer/Z Policy Predictions Mean    -34.0795\n",
      "trainer/Z Policy Predictions Std       9.84563\n",
      "trainer/Z Policy Predictions Max      49.3303\n",
      "trainer/Z Policy Predictions Min     -41.8469\n",
      "trainer/Z Expert Targets Mean         49.1606\n",
      "trainer/Z Expert Targets Std           6.30236\n",
      "trainer/Z Expert Targets Max          50.4144\n",
      "trainer/Z Expert Targets Min          -4.59377\n",
      "trainer/Z Policy Targets Mean        -24.5052\n",
      "trainer/Z Policy Targets Std          11.6093\n",
      "trainer/Z Policy Targets Max          42.6911\n",
      "trainer/Z Policy Targets Min         -34.1896\n",
      "trainer/Log Pis Mean                  30.0594\n",
      "trainer/Log Pis Std                   10.5785\n",
      "trainer/Policy mu Mean                 2.38991\n",
      "trainer/Policy mu Std                  2.50912\n",
      "trainer/Policy log std Mean           -1.5393\n",
      "trainer/Policy log std Std             0.776923\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        11531\n",
      "exploration/num paths total          518\n",
      "evaluation/num steps total          1557\n",
      "evaluation/num paths total            20\n",
      "evaluation/path length Mean           60.2\n",
      "evaluation/path length Std             5.0951\n",
      "evaluation/path length Max            68\n",
      "evaluation/path length Min            56\n",
      "evaluation/Rewards Mean                1.14769\n",
      "evaluation/Rewards Std                 0.534694\n",
      "evaluation/Rewards Max                 2.34166\n",
      "evaluation/Rewards Min                 0.438704\n",
      "evaluation/Returns Mean               69.0909\n",
      "evaluation/Returns Std                 5.66074\n",
      "evaluation/Returns Max                77.3159\n",
      "evaluation/Returns Min                64.1147\n",
      "evaluation/Estimation Bias Mean       82.5498\n",
      "evaluation/Estimation Bias Std        42.2273\n",
      "evaluation/EB/Q_True Mean              4.24495\n",
      "evaluation/EB/Q_True Std              12.6776\n",
      "evaluation/EB/Q_Pred Mean             86.7947\n",
      "evaluation/EB/Q_Pred Std              40.6902\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            69.0909\n",
      "evaluation/Actions Mean                0.510008\n",
      "evaluation/Actions Std                 0.643431\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.996581\n",
      "time/backward_policy (s)               1.68063\n",
      "time/backward_zf1 (s)                  1.81894\n",
      "time/backward_zf2 (s)                  1.74476\n",
      "time/data sampling (s)                 0.188184\n",
      "time/data storing (s)                  0.013414\n",
      "time/evaluation sampling (s)           0.117962\n",
      "time/exploration sampling (s)          0.196906\n",
      "time/logging (s)                       0.00174862\n",
      "time/preback_alpha (s)                 0.538838\n",
      "time/preback_policy (s)                0.949288\n",
      "time/preback_start (s)                 0.113824\n",
      "time/preback_zf (s)                    4.94757\n",
      "time/saving (s)                        0.00641304\n",
      "time/training (s)                      2.31463\n",
      "time/epoch (s)                        14.6331\n",
      "time/total (s)                        36.8626\n",
      "Epoch                                  1\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:52:55.903480 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 2 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 13000\n",
      "trainer/ZF1 Loss                     -17.7465\n",
      "trainer/ZF2 Loss                     -17.8493\n",
      "trainer/ZF Expert Reward              17.69\n",
      "trainer/ZF Policy Reward              -9.03081\n",
      "trainer/ZF CHI2 Term                   9.19673\n",
      "trainer/Policy Loss                   23.9938\n",
      "trainer/Bias Loss                     30.7185\n",
      "trainer/Bias Value                    10.0208\n",
      "trainer/Policy Grad Norm              15.0823\n",
      "trainer/Policy Param Norm             16.0533\n",
      "trainer/Zf1 Grad Norm                 67.1078\n",
      "trainer/Zf1 Param Norm                37.1709\n",
      "trainer/Zf2 Grad Norm                 75.658\n",
      "trainer/Zf2 Param Norm                37.143\n",
      "trainer/Z Expert Predictions Mean    137.959\n",
      "trainer/Z Expert Predictions Std      13.4835\n",
      "trainer/Z Expert Predictions Max     140.806\n",
      "trainer/Z Expert Predictions Min      13.7278\n",
      "trainer/Z Policy Predictions Mean    -36.3704\n",
      "trainer/Z Policy Predictions Std      21.8636\n",
      "trainer/Z Policy Predictions Max     102.047\n",
      "trainer/Z Policy Predictions Min     -66.9546\n",
      "trainer/Z Expert Targets Mean        120.269\n",
      "trainer/Z Expert Targets Std          13.3226\n",
      "trainer/Z Expert Targets Max         123.496\n",
      "trainer/Z Expert Targets Min          -0.748699\n",
      "trainer/Z Policy Targets Mean        -27.3396\n",
      "trainer/Z Policy Targets Std          22.8153\n",
      "trainer/Z Policy Targets Max         110.801\n",
      "trainer/Z Policy Targets Min         -61.0887\n",
      "trainer/Log Pis Mean                  27.3852\n",
      "trainer/Log Pis Std                    9.76193\n",
      "trainer/Policy mu Mean                 1.78281\n",
      "trainer/Policy mu Std                  2.88788\n",
      "trainer/Policy log std Mean           -1.43483\n",
      "trainer/Policy log std Std             1.04607\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        12195\n",
      "exploration/num paths total          526\n",
      "evaluation/num steps total          2120\n",
      "evaluation/num paths total            30\n",
      "evaluation/path length Mean           56.3\n",
      "evaluation/path length Std             0.458258\n",
      "evaluation/path length Max            57\n",
      "evaluation/path length Min            56\n",
      "evaluation/Rewards Mean                0.892335\n",
      "evaluation/Rewards Std                 0.543564\n",
      "evaluation/Rewards Max                 1.96789\n",
      "evaluation/Rewards Min                 0.0523137\n",
      "evaluation/Returns Mean               50.2385\n",
      "evaluation/Returns Std                 1.00627\n",
      "evaluation/Returns Max                52.0867\n",
      "evaluation/Returns Min                49.0733\n",
      "evaluation/Estimation Bias Mean      113.758\n",
      "evaluation/Estimation Bias Std        41.6133\n",
      "evaluation/EB/Q_True Mean              2.77367\n",
      "evaluation/EB/Q_True Std               8.77577\n",
      "evaluation/EB/Q_Pred Mean            116.532\n",
      "evaluation/EB/Q_Pred Std              40.3773\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            50.2385\n",
      "evaluation/Actions Mean                0.445176\n",
      "evaluation/Actions Std                 0.583936\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.998002\n",
      "time/backward_policy (s)               1.73066\n",
      "time/backward_zf1 (s)                  1.85472\n",
      "time/backward_zf2 (s)                  1.80405\n",
      "time/data sampling (s)                 0.180922\n",
      "time/data storing (s)                  0.0131582\n",
      "time/evaluation sampling (s)           0.109908\n",
      "time/exploration sampling (s)          0.191096\n",
      "time/logging (s)                       0.00188837\n",
      "time/preback_alpha (s)                 0.531522\n",
      "time/preback_policy (s)                1.0212\n",
      "time/preback_start (s)                 0.110758\n",
      "time/preback_zf (s)                    4.94607\n",
      "time/saving (s)                        0.00660343\n",
      "time/training (s)                      2.16063\n",
      "time/epoch (s)                        14.6632\n",
      "time/total (s)                        51.5469\n",
      "Epoch                                  2\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:53:10.770273 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 3 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 14000\n",
      "trainer/ZF1 Loss                     -16.5591\n",
      "trainer/ZF2 Loss                     -16.7973\n",
      "trainer/ZF Expert Reward              18.743\n",
      "trainer/ZF Policy Reward              -8.88074\n",
      "trainer/ZF CHI2 Term                  11.1894\n",
      "trainer/Policy Loss                   19.6896\n",
      "trainer/Bias Loss                     38.9661\n",
      "trainer/Bias Value                    10.0326\n",
      "trainer/Policy Grad Norm              25.7161\n",
      "trainer/Policy Param Norm             16.5793\n",
      "trainer/Zf1 Grad Norm                111.285\n",
      "trainer/Zf1 Param Norm                39.5831\n",
      "trainer/Zf2 Grad Norm                137.003\n",
      "trainer/Zf2 Param Norm                39.6423\n",
      "trainer/Z Expert Predictions Mean    215.325\n",
      "trainer/Z Expert Predictions Std      13.082\n",
      "trainer/Z Expert Predictions Max     218.708\n",
      "trainer/Z Expert Predictions Min     111.82\n",
      "trainer/Z Policy Predictions Mean    -29.1139\n",
      "trainer/Z Policy Predictions Std      49.8867\n",
      "trainer/Z Policy Predictions Max     202.5\n",
      "trainer/Z Policy Predictions Min     -77.7857\n",
      "trainer/Z Expert Targets Mean        196.582\n",
      "trainer/Z Expert Targets Std          13.4624\n",
      "trainer/Z Expert Targets Max         200.499\n",
      "trainer/Z Expert Targets Min          78.5057\n",
      "trainer/Z Policy Targets Mean        -20.2332\n",
      "trainer/Z Policy Targets Std          49.147\n",
      "trainer/Z Policy Targets Max         194.007\n",
      "trainer/Z Policy Targets Min         -73.7633\n",
      "trainer/Log Pis Mean                  24.3824\n",
      "trainer/Log Pis Std                   11.2715\n",
      "trainer/Policy mu Mean                -0.0291336\n",
      "trainer/Policy mu Std                  2.78827\n",
      "trainer/Policy log std Mean           -2.09608\n",
      "trainer/Policy log std Std             1.43579\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        13760\n",
      "exploration/num paths total          542\n",
      "evaluation/num steps total          2705\n",
      "evaluation/num paths total            40\n",
      "evaluation/path length Mean           58.5\n",
      "evaluation/path length Std             0.921954\n",
      "evaluation/path length Max            60\n",
      "evaluation/path length Min            57\n",
      "evaluation/Rewards Mean                0.768323\n",
      "evaluation/Rewards Std                 0.591349\n",
      "evaluation/Rewards Max                 1.93071\n",
      "evaluation/Rewards Min                -0.0554811\n",
      "evaluation/Returns Mean               44.9469\n",
      "evaluation/Returns Std                 2.35741\n",
      "evaluation/Returns Max                48.7238\n",
      "evaluation/Returns Min                41.5929\n",
      "evaluation/Estimation Bias Mean       88.5268\n",
      "evaluation/Estimation Bias Std        34.4745\n",
      "evaluation/EB/Q_True Mean              2.66702\n",
      "evaluation/EB/Q_True Std               8.33632\n",
      "evaluation/EB/Q_Pred Mean             91.1938\n",
      "evaluation/EB/Q_Pred Std              33.3089\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            44.9469\n",
      "evaluation/Actions Mean                0.469602\n",
      "evaluation/Actions Std                 0.573976\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.998829\n",
      "time/backward_policy (s)               1.85577\n",
      "time/backward_zf1 (s)                  1.95646\n",
      "time/backward_zf2 (s)                  1.93494\n",
      "time/data sampling (s)                 0.181295\n",
      "time/data storing (s)                  0.0131608\n",
      "time/evaluation sampling (s)           0.101522\n",
      "time/exploration sampling (s)          0.193353\n",
      "time/logging (s)                       0.00177529\n",
      "time/preback_alpha (s)                 0.525748\n",
      "time/preback_policy (s)                1.15232\n",
      "time/preback_start (s)                 0.110474\n",
      "time/preback_zf (s)                    4.90839\n",
      "time/saving (s)                        0.00496078\n",
      "time/training (s)                      1.8635\n",
      "time/epoch (s)                        14.8037\n",
      "time/total (s)                        66.3717\n",
      "Epoch                                  3\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:53:25.586915 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 4 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 15000\n",
      "trainer/ZF1 Loss                     -16.0692\n",
      "trainer/ZF2 Loss                     -16.3485\n",
      "trainer/ZF Expert Reward              18.6389\n",
      "trainer/ZF Policy Reward              -9.00447\n",
      "trainer/ZF CHI2 Term                  11.7046\n",
      "trainer/Policy Loss                    5.69123\n",
      "trainer/Bias Loss                     40.9925\n",
      "trainer/Bias Value                    10.0434\n",
      "trainer/Policy Grad Norm              38.3959\n",
      "trainer/Policy Param Norm             17.2209\n",
      "trainer/Zf1 Grad Norm                130.356\n",
      "trainer/Zf1 Param Norm                41.6026\n",
      "trainer/Zf2 Grad Norm                155.892\n",
      "trainer/Zf2 Param Norm                41.6607\n",
      "trainer/Z Expert Predictions Mean    279.482\n",
      "trainer/Z Expert Predictions Std      38.6846\n",
      "trainer/Z Expert Predictions Max     292.49\n",
      "trainer/Z Expert Predictions Min      84.9103\n",
      "trainer/Z Policy Predictions Mean    -19.5896\n",
      "trainer/Z Policy Predictions Std      61.0581\n",
      "trainer/Z Policy Predictions Max     235.784\n",
      "trainer/Z Policy Predictions Min     -76.4546\n",
      "trainer/Z Expert Targets Mean        260.843\n",
      "trainer/Z Expert Targets Std          37.8773\n",
      "trainer/Z Expert Targets Max         274.537\n",
      "trainer/Z Expert Targets Min          63.3674\n",
      "trainer/Z Policy Targets Mean        -10.5851\n",
      "trainer/Z Policy Targets Std          61.2128\n",
      "trainer/Z Policy Targets Max         245.447\n",
      "trainer/Z Policy Targets Min         -71.5686\n",
      "trainer/Log Pis Mean                  27.0111\n",
      "trainer/Log Pis Std                   12.7115\n",
      "trainer/Policy mu Mean                 0.136903\n",
      "trainer/Policy mu Std                  3.04578\n",
      "trainer/Policy log std Mean           -2.2485\n",
      "trainer/Policy log std Std             1.63118\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        14654\n",
      "exploration/num paths total          556\n",
      "evaluation/num steps total          4211\n",
      "evaluation/num paths total            50\n",
      "evaluation/path length Mean          150.6\n",
      "evaluation/path length Std             0.916515\n",
      "evaluation/path length Max           152\n",
      "evaluation/path length Min           149\n",
      "evaluation/Rewards Mean                2.78616\n",
      "evaluation/Rewards Std                 1.63588\n",
      "evaluation/Rewards Max                 5.4614\n",
      "evaluation/Rewards Min                 0.182761\n",
      "evaluation/Returns Mean              419.596\n",
      "evaluation/Returns Std                 1.89824\n",
      "evaluation/Returns Max               422.364\n",
      "evaluation/Returns Min               415.679\n",
      "evaluation/Estimation Bias Mean      178.199\n",
      "evaluation/Estimation Bias Std       111.402\n",
      "evaluation/EB/Q_True Mean             17.1786\n",
      "evaluation/EB/Q_True Std              54.669\n",
      "evaluation/EB/Q_Pred Mean            195.377\n",
      "evaluation/EB/Q_Pred Std              96.5545\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           419.596\n",
      "evaluation/Actions Mean                0.497391\n",
      "evaluation/Actions Std                 0.651564\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.998857\n",
      "time/backward_policy (s)               1.62522\n",
      "time/backward_zf1 (s)                  1.75428\n",
      "time/backward_zf2 (s)                  1.68083\n",
      "time/data sampling (s)                 0.181635\n",
      "time/data storing (s)                  0.0135804\n",
      "time/evaluation sampling (s)           0.255077\n",
      "time/exploration sampling (s)          0.192501\n",
      "time/logging (s)                       0.00277705\n",
      "time/preback_alpha (s)                 0.537517\n",
      "time/preback_policy (s)                0.89355\n",
      "time/preback_start (s)                 0.111551\n",
      "time/preback_zf (s)                    4.98829\n",
      "time/saving (s)                        0.0050121\n",
      "time/training (s)                      2.51374\n",
      "time/epoch (s)                        14.7556\n",
      "time/total (s)                        81.1465\n",
      "Epoch                                  4\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:53:41.277482 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 5 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 16000\n",
      "trainer/ZF1 Loss                       7.08423\n",
      "trainer/ZF2 Loss                       6.5486\n",
      "trainer/ZF Expert Reward              19.2954\n",
      "trainer/ZF Policy Reward             -10.4105\n",
      "trainer/ZF CHI2 Term                  36.7912\n",
      "trainer/Policy Loss                  -12.9137\n",
      "trainer/Bias Loss                    264.177\n",
      "trainer/Bias Value                    10.0539\n",
      "trainer/Policy Grad Norm              19.357\n",
      "trainer/Policy Param Norm             17.6882\n",
      "trainer/Zf1 Grad Norm                421.078\n",
      "trainer/Zf1 Param Norm                43.2721\n",
      "trainer/Zf2 Grad Norm                278.67\n",
      "trainer/Zf2 Param Norm                43.3664\n",
      "trainer/Z Expert Predictions Mean    333.354\n",
      "trainer/Z Expert Predictions Std      66.4637\n",
      "trainer/Z Expert Predictions Max     361.238\n",
      "trainer/Z Expert Predictions Min      54.7603\n",
      "trainer/Z Policy Predictions Mean     -2.25294\n",
      "trainer/Z Policy Predictions Std      69.9888\n",
      "trainer/Z Policy Predictions Max     253.902\n",
      "trainer/Z Policy Predictions Min     -73.9157\n",
      "trainer/Z Expert Targets Mean        314.059\n",
      "trainer/Z Expert Targets Std          68.2728\n",
      "trainer/Z Expert Targets Max         343.289\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean          8.15758\n",
      "trainer/Z Policy Targets Std          71.7334\n",
      "trainer/Z Policy Targets Max         273.365\n",
      "trainer/Z Policy Targets Min         -64.4309\n",
      "trainer/Log Pis Mean                  26.8848\n",
      "trainer/Log Pis Std                   12.5346\n",
      "trainer/Policy mu Mean                 0.820231\n",
      "trainer/Policy mu Std                  3.01546\n",
      "trainer/Policy log std Mean           -2.40639\n",
      "trainer/Policy log std Std             1.47344\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        15170\n",
      "exploration/num paths total          561\n",
      "evaluation/num steps total          5504\n",
      "evaluation/num paths total            60\n",
      "evaluation/path length Mean          129.3\n",
      "evaluation/path length Std             0.9\n",
      "evaluation/path length Max           131\n",
      "evaluation/path length Min           128\n",
      "evaluation/Rewards Mean                2.65265\n",
      "evaluation/Rewards Std                 1.81466\n",
      "evaluation/Rewards Max                 5.80276\n",
      "evaluation/Rewards Min                 0.150905\n",
      "evaluation/Returns Mean              342.988\n",
      "evaluation/Returns Std                 1.39986\n",
      "evaluation/Returns Max               346.485\n",
      "evaluation/Returns Min               341.598\n",
      "evaluation/Estimation Bias Mean      156.202\n",
      "evaluation/Estimation Bias Std       108.008\n",
      "evaluation/EB/Q_True Mean             15.4015\n",
      "evaluation/EB/Q_True Std              48.866\n",
      "evaluation/EB/Q_Pred Mean            171.603\n",
      "evaluation/EB/Q_Pred Std              96.5938\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           342.988\n",
      "evaluation/Actions Mean                0.44257\n",
      "evaluation/Actions Std                 0.678269\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999973\n",
      "time/backward_policy (s)               1.92422\n",
      "time/backward_zf1 (s)                  2.02339\n",
      "time/backward_zf2 (s)                  1.99431\n",
      "time/data sampling (s)                 0.202599\n",
      "time/data storing (s)                  0.0140339\n",
      "time/evaluation sampling (s)           0.206771\n",
      "time/exploration sampling (s)          0.197478\n",
      "time/logging (s)                       0.00271006\n",
      "time/preback_alpha (s)                 0.562411\n",
      "time/preback_policy (s)                1.13457\n",
      "time/preback_start (s)                 0.119729\n",
      "time/preback_zf (s)                    5.07859\n",
      "time/saving (s)                        0.00500066\n",
      "time/training (s)                      2.16237\n",
      "time/epoch (s)                        15.6282\n",
      "time/total (s)                        96.7922\n",
      "Epoch                                  5\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:53:56.663434 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 6 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 17000\n",
      "trainer/ZF1 Loss                     -15.8764\n",
      "trainer/ZF2 Loss                     -15.3325\n",
      "trainer/ZF Expert Reward              19.1492\n",
      "trainer/ZF Policy Reward              -9.08449\n",
      "trainer/ZF CHI2 Term                  12.896\n",
      "trainer/Policy Loss                  -17.8672\n",
      "trainer/Bias Loss                     45.8435\n",
      "trainer/Bias Value                    10.0642\n",
      "trainer/Policy Grad Norm              35.057\n",
      "trainer/Policy Param Norm             17.9806\n",
      "trainer/Zf1 Grad Norm                206.892\n",
      "trainer/Zf1 Param Norm                44.8011\n",
      "trainer/Zf2 Grad Norm                230.111\n",
      "trainer/Zf2 Param Norm                44.9029\n",
      "trainer/Z Expert Predictions Mean    394.275\n",
      "trainer/Z Expert Predictions Std      78.6862\n",
      "trainer/Z Expert Predictions Max     424.985\n",
      "trainer/Z Expert Predictions Min      28.705\n",
      "trainer/Z Policy Predictions Mean      8.43254\n",
      "trainer/Z Policy Predictions Std      83.8199\n",
      "trainer/Z Policy Predictions Max     365.151\n",
      "trainer/Z Policy Predictions Min     -77.8492\n",
      "trainer/Z Expert Targets Mean        375.126\n",
      "trainer/Z Expert Targets Std          79.5649\n",
      "trainer/Z Expert Targets Max         407.269\n",
      "trainer/Z Expert Targets Min           2.96306\n",
      "trainer/Z Policy Targets Mean         17.517\n",
      "trainer/Z Policy Targets Std          82.0479\n",
      "trainer/Z Policy Targets Max         367.536\n",
      "trainer/Z Policy Targets Min         -65.4906\n",
      "trainer/Log Pis Mean                  26.6716\n",
      "trainer/Log Pis Std                   11.1211\n",
      "trainer/Policy mu Mean                 0.566513\n",
      "trainer/Policy mu Std                  2.94995\n",
      "trainer/Policy log std Mean           -2.56318\n",
      "trainer/Policy log std Std             1.82999\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        16223\n",
      "exploration/num paths total          569\n",
      "evaluation/num steps total          7666\n",
      "evaluation/num paths total            70\n",
      "evaluation/path length Mean          216.2\n",
      "evaluation/path length Std            51.0153\n",
      "evaluation/path length Max           289\n",
      "evaluation/path length Min           155\n",
      "evaluation/Rewards Mean                1.83795\n",
      "evaluation/Rewards Std                 1.28925\n",
      "evaluation/Rewards Max                 4.45539\n",
      "evaluation/Rewards Min                -2.62204\n",
      "evaluation/Returns Mean              397.366\n",
      "evaluation/Returns Std                60.2091\n",
      "evaluation/Returns Max               489.718\n",
      "evaluation/Returns Min               262.629\n",
      "evaluation/Estimation Bias Mean       69.897\n",
      "evaluation/Estimation Bias Std       102.858\n",
      "evaluation/EB/Q_True Mean             16.4345\n",
      "evaluation/EB/Q_True Std              46.2287\n",
      "evaluation/EB/Q_Pred Mean             86.3315\n",
      "evaluation/EB/Q_Pred Std             102.772\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           397.366\n",
      "evaluation/Actions Mean                0.264676\n",
      "evaluation/Actions Std                 0.726105\n",
      "evaluation/Actions Max                 0.999997\n",
      "evaluation/Actions Min                -0.999885\n",
      "time/backward_policy (s)               1.79065\n",
      "time/backward_zf1 (s)                  1.92833\n",
      "time/backward_zf2 (s)                  1.86974\n",
      "time/data sampling (s)                 0.199343\n",
      "time/data storing (s)                  0.0139135\n",
      "time/evaluation sampling (s)           0.491507\n",
      "time/exploration sampling (s)          0.197693\n",
      "time/logging (s)                       0.00441552\n",
      "time/preback_alpha (s)                 0.544853\n",
      "time/preback_policy (s)                1.06823\n",
      "time/preback_start (s)                 0.117177\n",
      "time/preback_zf (s)                    4.98394\n",
      "time/saving (s)                        0.00532134\n",
      "time/training (s)                      2.10947\n",
      "time/epoch (s)                        15.3246\n",
      "time/total (s)                       112.136\n",
      "Epoch                                  6\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:54:11.900842 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 7 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 18000\n",
      "trainer/ZF1 Loss                      61.9408\n",
      "trainer/ZF2 Loss                      62.6243\n",
      "trainer/ZF Expert Reward              23.2507\n",
      "trainer/ZF Policy Reward              -8.75021\n",
      "trainer/ZF CHI2 Term                  94.5449\n",
      "trainer/Policy Loss                  -31.4479\n",
      "trainer/Bias Loss                    854.623\n",
      "trainer/Bias Value                    10.0741\n",
      "trainer/Policy Grad Norm              63.8663\n",
      "trainer/Policy Param Norm             18.1796\n",
      "trainer/Zf1 Grad Norm                218.813\n",
      "trainer/Zf1 Param Norm                46.2235\n",
      "trainer/Zf2 Grad Norm                215.242\n",
      "trainer/Zf2 Param Norm                46.2596\n",
      "trainer/Z Expert Predictions Mean    445.874\n",
      "trainer/Z Expert Predictions Std      82.6561\n",
      "trainer/Z Expert Predictions Max     483.356\n",
      "trainer/Z Expert Predictions Min      38.5525\n",
      "trainer/Z Policy Predictions Mean     15.4302\n",
      "trainer/Z Policy Predictions Std      89.9916\n",
      "trainer/Z Policy Predictions Max     397.117\n",
      "trainer/Z Policy Predictions Min     -84.0421\n",
      "trainer/Z Expert Targets Mean        422.624\n",
      "trainer/Z Expert Targets Std          89.8287\n",
      "trainer/Z Expert Targets Max         465.426\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         24.1805\n",
      "trainer/Z Policy Targets Std          89.1838\n",
      "trainer/Z Policy Targets Max         400.332\n",
      "trainer/Z Policy Targets Min         -73.3644\n",
      "trainer/Log Pis Mean                  26.149\n",
      "trainer/Log Pis Std                    9.08136\n",
      "trainer/Policy mu Mean                 0.402713\n",
      "trainer/Policy mu Std                  2.23078\n",
      "trainer/Policy log std Mean           -3.21947\n",
      "trainer/Policy log std Std             1.68634\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        16752\n",
      "exploration/num paths total          572\n",
      "evaluation/num steps total          9219\n",
      "evaluation/num paths total            80\n",
      "evaluation/path length Mean          155.3\n",
      "evaluation/path length Std             7.97559\n",
      "evaluation/path length Max           170\n",
      "evaluation/path length Min           148\n",
      "evaluation/Rewards Mean                2.68711\n",
      "evaluation/Rewards Std                 1.61257\n",
      "evaluation/Rewards Max                 5.67112\n",
      "evaluation/Rewards Min                 0.0482239\n",
      "evaluation/Returns Mean              417.308\n",
      "evaluation/Returns Std                28.1217\n",
      "evaluation/Returns Max               467.59\n",
      "evaluation/Returns Min               388.899\n",
      "evaluation/Estimation Bias Mean      151.922\n",
      "evaluation/Estimation Bias Std       151.92\n",
      "evaluation/EB/Q_True Mean             19.2881\n",
      "evaluation/EB/Q_True Std              59.4199\n",
      "evaluation/EB/Q_Pred Mean            171.21\n",
      "evaluation/EB/Q_Pred Std             141.476\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           417.308\n",
      "evaluation/Actions Mean                0.3522\n",
      "evaluation/Actions Std                 0.646767\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999995\n",
      "time/backward_policy (s)               1.74411\n",
      "time/backward_zf1 (s)                  1.91069\n",
      "time/backward_zf2 (s)                  1.81483\n",
      "time/data sampling (s)                 0.214849\n",
      "time/data storing (s)                  0.0146698\n",
      "time/evaluation sampling (s)           0.260436\n",
      "time/exploration sampling (s)          0.201596\n",
      "time/logging (s)                       0.00279942\n",
      "time/preback_alpha (s)                 0.551396\n",
      "time/preback_policy (s)                1.0232\n",
      "time/preback_start (s)                 0.119495\n",
      "time/preback_zf (s)                    5.03326\n",
      "time/saving (s)                        0.00512189\n",
      "time/training (s)                      2.27333\n",
      "time/epoch (s)                        15.1698\n",
      "time/total (s)                       127.327\n",
      "Epoch                                  7\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:54:27.381521 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 8 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 19000\n",
      "trainer/ZF1 Loss                     125.308\n",
      "trainer/ZF2 Loss                     124.932\n",
      "trainer/ZF Expert Reward              24.4697\n",
      "trainer/ZF Policy Reward             -10.9139\n",
      "trainer/ZF CHI2 Term                 160.777\n",
      "trainer/Policy Loss                  -38.515\n",
      "trainer/Bias Loss                   1484.24\n",
      "trainer/Bias Value                    10.0841\n",
      "trainer/Policy Grad Norm              32.8095\n",
      "trainer/Policy Param Norm             18.475\n",
      "trainer/Zf1 Grad Norm                786.379\n",
      "trainer/Zf1 Param Norm                47.5794\n",
      "trainer/Zf2 Grad Norm                522.556\n",
      "trainer/Zf2 Param Norm                47.5371\n",
      "trainer/Z Expert Predictions Mean    506.624\n",
      "trainer/Z Expert Predictions Std      66.4684\n",
      "trainer/Z Expert Predictions Max     539.836\n",
      "trainer/Z Expert Predictions Min      56.0403\n",
      "trainer/Z Policy Predictions Mean     25.3206\n",
      "trainer/Z Policy Predictions Std      94.5572\n",
      "trainer/Z Policy Predictions Max     391.082\n",
      "trainer/Z Policy Predictions Min     -87.4538\n",
      "trainer/Z Expert Targets Mean        482.154\n",
      "trainer/Z Expert Targets Std          82.731\n",
      "trainer/Z Expert Targets Max         521.604\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         36.2345\n",
      "trainer/Z Policy Targets Std          94.9741\n",
      "trainer/Z Policy Targets Max         393.702\n",
      "trainer/Z Policy Targets Min         -81.4288\n",
      "trainer/Log Pis Mean                  27.3583\n",
      "trainer/Log Pis Std                   10.2578\n",
      "trainer/Policy mu Mean                 0.488641\n",
      "trainer/Policy mu Std                  2.34163\n",
      "trainer/Policy log std Mean           -3.3077\n",
      "trainer/Policy log std Std             1.67806\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        17859\n",
      "exploration/num paths total          577\n",
      "evaluation/num steps total         10106\n",
      "evaluation/num paths total            90\n",
      "evaluation/path length Mean           88.7\n",
      "evaluation/path length Std             3.57911\n",
      "evaluation/path length Max            96\n",
      "evaluation/path length Min            84\n",
      "evaluation/Rewards Mean                0.645972\n",
      "evaluation/Rewards Std                 0.26531\n",
      "evaluation/Rewards Max                 1.71114\n",
      "evaluation/Rewards Min                -0.063256\n",
      "evaluation/Returns Mean               57.2978\n",
      "evaluation/Returns Std                 5.02304\n",
      "evaluation/Returns Max                66.7033\n",
      "evaluation/Returns Min                51.8679\n",
      "evaluation/Estimation Bias Mean      -38.4955\n",
      "evaluation/Estimation Bias Std        60.6719\n",
      "evaluation/EB/Q_True Mean              2.86755\n",
      "evaluation/EB/Q_True Std               9.08194\n",
      "evaluation/EB/Q_Pred Mean            -35.6279\n",
      "evaluation/EB/Q_Pred Std              60.7031\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns            57.2978\n",
      "evaluation/Actions Mean                0.430762\n",
      "evaluation/Actions Std                 0.645462\n",
      "evaluation/Actions Max                 0.999997\n",
      "evaluation/Actions Min                -0.997795\n",
      "time/backward_policy (s)               1.86977\n",
      "time/backward_zf1 (s)                  1.96827\n",
      "time/backward_zf2 (s)                  1.9108\n",
      "time/data sampling (s)                 0.224686\n",
      "time/data storing (s)                  0.0138443\n",
      "time/evaluation sampling (s)           0.15054\n",
      "time/exploration sampling (s)          0.200584\n",
      "time/logging (s)                       0.00222207\n",
      "time/preback_alpha (s)                 0.566731\n",
      "time/preback_policy (s)                1.08461\n",
      "time/preback_start (s)                 0.121034\n",
      "time/preback_zf (s)                    5.06857\n",
      "time/saving (s)                        0.00515168\n",
      "time/training (s)                      2.22443\n",
      "time/epoch (s)                        15.4112\n",
      "time/total (s)                       142.761\n",
      "Epoch                                  8\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:54:43.198134 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 9 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 20000\n",
      "trainer/ZF1 Loss                      -5.45333\n",
      "trainer/ZF2 Loss                      -7.48728\n",
      "trainer/ZF Expert Reward              18.4297\n",
      "trainer/ZF Policy Reward             -10.1828\n",
      "trainer/ZF CHI2 Term                  22.4165\n",
      "trainer/Policy Loss                  -48.1367\n",
      "trainer/Bias Loss                     61.0775\n",
      "trainer/Bias Value                    10.094\n",
      "trainer/Policy Grad Norm              88.2842\n",
      "trainer/Policy Param Norm             18.8931\n",
      "trainer/Zf1 Grad Norm                347.899\n",
      "trainer/Zf1 Param Norm                48.9203\n",
      "trainer/Zf2 Grad Norm                407.874\n",
      "trainer/Zf2 Param Norm                48.8475\n",
      "trainer/Z Expert Predictions Mean    545.872\n",
      "trainer/Z Expert Predictions Std      74.3653\n",
      "trainer/Z Expert Predictions Max     593.716\n",
      "trainer/Z Expert Predictions Min      87.0631\n",
      "trainer/Z Policy Predictions Mean     38.2459\n",
      "trainer/Z Policy Predictions Std     116.918\n",
      "trainer/Z Policy Predictions Max     481.484\n",
      "trainer/Z Policy Predictions Min     -97.098\n",
      "trainer/Z Expert Targets Mean        527.443\n",
      "trainer/Z Expert Targets Std          74.0147\n",
      "trainer/Z Expert Targets Max         575.833\n",
      "trainer/Z Expert Targets Min          85.0046\n",
      "trainer/Z Policy Targets Mean         48.4287\n",
      "trainer/Z Policy Targets Std         116.331\n",
      "trainer/Z Policy Targets Max         494.755\n",
      "trainer/Z Policy Targets Min         -95.123\n",
      "trainer/Log Pis Mean                  27.4338\n",
      "trainer/Log Pis Std                    9.83826\n",
      "trainer/Policy mu Mean                 0.721509\n",
      "trainer/Policy mu Std                  2.44215\n",
      "trainer/Policy log std Mean           -3.03861\n",
      "trainer/Policy log std Std             1.58775\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        18714\n",
      "exploration/num paths total          583\n",
      "evaluation/num steps total         12519\n",
      "evaluation/num paths total           100\n",
      "evaluation/path length Mean          241.3\n",
      "evaluation/path length Std            24.1415\n",
      "evaluation/path length Max           261\n",
      "evaluation/path length Min           172\n",
      "evaluation/Rewards Mean                2.31542\n",
      "evaluation/Rewards Std                 1.20023\n",
      "evaluation/Rewards Max                 5.61049\n",
      "evaluation/Rewards Min                -0.365547\n",
      "evaluation/Returns Mean              558.712\n",
      "evaluation/Returns Std                36.5076\n",
      "evaluation/Returns Max               598.383\n",
      "evaluation/Returns Min               454.876\n",
      "evaluation/Estimation Bias Mean      141.276\n",
      "evaluation/Estimation Bias Std       231.788\n",
      "evaluation/EB/Q_True Mean             17.2349\n",
      "evaluation/EB/Q_True Std              55.1275\n",
      "evaluation/EB/Q_Pred Mean            158.511\n",
      "evaluation/EB/Q_Pred Std             230.015\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           558.712\n",
      "evaluation/Actions Mean                0.326173\n",
      "evaluation/Actions Std                 0.735777\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.88997\n",
      "time/backward_zf1 (s)                  1.99182\n",
      "time/backward_zf2 (s)                  1.95112\n",
      "time/data sampling (s)                 0.218614\n",
      "time/data storing (s)                  0.0138909\n",
      "time/evaluation sampling (s)           0.457509\n",
      "time/exploration sampling (s)          0.201539\n",
      "time/logging (s)                       0.00441728\n",
      "time/preback_alpha (s)                 0.55017\n",
      "time/preback_policy (s)                1.08013\n",
      "time/preback_start (s)                 0.120009\n",
      "time/preback_zf (s)                    5.04993\n",
      "time/saving (s)                        0.00557701\n",
      "time/training (s)                      2.22114\n",
      "time/epoch (s)                        15.7558\n",
      "time/total (s)                       158.535\n",
      "Epoch                                  9\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:54:58.761120 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 10 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 21000\n",
      "trainer/ZF1 Loss                      -6.61856\n",
      "trainer/ZF2 Loss                      -6.39704\n",
      "trainer/ZF Expert Reward              17.2186\n",
      "trainer/ZF Policy Reward             -11.2019\n",
      "trainer/ZF CHI2 Term                  22.1928\n",
      "trainer/Policy Loss                  -44.9782\n",
      "trainer/Bias Loss                     78.4195\n",
      "trainer/Bias Value                    10.1039\n",
      "trainer/Policy Grad Norm              90.8885\n",
      "trainer/Policy Param Norm             19.1849\n",
      "trainer/Zf1 Grad Norm                718.938\n",
      "trainer/Zf1 Param Norm                50.1667\n",
      "trainer/Zf2 Grad Norm                628.467\n",
      "trainer/Zf2 Param Norm                50.0511\n",
      "trainer/Z Expert Predictions Mean    553.832\n",
      "trainer/Z Expert Predictions Std     112.476\n",
      "trainer/Z Expert Predictions Max     635.287\n",
      "trainer/Z Expert Predictions Min      38.0352\n",
      "trainer/Z Policy Predictions Mean     32.0371\n",
      "trainer/Z Policy Predictions Std     121.992\n",
      "trainer/Z Policy Predictions Max     527.579\n",
      "trainer/Z Policy Predictions Min    -118.108\n",
      "trainer/Z Expert Targets Mean        536.613\n",
      "trainer/Z Expert Targets Std         112.29\n",
      "trainer/Z Expert Targets Max         618.218\n",
      "trainer/Z Expert Targets Min          23.4414\n",
      "trainer/Z Policy Targets Mean         43.239\n",
      "trainer/Z Policy Targets Std         123.328\n",
      "trainer/Z Policy Targets Max         528.489\n",
      "trainer/Z Policy Targets Min        -107.163\n",
      "trainer/Log Pis Mean                  28.016\n",
      "trainer/Log Pis Std                    9.21344\n",
      "trainer/Policy mu Mean                 0.950627\n",
      "trainer/Policy mu Std                  2.39921\n",
      "trainer/Policy log std Mean           -3.12988\n",
      "trainer/Policy log std Std             1.37804\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        20135\n",
      "exploration/num paths total          590\n",
      "evaluation/num steps total         14289\n",
      "evaluation/num paths total           110\n",
      "evaluation/path length Mean          177\n",
      "evaluation/path length Std             5.93296\n",
      "evaluation/path length Max           184\n",
      "evaluation/path length Min           165\n",
      "evaluation/Rewards Mean                2.25133\n",
      "evaluation/Rewards Std                 1.27835\n",
      "evaluation/Rewards Max                 5.75922\n",
      "evaluation/Rewards Min                 0.379162\n",
      "evaluation/Returns Mean              398.486\n",
      "evaluation/Returns Std                16.6594\n",
      "evaluation/Returns Max               422.924\n",
      "evaluation/Returns Min               366.848\n",
      "evaluation/Estimation Bias Mean      241.195\n",
      "evaluation/Estimation Bias Std       204.033\n",
      "evaluation/EB/Q_True Mean             14.8209\n",
      "evaluation/EB/Q_True Std              48.3424\n",
      "evaluation/EB/Q_Pred Mean            256.016\n",
      "evaluation/EB/Q_Pred Std             202.761\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           398.486\n",
      "evaluation/Actions Mean                0.510012\n",
      "evaluation/Actions Std                 0.625382\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.79973\n",
      "time/backward_zf1 (s)                  1.96706\n",
      "time/backward_zf2 (s)                  1.89042\n",
      "time/data sampling (s)                 0.223105\n",
      "time/data storing (s)                  0.0140405\n",
      "time/evaluation sampling (s)           0.28384\n",
      "time/exploration sampling (s)          0.2027\n",
      "time/logging (s)                       0.00306936\n",
      "time/preback_alpha (s)                 0.55527\n",
      "time/preback_policy (s)                1.04001\n",
      "time/preback_start (s)                 0.120351\n",
      "time/preback_zf (s)                    5.07142\n",
      "time/saving (s)                        0.00528158\n",
      "time/training (s)                      2.31992\n",
      "time/epoch (s)                        15.4962\n",
      "time/total (s)                       174.052\n",
      "Epoch                                 10\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:55:14.453855 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 11 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 22000\n",
      "trainer/ZF1 Loss                       0.417746\n",
      "trainer/ZF2 Loss                      -0.810177\n",
      "trainer/ZF Expert Reward              17.1789\n",
      "trainer/ZF Policy Reward             -12.1655\n",
      "trainer/ZF CHI2 Term                  29.4454\n",
      "trainer/Policy Loss                  -44.9334\n",
      "trainer/Bias Loss                    124.88\n",
      "trainer/Bias Value                    10.1137\n",
      "trainer/Policy Grad Norm              44.4782\n",
      "trainer/Policy Param Norm             19.3842\n",
      "trainer/Zf1 Grad Norm               1123.95\n",
      "trainer/Zf1 Param Norm                51.2412\n",
      "trainer/Zf2 Grad Norm               1275.51\n",
      "trainer/Zf2 Param Norm                51.1466\n",
      "trainer/Z Expert Predictions Mean    559.763\n",
      "trainer/Z Expert Predictions Std     112.028\n",
      "trainer/Z Expert Predictions Max     666.311\n",
      "trainer/Z Expert Predictions Min      13.5539\n",
      "trainer/Z Policy Predictions Mean     34.2558\n",
      "trainer/Z Policy Predictions Std     127.681\n",
      "trainer/Z Policy Predictions Max     546.516\n",
      "trainer/Z Policy Predictions Min    -126.381\n",
      "trainer/Z Expert Targets Mean        542.584\n",
      "trainer/Z Expert Targets Std         111.209\n",
      "trainer/Z Expert Targets Max         649.168\n",
      "trainer/Z Expert Targets Min          33.4192\n",
      "trainer/Z Policy Targets Mean         46.4213\n",
      "trainer/Z Policy Targets Std         129.666\n",
      "trainer/Z Policy Targets Max         544.877\n",
      "trainer/Z Policy Targets Min        -125.346\n",
      "trainer/Log Pis Mean                  29.7295\n",
      "trainer/Log Pis Std                   10.4605\n",
      "trainer/Policy mu Mean                 1.24436\n",
      "trainer/Policy mu Std                  2.60815\n",
      "trainer/Policy log std Mean           -2.99355\n",
      "trainer/Policy log std Std             1.43989\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        20993\n",
      "exploration/num paths total          594\n",
      "evaluation/num steps total         16381\n",
      "evaluation/num paths total           120\n",
      "evaluation/path length Mean          209.2\n",
      "evaluation/path length Std            46.5614\n",
      "evaluation/path length Max           280\n",
      "evaluation/path length Min           166\n",
      "evaluation/Rewards Mean                2.69668\n",
      "evaluation/Rewards Std                 1.40443\n",
      "evaluation/Rewards Max                 5.83751\n",
      "evaluation/Rewards Min                 0.121843\n",
      "evaluation/Returns Mean              564.146\n",
      "evaluation/Returns Std               120.566\n",
      "evaluation/Returns Max               725.538\n",
      "evaluation/Returns Min               391.909\n",
      "evaluation/Estimation Bias Mean      233.522\n",
      "evaluation/Estimation Bias Std       207.934\n",
      "evaluation/EB/Q_True Mean             25.0822\n",
      "evaluation/EB/Q_True Std              68.6279\n",
      "evaluation/EB/Q_Pred Mean            258.604\n",
      "evaluation/EB/Q_Pred Std             204.952\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           564.146\n",
      "evaluation/Actions Mean                0.366887\n",
      "evaluation/Actions Std                 0.66645\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999978\n",
      "time/backward_policy (s)               1.79557\n",
      "time/backward_zf1 (s)                  1.92908\n",
      "time/backward_zf2 (s)                  1.87671\n",
      "time/data sampling (s)                 0.228025\n",
      "time/data storing (s)                  0.0148211\n",
      "time/evaluation sampling (s)           0.435146\n",
      "time/exploration sampling (s)          0.210891\n",
      "time/logging (s)                       0.00378296\n",
      "time/preback_alpha (s)                 0.559421\n",
      "time/preback_policy (s)                1.01529\n",
      "time/preback_start (s)                 0.123564\n",
      "time/preback_zf (s)                    5.04843\n",
      "time/saving (s)                        0.00578178\n",
      "time/training (s)                      2.38105\n",
      "time/epoch (s)                        15.6276\n",
      "time/total (s)                       189.7\n",
      "Epoch                                 11\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:55:30.006280 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 12 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 23000\n",
      "trainer/ZF1 Loss                      89.3436\n",
      "trainer/ZF2 Loss                      91.2737\n",
      "trainer/ZF Expert Reward              25.2577\n",
      "trainer/ZF Policy Reward              -5.9754\n",
      "trainer/ZF CHI2 Term                 121.831\n",
      "trainer/Policy Loss                  -49.2463\n",
      "trainer/Bias Loss                   1020.66\n",
      "trainer/Bias Value                    10.1234\n",
      "trainer/Policy Grad Norm              63.7867\n",
      "trainer/Policy Param Norm             19.6087\n",
      "trainer/Zf1 Grad Norm                747.909\n",
      "trainer/Zf1 Param Norm                52.0316\n",
      "trainer/Zf2 Grad Norm                814.423\n",
      "trainer/Zf2 Param Norm                51.8947\n",
      "trainer/Z Expert Predictions Mean    507.954\n",
      "trainer/Z Expert Predictions Std     110.34\n",
      "trainer/Z Expert Predictions Max     681.963\n",
      "trainer/Z Expert Predictions Min      -4.0886\n",
      "trainer/Z Policy Predictions Mean     42.2304\n",
      "trainer/Z Policy Predictions Std     150.789\n",
      "trainer/Z Policy Predictions Max     540.696\n",
      "trainer/Z Policy Predictions Min    -137.51\n",
      "trainer/Z Expert Targets Mean        482.697\n",
      "trainer/Z Expert Targets Std         115.921\n",
      "trainer/Z Expert Targets Max         668.503\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean         48.2058\n",
      "trainer/Z Policy Targets Std         148.25\n",
      "trainer/Z Policy Targets Max         546.297\n",
      "trainer/Z Policy Targets Min        -137.205\n",
      "trainer/Log Pis Mean                  28.9255\n",
      "trainer/Log Pis Std                   10.6387\n",
      "trainer/Policy mu Mean                 1.16861\n",
      "trainer/Policy mu Std                  2.78255\n",
      "trainer/Policy log std Mean           -2.60037\n",
      "trainer/Policy log std Std             1.60604\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        22423\n",
      "exploration/num paths total          602\n",
      "evaluation/num steps total         17948\n",
      "evaluation/num paths total           130\n",
      "evaluation/path length Mean          156.7\n",
      "evaluation/path length Std             0.781025\n",
      "evaluation/path length Max           158\n",
      "evaluation/path length Min           156\n",
      "evaluation/Rewards Mean                2.94978\n",
      "evaluation/Rewards Std                 1.7428\n",
      "evaluation/Rewards Max                 5.85766\n",
      "evaluation/Rewards Min                 0.155719\n",
      "evaluation/Returns Mean              462.231\n",
      "evaluation/Returns Std                 3.27647\n",
      "evaluation/Returns Max               468.082\n",
      "evaluation/Returns Min               456.43\n",
      "evaluation/Estimation Bias Mean      260.554\n",
      "evaluation/Estimation Bias Std       220.011\n",
      "evaluation/EB/Q_True Mean             18.6634\n",
      "evaluation/EB/Q_True Std              59.5353\n",
      "evaluation/EB/Q_Pred Mean            279.218\n",
      "evaluation/EB/Q_Pred Std             217.059\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           462.231\n",
      "evaluation/Actions Mean                0.370283\n",
      "evaluation/Actions Std                 0.649649\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999989\n",
      "time/backward_policy (s)               1.86285\n",
      "time/backward_zf1 (s)                  2.00238\n",
      "time/backward_zf2 (s)                  1.92233\n",
      "time/data sampling (s)                 0.228386\n",
      "time/data storing (s)                  0.0137307\n",
      "time/evaluation sampling (s)           0.255492\n",
      "time/exploration sampling (s)          0.200784\n",
      "time/logging (s)                       0.00337046\n",
      "time/preback_alpha (s)                 0.555388\n",
      "time/preback_policy (s)                1.10115\n",
      "time/preback_start (s)                 0.121752\n",
      "time/preback_zf (s)                    5.04849\n",
      "time/saving (s)                        0.00536866\n",
      "time/training (s)                      2.1633\n",
      "time/epoch (s)                        15.4848\n",
      "time/total (s)                       205.208\n",
      "Epoch                                 12\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:55:45.260796 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 13 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 24000\n",
      "trainer/ZF1 Loss                       6.12843\n",
      "trainer/ZF2 Loss                       1.87479\n",
      "trainer/ZF Expert Reward              14.8818\n",
      "trainer/ZF Policy Reward             -12.0185\n",
      "trainer/ZF CHI2 Term                  31.1826\n",
      "trainer/Policy Loss                  -63.015\n",
      "trainer/Bias Loss                    107.512\n",
      "trainer/Bias Value                    10.133\n",
      "trainer/Policy Grad Norm              78.6648\n",
      "trainer/Policy Param Norm             19.8966\n",
      "trainer/Zf1 Grad Norm               1750.62\n",
      "trainer/Zf1 Param Norm                52.6718\n",
      "trainer/Zf2 Grad Norm               1242.17\n",
      "trainer/Zf2 Param Norm                52.4914\n",
      "trainer/Z Expert Predictions Mean    480.298\n",
      "trainer/Z Expert Predictions Std     128.546\n",
      "trainer/Z Expert Predictions Max     684.273\n",
      "trainer/Z Expert Predictions Min       3.37294\n",
      "trainer/Z Policy Predictions Mean     49.322\n",
      "trainer/Z Policy Predictions Std     161.757\n",
      "trainer/Z Policy Predictions Max     532.238\n",
      "trainer/Z Policy Predictions Min    -155.608\n",
      "trainer/Z Expert Targets Mean        465.416\n",
      "trainer/Z Expert Targets Std         127.619\n",
      "trainer/Z Expert Targets Max         668.416\n",
      "trainer/Z Expert Targets Min          10.0541\n",
      "trainer/Z Policy Targets Mean         61.3405\n",
      "trainer/Z Policy Targets Std         161.868\n",
      "trainer/Z Policy Targets Max         531.638\n",
      "trainer/Z Policy Targets Min        -151.07\n",
      "trainer/Log Pis Mean                  28.065\n",
      "trainer/Log Pis Std                   10.7481\n",
      "trainer/Policy mu Mean                 1.32154\n",
      "trainer/Policy mu Std                  2.53808\n",
      "trainer/Policy log std Mean           -2.73107\n",
      "trainer/Policy log std Std             1.72942\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        23064\n",
      "exploration/num paths total          606\n",
      "evaluation/num steps total         19444\n",
      "evaluation/num paths total           140\n",
      "evaluation/path length Mean          149.6\n",
      "evaluation/path length Std             0.8\n",
      "evaluation/path length Max           151\n",
      "evaluation/path length Min           148\n",
      "evaluation/Rewards Mean                2.90363\n",
      "evaluation/Rewards Std                 1.84879\n",
      "evaluation/Rewards Max                 5.59682\n",
      "evaluation/Rewards Min                 0.0613599\n",
      "evaluation/Returns Mean              434.383\n",
      "evaluation/Returns Std                 1.80545\n",
      "evaluation/Returns Max               436.945\n",
      "evaluation/Returns Min               430.17\n",
      "evaluation/Estimation Bias Mean      285.664\n",
      "evaluation/Estimation Bias Std       213.676\n",
      "evaluation/EB/Q_True Mean             18.0731\n",
      "evaluation/EB/Q_True Std              57.3559\n",
      "evaluation/EB/Q_Pred Mean            303.738\n",
      "evaluation/EB/Q_Pred Std             210.763\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           434.383\n",
      "evaluation/Actions Mean                0.383263\n",
      "evaluation/Actions Std                 0.6284\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999998\n",
      "time/backward_policy (s)               1.77927\n",
      "time/backward_zf1 (s)                  1.90851\n",
      "time/backward_zf2 (s)                  1.8446\n",
      "time/data sampling (s)                 0.216288\n",
      "time/data storing (s)                  0.0141613\n",
      "time/evaluation sampling (s)           0.240365\n",
      "time/exploration sampling (s)          0.199333\n",
      "time/logging (s)                       0.00305547\n",
      "time/preback_alpha (s)                 0.550334\n",
      "time/preback_policy (s)                1.02055\n",
      "time/preback_start (s)                 0.121044\n",
      "time/preback_zf (s)                    5.00231\n",
      "time/saving (s)                        0.00526195\n",
      "time/training (s)                      2.27595\n",
      "time/epoch (s)                        15.181\n",
      "time/total (s)                       220.418\n",
      "Epoch                                 13\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:56:00.569325 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 14 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 25000\n",
      "trainer/ZF1 Loss                       1.90755\n",
      "trainer/ZF2 Loss                       1.51252\n",
      "trainer/ZF Expert Reward              17.3614\n",
      "trainer/ZF Policy Reward              -8.20697\n",
      "trainer/ZF CHI2 Term                  27.5687\n",
      "trainer/Policy Loss                 -102.319\n",
      "trainer/Bias Loss                    119.95\n",
      "trainer/Bias Value                    10.1426\n",
      "trainer/Policy Grad Norm              68.2724\n",
      "trainer/Policy Param Norm             20.1541\n",
      "trainer/Zf1 Grad Norm                865.538\n",
      "trainer/Zf1 Param Norm                53.2091\n",
      "trainer/Zf2 Grad Norm                590.798\n",
      "trainer/Zf2 Param Norm                52.9833\n",
      "trainer/Z Expert Predictions Mean    438.474\n",
      "trainer/Z Expert Predictions Std     157.056\n",
      "trainer/Z Expert Predictions Max     673.007\n",
      "trainer/Z Expert Predictions Min      82.7122\n",
      "trainer/Z Policy Predictions Mean     89.869\n",
      "trainer/Z Policy Predictions Std     199.985\n",
      "trainer/Z Policy Predictions Max     540.187\n",
      "trainer/Z Policy Predictions Min    -165.276\n",
      "trainer/Z Expert Targets Mean        421.112\n",
      "trainer/Z Expert Targets Std         156.61\n",
      "trainer/Z Expert Targets Max         658.182\n",
      "trainer/Z Expert Targets Min          54.7744\n",
      "trainer/Z Policy Targets Mean         98.076\n",
      "trainer/Z Policy Targets Std         198.974\n",
      "trainer/Z Policy Targets Max         542.732\n",
      "trainer/Z Policy Targets Min        -159.665\n",
      "trainer/Log Pis Mean                  29.0371\n",
      "trainer/Log Pis Std                   10.2793\n",
      "trainer/Policy mu Mean                 1.50008\n",
      "trainer/Policy mu Std                  2.6151\n",
      "trainer/Policy log std Mean           -2.77976\n",
      "trainer/Policy log std Std             1.61407\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        24111\n",
      "exploration/num paths total          613\n",
      "evaluation/num steps total         20780\n",
      "evaluation/num paths total           150\n",
      "evaluation/path length Mean          133.6\n",
      "evaluation/path length Std             2.05913\n",
      "evaluation/path length Max           137\n",
      "evaluation/path length Min           131\n",
      "evaluation/Rewards Mean                2.89948\n",
      "evaluation/Rewards Std                 1.98546\n",
      "evaluation/Rewards Max                 6.56048\n",
      "evaluation/Rewards Min                 0.217055\n",
      "evaluation/Returns Mean              387.37\n",
      "evaluation/Returns Std                 7.64529\n",
      "evaluation/Returns Max               399.152\n",
      "evaluation/Returns Min               376.416\n",
      "evaluation/Estimation Bias Mean      284.529\n",
      "evaluation/Estimation Bias Std       218.892\n",
      "evaluation/EB/Q_True Mean             17.6375\n",
      "evaluation/EB/Q_True Std              55.5842\n",
      "evaluation/EB/Q_Pred Mean            302.166\n",
      "evaluation/EB/Q_Pred Std             216.076\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           387.37\n",
      "evaluation/Actions Mean                0.361205\n",
      "evaluation/Actions Std                 0.634407\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.79811\n",
      "time/backward_zf1 (s)                  1.93603\n",
      "time/backward_zf2 (s)                  1.86822\n",
      "time/data sampling (s)                 0.218428\n",
      "time/data storing (s)                  0.0141847\n",
      "time/evaluation sampling (s)           0.211014\n",
      "time/exploration sampling (s)          0.20223\n",
      "time/logging (s)                       0.00255446\n",
      "time/preback_alpha (s)                 0.554811\n",
      "time/preback_policy (s)                1.04948\n",
      "time/preback_start (s)                 0.121763\n",
      "time/preback_zf (s)                    5.01554\n",
      "time/saving (s)                        0.00513595\n",
      "time/training (s)                      2.24312\n",
      "time/epoch (s)                        15.2406\n",
      "time/total (s)                       235.681\n",
      "Epoch                                 14\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:56:16.365509 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 15 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 26000\n",
      "trainer/ZF1 Loss                       8.86325\n",
      "trainer/ZF2 Loss                       9.10594\n",
      "trainer/ZF Expert Reward              18.4696\n",
      "trainer/ZF Policy Reward             -10.5204\n",
      "trainer/ZF CHI2 Term                  38.2747\n",
      "trainer/Policy Loss                 -113.605\n",
      "trainer/Bias Loss                    176.504\n",
      "trainer/Bias Value                    10.1522\n",
      "trainer/Policy Grad Norm              38.438\n",
      "trainer/Policy Param Norm             20.4106\n",
      "trainer/Zf1 Grad Norm               1038.8\n",
      "trainer/Zf1 Param Norm                53.5944\n",
      "trainer/Zf2 Grad Norm                794.516\n",
      "trainer/Zf2 Param Norm                53.3844\n",
      "trainer/Z Expert Predictions Mean    350.074\n",
      "trainer/Z Expert Predictions Std     151.926\n",
      "trainer/Z Expert Predictions Max     622.371\n",
      "trainer/Z Expert Predictions Min      56.6415\n",
      "trainer/Z Policy Predictions Mean     96.1259\n",
      "trainer/Z Policy Predictions Std     195.44\n",
      "trainer/Z Policy Predictions Max     526.876\n",
      "trainer/Z Policy Predictions Min    -171.111\n",
      "trainer/Z Expert Targets Mean        331.604\n",
      "trainer/Z Expert Targets Std         152.154\n",
      "trainer/Z Expert Targets Max         601.892\n",
      "trainer/Z Expert Targets Min          34.4137\n",
      "trainer/Z Policy Targets Mean        106.646\n",
      "trainer/Z Policy Targets Std         194.565\n",
      "trainer/Z Policy Targets Max         525.224\n",
      "trainer/Z Policy Targets Min        -161.473\n",
      "trainer/Log Pis Mean                  30.0004\n",
      "trainer/Log Pis Std                   10.4886\n",
      "trainer/Policy mu Mean                 1.72621\n",
      "trainer/Policy mu Std                  2.86828\n",
      "trainer/Policy log std Mean           -2.80997\n",
      "trainer/Policy log std Std             1.44196\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        25331\n",
      "exploration/num paths total          622\n",
      "evaluation/num steps total         22155\n",
      "evaluation/num paths total           160\n",
      "evaluation/path length Mean          137.5\n",
      "evaluation/path length Std             2.97489\n",
      "evaluation/path length Max           142\n",
      "evaluation/path length Min           132\n",
      "evaluation/Rewards Mean                2.84315\n",
      "evaluation/Rewards Std                 1.97027\n",
      "evaluation/Rewards Max                 6.99007\n",
      "evaluation/Rewards Min                -0.347237\n",
      "evaluation/Returns Mean              390.934\n",
      "evaluation/Returns Std                17.127\n",
      "evaluation/Returns Max               425.827\n",
      "evaluation/Returns Min               375.17\n",
      "evaluation/Estimation Bias Mean      290.15\n",
      "evaluation/Estimation Bias Std       201.558\n",
      "evaluation/EB/Q_True Mean             18.6692\n",
      "evaluation/EB/Q_True Std              58.7573\n",
      "evaluation/EB/Q_Pred Mean            308.819\n",
      "evaluation/EB/Q_Pred Std             196.948\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           390.934\n",
      "evaluation/Actions Mean                0.38532\n",
      "evaluation/Actions Std                 0.619894\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.93617\n",
      "time/backward_zf1 (s)                  2.07127\n",
      "time/backward_zf2 (s)                  2.02148\n",
      "time/data sampling (s)                 0.224627\n",
      "time/data storing (s)                  0.0140019\n",
      "time/evaluation sampling (s)           0.223317\n",
      "time/exploration sampling (s)          0.203459\n",
      "time/logging (s)                       0.0027807\n",
      "time/preback_alpha (s)                 0.568372\n",
      "time/preback_policy (s)                1.14962\n",
      "time/preback_start (s)                 0.123508\n",
      "time/preback_zf (s)                    5.06176\n",
      "time/saving (s)                        0.00532248\n",
      "time/training (s)                      2.12651\n",
      "time/epoch (s)                        15.7322\n",
      "time/total (s)                       251.432\n",
      "Epoch                                 15\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:56:31.847893 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 16 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 27000\n",
      "trainer/ZF1 Loss                       9.42033\n",
      "trainer/ZF2 Loss                       7.81332\n",
      "trainer/ZF Expert Reward              15.9315\n",
      "trainer/ZF Policy Reward             -11.7499\n",
      "trainer/ZF CHI2 Term                  36.5798\n",
      "trainer/Policy Loss                 -130.93\n",
      "trainer/Bias Loss                     90.7516\n",
      "trainer/Bias Value                    10.1616\n",
      "trainer/Policy Grad Norm              79.4617\n",
      "trainer/Policy Param Norm             20.687\n",
      "trainer/Zf1 Grad Norm               1424.81\n",
      "trainer/Zf1 Param Norm                53.9325\n",
      "trainer/Zf2 Grad Norm               1397.6\n",
      "trainer/Zf2 Param Norm                53.7191\n",
      "trainer/Z Expert Predictions Mean    330.759\n",
      "trainer/Z Expert Predictions Std     130.847\n",
      "trainer/Z Expert Predictions Max     571.509\n",
      "trainer/Z Expert Predictions Min      44.3957\n",
      "trainer/Z Policy Predictions Mean    111.757\n",
      "trainer/Z Policy Predictions Std     194.731\n",
      "trainer/Z Policy Predictions Max     508.558\n",
      "trainer/Z Policy Predictions Min    -156.748\n",
      "trainer/Z Expert Targets Mean        314.828\n",
      "trainer/Z Expert Targets Std         132.71\n",
      "trainer/Z Expert Targets Max         558.852\n",
      "trainer/Z Expert Targets Min          11.1055\n",
      "trainer/Z Policy Targets Mean        123.507\n",
      "trainer/Z Policy Targets Std         197.881\n",
      "trainer/Z Policy Targets Max         526.636\n",
      "trainer/Z Policy Targets Min        -147.597\n",
      "trainer/Log Pis Mean                  28.1558\n",
      "trainer/Log Pis Std                    8.97716\n",
      "trainer/Policy mu Mean                 1.425\n",
      "trainer/Policy mu Std                  2.71469\n",
      "trainer/Policy log std Mean           -2.88219\n",
      "trainer/Policy log std Std             1.43055\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        26566\n",
      "exploration/num paths total          631\n",
      "evaluation/num steps total         23596\n",
      "evaluation/num paths total           170\n",
      "evaluation/path length Mean          144.1\n",
      "evaluation/path length Std             2.07123\n",
      "evaluation/path length Max           148\n",
      "evaluation/path length Min           141\n",
      "evaluation/Rewards Mean                2.64147\n",
      "evaluation/Rewards Std                 1.84674\n",
      "evaluation/Rewards Max                 6.42938\n",
      "evaluation/Rewards Min                 0.0722384\n",
      "evaluation/Returns Mean              380.636\n",
      "evaluation/Returns Std                 7.31191\n",
      "evaluation/Returns Max               394.333\n",
      "evaluation/Returns Min               372.272\n",
      "evaluation/Estimation Bias Mean      301.064\n",
      "evaluation/Estimation Bias Std       196.486\n",
      "evaluation/EB/Q_True Mean             16.7838\n",
      "evaluation/EB/Q_True Std              53.262\n",
      "evaluation/EB/Q_Pred Mean            317.848\n",
      "evaluation/EB/Q_Pred Std             193.343\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           380.636\n",
      "evaluation/Actions Mean                0.406501\n",
      "evaluation/Actions Std                 0.598021\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.99986\n",
      "time/backward_policy (s)               1.85633\n",
      "time/backward_zf1 (s)                  1.95928\n",
      "time/backward_zf2 (s)                  1.89378\n",
      "time/data sampling (s)                 0.218475\n",
      "time/data storing (s)                  0.0136917\n",
      "time/evaluation sampling (s)           0.243724\n",
      "time/exploration sampling (s)          0.196707\n",
      "time/logging (s)                       0.00264146\n",
      "time/preback_alpha (s)                 0.561211\n",
      "time/preback_policy (s)                1.06011\n",
      "time/preback_start (s)                 0.121761\n",
      "time/preback_zf (s)                    5.03235\n",
      "time/saving (s)                        0.00530058\n",
      "time/training (s)                      2.25051\n",
      "time/epoch (s)                        15.4159\n",
      "time/total (s)                       266.87\n",
      "Epoch                                 16\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:56:47.220565 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 17 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 28000\n",
      "trainer/ZF1 Loss                       8.27385\n",
      "trainer/ZF2 Loss                       2.97614\n",
      "trainer/ZF Expert Reward              17.0647\n",
      "trainer/ZF Policy Reward              -9.03799\n",
      "trainer/ZF CHI2 Term                  32.0005\n",
      "trainer/Policy Loss                 -139.006\n",
      "trainer/Bias Loss                     86.8657\n",
      "trainer/Bias Value                    10.1711\n",
      "trainer/Policy Grad Norm             125.391\n",
      "trainer/Policy Param Norm             20.9408\n",
      "trainer/Zf1 Grad Norm               1149.95\n",
      "trainer/Zf1 Param Norm                54.2122\n",
      "trainer/Zf2 Grad Norm                678.295\n",
      "trainer/Zf2 Param Norm                53.9495\n",
      "trainer/Z Expert Predictions Mean    322.655\n",
      "trainer/Z Expert Predictions Std     126.071\n",
      "trainer/Z Expert Predictions Max     551.673\n",
      "trainer/Z Expert Predictions Min      38.266\n",
      "trainer/Z Policy Predictions Mean    120.262\n",
      "trainer/Z Policy Predictions Std     187.031\n",
      "trainer/Z Policy Predictions Max     507.226\n",
      "trainer/Z Policy Predictions Min    -124.168\n",
      "trainer/Z Expert Targets Mean        305.59\n",
      "trainer/Z Expert Targets Std         127.543\n",
      "trainer/Z Expert Targets Max         544.549\n",
      "trainer/Z Expert Targets Min          14.7309\n",
      "trainer/Z Policy Targets Mean        129.3\n",
      "trainer/Z Policy Targets Std         187.493\n",
      "trainer/Z Policy Targets Max         533.873\n",
      "trainer/Z Policy Targets Min        -115.354\n",
      "trainer/Log Pis Mean                  27.2803\n",
      "trainer/Log Pis Std                    8.175\n",
      "trainer/Policy mu Mean                 1.36206\n",
      "trainer/Policy mu Std                  2.55476\n",
      "trainer/Policy log std Mean           -2.97829\n",
      "trainer/Policy log std Std             1.48624\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        27144\n",
      "exploration/num paths total          635\n",
      "evaluation/num steps total         25224\n",
      "evaluation/num paths total           180\n",
      "evaluation/path length Mean          162.8\n",
      "evaluation/path length Std             6.73498\n",
      "evaluation/path length Max           171\n",
      "evaluation/path length Min           153\n",
      "evaluation/Rewards Mean                2.56758\n",
      "evaluation/Rewards Std                 1.58644\n",
      "evaluation/Rewards Max                 5.93226\n",
      "evaluation/Rewards Min                 0.0954916\n",
      "evaluation/Returns Mean              418.002\n",
      "evaluation/Returns Std                11.9935\n",
      "evaluation/Returns Max               432.751\n",
      "evaluation/Returns Min               399.861\n",
      "evaluation/Estimation Bias Mean      312.084\n",
      "evaluation/Estimation Bias Std       209.821\n",
      "evaluation/EB/Q_True Mean             16.9327\n",
      "evaluation/EB/Q_True Std              53.8339\n",
      "evaluation/EB/Q_Pred Mean            329.016\n",
      "evaluation/EB/Q_Pred Std             207.57\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           418.002\n",
      "evaluation/Actions Mean                0.398111\n",
      "evaluation/Actions Std                 0.616686\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999995\n",
      "time/backward_policy (s)               1.80038\n",
      "time/backward_zf1 (s)                  1.92576\n",
      "time/backward_zf2 (s)                  1.86426\n",
      "time/data sampling (s)                 0.214687\n",
      "time/data storing (s)                  0.0138238\n",
      "time/evaluation sampling (s)           0.263863\n",
      "time/exploration sampling (s)          0.19957\n",
      "time/logging (s)                       0.00296596\n",
      "time/preback_alpha (s)                 0.554752\n",
      "time/preback_policy (s)                1.04163\n",
      "time/preback_start (s)                 0.121646\n",
      "time/preback_zf (s)                    5.03478\n",
      "time/saving (s)                        0.00512977\n",
      "time/training (s)                      2.26714\n",
      "time/epoch (s)                        15.3104\n",
      "time/total (s)                       282.197\n",
      "Epoch                                 17\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:57:03.279848 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 18 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 29000\n",
      "trainer/ZF1 Loss                       8.15773\n",
      "trainer/ZF2 Loss                       4.99465\n",
      "trainer/ZF Expert Reward              19.5277\n",
      "trainer/ZF Policy Reward              -6.80835\n",
      "trainer/ZF CHI2 Term                  33.1671\n",
      "trainer/Policy Loss                 -164.553\n",
      "trainer/Bias Loss                    110.171\n",
      "trainer/Bias Value                    10.1807\n",
      "trainer/Policy Grad Norm             162.686\n",
      "trainer/Policy Param Norm             21.1868\n",
      "trainer/Zf1 Grad Norm                600.685\n",
      "trainer/Zf1 Param Norm                54.4902\n",
      "trainer/Zf2 Grad Norm                862.194\n",
      "trainer/Zf2 Param Norm                54.1613\n",
      "trainer/Z Expert Predictions Mean    303.361\n",
      "trainer/Z Expert Predictions Std     124.107\n",
      "trainer/Z Expert Predictions Max     586.687\n",
      "trainer/Z Expert Predictions Min      35.2985\n",
      "trainer/Z Policy Predictions Mean    147.419\n",
      "trainer/Z Policy Predictions Std     193.737\n",
      "trainer/Z Policy Predictions Max     570.815\n",
      "trainer/Z Policy Predictions Min     -89.1352\n",
      "trainer/Z Expert Targets Mean        283.834\n",
      "trainer/Z Expert Targets Std         126.928\n",
      "trainer/Z Expert Targets Max         580.391\n",
      "trainer/Z Expert Targets Min          13.4362\n",
      "trainer/Z Policy Targets Mean        154.227\n",
      "trainer/Z Policy Targets Std         194.457\n",
      "trainer/Z Policy Targets Max         575.357\n",
      "trainer/Z Policy Targets Min         -76.3037\n",
      "trainer/Log Pis Mean                  25.4762\n",
      "trainer/Log Pis Std                    7.62343\n",
      "trainer/Policy mu Mean                 1.09374\n",
      "trainer/Policy mu Std                  2.19992\n",
      "trainer/Policy log std Mean           -3.10623\n",
      "trainer/Policy log std Std             1.39298\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        28292\n",
      "exploration/num paths total          642\n",
      "evaluation/num steps total         26942\n",
      "evaluation/num paths total           190\n",
      "evaluation/path length Mean          171.8\n",
      "evaluation/path length Std             5.03587\n",
      "evaluation/path length Max           180\n",
      "evaluation/path length Min           164\n",
      "evaluation/Rewards Mean                2.51648\n",
      "evaluation/Rewards Std                 1.4062\n",
      "evaluation/Rewards Max                 5.80461\n",
      "evaluation/Rewards Min                 0.108167\n",
      "evaluation/Returns Mean              432.332\n",
      "evaluation/Returns Std                 8.89125\n",
      "evaluation/Returns Max               447.435\n",
      "evaluation/Returns Min               418.354\n",
      "evaluation/Estimation Bias Mean      265.721\n",
      "evaluation/Estimation Bias Std       230.261\n",
      "evaluation/EB/Q_True Mean             16.693\n",
      "evaluation/EB/Q_True Std              53.2856\n",
      "evaluation/EB/Q_Pred Mean            282.414\n",
      "evaluation/EB/Q_Pred Std             228.203\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           432.332\n",
      "evaluation/Actions Mean                0.371555\n",
      "evaluation/Actions Std                 0.626032\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999607\n",
      "time/backward_policy (s)               1.96457\n",
      "time/backward_zf1 (s)                  2.11579\n",
      "time/backward_zf2 (s)                  2.03909\n",
      "time/data sampling (s)                 0.229651\n",
      "time/data storing (s)                  0.0138389\n",
      "time/evaluation sampling (s)           0.27494\n",
      "time/exploration sampling (s)          0.201661\n",
      "time/logging (s)                       0.00291545\n",
      "time/preback_alpha (s)                 0.57907\n",
      "time/preback_policy (s)                1.15348\n",
      "time/preback_start (s)                 0.124555\n",
      "time/preback_zf (s)                    5.13869\n",
      "time/saving (s)                        0.00512366\n",
      "time/training (s)                      2.1513\n",
      "time/epoch (s)                        15.9947\n",
      "time/total (s)                       298.21\n",
      "Epoch                                 18\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:57:18.773280 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 19 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 30000\n",
      "trainer/ZF1 Loss                       2.87591\n",
      "trainer/ZF2 Loss                       0.426832\n",
      "trainer/ZF Expert Reward              18.6393\n",
      "trainer/ZF Policy Reward              -7.98471\n",
      "trainer/ZF CHI2 Term                  28.5282\n",
      "trainer/Policy Loss                 -174.027\n",
      "trainer/Bias Loss                    111.405\n",
      "trainer/Bias Value                    10.1902\n",
      "trainer/Policy Grad Norm             130.01\n",
      "trainer/Policy Param Norm             21.4026\n",
      "trainer/Zf1 Grad Norm                999.797\n",
      "trainer/Zf1 Param Norm                54.7571\n",
      "trainer/Zf2 Grad Norm                823.008\n",
      "trainer/Zf2 Param Norm                54.353\n",
      "trainer/Z Expert Predictions Mean    315.403\n",
      "trainer/Z Expert Predictions Std     124.442\n",
      "trainer/Z Expert Predictions Max     607.069\n",
      "trainer/Z Expert Predictions Min      54.2561\n",
      "trainer/Z Policy Predictions Mean    154.154\n",
      "trainer/Z Policy Predictions Std     195.053\n",
      "trainer/Z Policy Predictions Max     599.234\n",
      "trainer/Z Policy Predictions Min    -101.328\n",
      "trainer/Z Expert Targets Mean        296.764\n",
      "trainer/Z Expert Targets Std         125.662\n",
      "trainer/Z Expert Targets Max         601.247\n",
      "trainer/Z Expert Targets Min          43.7904\n",
      "trainer/Z Policy Targets Mean        162.139\n",
      "trainer/Z Policy Targets Std         195.889\n",
      "trainer/Z Policy Targets Max         593.607\n",
      "trainer/Z Policy Targets Min        -101.117\n",
      "trainer/Log Pis Mean                  25.2874\n",
      "trainer/Log Pis Std                    6.70209\n",
      "trainer/Policy mu Mean                 1.06124\n",
      "trainer/Policy mu Std                  2.13041\n",
      "trainer/Policy log std Mean           -3.15345\n",
      "trainer/Policy log std Std             1.37596\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        29055\n",
      "exploration/num paths total          646\n",
      "evaluation/num steps total         28674\n",
      "evaluation/num paths total           200\n",
      "evaluation/path length Mean          173.2\n",
      "evaluation/path length Std             9.98799\n",
      "evaluation/path length Max           200\n",
      "evaluation/path length Min           165\n",
      "evaluation/Rewards Mean                2.76977\n",
      "evaluation/Rewards Std                 1.55439\n",
      "evaluation/Rewards Max                 5.73687\n",
      "evaluation/Rewards Min                 0.125765\n",
      "evaluation/Returns Mean              479.724\n",
      "evaluation/Returns Std                31.7492\n",
      "evaluation/Returns Max               563.831\n",
      "evaluation/Returns Min               449.833\n",
      "evaluation/Estimation Bias Mean      260.033\n",
      "evaluation/Estimation Bias Std       223.554\n",
      "evaluation/EB/Q_True Mean             21.6937\n",
      "evaluation/EB/Q_True Std              65.8834\n",
      "evaluation/EB/Q_Pred Mean            281.727\n",
      "evaluation/EB/Q_Pred Std             218.658\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           479.724\n",
      "evaluation/Actions Mean                0.361417\n",
      "evaluation/Actions Std                 0.653569\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.99996\n",
      "time/backward_policy (s)               1.79397\n",
      "time/backward_zf1 (s)                  1.94127\n",
      "time/backward_zf2 (s)                  1.84619\n",
      "time/data sampling (s)                 0.224715\n",
      "time/data storing (s)                  0.0140514\n",
      "time/evaluation sampling (s)           0.355532\n",
      "time/exploration sampling (s)          0.19837\n",
      "time/logging (s)                       0.00337703\n",
      "time/preback_alpha (s)                 0.559964\n",
      "time/preback_policy (s)                1.02844\n",
      "time/preback_start (s)                 0.121153\n",
      "time/preback_zf (s)                    5.03717\n",
      "time/saving (s)                        0.00512048\n",
      "time/training (s)                      2.29882\n",
      "time/epoch (s)                        15.4281\n",
      "time/total (s)                       313.659\n",
      "Epoch                                 19\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:57:34.099987 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 20 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 31000\n",
      "trainer/ZF1 Loss                       6.41089\n",
      "trainer/ZF2 Loss                       6.14867\n",
      "trainer/ZF Expert Reward              17.3138\n",
      "trainer/ZF Policy Reward              -7.27342\n",
      "trainer/ZF CHI2 Term                  31.1297\n",
      "trainer/Policy Loss                 -188.883\n",
      "trainer/Bias Loss                     82.6007\n",
      "trainer/Bias Value                    10.1998\n",
      "trainer/Policy Grad Norm              62.2607\n",
      "trainer/Policy Param Norm             21.6277\n",
      "trainer/Zf1 Grad Norm                627.81\n",
      "trainer/Zf1 Param Norm                55.0322\n",
      "trainer/Zf2 Grad Norm               1194.04\n",
      "trainer/Zf2 Param Norm                54.5574\n",
      "trainer/Z Expert Predictions Mean    315.26\n",
      "trainer/Z Expert Predictions Std     133.271\n",
      "trainer/Z Expert Predictions Max     625.041\n",
      "trainer/Z Expert Predictions Min      72.3075\n",
      "trainer/Z Policy Predictions Mean    168.384\n",
      "trainer/Z Policy Predictions Std     183.587\n",
      "trainer/Z Policy Predictions Max     557.428\n",
      "trainer/Z Policy Predictions Min    -110.419\n",
      "trainer/Z Expert Targets Mean        297.946\n",
      "trainer/Z Expert Targets Std         134.051\n",
      "trainer/Z Expert Targets Max         609.66\n",
      "trainer/Z Expert Targets Min          34.2535\n",
      "trainer/Z Policy Targets Mean        175.658\n",
      "trainer/Z Policy Targets Std         182.801\n",
      "trainer/Z Policy Targets Max         572.035\n",
      "trainer/Z Policy Targets Min         -93.4463\n",
      "trainer/Log Pis Mean                  26.2735\n",
      "trainer/Log Pis Std                    6.69769\n",
      "trainer/Policy mu Mean                 1.05649\n",
      "trainer/Policy mu Std                  2.12653\n",
      "trainer/Policy log std Mean           -3.1835\n",
      "trainer/Policy log std Std             1.24726\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        30125\n",
      "exploration/num paths total          652\n",
      "evaluation/num steps total         30587\n",
      "evaluation/num paths total           210\n",
      "evaluation/path length Mean          191.3\n",
      "evaluation/path length Std             7.65572\n",
      "evaluation/path length Max           205\n",
      "evaluation/path length Min           176\n",
      "evaluation/Rewards Mean                3.00848\n",
      "evaluation/Rewards Std                 1.60376\n",
      "evaluation/Rewards Max                 5.89968\n",
      "evaluation/Rewards Min                 0.0974387\n",
      "evaluation/Returns Mean              575.522\n",
      "evaluation/Returns Std                31.3098\n",
      "evaluation/Returns Max               640.193\n",
      "evaluation/Returns Min               514.572\n",
      "evaluation/Estimation Bias Mean      251.787\n",
      "evaluation/Estimation Bias Std       219.954\n",
      "evaluation/EB/Q_True Mean             22.9057\n",
      "evaluation/EB/Q_True Std              71.7722\n",
      "evaluation/EB/Q_Pred Mean            274.693\n",
      "evaluation/EB/Q_Pred Std             211.945\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           575.522\n",
      "evaluation/Actions Mean                0.302021\n",
      "evaluation/Actions Std                 0.660738\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.71586\n",
      "time/backward_zf1 (s)                  1.84771\n",
      "time/backward_zf2 (s)                  1.76976\n",
      "time/data sampling (s)                 0.216378\n",
      "time/data storing (s)                  0.0136234\n",
      "time/evaluation sampling (s)           0.328243\n",
      "time/exploration sampling (s)          0.195214\n",
      "time/logging (s)                       0.00349239\n",
      "time/preback_alpha (s)                 0.552819\n",
      "time/preback_policy (s)                0.943271\n",
      "time/preback_start (s)                 0.121893\n",
      "time/preback_zf (s)                    5.04769\n",
      "time/saving (s)                        0.00551154\n",
      "time/training (s)                      2.49863\n",
      "time/epoch (s)                        15.2601\n",
      "time/total (s)                       328.942\n",
      "Epoch                                 20\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:57:49.490918 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 21 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 32000\n",
      "trainer/ZF1 Loss                      10.0757\n",
      "trainer/ZF2 Loss                       8.96571\n",
      "trainer/ZF Expert Reward              17.7929\n",
      "trainer/ZF Policy Reward              -5.22076\n",
      "trainer/ZF CHI2 Term                  32.7896\n",
      "trainer/Policy Loss                 -181.693\n",
      "trainer/Bias Loss                    139.321\n",
      "trainer/Bias Value                    10.2094\n",
      "trainer/Policy Grad Norm              81.1566\n",
      "trainer/Policy Param Norm             21.8249\n",
      "trainer/Zf1 Grad Norm                578.676\n",
      "trainer/Zf1 Param Norm                55.3595\n",
      "trainer/Zf2 Grad Norm                572.325\n",
      "trainer/Zf2 Param Norm                54.7811\n",
      "trainer/Z Expert Predictions Mean    338.254\n",
      "trainer/Z Expert Predictions Std     121.701\n",
      "trainer/Z Expert Predictions Max     624.358\n",
      "trainer/Z Expert Predictions Min      64.9147\n",
      "trainer/Z Policy Predictions Mean    165.417\n",
      "trainer/Z Policy Predictions Std     192.074\n",
      "trainer/Z Policy Predictions Max     593.754\n",
      "trainer/Z Policy Predictions Min    -114.081\n",
      "trainer/Z Expert Targets Mean        320.461\n",
      "trainer/Z Expert Targets Std         122.935\n",
      "trainer/Z Expert Targets Max         609.451\n",
      "trainer/Z Expert Targets Min          39.2273\n",
      "trainer/Z Policy Targets Mean        170.638\n",
      "trainer/Z Policy Targets Std         191.36\n",
      "trainer/Z Policy Targets Max         589.699\n",
      "trainer/Z Policy Targets Min        -112.413\n",
      "trainer/Log Pis Mean                  25.5254\n",
      "trainer/Log Pis Std                    7.85717\n",
      "trainer/Policy mu Mean                 0.930253\n",
      "trainer/Policy mu Std                  2.27763\n",
      "trainer/Policy log std Mean           -2.95274\n",
      "trainer/Policy log std Std             1.25709\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        31006\n",
      "exploration/num paths total          657\n",
      "evaluation/num steps total         32414\n",
      "evaluation/num paths total           220\n",
      "evaluation/path length Mean          182.7\n",
      "evaluation/path length Std             2.9\n",
      "evaluation/path length Max           187\n",
      "evaluation/path length Min           177\n",
      "evaluation/Rewards Mean                2.91324\n",
      "evaluation/Rewards Std                 1.64045\n",
      "evaluation/Rewards Max                 6.0053\n",
      "evaluation/Rewards Min                 0.0630218\n",
      "evaluation/Returns Mean              532.248\n",
      "evaluation/Returns Std                12.9959\n",
      "evaluation/Returns Max               552.245\n",
      "evaluation/Returns Min               510.145\n",
      "evaluation/Estimation Bias Mean      255.356\n",
      "evaluation/Estimation Bias Std       227.366\n",
      "evaluation/EB/Q_True Mean             19.8508\n",
      "evaluation/EB/Q_True Std              63.8549\n",
      "evaluation/EB/Q_Pred Mean            275.207\n",
      "evaluation/EB/Q_Pred Std             221.621\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           532.248\n",
      "evaluation/Actions Mean                0.369576\n",
      "evaluation/Actions Std                 0.630066\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999944\n",
      "time/backward_policy (s)               1.77898\n",
      "time/backward_zf1 (s)                  1.90462\n",
      "time/backward_zf2 (s)                  1.83841\n",
      "time/data sampling (s)                 0.220207\n",
      "time/data storing (s)                  0.0135652\n",
      "time/evaluation sampling (s)           0.313103\n",
      "time/exploration sampling (s)          0.193248\n",
      "time/logging (s)                       0.00349691\n",
      "time/preback_alpha (s)                 0.552835\n",
      "time/preback_policy (s)                1.02556\n",
      "time/preback_start (s)                 0.121715\n",
      "time/preback_zf (s)                    5.02569\n",
      "time/saving (s)                        0.00522459\n",
      "time/training (s)                      2.33168\n",
      "time/epoch (s)                        15.3283\n",
      "time/total (s)                       344.288\n",
      "Epoch                                 21\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:58:04.974534 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 22 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 33000\n",
      "trainer/ZF1 Loss                       1.37862\n",
      "trainer/ZF2 Loss                       2.71061\n",
      "trainer/ZF Expert Reward              17.7588\n",
      "trainer/ZF Policy Reward              -7.5399\n",
      "trainer/ZF CHI2 Term                  27.5969\n",
      "trainer/Policy Loss                 -221.547\n",
      "trainer/Bias Loss                     96.4609\n",
      "trainer/Bias Value                    10.2189\n",
      "trainer/Policy Grad Norm              64.145\n",
      "trainer/Policy Param Norm             21.9877\n",
      "trainer/Zf1 Grad Norm                770.973\n",
      "trainer/Zf1 Param Norm                55.724\n",
      "trainer/Zf2 Grad Norm               1095.76\n",
      "trainer/Zf2 Param Norm                55.0684\n",
      "trainer/Z Expert Predictions Mean    314.833\n",
      "trainer/Z Expert Predictions Std     123.767\n",
      "trainer/Z Expert Predictions Max     640.491\n",
      "trainer/Z Expert Predictions Min      70.7402\n",
      "trainer/Z Policy Predictions Mean    204.855\n",
      "trainer/Z Policy Predictions Std     190.636\n",
      "trainer/Z Policy Predictions Max     573.009\n",
      "trainer/Z Policy Predictions Min    -126.548\n",
      "trainer/Z Expert Targets Mean        297.074\n",
      "trainer/Z Expert Targets Std         124.357\n",
      "trainer/Z Expert Targets Max         628.213\n",
      "trainer/Z Expert Targets Min          48.3355\n",
      "trainer/Z Policy Targets Mean        212.395\n",
      "trainer/Z Policy Targets Std         191.391\n",
      "trainer/Z Policy Targets Max         595.156\n",
      "trainer/Z Policy Targets Min        -123.148\n",
      "trainer/Log Pis Mean                  25.3572\n",
      "trainer/Log Pis Std                    8.40053\n",
      "trainer/Policy mu Mean                 1.03705\n",
      "trainer/Policy mu Std                  2.16232\n",
      "trainer/Policy log std Mean           -3.11201\n",
      "trainer/Policy log std Std             1.21374\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        31922\n",
      "exploration/num paths total          662\n",
      "evaluation/num steps total         34148\n",
      "evaluation/num paths total           230\n",
      "evaluation/path length Mean          173.4\n",
      "evaluation/path length Std             2.498\n",
      "evaluation/path length Max           177\n",
      "evaluation/path length Min           170\n",
      "evaluation/Rewards Mean                3.02934\n",
      "evaluation/Rewards Std                 1.75272\n",
      "evaluation/Rewards Max                 6.03425\n",
      "evaluation/Rewards Min                 0.109275\n",
      "evaluation/Returns Mean              525.288\n",
      "evaluation/Returns Std                10.8373\n",
      "evaluation/Returns Max               545.538\n",
      "evaluation/Returns Min               509.565\n",
      "evaluation/Estimation Bias Mean      242.716\n",
      "evaluation/Estimation Bias Std       216.542\n",
      "evaluation/EB/Q_True Mean             19.6955\n",
      "evaluation/EB/Q_True Std              63.1796\n",
      "evaluation/EB/Q_Pred Mean            262.411\n",
      "evaluation/EB/Q_Pred Std             210.023\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           525.288\n",
      "evaluation/Actions Mean                0.357538\n",
      "evaluation/Actions Std                 0.619591\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.997623\n",
      "time/backward_policy (s)               1.75206\n",
      "time/backward_zf1 (s)                  1.91239\n",
      "time/backward_zf2 (s)                  1.82332\n",
      "time/data sampling (s)                 0.218994\n",
      "time/data storing (s)                  0.0139976\n",
      "time/evaluation sampling (s)           0.2944\n",
      "time/exploration sampling (s)          0.200497\n",
      "time/logging (s)                       0.00297687\n",
      "time/preback_alpha (s)                 0.557659\n",
      "time/preback_policy (s)                0.988576\n",
      "time/preback_start (s)                 0.123367\n",
      "time/preback_zf (s)                    5.08361\n",
      "time/saving (s)                        0.00511712\n",
      "time/training (s)                      2.44171\n",
      "time/epoch (s)                        15.4187\n",
      "time/total (s)                       359.726\n",
      "Epoch                                 22\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:58:20.730179 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 23 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 34000\n",
      "trainer/ZF1 Loss                      11.1958\n",
      "trainer/ZF2 Loss                       7.43592\n",
      "trainer/ZF Expert Reward              17.5102\n",
      "trainer/ZF Policy Reward              -8.16309\n",
      "trainer/ZF CHI2 Term                  35.2476\n",
      "trainer/Policy Loss                 -198.467\n",
      "trainer/Bias Loss                     75.3484\n",
      "trainer/Bias Value                    10.2285\n",
      "trainer/Policy Grad Norm             136.522\n",
      "trainer/Policy Param Norm             22.1398\n",
      "trainer/Zf1 Grad Norm                930.355\n",
      "trainer/Zf1 Param Norm                56.0525\n",
      "trainer/Zf2 Grad Norm                759.534\n",
      "trainer/Zf2 Param Norm                55.3539\n",
      "trainer/Z Expert Predictions Mean    299.499\n",
      "trainer/Z Expert Predictions Std     120.718\n",
      "trainer/Z Expert Predictions Max     650.26\n",
      "trainer/Z Expert Predictions Min      63.5414\n",
      "trainer/Z Policy Predictions Mean    183.549\n",
      "trainer/Z Policy Predictions Std     197.329\n",
      "trainer/Z Policy Predictions Max     659.401\n",
      "trainer/Z Policy Predictions Min     -71.3762\n",
      "trainer/Z Expert Targets Mean        281.988\n",
      "trainer/Z Expert Targets Std         121.622\n",
      "trainer/Z Expert Targets Max         644.002\n",
      "trainer/Z Expert Targets Min          48.6838\n",
      "trainer/Z Policy Targets Mean        191.712\n",
      "trainer/Z Policy Targets Std         196.688\n",
      "trainer/Z Policy Targets Max         653.679\n",
      "trainer/Z Policy Targets Min         -77.2861\n",
      "trainer/Log Pis Mean                  25.8549\n",
      "trainer/Log Pis Std                    7.7925\n",
      "trainer/Policy mu Mean                 1.26462\n",
      "trainer/Policy mu Std                  2.21156\n",
      "trainer/Policy log std Mean           -2.95218\n",
      "trainer/Policy log std Std             1.33984\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        33317\n",
      "exploration/num paths total          670\n",
      "evaluation/num steps total         36303\n",
      "evaluation/num paths total           240\n",
      "evaluation/path length Mean          215.5\n",
      "evaluation/path length Std            10.5948\n",
      "evaluation/path length Max           239\n",
      "evaluation/path length Min           199\n",
      "evaluation/Rewards Mean                3.08505\n",
      "evaluation/Rewards Std                 1.53552\n",
      "evaluation/Rewards Max                 5.84036\n",
      "evaluation/Rewards Min                 0.121385\n",
      "evaluation/Returns Mean              664.828\n",
      "evaluation/Returns Std                46.2587\n",
      "evaluation/Returns Max               767.601\n",
      "evaluation/Returns Min               598.246\n",
      "evaluation/Estimation Bias Mean      234.572\n",
      "evaluation/Estimation Bias Std       206.311\n",
      "evaluation/EB/Q_True Mean             25.8371\n",
      "evaluation/EB/Q_True Std              78.6474\n",
      "evaluation/EB/Q_Pred Mean            260.409\n",
      "evaluation/EB/Q_Pred Std             193.313\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           664.828\n",
      "evaluation/Actions Mean                0.369594\n",
      "evaluation/Actions Std                 0.636321\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999294\n",
      "time/backward_policy (s)               1.81588\n",
      "time/backward_zf1 (s)                  1.94764\n",
      "time/backward_zf2 (s)                  1.87136\n",
      "time/data sampling (s)                 0.22426\n",
      "time/data storing (s)                  0.0138811\n",
      "time/evaluation sampling (s)           0.393209\n",
      "time/exploration sampling (s)          0.200301\n",
      "time/logging (s)                       0.00393877\n",
      "time/preback_alpha (s)                 0.561928\n",
      "time/preback_policy (s)                1.04592\n",
      "time/preback_start (s)                 0.121926\n",
      "time/preback_zf (s)                    5.10532\n",
      "time/saving (s)                        0.00545435\n",
      "time/training (s)                      2.38011\n",
      "time/epoch (s)                        15.6911\n",
      "time/total (s)                       375.436\n",
      "Epoch                                 23\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:58:37.023061 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 24 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 35000\n",
      "trainer/ZF1 Loss                       0.604124\n",
      "trainer/ZF2 Loss                       1.56166\n",
      "trainer/ZF Expert Reward              19.7842\n",
      "trainer/ZF Policy Reward              -6.29632\n",
      "trainer/ZF CHI2 Term                  27.4114\n",
      "trainer/Policy Loss                 -224.399\n",
      "trainer/Bias Loss                    105.121\n",
      "trainer/Bias Value                    10.2381\n",
      "trainer/Policy Grad Norm              70.807\n",
      "trainer/Policy Param Norm             22.3438\n",
      "trainer/Zf1 Grad Norm                956.645\n",
      "trainer/Zf1 Param Norm                56.3785\n",
      "trainer/Zf2 Grad Norm                572.765\n",
      "trainer/Zf2 Param Norm                55.647\n",
      "trainer/Z Expert Predictions Mean    317.774\n",
      "trainer/Z Expert Predictions Std     109.063\n",
      "trainer/Z Expert Predictions Max     665.1\n",
      "trainer/Z Expert Predictions Min      69.7862\n",
      "trainer/Z Policy Predictions Mean    205.283\n",
      "trainer/Z Policy Predictions Std     186.973\n",
      "trainer/Z Policy Predictions Max     654.147\n",
      "trainer/Z Policy Predictions Min    -129.024\n",
      "trainer/Z Expert Targets Mean        297.99\n",
      "trainer/Z Expert Targets Std         111.546\n",
      "trainer/Z Expert Targets Max         658.22\n",
      "trainer/Z Expert Targets Min          47.5523\n",
      "trainer/Z Policy Targets Mean        211.579\n",
      "trainer/Z Policy Targets Std         187.679\n",
      "trainer/Z Policy Targets Max         658.812\n",
      "trainer/Z Policy Targets Min        -129.897\n",
      "trainer/Log Pis Mean                  24.803\n",
      "trainer/Log Pis Std                    6.60834\n",
      "trainer/Policy mu Mean                 1.19355\n",
      "trainer/Policy mu Std                  2.02846\n",
      "trainer/Policy log std Mean           -3.05069\n",
      "trainer/Policy log std Std             1.21104\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        33698\n",
      "exploration/num paths total          672\n",
      "evaluation/num steps total         38988\n",
      "evaluation/num paths total           250\n",
      "evaluation/path length Mean          268.5\n",
      "evaluation/path length Std            59.2001\n",
      "evaluation/path length Max           395\n",
      "evaluation/path length Min           221\n",
      "evaluation/Rewards Mean                2.84654\n",
      "evaluation/Rewards Std                 1.4831\n",
      "evaluation/Rewards Max                 6.03449\n",
      "evaluation/Rewards Min                -0.998767\n",
      "evaluation/Returns Mean              764.296\n",
      "evaluation/Returns Std                68.4534\n",
      "evaluation/Returns Max               909.236\n",
      "evaluation/Returns Min               689.568\n",
      "evaluation/Estimation Bias Mean      235.663\n",
      "evaluation/Estimation Bias Std       175.612\n",
      "evaluation/EB/Q_True Mean             22.1404\n",
      "evaluation/EB/Q_True Std              67.8294\n",
      "evaluation/EB/Q_Pred Mean            257.804\n",
      "evaluation/EB/Q_Pred Std             167.162\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           764.296\n",
      "evaluation/Actions Mean                0.414517\n",
      "evaluation/Actions Std                 0.635002\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999442\n",
      "time/backward_policy (s)               1.86941\n",
      "time/backward_zf1 (s)                  2.03202\n",
      "time/backward_zf2 (s)                  1.95594\n",
      "time/data sampling (s)                 0.233057\n",
      "time/data storing (s)                  0.0149608\n",
      "time/evaluation sampling (s)           0.610306\n",
      "time/exploration sampling (s)          0.199851\n",
      "time/logging (s)                       0.00696097\n",
      "time/preback_alpha (s)                 0.573257\n",
      "time/preback_policy (s)                1.07084\n",
      "time/preback_start (s)                 0.12591\n",
      "time/preback_zf (s)                    5.15719\n",
      "time/saving (s)                        0.00580911\n",
      "time/training (s)                      2.36958\n",
      "time/epoch (s)                        16.2251\n",
      "time/total (s)                       391.686\n",
      "Epoch                                 24\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:58:53.334308 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 25 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 36000\n",
      "trainer/ZF1 Loss                       1.76704\n",
      "trainer/ZF2 Loss                      -0.277851\n",
      "trainer/ZF Expert Reward              20.748\n",
      "trainer/ZF Policy Reward              -6.00271\n",
      "trainer/ZF CHI2 Term                  27.7537\n",
      "trainer/Policy Loss                 -222.551\n",
      "trainer/Bias Loss                    104.752\n",
      "trainer/Bias Value                    10.2476\n",
      "trainer/Policy Grad Norm              82.9118\n",
      "trainer/Policy Param Norm             22.543\n",
      "trainer/Zf1 Grad Norm                770.656\n",
      "trainer/Zf1 Param Norm                56.7051\n",
      "trainer/Zf2 Grad Norm                363.111\n",
      "trainer/Zf2 Param Norm                55.9318\n",
      "trainer/Z Expert Predictions Mean    330.634\n",
      "trainer/Z Expert Predictions Std     113.524\n",
      "trainer/Z Expert Predictions Max     667.317\n",
      "trainer/Z Expert Predictions Min      83.1401\n",
      "trainer/Z Policy Predictions Mean    208.76\n",
      "trainer/Z Policy Predictions Std     189.045\n",
      "trainer/Z Policy Predictions Max     608.498\n",
      "trainer/Z Policy Predictions Min     -97.0295\n",
      "trainer/Z Expert Targets Mean        309.886\n",
      "trainer/Z Expert Targets Std         114.866\n",
      "trainer/Z Expert Targets Max         655.853\n",
      "trainer/Z Expert Targets Min          60.1694\n",
      "trainer/Z Policy Targets Mean        214.762\n",
      "trainer/Z Policy Targets Std         186.922\n",
      "trainer/Z Policy Targets Max         608.648\n",
      "trainer/Z Policy Targets Min         -97.2611\n",
      "trainer/Log Pis Mean                  25.8367\n",
      "trainer/Log Pis Std                    7.85556\n",
      "trainer/Policy mu Mean                 1.35256\n",
      "trainer/Policy mu Std                  2.0799\n",
      "trainer/Policy log std Mean           -3.15162\n",
      "trainer/Policy log std Std             1.32132\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        35078\n",
      "exploration/num paths total          678\n",
      "evaluation/num steps total         41133\n",
      "evaluation/num paths total           260\n",
      "evaluation/path length Mean          214.5\n",
      "evaluation/path length Std            13.6033\n",
      "evaluation/path length Max           254\n",
      "evaluation/path length Min           203\n",
      "evaluation/Rewards Mean                3.43466\n",
      "evaluation/Rewards Std                 1.8553\n",
      "evaluation/Rewards Max                 6.33961\n",
      "evaluation/Rewards Min                 0.0434356\n",
      "evaluation/Returns Mean              736.734\n",
      "evaluation/Returns Std                48.3268\n",
      "evaluation/Returns Max               872.911\n",
      "evaluation/Returns Min               687.932\n",
      "evaluation/Estimation Bias Mean      242.567\n",
      "evaluation/Estimation Bias Std       189.706\n",
      "evaluation/EB/Q_True Mean             30.2626\n",
      "evaluation/EB/Q_True Std              88.2234\n",
      "evaluation/EB/Q_Pred Mean            272.83\n",
      "evaluation/EB/Q_Pred Std             171.691\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           736.734\n",
      "evaluation/Actions Mean                0.537344\n",
      "evaluation/Actions Std                 0.598082\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999162\n",
      "time/backward_policy (s)               1.87253\n",
      "time/backward_zf1 (s)                  2.07373\n",
      "time/backward_zf2 (s)                  1.96222\n",
      "time/data sampling (s)                 0.249446\n",
      "time/data storing (s)                  0.0144946\n",
      "time/evaluation sampling (s)           0.40113\n",
      "time/exploration sampling (s)          0.20308\n",
      "time/logging (s)                       0.00339672\n",
      "time/preback_alpha (s)                 0.58657\n",
      "time/preback_policy (s)                1.07133\n",
      "time/preback_start (s)                 0.126411\n",
      "time/preback_zf (s)                    5.20137\n",
      "time/saving (s)                        0.00529759\n",
      "time/training (s)                      2.46908\n",
      "time/epoch (s)                        16.2401\n",
      "time/total (s)                       407.946\n",
      "Epoch                                 25\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:59:10.399817 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 26 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 37000\n",
      "trainer/ZF1 Loss                       4.1094\n",
      "trainer/ZF2 Loss                       4.01328\n",
      "trainer/ZF Expert Reward              17.4902\n",
      "trainer/ZF Policy Reward              -7.02026\n",
      "trainer/ZF CHI2 Term                  28.8488\n",
      "trainer/Policy Loss                 -214.311\n",
      "trainer/Bias Loss                     85.7837\n",
      "trainer/Bias Value                    10.2573\n",
      "trainer/Policy Grad Norm              91.6034\n",
      "trainer/Policy Param Norm             22.7739\n",
      "trainer/Zf1 Grad Norm               1127.84\n",
      "trainer/Zf1 Param Norm                56.9966\n",
      "trainer/Zf2 Grad Norm                994.752\n",
      "trainer/Zf2 Param Norm                56.1342\n",
      "trainer/Z Expert Predictions Mean    333.954\n",
      "trainer/Z Expert Predictions Std     118.098\n",
      "trainer/Z Expert Predictions Max     619.901\n",
      "trainer/Z Expert Predictions Min      71.3305\n",
      "trainer/Z Policy Predictions Mean    198.181\n",
      "trainer/Z Policy Predictions Std     193.878\n",
      "trainer/Z Policy Predictions Max     619.001\n",
      "trainer/Z Policy Predictions Min    -129.071\n",
      "trainer/Z Expert Targets Mean        316.464\n",
      "trainer/Z Expert Targets Std         119.534\n",
      "trainer/Z Expert Targets Max         611.976\n",
      "trainer/Z Expert Targets Min          58.2546\n",
      "trainer/Z Policy Targets Mean        205.202\n",
      "trainer/Z Policy Targets Std         194.233\n",
      "trainer/Z Policy Targets Max         614.685\n",
      "trainer/Z Policy Targets Min        -131.743\n",
      "trainer/Log Pis Mean                  27.7\n",
      "trainer/Log Pis Std                    8.98994\n",
      "trainer/Policy mu Mean                 1.553\n",
      "trainer/Policy mu Std                  2.31145\n",
      "trainer/Policy log std Mean           -2.98069\n",
      "trainer/Policy log std Std             1.43873\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        35547\n",
      "exploration/num paths total          680\n",
      "evaluation/num steps total         43832\n",
      "evaluation/num paths total           270\n",
      "evaluation/path length Mean          269.9\n",
      "evaluation/path length Std            52.3344\n",
      "evaluation/path length Max           371\n",
      "evaluation/path length Min           219\n",
      "evaluation/Rewards Mean                2.79346\n",
      "evaluation/Rewards Std                 1.52898\n",
      "evaluation/Rewards Max                 6.27359\n",
      "evaluation/Rewards Min                -1.90341\n",
      "evaluation/Returns Mean              753.954\n",
      "evaluation/Returns Std                86.8141\n",
      "evaluation/Returns Max               915.501\n",
      "evaluation/Returns Min               661.341\n",
      "evaluation/Estimation Bias Mean      233.534\n",
      "evaluation/Estimation Bias Std       180.931\n",
      "evaluation/EB/Q_True Mean             24.188\n",
      "evaluation/EB/Q_True Std              74.8361\n",
      "evaluation/EB/Q_Pred Mean            257.722\n",
      "evaluation/EB/Q_Pred Std             172.942\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           753.954\n",
      "evaluation/Actions Mean                0.510684\n",
      "evaluation/Actions Std                 0.611559\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.99999\n",
      "time/backward_policy (s)               2.06009\n",
      "time/backward_zf1 (s)                  2.19786\n",
      "time/backward_zf2 (s)                  2.17069\n",
      "time/data sampling (s)                 0.255769\n",
      "time/data storing (s)                  0.0146637\n",
      "time/evaluation sampling (s)           0.573877\n",
      "time/exploration sampling (s)          0.207284\n",
      "time/logging (s)                       0.00397335\n",
      "time/preback_alpha (s)                 0.599469\n",
      "time/preback_policy (s)                1.18788\n",
      "time/preback_start (s)                 0.131331\n",
      "time/preback_zf (s)                    5.23598\n",
      "time/saving (s)                        0.00551855\n",
      "time/training (s)                      2.35375\n",
      "time/epoch (s)                        16.9981\n",
      "time/total (s)                       424.963\n",
      "Epoch                                 26\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:59:26.018026 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 27 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 38000\n",
      "trainer/ZF1 Loss                      -2.03417\n",
      "trainer/ZF2 Loss                       1.89989\n",
      "trainer/ZF Expert Reward              20.1831\n",
      "trainer/ZF Policy Reward              -6.00844\n",
      "trainer/ZF CHI2 Term                  26.3977\n",
      "trainer/Policy Loss                 -208.992\n",
      "trainer/Bias Loss                    104.615\n",
      "trainer/Bias Value                    10.2669\n",
      "trainer/Policy Grad Norm             179.552\n",
      "trainer/Policy Param Norm             22.9273\n",
      "trainer/Zf1 Grad Norm                509.983\n",
      "trainer/Zf1 Param Norm                57.2563\n",
      "trainer/Zf2 Grad Norm                644.119\n",
      "trainer/Zf2 Param Norm                56.4003\n",
      "trainer/Z Expert Predictions Mean    350.682\n",
      "trainer/Z Expert Predictions Std     132.169\n",
      "trainer/Z Expert Predictions Max     614.662\n",
      "trainer/Z Expert Predictions Min      86.551\n",
      "trainer/Z Policy Predictions Mean    197.854\n",
      "trainer/Z Policy Predictions Std     181.047\n",
      "trainer/Z Policy Predictions Max     595.261\n",
      "trainer/Z Policy Predictions Min    -107.474\n",
      "trainer/Z Expert Targets Mean        330.499\n",
      "trainer/Z Expert Targets Std         132.094\n",
      "trainer/Z Expert Targets Max         605.341\n",
      "trainer/Z Expert Targets Min          76.4157\n",
      "trainer/Z Policy Targets Mean        203.862\n",
      "trainer/Z Policy Targets Std         180.38\n",
      "trainer/Z Policy Targets Max         592.381\n",
      "trainer/Z Policy Targets Min        -113.242\n",
      "trainer/Log Pis Mean                  27.3323\n",
      "trainer/Log Pis Std                    7.25078\n",
      "trainer/Policy mu Mean                 1.50405\n",
      "trainer/Policy mu Std                  2.19644\n",
      "trainer/Policy log std Mean           -3.02639\n",
      "trainer/Policy log std Std             1.38757\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        36694\n",
      "exploration/num paths total          685\n",
      "evaluation/num steps total         45878\n",
      "evaluation/num paths total           280\n",
      "evaluation/path length Mean          204.6\n",
      "evaluation/path length Std            10.8738\n",
      "evaluation/path length Max           217\n",
      "evaluation/path length Min           192\n",
      "evaluation/Rewards Mean                3.05616\n",
      "evaluation/Rewards Std                 1.5543\n",
      "evaluation/Rewards Max                 5.89631\n",
      "evaluation/Rewards Min                 0.140012\n",
      "evaluation/Returns Mean              625.291\n",
      "evaluation/Returns Std                40.2436\n",
      "evaluation/Returns Max               666.897\n",
      "evaluation/Returns Min               578.708\n",
      "evaluation/Estimation Bias Mean      233.637\n",
      "evaluation/Estimation Bias Std       202.989\n",
      "evaluation/EB/Q_True Mean             22.8849\n",
      "evaluation/EB/Q_True Std              71.2525\n",
      "evaluation/EB/Q_Pred Mean            256.522\n",
      "evaluation/EB/Q_Pred Std             192.453\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           625.291\n",
      "evaluation/Actions Mean                0.486573\n",
      "evaluation/Actions Std                 0.653397\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999996\n",
      "time/backward_policy (s)               1.77043\n",
      "time/backward_zf1 (s)                  1.90695\n",
      "time/backward_zf2 (s)                  1.84077\n",
      "time/data sampling (s)                 0.238474\n",
      "time/data storing (s)                  0.0137889\n",
      "time/evaluation sampling (s)           0.341192\n",
      "time/exploration sampling (s)          0.20036\n",
      "time/logging (s)                       0.00406664\n",
      "time/preback_alpha (s)                 0.566101\n",
      "time/preback_policy (s)                0.988275\n",
      "time/preback_start (s)                 0.123377\n",
      "time/preback_zf (s)                    5.07506\n",
      "time/saving (s)                        0.00511129\n",
      "time/training (s)                      2.48067\n",
      "time/epoch (s)                        15.5546\n",
      "time/total (s)                       440.536\n",
      "Epoch                                 27\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:59:41.338362 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 28 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 39000\n",
      "trainer/ZF1 Loss                       2.51852\n",
      "trainer/ZF2 Loss                       2.48458\n",
      "trainer/ZF Expert Reward              20.5058\n",
      "trainer/ZF Policy Reward              -8.03528\n",
      "trainer/ZF CHI2 Term                  31.3089\n",
      "trainer/Policy Loss                 -208.949\n",
      "trainer/Bias Loss                    127.215\n",
      "trainer/Bias Value                    10.2765\n",
      "trainer/Policy Grad Norm             135.912\n",
      "trainer/Policy Param Norm             23.0319\n",
      "trainer/Zf1 Grad Norm                899.44\n",
      "trainer/Zf1 Param Norm                57.6491\n",
      "trainer/Zf2 Grad Norm                815.59\n",
      "trainer/Zf2 Param Norm                56.7479\n",
      "trainer/Z Expert Predictions Mean    380.95\n",
      "trainer/Z Expert Predictions Std     138.516\n",
      "trainer/Z Expert Predictions Max     628.225\n",
      "trainer/Z Expert Predictions Min     100.858\n",
      "trainer/Z Policy Predictions Mean    192.502\n",
      "trainer/Z Policy Predictions Std     178.94\n",
      "trainer/Z Policy Predictions Max     612.052\n",
      "trainer/Z Policy Predictions Min     -62.2119\n",
      "trainer/Z Expert Targets Mean        360.444\n",
      "trainer/Z Expert Targets Std         140.334\n",
      "trainer/Z Expert Targets Max         610.671\n",
      "trainer/Z Expert Targets Min          92.3546\n",
      "trainer/Z Policy Targets Mean        200.537\n",
      "trainer/Z Policy Targets Std         180.672\n",
      "trainer/Z Policy Targets Max         607.1\n",
      "trainer/Z Policy Targets Min         -71.5119\n",
      "trainer/Log Pis Mean                  26.6312\n",
      "trainer/Log Pis Std                    7.14145\n",
      "trainer/Policy mu Mean                 1.53377\n",
      "trainer/Policy mu Std                  2.25132\n",
      "trainer/Policy log std Mean           -2.86322\n",
      "trainer/Policy log std Std             1.47343\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        38208\n",
      "exploration/num paths total          690\n",
      "evaluation/num steps total         48557\n",
      "evaluation/num paths total           290\n",
      "evaluation/path length Mean          267.9\n",
      "evaluation/path length Std             8.22739\n",
      "evaluation/path length Max           283\n",
      "evaluation/path length Min           257\n",
      "evaluation/Rewards Mean                2.78645\n",
      "evaluation/Rewards Std                 1.28116\n",
      "evaluation/Rewards Max                 5.9204\n",
      "evaluation/Rewards Min                 0.100997\n",
      "evaluation/Returns Mean              746.49\n",
      "evaluation/Returns Std                17.3838\n",
      "evaluation/Returns Max               782.192\n",
      "evaluation/Returns Min               724.434\n",
      "evaluation/Estimation Bias Mean      228.216\n",
      "evaluation/Estimation Bias Std       191.453\n",
      "evaluation/EB/Q_True Mean             20.9419\n",
      "evaluation/EB/Q_True Std              67.3409\n",
      "evaluation/EB/Q_Pred Mean            249.158\n",
      "evaluation/EB/Q_Pred Std             181.661\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           746.49\n",
      "evaluation/Actions Mean                0.447201\n",
      "evaluation/Actions Std                 0.60404\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999666\n",
      "time/backward_policy (s)               1.73908\n",
      "time/backward_zf1 (s)                  1.86479\n",
      "time/backward_zf2 (s)                  1.80272\n",
      "time/data sampling (s)                 0.220699\n",
      "time/data storing (s)                  0.0139209\n",
      "time/evaluation sampling (s)           0.48517\n",
      "time/exploration sampling (s)          0.197669\n",
      "time/logging (s)                       0.00392686\n",
      "time/preback_alpha (s)                 0.546601\n",
      "time/preback_policy (s)                1.00941\n",
      "time/preback_start (s)                 0.118022\n",
      "time/preback_zf (s)                    4.99806\n",
      "time/saving (s)                        0.00503742\n",
      "time/training (s)                      2.24412\n",
      "time/epoch (s)                        15.2492\n",
      "time/total (s)                       455.812\n",
      "Epoch                                 28\n",
      "---------------------------------  --------------\n",
      "2024-06-25 17:59:57.000572 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 29 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 40000\n",
      "trainer/ZF1 Loss                       2.12168\n",
      "trainer/ZF2 Loss                       2.97328\n",
      "trainer/ZF Expert Reward              14.5032\n",
      "trainer/ZF Policy Reward              -7.64187\n",
      "trainer/ZF CHI2 Term                  24.9416\n",
      "trainer/Policy Loss                 -227.544\n",
      "trainer/Bias Loss                     77.8558\n",
      "trainer/Bias Value                    10.2861\n",
      "trainer/Policy Grad Norm             113.94\n",
      "trainer/Policy Param Norm             23.1296\n",
      "trainer/Zf1 Grad Norm               1511.73\n",
      "trainer/Zf1 Param Norm                58.1178\n",
      "trainer/Zf2 Grad Norm               1794.57\n",
      "trainer/Zf2 Param Norm                57.1168\n",
      "trainer/Z Expert Predictions Mean    363.766\n",
      "trainer/Z Expert Predictions Std     155.624\n",
      "trainer/Z Expert Predictions Max     632.974\n",
      "trainer/Z Expert Predictions Min      84.961\n",
      "trainer/Z Policy Predictions Mean    208.587\n",
      "trainer/Z Policy Predictions Std     190.219\n",
      "trainer/Z Policy Predictions Max     608.654\n",
      "trainer/Z Policy Predictions Min     -82.5314\n",
      "trainer/Z Expert Targets Mean        349.263\n",
      "trainer/Z Expert Targets Std         155.277\n",
      "trainer/Z Expert Targets Max         620.756\n",
      "trainer/Z Expert Targets Min          74.8188\n",
      "trainer/Z Policy Targets Mean        216.229\n",
      "trainer/Z Policy Targets Std         188.91\n",
      "trainer/Z Policy Targets Max         611.102\n",
      "trainer/Z Policy Targets Min         -91.6218\n",
      "trainer/Log Pis Mean                  24.9014\n",
      "trainer/Log Pis Std                    6.5245\n",
      "trainer/Policy mu Mean                 1.16657\n",
      "trainer/Policy mu Std                  1.96326\n",
      "trainer/Policy log std Mean           -3.18677\n",
      "trainer/Policy log std Std             1.3847\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        38208\n",
      "exploration/num paths total          690\n",
      "evaluation/num steps total         50522\n",
      "evaluation/num paths total           301\n",
      "evaluation/path length Mean          178.636\n",
      "evaluation/path length Std            29.3514\n",
      "evaluation/path length Max           270\n",
      "evaluation/path length Min           161\n",
      "evaluation/Rewards Mean                2.86112\n",
      "evaluation/Rewards Std                 1.64629\n",
      "evaluation/Rewards Max                 6.62957\n",
      "evaluation/Rewards Min                 0.114879\n",
      "evaluation/Returns Mean              511.1\n",
      "evaluation/Returns Std               109.269\n",
      "evaluation/Returns Max               845.325\n",
      "evaluation/Returns Min               433.924\n",
      "evaluation/Estimation Bias Mean      279.985\n",
      "evaluation/Estimation Bias Std       195.546\n",
      "evaluation/EB/Q_True Mean             21.5852\n",
      "evaluation/EB/Q_True Std              60.4732\n",
      "evaluation/EB/Q_Pred Mean            301.57\n",
      "evaluation/EB/Q_Pred Std             189.68\n",
      "evaluation/Num Paths                  11\n",
      "evaluation/Average Returns           511.1\n",
      "evaluation/Actions Mean                0.469403\n",
      "evaluation/Actions Std                 0.568848\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.99952\n",
      "time/backward_policy (s)               1.76738\n",
      "time/backward_zf1 (s)                  1.90556\n",
      "time/backward_zf2 (s)                  1.8221\n",
      "time/data sampling (s)                 0.2235\n",
      "time/data storing (s)                  0.0136897\n",
      "time/evaluation sampling (s)           0.528954\n",
      "time/exploration sampling (s)          0.194148\n",
      "time/logging (s)                       0.00321877\n",
      "time/preback_alpha (s)                 0.564674\n",
      "time/preback_policy (s)                1.01494\n",
      "time/preback_start (s)                 0.121332\n",
      "time/preback_zf (s)                    5.08925\n",
      "time/saving (s)                        0.00729154\n",
      "time/training (s)                      2.34085\n",
      "time/epoch (s)                        15.5969\n",
      "time/total (s)                       471.428\n",
      "Epoch                                 29\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:00:12.818091 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 30 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 41000\n",
      "trainer/ZF1 Loss                      12.7972\n",
      "trainer/ZF2 Loss                      11.9797\n",
      "trainer/ZF Expert Reward              20.5124\n",
      "trainer/ZF Policy Reward              -7.11746\n",
      "trainer/ZF CHI2 Term                  40.2587\n",
      "trainer/Policy Loss                 -189.214\n",
      "trainer/Bias Loss                    224.877\n",
      "trainer/Bias Value                    10.2957\n",
      "trainer/Policy Grad Norm              85.5547\n",
      "trainer/Policy Param Norm             23.2869\n",
      "trainer/Zf1 Grad Norm               1136.72\n",
      "trainer/Zf1 Param Norm                58.5761\n",
      "trainer/Zf2 Grad Norm                684.778\n",
      "trainer/Zf2 Param Norm                57.5354\n",
      "trainer/Z Expert Predictions Mean    375.026\n",
      "trainer/Z Expert Predictions Std     166.558\n",
      "trainer/Z Expert Predictions Max     660.302\n",
      "trainer/Z Expert Predictions Min      85.7438\n",
      "trainer/Z Policy Predictions Mean    175.421\n",
      "trainer/Z Policy Predictions Std     184.251\n",
      "trainer/Z Policy Predictions Max     623.028\n",
      "trainer/Z Policy Predictions Min    -168.674\n",
      "trainer/Z Expert Targets Mean        354.514\n",
      "trainer/Z Expert Targets Std         169.442\n",
      "trainer/Z Expert Targets Max         642.383\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        182.539\n",
      "trainer/Z Policy Targets Std         183.754\n",
      "trainer/Z Policy Targets Max         612.42\n",
      "trainer/Z Policy Targets Min        -161.689\n",
      "trainer/Log Pis Mean                  24.038\n",
      "trainer/Log Pis Std                    6.99186\n",
      "trainer/Policy mu Mean                 1.08474\n",
      "trainer/Policy mu Std                  1.91344\n",
      "trainer/Policy log std Mean           -3.15974\n",
      "trainer/Policy log std Std             1.38981\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        39639\n",
      "exploration/num paths total          697\n",
      "evaluation/num steps total         52714\n",
      "evaluation/num paths total           311\n",
      "evaluation/path length Mean          219.2\n",
      "evaluation/path length Std             9.80612\n",
      "evaluation/path length Max           234\n",
      "evaluation/path length Min           205\n",
      "evaluation/Rewards Mean                3.44517\n",
      "evaluation/Rewards Std                 1.81741\n",
      "evaluation/Rewards Max                 6.48682\n",
      "evaluation/Rewards Min                 0.0922459\n",
      "evaluation/Returns Mean              755.18\n",
      "evaluation/Returns Std                38.9398\n",
      "evaluation/Returns Max               815.285\n",
      "evaluation/Returns Min               697.147\n",
      "evaluation/Estimation Bias Mean      257.284\n",
      "evaluation/Estimation Bias Std       228.907\n",
      "evaluation/EB/Q_True Mean             27.2804\n",
      "evaluation/EB/Q_True Std              84.3133\n",
      "evaluation/EB/Q_Pred Mean            284.564\n",
      "evaluation/EB/Q_Pred Std             217.178\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           755.18\n",
      "evaluation/Actions Mean                0.469658\n",
      "evaluation/Actions Std                 0.649564\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.997135\n",
      "time/backward_policy (s)               1.82204\n",
      "time/backward_zf1 (s)                  2.00459\n",
      "time/backward_zf2 (s)                  1.91137\n",
      "time/data sampling (s)                 0.23114\n",
      "time/data storing (s)                  0.014268\n",
      "time/evaluation sampling (s)           0.372623\n",
      "time/exploration sampling (s)          0.204206\n",
      "time/logging (s)                       0.00382448\n",
      "time/preback_alpha (s)                 0.563356\n",
      "time/preback_policy (s)                1.04822\n",
      "time/preback_start (s)                 0.122487\n",
      "time/preback_zf (s)                    5.09676\n",
      "time/saving (s)                        0.00521168\n",
      "time/training (s)                      2.34762\n",
      "time/epoch (s)                        15.7477\n",
      "time/total (s)                       487.2\n",
      "Epoch                                 30\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:00:29.535816 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 31 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 42000\n",
      "trainer/ZF1 Loss                       5.98717\n",
      "trainer/ZF2 Loss                       4.76626\n",
      "trainer/ZF Expert Reward              17.6835\n",
      "trainer/ZF Policy Reward              -7.03322\n",
      "trainer/ZF CHI2 Term                  30.3401\n",
      "trainer/Policy Loss                 -191.004\n",
      "trainer/Bias Loss                     98.6775\n",
      "trainer/Bias Value                    10.3053\n",
      "trainer/Policy Grad Norm             129.785\n",
      "trainer/Policy Param Norm             23.5131\n",
      "trainer/Zf1 Grad Norm                906.412\n",
      "trainer/Zf1 Param Norm                59.0035\n",
      "trainer/Zf2 Grad Norm               1249.36\n",
      "trainer/Zf2 Param Norm                57.949\n",
      "trainer/Z Expert Predictions Mean    397.59\n",
      "trainer/Z Expert Predictions Std     171.084\n",
      "trainer/Z Expert Predictions Max     696.25\n",
      "trainer/Z Expert Predictions Min     102.988\n",
      "trainer/Z Policy Predictions Mean    173.225\n",
      "trainer/Z Policy Predictions Std     183.103\n",
      "trainer/Z Policy Predictions Max     612.993\n",
      "trainer/Z Policy Predictions Min    -173.242\n",
      "trainer/Z Expert Targets Mean        379.907\n",
      "trainer/Z Expert Targets Std         171.213\n",
      "trainer/Z Expert Targets Max         678.468\n",
      "trainer/Z Expert Targets Min          87.4308\n",
      "trainer/Z Policy Targets Mean        180.258\n",
      "trainer/Z Policy Targets Std         181.542\n",
      "trainer/Z Policy Targets Max         613.454\n",
      "trainer/Z Policy Targets Min        -162.724\n",
      "trainer/Log Pis Mean                  24.6689\n",
      "trainer/Log Pis Std                    6.71486\n",
      "trainer/Policy mu Mean                 1.28132\n",
      "trainer/Policy mu Std                  1.91695\n",
      "trainer/Policy log std Mean           -3.18599\n",
      "trainer/Policy log std Std             1.37507\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        40338\n",
      "exploration/num paths total          699\n",
      "evaluation/num steps total         62714\n",
      "evaluation/num paths total           321\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                1.05099\n",
      "evaluation/Rewards Std                 0.319961\n",
      "evaluation/Rewards Max                 3.45726\n",
      "evaluation/Rewards Min                -0.170539\n",
      "evaluation/Returns Mean             1050.99\n",
      "evaluation/Returns Std                 3.38263\n",
      "evaluation/Returns Max              1054.32\n",
      "evaluation/Returns Min              1042.63\n",
      "evaluation/Estimation Bias Mean      104.524\n",
      "evaluation/Estimation Bias Std       119.637\n",
      "evaluation/EB/Q_True Mean              9.33759\n",
      "evaluation/EB/Q_True Std              29.0362\n",
      "evaluation/EB/Q_Pred Mean            113.861\n",
      "evaluation/EB/Q_Pred Std             117.935\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1050.99\n",
      "evaluation/Actions Mean                0.441459\n",
      "evaluation/Actions Std                 0.433309\n",
      "evaluation/Actions Max                 0.999964\n",
      "evaluation/Actions Min                -0.993468\n",
      "time/backward_policy (s)               1.80084\n",
      "time/backward_zf1 (s)                  1.94084\n",
      "time/backward_zf2 (s)                  1.8742\n",
      "time/data sampling (s)                 0.236213\n",
      "time/data storing (s)                  0.0146292\n",
      "time/evaluation sampling (s)           1.41743\n",
      "time/exploration sampling (s)          0.196949\n",
      "time/logging (s)                       0.0123805\n",
      "time/preback_alpha (s)                 0.559922\n",
      "time/preback_policy (s)                1.00137\n",
      "time/preback_start (s)                 0.122863\n",
      "time/preback_zf (s)                    5.0669\n",
      "time/saving (s)                        0.0059424\n",
      "time/training (s)                      2.41258\n",
      "time/epoch (s)                        16.6631\n",
      "time/total (s)                       503.882\n",
      "Epoch                                 31\n",
      "---------------------------------  -------------\n",
      "2024-06-25 18:00:46.322302 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 32 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 43000\n",
      "trainer/ZF1 Loss                      10.6288\n",
      "trainer/ZF2 Loss                      12.7836\n",
      "trainer/ZF Expert Reward              15.6863\n",
      "trainer/ZF Policy Reward              -9.38905\n",
      "trainer/ZF CHI2 Term                  37.0348\n",
      "trainer/Policy Loss                 -180.66\n",
      "trainer/Bias Loss                    106.836\n",
      "trainer/Bias Value                    10.3149\n",
      "trainer/Policy Grad Norm             117.22\n",
      "trainer/Policy Param Norm             23.7302\n",
      "trainer/Zf1 Grad Norm               1989.55\n",
      "trainer/Zf1 Param Norm                59.4681\n",
      "trainer/Zf2 Grad Norm               1888.7\n",
      "trainer/Zf2 Param Norm                58.4267\n",
      "trainer/Z Expert Predictions Mean    430.907\n",
      "trainer/Z Expert Predictions Std     179.767\n",
      "trainer/Z Expert Predictions Max     742.68\n",
      "trainer/Z Expert Predictions Min     109.002\n",
      "trainer/Z Policy Predictions Mean    160.026\n",
      "trainer/Z Policy Predictions Std     173.54\n",
      "trainer/Z Policy Predictions Max     578.853\n",
      "trainer/Z Policy Predictions Min    -184.856\n",
      "trainer/Z Expert Targets Mean        415.22\n",
      "trainer/Z Expert Targets Std         182.105\n",
      "trainer/Z Expert Targets Max         719.921\n",
      "trainer/Z Expert Targets Min          81.5346\n",
      "trainer/Z Policy Targets Mean        169.415\n",
      "trainer/Z Policy Targets Std         177.334\n",
      "trainer/Z Policy Targets Max         605.557\n",
      "trainer/Z Policy Targets Min        -177.971\n",
      "trainer/Log Pis Mean                  25.328\n",
      "trainer/Log Pis Std                    6.66159\n",
      "trainer/Policy mu Mean                 1.3322\n",
      "trainer/Policy mu Std                  1.95028\n",
      "trainer/Policy log std Mean           -3.1649\n",
      "trainer/Policy log std Std             1.39742\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        42209\n",
      "exploration/num paths total          707\n",
      "evaluation/num steps total         72714\n",
      "evaluation/num paths total           331\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                1.04567\n",
      "evaluation/Rewards Std                 0.285811\n",
      "evaluation/Rewards Max                 3.25979\n",
      "evaluation/Rewards Min                 0.126872\n",
      "evaluation/Returns Mean             1045.67\n",
      "evaluation/Returns Std                 1.11994\n",
      "evaluation/Returns Max              1046.79\n",
      "evaluation/Returns Min              1042.92\n",
      "evaluation/Estimation Bias Mean      147.152\n",
      "evaluation/Estimation Bias Std        86.0593\n",
      "evaluation/EB/Q_True Mean              9.30205\n",
      "evaluation/EB/Q_True Std              28.8643\n",
      "evaluation/EB/Q_Pred Mean            156.454\n",
      "evaluation/EB/Q_Pred Std              81.1658\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1045.67\n",
      "evaluation/Actions Mean                0.409495\n",
      "evaluation/Actions Std                 0.37865\n",
      "evaluation/Actions Max                 0.999968\n",
      "evaluation/Actions Min                -0.994576\n",
      "time/backward_policy (s)               1.83445\n",
      "time/backward_zf1 (s)                  1.96843\n",
      "time/backward_zf2 (s)                  1.89358\n",
      "time/data sampling (s)                 0.231083\n",
      "time/data storing (s)                  0.0143274\n",
      "time/evaluation sampling (s)           1.43337\n",
      "time/exploration sampling (s)          0.206561\n",
      "time/logging (s)                       0.0118144\n",
      "time/preback_alpha (s)                 0.564177\n",
      "time/preback_policy (s)                1.07282\n",
      "time/preback_start (s)                 0.121408\n",
      "time/preback_zf (s)                    5.08695\n",
      "time/saving (s)                        0.00586978\n",
      "time/training (s)                      2.27327\n",
      "time/epoch (s)                        16.7181\n",
      "time/total (s)                       520.622\n",
      "Epoch                                 32\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:01:03.326309 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 33 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 44000\n",
      "trainer/ZF1 Loss                      61.035\n",
      "trainer/ZF2 Loss                      60.7769\n",
      "trainer/ZF Expert Reward              22.8437\n",
      "trainer/ZF Policy Reward              -7.59662\n",
      "trainer/ZF CHI2 Term                  91.5916\n",
      "trainer/Policy Loss                 -199.558\n",
      "trainer/Bias Loss                    693.642\n",
      "trainer/Bias Value                    10.3244\n",
      "trainer/Policy Grad Norm             124.51\n",
      "trainer/Policy Param Norm             23.9069\n",
      "trainer/Zf1 Grad Norm                829.255\n",
      "trainer/Zf1 Param Norm                59.9546\n",
      "trainer/Zf2 Grad Norm                953.919\n",
      "trainer/Zf2 Param Norm                58.9286\n",
      "trainer/Z Expert Predictions Mean    459.911\n",
      "trainer/Z Expert Predictions Std     199.992\n",
      "trainer/Z Expert Predictions Max     775.491\n",
      "trainer/Z Expert Predictions Min      67.1509\n",
      "trainer/Z Policy Predictions Mean    180.577\n",
      "trainer/Z Policy Predictions Std     188.215\n",
      "trainer/Z Policy Predictions Max     604.096\n",
      "trainer/Z Policy Predictions Min    -207.868\n",
      "trainer/Z Expert Targets Mean        437.067\n",
      "trainer/Z Expert Targets Std         203.652\n",
      "trainer/Z Expert Targets Max         757.336\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        188.174\n",
      "trainer/Z Policy Targets Std         188.617\n",
      "trainer/Z Policy Targets Max         596.993\n",
      "trainer/Z Policy Targets Min        -195.699\n",
      "trainer/Log Pis Mean                  24.5352\n",
      "trainer/Log Pis Std                    6.4859\n",
      "trainer/Policy mu Mean                 1.18867\n",
      "trainer/Policy mu Std                  1.97855\n",
      "trainer/Policy log std Mean           -3.17083\n",
      "trainer/Policy log std Std             1.42686\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        42209\n",
      "exploration/num paths total          707\n",
      "evaluation/num steps total         82714\n",
      "evaluation/num paths total           341\n",
      "evaluation/path length Mean         1000\n",
      "evaluation/path length Std             0\n",
      "evaluation/path length Max          1000\n",
      "evaluation/path length Min          1000\n",
      "evaluation/Rewards Mean                1.04296\n",
      "evaluation/Rewards Std                 0.293961\n",
      "evaluation/Rewards Max                 3.245\n",
      "evaluation/Rewards Min                 0.125591\n",
      "evaluation/Returns Mean             1042.96\n",
      "evaluation/Returns Std                 6.33347\n",
      "evaluation/Returns Max              1051.3\n",
      "evaluation/Returns Min              1030.07\n",
      "evaluation/Estimation Bias Mean      116.634\n",
      "evaluation/Estimation Bias Std        97.7803\n",
      "evaluation/EB/Q_True Mean              9.30668\n",
      "evaluation/EB/Q_True Std              28.9141\n",
      "evaluation/EB/Q_Pred Mean            125.941\n",
      "evaluation/EB/Q_Pred Std              90.8411\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1042.96\n",
      "evaluation/Actions Mean                0.395525\n",
      "evaluation/Actions Std                 0.336936\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.997148\n",
      "time/backward_policy (s)               1.85085\n",
      "time/backward_zf1 (s)                  2.00313\n",
      "time/backward_zf2 (s)                  1.92689\n",
      "time/data sampling (s)                 0.217322\n",
      "time/data storing (s)                  0.0141487\n",
      "time/evaluation sampling (s)           1.48371\n",
      "time/exploration sampling (s)          0.206342\n",
      "time/logging (s)                       0.011581\n",
      "time/preback_alpha (s)                 0.566846\n",
      "time/preback_policy (s)                1.07584\n",
      "time/preback_start (s)                 0.121425\n",
      "time/preback_zf (s)                    5.10667\n",
      "time/saving (s)                        0.00535527\n",
      "time/training (s)                      2.34929\n",
      "time/epoch (s)                        16.9394\n",
      "time/total (s)                       537.58\n",
      "Epoch                                 33\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:01:18.279670 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 34 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 45000\n",
      "trainer/ZF1 Loss                      18.7202\n",
      "trainer/ZF2 Loss                      18.427\n",
      "trainer/ZF Expert Reward              12.9692\n",
      "trainer/ZF Policy Reward              -9.42947\n",
      "trainer/ZF CHI2 Term                  41.2098\n",
      "trainer/Policy Loss                 -185.925\n",
      "trainer/Bias Loss                    111.472\n",
      "trainer/Bias Value                    10.3339\n",
      "trainer/Policy Grad Norm             106.699\n",
      "trainer/Policy Param Norm             24.1101\n",
      "trainer/Zf1 Grad Norm               1841.82\n",
      "trainer/Zf1 Param Norm                60.431\n",
      "trainer/Zf2 Grad Norm               2250.27\n",
      "trainer/Zf2 Param Norm                59.4218\n",
      "trainer/Z Expert Predictions Mean    447.708\n",
      "trainer/Z Expert Predictions Std     207.72\n",
      "trainer/Z Expert Predictions Max     803.16\n",
      "trainer/Z Expert Predictions Min     117.761\n",
      "trainer/Z Policy Predictions Mean    165.455\n",
      "trainer/Z Policy Predictions Std     177.044\n",
      "trainer/Z Policy Predictions Max     560.218\n",
      "trainer/Z Policy Predictions Min    -206.869\n",
      "trainer/Z Expert Targets Mean        434.739\n",
      "trainer/Z Expert Targets Std         204.891\n",
      "trainer/Z Expert Targets Max         789.812\n",
      "trainer/Z Expert Targets Min          97.1993\n",
      "trainer/Z Policy Targets Mean        174.884\n",
      "trainer/Z Policy Targets Std         177.252\n",
      "trainer/Z Policy Targets Max         561.343\n",
      "trainer/Z Policy Targets Min        -199.941\n",
      "trainer/Log Pis Mean                  23.7611\n",
      "trainer/Log Pis Std                    6.78279\n",
      "trainer/Policy mu Mean                 1.16886\n",
      "trainer/Policy mu Std                  1.83906\n",
      "trainer/Policy log std Mean           -3.20046\n",
      "trainer/Policy log std Std             1.2999\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        42209\n",
      "exploration/num paths total          707\n",
      "evaluation/num steps total         84986\n",
      "evaluation/num paths total           351\n",
      "evaluation/path length Mean          227.2\n",
      "evaluation/path length Std            15.2565\n",
      "evaluation/path length Max           248\n",
      "evaluation/path length Min           203\n",
      "evaluation/Rewards Mean                3.14228\n",
      "evaluation/Rewards Std                 1.49717\n",
      "evaluation/Rewards Max                 6.17946\n",
      "evaluation/Rewards Min                 0.140543\n",
      "evaluation/Returns Mean              713.925\n",
      "evaluation/Returns Std                48.4947\n",
      "evaluation/Returns Max               775.978\n",
      "evaluation/Returns Min               634.903\n",
      "evaluation/Estimation Bias Mean      221.255\n",
      "evaluation/Estimation Bias Std       172.24\n",
      "evaluation/EB/Q_True Mean             24.9141\n",
      "evaluation/EB/Q_True Std              76.8053\n",
      "evaluation/EB/Q_Pred Mean            246.169\n",
      "evaluation/EB/Q_Pred Std             161.739\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           713.925\n",
      "evaluation/Actions Mean                0.510283\n",
      "evaluation/Actions Std                 0.582102\n",
      "evaluation/Actions Max                 0.999999\n",
      "evaluation/Actions Min                -0.999951\n",
      "time/backward_policy (s)               1.61549\n",
      "time/backward_zf1 (s)                  1.73437\n",
      "time/backward_zf2 (s)                  1.67539\n",
      "time/data sampling (s)                 0.193127\n",
      "time/data storing (s)                  0.0136583\n",
      "time/evaluation sampling (s)           0.390047\n",
      "time/exploration sampling (s)          0.197987\n",
      "time/logging (s)                       0.00348058\n",
      "time/preback_alpha (s)                 0.533011\n",
      "time/preback_policy (s)                0.890752\n",
      "time/preback_start (s)                 0.1131\n",
      "time/preback_zf (s)                    4.98424\n",
      "time/saving (s)                        0.00531829\n",
      "time/training (s)                      2.52644\n",
      "time/epoch (s)                        14.8764\n",
      "time/total (s)                       552.482\n",
      "Epoch                                 34\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:01:33.379698 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 35 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 46000\n",
      "trainer/ZF1 Loss                      10.6838\n",
      "trainer/ZF2 Loss                       8.28998\n",
      "trainer/ZF Expert Reward              20.4121\n",
      "trainer/ZF Policy Reward              -4.75124\n",
      "trainer/ZF CHI2 Term                  34.89\n",
      "trainer/Policy Loss                 -188.124\n",
      "trainer/Bias Loss                    174.514\n",
      "trainer/Bias Value                    10.3433\n",
      "trainer/Policy Grad Norm              94.4272\n",
      "trainer/Policy Param Norm             24.3026\n",
      "trainer/Zf1 Grad Norm               1380.58\n",
      "trainer/Zf1 Param Norm                60.8532\n",
      "trainer/Zf2 Grad Norm                995.059\n",
      "trainer/Zf2 Param Norm                59.888\n",
      "trainer/Z Expert Predictions Mean    449.105\n",
      "trainer/Z Expert Predictions Std     188.578\n",
      "trainer/Z Expert Predictions Max     831.016\n",
      "trainer/Z Expert Predictions Min     164.433\n",
      "trainer/Z Policy Predictions Mean    175.911\n",
      "trainer/Z Policy Predictions Std     169.468\n",
      "trainer/Z Policy Predictions Max     548.408\n",
      "trainer/Z Policy Predictions Min    -103.804\n",
      "trainer/Z Expert Targets Mean        428.693\n",
      "trainer/Z Expert Targets Std         189.624\n",
      "trainer/Z Expert Targets Max         822.362\n",
      "trainer/Z Expert Targets Min         113.603\n",
      "trainer/Z Policy Targets Mean        180.663\n",
      "trainer/Z Policy Targets Std         168.709\n",
      "trainer/Z Policy Targets Max         551.819\n",
      "trainer/Z Policy Targets Min        -100.098\n",
      "trainer/Log Pis Mean                  23.9728\n",
      "trainer/Log Pis Std                    6.48528\n",
      "trainer/Policy mu Mean                 1.1171\n",
      "trainer/Policy mu Std                  1.85099\n",
      "trainer/Policy log std Mean           -3.28273\n",
      "trainer/Policy log std Std             1.3043\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        42209\n",
      "exploration/num paths total          707\n",
      "evaluation/num steps total         86906\n",
      "evaluation/num paths total           361\n",
      "evaluation/path length Mean          192\n",
      "evaluation/path length Std             5.09902\n",
      "evaluation/path length Max           200\n",
      "evaluation/path length Min           181\n",
      "evaluation/Rewards Mean                3.43062\n",
      "evaluation/Rewards Std                 1.90611\n",
      "evaluation/Rewards Max                 5.87392\n",
      "evaluation/Rewards Min                 0.205233\n",
      "evaluation/Returns Mean              658.679\n",
      "evaluation/Returns Std                25.2815\n",
      "evaluation/Returns Max               693.763\n",
      "evaluation/Returns Min               603.783\n",
      "evaluation/Estimation Bias Mean      272.001\n",
      "evaluation/Estimation Bias Std       168.418\n",
      "evaluation/EB/Q_True Mean             24.9806\n",
      "evaluation/EB/Q_True Std              78.6548\n",
      "evaluation/EB/Q_Pred Mean            296.982\n",
      "evaluation/EB/Q_Pred Std             152.668\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           658.679\n",
      "evaluation/Actions Mean                0.52501\n",
      "evaluation/Actions Std                 0.591212\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999989\n",
      "time/backward_policy (s)               1.67429\n",
      "time/backward_zf1 (s)                  1.79205\n",
      "time/backward_zf2 (s)                  1.71595\n",
      "time/data sampling (s)                 0.204352\n",
      "time/data storing (s)                  0.0139411\n",
      "time/evaluation sampling (s)           0.292302\n",
      "time/exploration sampling (s)          0.195043\n",
      "time/logging (s)                       0.0032411\n",
      "time/preback_alpha (s)                 0.538382\n",
      "time/preback_policy (s)                0.904879\n",
      "time/preback_start (s)                 0.115951\n",
      "time/preback_zf (s)                    5.01409\n",
      "time/saving (s)                        0.00494002\n",
      "time/training (s)                      2.56283\n",
      "time/epoch (s)                        15.0322\n",
      "time/total (s)                       567.539\n",
      "Epoch                                 35\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:01:48.754550 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 36 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 47000\n",
      "trainer/ZF1 Loss                      11.623\n",
      "trainer/ZF2 Loss                      15.5022\n",
      "trainer/ZF Expert Reward              20.6791\n",
      "trainer/ZF Policy Reward              -5.06808\n",
      "trainer/ZF CHI2 Term                  39.559\n",
      "trainer/Policy Loss                 -181.611\n",
      "trainer/Bias Loss                    193.235\n",
      "trainer/Bias Value                    10.3528\n",
      "trainer/Policy Grad Norm              89.6359\n",
      "trainer/Policy Param Norm             24.4628\n",
      "trainer/Zf1 Grad Norm               1954.57\n",
      "trainer/Zf1 Param Norm                61.2025\n",
      "trainer/Zf2 Grad Norm               1491.43\n",
      "trainer/Zf2 Param Norm                60.2471\n",
      "trainer/Z Expert Predictions Mean    419.718\n",
      "trainer/Z Expert Predictions Std     157.195\n",
      "trainer/Z Expert Predictions Max     834.6\n",
      "trainer/Z Expert Predictions Min     201.824\n",
      "trainer/Z Policy Predictions Mean    162.478\n",
      "trainer/Z Policy Predictions Std     164.443\n",
      "trainer/Z Policy Predictions Max     549.552\n",
      "trainer/Z Policy Predictions Min    -213.832\n",
      "trainer/Z Expert Targets Mean        399.039\n",
      "trainer/Z Expert Targets Std         157.939\n",
      "trainer/Z Expert Targets Max         833.504\n",
      "trainer/Z Expert Targets Min         189.443\n",
      "trainer/Z Policy Targets Mean        167.546\n",
      "trainer/Z Policy Targets Std         163.741\n",
      "trainer/Z Policy Targets Max         536.865\n",
      "trainer/Z Policy Targets Min        -212.504\n",
      "trainer/Log Pis Mean                  24.9291\n",
      "trainer/Log Pis Std                    6.64226\n",
      "trainer/Policy mu Mean                 1.20274\n",
      "trainer/Policy mu Std                  2.1748\n",
      "trainer/Policy log std Mean           -3.08732\n",
      "trainer/Policy log std Std             1.41253\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        44398\n",
      "exploration/num paths total          712\n",
      "evaluation/num steps total         88372\n",
      "evaluation/num paths total           371\n",
      "evaluation/path length Mean          146.6\n",
      "evaluation/path length Std             5.02394\n",
      "evaluation/path length Max           154\n",
      "evaluation/path length Min           139\n",
      "evaluation/Rewards Mean                2.86766\n",
      "evaluation/Rewards Std                 2.00788\n",
      "evaluation/Rewards Max                 6.42597\n",
      "evaluation/Rewards Min                 0.218631\n",
      "evaluation/Returns Mean              420.398\n",
      "evaluation/Returns Std                47.7193\n",
      "evaluation/Returns Max               481.181\n",
      "evaluation/Returns Min               298.856\n",
      "evaluation/Estimation Bias Mean      282.683\n",
      "evaluation/Estimation Bias Std       149.948\n",
      "evaluation/EB/Q_True Mean             12.1972\n",
      "evaluation/EB/Q_True Std              37.919\n",
      "evaluation/EB/Q_Pred Mean            294.881\n",
      "evaluation/EB/Q_Pred Std             148.074\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           420.398\n",
      "evaluation/Actions Mean                0.466826\n",
      "evaluation/Actions Std                 0.565322\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999996\n",
      "time/backward_policy (s)               1.81385\n",
      "time/backward_zf1 (s)                  1.93745\n",
      "time/backward_zf2 (s)                  1.88507\n",
      "time/data sampling (s)                 0.212565\n",
      "time/data storing (s)                  0.0136998\n",
      "time/evaluation sampling (s)           0.239485\n",
      "time/exploration sampling (s)          0.197737\n",
      "time/logging (s)                       0.00309227\n",
      "time/preback_alpha (s)                 0.545128\n",
      "time/preback_policy (s)                1.05971\n",
      "time/preback_start (s)                 0.115814\n",
      "time/preback_zf (s)                    5.02698\n",
      "time/saving (s)                        0.00608647\n",
      "time/training (s)                      2.25736\n",
      "time/epoch (s)                        15.314\n",
      "time/total (s)                       582.87\n",
      "Epoch                                 36\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:02:04.240485 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 37 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 48000\n",
      "trainer/ZF1 Loss                       8.71267\n",
      "trainer/ZF2 Loss                       8.47712\n",
      "trainer/ZF Expert Reward              17.7558\n",
      "trainer/ZF Policy Reward              -6.46057\n",
      "trainer/ZF CHI2 Term                  33.0669\n",
      "trainer/Policy Loss                 -166.58\n",
      "trainer/Bias Loss                    157.526\n",
      "trainer/Bias Value                    10.3624\n",
      "trainer/Policy Grad Norm             133.458\n",
      "trainer/Policy Param Norm             24.6149\n",
      "trainer/Zf1 Grad Norm                956.779\n",
      "trainer/Zf1 Param Norm                61.4291\n",
      "trainer/Zf2 Grad Norm                948.09\n",
      "trainer/Zf2 Param Norm                60.4273\n",
      "trainer/Z Expert Predictions Mean    353.84\n",
      "trainer/Z Expert Predictions Std     106.196\n",
      "trainer/Z Expert Predictions Max     702.977\n",
      "trainer/Z Expert Predictions Min     132.857\n",
      "trainer/Z Policy Predictions Mean    151.954\n",
      "trainer/Z Policy Predictions Std     157.069\n",
      "trainer/Z Policy Predictions Max     496.737\n",
      "trainer/Z Policy Predictions Min    -172.753\n",
      "trainer/Z Expert Targets Mean        336.084\n",
      "trainer/Z Expert Targets Std         106.656\n",
      "trainer/Z Expert Targets Max         709.916\n",
      "trainer/Z Expert Targets Min         117.358\n",
      "trainer/Z Policy Targets Mean        158.414\n",
      "trainer/Z Policy Targets Std         156.048\n",
      "trainer/Z Policy Targets Max         535.743\n",
      "trainer/Z Policy Targets Min        -166.519\n",
      "trainer/Log Pis Mean                  25.5653\n",
      "trainer/Log Pis Std                    6.12824\n",
      "trainer/Policy mu Mean                 1.18079\n",
      "trainer/Policy mu Std                  2.1795\n",
      "trainer/Policy log std Mean           -3.15948\n",
      "trainer/Policy log std Std             1.35165\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        46506\n",
      "exploration/num paths total          716\n",
      "evaluation/num steps total         90255\n",
      "evaluation/num paths total           381\n",
      "evaluation/path length Mean          188.3\n",
      "evaluation/path length Std             2.68514\n",
      "evaluation/path length Max           192\n",
      "evaluation/path length Min           183\n",
      "evaluation/Rewards Mean                3.36685\n",
      "evaluation/Rewards Std                 1.89024\n",
      "evaluation/Rewards Max                 5.92335\n",
      "evaluation/Rewards Min                 0.125608\n",
      "evaluation/Returns Mean              633.977\n",
      "evaluation/Returns Std                10.7023\n",
      "evaluation/Returns Max               645.299\n",
      "evaluation/Returns Min               609.63\n",
      "evaluation/Estimation Bias Mean      261.626\n",
      "evaluation/Estimation Bias Std       174.789\n",
      "evaluation/EB/Q_True Mean             23.4686\n",
      "evaluation/EB/Q_True Std              74.5899\n",
      "evaluation/EB/Q_Pred Mean            285.094\n",
      "evaluation/EB/Q_Pred Std             164.524\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           633.977\n",
      "evaluation/Actions Mean                0.538777\n",
      "evaluation/Actions Std                 0.604463\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999994\n",
      "time/backward_policy (s)               1.78897\n",
      "time/backward_zf1 (s)                  1.90191\n",
      "time/backward_zf2 (s)                  1.85064\n",
      "time/data sampling (s)                 0.222834\n",
      "time/data storing (s)                  0.0144474\n",
      "time/evaluation sampling (s)           0.322455\n",
      "time/exploration sampling (s)          0.201354\n",
      "time/logging (s)                       0.00346137\n",
      "time/preback_alpha (s)                 0.546941\n",
      "time/preback_policy (s)                1.00059\n",
      "time/preback_start (s)                 0.117463\n",
      "time/preback_zf (s)                    5.03807\n",
      "time/saving (s)                        0.00508588\n",
      "time/training (s)                      2.40933\n",
      "time/epoch (s)                        15.4236\n",
      "time/total (s)                       598.312\n",
      "Epoch                                 37\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:02:19.652035 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 38 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 49000\n",
      "trainer/ZF1 Loss                      -0.56702\n",
      "trainer/ZF2 Loss                      -1.19133\n",
      "trainer/ZF Expert Reward              18.7677\n",
      "trainer/ZF Policy Reward              -6.45414\n",
      "trainer/ZF CHI2 Term                  24.6038\n",
      "trainer/Policy Loss                 -177.965\n",
      "trainer/Bias Loss                    100.256\n",
      "trainer/Bias Value                    10.3719\n",
      "trainer/Policy Grad Norm             119.027\n",
      "trainer/Policy Param Norm             24.8002\n",
      "trainer/Zf1 Grad Norm                857.608\n",
      "trainer/Zf1 Param Norm                61.608\n",
      "trainer/Zf2 Grad Norm                894.545\n",
      "trainer/Zf2 Param Norm                60.5527\n",
      "trainer/Z Expert Predictions Mean    329.796\n",
      "trainer/Z Expert Predictions Std      86.6656\n",
      "trainer/Z Expert Predictions Max     621.977\n",
      "trainer/Z Expert Predictions Min     149.623\n",
      "trainer/Z Policy Predictions Mean    167.182\n",
      "trainer/Z Policy Predictions Std     174.099\n",
      "trainer/Z Policy Predictions Max     554.04\n",
      "trainer/Z Policy Predictions Min    -186.389\n",
      "trainer/Z Expert Targets Mean        311.029\n",
      "trainer/Z Expert Targets Std          87.6032\n",
      "trainer/Z Expert Targets Max         600.153\n",
      "trainer/Z Expert Targets Min         136.907\n",
      "trainer/Z Policy Targets Mean        173.636\n",
      "trainer/Z Policy Targets Std         171.35\n",
      "trainer/Z Policy Targets Max         565.152\n",
      "trainer/Z Policy Targets Min        -180.266\n",
      "trainer/Log Pis Mean                  26.1089\n",
      "trainer/Log Pis Std                    6.81604\n",
      "trainer/Policy mu Mean                 1.24793\n",
      "trainer/Policy mu Std                  2.47353\n",
      "trainer/Policy log std Mean           -3.06526\n",
      "trainer/Policy log std Std             1.43901\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        48322\n",
      "exploration/num paths total          725\n",
      "evaluation/num steps total         91802\n",
      "evaluation/num paths total           391\n",
      "evaluation/path length Mean          154.7\n",
      "evaluation/path length Std             1.9\n",
      "evaluation/path length Max           159\n",
      "evaluation/path length Min           152\n",
      "evaluation/Rewards Mean                3.02771\n",
      "evaluation/Rewards Std                 1.94381\n",
      "evaluation/Rewards Max                 6.23255\n",
      "evaluation/Rewards Min                 0.103494\n",
      "evaluation/Returns Mean              468.387\n",
      "evaluation/Returns Std                 6.75555\n",
      "evaluation/Returns Max               484.097\n",
      "evaluation/Returns Min               460.588\n",
      "evaluation/Estimation Bias Mean      309.682\n",
      "evaluation/Estimation Bias Std       173.033\n",
      "evaluation/EB/Q_True Mean             19.9141\n",
      "evaluation/EB/Q_True Std              62.7223\n",
      "evaluation/EB/Q_Pred Mean            329.596\n",
      "evaluation/EB/Q_Pred Std             166.789\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           468.387\n",
      "evaluation/Actions Mean                0.497757\n",
      "evaluation/Actions Std                 0.596941\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999997\n",
      "time/backward_policy (s)               1.89622\n",
      "time/backward_zf1 (s)                  2.0215\n",
      "time/backward_zf2 (s)                  1.98863\n",
      "time/data sampling (s)                 0.207308\n",
      "time/data storing (s)                  0.013779\n",
      "time/evaluation sampling (s)           0.235695\n",
      "time/exploration sampling (s)          0.195554\n",
      "time/logging (s)                       0.00273734\n",
      "time/preback_alpha (s)                 0.541706\n",
      "time/preback_policy (s)                1.17911\n",
      "time/preback_start (s)                 0.116\n",
      "time/preback_zf (s)                    5.02408\n",
      "time/saving (s)                        0.00510604\n",
      "time/training (s)                      1.91995\n",
      "time/epoch (s)                        15.3474\n",
      "time/total (s)                       613.68\n",
      "Epoch                                 38\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:02:35.159863 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 39 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 50000\n",
      "trainer/ZF1 Loss                       6.19589\n",
      "trainer/ZF2 Loss                       5.53436\n",
      "trainer/ZF Expert Reward              21.1589\n",
      "trainer/ZF Policy Reward              -1.41074\n",
      "trainer/ZF CHI2 Term                  28.7062\n",
      "trainer/Policy Loss                 -179.491\n",
      "trainer/Bias Loss                     99.2559\n",
      "trainer/Bias Value                    10.3814\n",
      "trainer/Policy Grad Norm             115.137\n",
      "trainer/Policy Param Norm             24.9564\n",
      "trainer/Zf1 Grad Norm                959.164\n",
      "trainer/Zf1 Param Norm                61.7893\n",
      "trainer/Zf2 Grad Norm                900.511\n",
      "trainer/Zf2 Param Norm                60.6804\n",
      "trainer/Z Expert Predictions Mean    315.155\n",
      "trainer/Z Expert Predictions Std      81.4328\n",
      "trainer/Z Expert Predictions Max     539.516\n",
      "trainer/Z Expert Predictions Min     148.653\n",
      "trainer/Z Policy Predictions Mean    169.528\n",
      "trainer/Z Policy Predictions Std     160.972\n",
      "trainer/Z Policy Predictions Max     581.601\n",
      "trainer/Z Policy Predictions Min    -213.403\n",
      "trainer/Z Expert Targets Mean        293.996\n",
      "trainer/Z Expert Targets Std          83.0562\n",
      "trainer/Z Expert Targets Max         531.446\n",
      "trainer/Z Expert Targets Min         127.885\n",
      "trainer/Z Policy Targets Mean        170.939\n",
      "trainer/Z Policy Targets Std         159.176\n",
      "trainer/Z Policy Targets Max         565.872\n",
      "trainer/Z Policy Targets Min        -200.964\n",
      "trainer/Log Pis Mean                  27.1501\n",
      "trainer/Log Pis Std                    7.18644\n",
      "trainer/Policy mu Mean                 1.25459\n",
      "trainer/Policy mu Std                  2.43995\n",
      "trainer/Policy log std Mean           -3.14641\n",
      "trainer/Policy log std Std             1.41756\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        49118\n",
      "exploration/num paths total          730\n",
      "evaluation/num steps total         93877\n",
      "evaluation/num paths total           401\n",
      "evaluation/path length Mean          207.5\n",
      "evaluation/path length Std             5.27731\n",
      "evaluation/path length Max           216\n",
      "evaluation/path length Min           195\n",
      "evaluation/Rewards Mean                3.30745\n",
      "evaluation/Rewards Std                 1.69857\n",
      "evaluation/Rewards Max                 5.94461\n",
      "evaluation/Rewards Min                 0.122786\n",
      "evaluation/Returns Mean              686.296\n",
      "evaluation/Returns Std                23.3993\n",
      "evaluation/Returns Max               720.56\n",
      "evaluation/Returns Min               630.853\n",
      "evaluation/Estimation Bias Mean      235.611\n",
      "evaluation/Estimation Bias Std       206.747\n",
      "evaluation/EB/Q_True Mean             24.5032\n",
      "evaluation/EB/Q_True Std              77.229\n",
      "evaluation/EB/Q_Pred Mean            260.115\n",
      "evaluation/EB/Q_Pred Std             199.246\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           686.296\n",
      "evaluation/Actions Mean                0.489549\n",
      "evaluation/Actions Std                 0.62774\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.81638\n",
      "time/backward_zf1 (s)                  1.92883\n",
      "time/backward_zf2 (s)                  1.88987\n",
      "time/data sampling (s)                 0.210085\n",
      "time/data storing (s)                  0.0146273\n",
      "time/evaluation sampling (s)           0.34836\n",
      "time/exploration sampling (s)          0.200109\n",
      "time/logging (s)                       0.00380673\n",
      "time/preback_alpha (s)                 0.547096\n",
      "time/preback_policy (s)                1.03705\n",
      "time/preback_start (s)                 0.116483\n",
      "time/preback_zf (s)                    5.03594\n",
      "time/saving (s)                        0.00625681\n",
      "time/training (s)                      2.29269\n",
      "time/epoch (s)                        15.4476\n",
      "time/total (s)                       629.145\n",
      "Epoch                                 39\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:02:50.838534 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 40 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 51000\n",
      "trainer/ZF1 Loss                       0.655628\n",
      "trainer/ZF2 Loss                      -1.28983\n",
      "trainer/ZF Expert Reward              20.7823\n",
      "trainer/ZF Policy Reward              -8.47509\n",
      "trainer/ZF CHI2 Term                  29.2188\n",
      "trainer/Policy Loss                 -173.121\n",
      "trainer/Bias Loss                    111.888\n",
      "trainer/Bias Value                    10.391\n",
      "trainer/Policy Grad Norm             152.478\n",
      "trainer/Policy Param Norm             25.0741\n",
      "trainer/Zf1 Grad Norm               1366.02\n",
      "trainer/Zf1 Param Norm                61.9555\n",
      "trainer/Zf2 Grad Norm               1161.09\n",
      "trainer/Zf2 Param Norm                60.8314\n",
      "trainer/Z Expert Predictions Mean    301.047\n",
      "trainer/Z Expert Predictions Std      96.361\n",
      "trainer/Z Expert Predictions Max     605.542\n",
      "trainer/Z Expert Predictions Min     117.83\n",
      "trainer/Z Policy Predictions Mean    156.15\n",
      "trainer/Z Policy Predictions Std     163.095\n",
      "trainer/Z Policy Predictions Max     553.113\n",
      "trainer/Z Policy Predictions Min    -136.724\n",
      "trainer/Z Expert Targets Mean        280.264\n",
      "trainer/Z Expert Targets Std          98.2517\n",
      "trainer/Z Expert Targets Max         588.912\n",
      "trainer/Z Expert Targets Min         103.691\n",
      "trainer/Z Policy Targets Mean        164.625\n",
      "trainer/Z Policy Targets Std         162.855\n",
      "trainer/Z Policy Targets Max         546.45\n",
      "trainer/Z Policy Targets Min        -135.646\n",
      "trainer/Log Pis Mean                  27.8528\n",
      "trainer/Log Pis Std                    6.85676\n",
      "trainer/Policy mu Mean                 1.38039\n",
      "trainer/Policy mu Std                  2.49541\n",
      "trainer/Policy log std Mean           -3.1762\n",
      "trainer/Policy log std Std             1.35695\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        50034\n",
      "exploration/num paths total          735\n",
      "evaluation/num steps total         96239\n",
      "evaluation/num paths total           411\n",
      "evaluation/path length Mean          236.2\n",
      "evaluation/path length Std             5.1342\n",
      "evaluation/path length Max           246\n",
      "evaluation/path length Min           230\n",
      "evaluation/Rewards Mean                3.29434\n",
      "evaluation/Rewards Std                 1.58982\n",
      "evaluation/Rewards Max                 6.2892\n",
      "evaluation/Rewards Min                 0.102058\n",
      "evaluation/Returns Mean              778.124\n",
      "evaluation/Returns Std                30.2895\n",
      "evaluation/Returns Max               838.766\n",
      "evaluation/Returns Min               745.617\n",
      "evaluation/Estimation Bias Mean      228.767\n",
      "evaluation/Estimation Bias Std       206.216\n",
      "evaluation/EB/Q_True Mean             25.9004\n",
      "evaluation/EB/Q_True Std              81.3788\n",
      "evaluation/EB/Q_Pred Mean            254.667\n",
      "evaluation/EB/Q_Pred Std             196.335\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           778.124\n",
      "evaluation/Actions Mean                0.448661\n",
      "evaluation/Actions Std                 0.637056\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999985\n",
      "time/backward_policy (s)               1.86865\n",
      "time/backward_zf1 (s)                  1.97399\n",
      "time/backward_zf2 (s)                  1.92346\n",
      "time/data sampling (s)                 0.21687\n",
      "time/data storing (s)                  0.0145006\n",
      "time/evaluation sampling (s)           0.388629\n",
      "time/exploration sampling (s)          0.200845\n",
      "time/logging (s)                       0.00380461\n",
      "time/preback_alpha (s)                 0.549215\n",
      "time/preback_policy (s)                1.07971\n",
      "time/preback_start (s)                 0.118209\n",
      "time/preback_zf (s)                    5.02008\n",
      "time/saving (s)                        0.00514919\n",
      "time/training (s)                      2.2522\n",
      "time/epoch (s)                        15.6153\n",
      "time/total (s)                       644.779\n",
      "Epoch                                 40\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:03:06.308884 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 41 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 52000\n",
      "trainer/ZF1 Loss                       1.03339\n",
      "trainer/ZF2 Loss                      -0.967104\n",
      "trainer/ZF Expert Reward              18.29\n",
      "trainer/ZF Policy Reward              -4.97784\n",
      "trainer/ZF CHI2 Term                  23.5691\n",
      "trainer/Policy Loss                 -156.43\n",
      "trainer/Bias Loss                     99.9031\n",
      "trainer/Bias Value                    10.4005\n",
      "trainer/Policy Grad Norm             142.26\n",
      "trainer/Policy Param Norm             25.189\n",
      "trainer/Zf1 Grad Norm               1086.76\n",
      "trainer/Zf1 Param Norm                62.1128\n",
      "trainer/Zf2 Grad Norm               1412.64\n",
      "trainer/Zf2 Param Norm                61.0265\n",
      "trainer/Z Expert Predictions Mean    297.141\n",
      "trainer/Z Expert Predictions Std     107.309\n",
      "trainer/Z Expert Predictions Max     606.651\n",
      "trainer/Z Expert Predictions Min      96.1261\n",
      "trainer/Z Policy Predictions Mean    147.696\n",
      "trainer/Z Policy Predictions Std     174.623\n",
      "trainer/Z Policy Predictions Max     587.332\n",
      "trainer/Z Policy Predictions Min    -143.827\n",
      "trainer/Z Expert Targets Mean        278.851\n",
      "trainer/Z Expert Targets Std         109.524\n",
      "trainer/Z Expert Targets Max         591.706\n",
      "trainer/Z Expert Targets Min          71.125\n",
      "trainer/Z Policy Targets Mean        152.673\n",
      "trainer/Z Policy Targets Std         174.267\n",
      "trainer/Z Policy Targets Max         581.987\n",
      "trainer/Z Policy Targets Min        -141.407\n",
      "trainer/Log Pis Mean                  26.8118\n",
      "trainer/Log Pis Std                    6.91809\n",
      "trainer/Policy mu Mean                 1.36468\n",
      "trainer/Policy mu Std                  2.39089\n",
      "trainer/Policy log std Mean           -3.09144\n",
      "trainer/Policy log std Std             1.43547\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        50493\n",
      "exploration/num paths total          737\n",
      "evaluation/num steps total         98903\n",
      "evaluation/num paths total           421\n",
      "evaluation/path length Mean          266.4\n",
      "evaluation/path length Std            32.0787\n",
      "evaluation/path length Max           352\n",
      "evaluation/path length Min           233\n",
      "evaluation/Rewards Mean                3.17235\n",
      "evaluation/Rewards Std                 1.44796\n",
      "evaluation/Rewards Max                 6.00309\n",
      "evaluation/Rewards Min                -2.88293\n",
      "evaluation/Returns Mean              845.115\n",
      "evaluation/Returns Std                89.691\n",
      "evaluation/Returns Max              1080.18\n",
      "evaluation/Returns Min               768.165\n",
      "evaluation/Estimation Bias Mean      187.105\n",
      "evaluation/Estimation Bias Std       206.954\n",
      "evaluation/EB/Q_True Mean             31.8872\n",
      "evaluation/EB/Q_True Std              88.9759\n",
      "evaluation/EB/Q_Pred Mean            218.992\n",
      "evaluation/EB/Q_Pred Std             199.923\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           845.115\n",
      "evaluation/Actions Mean                0.411908\n",
      "evaluation/Actions Std                 0.659503\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999996\n",
      "time/backward_policy (s)               1.77466\n",
      "time/backward_zf1 (s)                  1.89877\n",
      "time/backward_zf2 (s)                  1.8388\n",
      "time/data sampling (s)                 0.208122\n",
      "time/data storing (s)                  0.0141852\n",
      "time/evaluation sampling (s)           0.536119\n",
      "time/exploration sampling (s)          0.193988\n",
      "time/logging (s)                       0.00416414\n",
      "time/preback_alpha (s)                 0.541046\n",
      "time/preback_policy (s)                1.0355\n",
      "time/preback_start (s)                 0.116008\n",
      "time/preback_zf (s)                    5.01147\n",
      "time/saving (s)                        0.00522129\n",
      "time/training (s)                      2.2321\n",
      "time/epoch (s)                        15.4102\n",
      "time/total (s)                       660.207\n",
      "Epoch                                 41\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:03:22.173574 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 42 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  53000\n",
      "trainer/ZF1 Loss                       -5.03501\n",
      "trainer/ZF2 Loss                       -4.75753\n",
      "trainer/ZF Expert Reward               19.6296\n",
      "trainer/ZF Policy Reward               -7.29625\n",
      "trainer/ZF CHI2 Term                   22.2816\n",
      "trainer/Policy Loss                  -160.905\n",
      "trainer/Bias Loss                      87.4539\n",
      "trainer/Bias Value                     10.41\n",
      "trainer/Policy Grad Norm              182.016\n",
      "trainer/Policy Param Norm              25.2876\n",
      "trainer/Zf1 Grad Norm                1037.58\n",
      "trainer/Zf1 Param Norm                 62.2887\n",
      "trainer/Zf2 Grad Norm                 797.706\n",
      "trainer/Zf2 Param Norm                 61.2975\n",
      "trainer/Z Expert Predictions Mean     300.748\n",
      "trainer/Z Expert Predictions Std      102.277\n",
      "trainer/Z Expert Predictions Max      604.374\n",
      "trainer/Z Expert Predictions Min       94.0633\n",
      "trainer/Z Policy Predictions Mean     148.635\n",
      "trainer/Z Policy Predictions Std      173.294\n",
      "trainer/Z Policy Predictions Max      594.927\n",
      "trainer/Z Policy Predictions Min     -151.869\n",
      "trainer/Z Expert Targets Mean         281.119\n",
      "trainer/Z Expert Targets Std          104.533\n",
      "trainer/Z Expert Targets Max          596.52\n",
      "trainer/Z Expert Targets Min           73.0218\n",
      "trainer/Z Policy Targets Mean         155.931\n",
      "trainer/Z Policy Targets Std          172.776\n",
      "trainer/Z Policy Targets Max          604.09\n",
      "trainer/Z Policy Targets Min         -140.374\n",
      "trainer/Log Pis Mean                   25.1997\n",
      "trainer/Log Pis Std                     7.40899\n",
      "trainer/Policy mu Mean                  1.18239\n",
      "trainer/Policy mu Std                   2.2367\n",
      "trainer/Policy log std Mean            -3.09418\n",
      "trainer/Policy log std Std              1.3636\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         51659\n",
      "exploration/num paths total           742\n",
      "evaluation/num steps total         101785\n",
      "evaluation/num paths total            431\n",
      "evaluation/path length Mean           288.2\n",
      "evaluation/path length Std             44.0677\n",
      "evaluation/path length Max            388\n",
      "evaluation/path length Min            245\n",
      "evaluation/Rewards Mean                 2.99078\n",
      "evaluation/Rewards Std                  1.3343\n",
      "evaluation/Rewards Max                  5.95485\n",
      "evaluation/Rewards Min                 -1.35385\n",
      "evaluation/Returns Mean               861.944\n",
      "evaluation/Returns Std                134.923\n",
      "evaluation/Returns Max               1130.54\n",
      "evaluation/Returns Min                718.423\n",
      "evaluation/Estimation Bias Mean       162.128\n",
      "evaluation/Estimation Bias Std        220.489\n",
      "evaluation/EB/Q_True Mean              31.3707\n",
      "evaluation/EB/Q_True Std               85.4348\n",
      "evaluation/EB/Q_Pred Mean             193.499\n",
      "evaluation/EB/Q_Pred Std              217.925\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            861.944\n",
      "evaluation/Actions Mean                 0.368187\n",
      "evaluation/Actions Std                  0.655805\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999958\n",
      "time/backward_policy (s)                1.91111\n",
      "time/backward_zf1 (s)                   2.03444\n",
      "time/backward_zf2 (s)                   2.00687\n",
      "time/data sampling (s)                  0.21196\n",
      "time/data storing (s)                   0.0135229\n",
      "time/evaluation sampling (s)            0.631616\n",
      "time/exploration sampling (s)           0.190724\n",
      "time/logging (s)                        0.00438721\n",
      "time/preback_alpha (s)                  0.544642\n",
      "time/preback_policy (s)                 1.18444\n",
      "time/preback_start (s)                  0.115611\n",
      "time/preback_zf (s)                     5.02249\n",
      "time/saving (s)                         0.00525501\n",
      "time/training (s)                       1.91465\n",
      "time/epoch (s)                         15.7917\n",
      "time/total (s)                        676.028\n",
      "Epoch                                  42\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:03:37.545497 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 43 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  54000\n",
      "trainer/ZF1 Loss                       11.0562\n",
      "trainer/ZF2 Loss                       12.2708\n",
      "trainer/ZF Expert Reward               19.4025\n",
      "trainer/ZF Policy Reward               -6.62389\n",
      "trainer/ZF CHI2 Term                   37.9381\n",
      "trainer/Policy Loss                  -157.529\n",
      "trainer/Bias Loss                     210.509\n",
      "trainer/Bias Value                     10.4196\n",
      "trainer/Policy Grad Norm              254.444\n",
      "trainer/Policy Param Norm              25.3801\n",
      "trainer/Zf1 Grad Norm                 842.044\n",
      "trainer/Zf1 Param Norm                 62.5086\n",
      "trainer/Zf2 Grad Norm                1113.42\n",
      "trainer/Zf2 Param Norm                 61.5581\n",
      "trainer/Z Expert Predictions Mean     313.224\n",
      "trainer/Z Expert Predictions Std      109.746\n",
      "trainer/Z Expert Predictions Max      630.611\n",
      "trainer/Z Expert Predictions Min       82.8146\n",
      "trainer/Z Policy Predictions Mean     149.626\n",
      "trainer/Z Policy Predictions Std      192.892\n",
      "trainer/Z Policy Predictions Max      608.051\n",
      "trainer/Z Policy Predictions Min     -130.212\n",
      "trainer/Z Expert Targets Mean         293.821\n",
      "trainer/Z Expert Targets Std          111.529\n",
      "trainer/Z Expert Targets Max          618.899\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         156.25\n",
      "trainer/Z Policy Targets Std          190.996\n",
      "trainer/Z Policy Targets Max          594.22\n",
      "trainer/Z Policy Targets Min         -114.771\n",
      "trainer/Log Pis Mean                   24.8152\n",
      "trainer/Log Pis Std                     7.01039\n",
      "trainer/Policy mu Mean                  1.06883\n",
      "trainer/Policy mu Std                   2.23747\n",
      "trainer/Policy log std Mean            -3.15783\n",
      "trainer/Policy log std Std              1.4434\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         52492\n",
      "exploration/num paths total           745\n",
      "evaluation/num steps total         104184\n",
      "evaluation/num paths total            441\n",
      "evaluation/path length Mean           239.9\n",
      "evaluation/path length Std             31.1238\n",
      "evaluation/path length Max            298\n",
      "evaluation/path length Min            208\n",
      "evaluation/Rewards Mean                 3.33829\n",
      "evaluation/Rewards Std                  1.61074\n",
      "evaluation/Rewards Max                  8.03631\n",
      "evaluation/Rewards Min                 -2.38894\n",
      "evaluation/Returns Mean               800.856\n",
      "evaluation/Returns Std                110.581\n",
      "evaluation/Returns Max                998.016\n",
      "evaluation/Returns Min                652.079\n",
      "evaluation/Estimation Bias Mean       197.174\n",
      "evaluation/Estimation Bias Std        233.611\n",
      "evaluation/EB/Q_True Mean              31.9466\n",
      "evaluation/EB/Q_True Std               91.8097\n",
      "evaluation/EB/Q_Pred Mean             229.121\n",
      "evaluation/EB/Q_Pred Std              225.214\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            800.856\n",
      "evaluation/Actions Mean                 0.390628\n",
      "evaluation/Actions Std                  0.653072\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71001\n",
      "time/backward_zf1 (s)                   1.82838\n",
      "time/backward_zf2 (s)                   1.76548\n",
      "time/data sampling (s)                  0.218472\n",
      "time/data storing (s)                   0.0141672\n",
      "time/evaluation sampling (s)            0.463069\n",
      "time/exploration sampling (s)           0.193898\n",
      "time/logging (s)                        0.00410375\n",
      "time/preback_alpha (s)                  0.545835\n",
      "time/preback_policy (s)                 0.95786\n",
      "time/preback_start (s)                  0.11767\n",
      "time/preback_zf (s)                     5.03643\n",
      "time/saving (s)                         0.00556813\n",
      "time/training (s)                       2.44822\n",
      "time/epoch (s)                         15.3092\n",
      "time/total (s)                        691.356\n",
      "Epoch                                  43\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:03:52.911850 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 44 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  55000\n",
      "trainer/ZF1 Loss                        2.90009\n",
      "trainer/ZF2 Loss                        4.95428\n",
      "trainer/ZF Expert Reward               15.0421\n",
      "trainer/ZF Policy Reward               -9.72439\n",
      "trainer/ZF CHI2 Term                   28.9345\n",
      "trainer/Policy Loss                  -152.911\n",
      "trainer/Bias Loss                     119.531\n",
      "trainer/Bias Value                     10.4291\n",
      "trainer/Policy Grad Norm              132.756\n",
      "trainer/Policy Param Norm              25.4791\n",
      "trainer/Zf1 Grad Norm                1940.54\n",
      "trainer/Zf1 Param Norm                 62.7963\n",
      "trainer/Zf2 Grad Norm                2125.66\n",
      "trainer/Zf2 Param Norm                 61.8338\n",
      "trainer/Z Expert Predictions Mean     314.673\n",
      "trainer/Z Expert Predictions Std      128.437\n",
      "trainer/Z Expert Predictions Max      631.776\n",
      "trainer/Z Expert Predictions Min       70.3761\n",
      "trainer/Z Policy Predictions Mean     142.264\n",
      "trainer/Z Policy Predictions Std      193.652\n",
      "trainer/Z Policy Predictions Max      624.245\n",
      "trainer/Z Policy Predictions Min     -185.449\n",
      "trainer/Z Expert Targets Mean         299.631\n",
      "trainer/Z Expert Targets Std          130.242\n",
      "trainer/Z Expert Targets Max          629.588\n",
      "trainer/Z Expert Targets Min           41.733\n",
      "trainer/Z Policy Targets Mean         151.989\n",
      "trainer/Z Policy Targets Std          193.212\n",
      "trainer/Z Policy Targets Max          620.472\n",
      "trainer/Z Policy Targets Min         -174.924\n",
      "trainer/Log Pis Mean                   24.0902\n",
      "trainer/Log Pis Std                     6.53192\n",
      "trainer/Policy mu Mean                  0.964045\n",
      "trainer/Policy mu Std                   2.09227\n",
      "trainer/Policy log std Mean            -3.1115\n",
      "trainer/Policy log std Std              1.30115\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         54102\n",
      "exploration/num paths total           751\n",
      "evaluation/num steps total         106724\n",
      "evaluation/num paths total            451\n",
      "evaluation/path length Mean           254\n",
      "evaluation/path length Std             23.4734\n",
      "evaluation/path length Max            305\n",
      "evaluation/path length Min            228\n",
      "evaluation/Rewards Mean                 3.26452\n",
      "evaluation/Rewards Std                  1.58868\n",
      "evaluation/Rewards Max                  8.47586\n",
      "evaluation/Rewards Min                 -3.60701\n",
      "evaluation/Returns Mean               829.189\n",
      "evaluation/Returns Std                102.484\n",
      "evaluation/Returns Max               1031.96\n",
      "evaluation/Returns Min                710.644\n",
      "evaluation/Estimation Bias Mean       182.885\n",
      "evaluation/Estimation Bias Std        240.425\n",
      "evaluation/EB/Q_True Mean              31.4939\n",
      "evaluation/EB/Q_True Std               91.0065\n",
      "evaluation/EB/Q_Pred Mean             214.379\n",
      "evaluation/EB/Q_Pred Std              232.379\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            829.189\n",
      "evaluation/Actions Mean                 0.385728\n",
      "evaluation/Actions Std                  0.648966\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72878\n",
      "time/backward_zf1 (s)                   1.83096\n",
      "time/backward_zf2 (s)                   1.77095\n",
      "time/data sampling (s)                  0.213292\n",
      "time/data storing (s)                   0.0135619\n",
      "time/evaluation sampling (s)            0.507207\n",
      "time/exploration sampling (s)           0.193051\n",
      "time/logging (s)                        0.00413951\n",
      "time/preback_alpha (s)                  0.539173\n",
      "time/preback_policy (s)                 0.963681\n",
      "time/preback_start (s)                  0.116171\n",
      "time/preback_zf (s)                     4.99513\n",
      "time/saving (s)                         0.00528411\n",
      "time/training (s)                       2.42259\n",
      "time/epoch (s)                         15.304\n",
      "time/total (s)                        706.679\n",
      "Epoch                                  44\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:04:08.889535 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 45 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  56000\n",
      "trainer/ZF1 Loss                       12.7378\n",
      "trainer/ZF2 Loss                       10.7634\n",
      "trainer/ZF Expert Reward               17.7133\n",
      "trainer/ZF Policy Reward               -9.2238\n",
      "trainer/ZF CHI2 Term                   38.9297\n",
      "trainer/Policy Loss                  -147.068\n",
      "trainer/Bias Loss                     203.322\n",
      "trainer/Bias Value                     10.4385\n",
      "trainer/Policy Grad Norm              175.845\n",
      "trainer/Policy Param Norm              25.6115\n",
      "trainer/Zf1 Grad Norm                1646.66\n",
      "trainer/Zf1 Param Norm                 63.1028\n",
      "trainer/Zf2 Grad Norm                1720.88\n",
      "trainer/Zf2 Param Norm                 62.1203\n",
      "trainer/Z Expert Predictions Mean     333.426\n",
      "trainer/Z Expert Predictions Std      129.716\n",
      "trainer/Z Expert Predictions Max      641.461\n",
      "trainer/Z Expert Predictions Min       59.4365\n",
      "trainer/Z Policy Predictions Mean     132.013\n",
      "trainer/Z Policy Predictions Std      207.061\n",
      "trainer/Z Policy Predictions Max      633.796\n",
      "trainer/Z Policy Predictions Min     -203.123\n",
      "trainer/Z Expert Targets Mean         315.713\n",
      "trainer/Z Expert Targets Std          133.446\n",
      "trainer/Z Expert Targets Max          628.517\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         141.237\n",
      "trainer/Z Policy Targets Std          208.641\n",
      "trainer/Z Policy Targets Max          632.051\n",
      "trainer/Z Policy Targets Min         -201.288\n",
      "trainer/Log Pis Mean                   24.2025\n",
      "trainer/Log Pis Std                     6.70049\n",
      "trainer/Policy mu Mean                  0.959853\n",
      "trainer/Policy mu Std                   2.12082\n",
      "trainer/Policy log std Mean            -3.15127\n",
      "trainer/Policy log std Std              1.35199\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         54833\n",
      "exploration/num paths total           754\n",
      "evaluation/num steps total         109780\n",
      "evaluation/num paths total            461\n",
      "evaluation/path length Mean           305.6\n",
      "evaluation/path length Std             74.7077\n",
      "evaluation/path length Max            462\n",
      "evaluation/path length Min            243\n",
      "evaluation/Rewards Mean                 3.08118\n",
      "evaluation/Rewards Std                  1.53025\n",
      "evaluation/Rewards Max                  6.19348\n",
      "evaluation/Rewards Min                 -3.99289\n",
      "evaluation/Returns Mean               941.61\n",
      "evaluation/Returns Std                188.213\n",
      "evaluation/Returns Max               1416.57\n",
      "evaluation/Returns Min                792.498\n",
      "evaluation/Estimation Bias Mean       147.405\n",
      "evaluation/Estimation Bias Std        234.894\n",
      "evaluation/EB/Q_True Mean              38.5536\n",
      "evaluation/EB/Q_True Std               98.6405\n",
      "evaluation/EB/Q_Pred Mean             185.959\n",
      "evaluation/EB/Q_Pred Std              229.497\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            941.61\n",
      "evaluation/Actions Mean                 0.393641\n",
      "evaluation/Actions Std                  0.650371\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92495\n",
      "time/backward_zf1 (s)                   2.01235\n",
      "time/backward_zf2 (s)                   1.96409\n",
      "time/data sampling (s)                  0.227674\n",
      "time/data storing (s)                   0.0138046\n",
      "time/evaluation sampling (s)            0.686998\n",
      "time/exploration sampling (s)           0.19735\n",
      "time/logging (s)                        0.00439134\n",
      "time/preback_alpha (s)                  0.545252\n",
      "time/preback_policy (s)                 1.12057\n",
      "time/preback_start (s)                  0.117613\n",
      "time/preback_zf (s)                     5.01333\n",
      "time/saving (s)                         0.0049642\n",
      "time/training (s)                       2.08362\n",
      "time/epoch (s)                         15.917\n",
      "time/total (s)                        722.612\n",
      "Epoch                                  45\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:04:24.414223 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 46 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  57000\n",
      "trainer/ZF1 Loss                        8.66911\n",
      "trainer/ZF2 Loss                       10.6834\n",
      "trainer/ZF Expert Reward               18.5873\n",
      "trainer/ZF Policy Reward               -9.8751\n",
      "trainer/ZF CHI2 Term                   38.3932\n",
      "trainer/Policy Loss                  -160.109\n",
      "trainer/Bias Loss                     146.621\n",
      "trainer/Bias Value                     10.4479\n",
      "trainer/Policy Grad Norm              207.771\n",
      "trainer/Policy Param Norm              25.7646\n",
      "trainer/Zf1 Grad Norm                1549.29\n",
      "trainer/Zf1 Param Norm                 63.4061\n",
      "trainer/Zf2 Grad Norm                1654.76\n",
      "trainer/Zf2 Param Norm                 62.4102\n",
      "trainer/Z Expert Predictions Mean     333.864\n",
      "trainer/Z Expert Predictions Std      129.982\n",
      "trainer/Z Expert Predictions Max      637.123\n",
      "trainer/Z Expert Predictions Min       51.5711\n",
      "trainer/Z Policy Predictions Mean     150.916\n",
      "trainer/Z Policy Predictions Std      229.71\n",
      "trainer/Z Policy Predictions Max      624.708\n",
      "trainer/Z Policy Predictions Min     -211.204\n",
      "trainer/Z Expert Targets Mean         315.277\n",
      "trainer/Z Expert Targets Std          132.754\n",
      "trainer/Z Expert Targets Max          625.925\n",
      "trainer/Z Expert Targets Min           32.6071\n",
      "trainer/Z Policy Targets Mean         160.792\n",
      "trainer/Z Policy Targets Std          231.111\n",
      "trainer/Z Policy Targets Max          617.845\n",
      "trainer/Z Policy Targets Min         -194.732\n",
      "trainer/Log Pis Mean                   25.4565\n",
      "trainer/Log Pis Std                     7.78239\n",
      "trainer/Policy mu Mean                  0.812219\n",
      "trainer/Policy mu Std                   2.3511\n",
      "trainer/Policy log std Mean            -3.22514\n",
      "trainer/Policy log std Std              1.45539\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         55547\n",
      "exploration/num paths total           757\n",
      "evaluation/num steps total         112318\n",
      "evaluation/num paths total            471\n",
      "evaluation/path length Mean           253.8\n",
      "evaluation/path length Std              3.09192\n",
      "evaluation/path length Max            258\n",
      "evaluation/path length Min            248\n",
      "evaluation/Rewards Mean                 3.28683\n",
      "evaluation/Rewards Std                  1.72859\n",
      "evaluation/Rewards Max                  7.13082\n",
      "evaluation/Rewards Min                 -4.27554\n",
      "evaluation/Returns Mean               834.197\n",
      "evaluation/Returns Std                 20.3635\n",
      "evaluation/Returns Max                860.725\n",
      "evaluation/Returns Min                804.344\n",
      "evaluation/Estimation Bias Mean       217.134\n",
      "evaluation/Estimation Bias Std        242.572\n",
      "evaluation/EB/Q_True Mean              24.9282\n",
      "evaluation/EB/Q_True Std               81.4774\n",
      "evaluation/EB/Q_Pred Mean             242.062\n",
      "evaluation/EB/Q_Pred Std              235.474\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            834.197\n",
      "evaluation/Actions Mean                 0.435445\n",
      "evaluation/Actions Std                  0.656961\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9013\n",
      "time/backward_zf1 (s)                   2.00708\n",
      "time/backward_zf2 (s)                   1.9765\n",
      "time/data sampling (s)                  0.213969\n",
      "time/data storing (s)                   0.013397\n",
      "time/evaluation sampling (s)            0.401297\n",
      "time/exploration sampling (s)           0.189891\n",
      "time/logging (s)                        0.00432983\n",
      "time/preback_alpha (s)                  0.541287\n",
      "time/preback_policy (s)                 1.17289\n",
      "time/preback_start (s)                  0.11714\n",
      "time/preback_zf (s)                     4.98684\n",
      "time/saving (s)                         0.00512392\n",
      "time/training (s)                       1.93047\n",
      "time/epoch (s)                         15.4615\n",
      "time/total (s)                        738.093\n",
      "Epoch                                  46\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:04:39.792075 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 47 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  58000\n",
      "trainer/ZF1 Loss                       23.0554\n",
      "trainer/ZF2 Loss                       20.7989\n",
      "trainer/ZF Expert Reward               21.2691\n",
      "trainer/ZF Policy Reward               -4.98454\n",
      "trainer/ZF CHI2 Term                   48.4294\n",
      "trainer/Policy Loss                  -142.976\n",
      "trainer/Bias Loss                     307.028\n",
      "trainer/Bias Value                     10.4572\n",
      "trainer/Policy Grad Norm              129.974\n",
      "trainer/Policy Param Norm              25.925\n",
      "trainer/Zf1 Grad Norm                1481.37\n",
      "trainer/Zf1 Param Norm                 63.7077\n",
      "trainer/Zf2 Grad Norm                1312.36\n",
      "trainer/Zf2 Param Norm                 62.7278\n",
      "trainer/Z Expert Predictions Mean     338.454\n",
      "trainer/Z Expert Predictions Std      132.021\n",
      "trainer/Z Expert Predictions Max      640.99\n",
      "trainer/Z Expert Predictions Min       67.8526\n",
      "trainer/Z Policy Predictions Mean     134.408\n",
      "trainer/Z Policy Predictions Std      222.184\n",
      "trainer/Z Policy Predictions Max      643.398\n",
      "trainer/Z Policy Predictions Min     -146.012\n",
      "trainer/Z Expert Targets Mean         317.185\n",
      "trainer/Z Expert Targets Std          136.483\n",
      "trainer/Z Expert Targets Max          633.37\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         139.393\n",
      "trainer/Z Policy Targets Std          220.779\n",
      "trainer/Z Policy Targets Max          639.453\n",
      "trainer/Z Policy Targets Min         -134.46\n",
      "trainer/Log Pis Mean                   24.8642\n",
      "trainer/Log Pis Std                     8.03217\n",
      "trainer/Policy mu Mean                  0.868434\n",
      "trainer/Policy mu Std                   2.42346\n",
      "trainer/Policy log std Mean            -3.08711\n",
      "trainer/Policy log std Std              1.4498\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         56451\n",
      "exploration/num paths total           761\n",
      "evaluation/num steps total         114887\n",
      "evaluation/num paths total            481\n",
      "evaluation/path length Mean           256.9\n",
      "evaluation/path length Std             33.0195\n",
      "evaluation/path length Max            334\n",
      "evaluation/path length Min            219\n",
      "evaluation/Rewards Mean                 3.2289\n",
      "evaluation/Rewards Std                  1.58737\n",
      "evaluation/Rewards Max                  6.95073\n",
      "evaluation/Rewards Min                 -3.00601\n",
      "evaluation/Returns Mean               829.506\n",
      "evaluation/Returns Std                120.256\n",
      "evaluation/Returns Max               1068.27\n",
      "evaluation/Returns Min                694.066\n",
      "evaluation/Estimation Bias Mean       173.126\n",
      "evaluation/Estimation Bias Std        253.532\n",
      "evaluation/EB/Q_True Mean              32.4741\n",
      "evaluation/EB/Q_True Std               91.5741\n",
      "evaluation/EB/Q_Pred Mean             205.601\n",
      "evaluation/EB/Q_Pred Std              250.43\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            829.506\n",
      "evaluation/Actions Mean                 0.447244\n",
      "evaluation/Actions Std                  0.654046\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.69122\n",
      "time/backward_zf1 (s)                   1.80219\n",
      "time/backward_zf2 (s)                   1.73894\n",
      "time/data sampling (s)                  0.216582\n",
      "time/data storing (s)                   0.0137749\n",
      "time/evaluation sampling (s)            0.508902\n",
      "time/exploration sampling (s)           0.191854\n",
      "time/logging (s)                        0.00498741\n",
      "time/preback_alpha (s)                  0.540739\n",
      "time/preback_policy (s)                 0.919853\n",
      "time/preback_start (s)                  0.116663\n",
      "time/preback_zf (s)                     5.01457\n",
      "time/saving (s)                         0.0172396\n",
      "time/training (s)                       2.53325\n",
      "time/epoch (s)                         15.3108\n",
      "time/total (s)                        753.428\n",
      "Epoch                                  47\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:04:55.893147 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 48 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  59000\n",
      "trainer/ZF1 Loss                       12.0405\n",
      "trainer/ZF2 Loss                        9.76261\n",
      "trainer/ZF Expert Reward               17.0345\n",
      "trainer/ZF Policy Reward               -6.85965\n",
      "trainer/ZF CHI2 Term                   35.0376\n",
      "trainer/Policy Loss                  -137.631\n",
      "trainer/Bias Loss                     171.525\n",
      "trainer/Bias Value                     10.4664\n",
      "trainer/Policy Grad Norm              153.777\n",
      "trainer/Policy Param Norm              26.0732\n",
      "trainer/Zf1 Grad Norm                1918.57\n",
      "trainer/Zf1 Param Norm                 64.0037\n",
      "trainer/Zf2 Grad Norm                2072.13\n",
      "trainer/Zf2 Param Norm                 63.03\n",
      "trainer/Z Expert Predictions Mean     334.431\n",
      "trainer/Z Expert Predictions Std      151.194\n",
      "trainer/Z Expert Predictions Max      636.043\n",
      "trainer/Z Expert Predictions Min       41.95\n",
      "trainer/Z Policy Predictions Mean     122.619\n",
      "trainer/Z Policy Predictions Std      222.76\n",
      "trainer/Z Policy Predictions Max      628.967\n",
      "trainer/Z Policy Predictions Min     -151.115\n",
      "trainer/Z Expert Targets Mean         317.396\n",
      "trainer/Z Expert Targets Std          153.699\n",
      "trainer/Z Expert Targets Max          638.959\n",
      "trainer/Z Expert Targets Min           18.8454\n",
      "trainer/Z Policy Targets Mean         129.478\n",
      "trainer/Z Policy Targets Std          223.014\n",
      "trainer/Z Policy Targets Max          627.128\n",
      "trainer/Z Policy Targets Min         -142.987\n",
      "trainer/Log Pis Mean                   24.1892\n",
      "trainer/Log Pis Std                     7.62968\n",
      "trainer/Policy mu Mean                  0.925985\n",
      "trainer/Policy mu Std                   2.33098\n",
      "trainer/Policy log std Mean            -3.00062\n",
      "trainer/Policy log std Std              1.39656\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         56775\n",
      "exploration/num paths total           762\n",
      "evaluation/num steps total         118445\n",
      "evaluation/num paths total            491\n",
      "evaluation/path length Mean           355.8\n",
      "evaluation/path length Std             77.0036\n",
      "evaluation/path length Max            555\n",
      "evaluation/path length Min            294\n",
      "evaluation/Rewards Mean                 3.83899\n",
      "evaluation/Rewards Std                  1.69147\n",
      "evaluation/Rewards Max                  7.01064\n",
      "evaluation/Rewards Min                 -2.92866\n",
      "evaluation/Returns Mean              1365.91\n",
      "evaluation/Returns Std                443.053\n",
      "evaluation/Returns Max               2509.41\n",
      "evaluation/Returns Min               1037.27\n",
      "evaluation/Estimation Bias Mean       180.912\n",
      "evaluation/Estimation Bias Std        232.309\n",
      "evaluation/EB/Q_True Mean              46.6195\n",
      "evaluation/EB/Q_True Std              120.059\n",
      "evaluation/EB/Q_Pred Mean             227.531\n",
      "evaluation/EB/Q_Pred Std              216.442\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1365.91\n",
      "evaluation/Actions Mean                 0.536936\n",
      "evaluation/Actions Std                  0.633714\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88808\n",
      "time/backward_zf1 (s)                   2.00589\n",
      "time/backward_zf2 (s)                   1.95615\n",
      "time/data sampling (s)                  0.210782\n",
      "time/data storing (s)                   0.0140295\n",
      "time/evaluation sampling (s)            1.00141\n",
      "time/exploration sampling (s)           0.191069\n",
      "time/logging (s)                        0.00494263\n",
      "time/preback_alpha (s)                  0.539665\n",
      "time/preback_policy (s)                 1.14503\n",
      "time/preback_start (s)                  0.116146\n",
      "time/preback_zf (s)                     4.98978\n",
      "time/saving (s)                         0.00514599\n",
      "time/training (s)                       1.96977\n",
      "time/epoch (s)                         16.0379\n",
      "time/total (s)                        769.485\n",
      "Epoch                                  48\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:05:11.134320 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 49 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  60000\n",
      "trainer/ZF1 Loss                        7.08892\n",
      "trainer/ZF2 Loss                       12.7556\n",
      "trainer/ZF Expert Reward               23.7763\n",
      "trainer/ZF Policy Reward               -1.08949\n",
      "trainer/ZF CHI2 Term                   35.049\n",
      "trainer/Policy Loss                  -189.749\n",
      "trainer/Bias Loss                     195.632\n",
      "trainer/Bias Value                     10.4755\n",
      "trainer/Policy Grad Norm              214.805\n",
      "trainer/Policy Param Norm              26.2278\n",
      "trainer/Zf1 Grad Norm                1695.05\n",
      "trainer/Zf1 Param Norm                 64.267\n",
      "trainer/Zf2 Grad Norm                2311.55\n",
      "trainer/Zf2 Param Norm                 63.2813\n",
      "trainer/Z Expert Predictions Mean     330.816\n",
      "trainer/Z Expert Predictions Std      150.001\n",
      "trainer/Z Expert Predictions Max      628.971\n",
      "trainer/Z Expert Predictions Min       27.4064\n",
      "trainer/Z Policy Predictions Mean     180.91\n",
      "trainer/Z Policy Predictions Std      257.691\n",
      "trainer/Z Policy Predictions Max      645.56\n",
      "trainer/Z Policy Predictions Min     -163.23\n",
      "trainer/Z Expert Targets Mean         307.04\n",
      "trainer/Z Expert Targets Std          151.23\n",
      "trainer/Z Expert Targets Max          624.128\n",
      "trainer/Z Expert Targets Min            8.85188\n",
      "trainer/Z Policy Targets Mean         182\n",
      "trainer/Z Policy Targets Std          256.537\n",
      "trainer/Z Policy Targets Max          635.151\n",
      "trainer/Z Policy Targets Min         -165.451\n",
      "trainer/Log Pis Mean                   26.0975\n",
      "trainer/Log Pis Std                     8.31933\n",
      "trainer/Policy mu Mean                  0.964856\n",
      "trainer/Policy mu Std                   2.34698\n",
      "trainer/Policy log std Mean            -3.21319\n",
      "trainer/Policy log std Std              1.44312\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         59006\n",
      "exploration/num paths total           770\n",
      "evaluation/num steps total         119957\n",
      "evaluation/num paths total            501\n",
      "evaluation/path length Mean           151.2\n",
      "evaluation/path length Std             14.3234\n",
      "evaluation/path length Max            194\n",
      "evaluation/path length Min            145\n",
      "evaluation/Rewards Mean                 2.73811\n",
      "evaluation/Rewards Std                  1.77825\n",
      "evaluation/Rewards Max                  6.04179\n",
      "evaluation/Rewards Min                  0.0759559\n",
      "evaluation/Returns Mean               414.002\n",
      "evaluation/Returns Std                 58.0999\n",
      "evaluation/Returns Max                587.668\n",
      "evaluation/Returns Min                389.797\n",
      "evaluation/Estimation Bias Mean       331.208\n",
      "evaluation/Estimation Bias Std        218.461\n",
      "evaluation/EB/Q_True Mean              26.1661\n",
      "evaluation/EB/Q_True Std               74.8185\n",
      "evaluation/EB/Q_Pred Mean             357.374\n",
      "evaluation/EB/Q_Pred Std              210.061\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            414.002\n",
      "evaluation/Actions Mean                 0.442126\n",
      "evaluation/Actions Std                  0.627762\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72433\n",
      "time/backward_zf1 (s)                   1.84426\n",
      "time/backward_zf2 (s)                   1.78716\n",
      "time/data sampling (s)                  0.215313\n",
      "time/data storing (s)                   0.0133841\n",
      "time/evaluation sampling (s)            0.317638\n",
      "time/exploration sampling (s)           0.194464\n",
      "time/logging (s)                        0.00277876\n",
      "time/preback_alpha (s)                  0.541296\n",
      "time/preback_policy (s)                 0.964643\n",
      "time/preback_start (s)                  0.116\n",
      "time/preback_zf (s)                     5.0179\n",
      "time/saving (s)                         0.00526019\n",
      "time/training (s)                       2.43048\n",
      "time/epoch (s)                         15.1749\n",
      "time/total (s)                        784.68\n",
      "Epoch                                  49\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:05:26.803255 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 50 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  61000\n",
      "trainer/ZF1 Loss                        7.10003\n",
      "trainer/ZF2 Loss                        5.91728\n",
      "trainer/ZF Expert Reward               21.2358\n",
      "trainer/ZF Policy Reward               -2.071\n",
      "trainer/ZF CHI2 Term                   30.0771\n",
      "trainer/Policy Loss                  -175.049\n",
      "trainer/Bias Loss                     118.085\n",
      "trainer/Bias Value                     10.4847\n",
      "trainer/Policy Grad Norm              238.314\n",
      "trainer/Policy Param Norm              26.3562\n",
      "trainer/Zf1 Grad Norm                1589.26\n",
      "trainer/Zf1 Param Norm                 64.4916\n",
      "trainer/Zf2 Grad Norm                1565.53\n",
      "trainer/Zf2 Param Norm                 63.4727\n",
      "trainer/Z Expert Predictions Mean     312.929\n",
      "trainer/Z Expert Predictions Std      143.579\n",
      "trainer/Z Expert Predictions Max      661.337\n",
      "trainer/Z Expert Predictions Min       -9.23731\n",
      "trainer/Z Policy Predictions Mean     162.034\n",
      "trainer/Z Policy Predictions Std      253.037\n",
      "trainer/Z Policy Predictions Max      642.961\n",
      "trainer/Z Policy Predictions Min     -155.557\n",
      "trainer/Z Expert Targets Mean         291.693\n",
      "trainer/Z Expert Targets Std          146.159\n",
      "trainer/Z Expert Targets Max          650.698\n",
      "trainer/Z Expert Targets Min          -34.9896\n",
      "trainer/Z Policy Targets Mean         164.105\n",
      "trainer/Z Policy Targets Std          252.558\n",
      "trainer/Z Policy Targets Max          650.839\n",
      "trainer/Z Policy Targets Min         -166.635\n",
      "trainer/Log Pis Mean                   26.1613\n",
      "trainer/Log Pis Std                     8.69267\n",
      "trainer/Policy mu Mean                  0.869416\n",
      "trainer/Policy mu Std                   2.46677\n",
      "trainer/Policy log std Mean            -3.07288\n",
      "trainer/Policy log std Std              1.44702\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         60364\n",
      "exploration/num paths total           777\n",
      "evaluation/num steps total         121963\n",
      "evaluation/num paths total            511\n",
      "evaluation/path length Mean           200.6\n",
      "evaluation/path length Std             53.5466\n",
      "evaluation/path length Max            347\n",
      "evaluation/path length Min            150\n",
      "evaluation/Rewards Mean                 3.12301\n",
      "evaluation/Rewards Std                  1.76425\n",
      "evaluation/Rewards Max                  7.23097\n",
      "evaluation/Rewards Min                 -1.77757\n",
      "evaluation/Returns Mean               626.475\n",
      "evaluation/Returns Std                193.14\n",
      "evaluation/Returns Max               1107.31\n",
      "evaluation/Returns Min                404.061\n",
      "evaluation/Estimation Bias Mean       200.239\n",
      "evaluation/Estimation Bias Std        258.817\n",
      "evaluation/EB/Q_True Mean              43.5097\n",
      "evaluation/EB/Q_True Std              105.191\n",
      "evaluation/EB/Q_Pred Mean             243.748\n",
      "evaluation/EB/Q_Pred Std              257.014\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            626.475\n",
      "evaluation/Actions Mean                 0.483101\n",
      "evaluation/Actions Std                  0.628126\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88013\n",
      "time/backward_zf1 (s)                   2.01233\n",
      "time/backward_zf2 (s)                   1.97134\n",
      "time/data sampling (s)                  0.221813\n",
      "time/data storing (s)                   0.0138306\n",
      "time/evaluation sampling (s)            0.521264\n",
      "time/exploration sampling (s)           0.195745\n",
      "time/logging (s)                        0.00324662\n",
      "time/preback_alpha (s)                  0.542266\n",
      "time/preback_policy (s)                 1.15087\n",
      "time/preback_start (s)                  0.118234\n",
      "time/preback_zf (s)                     4.99626\n",
      "time/saving (s)                         0.00629795\n",
      "time/training (s)                       1.97415\n",
      "time/epoch (s)                         15.6078\n",
      "time/total (s)                        800.306\n",
      "Epoch                                  50\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:05:42.503394 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 51 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  62000\n",
      "trainer/ZF1 Loss                        7.33304\n",
      "trainer/ZF2 Loss                        8.09885\n",
      "trainer/ZF Expert Reward               12.995\n",
      "trainer/ZF Policy Reward               -6.23677\n",
      "trainer/ZF CHI2 Term                   27.1991\n",
      "trainer/Policy Loss                  -141.989\n",
      "trainer/Bias Loss                      72.4783\n",
      "trainer/Bias Value                     10.4941\n",
      "trainer/Policy Grad Norm              155.299\n",
      "trainer/Policy Param Norm              26.4596\n",
      "trainer/Zf1 Grad Norm                1480.13\n",
      "trainer/Zf1 Param Norm                 64.6672\n",
      "trainer/Zf2 Grad Norm                1957.45\n",
      "trainer/Zf2 Param Norm                 63.6523\n",
      "trainer/Z Expert Predictions Mean     264.113\n",
      "trainer/Z Expert Predictions Std      139.555\n",
      "trainer/Z Expert Predictions Max      620.179\n",
      "trainer/Z Expert Predictions Min      -18.0072\n",
      "trainer/Z Policy Predictions Mean     128.559\n",
      "trainer/Z Policy Predictions Std      243.7\n",
      "trainer/Z Policy Predictions Max      630.409\n",
      "trainer/Z Policy Predictions Min     -212.189\n",
      "trainer/Z Expert Targets Mean         251.118\n",
      "trainer/Z Expert Targets Std          143.047\n",
      "trainer/Z Expert Targets Max          615.027\n",
      "trainer/Z Expert Targets Min          -37.9878\n",
      "trainer/Z Policy Targets Mean         134.795\n",
      "trainer/Z Policy Targets Std          242.228\n",
      "trainer/Z Policy Targets Max          629.636\n",
      "trainer/Z Policy Targets Min         -203.192\n",
      "trainer/Log Pis Mean                   25.1456\n",
      "trainer/Log Pis Std                     8.56337\n",
      "trainer/Policy mu Mean                  0.7807\n",
      "trainer/Policy mu Std                   2.73401\n",
      "trainer/Policy log std Mean            -2.92586\n",
      "trainer/Policy log std Std              1.45724\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         60813\n",
      "exploration/num paths total           780\n",
      "evaluation/num steps total         124793\n",
      "evaluation/num paths total            521\n",
      "evaluation/path length Mean           283\n",
      "evaluation/path length Std             26.1343\n",
      "evaluation/path length Max            334\n",
      "evaluation/path length Min            254\n",
      "evaluation/Rewards Mean                 3.73396\n",
      "evaluation/Rewards Std                  1.78909\n",
      "evaluation/Rewards Max                  7.28104\n",
      "evaluation/Rewards Min                 -1.16444\n",
      "evaluation/Returns Mean              1056.71\n",
      "evaluation/Returns Std                139.815\n",
      "evaluation/Returns Max               1275.06\n",
      "evaluation/Returns Min                902.814\n",
      "evaluation/Estimation Bias Mean       167.736\n",
      "evaluation/Estimation Bias Std        246.959\n",
      "evaluation/EB/Q_True Mean              36.4352\n",
      "evaluation/EB/Q_True Std              106.637\n",
      "evaluation/EB/Q_Pred Mean             204.172\n",
      "evaluation/EB/Q_Pred Std              229.216\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1056.71\n",
      "evaluation/Actions Mean                 0.525201\n",
      "evaluation/Actions Std                  0.622871\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86565\n",
      "time/backward_zf1 (s)                   1.98622\n",
      "time/backward_zf2 (s)                   1.93768\n",
      "time/data sampling (s)                  0.213175\n",
      "time/data storing (s)                   0.0139647\n",
      "time/evaluation sampling (s)            0.534192\n",
      "time/exploration sampling (s)           0.195053\n",
      "time/logging (s)                        0.00430146\n",
      "time/preback_alpha (s)                  0.549352\n",
      "time/preback_policy (s)                 1.1247\n",
      "time/preback_start (s)                  0.117758\n",
      "time/preback_zf (s)                     5.04431\n",
      "time/saving (s)                         0.00531993\n",
      "time/training (s)                       2.04661\n",
      "time/epoch (s)                         15.6383\n",
      "time/total (s)                        815.962\n",
      "Epoch                                  51\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:05:57.788186 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 52 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  63000\n",
      "trainer/ZF1 Loss                        7.07531\n",
      "trainer/ZF2 Loss                        7.26267\n",
      "trainer/ZF Expert Reward               21.2828\n",
      "trainer/ZF Policy Reward               -2.54239\n",
      "trainer/ZF CHI2 Term                   31.2469\n",
      "trainer/Policy Loss                  -146.165\n",
      "trainer/Bias Loss                     128.632\n",
      "trainer/Bias Value                     10.5034\n",
      "trainer/Policy Grad Norm              131.346\n",
      "trainer/Policy Param Norm              26.5466\n",
      "trainer/Zf1 Grad Norm                 955.482\n",
      "trainer/Zf1 Param Norm                 64.7971\n",
      "trainer/Zf2 Grad Norm                1134.2\n",
      "trainer/Zf2 Param Norm                 63.8105\n",
      "trainer/Z Expert Predictions Mean     239.047\n",
      "trainer/Z Expert Predictions Std      140.28\n",
      "trainer/Z Expert Predictions Max      643.874\n",
      "trainer/Z Expert Predictions Min      -12.7062\n",
      "trainer/Z Policy Predictions Mean     136.423\n",
      "trainer/Z Policy Predictions Std      243.796\n",
      "trainer/Z Policy Predictions Max      633.2\n",
      "trainer/Z Policy Predictions Min     -184.882\n",
      "trainer/Z Expert Targets Mean         217.764\n",
      "trainer/Z Expert Targets Std          141.397\n",
      "trainer/Z Expert Targets Max          635.503\n",
      "trainer/Z Expert Targets Min          -28.9102\n",
      "trainer/Z Policy Targets Mean         138.965\n",
      "trainer/Z Policy Targets Std          242.607\n",
      "trainer/Z Policy Targets Max          632.538\n",
      "trainer/Z Policy Targets Min         -185.415\n",
      "trainer/Log Pis Mean                   25.2659\n",
      "trainer/Log Pis Std                     8.95405\n",
      "trainer/Policy mu Mean                  0.869596\n",
      "trainer/Policy mu Std                   2.61349\n",
      "trainer/Policy log std Mean            -3.03186\n",
      "trainer/Policy log std Std              1.44654\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         60813\n",
      "exploration/num paths total           780\n",
      "evaluation/num steps total         126936\n",
      "evaluation/num paths total            531\n",
      "evaluation/path length Mean           214.3\n",
      "evaluation/path length Std             40.5637\n",
      "evaluation/path length Max            318\n",
      "evaluation/path length Min            193\n",
      "evaluation/Rewards Mean                 3.189\n",
      "evaluation/Rewards Std                  1.65754\n",
      "evaluation/Rewards Max                  7.11643\n",
      "evaluation/Rewards Min                 -2.48904\n",
      "evaluation/Returns Mean               683.402\n",
      "evaluation/Returns Std                163.669\n",
      "evaluation/Returns Max               1101.51\n",
      "evaluation/Returns Min                600.612\n",
      "evaluation/Estimation Bias Mean       187.934\n",
      "evaluation/Estimation Bias Std        243.974\n",
      "evaluation/EB/Q_True Mean              28.2343\n",
      "evaluation/EB/Q_True Std               75.2881\n",
      "evaluation/EB/Q_Pred Mean             216.168\n",
      "evaluation/EB/Q_Pred Std              249.703\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            683.402\n",
      "evaluation/Actions Mean                 0.500952\n",
      "evaluation/Actions Std                  0.601708\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.65492\n",
      "time/backward_zf1 (s)                   1.77479\n",
      "time/backward_zf2 (s)                   1.7113\n",
      "time/data sampling (s)                  0.212394\n",
      "time/data storing (s)                   0.0132817\n",
      "time/evaluation sampling (s)            0.606207\n",
      "time/exploration sampling (s)           0.184389\n",
      "time/logging (s)                        0.003464\n",
      "time/preback_alpha (s)                  0.537126\n",
      "time/preback_policy (s)                 0.904447\n",
      "time/preback_start (s)                  0.114895\n",
      "time/preback_zf (s)                     4.99044\n",
      "time/saving (s)                         0.00550328\n",
      "time/training (s)                       2.50915\n",
      "time/epoch (s)                         15.2223\n",
      "time/total (s)                        831.203\n",
      "Epoch                                  52\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:06:13.823354 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 53 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  64000\n",
      "trainer/ZF1 Loss                        5.07501\n",
      "trainer/ZF2 Loss                        1.28749\n",
      "trainer/ZF Expert Reward               20.4608\n",
      "trainer/ZF Policy Reward               -5.10364\n",
      "trainer/ZF CHI2 Term                   29.0022\n",
      "trainer/Policy Loss                  -142.687\n",
      "trainer/Bias Loss                     129.671\n",
      "trainer/Bias Value                     10.5129\n",
      "trainer/Policy Grad Norm              154.361\n",
      "trainer/Policy Param Norm              26.662\n",
      "trainer/Zf1 Grad Norm                1174.42\n",
      "trainer/Zf1 Param Norm                 64.9946\n",
      "trainer/Zf2 Grad Norm                1214.79\n",
      "trainer/Zf2 Param Norm                 64.03\n",
      "trainer/Z Expert Predictions Mean     215.123\n",
      "trainer/Z Expert Predictions Std      142.56\n",
      "trainer/Z Expert Predictions Max      629.821\n",
      "trainer/Z Expert Predictions Min      -28.3967\n",
      "trainer/Z Policy Predictions Mean     131.388\n",
      "trainer/Z Policy Predictions Std      240.404\n",
      "trainer/Z Policy Predictions Max      627.199\n",
      "trainer/Z Policy Predictions Min     -197.069\n",
      "trainer/Z Expert Targets Mean         194.663\n",
      "trainer/Z Expert Targets Std          144.043\n",
      "trainer/Z Expert Targets Max          617.98\n",
      "trainer/Z Expert Targets Min          -40.6288\n",
      "trainer/Z Policy Targets Mean         136.491\n",
      "trainer/Z Policy Targets Std          238.555\n",
      "trainer/Z Policy Targets Max          632.122\n",
      "trainer/Z Policy Targets Min         -176.788\n",
      "trainer/Log Pis Mean                   25.6489\n",
      "trainer/Log Pis Std                     8.76813\n",
      "trainer/Policy mu Mean                  0.849926\n",
      "trainer/Policy mu Std                   2.62921\n",
      "trainer/Policy log std Mean            -3.12777\n",
      "trainer/Policy log std Std              1.47334\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         63090\n",
      "exploration/num paths total           789\n",
      "evaluation/num steps total         129531\n",
      "evaluation/num paths total            541\n",
      "evaluation/path length Mean           259.5\n",
      "evaluation/path length Std             36.4424\n",
      "evaluation/path length Max            325\n",
      "evaluation/path length Min            201\n",
      "evaluation/Rewards Mean                 3.60304\n",
      "evaluation/Rewards Std                  1.83011\n",
      "evaluation/Rewards Max                  7.54335\n",
      "evaluation/Rewards Min                 -2.42329\n",
      "evaluation/Returns Mean               934.989\n",
      "evaluation/Returns Std                194.847\n",
      "evaluation/Returns Max               1307.45\n",
      "evaluation/Returns Min                630.518\n",
      "evaluation/Estimation Bias Mean       157.835\n",
      "evaluation/Estimation Bias Std        223.953\n",
      "evaluation/EB/Q_True Mean              26.9951\n",
      "evaluation/EB/Q_True Std               79.1216\n",
      "evaluation/EB/Q_Pred Mean             184.83\n",
      "evaluation/EB/Q_Pred Std              229.073\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            934.989\n",
      "evaluation/Actions Mean                 0.524342\n",
      "evaluation/Actions Std                  0.606926\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94621\n",
      "time/backward_zf1 (s)                   2.05722\n",
      "time/backward_zf2 (s)                   2.01501\n",
      "time/data sampling (s)                  0.216785\n",
      "time/data storing (s)                   0.0142625\n",
      "time/evaluation sampling (s)            0.729311\n",
      "time/exploration sampling (s)           0.200567\n",
      "time/logging (s)                        0.00382796\n",
      "time/preback_alpha (s)                  0.543981\n",
      "time/preback_policy (s)                 1.18037\n",
      "time/preback_start (s)                  0.117403\n",
      "time/preback_zf (s)                     5.01358\n",
      "time/saving (s)                         0.00511704\n",
      "time/training (s)                       1.92846\n",
      "time/epoch (s)                         15.9721\n",
      "time/total (s)                        847.195\n",
      "Epoch                                  53\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:06:29.523955 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 54 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  65000\n",
      "trainer/ZF1 Loss                        2.62226\n",
      "trainer/ZF2 Loss                        3.01821\n",
      "trainer/ZF Expert Reward               16.6325\n",
      "trainer/ZF Policy Reward               -7.3616\n",
      "trainer/ZF CHI2 Term                   27.0742\n",
      "trainer/Policy Loss                  -169.721\n",
      "trainer/Bias Loss                      94.6722\n",
      "trainer/Bias Value                     10.5223\n",
      "trainer/Policy Grad Norm              138.298\n",
      "trainer/Policy Param Norm              26.7607\n",
      "trainer/Zf1 Grad Norm                1292.49\n",
      "trainer/Zf1 Param Norm                 65.263\n",
      "trainer/Zf2 Grad Norm                1867.93\n",
      "trainer/Zf2 Param Norm                 64.2249\n",
      "trainer/Z Expert Predictions Mean     183.552\n",
      "trainer/Z Expert Predictions Std      146.055\n",
      "trainer/Z Expert Predictions Max      623.006\n",
      "trainer/Z Expert Predictions Min      -50.4419\n",
      "trainer/Z Policy Predictions Mean     154.666\n",
      "trainer/Z Policy Predictions Std      247.51\n",
      "trainer/Z Policy Predictions Max      615.977\n",
      "trainer/Z Policy Predictions Min     -188.406\n",
      "trainer/Z Expert Targets Mean         166.919\n",
      "trainer/Z Expert Targets Std          149.296\n",
      "trainer/Z Expert Targets Max          620.481\n",
      "trainer/Z Expert Targets Min          -71.317\n",
      "trainer/Z Policy Targets Mean         162.028\n",
      "trainer/Z Policy Targets Std          246.654\n",
      "trainer/Z Policy Targets Max          622.951\n",
      "trainer/Z Policy Targets Min         -188.519\n",
      "trainer/Log Pis Mean                   25.9898\n",
      "trainer/Log Pis Std                     7.528\n",
      "trainer/Policy mu Mean                  1.00142\n",
      "trainer/Policy mu Std                   2.41953\n",
      "trainer/Policy log std Mean            -3.09875\n",
      "trainer/Policy log std Std              1.45744\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         63455\n",
      "exploration/num paths total           790\n",
      "evaluation/num steps total         132103\n",
      "evaluation/num paths total            551\n",
      "evaluation/path length Mean           257.2\n",
      "evaluation/path length Std             50.2589\n",
      "evaluation/path length Max            403\n",
      "evaluation/path length Min            216\n",
      "evaluation/Rewards Mean                 3.3911\n",
      "evaluation/Rewards Std                  1.69784\n",
      "evaluation/Rewards Max                  6.81826\n",
      "evaluation/Rewards Min                 -3.77072\n",
      "evaluation/Returns Mean               872.191\n",
      "evaluation/Returns Std                221.335\n",
      "evaluation/Returns Max               1514.59\n",
      "evaluation/Returns Min                695.226\n",
      "evaluation/Estimation Bias Mean       105.003\n",
      "evaluation/Estimation Bias Std        262.699\n",
      "evaluation/EB/Q_True Mean              38.6245\n",
      "evaluation/EB/Q_True Std               96.5662\n",
      "evaluation/EB/Q_Pred Mean             143.627\n",
      "evaluation/EB/Q_Pred Std              266.716\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            872.191\n",
      "evaluation/Actions Mean                 0.512001\n",
      "evaluation/Actions Std                  0.608322\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79479\n",
      "time/backward_zf1 (s)                   1.92593\n",
      "time/backward_zf2 (s)                   1.8666\n",
      "time/data sampling (s)                  0.209425\n",
      "time/data storing (s)                   0.0137248\n",
      "time/evaluation sampling (s)            0.663817\n",
      "time/exploration sampling (s)           0.193258\n",
      "time/logging (s)                        0.00413737\n",
      "time/preback_alpha (s)                  0.543418\n",
      "time/preback_policy (s)                 1.04987\n",
      "time/preback_start (s)                  0.117073\n",
      "time/preback_zf (s)                     5.01539\n",
      "time/saving (s)                         0.00528997\n",
      "time/training (s)                       2.23655\n",
      "time/epoch (s)                         15.6393\n",
      "time/total (s)                        862.852\n",
      "Epoch                                  54\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:06:44.828068 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 55 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  66000\n",
      "trainer/ZF1 Loss                        5.59828\n",
      "trainer/ZF2 Loss                        5.2959\n",
      "trainer/ZF Expert Reward               18.1994\n",
      "trainer/ZF Policy Reward               -5.82768\n",
      "trainer/ZF CHI2 Term                   29.7213\n",
      "trainer/Policy Loss                  -168.139\n",
      "trainer/Bias Loss                     137.043\n",
      "trainer/Bias Value                     10.5317\n",
      "trainer/Policy Grad Norm              150.782\n",
      "trainer/Policy Param Norm              26.8698\n",
      "trainer/Zf1 Grad Norm                1556.71\n",
      "trainer/Zf1 Param Norm                 65.4906\n",
      "trainer/Zf2 Grad Norm                2692.91\n",
      "trainer/Zf2 Param Norm                 64.4049\n",
      "trainer/Z Expert Predictions Mean     158.967\n",
      "trainer/Z Expert Predictions Std      147.195\n",
      "trainer/Z Expert Predictions Max      600.555\n",
      "trainer/Z Expert Predictions Min      -68.9559\n",
      "trainer/Z Policy Predictions Mean     154.571\n",
      "trainer/Z Policy Predictions Std      246.616\n",
      "trainer/Z Policy Predictions Max      609.842\n",
      "trainer/Z Policy Predictions Min     -175.191\n",
      "trainer/Z Expert Targets Mean         140.767\n",
      "trainer/Z Expert Targets Std          152.635\n",
      "trainer/Z Expert Targets Max          601.039\n",
      "trainer/Z Expert Targets Min          -86.7203\n",
      "trainer/Z Policy Targets Mean         160.399\n",
      "trainer/Z Policy Targets Std          246.962\n",
      "trainer/Z Policy Targets Max          611.023\n",
      "trainer/Z Policy Targets Min         -158.919\n",
      "trainer/Log Pis Mean                   24.717\n",
      "trainer/Log Pis Std                     8.15718\n",
      "trainer/Policy mu Mean                  0.96011\n",
      "trainer/Policy mu Std                   2.34851\n",
      "trainer/Policy log std Mean            -3.17025\n",
      "trainer/Policy log std Std              1.47029\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         63958\n",
      "exploration/num paths total           792\n",
      "evaluation/num steps total         134820\n",
      "evaluation/num paths total            561\n",
      "evaluation/path length Mean           271.7\n",
      "evaluation/path length Std             63.0017\n",
      "evaluation/path length Max            369\n",
      "evaluation/path length Min            196\n",
      "evaluation/Rewards Mean                 3.33133\n",
      "evaluation/Rewards Std                  1.57042\n",
      "evaluation/Rewards Max                  6.99463\n",
      "evaluation/Rewards Min                 -2.21991\n",
      "evaluation/Returns Mean               905.122\n",
      "evaluation/Returns Std                234.78\n",
      "evaluation/Returns Max               1152.48\n",
      "evaluation/Returns Min                611.457\n",
      "evaluation/Estimation Bias Mean       101.072\n",
      "evaluation/Estimation Bias Std        256.69\n",
      "evaluation/EB/Q_True Mean              33.7259\n",
      "evaluation/EB/Q_True Std               92.6464\n",
      "evaluation/EB/Q_Pred Mean             134.798\n",
      "evaluation/EB/Q_Pred Std              257.628\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            905.122\n",
      "evaluation/Actions Mean                 0.469733\n",
      "evaluation/Actions Std                  0.617819\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.65596\n",
      "time/backward_zf1 (s)                   1.78206\n",
      "time/backward_zf2 (s)                   1.69732\n",
      "time/data sampling (s)                  0.208183\n",
      "time/data storing (s)                   0.0133899\n",
      "time/evaluation sampling (s)            0.579047\n",
      "time/exploration sampling (s)           0.188651\n",
      "time/logging (s)                        0.00763094\n",
      "time/preback_alpha (s)                  0.536549\n",
      "time/preback_policy (s)                 0.903917\n",
      "time/preback_start (s)                  0.115183\n",
      "time/preback_zf (s)                     5.01482\n",
      "time/saving (s)                         0.0229024\n",
      "time/training (s)                       2.51938\n",
      "time/epoch (s)                         15.245\n",
      "time/total (s)                        878.116\n",
      "Epoch                                  55\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:07:00.488350 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 56 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  67000\n",
      "trainer/ZF1 Loss                        4.23696\n",
      "trainer/ZF2 Loss                        3.01551\n",
      "trainer/ZF Expert Reward               22.7668\n",
      "trainer/ZF Policy Reward               -4.73797\n",
      "trainer/ZF CHI2 Term                   31.3799\n",
      "trainer/Policy Loss                  -125.808\n",
      "trainer/Bias Loss                     157.573\n",
      "trainer/Bias Value                     10.5412\n",
      "trainer/Policy Grad Norm              139.475\n",
      "trainer/Policy Param Norm              26.9801\n",
      "trainer/Zf1 Grad Norm                1238.39\n",
      "trainer/Zf1 Param Norm                 65.6589\n",
      "trainer/Zf2 Grad Norm                1135.29\n",
      "trainer/Zf2 Param Norm                 64.5613\n",
      "trainer/Z Expert Predictions Mean     120.265\n",
      "trainer/Z Expert Predictions Std      137.183\n",
      "trainer/Z Expert Predictions Max      596.806\n",
      "trainer/Z Expert Predictions Min      -87.2217\n",
      "trainer/Z Policy Predictions Mean     114.819\n",
      "trainer/Z Policy Predictions Std      235.723\n",
      "trainer/Z Policy Predictions Max      599.417\n",
      "trainer/Z Policy Predictions Min     -183.43\n",
      "trainer/Z Expert Targets Mean          97.4985\n",
      "trainer/Z Expert Targets Std          139.676\n",
      "trainer/Z Expert Targets Max          594.999\n",
      "trainer/Z Expert Targets Min         -117.409\n",
      "trainer/Z Policy Targets Mean         119.557\n",
      "trainer/Z Policy Targets Std          233.059\n",
      "trainer/Z Policy Targets Max          598.211\n",
      "trainer/Z Policy Targets Min         -189.974\n",
      "trainer/Log Pis Mean                   24.8893\n",
      "trainer/Log Pis Std                     8.34622\n",
      "trainer/Policy mu Mean                  0.694393\n",
      "trainer/Policy mu Std                   2.69046\n",
      "trainer/Policy log std Mean            -3.04003\n",
      "trainer/Policy log std Std              1.50317\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         64863\n",
      "exploration/num paths total           795\n",
      "evaluation/num steps total         137176\n",
      "evaluation/num paths total            571\n",
      "evaluation/path length Mean           235.6\n",
      "evaluation/path length Std             72.7382\n",
      "evaluation/path length Max            354\n",
      "evaluation/path length Min            163\n",
      "evaluation/Rewards Mean                 3.47345\n",
      "evaluation/Rewards Std                  1.80293\n",
      "evaluation/Rewards Max                  7.2557\n",
      "evaluation/Rewards Min                 -1.91613\n",
      "evaluation/Returns Mean               818.346\n",
      "evaluation/Returns Std                334.745\n",
      "evaluation/Returns Max               1287.43\n",
      "evaluation/Returns Min                478.889\n",
      "evaluation/Estimation Bias Mean       149.118\n",
      "evaluation/Estimation Bias Std        238.573\n",
      "evaluation/EB/Q_True Mean              41.9224\n",
      "evaluation/EB/Q_True Std              109.536\n",
      "evaluation/EB/Q_Pred Mean             191.04\n",
      "evaluation/EB/Q_Pred Std              232.917\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            818.346\n",
      "evaluation/Actions Mean                 0.439008\n",
      "evaluation/Actions Std                  0.637\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83683\n",
      "time/backward_zf1 (s)                   1.95695\n",
      "time/backward_zf2 (s)                   1.90914\n",
      "time/data sampling (s)                  0.218142\n",
      "time/data storing (s)                   0.013443\n",
      "time/evaluation sampling (s)            0.564665\n",
      "time/exploration sampling (s)           0.191372\n",
      "time/logging (s)                        0.00361303\n",
      "time/preback_alpha (s)                  0.54294\n",
      "time/preback_policy (s)                 1.09789\n",
      "time/preback_start (s)                  0.117117\n",
      "time/preback_zf (s)                     5.02396\n",
      "time/saving (s)                         0.00535625\n",
      "time/training (s)                       2.10941\n",
      "time/epoch (s)                         15.5908\n",
      "time/total (s)                        893.728\n",
      "Epoch                                  56\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:07:15.774553 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 57 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  68000\n",
      "trainer/ZF1 Loss                        9.93464\n",
      "trainer/ZF2 Loss                        9.4084\n",
      "trainer/ZF Expert Reward               23.7838\n",
      "trainer/ZF Policy Reward               -4.22413\n",
      "trainer/ZF CHI2 Term                   37.9284\n",
      "trainer/Policy Loss                  -145.555\n",
      "trainer/Bias Loss                     229.643\n",
      "trainer/Bias Value                     10.5506\n",
      "trainer/Policy Grad Norm              143.59\n",
      "trainer/Policy Param Norm              27.0748\n",
      "trainer/Zf1 Grad Norm                1133.01\n",
      "trainer/Zf1 Param Norm                 65.8375\n",
      "trainer/Zf2 Grad Norm                1408.09\n",
      "trainer/Zf2 Param Norm                 64.7215\n",
      "trainer/Z Expert Predictions Mean     136.418\n",
      "trainer/Z Expert Predictions Std      142.022\n",
      "trainer/Z Expert Predictions Max      571.967\n",
      "trainer/Z Expert Predictions Min      -67.706\n",
      "trainer/Z Policy Predictions Mean     135.997\n",
      "trainer/Z Policy Predictions Std      241.093\n",
      "trainer/Z Policy Predictions Max      568.526\n",
      "trainer/Z Policy Predictions Min     -202.649\n",
      "trainer/Z Expert Targets Mean         112.635\n",
      "trainer/Z Expert Targets Std          148.892\n",
      "trainer/Z Expert Targets Max          575.993\n",
      "trainer/Z Expert Targets Min          -98.7508\n",
      "trainer/Z Policy Targets Mean         140.221\n",
      "trainer/Z Policy Targets Std          240.182\n",
      "trainer/Z Policy Targets Max          560.223\n",
      "trainer/Z Policy Targets Min         -195.206\n",
      "trainer/Log Pis Mean                   24.8907\n",
      "trainer/Log Pis Std                     7.95516\n",
      "trainer/Policy mu Mean                  0.75442\n",
      "trainer/Policy mu Std                   2.58275\n",
      "trainer/Policy log std Mean            -3.15137\n",
      "trainer/Policy log std Std              1.50127\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         67224\n",
      "exploration/num paths total           802\n",
      "evaluation/num steps total         138740\n",
      "evaluation/num paths total            581\n",
      "evaluation/path length Mean           156.4\n",
      "evaluation/path length Std              1.8\n",
      "evaluation/path length Max            160\n",
      "evaluation/path length Min            153\n",
      "evaluation/Rewards Mean                 2.80249\n",
      "evaluation/Rewards Std                  1.77147\n",
      "evaluation/Rewards Max                  6.23826\n",
      "evaluation/Rewards Min                  0.108356\n",
      "evaluation/Returns Mean               438.31\n",
      "evaluation/Returns Std                  4.44354\n",
      "evaluation/Returns Max                447.881\n",
      "evaluation/Returns Min                430.712\n",
      "evaluation/Estimation Bias Mean       283.436\n",
      "evaluation/Estimation Bias Std        194.183\n",
      "evaluation/EB/Q_True Mean              17.984\n",
      "evaluation/EB/Q_True Std               57.6105\n",
      "evaluation/EB/Q_Pred Mean             301.42\n",
      "evaluation/EB/Q_Pred Std              189.989\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            438.31\n",
      "evaluation/Actions Mean                 0.405542\n",
      "evaluation/Actions Std                  0.610334\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8482\n",
      "time/backward_zf1 (s)                   1.95775\n",
      "time/backward_zf2 (s)                   1.92777\n",
      "time/data sampling (s)                  0.224222\n",
      "time/data storing (s)                   0.0139797\n",
      "time/evaluation sampling (s)            0.26777\n",
      "time/exploration sampling (s)           0.199037\n",
      "time/logging (s)                        0.00284607\n",
      "time/preback_alpha (s)                  0.541552\n",
      "time/preback_policy (s)                 1.13023\n",
      "time/preback_start (s)                  0.116856\n",
      "time/preback_zf (s)                     4.99624\n",
      "time/saving (s)                         0.0052974\n",
      "time/training (s)                       1.98938\n",
      "time/epoch (s)                         15.2211\n",
      "time/total (s)                        908.969\n",
      "Epoch                                  57\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:07:31.051719 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 58 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  69000\n",
      "trainer/ZF1 Loss                        9.05008\n",
      "trainer/ZF2 Loss                        8.181\n",
      "trainer/ZF Expert Reward               18.3817\n",
      "trainer/ZF Policy Reward               -3.77012\n",
      "trainer/ZF CHI2 Term                   31.0184\n",
      "trainer/Policy Loss                  -124.384\n",
      "trainer/Bias Loss                     121.82\n",
      "trainer/Bias Value                     10.56\n",
      "trainer/Policy Grad Norm              112.524\n",
      "trainer/Policy Param Norm              27.1454\n",
      "trainer/Zf1 Grad Norm                1858.95\n",
      "trainer/Zf1 Param Norm                 66.0045\n",
      "trainer/Zf2 Grad Norm                1570.07\n",
      "trainer/Zf2 Param Norm                 64.9097\n",
      "trainer/Z Expert Predictions Mean     156.467\n",
      "trainer/Z Expert Predictions Std      129.883\n",
      "trainer/Z Expert Predictions Max      550.462\n",
      "trainer/Z Expert Predictions Min      -85.5145\n",
      "trainer/Z Policy Predictions Mean     112.548\n",
      "trainer/Z Policy Predictions Std      224.934\n",
      "trainer/Z Policy Predictions Max      555.843\n",
      "trainer/Z Policy Predictions Min     -215.927\n",
      "trainer/Z Expert Targets Mean         138.086\n",
      "trainer/Z Expert Targets Std          133.639\n",
      "trainer/Z Expert Targets Max          548.851\n",
      "trainer/Z Expert Targets Min         -116.513\n",
      "trainer/Z Policy Targets Mean         116.318\n",
      "trainer/Z Policy Targets Std          221.395\n",
      "trainer/Z Policy Targets Max          535.649\n",
      "trainer/Z Policy Targets Min         -209.031\n",
      "trainer/Log Pis Mean                   25.0994\n",
      "trainer/Log Pis Std                     6.67945\n",
      "trainer/Policy mu Mean                  0.609637\n",
      "trainer/Policy mu Std                   2.54749\n",
      "trainer/Policy log std Mean            -3.24577\n",
      "trainer/Policy log std Std              1.46314\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         68325\n",
      "exploration/num paths total           809\n",
      "evaluation/num steps total         140401\n",
      "evaluation/num paths total            591\n",
      "evaluation/path length Mean           166.1\n",
      "evaluation/path length Std              1.3\n",
      "evaluation/path length Max            168\n",
      "evaluation/path length Min            164\n",
      "evaluation/Rewards Mean                 2.93255\n",
      "evaluation/Rewards Std                  1.76726\n",
      "evaluation/Rewards Max                  6.22665\n",
      "evaluation/Rewards Min                  0.114096\n",
      "evaluation/Returns Mean               487.096\n",
      "evaluation/Returns Std                  2.05759\n",
      "evaluation/Returns Max                490.559\n",
      "evaluation/Returns Min                484.179\n",
      "evaluation/Estimation Bias Mean       263.842\n",
      "evaluation/Estimation Bias Std        173.941\n",
      "evaluation/EB/Q_True Mean              18.8987\n",
      "evaluation/EB/Q_True Std               60.8978\n",
      "evaluation/EB/Q_Pred Mean             282.74\n",
      "evaluation/EB/Q_Pred Std              168.179\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            487.096\n",
      "evaluation/Actions Mean                 0.414459\n",
      "evaluation/Actions Std                  0.61455\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75532\n",
      "time/backward_zf1 (s)                   1.87064\n",
      "time/backward_zf2 (s)                   1.83259\n",
      "time/data sampling (s)                  0.220717\n",
      "time/data storing (s)                   0.014128\n",
      "time/evaluation sampling (s)            0.258544\n",
      "time/exploration sampling (s)           0.196316\n",
      "time/logging (s)                        0.00306395\n",
      "time/preback_alpha (s)                  0.546777\n",
      "time/preback_policy (s)                 1.01243\n",
      "time/preback_start (s)                  0.118091\n",
      "time/preback_zf (s)                     5.03876\n",
      "time/saving (s)                         0.00512149\n",
      "time/training (s)                       2.34173\n",
      "time/epoch (s)                         15.2142\n",
      "time/total (s)                        924.203\n",
      "Epoch                                  58\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:07:46.160997 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 59 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  70000\n",
      "trainer/ZF1 Loss                        8.1972\n",
      "trainer/ZF2 Loss                       10.8715\n",
      "trainer/ZF Expert Reward               16.4363\n",
      "trainer/ZF Policy Reward               -7.74698\n",
      "trainer/ZF CHI2 Term                   33.9801\n",
      "trainer/Policy Loss                  -121.672\n",
      "trainer/Bias Loss                     140.724\n",
      "trainer/Bias Value                     10.5694\n",
      "trainer/Policy Grad Norm              157.711\n",
      "trainer/Policy Param Norm              27.218\n",
      "trainer/Zf1 Grad Norm                1415.79\n",
      "trainer/Zf1 Param Norm                 66.1149\n",
      "trainer/Zf2 Grad Norm                1638.64\n",
      "trainer/Zf2 Param Norm                 65.0682\n",
      "trainer/Z Expert Predictions Mean     176.758\n",
      "trainer/Z Expert Predictions Std      126.126\n",
      "trainer/Z Expert Predictions Max      519.686\n",
      "trainer/Z Expert Predictions Min      -98.1859\n",
      "trainer/Z Policy Predictions Mean     109.899\n",
      "trainer/Z Policy Predictions Std      217.121\n",
      "trainer/Z Policy Predictions Max      508.633\n",
      "trainer/Z Policy Predictions Min     -211.665\n",
      "trainer/Z Expert Targets Mean         160.322\n",
      "trainer/Z Expert Targets Std          131.217\n",
      "trainer/Z Expert Targets Max          517.189\n",
      "trainer/Z Expert Targets Min         -116.616\n",
      "trainer/Z Policy Targets Mean         117.646\n",
      "trainer/Z Policy Targets Std          216.058\n",
      "trainer/Z Policy Targets Max          512.626\n",
      "trainer/Z Policy Targets Min         -216.722\n",
      "trainer/Log Pis Mean                   26.2484\n",
      "trainer/Log Pis Std                     7.77058\n",
      "trainer/Policy mu Mean                  0.393441\n",
      "trainer/Policy mu Std                   2.91925\n",
      "trainer/Policy log std Mean            -3.13914\n",
      "trainer/Policy log std Std              1.53273\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         68989\n",
      "exploration/num paths total           813\n",
      "evaluation/num steps total         142616\n",
      "evaluation/num paths total            601\n",
      "evaluation/path length Mean           221.5\n",
      "evaluation/path length Std              2.76586\n",
      "evaluation/path length Max            226\n",
      "evaluation/path length Min            217\n",
      "evaluation/Rewards Mean                 3.39958\n",
      "evaluation/Rewards Std                  1.824\n",
      "evaluation/Rewards Max                  6.22911\n",
      "evaluation/Rewards Min                 -0.616549\n",
      "evaluation/Returns Mean               753.006\n",
      "evaluation/Returns Std                 15.9164\n",
      "evaluation/Returns Max                778.568\n",
      "evaluation/Returns Min                734.311\n",
      "evaluation/Estimation Bias Mean       188.928\n",
      "evaluation/Estimation Bias Std        200.568\n",
      "evaluation/EB/Q_True Mean              25.0681\n",
      "evaluation/EB/Q_True Std               80.5785\n",
      "evaluation/EB/Q_Pred Mean             213.996\n",
      "evaluation/EB/Q_Pred Std              190.804\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            753.006\n",
      "evaluation/Actions Mean                 0.391695\n",
      "evaluation/Actions Std                  0.64893\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.6559\n",
      "time/backward_zf1 (s)                   1.79605\n",
      "time/backward_zf2 (s)                   1.71686\n",
      "time/data sampling (s)                  0.208158\n",
      "time/data storing (s)                   0.0137354\n",
      "time/evaluation sampling (s)            0.350157\n",
      "time/exploration sampling (s)           0.191279\n",
      "time/logging (s)                        0.00345445\n",
      "time/preback_alpha (s)                  0.541479\n",
      "time/preback_policy (s)                 0.926871\n",
      "time/preback_start (s)                  0.116386\n",
      "time/preback_zf (s)                     5.02515\n",
      "time/saving (s)                         0.00509593\n",
      "time/training (s)                       2.49231\n",
      "time/epoch (s)                         15.0429\n",
      "time/total (s)                        939.269\n",
      "Epoch                                  59\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:08:01.836618 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 60 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  71000\n",
      "trainer/ZF1 Loss                        3.78561\n",
      "trainer/ZF2 Loss                        4.01064\n",
      "trainer/ZF Expert Reward               20.1749\n",
      "trainer/ZF Policy Reward               -6.41023\n",
      "trainer/ZF CHI2 Term                   30.7349\n",
      "trainer/Policy Loss                  -134.881\n",
      "trainer/Bias Loss                     132.39\n",
      "trainer/Bias Value                     10.5787\n",
      "trainer/Policy Grad Norm              232.884\n",
      "trainer/Policy Param Norm              27.2914\n",
      "trainer/Zf1 Grad Norm                1190.25\n",
      "trainer/Zf1 Param Norm                 66.245\n",
      "trainer/Zf2 Grad Norm                2694.8\n",
      "trainer/Zf2 Param Norm                 65.1879\n",
      "trainer/Z Expert Predictions Mean     201.042\n",
      "trainer/Z Expert Predictions Std      113.601\n",
      "trainer/Z Expert Predictions Max      478.591\n",
      "trainer/Z Expert Predictions Min      -51.2558\n",
      "trainer/Z Policy Predictions Mean     125.015\n",
      "trainer/Z Policy Predictions Std      222.424\n",
      "trainer/Z Policy Predictions Max      470.743\n",
      "trainer/Z Policy Predictions Min     -181.089\n",
      "trainer/Z Expert Targets Mean         180.867\n",
      "trainer/Z Expert Targets Std          118.932\n",
      "trainer/Z Expert Targets Max          475.1\n",
      "trainer/Z Expert Targets Min          -78.1454\n",
      "trainer/Z Policy Targets Mean         131.425\n",
      "trainer/Z Policy Targets Std          222.253\n",
      "trainer/Z Policy Targets Max          472.737\n",
      "trainer/Z Policy Targets Min         -181.331\n",
      "trainer/Log Pis Mean                   25.1638\n",
      "trainer/Log Pis Std                     7.52669\n",
      "trainer/Policy mu Mean                  0.523527\n",
      "trainer/Policy mu Std                   2.40765\n",
      "trainer/Policy log std Mean            -3.29849\n",
      "trainer/Policy log std Std              1.4109\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         69656\n",
      "exploration/num paths total           816\n",
      "evaluation/num steps total         144766\n",
      "evaluation/num paths total            611\n",
      "evaluation/path length Mean           215\n",
      "evaluation/path length Std              1.18322\n",
      "evaluation/path length Max            217\n",
      "evaluation/path length Min            213\n",
      "evaluation/Rewards Mean                 3.53601\n",
      "evaluation/Rewards Std                  1.96416\n",
      "evaluation/Rewards Max                  7.89663\n",
      "evaluation/Rewards Min                 -1.28814\n",
      "evaluation/Returns Mean               760.241\n",
      "evaluation/Returns Std                 14.8657\n",
      "evaluation/Returns Max                783.352\n",
      "evaluation/Returns Min                737.303\n",
      "evaluation/Estimation Bias Mean       196.746\n",
      "evaluation/Estimation Bias Std        193.134\n",
      "evaluation/EB/Q_True Mean              26.2166\n",
      "evaluation/EB/Q_True Std               83.1294\n",
      "evaluation/EB/Q_Pred Mean             222.963\n",
      "evaluation/EB/Q_Pred Std              180.961\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            760.241\n",
      "evaluation/Actions Mean                 0.434696\n",
      "evaluation/Actions Std                  0.629503\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88308\n",
      "time/backward_zf1 (s)                   2.03024\n",
      "time/backward_zf2 (s)                   1.98089\n",
      "time/data sampling (s)                  0.211299\n",
      "time/data storing (s)                   0.0145779\n",
      "time/evaluation sampling (s)            0.35525\n",
      "time/exploration sampling (s)           0.194338\n",
      "time/logging (s)                        0.00343744\n",
      "time/preback_alpha (s)                  0.552548\n",
      "time/preback_policy (s)                 1.12494\n",
      "time/preback_start (s)                  0.119369\n",
      "time/preback_zf (s)                     5.04706\n",
      "time/saving (s)                         0.00566565\n",
      "time/training (s)                       2.08915\n",
      "time/epoch (s)                         15.6119\n",
      "time/total (s)                        954.9\n",
      "Epoch                                  60\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:08:17.588141 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 61 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  72000\n",
      "trainer/ZF1 Loss                        0.294916\n",
      "trainer/ZF2 Loss                        0.246832\n",
      "trainer/ZF Expert Reward               21.2342\n",
      "trainer/ZF Policy Reward               -4.57074\n",
      "trainer/ZF CHI2 Term                   26.3243\n",
      "trainer/Policy Loss                  -107.671\n",
      "trainer/Bias Loss                     114.404\n",
      "trainer/Bias Value                     10.5881\n",
      "trainer/Policy Grad Norm              166.24\n",
      "trainer/Policy Param Norm              27.3486\n",
      "trainer/Zf1 Grad Norm                 901.014\n",
      "trainer/Zf1 Param Norm                 66.3872\n",
      "trainer/Zf2 Grad Norm                 970.721\n",
      "trainer/Zf2 Param Norm                 65.2769\n",
      "trainer/Z Expert Predictions Mean     208.424\n",
      "trainer/Z Expert Predictions Std      113.051\n",
      "trainer/Z Expert Predictions Max      447.969\n",
      "trainer/Z Expert Predictions Min      -22.4487\n",
      "trainer/Z Policy Predictions Mean      95.351\n",
      "trainer/Z Policy Predictions Std      209.035\n",
      "trainer/Z Policy Predictions Max      446.842\n",
      "trainer/Z Policy Predictions Min     -206.979\n",
      "trainer/Z Expert Targets Mean         187.189\n",
      "trainer/Z Expert Targets Std          117.465\n",
      "trainer/Z Expert Targets Max          450.307\n",
      "trainer/Z Expert Targets Min          -40.4966\n",
      "trainer/Z Policy Targets Mean          99.9218\n",
      "trainer/Z Policy Targets Std          210.127\n",
      "trainer/Z Policy Targets Max          446.147\n",
      "trainer/Z Policy Targets Min         -216.681\n",
      "trainer/Log Pis Mean                   24.8491\n",
      "trainer/Log Pis Std                     7.41017\n",
      "trainer/Policy mu Mean                  0.48713\n",
      "trainer/Policy mu Std                   2.46856\n",
      "trainer/Policy log std Mean            -3.21575\n",
      "trainer/Policy log std Std              1.4782\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         70991\n",
      "exploration/num paths total           822\n",
      "evaluation/num steps total         148044\n",
      "evaluation/num paths total            621\n",
      "evaluation/path length Mean           327.8\n",
      "evaluation/path length Std             73.2582\n",
      "evaluation/path length Max            480\n",
      "evaluation/path length Min            247\n",
      "evaluation/Rewards Mean                 4.14219\n",
      "evaluation/Rewards Std                  1.83336\n",
      "evaluation/Rewards Max                  8.38819\n",
      "evaluation/Rewards Min                 -2.10523\n",
      "evaluation/Returns Mean              1357.81\n",
      "evaluation/Returns Std                388.663\n",
      "evaluation/Returns Max               2203.16\n",
      "evaluation/Returns Min                924.394\n",
      "evaluation/Estimation Bias Mean       111.208\n",
      "evaluation/Estimation Bias Std        214.981\n",
      "evaluation/EB/Q_True Mean              58.7113\n",
      "evaluation/EB/Q_True Std              149.581\n",
      "evaluation/EB/Q_Pred Mean             169.919\n",
      "evaluation/EB/Q_Pred Std              179.703\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1357.81\n",
      "evaluation/Actions Mean                 0.443723\n",
      "evaluation/Actions Std                  0.6699\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81111\n",
      "time/backward_zf1 (s)                   1.92995\n",
      "time/backward_zf2 (s)                   1.88087\n",
      "time/data sampling (s)                  0.221695\n",
      "time/data storing (s)                   0.0133776\n",
      "time/evaluation sampling (s)            0.704339\n",
      "time/exploration sampling (s)           0.192456\n",
      "time/logging (s)                        0.00470121\n",
      "time/preback_alpha (s)                  0.542418\n",
      "time/preback_policy (s)                 1.02334\n",
      "time/preback_start (s)                  0.116573\n",
      "time/preback_zf (s)                     5.00886\n",
      "time/saving (s)                         0.00500616\n",
      "time/training (s)                       2.23608\n",
      "time/epoch (s)                         15.6908\n",
      "time/total (s)                        970.609\n",
      "Epoch                                  61\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:08:33.858717 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 62 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  73000\n",
      "trainer/ZF1 Loss                        6.39312\n",
      "trainer/ZF2 Loss                        3.66834\n",
      "trainer/ZF Expert Reward               17.5695\n",
      "trainer/ZF Policy Reward               -4.4955\n",
      "trainer/ZF CHI2 Term                   27.3541\n",
      "trainer/Policy Loss                  -108.061\n",
      "trainer/Bias Loss                      71.4961\n",
      "trainer/Bias Value                     10.5975\n",
      "trainer/Policy Grad Norm              133.251\n",
      "trainer/Policy Param Norm              27.4122\n",
      "trainer/Zf1 Grad Norm                1805.43\n",
      "trainer/Zf1 Param Norm                 66.5244\n",
      "trainer/Zf2 Grad Norm                1081.8\n",
      "trainer/Zf2 Param Norm                 65.3736\n",
      "trainer/Z Expert Predictions Mean     222.172\n",
      "trainer/Z Expert Predictions Std      122.266\n",
      "trainer/Z Expert Predictions Max      441.51\n",
      "trainer/Z Expert Predictions Min      -60.6041\n",
      "trainer/Z Policy Predictions Mean     101.31\n",
      "trainer/Z Policy Predictions Std      200.248\n",
      "trainer/Z Policy Predictions Max      428.866\n",
      "trainer/Z Policy Predictions Min     -218.519\n",
      "trainer/Z Expert Targets Mean         204.603\n",
      "trainer/Z Expert Targets Std          124.658\n",
      "trainer/Z Expert Targets Max          440.946\n",
      "trainer/Z Expert Targets Min          -74.5033\n",
      "trainer/Z Policy Targets Mean         105.806\n",
      "trainer/Z Policy Targets Std          199.811\n",
      "trainer/Z Policy Targets Max          431.557\n",
      "trainer/Z Policy Targets Min         -216.795\n",
      "trainer/Log Pis Mean                   25.8399\n",
      "trainer/Log Pis Std                     6.86557\n",
      "trainer/Policy mu Mean                  0.541277\n",
      "trainer/Policy mu Std                   2.65698\n",
      "trainer/Policy log std Mean            -3.22617\n",
      "trainer/Policy log std Std              1.51481\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         71241\n",
      "exploration/num paths total           823\n",
      "evaluation/num steps total         152712\n",
      "evaluation/num paths total            631\n",
      "evaluation/path length Mean           466.8\n",
      "evaluation/path length Std             89.6558\n",
      "evaluation/path length Max            634\n",
      "evaluation/path length Min            338\n",
      "evaluation/Rewards Mean                 4.13431\n",
      "evaluation/Rewards Std                  1.53712\n",
      "evaluation/Rewards Max                  7.91583\n",
      "evaluation/Rewards Min                 -2.64253\n",
      "evaluation/Returns Mean              1929.9\n",
      "evaluation/Returns Std                394.577\n",
      "evaluation/Returns Max               2654.59\n",
      "evaluation/Returns Min               1279.47\n",
      "evaluation/Estimation Bias Mean        81.6661\n",
      "evaluation/Estimation Bias Std        204.156\n",
      "evaluation/EB/Q_True Mean              51.0495\n",
      "evaluation/EB/Q_True Std              135.667\n",
      "evaluation/EB/Q_Pred Mean             132.716\n",
      "evaluation/EB/Q_Pred Std              166.664\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1929.9\n",
      "evaluation/Actions Mean                 0.4557\n",
      "evaluation/Actions Std                  0.667232\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94125\n",
      "time/backward_zf1 (s)                   2.05929\n",
      "time/backward_zf2 (s)                   2.01729\n",
      "time/data sampling (s)                  0.218968\n",
      "time/data storing (s)                   0.0137967\n",
      "time/evaluation sampling (s)            0.95488\n",
      "time/exploration sampling (s)           0.190139\n",
      "time/logging (s)                        0.00591498\n",
      "time/preback_alpha (s)                  0.546008\n",
      "time/preback_policy (s)                 1.19182\n",
      "time/preback_start (s)                  0.118022\n",
      "time/preback_zf (s)                     5.01584\n",
      "time/saving (s)                         0.00514371\n",
      "time/training (s)                       1.92972\n",
      "time/epoch (s)                         16.2081\n",
      "time/total (s)                        986.836\n",
      "Epoch                                  62\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:08:49.885433 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 63 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  74000\n",
      "trainer/ZF1 Loss                        4.64866\n",
      "trainer/ZF2 Loss                        4.51885\n",
      "trainer/ZF Expert Reward               18.248\n",
      "trainer/ZF Policy Reward               -4.26765\n",
      "trainer/ZF CHI2 Term                   27.3482\n",
      "trainer/Policy Loss                   -97.9025\n",
      "trainer/Bias Loss                      74.8164\n",
      "trainer/Bias Value                     10.6068\n",
      "trainer/Policy Grad Norm              161.927\n",
      "trainer/Policy Param Norm              27.4934\n",
      "trainer/Zf1 Grad Norm                1041.39\n",
      "trainer/Zf1 Param Norm                 66.7502\n",
      "trainer/Zf2 Grad Norm                 717.188\n",
      "trainer/Zf2 Param Norm                 65.4884\n",
      "trainer/Z Expert Predictions Mean     251.615\n",
      "trainer/Z Expert Predictions Std      137.874\n",
      "trainer/Z Expert Predictions Max      458.265\n",
      "trainer/Z Expert Predictions Min      -73.7833\n",
      "trainer/Z Policy Predictions Mean      88.3628\n",
      "trainer/Z Policy Predictions Std      197.962\n",
      "trainer/Z Policy Predictions Max      429.66\n",
      "trainer/Z Policy Predictions Min     -228.658\n",
      "trainer/Z Expert Targets Mean         233.367\n",
      "trainer/Z Expert Targets Std          140.164\n",
      "trainer/Z Expert Targets Max          441.173\n",
      "trainer/Z Expert Targets Min          -96.8365\n",
      "trainer/Z Policy Targets Mean          92.6304\n",
      "trainer/Z Policy Targets Std          197.119\n",
      "trainer/Z Policy Targets Max          428.594\n",
      "trainer/Z Policy Targets Min         -233.135\n",
      "trainer/Log Pis Mean                   24.8714\n",
      "trainer/Log Pis Std                     6.91421\n",
      "trainer/Policy mu Mean                  0.673775\n",
      "trainer/Policy mu Std                   2.48775\n",
      "trainer/Policy log std Mean            -3.18944\n",
      "trainer/Policy log std Std              1.37736\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         71241\n",
      "exploration/num paths total           823\n",
      "evaluation/num steps total         156095\n",
      "evaluation/num paths total            641\n",
      "evaluation/path length Mean           338.3\n",
      "evaluation/path length Std             73.6031\n",
      "evaluation/path length Max            479\n",
      "evaluation/path length Min            263\n",
      "evaluation/Rewards Mean                 4.29586\n",
      "evaluation/Rewards Std                  1.85304\n",
      "evaluation/Rewards Max                  7.60396\n",
      "evaluation/Rewards Min                 -2.1239\n",
      "evaluation/Returns Mean              1453.29\n",
      "evaluation/Returns Std                365.601\n",
      "evaluation/Returns Max               2021.78\n",
      "evaluation/Returns Min               1054.3\n",
      "evaluation/Estimation Bias Mean       149.429\n",
      "evaluation/Estimation Bias Std        202.749\n",
      "evaluation/EB/Q_True Mean              51.6177\n",
      "evaluation/EB/Q_True Std              135.661\n",
      "evaluation/EB/Q_Pred Mean             201.046\n",
      "evaluation/EB/Q_Pred Std              160.553\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1453.29\n",
      "evaluation/Actions Mean                 0.475089\n",
      "evaluation/Actions Std                  0.659949\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86521\n",
      "time/backward_zf1 (s)                   1.97607\n",
      "time/backward_zf2 (s)                   1.96106\n",
      "time/data sampling (s)                  0.227196\n",
      "time/data storing (s)                   0.0135389\n",
      "time/evaluation sampling (s)            0.718044\n",
      "time/exploration sampling (s)           0.19041\n",
      "time/logging (s)                        0.0049403\n",
      "time/preback_alpha (s)                  0.550792\n",
      "time/preback_policy (s)                 1.11156\n",
      "time/preback_start (s)                  0.118429\n",
      "time/preback_zf (s)                     5.05792\n",
      "time/saving (s)                         0.00524146\n",
      "time/training (s)                       2.16283\n",
      "time/epoch (s)                         15.9632\n",
      "time/total (s)                       1002.82\n",
      "Epoch                                  63\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:09:06.102348 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 64 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  75000\n",
      "trainer/ZF1 Loss                        7.1076\n",
      "trainer/ZF2 Loss                        6.69607\n",
      "trainer/ZF Expert Reward               17.4426\n",
      "trainer/ZF Policy Reward               -7.67083\n",
      "trainer/ZF CHI2 Term                   32.2683\n",
      "trainer/Policy Loss                  -100.549\n",
      "trainer/Bias Loss                     105.259\n",
      "trainer/Bias Value                     10.6161\n",
      "trainer/Policy Grad Norm              173.509\n",
      "trainer/Policy Param Norm              27.5723\n",
      "trainer/Zf1 Grad Norm                1794.99\n",
      "trainer/Zf1 Param Norm                 66.9931\n",
      "trainer/Zf2 Grad Norm                 755.727\n",
      "trainer/Zf2 Param Norm                 65.6266\n",
      "trainer/Z Expert Predictions Mean     264.797\n",
      "trainer/Z Expert Predictions Std      142.469\n",
      "trainer/Z Expert Predictions Max      494.075\n",
      "trainer/Z Expert Predictions Min      -49.7145\n",
      "trainer/Z Policy Predictions Mean      92.5913\n",
      "trainer/Z Policy Predictions Std      201.977\n",
      "trainer/Z Policy Predictions Max      412.378\n",
      "trainer/Z Policy Predictions Min     -246.125\n",
      "trainer/Z Expert Targets Mean         247.354\n",
      "trainer/Z Expert Targets Std          142.466\n",
      "trainer/Z Expert Targets Max          474.942\n",
      "trainer/Z Expert Targets Min          -68.8407\n",
      "trainer/Z Policy Targets Mean         100.262\n",
      "trainer/Z Policy Targets Std          200.645\n",
      "trainer/Z Policy Targets Max          418.06\n",
      "trainer/Z Policy Targets Min         -227.232\n",
      "trainer/Log Pis Mean                   25.3074\n",
      "trainer/Log Pis Std                     6.88282\n",
      "trainer/Policy mu Mean                  0.594661\n",
      "trainer/Policy mu Std                   2.59652\n",
      "trainer/Policy log std Mean            -3.19752\n",
      "trainer/Policy log std Std              1.40142\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         72482\n",
      "exploration/num paths total           827\n",
      "evaluation/num steps total         160673\n",
      "evaluation/num paths total            651\n",
      "evaluation/path length Mean           457.8\n",
      "evaluation/path length Std            105.13\n",
      "evaluation/path length Max            698\n",
      "evaluation/path length Min            303\n",
      "evaluation/Rewards Mean                 4.43534\n",
      "evaluation/Rewards Std                  1.62937\n",
      "evaluation/Rewards Max                  7.45606\n",
      "evaluation/Rewards Min                 -0.965104\n",
      "evaluation/Returns Mean              2030.5\n",
      "evaluation/Returns Std                567.921\n",
      "evaluation/Returns Max               3348.34\n",
      "evaluation/Returns Min               1202.74\n",
      "evaluation/Estimation Bias Mean       151.072\n",
      "evaluation/Estimation Bias Std        230.545\n",
      "evaluation/EB/Q_True Mean              67.0865\n",
      "evaluation/EB/Q_True Std              163.771\n",
      "evaluation/EB/Q_Pred Mean             218.158\n",
      "evaluation/EB/Q_Pred Std              158.211\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2030.5\n",
      "evaluation/Actions Mean                 0.491416\n",
      "evaluation/Actions Std                  0.65003\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82064\n",
      "time/backward_zf1 (s)                   1.95922\n",
      "time/backward_zf2 (s)                   1.8939\n",
      "time/data sampling (s)                  0.228416\n",
      "time/data storing (s)                   0.0140585\n",
      "time/evaluation sampling (s)            1.00413\n",
      "time/exploration sampling (s)           0.196059\n",
      "time/logging (s)                        0.0061928\n",
      "time/preback_alpha (s)                  0.552148\n",
      "time/preback_policy (s)                 1.05294\n",
      "time/preback_start (s)                  0.119922\n",
      "time/preback_zf (s)                     5.03587\n",
      "time/saving (s)                         0.00550297\n",
      "time/training (s)                       2.26346\n",
      "time/epoch (s)                         16.1525\n",
      "time/total (s)                       1018.99\n",
      "Epoch                                  64\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:09:21.901902 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 65 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  76000\n",
      "trainer/ZF1 Loss                       -1.69439\n",
      "trainer/ZF2 Loss                        0.0407772\n",
      "trainer/ZF Expert Reward               18.9132\n",
      "trainer/ZF Policy Reward               -5.23867\n",
      "trainer/ZF CHI2 Term                   23.5794\n",
      "trainer/Policy Loss                  -122.568\n",
      "trainer/Bias Loss                      83.7734\n",
      "trainer/Bias Value                     10.6253\n",
      "trainer/Policy Grad Norm              156.148\n",
      "trainer/Policy Param Norm              27.6389\n",
      "trainer/Zf1 Grad Norm                 814.717\n",
      "trainer/Zf1 Param Norm                 67.2074\n",
      "trainer/Zf2 Grad Norm                1503.94\n",
      "trainer/Zf2 Param Norm                 65.7906\n",
      "trainer/Z Expert Predictions Mean     292.048\n",
      "trainer/Z Expert Predictions Std      139.324\n",
      "trainer/Z Expert Predictions Max      563.012\n",
      "trainer/Z Expert Predictions Min       -2.9808\n",
      "trainer/Z Policy Predictions Mean     114.713\n",
      "trainer/Z Policy Predictions Std      194.721\n",
      "trainer/Z Policy Predictions Max      418.274\n",
      "trainer/Z Policy Predictions Min     -212.356\n",
      "trainer/Z Expert Targets Mean         273.135\n",
      "trainer/Z Expert Targets Std          141.118\n",
      "trainer/Z Expert Targets Max          550.918\n",
      "trainer/Z Expert Targets Min          -23.2705\n",
      "trainer/Z Policy Targets Mean         119.952\n",
      "trainer/Z Policy Targets Std          193.933\n",
      "trainer/Z Policy Targets Max          427.035\n",
      "trainer/Z Policy Targets Min         -220.934\n",
      "trainer/Log Pis Mean                   25.4312\n",
      "trainer/Log Pis Std                     7.20657\n",
      "trainer/Policy mu Mean                  0.792118\n",
      "trainer/Policy mu Std                   2.56082\n",
      "trainer/Policy log std Mean            -3.27395\n",
      "trainer/Policy log std Std              1.39489\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         74298\n",
      "exploration/num paths total           831\n",
      "evaluation/num steps total         163985\n",
      "evaluation/num paths total            661\n",
      "evaluation/path length Mean           331.2\n",
      "evaluation/path length Std             30.9864\n",
      "evaluation/path length Max            394\n",
      "evaluation/path length Min            291\n",
      "evaluation/Rewards Mean                 4.34099\n",
      "evaluation/Rewards Std                  1.90937\n",
      "evaluation/Rewards Max                  7.54714\n",
      "evaluation/Rewards Min                  0.100552\n",
      "evaluation/Returns Mean              1437.74\n",
      "evaluation/Returns Std                191.535\n",
      "evaluation/Returns Max               1792.24\n",
      "evaluation/Returns Min               1182.58\n",
      "evaluation/Estimation Bias Mean       216.355\n",
      "evaluation/Estimation Bias Std        192.853\n",
      "evaluation/EB/Q_True Mean              45.9908\n",
      "evaluation/EB/Q_True Std              131.772\n",
      "evaluation/EB/Q_Pred Mean             262.345\n",
      "evaluation/EB/Q_Pred Std              140.195\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1437.74\n",
      "evaluation/Actions Mean                 0.493984\n",
      "evaluation/Actions Std                  0.634058\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.89349\n",
      "time/backward_zf1 (s)                   2.01076\n",
      "time/backward_zf2 (s)                   1.96877\n",
      "time/data sampling (s)                  0.221873\n",
      "time/data storing (s)                   0.0132581\n",
      "time/evaluation sampling (s)            0.623862\n",
      "time/exploration sampling (s)           0.192624\n",
      "time/logging (s)                        0.00525458\n",
      "time/preback_alpha (s)                  0.543463\n",
      "time/preback_policy (s)                 1.17196\n",
      "time/preback_start (s)                  0.118327\n",
      "time/preback_zf (s)                     5.00675\n",
      "time/saving (s)                         0.00516757\n",
      "time/training (s)                       1.95805\n",
      "time/epoch (s)                         15.7336\n",
      "time/total (s)                       1034.75\n",
      "Epoch                                  65\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:09:38.564497 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 66 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  77000\n",
      "trainer/ZF1 Loss                        9.55733\n",
      "trainer/ZF2 Loss                        8.97434\n",
      "trainer/ZF Expert Reward               15.8939\n",
      "trainer/ZF Policy Reward               -6.3543\n",
      "trainer/ZF CHI2 Term                   31.7635\n",
      "trainer/Policy Loss                  -111.283\n",
      "trainer/Bias Loss                      93.5507\n",
      "trainer/Bias Value                     10.6345\n",
      "trainer/Policy Grad Norm              145.509\n",
      "trainer/Policy Param Norm              27.6961\n",
      "trainer/Zf1 Grad Norm                1442.31\n",
      "trainer/Zf1 Param Norm                 67.4562\n",
      "trainer/Zf2 Grad Norm                1811.41\n",
      "trainer/Zf2 Param Norm                 65.9872\n",
      "trainer/Z Expert Predictions Mean     305.309\n",
      "trainer/Z Expert Predictions Std      141.697\n",
      "trainer/Z Expert Predictions Max      559.391\n",
      "trainer/Z Expert Predictions Min       -9.22352\n",
      "trainer/Z Policy Predictions Mean     104.701\n",
      "trainer/Z Policy Predictions Std      200.929\n",
      "trainer/Z Policy Predictions Max      447.932\n",
      "trainer/Z Policy Predictions Min     -217.465\n",
      "trainer/Z Expert Targets Mean         289.416\n",
      "trainer/Z Expert Targets Std          143.897\n",
      "trainer/Z Expert Targets Max          538.767\n",
      "trainer/Z Expert Targets Min          -36.7421\n",
      "trainer/Z Policy Targets Mean         111.056\n",
      "trainer/Z Policy Targets Std          201.2\n",
      "trainer/Z Policy Targets Max          446.812\n",
      "trainer/Z Policy Targets Min         -214.529\n",
      "trainer/Log Pis Mean                   24.9473\n",
      "trainer/Log Pis Std                     6.59091\n",
      "trainer/Policy mu Mean                  0.625314\n",
      "trainer/Policy mu Std                   2.44362\n",
      "trainer/Policy log std Mean            -3.21251\n",
      "trainer/Policy log std Std              1.40261\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         74788\n",
      "exploration/num paths total           832\n",
      "evaluation/num steps total         173753\n",
      "evaluation/num paths total            671\n",
      "evaluation/path length Mean           976.8\n",
      "evaluation/path length Std             69.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            768\n",
      "evaluation/Rewards Mean                 4.31095\n",
      "evaluation/Rewards Std                  1.08999\n",
      "evaluation/Rewards Max                  6.31173\n",
      "evaluation/Rewards Min                  0.0858928\n",
      "evaluation/Returns Mean              4210.94\n",
      "evaluation/Returns Std                326.65\n",
      "evaluation/Returns Max               4341.51\n",
      "evaluation/Returns Min               3232.29\n",
      "evaluation/Estimation Bias Mean       120.906\n",
      "evaluation/Estimation Bias Std        181.229\n",
      "evaluation/EB/Q_True Mean              41.1165\n",
      "evaluation/EB/Q_True Std              125.218\n",
      "evaluation/EB/Q_Pred Mean             162.022\n",
      "evaluation/EB/Q_Pred Std              139.338\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4210.94\n",
      "evaluation/Actions Mean                 0.4809\n",
      "evaluation/Actions Std                  0.627774\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90419\n",
      "time/backward_zf1 (s)                   2.02174\n",
      "time/backward_zf2 (s)                   1.9836\n",
      "time/data sampling (s)                  0.227868\n",
      "time/data storing (s)                   0.0138055\n",
      "time/evaluation sampling (s)            1.44227\n",
      "time/exploration sampling (s)           0.190788\n",
      "time/logging (s)                        0.0120788\n",
      "time/preback_alpha (s)                  0.546858\n",
      "time/preback_policy (s)                 1.16949\n",
      "time/preback_start (s)                  0.118\n",
      "time/preback_zf (s)                     5.0124\n",
      "time/saving (s)                         0.0056894\n",
      "time/training (s)                       1.95886\n",
      "time/epoch (s)                         16.6076\n",
      "time/total (s)                       1051.37\n",
      "Epoch                                  66\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:09:54.993488 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 67 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  78000\n",
      "trainer/ZF1 Loss                        9.18167\n",
      "trainer/ZF2 Loss                       11.2191\n",
      "trainer/ZF Expert Reward               21.3482\n",
      "trainer/ZF Policy Reward               -2.19275\n",
      "trainer/ZF CHI2 Term                   34.0099\n",
      "trainer/Policy Loss                  -149.473\n",
      "trainer/Bias Loss                     143.975\n",
      "trainer/Bias Value                     10.6437\n",
      "trainer/Policy Grad Norm              149.233\n",
      "trainer/Policy Param Norm              27.7643\n",
      "trainer/Zf1 Grad Norm                1106.01\n",
      "trainer/Zf1 Param Norm                 67.7099\n",
      "trainer/Zf2 Grad Norm                1674.48\n",
      "trainer/Zf2 Param Norm                 66.1911\n",
      "trainer/Z Expert Predictions Mean     343.424\n",
      "trainer/Z Expert Predictions Std      136.952\n",
      "trainer/Z Expert Predictions Max      599.247\n",
      "trainer/Z Expert Predictions Min       36.3654\n",
      "trainer/Z Policy Predictions Mean     142.351\n",
      "trainer/Z Policy Predictions Std      194.959\n",
      "trainer/Z Policy Predictions Max      483.761\n",
      "trainer/Z Policy Predictions Min     -235.907\n",
      "trainer/Z Expert Targets Mean         322.076\n",
      "trainer/Z Expert Targets Std          135.379\n",
      "trainer/Z Expert Targets Max          576.463\n",
      "trainer/Z Expert Targets Min           25.4457\n",
      "trainer/Z Policy Targets Mean         144.544\n",
      "trainer/Z Policy Targets Std          192.916\n",
      "trainer/Z Policy Targets Max          483.937\n",
      "trainer/Z Policy Targets Min         -219.054\n",
      "trainer/Log Pis Mean                   26.8611\n",
      "trainer/Log Pis Std                     6.37345\n",
      "trainer/Policy mu Mean                  0.794037\n",
      "trainer/Policy mu Std                   2.56667\n",
      "trainer/Policy log std Mean            -3.36389\n",
      "trainer/Policy log std Std              1.40925\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         75348\n",
      "exploration/num paths total           833\n",
      "evaluation/num steps total         179907\n",
      "evaluation/num paths total            681\n",
      "evaluation/path length Mean           615.4\n",
      "evaluation/path length Std            147.581\n",
      "evaluation/path length Max            869\n",
      "evaluation/path length Min            363\n",
      "evaluation/Rewards Mean                 4.12416\n",
      "evaluation/Rewards Std                  1.28839\n",
      "evaluation/Rewards Max                  6.81787\n",
      "evaluation/Rewards Min                 -0.619115\n",
      "evaluation/Returns Mean              2538.01\n",
      "evaluation/Returns Std                682.984\n",
      "evaluation/Returns Max               3668.83\n",
      "evaluation/Returns Min               1371.1\n",
      "evaluation/Estimation Bias Mean       104.068\n",
      "evaluation/Estimation Bias Std        209.698\n",
      "evaluation/EB/Q_True Mean              55.2852\n",
      "evaluation/EB/Q_True Std              141.628\n",
      "evaluation/EB/Q_Pred Mean             159.353\n",
      "evaluation/EB/Q_Pred Std              162.038\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2538.01\n",
      "evaluation/Actions Mean                 0.462343\n",
      "evaluation/Actions Std                  0.638475\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7976\n",
      "time/backward_zf1 (s)                   1.91928\n",
      "time/backward_zf2 (s)                   1.86778\n",
      "time/data sampling (s)                  0.232866\n",
      "time/data storing (s)                   0.0138494\n",
      "time/evaluation sampling (s)            1.29519\n",
      "time/exploration sampling (s)           0.19119\n",
      "time/logging (s)                        0.00755887\n",
      "time/preback_alpha (s)                  0.551892\n",
      "time/preback_policy (s)                 1.02463\n",
      "time/preback_start (s)                  0.119283\n",
      "time/preback_zf (s)                     5.04289\n",
      "time/saving (s)                         0.0052882\n",
      "time/training (s)                       2.29003\n",
      "time/epoch (s)                         16.3593\n",
      "time/total (s)                       1067.75\n",
      "Epoch                                  67\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:10:11.499756 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 68 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  79000\n",
      "trainer/ZF1 Loss                        9.32276\n",
      "trainer/ZF2 Loss                        8.91318\n",
      "trainer/ZF Expert Reward               14.321\n",
      "trainer/ZF Policy Reward               -7.58901\n",
      "trainer/ZF CHI2 Term                   31.2867\n",
      "trainer/Policy Loss                  -140.084\n",
      "trainer/Bias Loss                      73.6036\n",
      "trainer/Bias Value                     10.6527\n",
      "trainer/Policy Grad Norm              180.89\n",
      "trainer/Policy Param Norm              27.8354\n",
      "trainer/Zf1 Grad Norm                2267.46\n",
      "trainer/Zf1 Param Norm                 67.9458\n",
      "trainer/Zf2 Grad Norm                1709.52\n",
      "trainer/Zf2 Param Norm                 66.4178\n",
      "trainer/Z Expert Predictions Mean     378.142\n",
      "trainer/Z Expert Predictions Std      128.469\n",
      "trainer/Z Expert Predictions Max      668.178\n",
      "trainer/Z Expert Predictions Min       97.3194\n",
      "trainer/Z Policy Predictions Mean     128.282\n",
      "trainer/Z Policy Predictions Std      200.335\n",
      "trainer/Z Policy Predictions Max      465.095\n",
      "trainer/Z Policy Predictions Min     -247.12\n",
      "trainer/Z Expert Targets Mean         363.821\n",
      "trainer/Z Expert Targets Std          131.252\n",
      "trainer/Z Expert Targets Max          656.491\n",
      "trainer/Z Expert Targets Min           98.2633\n",
      "trainer/Z Policy Targets Mean         135.871\n",
      "trainer/Z Policy Targets Std          200.042\n",
      "trainer/Z Policy Targets Max          498.181\n",
      "trainer/Z Policy Targets Min         -245.611\n",
      "trainer/Log Pis Mean                   25.8698\n",
      "trainer/Log Pis Std                     7.15722\n",
      "trainer/Policy mu Mean                  0.723992\n",
      "trainer/Policy mu Std                   2.38849\n",
      "trainer/Policy log std Mean            -3.40054\n",
      "trainer/Policy log std Std              1.30775\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         75708\n",
      "exploration/num paths total           834\n",
      "evaluation/num steps total         188344\n",
      "evaluation/num paths total            691\n",
      "evaluation/path length Mean           843.7\n",
      "evaluation/path length Std            206.385\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            462\n",
      "evaluation/Rewards Mean                 4.27114\n",
      "evaluation/Rewards Std                  1.17098\n",
      "evaluation/Rewards Max                  6.62413\n",
      "evaluation/Rewards Min                 -1.01329\n",
      "evaluation/Returns Mean              3603.56\n",
      "evaluation/Returns Std                981.867\n",
      "evaluation/Returns Max               4462\n",
      "evaluation/Returns Min               1810.57\n",
      "evaluation/Estimation Bias Mean       159.423\n",
      "evaluation/Estimation Bias Std        201.037\n",
      "evaluation/EB/Q_True Mean              47.9642\n",
      "evaluation/EB/Q_True Std              134.479\n",
      "evaluation/EB/Q_Pred Mean             207.387\n",
      "evaluation/EB/Q_Pred Std              140.535\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3603.56\n",
      "evaluation/Actions Mean                 0.480528\n",
      "evaluation/Actions Std                  0.631329\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73996\n",
      "time/backward_zf1 (s)                   1.85327\n",
      "time/backward_zf2 (s)                   1.78846\n",
      "time/data sampling (s)                  0.237831\n",
      "time/data storing (s)                   0.0136778\n",
      "time/evaluation sampling (s)            1.43675\n",
      "time/exploration sampling (s)           0.189495\n",
      "time/logging (s)                        0.0108202\n",
      "time/preback_alpha (s)                  0.550257\n",
      "time/preback_policy (s)                 0.954451\n",
      "time/preback_start (s)                  0.119238\n",
      "time/preback_zf (s)                     5.04239\n",
      "time/saving (s)                         0.0173794\n",
      "time/training (s)                       2.48785\n",
      "time/epoch (s)                         16.4418\n",
      "time/total (s)                       1084.22\n",
      "Epoch                                  68\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:10:27.897074 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 69 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  80000\n",
      "trainer/ZF1 Loss                       34.5816\n",
      "trainer/ZF2 Loss                       30.3208\n",
      "trainer/ZF Expert Reward               19.5383\n",
      "trainer/ZF Policy Reward               -3.2285\n",
      "trainer/ZF CHI2 Term                   55.476\n",
      "trainer/Policy Loss                  -125.202\n",
      "trainer/Bias Loss                     332.272\n",
      "trainer/Bias Value                     10.6617\n",
      "trainer/Policy Grad Norm              131.198\n",
      "trainer/Policy Param Norm              27.9181\n",
      "trainer/Zf1 Grad Norm                1272.14\n",
      "trainer/Zf1 Param Norm                 68.2255\n",
      "trainer/Zf2 Grad Norm                1098.69\n",
      "trainer/Zf2 Param Norm                 66.6853\n",
      "trainer/Z Expert Predictions Mean     405.847\n",
      "trainer/Z Expert Predictions Std      123.47\n",
      "trainer/Z Expert Predictions Max      684.657\n",
      "trainer/Z Expert Predictions Min       97.055\n",
      "trainer/Z Policy Predictions Mean     118.571\n",
      "trainer/Z Policy Predictions Std      204.687\n",
      "trainer/Z Policy Predictions Max      584.242\n",
      "trainer/Z Policy Predictions Min     -225.511\n",
      "trainer/Z Expert Targets Mean         386.308\n",
      "trainer/Z Expert Targets Std          126.157\n",
      "trainer/Z Expert Targets Max          656.654\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         121.8\n",
      "trainer/Z Policy Targets Std          204.138\n",
      "trainer/Z Policy Targets Max          584.433\n",
      "trainer/Z Policy Targets Min         -223.693\n",
      "trainer/Log Pis Mean                   25.8041\n",
      "trainer/Log Pis Std                     6.8198\n",
      "trainer/Policy mu Mean                  0.734063\n",
      "trainer/Policy mu Std                   2.45518\n",
      "trainer/Policy log std Mean            -3.28623\n",
      "trainer/Policy log std Std              1.30982\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         78027\n",
      "exploration/num paths total           839\n",
      "evaluation/num steps total         196774\n",
      "evaluation/num paths total            701\n",
      "evaluation/path length Mean           843\n",
      "evaluation/path length Std            175.813\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            553\n",
      "evaluation/Rewards Mean                 4.53891\n",
      "evaluation/Rewards Std                  1.29125\n",
      "evaluation/Rewards Max                  7.49389\n",
      "evaluation/Rewards Min                  0.10924\n",
      "evaluation/Returns Mean              3826.3\n",
      "evaluation/Returns Std                860.359\n",
      "evaluation/Returns Max               4736.4\n",
      "evaluation/Returns Min               2237.39\n",
      "evaluation/Estimation Bias Mean       235.216\n",
      "evaluation/Estimation Bias Std        206.187\n",
      "evaluation/EB/Q_True Mean              50.6728\n",
      "evaluation/EB/Q_True Std              141.27\n",
      "evaluation/EB/Q_Pred Mean             285.889\n",
      "evaluation/EB/Q_Pred Std              140.447\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3826.3\n",
      "evaluation/Actions Mean                 0.503264\n",
      "evaluation/Actions Std                  0.633763\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73336\n",
      "time/backward_zf1 (s)                   1.85007\n",
      "time/backward_zf2 (s)                   1.78049\n",
      "time/data sampling (s)                  0.240265\n",
      "time/data storing (s)                   0.0138206\n",
      "time/evaluation sampling (s)            1.42307\n",
      "time/exploration sampling (s)           0.198047\n",
      "time/logging (s)                        0.0101766\n",
      "time/preback_alpha (s)                  0.547451\n",
      "time/preback_policy (s)                 0.981973\n",
      "time/preback_start (s)                  0.119925\n",
      "time/preback_zf (s)                     5.02751\n",
      "time/saving (s)                         0.00538948\n",
      "time/training (s)                       2.40253\n",
      "time/epoch (s)                         16.3341\n",
      "time/total (s)                       1100.57\n",
      "Epoch                                  69\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:10:44.402484 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 70 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  81000\n",
      "trainer/ZF1 Loss                       12.9646\n",
      "trainer/ZF2 Loss                       11.2334\n",
      "trainer/ZF Expert Reward               17.6386\n",
      "trainer/ZF Policy Reward               -2.99719\n",
      "trainer/ZF CHI2 Term                   33.0009\n",
      "trainer/Policy Loss                  -172.221\n",
      "trainer/Bias Loss                     118.233\n",
      "trainer/Bias Value                     10.6707\n",
      "trainer/Policy Grad Norm              103.783\n",
      "trainer/Policy Param Norm              28.0069\n",
      "trainer/Zf1 Grad Norm                1222.15\n",
      "trainer/Zf1 Param Norm                 68.5378\n",
      "trainer/Zf2 Grad Norm                1311.47\n",
      "trainer/Zf2 Param Norm                 66.9515\n",
      "trainer/Z Expert Predictions Mean     432.399\n",
      "trainer/Z Expert Predictions Std      112.851\n",
      "trainer/Z Expert Predictions Max      716.556\n",
      "trainer/Z Expert Predictions Min      195.455\n",
      "trainer/Z Policy Predictions Mean     158.496\n",
      "trainer/Z Policy Predictions Std      202.302\n",
      "trainer/Z Policy Predictions Max      503.953\n",
      "trainer/Z Policy Predictions Min     -176.091\n",
      "trainer/Z Expert Targets Mean         414.761\n",
      "trainer/Z Expert Targets Std          113.768\n",
      "trainer/Z Expert Targets Max          692.283\n",
      "trainer/Z Expert Targets Min          176.256\n",
      "trainer/Z Policy Targets Mean         161.493\n",
      "trainer/Z Policy Targets Std          200.37\n",
      "trainer/Z Policy Targets Max          487.495\n",
      "trainer/Z Policy Targets Min         -193.233\n",
      "trainer/Log Pis Mean                   26.6142\n",
      "trainer/Log Pis Std                     6.97413\n",
      "trainer/Policy mu Mean                  0.910417\n",
      "trainer/Policy mu Std                   2.22044\n",
      "trainer/Policy log std Mean            -3.43886\n",
      "trainer/Policy log std Std              1.27439\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         78027\n",
      "exploration/num paths total           839\n",
      "evaluation/num steps total         202213\n",
      "evaluation/num paths total            711\n",
      "evaluation/path length Mean           543.9\n",
      "evaluation/path length Std             99.2547\n",
      "evaluation/path length Max            732\n",
      "evaluation/path length Min            442\n",
      "evaluation/Rewards Mean                 4.62329\n",
      "evaluation/Rewards Std                  1.59002\n",
      "evaluation/Rewards Max                  7.73534\n",
      "evaluation/Rewards Min                  0.118303\n",
      "evaluation/Returns Mean              2514.61\n",
      "evaluation/Returns Std                575.261\n",
      "evaluation/Returns Max               3644.18\n",
      "evaluation/Returns Min               1931.31\n",
      "evaluation/Estimation Bias Mean       282.398\n",
      "evaluation/Estimation Bias Std        210.141\n",
      "evaluation/EB/Q_True Mean              61.9462\n",
      "evaluation/EB/Q_True Std              162.234\n",
      "evaluation/EB/Q_Pred Mean             344.344\n",
      "evaluation/EB/Q_Pred Std              130.389\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2514.61\n",
      "evaluation/Actions Mean                 0.507833\n",
      "evaluation/Actions Std                  0.633684\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.92307\n",
      "time/backward_zf1 (s)                   2.04652\n",
      "time/backward_zf2 (s)                   2.00379\n",
      "time/data sampling (s)                  0.249109\n",
      "time/data storing (s)                   0.0140134\n",
      "time/evaluation sampling (s)            1.04232\n",
      "time/exploration sampling (s)           0.193438\n",
      "time/logging (s)                        0.00700137\n",
      "time/preback_alpha (s)                  0.559906\n",
      "time/preback_policy (s)                 1.14987\n",
      "time/preback_start (s)                  0.11983\n",
      "time/preback_zf (s)                     5.05546\n",
      "time/saving (s)                         0.00557659\n",
      "time/training (s)                       2.06969\n",
      "time/epoch (s)                         16.4396\n",
      "time/total (s)                       1117.02\n",
      "Epoch                                  70\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:11:01.440193 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 71 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  82000\n",
      "trainer/ZF1 Loss                       10.9749\n",
      "trainer/ZF2 Loss                       11.519\n",
      "trainer/ZF Expert Reward               16.986\n",
      "trainer/ZF Policy Reward               -4.21846\n",
      "trainer/ZF CHI2 Term                   32.7108\n",
      "trainer/Policy Loss                  -164.251\n",
      "trainer/Bias Loss                     122.126\n",
      "trainer/Bias Value                     10.6796\n",
      "trainer/Policy Grad Norm              142.063\n",
      "trainer/Policy Param Norm              28.0976\n",
      "trainer/Zf1 Grad Norm                1593.25\n",
      "trainer/Zf1 Param Norm                 68.8278\n",
      "trainer/Zf2 Grad Norm                1046.86\n",
      "trainer/Zf2 Param Norm                 67.2282\n",
      "trainer/Z Expert Predictions Mean     464.673\n",
      "trainer/Z Expert Predictions Std      108.427\n",
      "trainer/Z Expert Predictions Max      722.264\n",
      "trainer/Z Expert Predictions Min      167.861\n",
      "trainer/Z Policy Predictions Mean     155.65\n",
      "trainer/Z Policy Predictions Std      214.63\n",
      "trainer/Z Policy Predictions Max      587.429\n",
      "trainer/Z Policy Predictions Min     -210.16\n",
      "trainer/Z Expert Targets Mean         447.687\n",
      "trainer/Z Expert Targets Std          109.014\n",
      "trainer/Z Expert Targets Max          711.941\n",
      "trainer/Z Expert Targets Min          115.113\n",
      "trainer/Z Policy Targets Mean         159.868\n",
      "trainer/Z Policy Targets Std          211.797\n",
      "trainer/Z Policy Targets Max          564.52\n",
      "trainer/Z Policy Targets Min         -206.082\n",
      "trainer/Log Pis Mean                   25.9438\n",
      "trainer/Log Pis Std                     8.24157\n",
      "trainer/Policy mu Mean                  0.836385\n",
      "trainer/Policy mu Std                   2.41007\n",
      "trainer/Policy log std Mean            -3.29743\n",
      "trainer/Policy log std Std              1.33656\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         78389\n",
      "exploration/num paths total           840\n",
      "evaluation/num steps total         211310\n",
      "evaluation/num paths total            721\n",
      "evaluation/path length Mean           909.7\n",
      "evaluation/path length Std            106.766\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            703\n",
      "evaluation/Rewards Mean                 4.61741\n",
      "evaluation/Rewards Std                  1.2974\n",
      "evaluation/Rewards Max                  7.6286\n",
      "evaluation/Rewards Min                 -1.77626\n",
      "evaluation/Returns Mean              4200.45\n",
      "evaluation/Returns Std                463.817\n",
      "evaluation/Returns Max               4806.3\n",
      "evaluation/Returns Min               3230.6\n",
      "evaluation/Estimation Bias Mean       279.423\n",
      "evaluation/Estimation Bias Std        192.552\n",
      "evaluation/EB/Q_True Mean              44.807\n",
      "evaluation/EB/Q_True Std              131.718\n",
      "evaluation/EB/Q_Pred Mean             324.23\n",
      "evaluation/EB/Q_Pred Std              150.896\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4200.45\n",
      "evaluation/Actions Mean                 0.509423\n",
      "evaluation/Actions Std                  0.638523\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91745\n",
      "time/backward_zf1 (s)                   2.05307\n",
      "time/backward_zf2 (s)                   2.00246\n",
      "time/data sampling (s)                  0.244578\n",
      "time/data storing (s)                   0.0147455\n",
      "time/evaluation sampling (s)            1.4811\n",
      "time/exploration sampling (s)           0.195764\n",
      "time/logging (s)                        0.0140088\n",
      "time/preback_alpha (s)                  0.559783\n",
      "time/preback_policy (s)                 1.15952\n",
      "time/preback_start (s)                  0.122175\n",
      "time/preback_zf (s)                     5.09279\n",
      "time/saving (s)                         0.0215165\n",
      "time/training (s)                       2.09893\n",
      "time/epoch (s)                         16.9779\n",
      "time/total (s)                       1134.02\n",
      "Epoch                                  71\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:11:17.817523 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 72 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  83000\n",
      "trainer/ZF1 Loss                       93.5532\n",
      "trainer/ZF2 Loss                       91.5024\n",
      "trainer/ZF Expert Reward               25.1075\n",
      "trainer/ZF Policy Reward               -4.98715\n",
      "trainer/ZF CHI2 Term                  122.876\n",
      "trainer/Policy Loss                  -190.242\n",
      "trainer/Bias Loss                    1009.22\n",
      "trainer/Bias Value                     10.6885\n",
      "trainer/Policy Grad Norm              233.159\n",
      "trainer/Policy Param Norm              28.1821\n",
      "trainer/Zf1 Grad Norm                2539.75\n",
      "trainer/Zf1 Param Norm                 69.1404\n",
      "trainer/Zf2 Grad Norm                1872.24\n",
      "trainer/Zf2 Param Norm                 67.5093\n",
      "trainer/Z Expert Predictions Mean     493.718\n",
      "trainer/Z Expert Predictions Std      106.164\n",
      "trainer/Z Expert Predictions Max      686.853\n",
      "trainer/Z Expert Predictions Min      147.363\n",
      "trainer/Z Policy Predictions Mean     183.863\n",
      "trainer/Z Policy Predictions Std      223.73\n",
      "trainer/Z Policy Predictions Max      549.825\n",
      "trainer/Z Policy Predictions Min     -202.116\n",
      "trainer/Z Expert Targets Mean         468.611\n",
      "trainer/Z Expert Targets Std          114.569\n",
      "trainer/Z Expert Targets Max          667.116\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         188.85\n",
      "trainer/Z Policy Targets Std          218.899\n",
      "trainer/Z Policy Targets Max          516.499\n",
      "trainer/Z Policy Targets Min         -203.666\n",
      "trainer/Log Pis Mean                   25.3442\n",
      "trainer/Log Pis Std                     6.34907\n",
      "trainer/Policy mu Mean                  0.788129\n",
      "trainer/Policy mu Std                   2.38826\n",
      "trainer/Policy log std Mean            -3.4095\n",
      "trainer/Policy log std Std              1.28771\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         79073\n",
      "exploration/num paths total           841\n",
      "evaluation/num steps total         217733\n",
      "evaluation/num paths total            731\n",
      "evaluation/path length Mean           642.3\n",
      "evaluation/path length Std             46.6884\n",
      "evaluation/path length Max            750\n",
      "evaluation/path length Min            561\n",
      "evaluation/Rewards Mean                 4.93094\n",
      "evaluation/Rewards Std                  1.58174\n",
      "evaluation/Rewards Max                  7.56781\n",
      "evaluation/Rewards Min                  0.118104\n",
      "evaluation/Returns Mean              3167.15\n",
      "evaluation/Returns Std                276.667\n",
      "evaluation/Returns Max               3806.7\n",
      "evaluation/Returns Min               2704.33\n",
      "evaluation/Estimation Bias Mean       377.189\n",
      "evaluation/Estimation Bias Std        212.097\n",
      "evaluation/EB/Q_True Mean              54.9413\n",
      "evaluation/EB/Q_True Std              156.264\n",
      "evaluation/EB/Q_Pred Mean             432.13\n",
      "evaluation/EB/Q_Pred Std              141.859\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3167.15\n",
      "evaluation/Actions Mean                 0.507403\n",
      "evaluation/Actions Std                  0.659847\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.85648\n",
      "time/backward_zf1 (s)                   1.97984\n",
      "time/backward_zf2 (s)                   1.93543\n",
      "time/data sampling (s)                  0.247704\n",
      "time/data storing (s)                   0.0134818\n",
      "time/evaluation sampling (s)            1.10931\n",
      "time/exploration sampling (s)           0.19077\n",
      "time/logging (s)                        0.00789121\n",
      "time/preback_alpha (s)                  0.550042\n",
      "time/preback_policy (s)                 1.0952\n",
      "time/preback_start (s)                  0.119414\n",
      "time/preback_zf (s)                     5.0233\n",
      "time/saving (s)                         0.0055262\n",
      "time/training (s)                       2.17054\n",
      "time/epoch (s)                         16.3049\n",
      "time/total (s)                       1150.35\n",
      "Epoch                                  72\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:11:34.375423 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 73 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  84000\n",
      "trainer/ZF1 Loss                       20.9421\n",
      "trainer/ZF2 Loss                       25.6724\n",
      "trainer/ZF Expert Reward               24.7248\n",
      "trainer/ZF Policy Reward                1.73313\n",
      "trainer/ZF CHI2 Term                   46.5587\n",
      "trainer/Policy Loss                  -177.708\n",
      "trainer/Bias Loss                     209.236\n",
      "trainer/Bias Value                     10.6973\n",
      "trainer/Policy Grad Norm              193.71\n",
      "trainer/Policy Param Norm              28.2589\n",
      "trainer/Zf1 Grad Norm                2235.19\n",
      "trainer/Zf1 Param Norm                 69.4643\n",
      "trainer/Zf2 Grad Norm                2910.4\n",
      "trainer/Zf2 Param Norm                 67.8016\n",
      "trainer/Z Expert Predictions Mean     516.651\n",
      "trainer/Z Expert Predictions Std      105.154\n",
      "trainer/Z Expert Predictions Max      758.597\n",
      "trainer/Z Expert Predictions Min      178.427\n",
      "trainer/Z Policy Predictions Mean     171.983\n",
      "trainer/Z Policy Predictions Std      223.478\n",
      "trainer/Z Policy Predictions Max      721.686\n",
      "trainer/Z Policy Predictions Min     -189.412\n",
      "trainer/Z Expert Targets Mean         491.926\n",
      "trainer/Z Expert Targets Std          105.447\n",
      "trainer/Z Expert Targets Max          732.595\n",
      "trainer/Z Expert Targets Min          152.234\n",
      "trainer/Z Policy Targets Mean         170.25\n",
      "trainer/Z Policy Targets Std          217.319\n",
      "trainer/Z Policy Targets Max          683.044\n",
      "trainer/Z Policy Targets Min         -179.247\n",
      "trainer/Log Pis Mean                   25.9835\n",
      "trainer/Log Pis Std                     7.66069\n",
      "trainer/Policy mu Mean                  0.929622\n",
      "trainer/Policy mu Std                   2.27469\n",
      "trainer/Policy log std Mean            -3.32426\n",
      "trainer/Policy log std Std              1.27836\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         79073\n",
      "exploration/num paths total           841\n",
      "evaluation/num steps total         222778\n",
      "evaluation/num paths total            741\n",
      "evaluation/path length Mean           504.5\n",
      "evaluation/path length Std             91.2384\n",
      "evaluation/path length Max            740\n",
      "evaluation/path length Min            422\n",
      "evaluation/Rewards Mean                 4.68592\n",
      "evaluation/Rewards Std                  1.66774\n",
      "evaluation/Rewards Max                  7.5053\n",
      "evaluation/Rewards Min                 -0.792887\n",
      "evaluation/Returns Mean              2364.04\n",
      "evaluation/Returns Std                532.693\n",
      "evaluation/Returns Max               3724.72\n",
      "evaluation/Returns Min               1834.17\n",
      "evaluation/Estimation Bias Mean       341.346\n",
      "evaluation/Estimation Bias Std        234.211\n",
      "evaluation/EB/Q_True Mean              68.3581\n",
      "evaluation/EB/Q_True Std              170.828\n",
      "evaluation/EB/Q_Pred Mean             409.704\n",
      "evaluation/EB/Q_Pred Std              154.361\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2364.04\n",
      "evaluation/Actions Mean                 0.500203\n",
      "evaluation/Actions Std                  0.647811\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9111\n",
      "time/backward_zf1 (s)                   2.0509\n",
      "time/backward_zf2 (s)                   1.99041\n",
      "time/data sampling (s)                  0.241303\n",
      "time/data storing (s)                   0.0137134\n",
      "time/evaluation sampling (s)            1.07973\n",
      "time/exploration sampling (s)           0.190567\n",
      "time/logging (s)                        0.00669939\n",
      "time/preback_alpha (s)                  0.557092\n",
      "time/preback_policy (s)                 1.16286\n",
      "time/preback_start (s)                  0.120849\n",
      "time/preback_zf (s)                     5.06323\n",
      "time/saving (s)                         0.00558844\n",
      "time/training (s)                       2.09571\n",
      "time/epoch (s)                         16.4898\n",
      "time/total (s)                       1166.86\n",
      "Epoch                                  73\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:11:50.512749 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 74 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  85000\n",
      "trainer/ZF1 Loss                       16.7208\n",
      "trainer/ZF2 Loss                       17.6072\n",
      "trainer/ZF Expert Reward               14.2013\n",
      "trainer/ZF Policy Reward               -6.59854\n",
      "trainer/ZF CHI2 Term                   38.2258\n",
      "trainer/Policy Loss                  -190.238\n",
      "trainer/Bias Loss                     141.497\n",
      "trainer/Bias Value                     10.7058\n",
      "trainer/Policy Grad Norm              102.423\n",
      "trainer/Policy Param Norm              28.3403\n",
      "trainer/Zf1 Grad Norm                2244.08\n",
      "trainer/Zf1 Param Norm                 69.801\n",
      "trainer/Zf2 Grad Norm                3001.89\n",
      "trainer/Zf2 Param Norm                 68.1382\n",
      "trainer/Z Expert Predictions Mean     521.352\n",
      "trainer/Z Expert Predictions Std       99.4866\n",
      "trainer/Z Expert Predictions Max      720.683\n",
      "trainer/Z Expert Predictions Min      114.876\n",
      "trainer/Z Policy Predictions Mean     178.27\n",
      "trainer/Z Policy Predictions Std      234.393\n",
      "trainer/Z Policy Predictions Max      577.711\n",
      "trainer/Z Policy Predictions Min     -196.495\n",
      "trainer/Z Expert Targets Mean         507.151\n",
      "trainer/Z Expert Targets Std          101.566\n",
      "trainer/Z Expert Targets Max          718.555\n",
      "trainer/Z Expert Targets Min           97.9158\n",
      "trainer/Z Policy Targets Mean         184.869\n",
      "trainer/Z Policy Targets Std          233.613\n",
      "trainer/Z Policy Targets Max          571.586\n",
      "trainer/Z Policy Targets Min         -187.152\n",
      "trainer/Log Pis Mean                   26.193\n",
      "trainer/Log Pis Std                     6.84086\n",
      "trainer/Policy mu Mean                  0.791489\n",
      "trainer/Policy mu Std                   2.36801\n",
      "trainer/Policy log std Mean            -3.33016\n",
      "trainer/Policy log std Std              1.28346\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         80980\n",
      "exploration/num paths total           844\n",
      "evaluation/num steps total         230350\n",
      "evaluation/num paths total            752\n",
      "evaluation/path length Mean           688.364\n",
      "evaluation/path length Std            175.774\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            459\n",
      "evaluation/Rewards Mean                 4.94462\n",
      "evaluation/Rewards Std                  1.51931\n",
      "evaluation/Rewards Max                  7.67442\n",
      "evaluation/Rewards Min                  0.0941967\n",
      "evaluation/Returns Mean              3403.7\n",
      "evaluation/Returns Std                915.982\n",
      "evaluation/Returns Max               5066.74\n",
      "evaluation/Returns Min               2187.32\n",
      "evaluation/Estimation Bias Mean       455.643\n",
      "evaluation/Estimation Bias Std        224.634\n",
      "evaluation/EB/Q_True Mean              63.2146\n",
      "evaluation/EB/Q_True Std              166.166\n",
      "evaluation/EB/Q_Pred Mean             518.857\n",
      "evaluation/EB/Q_Pred Std              141.179\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3403.7\n",
      "evaluation/Actions Mean                 0.51278\n",
      "evaluation/Actions Std                  0.643631\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.63361\n",
      "time/backward_zf1 (s)                   1.76475\n",
      "time/backward_zf2 (s)                   1.6882\n",
      "time/data sampling (s)                  0.229479\n",
      "time/data storing (s)                   0.0139374\n",
      "time/evaluation sampling (s)            1.40172\n",
      "time/exploration sampling (s)           0.196392\n",
      "time/logging (s)                        0.00925993\n",
      "time/preback_alpha (s)                  0.542206\n",
      "time/preback_policy (s)                 0.892204\n",
      "time/preback_start (s)                  0.118051\n",
      "time/preback_zf (s)                     5.0352\n",
      "time/saving (s)                         0.00593266\n",
      "time/training (s)                       2.54452\n",
      "time/epoch (s)                         16.0755\n",
      "time/total (s)                       1182.96\n",
      "Epoch                                  74\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:12:07.197937 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 75 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  86000\n",
      "trainer/ZF1 Loss                       33.0296\n",
      "trainer/ZF2 Loss                       23.3763\n",
      "trainer/ZF Expert Reward               15.7308\n",
      "trainer/ZF Policy Reward               -5.12067\n",
      "trainer/ZF CHI2 Term                   49.3177\n",
      "trainer/Policy Loss                  -208.828\n",
      "trainer/Bias Loss                     141.402\n",
      "trainer/Bias Value                     10.7143\n",
      "trainer/Policy Grad Norm              157.248\n",
      "trainer/Policy Param Norm              28.408\n",
      "trainer/Zf1 Grad Norm                2825.13\n",
      "trainer/Zf1 Param Norm                 70.1645\n",
      "trainer/Zf2 Grad Norm                2194.27\n",
      "trainer/Zf2 Param Norm                 68.5075\n",
      "trainer/Z Expert Predictions Mean     552.171\n",
      "trainer/Z Expert Predictions Std      105.053\n",
      "trainer/Z Expert Predictions Max      754.653\n",
      "trainer/Z Expert Predictions Min       87.1947\n",
      "trainer/Z Policy Predictions Mean     197.504\n",
      "trainer/Z Policy Predictions Std      236.034\n",
      "trainer/Z Policy Predictions Max      665.726\n",
      "trainer/Z Policy Predictions Min     -177.824\n",
      "trainer/Z Expert Targets Mean         536.44\n",
      "trainer/Z Expert Targets Std          104.892\n",
      "trainer/Z Expert Targets Max          752.505\n",
      "trainer/Z Expert Targets Min           82.3289\n",
      "trainer/Z Policy Targets Mean         202.625\n",
      "trainer/Z Policy Targets Std          234.891\n",
      "trainer/Z Policy Targets Max          660.647\n",
      "trainer/Z Policy Targets Min         -187.173\n",
      "trainer/Log Pis Mean                   26.3275\n",
      "trainer/Log Pis Std                     7.03088\n",
      "trainer/Policy mu Mean                  0.771757\n",
      "trainer/Policy mu Std                   2.42236\n",
      "trainer/Policy log std Mean            -3.28512\n",
      "trainer/Policy log std Std              1.3671\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         81980\n",
      "exploration/num paths total           845\n",
      "evaluation/num steps total         238033\n",
      "evaluation/num paths total            762\n",
      "evaluation/path length Mean           768.3\n",
      "evaluation/path length Std            153.933\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            588\n",
      "evaluation/Rewards Mean                 4.95384\n",
      "evaluation/Rewards Std                  1.4271\n",
      "evaluation/Rewards Max                  7.55257\n",
      "evaluation/Rewards Min                  0.11846\n",
      "evaluation/Returns Mean              3806.04\n",
      "evaluation/Returns Std                800.774\n",
      "evaluation/Returns Max               4913.79\n",
      "evaluation/Returns Min               2829.38\n",
      "evaluation/Estimation Bias Mean       485.044\n",
      "evaluation/Estimation Bias Std        224.694\n",
      "evaluation/EB/Q_True Mean              60.3259\n",
      "evaluation/EB/Q_True Std              160.432\n",
      "evaluation/EB/Q_Pred Mean             545.37\n",
      "evaluation/EB/Q_Pred Std              144.157\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3806.04\n",
      "evaluation/Actions Mean                 0.518731\n",
      "evaluation/Actions Std                  0.639018\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                1.81042\n",
      "time/backward_zf1 (s)                   1.9424\n",
      "time/backward_zf2 (s)                   1.87801\n",
      "time/data sampling (s)                  0.240385\n",
      "time/data storing (s)                   0.013736\n",
      "time/evaluation sampling (s)            1.44288\n",
      "time/exploration sampling (s)           0.19503\n",
      "time/logging (s)                        0.00962413\n",
      "time/preback_alpha (s)                  0.553314\n",
      "time/preback_policy (s)                 1.01889\n",
      "time/preback_start (s)                  0.120271\n",
      "time/preback_zf (s)                     5.05268\n",
      "time/saving (s)                         0.00562308\n",
      "time/training (s)                       2.33635\n",
      "time/epoch (s)                         16.6196\n",
      "time/total (s)                       1199.6\n",
      "Epoch                                  75\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:12:24.022196 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 76 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  87000\n",
      "trainer/ZF1 Loss                       38.876\n",
      "trainer/ZF2 Loss                       45.6518\n",
      "trainer/ZF Expert Reward               19.4273\n",
      "trainer/ZF Policy Reward               -4.19221\n",
      "trainer/ZF CHI2 Term                   66.1512\n",
      "trainer/Policy Loss                  -226.225\n",
      "trainer/Bias Loss                     150.026\n",
      "trainer/Bias Value                     10.7226\n",
      "trainer/Policy Grad Norm              172.221\n",
      "trainer/Policy Param Norm              28.4831\n",
      "trainer/Zf1 Grad Norm                2747.88\n",
      "trainer/Zf1 Param Norm                 70.5892\n",
      "trainer/Zf2 Grad Norm                2443.03\n",
      "trainer/Zf2 Param Norm                 68.911\n",
      "trainer/Z Expert Predictions Mean     592.907\n",
      "trainer/Z Expert Predictions Std      110.733\n",
      "trainer/Z Expert Predictions Max      801.213\n",
      "trainer/Z Expert Predictions Min       84.1833\n",
      "trainer/Z Policy Predictions Mean     215.279\n",
      "trainer/Z Policy Predictions Std      242.786\n",
      "trainer/Z Policy Predictions Max      638.939\n",
      "trainer/Z Policy Predictions Min     -204.264\n",
      "trainer/Z Expert Targets Mean         573.479\n",
      "trainer/Z Expert Targets Std          110.318\n",
      "trainer/Z Expert Targets Max          775.121\n",
      "trainer/Z Expert Targets Min           37.5992\n",
      "trainer/Z Policy Targets Mean         219.471\n",
      "trainer/Z Policy Targets Std          240.32\n",
      "trainer/Z Policy Targets Max          646.351\n",
      "trainer/Z Policy Targets Min         -198.733\n",
      "trainer/Log Pis Mean                   26.771\n",
      "trainer/Log Pis Std                     6.49368\n",
      "trainer/Policy mu Mean                  0.790951\n",
      "trainer/Policy mu Std                   2.56127\n",
      "trainer/Policy log std Mean            -3.34371\n",
      "trainer/Policy log std Std              1.30935\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         84669\n",
      "exploration/num paths total           849\n",
      "evaluation/num steps total         246678\n",
      "evaluation/num paths total            773\n",
      "evaluation/path length Mean           785.909\n",
      "evaluation/path length Std            246.063\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            448\n",
      "evaluation/Rewards Mean                 4.90003\n",
      "evaluation/Rewards Std                  1.42978\n",
      "evaluation/Rewards Max                  7.5688\n",
      "evaluation/Rewards Min                  0.0964634\n",
      "evaluation/Returns Mean              3850.98\n",
      "evaluation/Returns Std               1372.82\n",
      "evaluation/Returns Max               5159.99\n",
      "evaluation/Returns Min               1967.17\n",
      "evaluation/Estimation Bias Mean       512.673\n",
      "evaluation/Estimation Bias Std        243.061\n",
      "evaluation/EB/Q_True Mean              54.0466\n",
      "evaluation/EB/Q_True Std              153.932\n",
      "evaluation/EB/Q_Pred Mean             566.72\n",
      "evaluation/EB/Q_Pred Std              147.348\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3850.98\n",
      "evaluation/Actions Mean                 0.527581\n",
      "evaluation/Actions Std                  0.637402\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999985\n",
      "time/backward_policy (s)                1.90307\n",
      "time/backward_zf1 (s)                   2.03353\n",
      "time/backward_zf2 (s)                   1.98443\n",
      "time/data sampling (s)                  0.244537\n",
      "time/data storing (s)                   0.013499\n",
      "time/evaluation sampling (s)            1.47138\n",
      "time/exploration sampling (s)           0.197952\n",
      "time/logging (s)                        0.0103257\n",
      "time/preback_alpha (s)                  0.552898\n",
      "time/preback_policy (s)                 1.16357\n",
      "time/preback_start (s)                  0.119927\n",
      "time/preback_zf (s)                     5.02174\n",
      "time/saving (s)                         0.00556848\n",
      "time/training (s)                       2.02737\n",
      "time/epoch (s)                         16.7498\n",
      "time/total (s)                       1216.38\n",
      "Epoch                                  76\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:12:40.527784 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 77 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  88000\n",
      "trainer/ZF1 Loss                       36.8558\n",
      "trainer/ZF2 Loss                       32.0078\n",
      "trainer/ZF Expert Reward               18.1815\n",
      "trainer/ZF Policy Reward               -4.46387\n",
      "trainer/ZF CHI2 Term                   57.3502\n",
      "trainer/Policy Loss                  -207.727\n",
      "trainer/Bias Loss                     225.086\n",
      "trainer/Bias Value                     10.731\n",
      "trainer/Policy Grad Norm              149.5\n",
      "trainer/Policy Param Norm              28.559\n",
      "trainer/Zf1 Grad Norm                2840.17\n",
      "trainer/Zf1 Param Norm                 71.0247\n",
      "trainer/Zf2 Grad Norm                2257.52\n",
      "trainer/Zf2 Param Norm                 69.3353\n",
      "trainer/Z Expert Predictions Mean     617.886\n",
      "trainer/Z Expert Predictions Std      117.853\n",
      "trainer/Z Expert Predictions Max      820.978\n",
      "trainer/Z Expert Predictions Min      105.357\n",
      "trainer/Z Policy Predictions Mean     203.944\n",
      "trainer/Z Policy Predictions Std      260.747\n",
      "trainer/Z Policy Predictions Max      732.202\n",
      "trainer/Z Policy Predictions Min     -248.57\n",
      "trainer/Z Expert Targets Mean         599.704\n",
      "trainer/Z Expert Targets Std          119.718\n",
      "trainer/Z Expert Targets Max          803.082\n",
      "trainer/Z Expert Targets Min           81.0012\n",
      "trainer/Z Policy Targets Mean         208.408\n",
      "trainer/Z Policy Targets Std          259.938\n",
      "trainer/Z Policy Targets Max          702.5\n",
      "trainer/Z Policy Targets Min         -237.516\n",
      "trainer/Log Pis Mean                   27.2977\n",
      "trainer/Log Pis Std                     6.71943\n",
      "trainer/Policy mu Mean                  0.695174\n",
      "trainer/Policy mu Std                   2.62334\n",
      "trainer/Policy log std Mean            -3.38963\n",
      "trainer/Policy log std Std              1.37829\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         84669\n",
      "exploration/num paths total           849\n",
      "evaluation/num steps total         256678\n",
      "evaluation/num paths total            783\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.73096\n",
      "evaluation/Rewards Std                  1.19137\n",
      "evaluation/Rewards Max                  6.89282\n",
      "evaluation/Rewards Min                  0.0993839\n",
      "evaluation/Returns Mean              4730.96\n",
      "evaluation/Returns Std                 35.3993\n",
      "evaluation/Returns Max               4813.62\n",
      "evaluation/Returns Min               4693.45\n",
      "evaluation/Estimation Bias Mean       527.657\n",
      "evaluation/Estimation Bias Std        161.373\n",
      "evaluation/EB/Q_True Mean              44.3049\n",
      "evaluation/EB/Q_True Std              136.715\n",
      "evaluation/EB/Q_Pred Mean             571.962\n",
      "evaluation/EB/Q_Pred Std               85.6161\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4730.96\n",
      "evaluation/Actions Mean                 0.521575\n",
      "evaluation/Actions Std                  0.622534\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999919\n",
      "time/backward_policy (s)                1.73446\n",
      "time/backward_zf1 (s)                   1.85116\n",
      "time/backward_zf2 (s)                   1.79246\n",
      "time/data sampling (s)                  0.244271\n",
      "time/data storing (s)                   0.0138654\n",
      "time/evaluation sampling (s)            1.43427\n",
      "time/exploration sampling (s)           0.191393\n",
      "time/logging (s)                        0.0123482\n",
      "time/preback_alpha (s)                  0.54907\n",
      "time/preback_policy (s)                 0.93102\n",
      "time/preback_start (s)                  0.118556\n",
      "time/preback_zf (s)                     5.0512\n",
      "time/saving (s)                         0.00554518\n",
      "time/training (s)                       2.5144\n",
      "time/epoch (s)                         16.444\n",
      "time/total (s)                       1232.84\n",
      "Epoch                                  77\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:12:57.187138 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 78 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  89000\n",
      "trainer/ZF1 Loss                       30.0219\n",
      "trainer/ZF2 Loss                       32.9187\n",
      "trainer/ZF Expert Reward               12.8468\n",
      "trainer/ZF Policy Reward               -5.62351\n",
      "trainer/ZF CHI2 Term                   50.2027\n",
      "trainer/Policy Loss                  -221.686\n",
      "trainer/Bias Loss                     175.1\n",
      "trainer/Bias Value                     10.7393\n",
      "trainer/Policy Grad Norm              217.379\n",
      "trainer/Policy Param Norm              28.634\n",
      "trainer/Zf1 Grad Norm                2132.14\n",
      "trainer/Zf1 Param Norm                 71.4704\n",
      "trainer/Zf2 Grad Norm                2786.72\n",
      "trainer/Zf2 Param Norm                 69.7853\n",
      "trainer/Z Expert Predictions Mean     631.291\n",
      "trainer/Z Expert Predictions Std      120.946\n",
      "trainer/Z Expert Predictions Max      834.389\n",
      "trainer/Z Expert Predictions Min      184.956\n",
      "trainer/Z Policy Predictions Mean     208.538\n",
      "trainer/Z Policy Predictions Std      257.934\n",
      "trainer/Z Policy Predictions Max      693.325\n",
      "trainer/Z Policy Predictions Min     -231.254\n",
      "trainer/Z Expert Targets Mean         618.444\n",
      "trainer/Z Expert Targets Std          118.015\n",
      "trainer/Z Expert Targets Max          819.723\n",
      "trainer/Z Expert Targets Min          176.506\n",
      "trainer/Z Policy Targets Mean         214.162\n",
      "trainer/Z Policy Targets Std          255.495\n",
      "trainer/Z Policy Targets Max          675.155\n",
      "trainer/Z Policy Targets Min         -220.39\n",
      "trainer/Log Pis Mean                   26.202\n",
      "trainer/Log Pis Std                     6.66879\n",
      "trainer/Policy mu Mean                  0.711863\n",
      "trainer/Policy mu Std                   2.58636\n",
      "trainer/Policy log std Mean            -3.36378\n",
      "trainer/Policy log std Std              1.357\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         84669\n",
      "exploration/num paths total           849\n",
      "evaluation/num steps total         266597\n",
      "evaluation/num paths total            793\n",
      "evaluation/path length Mean           991.9\n",
      "evaluation/path length Std             24.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            919\n",
      "evaluation/Rewards Mean                 4.69672\n",
      "evaluation/Rewards Std                  1.18103\n",
      "evaluation/Rewards Max                  6.78755\n",
      "evaluation/Rewards Min                 -1.57572\n",
      "evaluation/Returns Mean              4658.68\n",
      "evaluation/Returns Std                128.047\n",
      "evaluation/Returns Max               4819.9\n",
      "evaluation/Returns Min               4391.08\n",
      "evaluation/Estimation Bias Mean       505.524\n",
      "evaluation/Estimation Bias Std        176.425\n",
      "evaluation/EB/Q_True Mean              45.6389\n",
      "evaluation/EB/Q_True Std              140.183\n",
      "evaluation/EB/Q_Pred Mean             551.163\n",
      "evaluation/EB/Q_Pred Std              111.062\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4658.68\n",
      "evaluation/Actions Mean                 0.501865\n",
      "evaluation/Actions Std                  0.647972\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82342\n",
      "time/backward_zf1 (s)                   1.94499\n",
      "time/backward_zf2 (s)                   1.88549\n",
      "time/data sampling (s)                  0.243184\n",
      "time/data storing (s)                   0.0134653\n",
      "time/evaluation sampling (s)            1.53537\n",
      "time/exploration sampling (s)           0.187922\n",
      "time/logging (s)                        0.011954\n",
      "time/preback_alpha (s)                  0.551934\n",
      "time/preback_policy (s)                 1.08175\n",
      "time/preback_start (s)                  0.118826\n",
      "time/preback_zf (s)                     5.04751\n",
      "time/saving (s)                         0.00582042\n",
      "time/training (s)                       2.14222\n",
      "time/epoch (s)                         16.5939\n",
      "time/total (s)                       1249.46\n",
      "Epoch                                  78\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:13:13.882108 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 79 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  90000\n",
      "trainer/ZF1 Loss                       28.603\n",
      "trainer/ZF2 Loss                       24.7683\n",
      "trainer/ZF Expert Reward               12.0542\n",
      "trainer/ZF Policy Reward               -5.12284\n",
      "trainer/ZF CHI2 Term                   44.1308\n",
      "trainer/Policy Loss                  -251.056\n",
      "trainer/Bias Loss                     161.378\n",
      "trainer/Bias Value                     10.7476\n",
      "trainer/Policy Grad Norm              178.359\n",
      "trainer/Policy Param Norm              28.7291\n",
      "trainer/Zf1 Grad Norm                3792.6\n",
      "trainer/Zf1 Param Norm                 71.9119\n",
      "trainer/Zf2 Grad Norm                3355.45\n",
      "trainer/Zf2 Param Norm                 70.2417\n",
      "trainer/Z Expert Predictions Mean     641.729\n",
      "trainer/Z Expert Predictions Std      123.345\n",
      "trainer/Z Expert Predictions Max      850.482\n",
      "trainer/Z Expert Predictions Min      290.267\n",
      "trainer/Z Policy Predictions Mean     239.469\n",
      "trainer/Z Policy Predictions Std      278.927\n",
      "trainer/Z Policy Predictions Max      777.904\n",
      "trainer/Z Policy Predictions Min     -219.735\n",
      "trainer/Z Expert Targets Mean         629.675\n",
      "trainer/Z Expert Targets Std          121.953\n",
      "trainer/Z Expert Targets Max          851.007\n",
      "trainer/Z Expert Targets Min          282.113\n",
      "trainer/Z Policy Targets Mean         244.592\n",
      "trainer/Z Policy Targets Std          275.616\n",
      "trainer/Z Policy Targets Max          776.381\n",
      "trainer/Z Policy Targets Min         -200.325\n",
      "trainer/Log Pis Mean                   26.8173\n",
      "trainer/Log Pis Std                     7.18804\n",
      "trainer/Policy mu Mean                  0.720612\n",
      "trainer/Policy mu Std                   2.53184\n",
      "trainer/Policy log std Mean            -3.39788\n",
      "trainer/Policy log std Std              1.34885\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         85669\n",
      "exploration/num paths total           850\n",
      "evaluation/num steps total         274459\n",
      "evaluation/num paths total            803\n",
      "evaluation/path length Mean           786.2\n",
      "evaluation/path length Std            188.972\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            481\n",
      "evaluation/Rewards Mean                 4.873\n",
      "evaluation/Rewards Std                  1.3658\n",
      "evaluation/Rewards Max                  7.232\n",
      "evaluation/Rewards Min                  0.100324\n",
      "evaluation/Returns Mean              3831.15\n",
      "evaluation/Returns Std               1006.01\n",
      "evaluation/Returns Max               5069.12\n",
      "evaluation/Returns Min               2202.78\n",
      "evaluation/Estimation Bias Mean       530.977\n",
      "evaluation/Estimation Bias Std        243.525\n",
      "evaluation/EB/Q_True Mean              58.1183\n",
      "evaluation/EB/Q_True Std              156.8\n",
      "evaluation/EB/Q_Pred Mean             589.095\n",
      "evaluation/EB/Q_Pred Std              186.654\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3831.15\n",
      "evaluation/Actions Mean                 0.48309\n",
      "evaluation/Actions Std                  0.663732\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.86553\n",
      "time/backward_zf1 (s)                   1.98161\n",
      "time/backward_zf2 (s)                   1.93273\n",
      "time/data sampling (s)                  0.244412\n",
      "time/data storing (s)                   0.0142481\n",
      "time/evaluation sampling (s)            1.41803\n",
      "time/exploration sampling (s)           0.194875\n",
      "time/logging (s)                        0.00938417\n",
      "time/preback_alpha (s)                  0.553714\n",
      "time/preback_policy (s)                 1.10253\n",
      "time/preback_start (s)                  0.120325\n",
      "time/preback_zf (s)                     5.04853\n",
      "time/saving (s)                         0.00567745\n",
      "time/training (s)                       2.13474\n",
      "time/epoch (s)                         16.6263\n",
      "time/total (s)                       1266.1\n",
      "Epoch                                  79\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:13:30.615835 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 80 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  91000\n",
      "trainer/ZF1 Loss                       30.647\n",
      "trainer/ZF2 Loss                       32.2578\n",
      "trainer/ZF Expert Reward               17.1263\n",
      "trainer/ZF Policy Reward               -4.91432\n",
      "trainer/ZF CHI2 Term                   53.7574\n",
      "trainer/Policy Loss                  -265.225\n",
      "trainer/Bias Loss                     194.614\n",
      "trainer/Bias Value                     10.7558\n",
      "trainer/Policy Grad Norm              162.606\n",
      "trainer/Policy Param Norm              28.818\n",
      "trainer/Zf1 Grad Norm                2636.77\n",
      "trainer/Zf1 Param Norm                 72.3433\n",
      "trainer/Zf2 Grad Norm                2204.19\n",
      "trainer/Zf2 Param Norm                 70.6616\n",
      "trainer/Z Expert Predictions Mean     672.091\n",
      "trainer/Z Expert Predictions Std      123.11\n",
      "trainer/Z Expert Predictions Max      887.211\n",
      "trainer/Z Expert Predictions Min      247.837\n",
      "trainer/Z Policy Predictions Mean     253.805\n",
      "trainer/Z Policy Predictions Std      291.811\n",
      "trainer/Z Policy Predictions Max      778.978\n",
      "trainer/Z Policy Predictions Min     -272.434\n",
      "trainer/Z Expert Targets Mean         654.965\n",
      "trainer/Z Expert Targets Std          121.521\n",
      "trainer/Z Expert Targets Max          863.342\n",
      "trainer/Z Expert Targets Min          213.116\n",
      "trainer/Z Policy Targets Mean         258.719\n",
      "trainer/Z Policy Targets Std          288.002\n",
      "trainer/Z Policy Targets Max          768.484\n",
      "trainer/Z Policy Targets Min         -277.909\n",
      "trainer/Log Pis Mean                   26.4329\n",
      "trainer/Log Pis Std                     7.75369\n",
      "trainer/Policy mu Mean                  0.745662\n",
      "trainer/Policy mu Std                   2.50419\n",
      "trainer/Policy log std Mean            -3.3142\n",
      "trainer/Policy log std Std              1.32292\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         85669\n",
      "exploration/num paths total           850\n",
      "evaluation/num steps total         283758\n",
      "evaluation/num paths total            813\n",
      "evaluation/path length Mean           929.9\n",
      "evaluation/path length Std            127.781\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            583\n",
      "evaluation/Rewards Mean                 4.99106\n",
      "evaluation/Rewards Std                  1.28787\n",
      "evaluation/Rewards Max                  7.23423\n",
      "evaluation/Rewards Min                  0.127433\n",
      "evaluation/Returns Mean              4641.19\n",
      "evaluation/Returns Std                705.53\n",
      "evaluation/Returns Max               5103.85\n",
      "evaluation/Returns Min               2745.77\n",
      "evaluation/Estimation Bias Mean       614.378\n",
      "evaluation/Estimation Bias Std        231.656\n",
      "evaluation/EB/Q_True Mean              51.16\n",
      "evaluation/EB/Q_True Std              151.359\n",
      "evaluation/EB/Q_Pred Mean             665.538\n",
      "evaluation/EB/Q_Pred Std              157.993\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4641.19\n",
      "evaluation/Actions Mean                 0.494527\n",
      "evaluation/Actions Std                  0.645005\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.78236\n",
      "time/backward_zf1 (s)                   1.92711\n",
      "time/backward_zf2 (s)                   1.86273\n",
      "time/data sampling (s)                  0.256787\n",
      "time/data storing (s)                   0.0144282\n",
      "time/evaluation sampling (s)            1.43173\n",
      "time/exploration sampling (s)           0.196045\n",
      "time/logging (s)                        0.0111109\n",
      "time/preback_alpha (s)                  0.565581\n",
      "time/preback_policy (s)                 1.02187\n",
      "time/preback_start (s)                  0.121577\n",
      "time/preback_zf (s)                     5.06654\n",
      "time/saving (s)                         0.00521333\n",
      "time/training (s)                       2.40868\n",
      "time/epoch (s)                         16.6717\n",
      "time/total (s)                       1282.79\n",
      "Epoch                                  80\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:13:46.491187 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 81 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  92000\n",
      "trainer/ZF1 Loss                       24.8378\n",
      "trainer/ZF2 Loss                       29.8612\n",
      "trainer/ZF Expert Reward               19.3078\n",
      "trainer/ZF Policy Reward               -2.09999\n",
      "trainer/ZF CHI2 Term                   49.0113\n",
      "trainer/Policy Loss                  -257.61\n",
      "trainer/Bias Loss                     168.45\n",
      "trainer/Bias Value                     10.764\n",
      "trainer/Policy Grad Norm              147.475\n",
      "trainer/Policy Param Norm              28.8986\n",
      "trainer/Zf1 Grad Norm                2003.74\n",
      "trainer/Zf1 Param Norm                 72.7632\n",
      "trainer/Zf2 Grad Norm                2227.45\n",
      "trainer/Zf2 Param Norm                 71.0869\n",
      "trainer/Z Expert Predictions Mean     702.45\n",
      "trainer/Z Expert Predictions Std      133.099\n",
      "trainer/Z Expert Predictions Max      922.465\n",
      "trainer/Z Expert Predictions Min      272.869\n",
      "trainer/Z Policy Predictions Mean     248.531\n",
      "trainer/Z Policy Predictions Std      301.945\n",
      "trainer/Z Policy Predictions Max      876.442\n",
      "trainer/Z Policy Predictions Min     -207.428\n",
      "trainer/Z Expert Targets Mean         683.143\n",
      "trainer/Z Expert Targets Std          132.878\n",
      "trainer/Z Expert Targets Max          903.319\n",
      "trainer/Z Expert Targets Min          251.327\n",
      "trainer/Z Policy Targets Mean         250.631\n",
      "trainer/Z Policy Targets Std          297.712\n",
      "trainer/Z Policy Targets Max          845.031\n",
      "trainer/Z Policy Targets Min         -210.717\n",
      "trainer/Log Pis Mean                   25.3985\n",
      "trainer/Log Pis Std                     7.28814\n",
      "trainer/Policy mu Mean                  0.537515\n",
      "trainer/Policy mu Std                   2.76056\n",
      "trainer/Policy log std Mean            -3.32157\n",
      "trainer/Policy log std Std              1.301\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         86402\n",
      "exploration/num paths total           851\n",
      "evaluation/num steps total         289790\n",
      "evaluation/num paths total            823\n",
      "evaluation/path length Mean           603.2\n",
      "evaluation/path length Std            102.043\n",
      "evaluation/path length Max            762\n",
      "evaluation/path length Min            455\n",
      "evaluation/Rewards Mean                 4.85861\n",
      "evaluation/Rewards Std                  1.53157\n",
      "evaluation/Rewards Max                  7.65645\n",
      "evaluation/Rewards Min                  0.139068\n",
      "evaluation/Returns Mean              2930.71\n",
      "evaluation/Returns Std                583.595\n",
      "evaluation/Returns Max               3844.53\n",
      "evaluation/Returns Min               2074.29\n",
      "evaluation/Estimation Bias Mean       564.174\n",
      "evaluation/Estimation Bias Std        287.844\n",
      "evaluation/EB/Q_True Mean              58.9915\n",
      "evaluation/EB/Q_True Std              160.367\n",
      "evaluation/EB/Q_Pred Mean             623.165\n",
      "evaluation/EB/Q_Pred Std              229.674\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2930.71\n",
      "evaluation/Actions Mean                 0.488223\n",
      "evaluation/Actions Std                  0.649437\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                1.64702\n",
      "time/backward_zf1 (s)                   1.78437\n",
      "time/backward_zf2 (s)                   1.70034\n",
      "time/data sampling (s)                  0.243741\n",
      "time/data storing (s)                   0.0135269\n",
      "time/evaluation sampling (s)            1.10067\n",
      "time/exploration sampling (s)           0.189607\n",
      "time/logging (s)                        0.00790772\n",
      "time/preback_alpha (s)                  0.545694\n",
      "time/preback_policy (s)                 0.899856\n",
      "time/preback_start (s)                  0.118072\n",
      "time/preback_zf (s)                     5.01327\n",
      "time/saving (s)                         0.00543879\n",
      "time/training (s)                       2.53876\n",
      "time/epoch (s)                         15.8083\n",
      "time/total (s)                       1298.62\n",
      "Epoch                                  81\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:14:02.956944 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 82 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  93000\n",
      "trainer/ZF1 Loss                       37.2911\n",
      "trainer/ZF2 Loss                       29.9723\n",
      "trainer/ZF Expert Reward               24.9701\n",
      "trainer/ZF Policy Reward               -1.06922\n",
      "trainer/ZF CHI2 Term                   59.9311\n",
      "trainer/Policy Loss                  -288.075\n",
      "trainer/Bias Loss                     210.392\n",
      "trainer/Bias Value                     10.772\n",
      "trainer/Policy Grad Norm              183.264\n",
      "trainer/Policy Param Norm              28.9848\n",
      "trainer/Zf1 Grad Norm                2966.69\n",
      "trainer/Zf1 Param Norm                 73.1762\n",
      "trainer/Zf2 Grad Norm                2109.67\n",
      "trainer/Zf2 Param Norm                 71.4954\n",
      "trainer/Z Expert Predictions Mean     742.83\n",
      "trainer/Z Expert Predictions Std      127.228\n",
      "trainer/Z Expert Predictions Max      914.217\n",
      "trainer/Z Expert Predictions Min      237.84\n",
      "trainer/Z Policy Predictions Mean     279.614\n",
      "trainer/Z Policy Predictions Std      315.859\n",
      "trainer/Z Policy Predictions Max      888.093\n",
      "trainer/Z Policy Predictions Min     -218.872\n",
      "trainer/Z Expert Targets Mean         717.859\n",
      "trainer/Z Expert Targets Std          125.608\n",
      "trainer/Z Expert Targets Max          886.482\n",
      "trainer/Z Expert Targets Min          208.247\n",
      "trainer/Z Policy Targets Mean         280.683\n",
      "trainer/Z Policy Targets Std          312.296\n",
      "trainer/Z Policy Targets Max          847.782\n",
      "trainer/Z Policy Targets Min         -220.449\n",
      "trainer/Log Pis Mean                   26.0036\n",
      "trainer/Log Pis Std                     6.96486\n",
      "trainer/Policy mu Mean                  0.643339\n",
      "trainer/Policy mu Std                   2.42799\n",
      "trainer/Policy log std Mean            -3.27287\n",
      "trainer/Policy log std Std              1.30179\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         87402\n",
      "exploration/num paths total           852\n",
      "evaluation/num steps total         297144\n",
      "evaluation/num paths total            833\n",
      "evaluation/path length Mean           735.4\n",
      "evaluation/path length Std            176.576\n",
      "evaluation/path length Max            988\n",
      "evaluation/path length Min            523\n",
      "evaluation/Rewards Mean                 4.96451\n",
      "evaluation/Rewards Std                  1.43941\n",
      "evaluation/Rewards Max                  7.15537\n",
      "evaluation/Rewards Min                  0.101097\n",
      "evaluation/Returns Mean              3650.9\n",
      "evaluation/Returns Std                995.436\n",
      "evaluation/Returns Max               5063.24\n",
      "evaluation/Returns Min               2478.19\n",
      "evaluation/Estimation Bias Mean       602.127\n",
      "evaluation/Estimation Bias Std        282.775\n",
      "evaluation/EB/Q_True Mean              64.9569\n",
      "evaluation/EB/Q_True Std              169.408\n",
      "evaluation/EB/Q_Pred Mean             667.084\n",
      "evaluation/EB/Q_Pred Std              221.436\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3650.9\n",
      "evaluation/Actions Mean                 0.483965\n",
      "evaluation/Actions Std                  0.649399\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.75821\n",
      "time/backward_zf1 (s)                   1.87444\n",
      "time/backward_zf2 (s)                   1.82162\n",
      "time/data sampling (s)                  0.247192\n",
      "time/data storing (s)                   0.0138815\n",
      "time/evaluation sampling (s)            1.34521\n",
      "time/exploration sampling (s)           0.194639\n",
      "time/logging (s)                        0.00928148\n",
      "time/preback_alpha (s)                  0.557785\n",
      "time/preback_policy (s)                 1.01163\n",
      "time/preback_start (s)                  0.121881\n",
      "time/preback_zf (s)                     5.04852\n",
      "time/saving (s)                         0.00565716\n",
      "time/training (s)                       2.3914\n",
      "time/epoch (s)                         16.4014\n",
      "time/total (s)                       1315.04\n",
      "Epoch                                  82\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:14:19.817923 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 83 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  94000\n",
      "trainer/ZF1 Loss                       29.1495\n",
      "trainer/ZF2 Loss                       36.6788\n",
      "trainer/ZF Expert Reward               21.9979\n",
      "trainer/ZF Policy Reward                0.462157\n",
      "trainer/ZF CHI2 Term                   54.7006\n",
      "trainer/Policy Loss                  -314.839\n",
      "trainer/Bias Loss                     192.111\n",
      "trainer/Bias Value                     10.7801\n",
      "trainer/Policy Grad Norm              184.575\n",
      "trainer/Policy Param Norm              29.0717\n",
      "trainer/Zf1 Grad Norm                1907.2\n",
      "trainer/Zf1 Param Norm                 73.6294\n",
      "trainer/Zf2 Grad Norm                3485.77\n",
      "trainer/Zf2 Param Norm                 71.9406\n",
      "trainer/Z Expert Predictions Mean     778.436\n",
      "trainer/Z Expert Predictions Std      118.716\n",
      "trainer/Z Expert Predictions Max      967.952\n",
      "trainer/Z Expert Predictions Min      350.877\n",
      "trainer/Z Policy Predictions Mean     309.34\n",
      "trainer/Z Policy Predictions Std      327.372\n",
      "trainer/Z Policy Predictions Max      887.759\n",
      "trainer/Z Policy Predictions Min     -268.999\n",
      "trainer/Z Expert Targets Mean         756.438\n",
      "trainer/Z Expert Targets Std          119.382\n",
      "trainer/Z Expert Targets Max          948.169\n",
      "trainer/Z Expert Targets Min          339.263\n",
      "trainer/Z Policy Targets Mean         308.877\n",
      "trainer/Z Policy Targets Std          324.945\n",
      "trainer/Z Policy Targets Max          881.93\n",
      "trainer/Z Policy Targets Min         -262.991\n",
      "trainer/Log Pis Mean                   25.0692\n",
      "trainer/Log Pis Std                     7.01545\n",
      "trainer/Policy mu Mean                  0.685887\n",
      "trainer/Policy mu Std                   2.37825\n",
      "trainer/Policy log std Mean            -3.37664\n",
      "trainer/Policy log std Std              1.31422\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         90073\n",
      "exploration/num paths total           855\n",
      "evaluation/num steps total         305104\n",
      "evaluation/num paths total            843\n",
      "evaluation/path length Mean           796\n",
      "evaluation/path length Std            179.441\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            542\n",
      "evaluation/Rewards Mean                 5.03667\n",
      "evaluation/Rewards Std                  1.44393\n",
      "evaluation/Rewards Max                  7.50966\n",
      "evaluation/Rewards Min                  0.0661647\n",
      "evaluation/Returns Mean              4009.19\n",
      "evaluation/Returns Std               1019.18\n",
      "evaluation/Returns Max               5181.19\n",
      "evaluation/Returns Min               2597.37\n",
      "evaluation/Estimation Bias Mean       667.638\n",
      "evaluation/Estimation Bias Std        277.266\n",
      "evaluation/EB/Q_True Mean              61.3732\n",
      "evaluation/EB/Q_True Std              166.587\n",
      "evaluation/EB/Q_Pred Mean             729.012\n",
      "evaluation/EB/Q_Pred Std              205.468\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4009.19\n",
      "evaluation/Actions Mean                 0.496326\n",
      "evaluation/Actions Std                  0.636686\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999992\n",
      "time/backward_policy (s)                1.89002\n",
      "time/backward_zf1 (s)                   2.00125\n",
      "time/backward_zf2 (s)                   1.95934\n",
      "time/data sampling (s)                  0.247515\n",
      "time/data storing (s)                   0.0139944\n",
      "time/evaluation sampling (s)            1.53151\n",
      "time/exploration sampling (s)           0.196091\n",
      "time/logging (s)                        0.00979046\n",
      "time/preback_alpha (s)                  0.556936\n",
      "time/preback_policy (s)                 1.11755\n",
      "time/preback_start (s)                  0.121185\n",
      "time/preback_zf (s)                     5.03785\n",
      "time/saving (s)                         0.00574192\n",
      "time/training (s)                       2.10554\n",
      "time/epoch (s)                         16.7943\n",
      "time/total (s)                       1331.86\n",
      "Epoch                                  83\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:14:36.692440 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 84 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  95000\n",
      "trainer/ZF1 Loss                       39.1321\n",
      "trainer/ZF2 Loss                       48.5203\n",
      "trainer/ZF Expert Reward               17.6731\n",
      "trainer/ZF Policy Reward               -2.44151\n",
      "trainer/ZF CHI2 Term                   64.2029\n",
      "trainer/Policy Loss                  -329.705\n",
      "trainer/Bias Loss                     130.889\n",
      "trainer/Bias Value                     10.7882\n",
      "trainer/Policy Grad Norm              184.907\n",
      "trainer/Policy Param Norm              29.1573\n",
      "trainer/Zf1 Grad Norm                2796.88\n",
      "trainer/Zf1 Param Norm                 74.0461\n",
      "trainer/Zf2 Grad Norm                3383.34\n",
      "trainer/Zf2 Param Norm                 72.3547\n",
      "trainer/Z Expert Predictions Mean     787.96\n",
      "trainer/Z Expert Predictions Std      137.777\n",
      "trainer/Z Expert Predictions Max      989.14\n",
      "trainer/Z Expert Predictions Min      317.486\n",
      "trainer/Z Policy Predictions Mean     319.676\n",
      "trainer/Z Policy Predictions Std      315.949\n",
      "trainer/Z Policy Predictions Max      868.418\n",
      "trainer/Z Policy Predictions Min     -245.832\n",
      "trainer/Z Expert Targets Mean         770.287\n",
      "trainer/Z Expert Targets Std          138.377\n",
      "trainer/Z Expert Targets Max          983.234\n",
      "trainer/Z Expert Targets Min          322.148\n",
      "trainer/Z Policy Targets Mean         322.118\n",
      "trainer/Z Policy Targets Std          313.412\n",
      "trainer/Z Policy Targets Max          846.775\n",
      "trainer/Z Policy Targets Min         -245.006\n",
      "trainer/Log Pis Mean                   26.2079\n",
      "trainer/Log Pis Std                     6.70509\n",
      "trainer/Policy mu Mean                  0.77466\n",
      "trainer/Policy mu Std                   2.18779\n",
      "trainer/Policy log std Mean            -3.50234\n",
      "trainer/Policy log std Std              1.28517\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         90971\n",
      "exploration/num paths total           856\n",
      "evaluation/num steps total         312965\n",
      "evaluation/num paths total            853\n",
      "evaluation/path length Mean           786.1\n",
      "evaluation/path length Std            152.61\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            616\n",
      "evaluation/Rewards Mean                 5.09786\n",
      "evaluation/Rewards Std                  1.45185\n",
      "evaluation/Rewards Max                  7.59548\n",
      "evaluation/Rewards Min                  0.0988725\n",
      "evaluation/Returns Mean              4007.43\n",
      "evaluation/Returns Std                875.918\n",
      "evaluation/Returns Max               5285.15\n",
      "evaluation/Returns Min               3011.21\n",
      "evaluation/Estimation Bias Mean       700.033\n",
      "evaluation/Estimation Bias Std        281.697\n",
      "evaluation/EB/Q_True Mean              62.2865\n",
      "evaluation/EB/Q_True Std              167.94\n",
      "evaluation/EB/Q_Pred Mean             762.32\n",
      "evaluation/EB/Q_Pred Std              210.538\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4007.43\n",
      "evaluation/Actions Mean                 0.494421\n",
      "evaluation/Actions Std                  0.641058\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.90812\n",
      "time/backward_zf1 (s)                   2.0388\n",
      "time/backward_zf2 (s)                   1.98408\n",
      "time/data sampling (s)                  0.247661\n",
      "time/data storing (s)                   0.0151334\n",
      "time/evaluation sampling (s)            1.50965\n",
      "time/exploration sampling (s)           0.203119\n",
      "time/logging (s)                        0.00975009\n",
      "time/preback_alpha (s)                  0.556837\n",
      "time/preback_policy (s)                 1.16903\n",
      "time/preback_start (s)                  0.122088\n",
      "time/preback_zf (s)                     5.0369\n",
      "time/saving (s)                         0.00565129\n",
      "time/training (s)                       2.00473\n",
      "time/epoch (s)                         16.8116\n",
      "time/total (s)                       1348.69\n",
      "Epoch                                  84\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:14:53.514931 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 85 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  96000\n",
      "trainer/ZF1 Loss                      201.341\n",
      "trainer/ZF2 Loss                      201.931\n",
      "trainer/ZF Expert Reward               27.2038\n",
      "trainer/ZF Policy Reward                3.58592\n",
      "trainer/ZF CHI2 Term                  225.522\n",
      "trainer/Policy Loss                  -369.361\n",
      "trainer/Bias Loss                    1786.13\n",
      "trainer/Bias Value                     10.7962\n",
      "trainer/Policy Grad Norm              209.956\n",
      "trainer/Policy Param Norm              29.2475\n",
      "trainer/Zf1 Grad Norm                4319.04\n",
      "trainer/Zf1 Param Norm                 74.4991\n",
      "trainer/Zf2 Grad Norm                3265.41\n",
      "trainer/Zf2 Param Norm                 72.7896\n",
      "trainer/Z Expert Predictions Mean     841.432\n",
      "trainer/Z Expert Predictions Std      121.692\n",
      "trainer/Z Expert Predictions Max     1015.76\n",
      "trainer/Z Expert Predictions Min      325.033\n",
      "trainer/Z Policy Predictions Mean     365.4\n",
      "trainer/Z Policy Predictions Std      332.233\n",
      "trainer/Z Policy Predictions Max      942.799\n",
      "trainer/Z Policy Predictions Min     -157.574\n",
      "trainer/Z Expert Targets Mean         814.228\n",
      "trainer/Z Expert Targets Std          130.66\n",
      "trainer/Z Expert Targets Max          999.554\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         361.814\n",
      "trainer/Z Policy Targets Std          325.934\n",
      "trainer/Z Policy Targets Max          939.221\n",
      "trainer/Z Policy Targets Min         -167.224\n",
      "trainer/Log Pis Mean                   26.8205\n",
      "trainer/Log Pis Std                     7.52261\n",
      "trainer/Policy mu Mean                  1.01584\n",
      "trainer/Policy mu Std                   2.16275\n",
      "trainer/Policy log std Mean            -3.39012\n",
      "trainer/Policy log std Std              1.2732\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         91549\n",
      "exploration/num paths total           857\n",
      "evaluation/num steps total         322965\n",
      "evaluation/num paths total            863\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.00275\n",
      "evaluation/Rewards Std                  1.26111\n",
      "evaluation/Rewards Max                  7.12471\n",
      "evaluation/Rewards Min                  0.0854235\n",
      "evaluation/Returns Mean              5002.75\n",
      "evaluation/Returns Std                 22.5038\n",
      "evaluation/Returns Max               5051.87\n",
      "evaluation/Returns Min               4970.09\n",
      "evaluation/Estimation Bias Mean       826.889\n",
      "evaluation/Estimation Bias Std        190.101\n",
      "evaluation/EB/Q_True Mean              47.2966\n",
      "evaluation/EB/Q_True Std              145.995\n",
      "evaluation/EB/Q_Pred Mean             874.186\n",
      "evaluation/EB/Q_Pred Std              121.786\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5002.75\n",
      "evaluation/Actions Mean                 0.498146\n",
      "evaluation/Actions Std                  0.622697\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999864\n",
      "time/backward_policy (s)                1.87825\n",
      "time/backward_zf1 (s)                   2.02681\n",
      "time/backward_zf2 (s)                   1.97182\n",
      "time/data sampling (s)                  0.246371\n",
      "time/data storing (s)                   0.0138979\n",
      "time/evaluation sampling (s)            1.42292\n",
      "time/exploration sampling (s)           0.196089\n",
      "time/logging (s)                        0.0163442\n",
      "time/preback_alpha (s)                  0.559169\n",
      "time/preback_policy (s)                 1.12976\n",
      "time/preback_start (s)                  0.121583\n",
      "time/preback_zf (s)                     5.06006\n",
      "time/saving (s)                         0.0103322\n",
      "time/training (s)                       2.10671\n",
      "time/epoch (s)                         16.7601\n",
      "time/total (s)                       1365.47\n",
      "Epoch                                  85\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:15:10.371212 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 86 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  97000\n",
      "trainer/ZF1 Loss                       74.3534\n",
      "trainer/ZF2 Loss                       67.7203\n",
      "trainer/ZF Expert Reward               16.655\n",
      "trainer/ZF Policy Reward               -2.09897\n",
      "trainer/ZF CHI2 Term                   90.0519\n",
      "trainer/Policy Loss                  -368.3\n",
      "trainer/Bias Loss                     202.403\n",
      "trainer/Bias Value                     10.8041\n",
      "trainer/Policy Grad Norm              272.081\n",
      "trainer/Policy Param Norm              29.344\n",
      "trainer/Zf1 Grad Norm                3921.76\n",
      "trainer/Zf1 Param Norm                 74.9298\n",
      "trainer/Zf2 Grad Norm                3814.16\n",
      "trainer/Zf2 Param Norm                 73.2286\n",
      "trainer/Z Expert Predictions Mean     821.385\n",
      "trainer/Z Expert Predictions Std      159.388\n",
      "trainer/Z Expert Predictions Max     1016.56\n",
      "trainer/Z Expert Predictions Min      280.277\n",
      "trainer/Z Policy Predictions Mean     352.21\n",
      "trainer/Z Policy Predictions Std      339.727\n",
      "trainer/Z Policy Predictions Max      967.37\n",
      "trainer/Z Policy Predictions Min     -230.597\n",
      "trainer/Z Expert Targets Mean         804.73\n",
      "trainer/Z Expert Targets Std          157.354\n",
      "trainer/Z Expert Targets Max         1009.95\n",
      "trainer/Z Expert Targets Min          306.559\n",
      "trainer/Z Policy Targets Mean         354.309\n",
      "trainer/Z Policy Targets Std          334.97\n",
      "trainer/Z Policy Targets Max          958.739\n",
      "trainer/Z Policy Targets Min         -238.277\n",
      "trainer/Log Pis Mean                   26.1039\n",
      "trainer/Log Pis Std                     7.49117\n",
      "trainer/Policy mu Mean                  0.782118\n",
      "trainer/Policy mu Std                   2.38604\n",
      "trainer/Policy log std Mean            -3.36281\n",
      "trainer/Policy log std Std              1.31266\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         94510\n",
      "exploration/num paths total           860\n",
      "evaluation/num steps total         332118\n",
      "evaluation/num paths total            873\n",
      "evaluation/path length Mean           915.3\n",
      "evaluation/path length Std            131.954\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            653\n",
      "evaluation/Rewards Mean                 5.07639\n",
      "evaluation/Rewards Std                  1.33271\n",
      "evaluation/Rewards Max                  7.37027\n",
      "evaluation/Rewards Min                  0.093953\n",
      "evaluation/Returns Mean              4646.42\n",
      "evaluation/Returns Std                725.506\n",
      "evaluation/Returns Max               5205.56\n",
      "evaluation/Returns Min               3186.41\n",
      "evaluation/Estimation Bias Mean       769.821\n",
      "evaluation/Estimation Bias Std        255.902\n",
      "evaluation/EB/Q_True Mean              52.3625\n",
      "evaluation/EB/Q_True Std              153.663\n",
      "evaluation/EB/Q_Pred Mean             822.183\n",
      "evaluation/EB/Q_Pred Std              180.125\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4646.42\n",
      "evaluation/Actions Mean                 0.498069\n",
      "evaluation/Actions Std                  0.637213\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.9149\n",
      "time/backward_zf1 (s)                   2.0426\n",
      "time/backward_zf2 (s)                   1.98548\n",
      "time/data sampling (s)                  0.24154\n",
      "time/data storing (s)                   0.0135351\n",
      "time/evaluation sampling (s)            1.51889\n",
      "time/exploration sampling (s)           0.197379\n",
      "time/logging (s)                        0.0128057\n",
      "time/preback_alpha (s)                  0.554413\n",
      "time/preback_policy (s)                 1.16113\n",
      "time/preback_start (s)                  0.120306\n",
      "time/preback_zf (s)                     5.03544\n",
      "time/saving (s)                         0.00571185\n",
      "time/training (s)                       1.98544\n",
      "time/epoch (s)                         16.7896\n",
      "time/total (s)                       1382.28\n",
      "Epoch                                  86\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:15:27.312367 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 87 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  98000\n",
      "trainer/ZF1 Loss                       69.6959\n",
      "trainer/ZF2 Loss                       58.1159\n",
      "trainer/ZF Expert Reward               20.6335\n",
      "trainer/ZF Policy Reward                3.80259\n",
      "trainer/ZF CHI2 Term                   81.0005\n",
      "trainer/Policy Loss                  -385.701\n",
      "trainer/Bias Loss                     156.56\n",
      "trainer/Bias Value                     10.8119\n",
      "trainer/Policy Grad Norm              200.515\n",
      "trainer/Policy Param Norm              29.4381\n",
      "trainer/Zf1 Grad Norm                5589.93\n",
      "trainer/Zf1 Param Norm                 75.3564\n",
      "trainer/Zf2 Grad Norm                4718.89\n",
      "trainer/Zf2 Param Norm                 73.6286\n",
      "trainer/Z Expert Predictions Mean     868.827\n",
      "trainer/Z Expert Predictions Std      147.808\n",
      "trainer/Z Expert Predictions Max     1043.38\n",
      "trainer/Z Expert Predictions Min      352.566\n",
      "trainer/Z Policy Predictions Mean     375.866\n",
      "trainer/Z Policy Predictions Std      344.617\n",
      "trainer/Z Policy Predictions Max      982.324\n",
      "trainer/Z Policy Predictions Min     -221.969\n",
      "trainer/Z Expert Targets Mean         848.194\n",
      "trainer/Z Expert Targets Std          146.746\n",
      "trainer/Z Expert Targets Max         1030.3\n",
      "trainer/Z Expert Targets Min          338.148\n",
      "trainer/Z Policy Targets Mean         372.063\n",
      "trainer/Z Policy Targets Std          339.678\n",
      "trainer/Z Policy Targets Max          970.925\n",
      "trainer/Z Policy Targets Min         -238.103\n",
      "trainer/Log Pis Mean                   26.3656\n",
      "trainer/Log Pis Std                     7.11587\n",
      "trainer/Policy mu Mean                  0.831365\n",
      "trainer/Policy mu Std                   2.39732\n",
      "trainer/Policy log std Mean            -3.42795\n",
      "trainer/Policy log std Std              1.28124\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         94510\n",
      "exploration/num paths total           860\n",
      "evaluation/num steps total         341471\n",
      "evaluation/num paths total            883\n",
      "evaluation/path length Mean           935.3\n",
      "evaluation/path length Std             99.8579\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            748\n",
      "evaluation/Rewards Mean                 4.97547\n",
      "evaluation/Rewards Std                  1.27996\n",
      "evaluation/Rewards Max                  7.18768\n",
      "evaluation/Rewards Min                  0.101342\n",
      "evaluation/Returns Mean              4653.56\n",
      "evaluation/Returns Std                523.456\n",
      "evaluation/Returns Max               5051.09\n",
      "evaluation/Returns Min               3662.54\n",
      "evaluation/Estimation Bias Mean       765.822\n",
      "evaluation/Estimation Bias Std        255.167\n",
      "evaluation/EB/Q_True Mean              50.2138\n",
      "evaluation/EB/Q_True Std              149.402\n",
      "evaluation/EB/Q_Pred Mean             816.036\n",
      "evaluation/EB/Q_Pred Std              190.849\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4653.56\n",
      "evaluation/Actions Mean                 0.509332\n",
      "evaluation/Actions Std                  0.635446\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.95639\n",
      "time/backward_zf1 (s)                   2.06666\n",
      "time/backward_zf2 (s)                   2.03085\n",
      "time/data sampling (s)                  0.251403\n",
      "time/data storing (s)                   0.0144736\n",
      "time/evaluation sampling (s)            1.44739\n",
      "time/exploration sampling (s)           0.197766\n",
      "time/logging (s)                        0.0111696\n",
      "time/preback_alpha (s)                  0.556548\n",
      "time/preback_policy (s)                 1.1737\n",
      "time/preback_start (s)                  0.120679\n",
      "time/preback_zf (s)                     5.02361\n",
      "time/saving (s)                         0.00592277\n",
      "time/training (s)                       2.01008\n",
      "time/epoch (s)                         16.8666\n",
      "time/total (s)                       1399.17\n",
      "Epoch                                  87\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:15:44.122888 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 88 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  99000\n",
      "trainer/ZF1 Loss                       61.7042\n",
      "trainer/ZF2 Loss                       63.8389\n",
      "trainer/ZF Expert Reward                8.62582\n",
      "trainer/ZF Policy Reward              -12.9759\n",
      "trainer/ZF CHI2 Term                   84.6331\n",
      "trainer/Policy Loss                  -428.189\n",
      "trainer/Bias Loss                     193.348\n",
      "trainer/Bias Value                     10.8197\n",
      "trainer/Policy Grad Norm              188.866\n",
      "trainer/Policy Param Norm              29.5363\n",
      "trainer/Zf1 Grad Norm                9201.23\n",
      "trainer/Zf1 Param Norm                 75.7757\n",
      "trainer/Zf2 Grad Norm                6717.73\n",
      "trainer/Zf2 Param Norm                 74.0334\n",
      "trainer/Z Expert Predictions Mean     874.082\n",
      "trainer/Z Expert Predictions Std      149.087\n",
      "trainer/Z Expert Predictions Max     1056.12\n",
      "trainer/Z Expert Predictions Min      408.737\n",
      "trainer/Z Policy Predictions Mean     408.267\n",
      "trainer/Z Policy Predictions Std      359.191\n",
      "trainer/Z Policy Predictions Max     1056.44\n",
      "trainer/Z Policy Predictions Min     -183.989\n",
      "trainer/Z Expert Targets Mean         865.457\n",
      "trainer/Z Expert Targets Std          146.818\n",
      "trainer/Z Expert Targets Max         1042.18\n",
      "trainer/Z Expert Targets Min          416.786\n",
      "trainer/Z Policy Targets Mean         421.243\n",
      "trainer/Z Policy Targets Std          359.506\n",
      "trainer/Z Policy Targets Max         1036.19\n",
      "trainer/Z Policy Targets Min         -187.794\n",
      "trainer/Log Pis Mean                   25.9806\n",
      "trainer/Log Pis Std                     6.22714\n",
      "trainer/Policy mu Mean                  0.811852\n",
      "trainer/Policy mu Std                   2.33322\n",
      "trainer/Policy log std Mean            -3.46604\n",
      "trainer/Policy log std Std              1.23001\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         94510\n",
      "exploration/num paths total           860\n",
      "evaluation/num steps total         351471\n",
      "evaluation/num paths total            893\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.01773\n",
      "evaluation/Rewards Std                  1.26782\n",
      "evaluation/Rewards Max                  7.24199\n",
      "evaluation/Rewards Min                  0.0762216\n",
      "evaluation/Returns Mean              5017.73\n",
      "evaluation/Returns Std                 35.6934\n",
      "evaluation/Returns Max               5092.15\n",
      "evaluation/Returns Min               4972.71\n",
      "evaluation/Estimation Bias Mean       858.974\n",
      "evaluation/Estimation Bias Std        199.098\n",
      "evaluation/EB/Q_True Mean              47.3137\n",
      "evaluation/EB/Q_True Std              146.102\n",
      "evaluation/EB/Q_Pred Mean             906.288\n",
      "evaluation/EB/Q_Pred Std              129.643\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5017.73\n",
      "evaluation/Actions Mean                 0.50528\n",
      "evaluation/Actions Std                  0.630479\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.84308\n",
      "time/backward_zf1 (s)                   1.96967\n",
      "time/backward_zf2 (s)                   1.90029\n",
      "time/data sampling (s)                  0.245016\n",
      "time/data storing (s)                   0.0135416\n",
      "time/evaluation sampling (s)            1.49214\n",
      "time/exploration sampling (s)           0.190566\n",
      "time/logging (s)                        0.0123098\n",
      "time/preback_alpha (s)                  0.563766\n",
      "time/preback_policy (s)                 1.06013\n",
      "time/preback_start (s)                  0.12076\n",
      "time/preback_zf (s)                     5.06916\n",
      "time/saving (s)                         0.00547679\n",
      "time/training (s)                       2.25953\n",
      "time/epoch (s)                         16.7454\n",
      "time/total (s)                       1415.94\n",
      "Epoch                                  88\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:16:00.549892 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 89 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 100000\n",
      "trainer/ZF1 Loss                       41.6481\n",
      "trainer/ZF2 Loss                       35.6177\n",
      "trainer/ZF Expert Reward               13.6775\n",
      "trainer/ZF Policy Reward               -4.06016\n",
      "trainer/ZF CHI2 Term                   56.6284\n",
      "trainer/Policy Loss                  -405.237\n",
      "trainer/Bias Loss                     183.449\n",
      "trainer/Bias Value                     10.8273\n",
      "trainer/Policy Grad Norm              146.264\n",
      "trainer/Policy Param Norm              29.6269\n",
      "trainer/Zf1 Grad Norm                6349.45\n",
      "trainer/Zf1 Param Norm                 76.182\n",
      "trainer/Zf2 Grad Norm                3075.38\n",
      "trainer/Zf2 Param Norm                 74.4172\n",
      "trainer/Z Expert Predictions Mean     892.31\n",
      "trainer/Z Expert Predictions Std      158.808\n",
      "trainer/Z Expert Predictions Max     1087.59\n",
      "trainer/Z Expert Predictions Min      340.669\n",
      "trainer/Z Policy Predictions Mean     398.612\n",
      "trainer/Z Policy Predictions Std      369.237\n",
      "trainer/Z Policy Predictions Max     1027.12\n",
      "trainer/Z Policy Predictions Min     -184.752\n",
      "trainer/Z Expert Targets Mean         878.633\n",
      "trainer/Z Expert Targets Std          157.641\n",
      "trainer/Z Expert Targets Max         1074.53\n",
      "trainer/Z Expert Targets Min          345.632\n",
      "trainer/Z Policy Targets Mean         402.672\n",
      "trainer/Z Policy Targets Std          367.195\n",
      "trainer/Z Policy Targets Max         1010.73\n",
      "trainer/Z Policy Targets Min         -197.388\n",
      "trainer/Log Pis Mean                   25.7819\n",
      "trainer/Log Pis Std                     6.78204\n",
      "trainer/Policy mu Mean                  0.801767\n",
      "trainer/Policy mu Std                   2.24407\n",
      "trainer/Policy log std Mean            -3.33018\n",
      "trainer/Policy log std Std              1.31802\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         95109\n",
      "exploration/num paths total           861\n",
      "evaluation/num steps total         361471\n",
      "evaluation/num paths total            903\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.01551\n",
      "evaluation/Rewards Std                  1.26483\n",
      "evaluation/Rewards Max                  7.06338\n",
      "evaluation/Rewards Min                  0.0740372\n",
      "evaluation/Returns Mean              5015.51\n",
      "evaluation/Returns Std                 32.1195\n",
      "evaluation/Returns Max               5083.38\n",
      "evaluation/Returns Min               4974.45\n",
      "evaluation/Estimation Bias Mean       883.167\n",
      "evaluation/Estimation Bias Std        195.735\n",
      "evaluation/EB/Q_True Mean              47.2682\n",
      "evaluation/EB/Q_True Std              145.922\n",
      "evaluation/EB/Q_Pred Mean             930.436\n",
      "evaluation/EB/Q_Pred Std              133.859\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5015.51\n",
      "evaluation/Actions Mean                 0.490952\n",
      "evaluation/Actions Std                  0.63374\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.73489\n",
      "time/backward_zf1 (s)                   1.83187\n",
      "time/backward_zf2 (s)                   1.76131\n",
      "time/data sampling (s)                  0.242403\n",
      "time/data storing (s)                   0.0138391\n",
      "time/evaluation sampling (s)            1.40011\n",
      "time/exploration sampling (s)           0.192949\n",
      "time/logging (s)                        0.012735\n",
      "time/preback_alpha (s)                  0.555319\n",
      "time/preback_policy (s)                 0.936352\n",
      "time/preback_start (s)                  0.12123\n",
      "time/preback_zf (s)                     5.05044\n",
      "time/saving (s)                         0.00578251\n",
      "time/training (s)                       2.50104\n",
      "time/epoch (s)                         16.3603\n",
      "time/total (s)                       1432.32\n",
      "Epoch                                  89\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:16:17.291009 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 90 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 101000\n",
      "trainer/ZF1 Loss                       37.3259\n",
      "trainer/ZF2 Loss                       38.1205\n",
      "trainer/ZF Expert Reward               15.8184\n",
      "trainer/ZF Policy Reward               -2.14912\n",
      "trainer/ZF CHI2 Term                   55.9568\n",
      "trainer/Policy Loss                  -401.831\n",
      "trainer/Bias Loss                     150.47\n",
      "trainer/Bias Value                     10.835\n",
      "trainer/Policy Grad Norm              197.848\n",
      "trainer/Policy Param Norm              29.7102\n",
      "trainer/Zf1 Grad Norm                2937.7\n",
      "trainer/Zf1 Param Norm                 76.6193\n",
      "trainer/Zf2 Grad Norm                1674.46\n",
      "trainer/Zf2 Param Norm                 74.8279\n",
      "trainer/Z Expert Predictions Mean     926.425\n",
      "trainer/Z Expert Predictions Std      147.219\n",
      "trainer/Z Expert Predictions Max     1093.66\n",
      "trainer/Z Expert Predictions Min      394.662\n",
      "trainer/Z Policy Predictions Mean     395.999\n",
      "trainer/Z Policy Predictions Std      365.878\n",
      "trainer/Z Policy Predictions Max     1063.53\n",
      "trainer/Z Policy Predictions Min     -184.541\n",
      "trainer/Z Expert Targets Mean         910.607\n",
      "trainer/Z Expert Targets Std          145.251\n",
      "trainer/Z Expert Targets Max         1081.69\n",
      "trainer/Z Expert Targets Min          402.289\n",
      "trainer/Z Policy Targets Mean         398.148\n",
      "trainer/Z Policy Targets Std          359.862\n",
      "trainer/Z Policy Targets Max         1047.21\n",
      "trainer/Z Policy Targets Min         -186.748\n",
      "trainer/Log Pis Mean                   26.6051\n",
      "trainer/Log Pis Std                     7.42006\n",
      "trainer/Policy mu Mean                  0.887174\n",
      "trainer/Policy mu Std                   2.49406\n",
      "trainer/Policy log std Mean            -3.3558\n",
      "trainer/Policy log std Std              1.34469\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         95109\n",
      "exploration/num paths total           861\n",
      "evaluation/num steps total         371471\n",
      "evaluation/num paths total            913\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.89916\n",
      "evaluation/Rewards Std                  1.22936\n",
      "evaluation/Rewards Max                  6.91653\n",
      "evaluation/Rewards Min                  0.117434\n",
      "evaluation/Returns Mean              4899.16\n",
      "evaluation/Returns Std                 64.1495\n",
      "evaluation/Returns Max               5021.61\n",
      "evaluation/Returns Min               4809.29\n",
      "evaluation/Estimation Bias Mean       827.846\n",
      "evaluation/Estimation Bias Std        212.044\n",
      "evaluation/EB/Q_True Mean              46.1838\n",
      "evaluation/EB/Q_True Std              142.597\n",
      "evaluation/EB/Q_Pred Mean             874.029\n",
      "evaluation/EB/Q_Pred Std              171.025\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4899.16\n",
      "evaluation/Actions Mean                 0.514096\n",
      "evaluation/Actions Std                  0.629525\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.91871\n",
      "time/backward_zf1 (s)                   2.05021\n",
      "time/backward_zf2 (s)                   1.98581\n",
      "time/data sampling (s)                  0.231474\n",
      "time/data storing (s)                   0.0135844\n",
      "time/evaluation sampling (s)            1.37872\n",
      "time/exploration sampling (s)           0.190633\n",
      "time/logging (s)                        0.0116725\n",
      "time/preback_alpha (s)                  0.555\n",
      "time/preback_policy (s)                 1.15622\n",
      "time/preback_start (s)                  0.120707\n",
      "time/preback_zf (s)                     5.03124\n",
      "time/saving (s)                         0.00569684\n",
      "time/training (s)                       2.02585\n",
      "time/epoch (s)                         16.6755\n",
      "time/total (s)                       1449.02\n",
      "Epoch                                  90\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:16:34.266998 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 91 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 102000\n",
      "trainer/ZF1 Loss                       45.6037\n",
      "trainer/ZF2 Loss                       47.0082\n",
      "trainer/ZF Expert Reward               18.3768\n",
      "trainer/ZF Policy Reward                1.49447\n",
      "trainer/ZF CHI2 Term                   63.4558\n",
      "trainer/Policy Loss                  -477.247\n",
      "trainer/Bias Loss                     163.276\n",
      "trainer/Bias Value                     10.8426\n",
      "trainer/Policy Grad Norm              243.278\n",
      "trainer/Policy Param Norm              29.7725\n",
      "trainer/Zf1 Grad Norm                3463.4\n",
      "trainer/Zf1 Param Norm                 77.0242\n",
      "trainer/Zf2 Grad Norm                3745.87\n",
      "trainer/Zf2 Param Norm                 75.2314\n",
      "trainer/Z Expert Predictions Mean     951.974\n",
      "trainer/Z Expert Predictions Std      134.857\n",
      "trainer/Z Expert Predictions Max     1123.59\n",
      "trainer/Z Expert Predictions Min      419.899\n",
      "trainer/Z Policy Predictions Mean     465.087\n",
      "trainer/Z Policy Predictions Std      363.069\n",
      "trainer/Z Policy Predictions Max     1076.34\n",
      "trainer/Z Policy Predictions Min     -208.238\n",
      "trainer/Z Expert Targets Mean         933.597\n",
      "trainer/Z Expert Targets Std          133.632\n",
      "trainer/Z Expert Targets Max         1105.47\n",
      "trainer/Z Expert Targets Min          420.74\n",
      "trainer/Z Policy Targets Mean         463.593\n",
      "trainer/Z Policy Targets Std          360.204\n",
      "trainer/Z Policy Targets Max         1068.28\n",
      "trainer/Z Policy Targets Min         -211.831\n",
      "trainer/Log Pis Mean                   26.7557\n",
      "trainer/Log Pis Std                     6.81439\n",
      "trainer/Policy mu Mean                  1.02947\n",
      "trainer/Policy mu Std                   2.22882\n",
      "trainer/Policy log std Mean            -3.43802\n",
      "trainer/Policy log std Std              1.26012\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         96109\n",
      "exploration/num paths total           862\n",
      "evaluation/num steps total         381471\n",
      "evaluation/num paths total            923\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.85689\n",
      "evaluation/Rewards Std                  1.2561\n",
      "evaluation/Rewards Max                  6.95821\n",
      "evaluation/Rewards Min                  0.0674344\n",
      "evaluation/Returns Mean              4856.89\n",
      "evaluation/Returns Std                 44.5174\n",
      "evaluation/Returns Max               4912.95\n",
      "evaluation/Returns Min               4775\n",
      "evaluation/Estimation Bias Mean       833.443\n",
      "evaluation/Estimation Bias Std        262.348\n",
      "evaluation/EB/Q_True Mean              45.6841\n",
      "evaluation/EB/Q_True Std              140.957\n",
      "evaluation/EB/Q_Pred Mean             879.128\n",
      "evaluation/EB/Q_Pred Std              225.11\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4856.89\n",
      "evaluation/Actions Mean                 0.492123\n",
      "evaluation/Actions Std                  0.627395\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999902\n",
      "time/backward_policy (s)                1.95156\n",
      "time/backward_zf1 (s)                   2.07296\n",
      "time/backward_zf2 (s)                   2.01778\n",
      "time/data sampling (s)                  0.237923\n",
      "time/data storing (s)                   0.0136854\n",
      "time/evaluation sampling (s)            1.45072\n",
      "time/exploration sampling (s)           0.195969\n",
      "time/logging (s)                        0.0121093\n",
      "time/preback_alpha (s)                  0.560228\n",
      "time/preback_policy (s)                 1.16632\n",
      "time/preback_start (s)                  0.12267\n",
      "time/preback_zf (s)                     5.04928\n",
      "time/saving (s)                         0.00568588\n",
      "time/training (s)                       2.05311\n",
      "time/epoch (s)                         16.91\n",
      "time/total (s)                       1465.95\n",
      "Epoch                                  91\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:16:51.380388 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 92 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 103000\n",
      "trainer/ZF1 Loss                       46.1557\n",
      "trainer/ZF2 Loss                       32.3943\n",
      "trainer/ZF Expert Reward                8.76194\n",
      "trainer/ZF Policy Reward               -6.2706\n",
      "trainer/ZF CHI2 Term                   54.5706\n",
      "trainer/Policy Loss                  -518.36\n",
      "trainer/Bias Loss                     122.026\n",
      "trainer/Bias Value                     10.8501\n",
      "trainer/Policy Grad Norm              196.265\n",
      "trainer/Policy Param Norm              29.834\n",
      "trainer/Zf1 Grad Norm                6356.52\n",
      "trainer/Zf1 Param Norm                 77.4381\n",
      "trainer/Zf2 Grad Norm                3613.83\n",
      "trainer/Zf2 Param Norm                 75.6205\n",
      "trainer/Z Expert Predictions Mean     948.145\n",
      "trainer/Z Expert Predictions Std      142.602\n",
      "trainer/Z Expert Predictions Max     1138.69\n",
      "trainer/Z Expert Predictions Min      399.789\n",
      "trainer/Z Policy Predictions Mean     503.302\n",
      "trainer/Z Policy Predictions Std      368.955\n",
      "trainer/Z Policy Predictions Max     1104.71\n",
      "trainer/Z Policy Predictions Min     -153.776\n",
      "trainer/Z Expert Targets Mean         939.384\n",
      "trainer/Z Expert Targets Std          139.407\n",
      "trainer/Z Expert Targets Max         1110.65\n",
      "trainer/Z Expert Targets Min          402.303\n",
      "trainer/Z Policy Targets Mean         509.572\n",
      "trainer/Z Policy Targets Std          367.379\n",
      "trainer/Z Policy Targets Max         1111.08\n",
      "trainer/Z Policy Targets Min         -171.111\n",
      "trainer/Log Pis Mean                   26.3028\n",
      "trainer/Log Pis Std                     7.07115\n",
      "trainer/Policy mu Mean                  0.894415\n",
      "trainer/Policy mu Std                   2.41047\n",
      "trainer/Policy log std Mean            -3.39509\n",
      "trainer/Policy log std Std              1.25403\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         97109\n",
      "exploration/num paths total           863\n",
      "evaluation/num steps total         391471\n",
      "evaluation/num paths total            933\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.98273\n",
      "evaluation/Rewards Std                  1.32672\n",
      "evaluation/Rewards Max                  7.64012\n",
      "evaluation/Rewards Min                  0.0553683\n",
      "evaluation/Returns Mean              4982.73\n",
      "evaluation/Returns Std                111.272\n",
      "evaluation/Returns Max               5101.37\n",
      "evaluation/Returns Min               4777.09\n",
      "evaluation/Estimation Bias Mean       870.114\n",
      "evaluation/Estimation Bias Std        247.56\n",
      "evaluation/EB/Q_True Mean              45.3914\n",
      "evaluation/EB/Q_True Std              139.685\n",
      "evaluation/EB/Q_Pred Mean             915.505\n",
      "evaluation/EB/Q_Pred Std              215.15\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4982.73\n",
      "evaluation/Actions Mean                 0.506758\n",
      "evaluation/Actions Std                  0.623755\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94483\n",
      "time/backward_zf1 (s)                   2.07416\n",
      "time/backward_zf2 (s)                   2.04011\n",
      "time/data sampling (s)                  0.245215\n",
      "time/data storing (s)                   0.0144693\n",
      "time/evaluation sampling (s)            1.48087\n",
      "time/exploration sampling (s)           0.197087\n",
      "time/logging (s)                        0.0144631\n",
      "time/preback_alpha (s)                  0.564303\n",
      "time/preback_policy (s)                 1.17021\n",
      "time/preback_start (s)                  0.123015\n",
      "time/preback_zf (s)                     5.09238\n",
      "time/saving (s)                         0.00632674\n",
      "time/training (s)                       2.08097\n",
      "time/epoch (s)                         17.0484\n",
      "time/total (s)                       1483.02\n",
      "Epoch                                  92\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:17:08.002824 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 93 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 104000\n",
      "trainer/ZF1 Loss                       66.6447\n",
      "trainer/ZF2 Loss                       64.0911\n",
      "trainer/ZF Expert Reward               11.3036\n",
      "trainer/ZF Policy Reward               -3.974\n",
      "trainer/ZF CHI2 Term                   80.9144\n",
      "trainer/Policy Loss                  -503.855\n",
      "trainer/Bias Loss                     235.365\n",
      "trainer/Bias Value                     10.8577\n",
      "trainer/Policy Grad Norm              252.801\n",
      "trainer/Policy Param Norm              29.881\n",
      "trainer/Zf1 Grad Norm                6383.12\n",
      "trainer/Zf1 Param Norm                 77.8136\n",
      "trainer/Zf2 Grad Norm                7209.82\n",
      "trainer/Zf2 Param Norm                 75.976\n",
      "trainer/Z Expert Predictions Mean     971.483\n",
      "trainer/Z Expert Predictions Std      157.523\n",
      "trainer/Z Expert Predictions Max     1168.45\n",
      "trainer/Z Expert Predictions Min      382.142\n",
      "trainer/Z Policy Predictions Mean     484.4\n",
      "trainer/Z Policy Predictions Std      369.398\n",
      "trainer/Z Policy Predictions Max     1137.12\n",
      "trainer/Z Policy Predictions Min     -183.452\n",
      "trainer/Z Expert Targets Mean         960.179\n",
      "trainer/Z Expert Targets Std          152.579\n",
      "trainer/Z Expert Targets Max         1146.43\n",
      "trainer/Z Expert Targets Min          388.045\n",
      "trainer/Z Policy Targets Mean         488.374\n",
      "trainer/Z Policy Targets Std          366.618\n",
      "trainer/Z Policy Targets Max         1107.86\n",
      "trainer/Z Policy Targets Min         -189.613\n",
      "trainer/Log Pis Mean                   26.8926\n",
      "trainer/Log Pis Std                     7.65113\n",
      "trainer/Policy mu Mean                  1.05805\n",
      "trainer/Policy mu Std                   2.2494\n",
      "trainer/Policy log std Mean            -3.30876\n",
      "trainer/Policy log std Std              1.30375\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         99109\n",
      "exploration/num paths total           865\n",
      "evaluation/num steps total         401030\n",
      "evaluation/num paths total            943\n",
      "evaluation/path length Mean           955.9\n",
      "evaluation/path length Std             88.9926\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            753\n",
      "evaluation/Rewards Mean                 5.19678\n",
      "evaluation/Rewards Std                  1.36074\n",
      "evaluation/Rewards Max                  7.73645\n",
      "evaluation/Rewards Min                  0.0891319\n",
      "evaluation/Returns Mean              4967.6\n",
      "evaluation/Returns Std                509.832\n",
      "evaluation/Returns Max               5270.13\n",
      "evaluation/Returns Min               3794.16\n",
      "evaluation/Estimation Bias Mean       949.892\n",
      "evaluation/Estimation Bias Std        260\n",
      "evaluation/EB/Q_True Mean              51.0401\n",
      "evaluation/EB/Q_True Std              153.647\n",
      "evaluation/EB/Q_Pred Mean            1000.93\n",
      "evaluation/EB/Q_Pred Std              179.446\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4967.6\n",
      "evaluation/Actions Mean                 0.510091\n",
      "evaluation/Actions Std                  0.624044\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78669\n",
      "time/backward_zf1 (s)                   1.92573\n",
      "time/backward_zf2 (s)                   1.85819\n",
      "time/data sampling (s)                  0.233889\n",
      "time/data storing (s)                   0.0138346\n",
      "time/evaluation sampling (s)            1.46446\n",
      "time/exploration sampling (s)           0.195088\n",
      "time/logging (s)                        0.0115763\n",
      "time/preback_alpha (s)                  0.55144\n",
      "time/preback_policy (s)                 1.01013\n",
      "time/preback_start (s)                  0.11999\n",
      "time/preback_zf (s)                     5.04462\n",
      "time/saving (s)                         0.00614773\n",
      "time/training (s)                       2.3343\n",
      "time/epoch (s)                         16.5561\n",
      "time/total (s)                       1499.59\n",
      "Epoch                                  93\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:17:24.519518 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 94 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 105000\n",
      "trainer/ZF1 Loss                       47.8634\n",
      "trainer/ZF2 Loss                       32.7365\n",
      "trainer/ZF Expert Reward               16.8125\n",
      "trainer/ZF Policy Reward               -0.105727\n",
      "trainer/ZF CHI2 Term                   57.4918\n",
      "trainer/Policy Loss                  -593.313\n",
      "trainer/Bias Loss                     143.738\n",
      "trainer/Bias Value                     10.8652\n",
      "trainer/Policy Grad Norm              249.714\n",
      "trainer/Policy Param Norm              29.9254\n",
      "trainer/Zf1 Grad Norm                2351.09\n",
      "trainer/Zf1 Param Norm                 78.1983\n",
      "trainer/Zf2 Grad Norm                2361.26\n",
      "trainer/Zf2 Param Norm                 76.353\n",
      "trainer/Z Expert Predictions Mean    1003.82\n",
      "trainer/Z Expert Predictions Std      147.72\n",
      "trainer/Z Expert Predictions Max     1174.33\n",
      "trainer/Z Expert Predictions Min      454.369\n",
      "trainer/Z Policy Predictions Mean     582.933\n",
      "trainer/Z Policy Predictions Std      378.139\n",
      "trainer/Z Policy Predictions Max     1129.76\n",
      "trainer/Z Policy Predictions Min     -161.544\n",
      "trainer/Z Expert Targets Mean         987.01\n",
      "trainer/Z Expert Targets Std          145.985\n",
      "trainer/Z Expert Targets Max         1176.56\n",
      "trainer/Z Expert Targets Min          450.967\n",
      "trainer/Z Policy Targets Mean         583.039\n",
      "trainer/Z Policy Targets Std          372.188\n",
      "trainer/Z Policy Targets Max         1117.74\n",
      "trainer/Z Policy Targets Min         -158.966\n",
      "trainer/Log Pis Mean                   27.3633\n",
      "trainer/Log Pis Std                     6.95656\n",
      "trainer/Policy mu Mean                  1.02098\n",
      "trainer/Policy mu Std                   2.17218\n",
      "trainer/Policy log std Mean            -3.51596\n",
      "trainer/Policy log std Std              1.2372\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        100109\n",
      "exploration/num paths total           866\n",
      "evaluation/num steps total         411030\n",
      "evaluation/num paths total            953\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.03562\n",
      "evaluation/Rewards Std                  1.27232\n",
      "evaluation/Rewards Max                  6.97559\n",
      "evaluation/Rewards Min                  0.0743139\n",
      "evaluation/Returns Mean              5035.62\n",
      "evaluation/Returns Std                 16.5461\n",
      "evaluation/Returns Max               5061.44\n",
      "evaluation/Returns Min               4999.3\n",
      "evaluation/Estimation Bias Mean       989.407\n",
      "evaluation/Estimation Bias Std        191.07\n",
      "evaluation/EB/Q_True Mean              47.5072\n",
      "evaluation/EB/Q_True Std              146.722\n",
      "evaluation/EB/Q_Pred Mean            1036.91\n",
      "evaluation/EB/Q_Pred Std              121.727\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5035.62\n",
      "evaluation/Actions Mean                 0.485441\n",
      "evaluation/Actions Std                  0.637384\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999964\n",
      "time/backward_policy (s)                1.72746\n",
      "time/backward_zf1 (s)                   1.86617\n",
      "time/backward_zf2 (s)                   1.80319\n",
      "time/data sampling (s)                  0.24715\n",
      "time/data storing (s)                   0.0142442\n",
      "time/evaluation sampling (s)            1.39928\n",
      "time/exploration sampling (s)           0.195768\n",
      "time/logging (s)                        0.0119641\n",
      "time/preback_alpha (s)                  0.555283\n",
      "time/preback_policy (s)                 0.973908\n",
      "time/preback_start (s)                  0.119882\n",
      "time/preback_zf (s)                     5.0597\n",
      "time/saving (s)                         0.00576924\n",
      "time/training (s)                       2.46957\n",
      "time/epoch (s)                         16.4493\n",
      "time/total (s)                       1516.06\n",
      "Epoch                                  94\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:17:41.461915 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 95 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 106000\n",
      "trainer/ZF1 Loss                       40.1537\n",
      "trainer/ZF2 Loss                       54.4763\n",
      "trainer/ZF Expert Reward               17.4853\n",
      "trainer/ZF Policy Reward                0.434129\n",
      "trainer/ZF CHI2 Term                   64.6385\n",
      "trainer/Policy Loss                  -618.294\n",
      "trainer/Bias Loss                     168.005\n",
      "trainer/Bias Value                     10.8726\n",
      "trainer/Policy Grad Norm              182.004\n",
      "trainer/Policy Param Norm              29.9676\n",
      "trainer/Zf1 Grad Norm                2078.02\n",
      "trainer/Zf1 Param Norm                 78.5632\n",
      "trainer/Zf2 Grad Norm                2669.32\n",
      "trainer/Zf2 Param Norm                 76.6924\n",
      "trainer/Z Expert Predictions Mean    1021.99\n",
      "trainer/Z Expert Predictions Std      138.059\n",
      "trainer/Z Expert Predictions Max     1183.66\n",
      "trainer/Z Expert Predictions Min      402.706\n",
      "trainer/Z Policy Predictions Mean     605.948\n",
      "trainer/Z Policy Predictions Std      362.658\n",
      "trainer/Z Policy Predictions Max     1151.52\n",
      "trainer/Z Policy Predictions Min     -169.4\n",
      "trainer/Z Expert Targets Mean        1004.5\n",
      "trainer/Z Expert Targets Std          136.968\n",
      "trainer/Z Expert Targets Max         1178.2\n",
      "trainer/Z Expert Targets Min          413.479\n",
      "trainer/Z Policy Targets Mean         605.514\n",
      "trainer/Z Policy Targets Std          357.578\n",
      "trainer/Z Policy Targets Max         1130.5\n",
      "trainer/Z Policy Targets Min         -168.9\n",
      "trainer/Log Pis Mean                   27.2324\n",
      "trainer/Log Pis Std                     6.60784\n",
      "trainer/Policy mu Mean                  1.09719\n",
      "trainer/Policy mu Std                   2.08904\n",
      "trainer/Policy log std Mean            -3.51536\n",
      "trainer/Policy log std Std              1.19996\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        101109\n",
      "exploration/num paths total           867\n",
      "evaluation/num steps total         421030\n",
      "evaluation/num paths total            963\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16473\n",
      "evaluation/Rewards Std                  1.3411\n",
      "evaluation/Rewards Max                  7.57237\n",
      "evaluation/Rewards Min                  0.0747856\n",
      "evaluation/Returns Mean              5164.73\n",
      "evaluation/Returns Std                 26.4914\n",
      "evaluation/Returns Max               5191.42\n",
      "evaluation/Returns Min               5102.32\n",
      "evaluation/Estimation Bias Mean      1014.7\n",
      "evaluation/Estimation Bias Std        194.337\n",
      "evaluation/EB/Q_True Mean              48.8739\n",
      "evaluation/EB/Q_True Std              150.663\n",
      "evaluation/EB/Q_Pred Mean            1063.57\n",
      "evaluation/EB/Q_Pred Std              127.003\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5164.73\n",
      "evaluation/Actions Mean                 0.507804\n",
      "evaluation/Actions Std                  0.626043\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999968\n",
      "time/backward_policy (s)                1.90774\n",
      "time/backward_zf1 (s)                   2.02106\n",
      "time/backward_zf2 (s)                   1.97585\n",
      "time/data sampling (s)                  0.247087\n",
      "time/data storing (s)                   0.0137013\n",
      "time/evaluation sampling (s)            1.48741\n",
      "time/exploration sampling (s)           0.193693\n",
      "time/logging (s)                        0.0116642\n",
      "time/preback_alpha (s)                  0.56179\n",
      "time/preback_policy (s)                 1.13806\n",
      "time/preback_start (s)                  0.121283\n",
      "time/preback_zf (s)                     5.07088\n",
      "time/saving (s)                         0.00586861\n",
      "time/training (s)                       2.12075\n",
      "time/epoch (s)                         16.8768\n",
      "time/total (s)                       1532.96\n",
      "Epoch                                  95\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:17:58.283584 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 96 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 107000\n",
      "trainer/ZF1 Loss                      114.879\n",
      "trainer/ZF2 Loss                      109.956\n",
      "trainer/ZF Expert Reward               19.0664\n",
      "trainer/ZF Policy Reward               -2.84483\n",
      "trainer/ZF CHI2 Term                  134.597\n",
      "trainer/Policy Loss                  -581.429\n",
      "trainer/Bias Loss                     840.386\n",
      "trainer/Bias Value                     10.8799\n",
      "trainer/Policy Grad Norm              275.087\n",
      "trainer/Policy Param Norm              30.0054\n",
      "trainer/Zf1 Grad Norm                4654.48\n",
      "trainer/Zf1 Param Norm                 78.9249\n",
      "trainer/Zf2 Grad Norm                5770.22\n",
      "trainer/Zf2 Param Norm                 77.0449\n",
      "trainer/Z Expert Predictions Mean    1036.77\n",
      "trainer/Z Expert Predictions Std      146.68\n",
      "trainer/Z Expert Predictions Max     1218.99\n",
      "trainer/Z Expert Predictions Min      418.481\n",
      "trainer/Z Policy Predictions Mean     564.526\n",
      "trainer/Z Policy Predictions Std      373.503\n",
      "trainer/Z Policy Predictions Max     1144.2\n",
      "trainer/Z Policy Predictions Min     -149.744\n",
      "trainer/Z Expert Targets Mean        1017.7\n",
      "trainer/Z Expert Targets Std          157.269\n",
      "trainer/Z Expert Targets Max         1192.85\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         567.371\n",
      "trainer/Z Policy Targets Std          370.572\n",
      "trainer/Z Policy Targets Max         1144.69\n",
      "trainer/Z Policy Targets Min         -151.898\n",
      "trainer/Log Pis Mean                   26.8122\n",
      "trainer/Log Pis Std                     7.2028\n",
      "trainer/Policy mu Mean                  1.01336\n",
      "trainer/Policy mu Std                   2.30529\n",
      "trainer/Policy log std Mean            -3.38604\n",
      "trainer/Policy log std Std              1.27357\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        104109\n",
      "exploration/num paths total           870\n",
      "evaluation/num steps total         431030\n",
      "evaluation/num paths total            973\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.0248\n",
      "evaluation/Rewards Std                  1.2724\n",
      "evaluation/Rewards Max                  7.13809\n",
      "evaluation/Rewards Min                  0.107811\n",
      "evaluation/Returns Mean              5024.8\n",
      "evaluation/Returns Std                 48.2646\n",
      "evaluation/Returns Max               5093.48\n",
      "evaluation/Returns Min               4942.99\n",
      "evaluation/Estimation Bias Mean      1002.48\n",
      "evaluation/Estimation Bias Std        186.723\n",
      "evaluation/EB/Q_True Mean              47.0514\n",
      "evaluation/EB/Q_True Std              145.045\n",
      "evaluation/EB/Q_Pred Mean            1049.53\n",
      "evaluation/EB/Q_Pred Std              121.8\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5024.8\n",
      "evaluation/Actions Mean                 0.497836\n",
      "evaluation/Actions Std                  0.621656\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999976\n",
      "time/backward_policy (s)                1.80931\n",
      "time/backward_zf1 (s)                   1.93828\n",
      "time/backward_zf2 (s)                   1.85949\n",
      "time/data sampling (s)                  0.248089\n",
      "time/data storing (s)                   0.0142578\n",
      "time/evaluation sampling (s)            1.35124\n",
      "time/exploration sampling (s)           0.200492\n",
      "time/logging (s)                        0.0121709\n",
      "time/preback_alpha (s)                  0.570392\n",
      "time/preback_policy (s)                 1.01709\n",
      "time/preback_start (s)                  0.123467\n",
      "time/preback_zf (s)                     5.09368\n",
      "time/saving (s)                         0.00591404\n",
      "time/training (s)                       2.51147\n",
      "time/epoch (s)                         16.7553\n",
      "time/total (s)                       1549.73\n",
      "Epoch                                  96\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:18:15.370825 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 97 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 108000\n",
      "trainer/ZF1 Loss                       46.4048\n",
      "trainer/ZF2 Loss                       30.3567\n",
      "trainer/ZF Expert Reward               18.8171\n",
      "trainer/ZF Policy Reward               -1.59685\n",
      "trainer/ZF CHI2 Term                   59.053\n",
      "trainer/Policy Loss                  -597.831\n",
      "trainer/Bias Loss                     153.533\n",
      "trainer/Bias Value                     10.8871\n",
      "trainer/Policy Grad Norm              187.735\n",
      "trainer/Policy Param Norm              30.0478\n",
      "trainer/Zf1 Grad Norm                3170.52\n",
      "trainer/Zf1 Param Norm                 79.2483\n",
      "trainer/Zf2 Grad Norm                2871.66\n",
      "trainer/Zf2 Param Norm                 77.3572\n",
      "trainer/Z Expert Predictions Mean    1048.89\n",
      "trainer/Z Expert Predictions Std      125.001\n",
      "trainer/Z Expert Predictions Max     1218.88\n",
      "trainer/Z Expert Predictions Min      536.063\n",
      "trainer/Z Policy Predictions Mean     591.309\n",
      "trainer/Z Policy Predictions Std      392.806\n",
      "trainer/Z Policy Predictions Max     1223.11\n",
      "trainer/Z Policy Predictions Min     -243.435\n",
      "trainer/Z Expert Targets Mean        1030.07\n",
      "trainer/Z Expert Targets Std          124.802\n",
      "trainer/Z Expert Targets Max         1200.83\n",
      "trainer/Z Expert Targets Min          536.424\n",
      "trainer/Z Policy Targets Mean         592.906\n",
      "trainer/Z Policy Targets Std          388.459\n",
      "trainer/Z Policy Targets Max         1204.23\n",
      "trainer/Z Policy Targets Min         -296.543\n",
      "trainer/Log Pis Mean                   25.8398\n",
      "trainer/Log Pis Std                     6.52267\n",
      "trainer/Policy mu Mean                  0.968096\n",
      "trainer/Policy mu Std                   2.11204\n",
      "trainer/Policy log std Mean            -3.39012\n",
      "trainer/Policy log std Std              1.20536\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        104109\n",
      "exploration/num paths total           870\n",
      "evaluation/num steps total         441030\n",
      "evaluation/num paths total            983\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10457\n",
      "evaluation/Rewards Std                  1.30565\n",
      "evaluation/Rewards Max                  7.46398\n",
      "evaluation/Rewards Min                  0.0609977\n",
      "evaluation/Returns Mean              5104.57\n",
      "evaluation/Returns Std                 15.873\n",
      "evaluation/Returns Max               5132.03\n",
      "evaluation/Returns Min               5078.65\n",
      "evaluation/Estimation Bias Mean      1033.74\n",
      "evaluation/Estimation Bias Std        192.197\n",
      "evaluation/EB/Q_True Mean              48.2629\n",
      "evaluation/EB/Q_True Std              148.727\n",
      "evaluation/EB/Q_Pred Mean            1082\n",
      "evaluation/EB/Q_Pred Std              124.576\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5104.57\n",
      "evaluation/Actions Mean                 0.504616\n",
      "evaluation/Actions Std                  0.621213\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.9381\n",
      "time/backward_zf1 (s)                   2.06484\n",
      "time/backward_zf2 (s)                   2.02231\n",
      "time/data sampling (s)                  0.252894\n",
      "time/data storing (s)                   0.0153148\n",
      "time/evaluation sampling (s)            1.4735\n",
      "time/exploration sampling (s)           0.201112\n",
      "time/logging (s)                        0.0136976\n",
      "time/preback_alpha (s)                  0.562975\n",
      "time/preback_policy (s)                 1.17919\n",
      "time/preback_start (s)                  0.123174\n",
      "time/preback_zf (s)                     5.07802\n",
      "time/saving (s)                         0.00557147\n",
      "time/training (s)                       2.0884\n",
      "time/epoch (s)                         17.0191\n",
      "time/total (s)                       1566.78\n",
      "Epoch                                  97\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:18:32.016919 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 98 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 109000\n",
      "trainer/ZF1 Loss                      220.002\n",
      "trainer/ZF2 Loss                      223.856\n",
      "trainer/ZF Expert Reward               16.4902\n",
      "trainer/ZF Policy Reward               -2.04301\n",
      "trainer/ZF CHI2 Term                  240.727\n",
      "trainer/Policy Loss                  -650.468\n",
      "trainer/Bias Loss                    2049.45\n",
      "trainer/Bias Value                     10.8943\n",
      "trainer/Policy Grad Norm              230.897\n",
      "trainer/Policy Param Norm              30.0974\n",
      "trainer/Zf1 Grad Norm                5995.69\n",
      "trainer/Zf1 Param Norm                 79.5793\n",
      "trainer/Zf2 Grad Norm                5055.44\n",
      "trainer/Zf2 Param Norm                 77.6814\n",
      "trainer/Z Expert Predictions Mean    1041.32\n",
      "trainer/Z Expert Predictions Std      159.958\n",
      "trainer/Z Expert Predictions Max     1233.81\n",
      "trainer/Z Expert Predictions Min      508.568\n",
      "trainer/Z Policy Predictions Mean     634.227\n",
      "trainer/Z Policy Predictions Std      384.406\n",
      "trainer/Z Policy Predictions Max     1213.28\n",
      "trainer/Z Policy Predictions Min     -200.03\n",
      "trainer/Z Expert Targets Mean        1024.83\n",
      "trainer/Z Expert Targets Std          169.825\n",
      "trainer/Z Expert Targets Max         1231.41\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         636.27\n",
      "trainer/Z Policy Targets Std          383.571\n",
      "trainer/Z Policy Targets Max         1205.78\n",
      "trainer/Z Policy Targets Min         -182.27\n",
      "trainer/Log Pis Mean                   26.4952\n",
      "trainer/Log Pis Std                     5.60661\n",
      "trainer/Policy mu Mean                  1.16827\n",
      "trainer/Policy mu Std                   2.00659\n",
      "trainer/Policy log std Mean            -3.41979\n",
      "trainer/Policy log std Std              1.22497\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        104109\n",
      "exploration/num paths total           870\n",
      "evaluation/num steps total         450713\n",
      "evaluation/num paths total            993\n",
      "evaluation/path length Mean           968.3\n",
      "evaluation/path length Std             51.4005\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            862\n",
      "evaluation/Rewards Mean                 5.05552\n",
      "evaluation/Rewards Std                  1.31676\n",
      "evaluation/Rewards Max                  7.11136\n",
      "evaluation/Rewards Min                  0.0501537\n",
      "evaluation/Returns Mean              4895.26\n",
      "evaluation/Returns Std                271.079\n",
      "evaluation/Returns Max               5099.09\n",
      "evaluation/Returns Min               4342.7\n",
      "evaluation/Estimation Bias Mean       981.682\n",
      "evaluation/Estimation Bias Std        266.99\n",
      "evaluation/EB/Q_True Mean              48.9529\n",
      "evaluation/EB/Q_True Std              148.54\n",
      "evaluation/EB/Q_Pred Mean            1030.63\n",
      "evaluation/EB/Q_Pred Std              198.965\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4895.26\n",
      "evaluation/Actions Mean                 0.509073\n",
      "evaluation/Actions Std                  0.628074\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86118\n",
      "time/backward_zf1 (s)                   1.97906\n",
      "time/backward_zf2 (s)                   1.92038\n",
      "time/data sampling (s)                  0.233321\n",
      "time/data storing (s)                   0.0142851\n",
      "time/evaluation sampling (s)            1.45267\n",
      "time/exploration sampling (s)           0.192053\n",
      "time/logging (s)                        0.0115947\n",
      "time/preback_alpha (s)                  0.554857\n",
      "time/preback_policy (s)                 1.09644\n",
      "time/preback_start (s)                  0.120749\n",
      "time/preback_zf (s)                     5.02497\n",
      "time/saving (s)                         0.00625189\n",
      "time/training (s)                       2.11051\n",
      "time/epoch (s)                         16.5783\n",
      "time/total (s)                       1583.38\n",
      "Epoch                                  98\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:18:48.840695 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 99 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 110000\n",
      "trainer/ZF1 Loss                       50.1566\n",
      "trainer/ZF2 Loss                       48.0702\n",
      "trainer/ZF Expert Reward               11.8096\n",
      "trainer/ZF Policy Reward               -7.24044\n",
      "trainer/ZF CHI2 Term                   68.4345\n",
      "trainer/Policy Loss                  -648.861\n",
      "trainer/Bias Loss                     152.216\n",
      "trainer/Bias Value                     10.9015\n",
      "trainer/Policy Grad Norm              155.437\n",
      "trainer/Policy Param Norm              30.1521\n",
      "trainer/Zf1 Grad Norm                3505.84\n",
      "trainer/Zf1 Param Norm                 79.8879\n",
      "trainer/Zf2 Grad Norm                4136.48\n",
      "trainer/Zf2 Param Norm                 77.9494\n",
      "trainer/Z Expert Predictions Mean    1069.09\n",
      "trainer/Z Expert Predictions Std      153.826\n",
      "trainer/Z Expert Predictions Max     1248.38\n",
      "trainer/Z Expert Predictions Min      463.197\n",
      "trainer/Z Policy Predictions Mean     632.566\n",
      "trainer/Z Policy Predictions Std      368.598\n",
      "trainer/Z Policy Predictions Max     1229.98\n",
      "trainer/Z Policy Predictions Min     -136.991\n",
      "trainer/Z Expert Targets Mean        1057.29\n",
      "trainer/Z Expert Targets Std          151.643\n",
      "trainer/Z Expert Targets Max         1233\n",
      "trainer/Z Expert Targets Min          469.193\n",
      "trainer/Z Policy Targets Mean         639.806\n",
      "trainer/Z Policy Targets Std          363.951\n",
      "trainer/Z Policy Targets Max         1218.47\n",
      "trainer/Z Policy Targets Min         -150.438\n",
      "trainer/Log Pis Mean                   27.1128\n",
      "trainer/Log Pis Std                     6.09052\n",
      "trainer/Policy mu Mean                  1.13439\n",
      "trainer/Policy mu Std                   2.01536\n",
      "trainer/Policy log std Mean            -3.44454\n",
      "trainer/Policy log std Std              1.22569\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        105109\n",
      "exploration/num paths total           871\n",
      "evaluation/num steps total         460713\n",
      "evaluation/num paths total           1003\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12771\n",
      "evaluation/Rewards Std                  1.31885\n",
      "evaluation/Rewards Max                  7.53072\n",
      "evaluation/Rewards Min                  0.0948593\n",
      "evaluation/Returns Mean              5127.71\n",
      "evaluation/Returns Std                 17.7562\n",
      "evaluation/Returns Max               5149.29\n",
      "evaluation/Returns Min               5100.54\n",
      "evaluation/Estimation Bias Mean      1046.85\n",
      "evaluation/Estimation Bias Std        198.418\n",
      "evaluation/EB/Q_True Mean              48.4157\n",
      "evaluation/EB/Q_True Std              149.689\n",
      "evaluation/EB/Q_Pred Mean            1095.27\n",
      "evaluation/EB/Q_Pred Std              131.211\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5127.71\n",
      "evaluation/Actions Mean                 0.517464\n",
      "evaluation/Actions Std                  0.622777\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.9264\n",
      "time/backward_zf1 (s)                   2.05694\n",
      "time/backward_zf2 (s)                   2.00627\n",
      "time/data sampling (s)                  0.233654\n",
      "time/data storing (s)                   0.0137503\n",
      "time/evaluation sampling (s)            1.39788\n",
      "time/exploration sampling (s)           0.192344\n",
      "time/logging (s)                        0.0125756\n",
      "time/preback_alpha (s)                  0.555861\n",
      "time/preback_policy (s)                 1.16674\n",
      "time/preback_start (s)                  0.119857\n",
      "time/preback_zf (s)                     5.0632\n",
      "time/saving (s)                         0.00567499\n",
      "time/training (s)                       2.00624\n",
      "time/epoch (s)                         16.7574\n",
      "time/total (s)                       1600.15\n",
      "Epoch                                  99\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:19:05.714355 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 100 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 111000\n",
      "trainer/ZF1 Loss                       43.4006\n",
      "trainer/ZF2 Loss                       38.4847\n",
      "trainer/ZF Expert Reward               17.4667\n",
      "trainer/ZF Policy Reward               -2.48213\n",
      "trainer/ZF CHI2 Term                   61.1621\n",
      "trainer/Policy Loss                  -653.04\n",
      "trainer/Bias Loss                     144.105\n",
      "trainer/Bias Value                     10.9087\n",
      "trainer/Policy Grad Norm              243.134\n",
      "trainer/Policy Param Norm              30.2058\n",
      "trainer/Zf1 Grad Norm                2245.05\n",
      "trainer/Zf1 Param Norm                 80.1683\n",
      "trainer/Zf2 Grad Norm                2582.5\n",
      "trainer/Zf2 Param Norm                 78.2387\n",
      "trainer/Z Expert Predictions Mean    1071.15\n",
      "trainer/Z Expert Predictions Std      161.024\n",
      "trainer/Z Expert Predictions Max     1266.43\n",
      "trainer/Z Expert Predictions Min      478.168\n",
      "trainer/Z Policy Predictions Mean     641.747\n",
      "trainer/Z Policy Predictions Std      374.479\n",
      "trainer/Z Policy Predictions Max     1218.26\n",
      "trainer/Z Policy Predictions Min     -120.74\n",
      "trainer/Z Expert Targets Mean        1053.68\n",
      "trainer/Z Expert Targets Std          158.43\n",
      "trainer/Z Expert Targets Max         1246.02\n",
      "trainer/Z Expert Targets Min          486.682\n",
      "trainer/Z Policy Targets Mean         644.229\n",
      "trainer/Z Policy Targets Std          367.616\n",
      "trainer/Z Policy Targets Max         1220.84\n",
      "trainer/Z Policy Targets Min         -119.731\n",
      "trainer/Log Pis Mean                   27.0616\n",
      "trainer/Log Pis Std                     6.47643\n",
      "trainer/Policy mu Mean                  1.15373\n",
      "trainer/Policy mu Std                   2.2019\n",
      "trainer/Policy log std Mean            -3.32382\n",
      "trainer/Policy log std Std              1.23642\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        105109\n",
      "exploration/num paths total           871\n",
      "evaluation/num steps total         470713\n",
      "evaluation/num paths total           1013\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.05457\n",
      "evaluation/Rewards Std                  1.298\n",
      "evaluation/Rewards Max                  7.18913\n",
      "evaluation/Rewards Min                  0.0722802\n",
      "evaluation/Returns Mean              5054.57\n",
      "evaluation/Returns Std                 13.5343\n",
      "evaluation/Returns Max               5079.96\n",
      "evaluation/Returns Min               5034.87\n",
      "evaluation/Estimation Bias Mean      1056.92\n",
      "evaluation/Estimation Bias Std        198.507\n",
      "evaluation/EB/Q_True Mean              48.0481\n",
      "evaluation/EB/Q_True Std              148.405\n",
      "evaluation/EB/Q_Pred Mean            1104.97\n",
      "evaluation/EB/Q_Pred Std              134.468\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5054.57\n",
      "evaluation/Actions Mean                 0.515824\n",
      "evaluation/Actions Std                  0.614705\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999975\n",
      "time/backward_policy (s)                1.92997\n",
      "time/backward_zf1 (s)                   2.05357\n",
      "time/backward_zf2 (s)                   2.00827\n",
      "time/data sampling (s)                  0.236199\n",
      "time/data storing (s)                   0.0144895\n",
      "time/evaluation sampling (s)            1.44712\n",
      "time/exploration sampling (s)           0.198195\n",
      "time/logging (s)                        0.0118167\n",
      "time/preback_alpha (s)                  0.553261\n",
      "time/preback_policy (s)                 1.16405\n",
      "time/preback_start (s)                  0.120193\n",
      "time/preback_zf (s)                     5.03629\n",
      "time/saving (s)                         0.00556953\n",
      "time/training (s)                       2.01818\n",
      "time/epoch (s)                         16.7972\n",
      "time/total (s)                       1616.98\n",
      "Epoch                                 100\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:19:22.388271 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 101 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 112000\n",
      "trainer/ZF1 Loss                       31.3244\n",
      "trainer/ZF2 Loss                       26.4935\n",
      "trainer/ZF Expert Reward               17.0888\n",
      "trainer/ZF Policy Reward               -2.05704\n",
      "trainer/ZF CHI2 Term                   48.3164\n",
      "trainer/Policy Loss                  -701.657\n",
      "trainer/Bias Loss                     178.002\n",
      "trainer/Bias Value                     10.9158\n",
      "trainer/Policy Grad Norm              188.299\n",
      "trainer/Policy Param Norm              30.2637\n",
      "trainer/Zf1 Grad Norm                5215.96\n",
      "trainer/Zf1 Param Norm                 80.4494\n",
      "trainer/Zf2 Grad Norm                3230.34\n",
      "trainer/Zf2 Param Norm                 78.4948\n",
      "trainer/Z Expert Predictions Mean    1096.07\n",
      "trainer/Z Expert Predictions Std      134.147\n",
      "trainer/Z Expert Predictions Max     1284.82\n",
      "trainer/Z Expert Predictions Min      523.511\n",
      "trainer/Z Policy Predictions Mean     688.28\n",
      "trainer/Z Policy Predictions Std      384.898\n",
      "trainer/Z Policy Predictions Max     1232.35\n",
      "trainer/Z Policy Predictions Min     -162.523\n",
      "trainer/Z Expert Targets Mean        1078.98\n",
      "trainer/Z Expert Targets Std          132.824\n",
      "trainer/Z Expert Targets Max         1272.43\n",
      "trainer/Z Expert Targets Min          529.492\n",
      "trainer/Z Policy Targets Mean         690.337\n",
      "trainer/Z Policy Targets Std          378.634\n",
      "trainer/Z Policy Targets Max         1203.12\n",
      "trainer/Z Policy Targets Min         -144.245\n",
      "trainer/Log Pis Mean                   26.1538\n",
      "trainer/Log Pis Std                     5.49906\n",
      "trainer/Policy mu Mean                  1.15907\n",
      "trainer/Policy mu Std                   1.99918\n",
      "trainer/Policy log std Mean            -3.36756\n",
      "trainer/Policy log std Std              1.15373\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        106109\n",
      "exploration/num paths total           872\n",
      "evaluation/num steps total         480129\n",
      "evaluation/num paths total           1023\n",
      "evaluation/path length Mean           941.6\n",
      "evaluation/path length Std            123.395\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            619\n",
      "evaluation/Rewards Mean                 5.04102\n",
      "evaluation/Rewards Std                  1.31849\n",
      "evaluation/Rewards Max                  7.22418\n",
      "evaluation/Rewards Min                  0.089561\n",
      "evaluation/Returns Mean              4746.63\n",
      "evaluation/Returns Std                672.399\n",
      "evaluation/Returns Max               5167.89\n",
      "evaluation/Returns Min               3007.03\n",
      "evaluation/Estimation Bias Mean       996.56\n",
      "evaluation/Estimation Bias Std        265.274\n",
      "evaluation/EB/Q_True Mean              50.2039\n",
      "evaluation/EB/Q_True Std              149.572\n",
      "evaluation/EB/Q_Pred Mean            1046.76\n",
      "evaluation/EB/Q_Pred Std              185.358\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4746.63\n",
      "evaluation/Actions Mean                 0.501703\n",
      "evaluation/Actions Std                  0.640528\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76699\n",
      "time/backward_zf1 (s)                   1.89633\n",
      "time/backward_zf2 (s)                   1.83593\n",
      "time/data sampling (s)                  0.242892\n",
      "time/data storing (s)                   0.0133802\n",
      "time/evaluation sampling (s)            1.42947\n",
      "time/exploration sampling (s)           0.189992\n",
      "time/logging (s)                        0.0114972\n",
      "time/preback_alpha (s)                  0.557509\n",
      "time/preback_policy (s)                 0.982608\n",
      "time/preback_start (s)                  0.120914\n",
      "time/preback_zf (s)                     5.06009\n",
      "time/saving (s)                         0.00544025\n",
      "time/training (s)                       2.48209\n",
      "time/epoch (s)                         16.5951\n",
      "time/total (s)                       1633.61\n",
      "Epoch                                 101\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:19:38.958882 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 102 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 113000\n",
      "trainer/ZF1 Loss                      228.466\n",
      "trainer/ZF2 Loss                      243.39\n",
      "trainer/ZF Expert Reward               20.8867\n",
      "trainer/ZF Policy Reward                0.651196\n",
      "trainer/ZF CHI2 Term                  256.434\n",
      "trainer/Policy Loss                  -722.538\n",
      "trainer/Bias Loss                    2174.4\n",
      "trainer/Bias Value                     10.9227\n",
      "trainer/Policy Grad Norm              193.944\n",
      "trainer/Policy Param Norm              30.3204\n",
      "trainer/Zf1 Grad Norm               10727.5\n",
      "trainer/Zf1 Param Norm                 80.7117\n",
      "trainer/Zf2 Grad Norm                7661.71\n",
      "trainer/Zf2 Param Norm                 78.7482\n",
      "trainer/Z Expert Predictions Mean    1094.28\n",
      "trainer/Z Expert Predictions Std      150.652\n",
      "trainer/Z Expert Predictions Max     1288.77\n",
      "trainer/Z Expert Predictions Min      461.327\n",
      "trainer/Z Policy Predictions Mean     710.799\n",
      "trainer/Z Policy Predictions Std      373.826\n",
      "trainer/Z Policy Predictions Max     1259.56\n",
      "trainer/Z Policy Predictions Min     -106.245\n",
      "trainer/Z Expert Targets Mean        1073.39\n",
      "trainer/Z Expert Targets Std          171.327\n",
      "trainer/Z Expert Targets Max         1263.48\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         710.148\n",
      "trainer/Z Policy Targets Std          369.202\n",
      "trainer/Z Policy Targets Max         1244.23\n",
      "trainer/Z Policy Targets Min         -120.762\n",
      "trainer/Log Pis Mean                   27.0755\n",
      "trainer/Log Pis Std                     6.43163\n",
      "trainer/Policy mu Mean                  1.07827\n",
      "trainer/Policy mu Std                   2.13556\n",
      "trainer/Policy log std Mean            -3.46322\n",
      "trainer/Policy log std Std              1.17853\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        107109\n",
      "exploration/num paths total           873\n",
      "evaluation/num steps total         490129\n",
      "evaluation/num paths total           1033\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1149\n",
      "evaluation/Rewards Std                  1.32429\n",
      "evaluation/Rewards Max                  7.43417\n",
      "evaluation/Rewards Min                  0.0700945\n",
      "evaluation/Returns Mean              5114.9\n",
      "evaluation/Returns Std                 20.953\n",
      "evaluation/Returns Max               5150.47\n",
      "evaluation/Returns Min               5069.19\n",
      "evaluation/Estimation Bias Mean      1080.7\n",
      "evaluation/Estimation Bias Std        207.016\n",
      "evaluation/EB/Q_True Mean              48.5892\n",
      "evaluation/EB/Q_True Std              150.084\n",
      "evaluation/EB/Q_Pred Mean            1129.29\n",
      "evaluation/EB/Q_Pred Std              140.886\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5114.9\n",
      "evaluation/Actions Mean                 0.521299\n",
      "evaluation/Actions Std                  0.621192\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.75468\n",
      "time/backward_zf1 (s)                   1.86192\n",
      "time/backward_zf2 (s)                   1.80871\n",
      "time/data sampling (s)                  0.253479\n",
      "time/data storing (s)                   0.0135626\n",
      "time/evaluation sampling (s)            1.44552\n",
      "time/exploration sampling (s)           0.194133\n",
      "time/logging (s)                        0.0122943\n",
      "time/preback_alpha (s)                  0.557632\n",
      "time/preback_policy (s)                 0.977734\n",
      "time/preback_start (s)                  0.121218\n",
      "time/preback_zf (s)                     5.0488\n",
      "time/saving (s)                         0.00525387\n",
      "time/training (s)                       2.45087\n",
      "time/epoch (s)                         16.5058\n",
      "time/total (s)                       1650.14\n",
      "Epoch                                 102\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:19:56.846420 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 103 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 114000\n",
      "trainer/ZF1 Loss                      161.5\n",
      "trainer/ZF2 Loss                      215.019\n",
      "trainer/ZF Expert Reward               15.2572\n",
      "trainer/ZF Policy Reward               -1.35034\n",
      "trainer/ZF CHI2 Term                  205.133\n",
      "trainer/Policy Loss                  -695.441\n",
      "trainer/Bias Loss                    1164.3\n",
      "trainer/Bias Value                     10.9296\n",
      "trainer/Policy Grad Norm              207.016\n",
      "trainer/Policy Param Norm              30.3771\n",
      "trainer/Zf1 Grad Norm                6754.54\n",
      "trainer/Zf1 Param Norm                 80.9887\n",
      "trainer/Zf2 Grad Norm                5779.73\n",
      "trainer/Zf2 Param Norm                 79.0273\n",
      "trainer/Z Expert Predictions Mean    1107.27\n",
      "trainer/Z Expert Predictions Std      155.516\n",
      "trainer/Z Expert Predictions Max     1315.99\n",
      "trainer/Z Expert Predictions Min      509.755\n",
      "trainer/Z Policy Predictions Mean     681.687\n",
      "trainer/Z Policy Predictions Std      370.42\n",
      "trainer/Z Policy Predictions Max     1244.38\n",
      "trainer/Z Policy Predictions Min      -97.3222\n",
      "trainer/Z Expert Targets Mean        1092.01\n",
      "trainer/Z Expert Targets Std          165.41\n",
      "trainer/Z Expert Targets Max         1299.64\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         683.037\n",
      "trainer/Z Policy Targets Std          369.261\n",
      "trainer/Z Policy Targets Max         1229.35\n",
      "trainer/Z Policy Targets Min         -130.855\n",
      "trainer/Log Pis Mean                   26.5441\n",
      "trainer/Log Pis Std                     6.47645\n",
      "trainer/Policy mu Mean                  1.17922\n",
      "trainer/Policy mu Std                   2.04256\n",
      "trainer/Policy log std Mean            -3.38966\n",
      "trainer/Policy log std Std              1.16349\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        109109\n",
      "exploration/num paths total           875\n",
      "evaluation/num steps total         500129\n",
      "evaluation/num paths total           1043\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07116\n",
      "evaluation/Rewards Std                  1.30573\n",
      "evaluation/Rewards Max                  7.22678\n",
      "evaluation/Rewards Min                  0.0839813\n",
      "evaluation/Returns Mean              5071.16\n",
      "evaluation/Returns Std                 32.0493\n",
      "evaluation/Returns Max               5114.65\n",
      "evaluation/Returns Min               5000.11\n",
      "evaluation/Estimation Bias Mean      1072.53\n",
      "evaluation/Estimation Bias Std        196.766\n",
      "evaluation/EB/Q_True Mean              48.3596\n",
      "evaluation/EB/Q_True Std              149.281\n",
      "evaluation/EB/Q_Pred Mean            1120.89\n",
      "evaluation/EB/Q_Pred Std              131.402\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5071.16\n",
      "evaluation/Actions Mean                 0.487567\n",
      "evaluation/Actions Std                  0.638756\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.06446\n",
      "time/backward_zf1 (s)                   2.19229\n",
      "time/backward_zf2 (s)                   2.13909\n",
      "time/data sampling (s)                  0.287034\n",
      "time/data storing (s)                   0.0141161\n",
      "time/evaluation sampling (s)            1.4658\n",
      "time/exploration sampling (s)           0.204244\n",
      "time/logging (s)                        0.0136226\n",
      "time/preback_alpha (s)                  0.60571\n",
      "time/preback_policy (s)                 1.2023\n",
      "time/preback_start (s)                  0.130082\n",
      "time/preback_zf (s)                     5.21579\n",
      "time/saving (s)                         0.00636459\n",
      "time/training (s)                       2.27635\n",
      "time/epoch (s)                         17.8173\n",
      "time/total (s)                       1667.98\n",
      "Epoch                                 103\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:20:13.861750 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 104 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 115000\n",
      "trainer/ZF1 Loss                       47.6416\n",
      "trainer/ZF2 Loss                       47.9288\n",
      "trainer/ZF Expert Reward               20.3637\n",
      "trainer/ZF Policy Reward                7.31184\n",
      "trainer/ZF CHI2 Term                   61.1071\n",
      "trainer/Policy Loss                  -705.612\n",
      "trainer/Bias Loss                     176.402\n",
      "trainer/Bias Value                     10.9364\n",
      "trainer/Policy Grad Norm              300.5\n",
      "trainer/Policy Param Norm              30.443\n",
      "trainer/Zf1 Grad Norm                3178.87\n",
      "trainer/Zf1 Param Norm                 81.2822\n",
      "trainer/Zf2 Grad Norm                3599.47\n",
      "trainer/Zf2 Param Norm                 79.302\n",
      "trainer/Z Expert Predictions Mean    1121.82\n",
      "trainer/Z Expert Predictions Std      156.57\n",
      "trainer/Z Expert Predictions Max     1318.55\n",
      "trainer/Z Expert Predictions Min      560.976\n",
      "trainer/Z Policy Predictions Mean     697.508\n",
      "trainer/Z Policy Predictions Std      354.67\n",
      "trainer/Z Policy Predictions Max     1282.84\n",
      "trainer/Z Policy Predictions Min     -112.178\n",
      "trainer/Z Expert Targets Mean        1101.46\n",
      "trainer/Z Expert Targets Std          155.853\n",
      "trainer/Z Expert Targets Max         1304.3\n",
      "trainer/Z Expert Targets Min          550.668\n",
      "trainer/Z Policy Targets Mean         690.196\n",
      "trainer/Z Policy Targets Std          355.672\n",
      "trainer/Z Policy Targets Max         1270.3\n",
      "trainer/Z Policy Targets Min         -149.326\n",
      "trainer/Log Pis Mean                   27.0059\n",
      "trainer/Log Pis Std                     6.44117\n",
      "trainer/Policy mu Mean                  1.15521\n",
      "trainer/Policy mu Std                   2.07809\n",
      "trainer/Policy log std Mean            -3.42138\n",
      "trainer/Policy log std Std              1.21705\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        110109\n",
      "exploration/num paths total           876\n",
      "evaluation/num steps total         510119\n",
      "evaluation/num paths total           1053\n",
      "evaluation/path length Mean           999\n",
      "evaluation/path length Std              3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            990\n",
      "evaluation/Rewards Mean                 5.21601\n",
      "evaluation/Rewards Std                  1.3397\n",
      "evaluation/Rewards Max                  7.34821\n",
      "evaluation/Rewards Min                  0.0748324\n",
      "evaluation/Returns Mean              5210.79\n",
      "evaluation/Returns Std                 12.0864\n",
      "evaluation/Returns Max               5225.29\n",
      "evaluation/Returns Min               5190.6\n",
      "evaluation/Estimation Bias Mean      1090.41\n",
      "evaluation/Estimation Bias Std        234.82\n",
      "evaluation/EB/Q_True Mean              49.4769\n",
      "evaluation/EB/Q_True Std              152.875\n",
      "evaluation/EB/Q_Pred Mean            1139.89\n",
      "evaluation/EB/Q_Pred Std              162.044\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5210.79\n",
      "evaluation/Actions Mean                 0.515214\n",
      "evaluation/Actions Std                  0.636976\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84883\n",
      "time/backward_zf1 (s)                   2.02119\n",
      "time/backward_zf2 (s)                   1.93073\n",
      "time/data sampling (s)                  0.261077\n",
      "time/data storing (s)                   0.0149532\n",
      "time/evaluation sampling (s)            1.47493\n",
      "time/exploration sampling (s)           0.20321\n",
      "time/logging (s)                        0.0118789\n",
      "time/preback_alpha (s)                  0.573913\n",
      "time/preback_policy (s)                 1.06319\n",
      "time/preback_start (s)                  0.12439\n",
      "time/preback_zf (s)                     5.07427\n",
      "time/saving (s)                         0.00579859\n",
      "time/training (s)                       2.33479\n",
      "time/epoch (s)                         16.9431\n",
      "time/total (s)                       1684.94\n",
      "Epoch                                 104\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:20:31.364550 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 105 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 116000\n",
      "trainer/ZF1 Loss                      154.815\n",
      "trainer/ZF2 Loss                       99.2311\n",
      "trainer/ZF Expert Reward               11.793\n",
      "trainer/ZF Policy Reward               -3.98766\n",
      "trainer/ZF CHI2 Term                  143.08\n",
      "trainer/Policy Loss                  -695.842\n",
      "trainer/Bias Loss                     682.977\n",
      "trainer/Bias Value                     10.9431\n",
      "trainer/Policy Grad Norm              196.433\n",
      "trainer/Policy Param Norm              30.5113\n",
      "trainer/Zf1 Grad Norm               10087.2\n",
      "trainer/Zf1 Param Norm                 81.5469\n",
      "trainer/Zf2 Grad Norm                8387.96\n",
      "trainer/Zf2 Param Norm                 79.575\n",
      "trainer/Z Expert Predictions Mean    1102.72\n",
      "trainer/Z Expert Predictions Std      157.943\n",
      "trainer/Z Expert Predictions Max     1315.14\n",
      "trainer/Z Expert Predictions Min      502.088\n",
      "trainer/Z Policy Predictions Mean     680.465\n",
      "trainer/Z Policy Predictions Std      366.764\n",
      "trainer/Z Policy Predictions Max     1239.14\n",
      "trainer/Z Policy Predictions Min     -150.534\n",
      "trainer/Z Expert Targets Mean        1090.93\n",
      "trainer/Z Expert Targets Std          165.911\n",
      "trainer/Z Expert Targets Max         1293.97\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         684.453\n",
      "trainer/Z Policy Targets Std          367.446\n",
      "trainer/Z Policy Targets Max         1229.53\n",
      "trainer/Z Policy Targets Min         -134.022\n",
      "trainer/Log Pis Mean                   27.6491\n",
      "trainer/Log Pis Std                     6.3024\n",
      "trainer/Policy mu Mean                  1.14635\n",
      "trainer/Policy mu Std                   2.23895\n",
      "trainer/Policy log std Mean            -3.32164\n",
      "trainer/Policy log std Std              1.22078\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        111109\n",
      "exploration/num paths total           877\n",
      "evaluation/num steps total         520119\n",
      "evaluation/num paths total           1063\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19026\n",
      "evaluation/Rewards Std                  1.3417\n",
      "evaluation/Rewards Max                  7.28323\n",
      "evaluation/Rewards Min                  0.0787777\n",
      "evaluation/Returns Mean              5190.26\n",
      "evaluation/Returns Std                 10.701\n",
      "evaluation/Returns Max               5212.79\n",
      "evaluation/Returns Min               5176.39\n",
      "evaluation/Estimation Bias Mean      1112.62\n",
      "evaluation/Estimation Bias Std        203.208\n",
      "evaluation/EB/Q_True Mean              49.1161\n",
      "evaluation/EB/Q_True Std              151.619\n",
      "evaluation/EB/Q_Pred Mean            1161.74\n",
      "evaluation/EB/Q_Pred Std              138.104\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5190.26\n",
      "evaluation/Actions Mean                 0.509876\n",
      "evaluation/Actions Std                  0.633162\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999993\n",
      "time/backward_policy (s)                1.9071\n",
      "time/backward_zf1 (s)                   2.06144\n",
      "time/backward_zf2 (s)                   1.98379\n",
      "time/data sampling (s)                  0.2649\n",
      "time/data storing (s)                   0.0151332\n",
      "time/evaluation sampling (s)            1.46379\n",
      "time/exploration sampling (s)           0.208073\n",
      "time/logging (s)                        0.0128185\n",
      "time/preback_alpha (s)                  0.585641\n",
      "time/preback_policy (s)                 1.05624\n",
      "time/preback_start (s)                  0.126805\n",
      "time/preback_zf (s)                     5.22832\n",
      "time/saving (s)                         0.00594695\n",
      "time/training (s)                       2.51474\n",
      "time/epoch (s)                         17.4347\n",
      "time/total (s)                       1702.4\n",
      "Epoch                                 105\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:20:48.321902 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 106 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 117000\n",
      "trainer/ZF1 Loss                      302.614\n",
      "trainer/ZF2 Loss                      299.495\n",
      "trainer/ZF Expert Reward               17.7885\n",
      "trainer/ZF Policy Reward               -1.63492\n",
      "trainer/ZF CHI2 Term                  320.757\n",
      "trainer/Policy Loss                  -763.645\n",
      "trainer/Bias Loss                    2811.02\n",
      "trainer/Bias Value                     10.95\n",
      "trainer/Policy Grad Norm              225.24\n",
      "trainer/Policy Param Norm              30.5777\n",
      "trainer/Zf1 Grad Norm                3337.78\n",
      "trainer/Zf1 Param Norm                 81.8253\n",
      "trainer/Zf2 Grad Norm                3246.18\n",
      "trainer/Zf2 Param Norm                 79.8316\n",
      "trainer/Z Expert Predictions Mean    1141.94\n",
      "trainer/Z Expert Predictions Std      138.743\n",
      "trainer/Z Expert Predictions Max     1321.65\n",
      "trainer/Z Expert Predictions Min      641.571\n",
      "trainer/Z Policy Predictions Mean     748.674\n",
      "trainer/Z Policy Predictions Std      366.918\n",
      "trainer/Z Policy Predictions Max     1260.62\n",
      "trainer/Z Policy Predictions Min     -115.047\n",
      "trainer/Z Expert Targets Mean        1124.16\n",
      "trainer/Z Expert Targets Std          154.419\n",
      "trainer/Z Expert Targets Max         1329.21\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         750.309\n",
      "trainer/Z Policy Targets Std          362.771\n",
      "trainer/Z Policy Targets Max         1236.65\n",
      "trainer/Z Policy Targets Min          -96.0009\n",
      "trainer/Log Pis Mean                   27.9354\n",
      "trainer/Log Pis Std                     7.56121\n",
      "trainer/Policy mu Mean                  1.14928\n",
      "trainer/Policy mu Std                   2.48196\n",
      "trainer/Policy log std Mean            -3.25395\n",
      "trainer/Policy log std Std              1.2644\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        114109\n",
      "exploration/num paths total           880\n",
      "evaluation/num steps total         530119\n",
      "evaluation/num paths total           1073\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.90831\n",
      "evaluation/Rewards Std                  1.25194\n",
      "evaluation/Rewards Max                  6.89368\n",
      "evaluation/Rewards Min                  0.0664329\n",
      "evaluation/Returns Mean              4908.31\n",
      "evaluation/Returns Std                 37.169\n",
      "evaluation/Returns Max               4951.4\n",
      "evaluation/Returns Min               4829.3\n",
      "evaluation/Estimation Bias Mean      1057.04\n",
      "evaluation/Estimation Bias Std        189.969\n",
      "evaluation/EB/Q_True Mean              46.2293\n",
      "evaluation/EB/Q_True Std              142.694\n",
      "evaluation/EB/Q_Pred Mean            1103.27\n",
      "evaluation/EB/Q_Pred Std              122.875\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4908.31\n",
      "evaluation/Actions Mean                 0.507737\n",
      "evaluation/Actions Std                  0.636924\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.83414\n",
      "time/backward_zf1 (s)                   1.99185\n",
      "time/backward_zf2 (s)                   1.89652\n",
      "time/data sampling (s)                  0.261057\n",
      "time/data storing (s)                   0.0140062\n",
      "time/evaluation sampling (s)            1.48861\n",
      "time/exploration sampling (s)           0.202879\n",
      "time/logging (s)                        0.011871\n",
      "time/preback_alpha (s)                  0.573344\n",
      "time/preback_policy (s)                 1.04179\n",
      "time/preback_start (s)                  0.124807\n",
      "time/preback_zf (s)                     5.07813\n",
      "time/saving (s)                         0.00639548\n",
      "time/training (s)                       2.36485\n",
      "time/epoch (s)                         16.8903\n",
      "time/total (s)                       1719.31\n",
      "Epoch                                 106\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:21:05.331173 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 107 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 118000\n",
      "trainer/ZF1 Loss                      245.147\n",
      "trainer/ZF2 Loss                      256.492\n",
      "trainer/ZF Expert Reward               20.0453\n",
      "trainer/ZF Policy Reward                0.586628\n",
      "trainer/ZF CHI2 Term                  270.549\n",
      "trainer/Policy Loss                  -757.357\n",
      "trainer/Bias Loss                    2364.49\n",
      "trainer/Bias Value                     10.957\n",
      "trainer/Policy Grad Norm              180.199\n",
      "trainer/Policy Param Norm              30.6439\n",
      "trainer/Zf1 Grad Norm                4501.27\n",
      "trainer/Zf1 Param Norm                 82.0696\n",
      "trainer/Zf2 Grad Norm                4214.03\n",
      "trainer/Zf2 Param Norm                 80.0658\n",
      "trainer/Z Expert Predictions Mean    1154.94\n",
      "trainer/Z Expert Predictions Std      132.503\n",
      "trainer/Z Expert Predictions Max     1349.53\n",
      "trainer/Z Expert Predictions Min      721.242\n",
      "trainer/Z Policy Predictions Mean     745.693\n",
      "trainer/Z Policy Predictions Std      380.534\n",
      "trainer/Z Policy Predictions Max     1291.9\n",
      "trainer/Z Policy Predictions Min      -68.6463\n",
      "trainer/Z Expert Targets Mean        1134.89\n",
      "trainer/Z Expert Targets Std          150.677\n",
      "trainer/Z Expert Targets Max         1332.91\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         745.106\n",
      "trainer/Z Policy Targets Std          376.046\n",
      "trainer/Z Policy Targets Max         1271.35\n",
      "trainer/Z Policy Targets Min          -77.1518\n",
      "trainer/Log Pis Mean                   27.0453\n",
      "trainer/Log Pis Std                     6.71531\n",
      "trainer/Policy mu Mean                  1.17445\n",
      "trainer/Policy mu Std                   2.14918\n",
      "trainer/Policy log std Mean            -3.29693\n",
      "trainer/Policy log std Std              1.17584\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        114109\n",
      "exploration/num paths total           880\n",
      "evaluation/num steps total         540119\n",
      "evaluation/num paths total           1083\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25819\n",
      "evaluation/Rewards Std                  1.35811\n",
      "evaluation/Rewards Max                  7.50482\n",
      "evaluation/Rewards Min                  0.0549669\n",
      "evaluation/Returns Mean              5258.19\n",
      "evaluation/Returns Std                 23.2639\n",
      "evaluation/Returns Max               5297.82\n",
      "evaluation/Returns Min               5222.96\n",
      "evaluation/Estimation Bias Mean      1136.33\n",
      "evaluation/Estimation Bias Std        207.411\n",
      "evaluation/EB/Q_True Mean              49.5353\n",
      "evaluation/EB/Q_True Std              152.978\n",
      "evaluation/EB/Q_Pred Mean            1185.87\n",
      "evaluation/EB/Q_Pred Std              144.327\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5258.19\n",
      "evaluation/Actions Mean                 0.508798\n",
      "evaluation/Actions Std                  0.642788\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.87026\n",
      "time/backward_zf1 (s)                   1.99629\n",
      "time/backward_zf2 (s)                   1.93309\n",
      "time/data sampling (s)                  0.267819\n",
      "time/data storing (s)                   0.0145566\n",
      "time/evaluation sampling (s)            1.40924\n",
      "time/exploration sampling (s)           0.199347\n",
      "time/logging (s)                        0.0118966\n",
      "time/preback_alpha (s)                  0.577208\n",
      "time/preback_policy (s)                 1.09032\n",
      "time/preback_start (s)                  0.12509\n",
      "time/preback_zf (s)                     5.11008\n",
      "time/saving (s)                         0.00570289\n",
      "time/training (s)                       2.32795\n",
      "time/epoch (s)                         16.9389\n",
      "time/total (s)                       1736.27\n",
      "Epoch                                 107\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:21:22.583309 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 108 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 119000\n",
      "trainer/ZF1 Loss                       39.274\n",
      "trainer/ZF2 Loss                       36.5852\n",
      "trainer/ZF Expert Reward               16.9577\n",
      "trainer/ZF Policy Reward                2.71401\n",
      "trainer/ZF CHI2 Term                   52.4498\n",
      "trainer/Policy Loss                  -792.116\n",
      "trainer/Bias Loss                     153.044\n",
      "trainer/Bias Value                     10.9638\n",
      "trainer/Policy Grad Norm              180.213\n",
      "trainer/Policy Param Norm              30.7073\n",
      "trainer/Zf1 Grad Norm                3543.83\n",
      "trainer/Zf1 Param Norm                 82.3349\n",
      "trainer/Zf2 Grad Norm                3158.83\n",
      "trainer/Zf2 Param Norm                 80.3057\n",
      "trainer/Z Expert Predictions Mean    1137.29\n",
      "trainer/Z Expert Predictions Std      150.367\n",
      "trainer/Z Expert Predictions Max     1346.35\n",
      "trainer/Z Expert Predictions Min      563.663\n",
      "trainer/Z Policy Predictions Mean     782.014\n",
      "trainer/Z Policy Predictions Std      354.815\n",
      "trainer/Z Policy Predictions Max     1265.77\n",
      "trainer/Z Policy Predictions Min     -106.269\n",
      "trainer/Z Expert Targets Mean        1120.33\n",
      "trainer/Z Expert Targets Std          146.939\n",
      "trainer/Z Expert Targets Max         1318.09\n",
      "trainer/Z Expert Targets Min          570.109\n",
      "trainer/Z Policy Targets Mean         779.3\n",
      "trainer/Z Policy Targets Std          349.868\n",
      "trainer/Z Policy Targets Max         1260.55\n",
      "trainer/Z Policy Targets Min          -88.2316\n",
      "trainer/Log Pis Mean                   27.6509\n",
      "trainer/Log Pis Std                     7.54394\n",
      "trainer/Policy mu Mean                  1.24594\n",
      "trainer/Policy mu Std                   2.22882\n",
      "trainer/Policy log std Mean            -3.41364\n",
      "trainer/Policy log std Std              1.19832\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        114109\n",
      "exploration/num paths total           880\n",
      "evaluation/num steps total         550119\n",
      "evaluation/num paths total           1093\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12837\n",
      "evaluation/Rewards Std                  1.30287\n",
      "evaluation/Rewards Max                  7.04349\n",
      "evaluation/Rewards Min                  0.0803046\n",
      "evaluation/Returns Mean              5128.37\n",
      "evaluation/Returns Std                 12.7455\n",
      "evaluation/Returns Max               5153.55\n",
      "evaluation/Returns Min               5106.82\n",
      "evaluation/Estimation Bias Mean      1118.04\n",
      "evaluation/Estimation Bias Std        192.98\n",
      "evaluation/EB/Q_True Mean              48.3551\n",
      "evaluation/EB/Q_True Std              149.308\n",
      "evaluation/EB/Q_Pred Mean            1166.4\n",
      "evaluation/EB/Q_Pred Std              124.581\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5128.37\n",
      "evaluation/Actions Mean                 0.490728\n",
      "evaluation/Actions Std                  0.648432\n",
      "evaluation/Actions Max                  0.999999\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.93214\n",
      "time/backward_zf1 (s)                   2.06198\n",
      "time/backward_zf2 (s)                   2.00169\n",
      "time/data sampling (s)                  0.263312\n",
      "time/data storing (s)                   0.0153789\n",
      "time/evaluation sampling (s)            1.39386\n",
      "time/exploration sampling (s)           0.204298\n",
      "time/logging (s)                        0.0113875\n",
      "time/preback_alpha (s)                  0.587592\n",
      "time/preback_policy (s)                 1.09535\n",
      "time/preback_start (s)                  0.129556\n",
      "time/preback_zf (s)                     5.15192\n",
      "time/saving (s)                         0.00564788\n",
      "time/training (s)                       2.3261\n",
      "time/epoch (s)                         17.1802\n",
      "time/total (s)                       1753.47\n",
      "Epoch                                 108\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:21:41.035017 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 109 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 120000\n",
      "trainer/ZF1 Loss                       55.9086\n",
      "trainer/ZF2 Loss                       49.7653\n",
      "trainer/ZF Expert Reward               12.8171\n",
      "trainer/ZF Policy Reward               -2.02177\n",
      "trainer/ZF CHI2 Term                   67.9501\n",
      "trainer/Policy Loss                  -740.614\n",
      "trainer/Bias Loss                     156.944\n",
      "trainer/Bias Value                     10.9707\n",
      "trainer/Policy Grad Norm              255.983\n",
      "trainer/Policy Param Norm              30.7665\n",
      "trainer/Zf1 Grad Norm                4319.64\n",
      "trainer/Zf1 Param Norm                 82.5699\n",
      "trainer/Zf2 Grad Norm                4055.17\n",
      "trainer/Zf2 Param Norm                 80.5322\n",
      "trainer/Z Expert Predictions Mean    1155.92\n",
      "trainer/Z Expert Predictions Std      143.364\n",
      "trainer/Z Expert Predictions Max     1352.95\n",
      "trainer/Z Expert Predictions Min      565.027\n",
      "trainer/Z Policy Predictions Mean     728.441\n",
      "trainer/Z Policy Predictions Std      368.609\n",
      "trainer/Z Policy Predictions Max     1289.04\n",
      "trainer/Z Policy Predictions Min      -86.3963\n",
      "trainer/Z Expert Targets Mean        1143.1\n",
      "trainer/Z Expert Targets Std          141.329\n",
      "trainer/Z Expert Targets Max         1330.12\n",
      "trainer/Z Expert Targets Min          563.251\n",
      "trainer/Z Policy Targets Mean         730.463\n",
      "trainer/Z Policy Targets Std          364.859\n",
      "trainer/Z Policy Targets Max         1265.24\n",
      "trainer/Z Policy Targets Min          -69.7086\n",
      "trainer/Log Pis Mean                   27.4352\n",
      "trainer/Log Pis Std                     7.32992\n",
      "trainer/Policy mu Mean                  1.14046\n",
      "trainer/Policy mu Std                   2.32085\n",
      "trainer/Policy log std Mean            -3.24832\n",
      "trainer/Policy log std Std              1.22603\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        115109\n",
      "exploration/num paths total           881\n",
      "evaluation/num steps total         560119\n",
      "evaluation/num paths total           1103\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18168\n",
      "evaluation/Rewards Std                  1.33907\n",
      "evaluation/Rewards Max                  7.27353\n",
      "evaluation/Rewards Min                  0.0585562\n",
      "evaluation/Returns Mean              5181.68\n",
      "evaluation/Returns Std                 11.9649\n",
      "evaluation/Returns Max               5199.22\n",
      "evaluation/Returns Min               5161.2\n",
      "evaluation/Estimation Bias Mean      1142.59\n",
      "evaluation/Estimation Bias Std        197.873\n",
      "evaluation/EB/Q_True Mean              49.0645\n",
      "evaluation/EB/Q_True Std              151.525\n",
      "evaluation/EB/Q_Pred Mean            1191.66\n",
      "evaluation/EB/Q_Pred Std              130.173\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5181.68\n",
      "evaluation/Actions Mean                 0.510161\n",
      "evaluation/Actions Std                  0.642762\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.14595\n",
      "time/backward_zf1 (s)                   2.3502\n",
      "time/backward_zf2 (s)                   2.22331\n",
      "time/data sampling (s)                  0.281312\n",
      "time/data storing (s)                   0.0157334\n",
      "time/evaluation sampling (s)            1.36545\n",
      "time/exploration sampling (s)           0.212133\n",
      "time/logging (s)                        0.0122239\n",
      "time/preback_alpha (s)                  0.636489\n",
      "time/preback_policy (s)                 1.22922\n",
      "time/preback_start (s)                  0.135791\n",
      "time/preback_zf (s)                     5.32118\n",
      "time/saving (s)                         0.00566012\n",
      "time/training (s)                       2.44484\n",
      "time/epoch (s)                         18.3795\n",
      "time/total (s)                       1771.87\n",
      "Epoch                                 109\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:21:58.708423 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 110 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 121000\n",
      "trainer/ZF1 Loss                       29.7113\n",
      "trainer/ZF2 Loss                       33.3862\n",
      "trainer/ZF Expert Reward               22.3335\n",
      "trainer/ZF Policy Reward                4.30854\n",
      "trainer/ZF CHI2 Term                   49.8574\n",
      "trainer/Policy Loss                  -795.155\n",
      "trainer/Bias Loss                     190.52\n",
      "trainer/Bias Value                     10.9775\n",
      "trainer/Policy Grad Norm              193.23\n",
      "trainer/Policy Param Norm              30.8265\n",
      "trainer/Zf1 Grad Norm                3358.29\n",
      "trainer/Zf1 Param Norm                 82.7675\n",
      "trainer/Zf2 Grad Norm                3531.83\n",
      "trainer/Zf2 Param Norm                 80.745\n",
      "trainer/Z Expert Predictions Mean    1155.93\n",
      "trainer/Z Expert Predictions Std      147.05\n",
      "trainer/Z Expert Predictions Max     1343.69\n",
      "trainer/Z Expert Predictions Min      590.572\n",
      "trainer/Z Policy Predictions Mean     788.527\n",
      "trainer/Z Policy Predictions Std      355.048\n",
      "trainer/Z Policy Predictions Max     1324.93\n",
      "trainer/Z Policy Predictions Min      -32.0673\n",
      "trainer/Z Expert Targets Mean        1133.6\n",
      "trainer/Z Expert Targets Std          144.175\n",
      "trainer/Z Expert Targets Max         1318.09\n",
      "trainer/Z Expert Targets Min          596.823\n",
      "trainer/Z Policy Targets Mean         784.218\n",
      "trainer/Z Policy Targets Std          349.661\n",
      "trainer/Z Policy Targets Max         1301.15\n",
      "trainer/Z Policy Targets Min          -63.1959\n",
      "trainer/Log Pis Mean                   28.3718\n",
      "trainer/Log Pis Std                     7.39245\n",
      "trainer/Policy mu Mean                  1.3022\n",
      "trainer/Policy mu Std                   2.33925\n",
      "trainer/Policy log std Mean            -3.29635\n",
      "trainer/Policy log std Std              1.23744\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        115109\n",
      "exploration/num paths total           881\n",
      "evaluation/num steps total         570119\n",
      "evaluation/num paths total           1113\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08697\n",
      "evaluation/Rewards Std                  1.31334\n",
      "evaluation/Rewards Max                  7.26149\n",
      "evaluation/Rewards Min                  0.0714874\n",
      "evaluation/Returns Mean              5086.97\n",
      "evaluation/Returns Std                 12.0043\n",
      "evaluation/Returns Max               5103.64\n",
      "evaluation/Returns Min               5068.18\n",
      "evaluation/Estimation Bias Mean      1129.53\n",
      "evaluation/Estimation Bias Std        192.11\n",
      "evaluation/EB/Q_True Mean              48.2007\n",
      "evaluation/EB/Q_True Std              148.861\n",
      "evaluation/EB/Q_Pred Mean            1177.73\n",
      "evaluation/EB/Q_Pred Std              123.934\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5086.97\n",
      "evaluation/Actions Mean                 0.516463\n",
      "evaluation/Actions Std                  0.631082\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.96015\n",
      "time/backward_zf1 (s)                   2.13839\n",
      "time/backward_zf2 (s)                   2.03779\n",
      "time/data sampling (s)                  0.28771\n",
      "time/data storing (s)                   0.0154783\n",
      "time/evaluation sampling (s)            1.47482\n",
      "time/exploration sampling (s)           0.203828\n",
      "time/logging (s)                        0.0119083\n",
      "time/preback_alpha (s)                  0.608261\n",
      "time/preback_policy (s)                 1.10641\n",
      "time/preback_start (s)                  0.130749\n",
      "time/preback_zf (s)                     5.20316\n",
      "time/saving (s)                         0.00578744\n",
      "time/training (s)                       2.41466\n",
      "time/epoch (s)                         17.5991\n",
      "time/total (s)                       1789.49\n",
      "Epoch                                 110\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:22:16.463560 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 111 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 122000\n",
      "trainer/ZF1 Loss                      412.961\n",
      "trainer/ZF2 Loss                      376.402\n",
      "trainer/ZF Expert Reward               20.4587\n",
      "trainer/ZF Policy Reward                6.83364\n",
      "trainer/ZF CHI2 Term                  408.581\n",
      "trainer/Policy Loss                  -810.397\n",
      "trainer/Bias Loss                     632.883\n",
      "trainer/Bias Value                     10.9845\n",
      "trainer/Policy Grad Norm              158.937\n",
      "trainer/Policy Param Norm              30.8861\n",
      "trainer/Zf1 Grad Norm                5944.59\n",
      "trainer/Zf1 Param Norm                 83.0106\n",
      "trainer/Zf2 Grad Norm                5375.49\n",
      "trainer/Zf2 Param Norm                 80.9926\n",
      "trainer/Z Expert Predictions Mean    1147.16\n",
      "trainer/Z Expert Predictions Std      164.413\n",
      "trainer/Z Expert Predictions Max     1328.71\n",
      "trainer/Z Expert Predictions Min      507.451\n",
      "trainer/Z Policy Predictions Mean     805.373\n",
      "trainer/Z Policy Predictions Std      363.264\n",
      "trainer/Z Policy Predictions Max     1294.01\n",
      "trainer/Z Policy Predictions Min      -44.9777\n",
      "trainer/Z Expert Targets Mean        1126.7\n",
      "trainer/Z Expert Targets Std          172.39\n",
      "trainer/Z Expert Targets Max         1312.21\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         798.539\n",
      "trainer/Z Policy Targets Std          361.472\n",
      "trainer/Z Policy Targets Max         1283.18\n",
      "trainer/Z Policy Targets Min          -94.7134\n",
      "trainer/Log Pis Mean                   27.4942\n",
      "trainer/Log Pis Std                     7.67261\n",
      "trainer/Policy mu Mean                  1.21209\n",
      "trainer/Policy mu Std                   2.36806\n",
      "trainer/Policy log std Mean            -3.31302\n",
      "trainer/Policy log std Std              1.16265\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        116109\n",
      "exploration/num paths total           882\n",
      "evaluation/num steps total         580119\n",
      "evaluation/num paths total           1123\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12766\n",
      "evaluation/Rewards Std                  1.31518\n",
      "evaluation/Rewards Max                  7.03255\n",
      "evaluation/Rewards Min                  0.0724706\n",
      "evaluation/Returns Mean              5127.66\n",
      "evaluation/Returns Std                 12.1392\n",
      "evaluation/Returns Max               5148.47\n",
      "evaluation/Returns Min               5103.98\n",
      "evaluation/Estimation Bias Mean      1139.81\n",
      "evaluation/Estimation Bias Std        193.793\n",
      "evaluation/EB/Q_True Mean              48.4338\n",
      "evaluation/EB/Q_True Std              149.63\n",
      "evaluation/EB/Q_Pred Mean            1188.25\n",
      "evaluation/EB/Q_Pred Std              125.732\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5127.66\n",
      "evaluation/Actions Mean                 0.49965\n",
      "evaluation/Actions Std                  0.642307\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                2.01889\n",
      "time/backward_zf1 (s)                   2.17954\n",
      "time/backward_zf2 (s)                   2.07835\n",
      "time/data sampling (s)                  0.271025\n",
      "time/data storing (s)                   0.0168537\n",
      "time/evaluation sampling (s)            1.42217\n",
      "time/exploration sampling (s)           0.220016\n",
      "time/logging (s)                        0.0121954\n",
      "time/preback_alpha (s)                  0.610951\n",
      "time/preback_policy (s)                 1.16625\n",
      "time/preback_start (s)                  0.132323\n",
      "time/preback_zf (s)                     5.22532\n",
      "time/saving (s)                         0.00567017\n",
      "time/training (s)                       2.32515\n",
      "time/epoch (s)                         17.6847\n",
      "time/total (s)                       1807.2\n",
      "Epoch                                 111\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:22:34.451487 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 112 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 123000\n",
      "trainer/ZF1 Loss                       24.2077\n",
      "trainer/ZF2 Loss                       22.5716\n",
      "trainer/ZF Expert Reward               11.2507\n",
      "trainer/ZF Policy Reward               -1.52671\n",
      "trainer/ZF CHI2 Term                   36.4381\n",
      "trainer/Policy Loss                  -813.735\n",
      "trainer/Bias Loss                     107.456\n",
      "trainer/Bias Value                     10.9911\n",
      "trainer/Policy Grad Norm              218.758\n",
      "trainer/Policy Param Norm              30.9446\n",
      "trainer/Zf1 Grad Norm                3273.67\n",
      "trainer/Zf1 Param Norm                 83.2379\n",
      "trainer/Zf2 Grad Norm                2440.6\n",
      "trainer/Zf2 Param Norm                 81.2119\n",
      "trainer/Z Expert Predictions Mean    1164.22\n",
      "trainer/Z Expert Predictions Std      138.782\n",
      "trainer/Z Expert Predictions Max     1334.06\n",
      "trainer/Z Expert Predictions Min      594.224\n",
      "trainer/Z Policy Predictions Mean     800.605\n",
      "trainer/Z Policy Predictions Std      389.408\n",
      "trainer/Z Policy Predictions Max     1316.89\n",
      "trainer/Z Policy Predictions Min      -51.6495\n",
      "trainer/Z Expert Targets Mean        1152.97\n",
      "trainer/Z Expert Targets Std          136.71\n",
      "trainer/Z Expert Targets Max         1307.21\n",
      "trainer/Z Expert Targets Min          597.448\n",
      "trainer/Z Policy Targets Mean         802.131\n",
      "trainer/Z Policy Targets Std          383.408\n",
      "trainer/Z Policy Targets Max         1303.36\n",
      "trainer/Z Policy Targets Min          -42.0744\n",
      "trainer/Log Pis Mean                   27.1046\n",
      "trainer/Log Pis Std                     7.85377\n",
      "trainer/Policy mu Mean                  1.22647\n",
      "trainer/Policy mu Std                   2.3842\n",
      "trainer/Policy log std Mean            -3.15002\n",
      "trainer/Policy log std Std              1.2384\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        117109\n",
      "exploration/num paths total           883\n",
      "evaluation/num steps total         589779\n",
      "evaluation/num paths total           1133\n",
      "evaluation/path length Mean           966\n",
      "evaluation/path length Std             58.0741\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            834\n",
      "evaluation/Rewards Mean                 5.04663\n",
      "evaluation/Rewards Std                  1.3292\n",
      "evaluation/Rewards Max                  7.35031\n",
      "evaluation/Rewards Min                  0.110512\n",
      "evaluation/Returns Mean              4875.04\n",
      "evaluation/Returns Std                424.238\n",
      "evaluation/Returns Max               5226.06\n",
      "evaluation/Returns Min               3973.04\n",
      "evaluation/Estimation Bias Mean      1097.78\n",
      "evaluation/Estimation Bias Std        253.259\n",
      "evaluation/EB/Q_True Mean              50.6581\n",
      "evaluation/EB/Q_True Std              153.229\n",
      "evaluation/EB/Q_Pred Mean            1148.44\n",
      "evaluation/EB/Q_Pred Std              174.374\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4875.04\n",
      "evaluation/Actions Mean                 0.498986\n",
      "evaluation/Actions Std                  0.637701\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.08719\n",
      "time/backward_zf1 (s)                   2.29652\n",
      "time/backward_zf2 (s)                   2.20483\n",
      "time/data sampling (s)                  0.279208\n",
      "time/data storing (s)                   0.0157084\n",
      "time/evaluation sampling (s)            1.45365\n",
      "time/exploration sampling (s)           0.207397\n",
      "time/logging (s)                        0.0129044\n",
      "time/preback_alpha (s)                  0.604927\n",
      "time/preback_policy (s)                 1.23878\n",
      "time/preback_start (s)                  0.130825\n",
      "time/preback_zf (s)                     5.1978\n",
      "time/saving (s)                         0.00535464\n",
      "time/training (s)                       2.1828\n",
      "time/epoch (s)                         17.9179\n",
      "time/total (s)                       1825.14\n",
      "Epoch                                 112\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:22:52.548205 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 113 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 124000\n",
      "trainer/ZF1 Loss                      340.585\n",
      "trainer/ZF2 Loss                      336.08\n",
      "trainer/ZF Expert Reward               11.8122\n",
      "trainer/ZF Policy Reward                2.27439\n",
      "trainer/ZF CHI2 Term                  348.141\n",
      "trainer/Policy Loss                  -834.968\n",
      "trainer/Bias Loss                     194.829\n",
      "trainer/Bias Value                     10.9979\n",
      "trainer/Policy Grad Norm              229.153\n",
      "trainer/Policy Param Norm              31.0011\n",
      "trainer/Zf1 Grad Norm                3752.47\n",
      "trainer/Zf1 Param Norm                 83.4452\n",
      "trainer/Zf2 Grad Norm                3761.69\n",
      "trainer/Zf2 Param Norm                 81.428\n",
      "trainer/Z Expert Predictions Mean    1175.47\n",
      "trainer/Z Expert Predictions Std      137.257\n",
      "trainer/Z Expert Predictions Max     1343.77\n",
      "trainer/Z Expert Predictions Min      603.285\n",
      "trainer/Z Policy Predictions Mean     825.097\n",
      "trainer/Z Policy Predictions Std      369.837\n",
      "trainer/Z Policy Predictions Max     1298.03\n",
      "trainer/Z Policy Predictions Min      -51.9774\n",
      "trainer/Z Expert Targets Mean        1163.66\n",
      "trainer/Z Expert Targets Std          136.711\n",
      "trainer/Z Expert Targets Max         1323.91\n",
      "trainer/Z Expert Targets Min          604.284\n",
      "trainer/Z Policy Targets Mean         822.822\n",
      "trainer/Z Policy Targets Std          370.894\n",
      "trainer/Z Policy Targets Max         1283.59\n",
      "trainer/Z Policy Targets Min          -41.7329\n",
      "trainer/Log Pis Mean                   27.0954\n",
      "trainer/Log Pis Std                     7.53966\n",
      "trainer/Policy mu Mean                  1.09568\n",
      "trainer/Policy mu Std                   2.38881\n",
      "trainer/Policy log std Mean            -3.29132\n",
      "trainer/Policy log std Std              1.1973\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        119109\n",
      "exploration/num paths total           885\n",
      "evaluation/num steps total         598905\n",
      "evaluation/num paths total           1143\n",
      "evaluation/path length Mean           912.6\n",
      "evaluation/path length Std            112.773\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            665\n",
      "evaluation/Rewards Mean                 4.90993\n",
      "evaluation/Rewards Std                  1.31524\n",
      "evaluation/Rewards Max                  8.44154\n",
      "evaluation/Rewards Min                  0.106187\n",
      "evaluation/Returns Mean              4480.8\n",
      "evaluation/Returns Std                641.055\n",
      "evaluation/Returns Max               5088.21\n",
      "evaluation/Returns Min               3134.86\n",
      "evaluation/Estimation Bias Mean      1055.79\n",
      "evaluation/Estimation Bias Std        280.998\n",
      "evaluation/EB/Q_True Mean              52.6846\n",
      "evaluation/EB/Q_True Std              154.591\n",
      "evaluation/EB/Q_Pred Mean            1108.48\n",
      "evaluation/EB/Q_Pred Std              206.467\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4480.8\n",
      "evaluation/Actions Mean                 0.502927\n",
      "evaluation/Actions Std                  0.640185\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.01763\n",
      "time/backward_zf1 (s)                   2.22688\n",
      "time/backward_zf2 (s)                   2.12564\n",
      "time/data sampling (s)                  0.300693\n",
      "time/data storing (s)                   0.0170822\n",
      "time/evaluation sampling (s)            1.45585\n",
      "time/exploration sampling (s)           0.215001\n",
      "time/logging (s)                        0.0110236\n",
      "time/preback_alpha (s)                  0.625271\n",
      "time/preback_policy (s)                 1.15276\n",
      "time/preback_start (s)                  0.136311\n",
      "time/preback_zf (s)                     5.27166\n",
      "time/saving (s)                         0.00585923\n",
      "time/training (s)                       2.46128\n",
      "time/epoch (s)                         18.023\n",
      "time/total (s)                       1843.18\n",
      "Epoch                                 113\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:23:10.802743 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 114 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 125000\n",
      "trainer/ZF1 Loss                       45.9275\n",
      "trainer/ZF2 Loss                       27.6803\n",
      "trainer/ZF Expert Reward               12.7248\n",
      "trainer/ZF Policy Reward               -2.74654\n",
      "trainer/ZF CHI2 Term                   52.5623\n",
      "trainer/Policy Loss                  -770.562\n",
      "trainer/Bias Loss                     153.94\n",
      "trainer/Bias Value                     11.0046\n",
      "trainer/Policy Grad Norm              173.114\n",
      "trainer/Policy Param Norm              31.0479\n",
      "trainer/Zf1 Grad Norm                7725.89\n",
      "trainer/Zf1 Param Norm                 83.6646\n",
      "trainer/Zf2 Grad Norm                2774.1\n",
      "trainer/Zf2 Param Norm                 81.6475\n",
      "trainer/Z Expert Predictions Mean    1162.79\n",
      "trainer/Z Expert Predictions Std      136.853\n",
      "trainer/Z Expert Predictions Max     1370.19\n",
      "trainer/Z Expert Predictions Min      613.899\n",
      "trainer/Z Policy Predictions Mean     753.322\n",
      "trainer/Z Policy Predictions Std      368.203\n",
      "trainer/Z Policy Predictions Max     1303.32\n",
      "trainer/Z Policy Predictions Min      -34.1368\n",
      "trainer/Z Expert Targets Mean        1150.07\n",
      "trainer/Z Expert Targets Std          134.431\n",
      "trainer/Z Expert Targets Max         1350.15\n",
      "trainer/Z Expert Targets Min          612.817\n",
      "trainer/Z Policy Targets Mean         756.069\n",
      "trainer/Z Policy Targets Std          363.364\n",
      "trainer/Z Policy Targets Max         1309.59\n",
      "trainer/Z Policy Targets Min          -31.6379\n",
      "trainer/Log Pis Mean                   28.7084\n",
      "trainer/Log Pis Std                     8.85321\n",
      "trainer/Policy mu Mean                  1.25875\n",
      "trainer/Policy mu Std                   2.59265\n",
      "trainer/Policy log std Mean            -3.225\n",
      "trainer/Policy log std Std              1.25559\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        120109\n",
      "exploration/num paths total           886\n",
      "evaluation/num steps total         608280\n",
      "evaluation/num paths total           1153\n",
      "evaluation/path length Mean           937.5\n",
      "evaluation/path length Std            111.618\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            647\n",
      "evaluation/Rewards Mean                 5.04548\n",
      "evaluation/Rewards Std                  1.3542\n",
      "evaluation/Rewards Max                  7.39127\n",
      "evaluation/Rewards Min                  0.0761185\n",
      "evaluation/Returns Mean              4730.14\n",
      "evaluation/Returns Std                683.268\n",
      "evaluation/Returns Max               5227.25\n",
      "evaluation/Returns Min               3067.68\n",
      "evaluation/Estimation Bias Mean      1125.31\n",
      "evaluation/Estimation Bias Std        255.658\n",
      "evaluation/EB/Q_True Mean              50.1202\n",
      "evaluation/EB/Q_True Std              149.189\n",
      "evaluation/EB/Q_Pred Mean            1175.43\n",
      "evaluation/EB/Q_Pred Std              178.077\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4730.14\n",
      "evaluation/Actions Mean                 0.502543\n",
      "evaluation/Actions Std                  0.641702\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.10051\n",
      "time/backward_zf1 (s)                   2.2581\n",
      "time/backward_zf2 (s)                   2.16627\n",
      "time/data sampling (s)                  0.311925\n",
      "time/data storing (s)                   0.0159782\n",
      "time/evaluation sampling (s)            1.49571\n",
      "time/exploration sampling (s)           0.215705\n",
      "time/logging (s)                        0.0121113\n",
      "time/preback_alpha (s)                  0.630032\n",
      "time/preback_policy (s)                 1.20253\n",
      "time/preback_start (s)                  0.136652\n",
      "time/preback_zf (s)                     5.2438\n",
      "time/saving (s)                         0.00584245\n",
      "time/training (s)                       2.3873\n",
      "time/epoch (s)                         18.1825\n",
      "time/total (s)                       1861.38\n",
      "Epoch                                 114\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:23:28.796679 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 115 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 126000\n",
      "trainer/ZF1 Loss                      179.026\n",
      "trainer/ZF2 Loss                      154.846\n",
      "trainer/ZF Expert Reward               24.1432\n",
      "trainer/ZF Policy Reward                0.309854\n",
      "trainer/ZF CHI2 Term                  191.052\n",
      "trainer/Policy Loss                  -814.365\n",
      "trainer/Bias Loss                    1617.57\n",
      "trainer/Bias Value                     11.0116\n",
      "trainer/Policy Grad Norm              176.527\n",
      "trainer/Policy Param Norm              31.0998\n",
      "trainer/Zf1 Grad Norm                3864.74\n",
      "trainer/Zf1 Param Norm                 83.9056\n",
      "trainer/Zf2 Grad Norm                3533.89\n",
      "trainer/Zf2 Param Norm                 81.8841\n",
      "trainer/Z Expert Predictions Mean    1171.79\n",
      "trainer/Z Expert Predictions Std      137.164\n",
      "trainer/Z Expert Predictions Max     1372.11\n",
      "trainer/Z Expert Predictions Min      629.822\n",
      "trainer/Z Policy Predictions Mean     800.504\n",
      "trainer/Z Policy Predictions Std      368.788\n",
      "trainer/Z Policy Predictions Max     1317.38\n",
      "trainer/Z Policy Predictions Min     -106.955\n",
      "trainer/Z Expert Targets Mean        1147.65\n",
      "trainer/Z Expert Targets Std          150.86\n",
      "trainer/Z Expert Targets Max         1349.68\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         800.194\n",
      "trainer/Z Policy Targets Std          362.852\n",
      "trainer/Z Policy Targets Max         1323.55\n",
      "trainer/Z Policy Targets Min          -53.1676\n",
      "trainer/Log Pis Mean                   28.284\n",
      "trainer/Log Pis Std                     8.69527\n",
      "trainer/Policy mu Mean                  1.25982\n",
      "trainer/Policy mu Std                   2.45102\n",
      "trainer/Policy log std Mean            -3.32021\n",
      "trainer/Policy log std Std              1.23998\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        121109\n",
      "exploration/num paths total           887\n",
      "evaluation/num steps total         617479\n",
      "evaluation/num paths total           1163\n",
      "evaluation/path length Mean           919.9\n",
      "evaluation/path length Std            128.021\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            626\n",
      "evaluation/Rewards Mean                 4.93051\n",
      "evaluation/Rewards Std                  1.31841\n",
      "evaluation/Rewards Max                  7.25449\n",
      "evaluation/Rewards Min                  0.13152\n",
      "evaluation/Returns Mean              4535.58\n",
      "evaluation/Returns Std                768.113\n",
      "evaluation/Returns Max               5165.55\n",
      "evaluation/Returns Min               2876.63\n",
      "evaluation/Estimation Bias Mean      1086.42\n",
      "evaluation/Estimation Bias Std        250.998\n",
      "evaluation/EB/Q_True Mean              50.8063\n",
      "evaluation/EB/Q_True Std              150.35\n",
      "evaluation/EB/Q_Pred Mean            1137.23\n",
      "evaluation/EB/Q_Pred Std              178.203\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4535.58\n",
      "evaluation/Actions Mean                 0.503741\n",
      "evaluation/Actions Std                  0.6383\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97389\n",
      "time/backward_zf1 (s)                   2.19496\n",
      "time/backward_zf2 (s)                   2.06524\n",
      "time/data sampling (s)                  0.307154\n",
      "time/data storing (s)                   0.0159763\n",
      "time/evaluation sampling (s)            1.47081\n",
      "time/exploration sampling (s)           0.212852\n",
      "time/logging (s)                        0.016722\n",
      "time/preback_alpha (s)                  0.613029\n",
      "time/preback_policy (s)                 1.09056\n",
      "time/preback_start (s)                  0.134768\n",
      "time/preback_zf (s)                     5.25244\n",
      "time/saving (s)                         0.00873029\n",
      "time/training (s)                       2.56662\n",
      "time/epoch (s)                         17.9237\n",
      "time/total (s)                       1879.33\n",
      "Epoch                                 115\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:23:46.542572 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 116 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 127000\n",
      "trainer/ZF1 Loss                       34.8784\n",
      "trainer/ZF2 Loss                       32.9959\n",
      "trainer/ZF Expert Reward               15.6038\n",
      "trainer/ZF Policy Reward               -0.945601\n",
      "trainer/ZF CHI2 Term                   50.7675\n",
      "trainer/Policy Loss                  -830.448\n",
      "trainer/Bias Loss                     136.095\n",
      "trainer/Bias Value                     11.0183\n",
      "trainer/Policy Grad Norm              189.913\n",
      "trainer/Policy Param Norm              31.1431\n",
      "trainer/Zf1 Grad Norm                2640.73\n",
      "trainer/Zf1 Param Norm                 84.1232\n",
      "trainer/Zf2 Grad Norm                2295.03\n",
      "trainer/Zf2 Param Norm                 82.0961\n",
      "trainer/Z Expert Predictions Mean    1178.57\n",
      "trainer/Z Expert Predictions Std      130.197\n",
      "trainer/Z Expert Predictions Max     1344.79\n",
      "trainer/Z Expert Predictions Min      638.433\n",
      "trainer/Z Policy Predictions Mean     820.234\n",
      "trainer/Z Policy Predictions Std      358.6\n",
      "trainer/Z Policy Predictions Max     1342.33\n",
      "trainer/Z Policy Predictions Min       -9.89721\n",
      "trainer/Z Expert Targets Mean        1162.97\n",
      "trainer/Z Expert Targets Std          128.1\n",
      "trainer/Z Expert Targets Max         1331.65\n",
      "trainer/Z Expert Targets Min          645.575\n",
      "trainer/Z Policy Targets Mean         821.18\n",
      "trainer/Z Policy Targets Std          351.098\n",
      "trainer/Z Policy Targets Max         1334.01\n",
      "trainer/Z Policy Targets Min           -6.82304\n",
      "trainer/Log Pis Mean                   28.0879\n",
      "trainer/Log Pis Std                     7.58995\n",
      "trainer/Policy mu Mean                  1.23287\n",
      "trainer/Policy mu Std                   2.42005\n",
      "trainer/Policy log std Mean            -3.28528\n",
      "trainer/Policy log std Std              1.21\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        124109\n",
      "exploration/num paths total           890\n",
      "evaluation/num steps total         627247\n",
      "evaluation/num paths total           1173\n",
      "evaluation/path length Mean           976.8\n",
      "evaluation/path length Std             69.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            768\n",
      "evaluation/Rewards Mean                 4.63715\n",
      "evaluation/Rewards Std                  1.23316\n",
      "evaluation/Rewards Max                  7.11427\n",
      "evaluation/Rewards Min                  0.0943425\n",
      "evaluation/Returns Mean              4529.57\n",
      "evaluation/Returns Std                381.57\n",
      "evaluation/Returns Max               4788.5\n",
      "evaluation/Returns Min               3447.88\n",
      "evaluation/Estimation Bias Mean       991.943\n",
      "evaluation/Estimation Bias Std        237.466\n",
      "evaluation/EB/Q_True Mean              45.8016\n",
      "evaluation/EB/Q_True Std              139.424\n",
      "evaluation/EB/Q_Pred Mean            1037.75\n",
      "evaluation/EB/Q_Pred Std              174.309\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4529.57\n",
      "evaluation/Actions Mean                 0.510941\n",
      "evaluation/Actions Std                  0.632394\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93882\n",
      "time/backward_zf1 (s)                   2.15614\n",
      "time/backward_zf2 (s)                   2.02579\n",
      "time/data sampling (s)                  0.312526\n",
      "time/data storing (s)                   0.0149082\n",
      "time/evaluation sampling (s)            1.42911\n",
      "time/exploration sampling (s)           0.21219\n",
      "time/logging (s)                        0.0117243\n",
      "time/preback_alpha (s)                  0.619714\n",
      "time/preback_policy (s)                 1.11431\n",
      "time/preback_start (s)                  0.134478\n",
      "time/preback_zf (s)                     5.22151\n",
      "time/saving (s)                         0.00591861\n",
      "time/training (s)                       2.4679\n",
      "time/epoch (s)                         17.665\n",
      "time/total (s)                       1897.02\n",
      "Epoch                                 116\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:24:04.598408 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 117 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 128000\n",
      "trainer/ZF1 Loss                       28.6995\n",
      "trainer/ZF2 Loss                       25.0852\n",
      "trainer/ZF Expert Reward               15.0265\n",
      "trainer/ZF Policy Reward               -0.168972\n",
      "trainer/ZF CHI2 Term                   42.3768\n",
      "trainer/Policy Loss                  -839.148\n",
      "trainer/Bias Loss                     104.066\n",
      "trainer/Bias Value                     11.0249\n",
      "trainer/Policy Grad Norm              245.801\n",
      "trainer/Policy Param Norm              31.1877\n",
      "trainer/Zf1 Grad Norm                2677.51\n",
      "trainer/Zf1 Param Norm                 84.3294\n",
      "trainer/Zf2 Grad Norm                1813.58\n",
      "trainer/Zf2 Param Norm                 82.3052\n",
      "trainer/Z Expert Predictions Mean    1194.02\n",
      "trainer/Z Expert Predictions Std      117.42\n",
      "trainer/Z Expert Predictions Max     1336.6\n",
      "trainer/Z Expert Predictions Min      616.041\n",
      "trainer/Z Policy Predictions Mean     828.139\n",
      "trainer/Z Policy Predictions Std      342.502\n",
      "trainer/Z Policy Predictions Max     1315.65\n",
      "trainer/Z Policy Predictions Min      -14.2272\n",
      "trainer/Z Expert Targets Mean        1178.99\n",
      "trainer/Z Expert Targets Std          116.827\n",
      "trainer/Z Expert Targets Max         1325.6\n",
      "trainer/Z Expert Targets Min          618.736\n",
      "trainer/Z Policy Targets Mean         828.308\n",
      "trainer/Z Policy Targets Std          339.548\n",
      "trainer/Z Policy Targets Max         1312.72\n",
      "trainer/Z Policy Targets Min           -5.07988\n",
      "trainer/Log Pis Mean                   28.906\n",
      "trainer/Log Pis Std                     7.75225\n",
      "trainer/Policy mu Mean                  1.23336\n",
      "trainer/Policy mu Std                   2.50558\n",
      "trainer/Policy log std Mean            -3.37305\n",
      "trainer/Policy log std Std              1.30071\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        124109\n",
      "exploration/num paths total           890\n",
      "evaluation/num steps total         637247\n",
      "evaluation/num paths total           1183\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12554\n",
      "evaluation/Rewards Std                  1.31152\n",
      "evaluation/Rewards Max                  7.34215\n",
      "evaluation/Rewards Min                  0.082365\n",
      "evaluation/Returns Mean              5125.54\n",
      "evaluation/Returns Std                 15.8012\n",
      "evaluation/Returns Max               5153.14\n",
      "evaluation/Returns Min               5106.59\n",
      "evaluation/Estimation Bias Mean      1146.24\n",
      "evaluation/Estimation Bias Std        188.552\n",
      "evaluation/EB/Q_True Mean              48.7222\n",
      "evaluation/EB/Q_True Std              150.294\n",
      "evaluation/EB/Q_Pred Mean            1194.96\n",
      "evaluation/EB/Q_Pred Std              119.375\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5125.54\n",
      "evaluation/Actions Mean                 0.506172\n",
      "evaluation/Actions Std                  0.640218\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.99383\n",
      "time/backward_zf1 (s)                   2.23405\n",
      "time/backward_zf2 (s)                   2.10587\n",
      "time/data sampling (s)                  0.318175\n",
      "time/data storing (s)                   0.0150509\n",
      "time/evaluation sampling (s)            1.49303\n",
      "time/exploration sampling (s)           0.209868\n",
      "time/logging (s)                        0.0128295\n",
      "time/preback_alpha (s)                  0.626183\n",
      "time/preback_policy (s)                 1.16278\n",
      "time/preback_start (s)                  0.135451\n",
      "time/preback_zf (s)                     5.29007\n",
      "time/saving (s)                         0.00881958\n",
      "time/training (s)                       2.37497\n",
      "time/epoch (s)                         17.981\n",
      "time/total (s)                       1915.02\n",
      "Epoch                                 117\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:24:21.538221 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 118 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 129000\n",
      "trainer/ZF1 Loss                       27.0362\n",
      "trainer/ZF2 Loss                       25.9838\n",
      "trainer/ZF Expert Reward               14.7102\n",
      "trainer/ZF Policy Reward               -4.23418\n",
      "trainer/ZF CHI2 Term                   45.7348\n",
      "trainer/Policy Loss                  -806.738\n",
      "trainer/Bias Loss                     123.711\n",
      "trainer/Bias Value                     11.0315\n",
      "trainer/Policy Grad Norm              221.105\n",
      "trainer/Policy Param Norm              31.2249\n",
      "trainer/Zf1 Grad Norm                2222.77\n",
      "trainer/Zf1 Param Norm                 84.5409\n",
      "trainer/Zf2 Grad Norm                2467.12\n",
      "trainer/Zf2 Param Norm                 82.5183\n",
      "trainer/Z Expert Predictions Mean    1165.29\n",
      "trainer/Z Expert Predictions Std      140.929\n",
      "trainer/Z Expert Predictions Max     1359.33\n",
      "trainer/Z Expert Predictions Min      634.195\n",
      "trainer/Z Policy Predictions Mean     790.822\n",
      "trainer/Z Policy Predictions Std      357.665\n",
      "trainer/Z Policy Predictions Max     1312.89\n",
      "trainer/Z Policy Predictions Min      -30.0756\n",
      "trainer/Z Expert Targets Mean        1150.58\n",
      "trainer/Z Expert Targets Std          136.932\n",
      "trainer/Z Expert Targets Max         1334.72\n",
      "trainer/Z Expert Targets Min          637.575\n",
      "trainer/Z Policy Targets Mean         795.056\n",
      "trainer/Z Policy Targets Std          350.311\n",
      "trainer/Z Policy Targets Max         1321.43\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   28.0377\n",
      "trainer/Log Pis Std                     7.87853\n",
      "trainer/Policy mu Mean                  1.34687\n",
      "trainer/Policy mu Std                   2.37155\n",
      "trainer/Policy log std Mean            -3.23305\n",
      "trainer/Policy log std Std              1.28954\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        124109\n",
      "exploration/num paths total           890\n",
      "evaluation/num steps total         646219\n",
      "evaluation/num paths total           1193\n",
      "evaluation/path length Mean           897.2\n",
      "evaluation/path length Std            125.175\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            689\n",
      "evaluation/Rewards Mean                 4.61561\n",
      "evaluation/Rewards Std                  1.2906\n",
      "evaluation/Rewards Max                  7.31607\n",
      "evaluation/Rewards Min                  0.0868817\n",
      "evaluation/Returns Mean              4141.12\n",
      "evaluation/Returns Std                735.554\n",
      "evaluation/Returns Max               5052.7\n",
      "evaluation/Returns Min               3048.98\n",
      "evaluation/Estimation Bias Mean       962.081\n",
      "evaluation/Estimation Bias Std        265.801\n",
      "evaluation/EB/Q_True Mean              48.703\n",
      "evaluation/EB/Q_True Std              142.499\n",
      "evaluation/EB/Q_Pred Mean            1010.78\n",
      "evaluation/EB/Q_Pred Std              218.401\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4141.12\n",
      "evaluation/Actions Mean                 0.499542\n",
      "evaluation/Actions Std                  0.63982\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76894\n",
      "time/backward_zf1 (s)                   1.95825\n",
      "time/backward_zf2 (s)                   1.88022\n",
      "time/data sampling (s)                  0.263613\n",
      "time/data storing (s)                   0.0133623\n",
      "time/evaluation sampling (s)            1.4846\n",
      "time/exploration sampling (s)           0.188868\n",
      "time/logging (s)                        0.0108291\n",
      "time/preback_alpha (s)                  0.574857\n",
      "time/preback_policy (s)                 1.00651\n",
      "time/preback_start (s)                  0.124559\n",
      "time/preback_zf (s)                     5.11862\n",
      "time/saving (s)                         0.00567774\n",
      "time/training (s)                       2.46743\n",
      "time/epoch (s)                         16.8663\n",
      "time/total (s)                       1931.91\n",
      "Epoch                                 118\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:24:39.226693 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 119 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 130000\n",
      "trainer/ZF1 Loss                      196.63\n",
      "trainer/ZF2 Loss                      184.182\n",
      "trainer/ZF Expert Reward               15.1213\n",
      "trainer/ZF Policy Reward               -3.37355\n",
      "trainer/ZF CHI2 Term                  209.184\n",
      "trainer/Policy Loss                  -860.394\n",
      "trainer/Bias Loss                    1826.57\n",
      "trainer/Bias Value                     11.0383\n",
      "trainer/Policy Grad Norm              187.093\n",
      "trainer/Policy Param Norm              31.2624\n",
      "trainer/Zf1 Grad Norm                5039.57\n",
      "trainer/Zf1 Param Norm                 84.7577\n",
      "trainer/Zf2 Grad Norm                3795.12\n",
      "trainer/Zf2 Param Norm                 82.7373\n",
      "trainer/Z Expert Predictions Mean    1180.31\n",
      "trainer/Z Expert Predictions Std      124.048\n",
      "trainer/Z Expert Predictions Max     1347.94\n",
      "trainer/Z Expert Predictions Min      656.415\n",
      "trainer/Z Policy Predictions Mean     848.707\n",
      "trainer/Z Policy Predictions Std      352.489\n",
      "trainer/Z Policy Predictions Max     1297.43\n",
      "trainer/Z Policy Predictions Min      -44.5315\n",
      "trainer/Z Expert Targets Mean        1165.19\n",
      "trainer/Z Expert Targets Std          141.109\n",
      "trainer/Z Expert Targets Max         1326.98\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         852.081\n",
      "trainer/Z Policy Targets Std          349.498\n",
      "trainer/Z Policy Targets Max         1282.33\n",
      "trainer/Z Policy Targets Min          -13.5142\n",
      "trainer/Log Pis Mean                   28.2851\n",
      "trainer/Log Pis Std                     8.16073\n",
      "trainer/Policy mu Mean                  1.21361\n",
      "trainer/Policy mu Std                   2.48202\n",
      "trainer/Policy log std Mean            -3.27451\n",
      "trainer/Policy log std Std              1.23095\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        125109\n",
      "exploration/num paths total           891\n",
      "evaluation/num steps total         656219\n",
      "evaluation/num paths total           1203\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14838\n",
      "evaluation/Rewards Std                  1.31529\n",
      "evaluation/Rewards Max                  7.13748\n",
      "evaluation/Rewards Min                  0.0852226\n",
      "evaluation/Returns Mean              5148.38\n",
      "evaluation/Returns Std                 13.3517\n",
      "evaluation/Returns Max               5178.17\n",
      "evaluation/Returns Min               5136.98\n",
      "evaluation/Estimation Bias Mean      1160.46\n",
      "evaluation/Estimation Bias Std        189.832\n",
      "evaluation/EB/Q_True Mean              48.9527\n",
      "evaluation/EB/Q_True Std              151.381\n",
      "evaluation/EB/Q_Pred Mean            1209.42\n",
      "evaluation/EB/Q_Pred Std              116.308\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5148.38\n",
      "evaluation/Actions Mean                 0.505177\n",
      "evaluation/Actions Std                  0.632032\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.06232\n",
      "time/backward_zf1 (s)                   2.17417\n",
      "time/backward_zf2 (s)                   2.14223\n",
      "time/data sampling (s)                  0.266553\n",
      "time/data storing (s)                   0.0153497\n",
      "time/evaluation sampling (s)            1.47524\n",
      "time/exploration sampling (s)           0.206552\n",
      "time/logging (s)                        0.0125725\n",
      "time/preback_alpha (s)                  0.583132\n",
      "time/preback_policy (s)                 1.21034\n",
      "time/preback_start (s)                  0.127911\n",
      "time/preback_zf (s)                     5.13446\n",
      "time/saving (s)                         0.0070864\n",
      "time/training (s)                       2.20593\n",
      "time/epoch (s)                         17.6238\n",
      "time/total (s)                       1949.55\n",
      "Epoch                                 119\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:24:56.126943 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 120 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 131000\n",
      "trainer/ZF1 Loss                       35.873\n",
      "trainer/ZF2 Loss                       32.1007\n",
      "trainer/ZF Expert Reward               24.6512\n",
      "trainer/ZF Policy Reward                5.87404\n",
      "trainer/ZF CHI2 Term                   53.0644\n",
      "trainer/Policy Loss                  -812.953\n",
      "trainer/Bias Loss                     200.471\n",
      "trainer/Bias Value                     11.0453\n",
      "trainer/Policy Grad Norm              202.669\n",
      "trainer/Policy Param Norm              31.3032\n",
      "trainer/Zf1 Grad Norm                2636.63\n",
      "trainer/Zf1 Param Norm                 84.9817\n",
      "trainer/Zf2 Grad Norm                2586.23\n",
      "trainer/Zf2 Param Norm                 82.9606\n",
      "trainer/Z Expert Predictions Mean    1187.29\n",
      "trainer/Z Expert Predictions Std      135.2\n",
      "trainer/Z Expert Predictions Max     1340.54\n",
      "trainer/Z Expert Predictions Min      637.991\n",
      "trainer/Z Policy Predictions Mean     796.013\n",
      "trainer/Z Policy Predictions Std      368.114\n",
      "trainer/Z Policy Predictions Max     1297.61\n",
      "trainer/Z Policy Predictions Min        0.895393\n",
      "trainer/Z Expert Targets Mean        1162.64\n",
      "trainer/Z Expert Targets Std          133.158\n",
      "trainer/Z Expert Targets Max         1318.69\n",
      "trainer/Z Expert Targets Min          635.467\n",
      "trainer/Z Policy Targets Mean         790.139\n",
      "trainer/Z Policy Targets Std          362.347\n",
      "trainer/Z Policy Targets Max         1278.59\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   30.0422\n",
      "trainer/Log Pis Std                     8.79255\n",
      "trainer/Policy mu Mean                  1.34797\n",
      "trainer/Policy mu Std                   2.6323\n",
      "trainer/Policy log std Mean            -3.24943\n",
      "trainer/Policy log std Std              1.24521\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        125109\n",
      "exploration/num paths total           891\n",
      "evaluation/num steps total         666102\n",
      "evaluation/num paths total           1213\n",
      "evaluation/path length Mean           988.3\n",
      "evaluation/path length Std             35.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            883\n",
      "evaluation/Rewards Mean                 5.108\n",
      "evaluation/Rewards Std                  1.30923\n",
      "evaluation/Rewards Max                  7.35481\n",
      "evaluation/Rewards Min                  0.0968035\n",
      "evaluation/Returns Mean              5048.24\n",
      "evaluation/Returns Std                178.805\n",
      "evaluation/Returns Max               5126.22\n",
      "evaluation/Returns Min               4512.83\n",
      "evaluation/Estimation Bias Mean      1141.33\n",
      "evaluation/Estimation Bias Std        215.265\n",
      "evaluation/EB/Q_True Mean              48.9012\n",
      "evaluation/EB/Q_True Std              150.069\n",
      "evaluation/EB/Q_Pred Mean            1190.23\n",
      "evaluation/EB/Q_Pred Std              130.609\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5048.24\n",
      "evaluation/Actions Mean                 0.50355\n",
      "evaluation/Actions Std                  0.640463\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86512\n",
      "time/backward_zf1 (s)                   2.00307\n",
      "time/backward_zf2 (s)                   1.93973\n",
      "time/data sampling (s)                  0.25516\n",
      "time/data storing (s)                   0.0138638\n",
      "time/evaluation sampling (s)            1.46503\n",
      "time/exploration sampling (s)           0.191909\n",
      "time/logging (s)                        0.0116796\n",
      "time/preback_alpha (s)                  0.56329\n",
      "time/preback_policy (s)                 1.08984\n",
      "time/preback_start (s)                  0.122635\n",
      "time/preback_zf (s)                     5.05816\n",
      "time/saving (s)                         0.00569709\n",
      "time/training (s)                       2.24604\n",
      "time/epoch (s)                         16.8312\n",
      "time/total (s)                       1966.41\n",
      "Epoch                                 120\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:25:13.461922 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 121 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 132000\n",
      "trainer/ZF1 Loss                       18.1413\n",
      "trainer/ZF2 Loss                       16.1906\n",
      "trainer/ZF Expert Reward               21.3519\n",
      "trainer/ZF Policy Reward                3.67104\n",
      "trainer/ZF CHI2 Term                   35.1311\n",
      "trainer/Policy Loss                  -849.804\n",
      "trainer/Bias Loss                     135.638\n",
      "trainer/Bias Value                     11.052\n",
      "trainer/Policy Grad Norm              190.103\n",
      "trainer/Policy Param Norm              31.3445\n",
      "trainer/Zf1 Grad Norm                1943.67\n",
      "trainer/Zf1 Param Norm                 85.1856\n",
      "trainer/Zf2 Grad Norm                1950.55\n",
      "trainer/Zf2 Param Norm                 83.1593\n",
      "trainer/Z Expert Predictions Mean    1179.52\n",
      "trainer/Z Expert Predictions Std      127.967\n",
      "trainer/Z Expert Predictions Max     1329.53\n",
      "trainer/Z Expert Predictions Min      641.49\n",
      "trainer/Z Policy Predictions Mean     834.855\n",
      "trainer/Z Policy Predictions Std      352.585\n",
      "trainer/Z Policy Predictions Max     1291.5\n",
      "trainer/Z Policy Predictions Min      -44.7552\n",
      "trainer/Z Expert Targets Mean        1158.16\n",
      "trainer/Z Expert Targets Std          126.158\n",
      "trainer/Z Expert Targets Max         1315.29\n",
      "trainer/Z Expert Targets Min          642.83\n",
      "trainer/Z Policy Targets Mean         831.184\n",
      "trainer/Z Policy Targets Std          344.933\n",
      "trainer/Z Policy Targets Max         1288.9\n",
      "trainer/Z Policy Targets Min           -6.07806\n",
      "trainer/Log Pis Mean                   28.4294\n",
      "trainer/Log Pis Std                     8.67309\n",
      "trainer/Policy mu Mean                  1.23914\n",
      "trainer/Policy mu Std                   2.57077\n",
      "trainer/Policy log std Mean            -3.25788\n",
      "trainer/Policy log std Std              1.29281\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        126109\n",
      "exploration/num paths total           892\n",
      "evaluation/num steps total         676102\n",
      "evaluation/num paths total           1223\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.85296\n",
      "evaluation/Rewards Std                  1.28722\n",
      "evaluation/Rewards Max                  7.30313\n",
      "evaluation/Rewards Min                  0.094319\n",
      "evaluation/Returns Mean              4852.96\n",
      "evaluation/Returns Std                218.489\n",
      "evaluation/Returns Max               5180.33\n",
      "evaluation/Returns Min               4402.43\n",
      "evaluation/Estimation Bias Mean      1066.23\n",
      "evaluation/Estimation Bias Std        186.203\n",
      "evaluation/EB/Q_True Mean              44.5523\n",
      "evaluation/EB/Q_True Std              137.104\n",
      "evaluation/EB/Q_Pred Mean            1110.78\n",
      "evaluation/EB/Q_Pred Std              146.817\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4852.96\n",
      "evaluation/Actions Mean                 0.508629\n",
      "evaluation/Actions Std                  0.64558\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.89186\n",
      "time/backward_zf1 (s)                   2.05896\n",
      "time/backward_zf2 (s)                   2.00395\n",
      "time/data sampling (s)                  0.28327\n",
      "time/data storing (s)                   0.0140696\n",
      "time/evaluation sampling (s)            1.38444\n",
      "time/exploration sampling (s)           0.198531\n",
      "time/logging (s)                        0.0120407\n",
      "time/preback_alpha (s)                  0.593338\n",
      "time/preback_policy (s)                 1.10305\n",
      "time/preback_start (s)                  0.129544\n",
      "time/preback_zf (s)                     5.20153\n",
      "time/saving (s)                         0.00582126\n",
      "time/training (s)                       2.38283\n",
      "time/epoch (s)                         17.2632\n",
      "time/total (s)                       1983.69\n",
      "Epoch                                 121\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:25:30.474435 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 122 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 133000\n",
      "trainer/ZF1 Loss                       27.2879\n",
      "trainer/ZF2 Loss                       26.2567\n",
      "trainer/ZF Expert Reward               15.6569\n",
      "trainer/ZF Policy Reward               -0.520993\n",
      "trainer/ZF CHI2 Term                   43.2383\n",
      "trainer/Policy Loss                  -886.437\n",
      "trainer/Bias Loss                     124.396\n",
      "trainer/Bias Value                     11.0589\n",
      "trainer/Policy Grad Norm              262.111\n",
      "trainer/Policy Param Norm              31.384\n",
      "trainer/Zf1 Grad Norm                2059.86\n",
      "trainer/Zf1 Param Norm                 85.3968\n",
      "trainer/Zf2 Grad Norm                2200.25\n",
      "trainer/Zf2 Param Norm                 83.3642\n",
      "trainer/Z Expert Predictions Mean    1179.1\n",
      "trainer/Z Expert Predictions Std      133.514\n",
      "trainer/Z Expert Predictions Max     1335.49\n",
      "trainer/Z Expert Predictions Min      637.142\n",
      "trainer/Z Policy Predictions Mean     882.178\n",
      "trainer/Z Policy Predictions Std      341.98\n",
      "trainer/Z Policy Predictions Max     1338.04\n",
      "trainer/Z Policy Predictions Min      -24.2281\n",
      "trainer/Z Expert Targets Mean        1163.45\n",
      "trainer/Z Expert Targets Std          129.463\n",
      "trainer/Z Expert Targets Max         1321.5\n",
      "trainer/Z Expert Targets Min          640.715\n",
      "trainer/Z Policy Targets Mean         882.699\n",
      "trainer/Z Policy Targets Std          336.392\n",
      "trainer/Z Policy Targets Max         1319.72\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   28.8096\n",
      "trainer/Log Pis Std                     7.8738\n",
      "trainer/Policy mu Mean                  1.23081\n",
      "trainer/Policy mu Std                   2.44223\n",
      "trainer/Policy log std Mean            -3.38294\n",
      "trainer/Policy log std Std              1.18832\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        127109\n",
      "exploration/num paths total           893\n",
      "evaluation/num steps total         686102\n",
      "evaluation/num paths total           1233\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.04992\n",
      "evaluation/Rewards Std                  1.31138\n",
      "evaluation/Rewards Max                  7.36745\n",
      "evaluation/Rewards Min                  0.0893758\n",
      "evaluation/Returns Mean              5049.92\n",
      "evaluation/Returns Std                100.244\n",
      "evaluation/Returns Max               5148.54\n",
      "evaluation/Returns Min               4788.23\n",
      "evaluation/Estimation Bias Mean      1133.97\n",
      "evaluation/Estimation Bias Std        175.757\n",
      "evaluation/EB/Q_True Mean              45.1147\n",
      "evaluation/EB/Q_True Std              139.485\n",
      "evaluation/EB/Q_Pred Mean            1179.08\n",
      "evaluation/EB/Q_Pred Std              117.611\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5049.92\n",
      "evaluation/Actions Mean                 0.514742\n",
      "evaluation/Actions Std                  0.640426\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.81071\n",
      "time/backward_zf1 (s)                   1.96599\n",
      "time/backward_zf2 (s)                   1.90351\n",
      "time/data sampling (s)                  0.272204\n",
      "time/data storing (s)                   0.0140659\n",
      "time/evaluation sampling (s)            1.58017\n",
      "time/exploration sampling (s)           0.201582\n",
      "time/logging (s)                        0.0146667\n",
      "time/preback_alpha (s)                  0.575254\n",
      "time/preback_policy (s)                 1.02969\n",
      "time/preback_start (s)                  0.126175\n",
      "time/preback_zf (s)                     5.06791\n",
      "time/saving (s)                         0.00575446\n",
      "time/training (s)                       2.38132\n",
      "time/epoch (s)                         16.949\n",
      "time/total (s)                       2000.66\n",
      "Epoch                                 122\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:25:47.088904 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 123 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 134000\n",
      "trainer/ZF1 Loss                      363.331\n",
      "trainer/ZF2 Loss                      360.553\n",
      "trainer/ZF Expert Reward               16.3901\n",
      "trainer/ZF Policy Reward                7.04913\n",
      "trainer/ZF CHI2 Term                  371.575\n",
      "trainer/Policy Loss                  -816.812\n",
      "trainer/Bias Loss                     100.377\n",
      "trainer/Bias Value                     11.0658\n",
      "trainer/Policy Grad Norm              140.3\n",
      "trainer/Policy Param Norm              31.4231\n",
      "trainer/Zf1 Grad Norm                3033.2\n",
      "trainer/Zf1 Param Norm                 85.6129\n",
      "trainer/Zf2 Grad Norm                2812.28\n",
      "trainer/Zf2 Param Norm                 83.5666\n",
      "trainer/Z Expert Predictions Mean    1185.24\n",
      "trainer/Z Expert Predictions Std      122.262\n",
      "trainer/Z Expert Predictions Max     1349.7\n",
      "trainer/Z Expert Predictions Min      681.193\n",
      "trainer/Z Policy Predictions Mean     803.902\n",
      "trainer/Z Policy Predictions Std      355.455\n",
      "trainer/Z Policy Predictions Max     1303.11\n",
      "trainer/Z Policy Predictions Min      -27.4415\n",
      "trainer/Z Expert Targets Mean        1168.85\n",
      "trainer/Z Expert Targets Std          119.122\n",
      "trainer/Z Expert Targets Max         1322.04\n",
      "trainer/Z Expert Targets Min          674.709\n",
      "trainer/Z Policy Targets Mean         796.853\n",
      "trainer/Z Policy Targets Std          355.333\n",
      "trainer/Z Policy Targets Max         1295.38\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.2413\n",
      "trainer/Log Pis Std                     8.53338\n",
      "trainer/Policy mu Mean                  1.36539\n",
      "trainer/Policy mu Std                   2.59788\n",
      "trainer/Policy log std Mean            -3.19386\n",
      "trainer/Policy log std Std              1.32933\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        129109\n",
      "exploration/num paths total           895\n",
      "evaluation/num steps total         696102\n",
      "evaluation/num paths total           1243\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07752\n",
      "evaluation/Rewards Std                  1.30588\n",
      "evaluation/Rewards Max                  7.32572\n",
      "evaluation/Rewards Min                  0.116862\n",
      "evaluation/Returns Mean              5077.52\n",
      "evaluation/Returns Std                 80.0305\n",
      "evaluation/Returns Max               5185.93\n",
      "evaluation/Returns Min               4914.78\n",
      "evaluation/Estimation Bias Mean      1137.94\n",
      "evaluation/Estimation Bias Std        186.753\n",
      "evaluation/EB/Q_True Mean              47.4792\n",
      "evaluation/EB/Q_True Std              146.552\n",
      "evaluation/EB/Q_Pred Mean            1185.42\n",
      "evaluation/EB/Q_Pred Std              114.215\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5077.52\n",
      "evaluation/Actions Mean                 0.516531\n",
      "evaluation/Actions Std                  0.643081\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.77298\n",
      "time/backward_zf1 (s)                   1.90506\n",
      "time/backward_zf2 (s)                   1.83809\n",
      "time/data sampling (s)                  0.261014\n",
      "time/data storing (s)                   0.0136475\n",
      "time/evaluation sampling (s)            1.42769\n",
      "time/exploration sampling (s)           0.195649\n",
      "time/logging (s)                        0.013791\n",
      "time/preback_alpha (s)                  0.564761\n",
      "time/preback_policy (s)                 1.00777\n",
      "time/preback_start (s)                  0.12231\n",
      "time/preback_zf (s)                     5.06598\n",
      "time/saving (s)                         0.00585618\n",
      "time/training (s)                       2.35203\n",
      "time/epoch (s)                         16.5466\n",
      "time/total (s)                       2017.23\n",
      "Epoch                                 123\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:26:04.203761 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 124 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 135000\n",
      "trainer/ZF1 Loss                       16.7781\n",
      "trainer/ZF2 Loss                       18.4967\n",
      "trainer/ZF Expert Reward               13.2989\n",
      "trainer/ZF Policy Reward               -1.12413\n",
      "trainer/ZF CHI2 Term                   32.356\n",
      "trainer/Policy Loss                  -870.341\n",
      "trainer/Bias Loss                     107.763\n",
      "trainer/Bias Value                     11.0728\n",
      "trainer/Policy Grad Norm              155.805\n",
      "trainer/Policy Param Norm              31.4633\n",
      "trainer/Zf1 Grad Norm                2027.69\n",
      "trainer/Zf1 Param Norm                 85.822\n",
      "trainer/Zf2 Grad Norm                2498.39\n",
      "trainer/Zf2 Param Norm                 83.783\n",
      "trainer/Z Expert Predictions Mean    1177.08\n",
      "trainer/Z Expert Predictions Std      118.394\n",
      "trainer/Z Expert Predictions Max     1338.43\n",
      "trainer/Z Expert Predictions Min      700.663\n",
      "trainer/Z Policy Predictions Mean     861.679\n",
      "trainer/Z Policy Predictions Std      347.224\n",
      "trainer/Z Policy Predictions Max     1301.57\n",
      "trainer/Z Policy Predictions Min      -40.9107\n",
      "trainer/Z Expert Targets Mean        1163.79\n",
      "trainer/Z Expert Targets Std          116.98\n",
      "trainer/Z Expert Targets Max         1312.38\n",
      "trainer/Z Expert Targets Min          700.005\n",
      "trainer/Z Policy Targets Mean         862.803\n",
      "trainer/Z Policy Targets Std          342.643\n",
      "trainer/Z Policy Targets Max         1287.72\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.559\n",
      "trainer/Log Pis Std                     8.74893\n",
      "trainer/Policy mu Mean                  1.46943\n",
      "trainer/Policy mu Std                   2.58482\n",
      "trainer/Policy log std Mean            -3.29261\n",
      "trainer/Policy log std Std              1.31569\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        130109\n",
      "exploration/num paths total           896\n",
      "evaluation/num steps total         706102\n",
      "evaluation/num paths total           1253\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.11314\n",
      "evaluation/Rewards Std                  1.30893\n",
      "evaluation/Rewards Max                  7.43044\n",
      "evaluation/Rewards Min                  0.114559\n",
      "evaluation/Returns Mean              5113.14\n",
      "evaluation/Returns Std                 44.2266\n",
      "evaluation/Returns Max               5230.17\n",
      "evaluation/Returns Min               5053.96\n",
      "evaluation/Estimation Bias Mean      1145.81\n",
      "evaluation/Estimation Bias Std        188.364\n",
      "evaluation/EB/Q_True Mean              48.3341\n",
      "evaluation/EB/Q_True Std              148.864\n",
      "evaluation/EB/Q_Pred Mean            1194.14\n",
      "evaluation/EB/Q_Pred Std              117.656\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5113.14\n",
      "evaluation/Actions Mean                 0.514586\n",
      "evaluation/Actions Std                  0.643704\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.96544\n",
      "time/backward_zf1 (s)                   2.11039\n",
      "time/backward_zf2 (s)                   2.05195\n",
      "time/data sampling (s)                  0.254506\n",
      "time/data storing (s)                   0.0147596\n",
      "time/evaluation sampling (s)            1.40074\n",
      "time/exploration sampling (s)           0.204114\n",
      "time/logging (s)                        0.0126203\n",
      "time/preback_alpha (s)                  0.568168\n",
      "time/preback_policy (s)                 1.18477\n",
      "time/preback_start (s)                  0.123519\n",
      "time/preback_zf (s)                     5.08865\n",
      "time/saving (s)                         0.00577041\n",
      "time/training (s)                       2.05776\n",
      "time/epoch (s)                         17.0432\n",
      "time/total (s)                       2034.29\n",
      "Epoch                                 124\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:26:21.024366 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 125 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 136000\n",
      "trainer/ZF1 Loss                       23.6676\n",
      "trainer/ZF2 Loss                       17.1705\n",
      "trainer/ZF Expert Reward               15.5591\n",
      "trainer/ZF Policy Reward               -1.90679\n",
      "trainer/ZF CHI2 Term                   38.1755\n",
      "trainer/Policy Loss                  -837.564\n",
      "trainer/Bias Loss                     112.504\n",
      "trainer/Bias Value                     11.0795\n",
      "trainer/Policy Grad Norm              209.463\n",
      "trainer/Policy Param Norm              31.4943\n",
      "trainer/Zf1 Grad Norm                1851.84\n",
      "trainer/Zf1 Param Norm                 86.0231\n",
      "trainer/Zf2 Grad Norm                1215.63\n",
      "trainer/Zf2 Param Norm                 84.0089\n",
      "trainer/Z Expert Predictions Mean    1188.8\n",
      "trainer/Z Expert Predictions Std      120.99\n",
      "trainer/Z Expert Predictions Max     1355.56\n",
      "trainer/Z Expert Predictions Min      705.03\n",
      "trainer/Z Policy Predictions Mean     823.653\n",
      "trainer/Z Policy Predictions Std      358.301\n",
      "trainer/Z Policy Predictions Max     1317.4\n",
      "trainer/Z Policy Predictions Min      -25.0607\n",
      "trainer/Z Expert Targets Mean        1173.24\n",
      "trainer/Z Expert Targets Std          119.029\n",
      "trainer/Z Expert Targets Max         1347.62\n",
      "trainer/Z Expert Targets Min          706.729\n",
      "trainer/Z Policy Targets Mean         825.559\n",
      "trainer/Z Policy Targets Std          351.415\n",
      "trainer/Z Policy Targets Max         1306.98\n",
      "trainer/Z Policy Targets Min          -11.1572\n",
      "trainer/Log Pis Mean                   29.0478\n",
      "trainer/Log Pis Std                     8.4384\n",
      "trainer/Policy mu Mean                  1.38043\n",
      "trainer/Policy mu Std                   2.5204\n",
      "trainer/Policy log std Mean            -3.20911\n",
      "trainer/Policy log std Std              1.27169\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        131109\n",
      "exploration/num paths total           897\n",
      "evaluation/num steps total         716102\n",
      "evaluation/num paths total           1263\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15859\n",
      "evaluation/Rewards Std                  1.29971\n",
      "evaluation/Rewards Max                  7.23915\n",
      "evaluation/Rewards Min                  0.121363\n",
      "evaluation/Returns Mean              5158.59\n",
      "evaluation/Returns Std                 19.5622\n",
      "evaluation/Returns Max               5186.34\n",
      "evaluation/Returns Min               5122.49\n",
      "evaluation/Estimation Bias Mean      1160.27\n",
      "evaluation/Estimation Bias Std        186.311\n",
      "evaluation/EB/Q_True Mean              48.6414\n",
      "evaluation/EB/Q_True Std              150.251\n",
      "evaluation/EB/Q_Pred Mean            1208.91\n",
      "evaluation/EB/Q_Pred Std              113.458\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5158.59\n",
      "evaluation/Actions Mean                 0.509054\n",
      "evaluation/Actions Std                  0.641322\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.80063\n",
      "time/backward_zf1 (s)                   1.93359\n",
      "time/backward_zf2 (s)                   1.85709\n",
      "time/data sampling (s)                  0.247313\n",
      "time/data storing (s)                   0.0142757\n",
      "time/evaluation sampling (s)            1.41807\n",
      "time/exploration sampling (s)           0.196729\n",
      "time/logging (s)                        0.012696\n",
      "time/preback_alpha (s)                  0.562547\n",
      "time/preback_policy (s)                 0.997366\n",
      "time/preback_start (s)                  0.121903\n",
      "time/preback_zf (s)                     5.09142\n",
      "time/saving (s)                         0.0061266\n",
      "time/training (s)                       2.49468\n",
      "time/epoch (s)                         16.7544\n",
      "time/total (s)                       2051.07\n",
      "Epoch                                 125\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:26:38.133073 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 126 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 137000\n",
      "trainer/ZF1 Loss                       26.2938\n",
      "trainer/ZF2 Loss                       45.2724\n",
      "trainer/ZF Expert Reward                9.41629\n",
      "trainer/ZF Policy Reward               -3.3335\n",
      "trainer/ZF CHI2 Term                   48.825\n",
      "trainer/Policy Loss                  -901.421\n",
      "trainer/Bias Loss                     145.454\n",
      "trainer/Bias Value                     11.0863\n",
      "trainer/Policy Grad Norm              239.046\n",
      "trainer/Policy Param Norm              31.5306\n",
      "trainer/Zf1 Grad Norm                3991.73\n",
      "trainer/Zf1 Param Norm                 86.2435\n",
      "trainer/Zf2 Grad Norm                6732.06\n",
      "trainer/Zf2 Param Norm                 84.23\n",
      "trainer/Z Expert Predictions Mean    1200.81\n",
      "trainer/Z Expert Predictions Std      108.46\n",
      "trainer/Z Expert Predictions Max     1356.55\n",
      "trainer/Z Expert Predictions Min      665.257\n",
      "trainer/Z Policy Predictions Mean     886.276\n",
      "trainer/Z Policy Predictions Std      347.664\n",
      "trainer/Z Policy Predictions Max     1305.57\n",
      "trainer/Z Policy Predictions Min      -22.4164\n",
      "trainer/Z Expert Targets Mean        1191.39\n",
      "trainer/Z Expert Targets Std          106.546\n",
      "trainer/Z Expert Targets Max         1343.31\n",
      "trainer/Z Expert Targets Min          671.121\n",
      "trainer/Z Policy Targets Mean         889.609\n",
      "trainer/Z Policy Targets Std          345.225\n",
      "trainer/Z Policy Targets Max         1318.08\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.2099\n",
      "trainer/Log Pis Std                     8.4788\n",
      "trainer/Policy mu Mean                  1.38934\n",
      "trainer/Policy mu Std                   2.64739\n",
      "trainer/Policy log std Mean            -3.18929\n",
      "trainer/Policy log std Std              1.28144\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        134109\n",
      "exploration/num paths total           900\n",
      "evaluation/num steps total         726102\n",
      "evaluation/num paths total           1273\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.11527\n",
      "evaluation/Rewards Std                  1.29291\n",
      "evaluation/Rewards Max                  7.1473\n",
      "evaluation/Rewards Min                  0.0941731\n",
      "evaluation/Returns Mean              5115.27\n",
      "evaluation/Returns Std                 31.1961\n",
      "evaluation/Returns Max               5177.12\n",
      "evaluation/Returns Min               5076.67\n",
      "evaluation/Estimation Bias Mean      1156.28\n",
      "evaluation/Estimation Bias Std        185.743\n",
      "evaluation/EB/Q_True Mean              48.431\n",
      "evaluation/EB/Q_True Std              149.719\n",
      "evaluation/EB/Q_Pred Mean            1204.71\n",
      "evaluation/EB/Q_Pred Std              112.544\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5115.27\n",
      "evaluation/Actions Mean                 0.499531\n",
      "evaluation/Actions Std                  0.638303\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.95495\n",
      "time/backward_zf1 (s)                   2.09563\n",
      "time/backward_zf2 (s)                   2.02707\n",
      "time/data sampling (s)                  0.256207\n",
      "time/data storing (s)                   0.0141961\n",
      "time/evaluation sampling (s)            1.42814\n",
      "time/exploration sampling (s)           0.2012\n",
      "time/logging (s)                        0.0117044\n",
      "time/preback_alpha (s)                  0.56995\n",
      "time/preback_policy (s)                 1.13154\n",
      "time/preback_start (s)                  0.124411\n",
      "time/preback_zf (s)                     5.06212\n",
      "time/saving (s)                         0.00597705\n",
      "time/training (s)                       2.14913\n",
      "time/epoch (s)                         17.0322\n",
      "time/total (s)                       2068.13\n",
      "Epoch                                 126\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:26:54.913012 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 127 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 138000\n",
      "trainer/ZF1 Loss                       32.967\n",
      "trainer/ZF2 Loss                       31.9487\n",
      "trainer/ZF Expert Reward               15.2225\n",
      "trainer/ZF Policy Reward               -2.1525\n",
      "trainer/ZF CHI2 Term                   50.1205\n",
      "trainer/Policy Loss                  -894.07\n",
      "trainer/Bias Loss                     216.271\n",
      "trainer/Bias Value                     11.0931\n",
      "trainer/Policy Grad Norm              160.895\n",
      "trainer/Policy Param Norm              31.5617\n",
      "trainer/Zf1 Grad Norm                3228.92\n",
      "trainer/Zf1 Param Norm                 86.4496\n",
      "trainer/Zf2 Grad Norm                3998.25\n",
      "trainer/Zf2 Param Norm                 84.4667\n",
      "trainer/Z Expert Predictions Mean    1174.16\n",
      "trainer/Z Expert Predictions Std      125.669\n",
      "trainer/Z Expert Predictions Max     1345.24\n",
      "trainer/Z Expert Predictions Min      712.907\n",
      "trainer/Z Policy Predictions Mean     874.62\n",
      "trainer/Z Policy Predictions Std      351.187\n",
      "trainer/Z Policy Predictions Max     1323.56\n",
      "trainer/Z Policy Predictions Min      -67.5317\n",
      "trainer/Z Expert Targets Mean        1158.94\n",
      "trainer/Z Expert Targets Std          125.131\n",
      "trainer/Z Expert Targets Max         1337.65\n",
      "trainer/Z Expert Targets Min          707.844\n",
      "trainer/Z Policy Targets Mean         876.772\n",
      "trainer/Z Policy Targets Std          344.865\n",
      "trainer/Z Policy Targets Max         1302.66\n",
      "trainer/Z Policy Targets Min          -66.6853\n",
      "trainer/Log Pis Mean                   28.7613\n",
      "trainer/Log Pis Std                     8.26022\n",
      "trainer/Policy mu Mean                  1.28413\n",
      "trainer/Policy mu Std                   2.57959\n",
      "trainer/Policy log std Mean            -3.32341\n",
      "trainer/Policy log std Std              1.27938\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        134109\n",
      "exploration/num paths total           900\n",
      "evaluation/num steps total         736102\n",
      "evaluation/num paths total           1283\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19711\n",
      "evaluation/Rewards Std                  1.31798\n",
      "evaluation/Rewards Max                  7.12494\n",
      "evaluation/Rewards Min                  0.122157\n",
      "evaluation/Returns Mean              5197.11\n",
      "evaluation/Returns Std                 13.4896\n",
      "evaluation/Returns Max               5221.2\n",
      "evaluation/Returns Min               5178.62\n",
      "evaluation/Estimation Bias Mean      1172.38\n",
      "evaluation/Estimation Bias Std        192.267\n",
      "evaluation/EB/Q_True Mean              49.386\n",
      "evaluation/EB/Q_True Std              152.583\n",
      "evaluation/EB/Q_Pred Mean            1221.77\n",
      "evaluation/EB/Q_Pred Std              118.932\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5197.11\n",
      "evaluation/Actions Mean                 0.497343\n",
      "evaluation/Actions Std                  0.645383\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.8232\n",
      "time/backward_zf1 (s)                   2.00253\n",
      "time/backward_zf2 (s)                   1.89411\n",
      "time/data sampling (s)                  0.265221\n",
      "time/data storing (s)                   0.0136851\n",
      "time/evaluation sampling (s)            1.40019\n",
      "time/exploration sampling (s)           0.191633\n",
      "time/logging (s)                        0.012673\n",
      "time/preback_alpha (s)                  0.561395\n",
      "time/preback_policy (s)                 1.03383\n",
      "time/preback_start (s)                  0.12071\n",
      "time/preback_zf (s)                     5.04653\n",
      "time/saving (s)                         0.00565026\n",
      "time/training (s)                       2.3411\n",
      "time/epoch (s)                         16.7125\n",
      "time/total (s)                       2084.86\n",
      "Epoch                                 127\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:27:11.832184 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 128 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 139000\n",
      "trainer/ZF1 Loss                       31.993\n",
      "trainer/ZF2 Loss                       33.4441\n",
      "trainer/ZF Expert Reward               13.7539\n",
      "trainer/ZF Policy Reward               -1.32304\n",
      "trainer/ZF CHI2 Term                   48.0853\n",
      "trainer/Policy Loss                  -855.909\n",
      "trainer/Bias Loss                     154.165\n",
      "trainer/Bias Value                     11.0999\n",
      "trainer/Policy Grad Norm              177.263\n",
      "trainer/Policy Param Norm              31.5956\n",
      "trainer/Zf1 Grad Norm                1829.28\n",
      "trainer/Zf1 Param Norm                 86.668\n",
      "trainer/Zf2 Grad Norm                2183.19\n",
      "trainer/Zf2 Param Norm                 84.6876\n",
      "trainer/Z Expert Predictions Mean    1172.56\n",
      "trainer/Z Expert Predictions Std      131.803\n",
      "trainer/Z Expert Predictions Max     1339.74\n",
      "trainer/Z Expert Predictions Min      683.856\n",
      "trainer/Z Policy Predictions Mean     843.579\n",
      "trainer/Z Policy Predictions Std      357.084\n",
      "trainer/Z Policy Predictions Max     1340.05\n",
      "trainer/Z Policy Predictions Min        2.68397\n",
      "trainer/Z Expert Targets Mean        1158.8\n",
      "trainer/Z Expert Targets Std          128.993\n",
      "trainer/Z Expert Targets Max         1338.46\n",
      "trainer/Z Expert Targets Min          683.888\n",
      "trainer/Z Policy Targets Mean         844.903\n",
      "trainer/Z Policy Targets Std          352.199\n",
      "trainer/Z Policy Targets Max         1334.15\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   28.978\n",
      "trainer/Log Pis Std                     8.25738\n",
      "trainer/Policy mu Mean                  1.32781\n",
      "trainer/Policy mu Std                   2.57661\n",
      "trainer/Policy log std Mean            -3.2218\n",
      "trainer/Policy log std Std              1.32404\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        134109\n",
      "exploration/num paths total           900\n",
      "evaluation/num steps total         746102\n",
      "evaluation/num paths total           1293\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.24711\n",
      "evaluation/Rewards Std                  1.34761\n",
      "evaluation/Rewards Max                  7.23256\n",
      "evaluation/Rewards Min                  0.0960729\n",
      "evaluation/Returns Mean              5247.11\n",
      "evaluation/Returns Std                 21.8692\n",
      "evaluation/Returns Max               5283.23\n",
      "evaluation/Returns Min               5222.2\n",
      "evaluation/Estimation Bias Mean      1178.31\n",
      "evaluation/Estimation Bias Std        192.121\n",
      "evaluation/EB/Q_True Mean              49.9955\n",
      "evaluation/EB/Q_True Std              154.432\n",
      "evaluation/EB/Q_Pred Mean            1228.31\n",
      "evaluation/EB/Q_Pred Std              118.346\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5247.11\n",
      "evaluation/Actions Mean                 0.50022\n",
      "evaluation/Actions Std                  0.652256\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.83584\n",
      "time/backward_zf1 (s)                   1.99152\n",
      "time/backward_zf2 (s)                   1.90694\n",
      "time/data sampling (s)                  0.245047\n",
      "time/data storing (s)                   0.0146455\n",
      "time/evaluation sampling (s)            1.45616\n",
      "time/exploration sampling (s)           0.196493\n",
      "time/logging (s)                        0.011456\n",
      "time/preback_alpha (s)                  0.569401\n",
      "time/preback_policy (s)                 1.04507\n",
      "time/preback_start (s)                  0.121512\n",
      "time/preback_zf (s)                     5.09184\n",
      "time/saving (s)                         0.00509466\n",
      "time/training (s)                       2.35666\n",
      "time/epoch (s)                         16.8477\n",
      "time/total (s)                       2101.73\n",
      "Epoch                                 128\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:27:28.375659 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 129 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 140000\n",
      "trainer/ZF1 Loss                       14.7504\n",
      "trainer/ZF2 Loss                       11.275\n",
      "trainer/ZF Expert Reward               13.0534\n",
      "trainer/ZF Policy Reward               -4.59777\n",
      "trainer/ZF CHI2 Term                   30.9512\n",
      "trainer/Policy Loss                  -865.362\n",
      "trainer/Bias Loss                      74.2187\n",
      "trainer/Bias Value                     11.1064\n",
      "trainer/Policy Grad Norm              202.127\n",
      "trainer/Policy Param Norm              31.6324\n",
      "trainer/Zf1 Grad Norm                2331.34\n",
      "trainer/Zf1 Param Norm                 86.8856\n",
      "trainer/Zf2 Grad Norm                2187.51\n",
      "trainer/Zf2 Param Norm                 84.9117\n",
      "trainer/Z Expert Predictions Mean    1188.04\n",
      "trainer/Z Expert Predictions Std      128.191\n",
      "trainer/Z Expert Predictions Max     1346.54\n",
      "trainer/Z Expert Predictions Min      708.286\n",
      "trainer/Z Policy Predictions Mean     850.688\n",
      "trainer/Z Policy Predictions Std      354.18\n",
      "trainer/Z Policy Predictions Max     1319.73\n",
      "trainer/Z Policy Predictions Min        8.17712\n",
      "trainer/Z Expert Targets Mean        1174.99\n",
      "trainer/Z Expert Targets Std          126.321\n",
      "trainer/Z Expert Targets Max         1336.72\n",
      "trainer/Z Expert Targets Min          699.953\n",
      "trainer/Z Policy Targets Mean         855.286\n",
      "trainer/Z Policy Targets Std          347.782\n",
      "trainer/Z Policy Targets Max         1302.31\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   28.7218\n",
      "trainer/Log Pis Std                     7.14433\n",
      "trainer/Policy mu Mean                  1.28498\n",
      "trainer/Policy mu Std                   2.47048\n",
      "trainer/Policy log std Mean            -3.34882\n",
      "trainer/Policy log std Std              1.26603\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        135109\n",
      "exploration/num paths total           901\n",
      "evaluation/num steps total         756102\n",
      "evaluation/num paths total           1303\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16635\n",
      "evaluation/Rewards Std                  1.3334\n",
      "evaluation/Rewards Max                  7.256\n",
      "evaluation/Rewards Min                  0.103954\n",
      "evaluation/Returns Mean              5166.35\n",
      "evaluation/Returns Std                 27.4635\n",
      "evaluation/Returns Max               5201.66\n",
      "evaluation/Returns Min               5112.38\n",
      "evaluation/Estimation Bias Mean      1150.89\n",
      "evaluation/Estimation Bias Std        193.918\n",
      "evaluation/EB/Q_True Mean              48.8789\n",
      "evaluation/EB/Q_True Std              151.017\n",
      "evaluation/EB/Q_Pred Mean            1199.77\n",
      "evaluation/EB/Q_Pred Std              122.763\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5166.35\n",
      "evaluation/Actions Mean                 0.522802\n",
      "evaluation/Actions Std                  0.642067\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.77125\n",
      "time/backward_zf1 (s)                   1.90121\n",
      "time/backward_zf2 (s)                   1.83051\n",
      "time/data sampling (s)                  0.2301\n",
      "time/data storing (s)                   0.0135895\n",
      "time/evaluation sampling (s)            1.41038\n",
      "time/exploration sampling (s)           0.190967\n",
      "time/logging (s)                        0.0124596\n",
      "time/preback_alpha (s)                  0.558196\n",
      "time/preback_policy (s)                 1.0146\n",
      "time/preback_start (s)                  0.119592\n",
      "time/preback_zf (s)                     5.04028\n",
      "time/saving (s)                         0.00568132\n",
      "time/training (s)                       2.3814\n",
      "time/epoch (s)                         16.4802\n",
      "time/total (s)                       2118.23\n",
      "Epoch                                 129\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:27:45.169011 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 130 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 141000\n",
      "trainer/ZF1 Loss                       24.8808\n",
      "trainer/ZF2 Loss                       34.5574\n",
      "trainer/ZF Expert Reward               10.0821\n",
      "trainer/ZF Policy Reward               -6.12384\n",
      "trainer/ZF CHI2 Term                   46.2244\n",
      "trainer/Policy Loss                  -882.026\n",
      "trainer/Bias Loss                      74.4912\n",
      "trainer/Bias Value                     11.1132\n",
      "trainer/Policy Grad Norm              295.254\n",
      "trainer/Policy Param Norm              31.6801\n",
      "trainer/Zf1 Grad Norm                2684.93\n",
      "trainer/Zf1 Param Norm                 87.1272\n",
      "trainer/Zf2 Grad Norm                5494.95\n",
      "trainer/Zf2 Param Norm                 85.169\n",
      "trainer/Z Expert Predictions Mean    1182.59\n",
      "trainer/Z Expert Predictions Std      135.739\n",
      "trainer/Z Expert Predictions Max     1343.44\n",
      "trainer/Z Expert Predictions Min      668.725\n",
      "trainer/Z Policy Predictions Mean     870.256\n",
      "trainer/Z Policy Predictions Std      324.133\n",
      "trainer/Z Policy Predictions Max     1304.79\n",
      "trainer/Z Policy Predictions Min       15.8296\n",
      "trainer/Z Expert Targets Mean        1172.51\n",
      "trainer/Z Expert Targets Std          133.661\n",
      "trainer/Z Expert Targets Max         1350.59\n",
      "trainer/Z Expert Targets Min          662.713\n",
      "trainer/Z Policy Targets Mean         876.38\n",
      "trainer/Z Policy Targets Std          319.277\n",
      "trainer/Z Policy Targets Max         1298.88\n",
      "trainer/Z Policy Targets Min           35.5925\n",
      "trainer/Log Pis Mean                   29.9383\n",
      "trainer/Log Pis Std                     8.09433\n",
      "trainer/Policy mu Mean                  1.30037\n",
      "trainer/Policy mu Std                   2.45584\n",
      "trainer/Policy log std Mean            -3.39889\n",
      "trainer/Policy log std Std              1.27253\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        135109\n",
      "exploration/num paths total           901\n",
      "evaluation/num steps total         766102\n",
      "evaluation/num paths total           1313\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10926\n",
      "evaluation/Rewards Std                  1.31752\n",
      "evaluation/Rewards Max                  7.30264\n",
      "evaluation/Rewards Min                  0.0898428\n",
      "evaluation/Returns Mean              5109.26\n",
      "evaluation/Returns Std                 60.5308\n",
      "evaluation/Returns Max               5166.87\n",
      "evaluation/Returns Min               4937.67\n",
      "evaluation/Estimation Bias Mean      1162.46\n",
      "evaluation/Estimation Bias Std        189.438\n",
      "evaluation/EB/Q_True Mean              48.3186\n",
      "evaluation/EB/Q_True Std              149.234\n",
      "evaluation/EB/Q_Pred Mean            1210.78\n",
      "evaluation/EB/Q_Pred Std              117.105\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5109.26\n",
      "evaluation/Actions Mean                 0.501521\n",
      "evaluation/Actions Std                  0.65235\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82855\n",
      "time/backward_zf1 (s)                   1.98156\n",
      "time/backward_zf2 (s)                   1.89032\n",
      "time/data sampling (s)                  0.253275\n",
      "time/data storing (s)                   0.014024\n",
      "time/evaluation sampling (s)            1.42718\n",
      "time/exploration sampling (s)           0.194207\n",
      "time/logging (s)                        0.0115816\n",
      "time/preback_alpha (s)                  0.565422\n",
      "time/preback_policy (s)                 1.06933\n",
      "time/preback_start (s)                  0.122962\n",
      "time/preback_zf (s)                     5.06168\n",
      "time/saving (s)                         0.00535415\n",
      "time/training (s)                       2.29709\n",
      "time/epoch (s)                         16.7225\n",
      "time/total (s)                       2134.98\n",
      "Epoch                                 130\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:28:02.099759 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 131 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 142000\n",
      "trainer/ZF1 Loss                      285.631\n",
      "trainer/ZF2 Loss                      292.784\n",
      "trainer/ZF Expert Reward               31.3955\n",
      "trainer/ZF Policy Reward               11.2301\n",
      "trainer/ZF CHI2 Term                  309.67\n",
      "trainer/Policy Loss                  -892.007\n",
      "trainer/Bias Loss                    2802.38\n",
      "trainer/Bias Value                     11.1197\n",
      "trainer/Policy Grad Norm              242.658\n",
      "trainer/Policy Param Norm              31.7255\n",
      "trainer/Zf1 Grad Norm                4181.6\n",
      "trainer/Zf1 Param Norm                 87.3583\n",
      "trainer/Zf2 Grad Norm                5142.63\n",
      "trainer/Zf2 Param Norm                 85.424\n",
      "trainer/Z Expert Predictions Mean    1212.14\n",
      "trainer/Z Expert Predictions Std      110.275\n",
      "trainer/Z Expert Predictions Max     1360.99\n",
      "trainer/Z Expert Predictions Min      670.259\n",
      "trainer/Z Policy Predictions Mean     885.936\n",
      "trainer/Z Policy Predictions Std      352.224\n",
      "trainer/Z Policy Predictions Max     1326.2\n",
      "trainer/Z Policy Predictions Min       13.1671\n",
      "trainer/Z Expert Targets Mean        1180.75\n",
      "trainer/Z Expert Targets Std          130.55\n",
      "trainer/Z Expert Targets Max         1336.34\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         874.706\n",
      "trainer/Z Policy Targets Std          345.456\n",
      "trainer/Z Policy Targets Max         1336.02\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.7077\n",
      "trainer/Log Pis Std                     8.67359\n",
      "trainer/Policy mu Mean                  1.4108\n",
      "trainer/Policy mu Std                   2.88148\n",
      "trainer/Policy log std Mean            -3.20344\n",
      "trainer/Policy log std Std              1.34999\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        136109\n",
      "exploration/num paths total           902\n",
      "evaluation/num steps total         776102\n",
      "evaluation/num paths total           1323\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12593\n",
      "evaluation/Rewards Std                  1.33546\n",
      "evaluation/Rewards Max                  7.39757\n",
      "evaluation/Rewards Min                  0.0933964\n",
      "evaluation/Returns Mean              5125.93\n",
      "evaluation/Returns Std                117.034\n",
      "evaluation/Returns Max               5230.18\n",
      "evaluation/Returns Min               4838.88\n",
      "evaluation/Estimation Bias Mean      1121.66\n",
      "evaluation/Estimation Bias Std        197.023\n",
      "evaluation/EB/Q_True Mean              48.4165\n",
      "evaluation/EB/Q_True Std              149.38\n",
      "evaluation/EB/Q_Pred Mean            1170.08\n",
      "evaluation/EB/Q_Pred Std              117.782\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5125.93\n",
      "evaluation/Actions Mean                 0.523396\n",
      "evaluation/Actions Std                  0.649703\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88716\n",
      "time/backward_zf1 (s)                   2.04515\n",
      "time/backward_zf2 (s)                   1.96992\n",
      "time/data sampling (s)                  0.239179\n",
      "time/data storing (s)                   0.0135889\n",
      "time/evaluation sampling (s)            1.51685\n",
      "time/exploration sampling (s)           0.193302\n",
      "time/logging (s)                        0.0122904\n",
      "time/preback_alpha (s)                  0.558535\n",
      "time/preback_policy (s)                 1.11375\n",
      "time/preback_start (s)                  0.121783\n",
      "time/preback_zf (s)                     5.04087\n",
      "time/saving (s)                         0.00576055\n",
      "time/training (s)                       2.14807\n",
      "time/epoch (s)                         16.8662\n",
      "time/total (s)                       2151.86\n",
      "Epoch                                 131\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:28:18.966031 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 132 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 143000\n",
      "trainer/ZF1 Loss                       17.8536\n",
      "trainer/ZF2 Loss                       23.9184\n",
      "trainer/ZF Expert Reward               12.4707\n",
      "trainer/ZF Policy Reward               -1.65221\n",
      "trainer/ZF CHI2 Term                   35.3124\n",
      "trainer/Policy Loss                  -886.965\n",
      "trainer/Bias Loss                      78.2121\n",
      "trainer/Bias Value                     11.1264\n",
      "trainer/Policy Grad Norm              206.767\n",
      "trainer/Policy Param Norm              31.767\n",
      "trainer/Zf1 Grad Norm                2045.05\n",
      "trainer/Zf1 Param Norm                 87.6108\n",
      "trainer/Zf2 Grad Norm                1959.54\n",
      "trainer/Zf2 Param Norm                 85.6804\n",
      "trainer/Z Expert Predictions Mean    1195.92\n",
      "trainer/Z Expert Predictions Std      115.364\n",
      "trainer/Z Expert Predictions Max     1342.54\n",
      "trainer/Z Expert Predictions Min      700.535\n",
      "trainer/Z Policy Predictions Mean     874.108\n",
      "trainer/Z Policy Predictions Std      364.235\n",
      "trainer/Z Policy Predictions Max     1314.74\n",
      "trainer/Z Policy Predictions Min      -14.7137\n",
      "trainer/Z Expert Targets Mean        1183.45\n",
      "trainer/Z Expert Targets Std          112.967\n",
      "trainer/Z Expert Targets Max         1332.91\n",
      "trainer/Z Expert Targets Min          699.666\n",
      "trainer/Z Policy Targets Mean         875.761\n",
      "trainer/Z Policy Targets Std          357.059\n",
      "trainer/Z Policy Targets Max         1309.11\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   30.3429\n",
      "trainer/Log Pis Std                     8.40513\n",
      "trainer/Policy mu Mean                  1.37141\n",
      "trainer/Policy mu Std                   2.73379\n",
      "trainer/Policy log std Mean            -3.24194\n",
      "trainer/Policy log std Std              1.26031\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        137109\n",
      "exploration/num paths total           903\n",
      "evaluation/num steps total         786102\n",
      "evaluation/num paths total           1333\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21549\n",
      "evaluation/Rewards Std                  1.34801\n",
      "evaluation/Rewards Max                  7.33115\n",
      "evaluation/Rewards Min                  0.110723\n",
      "evaluation/Returns Mean              5215.49\n",
      "evaluation/Returns Std                 58.7102\n",
      "evaluation/Returns Max               5259.92\n",
      "evaluation/Returns Min               5060.88\n",
      "evaluation/Estimation Bias Mean      1145.14\n",
      "evaluation/Estimation Bias Std        186.036\n",
      "evaluation/EB/Q_True Mean              49.4848\n",
      "evaluation/EB/Q_True Std              152.787\n",
      "evaluation/EB/Q_Pred Mean            1194.63\n",
      "evaluation/EB/Q_Pred Std              112.983\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5215.49\n",
      "evaluation/Actions Mean                 0.512883\n",
      "evaluation/Actions Std                  0.652676\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.81143\n",
      "time/backward_zf1 (s)                   1.93721\n",
      "time/backward_zf2 (s)                   1.87098\n",
      "time/data sampling (s)                  0.252164\n",
      "time/data storing (s)                   0.0141699\n",
      "time/evaluation sampling (s)            1.4407\n",
      "time/exploration sampling (s)           0.193742\n",
      "time/logging (s)                        0.0119635\n",
      "time/preback_alpha (s)                  0.574968\n",
      "time/preback_policy (s)                 1.00597\n",
      "time/preback_start (s)                  0.124312\n",
      "time/preback_zf (s)                     5.08612\n",
      "time/saving (s)                         0.00557781\n",
      "time/training (s)                       2.46904\n",
      "time/epoch (s)                         16.7983\n",
      "time/total (s)                       2168.68\n",
      "Epoch                                 132\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:28:35.837515 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 133 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 144000\n",
      "trainer/ZF1 Loss                       55.9852\n",
      "trainer/ZF2 Loss                       28.206\n",
      "trainer/ZF Expert Reward                4.95857\n",
      "trainer/ZF Policy Reward               -6.79697\n",
      "trainer/ZF CHI2 Term                   54.1453\n",
      "trainer/Policy Loss                  -902.122\n",
      "trainer/Bias Loss                     122.938\n",
      "trainer/Bias Value                     11.1332\n",
      "trainer/Policy Grad Norm              247.097\n",
      "trainer/Policy Param Norm              31.8023\n",
      "trainer/Zf1 Grad Norm                7012.36\n",
      "trainer/Zf1 Param Norm                 87.8595\n",
      "trainer/Zf2 Grad Norm                4582.9\n",
      "trainer/Zf2 Param Norm                 85.9431\n",
      "trainer/Z Expert Predictions Mean    1192.9\n",
      "trainer/Z Expert Predictions Std      113.368\n",
      "trainer/Z Expert Predictions Max     1339.98\n",
      "trainer/Z Expert Predictions Min      692.621\n",
      "trainer/Z Policy Predictions Mean     888.709\n",
      "trainer/Z Policy Predictions Std      332.401\n",
      "trainer/Z Policy Predictions Max     1315.56\n",
      "trainer/Z Policy Predictions Min      -10.9126\n",
      "trainer/Z Expert Targets Mean        1187.94\n",
      "trainer/Z Expert Targets Std          112.418\n",
      "trainer/Z Expert Targets Max         1336.7\n",
      "trainer/Z Expert Targets Min          696.414\n",
      "trainer/Z Policy Targets Mean         895.506\n",
      "trainer/Z Policy Targets Std          330.649\n",
      "trainer/Z Policy Targets Max         1309.28\n",
      "trainer/Z Policy Targets Min          -24.9967\n",
      "trainer/Log Pis Mean                   29.4156\n",
      "trainer/Log Pis Std                     7.76363\n",
      "trainer/Policy mu Mean                  1.36399\n",
      "trainer/Policy mu Std                   2.61422\n",
      "trainer/Policy log std Mean            -3.24202\n",
      "trainer/Policy log std Std              1.31723\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        139109\n",
      "exploration/num paths total           905\n",
      "evaluation/num steps total         796102\n",
      "evaluation/num paths total           1343\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16804\n",
      "evaluation/Rewards Std                  1.31067\n",
      "evaluation/Rewards Max                  7.23919\n",
      "evaluation/Rewards Min                  0.113844\n",
      "evaluation/Returns Mean              5168.04\n",
      "evaluation/Returns Std                 13.22\n",
      "evaluation/Returns Max               5183.63\n",
      "evaluation/Returns Min               5143.16\n",
      "evaluation/Estimation Bias Mean      1163.22\n",
      "evaluation/Estimation Bias Std        189.07\n",
      "evaluation/EB/Q_True Mean              48.8766\n",
      "evaluation/EB/Q_True Std              151.062\n",
      "evaluation/EB/Q_Pred Mean            1212.1\n",
      "evaluation/EB/Q_Pred Std              117.788\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5168.04\n",
      "evaluation/Actions Mean                 0.506023\n",
      "evaluation/Actions Std                  0.651594\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90159\n",
      "time/backward_zf1 (s)                   2.0516\n",
      "time/backward_zf2 (s)                   1.99689\n",
      "time/data sampling (s)                  0.25075\n",
      "time/data storing (s)                   0.0139078\n",
      "time/evaluation sampling (s)            1.43462\n",
      "time/exploration sampling (s)           0.197881\n",
      "time/logging (s)                        0.0118825\n",
      "time/preback_alpha (s)                  0.563455\n",
      "time/preback_policy (s)                 1.15029\n",
      "time/preback_start (s)                  0.122934\n",
      "time/preback_zf (s)                     5.03621\n",
      "time/saving (s)                         0.0057648\n",
      "time/training (s)                       2.06806\n",
      "time/epoch (s)                         16.8058\n",
      "time/total (s)                       2185.51\n",
      "Epoch                                 133\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:28:52.390509 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 134 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 145000\n",
      "trainer/ZF1 Loss                       25.9553\n",
      "trainer/ZF2 Loss                       30.9764\n",
      "trainer/ZF Expert Reward               20.5898\n",
      "trainer/ZF Policy Reward                4.21676\n",
      "trainer/ZF CHI2 Term                   45.1401\n",
      "trainer/Policy Loss                  -869.836\n",
      "trainer/Bias Loss                     165.406\n",
      "trainer/Bias Value                     11.1399\n",
      "trainer/Policy Grad Norm              184.081\n",
      "trainer/Policy Param Norm              31.8395\n",
      "trainer/Zf1 Grad Norm                2163.91\n",
      "trainer/Zf1 Param Norm                 88.075\n",
      "trainer/Zf2 Grad Norm                3144.71\n",
      "trainer/Zf2 Param Norm                 86.1972\n",
      "trainer/Z Expert Predictions Mean    1200.88\n",
      "trainer/Z Expert Predictions Std      110.714\n",
      "trainer/Z Expert Predictions Max     1366.7\n",
      "trainer/Z Expert Predictions Min      703.028\n",
      "trainer/Z Policy Predictions Mean     856.646\n",
      "trainer/Z Policy Predictions Std      357.597\n",
      "trainer/Z Policy Predictions Max     1323.37\n",
      "trainer/Z Policy Predictions Min        4.95407\n",
      "trainer/Z Expert Targets Mean        1180.29\n",
      "trainer/Z Expert Targets Std          109.019\n",
      "trainer/Z Expert Targets Max         1340.01\n",
      "trainer/Z Expert Targets Min          698.26\n",
      "trainer/Z Policy Targets Mean         852.429\n",
      "trainer/Z Policy Targets Std          351.294\n",
      "trainer/Z Policy Targets Max         1327.89\n",
      "trainer/Z Policy Targets Min           -2.6454\n",
      "trainer/Log Pis Mean                   30.1238\n",
      "trainer/Log Pis Std                     8.91223\n",
      "trainer/Policy mu Mean                  1.29094\n",
      "trainer/Policy mu Std                   2.73459\n",
      "trainer/Policy log std Mean            -3.3791\n",
      "trainer/Policy log std Std              1.30674\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        140109\n",
      "exploration/num paths total           906\n",
      "evaluation/num steps total         806102\n",
      "evaluation/num paths total           1353\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1445\n",
      "evaluation/Rewards Std                  1.31513\n",
      "evaluation/Rewards Max                  7.07559\n",
      "evaluation/Rewards Min                  0.0786528\n",
      "evaluation/Returns Mean              5144.5\n",
      "evaluation/Returns Std                 20.2404\n",
      "evaluation/Returns Max               5177.5\n",
      "evaluation/Returns Min               5109.71\n",
      "evaluation/Estimation Bias Mean      1176.23\n",
      "evaluation/Estimation Bias Std        187.572\n",
      "evaluation/EB/Q_True Mean              48.9994\n",
      "evaluation/EB/Q_True Std              151.217\n",
      "evaluation/EB/Q_Pred Mean            1225.23\n",
      "evaluation/EB/Q_Pred Std              114.263\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5144.5\n",
      "evaluation/Actions Mean                 0.507864\n",
      "evaluation/Actions Std                  0.654206\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.74995\n",
      "time/backward_zf1 (s)                   1.88393\n",
      "time/backward_zf2 (s)                   1.79044\n",
      "time/data sampling (s)                  0.251897\n",
      "time/data storing (s)                   0.0145419\n",
      "time/evaluation sampling (s)            1.40024\n",
      "time/exploration sampling (s)           0.198555\n",
      "time/logging (s)                        0.0123761\n",
      "time/preback_alpha (s)                  0.56\n",
      "time/preback_policy (s)                 0.97359\n",
      "time/preback_start (s)                  0.121225\n",
      "time/preback_zf (s)                     5.05198\n",
      "time/saving (s)                         0.0057529\n",
      "time/training (s)                       2.47102\n",
      "time/epoch (s)                         16.4855\n",
      "time/total (s)                       2202.01\n",
      "Epoch                                 134\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:29:09.289362 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 135 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 146000\n",
      "trainer/ZF1 Loss                      337.304\n",
      "trainer/ZF2 Loss                      325.8\n",
      "trainer/ZF Expert Reward               17.497\n",
      "trainer/ZF Policy Reward                5.68873\n",
      "trainer/ZF CHI2 Term                  343.663\n",
      "trainer/Policy Loss                  -890.335\n",
      "trainer/Bias Loss                     128.997\n",
      "trainer/Bias Value                     11.1465\n",
      "trainer/Policy Grad Norm              255.837\n",
      "trainer/Policy Param Norm              31.876\n",
      "trainer/Zf1 Grad Norm                3530.04\n",
      "trainer/Zf1 Param Norm                 88.3199\n",
      "trainer/Zf2 Grad Norm                3055.95\n",
      "trainer/Zf2 Param Norm                 86.4657\n",
      "trainer/Z Expert Predictions Mean    1202.02\n",
      "trainer/Z Expert Predictions Std      109.435\n",
      "trainer/Z Expert Predictions Max     1373.42\n",
      "trainer/Z Expert Predictions Min      694.103\n",
      "trainer/Z Policy Predictions Mean     878.388\n",
      "trainer/Z Policy Predictions Std      360.578\n",
      "trainer/Z Policy Predictions Max     1349.07\n",
      "trainer/Z Policy Predictions Min        6.4695\n",
      "trainer/Z Expert Targets Mean        1184.52\n",
      "trainer/Z Expert Targets Std          108.579\n",
      "trainer/Z Expert Targets Max         1356.11\n",
      "trainer/Z Expert Targets Min          693.932\n",
      "trainer/Z Policy Targets Mean         872.699\n",
      "trainer/Z Policy Targets Std          359.708\n",
      "trainer/Z Policy Targets Max         1347.71\n",
      "trainer/Z Policy Targets Min           -2.40421\n",
      "trainer/Log Pis Mean                   30.2891\n",
      "trainer/Log Pis Std                     7.87493\n",
      "trainer/Policy mu Mean                  1.46129\n",
      "trainer/Policy mu Std                   2.65246\n",
      "trainer/Policy log std Mean            -3.21176\n",
      "trainer/Policy log std Std              1.37995\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        141109\n",
      "exploration/num paths total           907\n",
      "evaluation/num steps total         816102\n",
      "evaluation/num paths total           1363\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19554\n",
      "evaluation/Rewards Std                  1.33154\n",
      "evaluation/Rewards Max                  7.26116\n",
      "evaluation/Rewards Min                  0.102135\n",
      "evaluation/Returns Mean              5195.54\n",
      "evaluation/Returns Std                 21.762\n",
      "evaluation/Returns Max               5229.34\n",
      "evaluation/Returns Min               5153.13\n",
      "evaluation/Estimation Bias Mean      1170.01\n",
      "evaluation/Estimation Bias Std        188.839\n",
      "evaluation/EB/Q_True Mean              48.7893\n",
      "evaluation/EB/Q_True Std              150.73\n",
      "evaluation/EB/Q_Pred Mean            1218.8\n",
      "evaluation/EB/Q_Pred Std              117.716\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5195.54\n",
      "evaluation/Actions Mean                 0.507322\n",
      "evaluation/Actions Std                  0.65421\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999997\n",
      "time/backward_policy (s)                1.80979\n",
      "time/backward_zf1 (s)                   1.97531\n",
      "time/backward_zf2 (s)                   1.88694\n",
      "time/data sampling (s)                  0.258461\n",
      "time/data storing (s)                   0.0149158\n",
      "time/evaluation sampling (s)            1.40799\n",
      "time/exploration sampling (s)           0.199974\n",
      "time/logging (s)                        0.012166\n",
      "time/preback_alpha (s)                  0.568319\n",
      "time/preback_policy (s)                 1.00453\n",
      "time/preback_start (s)                  0.123324\n",
      "time/preback_zf (s)                     5.09315\n",
      "time/saving (s)                         0.005403\n",
      "time/training (s)                       2.47103\n",
      "time/epoch (s)                         16.8313\n",
      "time/total (s)                       2218.86\n",
      "Epoch                                 135\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:29:26.222900 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 136 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 147000\n",
      "trainer/ZF1 Loss                       30.3391\n",
      "trainer/ZF2 Loss                       20.6556\n",
      "trainer/ZF Expert Reward               13.0009\n",
      "trainer/ZF Policy Reward               -2.41055\n",
      "trainer/ZF CHI2 Term                   41.2061\n",
      "trainer/Policy Loss                  -929.791\n",
      "trainer/Bias Loss                     125.959\n",
      "trainer/Bias Value                     11.1531\n",
      "trainer/Policy Grad Norm              211.472\n",
      "trainer/Policy Param Norm              31.9108\n",
      "trainer/Zf1 Grad Norm                8407.69\n",
      "trainer/Zf1 Param Norm                 88.5479\n",
      "trainer/Zf2 Grad Norm                2437.19\n",
      "trainer/Zf2 Param Norm                 86.7099\n",
      "trainer/Z Expert Predictions Mean    1193.54\n",
      "trainer/Z Expert Predictions Std      136.044\n",
      "trainer/Z Expert Predictions Max     1381.29\n",
      "trainer/Z Expert Predictions Min      134.163\n",
      "trainer/Z Policy Predictions Mean     920.617\n",
      "trainer/Z Policy Predictions Std      324.659\n",
      "trainer/Z Policy Predictions Max     1333.08\n",
      "trainer/Z Policy Predictions Min      -19.1601\n",
      "trainer/Z Expert Targets Mean        1180.54\n",
      "trainer/Z Expert Targets Std          139.34\n",
      "trainer/Z Expert Targets Max         1362.43\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         923.027\n",
      "trainer/Z Policy Targets Std          322.854\n",
      "trainer/Z Policy Targets Max         1348.98\n",
      "trainer/Z Policy Targets Min          -16.9437\n",
      "trainer/Log Pis Mean                   29.733\n",
      "trainer/Log Pis Std                     7.72802\n",
      "trainer/Policy mu Mean                  1.44869\n",
      "trainer/Policy mu Std                   2.47869\n",
      "trainer/Policy log std Mean            -3.31924\n",
      "trainer/Policy log std Std              1.36595\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        144109\n",
      "exploration/num paths total           910\n",
      "evaluation/num steps total         826102\n",
      "evaluation/num paths total           1373\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2169\n",
      "evaluation/Rewards Std                  1.33217\n",
      "evaluation/Rewards Max                  7.29318\n",
      "evaluation/Rewards Min                  0.13117\n",
      "evaluation/Returns Mean              5216.9\n",
      "evaluation/Returns Std                 16.2638\n",
      "evaluation/Returns Max               5238.82\n",
      "evaluation/Returns Min               5178.63\n",
      "evaluation/Estimation Bias Mean      1182.07\n",
      "evaluation/Estimation Bias Std        190.845\n",
      "evaluation/EB/Q_True Mean              48.9979\n",
      "evaluation/EB/Q_True Std              151.356\n",
      "evaluation/EB/Q_Pred Mean            1231.07\n",
      "evaluation/EB/Q_Pred Std              116.829\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5216.9\n",
      "evaluation/Actions Mean                 0.50223\n",
      "evaluation/Actions Std                  0.654979\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.92211\n",
      "time/backward_zf1 (s)                   2.05171\n",
      "time/backward_zf2 (s)                   1.99369\n",
      "time/data sampling (s)                  0.24824\n",
      "time/data storing (s)                   0.0148918\n",
      "time/evaluation sampling (s)            1.41503\n",
      "time/exploration sampling (s)           0.20548\n",
      "time/logging (s)                        0.0116406\n",
      "time/preback_alpha (s)                  0.567406\n",
      "time/preback_policy (s)                 1.15782\n",
      "time/preback_start (s)                  0.124182\n",
      "time/preback_zf (s)                     5.05239\n",
      "time/saving (s)                         0.00903191\n",
      "time/training (s)                       2.08463\n",
      "time/epoch (s)                         16.8583\n",
      "time/total (s)                       2235.75\n",
      "Epoch                                 136\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:29:42.920302 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 137 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 148000\n",
      "trainer/ZF1 Loss                       35.739\n",
      "trainer/ZF2 Loss                       26.9416\n",
      "trainer/ZF Expert Reward               14.7024\n",
      "trainer/ZF Policy Reward               -0.0602242\n",
      "trainer/ZF CHI2 Term                   46.4009\n",
      "trainer/Policy Loss                  -894.815\n",
      "trainer/Bias Loss                     147.721\n",
      "trainer/Bias Value                     11.16\n",
      "trainer/Policy Grad Norm              243.023\n",
      "trainer/Policy Param Norm              31.9488\n",
      "trainer/Zf1 Grad Norm                5742.45\n",
      "trainer/Zf1 Param Norm                 88.8307\n",
      "trainer/Zf2 Grad Norm                2830.01\n",
      "trainer/Zf2 Param Norm                 87.009\n",
      "trainer/Z Expert Predictions Mean    1209.74\n",
      "trainer/Z Expert Predictions Std      111.472\n",
      "trainer/Z Expert Predictions Max     1406.15\n",
      "trainer/Z Expert Predictions Min      786.109\n",
      "trainer/Z Policy Predictions Mean     887.174\n",
      "trainer/Z Policy Predictions Std      363.416\n",
      "trainer/Z Policy Predictions Max     1349.04\n",
      "trainer/Z Policy Predictions Min       19.7602\n",
      "trainer/Z Expert Targets Mean        1195.04\n",
      "trainer/Z Expert Targets Std          109.212\n",
      "trainer/Z Expert Targets Max         1388.05\n",
      "trainer/Z Expert Targets Min          781.2\n",
      "trainer/Z Policy Targets Mean         887.235\n",
      "trainer/Z Policy Targets Std          361.661\n",
      "trainer/Z Policy Targets Max         1358.72\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.7907\n",
      "trainer/Log Pis Std                     8.0488\n",
      "trainer/Policy mu Mean                  1.34285\n",
      "trainer/Policy mu Std                   2.72002\n",
      "trainer/Policy log std Mean            -3.24308\n",
      "trainer/Policy log std Std              1.38759\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        144109\n",
      "exploration/num paths total           910\n",
      "evaluation/num steps total         836102\n",
      "evaluation/num paths total           1383\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16265\n",
      "evaluation/Rewards Std                  1.31318\n",
      "evaluation/Rewards Max                  7.2043\n",
      "evaluation/Rewards Min                  0.110331\n",
      "evaluation/Returns Mean              5162.65\n",
      "evaluation/Returns Std                 11.4517\n",
      "evaluation/Returns Max               5185.14\n",
      "evaluation/Returns Min               5143.01\n",
      "evaluation/Estimation Bias Mean      1173.61\n",
      "evaluation/Estimation Bias Std        190.327\n",
      "evaluation/EB/Q_True Mean              48.8007\n",
      "evaluation/EB/Q_True Std              150.76\n",
      "evaluation/EB/Q_Pred Mean            1222.41\n",
      "evaluation/EB/Q_Pred Std              117.637\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5162.65\n",
      "evaluation/Actions Mean                 0.495267\n",
      "evaluation/Actions Std                  0.660136\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.77636\n",
      "time/backward_zf1 (s)                   1.92697\n",
      "time/backward_zf2 (s)                   1.83887\n",
      "time/data sampling (s)                  0.26804\n",
      "time/data storing (s)                   0.0140576\n",
      "time/evaluation sampling (s)            1.43015\n",
      "time/exploration sampling (s)           0.193587\n",
      "time/logging (s)                        0.0122148\n",
      "time/preback_alpha (s)                  0.560361\n",
      "time/preback_policy (s)                 1.01381\n",
      "time/preback_start (s)                  0.122403\n",
      "time/preback_zf (s)                     5.06504\n",
      "time/saving (s)                         0.00551469\n",
      "time/training (s)                       2.40068\n",
      "time/epoch (s)                         16.6281\n",
      "time/total (s)                       2252.4\n",
      "Epoch                                 137\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:30:00.134563 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 138 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 149000\n",
      "trainer/ZF1 Loss                       37.1947\n",
      "trainer/ZF2 Loss                       36.8363\n",
      "trainer/ZF Expert Reward               11.6609\n",
      "trainer/ZF Policy Reward                1.474\n",
      "trainer/ZF CHI2 Term                   47.5038\n",
      "trainer/Policy Loss                  -881.282\n",
      "trainer/Bias Loss                     103.706\n",
      "trainer/Bias Value                     11.1669\n",
      "trainer/Policy Grad Norm              237.415\n",
      "trainer/Policy Param Norm              31.9854\n",
      "trainer/Zf1 Grad Norm                2352.98\n",
      "trainer/Zf1 Param Norm                 89.0772\n",
      "trainer/Zf2 Grad Norm                2030.96\n",
      "trainer/Zf2 Param Norm                 87.278\n",
      "trainer/Z Expert Predictions Mean    1195.72\n",
      "trainer/Z Expert Predictions Std      128.846\n",
      "trainer/Z Expert Predictions Max     1395.71\n",
      "trainer/Z Expert Predictions Min      697.088\n",
      "trainer/Z Policy Predictions Mean     870.438\n",
      "trainer/Z Policy Predictions Std      348.767\n",
      "trainer/Z Policy Predictions Max     1353.11\n",
      "trainer/Z Policy Predictions Min      -38.0105\n",
      "trainer/Z Expert Targets Mean        1184.06\n",
      "trainer/Z Expert Targets Std          127.047\n",
      "trainer/Z Expert Targets Max         1379.91\n",
      "trainer/Z Expert Targets Min          705.669\n",
      "trainer/Z Policy Targets Mean         868.965\n",
      "trainer/Z Policy Targets Std          346.15\n",
      "trainer/Z Policy Targets Max         1344.51\n",
      "trainer/Z Policy Targets Min          -36.4591\n",
      "trainer/Log Pis Mean                   30.1405\n",
      "trainer/Log Pis Std                     8.38993\n",
      "trainer/Policy mu Mean                  1.39007\n",
      "trainer/Policy mu Std                   2.71161\n",
      "trainer/Policy log std Mean            -3.23977\n",
      "trainer/Policy log std Std              1.36762\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        144109\n",
      "exploration/num paths total           910\n",
      "evaluation/num steps total         843882\n",
      "evaluation/num paths total           1393\n",
      "evaluation/path length Mean           778\n",
      "evaluation/path length Std            189.653\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            543\n",
      "evaluation/Rewards Mean                 5.09018\n",
      "evaluation/Rewards Std                  1.457\n",
      "evaluation/Rewards Max                  7.49411\n",
      "evaluation/Rewards Min                  0.111721\n",
      "evaluation/Returns Mean              3960.16\n",
      "evaluation/Returns Std               1068.47\n",
      "evaluation/Returns Max               5223.14\n",
      "evaluation/Returns Min               2581.32\n",
      "evaluation/Estimation Bias Mean      1079.99\n",
      "evaluation/Estimation Bias Std        314.724\n",
      "evaluation/EB/Q_True Mean              63.0337\n",
      "evaluation/EB/Q_True Std              169.229\n",
      "evaluation/EB/Q_Pred Mean            1143.02\n",
      "evaluation/EB/Q_Pred Std              243.901\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3960.16\n",
      "evaluation/Actions Mean                 0.493728\n",
      "evaluation/Actions Std                  0.664089\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97531\n",
      "time/backward_zf1 (s)                   2.13276\n",
      "time/backward_zf2 (s)                   2.0743\n",
      "time/data sampling (s)                  0.254036\n",
      "time/data storing (s)                   0.0141503\n",
      "time/evaluation sampling (s)            1.4138\n",
      "time/exploration sampling (s)           0.192932\n",
      "time/logging (s)                        0.00950449\n",
      "time/preback_alpha (s)                  0.572831\n",
      "time/preback_policy (s)                 1.18695\n",
      "time/preback_start (s)                  0.123698\n",
      "time/preback_zf (s)                     5.09205\n",
      "time/saving (s)                         0.00569292\n",
      "time/training (s)                       2.09441\n",
      "time/epoch (s)                         17.1424\n",
      "time/total (s)                       2269.57\n",
      "Epoch                                 138\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:30:17.403793 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 139 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 150000\n",
      "trainer/ZF1 Loss                       33.6678\n",
      "trainer/ZF2 Loss                       43.8954\n",
      "trainer/ZF Expert Reward                8.36422\n",
      "trainer/ZF Policy Reward               -3.34034\n",
      "trainer/ZF CHI2 Term                   50.7834\n",
      "trainer/Policy Loss                  -952.287\n",
      "trainer/Bias Loss                     144.073\n",
      "trainer/Bias Value                     11.1738\n",
      "trainer/Policy Grad Norm              249.985\n",
      "trainer/Policy Param Norm              32.0183\n",
      "trainer/Zf1 Grad Norm                3002.2\n",
      "trainer/Zf1 Param Norm                 89.3211\n",
      "trainer/Zf2 Grad Norm                4162.25\n",
      "trainer/Zf2 Param Norm                 87.5551\n",
      "trainer/Z Expert Predictions Mean    1203.91\n",
      "trainer/Z Expert Predictions Std      114.119\n",
      "trainer/Z Expert Predictions Max     1376.89\n",
      "trainer/Z Expert Predictions Min      753.86\n",
      "trainer/Z Policy Predictions Mean     939.352\n",
      "trainer/Z Policy Predictions Std      340.164\n",
      "trainer/Z Policy Predictions Max     1339.19\n",
      "trainer/Z Policy Predictions Min      -20.8685\n",
      "trainer/Z Expert Targets Mean        1195.54\n",
      "trainer/Z Expert Targets Std          113.337\n",
      "trainer/Z Expert Targets Max         1362.01\n",
      "trainer/Z Expert Targets Min          754.474\n",
      "trainer/Z Policy Targets Mean         942.692\n",
      "trainer/Z Policy Targets Std          338.966\n",
      "trainer/Z Policy Targets Max         1353.28\n",
      "trainer/Z Policy Targets Min          -20.3002\n",
      "trainer/Log Pis Mean                   29.7241\n",
      "trainer/Log Pis Std                     7.03077\n",
      "trainer/Policy mu Mean                  1.56403\n",
      "trainer/Policy mu Std                   2.54219\n",
      "trainer/Policy log std Mean            -3.19224\n",
      "trainer/Policy log std Std              1.36209\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        145109\n",
      "exploration/num paths total           911\n",
      "evaluation/num steps total         853882\n",
      "evaluation/num paths total           1403\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21032\n",
      "evaluation/Rewards Std                  1.32958\n",
      "evaluation/Rewards Max                  7.39452\n",
      "evaluation/Rewards Min                  0.101297\n",
      "evaluation/Returns Mean              5210.32\n",
      "evaluation/Returns Std                 17.2472\n",
      "evaluation/Returns Max               5234.53\n",
      "evaluation/Returns Min               5178.31\n",
      "evaluation/Estimation Bias Mean      1182.66\n",
      "evaluation/Estimation Bias Std        187.094\n",
      "evaluation/EB/Q_True Mean              49.07\n",
      "evaluation/EB/Q_True Std              151.383\n",
      "evaluation/EB/Q_Pred Mean            1231.73\n",
      "evaluation/EB/Q_Pred Std              114.207\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5210.32\n",
      "evaluation/Actions Mean                 0.503514\n",
      "evaluation/Actions Std                  0.652788\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99544\n",
      "time/backward_zf1 (s)                   2.14055\n",
      "time/backward_zf2 (s)                   2.09381\n",
      "time/data sampling (s)                  0.270199\n",
      "time/data storing (s)                   0.0149335\n",
      "time/evaluation sampling (s)            1.43331\n",
      "time/exploration sampling (s)           0.200168\n",
      "time/logging (s)                        0.0125735\n",
      "time/preback_alpha (s)                  0.567834\n",
      "time/preback_policy (s)                 1.18392\n",
      "time/preback_start (s)                  0.12401\n",
      "time/preback_zf (s)                     5.08013\n",
      "time/saving (s)                         0.0180108\n",
      "time/training (s)                       2.06775\n",
      "time/epoch (s)                         17.2027\n",
      "time/total (s)                       2286.79\n",
      "Epoch                                 139\n",
      "---------------------------------  --------------\n",
      "2024-06-25 18:30:34.950940 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 140 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 151000\n",
      "trainer/ZF1 Loss                       27.3068\n",
      "trainer/ZF2 Loss                       29.963\n",
      "trainer/ZF Expert Reward               11.6022\n",
      "trainer/ZF Policy Reward               -4.58457\n",
      "trainer/ZF CHI2 Term                   45.1167\n",
      "trainer/Policy Loss                  -905.163\n",
      "trainer/Bias Loss                     106.289\n",
      "trainer/Bias Value                     11.1804\n",
      "trainer/Policy Grad Norm              258.912\n",
      "trainer/Policy Param Norm              32.0425\n",
      "trainer/Zf1 Grad Norm                2540.21\n",
      "trainer/Zf1 Param Norm                 89.5628\n",
      "trainer/Zf2 Grad Norm                3308.52\n",
      "trainer/Zf2 Param Norm                 87.8197\n",
      "trainer/Z Expert Predictions Mean    1211.97\n",
      "trainer/Z Expert Predictions Std      104.552\n",
      "trainer/Z Expert Predictions Max     1378.13\n",
      "trainer/Z Expert Predictions Min      743.817\n",
      "trainer/Z Policy Predictions Mean     890.279\n",
      "trainer/Z Policy Predictions Std      361.99\n",
      "trainer/Z Policy Predictions Max     1362.47\n",
      "trainer/Z Policy Predictions Min       21.3004\n",
      "trainer/Z Expert Targets Mean        1200.37\n",
      "trainer/Z Expert Targets Std          101.684\n",
      "trainer/Z Expert Targets Max         1362.85\n",
      "trainer/Z Expert Targets Min          738.976\n",
      "trainer/Z Policy Targets Mean         894.863\n",
      "trainer/Z Policy Targets Std          357.827\n",
      "trainer/Z Policy Targets Max         1340.11\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.4991\n",
      "trainer/Log Pis Std                     7.71174\n",
      "trainer/Policy mu Mean                  1.43932\n",
      "trainer/Policy mu Std                   2.5636\n",
      "trainer/Policy log std Mean            -3.15315\n",
      "trainer/Policy log std Std              1.35018\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        145109\n",
      "exploration/num paths total           911\n",
      "evaluation/num steps total         861072\n",
      "evaluation/num paths total           1413\n",
      "evaluation/path length Mean           719\n",
      "evaluation/path length Std            148.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            572\n",
      "evaluation/Rewards Mean                 5.05461\n",
      "evaluation/Rewards Std                  1.476\n",
      "evaluation/Rewards Max                  7.27617\n",
      "evaluation/Rewards Min                  0.146742\n",
      "evaluation/Returns Mean              3634.27\n",
      "evaluation/Returns Std                837.92\n",
      "evaluation/Returns Max               5241.89\n",
      "evaluation/Returns Min               2813.91\n",
      "evaluation/Estimation Bias Mean      1017.68\n",
      "evaluation/Estimation Bias Std        322.088\n",
      "evaluation/EB/Q_True Mean              68.9163\n",
      "evaluation/EB/Q_True Std              176.745\n",
      "evaluation/EB/Q_Pred Mean            1086.6\n",
      "evaluation/EB/Q_Pred Std              262.104\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3634.27\n",
      "evaluation/Actions Mean                 0.503664\n",
      "evaluation/Actions Std                  0.657582\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.02896\n",
      "time/backward_zf1 (s)                   2.16376\n",
      "time/backward_zf2 (s)                   2.10665\n",
      "time/data sampling (s)                  0.274382\n",
      "time/data storing (s)                   0.0145181\n",
      "time/evaluation sampling (s)            1.50677\n",
      "time/exploration sampling (s)           0.201549\n",
      "time/logging (s)                        0.00880959\n",
      "time/preback_alpha (s)                  0.583013\n",
      "time/preback_policy (s)                 1.19771\n",
      "time/preback_start (s)                  0.126688\n",
      "time/preback_zf (s)                     5.09622\n",
      "time/saving (s)                         0.00586991\n",
      "time/training (s)                       2.15954\n",
      "time/epoch (s)                         17.4745\n",
      "time/total (s)                       2304.29\n",
      "Epoch                                 140\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:30:52.279346 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 141 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 152000\n",
      "trainer/ZF1 Loss                       26.2389\n",
      "trainer/ZF2 Loss                       34.034\n",
      "trainer/ZF Expert Reward               21.4445\n",
      "trainer/ZF Policy Reward                3.82436\n",
      "trainer/ZF CHI2 Term                   48.0513\n",
      "trainer/Policy Loss                  -930.157\n",
      "trainer/Bias Loss                     194.964\n",
      "trainer/Bias Value                     11.1869\n",
      "trainer/Policy Grad Norm              180.261\n",
      "trainer/Policy Param Norm              32.0743\n",
      "trainer/Zf1 Grad Norm                1373.24\n",
      "trainer/Zf1 Param Norm                 89.772\n",
      "trainer/Zf2 Grad Norm                2265.3\n",
      "trainer/Zf2 Param Norm                 88.0516\n",
      "trainer/Z Expert Predictions Mean    1208.23\n",
      "trainer/Z Expert Predictions Std      114.217\n",
      "trainer/Z Expert Predictions Max     1387.42\n",
      "trainer/Z Expert Predictions Min      746.359\n",
      "trainer/Z Policy Predictions Mean     914.123\n",
      "trainer/Z Policy Predictions Std      357.439\n",
      "trainer/Z Policy Predictions Max     1358.11\n",
      "trainer/Z Policy Predictions Min      -43.4179\n",
      "trainer/Z Expert Targets Mean        1186.79\n",
      "trainer/Z Expert Targets Std          114.044\n",
      "trainer/Z Expert Targets Max         1368.69\n",
      "trainer/Z Expert Targets Min          738.621\n",
      "trainer/Z Policy Targets Mean         910.299\n",
      "trainer/Z Policy Targets Std          351.322\n",
      "trainer/Z Policy Targets Max         1351.64\n",
      "trainer/Z Policy Targets Min          -33.2402\n",
      "trainer/Log Pis Mean                   29.4627\n",
      "trainer/Log Pis Std                     6.9457\n",
      "trainer/Policy mu Mean                  1.35304\n",
      "trainer/Policy mu Std                   2.47092\n",
      "trainer/Policy log std Mean            -3.30738\n",
      "trainer/Policy log std Std              1.31289\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        146109\n",
      "exploration/num paths total           912\n",
      "evaluation/num steps total         871072\n",
      "evaluation/num paths total           1423\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1965\n",
      "evaluation/Rewards Std                  1.30925\n",
      "evaluation/Rewards Max                  7.37266\n",
      "evaluation/Rewards Min                  0.148562\n",
      "evaluation/Returns Mean              5196.5\n",
      "evaluation/Returns Std                 27.4281\n",
      "evaluation/Returns Max               5256.3\n",
      "evaluation/Returns Min               5160.36\n",
      "evaluation/Estimation Bias Mean      1176.44\n",
      "evaluation/Estimation Bias Std        183.897\n",
      "evaluation/EB/Q_True Mean              49.0083\n",
      "evaluation/EB/Q_True Std              151.577\n",
      "evaluation/EB/Q_Pred Mean            1225.45\n",
      "evaluation/EB/Q_Pred Std              108.124\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5196.5\n",
      "evaluation/Actions Mean                 0.518971\n",
      "evaluation/Actions Std                  0.646575\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94528\n",
      "time/backward_zf1 (s)                   2.13757\n",
      "time/backward_zf2 (s)                   2.0482\n",
      "time/data sampling (s)                  0.276255\n",
      "time/data storing (s)                   0.0139651\n",
      "time/evaluation sampling (s)            1.39529\n",
      "time/exploration sampling (s)           0.19519\n",
      "time/logging (s)                        0.012154\n",
      "time/preback_alpha (s)                  0.578295\n",
      "time/preback_policy (s)                 1.09032\n",
      "time/preback_start (s)                  0.123743\n",
      "time/preback_zf (s)                     5.10837\n",
      "time/saving (s)                         0.00581148\n",
      "time/training (s)                       2.32861\n",
      "time/epoch (s)                         17.259\n",
      "time/total (s)                       2321.57\n",
      "Epoch                                 141\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:31:09.262053 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 142 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 153000\n",
      "trainer/ZF1 Loss                       25.3233\n",
      "trainer/ZF2 Loss                       33.046\n",
      "trainer/ZF Expert Reward               19.5734\n",
      "trainer/ZF Policy Reward                1.79312\n",
      "trainer/ZF CHI2 Term                   47.2632\n",
      "trainer/Policy Loss                  -924.715\n",
      "trainer/Bias Loss                     214.682\n",
      "trainer/Bias Value                     11.1935\n",
      "trainer/Policy Grad Norm              217.532\n",
      "trainer/Policy Param Norm              32.1064\n",
      "trainer/Zf1 Grad Norm                1879.82\n",
      "trainer/Zf1 Param Norm                 90.0016\n",
      "trainer/Zf2 Grad Norm                2292.97\n",
      "trainer/Zf2 Param Norm                 88.2734\n",
      "trainer/Z Expert Predictions Mean    1212.44\n",
      "trainer/Z Expert Predictions Std      112.5\n",
      "trainer/Z Expert Predictions Max     1368.73\n",
      "trainer/Z Expert Predictions Min      734.618\n",
      "trainer/Z Policy Predictions Mean     912.907\n",
      "trainer/Z Policy Predictions Std      341.954\n",
      "trainer/Z Policy Predictions Max     1327.15\n",
      "trainer/Z Policy Predictions Min      -28.0853\n",
      "trainer/Z Expert Targets Mean        1192.87\n",
      "trainer/Z Expert Targets Std          112.384\n",
      "trainer/Z Expert Targets Max         1355.54\n",
      "trainer/Z Expert Targets Min          731.207\n",
      "trainer/Z Policy Targets Mean         911.113\n",
      "trainer/Z Policy Targets Std          331.765\n",
      "trainer/Z Policy Targets Max         1313.02\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.8278\n",
      "trainer/Log Pis Std                     7.66432\n",
      "trainer/Policy mu Mean                  1.41991\n",
      "trainer/Policy mu Std                   2.61416\n",
      "trainer/Policy log std Mean            -3.30127\n",
      "trainer/Policy log std Std              1.34457\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        147109\n",
      "exploration/num paths total           913\n",
      "evaluation/num steps total         881072\n",
      "evaluation/num paths total           1433\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1256\n",
      "evaluation/Rewards Std                  1.3534\n",
      "evaluation/Rewards Max                  7.39306\n",
      "evaluation/Rewards Min                  0.107231\n",
      "evaluation/Returns Mean              5125.6\n",
      "evaluation/Returns Std                209.635\n",
      "evaluation/Returns Max               5250.84\n",
      "evaluation/Returns Min               4610.97\n",
      "evaluation/Estimation Bias Mean      1152.74\n",
      "evaluation/Estimation Bias Std        194.708\n",
      "evaluation/EB/Q_True Mean              49.5682\n",
      "evaluation/EB/Q_True Std              152.902\n",
      "evaluation/EB/Q_Pred Mean            1202.31\n",
      "evaluation/EB/Q_Pred Std              133.335\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5125.6\n",
      "evaluation/Actions Mean                 0.518567\n",
      "evaluation/Actions Std                  0.650676\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.88157\n",
      "time/backward_zf1 (s)                   2.02162\n",
      "time/backward_zf2 (s)                   1.95752\n",
      "time/data sampling (s)                  0.263347\n",
      "time/data storing (s)                   0.0146825\n",
      "time/evaluation sampling (s)            1.44337\n",
      "time/exploration sampling (s)           0.198718\n",
      "time/logging (s)                        0.0157067\n",
      "time/preback_alpha (s)                  0.570761\n",
      "time/preback_policy (s)                 1.10098\n",
      "time/preback_start (s)                  0.123232\n",
      "time/preback_zf (s)                     5.08813\n",
      "time/saving (s)                         0.00610218\n",
      "time/training (s)                       2.23165\n",
      "time/epoch (s)                         16.9174\n",
      "time/total (s)                       2338.51\n",
      "Epoch                                 142\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:31:26.657390 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 143 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 154000\n",
      "trainer/ZF1 Loss                       19.0855\n",
      "trainer/ZF2 Loss                       18.7411\n",
      "trainer/ZF Expert Reward               16.4963\n",
      "trainer/ZF Policy Reward               -0.769919\n",
      "trainer/ZF CHI2 Term                   36.4843\n",
      "trainer/Policy Loss                  -921.892\n",
      "trainer/Bias Loss                      77.6838\n",
      "trainer/Bias Value                     11.2003\n",
      "trainer/Policy Grad Norm              233.024\n",
      "trainer/Policy Param Norm              32.1333\n",
      "trainer/Zf1 Grad Norm                1876.22\n",
      "trainer/Zf1 Param Norm                 90.2218\n",
      "trainer/Zf2 Grad Norm                1432.69\n",
      "trainer/Zf2 Param Norm                 88.4862\n",
      "trainer/Z Expert Predictions Mean    1218.9\n",
      "trainer/Z Expert Predictions Std      103.503\n",
      "trainer/Z Expert Predictions Max     1371.28\n",
      "trainer/Z Expert Predictions Min      723.376\n",
      "trainer/Z Policy Predictions Mean     908.24\n",
      "trainer/Z Policy Predictions Std      358.328\n",
      "trainer/Z Policy Predictions Max     1323.84\n",
      "trainer/Z Policy Predictions Min      -13.484\n",
      "trainer/Z Expert Targets Mean        1202.41\n",
      "trainer/Z Expert Targets Std          102.031\n",
      "trainer/Z Expert Targets Max         1347.33\n",
      "trainer/Z Expert Targets Min          725.633\n",
      "trainer/Z Policy Targets Mean         909.01\n",
      "trainer/Z Policy Targets Std          352.248\n",
      "trainer/Z Policy Targets Max         1304.36\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   30.4721\n",
      "trainer/Log Pis Std                     8.54368\n",
      "trainer/Policy mu Mean                  1.38705\n",
      "trainer/Policy mu Std                   2.65817\n",
      "trainer/Policy log std Mean            -3.31404\n",
      "trainer/Policy log std Std              1.36356\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        149109\n",
      "exploration/num paths total           915\n",
      "evaluation/num steps total         890750\n",
      "evaluation/num paths total           1443\n",
      "evaluation/path length Mean           967.8\n",
      "evaluation/path length Std             96.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            678\n",
      "evaluation/Rewards Mean                 5.10237\n",
      "evaluation/Rewards Std                  1.31853\n",
      "evaluation/Rewards Max                  7.34915\n",
      "evaluation/Rewards Min                  0.115065\n",
      "evaluation/Returns Mean              4938.07\n",
      "evaluation/Returns Std                558.299\n",
      "evaluation/Returns Max               5162.29\n",
      "evaluation/Returns Min               3263.95\n",
      "evaluation/Estimation Bias Mean      1149.78\n",
      "evaluation/Estimation Bias Std        223.577\n",
      "evaluation/EB/Q_True Mean              49.9682\n",
      "evaluation/EB/Q_True Std              151.708\n",
      "evaluation/EB/Q_Pred Mean            1199.75\n",
      "evaluation/EB/Q_Pred Std              128.579\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4938.07\n",
      "evaluation/Actions Mean                 0.506806\n",
      "evaluation/Actions Std                  0.653005\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97943\n",
      "time/backward_zf1 (s)                   2.13838\n",
      "time/backward_zf2 (s)                   2.07949\n",
      "time/data sampling (s)                  0.275213\n",
      "time/data storing (s)                   0.015018\n",
      "time/evaluation sampling (s)            1.48332\n",
      "time/exploration sampling (s)           0.202077\n",
      "time/logging (s)                        0.0118731\n",
      "time/preback_alpha (s)                  0.57991\n",
      "time/preback_policy (s)                 1.17608\n",
      "time/preback_start (s)                  0.126074\n",
      "time/preback_zf (s)                     5.12935\n",
      "time/saving (s)                         0.00584457\n",
      "time/training (s)                       2.1218\n",
      "time/epoch (s)                         17.3239\n",
      "time/total (s)                       2355.85\n",
      "Epoch                                 143\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:31:43.613512 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 144 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 155000\n",
      "trainer/ZF1 Loss                      287.261\n",
      "trainer/ZF2 Loss                      301.201\n",
      "trainer/ZF Expert Reward               16.2281\n",
      "trainer/ZF Policy Reward               -5.6299\n",
      "trainer/ZF CHI2 Term                  316.391\n",
      "trainer/Policy Loss                  -891.797\n",
      "trainer/Bias Loss                    2766.28\n",
      "trainer/Bias Value                     11.207\n",
      "trainer/Policy Grad Norm              262.093\n",
      "trainer/Policy Param Norm              32.1655\n",
      "trainer/Zf1 Grad Norm                4318.13\n",
      "trainer/Zf1 Param Norm                 90.4271\n",
      "trainer/Zf2 Grad Norm                4807.59\n",
      "trainer/Zf2 Param Norm                 88.7019\n",
      "trainer/Z Expert Predictions Mean    1196.21\n",
      "trainer/Z Expert Predictions Std      126.198\n",
      "trainer/Z Expert Predictions Max     1352.19\n",
      "trainer/Z Expert Predictions Min      712.58\n",
      "trainer/Z Policy Predictions Mean     877.938\n",
      "trainer/Z Policy Predictions Std      379.028\n",
      "trainer/Z Policy Predictions Max     1326.47\n",
      "trainer/Z Policy Predictions Min      -38.0459\n",
      "trainer/Z Expert Targets Mean        1179.98\n",
      "trainer/Z Expert Targets Std          143.772\n",
      "trainer/Z Expert Targets Max         1357.94\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         883.568\n",
      "trainer/Z Policy Targets Std          374.898\n",
      "trainer/Z Policy Targets Max         1315.49\n",
      "trainer/Z Policy Targets Min          -13.9134\n",
      "trainer/Log Pis Mean                   30.1531\n",
      "trainer/Log Pis Std                     8.0056\n",
      "trainer/Policy mu Mean                  1.30451\n",
      "trainer/Policy mu Std                   2.76715\n",
      "trainer/Policy log std Mean            -3.21891\n",
      "trainer/Policy log std Std              1.3534\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        150109\n",
      "exploration/num paths total           916\n",
      "evaluation/num steps total         900121\n",
      "evaluation/num paths total           1453\n",
      "evaluation/path length Mean           937.1\n",
      "evaluation/path length Std            109.673\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            654\n",
      "evaluation/Rewards Mean                 5.20327\n",
      "evaluation/Rewards Std                  1.38931\n",
      "evaluation/Rewards Max                  7.42329\n",
      "evaluation/Rewards Min                  0.0912284\n",
      "evaluation/Returns Mean              4875.98\n",
      "evaluation/Returns Std                656.324\n",
      "evaluation/Returns Max               5309.95\n",
      "evaluation/Returns Min               3201.8\n",
      "evaluation/Estimation Bias Mean      1149.46\n",
      "evaluation/Estimation Bias Std        270.243\n",
      "evaluation/EB/Q_True Mean              52.5381\n",
      "evaluation/EB/Q_True Std              157.05\n",
      "evaluation/EB/Q_Pred Mean            1202\n",
      "evaluation/EB/Q_Pred Std              184.42\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4875.98\n",
      "evaluation/Actions Mean                 0.507961\n",
      "evaluation/Actions Std                  0.656291\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88022\n",
      "time/backward_zf1 (s)                   2.02851\n",
      "time/backward_zf2 (s)                   1.9389\n",
      "time/data sampling (s)                  0.270817\n",
      "time/data storing (s)                   0.0150609\n",
      "time/evaluation sampling (s)            1.36155\n",
      "time/exploration sampling (s)           0.201294\n",
      "time/logging (s)                        0.011239\n",
      "time/preback_alpha (s)                  0.573726\n",
      "time/preback_policy (s)                 1.07877\n",
      "time/preback_start (s)                  0.123804\n",
      "time/preback_zf (s)                     5.07342\n",
      "time/saving (s)                         0.00537255\n",
      "time/training (s)                       2.32561\n",
      "time/epoch (s)                         16.8883\n",
      "time/total (s)                       2372.76\n",
      "Epoch                                 144\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:32:00.891478 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 145 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 156000\n",
      "trainer/ZF1 Loss                       19.054\n",
      "trainer/ZF2 Loss                       23.6616\n",
      "trainer/ZF Expert Reward               11.3785\n",
      "trainer/ZF Policy Reward               -1.00535\n",
      "trainer/ZF CHI2 Term                   34.0451\n",
      "trainer/Policy Loss                  -937.155\n",
      "trainer/Bias Loss                      81.0589\n",
      "trainer/Bias Value                     11.2133\n",
      "trainer/Policy Grad Norm              244.049\n",
      "trainer/Policy Param Norm              32.2023\n",
      "trainer/Zf1 Grad Norm                2056.36\n",
      "trainer/Zf1 Param Norm                 90.6286\n",
      "trainer/Zf2 Grad Norm                1650.24\n",
      "trainer/Zf2 Param Norm                 88.8941\n",
      "trainer/Z Expert Predictions Mean    1191.37\n",
      "trainer/Z Expert Predictions Std      119.807\n",
      "trainer/Z Expert Predictions Max     1355.46\n",
      "trainer/Z Expert Predictions Min      741.661\n",
      "trainer/Z Policy Predictions Mean     921.568\n",
      "trainer/Z Policy Predictions Std      349.072\n",
      "trainer/Z Policy Predictions Max     1333.17\n",
      "trainer/Z Policy Predictions Min       22.2793\n",
      "trainer/Z Expert Targets Mean        1180\n",
      "trainer/Z Expert Targets Std          117.656\n",
      "trainer/Z Expert Targets Max         1327.86\n",
      "trainer/Z Expert Targets Min          742.069\n",
      "trainer/Z Policy Targets Mean         922.573\n",
      "trainer/Z Policy Targets Std          344.52\n",
      "trainer/Z Policy Targets Max         1324.44\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   30.3483\n",
      "trainer/Log Pis Std                     8.43867\n",
      "trainer/Policy mu Mean                  1.4896\n",
      "trainer/Policy mu Std                   2.6172\n",
      "trainer/Policy log std Mean            -3.24551\n",
      "trainer/Policy log std Std              1.33464\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        151109\n",
      "exploration/num paths total           917\n",
      "evaluation/num steps total         910121\n",
      "evaluation/num paths total           1463\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17776\n",
      "evaluation/Rewards Std                  1.35627\n",
      "evaluation/Rewards Max                  7.3364\n",
      "evaluation/Rewards Min                  0.105402\n",
      "evaluation/Returns Mean              5177.76\n",
      "evaluation/Returns Std                151.532\n",
      "evaluation/Returns Max               5272.86\n",
      "evaluation/Returns Min               4731.78\n",
      "evaluation/Estimation Bias Mean      1174.85\n",
      "evaluation/Estimation Bias Std        191.894\n",
      "evaluation/EB/Q_True Mean              44.5072\n",
      "evaluation/EB/Q_True Std              139.859\n",
      "evaluation/EB/Q_Pred Mean            1219.36\n",
      "evaluation/EB/Q_Pred Std              133.99\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5177.76\n",
      "evaluation/Actions Mean                 0.508961\n",
      "evaluation/Actions Std                  0.653018\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.97039\n",
      "time/backward_zf1 (s)                   2.14982\n",
      "time/backward_zf2 (s)                   2.05275\n",
      "time/data sampling (s)                  0.27032\n",
      "time/data storing (s)                   0.0136488\n",
      "time/evaluation sampling (s)            1.4112\n",
      "time/exploration sampling (s)           0.195424\n",
      "time/logging (s)                        0.0118712\n",
      "time/preback_alpha (s)                  0.572478\n",
      "time/preback_policy (s)                 1.1642\n",
      "time/preback_start (s)                  0.124028\n",
      "time/preback_zf (s)                     5.10146\n",
      "time/saving (s)                         0.00578235\n",
      "time/training (s)                       2.16375\n",
      "time/epoch (s)                         17.2071\n",
      "time/total (s)                       2389.99\n",
      "Epoch                                 145\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:32:17.838313 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 146 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 157000\n",
      "trainer/ZF1 Loss                       23.9431\n",
      "trainer/ZF2 Loss                       30.8067\n",
      "trainer/ZF Expert Reward               15.637\n",
      "trainer/ZF Policy Reward               -0.118467\n",
      "trainer/ZF CHI2 Term                   43.4235\n",
      "trainer/Policy Loss                  -941.399\n",
      "trainer/Bias Loss                     102.286\n",
      "trainer/Bias Value                     11.2199\n",
      "trainer/Policy Grad Norm              239.247\n",
      "trainer/Policy Param Norm              32.2392\n",
      "trainer/Zf1 Grad Norm                1125.09\n",
      "trainer/Zf1 Param Norm                 90.8584\n",
      "trainer/Zf2 Grad Norm                1750.25\n",
      "trainer/Zf2 Param Norm                 89.1014\n",
      "trainer/Z Expert Predictions Mean    1214.92\n",
      "trainer/Z Expert Predictions Std      108.085\n",
      "trainer/Z Expert Predictions Max     1381.59\n",
      "trainer/Z Expert Predictions Min      755.486\n",
      "trainer/Z Policy Predictions Mean     930.081\n",
      "trainer/Z Policy Predictions Std      336.7\n",
      "trainer/Z Policy Predictions Max     1318.77\n",
      "trainer/Z Policy Predictions Min      -25.3066\n",
      "trainer/Z Expert Targets Mean        1199.28\n",
      "trainer/Z Expert Targets Std          106.498\n",
      "trainer/Z Expert Targets Max         1373.95\n",
      "trainer/Z Expert Targets Min          758.603\n",
      "trainer/Z Policy Targets Mean         930.199\n",
      "trainer/Z Policy Targets Std          333.814\n",
      "trainer/Z Policy Targets Max         1326.66\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.3195\n",
      "trainer/Log Pis Std                     7.5159\n",
      "trainer/Policy mu Mean                  1.32929\n",
      "trainer/Policy mu Std                   2.52675\n",
      "trainer/Policy log std Mean            -3.31828\n",
      "trainer/Policy log std Std              1.31067\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        154109\n",
      "exploration/num paths total           920\n",
      "evaluation/num steps total         920121\n",
      "evaluation/num paths total           1473\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07867\n",
      "evaluation/Rewards Std                  1.33287\n",
      "evaluation/Rewards Max                  7.40218\n",
      "evaluation/Rewards Min                  0.108661\n",
      "evaluation/Returns Mean              5078.67\n",
      "evaluation/Returns Std                121.207\n",
      "evaluation/Returns Max               5239.32\n",
      "evaluation/Returns Min               4890.8\n",
      "evaluation/Estimation Bias Mean      1170.24\n",
      "evaluation/Estimation Bias Std        183.451\n",
      "evaluation/EB/Q_True Mean              48.9704\n",
      "evaluation/EB/Q_True Std              151.886\n",
      "evaluation/EB/Q_Pred Mean            1219.21\n",
      "evaluation/EB/Q_Pred Std              119.865\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5078.67\n",
      "evaluation/Actions Mean                 0.527791\n",
      "evaluation/Actions Std                  0.646965\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.85186\n",
      "time/backward_zf1 (s)                   1.98614\n",
      "time/backward_zf2 (s)                   1.90696\n",
      "time/data sampling (s)                  0.261724\n",
      "time/data storing (s)                   0.013945\n",
      "time/evaluation sampling (s)            1.45365\n",
      "time/exploration sampling (s)           0.200424\n",
      "time/logging (s)                        0.0114676\n",
      "time/preback_alpha (s)                  0.572386\n",
      "time/preback_policy (s)                 1.04951\n",
      "time/preback_start (s)                  0.124538\n",
      "time/preback_zf (s)                     5.08682\n",
      "time/saving (s)                         0.00572964\n",
      "time/training (s)                       2.34793\n",
      "time/epoch (s)                         16.8731\n",
      "time/total (s)                       2406.89\n",
      "Epoch                                 146\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:32:34.822799 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 147 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 158000\n",
      "trainer/ZF1 Loss                       32.8126\n",
      "trainer/ZF2 Loss                       26.5553\n",
      "trainer/ZF Expert Reward               22.4904\n",
      "trainer/ZF Policy Reward                3.3776\n",
      "trainer/ZF CHI2 Term                   49.0976\n",
      "trainer/Policy Loss                  -939.514\n",
      "trainer/Bias Loss                     178.287\n",
      "trainer/Bias Value                     11.2265\n",
      "trainer/Policy Grad Norm              223.506\n",
      "trainer/Policy Param Norm              32.2726\n",
      "trainer/Zf1 Grad Norm                2518.1\n",
      "trainer/Zf1 Param Norm                 91.0606\n",
      "trainer/Zf2 Grad Norm                2214.87\n",
      "trainer/Zf2 Param Norm                 89.3088\n",
      "trainer/Z Expert Predictions Mean    1212.04\n",
      "trainer/Z Expert Predictions Std      116.505\n",
      "trainer/Z Expert Predictions Max     1376.09\n",
      "trainer/Z Expert Predictions Min      731.798\n",
      "trainer/Z Policy Predictions Mean     931.775\n",
      "trainer/Z Policy Predictions Std      342.189\n",
      "trainer/Z Policy Predictions Max     1315.78\n",
      "trainer/Z Policy Predictions Min      -41.3228\n",
      "trainer/Z Expert Targets Mean        1189.55\n",
      "trainer/Z Expert Targets Std          114.18\n",
      "trainer/Z Expert Targets Max         1355.78\n",
      "trainer/Z Expert Targets Min          727.139\n",
      "trainer/Z Policy Targets Mean         928.397\n",
      "trainer/Z Policy Targets Std          336.284\n",
      "trainer/Z Policy Targets Max         1309.77\n",
      "trainer/Z Policy Targets Min          -58.4612\n",
      "trainer/Log Pis Mean                   30.0778\n",
      "trainer/Log Pis Std                     8.33358\n",
      "trainer/Policy mu Mean                  1.443\n",
      "trainer/Policy mu Std                   2.67663\n",
      "trainer/Policy log std Mean            -3.19097\n",
      "trainer/Policy log std Std              1.37846\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        154109\n",
      "exploration/num paths total           920\n",
      "evaluation/num steps total         929657\n",
      "evaluation/num paths total           1483\n",
      "evaluation/path length Mean           953.6\n",
      "evaluation/path length Std             92.8269\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            763\n",
      "evaluation/Rewards Mean                 5.22453\n",
      "evaluation/Rewards Std                  1.39038\n",
      "evaluation/Rewards Max                  7.34477\n",
      "evaluation/Rewards Min                  0.072781\n",
      "evaluation/Returns Mean              4982.11\n",
      "evaluation/Returns Std                554.711\n",
      "evaluation/Returns Max               5288.94\n",
      "evaluation/Returns Min               3808.1\n",
      "evaluation/Estimation Bias Mean      1170.37\n",
      "evaluation/Estimation Bias Std        247.513\n",
      "evaluation/EB/Q_True Mean              51.9587\n",
      "evaluation/EB/Q_True Std              156.448\n",
      "evaluation/EB/Q_Pred Mean            1222.33\n",
      "evaluation/EB/Q_Pred Std              163.494\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4982.11\n",
      "evaluation/Actions Mean                 0.507324\n",
      "evaluation/Actions Std                  0.65691\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93084\n",
      "time/backward_zf1 (s)                   2.0591\n",
      "time/backward_zf2 (s)                   2.00263\n",
      "time/data sampling (s)                  0.273287\n",
      "time/data storing (s)                   0.0136934\n",
      "time/evaluation sampling (s)            1.42974\n",
      "time/exploration sampling (s)           0.192035\n",
      "time/logging (s)                        0.0108528\n",
      "time/preback_alpha (s)                  0.56747\n",
      "time/preback_policy (s)                 1.15986\n",
      "time/preback_start (s)                  0.122331\n",
      "time/preback_zf (s)                     5.07106\n",
      "time/saving (s)                         0.00571411\n",
      "time/training (s)                       2.07552\n",
      "time/epoch (s)                         16.9141\n",
      "time/total (s)                       2423.83\n",
      "Epoch                                 147\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:32:51.483873 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 148 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 159000\n",
      "trainer/ZF1 Loss                       13.862\n",
      "trainer/ZF2 Loss                       15.8146\n",
      "trainer/ZF Expert Reward               16.5608\n",
      "trainer/ZF Policy Reward               -0.392493\n",
      "trainer/ZF CHI2 Term                   32.0945\n",
      "trainer/Policy Loss                  -924.912\n",
      "trainer/Bias Loss                      93.4938\n",
      "trainer/Bias Value                     11.2332\n",
      "trainer/Policy Grad Norm              302.152\n",
      "trainer/Policy Param Norm              32.3067\n",
      "trainer/Zf1 Grad Norm                1454.7\n",
      "trainer/Zf1 Param Norm                 91.2881\n",
      "trainer/Zf2 Grad Norm                1389.6\n",
      "trainer/Zf2 Param Norm                 89.5261\n",
      "trainer/Z Expert Predictions Mean    1226.37\n",
      "trainer/Z Expert Predictions Std       89.7412\n",
      "trainer/Z Expert Predictions Max     1381.92\n",
      "trainer/Z Expert Predictions Min      725.202\n",
      "trainer/Z Policy Predictions Mean     912.893\n",
      "trainer/Z Policy Predictions Std      347.339\n",
      "trainer/Z Policy Predictions Max     1342.94\n",
      "trainer/Z Policy Predictions Min        9.51237\n",
      "trainer/Z Expert Targets Mean        1209.81\n",
      "trainer/Z Expert Targets Std           88.6267\n",
      "trainer/Z Expert Targets Max         1372.36\n",
      "trainer/Z Expert Targets Min          732.675\n",
      "trainer/Z Policy Targets Mean         913.285\n",
      "trainer/Z Policy Targets Std          343.084\n",
      "trainer/Z Policy Targets Max         1345.2\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   30.293\n",
      "trainer/Log Pis Std                     7.28452\n",
      "trainer/Policy mu Mean                  1.52176\n",
      "trainer/Policy mu Std                   2.54436\n",
      "trainer/Policy log std Mean            -3.18708\n",
      "trainer/Policy log std Std              1.39029\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        154109\n",
      "exploration/num paths total           920\n",
      "evaluation/num steps total         939657\n",
      "evaluation/num paths total           1493\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07029\n",
      "evaluation/Rewards Std                  1.3384\n",
      "evaluation/Rewards Max                  7.48235\n",
      "evaluation/Rewards Min                  0.0950058\n",
      "evaluation/Returns Mean              5070.29\n",
      "evaluation/Returns Std                 78.4502\n",
      "evaluation/Returns Max               5193.71\n",
      "evaluation/Returns Min               4956.44\n",
      "evaluation/Estimation Bias Mean      1177.68\n",
      "evaluation/Estimation Bias Std        188.641\n",
      "evaluation/EB/Q_True Mean              49.0631\n",
      "evaluation/EB/Q_True Std              152.428\n",
      "evaluation/EB/Q_Pred Mean            1226.74\n",
      "evaluation/EB/Q_Pred Std              112.724\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5070.29\n",
      "evaluation/Actions Mean                 0.52348\n",
      "evaluation/Actions Std                  0.648608\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.77986\n",
      "time/backward_zf1 (s)                   1.9026\n",
      "time/backward_zf2 (s)                   1.83293\n",
      "time/data sampling (s)                  0.262003\n",
      "time/data storing (s)                   0.0139112\n",
      "time/evaluation sampling (s)            1.44612\n",
      "time/exploration sampling (s)           0.19134\n",
      "time/logging (s)                        0.0120769\n",
      "time/preback_alpha (s)                  0.564497\n",
      "time/preback_policy (s)                 0.997371\n",
      "time/preback_start (s)                  0.122542\n",
      "time/preback_zf (s)                     5.06028\n",
      "time/saving (s)                         0.00517849\n",
      "time/training (s)                       2.40498\n",
      "time/epoch (s)                         16.5957\n",
      "time/total (s)                       2440.44\n",
      "Epoch                                 148\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:33:08.648890 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 149 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 160000\n",
      "trainer/ZF1 Loss                       89.0993\n",
      "trainer/ZF2 Loss                       87.8863\n",
      "trainer/ZF Expert Reward               18.3315\n",
      "trainer/ZF Policy Reward               10.8433\n",
      "trainer/ZF CHI2 Term                   96.2766\n",
      "trainer/Policy Loss                  -978.126\n",
      "trainer/Bias Loss                     609.03\n",
      "trainer/Bias Value                     11.2401\n",
      "trainer/Policy Grad Norm              223.887\n",
      "trainer/Policy Param Norm              32.3435\n",
      "trainer/Zf1 Grad Norm               11382.3\n",
      "trainer/Zf1 Param Norm                 91.4984\n",
      "trainer/Zf2 Grad Norm               13179.8\n",
      "trainer/Zf2 Param Norm                 89.761\n",
      "trainer/Z Expert Predictions Mean    1224.6\n",
      "trainer/Z Expert Predictions Std      109.334\n",
      "trainer/Z Expert Predictions Max     1385.42\n",
      "trainer/Z Expert Predictions Min      651.31\n",
      "trainer/Z Policy Predictions Mean     962.49\n",
      "trainer/Z Policy Predictions Std      338.648\n",
      "trainer/Z Policy Predictions Max     1358.98\n",
      "trainer/Z Policy Predictions Min       -0.0795655\n",
      "trainer/Z Expert Targets Mean        1206.27\n",
      "trainer/Z Expert Targets Std          102.519\n",
      "trainer/Z Expert Targets Max         1366.49\n",
      "trainer/Z Expert Targets Min          726.21\n",
      "trainer/Z Policy Targets Mean         951.646\n",
      "trainer/Z Policy Targets Std          336.124\n",
      "trainer/Z Policy Targets Max         1336.47\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.5727\n",
      "trainer/Log Pis Std                     7.65959\n",
      "trainer/Policy mu Mean                  1.36426\n",
      "trainer/Policy mu Std                   2.54521\n",
      "trainer/Policy log std Mean            -3.3206\n",
      "trainer/Policy log std Std              1.35355\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        155109\n",
      "exploration/num paths total           921\n",
      "evaluation/num steps total         948811\n",
      "evaluation/num paths total           1503\n",
      "evaluation/path length Mean           915.4\n",
      "evaluation/path length Std            253.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            154\n",
      "evaluation/Rewards Mean                 5.13493\n",
      "evaluation/Rewards Std                  1.50463\n",
      "evaluation/Rewards Max                  7.35283\n",
      "evaluation/Rewards Min                 -1.60407\n",
      "evaluation/Returns Mean              4700.52\n",
      "evaluation/Returns Std               1569.2\n",
      "evaluation/Returns Max               5290.79\n",
      "evaluation/Returns Min                 -5.56017\n",
      "evaluation/Estimation Bias Mean      1170.56\n",
      "evaluation/Estimation Bias Std        244.454\n",
      "evaluation/EB/Q_True Mean              54.4757\n",
      "evaluation/EB/Q_True Std              160.058\n",
      "evaluation/EB/Q_Pred Mean            1225.03\n",
      "evaluation/EB/Q_Pred Std              148.568\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4700.52\n",
      "evaluation/Actions Mean                 0.51449\n",
      "evaluation/Actions Std                  0.654547\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.97398\n",
      "time/backward_zf1 (s)                   2.11655\n",
      "time/backward_zf2 (s)                   2.06402\n",
      "time/data sampling (s)                  0.242265\n",
      "time/data storing (s)                   0.0148816\n",
      "time/evaluation sampling (s)            1.45008\n",
      "time/exploration sampling (s)           0.201651\n",
      "time/logging (s)                        0.0111578\n",
      "time/preback_alpha (s)                  0.568945\n",
      "time/preback_policy (s)                 1.1588\n",
      "time/preback_start (s)                  0.123792\n",
      "time/preback_zf (s)                     5.06136\n",
      "time/saving (s)                         0.00582563\n",
      "time/training (s)                       2.09789\n",
      "time/epoch (s)                         17.0912\n",
      "time/total (s)                       2457.56\n",
      "Epoch                                 149\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:33:25.832170 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 150 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 161000\n",
      "trainer/ZF1 Loss                       22.5384\n",
      "trainer/ZF2 Loss                       20.9052\n",
      "trainer/ZF Expert Reward               13.9256\n",
      "trainer/ZF Policy Reward                1.96053\n",
      "trainer/ZF CHI2 Term                   33.9802\n",
      "trainer/Policy Loss                  -973.836\n",
      "trainer/Bias Loss                     135.836\n",
      "trainer/Bias Value                     11.2465\n",
      "trainer/Policy Grad Norm              185.661\n",
      "trainer/Policy Param Norm              32.3768\n",
      "trainer/Zf1 Grad Norm                1747.21\n",
      "trainer/Zf1 Param Norm                 91.6919\n",
      "trainer/Zf2 Grad Norm                1858.06\n",
      "trainer/Zf2 Param Norm                 89.9509\n",
      "trainer/Z Expert Predictions Mean    1204.75\n",
      "trainer/Z Expert Predictions Std      117.561\n",
      "trainer/Z Expert Predictions Max     1356.92\n",
      "trainer/Z Expert Predictions Min      751.108\n",
      "trainer/Z Policy Predictions Mean     959.803\n",
      "trainer/Z Policy Predictions Std      336.539\n",
      "trainer/Z Policy Predictions Max     1333.11\n",
      "trainer/Z Policy Predictions Min       -0.168064\n",
      "trainer/Z Expert Targets Mean        1190.82\n",
      "trainer/Z Expert Targets Std          114.67\n",
      "trainer/Z Expert Targets Max         1351.92\n",
      "trainer/Z Expert Targets Min          765.696\n",
      "trainer/Z Policy Targets Mean         957.843\n",
      "trainer/Z Policy Targets Std          333.509\n",
      "trainer/Z Policy Targets Max         1332.71\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.3278\n",
      "trainer/Log Pis Std                     6.94306\n",
      "trainer/Policy mu Mean                  1.40878\n",
      "trainer/Policy mu Std                   2.43158\n",
      "trainer/Policy log std Mean            -3.33291\n",
      "trainer/Policy log std Std              1.30686\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        155109\n",
      "exploration/num paths total           921\n",
      "evaluation/num steps total         957264\n",
      "evaluation/num paths total           1513\n",
      "evaluation/path length Mean           845.3\n",
      "evaluation/path length Std            162.112\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            547\n",
      "evaluation/Rewards Mean                 5.06726\n",
      "evaluation/Rewards Std                  1.3727\n",
      "evaluation/Rewards Max                  7.61321\n",
      "evaluation/Rewards Min                  0.133791\n",
      "evaluation/Returns Mean              4283.35\n",
      "evaluation/Returns Std                866.942\n",
      "evaluation/Returns Max               5204.41\n",
      "evaluation/Returns Min               2639.03\n",
      "evaluation/Estimation Bias Mean      1051.84\n",
      "evaluation/Estimation Bias Std        300.478\n",
      "evaluation/EB/Q_True Mean              55.6091\n",
      "evaluation/EB/Q_True Std              155.905\n",
      "evaluation/EB/Q_Pred Mean            1107.45\n",
      "evaluation/EB/Q_Pred Std              245.364\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4283.35\n",
      "evaluation/Actions Mean                 0.509622\n",
      "evaluation/Actions Std                  0.659633\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.96519\n",
      "time/backward_zf1 (s)                   2.0896\n",
      "time/backward_zf2 (s)                   2.04055\n",
      "time/data sampling (s)                  0.279333\n",
      "time/data storing (s)                   0.0147208\n",
      "time/evaluation sampling (s)            1.42781\n",
      "time/exploration sampling (s)           0.196821\n",
      "time/logging (s)                        0.0104976\n",
      "time/preback_alpha (s)                  0.576682\n",
      "time/preback_policy (s)                 1.17394\n",
      "time/preback_start (s)                  0.124713\n",
      "time/preback_zf (s)                     5.08945\n",
      "time/saving (s)                         0.00610963\n",
      "time/training (s)                       2.11615\n",
      "time/epoch (s)                         17.1116\n",
      "time/total (s)                       2474.69\n",
      "Epoch                                 150\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:33:42.751205 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 151 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 162000\n",
      "trainer/ZF1 Loss                       32.2774\n",
      "trainer/ZF2 Loss                       30.6343\n",
      "trainer/ZF Expert Reward               13.4336\n",
      "trainer/ZF Policy Reward               -0.0231804\n",
      "trainer/ZF CHI2 Term                   45.2084\n",
      "trainer/Policy Loss                  -970.776\n",
      "trainer/Bias Loss                     167.968\n",
      "trainer/Bias Value                     11.2527\n",
      "trainer/Policy Grad Norm              488.717\n",
      "trainer/Policy Param Norm              32.412\n",
      "trainer/Zf1 Grad Norm                2800.22\n",
      "trainer/Zf1 Param Norm                 91.8925\n",
      "trainer/Zf2 Grad Norm                2501.99\n",
      "trainer/Zf2 Param Norm                 90.1422\n",
      "trainer/Z Expert Predictions Mean    1210.2\n",
      "trainer/Z Expert Predictions Std      114.933\n",
      "trainer/Z Expert Predictions Max     1356.93\n",
      "trainer/Z Expert Predictions Min      765.044\n",
      "trainer/Z Policy Predictions Mean     961.248\n",
      "trainer/Z Policy Predictions Std      342.463\n",
      "trainer/Z Policy Predictions Max     1337.87\n",
      "trainer/Z Policy Predictions Min        8.51095\n",
      "trainer/Z Expert Targets Mean        1196.77\n",
      "trainer/Z Expert Targets Std          115.503\n",
      "trainer/Z Expert Targets Max         1344.92\n",
      "trainer/Z Expert Targets Min          760.636\n",
      "trainer/Z Policy Targets Mean         961.271\n",
      "trainer/Z Policy Targets Std          335.919\n",
      "trainer/Z Policy Targets Max         1316.85\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.579\n",
      "trainer/Log Pis Std                     7.22974\n",
      "trainer/Policy mu Mean                  1.50421\n",
      "trainer/Policy mu Std                   2.46017\n",
      "trainer/Policy log std Mean            -3.23265\n",
      "trainer/Policy log std Std              1.36972\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        156109\n",
      "exploration/num paths total           922\n",
      "evaluation/num steps total         967264\n",
      "evaluation/num paths total           1523\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10282\n",
      "evaluation/Rewards Std                  1.31123\n",
      "evaluation/Rewards Max                  7.25615\n",
      "evaluation/Rewards Min                  0.0773348\n",
      "evaluation/Returns Mean              5102.82\n",
      "evaluation/Returns Std                101.592\n",
      "evaluation/Returns Max               5225.42\n",
      "evaluation/Returns Min               4872.17\n",
      "evaluation/Estimation Bias Mean      1166.18\n",
      "evaluation/Estimation Bias Std        176.735\n",
      "evaluation/EB/Q_True Mean              48.0858\n",
      "evaluation/EB/Q_True Std              148.653\n",
      "evaluation/EB/Q_Pred Mean            1214.27\n",
      "evaluation/EB/Q_Pred Std              105.714\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5102.82\n",
      "evaluation/Actions Mean                 0.515464\n",
      "evaluation/Actions Std                  0.653858\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.79634\n",
      "time/backward_zf1 (s)                   1.94158\n",
      "time/backward_zf2 (s)                   1.85869\n",
      "time/data sampling (s)                  0.273629\n",
      "time/data storing (s)                   0.0139223\n",
      "time/evaluation sampling (s)            1.43318\n",
      "time/exploration sampling (s)           0.19519\n",
      "time/logging (s)                        0.012164\n",
      "time/preback_alpha (s)                  0.575053\n",
      "time/preback_policy (s)                 1.01725\n",
      "time/preback_start (s)                  0.125083\n",
      "time/preback_zf (s)                     5.11905\n",
      "time/saving (s)                         0.00587552\n",
      "time/training (s)                       2.4837\n",
      "time/epoch (s)                         16.8507\n",
      "time/total (s)                       2491.57\n",
      "Epoch                                 151\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:34:00.066058 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 152 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 163000\n",
      "trainer/ZF1 Loss                       19.869\n",
      "trainer/ZF2 Loss                       19.539\n",
      "trainer/ZF Expert Reward               13.9175\n",
      "trainer/ZF Policy Reward               -3.31008\n",
      "trainer/ZF CHI2 Term                   37.224\n",
      "trainer/Policy Loss                  -992.251\n",
      "trainer/Bias Loss                      93.3176\n",
      "trainer/Bias Value                     11.259\n",
      "trainer/Policy Grad Norm              248.513\n",
      "trainer/Policy Param Norm              32.4413\n",
      "trainer/Zf1 Grad Norm                1334.39\n",
      "trainer/Zf1 Param Norm                 92.0872\n",
      "trainer/Zf2 Grad Norm                2066.35\n",
      "trainer/Zf2 Param Norm                 90.3412\n",
      "trainer/Z Expert Predictions Mean    1223.58\n",
      "trainer/Z Expert Predictions Std      104.941\n",
      "trainer/Z Expert Predictions Max     1358.34\n",
      "trainer/Z Expert Predictions Min      748.639\n",
      "trainer/Z Policy Predictions Mean     980.471\n",
      "trainer/Z Policy Predictions Std      311.41\n",
      "trainer/Z Policy Predictions Max     1372.56\n",
      "trainer/Z Policy Predictions Min       -5.19041\n",
      "trainer/Z Expert Targets Mean        1209.67\n",
      "trainer/Z Expert Targets Std          102.859\n",
      "trainer/Z Expert Targets Max         1330.83\n",
      "trainer/Z Expert Targets Min          753.776\n",
      "trainer/Z Policy Targets Mean         983.781\n",
      "trainer/Z Policy Targets Std          301.198\n",
      "trainer/Z Policy Targets Max         1335.31\n",
      "trainer/Z Policy Targets Min           36.682\n",
      "trainer/Log Pis Mean                   29.2372\n",
      "trainer/Log Pis Std                     6.41153\n",
      "trainer/Policy mu Mean                  1.43215\n",
      "trainer/Policy mu Std                   2.43011\n",
      "trainer/Policy log std Mean            -3.26285\n",
      "trainer/Policy log std Std              1.27693\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        157109\n",
      "exploration/num paths total           923\n",
      "evaluation/num steps total         975218\n",
      "evaluation/num paths total           1533\n",
      "evaluation/path length Mean           795.4\n",
      "evaluation/path length Std            177.935\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            541\n",
      "evaluation/Rewards Mean                 5.0408\n",
      "evaluation/Rewards Std                  1.38584\n",
      "evaluation/Rewards Max                  7.26563\n",
      "evaluation/Rewards Min                  0.189202\n",
      "evaluation/Returns Mean              4009.45\n",
      "evaluation/Returns Std                977.799\n",
      "evaluation/Returns Max               5229.22\n",
      "evaluation/Returns Min               2609.16\n",
      "evaluation/Estimation Bias Mean      1053.51\n",
      "evaluation/Estimation Bias Std        306.448\n",
      "evaluation/EB/Q_True Mean              62.0553\n",
      "evaluation/EB/Q_True Std              168.568\n",
      "evaluation/EB/Q_Pred Mean            1115.57\n",
      "evaluation/EB/Q_Pred Std              250.709\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4009.45\n",
      "evaluation/Actions Mean                 0.499429\n",
      "evaluation/Actions Std                  0.663615\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.01804\n",
      "time/backward_zf1 (s)                   2.16346\n",
      "time/backward_zf2 (s)                   2.10223\n",
      "time/data sampling (s)                  0.26427\n",
      "time/data storing (s)                   0.0143844\n",
      "time/evaluation sampling (s)            1.40782\n",
      "time/exploration sampling (s)           0.199744\n",
      "time/logging (s)                        0.00956568\n",
      "time/preback_alpha (s)                  0.576398\n",
      "time/preback_policy (s)                 1.19522\n",
      "time/preback_start (s)                  0.124041\n",
      "time/preback_zf (s)                     5.07839\n",
      "time/saving (s)                         0.00563856\n",
      "time/training (s)                       2.08524\n",
      "time/epoch (s)                         17.2444\n",
      "time/total (s)                       2508.83\n",
      "Epoch                                 152\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:34:17.526507 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 153 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 164000\n",
      "trainer/ZF1 Loss                      258.051\n",
      "trainer/ZF2 Loss                      273.815\n",
      "trainer/ZF Expert Reward               24.7494\n",
      "trainer/ZF Policy Reward                5.79316\n",
      "trainer/ZF CHI2 Term                  285.2\n",
      "trainer/Policy Loss                  -969.447\n",
      "trainer/Bias Loss                    2603.68\n",
      "trainer/Bias Value                     11.2649\n",
      "trainer/Policy Grad Norm              367.79\n",
      "trainer/Policy Param Norm              32.4744\n",
      "trainer/Zf1 Grad Norm                4487.79\n",
      "trainer/Zf1 Param Norm                 92.2929\n",
      "trainer/Zf2 Grad Norm                5051.57\n",
      "trainer/Zf2 Param Norm                 90.5524\n",
      "trainer/Z Expert Predictions Mean    1233.82\n",
      "trainer/Z Expert Predictions Std       99.167\n",
      "trainer/Z Expert Predictions Max     1364.76\n",
      "trainer/Z Expert Predictions Min      732.833\n",
      "trainer/Z Policy Predictions Mean     962.079\n",
      "trainer/Z Policy Predictions Std      355.263\n",
      "trainer/Z Policy Predictions Max     1324.07\n",
      "trainer/Z Policy Predictions Min      -24.321\n",
      "trainer/Z Expert Targets Mean        1209.07\n",
      "trainer/Z Expert Targets Std          124.29\n",
      "trainer/Z Expert Targets Max         1354.46\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         956.286\n",
      "trainer/Z Policy Targets Std          350.418\n",
      "trainer/Z Policy Targets Max         1309.25\n",
      "trainer/Z Policy Targets Min          -17.0065\n",
      "trainer/Log Pis Mean                   31.1185\n",
      "trainer/Log Pis Std                     7.78932\n",
      "trainer/Policy mu Mean                  1.52892\n",
      "trainer/Policy mu Std                   2.68001\n",
      "trainer/Policy log std Mean            -3.23369\n",
      "trainer/Policy log std Std              1.33477\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        159109\n",
      "exploration/num paths total           925\n",
      "evaluation/num steps total         983326\n",
      "evaluation/num paths total           1544\n",
      "evaluation/path length Mean           737.091\n",
      "evaluation/path length Std            209.622\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            498\n",
      "evaluation/Rewards Mean                 4.97886\n",
      "evaluation/Rewards Std                  1.42301\n",
      "evaluation/Rewards Max                  7.30122\n",
      "evaluation/Rewards Min                  0.186143\n",
      "evaluation/Returns Mean              3669.88\n",
      "evaluation/Returns Std               1145.38\n",
      "evaluation/Returns Max               5167.14\n",
      "evaluation/Returns Min               2325.33\n",
      "evaluation/Estimation Bias Mean      1076.71\n",
      "evaluation/Estimation Bias Std        282.812\n",
      "evaluation/EB/Q_True Mean              53.0604\n",
      "evaluation/EB/Q_True Std              149.013\n",
      "evaluation/EB/Q_Pred Mean            1129.77\n",
      "evaluation/EB/Q_Pred Std              242.08\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3669.88\n",
      "evaluation/Actions Mean                 0.501121\n",
      "evaluation/Actions Std                  0.661978\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.01875\n",
      "time/backward_zf1 (s)                   2.18104\n",
      "time/backward_zf2 (s)                   2.11356\n",
      "time/data sampling (s)                  0.275914\n",
      "time/data storing (s)                   0.0145177\n",
      "time/evaluation sampling (s)            1.49566\n",
      "time/exploration sampling (s)           0.199723\n",
      "time/logging (s)                        0.0125599\n",
      "time/preback_alpha (s)                  0.579525\n",
      "time/preback_policy (s)                 1.20214\n",
      "time/preback_start (s)                  0.126284\n",
      "time/preback_zf (s)                     5.10045\n",
      "time/saving (s)                         0.00602057\n",
      "time/training (s)                       2.07214\n",
      "time/epoch (s)                         17.3983\n",
      "time/total (s)                       2526.25\n",
      "Epoch                                 153\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:34:34.915293 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 154 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 165000\n",
      "trainer/ZF1 Loss                       27.3798\n",
      "trainer/ZF2 Loss                       22.7619\n",
      "trainer/ZF Expert Reward               14.3437\n",
      "trainer/ZF Policy Reward               -1.18326\n",
      "trainer/ZF CHI2 Term                   40.8972\n",
      "trainer/Policy Loss                  -986.275\n",
      "trainer/Bias Loss                     102.766\n",
      "trainer/Bias Value                     11.2712\n",
      "trainer/Policy Grad Norm              265.754\n",
      "trainer/Policy Param Norm              32.5097\n",
      "trainer/Zf1 Grad Norm                1708.22\n",
      "trainer/Zf1 Param Norm                 92.4931\n",
      "trainer/Zf2 Grad Norm                1837.27\n",
      "trainer/Zf2 Param Norm                 90.762\n",
      "trainer/Z Expert Predictions Mean    1229.48\n",
      "trainer/Z Expert Predictions Std       97.7989\n",
      "trainer/Z Expert Predictions Max     1354.54\n",
      "trainer/Z Expert Predictions Min      744.963\n",
      "trainer/Z Policy Predictions Mean     975.255\n",
      "trainer/Z Policy Predictions Std      332.346\n",
      "trainer/Z Policy Predictions Max     1347.43\n",
      "trainer/Z Policy Predictions Min      -36.2859\n",
      "trainer/Z Expert Targets Mean        1215.14\n",
      "trainer/Z Expert Targets Std           97.8123\n",
      "trainer/Z Expert Targets Max         1339.09\n",
      "trainer/Z Expert Targets Min          741.713\n",
      "trainer/Z Policy Targets Mean         976.439\n",
      "trainer/Z Policy Targets Std          327.129\n",
      "trainer/Z Policy Targets Max         1327.84\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.9387\n",
      "trainer/Log Pis Std                     7.12846\n",
      "trainer/Policy mu Mean                  1.5057\n",
      "trainer/Policy mu Std                   2.55924\n",
      "trainer/Policy log std Mean            -3.26477\n",
      "trainer/Policy log std Std              1.32195\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        160109\n",
      "exploration/num paths total           926\n",
      "evaluation/num steps total         991881\n",
      "evaluation/num paths total           1554\n",
      "evaluation/path length Mean           855.5\n",
      "evaluation/path length Std            289.225\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            252\n",
      "evaluation/Rewards Mean                 4.62503\n",
      "evaluation/Rewards Std                  1.64784\n",
      "evaluation/Rewards Max                  7.36172\n",
      "evaluation/Rewards Min                 -1.17286\n",
      "evaluation/Returns Mean              3956.72\n",
      "evaluation/Returns Std               1922.51\n",
      "evaluation/Returns Max               5168.16\n",
      "evaluation/Returns Min                110.72\n",
      "evaluation/Estimation Bias Mean      1082.62\n",
      "evaluation/Estimation Bias Std        313.757\n",
      "evaluation/EB/Q_True Mean              53.5867\n",
      "evaluation/EB/Q_True Std              151.409\n",
      "evaluation/EB/Q_Pred Mean            1136.21\n",
      "evaluation/EB/Q_Pred Std              191.876\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3956.72\n",
      "evaluation/Actions Mean                 0.522544\n",
      "evaluation/Actions Std                  0.642338\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999994\n",
      "time/backward_policy (s)                1.98586\n",
      "time/backward_zf1 (s)                   2.13678\n",
      "time/backward_zf2 (s)                   2.06768\n",
      "time/data sampling (s)                  0.278782\n",
      "time/data storing (s)                   0.0150782\n",
      "time/evaluation sampling (s)            1.47697\n",
      "time/exploration sampling (s)           0.20788\n",
      "time/logging (s)                        0.0109211\n",
      "time/preback_alpha (s)                  0.582557\n",
      "time/preback_policy (s)                 1.17502\n",
      "time/preback_start (s)                  0.127163\n",
      "time/preback_zf (s)                     5.09565\n",
      "time/saving (s)                         0.00588462\n",
      "time/training (s)                       2.14669\n",
      "time/epoch (s)                         17.3129\n",
      "time/total (s)                       2543.59\n",
      "Epoch                                 154\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:34:51.940409 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 155 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 166000\n",
      "trainer/ZF1 Loss                       26.5934\n",
      "trainer/ZF2 Loss                       25.2982\n",
      "trainer/ZF Expert Reward               14.2957\n",
      "trainer/ZF Policy Reward                1.41497\n",
      "trainer/ZF CHI2 Term                   39.1355\n",
      "trainer/Policy Loss                  -976.233\n",
      "trainer/Bias Loss                      96.7325\n",
      "trainer/Bias Value                     11.2775\n",
      "trainer/Policy Grad Norm              301.769\n",
      "trainer/Policy Param Norm              32.543\n",
      "trainer/Zf1 Grad Norm                1791.92\n",
      "trainer/Zf1 Param Norm                 92.7201\n",
      "trainer/Zf2 Grad Norm                1809.01\n",
      "trainer/Zf2 Param Norm                 90.991\n",
      "trainer/Z Expert Predictions Mean    1218.65\n",
      "trainer/Z Expert Predictions Std      110.573\n",
      "trainer/Z Expert Predictions Max     1331.54\n",
      "trainer/Z Expert Predictions Min      740.05\n",
      "trainer/Z Policy Predictions Mean     968.363\n",
      "trainer/Z Policy Predictions Std      310.562\n",
      "trainer/Z Policy Predictions Max     1353.43\n",
      "trainer/Z Policy Predictions Min       51.0263\n",
      "trainer/Z Expert Targets Mean        1204.35\n",
      "trainer/Z Expert Targets Std          109.738\n",
      "trainer/Z Expert Targets Max         1321.21\n",
      "trainer/Z Expert Targets Min          740.053\n",
      "trainer/Z Policy Targets Mean         966.948\n",
      "trainer/Z Policy Targets Std          310.03\n",
      "trainer/Z Policy Targets Max         1319.72\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   30.8954\n",
      "trainer/Log Pis Std                     8.38055\n",
      "trainer/Policy mu Mean                  1.51874\n",
      "trainer/Policy mu Std                   2.71448\n",
      "trainer/Policy log std Mean            -3.29824\n",
      "trainer/Policy log std Std              1.3972\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        161109\n",
      "exploration/num paths total           927\n",
      "evaluation/num steps total              1.00166e+06\n",
      "evaluation/num paths total           1564\n",
      "evaluation/path length Mean           977.6\n",
      "evaluation/path length Std             67.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            776\n",
      "evaluation/Rewards Mean                 5.10973\n",
      "evaluation/Rewards Std                  1.31542\n",
      "evaluation/Rewards Max                  7.31171\n",
      "evaluation/Rewards Min                  0.222551\n",
      "evaluation/Returns Mean              4995.27\n",
      "evaluation/Returns Std                380.382\n",
      "evaluation/Returns Max               5223.43\n",
      "evaluation/Returns Min               3878.64\n",
      "evaluation/Estimation Bias Mean      1157.11\n",
      "evaluation/Estimation Bias Std        210.73\n",
      "evaluation/EB/Q_True Mean              49.3266\n",
      "evaluation/EB/Q_True Std              150.953\n",
      "evaluation/EB/Q_Pred Mean            1206.44\n",
      "evaluation/EB/Q_Pred Std              120.436\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4995.27\n",
      "evaluation/Actions Mean                 0.505561\n",
      "evaluation/Actions Std                  0.659292\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88897\n",
      "time/backward_zf1 (s)                   2.03531\n",
      "time/backward_zf2 (s)                   1.95553\n",
      "time/data sampling (s)                  0.274079\n",
      "time/data storing (s)                   0.0148458\n",
      "time/evaluation sampling (s)            1.40935\n",
      "time/exploration sampling (s)           0.200072\n",
      "time/logging (s)                        0.0118215\n",
      "time/preback_alpha (s)                  0.573649\n",
      "time/preback_policy (s)                 1.08131\n",
      "time/preback_start (s)                  0.124449\n",
      "time/preback_zf (s)                     5.0943\n",
      "time/saving (s)                         0.00585746\n",
      "time/training (s)                       2.29131\n",
      "time/epoch (s)                         16.9608\n",
      "time/total (s)                       2560.56\n",
      "Epoch                                 155\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:35:08.871518 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 156 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 167000\n",
      "trainer/ZF1 Loss                       24.8991\n",
      "trainer/ZF2 Loss                       16.7224\n",
      "trainer/ZF Expert Reward               18.7822\n",
      "trainer/ZF Policy Reward                4.77028\n",
      "trainer/ZF CHI2 Term                   35.1197\n",
      "trainer/Policy Loss                 -1003.27\n",
      "trainer/Bias Loss                     122.397\n",
      "trainer/Bias Value                     11.2835\n",
      "trainer/Policy Grad Norm              310.732\n",
      "trainer/Policy Param Norm              32.5787\n",
      "trainer/Zf1 Grad Norm                1767.02\n",
      "trainer/Zf1 Param Norm                 92.9458\n",
      "trainer/Zf2 Grad Norm                1417.4\n",
      "trainer/Zf2 Param Norm                 91.2095\n",
      "trainer/Z Expert Predictions Mean    1215.59\n",
      "trainer/Z Expert Predictions Std      114.112\n",
      "trainer/Z Expert Predictions Max     1336.01\n",
      "trainer/Z Expert Predictions Min      748.571\n",
      "trainer/Z Policy Predictions Mean     995.272\n",
      "trainer/Z Policy Predictions Std      298.478\n",
      "trainer/Z Policy Predictions Max     1305.21\n",
      "trainer/Z Policy Predictions Min       29.5657\n",
      "trainer/Z Expert Targets Mean        1196.81\n",
      "trainer/Z Expert Targets Std          113.056\n",
      "trainer/Z Expert Targets Max         1319.1\n",
      "trainer/Z Expert Targets Min          752.081\n",
      "trainer/Z Policy Targets Mean         990.502\n",
      "trainer/Z Policy Targets Std          293.489\n",
      "trainer/Z Policy Targets Max         1290.05\n",
      "trainer/Z Policy Targets Min           -9.74992\n",
      "trainer/Log Pis Mean                   29.6975\n",
      "trainer/Log Pis Std                     7.17429\n",
      "trainer/Policy mu Mean                  1.36287\n",
      "trainer/Policy mu Std                   2.47327\n",
      "trainer/Policy log std Mean            -3.35601\n",
      "trainer/Policy log std Std              1.33198\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        164109\n",
      "exploration/num paths total           930\n",
      "evaluation/num steps total              1.01166e+06\n",
      "evaluation/num paths total           1574\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.81783\n",
      "evaluation/Rewards Std                  1.24107\n",
      "evaluation/Rewards Max                  7.29704\n",
      "evaluation/Rewards Min                  0.133272\n",
      "evaluation/Returns Mean              4817.83\n",
      "evaluation/Returns Std                164.992\n",
      "evaluation/Returns Max               5048.26\n",
      "evaluation/Returns Min               4453.93\n",
      "evaluation/Estimation Bias Mean      1101.7\n",
      "evaluation/Estimation Bias Std        176.804\n",
      "evaluation/EB/Q_True Mean              45.9035\n",
      "evaluation/EB/Q_True Std              141.988\n",
      "evaluation/EB/Q_Pred Mean            1147.6\n",
      "evaluation/EB/Q_Pred Std              119.612\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4817.83\n",
      "evaluation/Actions Mean                 0.525598\n",
      "evaluation/Actions Std                  0.641831\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.82809\n",
      "time/backward_zf1 (s)                   1.98296\n",
      "time/backward_zf2 (s)                   1.90194\n",
      "time/data sampling (s)                  0.272268\n",
      "time/data storing (s)                   0.0154006\n",
      "time/evaluation sampling (s)            1.43126\n",
      "time/exploration sampling (s)           0.2047\n",
      "time/logging (s)                        0.011682\n",
      "time/preback_alpha (s)                  0.572467\n",
      "time/preback_policy (s)                 1.03629\n",
      "time/preback_start (s)                  0.125677\n",
      "time/preback_zf (s)                     5.10129\n",
      "time/saving (s)                         0.00581434\n",
      "time/training (s)                       2.3756\n",
      "time/epoch (s)                         16.8655\n",
      "time/total (s)                       2577.45\n",
      "Epoch                                 156\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:35:26.303511 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 157 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 168000\n",
      "trainer/ZF1 Loss                      316.518\n",
      "trainer/ZF2 Loss                      338.078\n",
      "trainer/ZF Expert Reward               12.8806\n",
      "trainer/ZF Policy Reward                6.55287\n",
      "trainer/ZF CHI2 Term                  333.932\n",
      "trainer/Policy Loss                  -987.373\n",
      "trainer/Bias Loss                     119.79\n",
      "trainer/Bias Value                     11.2897\n",
      "trainer/Policy Grad Norm              232.852\n",
      "trainer/Policy Param Norm              32.6117\n",
      "trainer/Zf1 Grad Norm                1802.92\n",
      "trainer/Zf1 Param Norm                 93.1649\n",
      "trainer/Zf2 Grad Norm                3396.61\n",
      "trainer/Zf2 Param Norm                 91.441\n",
      "trainer/Z Expert Predictions Mean    1219.68\n",
      "trainer/Z Expert Predictions Std      109.842\n",
      "trainer/Z Expert Predictions Max     1337.51\n",
      "trainer/Z Expert Predictions Min      757.419\n",
      "trainer/Z Policy Predictions Mean     981.979\n",
      "trainer/Z Policy Predictions Std      310.622\n",
      "trainer/Z Policy Predictions Max     1326.85\n",
      "trainer/Z Policy Predictions Min      -22.3468\n",
      "trainer/Z Expert Targets Mean        1206.8\n",
      "trainer/Z Expert Targets Std          107.068\n",
      "trainer/Z Expert Targets Max         1322.89\n",
      "trainer/Z Expert Targets Min          753.501\n",
      "trainer/Z Policy Targets Mean         975.427\n",
      "trainer/Z Policy Targets Std          316.785\n",
      "trainer/Z Policy Targets Max         1309.29\n",
      "trainer/Z Policy Targets Min          -27.9061\n",
      "trainer/Log Pis Mean                   30.6003\n",
      "trainer/Log Pis Std                     7.84559\n",
      "trainer/Policy mu Mean                  1.45284\n",
      "trainer/Policy mu Std                   2.65589\n",
      "trainer/Policy log std Mean            -3.27441\n",
      "trainer/Policy log std Std              1.36787\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        164109\n",
      "exploration/num paths total           930\n",
      "evaluation/num steps total              1.021e+06\n",
      "evaluation/num paths total           1584\n",
      "evaluation/path length Mean           934.2\n",
      "evaluation/path length Std            102.418\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            743\n",
      "evaluation/Rewards Mean                 5.01982\n",
      "evaluation/Rewards Std                  1.3078\n",
      "evaluation/Rewards Max                  7.37856\n",
      "evaluation/Rewards Min                  0.205517\n",
      "evaluation/Returns Mean              4689.52\n",
      "evaluation/Returns Std                554.602\n",
      "evaluation/Returns Max               5186.49\n",
      "evaluation/Returns Min               3684.2\n",
      "evaluation/Estimation Bias Mean      1133.48\n",
      "evaluation/Estimation Bias Std        235.856\n",
      "evaluation/EB/Q_True Mean              50.7414\n",
      "evaluation/EB/Q_True Std              150.603\n",
      "evaluation/EB/Q_Pred Mean            1184.22\n",
      "evaluation/EB/Q_Pred Std              159.601\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4689.52\n",
      "evaluation/Actions Mean                 0.508232\n",
      "evaluation/Actions Std                  0.653357\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97831\n",
      "time/backward_zf1 (s)                   2.11207\n",
      "time/backward_zf2 (s)                   2.06432\n",
      "time/data sampling (s)                  0.276911\n",
      "time/data storing (s)                   0.0138397\n",
      "time/evaluation sampling (s)            1.44464\n",
      "time/exploration sampling (s)           0.190795\n",
      "time/logging (s)                        0.0109286\n",
      "time/preback_alpha (s)                  0.587068\n",
      "time/preback_policy (s)                 1.16419\n",
      "time/preback_start (s)                  0.12647\n",
      "time/preback_zf (s)                     5.16344\n",
      "time/saving (s)                         0.00574014\n",
      "time/training (s)                       2.22605\n",
      "time/epoch (s)                         17.3648\n",
      "time/total (s)                       2594.83\n",
      "Epoch                                 157\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:35:43.340679 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 158 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 169000\n",
      "trainer/ZF1 Loss                       28.9139\n",
      "trainer/ZF2 Loss                       30.0771\n",
      "trainer/ZF Expert Reward               16.0174\n",
      "trainer/ZF Policy Reward                1.60081\n",
      "trainer/ZF CHI2 Term                   44.2101\n",
      "trainer/Policy Loss                  -987.149\n",
      "trainer/Bias Loss                     118.225\n",
      "trainer/Bias Value                     11.296\n",
      "trainer/Policy Grad Norm              284.985\n",
      "trainer/Policy Param Norm              32.6401\n",
      "trainer/Zf1 Grad Norm                2045.81\n",
      "trainer/Zf1 Param Norm                 93.3929\n",
      "trainer/Zf2 Grad Norm                2264.65\n",
      "trainer/Zf2 Param Norm                 91.6637\n",
      "trainer/Z Expert Predictions Mean    1221.99\n",
      "trainer/Z Expert Predictions Std       98.741\n",
      "trainer/Z Expert Predictions Max     1340.36\n",
      "trainer/Z Expert Predictions Min      767.508\n",
      "trainer/Z Policy Predictions Mean     971.855\n",
      "trainer/Z Policy Predictions Std      326.33\n",
      "trainer/Z Policy Predictions Max     1315.86\n",
      "trainer/Z Policy Predictions Min        0.966944\n",
      "trainer/Z Expert Targets Mean        1205.97\n",
      "trainer/Z Expert Targets Std           98.0568\n",
      "trainer/Z Expert Targets Max         1318.6\n",
      "trainer/Z Expert Targets Min          764.219\n",
      "trainer/Z Policy Targets Mean         970.254\n",
      "trainer/Z Policy Targets Std          325.042\n",
      "trainer/Z Policy Targets Max         1308.39\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.8086\n",
      "trainer/Log Pis Std                     7.0152\n",
      "trainer/Policy mu Mean                  1.35457\n",
      "trainer/Policy mu Std                   2.51898\n",
      "trainer/Policy log std Mean            -3.33301\n",
      "trainer/Policy log std Std              1.32385\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        164109\n",
      "exploration/num paths total           930\n",
      "evaluation/num steps total              1.031e+06\n",
      "evaluation/num paths total           1594\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.97202\n",
      "evaluation/Rewards Std                  1.26656\n",
      "evaluation/Rewards Max                  7.35906\n",
      "evaluation/Rewards Min                  0.056174\n",
      "evaluation/Returns Mean              4972.02\n",
      "evaluation/Returns Std                108.193\n",
      "evaluation/Returns Max               5076.59\n",
      "evaluation/Returns Min               4730.9\n",
      "evaluation/Estimation Bias Mean      1131.64\n",
      "evaluation/Estimation Bias Std        171.893\n",
      "evaluation/EB/Q_True Mean              47.6298\n",
      "evaluation/EB/Q_True Std              146.998\n",
      "evaluation/EB/Q_Pred Mean            1179.27\n",
      "evaluation/EB/Q_Pred Std               99.7582\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4972.02\n",
      "evaluation/Actions Mean                 0.51774\n",
      "evaluation/Actions Std                  0.651643\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88372\n",
      "time/backward_zf1 (s)                   2.04443\n",
      "time/backward_zf2 (s)                   1.96826\n",
      "time/data sampling (s)                  0.275914\n",
      "time/data storing (s)                   0.013993\n",
      "time/evaluation sampling (s)            1.43389\n",
      "time/exploration sampling (s)           0.195804\n",
      "time/logging (s)                        0.0119201\n",
      "time/preback_alpha (s)                  0.568638\n",
      "time/preback_policy (s)                 1.08984\n",
      "time/preback_start (s)                  0.122924\n",
      "time/preback_zf (s)                     5.07166\n",
      "time/saving (s)                         0.00576881\n",
      "time/training (s)                       2.28257\n",
      "time/epoch (s)                         16.9693\n",
      "time/total (s)                       2611.82\n",
      "Epoch                                 158\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:36:00.160243 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 159 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 170000\n",
      "trainer/ZF1 Loss                       66.7942\n",
      "trainer/ZF2 Loss                       67.1486\n",
      "trainer/ZF Expert Reward               17.5676\n",
      "trainer/ZF Policy Reward                7.5818\n",
      "trainer/ZF CHI2 Term                   77.2651\n",
      "trainer/Policy Loss                 -1007.94\n",
      "trainer/Bias Loss                     110\n",
      "trainer/Bias Value                     11.3022\n",
      "trainer/Policy Grad Norm              270.745\n",
      "trainer/Policy Param Norm              32.6708\n",
      "trainer/Zf1 Grad Norm                3047.55\n",
      "trainer/Zf1 Param Norm                 93.6128\n",
      "trainer/Zf2 Grad Norm                4120.39\n",
      "trainer/Zf2 Param Norm                 91.8892\n",
      "trainer/Z Expert Predictions Mean    1237.38\n",
      "trainer/Z Expert Predictions Std       88.5049\n",
      "trainer/Z Expert Predictions Max     1345.61\n",
      "trainer/Z Expert Predictions Min      782.165\n",
      "trainer/Z Policy Predictions Mean    1003.23\n",
      "trainer/Z Policy Predictions Std      301.988\n",
      "trainer/Z Policy Predictions Max     1319.4\n",
      "trainer/Z Policy Predictions Min      -44.2997\n",
      "trainer/Z Expert Targets Mean        1219.81\n",
      "trainer/Z Expert Targets Std           87.3064\n",
      "trainer/Z Expert Targets Max         1326.65\n",
      "trainer/Z Expert Targets Min          776.735\n",
      "trainer/Z Policy Targets Mean         995.646\n",
      "trainer/Z Policy Targets Std          303.517\n",
      "trainer/Z Policy Targets Max         1310.31\n",
      "trainer/Z Policy Targets Min          -43.1169\n",
      "trainer/Log Pis Mean                   30.7953\n",
      "trainer/Log Pis Std                     7.34995\n",
      "trainer/Policy mu Mean                  1.44544\n",
      "trainer/Policy mu Std                   2.5774\n",
      "trainer/Policy log std Mean            -3.33899\n",
      "trainer/Policy log std Std              1.40606\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        166156\n",
      "exploration/num paths total           933\n",
      "evaluation/num steps total              1.03991e+06\n",
      "evaluation/num paths total           1604\n",
      "evaluation/path length Mean           891\n",
      "evaluation/path length Std            176.186\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            420\n",
      "evaluation/Rewards Mean                 5.10694\n",
      "evaluation/Rewards Std                  1.32231\n",
      "evaluation/Rewards Max                  7.16936\n",
      "evaluation/Rewards Min                  0.182878\n",
      "evaluation/Returns Mean              4550.29\n",
      "evaluation/Returns Std                986.146\n",
      "evaluation/Returns Max               5195.1\n",
      "evaluation/Returns Min               1875.28\n",
      "evaluation/Estimation Bias Mean      1068.38\n",
      "evaluation/Estimation Bias Std        275.841\n",
      "evaluation/EB/Q_True Mean              54.4445\n",
      "evaluation/EB/Q_True Std              157.421\n",
      "evaluation/EB/Q_Pred Mean            1122.82\n",
      "evaluation/EB/Q_Pred Std              217.802\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4550.29\n",
      "evaluation/Actions Mean                 0.511746\n",
      "evaluation/Actions Std                  0.662226\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80136\n",
      "time/backward_zf1 (s)                   1.95826\n",
      "time/backward_zf2 (s)                   1.8731\n",
      "time/data sampling (s)                  0.257549\n",
      "time/data storing (s)                   0.0141342\n",
      "time/evaluation sampling (s)            1.46245\n",
      "time/exploration sampling (s)           0.19963\n",
      "time/logging (s)                        0.0108142\n",
      "time/preback_alpha (s)                  0.565686\n",
      "time/preback_policy (s)                 1.00889\n",
      "time/preback_start (s)                  0.122891\n",
      "time/preback_zf (s)                     5.05558\n",
      "time/saving (s)                         0.00522449\n",
      "time/training (s)                       2.41028\n",
      "time/epoch (s)                         16.7458\n",
      "time/total (s)                       2628.59\n",
      "Epoch                                 159\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:36:16.985516 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 160 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 171000\n",
      "trainer/ZF1 Loss                       19.8717\n",
      "trainer/ZF2 Loss                       29.1383\n",
      "trainer/ZF Expert Reward               14.4449\n",
      "trainer/ZF Policy Reward                0.943609\n",
      "trainer/ZF CHI2 Term                   38.311\n",
      "trainer/Policy Loss                  -986.057\n",
      "trainer/Bias Loss                     131.35\n",
      "trainer/Bias Value                     11.3084\n",
      "trainer/Policy Grad Norm              368.006\n",
      "trainer/Policy Param Norm              32.6985\n",
      "trainer/Zf1 Grad Norm                2057.24\n",
      "trainer/Zf1 Param Norm                 93.8377\n",
      "trainer/Zf2 Grad Norm                3852.74\n",
      "trainer/Zf2 Param Norm                 92.1212\n",
      "trainer/Z Expert Predictions Mean    1210.13\n",
      "trainer/Z Expert Predictions Std      107.623\n",
      "trainer/Z Expert Predictions Max     1334.76\n",
      "trainer/Z Expert Predictions Min      721.705\n",
      "trainer/Z Policy Predictions Mean     979.285\n",
      "trainer/Z Policy Predictions Std      309.952\n",
      "trainer/Z Policy Predictions Max     1318.57\n",
      "trainer/Z Policy Predictions Min       52.5018\n",
      "trainer/Z Expert Targets Mean        1195.69\n",
      "trainer/Z Expert Targets Std          107.211\n",
      "trainer/Z Expert Targets Max         1334.08\n",
      "trainer/Z Expert Targets Min          776.637\n",
      "trainer/Z Policy Targets Mean         978.341\n",
      "trainer/Z Policy Targets Std          305.478\n",
      "trainer/Z Policy Targets Max         1311.68\n",
      "trainer/Z Policy Targets Min           89.5969\n",
      "trainer/Log Pis Mean                   30.4779\n",
      "trainer/Log Pis Std                     7.3785\n",
      "trainer/Policy mu Mean                  1.4568\n",
      "trainer/Policy mu Std                   2.4856\n",
      "trainer/Policy log std Mean            -3.32112\n",
      "trainer/Policy log std Std              1.37936\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        166156\n",
      "exploration/num paths total           933\n",
      "evaluation/num steps total              1.04991e+06\n",
      "evaluation/num paths total           1614\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18423\n",
      "evaluation/Rewards Std                  1.31252\n",
      "evaluation/Rewards Max                  7.36215\n",
      "evaluation/Rewards Min                  0.128735\n",
      "evaluation/Returns Mean              5184.23\n",
      "evaluation/Returns Std                122.9\n",
      "evaluation/Returns Max               5304.79\n",
      "evaluation/Returns Min               4899.9\n",
      "evaluation/Estimation Bias Mean      1175.36\n",
      "evaluation/Estimation Bias Std        172.591\n",
      "evaluation/EB/Q_True Mean              49.4164\n",
      "evaluation/EB/Q_True Std              152.551\n",
      "evaluation/EB/Q_Pred Mean            1224.78\n",
      "evaluation/EB/Q_Pred Std               95.2452\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5184.23\n",
      "evaluation/Actions Mean                 0.517285\n",
      "evaluation/Actions Std                  0.646467\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.8611\n",
      "time/backward_zf1 (s)                   2.01039\n",
      "time/backward_zf2 (s)                   1.92858\n",
      "time/data sampling (s)                  0.277109\n",
      "time/data storing (s)                   0.0144774\n",
      "time/evaluation sampling (s)            1.42661\n",
      "time/exploration sampling (s)           0.197455\n",
      "time/logging (s)                        0.0120678\n",
      "time/preback_alpha (s)                  0.569082\n",
      "time/preback_policy (s)                 1.11287\n",
      "time/preback_start (s)                  0.123873\n",
      "time/preback_zf (s)                     5.05288\n",
      "time/saving (s)                         0.00555461\n",
      "time/training (s)                       2.16556\n",
      "time/epoch (s)                         16.7576\n",
      "time/total (s)                       2645.37\n",
      "Epoch                                 160\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:36:34.107708 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 161 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 172000\n",
      "trainer/ZF1 Loss                       23.6772\n",
      "trainer/ZF2 Loss                       22.8379\n",
      "trainer/ZF Expert Reward                9.23208\n",
      "trainer/ZF Policy Reward               -1.19636\n",
      "trainer/ZF CHI2 Term                   33.9981\n",
      "trainer/Policy Loss                 -1019.25\n",
      "trainer/Bias Loss                      95.4281\n",
      "trainer/Bias Value                     11.3149\n",
      "trainer/Policy Grad Norm              246.464\n",
      "trainer/Policy Param Norm              32.7253\n",
      "trainer/Zf1 Grad Norm                2403.57\n",
      "trainer/Zf1 Param Norm                 94.0944\n",
      "trainer/Zf2 Grad Norm                3185.49\n",
      "trainer/Zf2 Param Norm                 92.3851\n",
      "trainer/Z Expert Predictions Mean    1218.33\n",
      "trainer/Z Expert Predictions Std       96.939\n",
      "trainer/Z Expert Predictions Max     1355.84\n",
      "trainer/Z Expert Predictions Min      846.241\n",
      "trainer/Z Policy Predictions Mean    1009.25\n",
      "trainer/Z Policy Predictions Std      304.162\n",
      "trainer/Z Policy Predictions Max     1324.99\n",
      "trainer/Z Policy Predictions Min      -77.6792\n",
      "trainer/Z Expert Targets Mean        1209.09\n",
      "trainer/Z Expert Targets Std           95.7041\n",
      "trainer/Z Expert Targets Max         1342.53\n",
      "trainer/Z Expert Targets Min          844.071\n",
      "trainer/Z Policy Targets Mean        1010.44\n",
      "trainer/Z Policy Targets Std          299.888\n",
      "trainer/Z Policy Targets Max         1317.87\n",
      "trainer/Z Policy Targets Min          -70.5803\n",
      "trainer/Log Pis Mean                   31.2051\n",
      "trainer/Log Pis Std                     8.20014\n",
      "trainer/Policy mu Mean                  1.54092\n",
      "trainer/Policy mu Std                   2.65164\n",
      "trainer/Policy log std Mean            -3.34705\n",
      "trainer/Policy log std Std              1.43108\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        167156\n",
      "exploration/num paths total           934\n",
      "evaluation/num steps total              1.05829e+06\n",
      "evaluation/num paths total           1624\n",
      "evaluation/path length Mean           838.4\n",
      "evaluation/path length Std            173.727\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            495\n",
      "evaluation/Rewards Mean                 5.04821\n",
      "evaluation/Rewards Std                  1.35949\n",
      "evaluation/Rewards Max                  7.2201\n",
      "evaluation/Rewards Min                  0.282364\n",
      "evaluation/Returns Mean              4232.42\n",
      "evaluation/Returns Std                959.508\n",
      "evaluation/Returns Max               5189.67\n",
      "evaluation/Returns Min               2313.56\n",
      "evaluation/Estimation Bias Mean      1035.11\n",
      "evaluation/Estimation Bias Std        288.042\n",
      "evaluation/EB/Q_True Mean              55.1869\n",
      "evaluation/EB/Q_True Std              154.73\n",
      "evaluation/EB/Q_Pred Mean            1090.29\n",
      "evaluation/EB/Q_Pred Std              246.563\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4232.42\n",
      "evaluation/Actions Mean                 0.50763\n",
      "evaluation/Actions Std                  0.657642\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92548\n",
      "time/backward_zf1 (s)                   2.06599\n",
      "time/backward_zf2 (s)                   1.99536\n",
      "time/data sampling (s)                  0.268154\n",
      "time/data storing (s)                   0.0145513\n",
      "time/evaluation sampling (s)            1.43464\n",
      "time/exploration sampling (s)           0.200644\n",
      "time/logging (s)                        0.0103731\n",
      "time/preback_alpha (s)                  0.569843\n",
      "time/preback_policy (s)                 1.10315\n",
      "time/preback_start (s)                  0.12425\n",
      "time/preback_zf (s)                     5.08327\n",
      "time/saving (s)                         0.00544017\n",
      "time/training (s)                       2.24998\n",
      "time/epoch (s)                         17.0511\n",
      "time/total (s)                       2662.45\n",
      "Epoch                                 161\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:36:50.876798 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 162 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 173000\n",
      "trainer/ZF1 Loss                       16.8482\n",
      "trainer/ZF2 Loss                       15.9538\n",
      "trainer/ZF Expert Reward               15.5986\n",
      "trainer/ZF Policy Reward                0.437007\n",
      "trainer/ZF CHI2 Term                   31.8703\n",
      "trainer/Policy Loss                  -976.106\n",
      "trainer/Bias Loss                      92.92\n",
      "trainer/Bias Value                     11.3212\n",
      "trainer/Policy Grad Norm              251.289\n",
      "trainer/Policy Param Norm              32.7513\n",
      "trainer/Zf1 Grad Norm                1576.23\n",
      "trainer/Zf1 Param Norm                 94.324\n",
      "trainer/Zf2 Grad Norm                1477.48\n",
      "trainer/Zf2 Param Norm                 92.6333\n",
      "trainer/Z Expert Predictions Mean    1219.65\n",
      "trainer/Z Expert Predictions Std      110.255\n",
      "trainer/Z Expert Predictions Max     1358.97\n",
      "trainer/Z Expert Predictions Min      776.326\n",
      "trainer/Z Policy Predictions Mean     964.797\n",
      "trainer/Z Policy Predictions Std      345.333\n",
      "trainer/Z Policy Predictions Max     1313.7\n",
      "trainer/Z Policy Predictions Min       22.23\n",
      "trainer/Z Expert Targets Mean        1204.05\n",
      "trainer/Z Expert Targets Std          108.236\n",
      "trainer/Z Expert Targets Max         1335.28\n",
      "trainer/Z Expert Targets Min          774.843\n",
      "trainer/Z Policy Targets Mean         964.36\n",
      "trainer/Z Policy Targets Std          337.9\n",
      "trainer/Z Policy Targets Max         1301.7\n",
      "trainer/Z Policy Targets Min           24.1578\n",
      "trainer/Log Pis Mean                   30.7667\n",
      "trainer/Log Pis Std                     7.19254\n",
      "trainer/Policy mu Mean                  1.52689\n",
      "trainer/Policy mu Std                   2.67502\n",
      "trainer/Policy log std Mean            -3.22586\n",
      "trainer/Policy log std Std              1.40485\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        167156\n",
      "exploration/num paths total           934\n",
      "evaluation/num steps total              1.06813e+06\n",
      "evaluation/num paths total           1634\n",
      "evaluation/path length Mean           983.4\n",
      "evaluation/path length Std             49.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            834\n",
      "evaluation/Rewards Mean                 5.08798\n",
      "evaluation/Rewards Std                  1.26886\n",
      "evaluation/Rewards Max                  7.22929\n",
      "evaluation/Rewards Min                  0.16888\n",
      "evaluation/Returns Mean              5003.52\n",
      "evaluation/Returns Std                310.774\n",
      "evaluation/Returns Max               5199.59\n",
      "evaluation/Returns Min               4107.04\n",
      "evaluation/Estimation Bias Mean      1096.1\n",
      "evaluation/Estimation Bias Std        232.602\n",
      "evaluation/EB/Q_True Mean              49.9195\n",
      "evaluation/EB/Q_True Std              152.434\n",
      "evaluation/EB/Q_Pred Mean            1146.02\n",
      "evaluation/EB/Q_Pred Std              159.989\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5003.52\n",
      "evaluation/Actions Mean                 0.513755\n",
      "evaluation/Actions Std                  0.655231\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7922\n",
      "time/backward_zf1 (s)                   1.9246\n",
      "time/backward_zf2 (s)                   1.838\n",
      "time/data sampling (s)                  0.271128\n",
      "time/data storing (s)                   0.0139597\n",
      "time/evaluation sampling (s)            1.40918\n",
      "time/exploration sampling (s)           0.19298\n",
      "time/logging (s)                        0.0117956\n",
      "time/preback_alpha (s)                  0.570744\n",
      "time/preback_policy (s)                 0.993163\n",
      "time/preback_start (s)                  0.123499\n",
      "time/preback_zf (s)                     5.07843\n",
      "time/saving (s)                         0.00574653\n",
      "time/training (s)                       2.47594\n",
      "time/epoch (s)                         16.7014\n",
      "time/total (s)                       2679.17\n",
      "Epoch                                 162\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:37:08.226989 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 163 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 174000\n",
      "trainer/ZF1 Loss                       31.5741\n",
      "trainer/ZF2 Loss                       27.8071\n",
      "trainer/ZF Expert Reward               15.0123\n",
      "trainer/ZF Policy Reward                0.672283\n",
      "trainer/ZF CHI2 Term                   44.3422\n",
      "trainer/Policy Loss                  -999.284\n",
      "trainer/Bias Loss                     136.774\n",
      "trainer/Bias Value                     11.3274\n",
      "trainer/Policy Grad Norm              314.329\n",
      "trainer/Policy Param Norm              32.7816\n",
      "trainer/Zf1 Grad Norm                2084.75\n",
      "trainer/Zf1 Param Norm                 94.5969\n",
      "trainer/Zf2 Grad Norm                2104.71\n",
      "trainer/Zf2 Param Norm                 92.9175\n",
      "trainer/Z Expert Predictions Mean    1216.7\n",
      "trainer/Z Expert Predictions Std      102.55\n",
      "trainer/Z Expert Predictions Max     1358.7\n",
      "trainer/Z Expert Predictions Min      816.937\n",
      "trainer/Z Policy Predictions Mean     989.09\n",
      "trainer/Z Policy Predictions Std      328.825\n",
      "trainer/Z Policy Predictions Max     1343.63\n",
      "trainer/Z Policy Predictions Min      -41.1299\n",
      "trainer/Z Expert Targets Mean        1201.69\n",
      "trainer/Z Expert Targets Std          104.458\n",
      "trainer/Z Expert Targets Max         1327.16\n",
      "trainer/Z Expert Targets Min          813.454\n",
      "trainer/Z Policy Targets Mean         988.418\n",
      "trainer/Z Policy Targets Std          324.766\n",
      "trainer/Z Policy Targets Max         1345.21\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   31.164\n",
      "trainer/Log Pis Std                     7.3921\n",
      "trainer/Policy mu Mean                  1.51742\n",
      "trainer/Policy mu Std                   2.57909\n",
      "trainer/Policy log std Mean            -3.26567\n",
      "trainer/Policy log std Std              1.4291\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        169968\n",
      "exploration/num paths total           937\n",
      "evaluation/num steps total              1.07813e+06\n",
      "evaluation/num paths total           1644\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13422\n",
      "evaluation/Rewards Std                  1.28749\n",
      "evaluation/Rewards Max                  7.06208\n",
      "evaluation/Rewards Min                  0.0743739\n",
      "evaluation/Returns Mean              5134.22\n",
      "evaluation/Returns Std                 51.608\n",
      "evaluation/Returns Max               5214.76\n",
      "evaluation/Returns Min               5004.38\n",
      "evaluation/Estimation Bias Mean      1113.24\n",
      "evaluation/Estimation Bias Std        214.618\n",
      "evaluation/EB/Q_True Mean              48.5246\n",
      "evaluation/EB/Q_True Std              149.78\n",
      "evaluation/EB/Q_Pred Mean            1161.76\n",
      "evaluation/EB/Q_Pred Std              145.708\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5134.22\n",
      "evaluation/Actions Mean                 0.509929\n",
      "evaluation/Actions Std                  0.65398\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94688\n",
      "time/backward_zf1 (s)                   2.08789\n",
      "time/backward_zf2 (s)                   2.01712\n",
      "time/data sampling (s)                  0.270252\n",
      "time/data storing (s)                   0.014256\n",
      "time/evaluation sampling (s)            1.53169\n",
      "time/exploration sampling (s)           0.200872\n",
      "time/logging (s)                        0.0119094\n",
      "time/preback_alpha (s)                  0.58041\n",
      "time/preback_policy (s)                 1.13291\n",
      "time/preback_start (s)                  0.125065\n",
      "time/preback_zf (s)                     5.12154\n",
      "time/saving (s)                         0.00592461\n",
      "time/training (s)                       2.23396\n",
      "time/epoch (s)                         17.2807\n",
      "time/total (s)                       2696.47\n",
      "Epoch                                 163\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:37:25.810428 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 164 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 175000\n",
      "trainer/ZF1 Loss                       43.0007\n",
      "trainer/ZF2 Loss                       52.0827\n",
      "trainer/ZF Expert Reward               11.8742\n",
      "trainer/ZF Policy Reward               -4.11041\n",
      "trainer/ZF CHI2 Term                   63.8243\n",
      "trainer/Policy Loss                 -1010.46\n",
      "trainer/Bias Loss                     123.541\n",
      "trainer/Bias Value                     11.3337\n",
      "trainer/Policy Grad Norm              379.912\n",
      "trainer/Policy Param Norm              32.8151\n",
      "trainer/Zf1 Grad Norm                3471.03\n",
      "trainer/Zf1 Param Norm                 94.8533\n",
      "trainer/Zf2 Grad Norm                4198.87\n",
      "trainer/Zf2 Param Norm                 93.1971\n",
      "trainer/Z Expert Predictions Mean    1203.64\n",
      "trainer/Z Expert Predictions Std      123.136\n",
      "trainer/Z Expert Predictions Max     1369.83\n",
      "trainer/Z Expert Predictions Min      789.143\n",
      "trainer/Z Policy Predictions Mean     994.046\n",
      "trainer/Z Policy Predictions Std      309.085\n",
      "trainer/Z Policy Predictions Max     1332.77\n",
      "trainer/Z Policy Predictions Min       65.012\n",
      "trainer/Z Expert Targets Mean        1191.77\n",
      "trainer/Z Expert Targets Std          121.89\n",
      "trainer/Z Expert Targets Max         1357.72\n",
      "trainer/Z Expert Targets Min          772.392\n",
      "trainer/Z Policy Targets Mean         998.157\n",
      "trainer/Z Policy Targets Std          302.649\n",
      "trainer/Z Policy Targets Max         1317.24\n",
      "trainer/Z Policy Targets Min           70.9805\n",
      "trainer/Log Pis Mean                   29.799\n",
      "trainer/Log Pis Std                     6.50512\n",
      "trainer/Policy mu Mean                  1.39724\n",
      "trainer/Policy mu Std                   2.43821\n",
      "trainer/Policy log std Mean            -3.283\n",
      "trainer/Policy log std Std              1.4061\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        170968\n",
      "exploration/num paths total           938\n",
      "evaluation/num steps total              1.08748e+06\n",
      "evaluation/num paths total           1654\n",
      "evaluation/path length Mean           935.8\n",
      "evaluation/path length Std            173.224\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            419\n",
      "evaluation/Rewards Mean                 5.06916\n",
      "evaluation/Rewards Std                  1.27426\n",
      "evaluation/Rewards Max                  7.12885\n",
      "evaluation/Rewards Min                  0.329105\n",
      "evaluation/Returns Mean              4743.72\n",
      "evaluation/Returns Std                969.11\n",
      "evaluation/Returns Max               5160.64\n",
      "evaluation/Returns Min               1852.55\n",
      "evaluation/Estimation Bias Mean      1089.39\n",
      "evaluation/Estimation Bias Std        254.198\n",
      "evaluation/EB/Q_True Mean              51.8035\n",
      "evaluation/EB/Q_True Std              154.021\n",
      "evaluation/EB/Q_Pred Mean            1141.19\n",
      "evaluation/EB/Q_Pred Std              191.986\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4743.72\n",
      "evaluation/Actions Mean                 0.511135\n",
      "evaluation/Actions Std                  0.65567\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.03589\n",
      "time/backward_zf1 (s)                   2.1892\n",
      "time/backward_zf2 (s)                   2.11903\n",
      "time/data sampling (s)                  0.274587\n",
      "time/data storing (s)                   0.0140749\n",
      "time/evaluation sampling (s)            1.42106\n",
      "time/exploration sampling (s)           0.200109\n",
      "time/logging (s)                        0.0114568\n",
      "time/preback_alpha (s)                  0.589534\n",
      "time/preback_policy (s)                 1.22535\n",
      "time/preback_start (s)                  0.126935\n",
      "time/preback_zf (s)                     5.15531\n",
      "time/saving (s)                         0.00536613\n",
      "time/training (s)                       2.14864\n",
      "time/epoch (s)                         17.5166\n",
      "time/total (s)                       2714.01\n",
      "Epoch                                 164\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:37:42.717175 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 165 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 176000\n",
      "trainer/ZF1 Loss                       58.8361\n",
      "trainer/ZF2 Loss                       51.1271\n",
      "trainer/ZF Expert Reward               24.4065\n",
      "trainer/ZF Policy Reward               13.4006\n",
      "trainer/ZF CHI2 Term                   66.2928\n",
      "trainer/Policy Loss                 -1003.65\n",
      "trainer/Bias Loss                     287.86\n",
      "trainer/Bias Value                     11.3402\n",
      "trainer/Policy Grad Norm              369.271\n",
      "trainer/Policy Param Norm              32.8433\n",
      "trainer/Zf1 Grad Norm                4047.43\n",
      "trainer/Zf1 Param Norm                 95.1025\n",
      "trainer/Zf2 Grad Norm                3170.69\n",
      "trainer/Zf2 Param Norm                 93.4684\n",
      "trainer/Z Expert Predictions Mean    1235.26\n",
      "trainer/Z Expert Predictions Std       95.7457\n",
      "trainer/Z Expert Predictions Max     1368.79\n",
      "trainer/Z Expert Predictions Min      820.497\n",
      "trainer/Z Policy Predictions Mean     998.814\n",
      "trainer/Z Policy Predictions Std      334.762\n",
      "trainer/Z Policy Predictions Max     1341.72\n",
      "trainer/Z Policy Predictions Min       37.5334\n",
      "trainer/Z Expert Targets Mean        1210.85\n",
      "trainer/Z Expert Targets Std           96.2832\n",
      "trainer/Z Expert Targets Max         1345.92\n",
      "trainer/Z Expert Targets Min          818.482\n",
      "trainer/Z Policy Targets Mean         985.413\n",
      "trainer/Z Policy Targets Std          328.032\n",
      "trainer/Z Policy Targets Max         1309.98\n",
      "trainer/Z Policy Targets Min            4.9867\n",
      "trainer/Log Pis Mean                   30.5274\n",
      "trainer/Log Pis Std                     6.64746\n",
      "trainer/Policy mu Mean                  1.47681\n",
      "trainer/Policy mu Std                   2.50057\n",
      "trainer/Policy log std Mean            -3.38783\n",
      "trainer/Policy log std Std              1.35246\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        170968\n",
      "exploration/num paths total           938\n",
      "evaluation/num steps total              1.09748e+06\n",
      "evaluation/num paths total           1664\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07309\n",
      "evaluation/Rewards Std                  1.25676\n",
      "evaluation/Rewards Max                  7.14353\n",
      "evaluation/Rewards Min                  0.164132\n",
      "evaluation/Returns Mean              5073.09\n",
      "evaluation/Returns Std                 58.7772\n",
      "evaluation/Returns Max               5206.37\n",
      "evaluation/Returns Min               4983.91\n",
      "evaluation/Estimation Bias Mean      1129.59\n",
      "evaluation/Estimation Bias Std        177.773\n",
      "evaluation/EB/Q_True Mean              47.9098\n",
      "evaluation/EB/Q_True Std              147.768\n",
      "evaluation/EB/Q_Pred Mean            1177.5\n",
      "evaluation/EB/Q_Pred Std              102.407\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5073.09\n",
      "evaluation/Actions Mean                 0.518053\n",
      "evaluation/Actions Std                  0.649938\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88281\n",
      "time/backward_zf1 (s)                   2.03695\n",
      "time/backward_zf2 (s)                   1.96344\n",
      "time/data sampling (s)                  0.271742\n",
      "time/data storing (s)                   0.014755\n",
      "time/evaluation sampling (s)            1.40531\n",
      "time/exploration sampling (s)           0.199148\n",
      "time/logging (s)                        0.0121985\n",
      "time/preback_alpha (s)                  0.570759\n",
      "time/preback_policy (s)                 1.11414\n",
      "time/preback_start (s)                  0.124434\n",
      "time/preback_zf (s)                     5.06833\n",
      "time/saving (s)                         0.00588755\n",
      "time/training (s)                       2.17126\n",
      "time/epoch (s)                         16.8412\n",
      "time/total (s)                       2730.87\n",
      "Epoch                                 165\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:38:00.085521 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 166 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 177000\n",
      "trainer/ZF1 Loss                       27.029\n",
      "trainer/ZF2 Loss                       32.7695\n",
      "trainer/ZF Expert Reward               12.3525\n",
      "trainer/ZF Policy Reward               -0.529194\n",
      "trainer/ZF CHI2 Term                   43.0846\n",
      "trainer/Policy Loss                 -1019.87\n",
      "trainer/Bias Loss                     149.131\n",
      "trainer/Bias Value                     11.3462\n",
      "trainer/Policy Grad Norm              294.755\n",
      "trainer/Policy Param Norm              32.8736\n",
      "trainer/Zf1 Grad Norm                3836.95\n",
      "trainer/Zf1 Param Norm                 95.3744\n",
      "trainer/Zf2 Grad Norm                5287.56\n",
      "trainer/Zf2 Param Norm                 93.7355\n",
      "trainer/Z Expert Predictions Mean    1219.94\n",
      "trainer/Z Expert Predictions Std      107.559\n",
      "trainer/Z Expert Predictions Max     1381.31\n",
      "trainer/Z Expert Predictions Min      849.018\n",
      "trainer/Z Policy Predictions Mean    1006.01\n",
      "trainer/Z Policy Predictions Std      321.283\n",
      "trainer/Z Policy Predictions Max     1348.89\n",
      "trainer/Z Policy Predictions Min       17.878\n",
      "trainer/Z Expert Targets Mean        1207.59\n",
      "trainer/Z Expert Targets Std          106.034\n",
      "trainer/Z Expert Targets Max         1363.15\n",
      "trainer/Z Expert Targets Min          838.575\n",
      "trainer/Z Policy Targets Mean        1006.54\n",
      "trainer/Z Policy Targets Std          314.298\n",
      "trainer/Z Policy Targets Max         1345.8\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   30.3684\n",
      "trainer/Log Pis Std                     6.86281\n",
      "trainer/Policy mu Mean                  1.51304\n",
      "trainer/Policy mu Std                   2.53985\n",
      "trainer/Policy log std Mean            -3.33437\n",
      "trainer/Policy log std Std              1.44263\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        172968\n",
      "exploration/num paths total           940\n",
      "evaluation/num steps total              1.10748e+06\n",
      "evaluation/num paths total           1674\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.06853\n",
      "evaluation/Rewards Std                  1.241\n",
      "evaluation/Rewards Max                  7.17103\n",
      "evaluation/Rewards Min                  0.164859\n",
      "evaluation/Returns Mean              5068.53\n",
      "evaluation/Returns Std                 66.9602\n",
      "evaluation/Returns Max               5146.22\n",
      "evaluation/Returns Min               4913.46\n",
      "evaluation/Estimation Bias Mean      1120.34\n",
      "evaluation/Estimation Bias Std        184.592\n",
      "evaluation/EB/Q_True Mean              47.1444\n",
      "evaluation/EB/Q_True Std              145.63\n",
      "evaluation/EB/Q_Pred Mean            1167.48\n",
      "evaluation/EB/Q_Pred Std              124.38\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5068.53\n",
      "evaluation/Actions Mean                 0.512143\n",
      "evaluation/Actions Std                  0.651386\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95394\n",
      "time/backward_zf1 (s)                   2.11584\n",
      "time/backward_zf2 (s)                   2.04875\n",
      "time/data sampling (s)                  0.263023\n",
      "time/data storing (s)                   0.0146728\n",
      "time/evaluation sampling (s)            1.54551\n",
      "time/exploration sampling (s)           0.206197\n",
      "time/logging (s)                        0.0116234\n",
      "time/preback_alpha (s)                  0.576537\n",
      "time/preback_policy (s)                 1.18541\n",
      "time/preback_start (s)                  0.126112\n",
      "time/preback_zf (s)                     5.11279\n",
      "time/saving (s)                         0.00603549\n",
      "time/training (s)                       2.13164\n",
      "time/epoch (s)                         17.2981\n",
      "time/total (s)                       2748.19\n",
      "Epoch                                 166\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:38:16.900683 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 167 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 178000\n",
      "trainer/ZF1 Loss                       50.9007\n",
      "trainer/ZF2 Loss                       25.9072\n",
      "trainer/ZF Expert Reward               12.9972\n",
      "trainer/ZF Policy Reward                0.387434\n",
      "trainer/ZF CHI2 Term                   51.3153\n",
      "trainer/Policy Loss                  -986.614\n",
      "trainer/Bias Loss                     163.401\n",
      "trainer/Bias Value                     11.3524\n",
      "trainer/Policy Grad Norm              235.599\n",
      "trainer/Policy Param Norm              32.9082\n",
      "trainer/Zf1 Grad Norm                9071.69\n",
      "trainer/Zf1 Param Norm                 95.6352\n",
      "trainer/Zf2 Grad Norm                1937\n",
      "trainer/Zf2 Param Norm                 94.0085\n",
      "trainer/Z Expert Predictions Mean    1224.8\n",
      "trainer/Z Expert Predictions Std      106.843\n",
      "trainer/Z Expert Predictions Max     1392.68\n",
      "trainer/Z Expert Predictions Min      864.507\n",
      "trainer/Z Policy Predictions Mean     973.758\n",
      "trainer/Z Policy Predictions Std      334.11\n",
      "trainer/Z Policy Predictions Max     1316.9\n",
      "trainer/Z Policy Predictions Min      -22.1338\n",
      "trainer/Z Expert Targets Mean        1211.81\n",
      "trainer/Z Expert Targets Std          107.049\n",
      "trainer/Z Expert Targets Max         1374.91\n",
      "trainer/Z Expert Targets Min          809.147\n",
      "trainer/Z Policy Targets Mean         973.37\n",
      "trainer/Z Policy Targets Std          331.307\n",
      "trainer/Z Policy Targets Max         1313.36\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   30.1595\n",
      "trainer/Log Pis Std                     7.24983\n",
      "trainer/Policy mu Mean                  1.44557\n",
      "trainer/Policy mu Std                   2.50146\n",
      "trainer/Policy log std Mean            -3.33842\n",
      "trainer/Policy log std Std              1.37269\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        172968\n",
      "exploration/num paths total           940\n",
      "evaluation/num steps total              1.11748e+06\n",
      "evaluation/num paths total           1684\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09734\n",
      "evaluation/Rewards Std                  1.2819\n",
      "evaluation/Rewards Max                  7.31744\n",
      "evaluation/Rewards Min                  0.111516\n",
      "evaluation/Returns Mean              5097.34\n",
      "evaluation/Returns Std                102.316\n",
      "evaluation/Returns Max               5225.65\n",
      "evaluation/Returns Min               4907.7\n",
      "evaluation/Estimation Bias Mean      1140.57\n",
      "evaluation/Estimation Bias Std        187.395\n",
      "evaluation/EB/Q_True Mean              46.3172\n",
      "evaluation/EB/Q_True Std              142.733\n",
      "evaluation/EB/Q_Pred Mean            1186.89\n",
      "evaluation/EB/Q_Pred Std              102.932\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5097.34\n",
      "evaluation/Actions Mean                 0.517733\n",
      "evaluation/Actions Std                  0.647715\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79513\n",
      "time/backward_zf1 (s)                   1.91782\n",
      "time/backward_zf2 (s)                   1.84115\n",
      "time/data sampling (s)                  0.278686\n",
      "time/data storing (s)                   0.0138734\n",
      "time/evaluation sampling (s)            1.43899\n",
      "time/exploration sampling (s)           0.191846\n",
      "time/logging (s)                        0.0120014\n",
      "time/preback_alpha (s)                  0.572122\n",
      "time/preback_policy (s)                 1.0069\n",
      "time/preback_start (s)                  0.122956\n",
      "time/preback_zf (s)                     5.09847\n",
      "time/saving (s)                         0.00581373\n",
      "time/training (s)                       2.45451\n",
      "time/epoch (s)                         16.7503\n",
      "time/total (s)                       2764.95\n",
      "Epoch                                 167\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:38:33.799682 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 168 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 179000\n",
      "trainer/ZF1 Loss                       33.7719\n",
      "trainer/ZF2 Loss                       36.959\n",
      "trainer/ZF Expert Reward                7.68378\n",
      "trainer/ZF Policy Reward               -4.42563\n",
      "trainer/ZF CHI2 Term                   47.7719\n",
      "trainer/Policy Loss                 -1003.06\n",
      "trainer/Bias Loss                     134.594\n",
      "trainer/Bias Value                     11.3587\n",
      "trainer/Policy Grad Norm              316.272\n",
      "trainer/Policy Param Norm              32.9404\n",
      "trainer/Zf1 Grad Norm                3498.85\n",
      "trainer/Zf1 Param Norm                 95.9202\n",
      "trainer/Zf2 Grad Norm                4476.88\n",
      "trainer/Zf2 Param Norm                 94.2878\n",
      "trainer/Z Expert Predictions Mean    1213.61\n",
      "trainer/Z Expert Predictions Std      106.788\n",
      "trainer/Z Expert Predictions Max     1361.32\n",
      "trainer/Z Expert Predictions Min      816.775\n",
      "trainer/Z Policy Predictions Mean     988.837\n",
      "trainer/Z Policy Predictions Std      317.24\n",
      "trainer/Z Policy Predictions Max     1339.51\n",
      "trainer/Z Policy Predictions Min        5.45878\n",
      "trainer/Z Expert Targets Mean        1205.93\n",
      "trainer/Z Expert Targets Std          107.377\n",
      "trainer/Z Expert Targets Max         1347.67\n",
      "trainer/Z Expert Targets Min          826.287\n",
      "trainer/Z Policy Targets Mean         993.263\n",
      "trainer/Z Policy Targets Std          313.053\n",
      "trainer/Z Policy Targets Max         1334.2\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.7036\n",
      "trainer/Log Pis Std                     6.10391\n",
      "trainer/Policy mu Mean                  1.43576\n",
      "trainer/Policy mu Std                   2.39306\n",
      "trainer/Policy log std Mean            -3.33469\n",
      "trainer/Policy log std Std              1.36292\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        172968\n",
      "exploration/num paths total           940\n",
      "evaluation/num steps total              1.12704e+06\n",
      "evaluation/num paths total           1694\n",
      "evaluation/path length Mean           955.1\n",
      "evaluation/path length Std             76.495\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            789\n",
      "evaluation/Rewards Mean                 5.17185\n",
      "evaluation/Rewards Std                  1.28973\n",
      "evaluation/Rewards Max                  7.07201\n",
      "evaluation/Rewards Min                  0.192672\n",
      "evaluation/Returns Mean              4939.63\n",
      "evaluation/Returns Std                429.893\n",
      "evaluation/Returns Max               5243.11\n",
      "evaluation/Returns Min               3994.06\n",
      "evaluation/Estimation Bias Mean      1044.1\n",
      "evaluation/Estimation Bias Std        323.091\n",
      "evaluation/EB/Q_True Mean              50.9545\n",
      "evaluation/EB/Q_True Std              153.314\n",
      "evaluation/EB/Q_Pred Mean            1095.05\n",
      "evaluation/EB/Q_Pred Std              254.56\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4939.63\n",
      "evaluation/Actions Mean                 0.502786\n",
      "evaluation/Actions Std                  0.666871\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88375\n",
      "time/backward_zf1 (s)                   2.02194\n",
      "time/backward_zf2 (s)                   1.95223\n",
      "time/data sampling (s)                  0.246462\n",
      "time/data storing (s)                   0.0134197\n",
      "time/evaluation sampling (s)            1.51757\n",
      "time/exploration sampling (s)           0.187634\n",
      "time/logging (s)                        0.011384\n",
      "time/preback_alpha (s)                  0.567341\n",
      "time/preback_policy (s)                 1.13291\n",
      "time/preback_start (s)                  0.121119\n",
      "time/preback_zf (s)                     5.05564\n",
      "time/saving (s)                         0.00556481\n",
      "time/training (s)                       2.10702\n",
      "time/epoch (s)                         16.824\n",
      "time/total (s)                       2781.81\n",
      "Epoch                                 168\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:38:50.869189 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 169 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 180000\n",
      "trainer/ZF1 Loss                       55.2694\n",
      "trainer/ZF2 Loss                       60.7245\n",
      "trainer/ZF Expert Reward               15.7951\n",
      "trainer/ZF Policy Reward                2.0171\n",
      "trainer/ZF CHI2 Term                   72.0843\n",
      "trainer/Policy Loss                  -947.403\n",
      "trainer/Bias Loss                     127.804\n",
      "trainer/Bias Value                     11.3651\n",
      "trainer/Policy Grad Norm              270.605\n",
      "trainer/Policy Param Norm              32.972\n",
      "trainer/Zf1 Grad Norm                3613.83\n",
      "trainer/Zf1 Param Norm                 96.1867\n",
      "trainer/Zf2 Grad Norm                4484\n",
      "trainer/Zf2 Param Norm                 94.5694\n",
      "trainer/Z Expert Predictions Mean    1229.19\n",
      "trainer/Z Expert Predictions Std       98.189\n",
      "trainer/Z Expert Predictions Max     1382.6\n",
      "trainer/Z Expert Predictions Min      850.767\n",
      "trainer/Z Policy Predictions Mean     938.365\n",
      "trainer/Z Policy Predictions Std      360.266\n",
      "trainer/Z Policy Predictions Max     1320.77\n",
      "trainer/Z Policy Predictions Min      -33.9708\n",
      "trainer/Z Expert Targets Mean        1213.4\n",
      "trainer/Z Expert Targets Std           96.1343\n",
      "trainer/Z Expert Targets Max         1344.55\n",
      "trainer/Z Expert Targets Min          858.631\n",
      "trainer/Z Policy Targets Mean         936.348\n",
      "trainer/Z Policy Targets Std          357.19\n",
      "trainer/Z Policy Targets Max         1312.8\n",
      "trainer/Z Policy Targets Min          -47.6513\n",
      "trainer/Log Pis Mean                   30.9356\n",
      "trainer/Log Pis Std                     8.40105\n",
      "trainer/Policy mu Mean                  1.47374\n",
      "trainer/Policy mu Std                   2.69953\n",
      "trainer/Policy log std Mean            -3.31126\n",
      "trainer/Policy log std Std              1.41787\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        175968\n",
      "exploration/num paths total           943\n",
      "evaluation/num steps total              1.13704e+06\n",
      "evaluation/num paths total           1704\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09959\n",
      "evaluation/Rewards Std                  1.27035\n",
      "evaluation/Rewards Max                  7.28192\n",
      "evaluation/Rewards Min                  0.161148\n",
      "evaluation/Returns Mean              5099.59\n",
      "evaluation/Returns Std                 97.4467\n",
      "evaluation/Returns Max               5199.22\n",
      "evaluation/Returns Min               4885.3\n",
      "evaluation/Estimation Bias Mean      1143.52\n",
      "evaluation/Estimation Bias Std        183.241\n",
      "evaluation/EB/Q_True Mean              48.7138\n",
      "evaluation/EB/Q_True Std              150.565\n",
      "evaluation/EB/Q_Pred Mean            1192.23\n",
      "evaluation/EB/Q_Pred Std              102.592\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5099.59\n",
      "evaluation/Actions Mean                 0.519051\n",
      "evaluation/Actions Std                  0.647192\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.90268\n",
      "time/backward_zf1 (s)                   2.07372\n",
      "time/backward_zf2 (s)                   1.97847\n",
      "time/data sampling (s)                  0.259731\n",
      "time/data storing (s)                   0.0138337\n",
      "time/evaluation sampling (s)            1.47026\n",
      "time/exploration sampling (s)           0.20249\n",
      "time/logging (s)                        0.0145937\n",
      "time/preback_alpha (s)                  0.568177\n",
      "time/preback_policy (s)                 1.106\n",
      "time/preback_start (s)                  0.124116\n",
      "time/preback_zf (s)                     5.06841\n",
      "time/saving (s)                         0.00613214\n",
      "time/training (s)                       2.21628\n",
      "time/epoch (s)                         17.0049\n",
      "time/total (s)                       2798.83\n",
      "Epoch                                 169\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:39:08.055270 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 170 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 181000\n",
      "trainer/ZF1 Loss                       32.2065\n",
      "trainer/ZF2 Loss                       23.2998\n",
      "trainer/ZF Expert Reward               12.692\n",
      "trainer/ZF Policy Reward                0.845615\n",
      "trainer/ZF CHI2 Term                   39.8984\n",
      "trainer/Policy Loss                 -1009.77\n",
      "trainer/Bias Loss                      97.9265\n",
      "trainer/Bias Value                     11.3715\n",
      "trainer/Policy Grad Norm              249.728\n",
      "trainer/Policy Param Norm              33.0014\n",
      "trainer/Zf1 Grad Norm                2854.03\n",
      "trainer/Zf1 Param Norm                 96.4615\n",
      "trainer/Zf2 Grad Norm                2069.22\n",
      "trainer/Zf2 Param Norm                 94.8591\n",
      "trainer/Z Expert Predictions Mean    1224.52\n",
      "trainer/Z Expert Predictions Std      100.912\n",
      "trainer/Z Expert Predictions Max     1368.46\n",
      "trainer/Z Expert Predictions Min      809.494\n",
      "trainer/Z Policy Predictions Mean     998.967\n",
      "trainer/Z Policy Predictions Std      320.553\n",
      "trainer/Z Policy Predictions Max     1331.93\n",
      "trainer/Z Policy Predictions Min      -36.1941\n",
      "trainer/Z Expert Targets Mean        1211.82\n",
      "trainer/Z Expert Targets Std           98.1345\n",
      "trainer/Z Expert Targets Max         1352.17\n",
      "trainer/Z Expert Targets Min          761.882\n",
      "trainer/Z Policy Targets Mean         998.122\n",
      "trainer/Z Policy Targets Std          314.403\n",
      "trainer/Z Policy Targets Max         1303.07\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.8808\n",
      "trainer/Log Pis Std                     6.85397\n",
      "trainer/Policy mu Mean                  1.44766\n",
      "trainer/Policy mu Std                   2.36579\n",
      "trainer/Policy log std Mean            -3.33046\n",
      "trainer/Policy log std Std              1.34758\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        175968\n",
      "exploration/num paths total           943\n",
      "evaluation/num steps total              1.14704e+06\n",
      "evaluation/num paths total           1714\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12224\n",
      "evaluation/Rewards Std                  1.2822\n",
      "evaluation/Rewards Max                  7.14649\n",
      "evaluation/Rewards Min                  0.120627\n",
      "evaluation/Returns Mean              5122.24\n",
      "evaluation/Returns Std                 41.9492\n",
      "evaluation/Returns Max               5184.31\n",
      "evaluation/Returns Min               5050.48\n",
      "evaluation/Estimation Bias Mean      1151.69\n",
      "evaluation/Estimation Bias Std        172.654\n",
      "evaluation/EB/Q_True Mean              47.9399\n",
      "evaluation/EB/Q_True Std              148.128\n",
      "evaluation/EB/Q_Pred Mean            1199.63\n",
      "evaluation/EB/Q_Pred Std               90.3082\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5122.24\n",
      "evaluation/Actions Mean                 0.503179\n",
      "evaluation/Actions Std                  0.653691\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9665\n",
      "time/backward_zf1 (s)                   2.12284\n",
      "time/backward_zf2 (s)                   2.07231\n",
      "time/data sampling (s)                  0.264113\n",
      "time/data storing (s)                   0.0142664\n",
      "time/evaluation sampling (s)            1.42304\n",
      "time/exploration sampling (s)           0.196421\n",
      "time/logging (s)                        0.0116408\n",
      "time/preback_alpha (s)                  0.574709\n",
      "time/preback_policy (s)                 1.1847\n",
      "time/preback_start (s)                  0.127047\n",
      "time/preback_zf (s)                     5.08717\n",
      "time/saving (s)                         0.00570869\n",
      "time/training (s)                       2.05812\n",
      "time/epoch (s)                         17.1086\n",
      "time/total (s)                       2815.97\n",
      "Epoch                                 170\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:39:25.116350 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 171 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 182000\n",
      "trainer/ZF1 Loss                      368.722\n",
      "trainer/ZF2 Loss                      339.538\n",
      "trainer/ZF Expert Reward               19.2266\n",
      "trainer/ZF Policy Reward                7.94997\n",
      "trainer/ZF CHI2 Term                  365.715\n",
      "trainer/Policy Loss                  -994.059\n",
      "trainer/Bias Loss                     138.84\n",
      "trainer/Bias Value                     11.3776\n",
      "trainer/Policy Grad Norm              340.714\n",
      "trainer/Policy Param Norm              33.0348\n",
      "trainer/Zf1 Grad Norm                4377.18\n",
      "trainer/Zf1 Param Norm                 96.7298\n",
      "trainer/Zf2 Grad Norm                7037.15\n",
      "trainer/Zf2 Param Norm                 95.1355\n",
      "trainer/Z Expert Predictions Mean    1206.16\n",
      "trainer/Z Expert Predictions Std      134.782\n",
      "trainer/Z Expert Predictions Max     1379.88\n",
      "trainer/Z Expert Predictions Min       52.241\n",
      "trainer/Z Policy Predictions Mean     979.699\n",
      "trainer/Z Policy Predictions Std      363.293\n",
      "trainer/Z Policy Predictions Max     1321.31\n",
      "trainer/Z Policy Predictions Min      -43.0469\n",
      "trainer/Z Expert Targets Mean        1186.93\n",
      "trainer/Z Expert Targets Std          138.065\n",
      "trainer/Z Expert Targets Max         1368.29\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         971.749\n",
      "trainer/Z Policy Targets Std          361.839\n",
      "trainer/Z Policy Targets Max         1306.77\n",
      "trainer/Z Policy Targets Min          -34.1198\n",
      "trainer/Log Pis Mean                   30.7796\n",
      "trainer/Log Pis Std                     6.93876\n",
      "trainer/Policy mu Mean                  1.4817\n",
      "trainer/Policy mu Std                   2.4785\n",
      "trainer/Policy log std Mean            -3.39932\n",
      "trainer/Policy log std Std              1.32662\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        176968\n",
      "exploration/num paths total           944\n",
      "evaluation/num steps total              1.15704e+06\n",
      "evaluation/num paths total           1724\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20348\n",
      "evaluation/Rewards Std                  1.33142\n",
      "evaluation/Rewards Max                  7.27238\n",
      "evaluation/Rewards Min                  0.077704\n",
      "evaluation/Returns Mean              5203.48\n",
      "evaluation/Returns Std                 38.083\n",
      "evaluation/Returns Max               5250.37\n",
      "evaluation/Returns Min               5141.24\n",
      "evaluation/Estimation Bias Mean      1180.97\n",
      "evaluation/Estimation Bias Std        165.171\n",
      "evaluation/EB/Q_True Mean              48.7889\n",
      "evaluation/EB/Q_True Std              150.831\n",
      "evaluation/EB/Q_Pred Mean            1229.76\n",
      "evaluation/EB/Q_Pred Std               85.8317\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5203.48\n",
      "evaluation/Actions Mean                 0.514006\n",
      "evaluation/Actions Std                  0.645055\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.94619\n",
      "time/backward_zf1 (s)                   2.08355\n",
      "time/backward_zf2 (s)                   2.00659\n",
      "time/data sampling (s)                  0.274372\n",
      "time/data storing (s)                   0.0138239\n",
      "time/evaluation sampling (s)            1.43637\n",
      "time/exploration sampling (s)           0.196585\n",
      "time/logging (s)                        0.016915\n",
      "time/preback_alpha (s)                  0.573987\n",
      "time/preback_policy (s)                 1.13731\n",
      "time/preback_start (s)                  0.124407\n",
      "time/preback_zf (s)                     5.07053\n",
      "time/saving (s)                         0.00572499\n",
      "time/training (s)                       2.11428\n",
      "time/epoch (s)                         17.0006\n",
      "time/total (s)                       2832.99\n",
      "Epoch                                 171\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:39:42.195374 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 172 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 183000\n",
      "trainer/ZF1 Loss                       21.8038\n",
      "trainer/ZF2 Loss                       29.9633\n",
      "trainer/ZF Expert Reward               18.4846\n",
      "trainer/ZF Policy Reward                4.44654\n",
      "trainer/ZF CHI2 Term                   40.2258\n",
      "trainer/Policy Loss                  -985.593\n",
      "trainer/Bias Loss                     129.382\n",
      "trainer/Bias Value                     11.3837\n",
      "trainer/Policy Grad Norm              300.199\n",
      "trainer/Policy Param Norm              33.064\n",
      "trainer/Zf1 Grad Norm                2935.74\n",
      "trainer/Zf1 Param Norm                 96.9943\n",
      "trainer/Zf2 Grad Norm                3447.7\n",
      "trainer/Zf2 Param Norm                 95.3853\n",
      "trainer/Z Expert Predictions Mean    1216.97\n",
      "trainer/Z Expert Predictions Std      103.766\n",
      "trainer/Z Expert Predictions Max     1363.29\n",
      "trainer/Z Expert Predictions Min      827.061\n",
      "trainer/Z Policy Predictions Mean     977.759\n",
      "trainer/Z Policy Predictions Std      343.428\n",
      "trainer/Z Policy Predictions Max     1337.42\n",
      "trainer/Z Policy Predictions Min      -47.0425\n",
      "trainer/Z Expert Targets Mean        1198.48\n",
      "trainer/Z Expert Targets Std          104.194\n",
      "trainer/Z Expert Targets Max         1346.25\n",
      "trainer/Z Expert Targets Min          794.844\n",
      "trainer/Z Policy Targets Mean         973.313\n",
      "trainer/Z Policy Targets Std          337.144\n",
      "trainer/Z Policy Targets Max         1317.51\n",
      "trainer/Z Policy Targets Min          -39.1016\n",
      "trainer/Log Pis Mean                   30.4162\n",
      "trainer/Log Pis Std                     7.49313\n",
      "trainer/Policy mu Mean                  1.39708\n",
      "trainer/Policy mu Std                   2.60689\n",
      "trainer/Policy log std Mean            -3.4379\n",
      "trainer/Policy log std Std              1.43024\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        176968\n",
      "exploration/num paths total           944\n",
      "evaluation/num steps total              1.16704e+06\n",
      "evaluation/num paths total           1734\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20646\n",
      "evaluation/Rewards Std                  1.3337\n",
      "evaluation/Rewards Max                  7.30065\n",
      "evaluation/Rewards Min                  0.115589\n",
      "evaluation/Returns Mean              5206.46\n",
      "evaluation/Returns Std                 66.229\n",
      "evaluation/Returns Max               5276.96\n",
      "evaluation/Returns Min               5047.37\n",
      "evaluation/Estimation Bias Mean      1182.55\n",
      "evaluation/Estimation Bias Std        174.684\n",
      "evaluation/EB/Q_True Mean              49.9113\n",
      "evaluation/EB/Q_True Std              154.117\n",
      "evaluation/EB/Q_Pred Mean            1232.46\n",
      "evaluation/EB/Q_Pred Std               88.9433\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5206.46\n",
      "evaluation/Actions Mean                 0.511029\n",
      "evaluation/Actions Std                  0.64495\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.86949\n",
      "time/backward_zf1 (s)                   2.00508\n",
      "time/backward_zf2 (s)                   1.93052\n",
      "time/data sampling (s)                  0.263244\n",
      "time/data storing (s)                   0.0155129\n",
      "time/evaluation sampling (s)            1.46707\n",
      "time/exploration sampling (s)           0.202981\n",
      "time/logging (s)                        0.011519\n",
      "time/preback_alpha (s)                  0.577568\n",
      "time/preback_policy (s)                 1.04424\n",
      "time/preback_start (s)                  0.125479\n",
      "time/preback_zf (s)                     5.10282\n",
      "time/saving (s)                         0.0051312\n",
      "time/training (s)                       2.38511\n",
      "time/epoch (s)                         17.0058\n",
      "time/total (s)                       2850.01\n",
      "Epoch                                 172\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:39:59.284647 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 173 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 184000\n",
      "trainer/ZF1 Loss                       28.5468\n",
      "trainer/ZF2 Loss                       29.3192\n",
      "trainer/ZF Expert Reward               15.0871\n",
      "trainer/ZF Policy Reward                1.64985\n",
      "trainer/ZF CHI2 Term                   42.6718\n",
      "trainer/Policy Loss                  -981.141\n",
      "trainer/Bias Loss                      97.2043\n",
      "trainer/Bias Value                     11.3895\n",
      "trainer/Policy Grad Norm              319.433\n",
      "trainer/Policy Param Norm              33.0908\n",
      "trainer/Zf1 Grad Norm                2006.74\n",
      "trainer/Zf1 Param Norm                 97.2515\n",
      "trainer/Zf2 Grad Norm                1840.9\n",
      "trainer/Zf2 Param Norm                 95.6327\n",
      "trainer/Z Expert Predictions Mean    1208.71\n",
      "trainer/Z Expert Predictions Std      112.241\n",
      "trainer/Z Expert Predictions Max     1369.92\n",
      "trainer/Z Expert Predictions Min      855.637\n",
      "trainer/Z Policy Predictions Mean     965.473\n",
      "trainer/Z Policy Predictions Std      354.983\n",
      "trainer/Z Policy Predictions Max     1335.74\n",
      "trainer/Z Policy Predictions Min       -8.48074\n",
      "trainer/Z Expert Targets Mean        1193.62\n",
      "trainer/Z Expert Targets Std          111.637\n",
      "trainer/Z Expert Targets Max         1353.31\n",
      "trainer/Z Expert Targets Min          837.061\n",
      "trainer/Z Policy Targets Mean         963.823\n",
      "trainer/Z Policy Targets Std          351.246\n",
      "trainer/Z Policy Targets Max         1349.15\n",
      "trainer/Z Policy Targets Min          -50.5325\n",
      "trainer/Log Pis Mean                   30.1536\n",
      "trainer/Log Pis Std                     7.05768\n",
      "trainer/Policy mu Mean                  1.54121\n",
      "trainer/Policy mu Std                   2.49815\n",
      "trainer/Policy log std Mean            -3.27668\n",
      "trainer/Policy log std Std              1.43459\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        179968\n",
      "exploration/num paths total           947\n",
      "evaluation/num steps total              1.17704e+06\n",
      "evaluation/num paths total           1744\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.28718\n",
      "evaluation/Rewards Std                  1.32009\n",
      "evaluation/Rewards Max                  7.40447\n",
      "evaluation/Rewards Min                  0.256372\n",
      "evaluation/Returns Mean              5287.18\n",
      "evaluation/Returns Std                 41.6878\n",
      "evaluation/Returns Max               5353.4\n",
      "evaluation/Returns Min               5189.6\n",
      "evaluation/Estimation Bias Mean      1180.65\n",
      "evaluation/Estimation Bias Std        176.582\n",
      "evaluation/EB/Q_True Mean              49.8465\n",
      "evaluation/EB/Q_True Std              153.836\n",
      "evaluation/EB/Q_Pred Mean            1230.5\n",
      "evaluation/EB/Q_Pred Std               94.435\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5287.18\n",
      "evaluation/Actions Mean                 0.509737\n",
      "evaluation/Actions Std                  0.643543\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.91855\n",
      "time/backward_zf1 (s)                   2.05257\n",
      "time/backward_zf2 (s)                   1.98339\n",
      "time/data sampling (s)                  0.25669\n",
      "time/data storing (s)                   0.0146191\n",
      "time/evaluation sampling (s)            1.47827\n",
      "time/exploration sampling (s)           0.208285\n",
      "time/logging (s)                        0.0122414\n",
      "time/preback_alpha (s)                  0.570809\n",
      "time/preback_policy (s)                 1.11735\n",
      "time/preback_start (s)                  0.125395\n",
      "time/preback_zf (s)                     5.06468\n",
      "time/saving (s)                         0.0058079\n",
      "time/training (s)                       2.21169\n",
      "time/epoch (s)                         17.0203\n",
      "time/total (s)                       2867.05\n",
      "Epoch                                 173\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:40:16.413039 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 174 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 185000\n",
      "trainer/ZF1 Loss                       54.3121\n",
      "trainer/ZF2 Loss                       47.663\n",
      "trainer/ZF Expert Reward               16.9441\n",
      "trainer/ZF Policy Reward                5.09418\n",
      "trainer/ZF CHI2 Term                   63.1384\n",
      "trainer/Policy Loss                  -960.834\n",
      "trainer/Bias Loss                     146.829\n",
      "trainer/Bias Value                     11.3956\n",
      "trainer/Policy Grad Norm              617.27\n",
      "trainer/Policy Param Norm              33.1235\n",
      "trainer/Zf1 Grad Norm                3514.12\n",
      "trainer/Zf1 Param Norm                 97.5113\n",
      "trainer/Zf2 Grad Norm                2376.07\n",
      "trainer/Zf2 Param Norm                 95.9045\n",
      "trainer/Z Expert Predictions Mean    1196.77\n",
      "trainer/Z Expert Predictions Std      139.5\n",
      "trainer/Z Expert Predictions Max     1360.42\n",
      "trainer/Z Expert Predictions Min      654.827\n",
      "trainer/Z Policy Predictions Mean     953.376\n",
      "trainer/Z Policy Predictions Std      339.62\n",
      "trainer/Z Policy Predictions Max     1347.39\n",
      "trainer/Z Policy Predictions Min      -44.1984\n",
      "trainer/Z Expert Targets Mean        1179.82\n",
      "trainer/Z Expert Targets Std          140.292\n",
      "trainer/Z Expert Targets Max         1343.14\n",
      "trainer/Z Expert Targets Min          608.887\n",
      "trainer/Z Policy Targets Mean         948.282\n",
      "trainer/Z Policy Targets Std          337.481\n",
      "trainer/Z Policy Targets Max         1308.54\n",
      "trainer/Z Policy Targets Min          -45.6051\n",
      "trainer/Log Pis Mean                   30.0948\n",
      "trainer/Log Pis Std                     7.2392\n",
      "trainer/Policy mu Mean                  1.47042\n",
      "trainer/Policy mu Std                   2.4715\n",
      "trainer/Policy log std Mean            -3.38429\n",
      "trainer/Policy log std Std              1.3922\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        180968\n",
      "exploration/num paths total           948\n",
      "evaluation/num steps total              1.18704e+06\n",
      "evaluation/num paths total           1754\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.26875\n",
      "evaluation/Rewards Std                  1.34702\n",
      "evaluation/Rewards Max                  7.36576\n",
      "evaluation/Rewards Min                  0.110389\n",
      "evaluation/Returns Mean              5268.75\n",
      "evaluation/Returns Std                 47.4361\n",
      "evaluation/Returns Max               5341.22\n",
      "evaluation/Returns Min               5197.37\n",
      "evaluation/Estimation Bias Mean      1183.74\n",
      "evaluation/Estimation Bias Std        178.408\n",
      "evaluation/EB/Q_True Mean              50.2759\n",
      "evaluation/EB/Q_True Std              155.439\n",
      "evaluation/EB/Q_Pred Mean            1234.01\n",
      "evaluation/EB/Q_Pred Std               89.1532\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5268.75\n",
      "evaluation/Actions Mean                 0.509519\n",
      "evaluation/Actions Std                  0.645749\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.87909\n",
      "time/backward_zf1 (s)                   2.05911\n",
      "time/backward_zf2 (s)                   1.96429\n",
      "time/data sampling (s)                  0.262919\n",
      "time/data storing (s)                   0.0147245\n",
      "time/evaluation sampling (s)            1.48275\n",
      "time/exploration sampling (s)           0.202302\n",
      "time/logging (s)                        0.0123704\n",
      "time/preback_alpha (s)                  0.574811\n",
      "time/preback_policy (s)                 1.08034\n",
      "time/preback_start (s)                  0.124433\n",
      "time/preback_zf (s)                     5.11378\n",
      "time/saving (s)                         0.00625232\n",
      "time/training (s)                       2.28062\n",
      "time/epoch (s)                         17.0578\n",
      "time/total (s)                       2884.13\n",
      "Epoch                                 174\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:40:33.304501 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 175 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 186000\n",
      "trainer/ZF1 Loss                       37.2654\n",
      "trainer/ZF2 Loss                       46.9977\n",
      "trainer/ZF Expert Reward               15.8698\n",
      "trainer/ZF Policy Reward                1.19024\n",
      "trainer/ZF CHI2 Term                   57.1073\n",
      "trainer/Policy Loss                 -1014.29\n",
      "trainer/Bias Loss                     261.202\n",
      "trainer/Bias Value                     11.4018\n",
      "trainer/Policy Grad Norm              378.484\n",
      "trainer/Policy Param Norm              33.1581\n",
      "trainer/Zf1 Grad Norm                3906.9\n",
      "trainer/Zf1 Param Norm                 97.7714\n",
      "trainer/Zf2 Grad Norm                3969.94\n",
      "trainer/Zf2 Param Norm                 96.1738\n",
      "trainer/Z Expert Predictions Mean    1203.78\n",
      "trainer/Z Expert Predictions Std      121.096\n",
      "trainer/Z Expert Predictions Max     1367.78\n",
      "trainer/Z Expert Predictions Min      790.359\n",
      "trainer/Z Policy Predictions Mean    1001.88\n",
      "trainer/Z Policy Predictions Std      311.685\n",
      "trainer/Z Policy Predictions Max     1321.24\n",
      "trainer/Z Policy Predictions Min      -33.9803\n",
      "trainer/Z Expert Targets Mean        1187.91\n",
      "trainer/Z Expert Targets Std          121.533\n",
      "trainer/Z Expert Targets Max         1353.82\n",
      "trainer/Z Expert Targets Min          704.366\n",
      "trainer/Z Policy Targets Mean        1000.69\n",
      "trainer/Z Policy Targets Std          304.476\n",
      "trainer/Z Policy Targets Max         1307.29\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   29.6173\n",
      "trainer/Log Pis Std                     7.00378\n",
      "trainer/Policy mu Mean                  1.37462\n",
      "trainer/Policy mu Std                   2.35982\n",
      "trainer/Policy log std Mean            -3.39805\n",
      "trainer/Policy log std Std              1.37314\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        180968\n",
      "exploration/num paths total           948\n",
      "evaluation/num steps total              1.19704e+06\n",
      "evaluation/num paths total           1764\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2144\n",
      "evaluation/Rewards Std                  1.33572\n",
      "evaluation/Rewards Max                  7.365\n",
      "evaluation/Rewards Min                  0.117974\n",
      "evaluation/Returns Mean              5214.4\n",
      "evaluation/Returns Std                141.831\n",
      "evaluation/Returns Max               5312.6\n",
      "evaluation/Returns Min               4879.5\n",
      "evaluation/Estimation Bias Mean      1173.62\n",
      "evaluation/Estimation Bias Std        197.417\n",
      "evaluation/EB/Q_True Mean              50.0386\n",
      "evaluation/EB/Q_True Std              154.474\n",
      "evaluation/EB/Q_Pred Mean            1223.66\n",
      "evaluation/EB/Q_Pred Std              121.142\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5214.4\n",
      "evaluation/Actions Mean                 0.515931\n",
      "evaluation/Actions Std                  0.632714\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.8383\n",
      "time/backward_zf1 (s)                   2.00545\n",
      "time/backward_zf2 (s)                   1.91355\n",
      "time/data sampling (s)                  0.274878\n",
      "time/data storing (s)                   0.0138377\n",
      "time/evaluation sampling (s)            1.41179\n",
      "time/exploration sampling (s)           0.194185\n",
      "time/logging (s)                        0.0121968\n",
      "time/preback_alpha (s)                  0.572141\n",
      "time/preback_policy (s)                 1.04534\n",
      "time/preback_start (s)                  0.12518\n",
      "time/preback_zf (s)                     5.06771\n",
      "time/saving (s)                         0.0057335\n",
      "time/training (s)                       2.34454\n",
      "time/epoch (s)                         16.8248\n",
      "time/total (s)                       2900.98\n",
      "Epoch                                 175\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:40:50.166577 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 176 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 187000\n",
      "trainer/ZF1 Loss                       47.3965\n",
      "trainer/ZF2 Loss                       53.2189\n",
      "trainer/ZF Expert Reward               14.6227\n",
      "trainer/ZF Policy Reward                2.41096\n",
      "trainer/ZF CHI2 Term                   62.8183\n",
      "trainer/Policy Loss                 -1038.94\n",
      "trainer/Bias Loss                     195.424\n",
      "trainer/Bias Value                     11.4077\n",
      "trainer/Policy Grad Norm              489.246\n",
      "trainer/Policy Param Norm              33.1874\n",
      "trainer/Zf1 Grad Norm                3950.29\n",
      "trainer/Zf1 Param Norm                 98.0305\n",
      "trainer/Zf2 Grad Norm                3318.26\n",
      "trainer/Zf2 Param Norm                 96.4214\n",
      "trainer/Z Expert Predictions Mean    1215.43\n",
      "trainer/Z Expert Predictions Std      116.667\n",
      "trainer/Z Expert Predictions Max     1367.08\n",
      "trainer/Z Expert Predictions Min      764.306\n",
      "trainer/Z Policy Predictions Mean    1030.66\n",
      "trainer/Z Policy Predictions Std      301.888\n",
      "trainer/Z Policy Predictions Max     1352.54\n",
      "trainer/Z Policy Predictions Min       -0.667408\n",
      "trainer/Z Expert Targets Mean        1200.8\n",
      "trainer/Z Expert Targets Std          118.168\n",
      "trainer/Z Expert Targets Max         1352.58\n",
      "trainer/Z Expert Targets Min          754.108\n",
      "trainer/Z Policy Targets Mean        1028.25\n",
      "trainer/Z Policy Targets Std          301.368\n",
      "trainer/Z Policy Targets Max         1341.21\n",
      "trainer/Z Policy Targets Min            8.7939\n",
      "trainer/Log Pis Mean                   29.8885\n",
      "trainer/Log Pis Std                     6.79098\n",
      "trainer/Policy mu Mean                  1.40397\n",
      "trainer/Policy mu Std                   2.43096\n",
      "trainer/Policy log std Mean            -3.36717\n",
      "trainer/Policy log std Std              1.39705\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        182968\n",
      "exploration/num paths total           950\n",
      "evaluation/num steps total              1.20704e+06\n",
      "evaluation/num paths total           1774\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.0374\n",
      "evaluation/Rewards Std                  1.28641\n",
      "evaluation/Rewards Max                  7.19785\n",
      "evaluation/Rewards Min                  0.0984076\n",
      "evaluation/Returns Mean              5037.4\n",
      "evaluation/Returns Std                 49.1837\n",
      "evaluation/Returns Max               5119.46\n",
      "evaluation/Returns Min               4958.22\n",
      "evaluation/Estimation Bias Mean      1147.83\n",
      "evaluation/Estimation Bias Std        181.659\n",
      "evaluation/EB/Q_True Mean              47.188\n",
      "evaluation/EB/Q_True Std              145.585\n",
      "evaluation/EB/Q_Pred Mean            1195.02\n",
      "evaluation/EB/Q_Pred Std               97.7323\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5037.4\n",
      "evaluation/Actions Mean                 0.496311\n",
      "evaluation/Actions Std                  0.648375\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.79297\n",
      "time/backward_zf1 (s)                   1.97787\n",
      "time/backward_zf2 (s)                   1.87867\n",
      "time/data sampling (s)                  0.260347\n",
      "time/data storing (s)                   0.0141798\n",
      "time/evaluation sampling (s)            1.40849\n",
      "time/exploration sampling (s)           0.201092\n",
      "time/logging (s)                        0.0117383\n",
      "time/preback_alpha (s)                  0.570168\n",
      "time/preback_policy (s)                 1.0246\n",
      "time/preback_start (s)                  0.124401\n",
      "time/preback_zf (s)                     5.08128\n",
      "time/saving (s)                         0.00571947\n",
      "time/training (s)                       2.44064\n",
      "time/epoch (s)                         16.7922\n",
      "time/total (s)                       2917.79\n",
      "Epoch                                 176\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:41:07.339364 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 177 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 188000\n",
      "trainer/ZF1 Loss                       36.2725\n",
      "trainer/ZF2 Loss                       33.7948\n",
      "trainer/ZF Expert Reward               20.0959\n",
      "trainer/ZF Policy Reward                3.70342\n",
      "trainer/ZF CHI2 Term                   51.7391\n",
      "trainer/Policy Loss                 -1002.48\n",
      "trainer/Bias Loss                     160.318\n",
      "trainer/Bias Value                     11.414\n",
      "trainer/Policy Grad Norm              482.504\n",
      "trainer/Policy Param Norm              33.2139\n",
      "trainer/Zf1 Grad Norm                2950.05\n",
      "trainer/Zf1 Param Norm                 98.3243\n",
      "trainer/Zf2 Grad Norm                4311.91\n",
      "trainer/Zf2 Param Norm                 96.7083\n",
      "trainer/Z Expert Predictions Mean    1206.43\n",
      "trainer/Z Expert Predictions Std      126.53\n",
      "trainer/Z Expert Predictions Max     1357.43\n",
      "trainer/Z Expert Predictions Min      743.01\n",
      "trainer/Z Policy Predictions Mean     989.714\n",
      "trainer/Z Policy Predictions Std      317.542\n",
      "trainer/Z Policy Predictions Max     1319.35\n",
      "trainer/Z Policy Predictions Min      -17.9497\n",
      "trainer/Z Expert Targets Mean        1186.33\n",
      "trainer/Z Expert Targets Std          127.731\n",
      "trainer/Z Expert Targets Max         1330.74\n",
      "trainer/Z Expert Targets Min          714.599\n",
      "trainer/Z Policy Targets Mean         986.01\n",
      "trainer/Z Policy Targets Std          314.771\n",
      "trainer/Z Policy Targets Max         1309.85\n",
      "trainer/Z Policy Targets Min           -0.481986\n",
      "trainer/Log Pis Mean                   31.3057\n",
      "trainer/Log Pis Std                     8.16449\n",
      "trainer/Policy mu Mean                  1.4798\n",
      "trainer/Policy mu Std                   2.56763\n",
      "trainer/Policy log std Mean            -3.41049\n",
      "trainer/Policy log std Std              1.44278\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        182968\n",
      "exploration/num paths total           950\n",
      "evaluation/num steps total              1.21704e+06\n",
      "evaluation/num paths total           1784\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21517\n",
      "evaluation/Rewards Std                  1.31727\n",
      "evaluation/Rewards Max                  7.32308\n",
      "evaluation/Rewards Min                  0.0883904\n",
      "evaluation/Returns Mean              5215.17\n",
      "evaluation/Returns Std                 40.7376\n",
      "evaluation/Returns Max               5275.37\n",
      "evaluation/Returns Min               5114.91\n",
      "evaluation/Estimation Bias Mean      1193.52\n",
      "evaluation/Estimation Bias Std        168.244\n",
      "evaluation/EB/Q_True Mean              48.3264\n",
      "evaluation/EB/Q_True Std              149.407\n",
      "evaluation/EB/Q_Pred Mean            1241.85\n",
      "evaluation/EB/Q_Pred Std               82.2392\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5215.17\n",
      "evaluation/Actions Mean                 0.498871\n",
      "evaluation/Actions Std                  0.64307\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.88337\n",
      "time/backward_zf1 (s)                   2.01701\n",
      "time/backward_zf2 (s)                   1.91401\n",
      "time/data sampling (s)                  0.281268\n",
      "time/data storing (s)                   0.0150097\n",
      "time/evaluation sampling (s)            1.41641\n",
      "time/exploration sampling (s)           0.19788\n",
      "time/logging (s)                        0.014478\n",
      "time/preback_alpha (s)                  0.586635\n",
      "time/preback_policy (s)                 1.04279\n",
      "time/preback_start (s)                  0.126989\n",
      "time/preback_zf (s)                     5.14917\n",
      "time/saving (s)                         0.00741997\n",
      "time/training (s)                       2.45101\n",
      "time/epoch (s)                         17.1034\n",
      "time/total (s)                       2934.92\n",
      "Epoch                                 177\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:41:24.952788 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 178 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 189000\n",
      "trainer/ZF1 Loss                       47.0252\n",
      "trainer/ZF2 Loss                       55.4338\n",
      "trainer/ZF Expert Reward               11.5545\n",
      "trainer/ZF Policy Reward                2.66664\n",
      "trainer/ZF CHI2 Term                   60.419\n",
      "trainer/Policy Loss                  -986.326\n",
      "trainer/Bias Loss                     280.439\n",
      "trainer/Bias Value                     11.4202\n",
      "trainer/Policy Grad Norm              451.715\n",
      "trainer/Policy Param Norm              33.2502\n",
      "trainer/Zf1 Grad Norm                3597.12\n",
      "trainer/Zf1 Param Norm                 98.5845\n",
      "trainer/Zf2 Grad Norm                3686.18\n",
      "trainer/Zf2 Param Norm                 96.9621\n",
      "trainer/Z Expert Predictions Mean    1183.4\n",
      "trainer/Z Expert Predictions Std      150.23\n",
      "trainer/Z Expert Predictions Max     1357.18\n",
      "trainer/Z Expert Predictions Min       15.2084\n",
      "trainer/Z Policy Predictions Mean     974.985\n",
      "trainer/Z Policy Predictions Std      346.683\n",
      "trainer/Z Policy Predictions Max     1313.56\n",
      "trainer/Z Policy Predictions Min      -35.0684\n",
      "trainer/Z Expert Targets Mean        1171.85\n",
      "trainer/Z Expert Targets Std          151.772\n",
      "trainer/Z Expert Targets Max         1348.66\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         972.318\n",
      "trainer/Z Policy Targets Std          346.093\n",
      "trainer/Z Policy Targets Max         1322.53\n",
      "trainer/Z Policy Targets Min          -43.8588\n",
      "trainer/Log Pis Mean                   30.1727\n",
      "trainer/Log Pis Std                     7.18468\n",
      "trainer/Policy mu Mean                  1.3122\n",
      "trainer/Policy mu Std                   2.49311\n",
      "trainer/Policy log std Mean            -3.44893\n",
      "trainer/Policy log std Std              1.4468\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        182968\n",
      "exploration/num paths total           950\n",
      "evaluation/num steps total              1.22704e+06\n",
      "evaluation/num paths total           1794\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29187\n",
      "evaluation/Rewards Std                  1.33727\n",
      "evaluation/Rewards Max                  7.40897\n",
      "evaluation/Rewards Min                  0.126814\n",
      "evaluation/Returns Mean              5291.87\n",
      "evaluation/Returns Std                 29.5319\n",
      "evaluation/Returns Max               5349.24\n",
      "evaluation/Returns Min               5259.12\n",
      "evaluation/Estimation Bias Mean      1166.1\n",
      "evaluation/Estimation Bias Std        181.963\n",
      "evaluation/EB/Q_True Mean              49.9971\n",
      "evaluation/EB/Q_True Std              154.191\n",
      "evaluation/EB/Q_Pred Mean            1216.1\n",
      "evaluation/EB/Q_Pred Std              104.398\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5291.87\n",
      "evaluation/Actions Mean                 0.499612\n",
      "evaluation/Actions Std                  0.646784\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.0605\n",
      "time/backward_zf1 (s)                   2.20574\n",
      "time/backward_zf2 (s)                   2.12817\n",
      "time/data sampling (s)                  0.2614\n",
      "time/data storing (s)                   0.0144352\n",
      "time/evaluation sampling (s)            1.47757\n",
      "time/exploration sampling (s)           0.193661\n",
      "time/logging (s)                        0.0158018\n",
      "time/preback_alpha (s)                  0.583611\n",
      "time/preback_policy (s)                 1.19031\n",
      "time/preback_start (s)                  0.126954\n",
      "time/preback_zf (s)                     5.11684\n",
      "time/saving (s)                         0.00563974\n",
      "time/training (s)                       2.16098\n",
      "time/epoch (s)                         17.5416\n",
      "time/total (s)                       2952.48\n",
      "Epoch                                 178\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:41:41.875790 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 179 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 190000\n",
      "trainer/ZF1 Loss                       25.2436\n",
      "trainer/ZF2 Loss                       27.8287\n",
      "trainer/ZF Expert Reward               14.7971\n",
      "trainer/ZF Policy Reward                1.84837\n",
      "trainer/ZF CHI2 Term                   39.7896\n",
      "trainer/Policy Loss                  -996.718\n",
      "trainer/Bias Loss                     115.569\n",
      "trainer/Bias Value                     11.4263\n",
      "trainer/Policy Grad Norm              347.851\n",
      "trainer/Policy Param Norm              33.2821\n",
      "trainer/Zf1 Grad Norm                2280.09\n",
      "trainer/Zf1 Param Norm                 98.8495\n",
      "trainer/Zf2 Grad Norm                2262.1\n",
      "trainer/Zf2 Param Norm                 97.2193\n",
      "trainer/Z Expert Predictions Mean    1205.58\n",
      "trainer/Z Expert Predictions Std      109.627\n",
      "trainer/Z Expert Predictions Max     1352.98\n",
      "trainer/Z Expert Predictions Min      711.51\n",
      "trainer/Z Policy Predictions Mean     985.525\n",
      "trainer/Z Policy Predictions Std      355.863\n",
      "trainer/Z Policy Predictions Max     1328.77\n",
      "trainer/Z Policy Predictions Min      -40.3599\n",
      "trainer/Z Expert Targets Mean        1190.78\n",
      "trainer/Z Expert Targets Std          110.357\n",
      "trainer/Z Expert Targets Max         1331.06\n",
      "trainer/Z Expert Targets Min          700.542\n",
      "trainer/Z Policy Targets Mean         983.677\n",
      "trainer/Z Policy Targets Std          350.503\n",
      "trainer/Z Policy Targets Max         1311.43\n",
      "trainer/Z Policy Targets Min          -39.9146\n",
      "trainer/Log Pis Mean                   30.471\n",
      "trainer/Log Pis Std                     7.42971\n",
      "trainer/Policy mu Mean                  1.49976\n",
      "trainer/Policy mu Std                   2.58894\n",
      "trainer/Policy log std Mean            -3.35686\n",
      "trainer/Policy log std Std              1.39789\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        185968\n",
      "exploration/num paths total           953\n",
      "evaluation/num steps total              1.23704e+06\n",
      "evaluation/num paths total           1804\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25904\n",
      "evaluation/Rewards Std                  1.36286\n",
      "evaluation/Rewards Max                  7.44297\n",
      "evaluation/Rewards Min                  0.114702\n",
      "evaluation/Returns Mean              5259.04\n",
      "evaluation/Returns Std                121.001\n",
      "evaluation/Returns Max               5316.23\n",
      "evaluation/Returns Min               4898.54\n",
      "evaluation/Estimation Bias Mean      1174.93\n",
      "evaluation/Estimation Bias Std        172.186\n",
      "evaluation/EB/Q_True Mean              50.2444\n",
      "evaluation/EB/Q_True Std              155.048\n",
      "evaluation/EB/Q_Pred Mean            1225.18\n",
      "evaluation/EB/Q_Pred Std               85.487\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5259.04\n",
      "evaluation/Actions Mean                 0.514638\n",
      "evaluation/Actions Std                  0.638261\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.85225\n",
      "time/backward_zf1 (s)                   1.99438\n",
      "time/backward_zf2 (s)                   1.91224\n",
      "time/data sampling (s)                  0.250967\n",
      "time/data storing (s)                   0.0140374\n",
      "time/evaluation sampling (s)            1.4139\n",
      "time/exploration sampling (s)           0.199946\n",
      "time/logging (s)                        0.0121761\n",
      "time/preback_alpha (s)                  0.575314\n",
      "time/preback_policy (s)                 1.05718\n",
      "time/preback_start (s)                  0.125729\n",
      "time/preback_zf (s)                     5.08786\n",
      "time/saving (s)                         0.00620179\n",
      "time/training (s)                       2.34548\n",
      "time/epoch (s)                         16.8477\n",
      "time/total (s)                       2969.35\n",
      "Epoch                                 179\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:41:59.162665 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 180 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 191000\n",
      "trainer/ZF1 Loss                       46.3902\n",
      "trainer/ZF2 Loss                       35.8433\n",
      "trainer/ZF Expert Reward                6.28946\n",
      "trainer/ZF Policy Reward               -5.72016\n",
      "trainer/ZF CHI2 Term                   53.4374\n",
      "trainer/Policy Loss                  -981.528\n",
      "trainer/Bias Loss                     108.057\n",
      "trainer/Bias Value                     11.4322\n",
      "trainer/Policy Grad Norm              409.531\n",
      "trainer/Policy Param Norm              33.3116\n",
      "trainer/Zf1 Grad Norm                5028.44\n",
      "trainer/Zf1 Param Norm                 99.111\n",
      "trainer/Zf2 Grad Norm                4072.93\n",
      "trainer/Zf2 Param Norm                 97.4744\n",
      "trainer/Z Expert Predictions Mean    1190.64\n",
      "trainer/Z Expert Predictions Std      117.674\n",
      "trainer/Z Expert Predictions Max     1354.21\n",
      "trainer/Z Expert Predictions Min      613.298\n",
      "trainer/Z Policy Predictions Mean     969.089\n",
      "trainer/Z Policy Predictions Std      344.056\n",
      "trainer/Z Policy Predictions Max     1320.38\n",
      "trainer/Z Policy Predictions Min     -107.803\n",
      "trainer/Z Expert Targets Mean        1184.35\n",
      "trainer/Z Expert Targets Std          117.794\n",
      "trainer/Z Expert Targets Max         1338.22\n",
      "trainer/Z Expert Targets Min          581.497\n",
      "trainer/Z Policy Targets Mean         974.809\n",
      "trainer/Z Policy Targets Std          339.511\n",
      "trainer/Z Policy Targets Max         1320.97\n",
      "trainer/Z Policy Targets Min          -93.343\n",
      "trainer/Log Pis Mean                   31.1093\n",
      "trainer/Log Pis Std                     7.85958\n",
      "trainer/Policy mu Mean                  1.4767\n",
      "trainer/Policy mu Std                   2.61816\n",
      "trainer/Policy log std Mean            -3.43199\n",
      "trainer/Policy log std Std              1.42936\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        185968\n",
      "exploration/num paths total           953\n",
      "evaluation/num steps total              1.24704e+06\n",
      "evaluation/num paths total           1814\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.24863\n",
      "evaluation/Rewards Std                  1.34811\n",
      "evaluation/Rewards Max                  7.28983\n",
      "evaluation/Rewards Min                  0.117611\n",
      "evaluation/Returns Mean              5248.63\n",
      "evaluation/Returns Std                 27.2918\n",
      "evaluation/Returns Max               5296.29\n",
      "evaluation/Returns Min               5191.26\n",
      "evaluation/Estimation Bias Mean      1181\n",
      "evaluation/Estimation Bias Std        169.355\n",
      "evaluation/EB/Q_True Mean              49.818\n",
      "evaluation/EB/Q_True Std              153.962\n",
      "evaluation/EB/Q_Pred Mean            1230.82\n",
      "evaluation/EB/Q_Pred Std               77.6016\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5248.63\n",
      "evaluation/Actions Mean                 0.512014\n",
      "evaluation/Actions Std                  0.638474\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999995\n",
      "time/backward_policy (s)                1.98799\n",
      "time/backward_zf1 (s)                   2.14621\n",
      "time/backward_zf2 (s)                   2.07158\n",
      "time/data sampling (s)                  0.267202\n",
      "time/data storing (s)                   0.0143698\n",
      "time/evaluation sampling (s)            1.43358\n",
      "time/exploration sampling (s)           0.19571\n",
      "time/logging (s)                        0.0120778\n",
      "time/preback_alpha (s)                  0.57748\n",
      "time/preback_policy (s)                 1.18806\n",
      "time/preback_start (s)                  0.125199\n",
      "time/preback_zf (s)                     5.06585\n",
      "time/saving (s)                         0.00670066\n",
      "time/training (s)                       2.12329\n",
      "time/epoch (s)                         17.2153\n",
      "time/total (s)                       2986.59\n",
      "Epoch                                 180\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:42:16.268467 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 181 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 192000\n",
      "trainer/ZF1 Loss                       41.0491\n",
      "trainer/ZF2 Loss                       48.4118\n",
      "trainer/ZF Expert Reward                7.40395\n",
      "trainer/ZF Policy Reward               -5.4405\n",
      "trainer/ZF CHI2 Term                   57.8783\n",
      "trainer/Policy Loss                  -956.84\n",
      "trainer/Bias Loss                     128.829\n",
      "trainer/Bias Value                     11.438\n",
      "trainer/Policy Grad Norm              260.518\n",
      "trainer/Policy Param Norm              33.3445\n",
      "trainer/Zf1 Grad Norm                3578.02\n",
      "trainer/Zf1 Param Norm                 99.3717\n",
      "trainer/Zf2 Grad Norm                5915.72\n",
      "trainer/Zf2 Param Norm                 97.7269\n",
      "trainer/Z Expert Predictions Mean    1177.07\n",
      "trainer/Z Expert Predictions Std      122.885\n",
      "trainer/Z Expert Predictions Max     1331.39\n",
      "trainer/Z Expert Predictions Min      714.412\n",
      "trainer/Z Policy Predictions Mean     944.044\n",
      "trainer/Z Policy Predictions Std      348.504\n",
      "trainer/Z Policy Predictions Max     1302.04\n",
      "trainer/Z Policy Predictions Min      -57.1298\n",
      "trainer/Z Expert Targets Mean        1169.66\n",
      "trainer/Z Expert Targets Std          121.412\n",
      "trainer/Z Expert Targets Max         1327.55\n",
      "trainer/Z Expert Targets Min          724.591\n",
      "trainer/Z Policy Targets Mean         949.485\n",
      "trainer/Z Policy Targets Std          346.962\n",
      "trainer/Z Policy Targets Max         1300.4\n",
      "trainer/Z Policy Targets Min          -54.8005\n",
      "trainer/Log Pis Mean                   30.3378\n",
      "trainer/Log Pis Std                     7.6637\n",
      "trainer/Policy mu Mean                  1.35619\n",
      "trainer/Policy mu Std                   2.63462\n",
      "trainer/Policy log std Mean            -3.40034\n",
      "trainer/Policy log std Std              1.37709\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        186968\n",
      "exploration/num paths total           954\n",
      "evaluation/num steps total              1.25704e+06\n",
      "evaluation/num paths total           1824\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1835\n",
      "evaluation/Rewards Std                  1.32325\n",
      "evaluation/Rewards Max                  7.21071\n",
      "evaluation/Rewards Min                  0.0992932\n",
      "evaluation/Returns Mean              5183.5\n",
      "evaluation/Returns Std                 25.2386\n",
      "evaluation/Returns Max               5238.79\n",
      "evaluation/Returns Min               5140.93\n",
      "evaluation/Estimation Bias Mean      1179.82\n",
      "evaluation/Estimation Bias Std        173.245\n",
      "evaluation/EB/Q_True Mean              48.6238\n",
      "evaluation/EB/Q_True Std              150.012\n",
      "evaluation/EB/Q_Pred Mean            1228.45\n",
      "evaluation/EB/Q_Pred Std               82.9948\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5183.5\n",
      "evaluation/Actions Mean                 0.50406\n",
      "evaluation/Actions Std                  0.646339\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.87091\n",
      "time/backward_zf1 (s)                   2.03057\n",
      "time/backward_zf2 (s)                   1.94028\n",
      "time/data sampling (s)                  0.281147\n",
      "time/data storing (s)                   0.0153897\n",
      "time/evaluation sampling (s)            1.42902\n",
      "time/exploration sampling (s)           0.20308\n",
      "time/logging (s)                        0.0122421\n",
      "time/preback_alpha (s)                  0.57675\n",
      "time/preback_policy (s)                 1.03581\n",
      "time/preback_start (s)                  0.126035\n",
      "time/preback_zf (s)                     5.11474\n",
      "time/saving (s)                         0.00560864\n",
      "time/training (s)                       2.39603\n",
      "time/epoch (s)                         17.0376\n",
      "time/total (s)                       3003.65\n",
      "Epoch                                 181\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:42:33.342209 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 182 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 193000\n",
      "trainer/ZF1 Loss                       45.4464\n",
      "trainer/ZF2 Loss                       43.1006\n",
      "trainer/ZF Expert Reward               14.1352\n",
      "trainer/ZF Policy Reward               -1.11326\n",
      "trainer/ZF CHI2 Term                   59.8276\n",
      "trainer/Policy Loss                  -990.98\n",
      "trainer/Bias Loss                     114.826\n",
      "trainer/Bias Value                     11.444\n",
      "trainer/Policy Grad Norm              374.341\n",
      "trainer/Policy Param Norm              33.3769\n",
      "trainer/Zf1 Grad Norm                3046.43\n",
      "trainer/Zf1 Param Norm                 99.6087\n",
      "trainer/Zf2 Grad Norm                3593.11\n",
      "trainer/Zf2 Param Norm                 97.9562\n",
      "trainer/Z Expert Predictions Mean    1200.51\n",
      "trainer/Z Expert Predictions Std      109.534\n",
      "trainer/Z Expert Predictions Max     1336.08\n",
      "trainer/Z Expert Predictions Min      818.77\n",
      "trainer/Z Policy Predictions Mean     976.943\n",
      "trainer/Z Policy Predictions Std      346.537\n",
      "trainer/Z Policy Predictions Max     1305.46\n",
      "trainer/Z Policy Predictions Min     -139.762\n",
      "trainer/Z Expert Targets Mean        1186.38\n",
      "trainer/Z Expert Targets Std          108.836\n",
      "trainer/Z Expert Targets Max         1333.14\n",
      "trainer/Z Expert Targets Min          797.388\n",
      "trainer/Z Policy Targets Mean         978.057\n",
      "trainer/Z Policy Targets Std          339.051\n",
      "trainer/Z Policy Targets Max         1330.75\n",
      "trainer/Z Policy Targets Min         -150.552\n",
      "trainer/Log Pis Mean                   30.5623\n",
      "trainer/Log Pis Std                     6.94578\n",
      "trainer/Policy mu Mean                  1.47682\n",
      "trainer/Policy mu Std                   2.45507\n",
      "trainer/Policy log std Mean            -3.46215\n",
      "trainer/Policy log std Std              1.44372\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        186968\n",
      "exploration/num paths total           954\n",
      "evaluation/num steps total              1.26704e+06\n",
      "evaluation/num paths total           1834\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19515\n",
      "evaluation/Rewards Std                  1.31915\n",
      "evaluation/Rewards Max                  7.29877\n",
      "evaluation/Rewards Min                  0.113836\n",
      "evaluation/Returns Mean              5195.15\n",
      "evaluation/Returns Std                 36.7202\n",
      "evaluation/Returns Max               5242.53\n",
      "evaluation/Returns Min               5126.75\n",
      "evaluation/Estimation Bias Mean      1161.05\n",
      "evaluation/Estimation Bias Std        176.219\n",
      "evaluation/EB/Q_True Mean              48.7256\n",
      "evaluation/EB/Q_True Std              150.477\n",
      "evaluation/EB/Q_Pred Mean            1209.77\n",
      "evaluation/EB/Q_Pred Std               87.3484\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5195.15\n",
      "evaluation/Actions Mean                 0.506093\n",
      "evaluation/Actions Std                  0.645292\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.91433\n",
      "time/backward_zf1 (s)                   2.06501\n",
      "time/backward_zf2 (s)                   1.98038\n",
      "time/data sampling (s)                  0.265543\n",
      "time/data storing (s)                   0.0148048\n",
      "time/evaluation sampling (s)            1.48993\n",
      "time/exploration sampling (s)           0.201714\n",
      "time/logging (s)                        0.011854\n",
      "time/preback_alpha (s)                  0.569933\n",
      "time/preback_policy (s)                 1.12357\n",
      "time/preback_start (s)                  0.126041\n",
      "time/preback_zf (s)                     5.07096\n",
      "time/saving (s)                         0.00557771\n",
      "time/training (s)                       2.1667\n",
      "time/epoch (s)                         17.0063\n",
      "time/total (s)                       3020.67\n",
      "Epoch                                 182\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:42:50.149395 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 183 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 194000\n",
      "trainer/ZF1 Loss                       32.0909\n",
      "trainer/ZF2 Loss                       30.7804\n",
      "trainer/ZF Expert Reward                7.49841\n",
      "trainer/ZF Policy Reward               -2.57764\n",
      "trainer/ZF CHI2 Term                   41.8171\n",
      "trainer/Policy Loss                 -1001.46\n",
      "trainer/Bias Loss                      82.9155\n",
      "trainer/Bias Value                     11.4499\n",
      "trainer/Policy Grad Norm              327.446\n",
      "trainer/Policy Param Norm              33.4105\n",
      "trainer/Zf1 Grad Norm                3797.92\n",
      "trainer/Zf1 Param Norm                 99.8577\n",
      "trainer/Zf2 Grad Norm                3709.41\n",
      "trainer/Zf2 Param Norm                 98.1928\n",
      "trainer/Z Expert Predictions Mean    1180.64\n",
      "trainer/Z Expert Predictions Std      113.257\n",
      "trainer/Z Expert Predictions Max     1328.27\n",
      "trainer/Z Expert Predictions Min      813.886\n",
      "trainer/Z Policy Predictions Mean     991.873\n",
      "trainer/Z Policy Predictions Std      326.878\n",
      "trainer/Z Policy Predictions Max     1319.83\n",
      "trainer/Z Policy Predictions Min     -111.741\n",
      "trainer/Z Expert Targets Mean        1173.14\n",
      "trainer/Z Expert Targets Std          114.946\n",
      "trainer/Z Expert Targets Max         1325.65\n",
      "trainer/Z Expert Targets Min          782.264\n",
      "trainer/Z Policy Targets Mean         994.45\n",
      "trainer/Z Policy Targets Std          323.576\n",
      "trainer/Z Policy Targets Max         1320.47\n",
      "trainer/Z Policy Targets Min         -109.817\n",
      "trainer/Log Pis Mean                   30.5388\n",
      "trainer/Log Pis Std                     7.35095\n",
      "trainer/Policy mu Mean                  1.41291\n",
      "trainer/Policy mu Std                   2.58902\n",
      "trainer/Policy log std Mean            -3.34601\n",
      "trainer/Policy log std Std              1.41871\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        189968\n",
      "exploration/num paths total           957\n",
      "evaluation/num steps total              1.27704e+06\n",
      "evaluation/num paths total           1844\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.28045\n",
      "evaluation/Rewards Std                  1.36053\n",
      "evaluation/Rewards Max                  7.37944\n",
      "evaluation/Rewards Min                  0.112195\n",
      "evaluation/Returns Mean              5280.45\n",
      "evaluation/Returns Std                 20.7404\n",
      "evaluation/Returns Max               5317.92\n",
      "evaluation/Returns Min               5241.47\n",
      "evaluation/Estimation Bias Mean      1175.08\n",
      "evaluation/Estimation Bias Std        172.598\n",
      "evaluation/EB/Q_True Mean              49.8233\n",
      "evaluation/EB/Q_True Std              153.754\n",
      "evaluation/EB/Q_Pred Mean            1224.9\n",
      "evaluation/EB/Q_Pred Std               85.8308\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5280.45\n",
      "evaluation/Actions Mean                 0.523694\n",
      "evaluation/Actions Std                  0.631025\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78883\n",
      "time/backward_zf1 (s)                   1.94265\n",
      "time/backward_zf2 (s)                   1.85212\n",
      "time/data sampling (s)                  0.263479\n",
      "time/data storing (s)                   0.0137664\n",
      "time/evaluation sampling (s)            1.45745\n",
      "time/exploration sampling (s)           0.199542\n",
      "time/logging (s)                        0.0123976\n",
      "time/preback_alpha (s)                  0.567007\n",
      "time/preback_policy (s)                 1.01337\n",
      "time/preback_start (s)                  0.124967\n",
      "time/preback_zf (s)                     5.09861\n",
      "time/saving (s)                         0.00584144\n",
      "time/training (s)                       2.39961\n",
      "time/epoch (s)                         16.7396\n",
      "time/total (s)                       3037.43\n",
      "Epoch                                 183\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:43:07.192875 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 184 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 195000\n",
      "trainer/ZF1 Loss                      259.143\n",
      "trainer/ZF2 Loss                      261.388\n",
      "trainer/ZF Expert Reward               25.3703\n",
      "trainer/ZF Policy Reward                7.01328\n",
      "trainer/ZF CHI2 Term                  278.931\n",
      "trainer/Policy Loss                  -990.77\n",
      "trainer/Bias Loss                    2499.07\n",
      "trainer/Bias Value                     11.4557\n",
      "trainer/Policy Grad Norm              422.137\n",
      "trainer/Policy Param Norm              33.4413\n",
      "trainer/Zf1 Grad Norm                4813.41\n",
      "trainer/Zf1 Param Norm                100.097\n",
      "trainer/Zf2 Grad Norm                3721.26\n",
      "trainer/Zf2 Param Norm                 98.4293\n",
      "trainer/Z Expert Predictions Mean    1203.93\n",
      "trainer/Z Expert Predictions Std      109.474\n",
      "trainer/Z Expert Predictions Max     1365.04\n",
      "trainer/Z Expert Predictions Min      841.403\n",
      "trainer/Z Policy Predictions Mean     985.125\n",
      "trainer/Z Policy Predictions Std      338.301\n",
      "trainer/Z Policy Predictions Max     1312.14\n",
      "trainer/Z Policy Predictions Min      -71.3844\n",
      "trainer/Z Expert Targets Mean        1178.56\n",
      "trainer/Z Expert Targets Std          134.651\n",
      "trainer/Z Expert Targets Max         1342.79\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         978.112\n",
      "trainer/Z Policy Targets Std          334.331\n",
      "trainer/Z Policy Targets Max         1303.35\n",
      "trainer/Z Policy Targets Min          -77.6488\n",
      "trainer/Log Pis Mean                   30.8807\n",
      "trainer/Log Pis Std                     7.55928\n",
      "trainer/Policy mu Mean                  1.51897\n",
      "trainer/Policy mu Std                   2.51551\n",
      "trainer/Policy log std Mean            -3.37811\n",
      "trainer/Policy log std Std              1.401\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        190968\n",
      "exploration/num paths total           958\n",
      "evaluation/num steps total              1.28704e+06\n",
      "evaluation/num paths total           1854\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2361\n",
      "evaluation/Rewards Std                  1.33507\n",
      "evaluation/Rewards Max                  7.39531\n",
      "evaluation/Rewards Min                  0.123321\n",
      "evaluation/Returns Mean              5236.1\n",
      "evaluation/Returns Std                 37.337\n",
      "evaluation/Returns Max               5284.69\n",
      "evaluation/Returns Min               5150.14\n",
      "evaluation/Estimation Bias Mean      1148.61\n",
      "evaluation/Estimation Bias Std        194.829\n",
      "evaluation/EB/Q_True Mean              49.5232\n",
      "evaluation/EB/Q_True Std              153.295\n",
      "evaluation/EB/Q_Pred Mean            1198.14\n",
      "evaluation/EB/Q_Pred Std               98.8581\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5236.1\n",
      "evaluation/Actions Mean                 0.510852\n",
      "evaluation/Actions Std                  0.644548\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.87683\n",
      "time/backward_zf1 (s)                   2.03304\n",
      "time/backward_zf2 (s)                   1.96375\n",
      "time/data sampling (s)                  0.258048\n",
      "time/data storing (s)                   0.0149651\n",
      "time/evaluation sampling (s)            1.45323\n",
      "time/exploration sampling (s)           0.204903\n",
      "time/logging (s)                        0.011682\n",
      "time/preback_alpha (s)                  0.572194\n",
      "time/preback_policy (s)                 1.09597\n",
      "time/preback_start (s)                  0.125031\n",
      "time/preback_zf (s)                     5.08304\n",
      "time/saving (s)                         0.0058949\n",
      "time/training (s)                       2.27768\n",
      "time/epoch (s)                         16.9763\n",
      "time/total (s)                       3054.43\n",
      "Epoch                                 184\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:43:24.412590 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 185 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 196000\n",
      "trainer/ZF1 Loss                       29.3901\n",
      "trainer/ZF2 Loss                       28.917\n",
      "trainer/ZF Expert Reward               12.2417\n",
      "trainer/ZF Policy Reward               -2.76025\n",
      "trainer/ZF CHI2 Term                   44.4622\n",
      "trainer/Policy Loss                  -978.413\n",
      "trainer/Bias Loss                      87.5508\n",
      "trainer/Bias Value                     11.4614\n",
      "trainer/Policy Grad Norm              353.023\n",
      "trainer/Policy Param Norm              33.4723\n",
      "trainer/Zf1 Grad Norm                2467.72\n",
      "trainer/Zf1 Param Norm                100.337\n",
      "trainer/Zf2 Grad Norm                1554.71\n",
      "trainer/Zf2 Param Norm                 98.6661\n",
      "trainer/Z Expert Predictions Mean    1194.64\n",
      "trainer/Z Expert Predictions Std      112.073\n",
      "trainer/Z Expert Predictions Max     1354.2\n",
      "trainer/Z Expert Predictions Min      688.129\n",
      "trainer/Z Policy Predictions Mean     971.06\n",
      "trainer/Z Policy Predictions Std      336.984\n",
      "trainer/Z Policy Predictions Max     1325.53\n",
      "trainer/Z Policy Predictions Min      -67.5527\n",
      "trainer/Z Expert Targets Mean        1182.4\n",
      "trainer/Z Expert Targets Std          113.528\n",
      "trainer/Z Expert Targets Max         1341.38\n",
      "trainer/Z Expert Targets Min          649.617\n",
      "trainer/Z Policy Targets Mean         973.82\n",
      "trainer/Z Policy Targets Std          333.095\n",
      "trainer/Z Policy Targets Max         1305.74\n",
      "trainer/Z Policy Targets Min          -63.3471\n",
      "trainer/Log Pis Mean                   30.6616\n",
      "trainer/Log Pis Std                     7.49573\n",
      "trainer/Policy mu Mean                  1.50108\n",
      "trainer/Policy mu Std                   2.55361\n",
      "trainer/Policy log std Mean            -3.39764\n",
      "trainer/Policy log std Std              1.42797\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        190968\n",
      "exploration/num paths total           958\n",
      "evaluation/num steps total              1.29704e+06\n",
      "evaluation/num paths total           1864\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19283\n",
      "evaluation/Rewards Std                  1.33399\n",
      "evaluation/Rewards Max                  7.33548\n",
      "evaluation/Rewards Min                  0.0963006\n",
      "evaluation/Returns Mean              5192.83\n",
      "evaluation/Returns Std                 23.9378\n",
      "evaluation/Returns Max               5248.9\n",
      "evaluation/Returns Min               5164.9\n",
      "evaluation/Estimation Bias Mean      1158.92\n",
      "evaluation/Estimation Bias Std        167.423\n",
      "evaluation/EB/Q_True Mean              48.9584\n",
      "evaluation/EB/Q_True Std              150.975\n",
      "evaluation/EB/Q_Pred Mean            1207.87\n",
      "evaluation/EB/Q_Pred Std               84.27\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5192.83\n",
      "evaluation/Actions Mean                 0.519098\n",
      "evaluation/Actions Std                  0.638392\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.91038\n",
      "time/backward_zf1 (s)                   2.08587\n",
      "time/backward_zf2 (s)                   2.00736\n",
      "time/data sampling (s)                  0.275005\n",
      "time/data storing (s)                   0.0147293\n",
      "time/evaluation sampling (s)            1.47206\n",
      "time/exploration sampling (s)           0.196967\n",
      "time/logging (s)                        0.0118942\n",
      "time/preback_alpha (s)                  0.577938\n",
      "time/preback_policy (s)                 1.11949\n",
      "time/preback_start (s)                  0.12723\n",
      "time/preback_zf (s)                     5.10586\n",
      "time/saving (s)                         0.00507725\n",
      "time/training (s)                       2.23847\n",
      "time/epoch (s)                         17.1483\n",
      "time/total (s)                       3071.6\n",
      "Epoch                                 185\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:43:41.622553 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 186 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 197000\n",
      "trainer/ZF1 Loss                       40.089\n",
      "trainer/ZF2 Loss                       36.6454\n",
      "trainer/ZF Expert Reward               17.6965\n",
      "trainer/ZF Policy Reward                3.3867\n",
      "trainer/ZF CHI2 Term                   52.9846\n",
      "trainer/Policy Loss                  -966.766\n",
      "trainer/Bias Loss                     154.664\n",
      "trainer/Bias Value                     11.4673\n",
      "trainer/Policy Grad Norm              395.441\n",
      "trainer/Policy Param Norm              33.499\n",
      "trainer/Zf1 Grad Norm                2834.59\n",
      "trainer/Zf1 Param Norm                100.576\n",
      "trainer/Zf2 Grad Norm                2622.82\n",
      "trainer/Zf2 Param Norm                 98.9142\n",
      "trainer/Z Expert Predictions Mean    1184.78\n",
      "trainer/Z Expert Predictions Std      123.889\n",
      "trainer/Z Expert Predictions Max     1357.83\n",
      "trainer/Z Expert Predictions Min      713.601\n",
      "trainer/Z Policy Predictions Mean     960.931\n",
      "trainer/Z Policy Predictions Std      343.203\n",
      "trainer/Z Policy Predictions Max     1328.68\n",
      "trainer/Z Policy Predictions Min      -24.6699\n",
      "trainer/Z Expert Targets Mean        1167.09\n",
      "trainer/Z Expert Targets Std          127.195\n",
      "trainer/Z Expert Targets Max         1335.31\n",
      "trainer/Z Expert Targets Min          653.248\n",
      "trainer/Z Policy Targets Mean         957.545\n",
      "trainer/Z Policy Targets Std          339.748\n",
      "trainer/Z Policy Targets Max         1306.21\n",
      "trainer/Z Policy Targets Min          -15.3148\n",
      "trainer/Log Pis Mean                   30.7593\n",
      "trainer/Log Pis Std                     7.95393\n",
      "trainer/Policy mu Mean                  1.52814\n",
      "trainer/Policy mu Std                   2.60991\n",
      "trainer/Policy log std Mean            -3.35027\n",
      "trainer/Policy log std Std              1.40335\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        192968\n",
      "exploration/num paths total           960\n",
      "evaluation/num steps total              1.30704e+06\n",
      "evaluation/num paths total           1874\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20111\n",
      "evaluation/Rewards Std                  1.32286\n",
      "evaluation/Rewards Max                  7.2387\n",
      "evaluation/Rewards Min                  0.108527\n",
      "evaluation/Returns Mean              5201.11\n",
      "evaluation/Returns Std                 22.5022\n",
      "evaluation/Returns Max               5243.33\n",
      "evaluation/Returns Min               5175.22\n",
      "evaluation/Estimation Bias Mean      1146.8\n",
      "evaluation/Estimation Bias Std        195.536\n",
      "evaluation/EB/Q_True Mean              48.9655\n",
      "evaluation/EB/Q_True Std              151.277\n",
      "evaluation/EB/Q_Pred Mean            1195.76\n",
      "evaluation/EB/Q_Pred Std              109.229\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5201.11\n",
      "evaluation/Actions Mean                 0.500496\n",
      "evaluation/Actions Std                  0.652318\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.97052\n",
      "time/backward_zf1 (s)                   2.13723\n",
      "time/backward_zf2 (s)                   2.04789\n",
      "time/data sampling (s)                  0.267903\n",
      "time/data storing (s)                   0.0150679\n",
      "time/evaluation sampling (s)            1.37711\n",
      "time/exploration sampling (s)           0.206789\n",
      "time/logging (s)                        0.0119387\n",
      "time/preback_alpha (s)                  0.577757\n",
      "time/preback_policy (s)                 1.15656\n",
      "time/preback_start (s)                  0.126767\n",
      "time/preback_zf (s)                     5.09338\n",
      "time/saving (s)                         0.00564077\n",
      "time/training (s)                       2.14525\n",
      "time/epoch (s)                         17.1398\n",
      "time/total (s)                       3088.76\n",
      "Epoch                                 186\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:43:58.690555 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 187 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 198000\n",
      "trainer/ZF1 Loss                      246.89\n",
      "trainer/ZF2 Loss                      256.96\n",
      "trainer/ZF Expert Reward               16.9582\n",
      "trainer/ZF Policy Reward               -1.62471\n",
      "trainer/ZF CHI2 Term                  270.81\n",
      "trainer/Policy Loss                 -1010.65\n",
      "trainer/Bias Loss                    2367.06\n",
      "trainer/Bias Value                     11.4732\n",
      "trainer/Policy Grad Norm              286.833\n",
      "trainer/Policy Param Norm              33.5357\n",
      "trainer/Zf1 Grad Norm                3681.93\n",
      "trainer/Zf1 Param Norm                100.798\n",
      "trainer/Zf2 Grad Norm                3855.06\n",
      "trainer/Zf2 Param Norm                 99.14\n",
      "trainer/Z Expert Predictions Mean    1192.15\n",
      "trainer/Z Expert Predictions Std      109.536\n",
      "trainer/Z Expert Predictions Max     1358.72\n",
      "trainer/Z Expert Predictions Min      749.552\n",
      "trainer/Z Policy Predictions Mean    1004.95\n",
      "trainer/Z Policy Predictions Std      304.786\n",
      "trainer/Z Policy Predictions Max     1309.3\n",
      "trainer/Z Policy Predictions Min       -7.00877\n",
      "trainer/Z Expert Targets Mean        1175.19\n",
      "trainer/Z Expert Targets Std          131.732\n",
      "trainer/Z Expert Targets Max         1359.31\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1006.58\n",
      "trainer/Z Policy Targets Std          299.929\n",
      "trainer/Z Policy Targets Max         1314.63\n",
      "trainer/Z Policy Targets Min          -17.0437\n",
      "trainer/Log Pis Mean                   30.2168\n",
      "trainer/Log Pis Std                     6.90865\n",
      "trainer/Policy mu Mean                  1.32644\n",
      "trainer/Policy mu Std                   2.35267\n",
      "trainer/Policy log std Mean            -3.59826\n",
      "trainer/Policy log std Std              1.32824\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        192968\n",
      "exploration/num paths total           960\n",
      "evaluation/num steps total              1.31704e+06\n",
      "evaluation/num paths total           1884\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19775\n",
      "evaluation/Rewards Std                  1.31622\n",
      "evaluation/Rewards Max                  7.22476\n",
      "evaluation/Rewards Min                  0.132368\n",
      "evaluation/Returns Mean              5197.75\n",
      "evaluation/Returns Std                 27.2237\n",
      "evaluation/Returns Max               5239.72\n",
      "evaluation/Returns Min               5154.02\n",
      "evaluation/Estimation Bias Mean      1110.2\n",
      "evaluation/Estimation Bias Std        196.734\n",
      "evaluation/EB/Q_True Mean              49.2781\n",
      "evaluation/EB/Q_True Std              151.991\n",
      "evaluation/EB/Q_Pred Mean            1159.48\n",
      "evaluation/EB/Q_Pred Std              137.336\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5197.75\n",
      "evaluation/Actions Mean                 0.506556\n",
      "evaluation/Actions Std                  0.648369\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.93297\n",
      "time/backward_zf1 (s)                   2.10066\n",
      "time/backward_zf2 (s)                   2.01245\n",
      "time/data sampling (s)                  0.279088\n",
      "time/data storing (s)                   0.0138038\n",
      "time/evaluation sampling (s)            1.40832\n",
      "time/exploration sampling (s)           0.19635\n",
      "time/logging (s)                        0.0118596\n",
      "time/preback_alpha (s)                  0.568116\n",
      "time/preback_policy (s)                 1.15288\n",
      "time/preback_start (s)                  0.123244\n",
      "time/preback_zf (s)                     5.07265\n",
      "time/saving (s)                         0.00554381\n",
      "time/training (s)                       2.12046\n",
      "time/epoch (s)                         16.9984\n",
      "time/total (s)                       3105.78\n",
      "Epoch                                 187\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:44:15.709612 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 188 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 199000\n",
      "trainer/ZF1 Loss                       19.6672\n",
      "trainer/ZF2 Loss                       22.216\n",
      "trainer/ZF Expert Reward               12.3575\n",
      "trainer/ZF Policy Reward               -0.170039\n",
      "trainer/ZF CHI2 Term                   33.7879\n",
      "trainer/Policy Loss                  -974.534\n",
      "trainer/Bias Loss                      75.0216\n",
      "trainer/Bias Value                     11.4791\n",
      "trainer/Policy Grad Norm              345.152\n",
      "trainer/Policy Param Norm              33.5652\n",
      "trainer/Zf1 Grad Norm                1820.44\n",
      "trainer/Zf1 Param Norm                101.024\n",
      "trainer/Zf2 Grad Norm                2945.6\n",
      "trainer/Zf2 Param Norm                 99.37\n",
      "trainer/Z Expert Predictions Mean    1192.02\n",
      "trainer/Z Expert Predictions Std      100.356\n",
      "trainer/Z Expert Predictions Max     1348.62\n",
      "trainer/Z Expert Predictions Min      749.32\n",
      "trainer/Z Policy Predictions Mean     964.377\n",
      "trainer/Z Policy Predictions Std      344.652\n",
      "trainer/Z Policy Predictions Max     1316.54\n",
      "trainer/Z Policy Predictions Min      -19.4139\n",
      "trainer/Z Expert Targets Mean        1179.66\n",
      "trainer/Z Expert Targets Std           99.8998\n",
      "trainer/Z Expert Targets Max         1327.81\n",
      "trainer/Z Expert Targets Min          763.156\n",
      "trainer/Z Policy Targets Mean         964.547\n",
      "trainer/Z Policy Targets Std          340.25\n",
      "trainer/Z Policy Targets Max         1303.29\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   31.877\n",
      "trainer/Log Pis Std                     9.23721\n",
      "trainer/Policy mu Mean                  1.45305\n",
      "trainer/Policy mu Std                   2.83447\n",
      "trainer/Policy log std Mean            -3.42292\n",
      "trainer/Policy log std Std              1.3891\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        192968\n",
      "exploration/num paths total           960\n",
      "evaluation/num steps total              1.32704e+06\n",
      "evaluation/num paths total           1894\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.24055\n",
      "evaluation/Rewards Std                  1.35096\n",
      "evaluation/Rewards Max                  7.35579\n",
      "evaluation/Rewards Min                  0.0978101\n",
      "evaluation/Returns Mean              5240.55\n",
      "evaluation/Returns Std                 12.9943\n",
      "evaluation/Returns Max               5256.59\n",
      "evaluation/Returns Min               5215.27\n",
      "evaluation/Estimation Bias Mean      1153.43\n",
      "evaluation/Estimation Bias Std        172.536\n",
      "evaluation/EB/Q_True Mean              49.6088\n",
      "evaluation/EB/Q_True Std              153.285\n",
      "evaluation/EB/Q_Pred Mean            1203.04\n",
      "evaluation/EB/Q_Pred Std               83.8385\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5240.55\n",
      "evaluation/Actions Mean                 0.520351\n",
      "evaluation/Actions Std                  0.635677\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.86239\n",
      "time/backward_zf1 (s)                   1.99165\n",
      "time/backward_zf2 (s)                   1.90948\n",
      "time/data sampling (s)                  0.263528\n",
      "time/data storing (s)                   0.0150267\n",
      "time/evaluation sampling (s)            1.4248\n",
      "time/exploration sampling (s)           0.19953\n",
      "time/logging (s)                        0.0124113\n",
      "time/preback_alpha (s)                  0.573063\n",
      "time/preback_policy (s)                 1.03325\n",
      "time/preback_start (s)                  0.125764\n",
      "time/preback_zf (s)                     5.08793\n",
      "time/saving (s)                         0.00519736\n",
      "time/training (s)                       2.44689\n",
      "time/epoch (s)                         16.9509\n",
      "time/total (s)                       3122.75\n",
      "Epoch                                 188\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:44:32.722097 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 189 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 200000\n",
      "trainer/ZF1 Loss                       39.0505\n",
      "trainer/ZF2 Loss                       35.4362\n",
      "trainer/ZF Expert Reward               13.3504\n",
      "trainer/ZF Policy Reward                1.19865\n",
      "trainer/ZF CHI2 Term                   49.7001\n",
      "trainer/Policy Loss                  -996.868\n",
      "trainer/Bias Loss                     184.184\n",
      "trainer/Bias Value                     11.4855\n",
      "trainer/Policy Grad Norm              318.099\n",
      "trainer/Policy Param Norm              33.5942\n",
      "trainer/Zf1 Grad Norm                2753.38\n",
      "trainer/Zf1 Param Norm                101.258\n",
      "trainer/Zf2 Grad Norm                2452.71\n",
      "trainer/Zf2 Param Norm                 99.606\n",
      "trainer/Z Expert Predictions Mean    1183.26\n",
      "trainer/Z Expert Predictions Std      101.943\n",
      "trainer/Z Expert Predictions Max     1345.81\n",
      "trainer/Z Expert Predictions Min      771.987\n",
      "trainer/Z Policy Predictions Mean     989.749\n",
      "trainer/Z Policy Predictions Std      309.926\n",
      "trainer/Z Policy Predictions Max     1302.92\n",
      "trainer/Z Policy Predictions Min        0.0221293\n",
      "trainer/Z Expert Targets Mean        1169.91\n",
      "trainer/Z Expert Targets Std          106.936\n",
      "trainer/Z Expert Targets Max         1328.44\n",
      "trainer/Z Expert Targets Min          749.935\n",
      "trainer/Z Policy Targets Mean         988.55\n",
      "trainer/Z Policy Targets Std          307.922\n",
      "trainer/Z Policy Targets Max         1303.48\n",
      "trainer/Z Policy Targets Min           37.3595\n",
      "trainer/Log Pis Mean                   30.4991\n",
      "trainer/Log Pis Std                     5.8107\n",
      "trainer/Policy mu Mean                  1.53015\n",
      "trainer/Policy mu Std                   2.36593\n",
      "trainer/Policy log std Mean            -3.4204\n",
      "trainer/Policy log std Std              1.40313\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        195968\n",
      "exploration/num paths total           963\n",
      "evaluation/num steps total              1.33704e+06\n",
      "evaluation/num paths total           1904\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16551\n",
      "evaluation/Rewards Std                  1.31087\n",
      "evaluation/Rewards Max                  7.21157\n",
      "evaluation/Rewards Min                  0.130558\n",
      "evaluation/Returns Mean              5165.51\n",
      "evaluation/Returns Std                 44.1848\n",
      "evaluation/Returns Max               5238.08\n",
      "evaluation/Returns Min               5087.78\n",
      "evaluation/Estimation Bias Mean      1126.74\n",
      "evaluation/Estimation Bias Std        223.758\n",
      "evaluation/EB/Q_True Mean              48.0276\n",
      "evaluation/EB/Q_True Std              148.375\n",
      "evaluation/EB/Q_Pred Mean            1174.77\n",
      "evaluation/EB/Q_Pred Std              142.078\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5165.51\n",
      "evaluation/Actions Mean                 0.498316\n",
      "evaluation/Actions Std                  0.656303\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.94371\n",
      "time/backward_zf1 (s)                   2.08723\n",
      "time/backward_zf2 (s)                   2.00329\n",
      "time/data sampling (s)                  0.244688\n",
      "time/data storing (s)                   0.0139199\n",
      "time/evaluation sampling (s)            1.41149\n",
      "time/exploration sampling (s)           0.20261\n",
      "time/logging (s)                        0.0120132\n",
      "time/preback_alpha (s)                  0.565037\n",
      "time/preback_policy (s)                 1.12727\n",
      "time/preback_start (s)                  0.124601\n",
      "time/preback_zf (s)                     5.06359\n",
      "time/saving (s)                         0.0102531\n",
      "time/training (s)                       2.1328\n",
      "time/epoch (s)                         16.9425\n",
      "time/total (s)                       3139.72\n",
      "Epoch                                 189\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:44:50.423322 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 190 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 201000\n",
      "trainer/ZF1 Loss                       33.7474\n",
      "trainer/ZF2 Loss                       36.86\n",
      "trainer/ZF Expert Reward                9.42393\n",
      "trainer/ZF Policy Reward               -4.56381\n",
      "trainer/ZF CHI2 Term                   49.5984\n",
      "trainer/Policy Loss                 -1001.77\n",
      "trainer/Bias Loss                      99.173\n",
      "trainer/Bias Value                     11.4918\n",
      "trainer/Policy Grad Norm              321.212\n",
      "trainer/Policy Param Norm              33.6282\n",
      "trainer/Zf1 Grad Norm                3412.79\n",
      "trainer/Zf1 Param Norm                101.485\n",
      "trainer/Zf2 Grad Norm                4107.08\n",
      "trainer/Zf2 Param Norm                 99.8316\n",
      "trainer/Z Expert Predictions Mean    1175.84\n",
      "trainer/Z Expert Predictions Std      115.172\n",
      "trainer/Z Expert Predictions Max     1340.48\n",
      "trainer/Z Expert Predictions Min      726\n",
      "trainer/Z Policy Predictions Mean     993.344\n",
      "trainer/Z Policy Predictions Std      324.442\n",
      "trainer/Z Policy Predictions Max     1301.62\n",
      "trainer/Z Policy Predictions Min      -19.2594\n",
      "trainer/Z Expert Targets Mean        1166.42\n",
      "trainer/Z Expert Targets Std          116.788\n",
      "trainer/Z Expert Targets Max         1328.47\n",
      "trainer/Z Expert Targets Min          676.818\n",
      "trainer/Z Policy Targets Mean         997.908\n",
      "trainer/Z Policy Targets Std          320.401\n",
      "trainer/Z Policy Targets Max         1317.45\n",
      "trainer/Z Policy Targets Min          -12.9068\n",
      "trainer/Log Pis Mean                   30.6951\n",
      "trainer/Log Pis Std                     7.48696\n",
      "trainer/Policy mu Mean                  1.42419\n",
      "trainer/Policy mu Std                   2.49609\n",
      "trainer/Policy log std Mean            -3.54276\n",
      "trainer/Policy log std Std              1.43216\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        195968\n",
      "exploration/num paths total           963\n",
      "evaluation/num steps total              1.34511e+06\n",
      "evaluation/num paths total           1914\n",
      "evaluation/path length Mean           807.8\n",
      "evaluation/path length Std            171.854\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            490\n",
      "evaluation/Rewards Mean                 5.1292\n",
      "evaluation/Rewards Std                  1.42744\n",
      "evaluation/Rewards Max                  7.46563\n",
      "evaluation/Rewards Min                  0.12533\n",
      "evaluation/Returns Mean              4143.37\n",
      "evaluation/Returns Std                967.172\n",
      "evaluation/Returns Max               5206.13\n",
      "evaluation/Returns Min               2319.93\n",
      "evaluation/Estimation Bias Mean       894.637\n",
      "evaluation/Estimation Bias Std        371\n",
      "evaluation/EB/Q_True Mean              60.2425\n",
      "evaluation/EB/Q_True Std              165.217\n",
      "evaluation/EB/Q_Pred Mean             954.879\n",
      "evaluation/EB/Q_Pred Std              348.42\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4143.37\n",
      "evaluation/Actions Mean                 0.486457\n",
      "evaluation/Actions Std                  0.672727\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.09264\n",
      "time/backward_zf1 (s)                   2.23041\n",
      "time/backward_zf2 (s)                   2.16815\n",
      "time/data sampling (s)                  0.278982\n",
      "time/data storing (s)                   0.0145455\n",
      "time/evaluation sampling (s)            1.40746\n",
      "time/exploration sampling (s)           0.195072\n",
      "time/logging (s)                        0.010101\n",
      "time/preback_alpha (s)                  0.589991\n",
      "time/preback_policy (s)                 1.21193\n",
      "time/preback_start (s)                  0.128705\n",
      "time/preback_zf (s)                     5.14088\n",
      "time/saving (s)                         0.00565566\n",
      "time/training (s)                       2.15678\n",
      "time/epoch (s)                         17.6313\n",
      "time/total (s)                       3157.37\n",
      "Epoch                                 190\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:45:07.428071 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 191 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 202000\n",
      "trainer/ZF1 Loss                      280.469\n",
      "trainer/ZF2 Loss                      277.511\n",
      "trainer/ZF Expert Reward               13.1203\n",
      "trainer/ZF Policy Reward               -1.13659\n",
      "trainer/ZF CHI2 Term                  293.547\n",
      "trainer/Policy Loss                 -1016.09\n",
      "trainer/Bias Loss                    2612.18\n",
      "trainer/Bias Value                     11.4981\n",
      "trainer/Policy Grad Norm              329.612\n",
      "trainer/Policy Param Norm              33.6608\n",
      "trainer/Zf1 Grad Norm                5434.85\n",
      "trainer/Zf1 Param Norm                101.708\n",
      "trainer/Zf2 Grad Norm                4804.99\n",
      "trainer/Zf2 Param Norm                100.058\n",
      "trainer/Z Expert Predictions Mean    1189.95\n",
      "trainer/Z Expert Predictions Std      105.056\n",
      "trainer/Z Expert Predictions Max     1349.09\n",
      "trainer/Z Expert Predictions Min      770.141\n",
      "trainer/Z Policy Predictions Mean    1004.02\n",
      "trainer/Z Policy Predictions Std      313.72\n",
      "trainer/Z Policy Predictions Max     1304.62\n",
      "trainer/Z Policy Predictions Min      -29.192\n",
      "trainer/Z Expert Targets Mean        1176.83\n",
      "trainer/Z Expert Targets Std          129.357\n",
      "trainer/Z Expert Targets Max         1337.75\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1005.16\n",
      "trainer/Z Policy Targets Std          314.327\n",
      "trainer/Z Policy Targets Max         1304.04\n",
      "trainer/Z Policy Targets Min          -24.0591\n",
      "trainer/Log Pis Mean                   30.0276\n",
      "trainer/Log Pis Std                     5.69375\n",
      "trainer/Policy mu Mean                  1.48334\n",
      "trainer/Policy mu Std                   2.28554\n",
      "trainer/Policy log std Mean            -3.53785\n",
      "trainer/Policy log std Std              1.37174\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        196968\n",
      "exploration/num paths total           964\n",
      "evaluation/num steps total              1.35511e+06\n",
      "evaluation/num paths total           1924\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.26131\n",
      "evaluation/Rewards Std                  1.34557\n",
      "evaluation/Rewards Max                  7.36887\n",
      "evaluation/Rewards Min                  0.12019\n",
      "evaluation/Returns Mean              5261.31\n",
      "evaluation/Returns Std                 18.4973\n",
      "evaluation/Returns Max               5294.74\n",
      "evaluation/Returns Min               5219.96\n",
      "evaluation/Estimation Bias Mean      1162.74\n",
      "evaluation/Estimation Bias Std        165.688\n",
      "evaluation/EB/Q_True Mean              49.6691\n",
      "evaluation/EB/Q_True Std              153.494\n",
      "evaluation/EB/Q_Pred Mean            1212.41\n",
      "evaluation/EB/Q_Pred Std               69.7874\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5261.31\n",
      "evaluation/Actions Mean                 0.513139\n",
      "evaluation/Actions Std                  0.639459\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.83549\n",
      "time/backward_zf1 (s)                   1.99317\n",
      "time/backward_zf2 (s)                   1.90776\n",
      "time/data sampling (s)                  0.276992\n",
      "time/data storing (s)                   0.0149123\n",
      "time/evaluation sampling (s)            1.38151\n",
      "time/exploration sampling (s)           0.203297\n",
      "time/logging (s)                        0.0123974\n",
      "time/preback_alpha (s)                  0.577636\n",
      "time/preback_policy (s)                 1.05172\n",
      "time/preback_start (s)                  0.125986\n",
      "time/preback_zf (s)                     5.1178\n",
      "time/saving (s)                         0.0057831\n",
      "time/training (s)                       2.43488\n",
      "time/epoch (s)                         16.9393\n",
      "time/total (s)                       3174.33\n",
      "Epoch                                 191\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:45:24.572982 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 192 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 203000\n",
      "trainer/ZF1 Loss                      780.075\n",
      "trainer/ZF2 Loss                      816.271\n",
      "trainer/ZF Expert Reward               24.2329\n",
      "trainer/ZF Policy Reward                5.68036\n",
      "trainer/ZF CHI2 Term                  817.034\n",
      "trainer/Policy Loss                 -1006.69\n",
      "trainer/Bias Loss                    4752\n",
      "trainer/Bias Value                     11.5042\n",
      "trainer/Policy Grad Norm              460.881\n",
      "trainer/Policy Param Norm              33.6992\n",
      "trainer/Zf1 Grad Norm                8110.7\n",
      "trainer/Zf1 Param Norm                101.94\n",
      "trainer/Zf2 Grad Norm                9784.69\n",
      "trainer/Zf2 Param Norm                100.296\n",
      "trainer/Z Expert Predictions Mean    1183.69\n",
      "trainer/Z Expert Predictions Std      129.557\n",
      "trainer/Z Expert Predictions Max     1339.38\n",
      "trainer/Z Expert Predictions Min      -85.4699\n",
      "trainer/Z Policy Predictions Mean    1000.08\n",
      "trainer/Z Policy Predictions Std      314.112\n",
      "trainer/Z Policy Predictions Max     1313.06\n",
      "trainer/Z Policy Predictions Min      -48.1506\n",
      "trainer/Z Expert Targets Mean        1159.45\n",
      "trainer/Z Expert Targets Std          161.819\n",
      "trainer/Z Expert Targets Max         1330.52\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         994.398\n",
      "trainer/Z Policy Targets Std          317.005\n",
      "trainer/Z Policy Targets Max         1295.32\n",
      "trainer/Z Policy Targets Min          -61.1103\n",
      "trainer/Log Pis Mean                   30.7601\n",
      "trainer/Log Pis Std                     7.47441\n",
      "trainer/Policy mu Mean                  1.36714\n",
      "trainer/Policy mu Std                   2.46442\n",
      "trainer/Policy log std Mean            -3.45788\n",
      "trainer/Policy log std Std              1.41479\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        196968\n",
      "exploration/num paths total           964\n",
      "evaluation/num steps total              1.36511e+06\n",
      "evaluation/num paths total           1934\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15517\n",
      "evaluation/Rewards Std                  1.30885\n",
      "evaluation/Rewards Max                  7.16053\n",
      "evaluation/Rewards Min                  0.100207\n",
      "evaluation/Returns Mean              5155.17\n",
      "evaluation/Returns Std                 25.8352\n",
      "evaluation/Returns Max               5210.71\n",
      "evaluation/Returns Min               5113.4\n",
      "evaluation/Estimation Bias Mean      1177.35\n",
      "evaluation/Estimation Bias Std        169.155\n",
      "evaluation/EB/Q_True Mean              48.8994\n",
      "evaluation/EB/Q_True Std              151.173\n",
      "evaluation/EB/Q_Pred Mean            1226.25\n",
      "evaluation/EB/Q_Pred Std               87.1701\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5155.17\n",
      "evaluation/Actions Mean                 0.495056\n",
      "evaluation/Actions Std                  0.646409\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.90555\n",
      "time/backward_zf1 (s)                   2.08174\n",
      "time/backward_zf2 (s)                   1.98938\n",
      "time/data sampling (s)                  0.276766\n",
      "time/data storing (s)                   0.014363\n",
      "time/evaluation sampling (s)            1.39767\n",
      "time/exploration sampling (s)           0.197269\n",
      "time/logging (s)                        0.0114567\n",
      "time/preback_alpha (s)                  0.575297\n",
      "time/preback_policy (s)                 1.08521\n",
      "time/preback_start (s)                  0.12509\n",
      "time/preback_zf (s)                     5.08864\n",
      "time/saving (s)                         0.00603317\n",
      "time/training (s)                       2.32112\n",
      "time/epoch (s)                         17.0756\n",
      "time/total (s)                       3191.42\n",
      "Epoch                                 192\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:45:42.134240 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 193 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 204000\n",
      "trainer/ZF1 Loss                      238.686\n",
      "trainer/ZF2 Loss                      264.134\n",
      "trainer/ZF Expert Reward               24.5276\n",
      "trainer/ZF Policy Reward                6.05606\n",
      "trainer/ZF CHI2 Term                  270.18\n",
      "trainer/Policy Loss                 -1007.95\n",
      "trainer/Bias Loss                    2384.84\n",
      "trainer/Bias Value                     11.5103\n",
      "trainer/Policy Grad Norm              330.683\n",
      "trainer/Policy Param Norm              33.7302\n",
      "trainer/Zf1 Grad Norm                6608.87\n",
      "trainer/Zf1 Param Norm                102.177\n",
      "trainer/Zf2 Grad Norm                4542.71\n",
      "trainer/Zf2 Param Norm                100.533\n",
      "trainer/Z Expert Predictions Mean    1188.83\n",
      "trainer/Z Expert Predictions Std      113.227\n",
      "trainer/Z Expert Predictions Max     1348.88\n",
      "trainer/Z Expert Predictions Min      750.976\n",
      "trainer/Z Policy Predictions Mean    1001.56\n",
      "trainer/Z Policy Predictions Std      314.136\n",
      "trainer/Z Policy Predictions Max     1322.24\n",
      "trainer/Z Policy Predictions Min      -76.9271\n",
      "trainer/Z Expert Targets Mean        1164.31\n",
      "trainer/Z Expert Targets Std          136.094\n",
      "trainer/Z Expert Targets Max         1341.17\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         995.507\n",
      "trainer/Z Policy Targets Std          309.66\n",
      "trainer/Z Policy Targets Max         1331.55\n",
      "trainer/Z Policy Targets Min          -52.4918\n",
      "trainer/Log Pis Mean                   29.8723\n",
      "trainer/Log Pis Std                     7.07827\n",
      "trainer/Policy mu Mean                  1.42604\n",
      "trainer/Policy mu Std                   2.46759\n",
      "trainer/Policy log std Mean            -3.32769\n",
      "trainer/Policy log std Std              1.39144\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        199968\n",
      "exploration/num paths total           967\n",
      "evaluation/num steps total              1.37511e+06\n",
      "evaluation/num paths total           1944\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17153\n",
      "evaluation/Rewards Std                  1.31014\n",
      "evaluation/Rewards Max                  7.23001\n",
      "evaluation/Rewards Min                  0.107893\n",
      "evaluation/Returns Mean              5171.53\n",
      "evaluation/Returns Std                 20.6045\n",
      "evaluation/Returns Max               5198.89\n",
      "evaluation/Returns Min               5133.71\n",
      "evaluation/Estimation Bias Mean      1139.1\n",
      "evaluation/Estimation Bias Std        181.565\n",
      "evaluation/EB/Q_True Mean              48.5147\n",
      "evaluation/EB/Q_True Std              150.167\n",
      "evaluation/EB/Q_Pred Mean            1187.61\n",
      "evaluation/EB/Q_Pred Std              124.783\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5171.53\n",
      "evaluation/Actions Mean                 0.493745\n",
      "evaluation/Actions Std                  0.650333\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.03814\n",
      "time/backward_zf1 (s)                   2.16758\n",
      "time/backward_zf2 (s)                   2.08768\n",
      "time/data sampling (s)                  0.280548\n",
      "time/data storing (s)                   0.014816\n",
      "time/evaluation sampling (s)            1.44999\n",
      "time/exploration sampling (s)           0.207283\n",
      "time/logging (s)                        0.0119548\n",
      "time/preback_alpha (s)                  0.58674\n",
      "time/preback_policy (s)                 1.20022\n",
      "time/preback_start (s)                  0.128114\n",
      "time/preback_zf (s)                     5.14216\n",
      "time/saving (s)                         0.005919\n",
      "time/training (s)                       2.16886\n",
      "time/epoch (s)                         17.49\n",
      "time/total (s)                       3208.94\n",
      "Epoch                                 193\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:45:59.496599 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 194 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 205000\n",
      "trainer/ZF1 Loss                       31.0298\n",
      "trainer/ZF2 Loss                       36.1945\n",
      "trainer/ZF Expert Reward               19.7779\n",
      "trainer/ZF Policy Reward                2.82422\n",
      "trainer/ZF CHI2 Term                   50.8796\n",
      "trainer/Policy Loss                  -957.396\n",
      "trainer/Bias Loss                     155.01\n",
      "trainer/Bias Value                     11.5163\n",
      "trainer/Policy Grad Norm              378.422\n",
      "trainer/Policy Param Norm              33.764\n",
      "trainer/Zf1 Grad Norm                2128.35\n",
      "trainer/Zf1 Param Norm                102.419\n",
      "trainer/Zf2 Grad Norm                2161.91\n",
      "trainer/Zf2 Param Norm                100.769\n",
      "trainer/Z Expert Predictions Mean    1193.66\n",
      "trainer/Z Expert Predictions Std       96.6943\n",
      "trainer/Z Expert Predictions Max     1340.14\n",
      "trainer/Z Expert Predictions Min      746.93\n",
      "trainer/Z Policy Predictions Mean     948.552\n",
      "trainer/Z Policy Predictions Std      361.186\n",
      "trainer/Z Policy Predictions Max     1315.15\n",
      "trainer/Z Policy Predictions Min      -62.2335\n",
      "trainer/Z Expert Targets Mean        1173.88\n",
      "trainer/Z Expert Targets Std           98.1945\n",
      "trainer/Z Expert Targets Max         1332.04\n",
      "trainer/Z Expert Targets Min          719.652\n",
      "trainer/Z Policy Targets Mean         945.728\n",
      "trainer/Z Policy Targets Std          351.784\n",
      "trainer/Z Policy Targets Max         1317.85\n",
      "trainer/Z Policy Targets Min          -98.8538\n",
      "trainer/Log Pis Mean                   31.3775\n",
      "trainer/Log Pis Std                     7.4002\n",
      "trainer/Policy mu Mean                  1.43729\n",
      "trainer/Policy mu Std                   2.67905\n",
      "trainer/Policy log std Mean            -3.37184\n",
      "trainer/Policy log std Std              1.44881\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        200968\n",
      "exploration/num paths total           968\n",
      "evaluation/num steps total              1.38511e+06\n",
      "evaluation/num paths total           1954\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18758\n",
      "evaluation/Rewards Std                  1.30772\n",
      "evaluation/Rewards Max                  7.16317\n",
      "evaluation/Rewards Min                  0.114738\n",
      "evaluation/Returns Mean              5187.58\n",
      "evaluation/Returns Std                 24.245\n",
      "evaluation/Returns Max               5227.54\n",
      "evaluation/Returns Min               5147.33\n",
      "evaluation/Estimation Bias Mean      1102.22\n",
      "evaluation/Estimation Bias Std        182.918\n",
      "evaluation/EB/Q_True Mean              49.0133\n",
      "evaluation/EB/Q_True Std              151.464\n",
      "evaluation/EB/Q_Pred Mean            1151.23\n",
      "evaluation/EB/Q_Pred Std              113.282\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5187.58\n",
      "evaluation/Actions Mean                 0.500856\n",
      "evaluation/Actions Std                  0.650934\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.96547\n",
      "time/backward_zf1 (s)                   2.13595\n",
      "time/backward_zf2 (s)                   2.04018\n",
      "time/data sampling (s)                  0.274492\n",
      "time/data storing (s)                   0.0140948\n",
      "time/evaluation sampling (s)            1.4417\n",
      "time/exploration sampling (s)           0.200516\n",
      "time/logging (s)                        0.0121707\n",
      "time/preback_alpha (s)                  0.579767\n",
      "time/preback_policy (s)                 1.15331\n",
      "time/preback_start (s)                  0.127308\n",
      "time/preback_zf (s)                     5.10272\n",
      "time/saving (s)                         0.00576742\n",
      "time/training (s)                       2.24158\n",
      "time/epoch (s)                         17.295\n",
      "time/total (s)                       3226.25\n",
      "Epoch                                 194\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:46:16.816660 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 195 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 206000\n",
      "trainer/ZF1 Loss                       44.0456\n",
      "trainer/ZF2 Loss                       31.5664\n",
      "trainer/ZF Expert Reward               17.0991\n",
      "trainer/ZF Policy Reward                2.85998\n",
      "trainer/ZF CHI2 Term                   52.3458\n",
      "trainer/Policy Loss                 -1002.77\n",
      "trainer/Bias Loss                     153.327\n",
      "trainer/Bias Value                     11.5222\n",
      "trainer/Policy Grad Norm              428.174\n",
      "trainer/Policy Param Norm              33.7938\n",
      "trainer/Zf1 Grad Norm                3606.84\n",
      "trainer/Zf1 Param Norm                102.652\n",
      "trainer/Zf2 Grad Norm                1729.08\n",
      "trainer/Zf2 Param Norm                100.995\n",
      "trainer/Z Expert Predictions Mean    1177.74\n",
      "trainer/Z Expert Predictions Std      119.224\n",
      "trainer/Z Expert Predictions Max     1353.4\n",
      "trainer/Z Expert Predictions Min      178.762\n",
      "trainer/Z Policy Predictions Mean     996.64\n",
      "trainer/Z Policy Predictions Std      327.775\n",
      "trainer/Z Policy Predictions Max     1319.58\n",
      "trainer/Z Policy Predictions Min      -97.3663\n",
      "trainer/Z Expert Targets Mean        1160.64\n",
      "trainer/Z Expert Targets Std          125.437\n",
      "trainer/Z Expert Targets Max         1331.92\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         993.78\n",
      "trainer/Z Policy Targets Std          324.958\n",
      "trainer/Z Policy Targets Max         1293.99\n",
      "trainer/Z Policy Targets Min         -111.464\n",
      "trainer/Log Pis Mean                   30.0639\n",
      "trainer/Log Pis Std                     6.67849\n",
      "trainer/Policy mu Mean                  1.50117\n",
      "trainer/Policy mu Std                   2.43489\n",
      "trainer/Policy log std Mean            -3.33656\n",
      "trainer/Policy log std Std              1.39821\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        200968\n",
      "exploration/num paths total           968\n",
      "evaluation/num steps total              1.39483e+06\n",
      "evaluation/num paths total           1964\n",
      "evaluation/path length Mean           971.2\n",
      "evaluation/path length Std             63.5434\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            796\n",
      "evaluation/Rewards Mean                 5.1267\n",
      "evaluation/Rewards Std                  1.31233\n",
      "evaluation/Rewards Max                  7.08936\n",
      "evaluation/Rewards Min                  0.125175\n",
      "evaluation/Returns Mean              4979.06\n",
      "evaluation/Returns Std                349.417\n",
      "evaluation/Returns Max               5177.01\n",
      "evaluation/Returns Min               4013.17\n",
      "evaluation/Estimation Bias Mean      1044.67\n",
      "evaluation/Estimation Bias Std        311.028\n",
      "evaluation/EB/Q_True Mean              50.0223\n",
      "evaluation/EB/Q_True Std              152.241\n",
      "evaluation/EB/Q_Pred Mean            1094.69\n",
      "evaluation/EB/Q_Pred Std              253.906\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4979.06\n",
      "evaluation/Actions Mean                 0.500792\n",
      "evaluation/Actions Std                  0.657111\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95398\n",
      "time/backward_zf1 (s)                   2.09306\n",
      "time/backward_zf2 (s)                   2.02364\n",
      "time/data sampling (s)                  0.290147\n",
      "time/data storing (s)                   0.0141243\n",
      "time/evaluation sampling (s)            1.42085\n",
      "time/exploration sampling (s)           0.196163\n",
      "time/logging (s)                        0.0181743\n",
      "time/preback_alpha (s)                  0.58372\n",
      "time/preback_policy (s)                 1.11356\n",
      "time/preback_start (s)                  0.12776\n",
      "time/preback_zf (s)                     5.11811\n",
      "time/saving (s)                         0.0233411\n",
      "time/training (s)                       2.28063\n",
      "time/epoch (s)                         17.2572\n",
      "time/total (s)                       3243.53\n",
      "Epoch                                 195\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:46:33.859571 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 196 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 207000\n",
      "trainer/ZF1 Loss                       36.9316\n",
      "trainer/ZF2 Loss                       42.7208\n",
      "trainer/ZF Expert Reward               10.9275\n",
      "trainer/ZF Policy Reward               -4.63476\n",
      "trainer/ZF CHI2 Term                   55.6954\n",
      "trainer/Policy Loss                  -971.247\n",
      "trainer/Bias Loss                     123.396\n",
      "trainer/Bias Value                     11.5279\n",
      "trainer/Policy Grad Norm              329.718\n",
      "trainer/Policy Param Norm              33.8323\n",
      "trainer/Zf1 Grad Norm                3378.52\n",
      "trainer/Zf1 Param Norm                102.893\n",
      "trainer/Zf2 Grad Norm                4813.68\n",
      "trainer/Zf2 Param Norm                101.237\n",
      "trainer/Z Expert Predictions Mean    1171.34\n",
      "trainer/Z Expert Predictions Std      105.947\n",
      "trainer/Z Expert Predictions Max     1332.94\n",
      "trainer/Z Expert Predictions Min      785.511\n",
      "trainer/Z Policy Predictions Mean     954.779\n",
      "trainer/Z Policy Predictions Std      333.494\n",
      "trainer/Z Policy Predictions Max     1304.68\n",
      "trainer/Z Policy Predictions Min     -103.597\n",
      "trainer/Z Expert Targets Mean        1160.41\n",
      "trainer/Z Expert Targets Std          104.57\n",
      "trainer/Z Expert Targets Max         1334.59\n",
      "trainer/Z Expert Targets Min          802.213\n",
      "trainer/Z Policy Targets Mean         959.414\n",
      "trainer/Z Policy Targets Std          328.216\n",
      "trainer/Z Policy Targets Max         1318.01\n",
      "trainer/Z Policy Targets Min          -90.7149\n",
      "trainer/Log Pis Mean                   30.6997\n",
      "trainer/Log Pis Std                     7.57339\n",
      "trainer/Policy mu Mean                  1.4646\n",
      "trainer/Policy mu Std                   2.65054\n",
      "trainer/Policy log std Mean            -3.36948\n",
      "trainer/Policy log std Std              1.42167\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        202968\n",
      "exploration/num paths total           970\n",
      "evaluation/num steps total              1.40445e+06\n",
      "evaluation/num paths total           1974\n",
      "evaluation/path length Mean           962\n",
      "evaluation/path length Std            114\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            620\n",
      "evaluation/Rewards Mean                 5.11784\n",
      "evaluation/Rewards Std                  1.32603\n",
      "evaluation/Rewards Max                  7.27721\n",
      "evaluation/Rewards Min                  0.107341\n",
      "evaluation/Returns Mean              4923.36\n",
      "evaluation/Returns Std                645.928\n",
      "evaluation/Returns Max               5191.12\n",
      "evaluation/Returns Min               2989.23\n",
      "evaluation/Estimation Bias Mean      1044.42\n",
      "evaluation/Estimation Bias Std        280.314\n",
      "evaluation/EB/Q_True Mean              50.8234\n",
      "evaluation/EB/Q_True Std              153.738\n",
      "evaluation/EB/Q_Pred Mean            1095.24\n",
      "evaluation/EB/Q_Pred Std              196.61\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4923.36\n",
      "evaluation/Actions Mean                 0.509848\n",
      "evaluation/Actions Std                  0.656077\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85745\n",
      "time/backward_zf1 (s)                   2.00884\n",
      "time/backward_zf2 (s)                   1.9219\n",
      "time/data sampling (s)                  0.269521\n",
      "time/data storing (s)                   0.0138063\n",
      "time/evaluation sampling (s)            1.46218\n",
      "time/exploration sampling (s)           0.200668\n",
      "time/logging (s)                        0.0111388\n",
      "time/preback_alpha (s)                  0.572747\n",
      "time/preback_policy (s)                 1.0606\n",
      "time/preback_start (s)                  0.124312\n",
      "time/preback_zf (s)                     5.08943\n",
      "time/saving (s)                         0.00578345\n",
      "time/training (s)                       2.36773\n",
      "time/epoch (s)                         16.9661\n",
      "time/total (s)                       3260.51\n",
      "Epoch                                 196\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:46:51.053663 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 197 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 208000\n",
      "trainer/ZF1 Loss                       24.1665\n",
      "trainer/ZF2 Loss                       22.6667\n",
      "trainer/ZF Expert Reward               16.0876\n",
      "trainer/ZF Policy Reward                2.13715\n",
      "trainer/ZF CHI2 Term                   37.6695\n",
      "trainer/Policy Loss                  -988.985\n",
      "trainer/Bias Loss                     117.069\n",
      "trainer/Bias Value                     11.5342\n",
      "trainer/Policy Grad Norm              327.959\n",
      "trainer/Policy Param Norm              33.8665\n",
      "trainer/Zf1 Grad Norm                1851.96\n",
      "trainer/Zf1 Param Norm                103.133\n",
      "trainer/Zf2 Grad Norm                1895.55\n",
      "trainer/Zf2 Param Norm                101.466\n",
      "trainer/Z Expert Predictions Mean    1173.19\n",
      "trainer/Z Expert Predictions Std      114.609\n",
      "trainer/Z Expert Predictions Max     1362.19\n",
      "trainer/Z Expert Predictions Min      752.685\n",
      "trainer/Z Policy Predictions Mean     983.125\n",
      "trainer/Z Policy Predictions Std      303.437\n",
      "trainer/Z Policy Predictions Max     1333.09\n",
      "trainer/Z Policy Predictions Min      -42.4821\n",
      "trainer/Z Expert Targets Mean        1157.1\n",
      "trainer/Z Expert Targets Std          114.816\n",
      "trainer/Z Expert Targets Max         1309.34\n",
      "trainer/Z Expert Targets Min          719.108\n",
      "trainer/Z Policy Targets Mean         980.988\n",
      "trainer/Z Policy Targets Std          299.368\n",
      "trainer/Z Policy Targets Max         1319.01\n",
      "trainer/Z Policy Targets Min          -30.4847\n",
      "trainer/Log Pis Mean                   30.2408\n",
      "trainer/Log Pis Std                     7.15699\n",
      "trainer/Policy mu Mean                  1.49536\n",
      "trainer/Policy mu Std                   2.43547\n",
      "trainer/Policy log std Mean            -3.4301\n",
      "trainer/Policy log std Std              1.42805\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        202968\n",
      "exploration/num paths total           970\n",
      "evaluation/num steps total              1.41445e+06\n",
      "evaluation/num paths total           1984\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25652\n",
      "evaluation/Rewards Std                  1.34998\n",
      "evaluation/Rewards Max                  7.36842\n",
      "evaluation/Rewards Min                  0.127184\n",
      "evaluation/Returns Mean              5256.52\n",
      "evaluation/Returns Std                 14.9779\n",
      "evaluation/Returns Max               5275.85\n",
      "evaluation/Returns Min               5223.04\n",
      "evaluation/Estimation Bias Mean      1138.18\n",
      "evaluation/Estimation Bias Std        168.832\n",
      "evaluation/EB/Q_True Mean              49.9453\n",
      "evaluation/EB/Q_True Std              154.218\n",
      "evaluation/EB/Q_Pred Mean            1188.12\n",
      "evaluation/EB/Q_Pred Std               73.482\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5256.52\n",
      "evaluation/Actions Mean                 0.522467\n",
      "evaluation/Actions Std                  0.634139\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9759\n",
      "time/backward_zf1 (s)                   2.10298\n",
      "time/backward_zf2 (s)                   2.03625\n",
      "time/data sampling (s)                  0.277302\n",
      "time/data storing (s)                   0.0137607\n",
      "time/evaluation sampling (s)            1.35841\n",
      "time/exploration sampling (s)           0.193168\n",
      "time/logging (s)                        0.0127427\n",
      "time/preback_alpha (s)                  0.582406\n",
      "time/preback_policy (s)                 1.16371\n",
      "time/preback_start (s)                  0.128183\n",
      "time/preback_zf (s)                     5.11605\n",
      "time/saving (s)                         0.00668966\n",
      "time/training (s)                       2.15964\n",
      "time/epoch (s)                         17.1272\n",
      "time/total (s)                       3277.66\n",
      "Epoch                                 197\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:47:08.077977 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 198 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 209000\n",
      "trainer/ZF1 Loss                      164.388\n",
      "trainer/ZF2 Loss                      194.052\n",
      "trainer/ZF Expert Reward               15.0156\n",
      "trainer/ZF Policy Reward               -1.84077\n",
      "trainer/ZF CHI2 Term                  196.382\n",
      "trainer/Policy Loss                  -983.747\n",
      "trainer/Bias Loss                    1616.56\n",
      "trainer/Bias Value                     11.5403\n",
      "trainer/Policy Grad Norm              349.2\n",
      "trainer/Policy Param Norm              33.9026\n",
      "trainer/Zf1 Grad Norm                5037.73\n",
      "trainer/Zf1 Param Norm                103.36\n",
      "trainer/Zf2 Grad Norm                4294.78\n",
      "trainer/Zf2 Param Norm                101.697\n",
      "trainer/Z Expert Predictions Mean    1163.07\n",
      "trainer/Z Expert Predictions Std      108.908\n",
      "trainer/Z Expert Predictions Max     1317.15\n",
      "trainer/Z Expert Predictions Min      828.512\n",
      "trainer/Z Policy Predictions Mean     971.314\n",
      "trainer/Z Policy Predictions Std      303.863\n",
      "trainer/Z Policy Predictions Max     1309.14\n",
      "trainer/Z Policy Predictions Min       -3.26152\n",
      "trainer/Z Expert Targets Mean        1148.05\n",
      "trainer/Z Expert Targets Std          131.453\n",
      "trainer/Z Expert Targets Max         1334.79\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         973.155\n",
      "trainer/Z Policy Targets Std          302.285\n",
      "trainer/Z Policy Targets Max         1312.81\n",
      "trainer/Z Policy Targets Min           10.6379\n",
      "trainer/Log Pis Mean                   30.5805\n",
      "trainer/Log Pis Std                     7.96579\n",
      "trainer/Policy mu Mean                  1.46472\n",
      "trainer/Policy mu Std                   2.61046\n",
      "trainer/Policy log std Mean            -3.35092\n",
      "trainer/Policy log std Std              1.45714\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        202968\n",
      "exploration/num paths total           970\n",
      "evaluation/num steps total              1.42445e+06\n",
      "evaluation/num paths total           1994\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08793\n",
      "evaluation/Rewards Std                  1.29023\n",
      "evaluation/Rewards Max                  7.07848\n",
      "evaluation/Rewards Min                  0.106884\n",
      "evaluation/Returns Mean              5087.93\n",
      "evaluation/Returns Std                 60.1918\n",
      "evaluation/Returns Max               5148.39\n",
      "evaluation/Returns Min               4936.4\n",
      "evaluation/Estimation Bias Mean      1138.75\n",
      "evaluation/Estimation Bias Std        165.348\n",
      "evaluation/EB/Q_True Mean              48.6236\n",
      "evaluation/EB/Q_True Std              150.286\n",
      "evaluation/EB/Q_Pred Mean            1187.37\n",
      "evaluation/EB/Q_Pred Std               89.0761\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5087.93\n",
      "evaluation/Actions Mean                 0.499676\n",
      "evaluation/Actions Std                  0.646658\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.88508\n",
      "time/backward_zf1 (s)                   2.04876\n",
      "time/backward_zf2 (s)                   1.95026\n",
      "time/data sampling (s)                  0.267729\n",
      "time/data storing (s)                   0.0140113\n",
      "time/evaluation sampling (s)            1.43723\n",
      "time/exploration sampling (s)           0.194261\n",
      "time/logging (s)                        0.0120008\n",
      "time/preback_alpha (s)                  0.573589\n",
      "time/preback_policy (s)                 1.10528\n",
      "time/preback_start (s)                  0.122814\n",
      "time/preback_zf (s)                     5.09076\n",
      "time/saving (s)                         0.00579874\n",
      "time/training (s)                       2.24657\n",
      "time/epoch (s)                         16.9542\n",
      "time/total (s)                       3294.64\n",
      "Epoch                                 198\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:47:25.832519 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 199 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 210000\n",
      "trainer/ZF1 Loss                       39.0826\n",
      "trainer/ZF2 Loss                       30.5941\n",
      "trainer/ZF Expert Reward               15.9321\n",
      "trainer/ZF Policy Reward                2.82154\n",
      "trainer/ZF CHI2 Term                   48.2504\n",
      "trainer/Policy Loss                  -949.224\n",
      "trainer/Bias Loss                      88.9197\n",
      "trainer/Bias Value                     11.5465\n",
      "trainer/Policy Grad Norm              344.923\n",
      "trainer/Policy Param Norm              33.9376\n",
      "trainer/Zf1 Grad Norm                2896.59\n",
      "trainer/Zf1 Param Norm                103.577\n",
      "trainer/Zf2 Grad Norm                1919.25\n",
      "trainer/Zf2 Param Norm                101.908\n",
      "trainer/Z Expert Predictions Mean    1167.72\n",
      "trainer/Z Expert Predictions Std      112.049\n",
      "trainer/Z Expert Predictions Max     1323.75\n",
      "trainer/Z Expert Predictions Min      751.758\n",
      "trainer/Z Policy Predictions Mean     943.618\n",
      "trainer/Z Policy Predictions Std      334\n",
      "trainer/Z Policy Predictions Max     1286.35\n",
      "trainer/Z Policy Predictions Min      -94.3483\n",
      "trainer/Z Expert Targets Mean        1151.79\n",
      "trainer/Z Expert Targets Std          113.52\n",
      "trainer/Z Expert Targets Max         1301.1\n",
      "trainer/Z Expert Targets Min          688.912\n",
      "trainer/Z Policy Targets Mean         940.797\n",
      "trainer/Z Policy Targets Std          329.136\n",
      "trainer/Z Policy Targets Max         1265.62\n",
      "trainer/Z Policy Targets Min         -109.019\n",
      "trainer/Log Pis Mean                   30.1499\n",
      "trainer/Log Pis Std                     7.34992\n",
      "trainer/Policy mu Mean                  1.4284\n",
      "trainer/Policy mu Std                   2.49243\n",
      "trainer/Policy log std Mean            -3.42524\n",
      "trainer/Policy log std Std              1.38685\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        205968\n",
      "exploration/num paths total           973\n",
      "evaluation/num steps total              1.43445e+06\n",
      "evaluation/num paths total           2004\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.08545\n",
      "evaluation/Rewards Std                  1.28817\n",
      "evaluation/Rewards Max                  7.26054\n",
      "evaluation/Rewards Min                  0.12023\n",
      "evaluation/Returns Mean              5085.45\n",
      "evaluation/Returns Std                 28.159\n",
      "evaluation/Returns Max               5126.18\n",
      "evaluation/Returns Min               5047.24\n",
      "evaluation/Estimation Bias Mean      1138.67\n",
      "evaluation/Estimation Bias Std        154.291\n",
      "evaluation/EB/Q_True Mean              47.6711\n",
      "evaluation/EB/Q_True Std              147.238\n",
      "evaluation/EB/Q_Pred Mean            1186.34\n",
      "evaluation/EB/Q_Pred Std               74.5218\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5085.45\n",
      "evaluation/Actions Mean                 0.514538\n",
      "evaluation/Actions Std                  0.638516\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.1206\n",
      "time/backward_zf1 (s)                   2.27759\n",
      "time/backward_zf2 (s)                   2.2147\n",
      "time/data sampling (s)                  0.261082\n",
      "time/data storing (s)                   0.0140754\n",
      "time/evaluation sampling (s)            1.34865\n",
      "time/exploration sampling (s)           0.20828\n",
      "time/logging (s)                        0.0139942\n",
      "time/preback_alpha (s)                  0.585158\n",
      "time/preback_policy (s)                 1.23882\n",
      "time/preback_start (s)                  0.124798\n",
      "time/preback_zf (s)                     5.13492\n",
      "time/saving (s)                         0.00594283\n",
      "time/training (s)                       2.14056\n",
      "time/epoch (s)                         17.6892\n",
      "time/total (s)                       3312.34\n",
      "Epoch                                 199\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:47:42.773067 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 200 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 211000\n",
      "trainer/ZF1 Loss                       33.1719\n",
      "trainer/ZF2 Loss                       31.3573\n",
      "trainer/ZF Expert Reward               16.77\n",
      "trainer/ZF Policy Reward                5.25754\n",
      "trainer/ZF CHI2 Term                   44.0814\n",
      "trainer/Policy Loss                 -1013.1\n",
      "trainer/Bias Loss                     126.579\n",
      "trainer/Bias Value                     11.5525\n",
      "trainer/Policy Grad Norm              516.922\n",
      "trainer/Policy Param Norm              33.973\n",
      "trainer/Zf1 Grad Norm                3001.48\n",
      "trainer/Zf1 Param Norm                103.81\n",
      "trainer/Zf2 Grad Norm                2372.22\n",
      "trainer/Zf2 Param Norm                102.137\n",
      "trainer/Z Expert Predictions Mean    1167.09\n",
      "trainer/Z Expert Predictions Std      108.502\n",
      "trainer/Z Expert Predictions Max     1360.74\n",
      "trainer/Z Expert Predictions Min      649.836\n",
      "trainer/Z Policy Predictions Mean    1006.97\n",
      "trainer/Z Policy Predictions Std      313.561\n",
      "trainer/Z Policy Predictions Max     1311.89\n",
      "trainer/Z Policy Predictions Min     -129.108\n",
      "trainer/Z Expert Targets Mean        1150.32\n",
      "trainer/Z Expert Targets Std          106.814\n",
      "trainer/Z Expert Targets Max         1328.18\n",
      "trainer/Z Expert Targets Min          632.822\n",
      "trainer/Z Policy Targets Mean        1001.71\n",
      "trainer/Z Policy Targets Std          308.641\n",
      "trainer/Z Policy Targets Max         1286.17\n",
      "trainer/Z Policy Targets Min         -115.356\n",
      "trainer/Log Pis Mean                   30.4406\n",
      "trainer/Log Pis Std                     7.24169\n",
      "trainer/Policy mu Mean                  1.49327\n",
      "trainer/Policy mu Std                   2.54892\n",
      "trainer/Policy log std Mean            -3.28372\n",
      "trainer/Policy log std Std              1.43822\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        205968\n",
      "exploration/num paths total           973\n",
      "evaluation/num steps total              1.44445e+06\n",
      "evaluation/num paths total           2014\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10081\n",
      "evaluation/Rewards Std                  1.28648\n",
      "evaluation/Rewards Max                  7.20506\n",
      "evaluation/Rewards Min                  0.122837\n",
      "evaluation/Returns Mean              5100.81\n",
      "evaluation/Returns Std                 58.4061\n",
      "evaluation/Returns Max               5197.26\n",
      "evaluation/Returns Min               5020.67\n",
      "evaluation/Estimation Bias Mean      1071.76\n",
      "evaluation/Estimation Bias Std        228.665\n",
      "evaluation/EB/Q_True Mean              48.5547\n",
      "evaluation/EB/Q_True Std              150.236\n",
      "evaluation/EB/Q_Pred Mean            1120.32\n",
      "evaluation/EB/Q_Pred Std              175.474\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5100.81\n",
      "evaluation/Actions Mean                 0.499568\n",
      "evaluation/Actions Std                  0.653421\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80503\n",
      "time/backward_zf1 (s)                   1.96358\n",
      "time/backward_zf2 (s)                   1.87521\n",
      "time/data sampling (s)                  0.265873\n",
      "time/data storing (s)                   0.0144684\n",
      "time/evaluation sampling (s)            1.46787\n",
      "time/exploration sampling (s)           0.195818\n",
      "time/logging (s)                        0.01161\n",
      "time/preback_alpha (s)                  0.574387\n",
      "time/preback_policy (s)                 1.01139\n",
      "time/preback_start (s)                  0.124611\n",
      "time/preback_zf (s)                     5.10297\n",
      "time/saving (s)                         0.00526792\n",
      "time/training (s)                       2.4478\n",
      "time/epoch (s)                         16.8659\n",
      "time/total (s)                       3329.23\n",
      "Epoch                                 200\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:48:00.119074 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 201 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 212000\n",
      "trainer/ZF1 Loss                      103.983\n",
      "trainer/ZF2 Loss                       91.7991\n",
      "trainer/ZF Expert Reward               13.6603\n",
      "trainer/ZF Policy Reward                0.815801\n",
      "trainer/ZF CHI2 Term                  111.046\n",
      "trainer/Policy Loss                  -990.086\n",
      "trainer/Bias Loss                     125.568\n",
      "trainer/Bias Value                     11.5584\n",
      "trainer/Policy Grad Norm              411.39\n",
      "trainer/Policy Param Norm              34.0066\n",
      "trainer/Zf1 Grad Norm                3883.94\n",
      "trainer/Zf1 Param Norm                104.039\n",
      "trainer/Zf2 Grad Norm                3628.58\n",
      "trainer/Zf2 Param Norm                102.371\n",
      "trainer/Z Expert Predictions Mean    1145.97\n",
      "trainer/Z Expert Predictions Std      125.771\n",
      "trainer/Z Expert Predictions Max     1317.76\n",
      "trainer/Z Expert Predictions Min      730.148\n",
      "trainer/Z Policy Predictions Mean     981.19\n",
      "trainer/Z Policy Predictions Std      311.997\n",
      "trainer/Z Policy Predictions Max     1278.81\n",
      "trainer/Z Policy Predictions Min      -28.4866\n",
      "trainer/Z Expert Targets Mean        1132.31\n",
      "trainer/Z Expert Targets Std          126.72\n",
      "trainer/Z Expert Targets Max         1308.74\n",
      "trainer/Z Expert Targets Min          700.726\n",
      "trainer/Z Policy Targets Mean         980.375\n",
      "trainer/Z Policy Targets Std          310.402\n",
      "trainer/Z Policy Targets Max         1269.85\n",
      "trainer/Z Policy Targets Min          -27.6502\n",
      "trainer/Log Pis Mean                   31.0695\n",
      "trainer/Log Pis Std                     7.86913\n",
      "trainer/Policy mu Mean                  1.4494\n",
      "trainer/Policy mu Std                   2.62129\n",
      "trainer/Policy log std Mean            -3.44182\n",
      "trainer/Policy log std Std              1.4135\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        206968\n",
      "exploration/num paths total           974\n",
      "evaluation/num steps total              1.45445e+06\n",
      "evaluation/num paths total           2024\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1077\n",
      "evaluation/Rewards Std                  1.30675\n",
      "evaluation/Rewards Max                  7.16946\n",
      "evaluation/Rewards Min                  0.116372\n",
      "evaluation/Returns Mean              5107.7\n",
      "evaluation/Returns Std                 14.6429\n",
      "evaluation/Returns Max               5125.98\n",
      "evaluation/Returns Min               5081.09\n",
      "evaluation/Estimation Bias Mean      1128.26\n",
      "evaluation/Estimation Bias Std        166.913\n",
      "evaluation/EB/Q_True Mean              48.4808\n",
      "evaluation/EB/Q_True Std              149.586\n",
      "evaluation/EB/Q_Pred Mean            1176.74\n",
      "evaluation/EB/Q_Pred Std               78.3534\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5107.7\n",
      "evaluation/Actions Mean                 0.506949\n",
      "evaluation/Actions Std                  0.644533\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99684\n",
      "time/backward_zf1 (s)                   2.1461\n",
      "time/backward_zf2 (s)                   2.08567\n",
      "time/data sampling (s)                  0.279502\n",
      "time/data storing (s)                   0.0148592\n",
      "time/evaluation sampling (s)            1.40552\n",
      "time/exploration sampling (s)           0.202396\n",
      "time/logging (s)                        0.0117355\n",
      "time/preback_alpha (s)                  0.577715\n",
      "time/preback_policy (s)                 1.16663\n",
      "time/preback_start (s)                  0.125493\n",
      "time/preback_zf (s)                     5.09514\n",
      "time/saving (s)                         0.0057663\n",
      "time/training (s)                       2.16594\n",
      "time/epoch (s)                         17.2793\n",
      "time/total (s)                       3346.53\n",
      "Epoch                                 201\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:48:17.585328 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 202 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 213000\n",
      "trainer/ZF1 Loss                      108.353\n",
      "trainer/ZF2 Loss                      178.853\n",
      "trainer/ZF Expert Reward               18.7662\n",
      "trainer/ZF Policy Reward                4.15067\n",
      "trainer/ZF CHI2 Term                  158.524\n",
      "trainer/Policy Loss                 -1003.38\n",
      "trainer/Bias Loss                    1252.2\n",
      "trainer/Bias Value                     11.5646\n",
      "trainer/Policy Grad Norm              438.552\n",
      "trainer/Policy Param Norm              34.051\n",
      "trainer/Zf1 Grad Norm                9345.96\n",
      "trainer/Zf1 Param Norm                104.283\n",
      "trainer/Zf2 Grad Norm               10126.5\n",
      "trainer/Zf2 Param Norm                102.614\n",
      "trainer/Z Expert Predictions Mean    1161.43\n",
      "trainer/Z Expert Predictions Std      118.696\n",
      "trainer/Z Expert Predictions Max     1341.57\n",
      "trainer/Z Expert Predictions Min      689.851\n",
      "trainer/Z Policy Predictions Mean     996.759\n",
      "trainer/Z Policy Predictions Std      296.329\n",
      "trainer/Z Policy Predictions Max     1302.23\n",
      "trainer/Z Policy Predictions Min      -70.283\n",
      "trainer/Z Expert Targets Mean        1142.66\n",
      "trainer/Z Expert Targets Std          136.962\n",
      "trainer/Z Expert Targets Max         1357.82\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         992.608\n",
      "trainer/Z Policy Targets Std          293.27\n",
      "trainer/Z Policy Targets Max         1293.66\n",
      "trainer/Z Policy Targets Min          -50.4457\n",
      "trainer/Log Pis Mean                   30.5737\n",
      "trainer/Log Pis Std                     8.01506\n",
      "trainer/Policy mu Mean                  1.46172\n",
      "trainer/Policy mu Std                   2.46344\n",
      "trainer/Policy log std Mean            -3.47868\n",
      "trainer/Policy log std Std              1.45985\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        206968\n",
      "exploration/num paths total           974\n",
      "evaluation/num steps total              1.46445e+06\n",
      "evaluation/num paths total           2034\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16\n",
      "evaluation/Rewards Std                  1.3087\n",
      "evaluation/Rewards Max                  7.12787\n",
      "evaluation/Rewards Min                  0.105242\n",
      "evaluation/Returns Mean              5160\n",
      "evaluation/Returns Std                 27.0927\n",
      "evaluation/Returns Max               5198.13\n",
      "evaluation/Returns Min               5108.3\n",
      "evaluation/Estimation Bias Mean      1068.57\n",
      "evaluation/Estimation Bias Std        205.707\n",
      "evaluation/EB/Q_True Mean              48.6542\n",
      "evaluation/EB/Q_True Std              150.305\n",
      "evaluation/EB/Q_Pred Mean            1117.22\n",
      "evaluation/EB/Q_Pred Std              167.505\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5160\n",
      "evaluation/Actions Mean                 0.513817\n",
      "evaluation/Actions Std                  0.644711\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.0057\n",
      "time/backward_zf1 (s)                   2.1506\n",
      "time/backward_zf2 (s)                   2.06465\n",
      "time/data sampling (s)                  0.272682\n",
      "time/data storing (s)                   0.0147694\n",
      "time/evaluation sampling (s)            1.45449\n",
      "time/exploration sampling (s)           0.197197\n",
      "time/logging (s)                        0.0139174\n",
      "time/preback_alpha (s)                  0.577512\n",
      "time/preback_policy (s)                 1.18622\n",
      "time/preback_start (s)                  0.125432\n",
      "time/preback_zf (s)                     5.10793\n",
      "time/saving (s)                         0.0241889\n",
      "time/training (s)                       2.20504\n",
      "time/epoch (s)                         17.4003\n",
      "time/total (s)                       3363.95\n",
      "Epoch                                 202\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:48:34.931411 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 203 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 214000\n",
      "trainer/ZF1 Loss                       53.9933\n",
      "trainer/ZF2 Loss                       83.553\n",
      "trainer/ZF Expert Reward                8.74137\n",
      "trainer/ZF Policy Reward               -1.07617\n",
      "trainer/ZF CHI2 Term                   78.8953\n",
      "trainer/Policy Loss                  -998.649\n",
      "trainer/Bias Loss                     427.501\n",
      "trainer/Bias Value                     11.571\n",
      "trainer/Policy Grad Norm              302.89\n",
      "trainer/Policy Param Norm              34.0818\n",
      "trainer/Zf1 Grad Norm                5549.94\n",
      "trainer/Zf1 Param Norm                104.495\n",
      "trainer/Zf2 Grad Norm                6351.58\n",
      "trainer/Zf2 Param Norm                102.822\n",
      "trainer/Z Expert Predictions Mean    1146.96\n",
      "trainer/Z Expert Predictions Std      115.175\n",
      "trainer/Z Expert Predictions Max     1301.96\n",
      "trainer/Z Expert Predictions Min      382.97\n",
      "trainer/Z Policy Predictions Mean     992.998\n",
      "trainer/Z Policy Predictions Std      276.065\n",
      "trainer/Z Policy Predictions Max     1294.21\n",
      "trainer/Z Policy Predictions Min     -114.63\n",
      "trainer/Z Expert Targets Mean        1138.22\n",
      "trainer/Z Expert Targets Std          127.96\n",
      "trainer/Z Expert Targets Max         1309.61\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         994.074\n",
      "trainer/Z Policy Targets Std          274.714\n",
      "trainer/Z Policy Targets Max         1298.92\n",
      "trainer/Z Policy Targets Min          -79.5889\n",
      "trainer/Log Pis Mean                   30.4606\n",
      "trainer/Log Pis Std                     6.49883\n",
      "trainer/Policy mu Mean                  1.44594\n",
      "trainer/Policy mu Std                   2.34818\n",
      "trainer/Policy log std Mean            -3.46702\n",
      "trainer/Policy log std Std              1.34887\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        209924\n",
      "exploration/num paths total           977\n",
      "evaluation/num steps total              1.47445e+06\n",
      "evaluation/num paths total           2044\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.99836\n",
      "evaluation/Rewards Std                  1.28562\n",
      "evaluation/Rewards Max                  7.11371\n",
      "evaluation/Rewards Min                  0.0953735\n",
      "evaluation/Returns Mean              4998.36\n",
      "evaluation/Returns Std                 93.2545\n",
      "evaluation/Returns Max               5083.53\n",
      "evaluation/Returns Min               4791.09\n",
      "evaluation/Estimation Bias Mean      1102.89\n",
      "evaluation/Estimation Bias Std        167.514\n",
      "evaluation/EB/Q_True Mean              47.8095\n",
      "evaluation/EB/Q_True Std              147.513\n",
      "evaluation/EB/Q_Pred Mean            1150.7\n",
      "evaluation/EB/Q_Pred Std               95.5106\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4998.36\n",
      "evaluation/Actions Mean                 0.512148\n",
      "evaluation/Actions Std                  0.638032\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.0023\n",
      "time/backward_zf1 (s)                   2.16102\n",
      "time/backward_zf2 (s)                   2.09577\n",
      "time/data sampling (s)                  0.262086\n",
      "time/data storing (s)                   0.0135676\n",
      "time/evaluation sampling (s)            1.4277\n",
      "time/exploration sampling (s)           0.200024\n",
      "time/logging (s)                        0.0124882\n",
      "time/preback_alpha (s)                  0.577592\n",
      "time/preback_policy (s)                 1.18338\n",
      "time/preback_start (s)                  0.126338\n",
      "time/preback_zf (s)                     5.08251\n",
      "time/saving (s)                         0.00591771\n",
      "time/training (s)                       2.12395\n",
      "time/epoch (s)                         17.2746\n",
      "time/total (s)                       3381.25\n",
      "Epoch                                 203\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:48:52.111566 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 204 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 215000\n",
      "trainer/ZF1 Loss                       23.9486\n",
      "trainer/ZF2 Loss                       26.1699\n",
      "trainer/ZF Expert Reward               13.3344\n",
      "trainer/ZF Policy Reward                0.106979\n",
      "trainer/ZF CHI2 Term                   38.5999\n",
      "trainer/Policy Loss                 -1012.39\n",
      "trainer/Bias Loss                     101.857\n",
      "trainer/Bias Value                     11.5772\n",
      "trainer/Policy Grad Norm              419.692\n",
      "trainer/Policy Param Norm              34.1143\n",
      "trainer/Zf1 Grad Norm                2152.24\n",
      "trainer/Zf1 Param Norm                104.735\n",
      "trainer/Zf2 Grad Norm                2229.41\n",
      "trainer/Zf2 Param Norm                103.055\n",
      "trainer/Z Expert Predictions Mean    1163.38\n",
      "trainer/Z Expert Predictions Std      117.041\n",
      "trainer/Z Expert Predictions Max     1373.35\n",
      "trainer/Z Expert Predictions Min      107.039\n",
      "trainer/Z Policy Predictions Mean     998.024\n",
      "trainer/Z Policy Predictions Std      308.071\n",
      "trainer/Z Policy Predictions Max     1322.43\n",
      "trainer/Z Policy Predictions Min      -49.7543\n",
      "trainer/Z Expert Targets Mean        1150.04\n",
      "trainer/Z Expert Targets Std          123.045\n",
      "trainer/Z Expert Targets Max         1365.27\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         997.917\n",
      "trainer/Z Policy Targets Std          303.518\n",
      "trainer/Z Policy Targets Max         1317.45\n",
      "trainer/Z Policy Targets Min          -50.8829\n",
      "trainer/Log Pis Mean                   31.3156\n",
      "trainer/Log Pis Std                     7.04662\n",
      "trainer/Policy mu Mean                  1.43439\n",
      "trainer/Policy mu Std                   2.52196\n",
      "trainer/Policy log std Mean            -3.4333\n",
      "trainer/Policy log std Std              1.47783\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        210924\n",
      "exploration/num paths total           978\n",
      "evaluation/num steps total              1.48392e+06\n",
      "evaluation/num paths total           2054\n",
      "evaluation/path length Mean           947.2\n",
      "evaluation/path length Std             92.8933\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            708\n",
      "evaluation/Rewards Mean                 5.0303\n",
      "evaluation/Rewards Std                  1.30056\n",
      "evaluation/Rewards Max                  7.05055\n",
      "evaluation/Rewards Min                  0.101127\n",
      "evaluation/Returns Mean              4764.7\n",
      "evaluation/Returns Std                514.642\n",
      "evaluation/Returns Max               5120.29\n",
      "evaluation/Returns Min               3432.52\n",
      "evaluation/Estimation Bias Mean       996.547\n",
      "evaluation/Estimation Bias Std        301.29\n",
      "evaluation/EB/Q_True Mean              50.1675\n",
      "evaluation/EB/Q_True Std              150.395\n",
      "evaluation/EB/Q_Pred Mean            1046.71\n",
      "evaluation/EB/Q_Pred Std              237.278\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4764.7\n",
      "evaluation/Actions Mean                 0.507888\n",
      "evaluation/Actions Std                  0.654058\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.87614\n",
      "time/backward_zf1 (s)                   2.03497\n",
      "time/backward_zf2 (s)                   1.96087\n",
      "time/data sampling (s)                  0.268075\n",
      "time/data storing (s)                   0.0153357\n",
      "time/evaluation sampling (s)            1.46762\n",
      "time/exploration sampling (s)           0.205496\n",
      "time/logging (s)                        0.0114134\n",
      "time/preback_alpha (s)                  0.581325\n",
      "time/preback_policy (s)                 1.08989\n",
      "time/preback_start (s)                  0.125984\n",
      "time/preback_zf (s)                     5.13263\n",
      "time/saving (s)                         0.00566126\n",
      "time/training (s)                       2.33474\n",
      "time/epoch (s)                         17.1101\n",
      "time/total (s)                       3398.38\n",
      "Epoch                                 204\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:49:09.510167 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 205 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 216000\n",
      "trainer/ZF1 Loss                       38.8733\n",
      "trainer/ZF2 Loss                       36.1864\n",
      "trainer/ZF Expert Reward                9.47368\n",
      "trainer/ZF Policy Reward               -4.29505\n",
      "trainer/ZF CHI2 Term                   51.6044\n",
      "trainer/Policy Loss                  -960.348\n",
      "trainer/Bias Loss                     118.483\n",
      "trainer/Bias Value                     11.5834\n",
      "trainer/Policy Grad Norm              419.111\n",
      "trainer/Policy Param Norm              34.1488\n",
      "trainer/Zf1 Grad Norm                3480.57\n",
      "trainer/Zf1 Param Norm                104.952\n",
      "trainer/Zf2 Grad Norm                3613.67\n",
      "trainer/Zf2 Param Norm                103.262\n",
      "trainer/Z Expert Predictions Mean    1156.97\n",
      "trainer/Z Expert Predictions Std      109.89\n",
      "trainer/Z Expert Predictions Max     1352.64\n",
      "trainer/Z Expert Predictions Min      711.209\n",
      "trainer/Z Policy Predictions Mean     948.058\n",
      "trainer/Z Policy Predictions Std      332.436\n",
      "trainer/Z Policy Predictions Max     1268.43\n",
      "trainer/Z Policy Predictions Min      -75.918\n",
      "trainer/Z Expert Targets Mean        1147.49\n",
      "trainer/Z Expert Targets Std          109.371\n",
      "trainer/Z Expert Targets Max         1364.55\n",
      "trainer/Z Expert Targets Min          701.283\n",
      "trainer/Z Policy Targets Mean         952.353\n",
      "trainer/Z Policy Targets Std          328.462\n",
      "trainer/Z Policy Targets Max         1271.63\n",
      "trainer/Z Policy Targets Min          -72.9783\n",
      "trainer/Log Pis Mean                   30.5837\n",
      "trainer/Log Pis Std                     8.24988\n",
      "trainer/Policy mu Mean                  1.47248\n",
      "trainer/Policy mu Std                   2.60762\n",
      "trainer/Policy log std Mean            -3.37393\n",
      "trainer/Policy log std Std              1.44004\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        210924\n",
      "exploration/num paths total           978\n",
      "evaluation/num steps total              1.49324e+06\n",
      "evaluation/num paths total           2064\n",
      "evaluation/path length Mean           931.7\n",
      "evaluation/path length Std            138.528\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            607\n",
      "evaluation/Rewards Mean                 5.10457\n",
      "evaluation/Rewards Std                  1.32761\n",
      "evaluation/Rewards Max                  7.24091\n",
      "evaluation/Rewards Min                  0.122569\n",
      "evaluation/Returns Mean              4755.93\n",
      "evaluation/Returns Std                767.655\n",
      "evaluation/Returns Max               5173.58\n",
      "evaluation/Returns Min               2970.01\n",
      "evaluation/Estimation Bias Mean       984.564\n",
      "evaluation/Estimation Bias Std        299.907\n",
      "evaluation/EB/Q_True Mean              52.4153\n",
      "evaluation/EB/Q_True Std              155.689\n",
      "evaluation/EB/Q_Pred Mean            1036.98\n",
      "evaluation/EB/Q_Pred Std              250.211\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4755.93\n",
      "evaluation/Actions Mean                 0.505829\n",
      "evaluation/Actions Std                  0.654118\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99864\n",
      "time/backward_zf1 (s)                   2.13109\n",
      "time/backward_zf2 (s)                   2.06556\n",
      "time/data sampling (s)                  0.27593\n",
      "time/data storing (s)                   0.0137826\n",
      "time/evaluation sampling (s)            1.50292\n",
      "time/exploration sampling (s)           0.193913\n",
      "time/logging (s)                        0.0125534\n",
      "time/preback_alpha (s)                  0.577698\n",
      "time/preback_policy (s)                 1.17729\n",
      "time/preback_start (s)                  0.124908\n",
      "time/preback_zf (s)                     5.10354\n",
      "time/saving (s)                         0.0205925\n",
      "time/training (s)                       2.13447\n",
      "time/epoch (s)                         17.3329\n",
      "time/total (s)                       3415.73\n",
      "Epoch                                 205\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:49:26.939512 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 206 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 217000\n",
      "trainer/ZF1 Loss                       42.4385\n",
      "trainer/ZF2 Loss                       34.9248\n",
      "trainer/ZF Expert Reward               11.377\n",
      "trainer/ZF Policy Reward               -1.08388\n",
      "trainer/ZF CHI2 Term                   51.4468\n",
      "trainer/Policy Loss                  -948.733\n",
      "trainer/Bias Loss                      76.8418\n",
      "trainer/Bias Value                     11.5895\n",
      "trainer/Policy Grad Norm              331.923\n",
      "trainer/Policy Param Norm              34.1838\n",
      "trainer/Zf1 Grad Norm                3062.75\n",
      "trainer/Zf1 Param Norm                105.165\n",
      "trainer/Zf2 Grad Norm                2558.51\n",
      "trainer/Zf2 Param Norm                103.473\n",
      "trainer/Z Expert Predictions Mean    1159.32\n",
      "trainer/Z Expert Predictions Std       98.3846\n",
      "trainer/Z Expert Predictions Max     1310.42\n",
      "trainer/Z Expert Predictions Min      810.51\n",
      "trainer/Z Policy Predictions Mean     937.806\n",
      "trainer/Z Policy Predictions Std      316.195\n",
      "trainer/Z Policy Predictions Max     1260.66\n",
      "trainer/Z Policy Predictions Min      -48.5938\n",
      "trainer/Z Expert Targets Mean        1147.95\n",
      "trainer/Z Expert Targets Std           97.9218\n",
      "trainer/Z Expert Targets Max         1310.92\n",
      "trainer/Z Expert Targets Min          812.612\n",
      "trainer/Z Policy Targets Mean         938.89\n",
      "trainer/Z Policy Targets Std          311.889\n",
      "trainer/Z Policy Targets Max         1262.66\n",
      "trainer/Z Policy Targets Min          -29.1784\n",
      "trainer/Log Pis Mean                   30.423\n",
      "trainer/Log Pis Std                     7.62664\n",
      "trainer/Policy mu Mean                  1.48617\n",
      "trainer/Policy mu Std                   2.49856\n",
      "trainer/Policy log std Mean            -3.37327\n",
      "trainer/Policy log std Std              1.43397\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        212924\n",
      "exploration/num paths total           980\n",
      "evaluation/num steps total              1.50307e+06\n",
      "evaluation/num paths total           2074\n",
      "evaluation/path length Mean           983.9\n",
      "evaluation/path length Std             48.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            839\n",
      "evaluation/Rewards Mean                 5.05323\n",
      "evaluation/Rewards Std                  1.28583\n",
      "evaluation/Rewards Max                  7.04522\n",
      "evaluation/Rewards Min                  0.125375\n",
      "evaluation/Returns Mean              4971.87\n",
      "evaluation/Returns Std                260.585\n",
      "evaluation/Returns Max               5131.26\n",
      "evaluation/Returns Min               4199.5\n",
      "evaluation/Estimation Bias Mean      1078.85\n",
      "evaluation/Estimation Bias Std        250.584\n",
      "evaluation/EB/Q_True Mean              48.7232\n",
      "evaluation/EB/Q_True Std              149.026\n",
      "evaluation/EB/Q_Pred Mean            1127.58\n",
      "evaluation/EB/Q_Pred Std              156.806\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4971.87\n",
      "evaluation/Actions Mean                 0.499841\n",
      "evaluation/Actions Std                  0.643889\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98967\n",
      "time/backward_zf1 (s)                   2.14951\n",
      "time/backward_zf2 (s)                   2.06425\n",
      "time/data sampling (s)                  0.28728\n",
      "time/data storing (s)                   0.0152566\n",
      "time/evaluation sampling (s)            1.44036\n",
      "time/exploration sampling (s)           0.210363\n",
      "time/logging (s)                        0.0123118\n",
      "time/preback_alpha (s)                  0.583738\n",
      "time/preback_policy (s)                 1.17403\n",
      "time/preback_start (s)                  0.126731\n",
      "time/preback_zf (s)                     5.12164\n",
      "time/saving (s)                         0.00577263\n",
      "time/training (s)                       2.17613\n",
      "time/epoch (s)                         17.357\n",
      "time/total (s)                       3433.11\n",
      "Epoch                                 206\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:49:44.189526 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 207 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 218000\n",
      "trainer/ZF1 Loss                       46.7545\n",
      "trainer/ZF2 Loss                       46.9658\n",
      "trainer/ZF Expert Reward               12.6218\n",
      "trainer/ZF Policy Reward                0.848136\n",
      "trainer/ZF CHI2 Term                   58.9355\n",
      "trainer/Policy Loss                  -970.529\n",
      "trainer/Bias Loss                     125.267\n",
      "trainer/Bias Value                     11.5956\n",
      "trainer/Policy Grad Norm              567.678\n",
      "trainer/Policy Param Norm              34.2163\n",
      "trainer/Zf1 Grad Norm                4619.12\n",
      "trainer/Zf1 Param Norm                105.393\n",
      "trainer/Zf2 Grad Norm                3912.61\n",
      "trainer/Zf2 Param Norm                103.692\n",
      "trainer/Z Expert Predictions Mean    1152.72\n",
      "trainer/Z Expert Predictions Std      119.269\n",
      "trainer/Z Expert Predictions Max     1334.11\n",
      "trainer/Z Expert Predictions Min      619.292\n",
      "trainer/Z Policy Predictions Mean     964.751\n",
      "trainer/Z Policy Predictions Std      315.295\n",
      "trainer/Z Policy Predictions Max     1310.95\n",
      "trainer/Z Policy Predictions Min      -83.7845\n",
      "trainer/Z Expert Targets Mean        1140.1\n",
      "trainer/Z Expert Targets Std          118.326\n",
      "trainer/Z Expert Targets Max         1296.3\n",
      "trainer/Z Expert Targets Min          622.16\n",
      "trainer/Z Policy Targets Mean         963.903\n",
      "trainer/Z Policy Targets Std          314.952\n",
      "trainer/Z Policy Targets Max         1296.77\n",
      "trainer/Z Policy Targets Min          -99.3828\n",
      "trainer/Log Pis Mean                   30.1743\n",
      "trainer/Log Pis Std                     7.33764\n",
      "trainer/Policy mu Mean                  1.43959\n",
      "trainer/Policy mu Std                   2.51511\n",
      "trainer/Policy log std Mean            -3.42947\n",
      "trainer/Policy log std Std              1.42597\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        212924\n",
      "exploration/num paths total           980\n",
      "evaluation/num steps total              1.51307e+06\n",
      "evaluation/num paths total           2084\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09182\n",
      "evaluation/Rewards Std                  1.28282\n",
      "evaluation/Rewards Max                  7.21352\n",
      "evaluation/Rewards Min                  0.116808\n",
      "evaluation/Returns Mean              5091.82\n",
      "evaluation/Returns Std                 22.9206\n",
      "evaluation/Returns Max               5143.05\n",
      "evaluation/Returns Min               5056.85\n",
      "evaluation/Estimation Bias Mean      1029.29\n",
      "evaluation/Estimation Bias Std        249.728\n",
      "evaluation/EB/Q_True Mean              48.597\n",
      "evaluation/EB/Q_True Std              150.2\n",
      "evaluation/EB/Q_Pred Mean            1077.89\n",
      "evaluation/EB/Q_Pred Std              197.299\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5091.82\n",
      "evaluation/Actions Mean                 0.500601\n",
      "evaluation/Actions Std                  0.651686\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90405\n",
      "time/backward_zf1 (s)                   2.05098\n",
      "time/backward_zf2 (s)                   1.96398\n",
      "time/data sampling (s)                  0.292385\n",
      "time/data storing (s)                   0.0162949\n",
      "time/evaluation sampling (s)            1.46279\n",
      "time/exploration sampling (s)           0.196376\n",
      "time/logging (s)                        0.0134321\n",
      "time/preback_alpha (s)                  0.581259\n",
      "time/preback_policy (s)                 1.10659\n",
      "time/preback_start (s)                  0.128875\n",
      "time/preback_zf (s)                     5.12907\n",
      "time/saving (s)                         0.0100013\n",
      "time/training (s)                       2.32055\n",
      "time/epoch (s)                         17.1766\n",
      "time/total (s)                       3450.31\n",
      "Epoch                                 207\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:50:01.408449 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 208 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 219000\n",
      "trainer/ZF1 Loss                       20.6195\n",
      "trainer/ZF2 Loss                       24.5251\n",
      "trainer/ZF Expert Reward               11.7629\n",
      "trainer/ZF Policy Reward                0.276123\n",
      "trainer/ZF CHI2 Term                   34.3678\n",
      "trainer/Policy Loss                  -997.928\n",
      "trainer/Bias Loss                     115.262\n",
      "trainer/Bias Value                     11.6016\n",
      "trainer/Policy Grad Norm              267.624\n",
      "trainer/Policy Param Norm              34.2533\n",
      "trainer/Zf1 Grad Norm                1919.02\n",
      "trainer/Zf1 Param Norm                105.599\n",
      "trainer/Zf2 Grad Norm                2863.07\n",
      "trainer/Zf2 Param Norm                103.899\n",
      "trainer/Z Expert Predictions Mean    1145.09\n",
      "trainer/Z Expert Predictions Std      104.249\n",
      "trainer/Z Expert Predictions Max     1295.69\n",
      "trainer/Z Expert Predictions Min      768.621\n",
      "trainer/Z Policy Predictions Mean     988.466\n",
      "trainer/Z Policy Predictions Std      306.151\n",
      "trainer/Z Policy Predictions Max     1276.83\n",
      "trainer/Z Policy Predictions Min      -45.3341\n",
      "trainer/Z Expert Targets Mean        1133.32\n",
      "trainer/Z Expert Targets Std          106.496\n",
      "trainer/Z Expert Targets Max         1294.13\n",
      "trainer/Z Expert Targets Min          741.769\n",
      "trainer/Z Policy Targets Mean         988.19\n",
      "trainer/Z Policy Targets Std          303.073\n",
      "trainer/Z Policy Targets Max         1269.74\n",
      "trainer/Z Policy Targets Min          -38.6348\n",
      "trainer/Log Pis Mean                   30.8642\n",
      "trainer/Log Pis Std                     7.82375\n",
      "trainer/Policy mu Mean                  1.42516\n",
      "trainer/Policy mu Std                   2.5189\n",
      "trainer/Policy log std Mean            -3.46679\n",
      "trainer/Policy log std Std              1.49972\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        212924\n",
      "exploration/num paths total           980\n",
      "evaluation/num steps total              1.52302e+06\n",
      "evaluation/num paths total           2094\n",
      "evaluation/path length Mean           994.8\n",
      "evaluation/path length Std             15.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            948\n",
      "evaluation/Rewards Mean                 5.10553\n",
      "evaluation/Rewards Std                  1.29083\n",
      "evaluation/Rewards Max                  7.11061\n",
      "evaluation/Rewards Min                  0.120499\n",
      "evaluation/Returns Mean              5078.99\n",
      "evaluation/Returns Std                 94.1764\n",
      "evaluation/Returns Max               5161.19\n",
      "evaluation/Returns Min               4811.79\n",
      "evaluation/Estimation Bias Mean      1054.14\n",
      "evaluation/Estimation Bias Std        259.554\n",
      "evaluation/EB/Q_True Mean              48.1664\n",
      "evaluation/EB/Q_True Std              148.49\n",
      "evaluation/EB/Q_Pred Mean            1102.3\n",
      "evaluation/EB/Q_Pred Std              203.563\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5078.99\n",
      "evaluation/Actions Mean                 0.492259\n",
      "evaluation/Actions Std                  0.651377\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95054\n",
      "time/backward_zf1 (s)                   2.0868\n",
      "time/backward_zf2 (s)                   2.02935\n",
      "time/data sampling (s)                  0.285066\n",
      "time/data storing (s)                   0.0139311\n",
      "time/evaluation sampling (s)            1.46215\n",
      "time/exploration sampling (s)           0.192619\n",
      "time/logging (s)                        0.0114802\n",
      "time/preback_alpha (s)                  0.575676\n",
      "time/preback_policy (s)                 1.12056\n",
      "time/preback_start (s)                  0.125286\n",
      "time/preback_zf (s)                     5.10421\n",
      "time/saving (s)                         0.00553045\n",
      "time/training (s)                       2.18434\n",
      "time/epoch (s)                         17.1476\n",
      "time/total (s)                       3467.48\n",
      "Epoch                                 208\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:50:18.398687 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 209 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 220000\n",
      "trainer/ZF1 Loss                       21.4387\n",
      "trainer/ZF2 Loss                       27.7872\n",
      "trainer/ZF Expert Reward               17.8316\n",
      "trainer/ZF Policy Reward                2.92555\n",
      "trainer/ZF CHI2 Term                   39.8183\n",
      "trainer/Policy Loss                  -985.311\n",
      "trainer/Bias Loss                     133.783\n",
      "trainer/Bias Value                     11.6076\n",
      "trainer/Policy Grad Norm              410.624\n",
      "trainer/Policy Param Norm              34.2867\n",
      "trainer/Zf1 Grad Norm                2497.21\n",
      "trainer/Zf1 Param Norm                105.8\n",
      "trainer/Zf2 Grad Norm                2925.27\n",
      "trainer/Zf2 Param Norm                104.1\n",
      "trainer/Z Expert Predictions Mean    1151.5\n",
      "trainer/Z Expert Predictions Std      119.076\n",
      "trainer/Z Expert Predictions Max     1325.52\n",
      "trainer/Z Expert Predictions Min      112.35\n",
      "trainer/Z Policy Predictions Mean     979.128\n",
      "trainer/Z Policy Predictions Std      312.749\n",
      "trainer/Z Policy Predictions Max     1293.34\n",
      "trainer/Z Policy Predictions Min      -12.841\n",
      "trainer/Z Expert Targets Mean        1133.67\n",
      "trainer/Z Expert Targets Std          125.012\n",
      "trainer/Z Expert Targets Max         1314.76\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         976.202\n",
      "trainer/Z Policy Targets Std          307.983\n",
      "trainer/Z Policy Targets Max         1291.72\n",
      "trainer/Z Policy Targets Min           -7.85633\n",
      "trainer/Log Pis Mean                   29.9279\n",
      "trainer/Log Pis Std                     7.54382\n",
      "trainer/Policy mu Mean                  1.45395\n",
      "trainer/Policy mu Std                   2.47992\n",
      "trainer/Policy log std Mean            -3.37875\n",
      "trainer/Policy log std Std              1.49434\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        215924\n",
      "exploration/num paths total           983\n",
      "evaluation/num steps total              1.53302e+06\n",
      "evaluation/num paths total           2104\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10661\n",
      "evaluation/Rewards Std                  1.3022\n",
      "evaluation/Rewards Max                  7.10635\n",
      "evaluation/Rewards Min                  0.103432\n",
      "evaluation/Returns Mean              5106.61\n",
      "evaluation/Returns Std                 28.4532\n",
      "evaluation/Returns Max               5151.99\n",
      "evaluation/Returns Min               5070.21\n",
      "evaluation/Estimation Bias Mean      1069.46\n",
      "evaluation/Estimation Bias Std        193.01\n",
      "evaluation/EB/Q_True Mean              47.9585\n",
      "evaluation/EB/Q_True Std              148.161\n",
      "evaluation/EB/Q_Pred Mean            1117.41\n",
      "evaluation/EB/Q_Pred Std              128\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5106.61\n",
      "evaluation/Actions Mean                 0.504812\n",
      "evaluation/Actions Std                  0.64902\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86847\n",
      "time/backward_zf1 (s)                   2.00759\n",
      "time/backward_zf2 (s)                   1.93584\n",
      "time/data sampling (s)                  0.267579\n",
      "time/data storing (s)                   0.0142753\n",
      "time/evaluation sampling (s)            1.40131\n",
      "time/exploration sampling (s)           0.202641\n",
      "time/logging (s)                        0.0118603\n",
      "time/preback_alpha (s)                  0.577015\n",
      "time/preback_policy (s)                 1.0644\n",
      "time/preback_start (s)                  0.126377\n",
      "time/preback_zf (s)                     5.08358\n",
      "time/saving (s)                         0.00580659\n",
      "time/training (s)                       2.35662\n",
      "time/epoch (s)                         16.9234\n",
      "time/total (s)                       3484.42\n",
      "Epoch                                 209\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:50:35.605385 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 210 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 221000\n",
      "trainer/ZF1 Loss                      297.707\n",
      "trainer/ZF2 Loss                      284.405\n",
      "trainer/ZF Expert Reward               13.5207\n",
      "trainer/ZF Policy Reward                4.80875\n",
      "trainer/ZF CHI2 Term                  300.077\n",
      "trainer/Policy Loss                  -968.513\n",
      "trainer/Bias Loss                     149.246\n",
      "trainer/Bias Value                     11.6138\n",
      "trainer/Policy Grad Norm              458.502\n",
      "trainer/Policy Param Norm              34.3165\n",
      "trainer/Zf1 Grad Norm                3485.99\n",
      "trainer/Zf1 Param Norm                106.017\n",
      "trainer/Zf2 Grad Norm                3905.17\n",
      "trainer/Zf2 Param Norm                104.318\n",
      "trainer/Z Expert Predictions Mean    1153.59\n",
      "trainer/Z Expert Predictions Std       96.1873\n",
      "trainer/Z Expert Predictions Max     1315.23\n",
      "trainer/Z Expert Predictions Min      775.209\n",
      "trainer/Z Policy Predictions Mean     958.673\n",
      "trainer/Z Policy Predictions Std      327.973\n",
      "trainer/Z Policy Predictions Max     1261.84\n",
      "trainer/Z Policy Predictions Min      -45.1243\n",
      "trainer/Z Expert Targets Mean        1140.07\n",
      "trainer/Z Expert Targets Std           97.4845\n",
      "trainer/Z Expert Targets Max         1284.8\n",
      "trainer/Z Expert Targets Min          732.884\n",
      "trainer/Z Policy Targets Mean         953.864\n",
      "trainer/Z Policy Targets Std          327.551\n",
      "trainer/Z Policy Targets Max         1271.35\n",
      "trainer/Z Policy Targets Min          -58.1567\n",
      "trainer/Log Pis Mean                   30.888\n",
      "trainer/Log Pis Std                     8.94901\n",
      "trainer/Policy mu Mean                  1.48584\n",
      "trainer/Policy mu Std                   2.71864\n",
      "trainer/Policy log std Mean            -3.33229\n",
      "trainer/Policy log std Std              1.47793\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        215924\n",
      "exploration/num paths total           983\n",
      "evaluation/num steps total              1.54191e+06\n",
      "evaluation/num paths total           2114\n",
      "evaluation/path length Mean           888.4\n",
      "evaluation/path length Std            165.53\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            565\n",
      "evaluation/Rewards Mean                 5.0381\n",
      "evaluation/Rewards Std                  1.34245\n",
      "evaluation/Rewards Max                  7.02784\n",
      "evaluation/Rewards Min                  0.110009\n",
      "evaluation/Returns Mean              4475.85\n",
      "evaluation/Returns Std                924.352\n",
      "evaluation/Returns Max               5124.43\n",
      "evaluation/Returns Min               2692.39\n",
      "evaluation/Estimation Bias Mean       979.953\n",
      "evaluation/Estimation Bias Std        341.272\n",
      "evaluation/EB/Q_True Mean              54.544\n",
      "evaluation/EB/Q_True Std              157.717\n",
      "evaluation/EB/Q_Pred Mean            1034.5\n",
      "evaluation/EB/Q_Pred Std              291.764\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4475.85\n",
      "evaluation/Actions Mean                 0.493501\n",
      "evaluation/Actions Std                  0.660588\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91827\n",
      "time/backward_zf1 (s)                   2.06392\n",
      "time/backward_zf2 (s)                   1.97859\n",
      "time/data sampling (s)                  0.273238\n",
      "time/data storing (s)                   0.0160184\n",
      "time/evaluation sampling (s)            1.39472\n",
      "time/exploration sampling (s)           0.204983\n",
      "time/logging (s)                        0.0106926\n",
      "time/preback_alpha (s)                  0.584727\n",
      "time/preback_policy (s)                 1.09887\n",
      "time/preback_start (s)                  0.126783\n",
      "time/preback_zf (s)                     5.12271\n",
      "time/saving (s)                         0.00649349\n",
      "time/training (s)                       2.33875\n",
      "time/epoch (s)                         17.1388\n",
      "time/total (s)                       3501.58\n",
      "Epoch                                 210\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:50:53.478523 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 211 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 222000\n",
      "trainer/ZF1 Loss                       19.9668\n",
      "trainer/ZF2 Loss                       27.1602\n",
      "trainer/ZF Expert Reward               17.8217\n",
      "trainer/ZF Policy Reward                3.86425\n",
      "trainer/ZF CHI2 Term                   37.8294\n",
      "trainer/Policy Loss                 -1002.54\n",
      "trainer/Bias Loss                     109.152\n",
      "trainer/Bias Value                     11.6197\n",
      "trainer/Policy Grad Norm              460.617\n",
      "trainer/Policy Param Norm              34.3494\n",
      "trainer/Zf1 Grad Norm                1230.79\n",
      "trainer/Zf1 Param Norm                106.233\n",
      "trainer/Zf2 Grad Norm                2068.57\n",
      "trainer/Zf2 Param Norm                104.519\n",
      "trainer/Z Expert Predictions Mean    1150.54\n",
      "trainer/Z Expert Predictions Std      101.479\n",
      "trainer/Z Expert Predictions Max     1295.32\n",
      "trainer/Z Expert Predictions Min      747.001\n",
      "trainer/Z Policy Predictions Mean     995.89\n",
      "trainer/Z Policy Predictions Std      284.656\n",
      "trainer/Z Policy Predictions Max     1280.35\n",
      "trainer/Z Policy Predictions Min      -55.6131\n",
      "trainer/Z Expert Targets Mean        1132.72\n",
      "trainer/Z Expert Targets Std          104.732\n",
      "trainer/Z Expert Targets Max         1278.94\n",
      "trainer/Z Expert Targets Min          675.28\n",
      "trainer/Z Policy Targets Mean         992.026\n",
      "trainer/Z Policy Targets Std          278.012\n",
      "trainer/Z Policy Targets Max         1270.26\n",
      "trainer/Z Policy Targets Min          -87.1641\n",
      "trainer/Log Pis Mean                   30.8418\n",
      "trainer/Log Pis Std                     7.22407\n",
      "trainer/Policy mu Mean                  1.41437\n",
      "trainer/Policy mu Std                   2.52451\n",
      "trainer/Policy log std Mean            -3.50755\n",
      "trainer/Policy log std Std              1.43793\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        216924\n",
      "exploration/num paths total           984\n",
      "evaluation/num steps total              1.55174e+06\n",
      "evaluation/num paths total           2124\n",
      "evaluation/path length Mean           982.9\n",
      "evaluation/path length Std             36.9877\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            883\n",
      "evaluation/Rewards Mean                 5.06649\n",
      "evaluation/Rewards Std                  1.29239\n",
      "evaluation/Rewards Max                  7.10114\n",
      "evaluation/Rewards Min                  0.084863\n",
      "evaluation/Returns Mean              4979.85\n",
      "evaluation/Returns Std                186.989\n",
      "evaluation/Returns Max               5135.86\n",
      "evaluation/Returns Min               4485.29\n",
      "evaluation/Estimation Bias Mean      1005.47\n",
      "evaluation/Estimation Bias Std        303.362\n",
      "evaluation/EB/Q_True Mean              49.3969\n",
      "evaluation/EB/Q_True Std              151.113\n",
      "evaluation/EB/Q_Pred Mean            1054.87\n",
      "evaluation/EB/Q_Pred Std              237.056\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4979.85\n",
      "evaluation/Actions Mean                 0.506278\n",
      "evaluation/Actions Std                  0.653077\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.04589\n",
      "time/backward_zf1 (s)                   2.19176\n",
      "time/backward_zf2 (s)                   2.16985\n",
      "time/data sampling (s)                  0.295892\n",
      "time/data storing (s)                   0.0150864\n",
      "time/evaluation sampling (s)            1.40142\n",
      "time/exploration sampling (s)           0.204082\n",
      "time/logging (s)                        0.0114781\n",
      "time/preback_alpha (s)                  0.60455\n",
      "time/preback_policy (s)                 1.21732\n",
      "time/preback_start (s)                  0.13348\n",
      "time/preback_zf (s)                     5.20769\n",
      "time/saving (s)                         0.00568535\n",
      "time/training (s)                       2.29721\n",
      "time/epoch (s)                         17.8014\n",
      "time/total (s)                       3519.4\n",
      "Epoch                                 211\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:51:10.547993 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 212 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 223000\n",
      "trainer/ZF1 Loss                       31.0291\n",
      "trainer/ZF2 Loss                       27.6559\n",
      "trainer/ZF Expert Reward               14.076\n",
      "trainer/ZF Policy Reward               -1.37887\n",
      "trainer/ZF CHI2 Term                   45.1002\n",
      "trainer/Policy Loss                  -942.738\n",
      "trainer/Bias Loss                      96.2927\n",
      "trainer/Bias Value                     11.6257\n",
      "trainer/Policy Grad Norm              319.013\n",
      "trainer/Policy Param Norm              34.3862\n",
      "trainer/Zf1 Grad Norm                1968.3\n",
      "trainer/Zf1 Param Norm                106.434\n",
      "trainer/Zf2 Grad Norm                2203.99\n",
      "trainer/Zf2 Param Norm                104.713\n",
      "trainer/Z Expert Predictions Mean    1143.39\n",
      "trainer/Z Expert Predictions Std      121.811\n",
      "trainer/Z Expert Predictions Max     1305.59\n",
      "trainer/Z Expert Predictions Min       66.7386\n",
      "trainer/Z Policy Predictions Mean     926.627\n",
      "trainer/Z Policy Predictions Std      352.118\n",
      "trainer/Z Policy Predictions Max     1261.64\n",
      "trainer/Z Policy Predictions Min     -101.949\n",
      "trainer/Z Expert Targets Mean        1129.32\n",
      "trainer/Z Expert Targets Std          126.814\n",
      "trainer/Z Expert Targets Max         1287.87\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         928.006\n",
      "trainer/Z Policy Targets Std          349.699\n",
      "trainer/Z Policy Targets Max         1283.79\n",
      "trainer/Z Policy Targets Min         -113.344\n",
      "trainer/Log Pis Mean                   30.2803\n",
      "trainer/Log Pis Std                     7.88374\n",
      "trainer/Policy mu Mean                  1.42775\n",
      "trainer/Policy mu Std                   2.70591\n",
      "trainer/Policy log std Mean            -3.36453\n",
      "trainer/Policy log std Std              1.4194\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        216924\n",
      "exploration/num paths total           984\n",
      "evaluation/num steps total              1.56174e+06\n",
      "evaluation/num paths total           2134\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.03506\n",
      "evaluation/Rewards Std                  1.26862\n",
      "evaluation/Rewards Max                  6.89315\n",
      "evaluation/Rewards Min                  0.11843\n",
      "evaluation/Returns Mean              5035.06\n",
      "evaluation/Returns Std                 34.275\n",
      "evaluation/Returns Max               5089.46\n",
      "evaluation/Returns Min               4994.58\n",
      "evaluation/Estimation Bias Mean      1032.46\n",
      "evaluation/Estimation Bias Std        199.912\n",
      "evaluation/EB/Q_True Mean              48.042\n",
      "evaluation/EB/Q_True Std              148.288\n",
      "evaluation/EB/Q_Pred Mean            1080.5\n",
      "evaluation/EB/Q_Pred Std              140.878\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5035.06\n",
      "evaluation/Actions Mean                 0.504827\n",
      "evaluation/Actions Std                  0.652187\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92162\n",
      "time/backward_zf1 (s)                   2.03718\n",
      "time/backward_zf2 (s)                   1.97527\n",
      "time/data sampling (s)                  0.276866\n",
      "time/data storing (s)                   0.0148454\n",
      "time/evaluation sampling (s)            1.41086\n",
      "time/exploration sampling (s)           0.202181\n",
      "time/logging (s)                        0.012194\n",
      "time/preback_alpha (s)                  0.577052\n",
      "time/preback_policy (s)                 1.12265\n",
      "time/preback_start (s)                  0.125627\n",
      "time/preback_zf (s)                     5.11158\n",
      "time/saving (s)                         0.00519705\n",
      "time/training (s)                       2.21036\n",
      "time/epoch (s)                         17.0035\n",
      "time/total (s)                       3536.42\n",
      "Epoch                                 212\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:51:28.421512 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 213 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 224000\n",
      "trainer/ZF1 Loss                       34.1297\n",
      "trainer/ZF2 Loss                       41.7907\n",
      "trainer/ZF Expert Reward               17.0921\n",
      "trainer/ZF Policy Reward                1.67835\n",
      "trainer/ZF CHI2 Term                   53.6883\n",
      "trainer/Policy Loss                  -952.315\n",
      "trainer/Bias Loss                     130.518\n",
      "trainer/Bias Value                     11.6315\n",
      "trainer/Policy Grad Norm              354.35\n",
      "trainer/Policy Param Norm              34.4194\n",
      "trainer/Zf1 Grad Norm                2777.26\n",
      "trainer/Zf1 Param Norm                106.658\n",
      "trainer/Zf2 Grad Norm                4099.43\n",
      "trainer/Zf2 Param Norm                104.922\n",
      "trainer/Z Expert Predictions Mean    1142.95\n",
      "trainer/Z Expert Predictions Std      101.466\n",
      "trainer/Z Expert Predictions Max     1288.86\n",
      "trainer/Z Expert Predictions Min      724.683\n",
      "trainer/Z Policy Predictions Mean     939.821\n",
      "trainer/Z Policy Predictions Std      319.447\n",
      "trainer/Z Policy Predictions Max     1315.04\n",
      "trainer/Z Policy Predictions Min      -26.8449\n",
      "trainer/Z Expert Targets Mean        1125.86\n",
      "trainer/Z Expert Targets Std          104.614\n",
      "trainer/Z Expert Targets Max         1276.68\n",
      "trainer/Z Expert Targets Min          724.452\n",
      "trainer/Z Policy Targets Mean         938.143\n",
      "trainer/Z Policy Targets Std          317.714\n",
      "trainer/Z Policy Targets Max         1272.06\n",
      "trainer/Z Policy Targets Min          -47.1108\n",
      "trainer/Log Pis Mean                   31.433\n",
      "trainer/Log Pis Std                     8.22883\n",
      "trainer/Policy mu Mean                  1.42808\n",
      "trainer/Policy mu Std                   2.64329\n",
      "trainer/Policy log std Mean            -3.44081\n",
      "trainer/Policy log std Std              1.50752\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        219924\n",
      "exploration/num paths total           987\n",
      "evaluation/num steps total              1.57174e+06\n",
      "evaluation/num paths total           2144\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.03961\n",
      "evaluation/Rewards Std                  1.27871\n",
      "evaluation/Rewards Max                  7.03288\n",
      "evaluation/Rewards Min                  0.124815\n",
      "evaluation/Returns Mean              5039.61\n",
      "evaluation/Returns Std                 76.6722\n",
      "evaluation/Returns Max               5160.96\n",
      "evaluation/Returns Min               4914.62\n",
      "evaluation/Estimation Bias Mean      1080.75\n",
      "evaluation/Estimation Bias Std        176.739\n",
      "evaluation/EB/Q_True Mean              47.5947\n",
      "evaluation/EB/Q_True Std              146.885\n",
      "evaluation/EB/Q_Pred Mean            1128.35\n",
      "evaluation/EB/Q_Pred Std               96.7682\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5039.61\n",
      "evaluation/Actions Mean                 0.514348\n",
      "evaluation/Actions Std                  0.645041\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.09803\n",
      "time/backward_zf1 (s)                   2.24985\n",
      "time/backward_zf2 (s)                   2.16777\n",
      "time/data sampling (s)                  0.284706\n",
      "time/data storing (s)                   0.0155225\n",
      "time/evaluation sampling (s)            1.4484\n",
      "time/exploration sampling (s)           0.211616\n",
      "time/logging (s)                        0.0133811\n",
      "time/preback_alpha (s)                  0.599654\n",
      "time/preback_policy (s)                 1.20741\n",
      "time/preback_start (s)                  0.132073\n",
      "time/preback_zf (s)                     5.17881\n",
      "time/saving (s)                         0.00582568\n",
      "time/training (s)                       2.18407\n",
      "time/epoch (s)                         17.7971\n",
      "time/total (s)                       3554.25\n",
      "Epoch                                 213\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:51:46.135356 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 214 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 225000\n",
      "trainer/ZF1 Loss                       30.4343\n",
      "trainer/ZF2 Loss                       24.9159\n",
      "trainer/ZF Expert Reward               14.2247\n",
      "trainer/ZF Policy Reward               -1.40534\n",
      "trainer/ZF CHI2 Term                   43.62\n",
      "trainer/Policy Loss                  -927.977\n",
      "trainer/Bias Loss                      77.683\n",
      "trainer/Bias Value                     11.6376\n",
      "trainer/Policy Grad Norm              355.763\n",
      "trainer/Policy Param Norm              34.4512\n",
      "trainer/Zf1 Grad Norm                2696.22\n",
      "trainer/Zf1 Param Norm                106.874\n",
      "trainer/Zf2 Grad Norm                2812.57\n",
      "trainer/Zf2 Param Norm                105.122\n",
      "trainer/Z Expert Predictions Mean    1138.47\n",
      "trainer/Z Expert Predictions Std      118.177\n",
      "trainer/Z Expert Predictions Max     1293.54\n",
      "trainer/Z Expert Predictions Min      618.762\n",
      "trainer/Z Policy Predictions Mean     915.919\n",
      "trainer/Z Policy Predictions Std      343.92\n",
      "trainer/Z Policy Predictions Max     1269.33\n",
      "trainer/Z Policy Predictions Min      -76.7774\n",
      "trainer/Z Expert Targets Mean        1124.25\n",
      "trainer/Z Expert Targets Std          117.275\n",
      "trainer/Z Expert Targets Max         1282.32\n",
      "trainer/Z Expert Targets Min          567.797\n",
      "trainer/Z Policy Targets Mean         917.325\n",
      "trainer/Z Policy Targets Std          339.959\n",
      "trainer/Z Policy Targets Max         1247.3\n",
      "trainer/Z Policy Targets Min          -77.4488\n",
      "trainer/Log Pis Mean                   31.4932\n",
      "trainer/Log Pis Std                     8.44747\n",
      "trainer/Policy mu Mean                  1.46956\n",
      "trainer/Policy mu Std                   2.77871\n",
      "trainer/Policy log std Mean            -3.38902\n",
      "trainer/Policy log std Std              1.52018\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        220924\n",
      "exploration/num paths total           988\n",
      "evaluation/num steps total              1.58174e+06\n",
      "evaluation/num paths total           2154\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.99727\n",
      "evaluation/Rewards Std                  1.26873\n",
      "evaluation/Rewards Max                  7.06955\n",
      "evaluation/Rewards Min                  0.118833\n",
      "evaluation/Returns Mean              4997.27\n",
      "evaluation/Returns Std                 27.4729\n",
      "evaluation/Returns Max               5033.48\n",
      "evaluation/Returns Min               4950.8\n",
      "evaluation/Estimation Bias Mean      1042.37\n",
      "evaluation/Estimation Bias Std        161.703\n",
      "evaluation/EB/Q_True Mean              46.6989\n",
      "evaluation/EB/Q_True Std              144.573\n",
      "evaluation/EB/Q_Pred Mean            1089.07\n",
      "evaluation/EB/Q_Pred Std               67.0063\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4997.27\n",
      "evaluation/Actions Mean                 0.504761\n",
      "evaluation/Actions Std                  0.65214\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.06088\n",
      "time/backward_zf1 (s)                   2.22072\n",
      "time/backward_zf2 (s)                   2.12745\n",
      "time/data sampling (s)                  0.279916\n",
      "time/data storing (s)                   0.0157598\n",
      "time/evaluation sampling (s)            1.47231\n",
      "time/exploration sampling (s)           0.211775\n",
      "time/logging (s)                        0.0119652\n",
      "time/preback_alpha (s)                  0.589324\n",
      "time/preback_policy (s)                 1.20878\n",
      "time/preback_start (s)                  0.128929\n",
      "time/preback_zf (s)                     5.14512\n",
      "time/saving (s)                         0.00591116\n",
      "time/training (s)                       2.15796\n",
      "time/epoch (s)                         17.6368\n",
      "time/total (s)                       3571.91\n",
      "Epoch                                 214\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:52:03.341445 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 215 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 226000\n",
      "trainer/ZF1 Loss                       31.4764\n",
      "trainer/ZF2 Loss                       32.52\n",
      "trainer/ZF Expert Reward               15.4844\n",
      "trainer/ZF Policy Reward                1.42652\n",
      "trainer/ZF CHI2 Term                   46.3594\n",
      "trainer/Policy Loss                  -991.951\n",
      "trainer/Bias Loss                     129.234\n",
      "trainer/Bias Value                     11.6435\n",
      "trainer/Policy Grad Norm              427.199\n",
      "trainer/Policy Param Norm              34.4825\n",
      "trainer/Zf1 Grad Norm                1933.71\n",
      "trainer/Zf1 Param Norm                107.091\n",
      "trainer/Zf2 Grad Norm                2922.64\n",
      "trainer/Zf2 Param Norm                105.336\n",
      "trainer/Z Expert Predictions Mean    1151.52\n",
      "trainer/Z Expert Predictions Std       92.9224\n",
      "trainer/Z Expert Predictions Max     1350.9\n",
      "trainer/Z Expert Predictions Min      719.509\n",
      "trainer/Z Policy Predictions Mean     984.759\n",
      "trainer/Z Policy Predictions Std      292.445\n",
      "trainer/Z Policy Predictions Max     1251.16\n",
      "trainer/Z Policy Predictions Min      -88.8759\n",
      "trainer/Z Expert Targets Mean        1136.04\n",
      "trainer/Z Expert Targets Std           91.4238\n",
      "trainer/Z Expert Targets Max         1322.45\n",
      "trainer/Z Expert Targets Min          741.3\n",
      "trainer/Z Policy Targets Mean         983.332\n",
      "trainer/Z Policy Targets Std          285.269\n",
      "trainer/Z Policy Targets Max         1262.95\n",
      "trainer/Z Policy Targets Min          -75.2133\n",
      "trainer/Log Pis Mean                   30.323\n",
      "trainer/Log Pis Std                     7.02032\n",
      "trainer/Policy mu Mean                  1.39209\n",
      "trainer/Policy mu Std                   2.43858\n",
      "trainer/Policy log std Mean            -3.5193\n",
      "trainer/Policy log std Std              1.43573\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        220924\n",
      "exploration/num paths total           988\n",
      "evaluation/num steps total              1.59174e+06\n",
      "evaluation/num paths total           2164\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 4.9941\n",
      "evaluation/Rewards Std                  1.26676\n",
      "evaluation/Rewards Max                  6.90148\n",
      "evaluation/Rewards Min                  0.105497\n",
      "evaluation/Returns Mean              4994.1\n",
      "evaluation/Returns Std                 35.5839\n",
      "evaluation/Returns Max               5049.25\n",
      "evaluation/Returns Min               4939.95\n",
      "evaluation/Estimation Bias Mean      1059.14\n",
      "evaluation/Estimation Bias Std        194.948\n",
      "evaluation/EB/Q_True Mean              47.5776\n",
      "evaluation/EB/Q_True Std              146.826\n",
      "evaluation/EB/Q_Pred Mean            1106.71\n",
      "evaluation/EB/Q_Pred Std              109.028\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4994.1\n",
      "evaluation/Actions Mean                 0.495297\n",
      "evaluation/Actions Std                  0.650613\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92984\n",
      "time/backward_zf1 (s)                   2.07842\n",
      "time/backward_zf2 (s)                   1.98819\n",
      "time/data sampling (s)                  0.285181\n",
      "time/data storing (s)                   0.0141141\n",
      "time/evaluation sampling (s)            1.44067\n",
      "time/exploration sampling (s)           0.197843\n",
      "time/logging (s)                        0.0115353\n",
      "time/preback_alpha (s)                  0.579493\n",
      "time/preback_policy (s)                 1.13734\n",
      "time/preback_start (s)                  0.125161\n",
      "time/preback_zf (s)                     5.12646\n",
      "time/saving (s)                         0.00571612\n",
      "time/training (s)                       2.21429\n",
      "time/epoch (s)                         17.1342\n",
      "time/total (s)                       3589.07\n",
      "Epoch                                 215\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:52:20.464174 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 216 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 227000\n",
      "trainer/ZF1 Loss                      308.999\n",
      "trainer/ZF2 Loss                      317.788\n",
      "trainer/ZF Expert Reward               12.5637\n",
      "trainer/ZF Policy Reward                7.50885\n",
      "trainer/ZF CHI2 Term                  318.752\n",
      "trainer/Policy Loss                  -979.626\n",
      "trainer/Bias Loss                      86.2849\n",
      "trainer/Bias Value                     11.6494\n",
      "trainer/Policy Grad Norm              627.504\n",
      "trainer/Policy Param Norm              34.5111\n",
      "trainer/Zf1 Grad Norm                2314.03\n",
      "trainer/Zf1 Param Norm                107.298\n",
      "trainer/Zf2 Grad Norm                2420.38\n",
      "trainer/Zf2 Param Norm                105.548\n",
      "trainer/Z Expert Predictions Mean    1131.99\n",
      "trainer/Z Expert Predictions Std      103.95\n",
      "trainer/Z Expert Predictions Max     1285.12\n",
      "trainer/Z Expert Predictions Min      654.588\n",
      "trainer/Z Policy Predictions Mean     974.609\n",
      "trainer/Z Policy Predictions Std      297.302\n",
      "trainer/Z Policy Predictions Max     1244.06\n",
      "trainer/Z Policy Predictions Min      -82.4723\n",
      "trainer/Z Expert Targets Mean        1119.43\n",
      "trainer/Z Expert Targets Std          103.939\n",
      "trainer/Z Expert Targets Max         1261.29\n",
      "trainer/Z Expert Targets Min          614.517\n",
      "trainer/Z Policy Targets Mean         967.101\n",
      "trainer/Z Policy Targets Std          300.028\n",
      "trainer/Z Policy Targets Max         1229.36\n",
      "trainer/Z Policy Targets Min          -53.4425\n",
      "trainer/Log Pis Mean                   30.3343\n",
      "trainer/Log Pis Std                     8.0617\n",
      "trainer/Policy mu Mean                  1.35923\n",
      "trainer/Policy mu Std                   2.59348\n",
      "trainer/Policy log std Mean            -3.42788\n",
      "trainer/Policy log std Std              1.48178\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        222924\n",
      "exploration/num paths total           990\n",
      "evaluation/num steps total              1.60174e+06\n",
      "evaluation/num paths total           2174\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09301\n",
      "evaluation/Rewards Std                  1.28147\n",
      "evaluation/Rewards Max                  7.08475\n",
      "evaluation/Rewards Min                  0.125462\n",
      "evaluation/Returns Mean              5093.01\n",
      "evaluation/Returns Std                 22.1944\n",
      "evaluation/Returns Max               5122.29\n",
      "evaluation/Returns Min               5048.37\n",
      "evaluation/Estimation Bias Mean      1064.93\n",
      "evaluation/Estimation Bias Std        181.219\n",
      "evaluation/EB/Q_True Mean              48.2795\n",
      "evaluation/EB/Q_True Std              149.154\n",
      "evaluation/EB/Q_Pred Mean            1113.21\n",
      "evaluation/EB/Q_Pred Std              111.951\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5093.01\n",
      "evaluation/Actions Mean                 0.503059\n",
      "evaluation/Actions Std                  0.64741\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91019\n",
      "time/backward_zf1 (s)                   2.05993\n",
      "time/backward_zf2 (s)                   1.98154\n",
      "time/data sampling (s)                  0.270677\n",
      "time/data storing (s)                   0.0141901\n",
      "time/evaluation sampling (s)            1.41304\n",
      "time/exploration sampling (s)           0.19993\n",
      "time/logging (s)                        0.0122194\n",
      "time/preback_alpha (s)                  0.572838\n",
      "time/preback_policy (s)                 1.07291\n",
      "time/preback_start (s)                  0.123997\n",
      "time/preback_zf (s)                     5.09349\n",
      "time/saving (s)                         0.00572754\n",
      "time/training (s)                       2.32497\n",
      "time/epoch (s)                         17.0557\n",
      "time/total (s)                       3606.14\n",
      "Epoch                                 216\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:52:37.991041 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 217 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 228000\n",
      "trainer/ZF1 Loss                       29.2507\n",
      "trainer/ZF2 Loss                       33.0943\n",
      "trainer/ZF Expert Reward               13.7033\n",
      "trainer/ZF Policy Reward                0.495799\n",
      "trainer/ZF CHI2 Term                   44.6876\n",
      "trainer/Policy Loss                 -1006.1\n",
      "trainer/Bias Loss                      73.2517\n",
      "trainer/Bias Value                     11.6555\n",
      "trainer/Policy Grad Norm              439.705\n",
      "trainer/Policy Param Norm              34.5464\n",
      "trainer/Zf1 Grad Norm                2190.56\n",
      "trainer/Zf1 Param Norm                107.531\n",
      "trainer/Zf2 Grad Norm                2393.94\n",
      "trainer/Zf2 Param Norm                105.768\n",
      "trainer/Z Expert Predictions Mean    1124.91\n",
      "trainer/Z Expert Predictions Std      117.299\n",
      "trainer/Z Expert Predictions Max     1322.24\n",
      "trainer/Z Expert Predictions Min      629.976\n",
      "trainer/Z Policy Predictions Mean     993.72\n",
      "trainer/Z Policy Predictions Std      274.081\n",
      "trainer/Z Policy Predictions Max     1275.21\n",
      "trainer/Z Policy Predictions Min     -126.648\n",
      "trainer/Z Expert Targets Mean        1111.21\n",
      "trainer/Z Expert Targets Std          117.899\n",
      "trainer/Z Expert Targets Max         1280.55\n",
      "trainer/Z Expert Targets Min          599.091\n",
      "trainer/Z Policy Targets Mean         993.224\n",
      "trainer/Z Policy Targets Std          270.575\n",
      "trainer/Z Policy Targets Max         1261.16\n",
      "trainer/Z Policy Targets Min         -141.804\n",
      "trainer/Log Pis Mean                   30.7586\n",
      "trainer/Log Pis Std                     6.63558\n",
      "trainer/Policy mu Mean                  1.40898\n",
      "trainer/Policy mu Std                   2.40536\n",
      "trainer/Policy log std Mean            -3.53995\n",
      "trainer/Policy log std Std              1.37864\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        222924\n",
      "exploration/num paths total           990\n",
      "evaluation/num steps total              1.61174e+06\n",
      "evaluation/num paths total           2184\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14741\n",
      "evaluation/Rewards Std                  1.31381\n",
      "evaluation/Rewards Max                  7.16216\n",
      "evaluation/Rewards Min                  0.117255\n",
      "evaluation/Returns Mean              5147.41\n",
      "evaluation/Returns Std                 32.346\n",
      "evaluation/Returns Max               5203.73\n",
      "evaluation/Returns Min               5103.16\n",
      "evaluation/Estimation Bias Mean      1102.37\n",
      "evaluation/Estimation Bias Std        160.779\n",
      "evaluation/EB/Q_True Mean              48.3864\n",
      "evaluation/EB/Q_True Std              149.476\n",
      "evaluation/EB/Q_Pred Mean            1150.76\n",
      "evaluation/EB/Q_Pred Std               79.0157\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5147.41\n",
      "evaluation/Actions Mean                 0.503985\n",
      "evaluation/Actions Std                  0.645061\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92392\n",
      "time/backward_zf1 (s)                   2.08869\n",
      "time/backward_zf2 (s)                   2.00451\n",
      "time/data sampling (s)                  0.286445\n",
      "time/data storing (s)                   0.0155214\n",
      "time/evaluation sampling (s)            1.48344\n",
      "time/exploration sampling (s)           0.204133\n",
      "time/logging (s)                        0.0118974\n",
      "time/preback_alpha (s)                  0.589433\n",
      "time/preback_policy (s)                 1.06687\n",
      "time/preback_start (s)                  0.128921\n",
      "time/preback_zf (s)                     5.16996\n",
      "time/saving (s)                         0.0057491\n",
      "time/training (s)                       2.47308\n",
      "time/epoch (s)                         17.4526\n",
      "time/total (s)                       3623.62\n",
      "Epoch                                 217\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:52:55.469733 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 218 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 229000\n",
      "trainer/ZF1 Loss                       38.5388\n",
      "trainer/ZF2 Loss                       35.9846\n",
      "trainer/ZF Expert Reward               11.6093\n",
      "trainer/ZF Policy Reward               -0.86281\n",
      "trainer/ZF CHI2 Term                   50.0379\n",
      "trainer/Policy Loss                  -964.738\n",
      "trainer/Bias Loss                     116.131\n",
      "trainer/Bias Value                     11.6616\n",
      "trainer/Policy Grad Norm              457.974\n",
      "trainer/Policy Param Norm              34.5754\n",
      "trainer/Zf1 Grad Norm                3338.34\n",
      "trainer/Zf1 Param Norm                107.774\n",
      "trainer/Zf2 Grad Norm                2893.36\n",
      "trainer/Zf2 Param Norm                105.987\n",
      "trainer/Z Expert Predictions Mean    1132.61\n",
      "trainer/Z Expert Predictions Std      107.184\n",
      "trainer/Z Expert Predictions Max     1343.53\n",
      "trainer/Z Expert Predictions Min      674.241\n",
      "trainer/Z Policy Predictions Mean     951.412\n",
      "trainer/Z Policy Predictions Std      315.145\n",
      "trainer/Z Policy Predictions Max     1290.56\n",
      "trainer/Z Policy Predictions Min     -126.146\n",
      "trainer/Z Expert Targets Mean        1121\n",
      "trainer/Z Expert Targets Std          109.624\n",
      "trainer/Z Expert Targets Max         1313.22\n",
      "trainer/Z Expert Targets Min          648.825\n",
      "trainer/Z Policy Targets Mean         952.275\n",
      "trainer/Z Policy Targets Std          313.836\n",
      "trainer/Z Policy Targets Max         1275.29\n",
      "trainer/Z Policy Targets Min         -143.981\n",
      "trainer/Log Pis Mean                   30.4132\n",
      "trainer/Log Pis Std                     7.95124\n",
      "trainer/Policy mu Mean                  1.2831\n",
      "trainer/Policy mu Std                   2.48273\n",
      "trainer/Policy log std Mean            -3.59036\n",
      "trainer/Policy log std Std              1.36559\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        222924\n",
      "exploration/num paths total           990\n",
      "evaluation/num steps total              1.62174e+06\n",
      "evaluation/num paths total           2194\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.04611\n",
      "evaluation/Rewards Std                  1.27948\n",
      "evaluation/Rewards Max                  7.05921\n",
      "evaluation/Rewards Min                  0.131564\n",
      "evaluation/Returns Mean              5046.11\n",
      "evaluation/Returns Std                 59.7414\n",
      "evaluation/Returns Max               5145.76\n",
      "evaluation/Returns Min               4961.11\n",
      "evaluation/Estimation Bias Mean      1075.25\n",
      "evaluation/Estimation Bias Std        172.54\n",
      "evaluation/EB/Q_True Mean              47.7196\n",
      "evaluation/EB/Q_True Std              147.137\n",
      "evaluation/EB/Q_Pred Mean            1122.96\n",
      "evaluation/EB/Q_Pred Std               91.7278\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5046.11\n",
      "evaluation/Actions Mean                 0.516179\n",
      "evaluation/Actions Std                  0.641582\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.00804\n",
      "time/backward_zf1 (s)                   2.16411\n",
      "time/backward_zf2 (s)                   2.09049\n",
      "time/data sampling (s)                  0.258948\n",
      "time/data storing (s)                   0.0145211\n",
      "time/evaluation sampling (s)            1.41163\n",
      "time/exploration sampling (s)           0.198409\n",
      "time/logging (s)                        0.0119716\n",
      "time/preback_alpha (s)                  0.588005\n",
      "time/preback_policy (s)                 1.16678\n",
      "time/preback_start (s)                  0.126698\n",
      "time/preback_zf (s)                     5.1305\n",
      "time/saving (s)                         0.00551104\n",
      "time/training (s)                       2.22971\n",
      "time/epoch (s)                         17.4053\n",
      "time/total (s)                       3641.05\n",
      "Epoch                                 218\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:53:12.774078 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 219 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 230000\n",
      "trainer/ZF1 Loss                      203.322\n",
      "trainer/ZF2 Loss                      222.464\n",
      "trainer/ZF Expert Reward               19.1596\n",
      "trainer/ZF Policy Reward                2.18558\n",
      "trainer/ZF CHI2 Term                  230.181\n",
      "trainer/Policy Loss                  -949.582\n",
      "trainer/Bias Loss                    2004.75\n",
      "trainer/Bias Value                     11.6677\n",
      "trainer/Policy Grad Norm              412.062\n",
      "trainer/Policy Param Norm              34.6049\n",
      "trainer/Zf1 Grad Norm                2953.11\n",
      "trainer/Zf1 Param Norm                108.007\n",
      "trainer/Zf2 Grad Norm                4399.9\n",
      "trainer/Zf2 Param Norm                106.208\n",
      "trainer/Z Expert Predictions Mean    1140.72\n",
      "trainer/Z Expert Predictions Std      101.633\n",
      "trainer/Z Expert Predictions Max     1340.78\n",
      "trainer/Z Expert Predictions Min      692.754\n",
      "trainer/Z Policy Predictions Mean     943.983\n",
      "trainer/Z Policy Predictions Std      321.999\n",
      "trainer/Z Policy Predictions Max     1296.6\n",
      "trainer/Z Policy Predictions Min      -62.6362\n",
      "trainer/Z Expert Targets Mean        1121.56\n",
      "trainer/Z Expert Targets Std          125.203\n",
      "trainer/Z Expert Targets Max         1323.92\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         941.798\n",
      "trainer/Z Policy Targets Std          317.821\n",
      "trainer/Z Policy Targets Max         1302.71\n",
      "trainer/Z Policy Targets Min          -69.9067\n",
      "trainer/Log Pis Mean                   31.338\n",
      "trainer/Log Pis Std                     8.52147\n",
      "trainer/Policy mu Mean                  1.39984\n",
      "trainer/Policy mu Std                   2.66971\n",
      "trainer/Policy log std Mean            -3.53142\n",
      "trainer/Policy log std Std              1.48013\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        225924\n",
      "exploration/num paths total           993\n",
      "evaluation/num steps total              1.63174e+06\n",
      "evaluation/num paths total           2204\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1272\n",
      "evaluation/Rewards Std                  1.30002\n",
      "evaluation/Rewards Max                  7.11706\n",
      "evaluation/Rewards Min                  0.11465\n",
      "evaluation/Returns Mean              5127.2\n",
      "evaluation/Returns Std                 31.4843\n",
      "evaluation/Returns Max               5162.12\n",
      "evaluation/Returns Min               5081.9\n",
      "evaluation/Estimation Bias Mean      1070.79\n",
      "evaluation/Estimation Bias Std        177.084\n",
      "evaluation/EB/Q_True Mean              48.0296\n",
      "evaluation/EB/Q_True Std              148.189\n",
      "evaluation/EB/Q_Pred Mean            1118.82\n",
      "evaluation/EB/Q_Pred Std              125.366\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5127.2\n",
      "evaluation/Actions Mean                 0.512808\n",
      "evaluation/Actions Std                  0.644178\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93475\n",
      "time/backward_zf1 (s)                   2.09667\n",
      "time/backward_zf2 (s)                   2.01508\n",
      "time/data sampling (s)                  0.258337\n",
      "time/data storing (s)                   0.0142864\n",
      "time/evaluation sampling (s)            1.50523\n",
      "time/exploration sampling (s)           0.204621\n",
      "time/logging (s)                        0.0123551\n",
      "time/preback_alpha (s)                  0.582872\n",
      "time/preback_policy (s)                 1.12813\n",
      "time/preback_start (s)                  0.127192\n",
      "time/preback_zf (s)                     5.10454\n",
      "time/saving (s)                         0.00576743\n",
      "time/training (s)                       2.23243\n",
      "time/epoch (s)                         17.2222\n",
      "time/total (s)                       3658.31\n",
      "Epoch                                 219\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:53:29.971769 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 220 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 231000\n",
      "trainer/ZF1 Loss                       43.773\n",
      "trainer/ZF2 Loss                       91.6066\n",
      "trainer/ZF Expert Reward               14.7152\n",
      "trainer/ZF Policy Reward                0.304673\n",
      "trainer/ZF CHI2 Term                   82.4058\n",
      "trainer/Policy Loss                  -982.787\n",
      "trainer/Bias Loss                     527.44\n",
      "trainer/Bias Value                     11.6735\n",
      "trainer/Policy Grad Norm              426.953\n",
      "trainer/Policy Param Norm              34.6306\n",
      "trainer/Zf1 Grad Norm                5638.88\n",
      "trainer/Zf1 Param Norm                108.239\n",
      "trainer/Zf2 Grad Norm               10707.2\n",
      "trainer/Zf2 Param Norm                106.418\n",
      "trainer/Z Expert Predictions Mean    1145.8\n",
      "trainer/Z Expert Predictions Std      108.98\n",
      "trainer/Z Expert Predictions Max     1335.22\n",
      "trainer/Z Expert Predictions Min      475.884\n",
      "trainer/Z Policy Predictions Mean     976.805\n",
      "trainer/Z Policy Predictions Std      309.434\n",
      "trainer/Z Policy Predictions Max     1292.09\n",
      "trainer/Z Policy Predictions Min     -129.762\n",
      "trainer/Z Expert Targets Mean        1131.09\n",
      "trainer/Z Expert Targets Std          125.13\n",
      "trainer/Z Expert Targets Max         1307.93\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         976.501\n",
      "trainer/Z Policy Targets Std          303.603\n",
      "trainer/Z Policy Targets Max         1293.95\n",
      "trainer/Z Policy Targets Min         -148.855\n",
      "trainer/Log Pis Mean                   30.5442\n",
      "trainer/Log Pis Std                     7.96002\n",
      "trainer/Policy mu Mean                  1.43007\n",
      "trainer/Policy mu Std                   2.58645\n",
      "trainer/Policy log std Mean            -3.37515\n",
      "trainer/Policy log std Std              1.45309\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        225924\n",
      "exploration/num paths total           993\n",
      "evaluation/num steps total              1.64174e+06\n",
      "evaluation/num paths total           2214\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07374\n",
      "evaluation/Rewards Std                  1.27852\n",
      "evaluation/Rewards Max                  7.08888\n",
      "evaluation/Rewards Min                  0.0949881\n",
      "evaluation/Returns Mean              5073.74\n",
      "evaluation/Returns Std                 30.4008\n",
      "evaluation/Returns Max               5114.17\n",
      "evaluation/Returns Min               5023.72\n",
      "evaluation/Estimation Bias Mean      1067.26\n",
      "evaluation/Estimation Bias Std        185.979\n",
      "evaluation/EB/Q_True Mean              48.0892\n",
      "evaluation/EB/Q_True Std              148.482\n",
      "evaluation/EB/Q_Pred Mean            1115.35\n",
      "evaluation/EB/Q_Pred Std              111.745\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5073.74\n",
      "evaluation/Actions Mean                 0.50751\n",
      "evaluation/Actions Std                  0.646929\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92535\n",
      "time/backward_zf1 (s)                   2.07117\n",
      "time/backward_zf2 (s)                   2.00809\n",
      "time/data sampling (s)                  0.276661\n",
      "time/data storing (s)                   0.0151577\n",
      "time/evaluation sampling (s)            1.42909\n",
      "time/exploration sampling (s)           0.200025\n",
      "time/logging (s)                        0.0123098\n",
      "time/preback_alpha (s)                  0.580761\n",
      "time/preback_policy (s)                 1.12477\n",
      "time/preback_start (s)                  0.127207\n",
      "time/preback_zf (s)                     5.10092\n",
      "time/saving (s)                         0.00568343\n",
      "time/training (s)                       2.25025\n",
      "time/epoch (s)                         17.1275\n",
      "time/total (s)                       3675.45\n",
      "Epoch                                 220\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:53:47.184256 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 221 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 232000\n",
      "trainer/ZF1 Loss                      284.348\n",
      "trainer/ZF2 Loss                      270.576\n",
      "trainer/ZF Expert Reward               17.4477\n",
      "trainer/ZF Policy Reward                8.99335\n",
      "trainer/ZF CHI2 Term                  286.215\n",
      "trainer/Policy Loss                  -974.115\n",
      "trainer/Bias Loss                      99.7559\n",
      "trainer/Bias Value                     11.6794\n",
      "trainer/Policy Grad Norm              487.764\n",
      "trainer/Policy Param Norm              34.6584\n",
      "trainer/Zf1 Grad Norm                3893.02\n",
      "trainer/Zf1 Param Norm                108.475\n",
      "trainer/Zf2 Grad Norm                4448.03\n",
      "trainer/Zf2 Param Norm                106.642\n",
      "trainer/Z Expert Predictions Mean    1144.03\n",
      "trainer/Z Expert Predictions Std      105.895\n",
      "trainer/Z Expert Predictions Max     1348.16\n",
      "trainer/Z Expert Predictions Min      676.21\n",
      "trainer/Z Policy Predictions Mean     969.783\n",
      "trainer/Z Policy Predictions Std      298.924\n",
      "trainer/Z Policy Predictions Max     1295.53\n",
      "trainer/Z Policy Predictions Min      -53.5002\n",
      "trainer/Z Expert Targets Mean        1126.58\n",
      "trainer/Z Expert Targets Std          106.138\n",
      "trainer/Z Expert Targets Max         1333.45\n",
      "trainer/Z Expert Targets Min          646.498\n",
      "trainer/Z Policy Targets Mean         960.79\n",
      "trainer/Z Policy Targets Std          302.46\n",
      "trainer/Z Policy Targets Max         1293.88\n",
      "trainer/Z Policy Targets Min          -56.7387\n",
      "trainer/Log Pis Mean                   29.833\n",
      "trainer/Log Pis Std                     6.97252\n",
      "trainer/Policy mu Mean                  1.38969\n",
      "trainer/Policy mu Std                   2.37317\n",
      "trainer/Policy log std Mean            -3.43527\n",
      "trainer/Policy log std Std              1.40138\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        226924\n",
      "exploration/num paths total           994\n",
      "evaluation/num steps total              1.65146e+06\n",
      "evaluation/num paths total           2224\n",
      "evaluation/path length Mean           972.5\n",
      "evaluation/path length Std             82.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            725\n",
      "evaluation/Rewards Mean                 5.20525\n",
      "evaluation/Rewards Std                  1.3302\n",
      "evaluation/Rewards Max                  7.28582\n",
      "evaluation/Rewards Min                  0.103287\n",
      "evaluation/Returns Mean              5062.11\n",
      "evaluation/Returns Std                459.029\n",
      "evaluation/Returns Max               5280.53\n",
      "evaluation/Returns Min               3689.73\n",
      "evaluation/Estimation Bias Mean      1025.15\n",
      "evaluation/Estimation Bias Std        284.697\n",
      "evaluation/EB/Q_True Mean              50.5559\n",
      "evaluation/EB/Q_True Std              153.578\n",
      "evaluation/EB/Q_Pred Mean            1075.7\n",
      "evaluation/EB/Q_Pred Std              202.907\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5062.11\n",
      "evaluation/Actions Mean                 0.506746\n",
      "evaluation/Actions Std                  0.651384\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91339\n",
      "time/backward_zf1 (s)                   2.09494\n",
      "time/backward_zf2 (s)                   2.01873\n",
      "time/data sampling (s)                  0.279969\n",
      "time/data storing (s)                   0.0145466\n",
      "time/evaluation sampling (s)            1.37989\n",
      "time/exploration sampling (s)           0.201795\n",
      "time/logging (s)                        0.0124885\n",
      "time/preback_alpha (s)                  0.579743\n",
      "time/preback_policy (s)                 1.08845\n",
      "time/preback_start (s)                  0.12774\n",
      "time/preback_zf (s)                     5.09199\n",
      "time/saving (s)                         0.00941384\n",
      "time/training (s)                       2.32956\n",
      "time/epoch (s)                         17.1426\n",
      "time/total (s)                       3692.62\n",
      "Epoch                                 221\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:54:04.522831 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 222 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 233000\n",
      "trainer/ZF1 Loss                      274.06\n",
      "trainer/ZF2 Loss                      247.666\n",
      "trainer/ZF Expert Reward               11.396\n",
      "trainer/ZF Policy Reward                2.95742\n",
      "trainer/ZF CHI2 Term                  269.613\n",
      "trainer/Policy Loss                  -977.694\n",
      "trainer/Bias Loss                     129.191\n",
      "trainer/Bias Value                     11.6855\n",
      "trainer/Policy Grad Norm              522.587\n",
      "trainer/Policy Param Norm              34.6868\n",
      "trainer/Zf1 Grad Norm                7217.68\n",
      "trainer/Zf1 Param Norm                108.704\n",
      "trainer/Zf2 Grad Norm                4114.42\n",
      "trainer/Zf2 Param Norm                106.871\n",
      "trainer/Z Expert Predictions Mean    1121.45\n",
      "trainer/Z Expert Predictions Std      119.195\n",
      "trainer/Z Expert Predictions Max     1349.13\n",
      "trainer/Z Expert Predictions Min      617.518\n",
      "trainer/Z Policy Predictions Mean     969.202\n",
      "trainer/Z Policy Predictions Std      295.445\n",
      "trainer/Z Policy Predictions Max     1293.02\n",
      "trainer/Z Policy Predictions Min     -128.951\n",
      "trainer/Z Expert Targets Mean        1110.06\n",
      "trainer/Z Expert Targets Std          119.136\n",
      "trainer/Z Expert Targets Max         1397.64\n",
      "trainer/Z Expert Targets Min          565.538\n",
      "trainer/Z Policy Targets Mean         966.244\n",
      "trainer/Z Policy Targets Std          300.148\n",
      "trainer/Z Policy Targets Max         1291.32\n",
      "trainer/Z Policy Targets Min         -114.587\n",
      "trainer/Log Pis Mean                   31.1014\n",
      "trainer/Log Pis Std                     7.94872\n",
      "trainer/Policy mu Mean                  1.3675\n",
      "trainer/Policy mu Std                   2.45653\n",
      "trainer/Policy log std Mean            -3.57195\n",
      "trainer/Policy log std Std              1.3783\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        226924\n",
      "exploration/num paths total           994\n",
      "evaluation/num steps total              1.66082e+06\n",
      "evaluation/num paths total           2234\n",
      "evaluation/path length Mean           936.4\n",
      "evaluation/path length Std             82.5787\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            793\n",
      "evaluation/Rewards Mean                 4.91162\n",
      "evaluation/Rewards Std                  1.3043\n",
      "evaluation/Rewards Max                  7.12895\n",
      "evaluation/Rewards Min                  0.0973027\n",
      "evaluation/Returns Mean              4599.24\n",
      "evaluation/Returns Std                402.166\n",
      "evaluation/Returns Max               4951.88\n",
      "evaluation/Returns Min               3879.3\n",
      "evaluation/Estimation Bias Mean      1034.38\n",
      "evaluation/Estimation Bias Std        206.345\n",
      "evaluation/EB/Q_True Mean              49.6208\n",
      "evaluation/EB/Q_True Std              148.383\n",
      "evaluation/EB/Q_Pred Mean            1084\n",
      "evaluation/EB/Q_Pred Std              144.457\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4599.24\n",
      "evaluation/Actions Mean                 0.504698\n",
      "evaluation/Actions Std                  0.64594\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97695\n",
      "time/backward_zf1 (s)                   2.12346\n",
      "time/backward_zf2 (s)                   2.06289\n",
      "time/data sampling (s)                  0.285118\n",
      "time/data storing (s)                   0.0139229\n",
      "time/evaluation sampling (s)            1.42891\n",
      "time/exploration sampling (s)           0.192575\n",
      "time/logging (s)                        0.0116425\n",
      "time/preback_alpha (s)                  0.584127\n",
      "time/preback_policy (s)                 1.17788\n",
      "time/preback_start (s)                  0.126819\n",
      "time/preback_zf (s)                     5.12094\n",
      "time/saving (s)                         0.00567739\n",
      "time/training (s)                       2.1579\n",
      "time/epoch (s)                         17.2688\n",
      "time/total (s)                       3709.91\n",
      "Epoch                                 222\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:54:21.995874 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 223 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 234000\n",
      "trainer/ZF1 Loss                       26.0262\n",
      "trainer/ZF2 Loss                       21.891\n",
      "trainer/ZF Expert Reward               15.2431\n",
      "trainer/ZF Policy Reward               -1.92066\n",
      "trainer/ZF CHI2 Term                   41.4258\n",
      "trainer/Policy Loss                  -964.457\n",
      "trainer/Bias Loss                     100.24\n",
      "trainer/Bias Value                     11.6913\n",
      "trainer/Policy Grad Norm              418.539\n",
      "trainer/Policy Param Norm              34.7144\n",
      "trainer/Zf1 Grad Norm                3365.11\n",
      "trainer/Zf1 Param Norm                108.924\n",
      "trainer/Zf2 Grad Norm                1973.38\n",
      "trainer/Zf2 Param Norm                107.068\n",
      "trainer/Z Expert Predictions Mean    1143.3\n",
      "trainer/Z Expert Predictions Std      110.766\n",
      "trainer/Z Expert Predictions Max     1376.35\n",
      "trainer/Z Expert Predictions Min      671.561\n",
      "trainer/Z Policy Predictions Mean     951.179\n",
      "trainer/Z Policy Predictions Std      306.7\n",
      "trainer/Z Policy Predictions Max     1328.98\n",
      "trainer/Z Policy Predictions Min     -151.288\n",
      "trainer/Z Expert Targets Mean        1128.06\n",
      "trainer/Z Expert Targets Std          112.394\n",
      "trainer/Z Expert Targets Max         1345.07\n",
      "trainer/Z Expert Targets Min          623.362\n",
      "trainer/Z Policy Targets Mean         953.099\n",
      "trainer/Z Policy Targets Std          301.33\n",
      "trainer/Z Policy Targets Max         1315.45\n",
      "trainer/Z Policy Targets Min         -163.606\n",
      "trainer/Log Pis Mean                   30.3496\n",
      "trainer/Log Pis Std                     7.85111\n",
      "trainer/Policy mu Mean                  1.39212\n",
      "trainer/Policy mu Std                   2.52276\n",
      "trainer/Policy log std Mean            -3.46333\n",
      "trainer/Policy log std Std              1.43177\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        229924\n",
      "exploration/num paths total           997\n",
      "evaluation/num steps total              1.67082e+06\n",
      "evaluation/num paths total           2244\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14547\n",
      "evaluation/Rewards Std                  1.31243\n",
      "evaluation/Rewards Max                  7.20604\n",
      "evaluation/Rewards Min                  0.0908003\n",
      "evaluation/Returns Mean              5145.47\n",
      "evaluation/Returns Std                 46.3064\n",
      "evaluation/Returns Max               5211.09\n",
      "evaluation/Returns Min               5072.74\n",
      "evaluation/Estimation Bias Mean      1063.76\n",
      "evaluation/Estimation Bias Std        238.91\n",
      "evaluation/EB/Q_True Mean              47.9344\n",
      "evaluation/EB/Q_True Std              147.727\n",
      "evaluation/EB/Q_Pred Mean            1111.69\n",
      "evaluation/EB/Q_Pred Std              200.765\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5145.47\n",
      "evaluation/Actions Mean                 0.505012\n",
      "evaluation/Actions Std                  0.650555\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97414\n",
      "time/backward_zf1 (s)                   2.09891\n",
      "time/backward_zf2 (s)                   2.04679\n",
      "time/data sampling (s)                  0.279779\n",
      "time/data storing (s)                   0.0144477\n",
      "time/evaluation sampling (s)            1.42491\n",
      "time/exploration sampling (s)           0.203995\n",
      "time/logging (s)                        0.0119859\n",
      "time/preback_alpha (s)                  0.590089\n",
      "time/preback_policy (s)                 1.16504\n",
      "time/preback_start (s)                  0.129341\n",
      "time/preback_zf (s)                     5.16761\n",
      "time/saving (s)                         0.00575897\n",
      "time/training (s)                       2.29043\n",
      "time/epoch (s)                         17.4032\n",
      "time/total (s)                       3727.33\n",
      "Epoch                                 223\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:54:39.463945 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 224 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 235000\n",
      "trainer/ZF1 Loss                       35.2468\n",
      "trainer/ZF2 Loss                       35.1449\n",
      "trainer/ZF Expert Reward               12.0904\n",
      "trainer/ZF Policy Reward               -2.64171\n",
      "trainer/ZF CHI2 Term                   50.2283\n",
      "trainer/Policy Loss                 -1012.81\n",
      "trainer/Bias Loss                     113.473\n",
      "trainer/Bias Value                     11.6972\n",
      "trainer/Policy Grad Norm              640.99\n",
      "trainer/Policy Param Norm              34.7395\n",
      "trainer/Zf1 Grad Norm                4910.3\n",
      "trainer/Zf1 Param Norm                109.15\n",
      "trainer/Zf2 Grad Norm                3712.97\n",
      "trainer/Zf2 Param Norm                107.29\n",
      "trainer/Z Expert Predictions Mean    1129.47\n",
      "trainer/Z Expert Predictions Std      142.927\n",
      "trainer/Z Expert Predictions Max     1372.67\n",
      "trainer/Z Expert Predictions Min       83.789\n",
      "trainer/Z Policy Predictions Mean    1000.55\n",
      "trainer/Z Policy Predictions Std      277.807\n",
      "trainer/Z Policy Predictions Max     1327.27\n",
      "trainer/Z Policy Predictions Min     -109.646\n",
      "trainer/Z Expert Targets Mean        1117.38\n",
      "trainer/Z Expert Targets Std          146.106\n",
      "trainer/Z Expert Targets Max         1336.8\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1003.19\n",
      "trainer/Z Policy Targets Std          273.001\n",
      "trainer/Z Policy Targets Max         1297.49\n",
      "trainer/Z Policy Targets Min         -114.806\n",
      "trainer/Log Pis Mean                   30.0278\n",
      "trainer/Log Pis Std                     7.97864\n",
      "trainer/Policy mu Mean                  1.35674\n",
      "trainer/Policy mu Std                   2.49009\n",
      "trainer/Policy log std Mean            -3.49145\n",
      "trainer/Policy log std Std              1.38379\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        230924\n",
      "exploration/num paths total           998\n",
      "evaluation/num steps total              1.68046e+06\n",
      "evaluation/num paths total           2254\n",
      "evaluation/path length Mean           963.5\n",
      "evaluation/path length Std            109.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            635\n",
      "evaluation/Rewards Mean                 5.1502\n",
      "evaluation/Rewards Std                  1.33118\n",
      "evaluation/Rewards Max                  7.23944\n",
      "evaluation/Rewards Min                  0.0941794\n",
      "evaluation/Returns Mean              4962.22\n",
      "evaluation/Returns Std                617.008\n",
      "evaluation/Returns Max               5225.23\n",
      "evaluation/Returns Min               3116.25\n",
      "evaluation/Estimation Bias Mean      1058.87\n",
      "evaluation/Estimation Bias Std        265.87\n",
      "evaluation/EB/Q_True Mean              51.283\n",
      "evaluation/EB/Q_True Std              154.876\n",
      "evaluation/EB/Q_Pred Mean            1110.15\n",
      "evaluation/EB/Q_Pred Std              178.604\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4962.22\n",
      "evaluation/Actions Mean                 0.51127\n",
      "evaluation/Actions Std                  0.648349\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95771\n",
      "time/backward_zf1 (s)                   2.09847\n",
      "time/backward_zf2 (s)                   2.001\n",
      "time/data sampling (s)                  0.286727\n",
      "time/data storing (s)                   0.014965\n",
      "time/evaluation sampling (s)            1.41807\n",
      "time/exploration sampling (s)           0.202174\n",
      "time/logging (s)                        0.0116359\n",
      "time/preback_alpha (s)                  0.592708\n",
      "time/preback_policy (s)                 1.10064\n",
      "time/preback_start (s)                  0.127792\n",
      "time/preback_zf (s)                     5.1514\n",
      "time/saving (s)                         0.00548852\n",
      "time/training (s)                       2.42729\n",
      "time/epoch (s)                         17.3961\n",
      "time/total (s)                       3744.75\n",
      "Epoch                                 224\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:54:57.159254 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 225 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 236000\n",
      "trainer/ZF1 Loss                       37.1394\n",
      "trainer/ZF2 Loss                       45.2271\n",
      "trainer/ZF Expert Reward                7.3335\n",
      "trainer/ZF Policy Reward               -4.32144\n",
      "trainer/ZF CHI2 Term                   53.1363\n",
      "trainer/Policy Loss                 -1005.92\n",
      "trainer/Bias Loss                     108.603\n",
      "trainer/Bias Value                     11.7032\n",
      "trainer/Policy Grad Norm              422.101\n",
      "trainer/Policy Param Norm              34.7682\n",
      "trainer/Zf1 Grad Norm                4082.84\n",
      "trainer/Zf1 Param Norm                109.37\n",
      "trainer/Zf2 Grad Norm                4451.34\n",
      "trainer/Zf2 Param Norm                107.498\n",
      "trainer/Z Expert Predictions Mean    1136.5\n",
      "trainer/Z Expert Predictions Std      107.295\n",
      "trainer/Z Expert Predictions Max     1310.38\n",
      "trainer/Z Expert Predictions Min      699.11\n",
      "trainer/Z Policy Predictions Mean     996.111\n",
      "trainer/Z Policy Predictions Std      283.91\n",
      "trainer/Z Policy Predictions Max     1275.37\n",
      "trainer/Z Policy Predictions Min      -80.6167\n",
      "trainer/Z Expert Targets Mean        1129.16\n",
      "trainer/Z Expert Targets Std          108.379\n",
      "trainer/Z Expert Targets Max         1310.81\n",
      "trainer/Z Expert Targets Min          699.663\n",
      "trainer/Z Policy Targets Mean        1000.43\n",
      "trainer/Z Policy Targets Std          281.956\n",
      "trainer/Z Policy Targets Max         1295.84\n",
      "trainer/Z Policy Targets Min          -80.3094\n",
      "trainer/Log Pis Mean                   29.8069\n",
      "trainer/Log Pis Std                     7.14401\n",
      "trainer/Policy mu Mean                  1.31783\n",
      "trainer/Policy mu Std                   2.35776\n",
      "trainer/Policy log std Mean            -3.52853\n",
      "trainer/Policy log std Std              1.40205\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        230924\n",
      "exploration/num paths total           998\n",
      "evaluation/num steps total              1.69046e+06\n",
      "evaluation/num paths total           2264\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17944\n",
      "evaluation/Rewards Std                  1.32644\n",
      "evaluation/Rewards Max                  7.23431\n",
      "evaluation/Rewards Min                  0.100684\n",
      "evaluation/Returns Mean              5179.44\n",
      "evaluation/Returns Std                 32.2229\n",
      "evaluation/Returns Max               5222.06\n",
      "evaluation/Returns Min               5123.84\n",
      "evaluation/Estimation Bias Mean      1127.69\n",
      "evaluation/Estimation Bias Std        166.928\n",
      "evaluation/EB/Q_True Mean              49.4095\n",
      "evaluation/EB/Q_True Std              152.672\n",
      "evaluation/EB/Q_Pred Mean            1177.1\n",
      "evaluation/EB/Q_Pred Std               67.6374\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5179.44\n",
      "evaluation/Actions Mean                 0.505907\n",
      "evaluation/Actions Std                  0.64489\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.04309\n",
      "time/backward_zf1 (s)                   2.18161\n",
      "time/backward_zf2 (s)                   2.11706\n",
      "time/data sampling (s)                  0.298393\n",
      "time/data storing (s)                   0.0152322\n",
      "time/evaluation sampling (s)            1.46275\n",
      "time/exploration sampling (s)           0.203412\n",
      "time/logging (s)                        0.0170752\n",
      "time/preback_alpha (s)                  0.592206\n",
      "time/preback_policy (s)                 1.18562\n",
      "time/preback_start (s)                  0.129144\n",
      "time/preback_zf (s)                     5.14072\n",
      "time/saving (s)                         0.00668461\n",
      "time/training (s)                       2.23775\n",
      "time/epoch (s)                         17.6308\n",
      "time/total (s)                       3762.4\n",
      "Epoch                                 225\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:55:14.693936 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 226 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 237000\n",
      "trainer/ZF1 Loss                       31.8523\n",
      "trainer/ZF2 Loss                       27.7171\n",
      "trainer/ZF Expert Reward               15.9282\n",
      "trainer/ZF Policy Reward                1.14682\n",
      "trainer/ZF CHI2 Term                   44.8738\n",
      "trainer/Policy Loss                  -961.941\n",
      "trainer/Bias Loss                     113.699\n",
      "trainer/Bias Value                     11.7091\n",
      "trainer/Policy Grad Norm              353.366\n",
      "trainer/Policy Param Norm              34.7876\n",
      "trainer/Zf1 Grad Norm                1501.64\n",
      "trainer/Zf1 Param Norm                109.597\n",
      "trainer/Zf2 Grad Norm                2220.15\n",
      "trainer/Zf2 Param Norm                107.702\n",
      "trainer/Z Expert Predictions Mean    1140.19\n",
      "trainer/Z Expert Predictions Std      109.575\n",
      "trainer/Z Expert Predictions Max     1298.17\n",
      "trainer/Z Expert Predictions Min      582.681\n",
      "trainer/Z Policy Predictions Mean     955.241\n",
      "trainer/Z Policy Predictions Std      311.172\n",
      "trainer/Z Policy Predictions Max     1274.76\n",
      "trainer/Z Policy Predictions Min      -56.9146\n",
      "trainer/Z Expert Targets Mean        1124.26\n",
      "trainer/Z Expert Targets Std          113.753\n",
      "trainer/Z Expert Targets Max         1291.15\n",
      "trainer/Z Expert Targets Min          527.35\n",
      "trainer/Z Policy Targets Mean         954.094\n",
      "trainer/Z Policy Targets Std          307.9\n",
      "trainer/Z Policy Targets Max         1270.26\n",
      "trainer/Z Policy Targets Min          -50.3868\n",
      "trainer/Log Pis Mean                   30.7635\n",
      "trainer/Log Pis Std                     7.46835\n",
      "trainer/Policy mu Mean                  1.4783\n",
      "trainer/Policy mu Std                   2.60588\n",
      "trainer/Policy log std Mean            -3.39577\n",
      "trainer/Policy log std Std              1.43684\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        232924\n",
      "exploration/num paths total          1000\n",
      "evaluation/num steps total              1.70046e+06\n",
      "evaluation/num paths total           2274\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2284\n",
      "evaluation/Rewards Std                  1.31186\n",
      "evaluation/Rewards Max                  7.28364\n",
      "evaluation/Rewards Min                  0.124335\n",
      "evaluation/Returns Mean              5228.4\n",
      "evaluation/Returns Std                 26.2122\n",
      "evaluation/Returns Max               5269.65\n",
      "evaluation/Returns Min               5178.5\n",
      "evaluation/Estimation Bias Mean      1077.41\n",
      "evaluation/Estimation Bias Std        195.458\n",
      "evaluation/EB/Q_True Mean              49.1821\n",
      "evaluation/EB/Q_True Std              151.966\n",
      "evaluation/EB/Q_Pred Mean            1126.59\n",
      "evaluation/EB/Q_Pred Std              143.535\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5228.4\n",
      "evaluation/Actions Mean                 0.501228\n",
      "evaluation/Actions Std                  0.647507\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.00423\n",
      "time/backward_zf1 (s)                   2.20736\n",
      "time/backward_zf2 (s)                   2.09142\n",
      "time/data sampling (s)                  0.280193\n",
      "time/data storing (s)                   0.0135799\n",
      "time/evaluation sampling (s)            1.40371\n",
      "time/exploration sampling (s)           0.195948\n",
      "time/logging (s)                        0.011901\n",
      "time/preback_alpha (s)                  0.58739\n",
      "time/preback_policy (s)                 1.17153\n",
      "time/preback_start (s)                  0.128012\n",
      "time/preback_zf (s)                     5.14758\n",
      "time/saving (s)                         0.00578267\n",
      "time/training (s)                       2.20451\n",
      "time/epoch (s)                         17.4532\n",
      "time/total (s)                       3779.88\n",
      "Epoch                                 226\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:55:32.302843 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 227 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 238000\n",
      "trainer/ZF1 Loss                       43.4869\n",
      "trainer/ZF2 Loss                       37.3786\n",
      "trainer/ZF Expert Reward               14.4982\n",
      "trainer/ZF Policy Reward                2.06839\n",
      "trainer/ZF CHI2 Term                   53.1671\n",
      "trainer/Policy Loss                  -990.917\n",
      "trainer/Bias Loss                     169.683\n",
      "trainer/Bias Value                     11.7151\n",
      "trainer/Policy Grad Norm              600.792\n",
      "trainer/Policy Param Norm              34.8111\n",
      "trainer/Zf1 Grad Norm                2641.81\n",
      "trainer/Zf1 Param Norm                109.822\n",
      "trainer/Zf2 Grad Norm                3179.36\n",
      "trainer/Zf2 Param Norm                107.906\n",
      "trainer/Z Expert Predictions Mean    1125.21\n",
      "trainer/Z Expert Predictions Std      140.997\n",
      "trainer/Z Expert Predictions Max     1312.84\n",
      "trainer/Z Expert Predictions Min       93.3394\n",
      "trainer/Z Policy Predictions Mean     981.638\n",
      "trainer/Z Policy Predictions Std      300.784\n",
      "trainer/Z Policy Predictions Max     1262.6\n",
      "trainer/Z Policy Predictions Min     -151.447\n",
      "trainer/Z Expert Targets Mean        1110.71\n",
      "trainer/Z Expert Targets Std          146.816\n",
      "trainer/Z Expert Targets Max         1299.04\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         979.57\n",
      "trainer/Z Policy Targets Std          300.024\n",
      "trainer/Z Policy Targets Max         1267.05\n",
      "trainer/Z Policy Targets Min         -136.739\n",
      "trainer/Log Pis Mean                   30.4535\n",
      "trainer/Log Pis Std                     7.48169\n",
      "trainer/Policy mu Mean                  1.43766\n",
      "trainer/Policy mu Std                   2.42821\n",
      "trainer/Policy log std Mean            -3.48874\n",
      "trainer/Policy log std Std              1.3751\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        232924\n",
      "exploration/num paths total          1000\n",
      "evaluation/num steps total              1.71046e+06\n",
      "evaluation/num paths total           2284\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17151\n",
      "evaluation/Rewards Std                  1.30363\n",
      "evaluation/Rewards Max                  7.29924\n",
      "evaluation/Rewards Min                  0.11519\n",
      "evaluation/Returns Mean              5171.51\n",
      "evaluation/Returns Std                 40.2503\n",
      "evaluation/Returns Max               5253.57\n",
      "evaluation/Returns Min               5110.63\n",
      "evaluation/Estimation Bias Mean      1076.55\n",
      "evaluation/Estimation Bias Std        193.919\n",
      "evaluation/EB/Q_True Mean              48.8959\n",
      "evaluation/EB/Q_True Std              150.814\n",
      "evaluation/EB/Q_Pred Mean            1125.44\n",
      "evaluation/EB/Q_Pred Std              141.417\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5171.51\n",
      "evaluation/Actions Mean                 0.505247\n",
      "evaluation/Actions Std                  0.649091\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.02234\n",
      "time/backward_zf1 (s)                   2.18674\n",
      "time/backward_zf2 (s)                   2.09559\n",
      "time/data sampling (s)                  0.296197\n",
      "time/data storing (s)                   0.014789\n",
      "time/evaluation sampling (s)            1.4358\n",
      "time/exploration sampling (s)           0.200803\n",
      "time/logging (s)                        0.011442\n",
      "time/preback_alpha (s)                  0.593159\n",
      "time/preback_policy (s)                 1.19997\n",
      "time/preback_start (s)                  0.131503\n",
      "time/preback_zf (s)                     5.1804\n",
      "time/saving (s)                         0.00565532\n",
      "time/training (s)                       2.16209\n",
      "time/epoch (s)                         17.5365\n",
      "time/total (s)                       3797.44\n",
      "Epoch                                 227\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:55:49.648915 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 228 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 239000\n",
      "trainer/ZF1 Loss                       29.0033\n",
      "trainer/ZF2 Loss                       28.4458\n",
      "trainer/ZF Expert Reward               10.2412\n",
      "trainer/ZF Policy Reward                1.13835\n",
      "trainer/ZF CHI2 Term                   38.1374\n",
      "trainer/Policy Loss                  -938.469\n",
      "trainer/Bias Loss                      81.5313\n",
      "trainer/Bias Value                     11.721\n",
      "trainer/Policy Grad Norm              602.914\n",
      "trainer/Policy Param Norm              34.8368\n",
      "trainer/Zf1 Grad Norm                2514.17\n",
      "trainer/Zf1 Param Norm                110.032\n",
      "trainer/Zf2 Grad Norm                2863.48\n",
      "trainer/Zf2 Param Norm                108.101\n",
      "trainer/Z Expert Predictions Mean    1120.79\n",
      "trainer/Z Expert Predictions Std      122.531\n",
      "trainer/Z Expert Predictions Max     1316.99\n",
      "trainer/Z Expert Predictions Min      680.84\n",
      "trainer/Z Policy Predictions Mean     930.726\n",
      "trainer/Z Policy Predictions Std      356.783\n",
      "trainer/Z Policy Predictions Max     1293.24\n",
      "trainer/Z Policy Predictions Min     -290.279\n",
      "trainer/Z Expert Targets Mean        1110.54\n",
      "trainer/Z Expert Targets Std          124.935\n",
      "trainer/Z Expert Targets Max         1313.19\n",
      "trainer/Z Expert Targets Min          661.906\n",
      "trainer/Z Policy Targets Mean         929.588\n",
      "trainer/Z Policy Targets Std          351.91\n",
      "trainer/Z Policy Targets Max         1274.96\n",
      "trainer/Z Policy Targets Min         -174.465\n",
      "trainer/Log Pis Mean                   31.0077\n",
      "trainer/Log Pis Std                     8.01592\n",
      "trainer/Policy mu Mean                  1.35715\n",
      "trainer/Policy mu Std                   2.57796\n",
      "trainer/Policy log std Mean            -3.52325\n",
      "trainer/Policy log std Std              1.40023\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        232924\n",
      "exploration/num paths total          1000\n",
      "evaluation/num steps total              1.72046e+06\n",
      "evaluation/num paths total           2294\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20303\n",
      "evaluation/Rewards Std                  1.33247\n",
      "evaluation/Rewards Max                  7.2084\n",
      "evaluation/Rewards Min                  0.123625\n",
      "evaluation/Returns Mean              5203.03\n",
      "evaluation/Returns Std                 88.7585\n",
      "evaluation/Returns Max               5260.9\n",
      "evaluation/Returns Min               4944.12\n",
      "evaluation/Estimation Bias Mean      1101.8\n",
      "evaluation/Estimation Bias Std        161.605\n",
      "evaluation/EB/Q_True Mean              49.4688\n",
      "evaluation/EB/Q_True Std              152.818\n",
      "evaluation/EB/Q_Pred Mean            1151.27\n",
      "evaluation/EB/Q_Pred Std               53.6495\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5203.03\n",
      "evaluation/Actions Mean                 0.515402\n",
      "evaluation/Actions Std                  0.639017\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.91007\n",
      "time/backward_zf1 (s)                   2.06523\n",
      "time/backward_zf2 (s)                   1.99553\n",
      "time/data sampling (s)                  0.265996\n",
      "time/data storing (s)                   0.0146851\n",
      "time/evaluation sampling (s)            1.4798\n",
      "time/exploration sampling (s)           0.196447\n",
      "time/logging (s)                        0.0132166\n",
      "time/preback_alpha (s)                  0.589758\n",
      "time/preback_policy (s)                 1.08288\n",
      "time/preback_start (s)                  0.126808\n",
      "time/preback_zf (s)                     5.14886\n",
      "time/saving (s)                         0.00558199\n",
      "time/training (s)                       2.38563\n",
      "time/epoch (s)                         17.2805\n",
      "time/total (s)                       3814.73\n",
      "Epoch                                 228\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:56:06.886096 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 229 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 240000\n",
      "trainer/ZF1 Loss                       36.6731\n",
      "trainer/ZF2 Loss                       35.1161\n",
      "trainer/ZF Expert Reward               10.795\n",
      "trainer/ZF Policy Reward               -5.33093\n",
      "trainer/ZF CHI2 Term                   52.3251\n",
      "trainer/Policy Loss                  -972.769\n",
      "trainer/Bias Loss                     127.301\n",
      "trainer/Bias Value                     11.7269\n",
      "trainer/Policy Grad Norm              494.731\n",
      "trainer/Policy Param Norm              34.8662\n",
      "trainer/Zf1 Grad Norm                3895.57\n",
      "trainer/Zf1 Param Norm                110.251\n",
      "trainer/Zf2 Grad Norm                3873.34\n",
      "trainer/Zf2 Param Norm                108.305\n",
      "trainer/Z Expert Predictions Mean    1121.07\n",
      "trainer/Z Expert Predictions Std      114.878\n",
      "trainer/Z Expert Predictions Max     1320.13\n",
      "trainer/Z Expert Predictions Min      544.863\n",
      "trainer/Z Policy Predictions Mean     958.732\n",
      "trainer/Z Policy Predictions Std      291.109\n",
      "trainer/Z Policy Predictions Max     1264.02\n",
      "trainer/Z Policy Predictions Min     -102.546\n",
      "trainer/Z Expert Targets Mean        1110.27\n",
      "trainer/Z Expert Targets Std          117.33\n",
      "trainer/Z Expert Targets Max         1297.63\n",
      "trainer/Z Expert Targets Min          519.207\n",
      "trainer/Z Policy Targets Mean         964.063\n",
      "trainer/Z Policy Targets Std          287.236\n",
      "trainer/Z Policy Targets Max         1264.49\n",
      "trainer/Z Policy Targets Min          -34.6449\n",
      "trainer/Log Pis Mean                   30.4575\n",
      "trainer/Log Pis Std                     7.1173\n",
      "trainer/Policy mu Mean                  1.41722\n",
      "trainer/Policy mu Std                   2.43748\n",
      "trainer/Policy log std Mean            -3.41157\n",
      "trainer/Policy log std Std              1.38763\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        235924\n",
      "exploration/num paths total          1003\n",
      "evaluation/num steps total              1.73046e+06\n",
      "evaluation/num paths total           2304\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.155\n",
      "evaluation/Rewards Std                  1.31212\n",
      "evaluation/Rewards Max                  7.15657\n",
      "evaluation/Rewards Min                  0.111104\n",
      "evaluation/Returns Mean              5155\n",
      "evaluation/Returns Std                 56.7129\n",
      "evaluation/Returns Max               5254.18\n",
      "evaluation/Returns Min               5051.73\n",
      "evaluation/Estimation Bias Mean      1104.6\n",
      "evaluation/Estimation Bias Std        155.732\n",
      "evaluation/EB/Q_True Mean              47.7624\n",
      "evaluation/EB/Q_True Std              148.147\n",
      "evaluation/EB/Q_Pred Mean            1152.36\n",
      "evaluation/EB/Q_Pred Std               58.6709\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5155\n",
      "evaluation/Actions Mean                 0.519963\n",
      "evaluation/Actions Std                  0.641634\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                1.95084\n",
      "time/backward_zf1 (s)                   2.08414\n",
      "time/backward_zf2 (s)                   2.01531\n",
      "time/data sampling (s)                  0.265213\n",
      "time/data storing (s)                   0.0140497\n",
      "time/evaluation sampling (s)            1.42032\n",
      "time/exploration sampling (s)           0.204417\n",
      "time/logging (s)                        0.0118217\n",
      "time/preback_alpha (s)                  0.580359\n",
      "time/preback_policy (s)                 1.12182\n",
      "time/preback_start (s)                  0.129249\n",
      "time/preback_zf (s)                     5.10772\n",
      "time/saving (s)                         0.0193546\n",
      "time/training (s)                       2.23813\n",
      "time/epoch (s)                         17.1628\n",
      "time/total (s)                       3831.92\n",
      "Epoch                                 229\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:56:24.576396 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 230 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 241000\n",
      "trainer/ZF1 Loss                       34.6748\n",
      "trainer/ZF2 Loss                       32.7091\n",
      "trainer/ZF Expert Reward               12.2629\n",
      "trainer/ZF Policy Reward               -1.7158\n",
      "trainer/ZF CHI2 Term                   47.9759\n",
      "trainer/Policy Loss                  -962.003\n",
      "trainer/Bias Loss                      88.527\n",
      "trainer/Bias Value                     11.7325\n",
      "trainer/Policy Grad Norm              546.698\n",
      "trainer/Policy Param Norm              34.8903\n",
      "trainer/Zf1 Grad Norm                2932.26\n",
      "trainer/Zf1 Param Norm                110.462\n",
      "trainer/Zf2 Grad Norm                2378.65\n",
      "trainer/Zf2 Param Norm                108.489\n",
      "trainer/Z Expert Predictions Mean    1150.9\n",
      "trainer/Z Expert Predictions Std       94.0519\n",
      "trainer/Z Expert Predictions Max     1303.69\n",
      "trainer/Z Expert Predictions Min      666.671\n",
      "trainer/Z Policy Predictions Mean     951.635\n",
      "trainer/Z Policy Predictions Std      316.349\n",
      "trainer/Z Policy Predictions Max     1261.78\n",
      "trainer/Z Policy Predictions Min      -87.7661\n",
      "trainer/Z Expert Targets Mean        1138.63\n",
      "trainer/Z Expert Targets Std           94.0647\n",
      "trainer/Z Expert Targets Max         1295.36\n",
      "trainer/Z Expert Targets Min          633.72\n",
      "trainer/Z Policy Targets Mean         953.351\n",
      "trainer/Z Policy Targets Std          312.99\n",
      "trainer/Z Policy Targets Max         1258.57\n",
      "trainer/Z Policy Targets Min          -88.2705\n",
      "trainer/Log Pis Mean                   30.5179\n",
      "trainer/Log Pis Std                     7.22129\n",
      "trainer/Policy mu Mean                  1.4024\n",
      "trainer/Policy mu Std                   2.44544\n",
      "trainer/Policy log std Mean            -3.43843\n",
      "trainer/Policy log std Std              1.40739\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        235924\n",
      "exploration/num paths total          1003\n",
      "evaluation/num steps total              1.74046e+06\n",
      "evaluation/num paths total           2314\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19202\n",
      "evaluation/Rewards Std                  1.32097\n",
      "evaluation/Rewards Max                  7.15\n",
      "evaluation/Rewards Min                  0.0898582\n",
      "evaluation/Returns Mean              5192.02\n",
      "evaluation/Returns Std                 41.0653\n",
      "evaluation/Returns Max               5232.18\n",
      "evaluation/Returns Min               5089.78\n",
      "evaluation/Estimation Bias Mean      1113.91\n",
      "evaluation/Estimation Bias Std        153.641\n",
      "evaluation/EB/Q_True Mean              49.3167\n",
      "evaluation/EB/Q_True Std              152.184\n",
      "evaluation/EB/Q_Pred Mean            1163.23\n",
      "evaluation/EB/Q_Pred Std               57.0397\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5192.02\n",
      "evaluation/Actions Mean                 0.511437\n",
      "evaluation/Actions Std                  0.642335\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.04867\n",
      "time/backward_zf1 (s)                   2.20661\n",
      "time/backward_zf2 (s)                   2.14422\n",
      "time/data sampling (s)                  0.294887\n",
      "time/data storing (s)                   0.0144112\n",
      "time/evaluation sampling (s)            1.43376\n",
      "time/exploration sampling (s)           0.195509\n",
      "time/logging (s)                        0.0119255\n",
      "time/preback_alpha (s)                  0.591719\n",
      "time/preback_policy (s)                 1.18923\n",
      "time/preback_start (s)                  0.12898\n",
      "time/preback_zf (s)                     5.13353\n",
      "time/saving (s)                         0.0200166\n",
      "time/training (s)                       2.20242\n",
      "time/epoch (s)                         17.6159\n",
      "time/total (s)                       3849.56\n",
      "Epoch                                 230\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:56:42.344926 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 231 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 242000\n",
      "trainer/ZF1 Loss                       67.3855\n",
      "trainer/ZF2 Loss                       73.2816\n",
      "trainer/ZF Expert Reward               12.1484\n",
      "trainer/ZF Policy Reward                3.79976\n",
      "trainer/ZF CHI2 Term                   78.9904\n",
      "trainer/Policy Loss                  -948.171\n",
      "trainer/Bias Loss                      82.2511\n",
      "trainer/Bias Value                     11.7383\n",
      "trainer/Policy Grad Norm              338.051\n",
      "trainer/Policy Param Norm              34.9167\n",
      "trainer/Zf1 Grad Norm                2449.26\n",
      "trainer/Zf1 Param Norm                110.663\n",
      "trainer/Zf2 Grad Norm                4878.95\n",
      "trainer/Zf2 Param Norm                108.68\n",
      "trainer/Z Expert Predictions Mean    1135.9\n",
      "trainer/Z Expert Predictions Std       94.7335\n",
      "trainer/Z Expert Predictions Max     1317.23\n",
      "trainer/Z Expert Predictions Min      702.279\n",
      "trainer/Z Policy Predictions Mean     938.113\n",
      "trainer/Z Policy Predictions Std      338.709\n",
      "trainer/Z Policy Predictions Max     1257.19\n",
      "trainer/Z Policy Predictions Min      -91.4141\n",
      "trainer/Z Expert Targets Mean        1123.75\n",
      "trainer/Z Expert Targets Std           97.4187\n",
      "trainer/Z Expert Targets Max         1313.38\n",
      "trainer/Z Expert Targets Min          698.26\n",
      "trainer/Z Policy Targets Mean         934.314\n",
      "trainer/Z Policy Targets Std          339.24\n",
      "trainer/Z Policy Targets Max         1245.71\n",
      "trainer/Z Policy Targets Min          -96.966\n",
      "trainer/Log Pis Mean                   30.8145\n",
      "trainer/Log Pis Std                     7.67731\n",
      "trainer/Policy mu Mean                  1.47507\n",
      "trainer/Policy mu Std                   2.61989\n",
      "trainer/Policy log std Mean            -3.36206\n",
      "trainer/Policy log std Std              1.44807\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        236924\n",
      "exploration/num paths total          1004\n",
      "evaluation/num steps total              1.75046e+06\n",
      "evaluation/num paths total           2324\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18264\n",
      "evaluation/Rewards Std                  1.32367\n",
      "evaluation/Rewards Max                  7.2102\n",
      "evaluation/Rewards Min                  0.133376\n",
      "evaluation/Returns Mean              5182.64\n",
      "evaluation/Returns Std                 56.4917\n",
      "evaluation/Returns Max               5244.39\n",
      "evaluation/Returns Min               5072.39\n",
      "evaluation/Estimation Bias Mean      1114.19\n",
      "evaluation/Estimation Bias Std        163.818\n",
      "evaluation/EB/Q_True Mean              49.6121\n",
      "evaluation/EB/Q_True Std              153.028\n",
      "evaluation/EB/Q_Pred Mean            1163.8\n",
      "evaluation/EB/Q_Pred Std               64.6187\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5182.64\n",
      "evaluation/Actions Mean                 0.507184\n",
      "evaluation/Actions Std                  0.642738\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.03005\n",
      "time/backward_zf1 (s)                   2.19521\n",
      "time/backward_zf2 (s)                   2.09368\n",
      "time/data sampling (s)                  0.292247\n",
      "time/data storing (s)                   0.0155731\n",
      "time/evaluation sampling (s)            1.47047\n",
      "time/exploration sampling (s)           0.205039\n",
      "time/logging (s)                        0.0122301\n",
      "time/preback_alpha (s)                  0.604387\n",
      "time/preback_policy (s)                 1.20341\n",
      "time/preback_start (s)                  0.130689\n",
      "time/preback_zf (s)                     5.21564\n",
      "time/saving (s)                         0.00565937\n",
      "time/training (s)                       2.2254\n",
      "time/epoch (s)                         17.6997\n",
      "time/total (s)                       3867.28\n",
      "Epoch                                 231\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:56:59.717916 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 232 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 243000\n",
      "trainer/ZF1 Loss                       39.7905\n",
      "trainer/ZF2 Loss                       32.7932\n",
      "trainer/ZF Expert Reward               16.1012\n",
      "trainer/ZF Policy Reward                2.65018\n",
      "trainer/ZF CHI2 Term                   50.0485\n",
      "trainer/Policy Loss                  -985.852\n",
      "trainer/Bias Loss                     124.294\n",
      "trainer/Bias Value                     11.7442\n",
      "trainer/Policy Grad Norm              579.185\n",
      "trainer/Policy Param Norm              34.9444\n",
      "trainer/Zf1 Grad Norm                3352.35\n",
      "trainer/Zf1 Param Norm                110.882\n",
      "trainer/Zf2 Grad Norm                1987.16\n",
      "trainer/Zf2 Param Norm                108.891\n",
      "trainer/Z Expert Predictions Mean    1130.91\n",
      "trainer/Z Expert Predictions Std      116.618\n",
      "trainer/Z Expert Predictions Max     1343.45\n",
      "trainer/Z Expert Predictions Min      690.219\n",
      "trainer/Z Policy Predictions Mean     976.518\n",
      "trainer/Z Policy Predictions Std      302.072\n",
      "trainer/Z Policy Predictions Max     1311.75\n",
      "trainer/Z Policy Predictions Min      -79.9241\n",
      "trainer/Z Expert Targets Mean        1114.81\n",
      "trainer/Z Expert Targets Std          121.375\n",
      "trainer/Z Expert Targets Max         1354.49\n",
      "trainer/Z Expert Targets Min          652.292\n",
      "trainer/Z Policy Targets Mean         973.867\n",
      "trainer/Z Policy Targets Std          300.169\n",
      "trainer/Z Policy Targets Max         1301.87\n",
      "trainer/Z Policy Targets Min          -78.2366\n",
      "trainer/Log Pis Mean                   30.5636\n",
      "trainer/Log Pis Std                     8.17335\n",
      "trainer/Policy mu Mean                  1.32968\n",
      "trainer/Policy mu Std                   2.65911\n",
      "trainer/Policy log std Mean            -3.47656\n",
      "trainer/Policy log std Std              1.41034\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        236924\n",
      "exploration/num paths total          1004\n",
      "evaluation/num steps total              1.76022e+06\n",
      "evaluation/num paths total           2334\n",
      "evaluation/path length Mean           975.6\n",
      "evaluation/path length Std             49.6129\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            858\n",
      "evaluation/Rewards Mean                 5.16422\n",
      "evaluation/Rewards Std                  1.31038\n",
      "evaluation/Rewards Max                  7.16382\n",
      "evaluation/Rewards Min                  0.113456\n",
      "evaluation/Returns Mean              5038.21\n",
      "evaluation/Returns Std                271.693\n",
      "evaluation/Returns Max               5252.51\n",
      "evaluation/Returns Min               4398.27\n",
      "evaluation/Estimation Bias Mean       954.35\n",
      "evaluation/Estimation Bias Std        323.063\n",
      "evaluation/EB/Q_True Mean              50.364\n",
      "evaluation/EB/Q_True Std              153.6\n",
      "evaluation/EB/Q_Pred Mean            1004.71\n",
      "evaluation/EB/Q_Pred Std              281.024\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5038.21\n",
      "evaluation/Actions Mean                 0.491621\n",
      "evaluation/Actions Std                  0.662201\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98963\n",
      "time/backward_zf1 (s)                   2.13216\n",
      "time/backward_zf2 (s)                   2.03855\n",
      "time/data sampling (s)                  0.291682\n",
      "time/data storing (s)                   0.014135\n",
      "time/evaluation sampling (s)            1.41755\n",
      "time/exploration sampling (s)           0.198657\n",
      "time/logging (s)                        0.0115949\n",
      "time/preback_alpha (s)                  0.584551\n",
      "time/preback_policy (s)                 1.12514\n",
      "time/preback_start (s)                  0.1273\n",
      "time/preback_zf (s)                     5.09587\n",
      "time/saving (s)                         0.00573119\n",
      "time/training (s)                       2.26828\n",
      "time/epoch (s)                         17.3008\n",
      "time/total (s)                       3884.6\n",
      "Epoch                                 232\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:57:17.188977 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 233 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 244000\n",
      "trainer/ZF1 Loss                       32.482\n",
      "trainer/ZF2 Loss                       33.1798\n",
      "trainer/ZF Expert Reward               15.5942\n",
      "trainer/ZF Policy Reward                4.47777\n",
      "trainer/ZF CHI2 Term                   44.2434\n",
      "trainer/Policy Loss                  -974.437\n",
      "trainer/Bias Loss                     162.613\n",
      "trainer/Bias Value                     11.7501\n",
      "trainer/Policy Grad Norm              355.761\n",
      "trainer/Policy Param Norm              34.9715\n",
      "trainer/Zf1 Grad Norm                2588.41\n",
      "trainer/Zf1 Param Norm                111.079\n",
      "trainer/Zf2 Grad Norm                2803.07\n",
      "trainer/Zf2 Param Norm                109.076\n",
      "trainer/Z Expert Predictions Mean    1127.8\n",
      "trainer/Z Expert Predictions Std      106.756\n",
      "trainer/Z Expert Predictions Max     1353.53\n",
      "trainer/Z Expert Predictions Min      636.194\n",
      "trainer/Z Policy Predictions Mean     969.419\n",
      "trainer/Z Policy Predictions Std      308.204\n",
      "trainer/Z Policy Predictions Max     1317.67\n",
      "trainer/Z Policy Predictions Min      -82.9067\n",
      "trainer/Z Expert Targets Mean        1112.2\n",
      "trainer/Z Expert Targets Std          108.075\n",
      "trainer/Z Expert Targets Max         1316.21\n",
      "trainer/Z Expert Targets Min          636.359\n",
      "trainer/Z Policy Targets Mean         964.941\n",
      "trainer/Z Policy Targets Std          305.803\n",
      "trainer/Z Policy Targets Max         1313.73\n",
      "trainer/Z Policy Targets Min          -96.8931\n",
      "trainer/Log Pis Mean                   29.6032\n",
      "trainer/Log Pis Std                     6.70656\n",
      "trainer/Policy mu Mean                  1.3504\n",
      "trainer/Policy mu Std                   2.39027\n",
      "trainer/Policy log std Mean            -3.49734\n",
      "trainer/Policy log std Std              1.39847\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        239924\n",
      "exploration/num paths total          1007\n",
      "evaluation/num steps total              1.77022e+06\n",
      "evaluation/num paths total           2344\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09893\n",
      "evaluation/Rewards Std                  1.28833\n",
      "evaluation/Rewards Max                  7.13406\n",
      "evaluation/Rewards Min                  0.113491\n",
      "evaluation/Returns Mean              5098.93\n",
      "evaluation/Returns Std                 27.0331\n",
      "evaluation/Returns Max               5140.01\n",
      "evaluation/Returns Min               5058.49\n",
      "evaluation/Estimation Bias Mean      1056.13\n",
      "evaluation/Estimation Bias Std        204.179\n",
      "evaluation/EB/Q_True Mean              48.5798\n",
      "evaluation/EB/Q_True Std              150.119\n",
      "evaluation/EB/Q_Pred Mean            1104.71\n",
      "evaluation/EB/Q_Pred Std              113.548\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5098.93\n",
      "evaluation/Actions Mean                 0.504252\n",
      "evaluation/Actions Std                  0.649973\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94569\n",
      "time/backward_zf1 (s)                   2.10751\n",
      "time/backward_zf2 (s)                   2.0391\n",
      "time/data sampling (s)                  0.292314\n",
      "time/data storing (s)                   0.0159235\n",
      "time/evaluation sampling (s)            1.39438\n",
      "time/exploration sampling (s)           0.213388\n",
      "time/logging (s)                        0.0131913\n",
      "time/preback_alpha (s)                  0.595911\n",
      "time/preback_policy (s)                 1.1737\n",
      "time/preback_start (s)                  0.129989\n",
      "time/preback_zf (s)                     5.17931\n",
      "time/saving (s)                         0.00580839\n",
      "time/training (s)                       2.29418\n",
      "time/epoch (s)                         17.4004\n",
      "time/total (s)                       3902.02\n",
      "Epoch                                 233\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:57:34.946780 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 234 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 245000\n",
      "trainer/ZF1 Loss                       26.8197\n",
      "trainer/ZF2 Loss                       24.0519\n",
      "trainer/ZF Expert Reward               16.1863\n",
      "trainer/ZF Policy Reward                3.72916\n",
      "trainer/ZF CHI2 Term                   38.1938\n",
      "trainer/Policy Loss                  -983.286\n",
      "trainer/Bias Loss                      92.3193\n",
      "trainer/Bias Value                     11.7559\n",
      "trainer/Policy Grad Norm              409.823\n",
      "trainer/Policy Param Norm              34.9978\n",
      "trainer/Zf1 Grad Norm                1947.8\n",
      "trainer/Zf1 Param Norm                111.286\n",
      "trainer/Zf2 Grad Norm                2113.86\n",
      "trainer/Zf2 Param Norm                109.262\n",
      "trainer/Z Expert Predictions Mean    1145.1\n",
      "trainer/Z Expert Predictions Std       89.1352\n",
      "trainer/Z Expert Predictions Max     1335.41\n",
      "trainer/Z Expert Predictions Min      702.59\n",
      "trainer/Z Policy Predictions Mean     972.062\n",
      "trainer/Z Policy Predictions Std      285.106\n",
      "trainer/Z Policy Predictions Max     1244.42\n",
      "trainer/Z Policy Predictions Min      -92.4372\n",
      "trainer/Z Expert Targets Mean        1128.91\n",
      "trainer/Z Expert Targets Std           91.0233\n",
      "trainer/Z Expert Targets Max         1309.59\n",
      "trainer/Z Expert Targets Min          644.754\n",
      "trainer/Z Policy Targets Mean         968.333\n",
      "trainer/Z Policy Targets Std          282.698\n",
      "trainer/Z Policy Targets Max         1263.66\n",
      "trainer/Z Policy Targets Min          -98.5383\n",
      "trainer/Log Pis Mean                   30.0788\n",
      "trainer/Log Pis Std                     6.6236\n",
      "trainer/Policy mu Mean                  1.35276\n",
      "trainer/Policy mu Std                   2.32631\n",
      "trainer/Policy log std Mean            -3.52903\n",
      "trainer/Policy log std Std              1.4289\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        240924\n",
      "exploration/num paths total          1008\n",
      "evaluation/num steps total              1.78022e+06\n",
      "evaluation/num paths total           2354\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21094\n",
      "evaluation/Rewards Std                  1.33153\n",
      "evaluation/Rewards Max                  7.24328\n",
      "evaluation/Rewards Min                  0.100018\n",
      "evaluation/Returns Mean              5210.94\n",
      "evaluation/Returns Std                 16.2261\n",
      "evaluation/Returns Max               5244.49\n",
      "evaluation/Returns Min               5184.33\n",
      "evaluation/Estimation Bias Mean      1122.16\n",
      "evaluation/Estimation Bias Std        166.369\n",
      "evaluation/EB/Q_True Mean              49.3715\n",
      "evaluation/EB/Q_True Std              152.437\n",
      "evaluation/EB/Q_Pred Mean            1171.53\n",
      "evaluation/EB/Q_Pred Std               65.9005\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5210.94\n",
      "evaluation/Actions Mean                 0.495127\n",
      "evaluation/Actions Std                  0.646479\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.03567\n",
      "time/backward_zf1 (s)                   2.17507\n",
      "time/backward_zf2 (s)                   2.12582\n",
      "time/data sampling (s)                  0.296402\n",
      "time/data storing (s)                   0.0149518\n",
      "time/evaluation sampling (s)            1.43031\n",
      "time/exploration sampling (s)           0.204445\n",
      "time/logging (s)                        0.012157\n",
      "time/preback_alpha (s)                  0.598515\n",
      "time/preback_policy (s)                 1.18685\n",
      "time/preback_start (s)                  0.130173\n",
      "time/preback_zf (s)                     5.18004\n",
      "time/saving (s)                         0.00575731\n",
      "time/training (s)                       2.29103\n",
      "time/epoch (s)                         17.6872\n",
      "time/total (s)                       3919.73\n",
      "Epoch                                 234\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:57:52.354436 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 235 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 246000\n",
      "trainer/ZF1 Loss                       33.4133\n",
      "trainer/ZF2 Loss                       26.9663\n",
      "trainer/ZF Expert Reward               18.4801\n",
      "trainer/ZF Policy Reward                4.13608\n",
      "trainer/ZF CHI2 Term                   44.8465\n",
      "trainer/Policy Loss                  -949.525\n",
      "trainer/Bias Loss                     109.611\n",
      "trainer/Bias Value                     11.7619\n",
      "trainer/Policy Grad Norm              472.708\n",
      "trainer/Policy Param Norm              35.0217\n",
      "trainer/Zf1 Grad Norm                2328.01\n",
      "trainer/Zf1 Param Norm                111.496\n",
      "trainer/Zf2 Grad Norm                2161.4\n",
      "trainer/Zf2 Param Norm                109.464\n",
      "trainer/Z Expert Predictions Mean    1139.9\n",
      "trainer/Z Expert Predictions Std       99.1762\n",
      "trainer/Z Expert Predictions Max     1341.63\n",
      "trainer/Z Expert Predictions Min      811.022\n",
      "trainer/Z Policy Predictions Mean     940.376\n",
      "trainer/Z Policy Predictions Std      317.007\n",
      "trainer/Z Policy Predictions Max     1323.79\n",
      "trainer/Z Policy Predictions Min      -78.2494\n",
      "trainer/Z Expert Targets Mean        1121.42\n",
      "trainer/Z Expert Targets Std           98.7931\n",
      "trainer/Z Expert Targets Max         1314.88\n",
      "trainer/Z Expert Targets Min          772.276\n",
      "trainer/Z Policy Targets Mean         936.24\n",
      "trainer/Z Policy Targets Std          315.188\n",
      "trainer/Z Policy Targets Max         1277.88\n",
      "trainer/Z Policy Targets Min          -67.7691\n",
      "trainer/Log Pis Mean                   31.2702\n",
      "trainer/Log Pis Std                     8.09471\n",
      "trainer/Policy mu Mean                  1.45758\n",
      "trainer/Policy mu Std                   2.63133\n",
      "trainer/Policy log std Mean            -3.46801\n",
      "trainer/Policy log std Std              1.42523\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        240924\n",
      "exploration/num paths total          1008\n",
      "evaluation/num steps total              1.79022e+06\n",
      "evaluation/num paths total           2364\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18359\n",
      "evaluation/Rewards Std                  1.3187\n",
      "evaluation/Rewards Max                  7.2059\n",
      "evaluation/Rewards Min                  0.129606\n",
      "evaluation/Returns Mean              5183.59\n",
      "evaluation/Returns Std                 23.0668\n",
      "evaluation/Returns Max               5225.82\n",
      "evaluation/Returns Min               5134.85\n",
      "evaluation/Estimation Bias Mean      1097.21\n",
      "evaluation/Estimation Bias Std        164.869\n",
      "evaluation/EB/Q_True Mean              48.8495\n",
      "evaluation/EB/Q_True Std              150.86\n",
      "evaluation/EB/Q_Pred Mean            1146.06\n",
      "evaluation/EB/Q_Pred Std               64.7559\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5183.59\n",
      "evaluation/Actions Mean                 0.508805\n",
      "evaluation/Actions Std                  0.644369\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98133\n",
      "time/backward_zf1 (s)                   2.11101\n",
      "time/backward_zf2 (s)                   2.02789\n",
      "time/data sampling (s)                  0.307794\n",
      "time/data storing (s)                   0.0147803\n",
      "time/evaluation sampling (s)            1.41856\n",
      "time/exploration sampling (s)           0.203414\n",
      "time/logging (s)                        0.0118266\n",
      "time/preback_alpha (s)                  0.59\n",
      "time/preback_policy (s)                 1.13653\n",
      "time/preback_start (s)                  0.129257\n",
      "time/preback_zf (s)                     5.12805\n",
      "time/saving (s)                         0.00566251\n",
      "time/training (s)                       2.25813\n",
      "time/epoch (s)                         17.3242\n",
      "time/total (s)                       3937.09\n",
      "Epoch                                 235\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:58:09.984444 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 236 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 247000\n",
      "trainer/ZF1 Loss                       28.1754\n",
      "trainer/ZF2 Loss                       27.9706\n",
      "trainer/ZF Expert Reward               13.6658\n",
      "trainer/ZF Policy Reward               -1.89397\n",
      "trainer/ZF CHI2 Term                   43.9408\n",
      "trainer/Policy Loss                  -979.57\n",
      "trainer/Bias Loss                     140.249\n",
      "trainer/Bias Value                     11.768\n",
      "trainer/Policy Grad Norm              435.981\n",
      "trainer/Policy Param Norm              35.0477\n",
      "trainer/Zf1 Grad Norm                2402.7\n",
      "trainer/Zf1 Param Norm                111.705\n",
      "trainer/Zf2 Grad Norm                2834.53\n",
      "trainer/Zf2 Param Norm                109.653\n",
      "trainer/Z Expert Predictions Mean    1117.16\n",
      "trainer/Z Expert Predictions Std      116.282\n",
      "trainer/Z Expert Predictions Max     1298.17\n",
      "trainer/Z Expert Predictions Min      668.771\n",
      "trainer/Z Policy Predictions Mean     969.485\n",
      "trainer/Z Policy Predictions Std      296.584\n",
      "trainer/Z Policy Predictions Max     1282.96\n",
      "trainer/Z Policy Predictions Min      -83.8255\n",
      "trainer/Z Expert Targets Mean        1103.49\n",
      "trainer/Z Expert Targets Std          119.924\n",
      "trainer/Z Expert Targets Max         1305.9\n",
      "trainer/Z Expert Targets Min          611.684\n",
      "trainer/Z Policy Targets Mean         971.379\n",
      "trainer/Z Policy Targets Std          293.848\n",
      "trainer/Z Policy Targets Max         1277.62\n",
      "trainer/Z Policy Targets Min          -86.6483\n",
      "trainer/Log Pis Mean                   30.7994\n",
      "trainer/Log Pis Std                     8.58187\n",
      "trainer/Policy mu Mean                  1.3711\n",
      "trainer/Policy mu Std                   2.60609\n",
      "trainer/Policy log std Mean            -3.41586\n",
      "trainer/Policy log std Std              1.35253\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        242924\n",
      "exploration/num paths total          1010\n",
      "evaluation/num steps total              1.80022e+06\n",
      "evaluation/num paths total           2374\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1716\n",
      "evaluation/Rewards Std                  1.31122\n",
      "evaluation/Rewards Max                  7.15913\n",
      "evaluation/Rewards Min                  0.097858\n",
      "evaluation/Returns Mean              5171.6\n",
      "evaluation/Returns Std                 36.6078\n",
      "evaluation/Returns Max               5232.85\n",
      "evaluation/Returns Min               5120.84\n",
      "evaluation/Estimation Bias Mean      1004.29\n",
      "evaluation/Estimation Bias Std        237.952\n",
      "evaluation/EB/Q_True Mean              49.3464\n",
      "evaluation/EB/Q_True Std              152.468\n",
      "evaluation/EB/Q_Pred Mean            1053.64\n",
      "evaluation/EB/Q_Pred Std              197.28\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5171.6\n",
      "evaluation/Actions Mean                 0.502649\n",
      "evaluation/Actions Std                  0.656159\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.03632\n",
      "time/backward_zf1 (s)                   2.17916\n",
      "time/backward_zf2 (s)                   2.1086\n",
      "time/data sampling (s)                  0.283376\n",
      "time/data storing (s)                   0.014698\n",
      "time/evaluation sampling (s)            1.39598\n",
      "time/exploration sampling (s)           0.208903\n",
      "time/logging (s)                        0.0118393\n",
      "time/preback_alpha (s)                  0.594987\n",
      "time/preback_policy (s)                 1.15729\n",
      "time/preback_start (s)                  0.129474\n",
      "time/preback_zf (s)                     5.1489\n",
      "time/saving (s)                         0.00571853\n",
      "time/training (s)                       2.28343\n",
      "time/epoch (s)                         17.5587\n",
      "time/total (s)                       3954.67\n",
      "Epoch                                 236\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:58:27.560115 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 237 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 248000\n",
      "trainer/ZF1 Loss                       38.2119\n",
      "trainer/ZF2 Loss                       32.6858\n",
      "trainer/ZF Expert Reward               18.1091\n",
      "trainer/ZF Policy Reward                2.61188\n",
      "trainer/ZF CHI2 Term                   51.2418\n",
      "trainer/Policy Loss                  -958.939\n",
      "trainer/Bias Loss                     130.62\n",
      "trainer/Bias Value                     11.7742\n",
      "trainer/Policy Grad Norm              438.408\n",
      "trainer/Policy Param Norm              35.0764\n",
      "trainer/Zf1 Grad Norm                2493.04\n",
      "trainer/Zf1 Param Norm                111.898\n",
      "trainer/Zf2 Grad Norm                2176.53\n",
      "trainer/Zf2 Param Norm                109.845\n",
      "trainer/Z Expert Predictions Mean    1130.04\n",
      "trainer/Z Expert Predictions Std       97.63\n",
      "trainer/Z Expert Predictions Max     1302.36\n",
      "trainer/Z Expert Predictions Min      678.655\n",
      "trainer/Z Policy Predictions Mean     951.892\n",
      "trainer/Z Policy Predictions Std      292.409\n",
      "trainer/Z Policy Predictions Max     1323.81\n",
      "trainer/Z Policy Predictions Min     -114.488\n",
      "trainer/Z Expert Targets Mean        1111.94\n",
      "trainer/Z Expert Targets Std          101.12\n",
      "trainer/Z Expert Targets Max         1293.27\n",
      "trainer/Z Expert Targets Min          629.617\n",
      "trainer/Z Policy Targets Mean         949.28\n",
      "trainer/Z Policy Targets Std          287.209\n",
      "trainer/Z Policy Targets Max         1300.06\n",
      "trainer/Z Policy Targets Min          -90.0633\n",
      "trainer/Log Pis Mean                   29.5732\n",
      "trainer/Log Pis Std                     6.5709\n",
      "trainer/Policy mu Mean                  1.33977\n",
      "trainer/Policy mu Std                   2.31165\n",
      "trainer/Policy log std Mean            -3.50384\n",
      "trainer/Policy log std Std              1.36406\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        242924\n",
      "exploration/num paths total          1010\n",
      "evaluation/num steps total              1.81022e+06\n",
      "evaluation/num paths total           2384\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.208\n",
      "evaluation/Rewards Std                  1.32796\n",
      "evaluation/Rewards Max                  7.22977\n",
      "evaluation/Rewards Min                  0.0853202\n",
      "evaluation/Returns Mean              5208\n",
      "evaluation/Returns Std                 18.5758\n",
      "evaluation/Returns Max               5238.29\n",
      "evaluation/Returns Min               5181.55\n",
      "evaluation/Estimation Bias Mean      1081.92\n",
      "evaluation/Estimation Bias Std        171.631\n",
      "evaluation/EB/Q_True Mean              49.3379\n",
      "evaluation/EB/Q_True Std              152.274\n",
      "evaluation/EB/Q_Pred Mean            1131.25\n",
      "evaluation/EB/Q_Pred Std               87.6243\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5208\n",
      "evaluation/Actions Mean                 0.498385\n",
      "evaluation/Actions Std                  0.650979\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93486\n",
      "time/backward_zf1 (s)                   2.07586\n",
      "time/backward_zf2 (s)                   1.97902\n",
      "time/data sampling (s)                  0.302394\n",
      "time/data storing (s)                   0.0141175\n",
      "time/evaluation sampling (s)            1.57635\n",
      "time/exploration sampling (s)           0.196288\n",
      "time/logging (s)                        0.0121601\n",
      "time/preback_alpha (s)                  0.596498\n",
      "time/preback_policy (s)                 1.07328\n",
      "time/preback_start (s)                  0.128213\n",
      "time/preback_zf (s)                     5.17037\n",
      "time/saving (s)                         0.0069599\n",
      "time/training (s)                       2.42479\n",
      "time/epoch (s)                         17.4912\n",
      "time/total (s)                       3972.19\n",
      "Epoch                                 237\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:58:45.793541 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 238 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 249000\n",
      "trainer/ZF1 Loss                       28.875\n",
      "trainer/ZF2 Loss                       23.0602\n",
      "trainer/ZF Expert Reward               12.0923\n",
      "trainer/ZF Policy Reward               -2.26775\n",
      "trainer/ZF CHI2 Term                   40.6374\n",
      "trainer/Policy Loss                  -951.431\n",
      "trainer/Bias Loss                      85.2284\n",
      "trainer/Bias Value                     11.7801\n",
      "trainer/Policy Grad Norm              411.111\n",
      "trainer/Policy Param Norm              35.1036\n",
      "trainer/Zf1 Grad Norm                2402.57\n",
      "trainer/Zf1 Param Norm                112.09\n",
      "trainer/Zf2 Grad Norm                2812.26\n",
      "trainer/Zf2 Param Norm                110.024\n",
      "trainer/Z Expert Predictions Mean    1120.71\n",
      "trainer/Z Expert Predictions Std      115.661\n",
      "trainer/Z Expert Predictions Max     1324.67\n",
      "trainer/Z Expert Predictions Min      577.201\n",
      "trainer/Z Policy Predictions Mean     942.528\n",
      "trainer/Z Policy Predictions Std      317.014\n",
      "trainer/Z Policy Predictions Max     1268.95\n",
      "trainer/Z Policy Predictions Min      -72.0702\n",
      "trainer/Z Expert Targets Mean        1108.62\n",
      "trainer/Z Expert Targets Std          118.791\n",
      "trainer/Z Expert Targets Max         1314.8\n",
      "trainer/Z Expert Targets Min          526.82\n",
      "trainer/Z Policy Targets Mean         944.795\n",
      "trainer/Z Policy Targets Std          311.274\n",
      "trainer/Z Policy Targets Max         1278.35\n",
      "trainer/Z Policy Targets Min          -68.9176\n",
      "trainer/Log Pis Mean                   30.9799\n",
      "trainer/Log Pis Std                     7.47671\n",
      "trainer/Policy mu Mean                  1.47878\n",
      "trainer/Policy mu Std                   2.52\n",
      "trainer/Policy log std Mean            -3.4535\n",
      "trainer/Policy log std Std              1.42946\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        242924\n",
      "exploration/num paths total          1010\n",
      "evaluation/num steps total              1.82022e+06\n",
      "evaluation/num paths total           2394\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.205\n",
      "evaluation/Rewards Std                  1.32883\n",
      "evaluation/Rewards Max                  7.24099\n",
      "evaluation/Rewards Min                  0.0915427\n",
      "evaluation/Returns Mean              5205\n",
      "evaluation/Returns Std                 62.9255\n",
      "evaluation/Returns Max               5284.42\n",
      "evaluation/Returns Min               5064.61\n",
      "evaluation/Estimation Bias Mean      1084.29\n",
      "evaluation/Estimation Bias Std        170.322\n",
      "evaluation/EB/Q_True Mean              49.344\n",
      "evaluation/EB/Q_True Std              152.403\n",
      "evaluation/EB/Q_Pred Mean            1133.64\n",
      "evaluation/EB/Q_Pred Std               65.7344\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5205\n",
      "evaluation/Actions Mean                 0.502968\n",
      "evaluation/Actions Std                  0.646278\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.10659\n",
      "time/backward_zf1 (s)                   2.2791\n",
      "time/backward_zf2 (s)                   2.21608\n",
      "time/data sampling (s)                  0.296648\n",
      "time/data storing (s)                   0.0150914\n",
      "time/evaluation sampling (s)            1.44196\n",
      "time/exploration sampling (s)           0.200644\n",
      "time/logging (s)                        0.011516\n",
      "time/preback_alpha (s)                  0.619987\n",
      "time/preback_policy (s)                 1.2407\n",
      "time/preback_start (s)                  0.134297\n",
      "time/preback_zf (s)                     5.24714\n",
      "time/saving (s)                         0.00559575\n",
      "time/training (s)                       2.34601\n",
      "time/epoch (s)                         18.1614\n",
      "time/total (s)                       3990.37\n",
      "Epoch                                 238\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:59:03.360166 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 239 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 250000\n",
      "trainer/ZF1 Loss                      285.286\n",
      "trainer/ZF2 Loss                      285.145\n",
      "trainer/ZF Expert Reward               20.0673\n",
      "trainer/ZF Policy Reward               10.9004\n",
      "trainer/ZF CHI2 Term                  294.693\n",
      "trainer/Policy Loss                  -986.538\n",
      "trainer/Bias Loss                     138.352\n",
      "trainer/Bias Value                     11.7858\n",
      "trainer/Policy Grad Norm              633.226\n",
      "trainer/Policy Param Norm              35.126\n",
      "trainer/Zf1 Grad Norm                3461.47\n",
      "trainer/Zf1 Param Norm                112.276\n",
      "trainer/Zf2 Grad Norm                3421.05\n",
      "trainer/Zf2 Param Norm                110.197\n",
      "trainer/Z Expert Predictions Mean    1131.85\n",
      "trainer/Z Expert Predictions Std       98.5489\n",
      "trainer/Z Expert Predictions Max     1325.9\n",
      "trainer/Z Expert Predictions Min      699.605\n",
      "trainer/Z Policy Predictions Mean     980.189\n",
      "trainer/Z Policy Predictions Std      280.061\n",
      "trainer/Z Policy Predictions Max     1313.53\n",
      "trainer/Z Policy Predictions Min      -75.0895\n",
      "trainer/Z Expert Targets Mean        1111.78\n",
      "trainer/Z Expert Targets Std           98.8451\n",
      "trainer/Z Expert Targets Max         1291.33\n",
      "trainer/Z Expert Targets Min          698.764\n",
      "trainer/Z Policy Targets Mean         969.289\n",
      "trainer/Z Policy Targets Std          283.542\n",
      "trainer/Z Policy Targets Max         1302.68\n",
      "trainer/Z Policy Targets Min         -101.291\n",
      "trainer/Log Pis Mean                   31.0006\n",
      "trainer/Log Pis Std                     6.46297\n",
      "trainer/Policy mu Mean                  1.3865\n",
      "trainer/Policy mu Std                   2.41151\n",
      "trainer/Policy log std Mean            -3.62108\n",
      "trainer/Policy log std Std              1.44071\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        245924\n",
      "exploration/num paths total          1013\n",
      "evaluation/num steps total              1.83022e+06\n",
      "evaluation/num paths total           2404\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12887\n",
      "evaluation/Rewards Std                  1.31235\n",
      "evaluation/Rewards Max                  7.24634\n",
      "evaluation/Rewards Min                  0.102542\n",
      "evaluation/Returns Mean              5128.87\n",
      "evaluation/Returns Std                 32.1159\n",
      "evaluation/Returns Max               5182.03\n",
      "evaluation/Returns Min               5087.75\n",
      "evaluation/Estimation Bias Mean      1093.43\n",
      "evaluation/Estimation Bias Std        157.765\n",
      "evaluation/EB/Q_True Mean              48.0697\n",
      "evaluation/EB/Q_True Std              148.434\n",
      "evaluation/EB/Q_Pred Mean            1141.5\n",
      "evaluation/EB/Q_Pred Std               79.8321\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5128.87\n",
      "evaluation/Actions Mean                 0.508276\n",
      "evaluation/Actions Std                  0.646658\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98254\n",
      "time/backward_zf1 (s)                   2.14757\n",
      "time/backward_zf2 (s)                   2.05995\n",
      "time/data sampling (s)                  0.267255\n",
      "time/data storing (s)                   0.0147221\n",
      "time/evaluation sampling (s)            1.49534\n",
      "time/exploration sampling (s)           0.206108\n",
      "time/logging (s)                        0.0117979\n",
      "time/preback_alpha (s)                  0.590677\n",
      "time/preback_policy (s)                 1.13629\n",
      "time/preback_start (s)                  0.128612\n",
      "time/preback_zf (s)                     5.13134\n",
      "time/saving (s)                         0.0057954\n",
      "time/training (s)                       2.32139\n",
      "time/epoch (s)                         17.4994\n",
      "time/total (s)                       4007.89\n",
      "Epoch                                 239\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:59:21.295010 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 240 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 251000\n",
      "trainer/ZF1 Loss                      270.92\n",
      "trainer/ZF2 Loss                      267.108\n",
      "trainer/ZF Expert Reward               19.5166\n",
      "trainer/ZF Policy Reward                8.62314\n",
      "trainer/ZF CHI2 Term                  280.225\n",
      "trainer/Policy Loss                  -951.017\n",
      "trainer/Bias Loss                     140.569\n",
      "trainer/Bias Value                     11.7916\n",
      "trainer/Policy Grad Norm              338.946\n",
      "trainer/Policy Param Norm              35.154\n",
      "trainer/Zf1 Grad Norm                3863.53\n",
      "trainer/Zf1 Param Norm                112.468\n",
      "trainer/Zf2 Grad Norm                3432.44\n",
      "trainer/Zf2 Param Norm                110.371\n",
      "trainer/Z Expert Predictions Mean    1134.22\n",
      "trainer/Z Expert Predictions Std       95.6893\n",
      "trainer/Z Expert Predictions Max     1320.5\n",
      "trainer/Z Expert Predictions Min      651.579\n",
      "trainer/Z Policy Predictions Mean     945.148\n",
      "trainer/Z Policy Predictions Std      324.119\n",
      "trainer/Z Policy Predictions Max     1328.55\n",
      "trainer/Z Policy Predictions Min      -92.3573\n",
      "trainer/Z Expert Targets Mean        1114.71\n",
      "trainer/Z Expert Targets Std          100.048\n",
      "trainer/Z Expert Targets Max         1288.49\n",
      "trainer/Z Expert Targets Min          585.242\n",
      "trainer/Z Policy Targets Mean         936.525\n",
      "trainer/Z Policy Targets Std          324.123\n",
      "trainer/Z Policy Targets Max         1337.95\n",
      "trainer/Z Policy Targets Min         -124.604\n",
      "trainer/Log Pis Mean                   31.7289\n",
      "trainer/Log Pis Std                     7.85978\n",
      "trainer/Policy mu Mean                  1.38755\n",
      "trainer/Policy mu Std                   2.58255\n",
      "trainer/Policy log std Mean            -3.50066\n",
      "trainer/Policy log std Std              1.39286\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        245924\n",
      "exploration/num paths total          1013\n",
      "evaluation/num steps total              1.84011e+06\n",
      "evaluation/num paths total           2414\n",
      "evaluation/path length Mean           989.3\n",
      "evaluation/path length Std             32.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            893\n",
      "evaluation/Rewards Mean                 5.19315\n",
      "evaluation/Rewards Std                  1.33212\n",
      "evaluation/Rewards Max                  7.25486\n",
      "evaluation/Rewards Min                  0.101477\n",
      "evaluation/Returns Mean              5137.59\n",
      "evaluation/Returns Std                189.947\n",
      "evaluation/Returns Max               5270.89\n",
      "evaluation/Returns Min               4586.22\n",
      "evaluation/Estimation Bias Mean      1087.52\n",
      "evaluation/Estimation Bias Std        228.095\n",
      "evaluation/EB/Q_True Mean              49.4176\n",
      "evaluation/EB/Q_True Std              151.711\n",
      "evaluation/EB/Q_Pred Mean            1136.94\n",
      "evaluation/EB/Q_Pred Std              117.655\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5137.59\n",
      "evaluation/Actions Mean                 0.510502\n",
      "evaluation/Actions Std                  0.643434\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.0504\n",
      "time/backward_zf1 (s)                   2.2118\n",
      "time/backward_zf2 (s)                   2.12925\n",
      "time/data sampling (s)                  0.299842\n",
      "time/data storing (s)                   0.0144901\n",
      "time/evaluation sampling (s)            1.49956\n",
      "time/exploration sampling (s)           0.198763\n",
      "time/logging (s)                        0.0119006\n",
      "time/preback_alpha (s)                  0.603112\n",
      "time/preback_policy (s)                 1.17834\n",
      "time/preback_start (s)                  0.129701\n",
      "time/preback_zf (s)                     5.21317\n",
      "time/saving (s)                         0.00571379\n",
      "time/training (s)                       2.32029\n",
      "time/epoch (s)                         17.8663\n",
      "time/total (s)                       4025.77\n",
      "Epoch                                 240\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 18:59:38.464835 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 241 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 252000\n",
      "trainer/ZF1 Loss                      318.476\n",
      "trainer/ZF2 Loss                      314.273\n",
      "trainer/ZF Expert Reward               16.1932\n",
      "trainer/ZF Policy Reward                8.70159\n",
      "trainer/ZF CHI2 Term                  324.176\n",
      "trainer/Policy Loss                  -967.159\n",
      "trainer/Bias Loss                      98.9722\n",
      "trainer/Bias Value                     11.7972\n",
      "trainer/Policy Grad Norm              456.651\n",
      "trainer/Policy Param Norm              35.1807\n",
      "trainer/Zf1 Grad Norm                3065.18\n",
      "trainer/Zf1 Param Norm                112.649\n",
      "trainer/Zf2 Grad Norm                2636.79\n",
      "trainer/Zf2 Param Norm                110.541\n",
      "trainer/Z Expert Predictions Mean    1120.68\n",
      "trainer/Z Expert Predictions Std       99.6653\n",
      "trainer/Z Expert Predictions Max     1297.69\n",
      "trainer/Z Expert Predictions Min      666.352\n",
      "trainer/Z Policy Predictions Mean     960.222\n",
      "trainer/Z Policy Predictions Std      296.671\n",
      "trainer/Z Policy Predictions Max     1286.04\n",
      "trainer/Z Policy Predictions Min      -93.4817\n",
      "trainer/Z Expert Targets Mean        1104.48\n",
      "trainer/Z Expert Targets Std          104.096\n",
      "trainer/Z Expert Targets Max         1269.23\n",
      "trainer/Z Expert Targets Min          609.082\n",
      "trainer/Z Policy Targets Mean         951.52\n",
      "trainer/Z Policy Targets Std          299.563\n",
      "trainer/Z Policy Targets Max         1281.71\n",
      "trainer/Z Policy Targets Min          -95.1422\n",
      "trainer/Log Pis Mean                   30.9919\n",
      "trainer/Log Pis Std                     8.70889\n",
      "trainer/Policy mu Mean                  1.3104\n",
      "trainer/Policy mu Std                   2.58892\n",
      "trainer/Policy log std Mean            -3.53937\n",
      "trainer/Policy log std Std              1.39781\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        246924\n",
      "exploration/num paths total          1014\n",
      "evaluation/num steps total              1.8501e+06\n",
      "evaluation/num paths total           2424\n",
      "evaluation/path length Mean           999.5\n",
      "evaluation/path length Std              1.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            995\n",
      "evaluation/Rewards Mean                 5.16297\n",
      "evaluation/Rewards Std                  1.30385\n",
      "evaluation/Rewards Max                  7.20995\n",
      "evaluation/Rewards Min                  0.10709\n",
      "evaluation/Returns Mean              5160.39\n",
      "evaluation/Returns Std                 40.4708\n",
      "evaluation/Returns Max               5221.99\n",
      "evaluation/Returns Min               5099.61\n",
      "evaluation/Estimation Bias Mean      1001.26\n",
      "evaluation/Estimation Bias Std        258.03\n",
      "evaluation/EB/Q_True Mean              48.2587\n",
      "evaluation/EB/Q_True Std              148.866\n",
      "evaluation/EB/Q_Pred Mean            1049.52\n",
      "evaluation/EB/Q_Pred Std              193.457\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5160.39\n",
      "evaluation/Actions Mean                 0.500168\n",
      "evaluation/Actions Std                  0.65847\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84504\n",
      "time/backward_zf1 (s)                   2.03112\n",
      "time/backward_zf2 (s)                   1.91859\n",
      "time/data sampling (s)                  0.295753\n",
      "time/data storing (s)                   0.0141852\n",
      "time/evaluation sampling (s)            1.47145\n",
      "time/exploration sampling (s)           0.199399\n",
      "time/logging (s)                        0.0120765\n",
      "time/preback_alpha (s)                  0.586343\n",
      "time/preback_policy (s)                 1.01956\n",
      "time/preback_start (s)                  0.12853\n",
      "time/preback_zf (s)                     5.11855\n",
      "time/saving (s)                         0.00559709\n",
      "time/training (s)                       2.45018\n",
      "time/epoch (s)                         17.0964\n",
      "time/total (s)                       4042.89\n",
      "Epoch                                 241\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 18:59:56.116642 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 242 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 253000\n",
      "trainer/ZF1 Loss                       26.5251\n",
      "trainer/ZF2 Loss                       21.8913\n",
      "trainer/ZF Expert Reward               12.8599\n",
      "trainer/ZF Policy Reward               -2.73103\n",
      "trainer/ZF CHI2 Term                   40.1011\n",
      "trainer/Policy Loss                  -939.875\n",
      "trainer/Bias Loss                      70.4716\n",
      "trainer/Bias Value                     11.8032\n",
      "trainer/Policy Grad Norm              276.087\n",
      "trainer/Policy Param Norm              35.2072\n",
      "trainer/Zf1 Grad Norm                4441.06\n",
      "trainer/Zf1 Param Norm                112.84\n",
      "trainer/Zf2 Grad Norm                2293.55\n",
      "trainer/Zf2 Param Norm                110.714\n",
      "trainer/Z Expert Predictions Mean    1118.05\n",
      "trainer/Z Expert Predictions Std       95.9216\n",
      "trainer/Z Expert Predictions Max     1275.03\n",
      "trainer/Z Expert Predictions Min      599.652\n",
      "trainer/Z Policy Predictions Mean     928.768\n",
      "trainer/Z Policy Predictions Std      324.718\n",
      "trainer/Z Policy Predictions Max     1276.35\n",
      "trainer/Z Policy Predictions Min      -86.5374\n",
      "trainer/Z Expert Targets Mean        1105.19\n",
      "trainer/Z Expert Targets Std           95.459\n",
      "trainer/Z Expert Targets Max         1260.65\n",
      "trainer/Z Expert Targets Min          621.182\n",
      "trainer/Z Policy Targets Mean         931.499\n",
      "trainer/Z Policy Targets Std          318.731\n",
      "trainer/Z Policy Targets Max         1263.97\n",
      "trainer/Z Policy Targets Min          -67.4235\n",
      "trainer/Log Pis Mean                   30.2045\n",
      "trainer/Log Pis Std                     7.71304\n",
      "trainer/Policy mu Mean                  1.41966\n",
      "trainer/Policy mu Std                   2.56229\n",
      "trainer/Policy log std Mean            -3.39535\n",
      "trainer/Policy log std Std              1.38361\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        246924\n",
      "exploration/num paths total          1014\n",
      "evaluation/num steps total              1.85977e+06\n",
      "evaluation/num paths total           2434\n",
      "evaluation/path length Mean           966.9\n",
      "evaluation/path length Std             83.42\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            721\n",
      "evaluation/Rewards Mean                 5.13182\n",
      "evaluation/Rewards Std                  1.3163\n",
      "evaluation/Rewards Max                  7.15143\n",
      "evaluation/Rewards Min                  0.120948\n",
      "evaluation/Returns Mean              4961.95\n",
      "evaluation/Returns Std                469.13\n",
      "evaluation/Returns Max               5210.26\n",
      "evaluation/Returns Min               3583.07\n",
      "evaluation/Estimation Bias Mean      1003.07\n",
      "evaluation/Estimation Bias Std        285.742\n",
      "evaluation/EB/Q_True Mean              50.2717\n",
      "evaluation/EB/Q_True Std              152.825\n",
      "evaluation/EB/Q_Pred Mean            1053.35\n",
      "evaluation/EB/Q_Pred Std              222.282\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4961.95\n",
      "evaluation/Actions Mean                 0.498142\n",
      "evaluation/Actions Std                  0.660401\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.00795\n",
      "time/backward_zf1 (s)                   2.16372\n",
      "time/backward_zf2 (s)                   2.08525\n",
      "time/data sampling (s)                  0.291796\n",
      "time/data storing (s)                   0.0154066\n",
      "time/evaluation sampling (s)            1.49745\n",
      "time/exploration sampling (s)           0.206165\n",
      "time/logging (s)                        0.0133114\n",
      "time/preback_alpha (s)                  0.595524\n",
      "time/preback_policy (s)                 1.16926\n",
      "time/preback_start (s)                  0.12907\n",
      "time/preback_zf (s)                     5.16744\n",
      "time/saving (s)                         0.00544092\n",
      "time/training (s)                       2.23499\n",
      "time/epoch (s)                         17.5828\n",
      "time/total (s)                       4060.5\n",
      "Epoch                                 242\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:00:14.064620 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 243 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 254000\n",
      "trainer/ZF1 Loss                       30.0019\n",
      "trainer/ZF2 Loss                       36.7105\n",
      "trainer/ZF Expert Reward               11.9237\n",
      "trainer/ZF Policy Reward               -3.17916\n",
      "trainer/ZF CHI2 Term                   48.7637\n",
      "trainer/Policy Loss                  -969\n",
      "trainer/Bias Loss                     113.654\n",
      "trainer/Bias Value                     11.8093\n",
      "trainer/Policy Grad Norm              534.081\n",
      "trainer/Policy Param Norm              35.2314\n",
      "trainer/Zf1 Grad Norm                3159.58\n",
      "trainer/Zf1 Param Norm                113.036\n",
      "trainer/Zf2 Grad Norm                3075.16\n",
      "trainer/Zf2 Param Norm                110.897\n",
      "trainer/Z Expert Predictions Mean    1109.31\n",
      "trainer/Z Expert Predictions Std      105.85\n",
      "trainer/Z Expert Predictions Max     1290.72\n",
      "trainer/Z Expert Predictions Min      645.699\n",
      "trainer/Z Policy Predictions Mean     965.256\n",
      "trainer/Z Policy Predictions Std      292.95\n",
      "trainer/Z Policy Predictions Max     1338.37\n",
      "trainer/Z Policy Predictions Min      -89.3633\n",
      "trainer/Z Expert Targets Mean        1097.38\n",
      "trainer/Z Expert Targets Std          110.133\n",
      "trainer/Z Expert Targets Max         1279.12\n",
      "trainer/Z Expert Targets Min          607.718\n",
      "trainer/Z Policy Targets Mean         968.435\n",
      "trainer/Z Policy Targets Std          291.377\n",
      "trainer/Z Policy Targets Max         1305.7\n",
      "trainer/Z Policy Targets Min         -110.922\n",
      "trainer/Log Pis Mean                   30.4592\n",
      "trainer/Log Pis Std                     6.69447\n",
      "trainer/Policy mu Mean                  1.37927\n",
      "trainer/Policy mu Std                   2.42984\n",
      "trainer/Policy log std Mean            -3.51034\n",
      "trainer/Policy log std Std              1.43537\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        249924\n",
      "exploration/num paths total          1017\n",
      "evaluation/num steps total              1.86977e+06\n",
      "evaluation/num paths total           2444\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.09395\n",
      "evaluation/Rewards Std                  1.30193\n",
      "evaluation/Rewards Max                  7.17964\n",
      "evaluation/Rewards Min                  0.0939489\n",
      "evaluation/Returns Mean              5093.95\n",
      "evaluation/Returns Std                 61.8806\n",
      "evaluation/Returns Max               5174.76\n",
      "evaluation/Returns Min               4999.78\n",
      "evaluation/Estimation Bias Mean      1002.35\n",
      "evaluation/Estimation Bias Std        222.174\n",
      "evaluation/EB/Q_True Mean              47.7244\n",
      "evaluation/EB/Q_True Std              147.254\n",
      "evaluation/EB/Q_Pred Mean            1050.07\n",
      "evaluation/EB/Q_Pred Std              152.375\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5093.95\n",
      "evaluation/Actions Mean                 0.499297\n",
      "evaluation/Actions Std                  0.658482\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.06541\n",
      "time/backward_zf1 (s)                   2.2229\n",
      "time/backward_zf2 (s)                   2.14696\n",
      "time/data sampling (s)                  0.29561\n",
      "time/data storing (s)                   0.0150941\n",
      "time/evaluation sampling (s)            1.46447\n",
      "time/exploration sampling (s)           0.209351\n",
      "time/logging (s)                        0.0116343\n",
      "time/preback_alpha (s)                  0.60343\n",
      "time/preback_policy (s)                 1.20416\n",
      "time/preback_start (s)                  0.132678\n",
      "time/preback_zf (s)                     5.19379\n",
      "time/saving (s)                         0.0057831\n",
      "time/training (s)                       2.29817\n",
      "time/epoch (s)                         17.8694\n",
      "time/total (s)                       4078.39\n",
      "Epoch                                 243\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:00:31.790283 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 244 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 255000\n",
      "trainer/ZF1 Loss                       21.8343\n",
      "trainer/ZF2 Loss                       22.126\n",
      "trainer/ZF Expert Reward               12.5688\n",
      "trainer/ZF Policy Reward               -2.09167\n",
      "trainer/ZF CHI2 Term                   36.951\n",
      "trainer/Policy Loss                  -952.012\n",
      "trainer/Bias Loss                      69.4701\n",
      "trainer/Bias Value                     11.8154\n",
      "trainer/Policy Grad Norm              337.463\n",
      "trainer/Policy Param Norm              35.2565\n",
      "trainer/Zf1 Grad Norm                2442.66\n",
      "trainer/Zf1 Param Norm                113.209\n",
      "trainer/Zf2 Grad Norm                2341.4\n",
      "trainer/Zf2 Param Norm                111.055\n",
      "trainer/Z Expert Predictions Mean    1120.67\n",
      "trainer/Z Expert Predictions Std       90.5213\n",
      "trainer/Z Expert Predictions Max     1303.54\n",
      "trainer/Z Expert Predictions Min      565.321\n",
      "trainer/Z Policy Predictions Mean     940.205\n",
      "trainer/Z Policy Predictions Std      325.943\n",
      "trainer/Z Policy Predictions Max     1295.22\n",
      "trainer/Z Policy Predictions Min     -100.936\n",
      "trainer/Z Expert Targets Mean        1108.1\n",
      "trainer/Z Expert Targets Std           91.2736\n",
      "trainer/Z Expert Targets Max         1272.48\n",
      "trainer/Z Expert Targets Min          574.34\n",
      "trainer/Z Policy Targets Mean         942.296\n",
      "trainer/Z Policy Targets Std          322.281\n",
      "trainer/Z Policy Targets Max         1295.93\n",
      "trainer/Z Policy Targets Min          -97.7931\n",
      "trainer/Log Pis Mean                   31.0344\n",
      "trainer/Log Pis Std                     8.27208\n",
      "trainer/Policy mu Mean                  1.30682\n",
      "trainer/Policy mu Std                   2.68414\n",
      "trainer/Policy log std Mean            -3.54465\n",
      "trainer/Policy log std Std              1.45998\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        250924\n",
      "exploration/num paths total          1018\n",
      "evaluation/num steps total              1.87962e+06\n",
      "evaluation/num paths total           2454\n",
      "evaluation/path length Mean           984.9\n",
      "evaluation/path length Std             45.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            849\n",
      "evaluation/Rewards Mean                 5.12929\n",
      "evaluation/Rewards Std                  1.31667\n",
      "evaluation/Rewards Max                  7.14944\n",
      "evaluation/Rewards Min                  0.114375\n",
      "evaluation/Returns Mean              5051.84\n",
      "evaluation/Returns Std                253.12\n",
      "evaluation/Returns Max               5164.72\n",
      "evaluation/Returns Min               4294.7\n",
      "evaluation/Estimation Bias Mean      1062.68\n",
      "evaluation/Estimation Bias Std        222.588\n",
      "evaluation/EB/Q_True Mean              49.3057\n",
      "evaluation/EB/Q_True Std              150.822\n",
      "evaluation/EB/Q_Pred Mean            1111.99\n",
      "evaluation/EB/Q_Pred Std              130.268\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5051.84\n",
      "evaluation/Actions Mean                 0.497229\n",
      "evaluation/Actions Std                  0.652866\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.03961\n",
      "time/backward_zf1 (s)                   2.18692\n",
      "time/backward_zf2 (s)                   2.12109\n",
      "time/data sampling (s)                  0.29025\n",
      "time/data storing (s)                   0.0150859\n",
      "time/evaluation sampling (s)            1.45295\n",
      "time/exploration sampling (s)           0.203285\n",
      "time/logging (s)                        0.0120008\n",
      "time/preback_alpha (s)                  0.599473\n",
      "time/preback_policy (s)                 1.18378\n",
      "time/preback_start (s)                  0.130355\n",
      "time/preback_zf (s)                     5.15827\n",
      "time/saving (s)                         0.00589963\n",
      "time/training (s)                       2.25511\n",
      "time/epoch (s)                         17.6541\n",
      "time/total (s)                       4096.07\n",
      "Epoch                                 244\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:00:49.144819 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 245 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 256000\n",
      "trainer/ZF1 Loss                       29.0133\n",
      "trainer/ZF2 Loss                       29.4936\n",
      "trainer/ZF Expert Reward               16.3131\n",
      "trainer/ZF Policy Reward                2.36716\n",
      "trainer/ZF CHI2 Term                   43.5167\n",
      "trainer/Policy Loss                  -914.952\n",
      "trainer/Bias Loss                     114.024\n",
      "trainer/Bias Value                     11.8214\n",
      "trainer/Policy Grad Norm              589.307\n",
      "trainer/Policy Param Norm              35.2839\n",
      "trainer/Zf1 Grad Norm                2089.82\n",
      "trainer/Zf1 Param Norm                113.379\n",
      "trainer/Zf2 Grad Norm                2263.19\n",
      "trainer/Zf2 Param Norm                111.218\n",
      "trainer/Z Expert Predictions Mean    1102.57\n",
      "trainer/Z Expert Predictions Std       95.8261\n",
      "trainer/Z Expert Predictions Max     1269.55\n",
      "trainer/Z Expert Predictions Min      580.998\n",
      "trainer/Z Policy Predictions Mean     901.803\n",
      "trainer/Z Policy Predictions Std      341.146\n",
      "trainer/Z Policy Predictions Max     1251.74\n",
      "trainer/Z Policy Predictions Min     -111.38\n",
      "trainer/Z Expert Targets Mean        1086.25\n",
      "trainer/Z Expert Targets Std           99.9617\n",
      "trainer/Z Expert Targets Max         1254.37\n",
      "trainer/Z Expert Targets Min          514.507\n",
      "trainer/Z Policy Targets Mean         899.436\n",
      "trainer/Z Policy Targets Std          337.272\n",
      "trainer/Z Policy Targets Max         1262.02\n",
      "trainer/Z Policy Targets Min         -105.545\n",
      "trainer/Log Pis Mean                   31.7315\n",
      "trainer/Log Pis Std                     8.83213\n",
      "trainer/Policy mu Mean                  1.48441\n",
      "trainer/Policy mu Std                   2.77653\n",
      "trainer/Policy log std Mean            -3.44596\n",
      "trainer/Policy log std Std              1.48343\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        250924\n",
      "exploration/num paths total          1018\n",
      "evaluation/num steps total              1.88962e+06\n",
      "evaluation/num paths total           2464\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20124\n",
      "evaluation/Rewards Std                  1.34313\n",
      "evaluation/Rewards Max                  7.25747\n",
      "evaluation/Rewards Min                  0.0906995\n",
      "evaluation/Returns Mean              5201.24\n",
      "evaluation/Returns Std                 34.6601\n",
      "evaluation/Returns Max               5240.78\n",
      "evaluation/Returns Min               5144.76\n",
      "evaluation/Estimation Bias Mean      1086.1\n",
      "evaluation/Estimation Bias Std        163.189\n",
      "evaluation/EB/Q_True Mean              48.8463\n",
      "evaluation/EB/Q_True Std              150.885\n",
      "evaluation/EB/Q_Pred Mean            1134.94\n",
      "evaluation/EB/Q_Pred Std               52.2056\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5201.24\n",
      "evaluation/Actions Mean                 0.503343\n",
      "evaluation/Actions Std                  0.646853\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92046\n",
      "time/backward_zf1 (s)                   2.09513\n",
      "time/backward_zf2 (s)                   2.00595\n",
      "time/data sampling (s)                  0.298221\n",
      "time/data storing (s)                   0.0142901\n",
      "time/evaluation sampling (s)            1.46526\n",
      "time/exploration sampling (s)           0.196328\n",
      "time/logging (s)                        0.0120604\n",
      "time/preback_alpha (s)                  0.588435\n",
      "time/preback_policy (s)                 1.09833\n",
      "time/preback_start (s)                  0.127517\n",
      "time/preback_zf (s)                     5.11737\n",
      "time/saving (s)                         0.0059741\n",
      "time/training (s)                       2.33562\n",
      "time/epoch (s)                         17.2809\n",
      "time/total (s)                       4113.37\n",
      "Epoch                                 245\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:01:06.494636 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 246 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 257000\n",
      "trainer/ZF1 Loss                       42.4996\n",
      "trainer/ZF2 Loss                       36.5465\n",
      "trainer/ZF Expert Reward               17.2699\n",
      "trainer/ZF Policy Reward                2.42345\n",
      "trainer/ZF CHI2 Term                   54.6747\n",
      "trainer/Policy Loss                  -957.306\n",
      "trainer/Bias Loss                     245.486\n",
      "trainer/Bias Value                     11.8279\n",
      "trainer/Policy Grad Norm              522.564\n",
      "trainer/Policy Param Norm              35.3065\n",
      "trainer/Zf1 Grad Norm                2397.55\n",
      "trainer/Zf1 Param Norm                113.565\n",
      "trainer/Zf2 Grad Norm                2553.31\n",
      "trainer/Zf2 Param Norm                111.393\n",
      "trainer/Z Expert Predictions Mean    1105.05\n",
      "trainer/Z Expert Predictions Std      105.455\n",
      "trainer/Z Expert Predictions Max     1322.64\n",
      "trainer/Z Expert Predictions Min      650.571\n",
      "trainer/Z Policy Predictions Mean     949.313\n",
      "trainer/Z Policy Predictions Std      279.489\n",
      "trainer/Z Policy Predictions Max     1259.53\n",
      "trainer/Z Policy Predictions Min     -180.219\n",
      "trainer/Z Expert Targets Mean        1087.78\n",
      "trainer/Z Expert Targets Std          106.943\n",
      "trainer/Z Expert Targets Max         1293.65\n",
      "trainer/Z Expert Targets Min          597.131\n",
      "trainer/Z Policy Targets Mean         946.89\n",
      "trainer/Z Policy Targets Std          274.438\n",
      "trainer/Z Policy Targets Max         1256.31\n",
      "trainer/Z Policy Targets Min         -129.688\n",
      "trainer/Log Pis Mean                   30.5144\n",
      "trainer/Log Pis Std                     7.02568\n",
      "trainer/Policy mu Mean                  1.30856\n",
      "trainer/Policy mu Std                   2.52753\n",
      "trainer/Policy log std Mean            -3.58206\n",
      "trainer/Policy log std Std              1.40254\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        252924\n",
      "exploration/num paths total          1020\n",
      "evaluation/num steps total              1.89962e+06\n",
      "evaluation/num paths total           2474\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14542\n",
      "evaluation/Rewards Std                  1.29739\n",
      "evaluation/Rewards Max                  7.11119\n",
      "evaluation/Rewards Min                  0.117513\n",
      "evaluation/Returns Mean              5145.42\n",
      "evaluation/Returns Std                 10.5176\n",
      "evaluation/Returns Max               5167.7\n",
      "evaluation/Returns Min               5130.52\n",
      "evaluation/Estimation Bias Mean      1068.76\n",
      "evaluation/Estimation Bias Std        175.272\n",
      "evaluation/EB/Q_True Mean              48.5979\n",
      "evaluation/EB/Q_True Std              149.942\n",
      "evaluation/EB/Q_Pred Mean            1117.36\n",
      "evaluation/EB/Q_Pred Std              119.864\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5145.42\n",
      "evaluation/Actions Mean                 0.496338\n",
      "evaluation/Actions Std                  0.651084\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91166\n",
      "time/backward_zf1 (s)                   2.08574\n",
      "time/backward_zf2 (s)                   1.97632\n",
      "time/data sampling (s)                  0.284073\n",
      "time/data storing (s)                   0.014494\n",
      "time/evaluation sampling (s)            1.47157\n",
      "time/exploration sampling (s)           0.202416\n",
      "time/logging (s)                        0.0120361\n",
      "time/preback_alpha (s)                  0.584517\n",
      "time/preback_policy (s)                 1.05066\n",
      "time/preback_start (s)                  0.128533\n",
      "time/preback_zf (s)                     5.14288\n",
      "time/saving (s)                         0.00552663\n",
      "time/training (s)                       2.40394\n",
      "time/epoch (s)                         17.2744\n",
      "time/total (s)                       4130.67\n",
      "Epoch                                 246\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:01:24.249630 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 247 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 258000\n",
      "trainer/ZF1 Loss                       30.3223\n",
      "trainer/ZF2 Loss                       25.4062\n",
      "trainer/ZF Expert Reward               12.5433\n",
      "trainer/ZF Policy Reward               -2.0067\n",
      "trainer/ZF CHI2 Term                   42.7084\n",
      "trainer/Policy Loss                  -984.087\n",
      "trainer/Bias Loss                      96.9336\n",
      "trainer/Bias Value                     11.8341\n",
      "trainer/Policy Grad Norm              617.362\n",
      "trainer/Policy Param Norm              35.3271\n",
      "trainer/Zf1 Grad Norm                2634.39\n",
      "trainer/Zf1 Param Norm                113.748\n",
      "trainer/Zf2 Grad Norm                2400.13\n",
      "trainer/Zf2 Param Norm                111.568\n",
      "trainer/Z Expert Predictions Mean    1094.05\n",
      "trainer/Z Expert Predictions Std       95.5482\n",
      "trainer/Z Expert Predictions Max     1281.95\n",
      "trainer/Z Expert Predictions Min      728.679\n",
      "trainer/Z Policy Predictions Mean     974.571\n",
      "trainer/Z Policy Predictions Std      266.077\n",
      "trainer/Z Policy Predictions Max     1259.16\n",
      "trainer/Z Policy Predictions Min     -109.485\n",
      "trainer/Z Expert Targets Mean        1081.5\n",
      "trainer/Z Expert Targets Std           98.7739\n",
      "trainer/Z Expert Targets Max         1285.29\n",
      "trainer/Z Expert Targets Min          742.107\n",
      "trainer/Z Policy Targets Mean         976.578\n",
      "trainer/Z Policy Targets Std          260.106\n",
      "trainer/Z Policy Targets Max         1262.98\n",
      "trainer/Z Policy Targets Min         -123.988\n",
      "trainer/Log Pis Mean                   29.4153\n",
      "trainer/Log Pis Std                     5.67691\n",
      "trainer/Policy mu Mean                  1.39804\n",
      "trainer/Policy mu Std                   2.19927\n",
      "trainer/Policy log std Mean            -3.52561\n",
      "trainer/Policy log std Std              1.4059\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        252924\n",
      "exploration/num paths total          1020\n",
      "evaluation/num steps total              1.90962e+06\n",
      "evaluation/num paths total           2484\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14137\n",
      "evaluation/Rewards Std                  1.30523\n",
      "evaluation/Rewards Max                  7.08892\n",
      "evaluation/Rewards Min                  0.0821927\n",
      "evaluation/Returns Mean              5141.37\n",
      "evaluation/Returns Std                 28.967\n",
      "evaluation/Returns Max               5181.64\n",
      "evaluation/Returns Min               5068.57\n",
      "evaluation/Estimation Bias Mean      1087.09\n",
      "evaluation/Estimation Bias Std        169.134\n",
      "evaluation/EB/Q_True Mean              47.8705\n",
      "evaluation/EB/Q_True Std              147.973\n",
      "evaluation/EB/Q_Pred Mean            1134.96\n",
      "evaluation/EB/Q_Pred Std               78.7681\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5141.37\n",
      "evaluation/Actions Mean                 0.499324\n",
      "evaluation/Actions Std                  0.650115\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97683\n",
      "time/backward_zf1 (s)                   2.18434\n",
      "time/backward_zf2 (s)                   2.07366\n",
      "time/data sampling (s)                  0.30528\n",
      "time/data storing (s)                   0.0162422\n",
      "time/evaluation sampling (s)            1.42759\n",
      "time/exploration sampling (s)           0.208529\n",
      "time/logging (s)                        0.0116423\n",
      "time/preback_alpha (s)                  0.601999\n",
      "time/preback_policy (s)                 1.13131\n",
      "time/preback_start (s)                  0.1321\n",
      "time/preback_zf (s)                     5.20602\n",
      "time/saving (s)                         0.00587454\n",
      "time/training (s)                       2.40058\n",
      "time/epoch (s)                         17.682\n",
      "time/total (s)                       4148.38\n",
      "Epoch                                 247\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:01:41.823472 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 248 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 259000\n",
      "trainer/ZF1 Loss                       34.8215\n",
      "trainer/ZF2 Loss                       29.9675\n",
      "trainer/ZF Expert Reward                8.4399\n",
      "trainer/ZF Policy Reward               -0.52569\n",
      "trainer/ZF CHI2 Term                   41.6653\n",
      "trainer/Policy Loss                  -949.345\n",
      "trainer/Bias Loss                      96.4209\n",
      "trainer/Bias Value                     11.8401\n",
      "trainer/Policy Grad Norm              664.077\n",
      "trainer/Policy Param Norm              35.3533\n",
      "trainer/Zf1 Grad Norm                4346.11\n",
      "trainer/Zf1 Param Norm                113.927\n",
      "trainer/Zf2 Grad Norm                3904.43\n",
      "trainer/Zf2 Param Norm                111.729\n",
      "trainer/Z Expert Predictions Mean    1106.25\n",
      "trainer/Z Expert Predictions Std       75.6313\n",
      "trainer/Z Expert Predictions Max     1288.61\n",
      "trainer/Z Expert Predictions Min      837.51\n",
      "trainer/Z Policy Predictions Mean     945.888\n",
      "trainer/Z Policy Predictions Std      286.529\n",
      "trainer/Z Policy Predictions Max     1213.98\n",
      "trainer/Z Policy Predictions Min      -68.8387\n",
      "trainer/Z Expert Targets Mean        1097.81\n",
      "trainer/Z Expert Targets Std           75.6273\n",
      "trainer/Z Expert Targets Max         1284.3\n",
      "trainer/Z Expert Targets Min          830.134\n",
      "trainer/Z Policy Targets Mean         946.414\n",
      "trainer/Z Policy Targets Std          284.768\n",
      "trainer/Z Policy Targets Max         1220.11\n",
      "trainer/Z Policy Targets Min          -60.2532\n",
      "trainer/Log Pis Mean                   30.5176\n",
      "trainer/Log Pis Std                     6.65892\n",
      "trainer/Policy mu Mean                  1.42874\n",
      "trainer/Policy mu Std                   2.35301\n",
      "trainer/Policy log std Mean            -3.46864\n",
      "trainer/Policy log std Std              1.42963\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        252924\n",
      "exploration/num paths total          1020\n",
      "evaluation/num steps total              1.91962e+06\n",
      "evaluation/num paths total           2494\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13339\n",
      "evaluation/Rewards Std                  1.31587\n",
      "evaluation/Rewards Max                  7.13605\n",
      "evaluation/Rewards Min                  0.114317\n",
      "evaluation/Returns Mean              5133.39\n",
      "evaluation/Returns Std                 21.264\n",
      "evaluation/Returns Max               5168.12\n",
      "evaluation/Returns Min               5097.29\n",
      "evaluation/Estimation Bias Mean      1049.97\n",
      "evaluation/Estimation Bias Std        184.76\n",
      "evaluation/EB/Q_True Mean              48.6162\n",
      "evaluation/EB/Q_True Std              150.059\n",
      "evaluation/EB/Q_Pred Mean            1098.59\n",
      "evaluation/EB/Q_Pred Std              124.527\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5133.39\n",
      "evaluation/Actions Mean                 0.506151\n",
      "evaluation/Actions Std                  0.656182\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95973\n",
      "time/backward_zf1 (s)                   2.11479\n",
      "time/backward_zf2 (s)                   2.0503\n",
      "time/data sampling (s)                  0.27595\n",
      "time/data storing (s)                   0.0151205\n",
      "time/evaluation sampling (s)            1.39974\n",
      "time/exploration sampling (s)           0.201386\n",
      "time/logging (s)                        0.0115406\n",
      "time/preback_alpha (s)                  0.600464\n",
      "time/preback_policy (s)                 1.12099\n",
      "time/preback_start (s)                  0.130849\n",
      "time/preback_zf (s)                     5.19888\n",
      "time/saving (s)                         0.00562968\n",
      "time/training (s)                       2.42043\n",
      "time/epoch (s)                         17.5058\n",
      "time/total (s)                       4165.9\n",
      "Epoch                                 248\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:01:59.300808 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 249 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 260000\n",
      "trainer/ZF1 Loss                       29.1791\n",
      "trainer/ZF2 Loss                       40.857\n",
      "trainer/ZF Expert Reward               16.4866\n",
      "trainer/ZF Policy Reward                0.749421\n",
      "trainer/ZF CHI2 Term                   51.067\n",
      "trainer/Policy Loss                  -940.978\n",
      "trainer/Bias Loss                     148.665\n",
      "trainer/Bias Value                     11.8463\n",
      "trainer/Policy Grad Norm              544.976\n",
      "trainer/Policy Param Norm              35.375\n",
      "trainer/Zf1 Grad Norm                2761.43\n",
      "trainer/Zf1 Param Norm                114.107\n",
      "trainer/Zf2 Grad Norm                4606.96\n",
      "trainer/Zf2 Param Norm                111.908\n",
      "trainer/Z Expert Predictions Mean    1090.18\n",
      "trainer/Z Expert Predictions Std      105.821\n",
      "trainer/Z Expert Predictions Max     1273.88\n",
      "trainer/Z Expert Predictions Min      657.518\n",
      "trainer/Z Policy Predictions Mean     931.839\n",
      "trainer/Z Policy Predictions Std      288.219\n",
      "trainer/Z Policy Predictions Max     1241.51\n",
      "trainer/Z Policy Predictions Min     -116.535\n",
      "trainer/Z Expert Targets Mean        1073.69\n",
      "trainer/Z Expert Targets Std          108.446\n",
      "trainer/Z Expert Targets Max         1259.28\n",
      "trainer/Z Expert Targets Min          637.454\n",
      "trainer/Z Policy Targets Mean         931.089\n",
      "trainer/Z Policy Targets Std          284.801\n",
      "trainer/Z Policy Targets Max         1218.08\n",
      "trainer/Z Policy Targets Min         -136.589\n",
      "trainer/Log Pis Mean                   31.183\n",
      "trainer/Log Pis Std                     7.80842\n",
      "trainer/Policy mu Mean                  1.39208\n",
      "trainer/Policy mu Std                   2.53921\n",
      "trainer/Policy log std Mean            -3.45614\n",
      "trainer/Policy log std Std              1.44015\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        255924\n",
      "exploration/num paths total          1023\n",
      "evaluation/num steps total              1.92962e+06\n",
      "evaluation/num paths total           2504\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15075\n",
      "evaluation/Rewards Std                  1.32758\n",
      "evaluation/Rewards Max                  7.18918\n",
      "evaluation/Rewards Min                  0.0854018\n",
      "evaluation/Returns Mean              5150.75\n",
      "evaluation/Returns Std                 55.2391\n",
      "evaluation/Returns Max               5220.57\n",
      "evaluation/Returns Min               5027.64\n",
      "evaluation/Estimation Bias Mean      1055.08\n",
      "evaluation/Estimation Bias Std        177.167\n",
      "evaluation/EB/Q_True Mean              48.9989\n",
      "evaluation/EB/Q_True Std              151.249\n",
      "evaluation/EB/Q_Pred Mean            1104.08\n",
      "evaluation/EB/Q_Pred Std               62.1127\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5150.75\n",
      "evaluation/Actions Mean                 0.5115\n",
      "evaluation/Actions Std                  0.645529\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98561\n",
      "time/backward_zf1 (s)                   2.15437\n",
      "time/backward_zf2 (s)                   2.075\n",
      "time/data sampling (s)                  0.277915\n",
      "time/data storing (s)                   0.0144727\n",
      "time/evaluation sampling (s)            1.44131\n",
      "time/exploration sampling (s)           0.204718\n",
      "time/logging (s)                        0.0131201\n",
      "time/preback_alpha (s)                  0.589391\n",
      "time/preback_policy (s)                 1.14581\n",
      "time/preback_start (s)                  0.127699\n",
      "time/preback_zf (s)                     5.15726\n",
      "time/saving (s)                         0.00586889\n",
      "time/training (s)                       2.21849\n",
      "time/epoch (s)                         17.411\n",
      "time/total (s)                       4183.33\n",
      "Epoch                                 249\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:02:17.085911 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 250 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 261000\n",
      "trainer/ZF1 Loss                      218.887\n",
      "trainer/ZF2 Loss                      188.634\n",
      "trainer/ZF Expert Reward               13.553\n",
      "trainer/ZF Policy Reward                3.10076\n",
      "trainer/ZF CHI2 Term                  214.519\n",
      "trainer/Policy Loss                  -948.586\n",
      "trainer/Bias Loss                      67.3372\n",
      "trainer/Bias Value                     11.8523\n",
      "trainer/Policy Grad Norm              419.554\n",
      "trainer/Policy Param Norm              35.3982\n",
      "trainer/Zf1 Grad Norm                2815.91\n",
      "trainer/Zf1 Param Norm                114.296\n",
      "trainer/Zf2 Grad Norm                3844.17\n",
      "trainer/Zf2 Param Norm                112.09\n",
      "trainer/Z Expert Predictions Mean    1091.29\n",
      "trainer/Z Expert Predictions Std       93.3053\n",
      "trainer/Z Expert Predictions Max     1270.07\n",
      "trainer/Z Expert Predictions Min      634.563\n",
      "trainer/Z Policy Predictions Mean     942.167\n",
      "trainer/Z Policy Predictions Std      285.248\n",
      "trainer/Z Policy Predictions Max     1232.66\n",
      "trainer/Z Policy Predictions Min      -82.9054\n",
      "trainer/Z Expert Targets Mean        1077.74\n",
      "trainer/Z Expert Targets Std           94.8098\n",
      "trainer/Z Expert Targets Max         1256.86\n",
      "trainer/Z Expert Targets Min          618.033\n",
      "trainer/Z Policy Targets Mean         939.066\n",
      "trainer/Z Policy Targets Std          287.78\n",
      "trainer/Z Policy Targets Max         1227.91\n",
      "trainer/Z Policy Targets Min          -94.931\n",
      "trainer/Log Pis Mean                   30.638\n",
      "trainer/Log Pis Std                     7.0992\n",
      "trainer/Policy mu Mean                  1.41627\n",
      "trainer/Policy mu Std                   2.46048\n",
      "trainer/Policy log std Mean            -3.46662\n",
      "trainer/Policy log std Std              1.43667\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        255924\n",
      "exploration/num paths total          1023\n",
      "evaluation/num steps total              1.93962e+06\n",
      "evaluation/num paths total           2514\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.15155\n",
      "evaluation/Rewards Std                  1.29971\n",
      "evaluation/Rewards Max                  7.01219\n",
      "evaluation/Rewards Min                  0.122962\n",
      "evaluation/Returns Mean              5151.55\n",
      "evaluation/Returns Std                 15.6019\n",
      "evaluation/Returns Max               5173.3\n",
      "evaluation/Returns Min               5125.21\n",
      "evaluation/Estimation Bias Mean      1089.59\n",
      "evaluation/Estimation Bias Std        163.739\n",
      "evaluation/EB/Q_True Mean              48.7334\n",
      "evaluation/EB/Q_True Std              150.433\n",
      "evaluation/EB/Q_Pred Mean            1138.32\n",
      "evaluation/EB/Q_Pred Std               71.6761\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5151.55\n",
      "evaluation/Actions Mean                 0.500223\n",
      "evaluation/Actions Std                  0.645725\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.03983\n",
      "time/backward_zf1 (s)                   2.22013\n",
      "time/backward_zf2 (s)                   2.10597\n",
      "time/data sampling (s)                  0.289133\n",
      "time/data storing (s)                   0.014532\n",
      "time/evaluation sampling (s)            1.45436\n",
      "time/exploration sampling (s)           0.201933\n",
      "time/logging (s)                        0.0115729\n",
      "time/preback_alpha (s)                  0.599404\n",
      "time/preback_policy (s)                 1.16575\n",
      "time/preback_start (s)                  0.131752\n",
      "time/preback_zf (s)                     5.1735\n",
      "time/saving (s)                         0.00576162\n",
      "time/training (s)                       2.28928\n",
      "time/epoch (s)                         17.7029\n",
      "time/total (s)                       4201.06\n",
      "Epoch                                 250\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:02:34.853861 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 251 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 262000\n",
      "trainer/ZF1 Loss                       26.2757\n",
      "trainer/ZF2 Loss                       31.0403\n",
      "trainer/ZF Expert Reward               13.0769\n",
      "trainer/ZF Policy Reward                0.245582\n",
      "trainer/ZF CHI2 Term                   41.8004\n",
      "trainer/Policy Loss                  -966.42\n",
      "trainer/Bias Loss                     127.436\n",
      "trainer/Bias Value                     11.8585\n",
      "trainer/Policy Grad Norm              435.326\n",
      "trainer/Policy Param Norm              35.4211\n",
      "trainer/Zf1 Grad Norm                2747.38\n",
      "trainer/Zf1 Param Norm                114.454\n",
      "trainer/Zf2 Grad Norm                2962.35\n",
      "trainer/Zf2 Param Norm                112.251\n",
      "trainer/Z Expert Predictions Mean    1081.36\n",
      "trainer/Z Expert Predictions Std      114.761\n",
      "trainer/Z Expert Predictions Max     1254.96\n",
      "trainer/Z Expert Predictions Min       79.3668\n",
      "trainer/Z Policy Predictions Mean     958.068\n",
      "trainer/Z Policy Predictions Std      286.158\n",
      "trainer/Z Policy Predictions Max     1219.44\n",
      "trainer/Z Policy Predictions Min     -132.201\n",
      "trainer/Z Expert Targets Mean        1068.29\n",
      "trainer/Z Expert Targets Std          120.456\n",
      "trainer/Z Expert Targets Max         1241.31\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         957.822\n",
      "trainer/Z Policy Targets Std          286.186\n",
      "trainer/Z Policy Targets Max         1261.01\n",
      "trainer/Z Policy Targets Min         -160.233\n",
      "trainer/Log Pis Mean                   31.0968\n",
      "trainer/Log Pis Std                     8.20043\n",
      "trainer/Policy mu Mean                  1.27092\n",
      "trainer/Policy mu Std                   2.62373\n",
      "trainer/Policy log std Mean            -3.62242\n",
      "trainer/Policy log std Std              1.39931\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        256924\n",
      "exploration/num paths total          1024\n",
      "evaluation/num steps total              1.94962e+06\n",
      "evaluation/num paths total           2524\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18889\n",
      "evaluation/Rewards Std                  1.33368\n",
      "evaluation/Rewards Max                  7.24981\n",
      "evaluation/Rewards Min                  0.115855\n",
      "evaluation/Returns Mean              5188.89\n",
      "evaluation/Returns Std                 26.3642\n",
      "evaluation/Returns Max               5222.53\n",
      "evaluation/Returns Min               5144.72\n",
      "evaluation/Estimation Bias Mean      1060.56\n",
      "evaluation/Estimation Bias Std        164.51\n",
      "evaluation/EB/Q_True Mean              48.9041\n",
      "evaluation/EB/Q_True Std              151.43\n",
      "evaluation/EB/Q_Pred Mean            1109.47\n",
      "evaluation/EB/Q_Pred Std               62.8363\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5188.89\n",
      "evaluation/Actions Mean                 0.499433\n",
      "evaluation/Actions Std                  0.651042\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9962\n",
      "time/backward_zf1 (s)                   2.18665\n",
      "time/backward_zf2 (s)                   2.07895\n",
      "time/data sampling (s)                  0.302434\n",
      "time/data storing (s)                   0.0152469\n",
      "time/evaluation sampling (s)            1.51081\n",
      "time/exploration sampling (s)           0.208373\n",
      "time/logging (s)                        0.0134252\n",
      "time/preback_alpha (s)                  0.599641\n",
      "time/preback_policy (s)                 1.10642\n",
      "time/preback_start (s)                  0.130663\n",
      "time/preback_zf (s)                     5.15069\n",
      "time/saving (s)                         0.00588849\n",
      "time/training (s)                       2.39624\n",
      "time/epoch (s)                         17.7016\n",
      "time/total (s)                       4218.78\n",
      "Epoch                                 251\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:02:53.399767 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 252 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 263000\n",
      "trainer/ZF1 Loss                      131.428\n",
      "trainer/ZF2 Loss                      136.929\n",
      "trainer/ZF Expert Reward               13.2769\n",
      "trainer/ZF Policy Reward                4.35193\n",
      "trainer/ZF CHI2 Term                  143.41\n",
      "trainer/Policy Loss                  -940.342\n",
      "trainer/Bias Loss                     143.289\n",
      "trainer/Bias Value                     11.8648\n",
      "trainer/Policy Grad Norm              483.774\n",
      "trainer/Policy Param Norm              35.442\n",
      "trainer/Zf1 Grad Norm                4625.18\n",
      "trainer/Zf1 Param Norm                114.63\n",
      "trainer/Zf2 Grad Norm                5998.26\n",
      "trainer/Zf2 Param Norm                112.408\n",
      "trainer/Z Expert Predictions Mean    1078.12\n",
      "trainer/Z Expert Predictions Std       97.7977\n",
      "trainer/Z Expert Predictions Max     1254.71\n",
      "trainer/Z Expert Predictions Min      571.37\n",
      "trainer/Z Policy Predictions Mean     933.952\n",
      "trainer/Z Policy Predictions Std      296.411\n",
      "trainer/Z Policy Predictions Max     1235.61\n",
      "trainer/Z Policy Predictions Min     -107.223\n",
      "trainer/Z Expert Targets Mean        1064.84\n",
      "trainer/Z Expert Targets Std           99.3707\n",
      "trainer/Z Expert Targets Max         1221.65\n",
      "trainer/Z Expert Targets Min          547.84\n",
      "trainer/Z Policy Targets Mean         929.6\n",
      "trainer/Z Policy Targets Std          298.745\n",
      "trainer/Z Policy Targets Max         1210.07\n",
      "trainer/Z Policy Targets Min         -102.719\n",
      "trainer/Log Pis Mean                   30.6566\n",
      "trainer/Log Pis Std                     7.76796\n",
      "trainer/Policy mu Mean                  1.36429\n",
      "trainer/Policy mu Std                   2.60257\n",
      "trainer/Policy log std Mean            -3.4415\n",
      "trainer/Policy log std Std              1.43751\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        256924\n",
      "exploration/num paths total          1024\n",
      "evaluation/num steps total              1.95942e+06\n",
      "evaluation/num paths total           2534\n",
      "evaluation/path length Mean           980.1\n",
      "evaluation/path length Std             41.9296\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            871\n",
      "evaluation/Rewards Mean                 5.15666\n",
      "evaluation/Rewards Std                  1.32237\n",
      "evaluation/Rewards Max                  7.11089\n",
      "evaluation/Rewards Min                  0.108387\n",
      "evaluation/Returns Mean              5054.04\n",
      "evaluation/Returns Std                228.971\n",
      "evaluation/Returns Max               5190.71\n",
      "evaluation/Returns Min               4435.72\n",
      "evaluation/Estimation Bias Mean      1033.79\n",
      "evaluation/Estimation Bias Std        279.485\n",
      "evaluation/EB/Q_True Mean              49.715\n",
      "evaluation/EB/Q_True Std              151.99\n",
      "evaluation/EB/Q_Pred Mean            1083.5\n",
      "evaluation/EB/Q_Pred Std              205.489\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5054.04\n",
      "evaluation/Actions Mean                 0.490355\n",
      "evaluation/Actions Std                  0.656906\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.14473\n",
      "time/backward_zf1 (s)                   2.36409\n",
      "time/backward_zf2 (s)                   2.26333\n",
      "time/data sampling (s)                  0.316673\n",
      "time/data storing (s)                   0.0162103\n",
      "time/evaluation sampling (s)            1.57082\n",
      "time/exploration sampling (s)           0.209605\n",
      "time/logging (s)                        0.0120365\n",
      "time/preback_alpha (s)                  0.624603\n",
      "time/preback_policy (s)                 1.22395\n",
      "time/preback_start (s)                  0.135577\n",
      "time/preback_zf (s)                     5.26384\n",
      "time/saving (s)                         0.0062497\n",
      "time/training (s)                       2.31623\n",
      "time/epoch (s)                         18.4679\n",
      "time/total (s)                       4237.27\n",
      "Epoch                                 252\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:03:10.834689 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 253 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 264000\n",
      "trainer/ZF1 Loss                       54.3241\n",
      "trainer/ZF2 Loss                       74.7813\n",
      "trainer/ZF Expert Reward               19.3065\n",
      "trainer/ZF Policy Reward                8.64287\n",
      "trainer/ZF CHI2 Term                   75.5272\n",
      "trainer/Policy Loss                  -920.397\n",
      "trainer/Bias Loss                     147.485\n",
      "trainer/Bias Value                     11.8711\n",
      "trainer/Policy Grad Norm              589.097\n",
      "trainer/Policy Param Norm              35.4592\n",
      "trainer/Zf1 Grad Norm                2836.66\n",
      "trainer/Zf1 Param Norm                114.79\n",
      "trainer/Zf2 Grad Norm                4304.13\n",
      "trainer/Zf2 Param Norm                112.575\n",
      "trainer/Z Expert Predictions Mean    1077.86\n",
      "trainer/Z Expert Predictions Std      111.688\n",
      "trainer/Z Expert Predictions Max     1265.86\n",
      "trainer/Z Expert Predictions Min      548.714\n",
      "trainer/Z Policy Predictions Mean     914.419\n",
      "trainer/Z Policy Predictions Std      329.705\n",
      "trainer/Z Policy Predictions Max     1250.58\n",
      "trainer/Z Policy Predictions Min     -119.494\n",
      "trainer/Z Expert Targets Mean        1058.56\n",
      "trainer/Z Expert Targets Std          115.434\n",
      "trainer/Z Expert Targets Max         1264.56\n",
      "trainer/Z Expert Targets Min          473.597\n",
      "trainer/Z Policy Targets Mean         905.777\n",
      "trainer/Z Policy Targets Std          330.539\n",
      "trainer/Z Policy Targets Max         1250.29\n",
      "trainer/Z Policy Targets Min         -138.516\n",
      "trainer/Log Pis Mean                   31.0828\n",
      "trainer/Log Pis Std                     7.16043\n",
      "trainer/Policy mu Mean                  1.47723\n",
      "trainer/Policy mu Std                   2.5817\n",
      "trainer/Policy log std Mean            -3.47827\n",
      "trainer/Policy log std Std              1.47952\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        259924\n",
      "exploration/num paths total          1027\n",
      "evaluation/num steps total              1.96867e+06\n",
      "evaluation/num paths total           2544\n",
      "evaluation/path length Mean           925\n",
      "evaluation/path length Std            123.88\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            590\n",
      "evaluation/Rewards Mean                 5.13587\n",
      "evaluation/Rewards Std                  1.35662\n",
      "evaluation/Rewards Max                  8.22285\n",
      "evaluation/Rewards Min                  0.101776\n",
      "evaluation/Returns Mean              4750.68\n",
      "evaluation/Returns Std                684.005\n",
      "evaluation/Returns Max               5184.6\n",
      "evaluation/Returns Min               2896.36\n",
      "evaluation/Estimation Bias Mean       987.422\n",
      "evaluation/Estimation Bias Std        284.408\n",
      "evaluation/EB/Q_True Mean              52.6586\n",
      "evaluation/EB/Q_True Std              155.955\n",
      "evaluation/EB/Q_Pred Mean            1040.08\n",
      "evaluation/EB/Q_Pred Std              229.448\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4750.68\n",
      "evaluation/Actions Mean                 0.497356\n",
      "evaluation/Actions Std                  0.656166\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89506\n",
      "time/backward_zf1 (s)                   2.08574\n",
      "time/backward_zf2 (s)                   1.97053\n",
      "time/data sampling (s)                  0.303243\n",
      "time/data storing (s)                   0.0150544\n",
      "time/evaluation sampling (s)            1.45202\n",
      "time/exploration sampling (s)           0.217051\n",
      "time/logging (s)                        0.0109587\n",
      "time/preback_alpha (s)                  0.601633\n",
      "time/preback_policy (s)                 1.09804\n",
      "time/preback_start (s)                  0.131987\n",
      "time/preback_zf (s)                     5.16677\n",
      "time/saving (s)                         0.00571966\n",
      "time/training (s)                       2.39636\n",
      "time/epoch (s)                         17.3502\n",
      "time/total (s)                       4254.65\n",
      "Epoch                                 253\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:03:28.946668 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 254 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 265000\n",
      "trainer/ZF1 Loss                       34.2228\n",
      "trainer/ZF2 Loss                       30.1418\n",
      "trainer/ZF Expert Reward               12.2247\n",
      "trainer/ZF Policy Reward                1.45595\n",
      "trainer/ZF CHI2 Term                   43.2543\n",
      "trainer/Policy Loss                  -946.429\n",
      "trainer/Bias Loss                      82.4563\n",
      "trainer/Bias Value                     11.8771\n",
      "trainer/Policy Grad Norm              573.555\n",
      "trainer/Policy Param Norm              35.4802\n",
      "trainer/Zf1 Grad Norm                2747.77\n",
      "trainer/Zf1 Param Norm                114.948\n",
      "trainer/Zf2 Grad Norm                2891.6\n",
      "trainer/Zf2 Param Norm                112.73\n",
      "trainer/Z Expert Predictions Mean    1084.58\n",
      "trainer/Z Expert Predictions Std       93.5984\n",
      "trainer/Z Expert Predictions Max     1254.33\n",
      "trainer/Z Expert Predictions Min      697.866\n",
      "trainer/Z Policy Predictions Mean     942.533\n",
      "trainer/Z Policy Predictions Std      269.303\n",
      "trainer/Z Policy Predictions Max     1207.57\n",
      "trainer/Z Policy Predictions Min     -128.106\n",
      "trainer/Z Expert Targets Mean        1072.36\n",
      "trainer/Z Expert Targets Std           96.5588\n",
      "trainer/Z Expert Targets Max         1236.52\n",
      "trainer/Z Expert Targets Min          689.875\n",
      "trainer/Z Policy Targets Mean         941.077\n",
      "trainer/Z Policy Targets Std          268.121\n",
      "trainer/Z Policy Targets Max         1220.21\n",
      "trainer/Z Policy Targets Min         -136.943\n",
      "trainer/Log Pis Mean                   30.3231\n",
      "trainer/Log Pis Std                     6.79896\n",
      "trainer/Policy mu Mean                  1.35274\n",
      "trainer/Policy mu Std                   2.49207\n",
      "trainer/Policy log std Mean            -3.5165\n",
      "trainer/Policy log std Std              1.4778\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        260924\n",
      "exploration/num paths total          1028\n",
      "evaluation/num steps total              1.97867e+06\n",
      "evaluation/num paths total           2554\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.1878\n",
      "evaluation/Rewards Std                  1.33207\n",
      "evaluation/Rewards Max                  7.42212\n",
      "evaluation/Rewards Min                  0.0985978\n",
      "evaluation/Returns Mean              5187.8\n",
      "evaluation/Returns Std                 14.3827\n",
      "evaluation/Returns Max               5216.85\n",
      "evaluation/Returns Min               5165.39\n",
      "evaluation/Estimation Bias Mean      1014.9\n",
      "evaluation/Estimation Bias Std        159.76\n",
      "evaluation/EB/Q_True Mean              49.0556\n",
      "evaluation/EB/Q_True Std              151.629\n",
      "evaluation/EB/Q_Pred Mean            1063.95\n",
      "evaluation/EB/Q_Pred Std               55.4184\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5187.8\n",
      "evaluation/Actions Mean                 0.515011\n",
      "evaluation/Actions Std                  0.640099\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.05442\n",
      "time/backward_zf1 (s)                   2.27717\n",
      "time/backward_zf2 (s)                   2.16855\n",
      "time/data sampling (s)                  0.327648\n",
      "time/data storing (s)                   0.0149827\n",
      "time/evaluation sampling (s)            1.52338\n",
      "time/exploration sampling (s)           0.205586\n",
      "time/logging (s)                        0.0122218\n",
      "time/preback_alpha (s)                  0.617782\n",
      "time/preback_policy (s)                 1.20246\n",
      "time/preback_start (s)                  0.133978\n",
      "time/preback_zf (s)                     5.23107\n",
      "time/saving (s)                         0.00593524\n",
      "time/training (s)                       2.26128\n",
      "time/epoch (s)                         18.0365\n",
      "time/total (s)                       4272.72\n",
      "Epoch                                 254\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:03:46.105692 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 255 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 266000\n",
      "trainer/ZF1 Loss                       25.7853\n",
      "trainer/ZF2 Loss                       25.1227\n",
      "trainer/ZF Expert Reward               13.1482\n",
      "trainer/ZF Policy Reward                0.973968\n",
      "trainer/ZF CHI2 Term                   37.9277\n",
      "trainer/Policy Loss                  -947.743\n",
      "trainer/Bias Loss                      59.7721\n",
      "trainer/Bias Value                     11.8834\n",
      "trainer/Policy Grad Norm              426.909\n",
      "trainer/Policy Param Norm              35.5038\n",
      "trainer/Zf1 Grad Norm                2225.69\n",
      "trainer/Zf1 Param Norm                115.109\n",
      "trainer/Zf2 Grad Norm                1896.75\n",
      "trainer/Zf2 Param Norm                112.902\n",
      "trainer/Z Expert Predictions Mean    1063.07\n",
      "trainer/Z Expert Predictions Std      103.833\n",
      "trainer/Z Expert Predictions Max     1270.94\n",
      "trainer/Z Expert Predictions Min      721.894\n",
      "trainer/Z Policy Predictions Mean     939.043\n",
      "trainer/Z Policy Predictions Std      264.927\n",
      "trainer/Z Policy Predictions Max     1239.3\n",
      "trainer/Z Policy Predictions Min      -43.1896\n",
      "trainer/Z Expert Targets Mean        1049.92\n",
      "trainer/Z Expert Targets Std          105.706\n",
      "trainer/Z Expert Targets Max         1264.18\n",
      "trainer/Z Expert Targets Min          709.373\n",
      "trainer/Z Policy Targets Mean         938.069\n",
      "trainer/Z Policy Targets Std          263.253\n",
      "trainer/Z Policy Targets Max         1224.16\n",
      "trainer/Z Policy Targets Min          -45.8802\n",
      "trainer/Log Pis Mean                   29.942\n",
      "trainer/Log Pis Std                     6.6793\n",
      "trainer/Policy mu Mean                  1.41778\n",
      "trainer/Policy mu Std                   2.53138\n",
      "trainer/Policy log std Mean            -3.53609\n",
      "trainer/Policy log std Std              1.41021\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        260924\n",
      "exploration/num paths total          1028\n",
      "evaluation/num steps total              1.98867e+06\n",
      "evaluation/num paths total           2564\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.22706\n",
      "evaluation/Rewards Std                  1.34147\n",
      "evaluation/Rewards Max                  7.36832\n",
      "evaluation/Rewards Min                  0.0861982\n",
      "evaluation/Returns Mean              5227.06\n",
      "evaluation/Returns Std                 30.7646\n",
      "evaluation/Returns Max               5270.96\n",
      "evaluation/Returns Min               5166.73\n",
      "evaluation/Estimation Bias Mean      1026.15\n",
      "evaluation/Estimation Bias Std        168.657\n",
      "evaluation/EB/Q_True Mean              49.716\n",
      "evaluation/EB/Q_True Std              153.733\n",
      "evaluation/EB/Q_Pred Mean            1075.87\n",
      "evaluation/EB/Q_Pred Std               54.6674\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5227.06\n",
      "evaluation/Actions Mean                 0.503912\n",
      "evaluation/Actions Std                  0.642202\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93962\n",
      "time/backward_zf1 (s)                   2.08176\n",
      "time/backward_zf2 (s)                   2.01996\n",
      "time/data sampling (s)                  0.271899\n",
      "time/data storing (s)                   0.0149452\n",
      "time/evaluation sampling (s)            1.39376\n",
      "time/exploration sampling (s)           0.199322\n",
      "time/logging (s)                        0.0118384\n",
      "time/preback_alpha (s)                  0.583449\n",
      "time/preback_policy (s)                 1.16897\n",
      "time/preback_start (s)                  0.125719\n",
      "time/preback_zf (s)                     5.14408\n",
      "time/saving (s)                         0.00577071\n",
      "time/training (s)                       2.12637\n",
      "time/epoch (s)                         17.0875\n",
      "time/total (s)                       4289.82\n",
      "Epoch                                 255\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:04:02.542552 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 256 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 267000\n",
      "trainer/ZF1 Loss                       42.7117\n",
      "trainer/ZF2 Loss                       45.8353\n",
      "trainer/ZF Expert Reward               13.034\n",
      "trainer/ZF Policy Reward               -2.71381\n",
      "trainer/ZF CHI2 Term                   60.3181\n",
      "trainer/Policy Loss                  -955.718\n",
      "trainer/Bias Loss                     146.907\n",
      "trainer/Bias Value                     11.8897\n",
      "trainer/Policy Grad Norm              779.876\n",
      "trainer/Policy Param Norm              35.5233\n",
      "trainer/Zf1 Grad Norm                2512.75\n",
      "trainer/Zf1 Param Norm                115.284\n",
      "trainer/Zf2 Grad Norm                3869.97\n",
      "trainer/Zf2 Param Norm                113.065\n",
      "trainer/Z Expert Predictions Mean    1079.61\n",
      "trainer/Z Expert Predictions Std       85.0336\n",
      "trainer/Z Expert Predictions Max     1243.96\n",
      "trainer/Z Expert Predictions Min      684.083\n",
      "trainer/Z Policy Predictions Mean     945.983\n",
      "trainer/Z Policy Predictions Std      259.782\n",
      "trainer/Z Policy Predictions Max     1196.39\n",
      "trainer/Z Policy Predictions Min      -82.5095\n",
      "trainer/Z Expert Targets Mean        1066.58\n",
      "trainer/Z Expert Targets Std           87.9482\n",
      "trainer/Z Expert Targets Max         1258.17\n",
      "trainer/Z Expert Targets Min          652.297\n",
      "trainer/Z Policy Targets Mean         948.697\n",
      "trainer/Z Policy Targets Std          254.776\n",
      "trainer/Z Policy Targets Max         1190.31\n",
      "trainer/Z Policy Targets Min          -86.4947\n",
      "trainer/Log Pis Mean                   29.6874\n",
      "trainer/Log Pis Std                     6.71403\n",
      "trainer/Policy mu Mean                  1.31534\n",
      "trainer/Policy mu Std                   2.23969\n",
      "trainer/Policy log std Mean            -3.56741\n",
      "trainer/Policy log std Std              1.39465\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        262924\n",
      "exploration/num paths total          1030\n",
      "evaluation/num steps total              1.99867e+06\n",
      "evaluation/num paths total           2574\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16074\n",
      "evaluation/Rewards Std                  1.31234\n",
      "evaluation/Rewards Max                  7.29196\n",
      "evaluation/Rewards Min                  0.102393\n",
      "evaluation/Returns Mean              5160.74\n",
      "evaluation/Returns Std                 37.847\n",
      "evaluation/Returns Max               5216.1\n",
      "evaluation/Returns Min               5102.34\n",
      "evaluation/Estimation Bias Mean      1027.43\n",
      "evaluation/Estimation Bias Std        169.552\n",
      "evaluation/EB/Q_True Mean              48.7271\n",
      "evaluation/EB/Q_True Std              150.239\n",
      "evaluation/EB/Q_Pred Mean            1076.16\n",
      "evaluation/EB/Q_Pred Std               69.3596\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5160.74\n",
      "evaluation/Actions Mean                 0.513102\n",
      "evaluation/Actions Std                  0.638972\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81253\n",
      "time/backward_zf1 (s)                   1.92278\n",
      "time/backward_zf2 (s)                   1.87106\n",
      "time/data sampling (s)                  0.235444\n",
      "time/data storing (s)                   0.0139127\n",
      "time/evaluation sampling (s)            1.46482\n",
      "time/exploration sampling (s)           0.198118\n",
      "time/logging (s)                        0.0119666\n",
      "time/preback_alpha (s)                  0.541255\n",
      "time/preback_policy (s)                 1.08654\n",
      "time/preback_start (s)                  0.117737\n",
      "time/preback_zf (s)                     4.97365\n",
      "time/saving (s)                         0.0176864\n",
      "time/training (s)                       2.10238\n",
      "time/epoch (s)                         16.3699\n",
      "time/total (s)                       4306.22\n",
      "Epoch                                 256\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:04:19.401974 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 257 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 268000\n",
      "trainer/ZF1 Loss                       20.9171\n",
      "trainer/ZF2 Loss                       22.5827\n",
      "trainer/ZF Expert Reward               11.635\n",
      "trainer/ZF Policy Reward               -1.49519\n",
      "trainer/ZF CHI2 Term                   35.1857\n",
      "trainer/Policy Loss                  -943.297\n",
      "trainer/Bias Loss                      76.872\n",
      "trainer/Bias Value                     11.896\n",
      "trainer/Policy Grad Norm              497.196\n",
      "trainer/Policy Param Norm              35.5407\n",
      "trainer/Zf1 Grad Norm                2163.23\n",
      "trainer/Zf1 Param Norm                115.451\n",
      "trainer/Zf2 Grad Norm                2446.51\n",
      "trainer/Zf2 Param Norm                113.223\n",
      "trainer/Z Expert Predictions Mean    1066.78\n",
      "trainer/Z Expert Predictions Std       92.6155\n",
      "trainer/Z Expert Predictions Max     1218.07\n",
      "trainer/Z Expert Predictions Min      573.529\n",
      "trainer/Z Policy Predictions Mean     933.165\n",
      "trainer/Z Policy Predictions Std      289.045\n",
      "trainer/Z Policy Predictions Max     1219.87\n",
      "trainer/Z Policy Predictions Min      -95.6328\n",
      "trainer/Z Expert Targets Mean        1055.14\n",
      "trainer/Z Expert Targets Std           94.4446\n",
      "trainer/Z Expert Targets Max         1204.3\n",
      "trainer/Z Expert Targets Min          542.934\n",
      "trainer/Z Policy Targets Mean         934.66\n",
      "trainer/Z Policy Targets Std          286.947\n",
      "trainer/Z Policy Targets Max         1212.65\n",
      "trainer/Z Policy Targets Min          -85.9165\n",
      "trainer/Log Pis Mean                   30.5594\n",
      "trainer/Log Pis Std                     6.99727\n",
      "trainer/Policy mu Mean                  1.4358\n",
      "trainer/Policy mu Std                   2.53759\n",
      "trainer/Policy log std Mean            -3.56347\n",
      "trainer/Policy log std Std              1.4791\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        262924\n",
      "exploration/num paths total          1030\n",
      "evaluation/num steps total              2.00743e+06\n",
      "evaluation/num paths total           2584\n",
      "evaluation/path length Mean           875.4\n",
      "evaluation/path length Std            168.423\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            458\n",
      "evaluation/Rewards Mean                 5.07354\n",
      "evaluation/Rewards Std                  1.34262\n",
      "evaluation/Rewards Max                  7.05903\n",
      "evaluation/Rewards Min                  0.139585\n",
      "evaluation/Returns Mean              4441.38\n",
      "evaluation/Returns Std                925.595\n",
      "evaluation/Returns Max               5150.41\n",
      "evaluation/Returns Min               2139.22\n",
      "evaluation/Estimation Bias Mean       888.427\n",
      "evaluation/Estimation Bias Std        331.085\n",
      "evaluation/EB/Q_True Mean              55.5461\n",
      "evaluation/EB/Q_True Std              159.245\n",
      "evaluation/EB/Q_Pred Mean             943.973\n",
      "evaluation/EB/Q_Pred Std              296.247\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4441.38\n",
      "evaluation/Actions Mean                 0.478162\n",
      "evaluation/Actions Std                  0.668878\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85116\n",
      "time/backward_zf1 (s)                   1.98123\n",
      "time/backward_zf2 (s)                   1.90102\n",
      "time/data sampling (s)                  0.269433\n",
      "time/data storing (s)                   0.0137863\n",
      "time/evaluation sampling (s)            1.47607\n",
      "time/exploration sampling (s)           0.192393\n",
      "time/logging (s)                        0.0105147\n",
      "time/preback_alpha (s)                  0.564427\n",
      "time/preback_policy (s)                 1.04702\n",
      "time/preback_start (s)                  0.12095\n",
      "time/preback_zf (s)                     5.06974\n",
      "time/saving (s)                         0.00563191\n",
      "time/training (s)                       2.27771\n",
      "time/epoch (s)                         16.7811\n",
      "time/total (s)                       4323.02\n",
      "Epoch                                 257\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:04:35.730721 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 258 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 269000\n",
      "trainer/ZF1 Loss                       60.5054\n",
      "trainer/ZF2 Loss                       58.1184\n",
      "trainer/ZF Expert Reward               16.6731\n",
      "trainer/ZF Policy Reward                4.68712\n",
      "trainer/ZF CHI2 Term                   71.6034\n",
      "trainer/Policy Loss                  -948.335\n",
      "trainer/Bias Loss                     195.173\n",
      "trainer/Bias Value                     11.9022\n",
      "trainer/Policy Grad Norm              429.87\n",
      "trainer/Policy Param Norm              35.5671\n",
      "trainer/Zf1 Grad Norm                4722.69\n",
      "trainer/Zf1 Param Norm                115.617\n",
      "trainer/Zf2 Grad Norm                3777.26\n",
      "trainer/Zf2 Param Norm                113.388\n",
      "trainer/Z Expert Predictions Mean    1070.43\n",
      "trainer/Z Expert Predictions Std       99.6495\n",
      "trainer/Z Expert Predictions Max     1284.71\n",
      "trainer/Z Expert Predictions Min      705.545\n",
      "trainer/Z Policy Predictions Mean     946.894\n",
      "trainer/Z Policy Predictions Std      258.046\n",
      "trainer/Z Policy Predictions Max     1187.07\n",
      "trainer/Z Policy Predictions Min      -59.8779\n",
      "trainer/Z Expert Targets Mean        1053.76\n",
      "trainer/Z Expert Targets Std          104.931\n",
      "trainer/Z Expert Targets Max         1249.74\n",
      "trainer/Z Expert Targets Min          619.41\n",
      "trainer/Z Policy Targets Mean         942.207\n",
      "trainer/Z Policy Targets Std          260.581\n",
      "trainer/Z Policy Targets Max         1166.71\n",
      "trainer/Z Policy Targets Min          -79.2792\n",
      "trainer/Log Pis Mean                   30.5487\n",
      "trainer/Log Pis Std                     7.06043\n",
      "trainer/Policy mu Mean                  1.28477\n",
      "trainer/Policy mu Std                   2.43416\n",
      "trainer/Policy log std Mean            -3.54753\n",
      "trainer/Policy log std Std              1.38871\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        262924\n",
      "exploration/num paths total          1030\n",
      "evaluation/num steps total              2.01743e+06\n",
      "evaluation/num paths total           2594\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20392\n",
      "evaluation/Rewards Std                  1.33495\n",
      "evaluation/Rewards Max                  7.35463\n",
      "evaluation/Rewards Min                  0.0939072\n",
      "evaluation/Returns Mean              5203.92\n",
      "evaluation/Returns Std                 28.7034\n",
      "evaluation/Returns Max               5248.74\n",
      "evaluation/Returns Min               5158.43\n",
      "evaluation/Estimation Bias Mean      1048.7\n",
      "evaluation/Estimation Bias Std        148.744\n",
      "evaluation/EB/Q_True Mean              49.019\n",
      "evaluation/EB/Q_True Std              151.321\n",
      "evaluation/EB/Q_Pred Mean            1097.72\n",
      "evaluation/EB/Q_Pred Std               52.8902\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5203.92\n",
      "evaluation/Actions Mean                 0.514485\n",
      "evaluation/Actions Std                  0.639754\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.67341\n",
      "time/backward_zf1 (s)                   1.81932\n",
      "time/backward_zf2 (s)                   1.73587\n",
      "time/data sampling (s)                  0.250831\n",
      "time/data storing (s)                   0.0138138\n",
      "time/evaluation sampling (s)            1.44237\n",
      "time/exploration sampling (s)           0.190772\n",
      "time/logging (s)                        0.0119611\n",
      "time/preback_alpha (s)                  0.553243\n",
      "time/preback_policy (s)                 0.934565\n",
      "time/preback_start (s)                  0.121296\n",
      "time/preback_zf (s)                     5.03676\n",
      "time/saving (s)                         0.00590218\n",
      "time/training (s)                       2.47312\n",
      "time/epoch (s)                         16.2632\n",
      "time/total (s)                       4339.31\n",
      "Epoch                                 258\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:04:52.999406 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 259 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 270000\n",
      "trainer/ZF1 Loss                      250.819\n",
      "trainer/ZF2 Loss                      246.533\n",
      "trainer/ZF Expert Reward               16.69\n",
      "trainer/ZF Policy Reward                7.2414\n",
      "trainer/ZF CHI2 Term                  258.439\n",
      "trainer/Policy Loss                  -943.784\n",
      "trainer/Bias Loss                     130.564\n",
      "trainer/Bias Value                     11.9086\n",
      "trainer/Policy Grad Norm              357.196\n",
      "trainer/Policy Param Norm              35.5837\n",
      "trainer/Zf1 Grad Norm                6343.19\n",
      "trainer/Zf1 Param Norm                115.774\n",
      "trainer/Zf2 Grad Norm                4375.24\n",
      "trainer/Zf2 Param Norm                113.543\n",
      "trainer/Z Expert Predictions Mean    1065.11\n",
      "trainer/Z Expert Predictions Std      103.555\n",
      "trainer/Z Expert Predictions Max     1244.03\n",
      "trainer/Z Expert Predictions Min      188.359\n",
      "trainer/Z Policy Predictions Mean     940.793\n",
      "trainer/Z Policy Predictions Std      291.321\n",
      "trainer/Z Policy Predictions Max     1199.98\n",
      "trainer/Z Policy Predictions Min     -156.904\n",
      "trainer/Z Expert Targets Mean        1048.42\n",
      "trainer/Z Expert Targets Std          112.152\n",
      "trainer/Z Expert Targets Max         1238.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         933.551\n",
      "trainer/Z Policy Targets Std          292.027\n",
      "trainer/Z Policy Targets Max         1191.54\n",
      "trainer/Z Policy Targets Min         -140.232\n",
      "trainer/Log Pis Mean                   31.5141\n",
      "trainer/Log Pis Std                     8.47197\n",
      "trainer/Policy mu Mean                  1.29512\n",
      "trainer/Policy mu Std                   2.67436\n",
      "trainer/Policy log std Mean            -3.67276\n",
      "trainer/Policy log std Std              1.46471\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        265924\n",
      "exploration/num paths total          1033\n",
      "evaluation/num steps total              2.02743e+06\n",
      "evaluation/num paths total           2604\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.11472\n",
      "evaluation/Rewards Std                  1.29676\n",
      "evaluation/Rewards Max                  7.04908\n",
      "evaluation/Rewards Min                  0.0988787\n",
      "evaluation/Returns Mean              5114.72\n",
      "evaluation/Returns Std                 17.94\n",
      "evaluation/Returns Max               5155.93\n",
      "evaluation/Returns Min               5079.97\n",
      "evaluation/Estimation Bias Mean       997.737\n",
      "evaluation/Estimation Bias Std        171.764\n",
      "evaluation/EB/Q_True Mean              48.379\n",
      "evaluation/EB/Q_True Std              149.291\n",
      "evaluation/EB/Q_Pred Mean            1046.12\n",
      "evaluation/EB/Q_Pred Std               94.012\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5114.72\n",
      "evaluation/Actions Mean                 0.49877\n",
      "evaluation/Actions Std                  0.651987\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82841\n",
      "time/backward_zf1 (s)                   2.06417\n",
      "time/backward_zf2 (s)                   1.92814\n",
      "time/data sampling (s)                  0.25558\n",
      "time/data storing (s)                   0.0147449\n",
      "time/evaluation sampling (s)            1.49485\n",
      "time/exploration sampling (s)           0.202141\n",
      "time/logging (s)                        0.0134083\n",
      "time/preback_alpha (s)                  0.577013\n",
      "time/preback_policy (s)                 1.05955\n",
      "time/preback_start (s)                  0.124258\n",
      "time/preback_zf (s)                     5.19254\n",
      "time/saving (s)                         0.00640971\n",
      "time/training (s)                       2.43798\n",
      "time/epoch (s)                         17.1992\n",
      "time/total (s)                       4356.53\n",
      "Epoch                                 259\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:05:09.661834 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 260 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 271000\n",
      "trainer/ZF1 Loss                       34.3103\n",
      "trainer/ZF2 Loss                       44.4586\n",
      "trainer/ZF Expert Reward               17.6034\n",
      "trainer/ZF Policy Reward                4.55301\n",
      "trainer/ZF CHI2 Term                   52.7406\n",
      "trainer/Policy Loss                  -906.903\n",
      "trainer/Bias Loss                     132.247\n",
      "trainer/Bias Value                     11.9146\n",
      "trainer/Policy Grad Norm              531.017\n",
      "trainer/Policy Param Norm              35.6052\n",
      "trainer/Zf1 Grad Norm                2618.57\n",
      "trainer/Zf1 Param Norm                115.918\n",
      "trainer/Zf2 Grad Norm                3728.42\n",
      "trainer/Zf2 Param Norm                113.697\n",
      "trainer/Z Expert Predictions Mean    1073.17\n",
      "trainer/Z Expert Predictions Std      100.014\n",
      "trainer/Z Expert Predictions Max     1245.36\n",
      "trainer/Z Expert Predictions Min      126.354\n",
      "trainer/Z Policy Predictions Mean     897.619\n",
      "trainer/Z Policy Predictions Std      301.748\n",
      "trainer/Z Policy Predictions Max     1243.38\n",
      "trainer/Z Policy Predictions Min      -98.9866\n",
      "trainer/Z Expert Targets Mean        1055.57\n",
      "trainer/Z Expert Targets Std          106.688\n",
      "trainer/Z Expert Targets Max         1212.8\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         893.066\n",
      "trainer/Z Policy Targets Std          301.317\n",
      "trainer/Z Policy Targets Max         1224.08\n",
      "trainer/Z Policy Targets Min         -136.731\n",
      "trainer/Log Pis Mean                   30.5749\n",
      "trainer/Log Pis Std                     7.17622\n",
      "trainer/Policy mu Mean                  1.38737\n",
      "trainer/Policy mu Std                   2.54374\n",
      "trainer/Policy log std Mean            -3.42772\n",
      "trainer/Policy log std Std              1.44298\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        265924\n",
      "exploration/num paths total          1033\n",
      "evaluation/num steps total              2.03743e+06\n",
      "evaluation/num paths total           2614\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12324\n",
      "evaluation/Rewards Std                  1.28933\n",
      "evaluation/Rewards Max                  7.02426\n",
      "evaluation/Rewards Min                  0.119205\n",
      "evaluation/Returns Mean              5123.24\n",
      "evaluation/Returns Std                 23.3257\n",
      "evaluation/Returns Max               5168.64\n",
      "evaluation/Returns Min               5091.02\n",
      "evaluation/Estimation Bias Mean      1047.63\n",
      "evaluation/Estimation Bias Std        164.814\n",
      "evaluation/EB/Q_True Mean              48.313\n",
      "evaluation/EB/Q_True Std              149.361\n",
      "evaluation/EB/Q_Pred Mean            1095.94\n",
      "evaluation/EB/Q_Pred Std               63.4864\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5123.24\n",
      "evaluation/Actions Mean                 0.494207\n",
      "evaluation/Actions Std                  0.644958\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89756\n",
      "time/backward_zf1 (s)                   2.011\n",
      "time/backward_zf2 (s)                   1.97851\n",
      "time/data sampling (s)                  0.234862\n",
      "time/data storing (s)                   0.0136721\n",
      "time/evaluation sampling (s)            1.48311\n",
      "time/exploration sampling (s)           0.189921\n",
      "time/logging (s)                        0.0117141\n",
      "time/preback_alpha (s)                  0.544016\n",
      "time/preback_policy (s)                 1.13976\n",
      "time/preback_start (s)                  0.117314\n",
      "time/preback_zf (s)                     4.9833\n",
      "time/saving (s)                         0.00581966\n",
      "time/training (s)                       1.98317\n",
      "time/epoch (s)                         16.5937\n",
      "time/total (s)                       4373.14\n",
      "Epoch                                 260\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:05:27.238332 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 261 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 272000\n",
      "trainer/ZF1 Loss                       28.4633\n",
      "trainer/ZF2 Loss                       28.9083\n",
      "trainer/ZF Expert Reward               12.8328\n",
      "trainer/ZF Policy Reward                0.0145254\n",
      "trainer/ZF CHI2 Term                   41.8095\n",
      "trainer/Policy Loss                  -941.927\n",
      "trainer/Bias Loss                      77.4041\n",
      "trainer/Bias Value                     11.9209\n",
      "trainer/Policy Grad Norm              472.823\n",
      "trainer/Policy Param Norm              35.6238\n",
      "trainer/Zf1 Grad Norm                2693.67\n",
      "trainer/Zf1 Param Norm                116.086\n",
      "trainer/Zf2 Grad Norm                2518.4\n",
      "trainer/Zf2 Param Norm                113.861\n",
      "trainer/Z Expert Predictions Mean    1063.63\n",
      "trainer/Z Expert Predictions Std       92.3964\n",
      "trainer/Z Expert Predictions Max     1216.27\n",
      "trainer/Z Expert Predictions Min      630.36\n",
      "trainer/Z Policy Predictions Mean     938.066\n",
      "trainer/Z Policy Predictions Std      265.246\n",
      "trainer/Z Policy Predictions Max     1184.83\n",
      "trainer/Z Policy Predictions Min      -55.2104\n",
      "trainer/Z Expert Targets Mean        1050.8\n",
      "trainer/Z Expert Targets Std           92.7846\n",
      "trainer/Z Expert Targets Max         1198.08\n",
      "trainer/Z Expert Targets Min          603.342\n",
      "trainer/Z Policy Targets Mean         938.052\n",
      "trainer/Z Policy Targets Std          259.619\n",
      "trainer/Z Policy Targets Max         1187.66\n",
      "trainer/Z Policy Targets Min          -63.6584\n",
      "trainer/Log Pis Mean                   30.5383\n",
      "trainer/Log Pis Std                     6.49516\n",
      "trainer/Policy mu Mean                  1.38728\n",
      "trainer/Policy mu Std                   2.36291\n",
      "trainer/Policy log std Mean            -3.63452\n",
      "trainer/Policy log std Std              1.46502\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        266924\n",
      "exploration/num paths total          1034\n",
      "evaluation/num steps total              2.04743e+06\n",
      "evaluation/num paths total           2624\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14974\n",
      "evaluation/Rewards Std                  1.31335\n",
      "evaluation/Rewards Max                  7.14883\n",
      "evaluation/Rewards Min                  0.094425\n",
      "evaluation/Returns Mean              5149.74\n",
      "evaluation/Returns Std                 14.8259\n",
      "evaluation/Returns Max               5170.35\n",
      "evaluation/Returns Min               5121.41\n",
      "evaluation/Estimation Bias Mean      1012.37\n",
      "evaluation/Estimation Bias Std        166.5\n",
      "evaluation/EB/Q_True Mean              48.649\n",
      "evaluation/EB/Q_True Std              150.244\n",
      "evaluation/EB/Q_Pred Mean            1061.02\n",
      "evaluation/EB/Q_Pred Std               86.4167\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5149.74\n",
      "evaluation/Actions Mean                 0.507211\n",
      "evaluation/Actions Std                  0.646096\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.02613\n",
      "time/backward_zf1 (s)                   2.17096\n",
      "time/backward_zf2 (s)                   2.13035\n",
      "time/data sampling (s)                  0.269908\n",
      "time/data storing (s)                   0.0145927\n",
      "time/evaluation sampling (s)            1.50946\n",
      "time/exploration sampling (s)           0.200717\n",
      "time/logging (s)                        0.0125095\n",
      "time/preback_alpha (s)                  0.574461\n",
      "time/preback_policy (s)                 1.21693\n",
      "time/preback_start (s)                  0.126822\n",
      "time/preback_zf (s)                     5.10451\n",
      "time/saving (s)                         0.00655966\n",
      "time/training (s)                       2.14327\n",
      "time/epoch (s)                         17.5072\n",
      "time/total (s)                       4390.67\n",
      "Epoch                                 261\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:05:44.506427 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 262 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 273000\n",
      "trainer/ZF1 Loss                       36.3518\n",
      "trainer/ZF2 Loss                       34.4128\n",
      "trainer/ZF Expert Reward               11.574\n",
      "trainer/ZF Policy Reward                0.387948\n",
      "trainer/ZF CHI2 Term                   46.882\n",
      "trainer/Policy Loss                  -935.031\n",
      "trainer/Bias Loss                      76.2699\n",
      "trainer/Bias Value                     11.9274\n",
      "trainer/Policy Grad Norm              492.805\n",
      "trainer/Policy Param Norm              35.6463\n",
      "trainer/Zf1 Grad Norm                2460.65\n",
      "trainer/Zf1 Param Norm                116.237\n",
      "trainer/Zf2 Grad Norm                2922.24\n",
      "trainer/Zf2 Param Norm                113.999\n",
      "trainer/Z Expert Predictions Mean    1058.79\n",
      "trainer/Z Expert Predictions Std       87.5571\n",
      "trainer/Z Expert Predictions Max     1233.55\n",
      "trainer/Z Expert Predictions Min      609.688\n",
      "trainer/Z Policy Predictions Mean     925.125\n",
      "trainer/Z Policy Predictions Std      282.034\n",
      "trainer/Z Policy Predictions Max     1176.65\n",
      "trainer/Z Policy Predictions Min     -135.978\n",
      "trainer/Z Expert Targets Mean        1047.21\n",
      "trainer/Z Expert Targets Std           89.7011\n",
      "trainer/Z Expert Targets Max         1229.22\n",
      "trainer/Z Expert Targets Min          605.652\n",
      "trainer/Z Policy Targets Mean         924.737\n",
      "trainer/Z Policy Targets Std          281.624\n",
      "trainer/Z Policy Targets Max         1179.9\n",
      "trainer/Z Policy Targets Min         -111.256\n",
      "trainer/Log Pis Mean                   31.3624\n",
      "trainer/Log Pis Std                     8.01383\n",
      "trainer/Policy mu Mean                  1.36157\n",
      "trainer/Policy mu Std                   2.76537\n",
      "trainer/Policy log std Mean            -3.55098\n",
      "trainer/Policy log std Std              1.49839\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        266924\n",
      "exploration/num paths total          1034\n",
      "evaluation/num steps total              2.05682e+06\n",
      "evaluation/num paths total           2635\n",
      "evaluation/path length Mean           853.818\n",
      "evaluation/path length Std            241.98\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            338\n",
      "evaluation/Rewards Mean                 5.01014\n",
      "evaluation/Rewards Std                  1.35856\n",
      "evaluation/Rewards Max                  7.10774\n",
      "evaluation/Rewards Min                  0.119675\n",
      "evaluation/Returns Mean              4277.75\n",
      "evaluation/Returns Std               1365.42\n",
      "evaluation/Returns Max               5147.48\n",
      "evaluation/Returns Min               1391.77\n",
      "evaluation/Estimation Bias Mean       982.886\n",
      "evaluation/Estimation Bias Std        255.85\n",
      "evaluation/EB/Q_True Mean              51.3373\n",
      "evaluation/EB/Q_True Std              153.153\n",
      "evaluation/EB/Q_Pred Mean            1034.22\n",
      "evaluation/EB/Q_Pred Std              183.782\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4277.75\n",
      "evaluation/Actions Mean                 0.491724\n",
      "evaluation/Actions Std                  0.652583\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85152\n",
      "time/backward_zf1 (s)                   2.06393\n",
      "time/backward_zf2 (s)                   1.94609\n",
      "time/data sampling (s)                  0.306492\n",
      "time/data storing (s)                   0.0153309\n",
      "time/evaluation sampling (s)            1.40259\n",
      "time/exploration sampling (s)           0.205879\n",
      "time/logging (s)                        0.0125487\n",
      "time/preback_alpha (s)                  0.599148\n",
      "time/preback_policy (s)                 1.04392\n",
      "time/preback_start (s)                  0.133295\n",
      "time/preback_zf (s)                     5.16354\n",
      "time/saving (s)                         0.00638492\n",
      "time/training (s)                       2.44229\n",
      "time/epoch (s)                         17.193\n",
      "time/total (s)                       4407.89\n",
      "Epoch                                 262\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:06:02.647380 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 263 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 274000\n",
      "trainer/ZF1 Loss                       26.4541\n",
      "trainer/ZF2 Loss                       24.2689\n",
      "trainer/ZF Expert Reward               13.2025\n",
      "trainer/ZF Policy Reward               -1.94378\n",
      "trainer/ZF CHI2 Term                   40.8107\n",
      "trainer/Policy Loss                  -927.348\n",
      "trainer/Bias Loss                      75.7411\n",
      "trainer/Bias Value                     11.9336\n",
      "trainer/Policy Grad Norm              405.259\n",
      "trainer/Policy Param Norm              35.6701\n",
      "trainer/Zf1 Grad Norm                1907.36\n",
      "trainer/Zf1 Param Norm                116.38\n",
      "trainer/Zf2 Grad Norm                2660.9\n",
      "trainer/Zf2 Param Norm                114.133\n",
      "trainer/Z Expert Predictions Mean    1042.77\n",
      "trainer/Z Expert Predictions Std       96.9557\n",
      "trainer/Z Expert Predictions Max     1223.03\n",
      "trainer/Z Expert Predictions Min      622.974\n",
      "trainer/Z Policy Predictions Mean     919.061\n",
      "trainer/Z Policy Predictions Std      270.626\n",
      "trainer/Z Policy Predictions Max     1175.35\n",
      "trainer/Z Policy Predictions Min     -102.096\n",
      "trainer/Z Expert Targets Mean        1029.57\n",
      "trainer/Z Expert Targets Std           99.2244\n",
      "trainer/Z Expert Targets Max         1207.25\n",
      "trainer/Z Expert Targets Min          622.438\n",
      "trainer/Z Policy Targets Mean         921.005\n",
      "trainer/Z Policy Targets Std          269.649\n",
      "trainer/Z Policy Targets Max         1172.54\n",
      "trainer/Z Policy Targets Min          -99.8996\n",
      "trainer/Log Pis Mean                   30.2903\n",
      "trainer/Log Pis Std                     6.98299\n",
      "trainer/Policy mu Mean                  1.37496\n",
      "trainer/Policy mu Std                   2.4506\n",
      "trainer/Policy log std Mean            -3.50309\n",
      "trainer/Policy log std Std              1.50067\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        269924\n",
      "exploration/num paths total          1037\n",
      "evaluation/num steps total              2.06566e+06\n",
      "evaluation/num paths total           2645\n",
      "evaluation/path length Mean           884.6\n",
      "evaluation/path length Std            155.915\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            598\n",
      "evaluation/Rewards Mean                 5.05874\n",
      "evaluation/Rewards Std                  1.35151\n",
      "evaluation/Rewards Max                  7.00318\n",
      "evaluation/Rewards Min                  0.0967618\n",
      "evaluation/Returns Mean              4474.96\n",
      "evaluation/Returns Std                888.228\n",
      "evaluation/Returns Max               5160.33\n",
      "evaluation/Returns Min               2832.2\n",
      "evaluation/Estimation Bias Mean       941.825\n",
      "evaluation/Estimation Bias Std        285.18\n",
      "evaluation/EB/Q_True Mean              55.0098\n",
      "evaluation/EB/Q_True Std              158.474\n",
      "evaluation/EB/Q_Pred Mean             996.835\n",
      "evaluation/EB/Q_Pred Std              228.262\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4474.96\n",
      "evaluation/Actions Mean                 0.49312\n",
      "evaluation/Actions Std                  0.655715\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.07372\n",
      "time/backward_zf1 (s)                   2.24228\n",
      "time/backward_zf2 (s)                   2.16823\n",
      "time/data sampling (s)                  0.307151\n",
      "time/data storing (s)                   0.0156516\n",
      "time/evaluation sampling (s)            1.43957\n",
      "time/exploration sampling (s)           0.213512\n",
      "time/logging (s)                        0.0119709\n",
      "time/preback_alpha (s)                  0.621603\n",
      "time/preback_policy (s)                 1.22063\n",
      "time/preback_start (s)                  0.134372\n",
      "time/preback_zf (s)                     5.24176\n",
      "time/saving (s)                         0.00567726\n",
      "time/training (s)                       2.36958\n",
      "time/epoch (s)                         18.0657\n",
      "time/total (s)                       4425.98\n",
      "Epoch                                 263\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:06:21.979716 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 264 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 275000\n",
      "trainer/ZF1 Loss                       21.2147\n",
      "trainer/ZF2 Loss                       19.424\n",
      "trainer/ZF Expert Reward               12.0651\n",
      "trainer/ZF Policy Reward               -1.33273\n",
      "trainer/ZF CHI2 Term                   34.0335\n",
      "trainer/Policy Loss                  -911.286\n",
      "trainer/Bias Loss                      54.7017\n",
      "trainer/Bias Value                     11.9399\n",
      "trainer/Policy Grad Norm              392.781\n",
      "trainer/Policy Param Norm              35.6946\n",
      "trainer/Zf1 Grad Norm                2240.1\n",
      "trainer/Zf1 Param Norm                116.524\n",
      "trainer/Zf2 Grad Norm                2087.75\n",
      "trainer/Zf2 Param Norm                114.27\n",
      "trainer/Z Expert Predictions Mean    1050.57\n",
      "trainer/Z Expert Predictions Std       91.0294\n",
      "trainer/Z Expert Predictions Max     1219.98\n",
      "trainer/Z Expert Predictions Min      529.313\n",
      "trainer/Z Policy Predictions Mean     903.663\n",
      "trainer/Z Policy Predictions Std      304.689\n",
      "trainer/Z Policy Predictions Max     1218.41\n",
      "trainer/Z Policy Predictions Min     -104.097\n",
      "trainer/Z Expert Targets Mean        1038.51\n",
      "trainer/Z Expert Targets Std           92.3127\n",
      "trainer/Z Expert Targets Max         1196.75\n",
      "trainer/Z Expert Targets Min          510.841\n",
      "trainer/Z Policy Targets Mean         904.996\n",
      "trainer/Z Policy Targets Std          302.783\n",
      "trainer/Z Policy Targets Max         1219.33\n",
      "trainer/Z Policy Targets Min         -110.03\n",
      "trainer/Log Pis Mean                   31.635\n",
      "trainer/Log Pis Std                     8.64672\n",
      "trainer/Policy mu Mean                  1.32731\n",
      "trainer/Policy mu Std                   2.76916\n",
      "trainer/Policy log std Mean            -3.55784\n",
      "trainer/Policy log std Std              1.56012\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        270924\n",
      "exploration/num paths total          1038\n",
      "evaluation/num steps total              2.07512e+06\n",
      "evaluation/num paths total           2655\n",
      "evaluation/path length Mean           945.1\n",
      "evaluation/path length Std            164.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            451\n",
      "evaluation/Rewards Mean                 5.14198\n",
      "evaluation/Rewards Std                  1.34134\n",
      "evaluation/Rewards Max                  7.18144\n",
      "evaluation/Rewards Min                  0.103499\n",
      "evaluation/Returns Mean              4859.68\n",
      "evaluation/Returns Std                931.827\n",
      "evaluation/Returns Max               5200.81\n",
      "evaluation/Returns Min               2064.52\n",
      "evaluation/Estimation Bias Mean      1009.13\n",
      "evaluation/Estimation Bias Std        231.116\n",
      "evaluation/EB/Q_True Mean              51.822\n",
      "evaluation/EB/Q_True Std              155.196\n",
      "evaluation/EB/Q_Pred Mean            1060.95\n",
      "evaluation/EB/Q_Pred Std              129.681\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4859.68\n",
      "evaluation/Actions Mean                 0.496379\n",
      "evaluation/Actions Std                  0.652946\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.22467\n",
      "time/backward_zf1 (s)                   2.44636\n",
      "time/backward_zf2 (s)                   2.3419\n",
      "time/data sampling (s)                  0.372606\n",
      "time/data storing (s)                   0.016192\n",
      "time/evaluation sampling (s)            1.4542\n",
      "time/exploration sampling (s)           0.215872\n",
      "time/logging (s)                        0.0116325\n",
      "time/preback_alpha (s)                  0.678762\n",
      "time/preback_policy (s)                 1.28537\n",
      "time/preback_start (s)                  0.144903\n",
      "time/preback_zf (s)                     5.51303\n",
      "time/saving (s)                         0.0071426\n",
      "time/training (s)                       2.54246\n",
      "time/epoch (s)                         19.2551\n",
      "time/total (s)                       4445.25\n",
      "Epoch                                 264\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:06:42.138283 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 265 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 276000\n",
      "trainer/ZF1 Loss                       31.4471\n",
      "trainer/ZF2 Loss                       54.0744\n",
      "trainer/ZF Expert Reward               10.0029\n",
      "trainer/ZF Policy Reward               -1.48203\n",
      "trainer/ZF CHI2 Term                   54.5489\n",
      "trainer/Policy Loss                  -909.963\n",
      "trainer/Bias Loss                     137.952\n",
      "trainer/Bias Value                     11.9464\n",
      "trainer/Policy Grad Norm              426.855\n",
      "trainer/Policy Param Norm              35.7184\n",
      "trainer/Zf1 Grad Norm                2673.45\n",
      "trainer/Zf1 Param Norm                116.681\n",
      "trainer/Zf2 Grad Norm                5358.38\n",
      "trainer/Zf2 Param Norm                114.422\n",
      "trainer/Z Expert Predictions Mean    1045.27\n",
      "trainer/Z Expert Predictions Std       92.2347\n",
      "trainer/Z Expert Predictions Max     1200.35\n",
      "trainer/Z Expert Predictions Min      596.588\n",
      "trainer/Z Policy Predictions Mean     902.603\n",
      "trainer/Z Policy Predictions Std      284.599\n",
      "trainer/Z Policy Predictions Max     1187.68\n",
      "trainer/Z Policy Predictions Min     -102.387\n",
      "trainer/Z Expert Targets Mean        1035.27\n",
      "trainer/Z Expert Targets Std           93.5683\n",
      "trainer/Z Expert Targets Max         1176.66\n",
      "trainer/Z Expert Targets Min          576.466\n",
      "trainer/Z Policy Targets Mean         904.085\n",
      "trainer/Z Policy Targets Std          283.611\n",
      "trainer/Z Policy Targets Max         1172.11\n",
      "trainer/Z Policy Targets Min          -82.7997\n",
      "trainer/Log Pis Mean                   30.3195\n",
      "trainer/Log Pis Std                     7.55804\n",
      "trainer/Policy mu Mean                  1.30655\n",
      "trainer/Policy mu Std                   2.58462\n",
      "trainer/Policy log std Mean            -3.52238\n",
      "trainer/Policy log std Std              1.40046\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        270924\n",
      "exploration/num paths total          1038\n",
      "evaluation/num steps total              2.08499e+06\n",
      "evaluation/num paths total           2665\n",
      "evaluation/path length Mean           987.7\n",
      "evaluation/path length Std             36.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            877\n",
      "evaluation/Rewards Mean                 5.13423\n",
      "evaluation/Rewards Std                  1.30541\n",
      "evaluation/Rewards Max                  7.06188\n",
      "evaluation/Rewards Min                  0.105841\n",
      "evaluation/Returns Mean              5071.08\n",
      "evaluation/Returns Std                200.821\n",
      "evaluation/Returns Max               5165.74\n",
      "evaluation/Returns Min               4473.51\n",
      "evaluation/Estimation Bias Mean       968.907\n",
      "evaluation/Estimation Bias Std        254.403\n",
      "evaluation/EB/Q_True Mean              49.3359\n",
      "evaluation/EB/Q_True Std              151.381\n",
      "evaluation/EB/Q_Pred Mean            1018.24\n",
      "evaluation/EB/Q_Pred Std              181.349\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5071.08\n",
      "evaluation/Actions Mean                 0.492338\n",
      "evaluation/Actions Std                  0.654955\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.39692\n",
      "time/backward_zf1 (s)                   2.63839\n",
      "time/backward_zf2 (s)                   2.49139\n",
      "time/data sampling (s)                  0.415872\n",
      "time/data storing (s)                   0.0175477\n",
      "time/evaluation sampling (s)            1.46241\n",
      "time/exploration sampling (s)           0.219429\n",
      "time/logging (s)                        0.0121171\n",
      "time/preback_alpha (s)                  0.71753\n",
      "time/preback_policy (s)                 1.33551\n",
      "time/preback_start (s)                  0.152494\n",
      "time/preback_zf (s)                     5.59803\n",
      "time/saving (s)                         0.00542766\n",
      "time/training (s)                       2.6136\n",
      "time/epoch (s)                         20.0767\n",
      "time/total (s)                       4465.35\n",
      "Epoch                                 265\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:07:00.933735 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 266 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 277000\n",
      "trainer/ZF1 Loss                       23.9975\n",
      "trainer/ZF2 Loss                       21.2462\n",
      "trainer/ZF Expert Reward               18.2513\n",
      "trainer/ZF Policy Reward                3.52887\n",
      "trainer/ZF CHI2 Term                   37.652\n",
      "trainer/Policy Loss                  -937.597\n",
      "trainer/Bias Loss                      99.3231\n",
      "trainer/Bias Value                     11.9527\n",
      "trainer/Policy Grad Norm              348.264\n",
      "trainer/Policy Param Norm              35.743\n",
      "trainer/Zf1 Grad Norm                2130.27\n",
      "trainer/Zf1 Param Norm                116.853\n",
      "trainer/Zf2 Grad Norm                2045.58\n",
      "trainer/Zf2 Param Norm                114.577\n",
      "trainer/Z Expert Predictions Mean    1042.61\n",
      "trainer/Z Expert Predictions Std       99.5312\n",
      "trainer/Z Expert Predictions Max     1196.47\n",
      "trainer/Z Expert Predictions Min      569.731\n",
      "trainer/Z Policy Predictions Mean     935.902\n",
      "trainer/Z Policy Predictions Std      244.555\n",
      "trainer/Z Policy Predictions Max     1190.16\n",
      "trainer/Z Policy Predictions Min      -41.1758\n",
      "trainer/Z Expert Targets Mean        1024.36\n",
      "trainer/Z Expert Targets Std          104.215\n",
      "trainer/Z Expert Targets Max         1187.56\n",
      "trainer/Z Expert Targets Min          488.581\n",
      "trainer/Z Policy Targets Mean         932.373\n",
      "trainer/Z Policy Targets Std          240.1\n",
      "trainer/Z Policy Targets Max         1182.48\n",
      "trainer/Z Policy Targets Min          -46.5948\n",
      "trainer/Log Pis Mean                   30.7629\n",
      "trainer/Log Pis Std                     6.8825\n",
      "trainer/Policy mu Mean                  1.42337\n",
      "trainer/Policy mu Std                   2.33776\n",
      "trainer/Policy log std Mean            -3.62669\n",
      "trainer/Policy log std Std              1.41865\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        272924\n",
      "exploration/num paths total          1040\n",
      "evaluation/num steps total              2.09397e+06\n",
      "evaluation/num paths total           2675\n",
      "evaluation/path length Mean           897.4\n",
      "evaluation/path length Std            208.069\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            410\n",
      "evaluation/Rewards Mean                 5.09553\n",
      "evaluation/Rewards Std                  1.35168\n",
      "evaluation/Rewards Max                  7.27527\n",
      "evaluation/Rewards Min                  0.136309\n",
      "evaluation/Returns Mean              4572.73\n",
      "evaluation/Returns Std               1197.23\n",
      "evaluation/Returns Max               5201.43\n",
      "evaluation/Returns Min               1731.85\n",
      "evaluation/Estimation Bias Mean       964.814\n",
      "evaluation/Estimation Bias Std        251.032\n",
      "evaluation/EB/Q_True Mean              54.3432\n",
      "evaluation/EB/Q_True Std              158.019\n",
      "evaluation/EB/Q_Pred Mean            1019.16\n",
      "evaluation/EB/Q_Pred Std              153.212\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4572.73\n",
      "evaluation/Actions Mean                 0.500396\n",
      "evaluation/Actions Std                  0.647045\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.1761\n",
      "time/backward_zf1 (s)                   2.38495\n",
      "time/backward_zf2 (s)                   2.29081\n",
      "time/data sampling (s)                  0.342946\n",
      "time/data storing (s)                   0.0160316\n",
      "time/evaluation sampling (s)            1.51123\n",
      "time/exploration sampling (s)           0.214944\n",
      "time/logging (s)                        0.0108608\n",
      "time/preback_alpha (s)                  0.64401\n",
      "time/preback_policy (s)                 1.20607\n",
      "time/preback_start (s)                  0.13838\n",
      "time/preback_zf (s)                     5.31132\n",
      "time/saving (s)                         0.0054774\n",
      "time/training (s)                       2.46389\n",
      "time/epoch (s)                         18.717\n",
      "time/total (s)                       4484.09\n",
      "Epoch                                 266\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:07:19.374449 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 267 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 278000\n",
      "trainer/ZF1 Loss                       29.9241\n",
      "trainer/ZF2 Loss                       35.0829\n",
      "trainer/ZF Expert Reward               14.4098\n",
      "trainer/ZF Policy Reward                1.13364\n",
      "trainer/ZF CHI2 Term                   46.093\n",
      "trainer/Policy Loss                  -909.293\n",
      "trainer/Bias Loss                      61.4889\n",
      "trainer/Bias Value                     11.9591\n",
      "trainer/Policy Grad Norm              668.81\n",
      "trainer/Policy Param Norm              35.7696\n",
      "trainer/Zf1 Grad Norm                1643.2\n",
      "trainer/Zf1 Param Norm                116.985\n",
      "trainer/Zf2 Grad Norm                2910.57\n",
      "trainer/Zf2 Param Norm                114.712\n",
      "trainer/Z Expert Predictions Mean    1040.36\n",
      "trainer/Z Expert Predictions Std       87.8503\n",
      "trainer/Z Expert Predictions Max     1193.98\n",
      "trainer/Z Expert Predictions Min      723.376\n",
      "trainer/Z Policy Predictions Mean     902.062\n",
      "trainer/Z Policy Predictions Std      287.386\n",
      "trainer/Z Policy Predictions Max     1174.99\n",
      "trainer/Z Policy Predictions Min     -128.55\n",
      "trainer/Z Expert Targets Mean        1025.95\n",
      "trainer/Z Expert Targets Std           89.2535\n",
      "trainer/Z Expert Targets Max         1185.68\n",
      "trainer/Z Expert Targets Min          711.678\n",
      "trainer/Z Policy Targets Mean         900.929\n",
      "trainer/Z Policy Targets Std          287.735\n",
      "trainer/Z Policy Targets Max         1171.66\n",
      "trainer/Z Policy Targets Min         -115.448\n",
      "trainer/Log Pis Mean                   31.3311\n",
      "trainer/Log Pis Std                     5.85297\n",
      "trainer/Policy mu Mean                  1.45123\n",
      "trainer/Policy mu Std                   2.427\n",
      "trainer/Policy log std Mean            -3.59322\n",
      "trainer/Policy log std Std              1.50335\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        272924\n",
      "exploration/num paths total          1040\n",
      "evaluation/num steps total              2.10342e+06\n",
      "evaluation/num paths total           2685\n",
      "evaluation/path length Mean           945.2\n",
      "evaluation/path length Std            152.466\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            489\n",
      "evaluation/Rewards Mean                 5.07197\n",
      "evaluation/Rewards Std                  1.31837\n",
      "evaluation/Rewards Max                  7.09022\n",
      "evaluation/Rewards Min                  0.114438\n",
      "evaluation/Returns Mean              4794.03\n",
      "evaluation/Returns Std                867.741\n",
      "evaluation/Returns Max               5145.84\n",
      "evaluation/Returns Min               2201.72\n",
      "evaluation/Estimation Bias Mean       937.215\n",
      "evaluation/Estimation Bias Std        262.278\n",
      "evaluation/EB/Q_True Mean              51.2946\n",
      "evaluation/EB/Q_True Std              153.573\n",
      "evaluation/EB/Q_Pred Mean             988.509\n",
      "evaluation/EB/Q_Pred Std              192.912\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4794.03\n",
      "evaluation/Actions Mean                 0.494397\n",
      "evaluation/Actions Std                  0.655003\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.09615\n",
      "time/backward_zf1 (s)                   2.27234\n",
      "time/backward_zf2 (s)                   2.16359\n",
      "time/data sampling (s)                  0.351192\n",
      "time/data storing (s)                   0.0174896\n",
      "time/evaluation sampling (s)            1.42232\n",
      "time/exploration sampling (s)           0.218172\n",
      "time/logging (s)                        0.0117355\n",
      "time/preback_alpha (s)                  0.646658\n",
      "time/preback_policy (s)                 1.19008\n",
      "time/preback_start (s)                  0.138946\n",
      "time/preback_zf (s)                     5.33675\n",
      "time/saving (s)                         0.00585052\n",
      "time/training (s)                       2.49439\n",
      "time/epoch (s)                         18.3657\n",
      "time/total (s)                       4502.47\n",
      "Epoch                                 267\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:07:38.564836 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 268 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 279000\n",
      "trainer/ZF1 Loss                       23.2177\n",
      "trainer/ZF2 Loss                       22.2232\n",
      "trainer/ZF Expert Reward               16.2833\n",
      "trainer/ZF Policy Reward                0.115684\n",
      "trainer/ZF CHI2 Term                   39.1921\n",
      "trainer/Policy Loss                  -920.641\n",
      "trainer/Bias Loss                      86.2177\n",
      "trainer/Bias Value                     11.9655\n",
      "trainer/Policy Grad Norm              576.486\n",
      "trainer/Policy Param Norm              35.7918\n",
      "trainer/Zf1 Grad Norm                2146.9\n",
      "trainer/Zf1 Param Norm                117.126\n",
      "trainer/Zf2 Grad Norm                1891.86\n",
      "trainer/Zf2 Param Norm                114.844\n",
      "trainer/Z Expert Predictions Mean    1024.42\n",
      "trainer/Z Expert Predictions Std       98.0915\n",
      "trainer/Z Expert Predictions Max     1192.35\n",
      "trainer/Z Expert Predictions Min      495.546\n",
      "trainer/Z Policy Predictions Mean     912.065\n",
      "trainer/Z Policy Predictions Std      269.084\n",
      "trainer/Z Policy Predictions Max     1196.1\n",
      "trainer/Z Policy Predictions Min      -22.3401\n",
      "trainer/Z Expert Targets Mean        1008.13\n",
      "trainer/Z Expert Targets Std          101.895\n",
      "trainer/Z Expert Targets Max         1179.74\n",
      "trainer/Z Expert Targets Min          435.564\n",
      "trainer/Z Policy Targets Mean         911.949\n",
      "trainer/Z Policy Targets Std          264.084\n",
      "trainer/Z Policy Targets Max         1190.11\n",
      "trainer/Z Policy Targets Min          -10.6092\n",
      "trainer/Log Pis Mean                   30.4004\n",
      "trainer/Log Pis Std                     6.29718\n",
      "trainer/Policy mu Mean                  1.43688\n",
      "trainer/Policy mu Std                   2.37082\n",
      "trainer/Policy log std Mean            -3.54782\n",
      "trainer/Policy log std Std              1.46176\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        272924\n",
      "exploration/num paths total          1040\n",
      "evaluation/num steps total              2.11342e+06\n",
      "evaluation/num paths total           2695\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.06802\n",
      "evaluation/Rewards Std                  1.29686\n",
      "evaluation/Rewards Max                  7.02573\n",
      "evaluation/Rewards Min                  0.100427\n",
      "evaluation/Returns Mean              5068.02\n",
      "evaluation/Returns Std                 35.0083\n",
      "evaluation/Returns Max               5132.11\n",
      "evaluation/Returns Min               5007.84\n",
      "evaluation/Estimation Bias Mean       968.304\n",
      "evaluation/Estimation Bias Std        190.547\n",
      "evaluation/EB/Q_True Mean              47.7055\n",
      "evaluation/EB/Q_True Std              147.332\n",
      "evaluation/EB/Q_Pred Mean            1016.01\n",
      "evaluation/EB/Q_Pred Std              130.907\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5068.02\n",
      "evaluation/Actions Mean                 0.499674\n",
      "evaluation/Actions Std                  0.654221\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.25263\n",
      "time/backward_zf1 (s)                   2.46118\n",
      "time/backward_zf2 (s)                   2.32463\n",
      "time/data sampling (s)                  0.372436\n",
      "time/data storing (s)                   0.0163248\n",
      "time/evaluation sampling (s)            1.49778\n",
      "time/exploration sampling (s)           0.213383\n",
      "time/logging (s)                        0.0125264\n",
      "time/preback_alpha (s)                  0.668776\n",
      "time/preback_policy (s)                 1.26976\n",
      "time/preback_start (s)                  0.141919\n",
      "time/preback_zf (s)                     5.37294\n",
      "time/saving (s)                         0.00620118\n",
      "time/training (s)                       2.49749\n",
      "time/epoch (s)                         19.108\n",
      "time/total (s)                       4521.6\n",
      "Epoch                                 268\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:07:56.694042 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 269 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 280000\n",
      "trainer/ZF1 Loss                       31.4948\n",
      "trainer/ZF2 Loss                       31.3363\n",
      "trainer/ZF Expert Reward               12.5098\n",
      "trainer/ZF Policy Reward                1.60458\n",
      "trainer/ZF CHI2 Term                   42.6327\n",
      "trainer/Policy Loss                  -885.613\n",
      "trainer/Bias Loss                      70.1942\n",
      "trainer/Bias Value                     11.9721\n",
      "trainer/Policy Grad Norm              485.854\n",
      "trainer/Policy Param Norm              35.8177\n",
      "trainer/Zf1 Grad Norm                1906.13\n",
      "trainer/Zf1 Param Norm                117.285\n",
      "trainer/Zf2 Grad Norm                2088.64\n",
      "trainer/Zf2 Param Norm                114.997\n",
      "trainer/Z Expert Predictions Mean    1024.29\n",
      "trainer/Z Expert Predictions Std       98.2024\n",
      "trainer/Z Expert Predictions Max     1199.99\n",
      "trainer/Z Expert Predictions Min      591.797\n",
      "trainer/Z Policy Predictions Mean     878.939\n",
      "trainer/Z Policy Predictions Std      293.76\n",
      "trainer/Z Policy Predictions Max     1196.4\n",
      "trainer/Z Policy Predictions Min     -123.543\n",
      "trainer/Z Expert Targets Mean        1011.78\n",
      "trainer/Z Expert Targets Std          100.132\n",
      "trainer/Z Expert Targets Max         1189.47\n",
      "trainer/Z Expert Targets Min          562.707\n",
      "trainer/Z Policy Targets Mean         877.334\n",
      "trainer/Z Policy Targets Std          292.273\n",
      "trainer/Z Policy Targets Max         1192.14\n",
      "trainer/Z Policy Targets Min         -126.598\n",
      "trainer/Log Pis Mean                   31.2003\n",
      "trainer/Log Pis Std                     6.75801\n",
      "trainer/Policy mu Mean                  1.33504\n",
      "trainer/Policy mu Std                   2.66063\n",
      "trainer/Policy log std Mean            -3.43754\n",
      "trainer/Policy log std Std              1.45012\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        275924\n",
      "exploration/num paths total          1043\n",
      "evaluation/num steps total              2.12342e+06\n",
      "evaluation/num paths total           2705\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.13568\n",
      "evaluation/Rewards Std                  1.30243\n",
      "evaluation/Rewards Max                  7.15449\n",
      "evaluation/Rewards Min                  0.130161\n",
      "evaluation/Returns Mean              5135.68\n",
      "evaluation/Returns Std                 22.9786\n",
      "evaluation/Returns Max               5172.4\n",
      "evaluation/Returns Min               5079.27\n",
      "evaluation/Estimation Bias Mean       985.215\n",
      "evaluation/Estimation Bias Std        174.811\n",
      "evaluation/EB/Q_True Mean              48.8982\n",
      "evaluation/EB/Q_True Std              151.148\n",
      "evaluation/EB/Q_Pred Mean            1034.11\n",
      "evaluation/EB/Q_Pred Std               95.9816\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5135.68\n",
      "evaluation/Actions Mean                 0.502825\n",
      "evaluation/Actions Std                  0.650184\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.04119\n",
      "time/backward_zf1 (s)                   2.24231\n",
      "time/backward_zf2 (s)                   2.10127\n",
      "time/data sampling (s)                  0.315038\n",
      "time/data storing (s)                   0.0157141\n",
      "time/evaluation sampling (s)            1.48792\n",
      "time/exploration sampling (s)           0.218517\n",
      "time/logging (s)                        0.0122932\n",
      "time/preback_alpha (s)                  0.624007\n",
      "time/preback_policy (s)                 1.17191\n",
      "time/preback_start (s)                  0.136065\n",
      "time/preback_zf (s)                     5.26838\n",
      "time/saving (s)                         0.00556322\n",
      "time/training (s)                       2.41482\n",
      "time/epoch (s)                         18.055\n",
      "time/total (s)                       4539.68\n",
      "Epoch                                 269\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:08:14.280625 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 270 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 281000\n",
      "trainer/ZF1 Loss                       27.8615\n",
      "trainer/ZF2 Loss                       30.3014\n",
      "trainer/ZF Expert Reward               17.4082\n",
      "trainer/ZF Policy Reward                4.30769\n",
      "trainer/ZF CHI2 Term                   42.4891\n",
      "trainer/Policy Loss                  -911.119\n",
      "trainer/Bias Loss                      88.5667\n",
      "trainer/Bias Value                     11.9787\n",
      "trainer/Policy Grad Norm              476.164\n",
      "trainer/Policy Param Norm              35.8463\n",
      "trainer/Zf1 Grad Norm                1838.37\n",
      "trainer/Zf1 Param Norm                117.442\n",
      "trainer/Zf2 Grad Norm                2721.06\n",
      "trainer/Zf2 Param Norm                115.147\n",
      "trainer/Z Expert Predictions Mean    1028.02\n",
      "trainer/Z Expert Predictions Std      110.771\n",
      "trainer/Z Expert Predictions Max     1198.54\n",
      "trainer/Z Expert Predictions Min      562.633\n",
      "trainer/Z Policy Predictions Mean     907.019\n",
      "trainer/Z Policy Predictions Std      290.016\n",
      "trainer/Z Policy Predictions Max     1192.09\n",
      "trainer/Z Policy Predictions Min     -141.905\n",
      "trainer/Z Expert Targets Mean        1010.61\n",
      "trainer/Z Expert Targets Std          112.685\n",
      "trainer/Z Expert Targets Max         1187.32\n",
      "trainer/Z Expert Targets Min          525.294\n",
      "trainer/Z Policy Targets Mean         902.711\n",
      "trainer/Z Policy Targets Std          285.97\n",
      "trainer/Z Policy Targets Max         1188.84\n",
      "trainer/Z Policy Targets Min         -126.531\n",
      "trainer/Log Pis Mean                   30.7183\n",
      "trainer/Log Pis Std                     6.55159\n",
      "trainer/Policy mu Mean                  1.34256\n",
      "trainer/Policy mu Std                   2.39999\n",
      "trainer/Policy log std Mean            -3.55654\n",
      "trainer/Policy log std Std              1.49246\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        275924\n",
      "exploration/num paths total          1043\n",
      "evaluation/num steps total              2.13289e+06\n",
      "evaluation/num paths total           2715\n",
      "evaluation/path length Mean           947\n",
      "evaluation/path length Std            159\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            470\n",
      "evaluation/Rewards Mean                 5.08538\n",
      "evaluation/Rewards Std                  1.33265\n",
      "evaluation/Rewards Max                  7.24225\n",
      "evaluation/Rewards Min                  0.0999204\n",
      "evaluation/Returns Mean              4815.85\n",
      "evaluation/Returns Std                910.393\n",
      "evaluation/Returns Max               5186.9\n",
      "evaluation/Returns Min               2087.18\n",
      "evaluation/Estimation Bias Mean       952.846\n",
      "evaluation/Estimation Bias Std        244.891\n",
      "evaluation/EB/Q_True Mean              51.2411\n",
      "evaluation/EB/Q_True Std              153.523\n",
      "evaluation/EB/Q_Pred Mean            1004.09\n",
      "evaluation/EB/Q_Pred Std              142.598\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4815.85\n",
      "evaluation/Actions Mean                 0.506392\n",
      "evaluation/Actions Std                  0.648596\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97362\n",
      "time/backward_zf1 (s)                   2.13526\n",
      "time/backward_zf2 (s)                   2.04248\n",
      "time/data sampling (s)                  0.301879\n",
      "time/data storing (s)                   0.0145864\n",
      "time/evaluation sampling (s)            1.43518\n",
      "time/exploration sampling (s)           0.203208\n",
      "time/logging (s)                        0.0127041\n",
      "time/preback_alpha (s)                  0.603537\n",
      "time/preback_policy (s)                 1.16008\n",
      "time/preback_start (s)                  0.130131\n",
      "time/preback_zf (s)                     5.18425\n",
      "time/saving (s)                         0.00758615\n",
      "time/training (s)                       2.31033\n",
      "time/epoch (s)                         17.5148\n",
      "time/total (s)                       4557.22\n",
      "Epoch                                 270\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:08:32.276010 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 271 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 282000\n",
      "trainer/ZF1 Loss                      213.065\n",
      "trainer/ZF2 Loss                      220.885\n",
      "trainer/ZF Expert Reward               14.2667\n",
      "trainer/ZF Policy Reward                4.48517\n",
      "trainer/ZF CHI2 Term                  227.064\n",
      "trainer/Policy Loss                  -919.965\n",
      "trainer/Bias Loss                      72.7813\n",
      "trainer/Bias Value                     11.985\n",
      "trainer/Policy Grad Norm              540.248\n",
      "trainer/Policy Param Norm              35.874\n",
      "trainer/Zf1 Grad Norm                3425.05\n",
      "trainer/Zf1 Param Norm                117.601\n",
      "trainer/Zf2 Grad Norm                3863.67\n",
      "trainer/Zf2 Param Norm                115.3\n",
      "trainer/Z Expert Predictions Mean    1030.13\n",
      "trainer/Z Expert Predictions Std       95.4174\n",
      "trainer/Z Expert Predictions Max     1207.39\n",
      "trainer/Z Expert Predictions Min      599.225\n",
      "trainer/Z Policy Predictions Mean     914.877\n",
      "trainer/Z Policy Predictions Std      267.359\n",
      "trainer/Z Policy Predictions Max     1200.51\n",
      "trainer/Z Policy Predictions Min     -181.757\n",
      "trainer/Z Expert Targets Mean        1015.86\n",
      "trainer/Z Expert Targets Std           97.1572\n",
      "trainer/Z Expert Targets Max         1189.31\n",
      "trainer/Z Expert Targets Min          584.758\n",
      "trainer/Z Policy Targets Mean         910.392\n",
      "trainer/Z Policy Targets Std          271.825\n",
      "trainer/Z Policy Targets Max         1188.58\n",
      "trainer/Z Policy Targets Min         -178.039\n",
      "trainer/Log Pis Mean                   30.751\n",
      "trainer/Log Pis Std                     7.05809\n",
      "trainer/Policy mu Mean                  1.38032\n",
      "trainer/Policy mu Std                   2.48456\n",
      "trainer/Policy log std Mean            -3.58339\n",
      "trainer/Policy log std Std              1.46686\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        276924\n",
      "exploration/num paths total          1044\n",
      "evaluation/num steps total              2.142e+06\n",
      "evaluation/num paths total           2725\n",
      "evaluation/path length Mean           911.1\n",
      "evaluation/path length Std            188.998\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            368\n",
      "evaluation/Rewards Mean                 5.02958\n",
      "evaluation/Rewards Std                  1.31846\n",
      "evaluation/Rewards Max                  7.3087\n",
      "evaluation/Rewards Min                  0.139978\n",
      "evaluation/Returns Mean              4582.45\n",
      "evaluation/Returns Std               1039.15\n",
      "evaluation/Returns Max               5110.71\n",
      "evaluation/Returns Min               1594.68\n",
      "evaluation/Estimation Bias Mean       919.812\n",
      "evaluation/Estimation Bias Std        261.915\n",
      "evaluation/EB/Q_True Mean              52.8022\n",
      "evaluation/EB/Q_True Std              154.843\n",
      "evaluation/EB/Q_Pred Mean             972.614\n",
      "evaluation/EB/Q_Pred Std              195.635\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4582.45\n",
      "evaluation/Actions Mean                 0.495935\n",
      "evaluation/Actions Std                  0.660743\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.01132\n",
      "time/backward_zf1 (s)                   2.21161\n",
      "time/backward_zf2 (s)                   2.09966\n",
      "time/data sampling (s)                  0.324088\n",
      "time/data storing (s)                   0.0157221\n",
      "time/evaluation sampling (s)            1.54288\n",
      "time/exploration sampling (s)           0.211354\n",
      "time/logging (s)                        0.0114662\n",
      "time/preback_alpha (s)                  0.61464\n",
      "time/preback_policy (s)                 1.17977\n",
      "time/preback_start (s)                  0.132954\n",
      "time/preback_zf (s)                     5.21829\n",
      "time/saving (s)                         0.00622561\n",
      "time/training (s)                       2.34181\n",
      "time/epoch (s)                         17.9218\n",
      "time/total (s)                       4575.16\n",
      "Epoch                                 271\n",
      "---------------------------------  ---------------\n",
      "2024-06-25 19:08:50.454691 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 272 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 283000\n",
      "trainer/ZF1 Loss                       25.2338\n",
      "trainer/ZF2 Loss                       23.0211\n",
      "trainer/ZF Expert Reward               15.8155\n",
      "trainer/ZF Policy Reward                3.34925\n",
      "trainer/ZF CHI2 Term                   36.8991\n",
      "trainer/Policy Loss                  -894.574\n",
      "trainer/Bias Loss                     106.448\n",
      "trainer/Bias Value                     11.9915\n",
      "trainer/Policy Grad Norm              554.597\n",
      "trainer/Policy Param Norm              35.9005\n",
      "trainer/Zf1 Grad Norm                3391.23\n",
      "trainer/Zf1 Param Norm                117.749\n",
      "trainer/Zf2 Grad Norm                2282.28\n",
      "trainer/Zf2 Param Norm                115.441\n",
      "trainer/Z Expert Predictions Mean    1022.83\n",
      "trainer/Z Expert Predictions Std      110.712\n",
      "trainer/Z Expert Predictions Max     1199.42\n",
      "trainer/Z Expert Predictions Min      111.531\n",
      "trainer/Z Policy Predictions Mean     888.507\n",
      "trainer/Z Policy Predictions Std      285.181\n",
      "trainer/Z Policy Predictions Max     1202.75\n",
      "trainer/Z Policy Predictions Min     -116.284\n",
      "trainer/Z Expert Targets Mean        1007.01\n",
      "trainer/Z Expert Targets Std          116.677\n",
      "trainer/Z Expert Targets Max         1185.83\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         885.157\n",
      "trainer/Z Policy Targets Std          279.893\n",
      "trainer/Z Policy Targets Max         1188.45\n",
      "trainer/Z Policy Targets Min         -112.162\n",
      "trainer/Log Pis Mean                   30.5514\n",
      "trainer/Log Pis Std                     7.4131\n",
      "trainer/Policy mu Mean                  1.40637\n",
      "trainer/Policy mu Std                   2.65734\n",
      "trainer/Policy log std Mean            -3.45072\n",
      "trainer/Policy log std Std              1.47028\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        276924\n",
      "exploration/num paths total          1044\n",
      "evaluation/num steps total              2.152e+06\n",
      "evaluation/num paths total           2735\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.07471\n",
      "evaluation/Rewards Std                  1.3015\n",
      "evaluation/Rewards Max                  7.1297\n",
      "evaluation/Rewards Min                  0.0949825\n",
      "evaluation/Returns Mean              5074.71\n",
      "evaluation/Returns Std                 30.8885\n",
      "evaluation/Returns Max               5124.64\n",
      "evaluation/Returns Min               5040.27\n",
      "evaluation/Estimation Bias Mean       934.459\n",
      "evaluation/Estimation Bias Std        204.708\n",
      "evaluation/EB/Q_True Mean              48.4545\n",
      "evaluation/EB/Q_True Std              149.457\n",
      "evaluation/EB/Q_Pred Mean             982.914\n",
      "evaluation/EB/Q_Pred Std              139.363\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5074.71\n",
      "evaluation/Actions Mean                 0.502771\n",
      "evaluation/Actions Std                  0.655525\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.0882\n",
      "time/backward_zf1 (s)                   2.27685\n",
      "time/backward_zf2 (s)                   2.18469\n",
      "time/data sampling (s)                  0.319434\n",
      "time/data storing (s)                   0.0159733\n",
      "time/evaluation sampling (s)            1.48487\n",
      "time/exploration sampling (s)           0.211261\n",
      "time/logging (s)                        0.0120654\n",
      "time/preback_alpha (s)                  0.613951\n",
      "time/preback_policy (s)                 1.19111\n",
      "time/preback_start (s)                  0.135794\n",
      "time/preback_zf (s)                     5.23355\n",
      "time/saving (s)                         0.0062099\n",
      "time/training (s)                       2.32573\n",
      "time/epoch (s)                         18.0997\n",
      "time/total (s)                       4593.28\n",
      "Epoch                                 272\n",
      "---------------------------------  --------------\n",
      "2024-06-25 19:09:09.237643 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 273 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 284000\n",
      "trainer/ZF1 Loss                       32.0442\n",
      "trainer/ZF2 Loss                       38.7878\n",
      "trainer/ZF Expert Reward               17.865\n",
      "trainer/ZF Policy Reward                3.83952\n",
      "trainer/ZF CHI2 Term                   49.7443\n",
      "trainer/Policy Loss                  -883.582\n",
      "trainer/Bias Loss                     105.556\n",
      "trainer/Bias Value                     11.998\n",
      "trainer/Policy Grad Norm              416.17\n",
      "trainer/Policy Param Norm              35.9237\n",
      "trainer/Zf1 Grad Norm                2631.45\n",
      "trainer/Zf1 Param Norm                117.893\n",
      "trainer/Zf2 Grad Norm                3029.36\n",
      "trainer/Zf2 Param Norm                115.582\n",
      "trainer/Z Expert Predictions Mean    1026.93\n",
      "trainer/Z Expert Predictions Std      104.41\n",
      "trainer/Z Expert Predictions Max     1191.69\n",
      "trainer/Z Expert Predictions Min      507.1\n",
      "trainer/Z Policy Predictions Mean     878.248\n",
      "trainer/Z Policy Predictions Std      305.036\n",
      "trainer/Z Policy Predictions Max     1200.06\n",
      "trainer/Z Policy Predictions Min     -152.03\n",
      "trainer/Z Expert Targets Mean        1009.06\n",
      "trainer/Z Expert Targets Std          102.373\n",
      "trainer/Z Expert Targets Max         1179.96\n",
      "trainer/Z Expert Targets Min          507.136\n",
      "trainer/Z Policy Targets Mean         874.409\n",
      "trainer/Z Policy Targets Std          299.496\n",
      "trainer/Z Policy Targets Max         1186.87\n",
      "trainer/Z Policy Targets Min         -133.149\n",
      "trainer/Log Pis Mean                   30.2899\n",
      "trainer/Log Pis Std                     7.16197\n",
      "trainer/Policy mu Mean                  1.36636\n",
      "trainer/Policy mu Std                   2.44948\n",
      "trainer/Policy log std Mean            -3.51973\n",
      "trainer/Policy log std Std              1.47054\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        279924\n",
      "exploration/num paths total          1047\n",
      "evaluation/num steps total              2.16196e+06\n",
      "evaluation/num paths total           2745\n",
      "evaluation/path length Mean           996\n",
      "evaluation/path length Std             12\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            960\n",
      "evaluation/Rewards Mean                 5.06112\n",
      "evaluation/Rewards Std                  1.29764\n",
      "evaluation/Rewards Max                  7.26226\n",
      "evaluation/Rewards Min                  0.127751\n",
      "evaluation/Returns Mean              5040.88\n",
      "evaluation/Returns Std                 55.8634\n",
      "evaluation/Returns Max               5093.19\n",
      "evaluation/Returns Min               4884.63\n",
      "evaluation/Estimation Bias Mean       925.978\n",
      "evaluation/Estimation Bias Std        199.963\n",
      "evaluation/EB/Q_True Mean              48.1225\n",
      "evaluation/EB/Q_True Std              148.304\n",
      "evaluation/EB/Q_Pred Mean             974.1\n",
      "evaluation/EB/Q_Pred Std              122.7\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5040.88\n",
      "evaluation/Actions Mean                 0.50033\n",
      "evaluation/Actions Std                  0.655591\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.1642\n",
      "time/backward_zf1 (s)                   2.387\n",
      "time/backward_zf2 (s)                   2.24888\n",
      "time/data sampling (s)                  0.352184\n",
      "time/data storing (s)                   0.0163587\n",
      "time/evaluation sampling (s)            1.45198\n",
      "time/exploration sampling (s)           0.220868\n",
      "time/logging (s)                        0.0121102\n",
      "time/preback_alpha (s)                  0.659601\n",
      "time/preback_policy (s)                 1.20017\n",
      "time/preback_start (s)                  0.142254\n",
      "time/preback_zf (s)                     5.32822\n",
      "time/saving (s)                         0.00575589\n",
      "time/training (s)                       2.51797\n",
      "time/epoch (s)                         18.7075\n",
      "time/total (s)                       4612.01\n",
      "Epoch                                 273\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:09:28.621828 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 274 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 285000\n",
      "trainer/ZF1 Loss                      194.062\n",
      "trainer/ZF2 Loss                      191.108\n",
      "trainer/ZF Expert Reward               16.534\n",
      "trainer/ZF Policy Reward                9.79621\n",
      "trainer/ZF CHI2 Term                  199.633\n",
      "trainer/Policy Loss                  -888.602\n",
      "trainer/Bias Loss                     100.798\n",
      "trainer/Bias Value                     12.0043\n",
      "trainer/Policy Grad Norm              537.791\n",
      "trainer/Policy Param Norm              35.9465\n",
      "trainer/Zf1 Grad Norm                3326.71\n",
      "trainer/Zf1 Param Norm                118.033\n",
      "trainer/Zf2 Grad Norm                3275.15\n",
      "trainer/Zf2 Param Norm                115.728\n",
      "trainer/Z Expert Predictions Mean    1008.28\n",
      "trainer/Z Expert Predictions Std      113.746\n",
      "trainer/Z Expert Predictions Max     1195.27\n",
      "trainer/Z Expert Predictions Min      533.381\n",
      "trainer/Z Policy Predictions Mean     885.964\n",
      "trainer/Z Policy Predictions Std      288.909\n",
      "trainer/Z Policy Predictions Max     1184.91\n",
      "trainer/Z Policy Predictions Min      -90.5346\n",
      "trainer/Z Expert Targets Mean         991.744\n",
      "trainer/Z Expert Targets Std          118.292\n",
      "trainer/Z Expert Targets Max         1180.06\n",
      "trainer/Z Expert Targets Min          497.992\n",
      "trainer/Z Policy Targets Mean         876.168\n",
      "trainer/Z Policy Targets Std          290.904\n",
      "trainer/Z Policy Targets Max         1177.5\n",
      "trainer/Z Policy Targets Min         -103.177\n",
      "trainer/Log Pis Mean                   30.9599\n",
      "trainer/Log Pis Std                     6.83891\n",
      "trainer/Policy mu Mean                  1.35871\n",
      "trainer/Policy mu Std                   2.49623\n",
      "trainer/Policy log std Mean            -3.54526\n",
      "trainer/Policy log std Std              1.49324\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        280924\n",
      "exploration/num paths total          1048\n",
      "evaluation/num steps total              2.17196e+06\n",
      "evaluation/num paths total           2755\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10434\n",
      "evaluation/Rewards Std                  1.31685\n",
      "evaluation/Rewards Max                  7.27945\n",
      "evaluation/Rewards Min                  0.0891608\n",
      "evaluation/Returns Mean              5104.34\n",
      "evaluation/Returns Std                 54.8681\n",
      "evaluation/Returns Max               5210.69\n",
      "evaluation/Returns Min               5031.79\n",
      "evaluation/Estimation Bias Mean       953.91\n",
      "evaluation/Estimation Bias Std        166.191\n",
      "evaluation/EB/Q_True Mean              48.1796\n",
      "evaluation/EB/Q_True Std              148.818\n",
      "evaluation/EB/Q_Pred Mean            1002.09\n",
      "evaluation/EB/Q_Pred Std               71.8065\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5104.34\n",
      "evaluation/Actions Mean                 0.505089\n",
      "evaluation/Actions Std                  0.650001\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.28081\n",
      "time/backward_zf1 (s)                   2.50715\n",
      "time/backward_zf2 (s)                   2.36202\n",
      "time/data sampling (s)                  0.376004\n",
      "time/data storing (s)                   0.0167037\n",
      "time/evaluation sampling (s)            1.44679\n",
      "time/exploration sampling (s)           0.224236\n",
      "time/logging (s)                        0.0123756\n",
      "time/preback_alpha (s)                  0.677447\n",
      "time/preback_policy (s)                 1.26155\n",
      "time/preback_start (s)                  0.14655\n",
      "time/preback_zf (s)                     5.46331\n",
      "time/saving (s)                         0.00561918\n",
      "time/training (s)                       2.52492\n",
      "time/epoch (s)                         19.3055\n",
      "time/total (s)                       4631.34\n",
      "Epoch                                 274\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:09:48.358702 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 275 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 286000\n",
      "trainer/ZF1 Loss                       27.9232\n",
      "trainer/ZF2 Loss                       30.3071\n",
      "trainer/ZF Expert Reward               16.3082\n",
      "trainer/ZF Policy Reward                2.8648\n",
      "trainer/ZF CHI2 Term                   42.8641\n",
      "trainer/Policy Loss                  -913.641\n",
      "trainer/Bias Loss                      97.5585\n",
      "trainer/Bias Value                     12.0107\n",
      "trainer/Policy Grad Norm              488.307\n",
      "trainer/Policy Param Norm              35.9776\n",
      "trainer/Zf1 Grad Norm                2041.82\n",
      "trainer/Zf1 Param Norm                118.187\n",
      "trainer/Zf2 Grad Norm                2326.72\n",
      "trainer/Zf2 Param Norm                115.873\n",
      "trainer/Z Expert Predictions Mean    1012.89\n",
      "trainer/Z Expert Predictions Std       98.7754\n",
      "trainer/Z Expert Predictions Max     1199\n",
      "trainer/Z Expert Predictions Min      596.014\n",
      "trainer/Z Policy Predictions Mean     908.049\n",
      "trainer/Z Policy Predictions Std      263.352\n",
      "trainer/Z Policy Predictions Max     1188.54\n",
      "trainer/Z Policy Predictions Min     -135.738\n",
      "trainer/Z Expert Targets Mean         996.584\n",
      "trainer/Z Expert Targets Std           99.996\n",
      "trainer/Z Expert Targets Max         1188.59\n",
      "trainer/Z Expert Targets Min          581.737\n",
      "trainer/Z Policy Targets Mean         905.184\n",
      "trainer/Z Policy Targets Std          257.17\n",
      "trainer/Z Policy Targets Max         1176.19\n",
      "trainer/Z Policy Targets Min         -138.819\n",
      "trainer/Log Pis Mean                   30.548\n",
      "trainer/Log Pis Std                     6.25252\n",
      "trainer/Policy mu Mean                  1.38121\n",
      "trainer/Policy mu Std                   2.47115\n",
      "trainer/Policy log std Mean            -3.45559\n",
      "trainer/Policy log std Std              1.47068\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        280924\n",
      "exploration/num paths total          1048\n",
      "evaluation/num steps total              2.18196e+06\n",
      "evaluation/num paths total           2765\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.02288\n",
      "evaluation/Rewards Std                  1.29038\n",
      "evaluation/Rewards Max                  6.99645\n",
      "evaluation/Rewards Min                  0.0821266\n",
      "evaluation/Returns Mean              5022.88\n",
      "evaluation/Returns Std                 36.8025\n",
      "evaluation/Returns Max               5053.21\n",
      "evaluation/Returns Min               4919.88\n",
      "evaluation/Estimation Bias Mean       907.707\n",
      "evaluation/Estimation Bias Std        177.583\n",
      "evaluation/EB/Q_True Mean              46.4206\n",
      "evaluation/EB/Q_True Std              143.138\n",
      "evaluation/EB/Q_Pred Mean             954.127\n",
      "evaluation/EB/Q_Pred Std              112.574\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5022.88\n",
      "evaluation/Actions Mean                 0.507352\n",
      "evaluation/Actions Std                  0.654152\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.27997\n",
      "time/backward_zf1 (s)                   2.55183\n",
      "time/backward_zf2 (s)                   2.41307\n",
      "time/data sampling (s)                  0.381842\n",
      "time/data storing (s)                   0.0183362\n",
      "time/evaluation sampling (s)            1.52314\n",
      "time/exploration sampling (s)           0.222893\n",
      "time/logging (s)                        0.0127816\n",
      "time/preback_alpha (s)                  0.688198\n",
      "time/preback_policy (s)                 1.31851\n",
      "time/preback_start (s)                  0.151547\n",
      "time/preback_zf (s)                     5.54759\n",
      "time/saving (s)                         0.00742256\n",
      "time/training (s)                       2.53254\n",
      "time/epoch (s)                         19.6497\n",
      "time/total (s)                       4651.01\n",
      "Epoch                                 275\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:10:07.883817 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 276 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 287000\n",
      "trainer/ZF1 Loss                       16.6929\n",
      "trainer/ZF2 Loss                       13.2811\n",
      "trainer/ZF Expert Reward               16.9083\n",
      "trainer/ZF Policy Reward                2.13147\n",
      "trainer/ZF CHI2 Term                   30.0697\n",
      "trainer/Policy Loss                  -905.132\n",
      "trainer/Bias Loss                      73.8605\n",
      "trainer/Bias Value                     12.0173\n",
      "trainer/Policy Grad Norm              375.968\n",
      "trainer/Policy Param Norm              36.0012\n",
      "trainer/Zf1 Grad Norm                2245.56\n",
      "trainer/Zf1 Param Norm                118.344\n",
      "trainer/Zf2 Grad Norm                1744.2\n",
      "trainer/Zf2 Param Norm                116.021\n",
      "trainer/Z Expert Predictions Mean    1013.68\n",
      "trainer/Z Expert Predictions Std       90.6823\n",
      "trainer/Z Expert Predictions Max     1192.18\n",
      "trainer/Z Expert Predictions Min      600.451\n",
      "trainer/Z Policy Predictions Mean     902.357\n",
      "trainer/Z Policy Predictions Std      241.988\n",
      "trainer/Z Policy Predictions Max     1182.59\n",
      "trainer/Z Policy Predictions Min     -112.112\n",
      "trainer/Z Expert Targets Mean         996.771\n",
      "trainer/Z Expert Targets Std           91.1173\n",
      "trainer/Z Expert Targets Max         1185.06\n",
      "trainer/Z Expert Targets Min          577.265\n",
      "trainer/Z Policy Targets Mean         900.226\n",
      "trainer/Z Policy Targets Std          238.224\n",
      "trainer/Z Policy Targets Max         1180.88\n",
      "trainer/Z Policy Targets Min         -107.588\n",
      "trainer/Log Pis Mean                   30.5955\n",
      "trainer/Log Pis Std                     6.21694\n",
      "trainer/Policy mu Mean                  1.38476\n",
      "trainer/Policy mu Std                   2.42173\n",
      "trainer/Policy log std Mean            -3.61647\n",
      "trainer/Policy log std Std              1.5004\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        282924\n",
      "exploration/num paths total          1050\n",
      "evaluation/num steps total              2.19171e+06\n",
      "evaluation/num paths total           2775\n",
      "evaluation/path length Mean           974.9\n",
      "evaluation/path length Std             75.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            749\n",
      "evaluation/Rewards Mean                 5.13399\n",
      "evaluation/Rewards Std                  1.34148\n",
      "evaluation/Rewards Max                  7.6559\n",
      "evaluation/Rewards Min                  0.073321\n",
      "evaluation/Returns Mean              5005.13\n",
      "evaluation/Returns Std                436.893\n",
      "evaluation/Returns Max               5239.76\n",
      "evaluation/Returns Min               3706.52\n",
      "evaluation/Estimation Bias Mean       935.668\n",
      "evaluation/Estimation Bias Std        248.908\n",
      "evaluation/EB/Q_True Mean              50.3548\n",
      "evaluation/EB/Q_True Std              153.477\n",
      "evaluation/EB/Q_Pred Mean             986.023\n",
      "evaluation/EB/Q_Pred Std              148.194\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5005.13\n",
      "evaluation/Actions Mean                 0.501601\n",
      "evaluation/Actions Std                  0.646135\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.29327\n",
      "time/backward_zf1 (s)                   2.52629\n",
      "time/backward_zf2 (s)                   2.38563\n",
      "time/data sampling (s)                  0.356481\n",
      "time/data storing (s)                   0.0173856\n",
      "time/evaluation sampling (s)            1.49384\n",
      "time/exploration sampling (s)           0.221147\n",
      "time/logging (s)                        0.0135813\n",
      "time/preback_alpha (s)                  0.670495\n",
      "time/preback_policy (s)                 1.29504\n",
      "time/preback_start (s)                  0.144581\n",
      "time/preback_zf (s)                     5.49362\n",
      "time/saving (s)                         0.00801251\n",
      "time/training (s)                       2.52437\n",
      "time/epoch (s)                         19.4437\n",
      "time/total (s)                       4670.48\n",
      "Epoch                                 276\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:10:26.986900 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 277 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 288000\n",
      "trainer/ZF1 Loss                       23.4724\n",
      "trainer/ZF2 Loss                       17.9908\n",
      "trainer/ZF Expert Reward               16.8551\n",
      "trainer/ZF Policy Reward                2.02474\n",
      "trainer/ZF CHI2 Term                   35.862\n",
      "trainer/Policy Loss                  -861.096\n",
      "trainer/Bias Loss                      70.9171\n",
      "trainer/Bias Value                     12.024\n",
      "trainer/Policy Grad Norm              660.116\n",
      "trainer/Policy Param Norm              36.0249\n",
      "trainer/Zf1 Grad Norm                2361.11\n",
      "trainer/Zf1 Param Norm                118.492\n",
      "trainer/Zf2 Grad Norm                2186.73\n",
      "trainer/Zf2 Param Norm                116.165\n",
      "trainer/Z Expert Predictions Mean     995.986\n",
      "trainer/Z Expert Predictions Std      112.73\n",
      "trainer/Z Expert Predictions Max     1203.74\n",
      "trainer/Z Expert Predictions Min      451.615\n",
      "trainer/Z Policy Predictions Mean     852.336\n",
      "trainer/Z Policy Predictions Std      293.19\n",
      "trainer/Z Policy Predictions Max     1182.23\n",
      "trainer/Z Policy Predictions Min     -126.351\n",
      "trainer/Z Expert Targets Mean         979.131\n",
      "trainer/Z Expert Targets Std          114.629\n",
      "trainer/Z Expert Targets Max         1184.58\n",
      "trainer/Z Expert Targets Min          429.852\n",
      "trainer/Z Policy Targets Mean         850.311\n",
      "trainer/Z Policy Targets Std          289.428\n",
      "trainer/Z Policy Targets Max         1174.64\n",
      "trainer/Z Policy Targets Min         -114.277\n",
      "trainer/Log Pis Mean                   30.0007\n",
      "trainer/Log Pis Std                     6.08264\n",
      "trainer/Policy mu Mean                  1.33863\n",
      "trainer/Policy mu Std                   2.45045\n",
      "trainer/Policy log std Mean            -3.54501\n",
      "trainer/Policy log std Std              1.47617\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        282924\n",
      "exploration/num paths total          1050\n",
      "evaluation/num steps total              2.20171e+06\n",
      "evaluation/num paths total           2785\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.10967\n",
      "evaluation/Rewards Std                  1.30159\n",
      "evaluation/Rewards Max                  7.31679\n",
      "evaluation/Rewards Min                  0.123865\n",
      "evaluation/Returns Mean              5109.67\n",
      "evaluation/Returns Std                 30.0895\n",
      "evaluation/Returns Max               5158.42\n",
      "evaluation/Returns Min               5060.69\n",
      "evaluation/Estimation Bias Mean       920.609\n",
      "evaluation/Estimation Bias Std        204.294\n",
      "evaluation/EB/Q_True Mean              48.1751\n",
      "evaluation/EB/Q_True Std              148.83\n",
      "evaluation/EB/Q_Pred Mean             968.784\n",
      "evaluation/EB/Q_Pred Std              140\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5109.67\n",
      "evaluation/Actions Mean                 0.509362\n",
      "evaluation/Actions Std                  0.658045\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.20095\n",
      "time/backward_zf1 (s)                   2.41411\n",
      "time/backward_zf2 (s)                   2.28387\n",
      "time/data sampling (s)                  0.373721\n",
      "time/data storing (s)                   0.016533\n",
      "time/evaluation sampling (s)            1.40257\n",
      "time/exploration sampling (s)           0.215393\n",
      "time/logging (s)                        0.0122821\n",
      "time/preback_alpha (s)                  0.677124\n",
      "time/preback_policy (s)                 1.23145\n",
      "time/preback_start (s)                  0.144396\n",
      "time/preback_zf (s)                     5.46765\n",
      "time/saving (s)                         0.00585549\n",
      "time/training (s)                       2.5756\n",
      "time/epoch (s)                         19.0215\n",
      "time/total (s)                       4689.52\n",
      "Epoch                                 277\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:10:46.520902 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 278 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 289000\n",
      "trainer/ZF1 Loss                       74.0214\n",
      "trainer/ZF2 Loss                       41.2982\n",
      "trainer/ZF Expert Reward               21.2976\n",
      "trainer/ZF Policy Reward                6.55302\n",
      "trainer/ZF CHI2 Term                   72.7122\n",
      "trainer/Policy Loss                  -897.776\n",
      "trainer/Bias Loss                     264.839\n",
      "trainer/Bias Value                     12.0304\n",
      "trainer/Policy Grad Norm              650.202\n",
      "trainer/Policy Param Norm              36.0465\n",
      "trainer/Zf1 Grad Norm                8963.88\n",
      "trainer/Zf1 Param Norm                118.651\n",
      "trainer/Zf2 Grad Norm                4535.3\n",
      "trainer/Zf2 Param Norm                116.334\n",
      "trainer/Z Expert Predictions Mean     991.515\n",
      "trainer/Z Expert Predictions Std      116.084\n",
      "trainer/Z Expert Predictions Max     1183.9\n",
      "trainer/Z Expert Predictions Min      226.298\n",
      "trainer/Z Policy Predictions Mean     892.357\n",
      "trainer/Z Policy Predictions Std      256.501\n",
      "trainer/Z Policy Predictions Max     1176.92\n",
      "trainer/Z Policy Predictions Min      -81.5693\n",
      "trainer/Z Expert Targets Mean         970.217\n",
      "trainer/Z Expert Targets Std          127.398\n",
      "trainer/Z Expert Targets Max         1170.83\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         885.804\n",
      "trainer/Z Policy Targets Std          251.505\n",
      "trainer/Z Policy Targets Max         1180.31\n",
      "trainer/Z Policy Targets Min          -24.7404\n",
      "trainer/Log Pis Mean                   30.7827\n",
      "trainer/Log Pis Std                     6.14865\n",
      "trainer/Policy mu Mean                  1.42556\n",
      "trainer/Policy mu Std                   2.47467\n",
      "trainer/Policy log std Mean            -3.56517\n",
      "trainer/Policy log std Std              1.50433\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        282924\n",
      "exploration/num paths total          1050\n",
      "evaluation/num steps total              2.21171e+06\n",
      "evaluation/num paths total           2795\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.14181\n",
      "evaluation/Rewards Std                  1.31907\n",
      "evaluation/Rewards Max                  7.32993\n",
      "evaluation/Rewards Min                  0.0904973\n",
      "evaluation/Returns Mean              5141.81\n",
      "evaluation/Returns Std                 60.4555\n",
      "evaluation/Returns Max               5244.88\n",
      "evaluation/Returns Min               5031.71\n",
      "evaluation/Estimation Bias Mean       932.111\n",
      "evaluation/Estimation Bias Std        201.613\n",
      "evaluation/EB/Q_True Mean              47.5058\n",
      "evaluation/EB/Q_True Std              146.648\n",
      "evaluation/EB/Q_Pred Mean             979.617\n",
      "evaluation/EB/Q_Pred Std              139.82\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5141.81\n",
      "evaluation/Actions Mean                 0.505164\n",
      "evaluation/Actions Std                  0.654833\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.3604\n",
      "time/backward_zf1 (s)                   2.54568\n",
      "time/backward_zf2 (s)                   2.3951\n",
      "time/data sampling (s)                  0.339361\n",
      "time/data storing (s)                   0.0181783\n",
      "time/evaluation sampling (s)            1.42623\n",
      "time/exploration sampling (s)           0.223716\n",
      "time/logging (s)                        0.0118477\n",
      "time/preback_alpha (s)                  0.678648\n",
      "time/preback_policy (s)                 1.33785\n",
      "time/preback_start (s)                  0.145754\n",
      "time/preback_zf (s)                     5.47184\n",
      "time/saving (s)                         0.0058067\n",
      "time/training (s)                       2.48872\n",
      "time/epoch (s)                         19.4491\n",
      "time/total (s)                       4709\n",
      "Epoch                                 278\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:11:06.113623 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 279 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 290000\n",
      "trainer/ZF1 Loss                       20.838\n",
      "trainer/ZF2 Loss                       27.4163\n",
      "trainer/ZF Expert Reward               13.1614\n",
      "trainer/ZF Policy Reward               -0.0427769\n",
      "trainer/ZF CHI2 Term                   37.6532\n",
      "trainer/Policy Loss                  -872.736\n",
      "trainer/Bias Loss                      60.842\n",
      "trainer/Bias Value                     12.0369\n",
      "trainer/Policy Grad Norm              522.262\n",
      "trainer/Policy Param Norm              36.0687\n",
      "trainer/Zf1 Grad Norm                2179.31\n",
      "trainer/Zf1 Param Norm                118.803\n",
      "trainer/Zf2 Grad Norm                1962.27\n",
      "trainer/Zf2 Param Norm                116.488\n",
      "trainer/Z Expert Predictions Mean     997.547\n",
      "trainer/Z Expert Predictions Std      109.553\n",
      "trainer/Z Expert Predictions Max     1184.18\n",
      "trainer/Z Expert Predictions Min      438.504\n",
      "trainer/Z Policy Predictions Mean     867.549\n",
      "trainer/Z Policy Predictions Std      288.89\n",
      "trainer/Z Policy Predictions Max     1184.94\n",
      "trainer/Z Policy Predictions Min     -136.103\n",
      "trainer/Z Expert Targets Mean         984.386\n",
      "trainer/Z Expert Targets Std          113.459\n",
      "trainer/Z Expert Targets Max         1178.35\n",
      "trainer/Z Expert Targets Min          419.568\n",
      "trainer/Z Policy Targets Mean         867.592\n",
      "trainer/Z Policy Targets Std          285.936\n",
      "trainer/Z Policy Targets Max         1177.49\n",
      "trainer/Z Policy Targets Min         -115.967\n",
      "trainer/Log Pis Mean                   32.184\n",
      "trainer/Log Pis Std                     8.31882\n",
      "trainer/Policy mu Mean                  1.35136\n",
      "trainer/Policy mu Std                   2.75231\n",
      "trainer/Policy log std Mean            -3.62618\n",
      "trainer/Policy log std Std              1.50091\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        285924\n",
      "exploration/num paths total          1053\n",
      "evaluation/num steps total              2.22171e+06\n",
      "evaluation/num paths total           2805\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2065\n",
      "evaluation/Rewards Std                  1.32921\n",
      "evaluation/Rewards Max                  7.31126\n",
      "evaluation/Rewards Min                  0.115158\n",
      "evaluation/Returns Mean              5206.5\n",
      "evaluation/Returns Std                 46.38\n",
      "evaluation/Returns Max               5248.04\n",
      "evaluation/Returns Min               5080.65\n",
      "evaluation/Estimation Bias Mean       930.852\n",
      "evaluation/Estimation Bias Std        202.483\n",
      "evaluation/EB/Q_True Mean              48.9304\n",
      "evaluation/EB/Q_True Std              150.985\n",
      "evaluation/EB/Q_Pred Mean             979.783\n",
      "evaluation/EB/Q_Pred Std              111.744\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5206.5\n",
      "evaluation/Actions Mean                 0.506588\n",
      "evaluation/Actions Std                  0.651409\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.34251\n",
      "time/backward_zf1 (s)                   2.55963\n",
      "time/backward_zf2 (s)                   2.45521\n",
      "time/data sampling (s)                  0.340465\n",
      "time/data storing (s)                   0.0169189\n",
      "time/evaluation sampling (s)            1.41214\n",
      "time/exploration sampling (s)           0.222612\n",
      "time/logging (s)                        0.0120101\n",
      "time/preback_alpha (s)                  0.685918\n",
      "time/preback_policy (s)                 1.33686\n",
      "time/preback_start (s)                  0.147595\n",
      "time/preback_zf (s)                     5.48131\n",
      "time/saving (s)                         0.0057868\n",
      "time/training (s)                       2.49317\n",
      "time/epoch (s)                         19.5121\n",
      "time/total (s)                       4728.53\n",
      "Epoch                                 279\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:11:25.581411 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 280 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 291000\n",
      "trainer/ZF1 Loss                      142.306\n",
      "trainer/ZF2 Loss                      153.646\n",
      "trainer/ZF Expert Reward               13.3037\n",
      "trainer/ZF Policy Reward               -3.83523\n",
      "trainer/ZF CHI2 Term                  165.426\n",
      "trainer/Policy Loss                  -843.851\n",
      "trainer/Bias Loss                    1320.24\n",
      "trainer/Bias Value                     12.0435\n",
      "trainer/Policy Grad Norm              404.23\n",
      "trainer/Policy Param Norm              36.0922\n",
      "trainer/Zf1 Grad Norm                5995.64\n",
      "trainer/Zf1 Param Norm                118.962\n",
      "trainer/Zf2 Grad Norm                5307.08\n",
      "trainer/Zf2 Param Norm                116.649\n",
      "trainer/Z Expert Predictions Mean     989.943\n",
      "trainer/Z Expert Predictions Std      110.227\n",
      "trainer/Z Expert Predictions Max     1193.3\n",
      "trainer/Z Expert Predictions Min      540.09\n",
      "trainer/Z Policy Predictions Mean     840.591\n",
      "trainer/Z Policy Predictions Std      314.016\n",
      "trainer/Z Policy Predictions Max     1187.54\n",
      "trainer/Z Policy Predictions Min     -173.771\n",
      "trainer/Z Expert Targets Mean         976.639\n",
      "trainer/Z Expert Targets Std          127.561\n",
      "trainer/Z Expert Targets Max         1174.14\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         844.426\n",
      "trainer/Z Policy Targets Std          311.665\n",
      "trainer/Z Policy Targets Max         1178.09\n",
      "trainer/Z Policy Targets Min         -155.638\n",
      "trainer/Log Pis Mean                   31.1151\n",
      "trainer/Log Pis Std                     6.12082\n",
      "trainer/Policy mu Mean                  1.47721\n",
      "trainer/Policy mu Std                   2.49705\n",
      "trainer/Policy log std Mean            -3.42062\n",
      "trainer/Policy log std Std              1.52003\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        285924\n",
      "exploration/num paths total          1053\n",
      "evaluation/num steps total              2.23171e+06\n",
      "evaluation/num paths total           2815\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.16992\n",
      "evaluation/Rewards Std                  1.32295\n",
      "evaluation/Rewards Max                  7.31543\n",
      "evaluation/Rewards Min                  0.110451\n",
      "evaluation/Returns Mean              5169.92\n",
      "evaluation/Returns Std                 29.431\n",
      "evaluation/Returns Max               5210.24\n",
      "evaluation/Returns Min               5122.28\n",
      "evaluation/Estimation Bias Mean       902.212\n",
      "evaluation/Estimation Bias Std        224.323\n",
      "evaluation/EB/Q_True Mean              49.1772\n",
      "evaluation/EB/Q_True Std              151.886\n",
      "evaluation/EB/Q_Pred Mean             951.389\n",
      "evaluation/EB/Q_Pred Std              162.111\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5169.92\n",
      "evaluation/Actions Mean                 0.507764\n",
      "evaluation/Actions Std                  0.651586\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.26052\n",
      "time/backward_zf1 (s)                   2.49759\n",
      "time/backward_zf2 (s)                   2.39914\n",
      "time/data sampling (s)                  0.347483\n",
      "time/data storing (s)                   0.0185555\n",
      "time/evaluation sampling (s)            1.43027\n",
      "time/exploration sampling (s)           0.228229\n",
      "time/logging (s)                        0.0121057\n",
      "time/preback_alpha (s)                  0.683834\n",
      "time/preback_policy (s)                 1.27469\n",
      "time/preback_start (s)                  0.147709\n",
      "time/preback_zf (s)                     5.49604\n",
      "time/saving (s)                         0.00582764\n",
      "time/training (s)                       2.58603\n",
      "time/epoch (s)                         19.388\n",
      "time/total (s)                       4747.94\n",
      "Epoch                                 280\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:11:45.322333 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 281 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 292000\n",
      "trainer/ZF1 Loss                       27.422\n",
      "trainer/ZF2 Loss                       31.3145\n",
      "trainer/ZF Expert Reward               11.2827\n",
      "trainer/ZF Policy Reward               -2.82104\n",
      "trainer/ZF CHI2 Term                   43.784\n",
      "trainer/Policy Loss                  -865.977\n",
      "trainer/Bias Loss                      69.7175\n",
      "trainer/Bias Value                     12.0501\n",
      "trainer/Policy Grad Norm              614.333\n",
      "trainer/Policy Param Norm              36.1185\n",
      "trainer/Zf1 Grad Norm                2685.59\n",
      "trainer/Zf1 Param Norm                119.12\n",
      "trainer/Zf2 Grad Norm                2712.62\n",
      "trainer/Zf2 Param Norm                116.802\n",
      "trainer/Z Expert Predictions Mean    1002.87\n",
      "trainer/Z Expert Predictions Std       99.7429\n",
      "trainer/Z Expert Predictions Max     1186\n",
      "trainer/Z Expert Predictions Min      483.593\n",
      "trainer/Z Policy Predictions Mean     858.618\n",
      "trainer/Z Policy Predictions Std      292.464\n",
      "trainer/Z Policy Predictions Max     1174.43\n",
      "trainer/Z Policy Predictions Min     -143.137\n",
      "trainer/Z Expert Targets Mean         991.588\n",
      "trainer/Z Expert Targets Std          102.749\n",
      "trainer/Z Expert Targets Max         1180.22\n",
      "trainer/Z Expert Targets Min          465.755\n",
      "trainer/Z Policy Targets Mean         861.439\n",
      "trainer/Z Policy Targets Std          291.411\n",
      "trainer/Z Policy Targets Max         1178.76\n",
      "trainer/Z Policy Targets Min         -146.268\n",
      "trainer/Log Pis Mean                   31.19\n",
      "trainer/Log Pis Std                     6.77263\n",
      "trainer/Policy mu Mean                  1.40957\n",
      "trainer/Policy mu Std                   2.42263\n",
      "trainer/Policy log std Mean            -3.52093\n",
      "trainer/Policy log std Std              1.46714\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        286924\n",
      "exploration/num paths total          1054\n",
      "evaluation/num steps total              2.24104e+06\n",
      "evaluation/num paths total           2825\n",
      "evaluation/path length Mean           933.5\n",
      "evaluation/path length Std            199.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            335\n",
      "evaluation/Rewards Mean                 5.12326\n",
      "evaluation/Rewards Std                  1.35019\n",
      "evaluation/Rewards Max                  7.86478\n",
      "evaluation/Rewards Min                  0.0937586\n",
      "evaluation/Returns Mean              4782.57\n",
      "evaluation/Returns Std               1138.01\n",
      "evaluation/Returns Max               5196.25\n",
      "evaluation/Returns Min               1369.91\n",
      "evaluation/Estimation Bias Mean       925.367\n",
      "evaluation/Estimation Bias Std        216.529\n",
      "evaluation/EB/Q_True Mean              52.5428\n",
      "evaluation/EB/Q_True Std              156.203\n",
      "evaluation/EB/Q_Pred Mean             977.91\n",
      "evaluation/EB/Q_Pred Std              144.143\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4782.57\n",
      "evaluation/Actions Mean                 0.505889\n",
      "evaluation/Actions Std                  0.649179\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.31616\n",
      "time/backward_zf1 (s)                   2.57237\n",
      "time/backward_zf2 (s)                   2.4356\n",
      "time/data sampling (s)                  0.375106\n",
      "time/data storing (s)                   0.0171967\n",
      "time/evaluation sampling (s)            1.51819\n",
      "time/exploration sampling (s)           0.223944\n",
      "time/logging (s)                        0.0113467\n",
      "time/preback_alpha (s)                  0.692269\n",
      "time/preback_policy (s)                 1.32971\n",
      "time/preback_start (s)                  0.148353\n",
      "time/preback_zf (s)                     5.51303\n",
      "time/saving (s)                         0.00593189\n",
      "time/training (s)                       2.49677\n",
      "time/epoch (s)                         19.656\n",
      "time/total (s)                       4767.62\n",
      "Epoch                                 281\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:12:03.147517 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 282 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 293000\n",
      "trainer/ZF1 Loss                       33.0043\n",
      "trainer/ZF2 Loss                       34.3327\n",
      "trainer/ZF Expert Reward                8.42548\n",
      "trainer/ZF Policy Reward               -6.68623\n",
      "trainer/ZF CHI2 Term                   49.0826\n",
      "trainer/Policy Loss                  -896.255\n",
      "trainer/Bias Loss                      94.5616\n",
      "trainer/Bias Value                     12.0566\n",
      "trainer/Policy Grad Norm              546.722\n",
      "trainer/Policy Param Norm              36.1414\n",
      "trainer/Zf1 Grad Norm                3865.1\n",
      "trainer/Zf1 Param Norm                119.284\n",
      "trainer/Zf2 Grad Norm                3370.15\n",
      "trainer/Zf2 Param Norm                116.968\n",
      "trainer/Z Expert Predictions Mean     984.477\n",
      "trainer/Z Expert Predictions Std      102.536\n",
      "trainer/Z Expert Predictions Max     1182.72\n",
      "trainer/Z Expert Predictions Min      592.332\n",
      "trainer/Z Policy Predictions Mean     881.802\n",
      "trainer/Z Policy Predictions Std      242.539\n",
      "trainer/Z Policy Predictions Max     1175.34\n",
      "trainer/Z Policy Predictions Min      -79.9218\n",
      "trainer/Z Expert Targets Mean         976.051\n",
      "trainer/Z Expert Targets Std          106.048\n",
      "trainer/Z Expert Targets Max         1179.35\n",
      "trainer/Z Expert Targets Min          590.087\n",
      "trainer/Z Policy Targets Mean         888.488\n",
      "trainer/Z Policy Targets Std          239.909\n",
      "trainer/Z Policy Targets Max         1172.18\n",
      "trainer/Z Policy Targets Min          -84.7375\n",
      "trainer/Log Pis Mean                   30.2383\n",
      "trainer/Log Pis Std                     4.77316\n",
      "trainer/Policy mu Mean                  1.48231\n",
      "trainer/Policy mu Std                   2.25207\n",
      "trainer/Policy log std Mean            -3.57281\n",
      "trainer/Policy log std Std              1.46038\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        286924\n",
      "exploration/num paths total          1054\n",
      "evaluation/num steps total              2.25104e+06\n",
      "evaluation/num paths total           2835\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17432\n",
      "evaluation/Rewards Std                  1.33773\n",
      "evaluation/Rewards Max                  7.25313\n",
      "evaluation/Rewards Min                  0.0801589\n",
      "evaluation/Returns Mean              5174.32\n",
      "evaluation/Returns Std                 26.0479\n",
      "evaluation/Returns Max               5223.01\n",
      "evaluation/Returns Min               5130.56\n",
      "evaluation/Estimation Bias Mean       936.234\n",
      "evaluation/Estimation Bias Std        168.622\n",
      "evaluation/EB/Q_True Mean              49.016\n",
      "evaluation/EB/Q_True Std              151.472\n",
      "evaluation/EB/Q_Pred Mean             985.249\n",
      "evaluation/EB/Q_Pred Std               71.9502\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5174.32\n",
      "evaluation/Actions Mean                 0.505427\n",
      "evaluation/Actions Std                  0.648047\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.96533\n",
      "time/backward_zf1 (s)                   2.13722\n",
      "time/backward_zf2 (s)                   2.05635\n",
      "time/data sampling (s)                  0.278067\n",
      "time/data storing (s)                   0.0163335\n",
      "time/evaluation sampling (s)            1.4924\n",
      "time/exploration sampling (s)           0.208954\n",
      "time/logging (s)                        0.0125834\n",
      "time/preback_alpha (s)                  0.593467\n",
      "time/preback_policy (s)                 1.11884\n",
      "time/preback_start (s)                  0.129669\n",
      "time/preback_zf (s)                     5.27358\n",
      "time/saving (s)                         0.00681805\n",
      "time/training (s)                       2.46606\n",
      "time/epoch (s)                         17.7557\n",
      "time/total (s)                       4785.39\n",
      "Epoch                                 282\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:12:21.440056 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 283 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 294000\n",
      "trainer/ZF1 Loss                       30.6335\n",
      "trainer/ZF2 Loss                       28.7854\n",
      "trainer/ZF Expert Reward               15.0979\n",
      "trainer/ZF Policy Reward               -0.276559\n",
      "trainer/ZF CHI2 Term                   45.3997\n",
      "trainer/Policy Loss                  -844.465\n",
      "trainer/Bias Loss                      76.0047\n",
      "trainer/Bias Value                     12.0633\n",
      "trainer/Policy Grad Norm              455.357\n",
      "trainer/Policy Param Norm              36.1631\n",
      "trainer/Zf1 Grad Norm                1972.83\n",
      "trainer/Zf1 Param Norm                119.437\n",
      "trainer/Zf2 Grad Norm                2279.06\n",
      "trainer/Zf2 Param Norm                117.128\n",
      "trainer/Z Expert Predictions Mean     993.327\n",
      "trainer/Z Expert Predictions Std       92.5706\n",
      "trainer/Z Expert Predictions Max     1187.88\n",
      "trainer/Z Expert Predictions Min      554.821\n",
      "trainer/Z Policy Predictions Mean     834.42\n",
      "trainer/Z Policy Predictions Std      291.873\n",
      "trainer/Z Policy Predictions Max     1176.83\n",
      "trainer/Z Policy Predictions Min     -164.037\n",
      "trainer/Z Expert Targets Mean         978.229\n",
      "trainer/Z Expert Targets Std           93.935\n",
      "trainer/Z Expert Targets Max         1171.78\n",
      "trainer/Z Expert Targets Min          541.015\n",
      "trainer/Z Policy Targets Mean         834.697\n",
      "trainer/Z Policy Targets Std          287.981\n",
      "trainer/Z Policy Targets Max         1171.99\n",
      "trainer/Z Policy Targets Min         -152.848\n",
      "trainer/Log Pis Mean                   31.5816\n",
      "trainer/Log Pis Std                     6.76147\n",
      "trainer/Policy mu Mean                  1.41198\n",
      "trainer/Policy mu Std                   2.52295\n",
      "trainer/Policy log std Mean            -3.54221\n",
      "trainer/Policy log std Std              1.50084\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        289924\n",
      "exploration/num paths total          1057\n",
      "evaluation/num steps total              2.26104e+06\n",
      "evaluation/num paths total           2845\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.22607\n",
      "evaluation/Rewards Std                  1.35655\n",
      "evaluation/Rewards Max                  7.28297\n",
      "evaluation/Rewards Min                  0.0948005\n",
      "evaluation/Returns Mean              5226.07\n",
      "evaluation/Returns Std                 19.3297\n",
      "evaluation/Returns Max               5248.87\n",
      "evaluation/Returns Min               5186.21\n",
      "evaluation/Estimation Bias Mean       950.819\n",
      "evaluation/Estimation Bias Std        168.594\n",
      "evaluation/EB/Q_True Mean              49.4403\n",
      "evaluation/EB/Q_True Std              152.574\n",
      "evaluation/EB/Q_Pred Mean            1000.26\n",
      "evaluation/EB/Q_Pred Std               63.4163\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5226.07\n",
      "evaluation/Actions Mean                 0.510339\n",
      "evaluation/Actions Std                  0.643273\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.11552\n",
      "time/backward_zf1 (s)                   2.30446\n",
      "time/backward_zf2 (s)                   2.2188\n",
      "time/data sampling (s)                  0.312322\n",
      "time/data storing (s)                   0.0151521\n",
      "time/evaluation sampling (s)            1.42613\n",
      "time/exploration sampling (s)           0.210355\n",
      "time/logging (s)                        0.013274\n",
      "time/preback_alpha (s)                  0.624074\n",
      "time/preback_policy (s)                 1.22888\n",
      "time/preback_start (s)                  0.135291\n",
      "time/preback_zf (s)                     5.27476\n",
      "time/saving (s)                         0.00765959\n",
      "time/training (s)                       2.33431\n",
      "time/epoch (s)                         18.221\n",
      "time/total (s)                       4803.63\n",
      "Epoch                                 283\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:12:39.281466 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 284 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 295000\n",
      "trainer/ZF1 Loss                       26.9759\n",
      "trainer/ZF2 Loss                       15.8984\n",
      "trainer/ZF Expert Reward               13.7553\n",
      "trainer/ZF Policy Reward               -1.33332\n",
      "trainer/ZF CHI2 Term                   36.8372\n",
      "trainer/Policy Loss                  -846.01\n",
      "trainer/Bias Loss                      63.4847\n",
      "trainer/Bias Value                     12.0698\n",
      "trainer/Policy Grad Norm              670.828\n",
      "trainer/Policy Param Norm              36.1859\n",
      "trainer/Zf1 Grad Norm                2398.13\n",
      "trainer/Zf1 Param Norm                119.59\n",
      "trainer/Zf2 Grad Norm                2148.26\n",
      "trainer/Zf2 Param Norm                117.288\n",
      "trainer/Z Expert Predictions Mean     984.74\n",
      "trainer/Z Expert Predictions Std       96.7932\n",
      "trainer/Z Expert Predictions Max     1191.15\n",
      "trainer/Z Expert Predictions Min      606.004\n",
      "trainer/Z Policy Predictions Mean     835.033\n",
      "trainer/Z Policy Predictions Std      302.682\n",
      "trainer/Z Policy Predictions Max     1194.83\n",
      "trainer/Z Policy Predictions Min     -130.204\n",
      "trainer/Z Expert Targets Mean         970.984\n",
      "trainer/Z Expert Targets Std           98.0579\n",
      "trainer/Z Expert Targets Max         1177.51\n",
      "trainer/Z Expert Targets Min          569.721\n",
      "trainer/Z Policy Targets Mean         836.367\n",
      "trainer/Z Policy Targets Std          301.379\n",
      "trainer/Z Policy Targets Max         1178.32\n",
      "trainer/Z Policy Targets Min         -129.607\n",
      "trainer/Log Pis Mean                   31.146\n",
      "trainer/Log Pis Std                     6.78488\n",
      "trainer/Policy mu Mean                  1.42783\n",
      "trainer/Policy mu Std                   2.58532\n",
      "trainer/Policy log std Mean            -3.50845\n",
      "trainer/Policy log std Std              1.51749\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        290924\n",
      "exploration/num paths total          1058\n",
      "evaluation/num steps total              2.27104e+06\n",
      "evaluation/num paths total           2855\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.21815\n",
      "evaluation/Rewards Std                  1.34203\n",
      "evaluation/Rewards Max                  7.29367\n",
      "evaluation/Rewards Min                  0.0949744\n",
      "evaluation/Returns Mean              5218.15\n",
      "evaluation/Returns Std                 19.0792\n",
      "evaluation/Returns Max               5256.45\n",
      "evaluation/Returns Min               5187.36\n",
      "evaluation/Estimation Bias Mean       945.539\n",
      "evaluation/Estimation Bias Std        173.719\n",
      "evaluation/EB/Q_True Mean              49.1601\n",
      "evaluation/EB/Q_True Std              151.865\n",
      "evaluation/EB/Q_Pred Mean             994.699\n",
      "evaluation/EB/Q_Pred Std               75.3928\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5218.15\n",
      "evaluation/Actions Mean                 0.505077\n",
      "evaluation/Actions Std                  0.651088\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.00696\n",
      "time/backward_zf1 (s)                   2.20358\n",
      "time/backward_zf2 (s)                   2.10369\n",
      "time/data sampling (s)                  0.301897\n",
      "time/data storing (s)                   0.0165764\n",
      "time/evaluation sampling (s)            1.51873\n",
      "time/exploration sampling (s)           0.214713\n",
      "time/logging (s)                        0.0120398\n",
      "time/preback_alpha (s)                  0.606349\n",
      "time/preback_policy (s)                 1.15105\n",
      "time/preback_start (s)                  0.132195\n",
      "time/preback_zf (s)                     5.17867\n",
      "time/saving (s)                         0.0058834\n",
      "time/training (s)                       2.31396\n",
      "time/epoch (s)                         17.7663\n",
      "time/total (s)                       4821.42\n",
      "Epoch                                 284\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:12:57.180946 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 285 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 296000\n",
      "trainer/ZF1 Loss                       22.0197\n",
      "trainer/ZF2 Loss                       29.5951\n",
      "trainer/ZF Expert Reward               14.6396\n",
      "trainer/ZF Policy Reward               -1.1272\n",
      "trainer/ZF CHI2 Term                   41.8912\n",
      "trainer/Policy Loss                  -892.873\n",
      "trainer/Bias Loss                      92.3775\n",
      "trainer/Bias Value                     12.076\n",
      "trainer/Policy Grad Norm              384.514\n",
      "trainer/Policy Param Norm              36.2074\n",
      "trainer/Zf1 Grad Norm                2778.72\n",
      "trainer/Zf1 Param Norm                119.749\n",
      "trainer/Zf2 Grad Norm                3193.35\n",
      "trainer/Zf2 Param Norm                117.448\n",
      "trainer/Z Expert Predictions Mean     979.433\n",
      "trainer/Z Expert Predictions Std      134.167\n",
      "trainer/Z Expert Predictions Max     1188.05\n",
      "trainer/Z Expert Predictions Min       82.8886\n",
      "trainer/Z Policy Predictions Mean     888.788\n",
      "trainer/Z Policy Predictions Std      234.234\n",
      "trainer/Z Policy Predictions Max     1176.69\n",
      "trainer/Z Policy Predictions Min     -171.691\n",
      "trainer/Z Expert Targets Mean         964.793\n",
      "trainer/Z Expert Targets Std          141.395\n",
      "trainer/Z Expert Targets Max         1178.81\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         889.915\n",
      "trainer/Z Policy Targets Std          230.422\n",
      "trainer/Z Policy Targets Max         1170.86\n",
      "trainer/Z Policy Targets Min         -152.014\n",
      "trainer/Log Pis Mean                   31.7066\n",
      "trainer/Log Pis Std                     6.28228\n",
      "trainer/Policy mu Mean                  1.461\n",
      "trainer/Policy mu Std                   2.50488\n",
      "trainer/Policy log std Mean            -3.47536\n",
      "trainer/Policy log std Std              1.50898\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        290924\n",
      "exploration/num paths total          1058\n",
      "evaluation/num steps total              2.28104e+06\n",
      "evaluation/num paths total           2865\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19981\n",
      "evaluation/Rewards Std                  1.35286\n",
      "evaluation/Rewards Max                  7.24545\n",
      "evaluation/Rewards Min                  0.0873978\n",
      "evaluation/Returns Mean              5199.81\n",
      "evaluation/Returns Std                 36.9395\n",
      "evaluation/Returns Max               5245.04\n",
      "evaluation/Returns Min               5131.18\n",
      "evaluation/Estimation Bias Mean       927.934\n",
      "evaluation/Estimation Bias Std        168.049\n",
      "evaluation/EB/Q_True Mean              49.4183\n",
      "evaluation/EB/Q_True Std              152.538\n",
      "evaluation/EB/Q_Pred Mean             977.352\n",
      "evaluation/EB/Q_Pred Std               70.0224\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5199.81\n",
      "evaluation/Actions Mean                 0.508152\n",
      "evaluation/Actions Std                  0.642988\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.05971\n",
      "time/backward_zf1 (s)                   2.21106\n",
      "time/backward_zf2 (s)                   2.12868\n",
      "time/data sampling (s)                  0.31865\n",
      "time/data storing (s)                   0.0150314\n",
      "time/evaluation sampling (s)            1.40588\n",
      "time/exploration sampling (s)           0.203904\n",
      "time/logging (s)                        0.0123436\n",
      "time/preback_alpha (s)                  0.605115\n",
      "time/preback_policy (s)                 1.14127\n",
      "time/preback_start (s)                  0.130977\n",
      "time/preback_zf (s)                     5.18768\n",
      "time/saving (s)                         0.0058416\n",
      "time/training (s)                       2.40299\n",
      "time/epoch (s)                         17.8291\n",
      "time/total (s)                       4839.27\n",
      "Epoch                                 285\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:13:14.963849 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 286 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 297000\n",
      "trainer/ZF1 Loss                      200.394\n",
      "trainer/ZF2 Loss                      189.748\n",
      "trainer/ZF Expert Reward               18.492\n",
      "trainer/ZF Policy Reward                7.07504\n",
      "trainer/ZF CHI2 Term                  206.809\n",
      "trainer/Policy Loss                  -840\n",
      "trainer/Bias Loss                     127.236\n",
      "trainer/Bias Value                     12.0825\n",
      "trainer/Policy Grad Norm              461.423\n",
      "trainer/Policy Param Norm              36.2263\n",
      "trainer/Zf1 Grad Norm                2293.96\n",
      "trainer/Zf1 Param Norm                119.9\n",
      "trainer/Zf2 Grad Norm                2637.6\n",
      "trainer/Zf2 Param Norm                117.605\n",
      "trainer/Z Expert Predictions Mean     984.079\n",
      "trainer/Z Expert Predictions Std       97.0821\n",
      "trainer/Z Expert Predictions Max     1185.93\n",
      "trainer/Z Expert Predictions Min      577.24\n",
      "trainer/Z Policy Predictions Mean     838.017\n",
      "trainer/Z Policy Predictions Std      311.27\n",
      "trainer/Z Policy Predictions Max     1176.05\n",
      "trainer/Z Policy Predictions Min     -124.585\n",
      "trainer/Z Expert Targets Mean         965.587\n",
      "trainer/Z Expert Targets Std           99.5956\n",
      "trainer/Z Expert Targets Max         1173.17\n",
      "trainer/Z Expert Targets Min          549.317\n",
      "trainer/Z Policy Targets Mean         830.942\n",
      "trainer/Z Policy Targets Std          312.119\n",
      "trainer/Z Policy Targets Max         1169.02\n",
      "trainer/Z Policy Targets Min         -139.147\n",
      "trainer/Log Pis Mean                   32.179\n",
      "trainer/Log Pis Std                     7.21123\n",
      "trainer/Policy mu Mean                  1.46891\n",
      "trainer/Policy mu Std                   2.60706\n",
      "trainer/Policy log std Mean            -3.44514\n",
      "trainer/Policy log std Std              1.48046\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        292924\n",
      "exploration/num paths total          1060\n",
      "evaluation/num steps total              2.29104e+06\n",
      "evaluation/num paths total           2875\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17635\n",
      "evaluation/Rewards Std                  1.33079\n",
      "evaluation/Rewards Max                  7.25813\n",
      "evaluation/Rewards Min                  0.102324\n",
      "evaluation/Returns Mean              5176.35\n",
      "evaluation/Returns Std                 43.3655\n",
      "evaluation/Returns Max               5235.33\n",
      "evaluation/Returns Min               5100.82\n",
      "evaluation/Estimation Bias Mean       920.841\n",
      "evaluation/Estimation Bias Std        185.381\n",
      "evaluation/EB/Q_True Mean              48.608\n",
      "evaluation/EB/Q_True Std              149.96\n",
      "evaluation/EB/Q_Pred Mean             969.449\n",
      "evaluation/EB/Q_Pred Std              122.333\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5176.35\n",
      "evaluation/Actions Mean                 0.509161\n",
      "evaluation/Actions Std                  0.641672\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99051\n",
      "time/backward_zf1 (s)                   2.18461\n",
      "time/backward_zf2 (s)                   2.06787\n",
      "time/data sampling (s)                  0.299\n",
      "time/data storing (s)                   0.0146895\n",
      "time/evaluation sampling (s)            1.44973\n",
      "time/exploration sampling (s)           0.204607\n",
      "time/logging (s)                        0.012021\n",
      "time/preback_alpha (s)                  0.605489\n",
      "time/preback_policy (s)                 1.123\n",
      "time/preback_start (s)                  0.130585\n",
      "time/preback_zf (s)                     5.21394\n",
      "time/saving (s)                         0.00583877\n",
      "time/training (s)                       2.40712\n",
      "time/epoch (s)                         17.709\n",
      "time/total (s)                       4857\n",
      "Epoch                                 286\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:13:32.727981 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 287 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 298000\n",
      "trainer/ZF1 Loss                       34.4544\n",
      "trainer/ZF2 Loss                       26.6653\n",
      "trainer/ZF Expert Reward               21.087\n",
      "trainer/ZF Policy Reward                6.16959\n",
      "trainer/ZF CHI2 Term                   45.7922\n",
      "trainer/Policy Loss                  -825.086\n",
      "trainer/Bias Loss                     133.311\n",
      "trainer/Bias Value                     12.089\n",
      "trainer/Policy Grad Norm              384.224\n",
      "trainer/Policy Param Norm              36.2483\n",
      "trainer/Zf1 Grad Norm                2649.18\n",
      "trainer/Zf1 Param Norm                120.064\n",
      "trainer/Zf2 Grad Norm                1978.6\n",
      "trainer/Zf2 Param Norm                117.767\n",
      "trainer/Z Expert Predictions Mean     987.183\n",
      "trainer/Z Expert Predictions Std      105.74\n",
      "trainer/Z Expert Predictions Max     1193.38\n",
      "trainer/Z Expert Predictions Min      646.356\n",
      "trainer/Z Policy Predictions Mean     814.887\n",
      "trainer/Z Policy Predictions Std      320.848\n",
      "trainer/Z Policy Predictions Max     1185.78\n",
      "trainer/Z Policy Predictions Min     -203.247\n",
      "trainer/Z Expert Targets Mean         966.096\n",
      "trainer/Z Expert Targets Std          109.664\n",
      "trainer/Z Expert Targets Max         1179.43\n",
      "trainer/Z Expert Targets Min          609.47\n",
      "trainer/Z Policy Targets Mean         808.718\n",
      "trainer/Z Policy Targets Std          318.215\n",
      "trainer/Z Policy Targets Max         1177.9\n",
      "trainer/Z Policy Targets Min         -202.484\n",
      "trainer/Log Pis Mean                   31.4969\n",
      "trainer/Log Pis Std                     7.17498\n",
      "trainer/Policy mu Mean                  1.42199\n",
      "trainer/Policy mu Std                   2.63142\n",
      "trainer/Policy log std Mean            -3.44986\n",
      "trainer/Policy log std Std              1.5004\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        292924\n",
      "exploration/num paths total          1060\n",
      "evaluation/num steps total              2.29915e+06\n",
      "evaluation/num paths total           2886\n",
      "evaluation/path length Mean           737.273\n",
      "evaluation/path length Std            347.882\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            258\n",
      "evaluation/Rewards Mean                 5.00565\n",
      "evaluation/Rewards Std                  1.48061\n",
      "evaluation/Rewards Max                  7.38252\n",
      "evaluation/Rewards Min                  0.104796\n",
      "evaluation/Returns Mean              3690.53\n",
      "evaluation/Returns Std               1980.84\n",
      "evaluation/Returns Max               5242.72\n",
      "evaluation/Returns Min                978.55\n",
      "evaluation/Estimation Bias Mean       887.27\n",
      "evaluation/Estimation Bias Std        246.965\n",
      "evaluation/EB/Q_True Mean              60.9489\n",
      "evaluation/EB/Q_True Std              167.372\n",
      "evaluation/EB/Q_Pred Mean             948.219\n",
      "evaluation/EB/Q_Pred Std              170.994\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3690.53\n",
      "evaluation/Actions Mean                 0.502685\n",
      "evaluation/Actions Std                  0.6405\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98958\n",
      "time/backward_zf1 (s)                   2.16653\n",
      "time/backward_zf2 (s)                   2.07765\n",
      "time/data sampling (s)                  0.301261\n",
      "time/data storing (s)                   0.0141417\n",
      "time/evaluation sampling (s)            1.52471\n",
      "time/exploration sampling (s)           0.198746\n",
      "time/logging (s)                        0.00957697\n",
      "time/preback_alpha (s)                  0.601309\n",
      "time/preback_policy (s)                 1.1308\n",
      "time/preback_start (s)                  0.130491\n",
      "time/preback_zf (s)                     5.1998\n",
      "time/saving (s)                         0.00548499\n",
      "time/training (s)                       2.34079\n",
      "time/epoch (s)                         17.6909\n",
      "time/total (s)                       4874.71\n",
      "Epoch                                 287\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:13:50.852775 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 288 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 299000\n",
      "trainer/ZF1 Loss                       25.0927\n",
      "trainer/ZF2 Loss                       28.8719\n",
      "trainer/ZF Expert Reward               16.7816\n",
      "trainer/ZF Policy Reward                3.80185\n",
      "trainer/ZF CHI2 Term                   40.2647\n",
      "trainer/Policy Loss                  -888.677\n",
      "trainer/Bias Loss                      64.9459\n",
      "trainer/Bias Value                     12.0954\n",
      "trainer/Policy Grad Norm              427.256\n",
      "trainer/Policy Param Norm              36.2681\n",
      "trainer/Zf1 Grad Norm                1834.31\n",
      "trainer/Zf1 Param Norm                120.222\n",
      "trainer/Zf2 Grad Norm                2611.37\n",
      "trainer/Zf2 Param Norm                117.926\n",
      "trainer/Z Expert Predictions Mean     986.614\n",
      "trainer/Z Expert Predictions Std       91.3744\n",
      "trainer/Z Expert Predictions Max     1185.68\n",
      "trainer/Z Expert Predictions Min      687.658\n",
      "trainer/Z Policy Predictions Mean     883.367\n",
      "trainer/Z Policy Predictions Std      264.773\n",
      "trainer/Z Policy Predictions Max     1183.44\n",
      "trainer/Z Policy Predictions Min     -179.823\n",
      "trainer/Z Expert Targets Mean         969.833\n",
      "trainer/Z Expert Targets Std           94.5226\n",
      "trainer/Z Expert Targets Max         1177.82\n",
      "trainer/Z Expert Targets Min          659.372\n",
      "trainer/Z Policy Targets Mean         879.566\n",
      "trainer/Z Policy Targets Std          266.529\n",
      "trainer/Z Policy Targets Max         1173.86\n",
      "trainer/Z Policy Targets Min         -199.52\n",
      "trainer/Log Pis Mean                   30.2627\n",
      "trainer/Log Pis Std                     5.83586\n",
      "trainer/Policy mu Mean                  1.42468\n",
      "trainer/Policy mu Std                   2.32957\n",
      "trainer/Policy log std Mean            -3.54863\n",
      "trainer/Policy log std Std              1.47238\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        292924\n",
      "exploration/num paths total          1060\n",
      "evaluation/num steps total              2.30915e+06\n",
      "evaluation/num paths total           2896\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.24863\n",
      "evaluation/Rewards Std                  1.36074\n",
      "evaluation/Rewards Max                  7.29291\n",
      "evaluation/Rewards Min                  0.0905837\n",
      "evaluation/Returns Mean              5248.63\n",
      "evaluation/Returns Std                 14.9607\n",
      "evaluation/Returns Max               5268.88\n",
      "evaluation/Returns Min               5222.61\n",
      "evaluation/Estimation Bias Mean       927.158\n",
      "evaluation/Estimation Bias Std        170.956\n",
      "evaluation/EB/Q_True Mean              49.6437\n",
      "evaluation/EB/Q_True Std              153.262\n",
      "evaluation/EB/Q_Pred Mean             976.801\n",
      "evaluation/EB/Q_Pred Std               70.5264\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5248.63\n",
      "evaluation/Actions Mean                 0.506473\n",
      "evaluation/Actions Std                  0.649821\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.05623\n",
      "time/backward_zf1 (s)                   2.25334\n",
      "time/backward_zf2 (s)                   2.15834\n",
      "time/data sampling (s)                  0.331503\n",
      "time/data storing (s)                   0.0164965\n",
      "time/evaluation sampling (s)            1.4575\n",
      "time/exploration sampling (s)           0.209145\n",
      "time/logging (s)                        0.0118254\n",
      "time/preback_alpha (s)                  0.62823\n",
      "time/preback_policy (s)                 1.21547\n",
      "time/preback_start (s)                  0.135846\n",
      "time/preback_zf (s)                     5.22064\n",
      "time/saving (s)                         0.00561925\n",
      "time/training (s)                       2.35518\n",
      "time/epoch (s)                         18.0554\n",
      "time/total (s)                       4892.79\n",
      "Epoch                                 288\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:14:10.282353 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 289 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 300000\n",
      "trainer/ZF1 Loss                       25.1929\n",
      "trainer/ZF2 Loss                       18.4779\n",
      "trainer/ZF Expert Reward               13.7429\n",
      "trainer/ZF Policy Reward                0.969429\n",
      "trainer/ZF CHI2 Term                   34.9237\n",
      "trainer/Policy Loss                  -867.137\n",
      "trainer/Bias Loss                      56.1577\n",
      "trainer/Bias Value                     12.1018\n",
      "trainer/Policy Grad Norm              405.772\n",
      "trainer/Policy Param Norm              36.2853\n",
      "trainer/Zf1 Grad Norm                1636\n",
      "trainer/Zf1 Param Norm                120.373\n",
      "trainer/Zf2 Grad Norm                2118.69\n",
      "trainer/Zf2 Param Norm                118.078\n",
      "trainer/Z Expert Predictions Mean     961.951\n",
      "trainer/Z Expert Predictions Std      124.343\n",
      "trainer/Z Expert Predictions Max     1182.35\n",
      "trainer/Z Expert Predictions Min       49.8805\n",
      "trainer/Z Policy Predictions Mean     857.643\n",
      "trainer/Z Policy Predictions Std      254.187\n",
      "trainer/Z Policy Predictions Max     1171.24\n",
      "trainer/Z Policy Predictions Min     -132.995\n",
      "trainer/Z Expert Targets Mean         948.208\n",
      "trainer/Z Expert Targets Std          128.075\n",
      "trainer/Z Expert Targets Max         1176.12\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         856.673\n",
      "trainer/Z Policy Targets Std          251.077\n",
      "trainer/Z Policy Targets Max         1174.52\n",
      "trainer/Z Policy Targets Min         -179.285\n",
      "trainer/Log Pis Mean                   31.4826\n",
      "trainer/Log Pis Std                     6.88724\n",
      "trainer/Policy mu Mean                  1.34936\n",
      "trainer/Policy mu Std                   2.55203\n",
      "trainer/Policy log std Mean            -3.58817\n",
      "trainer/Policy log std Std              1.41174\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        295924\n",
      "exploration/num paths total          1063\n",
      "evaluation/num steps total              2.31915e+06\n",
      "evaluation/num paths total           2906\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.20294\n",
      "evaluation/Rewards Std                  1.33334\n",
      "evaluation/Rewards Max                  7.29258\n",
      "evaluation/Rewards Min                  0.113103\n",
      "evaluation/Returns Mean              5202.94\n",
      "evaluation/Returns Std                 16.0594\n",
      "evaluation/Returns Max               5218.27\n",
      "evaluation/Returns Min               5168.56\n",
      "evaluation/Estimation Bias Mean       928.481\n",
      "evaluation/Estimation Bias Std        167.791\n",
      "evaluation/EB/Q_True Mean              49.2945\n",
      "evaluation/EB/Q_True Std              152.06\n",
      "evaluation/EB/Q_Pred Mean             977.775\n",
      "evaluation/EB/Q_Pred Std               65.4434\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5202.94\n",
      "evaluation/Actions Mean                 0.511677\n",
      "evaluation/Actions Std                  0.639312\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.3332\n",
      "time/backward_zf1 (s)                   2.57107\n",
      "time/backward_zf2 (s)                   2.43825\n",
      "time/data sampling (s)                  0.349219\n",
      "time/data storing (s)                   0.0167381\n",
      "time/evaluation sampling (s)            1.44977\n",
      "time/exploration sampling (s)           0.223709\n",
      "time/logging (s)                        0.0123273\n",
      "time/preback_alpha (s)                  0.657639\n",
      "time/preback_policy (s)                 1.31607\n",
      "time/preback_start (s)                  0.144375\n",
      "time/preback_zf (s)                     5.4032\n",
      "time/saving (s)                         0.00723369\n",
      "time/training (s)                       2.43145\n",
      "time/epoch (s)                         19.3542\n",
      "time/total (s)                       4912.16\n",
      "Epoch                                 289\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:14:29.701501 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 290 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 301000\n",
      "trainer/ZF1 Loss                       30.5118\n",
      "trainer/ZF2 Loss                       29.0973\n",
      "trainer/ZF Expert Reward               11.5341\n",
      "trainer/ZF Policy Reward               -1.8676\n",
      "trainer/ZF CHI2 Term                   43.5205\n",
      "trainer/Policy Loss                  -864.361\n",
      "trainer/Bias Loss                      83.7746\n",
      "trainer/Bias Value                     12.1083\n",
      "trainer/Policy Grad Norm              495.703\n",
      "trainer/Policy Param Norm              36.3058\n",
      "trainer/Zf1 Grad Norm                3108.09\n",
      "trainer/Zf1 Param Norm                120.526\n",
      "trainer/Zf2 Grad Norm                3587.84\n",
      "trainer/Zf2 Param Norm                118.223\n",
      "trainer/Z Expert Predictions Mean     973.991\n",
      "trainer/Z Expert Predictions Std       96.1184\n",
      "trainer/Z Expert Predictions Max     1185.03\n",
      "trainer/Z Expert Predictions Min      660.101\n",
      "trainer/Z Policy Predictions Mean     861.295\n",
      "trainer/Z Policy Predictions Std      281.736\n",
      "trainer/Z Policy Predictions Max     1183.49\n",
      "trainer/Z Policy Predictions Min     -137.525\n",
      "trainer/Z Expert Targets Mean         962.457\n",
      "trainer/Z Expert Targets Std           99.972\n",
      "trainer/Z Expert Targets Max         1185.24\n",
      "trainer/Z Expert Targets Min          645.212\n",
      "trainer/Z Policy Targets Mean         863.163\n",
      "trainer/Z Policy Targets Std          280.318\n",
      "trainer/Z Policy Targets Max         1183.05\n",
      "trainer/Z Policy Targets Min         -138.758\n",
      "trainer/Log Pis Mean                   31.4237\n",
      "trainer/Log Pis Std                     6.67062\n",
      "trainer/Policy mu Mean                  1.42744\n",
      "trainer/Policy mu Std                   2.66077\n",
      "trainer/Policy log std Mean            -3.51976\n",
      "trainer/Policy log std Std              1.56789\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        295924\n",
      "exploration/num paths total          1063\n",
      "evaluation/num steps total              2.32915e+06\n",
      "evaluation/num paths total           2916\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.12521\n",
      "evaluation/Rewards Std                  1.32649\n",
      "evaluation/Rewards Max                  7.25991\n",
      "evaluation/Rewards Min                  0.073218\n",
      "evaluation/Returns Mean              5125.21\n",
      "evaluation/Returns Std                 90.4893\n",
      "evaluation/Returns Max               5215.29\n",
      "evaluation/Returns Min               4883.15\n",
      "evaluation/Estimation Bias Mean       891.869\n",
      "evaluation/Estimation Bias Std        200.443\n",
      "evaluation/EB/Q_True Mean              48.9293\n",
      "evaluation/EB/Q_True Std              151.337\n",
      "evaluation/EB/Q_Pred Mean             940.798\n",
      "evaluation/EB/Q_Pred Std              133.522\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5125.21\n",
      "evaluation/Actions Mean                 0.50508\n",
      "evaluation/Actions Std                  0.646439\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.27931\n",
      "time/backward_zf1 (s)                   2.53773\n",
      "time/backward_zf2 (s)                   2.41598\n",
      "time/data sampling (s)                  0.36126\n",
      "time/data storing (s)                   0.0172622\n",
      "time/evaluation sampling (s)            1.41648\n",
      "time/exploration sampling (s)           0.222465\n",
      "time/logging (s)                        0.0115306\n",
      "time/preback_alpha (s)                  0.677666\n",
      "time/preback_policy (s)                 1.3025\n",
      "time/preback_start (s)                  0.146883\n",
      "time/preback_zf (s)                     5.44854\n",
      "time/saving (s)                         0.00585506\n",
      "time/training (s)                       2.48329\n",
      "time/epoch (s)                         19.3267\n",
      "time/total (s)                       4931.52\n",
      "Epoch                                 290\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:14:49.840420 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 291 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 302000\n",
      "trainer/ZF1 Loss                       24.2499\n",
      "trainer/ZF2 Loss                       24.8829\n",
      "trainer/ZF Expert Reward               15.6265\n",
      "trainer/ZF Policy Reward                1.56654\n",
      "trainer/ZF CHI2 Term                   38.9484\n",
      "trainer/Policy Loss                  -826.991\n",
      "trainer/Bias Loss                      97.6236\n",
      "trainer/Bias Value                     12.1149\n",
      "trainer/Policy Grad Norm              333.064\n",
      "trainer/Policy Param Norm              36.3261\n",
      "trainer/Zf1 Grad Norm                1831.27\n",
      "trainer/Zf1 Param Norm                120.686\n",
      "trainer/Zf2 Grad Norm                2869.69\n",
      "trainer/Zf2 Param Norm                118.38\n",
      "trainer/Z Expert Predictions Mean     971.464\n",
      "trainer/Z Expert Predictions Std      124.498\n",
      "trainer/Z Expert Predictions Max     1186.39\n",
      "trainer/Z Expert Predictions Min      409.485\n",
      "trainer/Z Policy Predictions Mean     821.669\n",
      "trainer/Z Policy Predictions Std      293.825\n",
      "trainer/Z Policy Predictions Max     1169.01\n",
      "trainer/Z Policy Predictions Min     -190.168\n",
      "trainer/Z Expert Targets Mean         955.837\n",
      "trainer/Z Expert Targets Std          128.324\n",
      "trainer/Z Expert Targets Max         1177.24\n",
      "trainer/Z Expert Targets Min          383.569\n",
      "trainer/Z Policy Targets Mean         820.103\n",
      "trainer/Z Policy Targets Std          289.944\n",
      "trainer/Z Policy Targets Max         1167.06\n",
      "trainer/Z Policy Targets Min         -174.556\n",
      "trainer/Log Pis Mean                   32.2089\n",
      "trainer/Log Pis Std                     7.36475\n",
      "trainer/Policy mu Mean                  1.39663\n",
      "trainer/Policy mu Std                   2.64113\n",
      "trainer/Policy log std Mean            -3.50934\n",
      "trainer/Policy log std Std              1.52079\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        296924\n",
      "exploration/num paths total          1064\n",
      "evaluation/num steps total              2.33915e+06\n",
      "evaluation/num paths total           2926\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.22393\n",
      "evaluation/Rewards Std                  1.34803\n",
      "evaluation/Rewards Max                  7.26461\n",
      "evaluation/Rewards Min                  0.0953561\n",
      "evaluation/Returns Mean              5223.93\n",
      "evaluation/Returns Std                  9.95648\n",
      "evaluation/Returns Max               5244.26\n",
      "evaluation/Returns Min               5211.37\n",
      "evaluation/Estimation Bias Mean       929.133\n",
      "evaluation/Estimation Bias Std        169.281\n",
      "evaluation/EB/Q_True Mean              49.3964\n",
      "evaluation/EB/Q_True Std              152.382\n",
      "evaluation/EB/Q_Pred Mean             978.53\n",
      "evaluation/EB/Q_Pred Std               69.0699\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5223.93\n",
      "evaluation/Actions Mean                 0.513765\n",
      "evaluation/Actions Std                  0.637837\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.36985\n",
      "time/backward_zf1 (s)                   2.65484\n",
      "time/backward_zf2 (s)                   2.49558\n",
      "time/data sampling (s)                  0.380533\n",
      "time/data storing (s)                   0.0177045\n",
      "time/evaluation sampling (s)            1.45095\n",
      "time/exploration sampling (s)           0.231344\n",
      "time/logging (s)                        0.0139072\n",
      "time/preback_alpha (s)                  0.70565\n",
      "time/preback_policy (s)                 1.31941\n",
      "time/preback_start (s)                  0.152219\n",
      "time/preback_zf (s)                     5.61534\n",
      "time/saving (s)                         0.00601321\n",
      "time/training (s)                       2.64801\n",
      "time/epoch (s)                         20.0613\n",
      "time/total (s)                       4951.6\n",
      "Epoch                                 291\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:15:09.160389 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 292 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 303000\n",
      "trainer/ZF1 Loss                       37.5229\n",
      "trainer/ZF2 Loss                       36.217\n",
      "trainer/ZF Expert Reward               14.562\n",
      "trainer/ZF Policy Reward                3.69429\n",
      "trainer/ZF CHI2 Term                   48.0487\n",
      "trainer/Policy Loss                  -872.376\n",
      "trainer/Bias Loss                     130.697\n",
      "trainer/Bias Value                     12.1216\n",
      "trainer/Policy Grad Norm              638.78\n",
      "trainer/Policy Param Norm              36.3504\n",
      "trainer/Zf1 Grad Norm                2370.51\n",
      "trainer/Zf1 Param Norm                120.844\n",
      "trainer/Zf2 Grad Norm                1767.85\n",
      "trainer/Zf2 Param Norm                118.535\n",
      "trainer/Z Expert Predictions Mean     964.872\n",
      "trainer/Z Expert Predictions Std      119.789\n",
      "trainer/Z Expert Predictions Max     1186.35\n",
      "trainer/Z Expert Predictions Min        3.33066\n",
      "trainer/Z Policy Predictions Mean     868.689\n",
      "trainer/Z Policy Predictions Std      250.88\n",
      "trainer/Z Policy Predictions Max     1188.25\n",
      "trainer/Z Policy Predictions Min     -156.379\n",
      "trainer/Z Expert Targets Mean         950.31\n",
      "trainer/Z Expert Targets Std          123.097\n",
      "trainer/Z Expert Targets Max         1181.99\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         864.995\n",
      "trainer/Z Policy Targets Std          249.981\n",
      "trainer/Z Policy Targets Max         1184.94\n",
      "trainer/Z Policy Targets Min         -171.618\n",
      "trainer/Log Pis Mean                   31.092\n",
      "trainer/Log Pis Std                     6.00641\n",
      "trainer/Policy mu Mean                  1.46495\n",
      "trainer/Policy mu Std                   2.65421\n",
      "trainer/Policy log std Mean            -3.48438\n",
      "trainer/Policy log std Std              1.52671\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        296924\n",
      "exploration/num paths total          1064\n",
      "evaluation/num steps total              2.34915e+06\n",
      "evaluation/num paths total           2936\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.2227\n",
      "evaluation/Rewards Std                  1.34227\n",
      "evaluation/Rewards Max                  7.3455\n",
      "evaluation/Rewards Min                  0.114465\n",
      "evaluation/Returns Mean              5222.7\n",
      "evaluation/Returns Std                 24.0959\n",
      "evaluation/Returns Max               5246.57\n",
      "evaluation/Returns Min               5157.51\n",
      "evaluation/Estimation Bias Mean       929.751\n",
      "evaluation/Estimation Bias Std        173.128\n",
      "evaluation/EB/Q_True Mean              49.5342\n",
      "evaluation/EB/Q_True Std              152.893\n",
      "evaluation/EB/Q_Pred Mean             979.285\n",
      "evaluation/EB/Q_Pred Std               85.1201\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5222.7\n",
      "evaluation/Actions Mean                 0.510557\n",
      "evaluation/Actions Std                  0.643625\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.24549\n",
      "time/backward_zf1 (s)                   2.47877\n",
      "time/backward_zf2 (s)                   2.38611\n",
      "time/data sampling (s)                  0.361475\n",
      "time/data storing (s)                   0.016096\n",
      "time/evaluation sampling (s)            1.47831\n",
      "time/exploration sampling (s)           0.212297\n",
      "time/logging (s)                        0.0120906\n",
      "time/preback_alpha (s)                  0.677326\n",
      "time/preback_policy (s)                 1.29032\n",
      "time/preback_start (s)                  0.146191\n",
      "time/preback_zf (s)                     5.45526\n",
      "time/saving (s)                         0.00565312\n",
      "time/training (s)                       2.47222\n",
      "time/epoch (s)                         19.2376\n",
      "time/total (s)                       4970.86\n",
      "Epoch                                 292\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:15:29.424266 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 293 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 304000\n",
      "trainer/ZF1 Loss                       27.762\n",
      "trainer/ZF2 Loss                       29.9505\n",
      "trainer/ZF Expert Reward               13.7478\n",
      "trainer/ZF Policy Reward                0.877051\n",
      "trainer/ZF CHI2 Term                   42.0414\n",
      "trainer/Policy Loss                  -865.315\n",
      "trainer/Bias Loss                      88.6732\n",
      "trainer/Bias Value                     12.1282\n",
      "trainer/Policy Grad Norm              638.996\n",
      "trainer/Policy Param Norm              36.3749\n",
      "trainer/Zf1 Grad Norm                2720.74\n",
      "trainer/Zf1 Param Norm                121.004\n",
      "trainer/Zf2 Grad Norm                2309.4\n",
      "trainer/Zf2 Param Norm                118.699\n",
      "trainer/Z Expert Predictions Mean     947.295\n",
      "trainer/Z Expert Predictions Std      136.54\n",
      "trainer/Z Expert Predictions Max     1183.22\n",
      "trainer/Z Expert Predictions Min      288.665\n",
      "trainer/Z Policy Predictions Mean     860.77\n",
      "trainer/Z Policy Predictions Std      260.015\n",
      "trainer/Z Policy Predictions Max     1175.73\n",
      "trainer/Z Policy Predictions Min     -180.579\n",
      "trainer/Z Expert Targets Mean         933.547\n",
      "trainer/Z Expert Targets Std          140.401\n",
      "trainer/Z Expert Targets Max         1172.72\n",
      "trainer/Z Expert Targets Min          255.02\n",
      "trainer/Z Policy Targets Mean         859.894\n",
      "trainer/Z Policy Targets Std          258.806\n",
      "trainer/Z Policy Targets Max         1173.92\n",
      "trainer/Z Policy Targets Min         -186.838\n",
      "trainer/Log Pis Mean                   31.438\n",
      "trainer/Log Pis Std                     6.85489\n",
      "trainer/Policy mu Mean                  1.4123\n",
      "trainer/Policy mu Std                   2.5787\n",
      "trainer/Policy log std Mean            -3.61057\n",
      "trainer/Policy log std Std              1.53496\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        299924\n",
      "exploration/num paths total          1067\n",
      "evaluation/num steps total              2.35915e+06\n",
      "evaluation/num paths total           2946\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.18575\n",
      "evaluation/Rewards Std                  1.31659\n",
      "evaluation/Rewards Max                  7.30239\n",
      "evaluation/Rewards Min                  0.112023\n",
      "evaluation/Returns Mean              5185.75\n",
      "evaluation/Returns Std                 27.4137\n",
      "evaluation/Returns Max               5253.5\n",
      "evaluation/Returns Min               5157.46\n",
      "evaluation/Estimation Bias Mean       914.972\n",
      "evaluation/Estimation Bias Std        176.949\n",
      "evaluation/EB/Q_True Mean              48.9097\n",
      "evaluation/EB/Q_True Std              150.981\n",
      "evaluation/EB/Q_Pred Mean             963.882\n",
      "evaluation/EB/Q_Pred Std              105.092\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5185.75\n",
      "evaluation/Actions Mean                 0.496174\n",
      "evaluation/Actions Std                  0.653504\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.42742\n",
      "time/backward_zf1 (s)                   2.67447\n",
      "time/backward_zf2 (s)                   2.56035\n",
      "time/data sampling (s)                  0.365752\n",
      "time/data storing (s)                   0.0171486\n",
      "time/evaluation sampling (s)            1.45392\n",
      "time/exploration sampling (s)           0.231307\n",
      "time/logging (s)                        0.0120591\n",
      "time/preback_alpha (s)                  0.714614\n",
      "time/preback_policy (s)                 1.38523\n",
      "time/preback_start (s)                  0.152324\n",
      "time/preback_zf (s)                     5.59414\n",
      "time/saving (s)                         0.00592819\n",
      "time/training (s)                       2.58322\n",
      "time/epoch (s)                         20.1779\n",
      "time/total (s)                       4991.06\n",
      "Epoch                                 293\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:15:49.523643 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 294 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 305000\n",
      "trainer/ZF1 Loss                       50.6025\n",
      "trainer/ZF2 Loss                       47.5406\n",
      "trainer/ZF Expert Reward               13.3488\n",
      "trainer/ZF Policy Reward                2.12982\n",
      "trainer/ZF CHI2 Term                   60.607\n",
      "trainer/Policy Loss                  -835.439\n",
      "trainer/Bias Loss                     220.533\n",
      "trainer/Bias Value                     12.1347\n",
      "trainer/Policy Grad Norm              427.918\n",
      "trainer/Policy Param Norm              36.3948\n",
      "trainer/Zf1 Grad Norm                3457.06\n",
      "trainer/Zf1 Param Norm                121.169\n",
      "trainer/Zf2 Grad Norm                3773.64\n",
      "trainer/Zf2 Param Norm                118.859\n",
      "trainer/Z Expert Predictions Mean     973.67\n",
      "trainer/Z Expert Predictions Std      127.861\n",
      "trainer/Z Expert Predictions Max     1183.25\n",
      "trainer/Z Expert Predictions Min       92.6199\n",
      "trainer/Z Policy Predictions Mean     830.519\n",
      "trainer/Z Policy Predictions Std      256.22\n",
      "trainer/Z Policy Predictions Max     1157.05\n",
      "trainer/Z Policy Predictions Min     -111.412\n",
      "trainer/Z Expert Targets Mean         960.321\n",
      "trainer/Z Expert Targets Std          131.245\n",
      "trainer/Z Expert Targets Max         1170.79\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         828.389\n",
      "trainer/Z Policy Targets Std          253.139\n",
      "trainer/Z Policy Targets Max         1156.99\n",
      "trainer/Z Policy Targets Min         -111.522\n",
      "trainer/Log Pis Mean                   31.6428\n",
      "trainer/Log Pis Std                     7.05405\n",
      "trainer/Policy mu Mean                  1.48543\n",
      "trainer/Policy mu Std                   2.48769\n",
      "trainer/Policy log std Mean            -3.4671\n",
      "trainer/Policy log std Std              1.47585\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        300924\n",
      "exploration/num paths total          1068\n",
      "evaluation/num steps total              2.36915e+06\n",
      "evaluation/num paths total           2956\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.17896\n",
      "evaluation/Rewards Std                  1.344\n",
      "evaluation/Rewards Max                  7.35456\n",
      "evaluation/Rewards Min                  0.113533\n",
      "evaluation/Returns Mean              5178.96\n",
      "evaluation/Returns Std                 44.5151\n",
      "evaluation/Returns Max               5251.88\n",
      "evaluation/Returns Min               5104.75\n",
      "evaluation/Estimation Bias Mean       901.257\n",
      "evaluation/Estimation Bias Std        195.754\n",
      "evaluation/EB/Q_True Mean              49.4047\n",
      "evaluation/EB/Q_True Std              152.744\n",
      "evaluation/EB/Q_Pred Mean             950.662\n",
      "evaluation/EB/Q_Pred Std               94.5894\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5178.96\n",
      "evaluation/Actions Mean                 0.512918\n",
      "evaluation/Actions Std                  0.649394\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.3665\n",
      "time/backward_zf1 (s)                   2.65272\n",
      "time/backward_zf2 (s)                   2.51539\n",
      "time/data sampling (s)                  0.37135\n",
      "time/data storing (s)                   0.0176748\n",
      "time/evaluation sampling (s)            1.49517\n",
      "time/exploration sampling (s)           0.22922\n",
      "time/logging (s)                        0.0138613\n",
      "time/preback_alpha (s)                  0.699951\n",
      "time/preback_policy (s)                 1.3484\n",
      "time/preback_start (s)                  0.15016\n",
      "time/preback_zf (s)                     5.51683\n",
      "time/saving (s)                         0.0072619\n",
      "time/training (s)                       2.62833\n",
      "time/epoch (s)                         20.0128\n",
      "time/total (s)                       5011.1\n",
      "Epoch                                 294\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:16:09.824507 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 295 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 306000\n",
      "trainer/ZF1 Loss                       24.2074\n",
      "trainer/ZF2 Loss                       25.8743\n",
      "trainer/ZF Expert Reward               14.8386\n",
      "trainer/ZF Policy Reward                2.341\n",
      "trainer/ZF CHI2 Term                   37.846\n",
      "trainer/Policy Loss                  -864.39\n",
      "trainer/Bias Loss                      81.52\n",
      "trainer/Bias Value                     12.1412\n",
      "trainer/Policy Grad Norm              599.743\n",
      "trainer/Policy Param Norm              36.415\n",
      "trainer/Zf1 Grad Norm                2451.87\n",
      "trainer/Zf1 Param Norm                121.33\n",
      "trainer/Zf2 Grad Norm                2550.58\n",
      "trainer/Zf2 Param Norm                119.029\n",
      "trainer/Z Expert Predictions Mean     945.14\n",
      "trainer/Z Expert Predictions Std      122.017\n",
      "trainer/Z Expert Predictions Max     1183.57\n",
      "trainer/Z Expert Predictions Min      480.372\n",
      "trainer/Z Policy Predictions Mean     858.678\n",
      "trainer/Z Policy Predictions Std      260.696\n",
      "trainer/Z Policy Predictions Max     1174.93\n",
      "trainer/Z Policy Predictions Min     -121.48\n",
      "trainer/Z Expert Targets Mean         930.302\n",
      "trainer/Z Expert Targets Std          125.486\n",
      "trainer/Z Expert Targets Max         1176.86\n",
      "trainer/Z Expert Targets Min          467.03\n",
      "trainer/Z Policy Targets Mean         856.337\n",
      "trainer/Z Policy Targets Std          260.313\n",
      "trainer/Z Policy Targets Max         1171.79\n",
      "trainer/Z Policy Targets Min         -123.117\n",
      "trainer/Log Pis Mean                   30.7562\n",
      "trainer/Log Pis Std                     5.7267\n",
      "trainer/Policy mu Mean                  1.37355\n",
      "trainer/Policy mu Std                   2.33218\n",
      "trainer/Policy log std Mean            -3.65013\n",
      "trainer/Policy log std Std              1.40011\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        300924\n",
      "exploration/num paths total          1068\n",
      "evaluation/num steps total              2.37872e+06\n",
      "evaluation/num paths total           2966\n",
      "evaluation/path length Mean           957.2\n",
      "evaluation/path length Std             86.066\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            766\n",
      "evaluation/Rewards Mean                 5.16241\n",
      "evaluation/Rewards Std                  1.3379\n",
      "evaluation/Rewards Max                  7.2372\n",
      "evaluation/Rewards Min                  0.120939\n",
      "evaluation/Returns Mean              4941.46\n",
      "evaluation/Returns Std                500.074\n",
      "evaluation/Returns Max               5251.52\n",
      "evaluation/Returns Min               3843.76\n",
      "evaluation/Estimation Bias Mean       905.552\n",
      "evaluation/Estimation Bias Std        226.954\n",
      "evaluation/EB/Q_True Mean              51.3269\n",
      "evaluation/EB/Q_True Std              154.747\n",
      "evaluation/EB/Q_Pred Mean             956.879\n",
      "evaluation/EB/Q_Pred Std              150.153\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4941.46\n",
      "evaluation/Actions Mean                 0.496603\n",
      "evaluation/Actions Std                  0.652919\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.40988\n",
      "time/backward_zf1 (s)                   2.64027\n",
      "time/backward_zf2 (s)                   2.51303\n",
      "time/data sampling (s)                  0.405931\n",
      "time/data storing (s)                   0.0181258\n",
      "time/evaluation sampling (s)            1.73729\n",
      "time/exploration sampling (s)           0.23135\n",
      "time/logging (s)                        0.0134214\n",
      "time/preback_alpha (s)                  0.697538\n",
      "time/preback_policy (s)                 1.35485\n",
      "time/preback_start (s)                  0.14954\n",
      "time/preback_zf (s)                     5.50608\n",
      "time/saving (s)                         0.00652556\n",
      "time/training (s)                       2.53426\n",
      "time/epoch (s)                         20.2181\n",
      "time/total (s)                       5031.34\n",
      "Epoch                                 295\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:16:29.587295 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 296 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 307000\n",
      "trainer/ZF1 Loss                       27.714\n",
      "trainer/ZF2 Loss                       28.8656\n",
      "trainer/ZF Expert Reward               15.0195\n",
      "trainer/ZF Policy Reward                3.83909\n",
      "trainer/ZF CHI2 Term                   39.7824\n",
      "trainer/Policy Loss                  -858.505\n",
      "trainer/Bias Loss                     106.739\n",
      "trainer/Bias Value                     12.1477\n",
      "trainer/Policy Grad Norm              577.36\n",
      "trainer/Policy Param Norm              36.4332\n",
      "trainer/Zf1 Grad Norm                2609.98\n",
      "trainer/Zf1 Param Norm                121.5\n",
      "trainer/Zf2 Grad Norm                2151.52\n",
      "trainer/Zf2 Param Norm                119.195\n",
      "trainer/Z Expert Predictions Mean     951.047\n",
      "trainer/Z Expert Predictions Std      118.854\n",
      "trainer/Z Expert Predictions Max     1194.7\n",
      "trainer/Z Expert Predictions Min      569.38\n",
      "trainer/Z Policy Predictions Mean     852.301\n",
      "trainer/Z Policy Predictions Std      262.046\n",
      "trainer/Z Policy Predictions Max     1182.42\n",
      "trainer/Z Policy Predictions Min     -161.836\n",
      "trainer/Z Expert Targets Mean         936.028\n",
      "trainer/Z Expert Targets Std          120.399\n",
      "trainer/Z Expert Targets Max         1176.23\n",
      "trainer/Z Expert Targets Min          572.597\n",
      "trainer/Z Policy Targets Mean         848.462\n",
      "trainer/Z Policy Targets Std          258.912\n",
      "trainer/Z Policy Targets Max         1171.25\n",
      "trainer/Z Policy Targets Min         -145.368\n",
      "trainer/Log Pis Mean                   31.2216\n",
      "trainer/Log Pis Std                     6.55135\n",
      "trainer/Policy mu Mean                  1.42852\n",
      "trainer/Policy mu Std                   2.45253\n",
      "trainer/Policy log std Mean            -3.61678\n",
      "trainer/Policy log std Std              1.46661\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        302924\n",
      "exploration/num paths total          1070\n",
      "evaluation/num steps total              2.38844e+06\n",
      "evaluation/num paths total           2976\n",
      "evaluation/path length Mean           971.6\n",
      "evaluation/path length Std             57.3676\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            840\n",
      "evaluation/Rewards Mean                 5.17105\n",
      "evaluation/Rewards Std                  1.33533\n",
      "evaluation/Rewards Max                  7.65615\n",
      "evaluation/Rewards Min                  0.100779\n",
      "evaluation/Returns Mean              5024.19\n",
      "evaluation/Returns Std                316.983\n",
      "evaluation/Returns Max               5240.62\n",
      "evaluation/Returns Min               4265.9\n",
      "evaluation/Estimation Bias Mean       912.62\n",
      "evaluation/Estimation Bias Std        224.34\n",
      "evaluation/EB/Q_True Mean              50.4687\n",
      "evaluation/EB/Q_True Std              153.235\n",
      "evaluation/EB/Q_Pred Mean             963.089\n",
      "evaluation/EB/Q_Pred Std              141.698\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5024.19\n",
      "evaluation/Actions Mean                 0.500843\n",
      "evaluation/Actions Std                  0.653799\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.35909\n",
      "time/backward_zf1 (s)                   2.60994\n",
      "time/backward_zf2 (s)                   2.45807\n",
      "time/data sampling (s)                  0.369538\n",
      "time/data storing (s)                   0.0175277\n",
      "time/evaluation sampling (s)            1.40937\n",
      "time/exploration sampling (s)           0.227167\n",
      "time/logging (s)                        0.0121222\n",
      "time/preback_alpha (s)                  0.702363\n",
      "time/preback_policy (s)                 1.35043\n",
      "time/preback_start (s)                  0.149615\n",
      "time/preback_zf (s)                     5.49942\n",
      "time/saving (s)                         0.00564313\n",
      "time/training (s)                       2.50881\n",
      "time/epoch (s)                         19.6791\n",
      "time/total (s)                       5051.04\n",
      "Epoch                                 296\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:16:49.493686 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 297 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 308000\n",
      "trainer/ZF1 Loss                       31.0326\n",
      "trainer/ZF2 Loss                       27.5079\n",
      "trainer/ZF Expert Reward               14.0128\n",
      "trainer/ZF Policy Reward                3.1471\n",
      "trainer/ZF CHI2 Term                   40.4457\n",
      "trainer/Policy Loss                  -862.297\n",
      "trainer/Bias Loss                     125.429\n",
      "trainer/Bias Value                     12.1542\n",
      "trainer/Policy Grad Norm              441.008\n",
      "trainer/Policy Param Norm              36.4537\n",
      "trainer/Zf1 Grad Norm                2666.29\n",
      "trainer/Zf1 Param Norm                121.667\n",
      "trainer/Zf2 Grad Norm                2828.38\n",
      "trainer/Zf2 Param Norm                119.354\n",
      "trainer/Z Expert Predictions Mean     946.853\n",
      "trainer/Z Expert Predictions Std      141.586\n",
      "trainer/Z Expert Predictions Max     1188.65\n",
      "trainer/Z Expert Predictions Min     -106.216\n",
      "trainer/Z Policy Predictions Mean     860.887\n",
      "trainer/Z Policy Predictions Std      247.088\n",
      "trainer/Z Policy Predictions Max     1167.68\n",
      "trainer/Z Policy Predictions Min     -192.909\n",
      "trainer/Z Expert Targets Mean         932.84\n",
      "trainer/Z Expert Targets Std          140.288\n",
      "trainer/Z Expert Targets Max         1176.83\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         857.74\n",
      "trainer/Z Policy Targets Std          245.319\n",
      "trainer/Z Policy Targets Max         1158.63\n",
      "trainer/Z Policy Targets Min         -205.981\n",
      "trainer/Log Pis Mean                   30.9819\n",
      "trainer/Log Pis Std                     6.17938\n",
      "trainer/Policy mu Mean                  1.40126\n",
      "trainer/Policy mu Std                   2.38889\n",
      "trainer/Policy log std Mean            -3.59994\n",
      "trainer/Policy log std Std              1.49809\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        302924\n",
      "exploration/num paths total          1070\n",
      "evaluation/num steps total              2.39698e+06\n",
      "evaluation/num paths total           2986\n",
      "evaluation/path length Mean           854.3\n",
      "evaluation/path length Std            184.028\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            424\n",
      "evaluation/Rewards Mean                 5.09861\n",
      "evaluation/Rewards Std                  1.40722\n",
      "evaluation/Rewards Max                  9.16615\n",
      "evaluation/Rewards Min                  0.10255\n",
      "evaluation/Returns Mean              4355.74\n",
      "evaluation/Returns Std               1035.53\n",
      "evaluation/Returns Max               5241.18\n",
      "evaluation/Returns Min               1924.85\n",
      "evaluation/Estimation Bias Mean       844.228\n",
      "evaluation/Estimation Bias Std        302.388\n",
      "evaluation/EB/Q_True Mean              57.6454\n",
      "evaluation/EB/Q_True Std              163.018\n",
      "evaluation/EB/Q_Pred Mean             901.873\n",
      "evaluation/EB/Q_Pred Std              250.374\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4355.74\n",
      "evaluation/Actions Mean                 0.494097\n",
      "evaluation/Actions Std                  0.66233\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.41568\n",
      "time/backward_zf1 (s)                   2.65347\n",
      "time/backward_zf2 (s)                   2.50943\n",
      "time/data sampling (s)                  0.389445\n",
      "time/data storing (s)                   0.0166345\n",
      "time/evaluation sampling (s)            1.45135\n",
      "time/exploration sampling (s)           0.218434\n",
      "time/logging (s)                        0.0110991\n",
      "time/preback_alpha (s)                  0.691596\n",
      "time/preback_policy (s)                 1.34821\n",
      "time/preback_start (s)                  0.146458\n",
      "time/preback_zf (s)                     5.51827\n",
      "time/saving (s)                         0.00598943\n",
      "time/training (s)                       2.44508\n",
      "time/epoch (s)                         19.8212\n",
      "time/total (s)                       5070.88\n",
      "Epoch                                 297\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:17:08.507781 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 298 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 309000\n",
      "trainer/ZF1 Loss                       26.743\n",
      "trainer/ZF2 Loss                       35.4343\n",
      "trainer/ZF Expert Reward               12.3152\n",
      "trainer/ZF Policy Reward                0.704554\n",
      "trainer/ZF CHI2 Term                   43.0142\n",
      "trainer/Policy Loss                  -848.761\n",
      "trainer/Bias Loss                      75.0593\n",
      "trainer/Bias Value                     12.1607\n",
      "trainer/Policy Grad Norm              545.039\n",
      "trainer/Policy Param Norm              36.4765\n",
      "trainer/Zf1 Grad Norm                2229.83\n",
      "trainer/Zf1 Param Norm                121.836\n",
      "trainer/Zf2 Grad Norm                3165.48\n",
      "trainer/Zf2 Param Norm                119.515\n",
      "trainer/Z Expert Predictions Mean     946.913\n",
      "trainer/Z Expert Predictions Std      136.282\n",
      "trainer/Z Expert Predictions Max     1180.64\n",
      "trainer/Z Expert Predictions Min      -64.1523\n",
      "trainer/Z Policy Predictions Mean     836.918\n",
      "trainer/Z Policy Predictions Std      264.93\n",
      "trainer/Z Policy Predictions Max     1167.05\n",
      "trainer/Z Policy Predictions Min     -165.706\n",
      "trainer/Z Expert Targets Mean         934.598\n",
      "trainer/Z Expert Targets Std          135.999\n",
      "trainer/Z Expert Targets Max         1167.61\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         836.214\n",
      "trainer/Z Policy Targets Std          262.988\n",
      "trainer/Z Policy Targets Max         1162.97\n",
      "trainer/Z Policy Targets Min         -161.611\n",
      "trainer/Log Pis Mean                   31.5006\n",
      "trainer/Log Pis Std                     7.27694\n",
      "trainer/Policy mu Mean                  1.42022\n",
      "trainer/Policy mu Std                   2.56011\n",
      "trainer/Policy log std Mean            -3.53231\n",
      "trainer/Policy log std Std              1.52038\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        302924\n",
      "exploration/num paths total          1070\n",
      "evaluation/num steps total              2.40662e+06\n",
      "evaluation/num paths total           2996\n",
      "evaluation/path length Mean           963.5\n",
      "evaluation/path length Std            109.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            635\n",
      "evaluation/Rewards Mean                 5.17297\n",
      "evaluation/Rewards Std                  1.35871\n",
      "evaluation/Rewards Max                  7.61356\n",
      "evaluation/Rewards Min                  0.108179\n",
      "evaluation/Returns Mean              4984.15\n",
      "evaluation/Returns Std                627.764\n",
      "evaluation/Returns Max               5228.76\n",
      "evaluation/Returns Min               3101.8\n",
      "evaluation/Estimation Bias Mean       898.295\n",
      "evaluation/Estimation Bias Std        247.78\n",
      "evaluation/EB/Q_True Mean              51.3267\n",
      "evaluation/EB/Q_True Std              155.162\n",
      "evaluation/EB/Q_Pred Mean             949.621\n",
      "evaluation/EB/Q_Pred Std              145.987\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4984.15\n",
      "evaluation/Actions Mean                 0.506685\n",
      "evaluation/Actions Std                  0.644642\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.20608\n",
      "time/backward_zf1 (s)                   2.43015\n",
      "time/backward_zf2 (s)                   2.30619\n",
      "time/data sampling (s)                  0.366187\n",
      "time/data storing (s)                   0.0164855\n",
      "time/evaluation sampling (s)            1.46831\n",
      "time/exploration sampling (s)           0.215753\n",
      "time/logging (s)                        0.0114601\n",
      "time/preback_alpha (s)                  0.665135\n",
      "time/preback_policy (s)                 1.2443\n",
      "time/preback_start (s)                  0.142938\n",
      "time/preback_zf (s)                     5.37163\n",
      "time/saving (s)                         0.00561643\n",
      "time/training (s)                       2.48154\n",
      "time/epoch (s)                         18.9318\n",
      "time/total (s)                       5089.84\n",
      "Epoch                                 298\n",
      "---------------------------------  ----------------\n",
      "2024-06-25 19:17:28.263169 +0330 | [idsac_walker2d_normal-iqn-neutral_2024_06_25_17_52_08_0000--s-1] Epoch 299 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 310000\n",
      "trainer/ZF1 Loss                       31.3962\n",
      "trainer/ZF2 Loss                       24.8619\n",
      "trainer/ZF Expert Reward               17.9167\n",
      "trainer/ZF Policy Reward                3.39244\n",
      "trainer/ZF CHI2 Term                   42.9675\n",
      "trainer/Policy Loss                  -844.582\n",
      "trainer/Bias Loss                      99.3926\n",
      "trainer/Bias Value                     12.1676\n",
      "trainer/Policy Grad Norm              647.265\n",
      "trainer/Policy Param Norm              36.4988\n",
      "trainer/Zf1 Grad Norm                2173\n",
      "trainer/Zf1 Param Norm                121.985\n",
      "trainer/Zf2 Grad Norm                2882.99\n",
      "trainer/Zf2 Param Norm                119.67\n",
      "trainer/Z Expert Predictions Mean     955.883\n",
      "trainer/Z Expert Predictions Std      131.585\n",
      "trainer/Z Expert Predictions Max     1180.33\n",
      "trainer/Z Expert Predictions Min       97.766\n",
      "trainer/Z Policy Predictions Mean     840.265\n",
      "trainer/Z Policy Predictions Std      261.205\n",
      "trainer/Z Policy Predictions Max     1161.58\n",
      "trainer/Z Policy Predictions Min     -118.824\n",
      "trainer/Z Expert Targets Mean         937.967\n",
      "trainer/Z Expert Targets Std          136.027\n",
      "trainer/Z Expert Targets Max         1168.38\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         836.872\n",
      "trainer/Z Policy Targets Std          259.994\n",
      "trainer/Z Policy Targets Max         1160.71\n",
      "trainer/Z Policy Targets Min         -144.168\n",
      "trainer/Log Pis Mean                   31.4275\n",
      "trainer/Log Pis Std                     6.14116\n",
      "trainer/Policy mu Mean                  1.48115\n",
      "trainer/Policy mu Std                   2.48133\n",
      "trainer/Policy log std Mean            -3.57226\n",
      "trainer/Policy log std Std              1.53625\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        305924\n",
      "exploration/num paths total          1073\n",
      "evaluation/num steps total              2.41662e+06\n",
      "evaluation/num paths total           3006\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.19699\n",
      "evaluation/Rewards Std                  1.34372\n",
      "evaluation/Rewards Max                  7.21307\n",
      "evaluation/Rewards Min                  0.0933731\n",
      "evaluation/Returns Mean              5196.99\n",
      "evaluation/Returns Std                 17.0549\n",
      "evaluation/Returns Max               5222.66\n",
      "evaluation/Returns Min               5167.28\n",
      "evaluation/Estimation Bias Mean       901.001\n",
      "evaluation/Estimation Bias Std        169.02\n",
      "evaluation/EB/Q_True Mean              49.2682\n",
      "evaluation/EB/Q_True Std              152.234\n",
      "evaluation/EB/Q_Pred Mean             950.27\n",
      "evaluation/EB/Q_Pred Std               71.9674\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5196.99\n",
      "evaluation/Actions Mean                 0.508925\n",
      "evaluation/Actions Std                  0.645799\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                2.32878\n",
      "time/backward_zf1 (s)                   2.56698\n",
      "time/backward_zf2 (s)                   2.39748\n",
      "time/data sampling (s)                  0.363611\n",
      "time/data storing (s)                   0.0170924\n",
      "time/evaluation sampling (s)            1.49711\n",
      "time/exploration sampling (s)           0.230857\n",
      "time/logging (s)                        0.0120455\n",
      "time/preback_alpha (s)                  0.688314\n",
      "time/preback_policy (s)                 1.30344\n",
      "time/preback_start (s)                  0.149391\n",
      "time/preback_zf (s)                     5.52851\n",
      "time/saving (s)                         0.0055032\n",
      "time/training (s)                       2.58473\n",
      "time/epoch (s)                         19.6738\n",
      "time/total (s)                       5109.53\n",
      "Epoch                                 299\n",
      "---------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    experiment(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bae6a1-25e3-4451-89d4-109cf43dd8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

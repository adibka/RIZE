{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b40f96-5af4-4fc9-8f5d-34bacdc440d8",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df783e4e-ddf6-45d9-8b26-6863e89107f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.data_management.torch_replay_buffer import TorchReplayBuffer\n",
    "from rlkit.envs import make_env\n",
    "from rlkit.envs.vecenv import SubprocVectorEnv, VectorEnv\n",
    "from rlkit.launchers.launcher_util import set_seed, setup_logger\n",
    "from rlkit.samplers.data_collector import (VecMdpPathCollector, VecMdpStepCollector)\n",
    "from rlkit.torch.idsac.idsac import IDSACTrainer\n",
    "from rlkit.torch.idsac.networks import QuantileMlp, Critic, softmax\n",
    "from rlkit.torch.networks import FlattenMlp\n",
    "from rlkit.torch.sac.policies import MakeDeterministic, TanhGaussianPolicy\n",
    "from rlkit.torch.torch_iq_algorithm import TorchVecOnlineIQAlgorithm\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba84c8-f8f8-4272-8885-83a6c028ee37",
   "metadata": {},
   "source": [
    "# experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c847e24-53fa-4f9b-850b-c7b648d30304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(variant):\n",
    "    dummy_env = make_env(variant['env'])\n",
    "    obs_dim = dummy_env.observation_space.low.size\n",
    "    action_dim = dummy_env.action_space.low.size\n",
    "    expl_env = VectorEnv([lambda: make_env(variant['env']) for _ in range(variant['expl_env_num'])])\n",
    "    expl_env.seed(variant[\"seed\"])\n",
    "    expl_env.action_space.seed(variant[\"seed\"])\n",
    "    eval_env = SubprocVectorEnv([lambda: make_env(variant['env']) for _ in range(variant['eval_env_num'])])\n",
    "    eval_env.seed(variant[\"seed\"])\n",
    "\n",
    "    M = variant[\"layer_size\"]\n",
    "    num_quantiles = variant[\"num_quantiles\"]\n",
    "    tau_type = variant[\"trainer_kwargs\"][\"tau_type\"]\n",
    "    \n",
    "    zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf1 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_zf2 = QuantileMlp(\n",
    "        input_size=obs_dim + action_dim,\n",
    "        output_size=1,\n",
    "        num_quantiles=num_quantiles,\n",
    "        hidden_sizes=[M, M],\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    target_policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_sizes=[M, M, M],\n",
    "    )\n",
    "    # fraction proposal network\n",
    "    fp = target_fp = None\n",
    "    if variant['trainer_kwargs'].get('tau_type') == 'fqf':\n",
    "        fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "        target_fp = FlattenMlp(\n",
    "            input_size=obs_dim + action_dim,\n",
    "            output_size=num_quantiles,\n",
    "            hidden_sizes=[M // 2, M // 2],\n",
    "            output_activation=softmax,\n",
    "        )\n",
    "    eval_path_collector = VecMdpPathCollector(\n",
    "        eval_env,\n",
    "        eval_policy,\n",
    "        zf1,\n",
    "        tau_type,\n",
    "    )\n",
    "    expl_path_collector = VecMdpStepCollector(\n",
    "        expl_env,\n",
    "        policy,\n",
    "    )\n",
    "    replay_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'],\n",
    "        dummy_env,\n",
    "    )\n",
    "    expert_buffer = TorchReplayBuffer(\n",
    "        variant['replay_buffer_size'] // 10,\n",
    "        dummy_env,\n",
    "    )\n",
    "    iq_args = variant['iq_kwargs']\n",
    "    expert_buffer.load(iq_args['expert_path'], iq_args['demos'], \n",
    "                       iq_args['subsample_freq'], variant['seed']\n",
    "                      )\n",
    "    trainer = IDSACTrainer(\n",
    "        args=variant,\n",
    "        env=dummy_env,\n",
    "        policy=policy,\n",
    "        target_policy=target_policy,\n",
    "        zf1=zf1,\n",
    "        zf2=zf2,\n",
    "        target_zf1=target_zf1,\n",
    "        target_zf2=target_zf2,\n",
    "        fp=fp,\n",
    "        target_fp=target_fp,\n",
    "        num_quantiles=num_quantiles,\n",
    "        **variant['trainer_kwargs'],\n",
    "    )\n",
    "    algorithm = TorchVecOnlineIQAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        expert_buffer=expert_buffer,\n",
    "        **variant['algorithm_kwargs'],\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e380543-9ff2-4947-8cda-2f5b05957627",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fa2c3c-ae22-4830-bad1-8b99032cb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(dsac_cfg_path,\n",
    "               expert_path,\n",
    "               iq_cfg_path='configs/dsac-normal-iqn-neutral/iq.yaml',\n",
    "               cql_cfg_path='configs/dsac-normal-iqn-neutral/cql.yaml'\n",
    "              ):\n",
    "    \n",
    "    with open(dsac_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        variant = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    with open(iq_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        iq_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    with open(cql_cfg_path, 'r', encoding=\"utf-8\") as f:\n",
    "        cql_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    iq_cfg['expert_path'] = expert_path\n",
    "    variant['iq_kwargs'] = iq_cfg\n",
    "    variant['cql_kwargs'] = cql_cfg\n",
    "    return variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40faac3-2a8c-49fc-bece-f891df61d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = get_config(dsac_cfg_path='configs/dsac-normal-iqn-neutral/humanoid.yaml',\n",
    "                     expert_path='experts/Humanoid-v2_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00203431-e8bc-4e42-977f-298ec40d51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-28 20:25:22.030069 +0330 | Variant:\n",
      "2024-07-28 20:25:22.030960 +0330 | {\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"min_num_steps_before_training\": 10000,\n",
      "    \"num_epochs\": 330,\n",
      "    \"num_eval_paths_per_epoch\": 10,\n",
      "    \"num_expl_steps_per_train_loop\": 1000,\n",
      "    \"num_trains_per_train_loop\": 1000\n",
      "  },\n",
      "  \"env\": \"Humanoid-v2\",\n",
      "  \"seed\": 1,\n",
      "  \"expectation_z\": false,\n",
      "  \"eval_env_num\": 10,\n",
      "  \"expl_env_num\": 10,\n",
      "  \"layer_size\": 256,\n",
      "  \"num_quantiles\": 24,\n",
      "  \"replay_buffer_size\": 1000000,\n",
      "  \"trainer_kwargs\": {\n",
      "    \"alpha\": 0.01,\n",
      "    \"discount\": 0.99,\n",
      "    \"policy_lr\": 5e-05,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"tau_type\": \"iqn\",\n",
      "    \"use_automatic_entropy_tuning\": false,\n",
      "    \"zf_lr\": 0.0003,\n",
      "    \"bias\": 10,\n",
      "    \"bias_lr\": 0.0001,\n",
      "    \"use_automatic_bias_tuning\": true\n",
      "  },\n",
      "  \"version\": \"normal-iqn-neutral\",\n",
      "  \"iq_kwargs\": {\n",
      "    \"expert_path\": \"experts/Humanoid-v2_25.pkl\",\n",
      "    \"subsample_freq\": 1,\n",
      "    \"demos\": 1,\n",
      "    \"regularize\": true,\n",
      "    \"div\": null,\n",
      "    \"loss\": \"v0\",\n",
      "    \"alpha\": 0.5\n",
      "  },\n",
      "  \"cql_kwargs\": {\n",
      "    \"use_cql\": false,\n",
      "    \"cql_weight\": 0.05,\n",
      "    \"num_random\": 10,\n",
      "    \"with_lagrange\": false,\n",
      "    \"lagrange_thresh\": 10.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    ptu.set_gpu_mode(True, 0)\n",
    "seed = variant[\"seed\"]\n",
    "set_seed(seed)\n",
    "log_prefix = variant[\"env\"][:-3].lower()\n",
    "setup_logger(log_prefix, variant=variant, seed=seed)\n",
    "variant[\"device\"] = ptu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9e0ac-93fd-4003-bfd1-29f851badba5",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21b2b4-9bf0-4965-91a7-ff8ca706fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddie/venvs/IQ/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-28 20:25:46.650281 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 0 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 11000\n",
      "trainer/ZF1 Loss                      29.6176\n",
      "trainer/ZF2 Loss                      30.5303\n",
      "trainer/ZF Expert Reward               0.155695\n",
      "trainer/ZF Policy Reward               0.169333\n",
      "trainer/ZF CHI2 Term                  30.2271\n",
      "trainer/Policy Loss                   -0.31563\n",
      "trainer/Bias Loss                     48.4921\n",
      "trainer/Bias Value                     9.9999\n",
      "trainer/Policy Grad Norm               0.0828205\n",
      "trainer/Policy Param Norm             17.4104\n",
      "trainer/Zf1 Grad Norm                 95.063\n",
      "trainer/Zf1 Param Norm                32.0396\n",
      "trainer/Zf2 Grad Norm                 99.6959\n",
      "trainer/Zf2 Param Norm                32.0198\n",
      "trainer/Z Expert Predictions Mean      0.137817\n",
      "trainer/Z Expert Predictions Std       0.184351\n",
      "trainer/Z Expert Predictions Max       0.703985\n",
      "trainer/Z Expert Predictions Min      -0.696398\n",
      "trainer/Z Policy Predictions Mean      0.0160752\n",
      "trainer/Z Policy Predictions Std       0.195908\n",
      "trainer/Z Policy Predictions Max       0.746054\n",
      "trainer/Z Policy Predictions Min      -0.698585\n",
      "trainer/Z Expert Targets Mean         -0.0178774\n",
      "trainer/Z Expert Targets Std           0.192679\n",
      "trainer/Z Expert Targets Max           0.639637\n",
      "trainer/Z Expert Targets Min          -0.853291\n",
      "trainer/Z Policy Targets Mean         -0.153257\n",
      "trainer/Z Policy Targets Std           0.209855\n",
      "trainer/Z Policy Targets Max           0.484943\n",
      "trainer/Z Policy Targets Min          -0.933653\n",
      "trainer/Log Pis Mean                 -11.4818\n",
      "trainer/Log Pis Std                    0.983032\n",
      "trainer/Policy mu Mean                -0.000846702\n",
      "trainer/Policy mu Std                  0.00492743\n",
      "trainer/Policy log std Mean            0.00101805\n",
      "trainer/Policy log std Std             0.00633573\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        10878\n",
      "exploration/num paths total          443\n",
      "evaluation/num steps total           463\n",
      "evaluation/num paths total            10\n",
      "evaluation/path length Mean           46.3\n",
      "evaluation/path length Std             3.55106\n",
      "evaluation/path length Max            51\n",
      "evaluation/path length Min            40\n",
      "evaluation/Rewards Mean                4.59036\n",
      "evaluation/Rewards Std                 0.162441\n",
      "evaluation/Rewards Max                 4.8084\n",
      "evaluation/Rewards Min                 4.10509\n",
      "evaluation/Returns Mean              212.534\n",
      "evaluation/Returns Std                16.7935\n",
      "evaluation/Returns Max               235.552\n",
      "evaluation/Returns Min               182.852\n",
      "evaluation/Estimation Bias Mean       34.9966\n",
      "evaluation/Estimation Bias Std        36.62\n",
      "evaluation/EB/Q_True Mean             11.0743\n",
      "evaluation/EB/Q_True Std              36.1967\n",
      "evaluation/EB/Q_Pred Mean             46.0709\n",
      "evaluation/EB/Q_Pred Std               2.85158\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           212.534\n",
      "evaluation/Actions Mean                0.192719\n",
      "evaluation/Actions Std                 0.847526\n",
      "evaluation/Actions Max                 0.999787\n",
      "evaluation/Actions Min                -0.999524\n",
      "time/backward_policy (s)               1.7637\n",
      "time/backward_zf1 (s)                  2.14239\n",
      "time/backward_zf2 (s)                  2.09237\n",
      "time/data sampling (s)                 0.271267\n",
      "time/data storing (s)                  0.0144588\n",
      "time/evaluation sampling (s)           0.145626\n",
      "time/exploration sampling (s)          0.816303\n",
      "time/logging (s)                       0.00321504\n",
      "time/preback_alpha (s)                 0.551749\n",
      "time/preback_policy (s)                1.01786\n",
      "time/preback_start (s)                 0.169073\n",
      "time/preback_zf (s)                    6.47697\n",
      "time/saving (s)                        3.748e-06\n",
      "time/training (s)                      3.3358\n",
      "time/epoch (s)                        18.8008\n",
      "time/total (s)                        28.076\n",
      "Epoch                                  0\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:26:05.351267 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 1 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 12000\n",
      "trainer/ZF1 Loss                      -7.25388\n",
      "trainer/ZF2 Loss                      -7.23078\n",
      "trainer/ZF Expert Reward              10.7956\n",
      "trainer/ZF Policy Reward               4.88251\n",
      "trainer/ZF CHI2 Term                   3.04837\n",
      "trainer/Policy Loss                  -33.8605\n",
      "trainer/Bias Loss                      0.369448\n",
      "trainer/Bias Value                     9.98844\n",
      "trainer/Policy Grad Norm               1.01231\n",
      "trainer/Policy Param Norm             18.2468\n",
      "trainer/Zf1 Grad Norm                 46.8443\n",
      "trainer/Zf1 Param Norm                35.9089\n",
      "trainer/Zf2 Grad Norm                 58.6304\n",
      "trainer/Zf2 Param Norm                35.7575\n",
      "trainer/Z Expert Predictions Mean     51.1333\n",
      "trainer/Z Expert Predictions Std       0.34755\n",
      "trainer/Z Expert Predictions Max      51.2765\n",
      "trainer/Z Expert Predictions Min      48.2151\n",
      "trainer/Z Policy Predictions Mean     30.616\n",
      "trainer/Z Policy Predictions Std       5.91377\n",
      "trainer/Z Policy Predictions Max      46.0346\n",
      "trainer/Z Policy Predictions Min       4.44503\n",
      "trainer/Z Expert Targets Mean         40.3377\n",
      "trainer/Z Expert Targets Std           0.165399\n",
      "trainer/Z Expert Targets Max          40.599\n",
      "trainer/Z Expert Targets Min          38.8204\n",
      "trainer/Z Policy Targets Mean         25.7334\n",
      "trainer/Z Policy Targets Std           7.08962\n",
      "trainer/Z Policy Targets Max          39.2632\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  30.0087\n",
      "trainer/Log Pis Std                    9.08892\n",
      "trainer/Policy mu Mean                 0.512854\n",
      "trainer/Policy mu Std                  1.97925\n",
      "trainer/Policy log std Mean           -0.61703\n",
      "trainer/Policy log std Std             0.13047\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        11598\n",
      "exploration/num paths total          461\n",
      "evaluation/num steps total          1058\n",
      "evaluation/num paths total            20\n",
      "evaluation/path length Mean           59.5\n",
      "evaluation/path length Std             1.85742\n",
      "evaluation/path length Max            63\n",
      "evaluation/path length Min            57\n",
      "evaluation/Rewards Mean                5.4979\n",
      "evaluation/Rewards Std                 0.520641\n",
      "evaluation/Rewards Max                 6.62456\n",
      "evaluation/Rewards Min                 4.73529\n",
      "evaluation/Returns Mean              327.125\n",
      "evaluation/Returns Std                 9.69046\n",
      "evaluation/Returns Max               345.271\n",
      "evaluation/Returns Min               314.203\n",
      "evaluation/Estimation Bias Mean       67.0841\n",
      "evaluation/Estimation Bias Std        52.0751\n",
      "evaluation/EB/Q_True Mean             15.9708\n",
      "evaluation/EB/Q_True Std              51.8807\n",
      "evaluation/EB/Q_Pred Mean             83.0549\n",
      "evaluation/EB/Q_Pred Std               3.2503\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           327.125\n",
      "evaluation/Actions Mean                0.226979\n",
      "evaluation/Actions Std                 0.722837\n",
      "evaluation/Actions Max                 0.998438\n",
      "evaluation/Actions Min                -0.996306\n",
      "time/backward_policy (s)               1.8183\n",
      "time/backward_zf1 (s)                  2.19384\n",
      "time/backward_zf2 (s)                  2.14535\n",
      "time/data sampling (s)                 0.273921\n",
      "time/data storing (s)                  0.0142463\n",
      "time/evaluation sampling (s)           0.164483\n",
      "time/exploration sampling (s)          0.565594\n",
      "time/logging (s)                       0.00314102\n",
      "time/preback_alpha (s)                 0.553228\n",
      "time/preback_policy (s)                1.08709\n",
      "time/preback_start (s)                 0.168167\n",
      "time/preback_zf (s)                    6.51313\n",
      "time/saving (s)                        3.44501e-06\n",
      "time/training (s)                      3.1387\n",
      "time/epoch (s)                        18.6392\n",
      "time/total (s)                        46.7331\n",
      "Epoch                                  1\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:26:24.066472 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 2 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 13000\n",
      "trainer/ZF1 Loss                      -6.1059\n",
      "trainer/ZF2 Loss                      -6.00444\n",
      "trainer/ZF Expert Reward              11.7895\n",
      "trainer/ZF Policy Reward               5.7544\n",
      "trainer/ZF CHI2 Term                   4.81274\n",
      "trainer/Policy Loss                  -69.9678\n",
      "trainer/Bias Loss                      2.45056\n",
      "trainer/Bias Value                    10.0848\n",
      "trainer/Policy Grad Norm               2.43891\n",
      "trainer/Policy Param Norm             19.4328\n",
      "trainer/Zf1 Grad Norm                134.366\n",
      "trainer/Zf1 Param Norm                38.8089\n",
      "trainer/Zf2 Grad Norm                138.747\n",
      "trainer/Zf2 Param Norm                38.4765\n",
      "trainer/Z Expert Predictions Mean     96.0119\n",
      "trainer/Z Expert Predictions Std       1.19768\n",
      "trainer/Z Expert Predictions Max      96.9331\n",
      "trainer/Z Expert Predictions Min      86.8547\n",
      "trainer/Z Policy Predictions Mean     64.1996\n",
      "trainer/Z Policy Predictions Std      17.4687\n",
      "trainer/Z Policy Predictions Max      91.249\n",
      "trainer/Z Policy Predictions Min       0.745891\n",
      "trainer/Z Expert Targets Mean         84.2225\n",
      "trainer/Z Expert Targets Std           2.02349\n",
      "trainer/Z Expert Targets Max          86.6594\n",
      "trainer/Z Expert Targets Min          72.3332\n",
      "trainer/Z Policy Targets Mean         58.4452\n",
      "trainer/Z Policy Targets Std          18.4253\n",
      "trainer/Z Policy Targets Max          83.7963\n",
      "trainer/Z Policy Targets Min          -2.32213\n",
      "trainer/Log Pis Mean                  37.0956\n",
      "trainer/Log Pis Std                   11.6861\n",
      "trainer/Policy mu Mean                 0.70223\n",
      "trainer/Policy mu Std                  2.18426\n",
      "trainer/Policy log std Mean           -0.698733\n",
      "trainer/Policy log std Std             0.257537\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        12908\n",
      "exploration/num paths total          487\n",
      "evaluation/num steps total          1792\n",
      "evaluation/num paths total            30\n",
      "evaluation/path length Mean           73.4\n",
      "evaluation/path length Std            10.6132\n",
      "evaluation/path length Max            94\n",
      "evaluation/path length Min            57\n",
      "evaluation/Rewards Mean                4.43602\n",
      "evaluation/Rewards Std                 0.323881\n",
      "evaluation/Rewards Max                 4.87615\n",
      "evaluation/Rewards Min                 3.44169\n",
      "evaluation/Returns Mean              325.604\n",
      "evaluation/Returns Std                49.7011\n",
      "evaluation/Returns Max               423.383\n",
      "evaluation/Returns Min               256.81\n",
      "evaluation/Estimation Bias Mean       89.8447\n",
      "evaluation/Estimation Bias Std        60.4883\n",
      "evaluation/EB/Q_True Mean             20.0382\n",
      "evaluation/EB/Q_True Std              59.9179\n",
      "evaluation/EB/Q_Pred Mean            109.883\n",
      "evaluation/EB/Q_Pred Std               5.03676\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           325.604\n",
      "evaluation/Actions Mean                0.159288\n",
      "evaluation/Actions Std                 0.741808\n",
      "evaluation/Actions Max                 0.999461\n",
      "evaluation/Actions Min                -0.999602\n",
      "time/backward_policy (s)               1.78464\n",
      "time/backward_zf1 (s)                  2.16149\n",
      "time/backward_zf2 (s)                  2.11118\n",
      "time/data sampling (s)                 0.266698\n",
      "time/data storing (s)                  0.0141041\n",
      "time/evaluation sampling (s)           0.31995\n",
      "time/exploration sampling (s)          0.472106\n",
      "time/logging (s)                       0.00262316\n",
      "time/preback_alpha (s)                 0.545715\n",
      "time/preback_policy (s)                1.06612\n",
      "time/preback_start (s)                 0.163914\n",
      "time/preback_zf (s)                    6.51466\n",
      "time/saving (s)                        3.639e-06\n",
      "time/training (s)                      3.22497\n",
      "time/epoch (s)                        18.6482\n",
      "time/total (s)                        65.4041\n",
      "Epoch                                  2\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:26:43.122327 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 3 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 14000\n",
      "trainer/ZF1 Loss                      -1.78671\n",
      "trainer/ZF2 Loss                      -1.59938\n",
      "trainer/ZF Expert Reward              13.2825\n",
      "trainer/ZF Policy Reward               5.41521\n",
      "trainer/ZF CHI2 Term                  10.6827\n",
      "trainer/Policy Loss                 -100.732\n",
      "trainer/Bias Loss                     10.4655\n",
      "trainer/Bias Value                    10.1994\n",
      "trainer/Policy Grad Norm               4.44875\n",
      "trainer/Policy Param Norm             20.2937\n",
      "trainer/Zf1 Grad Norm                442.959\n",
      "trainer/Zf1 Param Norm                40.7284\n",
      "trainer/Zf2 Grad Norm                498.199\n",
      "trainer/Zf2 Param Norm                40.219\n",
      "trainer/Z Expert Predictions Mean    100.694\n",
      "trainer/Z Expert Predictions Std      13.2933\n",
      "trainer/Z Expert Predictions Max     122.284\n",
      "trainer/Z Expert Predictions Min      29.5413\n",
      "trainer/Z Policy Predictions Mean     96.8108\n",
      "trainer/Z Policy Predictions Std      26.1515\n",
      "trainer/Z Policy Predictions Max     117.53\n",
      "trainer/Z Policy Predictions Min       1.84099\n",
      "trainer/Z Expert Targets Mean         87.412\n",
      "trainer/Z Expert Targets Std          14.5047\n",
      "trainer/Z Expert Targets Max         115.861\n",
      "trainer/Z Expert Targets Min          16.1777\n",
      "trainer/Z Policy Targets Mean         91.3956\n",
      "trainer/Z Policy Targets Std          27.526\n",
      "trainer/Z Policy Targets Max         112.297\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  29.5924\n",
      "trainer/Log Pis Std                   13.9111\n",
      "trainer/Policy mu Mean                 0.493024\n",
      "trainer/Policy mu Std                  2.04761\n",
      "trainer/Policy log std Mean           -0.650278\n",
      "trainer/Policy log std Std             0.285385\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        13722\n",
      "exploration/num paths total          498\n",
      "evaluation/num steps total          2255\n",
      "evaluation/num paths total            40\n",
      "evaluation/path length Mean           46.3\n",
      "evaluation/path length Std             2.6096\n",
      "evaluation/path length Max            50\n",
      "evaluation/path length Min            41\n",
      "evaluation/Rewards Mean                4.43734\n",
      "evaluation/Rewards Std                 0.406291\n",
      "evaluation/Rewards Max                 5.0856\n",
      "evaluation/Rewards Min                 3.50261\n",
      "evaluation/Returns Mean              205.449\n",
      "evaluation/Returns Std                 9.10643\n",
      "evaluation/Returns Max               218.548\n",
      "evaluation/Returns Min               188.737\n",
      "evaluation/Estimation Bias Mean      119.229\n",
      "evaluation/Estimation Bias Std        32.7003\n",
      "evaluation/EB/Q_True Mean              9.78672\n",
      "evaluation/EB/Q_True Std              32.7252\n",
      "evaluation/EB/Q_Pred Mean            129.016\n",
      "evaluation/EB/Q_Pred Std               6.47441\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           205.449\n",
      "evaluation/Actions Mean               -0.111707\n",
      "evaluation/Actions Std                 0.811773\n",
      "evaluation/Actions Max                 0.999986\n",
      "evaluation/Actions Min                -0.999942\n",
      "time/backward_policy (s)               1.69605\n",
      "time/backward_zf1 (s)                  2.11282\n",
      "time/backward_zf2 (s)                  2.01786\n",
      "time/data sampling (s)                 0.285801\n",
      "time/data storing (s)                  0.0146246\n",
      "time/evaluation sampling (s)           0.186693\n",
      "time/exploration sampling (s)          0.51191\n",
      "time/logging (s)                       0.00316563\n",
      "time/preback_alpha (s)                 0.575425\n",
      "time/preback_policy (s)                0.949878\n",
      "time/preback_start (s)                 0.171188\n",
      "time/preback_zf (s)                    6.67148\n",
      "time/saving (s)                        6.128e-06\n",
      "time/training (s)                      3.78749\n",
      "time/epoch (s)                        18.9844\n",
      "time/total (s)                        84.4152\n",
      "Epoch                                  3\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:27:02.159677 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 4 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 15000\n",
      "trainer/ZF1 Loss                      -3.80248\n",
      "trainer/ZF2 Loss                      -3.04909\n",
      "trainer/ZF Expert Reward              12.8817\n",
      "trainer/ZF Policy Reward               5.23685\n",
      "trainer/ZF CHI2 Term                   8.21374\n",
      "trainer/Policy Loss                 -123.071\n",
      "trainer/Bias Loss                      8.93713\n",
      "trainer/Bias Value                    10.2996\n",
      "trainer/Policy Grad Norm               4.22556\n",
      "trainer/Policy Param Norm             20.9733\n",
      "trainer/Zf1 Grad Norm                484.5\n",
      "trainer/Zf1 Param Norm                41.9377\n",
      "trainer/Zf2 Grad Norm                478.677\n",
      "trainer/Zf2 Param Norm                41.414\n",
      "trainer/Z Expert Predictions Mean    125.859\n",
      "trainer/Z Expert Predictions Std       7.72081\n",
      "trainer/Z Expert Predictions Max     143.494\n",
      "trainer/Z Expert Predictions Min     103.679\n",
      "trainer/Z Policy Predictions Mean    118.702\n",
      "trainer/Z Policy Predictions Std      32.6567\n",
      "trainer/Z Policy Predictions Max     140.374\n",
      "trainer/Z Policy Predictions Min      -1.67453\n",
      "trainer/Z Expert Targets Mean        112.978\n",
      "trainer/Z Expert Targets Std           9.28109\n",
      "trainer/Z Expert Targets Max         137.278\n",
      "trainer/Z Expert Targets Min          84.1431\n",
      "trainer/Z Policy Targets Mean        113.465\n",
      "trainer/Z Policy Targets Std          33.1982\n",
      "trainer/Z Policy Targets Max         134.553\n",
      "trainer/Z Policy Targets Min          -1.04493\n",
      "trainer/Log Pis Mean                  25.1271\n",
      "trainer/Log Pis Std                   18.1008\n",
      "trainer/Policy mu Mean                 0.186395\n",
      "trainer/Policy mu Std                  1.93486\n",
      "trainer/Policy log std Mean           -0.683278\n",
      "trainer/Policy log std Std             0.277913\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        14749\n",
      "exploration/num paths total          520\n",
      "evaluation/num steps total          2606\n",
      "evaluation/num paths total            50\n",
      "evaluation/path length Mean           35.1\n",
      "evaluation/path length Std             5.46717\n",
      "evaluation/path length Max            39\n",
      "evaluation/path length Min            21\n",
      "evaluation/Rewards Mean                5.25435\n",
      "evaluation/Rewards Std                 0.591865\n",
      "evaluation/Rewards Max                 6.35268\n",
      "evaluation/Rewards Min                 3.64027\n",
      "evaluation/Returns Mean              184.428\n",
      "evaluation/Returns Std                35.9474\n",
      "evaluation/Returns Max               210.853\n",
      "evaluation/Returns Min                92.1833\n",
      "evaluation/Estimation Bias Mean      118.81\n",
      "evaluation/Estimation Bias Std        44.0832\n",
      "evaluation/EB/Q_True Mean             11.096\n",
      "evaluation/EB/Q_True Std              35.363\n",
      "evaluation/EB/Q_Pred Mean            129.906\n",
      "evaluation/EB/Q_Pred Std              30.9411\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           184.428\n",
      "evaluation/Actions Mean                0.17538\n",
      "evaluation/Actions Std                 0.798918\n",
      "evaluation/Actions Max                 0.999994\n",
      "evaluation/Actions Min                -0.999987\n",
      "time/backward_policy (s)               1.82759\n",
      "time/backward_zf1 (s)                  2.24125\n",
      "time/backward_zf2 (s)                  2.1839\n",
      "time/data sampling (s)                 0.284078\n",
      "time/data storing (s)                  0.0152309\n",
      "time/evaluation sampling (s)           0.133659\n",
      "time/exploration sampling (s)          0.479307\n",
      "time/logging (s)                       0.00355258\n",
      "time/preback_alpha (s)                 0.5652\n",
      "time/preback_policy (s)                1.07907\n",
      "time/preback_start (s)                 0.170824\n",
      "time/preback_zf (s)                    6.61297\n",
      "time/saving (s)                        4.241e-06\n",
      "time/training (s)                      3.37219\n",
      "time/epoch (s)                        18.9688\n",
      "time/total (s)                       103.408\n",
      "Epoch                                  4\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:27:21.054800 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 5 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 16000\n",
      "trainer/ZF1 Loss                      -2.48009\n",
      "trainer/ZF2 Loss                      -0.300109\n",
      "trainer/ZF Expert Reward              10.7354\n",
      "trainer/ZF Policy Reward               4.89467\n",
      "trainer/ZF CHI2 Term                   7.88913\n",
      "trainer/Policy Loss                 -141.75\n",
      "trainer/Bias Loss                      6.83424\n",
      "trainer/Bias Value                    10.3908\n",
      "trainer/Policy Grad Norm               4.85531\n",
      "trainer/Policy Param Norm             21.5786\n",
      "trainer/Zf1 Grad Norm                495.183\n",
      "trainer/Zf1 Param Norm                43.2515\n",
      "trainer/Zf2 Grad Norm                743.838\n",
      "trainer/Zf2 Param Norm                42.6973\n",
      "trainer/Z Expert Predictions Mean    150.771\n",
      "trainer/Z Expert Predictions Std      11.7367\n",
      "trainer/Z Expert Predictions Max     168.896\n",
      "trainer/Z Expert Predictions Min      55.6768\n",
      "trainer/Z Policy Predictions Mean    136.583\n",
      "trainer/Z Policy Predictions Std      40.6566\n",
      "trainer/Z Policy Predictions Max     161.766\n",
      "trainer/Z Policy Predictions Min      -0.437828\n",
      "trainer/Z Expert Targets Mean        140.035\n",
      "trainer/Z Expert Targets Std          12.3547\n",
      "trainer/Z Expert Targets Max         161.864\n",
      "trainer/Z Expert Targets Min          37.6358\n",
      "trainer/Z Policy Targets Mean        131.688\n",
      "trainer/Z Policy Targets Std          40.0601\n",
      "trainer/Z Policy Targets Max         157.437\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  28.0803\n",
      "trainer/Log Pis Std                   19.185\n",
      "trainer/Policy mu Mean                 0.390579\n",
      "trainer/Policy mu Std                  2.03148\n",
      "trainer/Policy log std Mean           -0.751639\n",
      "trainer/Policy log std Std             0.29621\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        15477\n",
      "exploration/num paths total          538\n",
      "evaluation/num steps total          3417\n",
      "evaluation/num paths total            60\n",
      "evaluation/path length Mean           81.1\n",
      "evaluation/path length Std            11.7512\n",
      "evaluation/path length Max           102\n",
      "evaluation/path length Min            69\n",
      "evaluation/Rewards Mean                5.09069\n",
      "evaluation/Rewards Std                 0.215802\n",
      "evaluation/Rewards Max                 5.85628\n",
      "evaluation/Rewards Min                 4.76519\n",
      "evaluation/Returns Mean              412.855\n",
      "evaluation/Returns Std                53.748\n",
      "evaluation/Returns Max               508.717\n",
      "evaluation/Returns Min               357.262\n",
      "evaluation/Estimation Bias Mean      144.493\n",
      "evaluation/Estimation Bias Std        71.6459\n",
      "evaluation/EB/Q_True Mean             23.9017\n",
      "evaluation/EB/Q_True Std              70.6341\n",
      "evaluation/EB/Q_Pred Mean            168.394\n",
      "evaluation/EB/Q_Pred Std              11.819\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           412.855\n",
      "evaluation/Actions Mean                0.220542\n",
      "evaluation/Actions Std                 0.81242\n",
      "evaluation/Actions Max                 0.999992\n",
      "evaluation/Actions Min                -0.999791\n",
      "time/backward_policy (s)               1.74259\n",
      "time/backward_zf1 (s)                  2.11234\n",
      "time/backward_zf2 (s)                  2.06201\n",
      "time/data sampling (s)                 0.26792\n",
      "time/data storing (s)                  0.0144848\n",
      "time/evaluation sampling (s)           0.398596\n",
      "time/exploration sampling (s)          0.488261\n",
      "time/logging (s)                       0.00350824\n",
      "time/preback_alpha (s)                 0.543158\n",
      "time/preback_policy (s)                1.01523\n",
      "time/preback_start (s)                 0.162474\n",
      "time/preback_zf (s)                    6.53567\n",
      "time/saving (s)                        3.7e-06\n",
      "time/training (s)                      3.48365\n",
      "time/epoch (s)                        18.8299\n",
      "time/total (s)                       122.259\n",
      "Epoch                                  5\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:27:39.978492 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 6 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 17000\n",
      "trainer/ZF1 Loss                       2.94645\n",
      "trainer/ZF2 Loss                       2.78416\n",
      "trainer/ZF Expert Reward              11.841\n",
      "trainer/ZF Policy Reward               5.56701\n",
      "trainer/ZF CHI2 Term                  12.8925\n",
      "trainer/Policy Loss                 -159.069\n",
      "trainer/Bias Loss                      7.34682\n",
      "trainer/Bias Value                    10.48\n",
      "trainer/Policy Grad Norm               7.55106\n",
      "trainer/Policy Param Norm             22.0806\n",
      "trainer/Zf1 Grad Norm                771.275\n",
      "trainer/Zf1 Param Norm                44.4243\n",
      "trainer/Zf2 Grad Norm                846.54\n",
      "trainer/Zf2 Param Norm                43.8922\n",
      "trainer/Z Expert Predictions Mean    183.295\n",
      "trainer/Z Expert Predictions Std       9.3506\n",
      "trainer/Z Expert Predictions Max     196.861\n",
      "trainer/Z Expert Predictions Min     137.254\n",
      "trainer/Z Policy Predictions Mean    153.828\n",
      "trainer/Z Policy Predictions Std      47.105\n",
      "trainer/Z Policy Predictions Max     187.542\n",
      "trainer/Z Policy Predictions Min       2.11718\n",
      "trainer/Z Expert Targets Mean        171.454\n",
      "trainer/Z Expert Targets Std          10.8473\n",
      "trainer/Z Expert Targets Max         189.193\n",
      "trainer/Z Expert Targets Min         112.688\n",
      "trainer/Z Policy Targets Mean        148.261\n",
      "trainer/Z Policy Targets Std          47.9221\n",
      "trainer/Z Policy Targets Max         183.008\n",
      "trainer/Z Policy Targets Min          -0.440609\n",
      "trainer/Log Pis Mean                  32.6411\n",
      "trainer/Log Pis Std                   18.0512\n",
      "trainer/Policy mu Mean                 0.488318\n",
      "trainer/Policy mu Std                  2.17622\n",
      "trainer/Policy log std Mean           -0.768468\n",
      "trainer/Policy log std Std             0.337048\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        16848\n",
      "exploration/num paths total          560\n",
      "evaluation/num steps total          4102\n",
      "evaluation/num paths total            70\n",
      "evaluation/path length Mean           68.5\n",
      "evaluation/path length Std             7.5\n",
      "evaluation/path length Max            84\n",
      "evaluation/path length Min            57\n",
      "evaluation/Rewards Mean                4.672\n",
      "evaluation/Rewards Std                 0.220288\n",
      "evaluation/Rewards Max                 5.13544\n",
      "evaluation/Rewards Min                 3.52453\n",
      "evaluation/Returns Mean              320.032\n",
      "evaluation/Returns Std                33.5931\n",
      "evaluation/Returns Max               368.012\n",
      "evaluation/Returns Min               256.559\n",
      "evaluation/Estimation Bias Mean      180.047\n",
      "evaluation/Estimation Bias Std        56.8146\n",
      "evaluation/EB/Q_True Mean             17.0209\n",
      "evaluation/EB/Q_True Std              52.3121\n",
      "evaluation/EB/Q_Pred Mean            197.068\n",
      "evaluation/EB/Q_Pred Std              25.5436\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           320.032\n",
      "evaluation/Actions Mean                0.353635\n",
      "evaluation/Actions Std                 0.737979\n",
      "evaluation/Actions Max                 0.999995\n",
      "evaluation/Actions Min                -0.99999\n",
      "time/backward_policy (s)               1.80772\n",
      "time/backward_zf1 (s)                  2.16493\n",
      "time/backward_zf2 (s)                  2.13346\n",
      "time/data sampling (s)                 0.275962\n",
      "time/data storing (s)                  0.0149905\n",
      "time/evaluation sampling (s)           0.253549\n",
      "time/exploration sampling (s)          0.534234\n",
      "time/logging (s)                       0.00453083\n",
      "time/preback_alpha (s)                 0.551565\n",
      "time/preback_policy (s)                1.09579\n",
      "time/preback_start (s)                 0.166374\n",
      "time/preback_zf (s)                    6.57701\n",
      "time/saving (s)                        4.149e-06\n",
      "time/training (s)                      3.26686\n",
      "time/epoch (s)                        18.847\n",
      "time/total (s)                       141.14\n",
      "Epoch                                  6\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:27:58.718317 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 7 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 18000\n",
      "trainer/ZF1 Loss                      12.7721\n",
      "trainer/ZF2 Loss                      14.2683\n",
      "trainer/ZF Expert Reward              12.9635\n",
      "trainer/ZF Policy Reward               7.20912\n",
      "trainer/ZF CHI2 Term                  24.288\n",
      "trainer/Policy Loss                 -180.246\n",
      "trainer/Bias Loss                      7.00829\n",
      "trainer/Bias Value                    10.5679\n",
      "trainer/Policy Grad Norm               7.84821\n",
      "trainer/Policy Param Norm             22.5542\n",
      "trainer/Zf1 Grad Norm               2121.52\n",
      "trainer/Zf1 Param Norm                45.634\n",
      "trainer/Zf2 Grad Norm               2027.58\n",
      "trainer/Zf2 Param Norm                45.1135\n",
      "trainer/Z Expert Predictions Mean    222.242\n",
      "trainer/Z Expert Predictions Std       4.07043\n",
      "trainer/Z Expert Predictions Max     228.136\n",
      "trainer/Z Expert Predictions Min     199.35\n",
      "trainer/Z Policy Predictions Mean    175.32\n",
      "trainer/Z Policy Predictions Std      51.7102\n",
      "trainer/Z Policy Predictions Max     212.625\n",
      "trainer/Z Policy Predictions Min       1.23584\n",
      "trainer/Z Expert Targets Mean        209.279\n",
      "trainer/Z Expert Targets Std           5.38503\n",
      "trainer/Z Expert Targets Max         218.424\n",
      "trainer/Z Expert Targets Min         187.551\n",
      "trainer/Z Policy Targets Mean        168.111\n",
      "trainer/Z Policy Targets Std          53.4738\n",
      "trainer/Z Policy Targets Max         207.159\n",
      "trainer/Z Policy Targets Min          -1.82164\n",
      "trainer/Log Pis Mean                  36.892\n",
      "trainer/Log Pis Std                   17.6606\n",
      "trainer/Policy mu Mean                 0.495036\n",
      "trainer/Policy mu Std                  2.33709\n",
      "trainer/Policy log std Mean           -0.79385\n",
      "trainer/Policy log std Std             0.36317\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        17805\n",
      "exploration/num paths total          577\n",
      "evaluation/num steps total          4593\n",
      "evaluation/num paths total            80\n",
      "evaluation/path length Mean           49.1\n",
      "evaluation/path length Std             1.81384\n",
      "evaluation/path length Max            53\n",
      "evaluation/path length Min            46\n",
      "evaluation/Rewards Mean                4.93382\n",
      "evaluation/Rewards Std                 0.101245\n",
      "evaluation/Rewards Max                 5.26507\n",
      "evaluation/Rewards Min                 4.71613\n",
      "evaluation/Returns Mean              242.251\n",
      "evaluation/Returns Std                11.2716\n",
      "evaluation/Returns Max               264.82\n",
      "evaluation/Returns Min               223.94\n",
      "evaluation/Estimation Bias Mean      208.667\n",
      "evaluation/Estimation Bias Std        43.8118\n",
      "evaluation/EB/Q_True Mean             12.4293\n",
      "evaluation/EB/Q_True Std              40.6971\n",
      "evaluation/EB/Q_Pred Mean            221.096\n",
      "evaluation/EB/Q_Pred Std              19.9632\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           242.251\n",
      "evaluation/Actions Mean                0.211634\n",
      "evaluation/Actions Std                 0.729972\n",
      "evaluation/Actions Max                 0.999996\n",
      "evaluation/Actions Min                -0.999837\n",
      "time/backward_policy (s)               1.74294\n",
      "time/backward_zf1 (s)                  2.12374\n",
      "time/backward_zf2 (s)                  2.06359\n",
      "time/data sampling (s)                 0.274141\n",
      "time/data storing (s)                  0.0141767\n",
      "time/evaluation sampling (s)           0.154056\n",
      "time/exploration sampling (s)          0.525406\n",
      "time/logging (s)                       0.00373383\n",
      "time/preback_alpha (s)                 0.546807\n",
      "time/preback_policy (s)                1.00673\n",
      "time/preback_start (s)                 0.163999\n",
      "time/preback_zf (s)                    6.55762\n",
      "time/saving (s)                        4.3e-06\n",
      "time/training (s)                      3.49665\n",
      "time/epoch (s)                        18.6736\n",
      "time/total (s)                       159.835\n",
      "Epoch                                  7\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:28:17.626149 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 8 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 19000\n",
      "trainer/ZF1 Loss                      32.9582\n",
      "trainer/ZF2 Loss                      21.8093\n",
      "trainer/ZF Expert Reward              12.2161\n",
      "trainer/ZF Policy Reward               6.77774\n",
      "trainer/ZF CHI2 Term                  37.2039\n",
      "trainer/Policy Loss                 -194.446\n",
      "trainer/Bias Loss                      6.24592\n",
      "trainer/Bias Value                    10.662\n",
      "trainer/Policy Grad Norm              10.4917\n",
      "trainer/Policy Param Norm             23.0295\n",
      "trainer/Zf1 Grad Norm               2334.78\n",
      "trainer/Zf1 Param Norm                46.8148\n",
      "trainer/Zf2 Grad Norm               2967.26\n",
      "trainer/Zf2 Param Norm                46.2767\n",
      "trainer/Z Expert Predictions Mean    245.198\n",
      "trainer/Z Expert Predictions Std      17.0554\n",
      "trainer/Z Expert Predictions Max     257.844\n",
      "trainer/Z Expert Predictions Min      18.5128\n",
      "trainer/Z Policy Predictions Mean    190.444\n",
      "trainer/Z Policy Predictions Std      66.0073\n",
      "trainer/Z Policy Predictions Max     237.951\n",
      "trainer/Z Policy Predictions Min       1.89079\n",
      "trainer/Z Expert Targets Mean        232.982\n",
      "trainer/Z Expert Targets Std          18.1065\n",
      "trainer/Z Expert Targets Max         248.744\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        183.667\n",
      "trainer/Z Policy Targets Std          68.12\n",
      "trainer/Z Policy Targets Max         234.902\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  39.7232\n",
      "trainer/Log Pis Std                   21.0778\n",
      "trainer/Policy mu Mean                 0.320272\n",
      "trainer/Policy mu Std                  2.47894\n",
      "trainer/Policy log std Mean           -0.901797\n",
      "trainer/Policy log std Std             0.386213\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        18566\n",
      "exploration/num paths total          590\n",
      "evaluation/num steps total          5310\n",
      "evaluation/num paths total            90\n",
      "evaluation/path length Mean           71.7\n",
      "evaluation/path length Std             7.22565\n",
      "evaluation/path length Max            86\n",
      "evaluation/path length Min            59\n",
      "evaluation/Rewards Mean                4.76303\n",
      "evaluation/Rewards Std                 0.238067\n",
      "evaluation/Rewards Max                 5.94828\n",
      "evaluation/Rewards Min                 4.07398\n",
      "evaluation/Returns Mean              341.51\n",
      "evaluation/Returns Std                34.4077\n",
      "evaluation/Returns Max               400.087\n",
      "evaluation/Returns Min               277.304\n",
      "evaluation/Estimation Bias Mean      220.965\n",
      "evaluation/Estimation Bias Std        65.0439\n",
      "evaluation/EB/Q_True Mean             18.1808\n",
      "evaluation/EB/Q_True Std              56.276\n",
      "evaluation/EB/Q_Pred Mean            239.146\n",
      "evaluation/EB/Q_Pred Std              31.867\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           341.51\n",
      "evaluation/Actions Mean                0.147696\n",
      "evaluation/Actions Std                 0.743526\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999998\n",
      "time/backward_policy (s)               1.8696\n",
      "time/backward_zf1 (s)                  2.24892\n",
      "time/backward_zf2 (s)                  2.20785\n",
      "time/data sampling (s)                 0.277468\n",
      "time/data storing (s)                  0.0141516\n",
      "time/evaluation sampling (s)           0.244712\n",
      "time/exploration sampling (s)          0.48239\n",
      "time/logging (s)                       0.00226829\n",
      "time/preback_alpha (s)                 0.54778\n",
      "time/preback_policy (s)                1.14824\n",
      "time/preback_start (s)                 0.16524\n",
      "time/preback_zf (s)                    6.56444\n",
      "time/saving (s)                        3.45e-06\n",
      "time/training (s)                      3.06821\n",
      "time/epoch (s)                        18.8413\n",
      "time/total (s)                       178.698\n",
      "Epoch                                  8\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:28:36.527768 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 9 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 20000\n",
      "trainer/ZF1 Loss                      24.3315\n",
      "trainer/ZF2 Loss                      19.1736\n",
      "trainer/ZF Expert Reward              13.3118\n",
      "trainer/ZF Policy Reward               7.13909\n",
      "trainer/ZF CHI2 Term                  32.6501\n",
      "trainer/Policy Loss                 -213.947\n",
      "trainer/Bias Loss                     28.2523\n",
      "trainer/Bias Value                    10.7559\n",
      "trainer/Policy Grad Norm              13.8629\n",
      "trainer/Policy Param Norm             23.5327\n",
      "trainer/Zf1 Grad Norm               3390.82\n",
      "trainer/Zf1 Param Norm                47.7851\n",
      "trainer/Zf2 Grad Norm               2920.09\n",
      "trainer/Zf2 Param Norm                47.2592\n",
      "trainer/Z Expert Predictions Mean    251.099\n",
      "trainer/Z Expert Predictions Std      20.9298\n",
      "trainer/Z Expert Predictions Max     280.309\n",
      "trainer/Z Expert Predictions Min      99.9885\n",
      "trainer/Z Policy Predictions Mean    207.439\n",
      "trainer/Z Policy Predictions Std      71.014\n",
      "trainer/Z Policy Predictions Max     260.418\n",
      "trainer/Z Policy Predictions Min       0.833137\n",
      "trainer/Z Expert Targets Mean        237.788\n",
      "trainer/Z Expert Targets Std          24.1639\n",
      "trainer/Z Expert Targets Max         273.254\n",
      "trainer/Z Expert Targets Min          87.9845\n",
      "trainer/Z Policy Targets Mean        200.3\n",
      "trainer/Z Policy Targets Std          73.644\n",
      "trainer/Z Policy Targets Max         254.68\n",
      "trainer/Z Policy Targets Min          -2.7802\n",
      "trainer/Log Pis Mean                  39.5859\n",
      "trainer/Log Pis Std                   22.5836\n",
      "trainer/Policy mu Mean                 0.219148\n",
      "trainer/Policy mu Std                  2.48046\n",
      "trainer/Policy log std Mean           -0.924944\n",
      "trainer/Policy log std Std             0.42894\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        19506\n",
      "exploration/num paths total          602\n",
      "evaluation/num steps total          5909\n",
      "evaluation/num paths total           100\n",
      "evaluation/path length Mean           59.9\n",
      "evaluation/path length Std             2.73679\n",
      "evaluation/path length Max            63\n",
      "evaluation/path length Min            55\n",
      "evaluation/Rewards Mean                5.31307\n",
      "evaluation/Rewards Std                 0.351968\n",
      "evaluation/Rewards Max                 6.29191\n",
      "evaluation/Rewards Min                 4.77471\n",
      "evaluation/Returns Mean              318.253\n",
      "evaluation/Returns Std                16.0819\n",
      "evaluation/Returns Max               338.331\n",
      "evaluation/Returns Min               288.211\n",
      "evaluation/Estimation Bias Mean      240.887\n",
      "evaluation/Estimation Bias Std        51.1329\n",
      "evaluation/EB/Q_True Mean             14.8352\n",
      "evaluation/EB/Q_True Std              48.7168\n",
      "evaluation/EB/Q_Pred Mean            255.723\n",
      "evaluation/EB/Q_Pred Std              20.7041\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           318.253\n",
      "evaluation/Actions Mean                0.188218\n",
      "evaluation/Actions Std                 0.75953\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999991\n",
      "time/backward_policy (s)               1.91568\n",
      "time/backward_zf1 (s)                  2.29079\n",
      "time/backward_zf2 (s)                  2.2652\n",
      "time/data sampling (s)                 0.282128\n",
      "time/data storing (s)                  0.0141768\n",
      "time/evaluation sampling (s)           0.194491\n",
      "time/exploration sampling (s)          0.462571\n",
      "time/logging (s)                       0.00230456\n",
      "time/preback_alpha (s)                 0.549448\n",
      "time/preback_policy (s)                1.1893\n",
      "time/preback_start (s)                 0.165765\n",
      "time/preback_zf (s)                    6.55346\n",
      "time/saving (s)                        2.543e-06\n",
      "time/training (s)                      2.95397\n",
      "time/epoch (s)                        18.8393\n",
      "time/total (s)                       197.555\n",
      "Epoch                                  9\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:28:55.971507 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 10 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 21000\n",
      "trainer/ZF1 Loss                      15.0708\n",
      "trainer/ZF2 Loss                      21.986\n",
      "trainer/ZF Expert Reward              11.249\n",
      "trainer/ZF Policy Reward               5.4791\n",
      "trainer/ZF CHI2 Term                  27.1837\n",
      "trainer/Policy Loss                 -230.641\n",
      "trainer/Bias Loss                     14.6029\n",
      "trainer/Bias Value                    10.841\n",
      "trainer/Policy Grad Norm              17.0384\n",
      "trainer/Policy Param Norm             23.9935\n",
      "trainer/Zf1 Grad Norm               1664.34\n",
      "trainer/Zf1 Param Norm                48.6133\n",
      "trainer/Zf2 Grad Norm               2266.01\n",
      "trainer/Zf2 Param Norm                48.1371\n",
      "trainer/Z Expert Predictions Mean    254.842\n",
      "trainer/Z Expert Predictions Std      27.6304\n",
      "trainer/Z Expert Predictions Max     294.243\n",
      "trainer/Z Expert Predictions Min      48.7089\n",
      "trainer/Z Policy Predictions Mean    222.252\n",
      "trainer/Z Policy Predictions Std      74.4926\n",
      "trainer/Z Policy Predictions Max     275.313\n",
      "trainer/Z Policy Predictions Min       1.3118\n",
      "trainer/Z Expert Targets Mean        243.593\n",
      "trainer/Z Expert Targets Std          27.6756\n",
      "trainer/Z Expert Targets Max         287.064\n",
      "trainer/Z Expert Targets Min          37.8962\n",
      "trainer/Z Policy Targets Mean        216.773\n",
      "trainer/Z Policy Targets Std          76.2337\n",
      "trainer/Z Policy Targets Max         272.264\n",
      "trainer/Z Policy Targets Min          -3.58571\n",
      "trainer/Log Pis Mean                  38.489\n",
      "trainer/Log Pis Std                   23.5496\n",
      "trainer/Policy mu Mean                 0.244109\n",
      "trainer/Policy mu Std                  2.41009\n",
      "trainer/Policy log std Mean           -1.00997\n",
      "trainer/Policy log std Std             0.429328\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        20765\n",
      "exploration/num paths total          619\n",
      "evaluation/num steps total          6879\n",
      "evaluation/num paths total           110\n",
      "evaluation/path length Mean           97\n",
      "evaluation/path length Std            12.1573\n",
      "evaluation/path length Max           124\n",
      "evaluation/path length Min            88\n",
      "evaluation/Rewards Mean                5.07796\n",
      "evaluation/Rewards Std                 0.309048\n",
      "evaluation/Rewards Max                 6.04245\n",
      "evaluation/Rewards Min                 4.56088\n",
      "evaluation/Returns Mean              492.562\n",
      "evaluation/Returns Std                69.4946\n",
      "evaluation/Returns Max               637.273\n",
      "evaluation/Returns Min               430.255\n",
      "evaluation/Estimation Bias Mean      229.43\n",
      "evaluation/Estimation Bias Std       101.19\n",
      "evaluation/EB/Q_True Mean             28.9821\n",
      "evaluation/EB/Q_True Std              83.8172\n",
      "evaluation/EB/Q_Pred Mean            258.412\n",
      "evaluation/EB/Q_Pred Std              64.0684\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           492.562\n",
      "evaluation/Actions Mean                0.193499\n",
      "evaluation/Actions Std                 0.756369\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.96481\n",
      "time/backward_zf1 (s)                  2.35688\n",
      "time/backward_zf2 (s)                  2.33676\n",
      "time/data sampling (s)                 0.288839\n",
      "time/data storing (s)                  0.0150269\n",
      "time/evaluation sampling (s)           0.311475\n",
      "time/exploration sampling (s)          0.530153\n",
      "time/logging (s)                       0.00277801\n",
      "time/preback_alpha (s)                 0.56492\n",
      "time/preback_policy (s)                1.20513\n",
      "time/preback_start (s)                 0.170516\n",
      "time/preback_zf (s)                    6.61596\n",
      "time/saving (s)                        3.005e-06\n",
      "time/training (s)                      3.01211\n",
      "time/epoch (s)                        19.3754\n",
      "time/total (s)                       216.955\n",
      "Epoch                                 10\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:29:14.905384 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 11 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 22000\n",
      "trainer/ZF1 Loss                      12.8612\n",
      "trainer/ZF2 Loss                      13.5979\n",
      "trainer/ZF Expert Reward              12.5227\n",
      "trainer/ZF Policy Reward               4.66748\n",
      "trainer/ZF CHI2 Term                  22.813\n",
      "trainer/Policy Loss                 -237.954\n",
      "trainer/Bias Loss                     12.1821\n",
      "trainer/Bias Value                    10.9177\n",
      "trainer/Policy Grad Norm              14.1943\n",
      "trainer/Policy Param Norm             24.3664\n",
      "trainer/Zf1 Grad Norm               1834.95\n",
      "trainer/Zf1 Param Norm                49.4058\n",
      "trainer/Zf2 Grad Norm               2076.18\n",
      "trainer/Zf2 Param Norm                48.8974\n",
      "trainer/Z Expert Predictions Mean    296.367\n",
      "trainer/Z Expert Predictions Std      16.3004\n",
      "trainer/Z Expert Predictions Max     312.941\n",
      "trainer/Z Expert Predictions Min     186.212\n",
      "trainer/Z Policy Predictions Mean    229.35\n",
      "trainer/Z Policy Predictions Std      85.7767\n",
      "trainer/Z Policy Predictions Max     290.761\n",
      "trainer/Z Policy Predictions Min      -0.422558\n",
      "trainer/Z Expert Targets Mean        283.844\n",
      "trainer/Z Expert Targets Std          17.2268\n",
      "trainer/Z Expert Targets Max         305.784\n",
      "trainer/Z Expert Targets Min         152.996\n",
      "trainer/Z Policy Targets Mean        224.683\n",
      "trainer/Z Policy Targets Std          84.7558\n",
      "trainer/Z Policy Targets Max         287.382\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  41.0653\n",
      "trainer/Log Pis Std                   27.028\n",
      "trainer/Policy mu Mean                 0.28101\n",
      "trainer/Policy mu Std                  2.59445\n",
      "trainer/Policy log std Mean           -0.921028\n",
      "trainer/Policy log std Std             0.428994\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        21553\n",
      "exploration/num paths total          630\n",
      "evaluation/num steps total          7475\n",
      "evaluation/num paths total           120\n",
      "evaluation/path length Mean           59.6\n",
      "evaluation/path length Std             3.58329\n",
      "evaluation/path length Max            66\n",
      "evaluation/path length Min            55\n",
      "evaluation/Rewards Mean                4.86049\n",
      "evaluation/Rewards Std                 0.262982\n",
      "evaluation/Rewards Max                 5.32056\n",
      "evaluation/Rewards Min                 3.7769\n",
      "evaluation/Returns Mean              289.685\n",
      "evaluation/Returns Std                11.3972\n",
      "evaluation/Returns Max               307.955\n",
      "evaluation/Returns Min               270.202\n",
      "evaluation/Estimation Bias Mean      230.297\n",
      "evaluation/Estimation Bias Std       102.962\n",
      "evaluation/EB/Q_True Mean             13.0763\n",
      "evaluation/EB/Q_True Std              42.8831\n",
      "evaluation/EB/Q_Pred Mean            243.374\n",
      "evaluation/EB/Q_Pred Std              96.8208\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           289.685\n",
      "evaluation/Actions Mean                0.162825\n",
      "evaluation/Actions Std                 0.782741\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.77564\n",
      "time/backward_zf1 (s)                  2.14554\n",
      "time/backward_zf2 (s)                  2.10128\n",
      "time/data sampling (s)                 0.27843\n",
      "time/data storing (s)                  0.014318\n",
      "time/evaluation sampling (s)           0.171524\n",
      "time/exploration sampling (s)          0.529251\n",
      "time/logging (s)                       0.00252611\n",
      "time/preback_alpha (s)                 0.552313\n",
      "time/preback_policy (s)                1.01926\n",
      "time/preback_start (s)                 0.165577\n",
      "time/preback_zf (s)                    6.587\n",
      "time/saving (s)                        3.493e-06\n",
      "time/training (s)                      3.52817\n",
      "time/epoch (s)                        18.8708\n",
      "time/total (s)                       235.845\n",
      "Epoch                                 11\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:29:33.732573 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 12 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 23000\n",
      "trainer/ZF1 Loss                      14.3091\n",
      "trainer/ZF2 Loss                      11.9467\n",
      "trainer/ZF Expert Reward              13.225\n",
      "trainer/ZF Policy Reward               7.53477\n",
      "trainer/ZF CHI2 Term                  23.2292\n",
      "trainer/Policy Loss                 -247.93\n",
      "trainer/Bias Loss                     15.0152\n",
      "trainer/Bias Value                    10.9997\n",
      "trainer/Policy Grad Norm              21.1408\n",
      "trainer/Policy Param Norm             24.6918\n",
      "trainer/Zf1 Grad Norm               2127.24\n",
      "trainer/Zf1 Param Norm                50.1893\n",
      "trainer/Zf2 Grad Norm               1562.76\n",
      "trainer/Zf2 Param Norm                49.6255\n",
      "trainer/Z Expert Predictions Mean    318.062\n",
      "trainer/Z Expert Predictions Std      17.3465\n",
      "trainer/Z Expert Predictions Max     338.225\n",
      "trainer/Z Expert Predictions Min     206.651\n",
      "trainer/Z Policy Predictions Mean    239.129\n",
      "trainer/Z Policy Predictions Std      96.0531\n",
      "trainer/Z Policy Predictions Max     311.967\n",
      "trainer/Z Policy Predictions Min       4.79216\n",
      "trainer/Z Expert Targets Mean        304.837\n",
      "trainer/Z Expert Targets Std          18.0326\n",
      "trainer/Z Expert Targets Max         328.404\n",
      "trainer/Z Expert Targets Min         202.877\n",
      "trainer/Z Policy Targets Mean        231.594\n",
      "trainer/Z Policy Targets Std          97.3\n",
      "trainer/Z Policy Targets Max         304.034\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  41.7077\n",
      "trainer/Log Pis Std                   26.2051\n",
      "trainer/Policy mu Mean                 0.366735\n",
      "trainer/Policy mu Std                  2.57089\n",
      "trainer/Policy log std Mean           -1.02516\n",
      "trainer/Policy log std Std             0.418586\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        22693\n",
      "exploration/num paths total          646\n",
      "evaluation/num steps total          8171\n",
      "evaluation/num paths total           130\n",
      "evaluation/path length Mean           69.6\n",
      "evaluation/path length Std             9.7591\n",
      "evaluation/path length Max            88\n",
      "evaluation/path length Min            50\n",
      "evaluation/Rewards Mean                4.46039\n",
      "evaluation/Rewards Std                 0.387709\n",
      "evaluation/Rewards Max                 5.77942\n",
      "evaluation/Rewards Min                 3.33042\n",
      "evaluation/Returns Mean              310.443\n",
      "evaluation/Returns Std                52.0317\n",
      "evaluation/Returns Max               436.574\n",
      "evaluation/Returns Min               224.141\n",
      "evaluation/Estimation Bias Mean      268.188\n",
      "evaluation/Estimation Bias Std        85.2316\n",
      "evaluation/EB/Q_True Mean             21.9798\n",
      "evaluation/EB/Q_True Std              64.216\n",
      "evaluation/EB/Q_Pred Mean            290.168\n",
      "evaluation/EB/Q_Pred Std              64.3237\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           310.443\n",
      "evaluation/Actions Mean                0.144173\n",
      "evaluation/Actions Std                 0.749582\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.85\n",
      "time/backward_zf1 (s)                  2.23164\n",
      "time/backward_zf2 (s)                  2.18102\n",
      "time/data sampling (s)                 0.277451\n",
      "time/data storing (s)                  0.0143564\n",
      "time/evaluation sampling (s)           0.227361\n",
      "time/exploration sampling (s)          0.467589\n",
      "time/logging (s)                       0.00253963\n",
      "time/preback_alpha (s)                 0.54854\n",
      "time/preback_policy (s)                1.1359\n",
      "time/preback_start (s)                 0.16483\n",
      "time/preback_zf (s)                    6.5733\n",
      "time/saving (s)                        3.474e-06\n",
      "time/training (s)                      3.08902\n",
      "time/epoch (s)                        18.7635\n",
      "time/total (s)                       254.628\n",
      "Epoch                                 12\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:29:52.560510 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 13 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 24000\n",
      "trainer/ZF1 Loss                      19.2679\n",
      "trainer/ZF2 Loss                      15.9744\n",
      "trainer/ZF Expert Reward              13.1117\n",
      "trainer/ZF Policy Reward               5.70558\n",
      "trainer/ZF CHI2 Term                  27.4196\n",
      "trainer/Policy Loss                 -263.799\n",
      "trainer/Bias Loss                     19.3713\n",
      "trainer/Bias Value                    11.085\n",
      "trainer/Policy Grad Norm              21.6414\n",
      "trainer/Policy Param Norm             25.0381\n",
      "trainer/Zf1 Grad Norm               2722.96\n",
      "trainer/Zf1 Param Norm                50.9778\n",
      "trainer/Zf2 Grad Norm               1651.02\n",
      "trainer/Zf2 Param Norm                50.375\n",
      "trainer/Z Expert Predictions Mean    337.132\n",
      "trainer/Z Expert Predictions Std      21.4598\n",
      "trainer/Z Expert Predictions Max     362.53\n",
      "trainer/Z Expert Predictions Min     245.398\n",
      "trainer/Z Policy Predictions Mean    257.257\n",
      "trainer/Z Policy Predictions Std      95.1236\n",
      "trainer/Z Policy Predictions Max     323.087\n",
      "trainer/Z Policy Predictions Min      -3.51802\n",
      "trainer/Z Expert Targets Mean        324.02\n",
      "trainer/Z Expert Targets Std          22.4764\n",
      "trainer/Z Expert Targets Max         351.199\n",
      "trainer/Z Expert Targets Min         243.731\n",
      "trainer/Z Policy Targets Mean        251.552\n",
      "trainer/Z Policy Targets Std          96.0071\n",
      "trainer/Z Policy Targets Max         320.942\n",
      "trainer/Z Policy Targets Min          -1.09598\n",
      "trainer/Log Pis Mean                  39.7078\n",
      "trainer/Log Pis Std                   20.7164\n",
      "trainer/Policy mu Mean                 0.325009\n",
      "trainer/Policy mu Std                  2.44402\n",
      "trainer/Policy log std Mean           -1.03791\n",
      "trainer/Policy log std Std             0.434829\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        23657\n",
      "exploration/num paths total          658\n",
      "evaluation/num steps total          8707\n",
      "evaluation/num paths total           140\n",
      "evaluation/path length Mean           53.6\n",
      "evaluation/path length Std             8.01499\n",
      "evaluation/path length Max            68\n",
      "evaluation/path length Min            43\n",
      "evaluation/Rewards Mean                4.82441\n",
      "evaluation/Rewards Std                 0.286102\n",
      "evaluation/Rewards Max                 5.31047\n",
      "evaluation/Rewards Min                 3.91413\n",
      "evaluation/Returns Mean              258.588\n",
      "evaluation/Returns Std                39.6301\n",
      "evaluation/Returns Max               331.88\n",
      "evaluation/Returns Min               207.384\n",
      "evaluation/Estimation Bias Mean      241.319\n",
      "evaluation/Estimation Bias Std       105.984\n",
      "evaluation/EB/Q_True Mean             16.9486\n",
      "evaluation/EB/Q_True Std              51.285\n",
      "evaluation/EB/Q_Pred Mean            258.268\n",
      "evaluation/EB/Q_Pred Std              98.6142\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           258.588\n",
      "evaluation/Actions Mean                0.0251043\n",
      "evaluation/Actions Std                 0.822974\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.86456\n",
      "time/backward_zf1 (s)                  2.21975\n",
      "time/backward_zf2 (s)                  2.18372\n",
      "time/data sampling (s)                 0.277435\n",
      "time/data storing (s)                  0.0143483\n",
      "time/evaluation sampling (s)           0.217833\n",
      "time/exploration sampling (s)          0.455698\n",
      "time/logging (s)                       0.00231627\n",
      "time/preback_alpha (s)                 0.54803\n",
      "time/preback_policy (s)                1.13112\n",
      "time/preback_start (s)                 0.165608\n",
      "time/preback_zf (s)                    6.56634\n",
      "time/saving (s)                        3.935e-06\n",
      "time/training (s)                      3.12172\n",
      "time/epoch (s)                        18.7685\n",
      "time/total (s)                       273.412\n",
      "Epoch                                 13\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:30:11.433586 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 14 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 25000\n",
      "trainer/ZF1 Loss                      26.6771\n",
      "trainer/ZF2 Loss                      33.6063\n",
      "trainer/ZF Expert Reward              14.9805\n",
      "trainer/ZF Policy Reward               3.54085\n",
      "trainer/ZF CHI2 Term                  41.7595\n",
      "trainer/Policy Loss                 -272.317\n",
      "trainer/Bias Loss                     38.7047\n",
      "trainer/Bias Value                    11.1656\n",
      "trainer/Policy Grad Norm              18.4877\n",
      "trainer/Policy Param Norm             25.4161\n",
      "trainer/Zf1 Grad Norm               3701.77\n",
      "trainer/Zf1 Param Norm                51.7759\n",
      "trainer/Zf2 Grad Norm               4256.45\n",
      "trainer/Zf2 Param Norm                51.1437\n",
      "trainer/Z Expert Predictions Mean    337.437\n",
      "trainer/Z Expert Predictions Std      36.1495\n",
      "trainer/Z Expert Predictions Max     379.365\n",
      "trainer/Z Expert Predictions Min     186.067\n",
      "trainer/Z Policy Predictions Mean    265.337\n",
      "trainer/Z Policy Predictions Std     102.633\n",
      "trainer/Z Policy Predictions Max     344.628\n",
      "trainer/Z Policy Predictions Min       2.23157\n",
      "trainer/Z Expert Targets Mean        322.456\n",
      "trainer/Z Expert Targets Std          39.477\n",
      "trainer/Z Expert Targets Max         373.051\n",
      "trainer/Z Expert Targets Min         167.477\n",
      "trainer/Z Policy Targets Mean        261.796\n",
      "trainer/Z Policy Targets Std         103.375\n",
      "trainer/Z Policy Targets Max         339.682\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  40.9468\n",
      "trainer/Log Pis Std                   22.3485\n",
      "trainer/Policy mu Mean                 0.237609\n",
      "trainer/Policy mu Std                  2.50221\n",
      "trainer/Policy log std Mean           -1.07994\n",
      "trainer/Policy log std Std             0.451221\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        24531\n",
      "exploration/num paths total          670\n",
      "evaluation/num steps total          9476\n",
      "evaluation/num paths total           150\n",
      "evaluation/path length Mean           76.9\n",
      "evaluation/path length Std             5.95735\n",
      "evaluation/path length Max            84\n",
      "evaluation/path length Min            64\n",
      "evaluation/Rewards Mean                5.24972\n",
      "evaluation/Rewards Std                 0.309118\n",
      "evaluation/Rewards Max                 6.4213\n",
      "evaluation/Rewards Min                 4.80442\n",
      "evaluation/Returns Mean              403.704\n",
      "evaluation/Returns Std                29.2327\n",
      "evaluation/Returns Max               437.427\n",
      "evaluation/Returns Min               336.263\n",
      "evaluation/Estimation Bias Mean      250.547\n",
      "evaluation/Estimation Bias Std       127.577\n",
      "evaluation/EB/Q_True Mean             18.975\n",
      "evaluation/EB/Q_True Std              60.7118\n",
      "evaluation/EB/Q_Pred Mean            269.522\n",
      "evaluation/EB/Q_Pred Std             119.365\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           403.704\n",
      "evaluation/Actions Mean                0.0545853\n",
      "evaluation/Actions Std                 0.803951\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.85669\n",
      "time/backward_zf1 (s)                  2.23006\n",
      "time/backward_zf2 (s)                  2.19209\n",
      "time/data sampling (s)                 0.279248\n",
      "time/data storing (s)                  0.0142316\n",
      "time/evaluation sampling (s)           0.20984\n",
      "time/exploration sampling (s)          0.458541\n",
      "time/logging (s)                       0.00190587\n",
      "time/preback_alpha (s)                 0.552165\n",
      "time/preback_policy (s)                1.11913\n",
      "time/preback_start (s)                 0.165504\n",
      "time/preback_zf (s)                    6.56621\n",
      "time/saving (s)                        7.487e-06\n",
      "time/training (s)                      3.16467\n",
      "time/epoch (s)                        18.8103\n",
      "time/total (s)                       292.241\n",
      "Epoch                                 14\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:30:30.263567 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 15 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 26000\n",
      "trainer/ZF1 Loss                      25.6667\n",
      "trainer/ZF2 Loss                      24.5863\n",
      "trainer/ZF Expert Reward              12.6618\n",
      "trainer/ZF Policy Reward               6.52434\n",
      "trainer/ZF CHI2 Term                  34.1218\n",
      "trainer/Policy Loss                 -280.44\n",
      "trainer/Bias Loss                     21.4503\n",
      "trainer/Bias Value                    11.2373\n",
      "trainer/Policy Grad Norm              24.0264\n",
      "trainer/Policy Param Norm             25.7668\n",
      "trainer/Zf1 Grad Norm               2193.48\n",
      "trainer/Zf1 Param Norm                52.4835\n",
      "trainer/Zf2 Grad Norm               2641.42\n",
      "trainer/Zf2 Param Norm                51.8418\n",
      "trainer/Z Expert Predictions Mean    366.973\n",
      "trainer/Z Expert Predictions Std      23.0204\n",
      "trainer/Z Expert Predictions Max     396.245\n",
      "trainer/Z Expert Predictions Min     283.789\n",
      "trainer/Z Policy Predictions Mean    273.568\n",
      "trainer/Z Policy Predictions Std     112.24\n",
      "trainer/Z Policy Predictions Max     366.015\n",
      "trainer/Z Policy Predictions Min      -1.73397\n",
      "trainer/Z Expert Targets Mean        354.311\n",
      "trainer/Z Expert Targets Std          24.4437\n",
      "trainer/Z Expert Targets Max         387.41\n",
      "trainer/Z Expert Targets Min         264.349\n",
      "trainer/Z Policy Targets Mean        267.044\n",
      "trainer/Z Policy Targets Std         113.044\n",
      "trainer/Z Policy Targets Max         362.33\n",
      "trainer/Z Policy Targets Min          -6.86764\n",
      "trainer/Log Pis Mean                  43.0524\n",
      "trainer/Log Pis Std                   26.6311\n",
      "trainer/Policy mu Mean                 0.49599\n",
      "trainer/Policy mu Std                  2.61643\n",
      "trainer/Policy log std Mean           -1.13789\n",
      "trainer/Policy log std Std             0.474666\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        25489\n",
      "exploration/num paths total          681\n",
      "evaluation/num steps total         10046\n",
      "evaluation/num paths total           160\n",
      "evaluation/path length Mean           57\n",
      "evaluation/path length Std            11.619\n",
      "evaluation/path length Max            84\n",
      "evaluation/path length Min            46\n",
      "evaluation/Rewards Mean                4.79047\n",
      "evaluation/Rewards Std                 0.218753\n",
      "evaluation/Rewards Max                 5.31124\n",
      "evaluation/Rewards Min                 3.55826\n",
      "evaluation/Returns Mean              273.057\n",
      "evaluation/Returns Std                55.1617\n",
      "evaluation/Returns Max               398\n",
      "evaluation/Returns Min               222.979\n",
      "evaluation/Estimation Bias Mean      236.07\n",
      "evaluation/Estimation Bias Std       138.747\n",
      "evaluation/EB/Q_True Mean             22.6038\n",
      "evaluation/EB/Q_True Std              62.3434\n",
      "evaluation/EB/Q_Pred Mean            258.674\n",
      "evaluation/EB/Q_Pred Std             128.032\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           273.057\n",
      "evaluation/Actions Mean                0.0404087\n",
      "evaluation/Actions Std                 0.817875\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.83803\n",
      "time/backward_zf1 (s)                  2.20954\n",
      "time/backward_zf2 (s)                  2.16672\n",
      "time/data sampling (s)                 0.277608\n",
      "time/data storing (s)                  0.0141858\n",
      "time/evaluation sampling (s)           0.248062\n",
      "time/exploration sampling (s)          0.458256\n",
      "time/logging (s)                       0.00189762\n",
      "time/preback_alpha (s)                 0.547742\n",
      "time/preback_policy (s)                1.11617\n",
      "time/preback_start (s)                 0.164803\n",
      "time/preback_zf (s)                    6.57163\n",
      "time/saving (s)                        3.932e-06\n",
      "time/training (s)                      3.15238\n",
      "time/epoch (s)                        18.767\n",
      "time/total (s)                       311.027\n",
      "Epoch                                 15\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:30:49.241984 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 16 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 27000\n",
      "trainer/ZF1 Loss                      22.8606\n",
      "trainer/ZF2 Loss                      23.2921\n",
      "trainer/ZF Expert Reward              12.143\n",
      "trainer/ZF Policy Reward               5.84234\n",
      "trainer/ZF CHI2 Term                  31.2535\n",
      "trainer/Policy Loss                 -280.795\n",
      "trainer/Bias Loss                     11.49\n",
      "trainer/Bias Value                    11.3122\n",
      "trainer/Policy Grad Norm              23.896\n",
      "trainer/Policy Param Norm             26.097\n",
      "trainer/Zf1 Grad Norm               2442.49\n",
      "trainer/Zf1 Param Norm                53.2153\n",
      "trainer/Zf2 Grad Norm               2853.14\n",
      "trainer/Zf2 Param Norm                52.5769\n",
      "trainer/Z Expert Predictions Mean    397.597\n",
      "trainer/Z Expert Predictions Std      25.8589\n",
      "trainer/Z Expert Predictions Max     415.474\n",
      "trainer/Z Expert Predictions Min      20.8637\n",
      "trainer/Z Policy Predictions Mean    272.966\n",
      "trainer/Z Policy Predictions Std     121.991\n",
      "trainer/Z Policy Predictions Max     374.702\n",
      "trainer/Z Policy Predictions Min      -6.46477\n",
      "trainer/Z Expert Targets Mean        385.454\n",
      "trainer/Z Expert Targets Std          27.001\n",
      "trainer/Z Expert Targets Max         405.148\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        267.123\n",
      "trainer/Z Policy Targets Std         122.345\n",
      "trainer/Z Policy Targets Max         368.378\n",
      "trainer/Z Policy Targets Min          -5.81495\n",
      "trainer/Log Pis Mean                  43.0441\n",
      "trainer/Log Pis Std                   23.6577\n",
      "trainer/Policy mu Mean                 0.306885\n",
      "trainer/Policy mu Std                  2.61844\n",
      "trainer/Policy log std Mean           -1.14956\n",
      "trainer/Policy log std Std             0.494652\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        26585\n",
      "exploration/num paths total          697\n",
      "evaluation/num steps total         10627\n",
      "evaluation/num paths total           170\n",
      "evaluation/path length Mean           58.1\n",
      "evaluation/path length Std             7.96806\n",
      "evaluation/path length Max            77\n",
      "evaluation/path length Min            51\n",
      "evaluation/Rewards Mean                5.44561\n",
      "evaluation/Rewards Std                 0.416006\n",
      "evaluation/Rewards Max                 6.39934\n",
      "evaluation/Rewards Min                 4.80872\n",
      "evaluation/Returns Mean              316.39\n",
      "evaluation/Returns Std                42.2673\n",
      "evaluation/Returns Max               417.125\n",
      "evaluation/Returns Min               275.272\n",
      "evaluation/Estimation Bias Mean      227.89\n",
      "evaluation/Estimation Bias Std       141.75\n",
      "evaluation/EB/Q_True Mean             22.7514\n",
      "evaluation/EB/Q_True Std              65.4264\n",
      "evaluation/EB/Q_Pred Mean            250.641\n",
      "evaluation/EB/Q_Pred Std             133.752\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           316.39\n",
      "evaluation/Actions Mean                0.0580406\n",
      "evaluation/Actions Std                 0.808585\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.90231\n",
      "time/backward_zf1 (s)                  2.27663\n",
      "time/backward_zf2 (s)                  2.24357\n",
      "time/data sampling (s)                 0.282175\n",
      "time/data storing (s)                  0.0148421\n",
      "time/evaluation sampling (s)           0.18872\n",
      "time/exploration sampling (s)          0.467402\n",
      "time/logging (s)                       0.00206514\n",
      "time/preback_alpha (s)                 0.553106\n",
      "time/preback_policy (s)                1.17705\n",
      "time/preback_start (s)                 0.166635\n",
      "time/preback_zf (s)                    6.59439\n",
      "time/saving (s)                        3.447e-06\n",
      "time/training (s)                      3.02617\n",
      "time/epoch (s)                        18.8951\n",
      "time/total (s)                       329.961\n",
      "Epoch                                 16\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:31:08.124968 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 17 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 28000\n",
      "trainer/ZF1 Loss                      31.366\n",
      "trainer/ZF2 Loss                      29.4329\n",
      "trainer/ZF Expert Reward              12.0033\n",
      "trainer/ZF Policy Reward               5.06445\n",
      "trainer/ZF CHI2 Term                  38.2432\n",
      "trainer/Policy Loss                 -277.775\n",
      "trainer/Bias Loss                     11.2944\n",
      "trainer/Bias Value                    11.3952\n",
      "trainer/Policy Grad Norm              28.9176\n",
      "trainer/Policy Param Norm             26.4052\n",
      "trainer/Zf1 Grad Norm               3298.91\n",
      "trainer/Zf1 Param Norm                53.998\n",
      "trainer/Zf2 Grad Norm               2402.24\n",
      "trainer/Zf2 Param Norm                53.3178\n",
      "trainer/Z Expert Predictions Mean    421.387\n",
      "trainer/Z Expert Predictions Std      11.2339\n",
      "trainer/Z Expert Predictions Max     437.011\n",
      "trainer/Z Expert Predictions Min     375.611\n",
      "trainer/Z Policy Predictions Mean    271.842\n",
      "trainer/Z Policy Predictions Std     133.419\n",
      "trainer/Z Policy Predictions Max     387.614\n",
      "trainer/Z Policy Predictions Min      -5.94896\n",
      "trainer/Z Expert Targets Mean        409.383\n",
      "trainer/Z Expert Targets Std          11.9765\n",
      "trainer/Z Expert Targets Max         425.888\n",
      "trainer/Z Expert Targets Min         358.212\n",
      "trainer/Z Policy Targets Mean        266.778\n",
      "trainer/Z Policy Targets Std         134.001\n",
      "trainer/Z Policy Targets Max         381.914\n",
      "trainer/Z Policy Targets Min          -7.60044\n",
      "trainer/Log Pis Mean                  44.5305\n",
      "trainer/Log Pis Std                   24.8661\n",
      "trainer/Policy mu Mean                 0.497581\n",
      "trainer/Policy mu Std                  2.65271\n",
      "trainer/Policy log std Mean           -1.1367\n",
      "trainer/Policy log std Std             0.539696\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        27701\n",
      "exploration/num paths total          715\n",
      "evaluation/num steps total         11656\n",
      "evaluation/num paths total           180\n",
      "evaluation/path length Mean          102.9\n",
      "evaluation/path length Std            19.6695\n",
      "evaluation/path length Max           137\n",
      "evaluation/path length Min            75\n",
      "evaluation/Rewards Mean                5.00085\n",
      "evaluation/Rewards Std                 0.434705\n",
      "evaluation/Rewards Max                 5.87306\n",
      "evaluation/Rewards Min                 3.54294\n",
      "evaluation/Returns Mean              514.587\n",
      "evaluation/Returns Std                92.3521\n",
      "evaluation/Returns Max               679.111\n",
      "evaluation/Returns Min               378.019\n",
      "evaluation/Estimation Bias Mean      199.352\n",
      "evaluation/Estimation Bias Std       144.513\n",
      "evaluation/EB/Q_True Mean             29.9712\n",
      "evaluation/EB/Q_True Std              85.4065\n",
      "evaluation/EB/Q_Pred Mean            229.324\n",
      "evaluation/EB/Q_Pred Std             132.561\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           514.587\n",
      "evaluation/Actions Mean                0.0971101\n",
      "evaluation/Actions Std                 0.829716\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.68949\n",
      "time/backward_zf1 (s)                  2.05536\n",
      "time/backward_zf2 (s)                  1.99177\n",
      "time/data sampling (s)                 0.278899\n",
      "time/data storing (s)                  0.0142153\n",
      "time/evaluation sampling (s)           0.324314\n",
      "time/exploration sampling (s)          0.441959\n",
      "time/logging (s)                       0.00255545\n",
      "time/preback_alpha (s)                 0.552535\n",
      "time/preback_policy (s)                0.958161\n",
      "time/preback_start (s)                 0.165498\n",
      "time/preback_zf (s)                    6.58812\n",
      "time/saving (s)                        3.036e-06\n",
      "time/training (s)                      3.75595\n",
      "time/epoch (s)                        18.8188\n",
      "time/total (s)                       348.801\n",
      "Epoch                                 17\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:31:26.816066 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 18 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 29000\n",
      "trainer/ZF1 Loss                      54.5146\n",
      "trainer/ZF2 Loss                      45.5961\n",
      "trainer/ZF Expert Reward              14.2863\n",
      "trainer/ZF Policy Reward               4.64274\n",
      "trainer/ZF CHI2 Term                  60.0356\n",
      "trainer/Policy Loss                 -292.303\n",
      "trainer/Bias Loss                     17.5076\n",
      "trainer/Bias Value                    11.4833\n",
      "trainer/Policy Grad Norm              25.1686\n",
      "trainer/Policy Param Norm             26.7063\n",
      "trainer/Zf1 Grad Norm               6242.05\n",
      "trainer/Zf1 Param Norm                54.7277\n",
      "trainer/Zf2 Grad Norm               4522.1\n",
      "trainer/Zf2 Param Norm                54.0604\n",
      "trainer/Z Expert Predictions Mean    432.797\n",
      "trainer/Z Expert Predictions Std      15.4577\n",
      "trainer/Z Expert Predictions Max     451.787\n",
      "trainer/Z Expert Predictions Min     367.366\n",
      "trainer/Z Policy Predictions Mean    285.919\n",
      "trainer/Z Policy Predictions Std     132.279\n",
      "trainer/Z Policy Predictions Max     401.74\n",
      "trainer/Z Policy Predictions Min       1.98711\n",
      "trainer/Z Expert Targets Mean        418.51\n",
      "trainer/Z Expert Targets Std          18.3061\n",
      "trainer/Z Expert Targets Max         443.53\n",
      "trainer/Z Expert Targets Min         339.942\n",
      "trainer/Z Policy Targets Mean        281.277\n",
      "trainer/Z Policy Targets Std         135.332\n",
      "trainer/Z Policy Targets Max         403.868\n",
      "trainer/Z Policy Targets Min          -4.69688\n",
      "trainer/Log Pis Mean                  46.4621\n",
      "trainer/Log Pis Std                   26.0617\n",
      "trainer/Policy mu Mean                 0.384966\n",
      "trainer/Policy mu Std                  2.77679\n",
      "trainer/Policy log std Mean           -1.13682\n",
      "trainer/Policy log std Std             0.591015\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        28526\n",
      "exploration/num paths total          725\n",
      "evaluation/num steps total         12136\n",
      "evaluation/num paths total           190\n",
      "evaluation/path length Mean           48\n",
      "evaluation/path length Std             5.45894\n",
      "evaluation/path length Max            61\n",
      "evaluation/path length Min            42\n",
      "evaluation/Rewards Mean                5.17257\n",
      "evaluation/Rewards Std                 0.316491\n",
      "evaluation/Rewards Max                 6.3609\n",
      "evaluation/Rewards Min                 4.81631\n",
      "evaluation/Returns Mean              248.283\n",
      "evaluation/Returns Std                33.5238\n",
      "evaluation/Returns Max               329.767\n",
      "evaluation/Returns Min               213.225\n",
      "evaluation/Estimation Bias Mean      298.761\n",
      "evaluation/Estimation Bias Std       119.522\n",
      "evaluation/EB/Q_True Mean             18.3043\n",
      "evaluation/EB/Q_True Std              53.9486\n",
      "evaluation/EB/Q_Pred Mean            317.066\n",
      "evaluation/EB/Q_Pred Std             115.76\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           248.283\n",
      "evaluation/Actions Mean                0.108251\n",
      "evaluation/Actions Std                 0.799047\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.69029\n",
      "time/backward_zf1 (s)                  2.06564\n",
      "time/backward_zf2 (s)                  2.00737\n",
      "time/data sampling (s)                 0.279407\n",
      "time/data storing (s)                  0.0141439\n",
      "time/evaluation sampling (s)           0.140829\n",
      "time/exploration sampling (s)          0.455777\n",
      "time/logging (s)                       0.00207937\n",
      "time/preback_alpha (s)                 0.547155\n",
      "time/preback_policy (s)                0.929687\n",
      "time/preback_start (s)                 0.165337\n",
      "time/preback_zf (s)                    6.56235\n",
      "time/saving (s)                        3.528e-06\n",
      "time/training (s)                      3.76503\n",
      "time/epoch (s)                        18.6251\n",
      "time/total (s)                       367.448\n",
      "Epoch                                 18\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:31:46.344321 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 19 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 30000\n",
      "trainer/ZF1 Loss                      38.5356\n",
      "trainer/ZF2 Loss                      38.8952\n",
      "trainer/ZF Expert Reward              11.8621\n",
      "trainer/ZF Policy Reward               3.81511\n",
      "trainer/ZF CHI2 Term                  46.2651\n",
      "trainer/Policy Loss                 -277.375\n",
      "trainer/Bias Loss                     11.6684\n",
      "trainer/Bias Value                    11.5694\n",
      "trainer/Policy Grad Norm              35.4343\n",
      "trainer/Policy Param Norm             26.9921\n",
      "trainer/Zf1 Grad Norm               4509.82\n",
      "trainer/Zf1 Param Norm                55.4343\n",
      "trainer/Zf2 Grad Norm               3993.8\n",
      "trainer/Zf2 Param Norm                54.725\n",
      "trainer/Z Expert Predictions Mean    432.784\n",
      "trainer/Z Expert Predictions Std      32.0584\n",
      "trainer/Z Expert Predictions Max     462.491\n",
      "trainer/Z Expert Predictions Min      22.2586\n",
      "trainer/Z Policy Predictions Mean    271.281\n",
      "trainer/Z Policy Predictions Std     148.81\n",
      "trainer/Z Policy Predictions Max     410.802\n",
      "trainer/Z Policy Predictions Min     -10.6662\n",
      "trainer/Z Expert Targets Mean        420.922\n",
      "trainer/Z Expert Targets Std          33.427\n",
      "trainer/Z Expert Targets Max         456.447\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        267.466\n",
      "trainer/Z Policy Targets Std         149.38\n",
      "trainer/Z Policy Targets Max         407.286\n",
      "trainer/Z Policy Targets Min          -4.41464\n",
      "trainer/Log Pis Mean                  48.0035\n",
      "trainer/Log Pis Std                   25.7111\n",
      "trainer/Policy mu Mean                 0.471751\n",
      "trainer/Policy mu Std                  2.81063\n",
      "trainer/Policy log std Mean           -1.16727\n",
      "trainer/Policy log std Std             0.598141\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        29685\n",
      "exploration/num paths total          743\n",
      "evaluation/num steps total         12833\n",
      "evaluation/num paths total           200\n",
      "evaluation/path length Mean           69.7\n",
      "evaluation/path length Std            11.4634\n",
      "evaluation/path length Max            87\n",
      "evaluation/path length Min            47\n",
      "evaluation/Rewards Mean                5.25898\n",
      "evaluation/Rewards Std                 0.367296\n",
      "evaluation/Rewards Max                 6.46702\n",
      "evaluation/Rewards Min                 4.78102\n",
      "evaluation/Returns Mean              366.551\n",
      "evaluation/Returns Std                64.3658\n",
      "evaluation/Returns Max               465.371\n",
      "evaluation/Returns Min               246.981\n",
      "evaluation/Estimation Bias Mean      296.441\n",
      "evaluation/Estimation Bias Std       142.256\n",
      "evaluation/EB/Q_True Mean             22.7224\n",
      "evaluation/EB/Q_True Std              67.4062\n",
      "evaluation/EB/Q_Pred Mean            319.164\n",
      "evaluation/EB/Q_Pred Std             131.762\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           366.551\n",
      "evaluation/Actions Mean                0.0743434\n",
      "evaluation/Actions Std                 0.78194\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               2.02045\n",
      "time/backward_zf1 (s)                  2.40666\n",
      "time/backward_zf2 (s)                  2.39388\n",
      "time/data sampling (s)                 0.298724\n",
      "time/data storing (s)                  0.0151366\n",
      "time/evaluation sampling (s)           0.2282\n",
      "time/exploration sampling (s)          0.460192\n",
      "time/logging (s)                       0.00374811\n",
      "time/preback_alpha (s)                 0.573296\n",
      "time/preback_policy (s)                1.22627\n",
      "time/preback_start (s)                 0.171446\n",
      "time/preback_zf (s)                    6.65735\n",
      "time/saving (s)                        3.396e-06\n",
      "time/training (s)                      2.99753\n",
      "time/epoch (s)                        19.4529\n",
      "time/total (s)                       386.933\n",
      "Epoch                                 19\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:32:05.922860 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 20 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 31000\n",
      "trainer/ZF1 Loss                      32.8228\n",
      "trainer/ZF2 Loss                      33.5509\n",
      "trainer/ZF Expert Reward              13.4058\n",
      "trainer/ZF Policy Reward               5.41154\n",
      "trainer/ZF CHI2 Term                  42.3599\n",
      "trainer/Policy Loss                 -279.924\n",
      "trainer/Bias Loss                     15.1481\n",
      "trainer/Bias Value                    11.6534\n",
      "trainer/Policy Grad Norm              25.352\n",
      "trainer/Policy Param Norm             27.2743\n",
      "trainer/Zf1 Grad Norm               3435.7\n",
      "trainer/Zf1 Param Norm                56.0433\n",
      "trainer/Zf2 Grad Norm               4510.2\n",
      "trainer/Zf2 Param Norm                55.277\n",
      "trainer/Z Expert Predictions Mean    430.909\n",
      "trainer/Z Expert Predictions Std      16.8736\n",
      "trainer/Z Expert Predictions Max     469.805\n",
      "trainer/Z Expert Predictions Min     366.952\n",
      "trainer/Z Policy Predictions Mean    271.258\n",
      "trainer/Z Policy Predictions Std     154.627\n",
      "trainer/Z Policy Predictions Max     425.664\n",
      "trainer/Z Policy Predictions Min      -6.31473\n",
      "trainer/Z Expert Targets Mean        417.503\n",
      "trainer/Z Expert Targets Std          18.9556\n",
      "trainer/Z Expert Targets Max         462.277\n",
      "trainer/Z Expert Targets Min         343.611\n",
      "trainer/Z Policy Targets Mean        265.847\n",
      "trainer/Z Policy Targets Std         154.86\n",
      "trainer/Z Policy Targets Max         424.667\n",
      "trainer/Z Policy Targets Min         -11.9061\n",
      "trainer/Log Pis Mean                  51.0099\n",
      "trainer/Log Pis Std                   27.5429\n",
      "trainer/Policy mu Mean                 0.371728\n",
      "trainer/Policy mu Std                  2.95295\n",
      "trainer/Policy log std Mean           -1.21997\n",
      "trainer/Policy log std Std             0.596263\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        30547\n",
      "exploration/num paths total          756\n",
      "evaluation/num steps total         13656\n",
      "evaluation/num paths total           210\n",
      "evaluation/path length Mean           82.3\n",
      "evaluation/path length Std            10.3058\n",
      "evaluation/path length Max           109\n",
      "evaluation/path length Min            71\n",
      "evaluation/Rewards Mean                4.79787\n",
      "evaluation/Rewards Std                 0.307685\n",
      "evaluation/Rewards Max                 6.6281\n",
      "evaluation/Rewards Min                 4.0862\n",
      "evaluation/Returns Mean              394.865\n",
      "evaluation/Returns Std                46.6098\n",
      "evaluation/Returns Max               515.26\n",
      "evaluation/Returns Min               338.935\n",
      "evaluation/Estimation Bias Mean      256.771\n",
      "evaluation/Estimation Bias Std       167.075\n",
      "evaluation/EB/Q_True Mean             24.8484\n",
      "evaluation/EB/Q_True Std              70.9155\n",
      "evaluation/EB/Q_Pred Mean            281.619\n",
      "evaluation/EB/Q_Pred Std             156.952\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           394.865\n",
      "evaluation/Actions Mean                0.169442\n",
      "evaluation/Actions Std                 0.783939\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               2.01092\n",
      "time/backward_zf1 (s)                  2.38774\n",
      "time/backward_zf2 (s)                  2.3713\n",
      "time/data sampling (s)                 0.299149\n",
      "time/data storing (s)                  0.0153857\n",
      "time/evaluation sampling (s)           0.312371\n",
      "time/exploration sampling (s)          0.480311\n",
      "time/logging (s)                       0.00355009\n",
      "time/preback_alpha (s)                 0.570232\n",
      "time/preback_policy (s)                1.20201\n",
      "time/preback_start (s)                 0.171342\n",
      "time/preback_zf (s)                    6.6445\n",
      "time/saving (s)                        3.302e-06\n",
      "time/training (s)                      3.04144\n",
      "time/epoch (s)                        19.5102\n",
      "time/total (s)                       406.466\n",
      "Epoch                                 20\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:32:24.571380 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 21 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 32000\n",
      "trainer/ZF1 Loss                      44.9928\n",
      "trainer/ZF2 Loss                      48.8425\n",
      "trainer/ZF Expert Reward              11.2986\n",
      "trainer/ZF Policy Reward               1.19687\n",
      "trainer/ZF CHI2 Term                  54.012\n",
      "trainer/Policy Loss                 -292.423\n",
      "trainer/Bias Loss                     10.757\n",
      "trainer/Bias Value                    11.7359\n",
      "trainer/Policy Grad Norm              31.1788\n",
      "trainer/Policy Param Norm             27.5476\n",
      "trainer/Zf1 Grad Norm               8362.83\n",
      "trainer/Zf1 Param Norm                56.6098\n",
      "trainer/Zf2 Grad Norm               8450.1\n",
      "trainer/Zf2 Param Norm                55.8134\n",
      "trainer/Z Expert Predictions Mean    424.977\n",
      "trainer/Z Expert Predictions Std      20.8308\n",
      "trainer/Z Expert Predictions Max     472.946\n",
      "trainer/Z Expert Predictions Min     275.095\n",
      "trainer/Z Policy Predictions Mean    284.98\n",
      "trainer/Z Policy Predictions Std     145.532\n",
      "trainer/Z Policy Predictions Max     426.797\n",
      "trainer/Z Policy Predictions Min       1.83366\n",
      "trainer/Z Expert Targets Mean        413.678\n",
      "trainer/Z Expert Targets Std          20.7466\n",
      "trainer/Z Expert Targets Max         465.629\n",
      "trainer/Z Expert Targets Min         256.039\n",
      "trainer/Z Policy Targets Mean        283.783\n",
      "trainer/Z Policy Targets Std         144.591\n",
      "trainer/Z Policy Targets Max         432.877\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  46.6075\n",
      "trainer/Log Pis Std                   25.6971\n",
      "trainer/Policy mu Mean                 0.199791\n",
      "trainer/Policy mu Std                  2.90391\n",
      "trainer/Policy log std Mean           -1.15421\n",
      "trainer/Policy log std Std             0.617113\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        31494\n",
      "exploration/num paths total          767\n",
      "evaluation/num steps total         14323\n",
      "evaluation/num paths total           220\n",
      "evaluation/path length Mean           66.7\n",
      "evaluation/path length Std             6.18142\n",
      "evaluation/path length Max            78\n",
      "evaluation/path length Min            60\n",
      "evaluation/Rewards Mean                4.51817\n",
      "evaluation/Rewards Std                 0.336688\n",
      "evaluation/Rewards Max                 4.90609\n",
      "evaluation/Rewards Min                 3.40362\n",
      "evaluation/Returns Mean              301.362\n",
      "evaluation/Returns Std                27.5166\n",
      "evaluation/Returns Max               349.968\n",
      "evaluation/Returns Min               269.005\n",
      "evaluation/Estimation Bias Mean      246.38\n",
      "evaluation/Estimation Bias Std       153.694\n",
      "evaluation/EB/Q_True Mean             15.6269\n",
      "evaluation/EB/Q_True Std              49.4577\n",
      "evaluation/EB/Q_Pred Mean            262.007\n",
      "evaluation/EB/Q_Pred Std             151.832\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           301.362\n",
      "evaluation/Actions Mean                0.119435\n",
      "evaluation/Actions Std                 0.807124\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.61085\n",
      "time/backward_zf1 (s)                  1.98924\n",
      "time/backward_zf2 (s)                  1.91414\n",
      "time/data sampling (s)                 0.273027\n",
      "time/data storing (s)                  0.0141135\n",
      "time/evaluation sampling (s)           0.220618\n",
      "time/exploration sampling (s)          0.477472\n",
      "time/logging (s)                       0.00208282\n",
      "time/preback_alpha (s)                 0.542832\n",
      "time/preback_policy (s)                0.872044\n",
      "time/preback_start (s)                 0.162268\n",
      "time/preback_zf (s)                    6.54722\n",
      "time/saving (s)                        2.88701e-06\n",
      "time/training (s)                      3.95511\n",
      "time/epoch (s)                        18.581\n",
      "time/total (s)                       425.069\n",
      "Epoch                                 21\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:32:43.539795 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 22 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 33000\n",
      "trainer/ZF1 Loss                      55.2788\n",
      "trainer/ZF2 Loss                      55.2201\n",
      "trainer/ZF Expert Reward              11.6431\n",
      "trainer/ZF Policy Reward               3.41232\n",
      "trainer/ZF CHI2 Term                  62.615\n",
      "trainer/Policy Loss                 -272.983\n",
      "trainer/Bias Loss                      9.12227\n",
      "trainer/Bias Value                    11.8173\n",
      "trainer/Policy Grad Norm              32.0626\n",
      "trainer/Policy Param Norm             27.8305\n",
      "trainer/Zf1 Grad Norm               6234.05\n",
      "trainer/Zf1 Param Norm                57.1944\n",
      "trainer/Zf2 Grad Norm               5098.74\n",
      "trainer/Zf2 Param Norm                56.3862\n",
      "trainer/Z Expert Predictions Mean    428.976\n",
      "trainer/Z Expert Predictions Std      21.2173\n",
      "trainer/Z Expert Predictions Max     477.758\n",
      "trainer/Z Expert Predictions Min     268.63\n",
      "trainer/Z Policy Predictions Mean    265.689\n",
      "trainer/Z Policy Predictions Std     153.455\n",
      "trainer/Z Policy Predictions Max     430.582\n",
      "trainer/Z Policy Predictions Min       2.6408\n",
      "trainer/Z Expert Targets Mean        417.333\n",
      "trainer/Z Expert Targets Std          20.9668\n",
      "trainer/Z Expert Targets Max         472.291\n",
      "trainer/Z Expert Targets Min         264.42\n",
      "trainer/Z Policy Targets Mean        262.277\n",
      "trainer/Z Policy Targets Std         154.655\n",
      "trainer/Z Policy Targets Max         432.132\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  50.825\n",
      "trainer/Log Pis Std                   25.7359\n",
      "trainer/Policy mu Mean                 0.307623\n",
      "trainer/Policy mu Std                  3.15482\n",
      "trainer/Policy log std Mean           -1.09764\n",
      "trainer/Policy log std Std             0.737416\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        32581\n",
      "exploration/num paths total          781\n",
      "evaluation/num steps total         15034\n",
      "evaluation/num paths total           230\n",
      "evaluation/path length Mean           71.1\n",
      "evaluation/path length Std             7.77753\n",
      "evaluation/path length Max            88\n",
      "evaluation/path length Min            62\n",
      "evaluation/Rewards Mean                4.58114\n",
      "evaluation/Rewards Std                 0.317234\n",
      "evaluation/Rewards Max                 5.08802\n",
      "evaluation/Rewards Min                 3.57243\n",
      "evaluation/Returns Mean              325.719\n",
      "evaluation/Returns Std                34.9053\n",
      "evaluation/Returns Max               399.147\n",
      "evaluation/Returns Min               281.046\n",
      "evaluation/Estimation Bias Mean      272.961\n",
      "evaluation/Estimation Bias Std       158.818\n",
      "evaluation/EB/Q_True Mean             18.4334\n",
      "evaluation/EB/Q_True Std              56.435\n",
      "evaluation/EB/Q_Pred Mean            291.395\n",
      "evaluation/EB/Q_Pred Std             153.861\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           325.719\n",
      "evaluation/Actions Mean                0.202813\n",
      "evaluation/Actions Std                 0.786206\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.88046\n",
      "time/backward_zf1 (s)                  2.25718\n",
      "time/backward_zf2 (s)                  2.21018\n",
      "time/data sampling (s)                 0.283599\n",
      "time/data storing (s)                  0.0145521\n",
      "time/evaluation sampling (s)           0.231612\n",
      "time/exploration sampling (s)          0.478701\n",
      "time/logging (s)                       0.0027532\n",
      "time/preback_alpha (s)                 0.553617\n",
      "time/preback_policy (s)                1.1199\n",
      "time/preback_start (s)                 0.167229\n",
      "time/preback_zf (s)                    6.5805\n",
      "time/saving (s)                        4.087e-06\n",
      "time/training (s)                      3.12726\n",
      "time/epoch (s)                        18.9075\n",
      "time/total (s)                       443.994\n",
      "Epoch                                 22\n",
      "---------------------------------  -------------\n",
      "2024-07-28 20:33:02.530332 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 23 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 34000\n",
      "trainer/ZF1 Loss                      31.4769\n",
      "trainer/ZF2 Loss                      43.3602\n",
      "trainer/ZF Expert Reward              12.7495\n",
      "trainer/ZF Policy Reward               2.33846\n",
      "trainer/ZF CHI2 Term                  45.711\n",
      "trainer/Policy Loss                 -272.02\n",
      "trainer/Bias Loss                      4.77705\n",
      "trainer/Bias Value                    11.8965\n",
      "trainer/Policy Grad Norm              29.9798\n",
      "trainer/Policy Param Norm             28.0984\n",
      "trainer/Zf1 Grad Norm               4450.52\n",
      "trainer/Zf1 Param Norm                57.8123\n",
      "trainer/Zf2 Grad Norm               5774.75\n",
      "trainer/Zf2 Param Norm                56.9791\n",
      "trainer/Z Expert Predictions Mean    449.294\n",
      "trainer/Z Expert Predictions Std      14.2485\n",
      "trainer/Z Expert Predictions Max     484.749\n",
      "trainer/Z Expert Predictions Min     401.281\n",
      "trainer/Z Policy Predictions Mean    262.817\n",
      "trainer/Z Policy Predictions Std     161.887\n",
      "trainer/Z Policy Predictions Max     440.772\n",
      "trainer/Z Policy Predictions Min      -2.95291\n",
      "trainer/Z Expert Targets Mean        436.544\n",
      "trainer/Z Expert Targets Std          15.0304\n",
      "trainer/Z Expert Targets Max         478.348\n",
      "trainer/Z Expert Targets Min         382.741\n",
      "trainer/Z Policy Targets Mean        260.478\n",
      "trainer/Z Policy Targets Std         160.675\n",
      "trainer/Z Policy Targets Max         432.21\n",
      "trainer/Z Policy Targets Min          -8.34472\n",
      "trainer/Log Pis Mean                  52.2351\n",
      "trainer/Log Pis Std                   24.6186\n",
      "trainer/Policy mu Mean                 0.324808\n",
      "trainer/Policy mu Std                  3.1387\n",
      "trainer/Policy log std Mean           -1.14319\n",
      "trainer/Policy log std Std             0.688532\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        33482\n",
      "exploration/num paths total          792\n",
      "evaluation/num steps total         15924\n",
      "evaluation/num paths total           240\n",
      "evaluation/path length Mean           89\n",
      "evaluation/path length Std            14.8795\n",
      "evaluation/path length Max           116\n",
      "evaluation/path length Min            69\n",
      "evaluation/Rewards Mean                4.43634\n",
      "evaluation/Rewards Std                 0.442101\n",
      "evaluation/Rewards Max                 5.01201\n",
      "evaluation/Rewards Min                 3.0498\n",
      "evaluation/Returns Mean              394.834\n",
      "evaluation/Returns Std                66.5928\n",
      "evaluation/Returns Max               515.278\n",
      "evaluation/Returns Min               300.878\n",
      "evaluation/Estimation Bias Mean      251.375\n",
      "evaluation/Estimation Bias Std       176.037\n",
      "evaluation/EB/Q_True Mean             22.8259\n",
      "evaluation/EB/Q_True Std              67.9014\n",
      "evaluation/EB/Q_Pred Mean            274.201\n",
      "evaluation/EB/Q_Pred Std             165.041\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           394.834\n",
      "evaluation/Actions Mean                0.179583\n",
      "evaluation/Actions Std                 0.80689\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.73665\n",
      "time/backward_zf1 (s)                  2.11568\n",
      "time/backward_zf2 (s)                  2.05722\n",
      "time/data sampling (s)                 0.280167\n",
      "time/data storing (s)                  0.0143064\n",
      "time/evaluation sampling (s)           0.411589\n",
      "time/exploration sampling (s)          0.476544\n",
      "time/logging (s)                       0.00210457\n",
      "time/preback_alpha (s)                 0.552655\n",
      "time/preback_policy (s)                1.01404\n",
      "time/preback_start (s)                 0.165438\n",
      "time/preback_zf (s)                    6.58334\n",
      "time/saving (s)                        3.644e-06\n",
      "time/training (s)                      3.5187\n",
      "time/epoch (s)                        18.9284\n",
      "time/total (s)                       462.94\n",
      "Epoch                                 23\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:33:21.427029 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 24 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 35000\n",
      "trainer/ZF1 Loss                      44.0352\n",
      "trainer/ZF2 Loss                      35.0664\n",
      "trainer/ZF Expert Reward              15.7819\n",
      "trainer/ZF Policy Reward               9.75891\n",
      "trainer/ZF CHI2 Term                  50.7203\n",
      "trainer/Policy Loss                 -285.752\n",
      "trainer/Bias Loss                     13.0498\n",
      "trainer/Bias Value                    11.9787\n",
      "trainer/Policy Grad Norm              32.3249\n",
      "trainer/Policy Param Norm             28.3636\n",
      "trainer/Zf1 Grad Norm               8309.95\n",
      "trainer/Zf1 Param Norm                58.4656\n",
      "trainer/Zf2 Grad Norm               4926.54\n",
      "trainer/Zf2 Param Norm                57.5749\n",
      "trainer/Z Expert Predictions Mean    464.426\n",
      "trainer/Z Expert Predictions Std      41.1854\n",
      "trainer/Z Expert Predictions Max     497.148\n",
      "trainer/Z Expert Predictions Min      20.8006\n",
      "trainer/Z Policy Predictions Mean    280.792\n",
      "trainer/Z Policy Predictions Std     157.421\n",
      "trainer/Z Policy Predictions Max     444.512\n",
      "trainer/Z Policy Predictions Min       4.67464\n",
      "trainer/Z Expert Targets Mean        448.644\n",
      "trainer/Z Expert Targets Std          42.1194\n",
      "trainer/Z Expert Targets Max         487.952\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        271.033\n",
      "trainer/Z Policy Targets Std         158.74\n",
      "trainer/Z Policy Targets Max         445.214\n",
      "trainer/Z Policy Targets Min          -2.86076\n",
      "trainer/Log Pis Mean                  50.213\n",
      "trainer/Log Pis Std                   25.5497\n",
      "trainer/Policy mu Mean                 0.367748\n",
      "trainer/Policy mu Std                  2.96537\n",
      "trainer/Policy log std Mean           -1.20717\n",
      "trainer/Policy log std Std             0.651573\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        34481\n",
      "exploration/num paths total          803\n",
      "evaluation/num steps total         16912\n",
      "evaluation/num paths total           250\n",
      "evaluation/path length Mean           98.8\n",
      "evaluation/path length Std            20.0489\n",
      "evaluation/path length Max           132\n",
      "evaluation/path length Min            72\n",
      "evaluation/Rewards Mean                4.56468\n",
      "evaluation/Rewards Std                 0.360064\n",
      "evaluation/Rewards Max                 5.07789\n",
      "evaluation/Rewards Min                 3.21332\n",
      "evaluation/Returns Mean              450.99\n",
      "evaluation/Returns Std                98.0607\n",
      "evaluation/Returns Max               614.017\n",
      "evaluation/Returns Min               345.792\n",
      "evaluation/Estimation Bias Mean      272.009\n",
      "evaluation/Estimation Bias Std       163.787\n",
      "evaluation/EB/Q_True Mean             27.2939\n",
      "evaluation/EB/Q_True Std              78.8061\n",
      "evaluation/EB/Q_Pred Mean            299.303\n",
      "evaluation/EB/Q_Pred Std             156.585\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           450.99\n",
      "evaluation/Actions Mean                0.0885331\n",
      "evaluation/Actions Std                 0.779612\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.70886\n",
      "time/backward_zf1 (s)                  2.09168\n",
      "time/backward_zf2 (s)                  2.01315\n",
      "time/data sampling (s)                 0.283979\n",
      "time/data storing (s)                  0.0142166\n",
      "time/evaluation sampling (s)           0.344074\n",
      "time/exploration sampling (s)          0.461647\n",
      "time/logging (s)                       0.00227135\n",
      "time/preback_alpha (s)                 0.549464\n",
      "time/preback_policy (s)                0.972574\n",
      "time/preback_start (s)                 0.164249\n",
      "time/preback_zf (s)                    6.57653\n",
      "time/saving (s)                        3.337e-06\n",
      "time/training (s)                      3.65263\n",
      "time/epoch (s)                        18.8353\n",
      "time/total (s)                       481.793\n",
      "Epoch                                 24\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:33:40.234974 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 25 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 36000\n",
      "trainer/ZF1 Loss                      36.1258\n",
      "trainer/ZF2 Loss                      33.1804\n",
      "trainer/ZF Expert Reward              14.4427\n",
      "trainer/ZF Policy Reward               5.95148\n",
      "trainer/ZF CHI2 Term                  44.4577\n",
      "trainer/Policy Loss                 -285.743\n",
      "trainer/Bias Loss                     14.7902\n",
      "trainer/Bias Value                    12.0642\n",
      "trainer/Policy Grad Norm              35.7962\n",
      "trainer/Policy Param Norm             28.6102\n",
      "trainer/Zf1 Grad Norm               4480.6\n",
      "trainer/Zf1 Param Norm                59.1285\n",
      "trainer/Zf2 Grad Norm               2659.7\n",
      "trainer/Zf2 Param Norm                58.176\n",
      "trainer/Z Expert Predictions Mean    469.649\n",
      "trainer/Z Expert Predictions Std      17.0801\n",
      "trainer/Z Expert Predictions Max     507.449\n",
      "trainer/Z Expert Predictions Min     404.667\n",
      "trainer/Z Policy Predictions Mean    280.91\n",
      "trainer/Z Policy Predictions Std     156.667\n",
      "trainer/Z Policy Predictions Max     448.176\n",
      "trainer/Z Policy Predictions Min       0.250068\n",
      "trainer/Z Expert Targets Mean        455.206\n",
      "trainer/Z Expert Targets Std          18.6069\n",
      "trainer/Z Expert Targets Max         500.451\n",
      "trainer/Z Expert Targets Min         378.662\n",
      "trainer/Z Policy Targets Mean        274.959\n",
      "trainer/Z Policy Targets Std         157.182\n",
      "trainer/Z Policy Targets Max         447.116\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  47.8532\n",
      "trainer/Log Pis Std                   24.3112\n",
      "trainer/Policy mu Mean                 0.328342\n",
      "trainer/Policy mu Std                  2.9799\n",
      "trainer/Policy log std Mean           -1.2475\n",
      "trainer/Policy log std Std             0.714338\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        35461\n",
      "exploration/num paths total          813\n",
      "evaluation/num steps total         17836\n",
      "evaluation/num paths total           260\n",
      "evaluation/path length Mean           92.4\n",
      "evaluation/path length Std            16.6505\n",
      "evaluation/path length Max           132\n",
      "evaluation/path length Min            74\n",
      "evaluation/Rewards Mean                5.1421\n",
      "evaluation/Rewards Std                 0.353848\n",
      "evaluation/Rewards Max                 6.34599\n",
      "evaluation/Rewards Min                 4.2448\n",
      "evaluation/Returns Mean              475.13\n",
      "evaluation/Returns Std                80.0703\n",
      "evaluation/Returns Max               643.408\n",
      "evaluation/Returns Min               366.448\n",
      "evaluation/Estimation Bias Mean      270.879\n",
      "evaluation/Estimation Bias Std       160.253\n",
      "evaluation/EB/Q_True Mean             31.1337\n",
      "evaluation/EB/Q_True Std              85.8534\n",
      "evaluation/EB/Q_Pred Mean            302.012\n",
      "evaluation/EB/Q_Pred Std             145.815\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           475.13\n",
      "evaluation/Actions Mean                0.1964\n",
      "evaluation/Actions Std                 0.776439\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.68318\n",
      "time/backward_zf1 (s)                  2.06498\n",
      "time/backward_zf2 (s)                  1.99252\n",
      "time/data sampling (s)                 0.281872\n",
      "time/data storing (s)                  0.0143242\n",
      "time/evaluation sampling (s)           0.320169\n",
      "time/exploration sampling (s)          0.461314\n",
      "time/logging (s)                       0.00219753\n",
      "time/preback_alpha (s)                 0.546332\n",
      "time/preback_policy (s)                0.945368\n",
      "time/preback_start (s)                 0.16437\n",
      "time/preback_zf (s)                    6.54687\n",
      "time/saving (s)                        3.033e-06\n",
      "time/training (s)                      3.72437\n",
      "time/epoch (s)                        18.7479\n",
      "time/total (s)                       500.558\n",
      "Epoch                                 25\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:33:59.212862 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 26 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 37000\n",
      "trainer/ZF1 Loss                      27.4443\n",
      "trainer/ZF2 Loss                      25.8058\n",
      "trainer/ZF Expert Reward              13.5509\n",
      "trainer/ZF Policy Reward               3.91566\n",
      "trainer/ZF CHI2 Term                  35.5216\n",
      "trainer/Policy Loss                 -278.614\n",
      "trainer/Bias Loss                     13.945\n",
      "trainer/Bias Value                    12.1491\n",
      "trainer/Policy Grad Norm              34.8882\n",
      "trainer/Policy Param Norm             28.8427\n",
      "trainer/Zf1 Grad Norm               2912.37\n",
      "trainer/Zf1 Param Norm                59.7327\n",
      "trainer/Zf2 Grad Norm               2610.47\n",
      "trainer/Zf2 Param Norm                58.7273\n",
      "trainer/Z Expert Predictions Mean    469.779\n",
      "trainer/Z Expert Predictions Std      33.1663\n",
      "trainer/Z Expert Predictions Max     515.251\n",
      "trainer/Z Expert Predictions Min      18.7059\n",
      "trainer/Z Policy Predictions Mean    272.801\n",
      "trainer/Z Policy Predictions Std     170.581\n",
      "trainer/Z Policy Predictions Max     460.276\n",
      "trainer/Z Policy Predictions Min      -2.21276\n",
      "trainer/Z Expert Targets Mean        456.228\n",
      "trainer/Z Expert Targets Std          34.216\n",
      "trainer/Z Expert Targets Max         508.866\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        268.886\n",
      "trainer/Z Policy Targets Std         171.229\n",
      "trainer/Z Policy Targets Max         464.856\n",
      "trainer/Z Policy Targets Min          -0.545905\n",
      "trainer/Log Pis Mean                  50.3616\n",
      "trainer/Log Pis Std                   27.5272\n",
      "trainer/Policy mu Mean                 0.446846\n",
      "trainer/Policy mu Std                  3.25726\n",
      "trainer/Policy log std Mean           -1.12226\n",
      "trainer/Policy log std Std             0.734877\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        36686\n",
      "exploration/num paths total          826\n",
      "evaluation/num steps total         18770\n",
      "evaluation/num paths total           270\n",
      "evaluation/path length Mean           93.4\n",
      "evaluation/path length Std            20.7759\n",
      "evaluation/path length Max           136\n",
      "evaluation/path length Min            73\n",
      "evaluation/Rewards Mean                5.22674\n",
      "evaluation/Rewards Std                 0.446861\n",
      "evaluation/Rewards Max                 6.46037\n",
      "evaluation/Rewards Min                 3.85085\n",
      "evaluation/Returns Mean              488.178\n",
      "evaluation/Returns Std                98.2535\n",
      "evaluation/Returns Max               725.117\n",
      "evaluation/Returns Min               391.799\n",
      "evaluation/Estimation Bias Mean      253.013\n",
      "evaluation/Estimation Bias Std       177.513\n",
      "evaluation/EB/Q_True Mean             36.4087\n",
      "evaluation/EB/Q_True Std              97.2987\n",
      "evaluation/EB/Q_Pred Mean            289.422\n",
      "evaluation/EB/Q_Pred Std             157.969\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           488.178\n",
      "evaluation/Actions Mean                0.0763668\n",
      "evaluation/Actions Std                 0.793135\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.84746\n",
      "time/backward_zf1 (s)                  2.21461\n",
      "time/backward_zf2 (s)                  2.16027\n",
      "time/data sampling (s)                 0.287344\n",
      "time/data storing (s)                  0.0142511\n",
      "time/evaluation sampling (s)           0.306791\n",
      "time/exploration sampling (s)          0.473561\n",
      "time/logging (s)                       0.00232952\n",
      "time/preback_alpha (s)                 0.552756\n",
      "time/preback_policy (s)                1.09408\n",
      "time/preback_start (s)                 0.166203\n",
      "time/preback_zf (s)                    6.55944\n",
      "time/saving (s)                        3.851e-06\n",
      "time/training (s)                      3.23699\n",
      "time/epoch (s)                        18.9161\n",
      "time/total (s)                       519.491\n",
      "Epoch                                 26\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:34:18.071929 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 27 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 38000\n",
      "trainer/ZF1 Loss                      29.3872\n",
      "trainer/ZF2 Loss                      40.8734\n",
      "trainer/ZF Expert Reward              12.1597\n",
      "trainer/ZF Policy Reward               3.06634\n",
      "trainer/ZF CHI2 Term                  42.6417\n",
      "trainer/Policy Loss                 -278.31\n",
      "trainer/Bias Loss                      7.52959\n",
      "trainer/Bias Value                    12.2338\n",
      "trainer/Policy Grad Norm              37.6481\n",
      "trainer/Policy Param Norm             29.0845\n",
      "trainer/Zf1 Grad Norm               3312.35\n",
      "trainer/Zf1 Param Norm                60.2839\n",
      "trainer/Zf2 Grad Norm               4954.9\n",
      "trainer/Zf2 Param Norm                59.2461\n",
      "trainer/Z Expert Predictions Mean    467.042\n",
      "trainer/Z Expert Predictions Std      34.2251\n",
      "trainer/Z Expert Predictions Max     513.964\n",
      "trainer/Z Expert Predictions Min      17.2797\n",
      "trainer/Z Policy Predictions Mean    267.032\n",
      "trainer/Z Policy Predictions Std     158.625\n",
      "trainer/Z Policy Predictions Max     465.036\n",
      "trainer/Z Policy Predictions Min      -2.53371\n",
      "trainer/Z Expert Targets Mean        454.883\n",
      "trainer/Z Expert Targets Std          34.5198\n",
      "trainer/Z Expert Targets Max         504.277\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        263.965\n",
      "trainer/Z Policy Targets Std         158.644\n",
      "trainer/Z Policy Targets Max         464.339\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  50.8631\n",
      "trainer/Log Pis Std                   23.3437\n",
      "trainer/Policy mu Mean                 0.3358\n",
      "trainer/Policy mu Std                  3.08781\n",
      "trainer/Policy log std Mean           -1.2386\n",
      "trainer/Policy log std Std             0.721138\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        37594\n",
      "exploration/num paths total          836\n",
      "evaluation/num steps total         19813\n",
      "evaluation/num paths total           280\n",
      "evaluation/path length Mean          104.3\n",
      "evaluation/path length Std            20.0202\n",
      "evaluation/path length Max           141\n",
      "evaluation/path length Min            76\n",
      "evaluation/Rewards Mean                5.0218\n",
      "evaluation/Rewards Std                 0.398745\n",
      "evaluation/Rewards Max                 6.07662\n",
      "evaluation/Rewards Min                 3.52994\n",
      "evaluation/Returns Mean              523.774\n",
      "evaluation/Returns Std               111.763\n",
      "evaluation/Returns Max               715.916\n",
      "evaluation/Returns Min               385.564\n",
      "evaluation/Estimation Bias Mean      287.657\n",
      "evaluation/Estimation Bias Std       150.542\n",
      "evaluation/EB/Q_True Mean             32.3768\n",
      "evaluation/EB/Q_True Std              90.62\n",
      "evaluation/EB/Q_Pred Mean            320.034\n",
      "evaluation/EB/Q_Pred Std             129.657\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           523.774\n",
      "evaluation/Actions Mean                0.219261\n",
      "evaluation/Actions Std                 0.766511\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.70751\n",
      "time/backward_zf1 (s)                  2.08978\n",
      "time/backward_zf2 (s)                  2.02368\n",
      "time/data sampling (s)                 0.281323\n",
      "time/data storing (s)                  0.0143322\n",
      "time/evaluation sampling (s)           0.33202\n",
      "time/exploration sampling (s)          0.459643\n",
      "time/logging (s)                       0.00285821\n",
      "time/preback_alpha (s)                 0.548908\n",
      "time/preback_policy (s)                0.984719\n",
      "time/preback_start (s)                 0.164204\n",
      "time/preback_zf (s)                    6.57304\n",
      "time/saving (s)                        3.22e-06\n",
      "time/training (s)                      3.60987\n",
      "time/epoch (s)                        18.7919\n",
      "time/total (s)                       538.307\n",
      "Epoch                                 27\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:34:37.942527 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 28 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 39000\n",
      "trainer/ZF1 Loss                      35.0696\n",
      "trainer/ZF2 Loss                      45.1085\n",
      "trainer/ZF Expert Reward              15.2937\n",
      "trainer/ZF Policy Reward               5.6534\n",
      "trainer/ZF CHI2 Term                  50.7503\n",
      "trainer/Policy Loss                 -266.938\n",
      "trainer/Bias Loss                     17.2155\n",
      "trainer/Bias Value                    12.318\n",
      "trainer/Policy Grad Norm              32.952\n",
      "trainer/Policy Param Norm             29.3488\n",
      "trainer/Zf1 Grad Norm               3327.37\n",
      "trainer/Zf1 Param Norm                60.8668\n",
      "trainer/Zf2 Grad Norm               3294.55\n",
      "trainer/Zf2 Param Norm                59.7829\n",
      "trainer/Z Expert Predictions Mean    469.66\n",
      "trainer/Z Expert Predictions Std      22.3128\n",
      "trainer/Z Expert Predictions Max     526.842\n",
      "trainer/Z Expert Predictions Min     386.782\n",
      "trainer/Z Policy Predictions Mean    259.448\n",
      "trainer/Z Policy Predictions Std     161.079\n",
      "trainer/Z Policy Predictions Max     465.728\n",
      "trainer/Z Policy Predictions Min       1.58718\n",
      "trainer/Z Expert Targets Mean        454.366\n",
      "trainer/Z Expert Targets Std          23.9986\n",
      "trainer/Z Expert Targets Max         516.731\n",
      "trainer/Z Expert Targets Min         363.03\n",
      "trainer/Z Policy Targets Mean        253.795\n",
      "trainer/Z Policy Targets Std         162.315\n",
      "trainer/Z Policy Targets Max         463.872\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  51.2617\n",
      "trainer/Log Pis Std                   24.6079\n",
      "trainer/Policy mu Mean                 0.397398\n",
      "trainer/Policy mu Std                  3.22336\n",
      "trainer/Policy log std Mean           -1.16449\n",
      "trainer/Policy log std Std             0.781031\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        38586\n",
      "exploration/num paths total          846\n",
      "evaluation/num steps total         20723\n",
      "evaluation/num paths total           290\n",
      "evaluation/path length Mean           91\n",
      "evaluation/path length Std            16.8997\n",
      "evaluation/path length Max           126\n",
      "evaluation/path length Min            68\n",
      "evaluation/Rewards Mean                5.27514\n",
      "evaluation/Rewards Std                 0.434253\n",
      "evaluation/Rewards Max                 6.36709\n",
      "evaluation/Rewards Min                 3.58707\n",
      "evaluation/Returns Mean              480.038\n",
      "evaluation/Returns Std                75.8033\n",
      "evaluation/Returns Max               656.244\n",
      "evaluation/Returns Min               375.759\n",
      "evaluation/Estimation Bias Mean      259.178\n",
      "evaluation/Estimation Bias Std       171.434\n",
      "evaluation/EB/Q_True Mean             31.7042\n",
      "evaluation/EB/Q_True Std              88.2591\n",
      "evaluation/EB/Q_Pred Mean            290.883\n",
      "evaluation/EB/Q_Pred Std             152.324\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           480.038\n",
      "evaluation/Actions Mean                0.069044\n",
      "evaluation/Actions Std                 0.813963\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               2.0508\n",
      "time/backward_zf1 (s)                  2.45162\n",
      "time/backward_zf2 (s)                  2.42314\n",
      "time/data sampling (s)                 0.305521\n",
      "time/data storing (s)                  0.015274\n",
      "time/evaluation sampling (s)           0.318294\n",
      "time/exploration sampling (s)          0.47596\n",
      "time/logging (s)                       0.00280177\n",
      "time/preback_alpha (s)                 0.581363\n",
      "time/preback_policy (s)                1.25247\n",
      "time/preback_start (s)                 0.174343\n",
      "time/preback_zf (s)                    6.713\n",
      "time/saving (s)                        3.275e-06\n",
      "time/training (s)                      3.03134\n",
      "time/epoch (s)                        19.7959\n",
      "time/total (s)                       558.131\n",
      "Epoch                                 28\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:34:56.706771 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 29 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 40000\n",
      "trainer/ZF1 Loss                      24.9478\n",
      "trainer/ZF2 Loss                      29.1702\n",
      "trainer/ZF Expert Reward              14.2358\n",
      "trainer/ZF Policy Reward               3.03575\n",
      "trainer/ZF CHI2 Term                  36.7274\n",
      "trainer/Policy Loss                 -276.699\n",
      "trainer/Bias Loss                      6.23417\n",
      "trainer/Bias Value                    12.3987\n",
      "trainer/Policy Grad Norm              31.1114\n",
      "trainer/Policy Param Norm             29.6088\n",
      "trainer/Zf1 Grad Norm               3137.56\n",
      "trainer/Zf1 Param Norm                61.4303\n",
      "trainer/Zf2 Grad Norm               3563.54\n",
      "trainer/Zf2 Param Norm                60.2996\n",
      "trainer/Z Expert Predictions Mean    463.859\n",
      "trainer/Z Expert Predictions Std      37.6513\n",
      "trainer/Z Expert Predictions Max     533.952\n",
      "trainer/Z Expert Predictions Min      21.7344\n",
      "trainer/Z Policy Predictions Mean    271.104\n",
      "trainer/Z Policy Predictions Std     165.541\n",
      "trainer/Z Policy Predictions Max     466.414\n",
      "trainer/Z Policy Predictions Min       2.70202\n",
      "trainer/Z Expert Targets Mean        449.624\n",
      "trainer/Z Expert Targets Std          38.6761\n",
      "trainer/Z Expert Targets Max         525.522\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        268.068\n",
      "trainer/Z Policy Targets Std         166.563\n",
      "trainer/Z Policy Targets Max         461.633\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  49.1446\n",
      "trainer/Log Pis Std                   24.6494\n",
      "trainer/Policy mu Mean                 0.300183\n",
      "trainer/Policy mu Std                  3.09596\n",
      "trainer/Policy log std Mean           -1.2005\n",
      "trainer/Policy log std Std             0.767257\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        39505\n",
      "exploration/num paths total          855\n",
      "evaluation/num steps total         21265\n",
      "evaluation/num paths total           300\n",
      "evaluation/path length Mean           54.2\n",
      "evaluation/path length Std             9.42125\n",
      "evaluation/path length Max            78\n",
      "evaluation/path length Min            44\n",
      "evaluation/Rewards Mean                5.11196\n",
      "evaluation/Rewards Std                 0.273058\n",
      "evaluation/Rewards Max                 6.34364\n",
      "evaluation/Rewards Min                 4.81058\n",
      "evaluation/Returns Mean              277.068\n",
      "evaluation/Returns Std                48.6038\n",
      "evaluation/Returns Max               388.013\n",
      "evaluation/Returns Min               222.328\n",
      "evaluation/Estimation Bias Mean      347.143\n",
      "evaluation/Estimation Bias Std       135.835\n",
      "evaluation/EB/Q_True Mean             22.3024\n",
      "evaluation/EB/Q_True Std              61.7314\n",
      "evaluation/EB/Q_Pred Mean            369.445\n",
      "evaluation/EB/Q_Pred Std             130.918\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           277.068\n",
      "evaluation/Actions Mean                0.183283\n",
      "evaluation/Actions Std                 0.728414\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.64497\n",
      "time/backward_zf1 (s)                  2.01855\n",
      "time/backward_zf2 (s)                  1.94169\n",
      "time/data sampling (s)                 0.283775\n",
      "time/data storing (s)                  0.0144955\n",
      "time/evaluation sampling (s)           0.190319\n",
      "time/exploration sampling (s)          0.470847\n",
      "time/logging (s)                       0.00181028\n",
      "time/preback_alpha (s)                 0.551433\n",
      "time/preback_policy (s)                0.909269\n",
      "time/preback_start (s)                 0.16406\n",
      "time/preback_zf (s)                    6.60684\n",
      "time/saving (s)                        4.265e-06\n",
      "time/training (s)                      3.90116\n",
      "time/epoch (s)                        18.6992\n",
      "time/total (s)                       576.85\n",
      "Epoch                                 29\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:35:15.652081 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 30 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 41000\n",
      "trainer/ZF1 Loss                      26.3509\n",
      "trainer/ZF2 Loss                      31.7224\n",
      "trainer/ZF Expert Reward              14.3259\n",
      "trainer/ZF Policy Reward               5.78984\n",
      "trainer/ZF CHI2 Term                  38.8129\n",
      "trainer/Policy Loss                 -293.084\n",
      "trainer/Bias Loss                      6.46896\n",
      "trainer/Bias Value                    12.4787\n",
      "trainer/Policy Grad Norm              35.8116\n",
      "trainer/Policy Param Norm             29.8631\n",
      "trainer/Zf1 Grad Norm               3074.34\n",
      "trainer/Zf1 Param Norm                61.9673\n",
      "trainer/Zf2 Grad Norm               3771.88\n",
      "trainer/Zf2 Param Norm                60.7824\n",
      "trainer/Z Expert Predictions Mean    460.26\n",
      "trainer/Z Expert Predictions Std      24.492\n",
      "trainer/Z Expert Predictions Max     535.713\n",
      "trainer/Z Expert Predictions Min     389.89\n",
      "trainer/Z Policy Predictions Mean    282.976\n",
      "trainer/Z Policy Predictions Std     162.213\n",
      "trainer/Z Policy Predictions Max     477.789\n",
      "trainer/Z Policy Predictions Min      -2.35027\n",
      "trainer/Z Expert Targets Mean        445.934\n",
      "trainer/Z Expert Targets Std          25.1388\n",
      "trainer/Z Expert Targets Max         526.447\n",
      "trainer/Z Expert Targets Min         375.85\n",
      "trainer/Z Policy Targets Mean        277.186\n",
      "trainer/Z Policy Targets Std         162.165\n",
      "trainer/Z Policy Targets Max         468.101\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  48.3499\n",
      "trainer/Log Pis Std                   24.6804\n",
      "trainer/Policy mu Mean                 0.141876\n",
      "trainer/Policy mu Std                  2.95028\n",
      "trainer/Policy log std Mean           -1.28462\n",
      "trainer/Policy log std Std             0.7496\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        40596\n",
      "exploration/num paths total          869\n",
      "evaluation/num steps total         22123\n",
      "evaluation/num paths total           310\n",
      "evaluation/path length Mean           85.8\n",
      "evaluation/path length Std            11.0887\n",
      "evaluation/path length Max           106\n",
      "evaluation/path length Min            70\n",
      "evaluation/Rewards Mean                5.00303\n",
      "evaluation/Rewards Std                 0.394897\n",
      "evaluation/Rewards Max                 6.26325\n",
      "evaluation/Rewards Min                 3.81299\n",
      "evaluation/Returns Mean              429.26\n",
      "evaluation/Returns Std                47.6738\n",
      "evaluation/Returns Max               526.419\n",
      "evaluation/Returns Min               361.732\n",
      "evaluation/Estimation Bias Mean      293.618\n",
      "evaluation/Estimation Bias Std       172.26\n",
      "evaluation/EB/Q_True Mean             22.4919\n",
      "evaluation/EB/Q_True Std              67.9322\n",
      "evaluation/EB/Q_Pred Mean            316.11\n",
      "evaluation/EB/Q_Pred Std             163.306\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           429.26\n",
      "evaluation/Actions Mean                0.195274\n",
      "evaluation/Actions Std                 0.731503\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.87887\n",
      "time/backward_zf1 (s)                  2.25265\n",
      "time/backward_zf2 (s)                  2.22537\n",
      "time/data sampling (s)                 0.286082\n",
      "time/data storing (s)                  0.0142756\n",
      "time/evaluation sampling (s)           0.275638\n",
      "time/exploration sampling (s)          0.460123\n",
      "time/logging (s)                       0.00319499\n",
      "time/preback_alpha (s)                 0.550454\n",
      "time/preback_policy (s)                1.16223\n",
      "time/preback_start (s)                 0.166316\n",
      "time/preback_zf (s)                    6.57751\n",
      "time/saving (s)                        4.62e-06\n",
      "time/training (s)                      3.03249\n",
      "time/epoch (s)                        18.8852\n",
      "time/total (s)                       595.753\n",
      "Epoch                                 30\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:35:34.548125 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 31 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 42000\n",
      "trainer/ZF1 Loss                      29.7357\n",
      "trainer/ZF2 Loss                      32.866\n",
      "trainer/ZF Expert Reward              12.8208\n",
      "trainer/ZF Policy Reward               5.63603\n",
      "trainer/ZF CHI2 Term                  39.6289\n",
      "trainer/Policy Loss                 -272.957\n",
      "trainer/Bias Loss                      4.29501\n",
      "trainer/Bias Value                    12.5595\n",
      "trainer/Policy Grad Norm              30.5218\n",
      "trainer/Policy Param Norm             30.0957\n",
      "trainer/Zf1 Grad Norm               3255.46\n",
      "trainer/Zf1 Param Norm                62.4718\n",
      "trainer/Zf2 Grad Norm               3631.21\n",
      "trainer/Zf2 Param Norm                61.2538\n",
      "trainer/Z Expert Predictions Mean    455.763\n",
      "trainer/Z Expert Predictions Std      25.0743\n",
      "trainer/Z Expert Predictions Max     537.483\n",
      "trainer/Z Expert Predictions Min     394.673\n",
      "trainer/Z Policy Predictions Mean    269.155\n",
      "trainer/Z Policy Predictions Std     164.465\n",
      "trainer/Z Policy Predictions Max     491.587\n",
      "trainer/Z Policy Predictions Min       0.0126085\n",
      "trainer/Z Expert Targets Mean        442.942\n",
      "trainer/Z Expert Targets Std          25.2274\n",
      "trainer/Z Expert Targets Max         530.374\n",
      "trainer/Z Expert Targets Min         382.258\n",
      "trainer/Z Policy Targets Mean        263.519\n",
      "trainer/Z Policy Targets Std         165.304\n",
      "trainer/Z Policy Targets Max         476.521\n",
      "trainer/Z Policy Targets Min          -0.0598209\n",
      "trainer/Log Pis Mean                  50.698\n",
      "trainer/Log Pis Std                   26.5186\n",
      "trainer/Policy mu Mean                 0.332308\n",
      "trainer/Policy mu Std                  3.24135\n",
      "trainer/Policy log std Mean           -1.164\n",
      "trainer/Policy log std Std             0.830051\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        41560\n",
      "exploration/num paths total          882\n",
      "evaluation/num steps total         23147\n",
      "evaluation/num paths total           320\n",
      "evaluation/path length Mean          102.4\n",
      "evaluation/path length Std            12.1589\n",
      "evaluation/path length Max           123\n",
      "evaluation/path length Min            88\n",
      "evaluation/Rewards Mean                4.5527\n",
      "evaluation/Rewards Std                 0.322828\n",
      "evaluation/Rewards Max                 5.02423\n",
      "evaluation/Rewards Min                 3.19875\n",
      "evaluation/Returns Mean              466.197\n",
      "evaluation/Returns Std                57.4586\n",
      "evaluation/Returns Max               544.535\n",
      "evaluation/Returns Min               388.222\n",
      "evaluation/Estimation Bias Mean      217.37\n",
      "evaluation/Estimation Bias Std       175.816\n",
      "evaluation/EB/Q_True Mean             21.9625\n",
      "evaluation/EB/Q_True Std              67.7886\n",
      "evaluation/EB/Q_Pred Mean            239.332\n",
      "evaluation/EB/Q_Pred Std             169.536\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           466.197\n",
      "evaluation/Actions Mean                0.149837\n",
      "evaluation/Actions Std                 0.780692\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.78756\n",
      "time/backward_zf1 (s)                  2.15854\n",
      "time/backward_zf2 (s)                  2.11071\n",
      "time/data sampling (s)                 0.283674\n",
      "time/data storing (s)                  0.0142683\n",
      "time/evaluation sampling (s)           0.300451\n",
      "time/exploration sampling (s)          0.491752\n",
      "time/logging (s)                       0.00673325\n",
      "time/preback_alpha (s)                 0.548862\n",
      "time/preback_policy (s)                1.07457\n",
      "time/preback_start (s)                 0.166312\n",
      "time/preback_zf (s)                    6.56217\n",
      "time/saving (s)                        7.16e-06\n",
      "time/training (s)                      3.32954\n",
      "time/epoch (s)                        18.8352\n",
      "time/total (s)                       614.608\n",
      "Epoch                                 31\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:35:53.590135 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 32 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 43000\n",
      "trainer/ZF1 Loss                      36.395\n",
      "trainer/ZF2 Loss                      33.7008\n",
      "trainer/ZF Expert Reward              15.0312\n",
      "trainer/ZF Policy Reward               4.17836\n",
      "trainer/ZF CHI2 Term                  45.6289\n",
      "trainer/Policy Loss                 -275.622\n",
      "trainer/Bias Loss                      7.60205\n",
      "trainer/Bias Value                    12.6411\n",
      "trainer/Policy Grad Norm              36.3013\n",
      "trainer/Policy Param Norm             30.3298\n",
      "trainer/Zf1 Grad Norm               4646.15\n",
      "trainer/Zf1 Param Norm                62.9808\n",
      "trainer/Zf2 Grad Norm               6652.08\n",
      "trainer/Zf2 Param Norm                61.7299\n",
      "trainer/Z Expert Predictions Mean    451.456\n",
      "trainer/Z Expert Predictions Std      38.1454\n",
      "trainer/Z Expert Predictions Max     542.678\n",
      "trainer/Z Expert Predictions Min      16.8315\n",
      "trainer/Z Policy Predictions Mean    269.692\n",
      "trainer/Z Policy Predictions Std     158.077\n",
      "trainer/Z Policy Predictions Max     476.02\n",
      "trainer/Z Policy Predictions Min      -5.0466\n",
      "trainer/Z Expert Targets Mean        436.424\n",
      "trainer/Z Expert Targets Std          38.6564\n",
      "trainer/Z Expert Targets Max         531.907\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        265.514\n",
      "trainer/Z Policy Targets Std         157.639\n",
      "trainer/Z Policy Targets Max         480.512\n",
      "trainer/Z Policy Targets Min          -8.02583\n",
      "trainer/Log Pis Mean                  51.16\n",
      "trainer/Log Pis Std                   24.1734\n",
      "trainer/Policy mu Mean                 0.338705\n",
      "trainer/Policy mu Std                  3.15756\n",
      "trainer/Policy log std Mean           -1.27743\n",
      "trainer/Policy log std Std             0.796961\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        42624\n",
      "exploration/num paths total          893\n",
      "evaluation/num steps total         23982\n",
      "evaluation/num paths total           330\n",
      "evaluation/path length Mean           83.5\n",
      "evaluation/path length Std             7.0746\n",
      "evaluation/path length Max            98\n",
      "evaluation/path length Min            72\n",
      "evaluation/Rewards Mean                5.27278\n",
      "evaluation/Rewards Std                 0.476795\n",
      "evaluation/Rewards Max                 6.60713\n",
      "evaluation/Rewards Min                 4.74924\n",
      "evaluation/Returns Mean              440.277\n",
      "evaluation/Returns Std                39.1964\n",
      "evaluation/Returns Max               522.939\n",
      "evaluation/Returns Min               372.31\n",
      "evaluation/Estimation Bias Mean      252.693\n",
      "evaluation/Estimation Bias Std       177.885\n",
      "evaluation/EB/Q_True Mean             23.9856\n",
      "evaluation/EB/Q_True Std              72.6279\n",
      "evaluation/EB/Q_Pred Mean            276.679\n",
      "evaluation/EB/Q_Pred Std             171.18\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           440.277\n",
      "evaluation/Actions Mean                0.206193\n",
      "evaluation/Actions Std                 0.750978\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.87154\n",
      "time/backward_zf1 (s)                  2.24262\n",
      "time/backward_zf2 (s)                  2.20248\n",
      "time/data sampling (s)                 0.283786\n",
      "time/data storing (s)                  0.0149439\n",
      "time/evaluation sampling (s)           0.236381\n",
      "time/exploration sampling (s)          0.50685\n",
      "time/logging (s)                       0.00208102\n",
      "time/preback_alpha (s)                 0.557315\n",
      "time/preback_policy (s)                1.15382\n",
      "time/preback_start (s)                 0.166905\n",
      "time/preback_zf (s)                    6.618\n",
      "time/saving (s)                        2.799e-06\n",
      "time/training (s)                      3.11274\n",
      "time/epoch (s)                        18.9695\n",
      "time/total (s)                       633.6\n",
      "Epoch                                 32\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:36:12.637663 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 33 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 44000\n",
      "trainer/ZF1 Loss                      38.6201\n",
      "trainer/ZF2 Loss                      36.28\n",
      "trainer/ZF Expert Reward              14.0493\n",
      "trainer/ZF Policy Reward               5.3185\n",
      "trainer/ZF CHI2 Term                  47.1211\n",
      "trainer/Policy Loss                 -269.853\n",
      "trainer/Bias Loss                      6.08108\n",
      "trainer/Bias Value                    12.7222\n",
      "trainer/Policy Grad Norm              30.854\n",
      "trainer/Policy Param Norm             30.546\n",
      "trainer/Zf1 Grad Norm               3945.8\n",
      "trainer/Zf1 Param Norm                63.4696\n",
      "trainer/Zf2 Grad Norm               4583.9\n",
      "trainer/Zf2 Param Norm                62.1976\n",
      "trainer/Z Expert Predictions Mean    446.174\n",
      "trainer/Z Expert Predictions Std      28.0173\n",
      "trainer/Z Expert Predictions Max     544.319\n",
      "trainer/Z Expert Predictions Min     301.971\n",
      "trainer/Z Policy Predictions Mean    263.075\n",
      "trainer/Z Policy Predictions Std     159.258\n",
      "trainer/Z Policy Predictions Max     490.449\n",
      "trainer/Z Policy Predictions Min       5.93905\n",
      "trainer/Z Expert Targets Mean        432.125\n",
      "trainer/Z Expert Targets Std          27.6713\n",
      "trainer/Z Expert Targets Max         534.103\n",
      "trainer/Z Expert Targets Min         304.597\n",
      "trainer/Z Policy Targets Mean        257.756\n",
      "trainer/Z Policy Targets Std         159.796\n",
      "trainer/Z Policy Targets Max         475.906\n",
      "trainer/Z Policy Targets Min          -4.47318\n",
      "trainer/Log Pis Mean                  51.3493\n",
      "trainer/Log Pis Std                   24.7174\n",
      "trainer/Policy mu Mean                 0.405645\n",
      "trainer/Policy mu Std                  3.17682\n",
      "trainer/Policy log std Mean           -1.31203\n",
      "trainer/Policy log std Std             0.83868\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        43580\n",
      "exploration/num paths total          903\n",
      "evaluation/num steps total         25078\n",
      "evaluation/num paths total           340\n",
      "evaluation/path length Mean          109.6\n",
      "evaluation/path length Std            12.4193\n",
      "evaluation/path length Max           130\n",
      "evaluation/path length Min            91\n",
      "evaluation/Rewards Mean                4.93213\n",
      "evaluation/Rewards Std                 0.469924\n",
      "evaluation/Rewards Max                 6.34194\n",
      "evaluation/Rewards Min                 3.04154\n",
      "evaluation/Returns Mean              540.561\n",
      "evaluation/Returns Std                69.2673\n",
      "evaluation/Returns Max               623.365\n",
      "evaluation/Returns Min               435.439\n",
      "evaluation/Estimation Bias Mean      275.286\n",
      "evaluation/Estimation Bias Std       169.589\n",
      "evaluation/EB/Q_True Mean             25.0994\n",
      "evaluation/EB/Q_True Std              76.9213\n",
      "evaluation/EB/Q_Pred Mean            300.385\n",
      "evaluation/EB/Q_Pred Std             157.286\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           540.561\n",
      "evaluation/Actions Mean                0.180006\n",
      "evaluation/Actions Std                 0.752498\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.90237\n",
      "time/backward_zf1 (s)                  2.2674\n",
      "time/backward_zf2 (s)                  2.23139\n",
      "time/data sampling (s)                 0.279317\n",
      "time/data storing (s)                  0.0141136\n",
      "time/evaluation sampling (s)           0.389286\n",
      "time/exploration sampling (s)          0.473839\n",
      "time/logging (s)                       0.00279491\n",
      "time/preback_alpha (s)                 0.545901\n",
      "time/preback_policy (s)                1.17776\n",
      "time/preback_start (s)                 0.165133\n",
      "time/preback_zf (s)                    6.55659\n",
      "time/saving (s)                        4.009e-06\n",
      "time/training (s)                      2.9724\n",
      "time/epoch (s)                        18.9783\n",
      "time/total (s)                       652.604\n",
      "Epoch                                 33\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:36:31.567631 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 34 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 45000\n",
      "trainer/ZF1 Loss                      40.4777\n",
      "trainer/ZF2 Loss                      28.0232\n",
      "trainer/ZF Expert Reward              16.3142\n",
      "trainer/ZF Policy Reward               6.24596\n",
      "trainer/ZF CHI2 Term                  46.1915\n",
      "trainer/Policy Loss                 -284.12\n",
      "trainer/Bias Loss                      9.72773\n",
      "trainer/Bias Value                    12.8026\n",
      "trainer/Policy Grad Norm              36.1396\n",
      "trainer/Policy Param Norm             30.7581\n",
      "trainer/Zf1 Grad Norm               4397.52\n",
      "trainer/Zf1 Param Norm                63.9431\n",
      "trainer/Zf2 Grad Norm               4100.4\n",
      "trainer/Zf2 Param Norm                62.6417\n",
      "trainer/Z Expert Predictions Mean    444.512\n",
      "trainer/Z Expert Predictions Std      27.0892\n",
      "trainer/Z Expert Predictions Max     545.586\n",
      "trainer/Z Expert Predictions Min     391.737\n",
      "trainer/Z Policy Predictions Mean    276.493\n",
      "trainer/Z Policy Predictions Std     158.836\n",
      "trainer/Z Policy Predictions Max     478.614\n",
      "trainer/Z Policy Predictions Min      12.6422\n",
      "trainer/Z Expert Targets Mean        428.198\n",
      "trainer/Z Expert Targets Std          27.8045\n",
      "trainer/Z Expert Targets Max         538.235\n",
      "trainer/Z Expert Targets Min         377.083\n",
      "trainer/Z Policy Targets Mean        270.247\n",
      "trainer/Z Policy Targets Std         159.486\n",
      "trainer/Z Policy Targets Max         477.17\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  48.7541\n",
      "trainer/Log Pis Std                   24.6711\n",
      "trainer/Policy mu Mean                 0.375527\n",
      "trainer/Policy mu Std                  3.0495\n",
      "trainer/Policy log std Mean           -1.31572\n",
      "trainer/Policy log std Std             0.814508\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        44432\n",
      "exploration/num paths total          911\n",
      "evaluation/num steps total         25996\n",
      "evaluation/num paths total           350\n",
      "evaluation/path length Mean           91.8\n",
      "evaluation/path length Std            17.2441\n",
      "evaluation/path length Max           125\n",
      "evaluation/path length Min            71\n",
      "evaluation/Rewards Mean                5.38077\n",
      "evaluation/Rewards Std                 0.354239\n",
      "evaluation/Rewards Max                 6.55575\n",
      "evaluation/Rewards Min                 4.84394\n",
      "evaluation/Returns Mean              493.955\n",
      "evaluation/Returns Std                91.3202\n",
      "evaluation/Returns Max               670.422\n",
      "evaluation/Returns Min               390.601\n",
      "evaluation/Estimation Bias Mean      244.661\n",
      "evaluation/Estimation Bias Std       167.974\n",
      "evaluation/EB/Q_True Mean             32.3218\n",
      "evaluation/EB/Q_True Std              90.2365\n",
      "evaluation/EB/Q_Pred Mean            276.982\n",
      "evaluation/EB/Q_Pred Std             148.465\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           493.955\n",
      "evaluation/Actions Mean                0.198637\n",
      "evaluation/Actions Std                 0.760246\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.67412\n",
      "time/backward_zf1 (s)                  2.04483\n",
      "time/backward_zf2 (s)                  1.97557\n",
      "time/data sampling (s)                 0.286313\n",
      "time/data storing (s)                  0.0150548\n",
      "time/evaluation sampling (s)           0.326156\n",
      "time/exploration sampling (s)          0.470348\n",
      "time/logging (s)                       0.00290898\n",
      "time/preback_alpha (s)                 0.549174\n",
      "time/preback_policy (s)                0.929356\n",
      "time/preback_start (s)                 0.165461\n",
      "time/preback_zf (s)                    6.58986\n",
      "time/saving (s)                        2.981e-06\n",
      "time/training (s)                      3.83652\n",
      "time/epoch (s)                        18.8657\n",
      "time/total (s)                       671.491\n",
      "Epoch                                 34\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:36:50.803767 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 35 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 46000\n",
      "trainer/ZF1 Loss                      31.8074\n",
      "trainer/ZF2 Loss                      25.4629\n",
      "trainer/ZF Expert Reward              13.5841\n",
      "trainer/ZF Policy Reward               5.19206\n",
      "trainer/ZF CHI2 Term                  38.003\n",
      "trainer/Policy Loss                 -263.022\n",
      "trainer/Bias Loss                      8.28293\n",
      "trainer/Bias Value                    12.8826\n",
      "trainer/Policy Grad Norm              38.4309\n",
      "trainer/Policy Param Norm             30.986\n",
      "trainer/Zf1 Grad Norm               3253.68\n",
      "trainer/Zf1 Param Norm                64.4279\n",
      "trainer/Zf2 Grad Norm               2529.49\n",
      "trainer/Zf2 Param Norm                63.1003\n",
      "trainer/Z Expert Predictions Mean    429.073\n",
      "trainer/Z Expert Predictions Std      27.0683\n",
      "trainer/Z Expert Predictions Max     546.602\n",
      "trainer/Z Expert Predictions Min     364.869\n",
      "trainer/Z Policy Predictions Mean    256.353\n",
      "trainer/Z Policy Predictions Std     160.861\n",
      "trainer/Z Policy Predictions Max     479.968\n",
      "trainer/Z Policy Predictions Min      -4.61754\n",
      "trainer/Z Expert Targets Mean        415.489\n",
      "trainer/Z Expert Targets Std          28.4938\n",
      "trainer/Z Expert Targets Max         539.775\n",
      "trainer/Z Expert Targets Min         352.057\n",
      "trainer/Z Policy Targets Mean        251.161\n",
      "trainer/Z Policy Targets Std         161.186\n",
      "trainer/Z Policy Targets Max         480.142\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  51.4308\n",
      "trainer/Log Pis Std                   24.9635\n",
      "trainer/Policy mu Mean                 0.531815\n",
      "trainer/Policy mu Std                  3.21669\n",
      "trainer/Policy log std Mean           -1.27616\n",
      "trainer/Policy log std Std             0.847046\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        45592\n",
      "exploration/num paths total          922\n",
      "evaluation/num steps total         26877\n",
      "evaluation/num paths total           360\n",
      "evaluation/path length Mean           88.1\n",
      "evaluation/path length Std            25.9286\n",
      "evaluation/path length Max           127\n",
      "evaluation/path length Min            56\n",
      "evaluation/Rewards Mean                5.16024\n",
      "evaluation/Rewards Std                 0.19894\n",
      "evaluation/Rewards Max                 5.93445\n",
      "evaluation/Rewards Min                 4.82931\n",
      "evaluation/Returns Mean              454.617\n",
      "evaluation/Returns Std               134.343\n",
      "evaluation/Returns Max               651.433\n",
      "evaluation/Returns Min               289.747\n",
      "evaluation/Estimation Bias Mean      310.343\n",
      "evaluation/Estimation Bias Std       148.121\n",
      "evaluation/EB/Q_True Mean             32.7694\n",
      "evaluation/EB/Q_True Std              88.9986\n",
      "evaluation/EB/Q_Pred Mean            343.113\n",
      "evaluation/EB/Q_Pred Std             131.489\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           454.617\n",
      "evaluation/Actions Mean                0.142359\n",
      "evaluation/Actions Std                 0.723345\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.90964\n",
      "time/backward_zf1 (s)                  2.29148\n",
      "time/backward_zf2 (s)                  2.24199\n",
      "time/data sampling (s)                 0.295937\n",
      "time/data storing (s)                  0.0145923\n",
      "time/evaluation sampling (s)           0.296348\n",
      "time/exploration sampling (s)          0.481091\n",
      "time/logging (s)                       0.00266271\n",
      "time/preback_alpha (s)                 0.558064\n",
      "time/preback_policy (s)                1.14559\n",
      "time/preback_start (s)                 0.16897\n",
      "time/preback_zf (s)                    6.59932\n",
      "time/saving (s)                        2.957e-06\n",
      "time/training (s)                      3.1628\n",
      "time/epoch (s)                        19.1685\n",
      "time/total (s)                       690.679\n",
      "Epoch                                 35\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:37:09.727661 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 36 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 47000\n",
      "trainer/ZF1 Loss                      23.3416\n",
      "trainer/ZF2 Loss                      22.2945\n",
      "trainer/ZF Expert Reward              13.8847\n",
      "trainer/ZF Policy Reward               4.20562\n",
      "trainer/ZF CHI2 Term                  32.598\n",
      "trainer/Policy Loss                 -266.156\n",
      "trainer/Bias Loss                      3.80675\n",
      "trainer/Bias Value                    12.9629\n",
      "trainer/Policy Grad Norm              35.2878\n",
      "trainer/Policy Param Norm             31.2286\n",
      "trainer/Zf1 Grad Norm               2841.08\n",
      "trainer/Zf1 Param Norm                64.885\n",
      "trainer/Zf2 Grad Norm               4237.6\n",
      "trainer/Zf2 Param Norm                63.5131\n",
      "trainer/Z Expert Predictions Mean    420.141\n",
      "trainer/Z Expert Predictions Std      28.3753\n",
      "trainer/Z Expert Predictions Max     547.784\n",
      "trainer/Z Expert Predictions Min     338.397\n",
      "trainer/Z Policy Predictions Mean    257.317\n",
      "trainer/Z Policy Predictions Std     159.67\n",
      "trainer/Z Policy Predictions Max     496.206\n",
      "trainer/Z Policy Predictions Min       9.61246\n",
      "trainer/Z Expert Targets Mean        406.256\n",
      "trainer/Z Expert Targets Std          29.1779\n",
      "trainer/Z Expert Targets Max         536.951\n",
      "trainer/Z Expert Targets Min         312.678\n",
      "trainer/Z Policy Targets Mean        253.111\n",
      "trainer/Z Policy Targets Std         160.696\n",
      "trainer/Z Policy Targets Max         488.666\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  48.7947\n",
      "trainer/Log Pis Std                   22.0648\n",
      "trainer/Policy mu Mean                 0.611304\n",
      "trainer/Policy mu Std                  2.99264\n",
      "trainer/Policy log std Mean           -1.31343\n",
      "trainer/Policy log std Std             0.848606\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        46510\n",
      "exploration/num paths total          931\n",
      "evaluation/num steps total         27889\n",
      "evaluation/num paths total           370\n",
      "evaluation/path length Mean          101.2\n",
      "evaluation/path length Std            23.3872\n",
      "evaluation/path length Max           151\n",
      "evaluation/path length Min            79\n",
      "evaluation/Rewards Mean                5.31965\n",
      "evaluation/Rewards Std                 0.347096\n",
      "evaluation/Rewards Max                 6.49092\n",
      "evaluation/Rewards Min                 4.85205\n",
      "evaluation/Returns Mean              538.349\n",
      "evaluation/Returns Std               121.383\n",
      "evaluation/Returns Max               790.76\n",
      "evaluation/Returns Min               421.129\n",
      "evaluation/Estimation Bias Mean      262.591\n",
      "evaluation/Estimation Bias Std       176.594\n",
      "evaluation/EB/Q_True Mean             38.8863\n",
      "evaluation/EB/Q_True Std             102.48\n",
      "evaluation/EB/Q_Pred Mean            301.478\n",
      "evaluation/EB/Q_Pred Std             149.468\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           538.349\n",
      "evaluation/Actions Mean                0.163474\n",
      "evaluation/Actions Std                 0.738984\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.74726\n",
      "time/backward_zf1 (s)                  2.13097\n",
      "time/backward_zf2 (s)                  2.06922\n",
      "time/data sampling (s)                 0.284553\n",
      "time/data storing (s)                  0.0143112\n",
      "time/evaluation sampling (s)           0.365717\n",
      "time/exploration sampling (s)          0.453109\n",
      "time/logging (s)                       0.0026385\n",
      "time/preback_alpha (s)                 0.550134\n",
      "time/preback_policy (s)                1.01934\n",
      "time/preback_start (s)                 0.167243\n",
      "time/preback_zf (s)                    6.59144\n",
      "time/saving (s)                        2.881e-06\n",
      "time/training (s)                      3.46273\n",
      "time/epoch (s)                        18.8587\n",
      "time/total (s)                       709.559\n",
      "Epoch                                 36\n",
      "---------------------------------  -------------\n",
      "2024-07-28 20:37:28.738731 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 37 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 48000\n",
      "trainer/ZF1 Loss                      21.5501\n",
      "trainer/ZF2 Loss                      26.4527\n",
      "trainer/ZF Expert Reward              14.3935\n",
      "trainer/ZF Policy Reward               4.17021\n",
      "trainer/ZF CHI2 Term                  34.3046\n",
      "trainer/Policy Loss                 -273.033\n",
      "trainer/Bias Loss                      4.82009\n",
      "trainer/Bias Value                    13.0445\n",
      "trainer/Policy Grad Norm              34.26\n",
      "trainer/Policy Param Norm             31.4645\n",
      "trainer/Zf1 Grad Norm               2441.39\n",
      "trainer/Zf1 Param Norm                65.3632\n",
      "trainer/Zf2 Grad Norm               2969.43\n",
      "trainer/Zf2 Param Norm                63.969\n",
      "trainer/Z Expert Predictions Mean    417.107\n",
      "trainer/Z Expert Predictions Std      27.6566\n",
      "trainer/Z Expert Predictions Max     546.215\n",
      "trainer/Z Expert Predictions Min     352.932\n",
      "trainer/Z Policy Predictions Mean    265.207\n",
      "trainer/Z Policy Predictions Std     161.161\n",
      "trainer/Z Policy Predictions Max     489.004\n",
      "trainer/Z Policy Predictions Min       0.039942\n",
      "trainer/Z Expert Targets Mean        402.713\n",
      "trainer/Z Expert Targets Std          28.2066\n",
      "trainer/Z Expert Targets Max         535.113\n",
      "trainer/Z Expert Targets Min         339.357\n",
      "trainer/Z Policy Targets Mean        261.036\n",
      "trainer/Z Policy Targets Std         161.615\n",
      "trainer/Z Policy Targets Max         476.048\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  48.7493\n",
      "trainer/Log Pis Std                   24.8491\n",
      "trainer/Policy mu Mean                 0.52468\n",
      "trainer/Policy mu Std                  3.17291\n",
      "trainer/Policy log std Mean           -1.30749\n",
      "trainer/Policy log std Std             0.897825\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        47668\n",
      "exploration/num paths total          943\n",
      "evaluation/num steps total         28756\n",
      "evaluation/num paths total           380\n",
      "evaluation/path length Mean           86.7\n",
      "evaluation/path length Std             9.70618\n",
      "evaluation/path length Max           112\n",
      "evaluation/path length Min            74\n",
      "evaluation/Rewards Mean                5.3748\n",
      "evaluation/Rewards Std                 0.4458\n",
      "evaluation/Rewards Max                 6.64356\n",
      "evaluation/Rewards Min                 4.83859\n",
      "evaluation/Returns Mean              465.995\n",
      "evaluation/Returns Std                51.7909\n",
      "evaluation/Returns Max               596.506\n",
      "evaluation/Returns Min               391.239\n",
      "evaluation/Estimation Bias Mean      236.864\n",
      "evaluation/Estimation Bias Std       181.232\n",
      "evaluation/EB/Q_True Mean             28.63\n",
      "evaluation/EB/Q_True Std              82.1855\n",
      "evaluation/EB/Q_Pred Mean            265.494\n",
      "evaluation/EB/Q_Pred Std             169.92\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           465.995\n",
      "evaluation/Actions Mean                0.135479\n",
      "evaluation/Actions Std                 0.743702\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.85335\n",
      "time/backward_zf1 (s)                  2.2348\n",
      "time/backward_zf2 (s)                  2.19199\n",
      "time/data sampling (s)                 0.296847\n",
      "time/data storing (s)                  0.0144804\n",
      "time/evaluation sampling (s)           0.292691\n",
      "time/exploration sampling (s)          0.465892\n",
      "time/logging (s)                       0.00209003\n",
      "time/preback_alpha (s)                 0.554256\n",
      "time/preback_policy (s)                1.13639\n",
      "time/preback_start (s)                 0.168464\n",
      "time/preback_zf (s)                    6.58231\n",
      "time/saving (s)                        2.938e-06\n",
      "time/training (s)                      3.15552\n",
      "time/epoch (s)                        18.9491\n",
      "time/total (s)                       728.524\n",
      "Epoch                                 37\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:37:47.822854 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 38 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 49000\n",
      "trainer/ZF1 Loss                      27.4315\n",
      "trainer/ZF2 Loss                      25.4301\n",
      "trainer/ZF Expert Reward              15.3556\n",
      "trainer/ZF Policy Reward               5.63968\n",
      "trainer/ZF CHI2 Term                  37.6965\n",
      "trainer/Policy Loss                 -255.521\n",
      "trainer/Bias Loss                     11.4324\n",
      "trainer/Bias Value                    13.126\n",
      "trainer/Policy Grad Norm              41.2456\n",
      "trainer/Policy Param Norm             31.7073\n",
      "trainer/Zf1 Grad Norm               3922.03\n",
      "trainer/Zf1 Param Norm                65.8111\n",
      "trainer/Zf2 Grad Norm               4140.38\n",
      "trainer/Zf2 Param Norm                64.3887\n",
      "trainer/Z Expert Predictions Mean    414.932\n",
      "trainer/Z Expert Predictions Std      37.7033\n",
      "trainer/Z Expert Predictions Max     550.434\n",
      "trainer/Z Expert Predictions Min      18.072\n",
      "trainer/Z Policy Predictions Mean    251.033\n",
      "trainer/Z Policy Predictions Std     155.091\n",
      "trainer/Z Policy Predictions Max     503.537\n",
      "trainer/Z Policy Predictions Min      -4.90205\n",
      "trainer/Z Expert Targets Mean        399.576\n",
      "trainer/Z Expert Targets Std          39.0496\n",
      "trainer/Z Expert Targets Max         542.101\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        245.394\n",
      "trainer/Z Policy Targets Std         155.916\n",
      "trainer/Z Policy Targets Max         497.171\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  48.4259\n",
      "trainer/Log Pis Std                   23.6425\n",
      "trainer/Policy mu Mean                 0.308174\n",
      "trainer/Policy mu Std                  3.32025\n",
      "trainer/Policy log std Mean           -1.24811\n",
      "trainer/Policy log std Std             0.890819\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        48495\n",
      "exploration/num paths total          954\n",
      "evaluation/num steps total         29719\n",
      "evaluation/num paths total           390\n",
      "evaluation/path length Mean           96.3\n",
      "evaluation/path length Std            14.8395\n",
      "evaluation/path length Max           129\n",
      "evaluation/path length Min            81\n",
      "evaluation/Rewards Mean                5.25746\n",
      "evaluation/Rewards Std                 0.356903\n",
      "evaluation/Rewards Max                 6.65774\n",
      "evaluation/Rewards Min                 4.82651\n",
      "evaluation/Returns Mean              506.293\n",
      "evaluation/Returns Std                79.1768\n",
      "evaluation/Returns Max               676.106\n",
      "evaluation/Returns Min               433.588\n",
      "evaluation/Estimation Bias Mean      250.941\n",
      "evaluation/Estimation Bias Std       173.149\n",
      "evaluation/EB/Q_True Mean             31.8521\n",
      "evaluation/EB/Q_True Std              89.4209\n",
      "evaluation/EB/Q_Pred Mean            282.793\n",
      "evaluation/EB/Q_Pred Std             153.808\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           506.293\n",
      "evaluation/Actions Mean                0.182758\n",
      "evaluation/Actions Std                 0.740299\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.88645\n",
      "time/backward_zf1 (s)                  2.27633\n",
      "time/backward_zf2 (s)                  2.2332\n",
      "time/data sampling (s)                 0.290822\n",
      "time/data storing (s)                  0.0142201\n",
      "time/evaluation sampling (s)           0.369189\n",
      "time/exploration sampling (s)          0.458781\n",
      "time/logging (s)                       0.00226813\n",
      "time/preback_alpha (s)                 0.551266\n",
      "time/preback_policy (s)                1.15162\n",
      "time/preback_start (s)                 0.167612\n",
      "time/preback_zf (s)                    6.56079\n",
      "time/saving (s)                        3.083e-06\n",
      "time/training (s)                      3.05621\n",
      "time/epoch (s)                        19.0188\n",
      "time/total (s)                       747.564\n",
      "Epoch                                 38\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:38:07.350022 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 39 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 50000\n",
      "trainer/ZF1 Loss                      27.9186\n",
      "trainer/ZF2 Loss                      22.04\n",
      "trainer/ZF Expert Reward              14.4778\n",
      "trainer/ZF Policy Reward               5.44954\n",
      "trainer/ZF CHI2 Term                  35.3659\n",
      "trainer/Policy Loss                 -258.158\n",
      "trainer/Bias Loss                      4.65667\n",
      "trainer/Bias Value                    13.2061\n",
      "trainer/Policy Grad Norm              37.1363\n",
      "trainer/Policy Param Norm             31.9309\n",
      "trainer/Zf1 Grad Norm               3870.66\n",
      "trainer/Zf1 Param Norm                66.2658\n",
      "trainer/Zf2 Grad Norm               2576.05\n",
      "trainer/Zf2 Param Norm                64.8145\n",
      "trainer/Z Expert Predictions Mean    414.807\n",
      "trainer/Z Expert Predictions Std      30.8893\n",
      "trainer/Z Expert Predictions Max     553.831\n",
      "trainer/Z Expert Predictions Min     349.922\n",
      "trainer/Z Policy Predictions Mean    252.409\n",
      "trainer/Z Policy Predictions Std     153.58\n",
      "trainer/Z Policy Predictions Max     476.726\n",
      "trainer/Z Policy Predictions Min       6.02644\n",
      "trainer/Z Expert Targets Mean        400.329\n",
      "trainer/Z Expert Targets Std          31.2129\n",
      "trainer/Z Expert Targets Max         544.355\n",
      "trainer/Z Expert Targets Min         339.122\n",
      "trainer/Z Policy Targets Mean        246.959\n",
      "trainer/Z Policy Targets Std         153.763\n",
      "trainer/Z Policy Targets Max         478.98\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  46.7475\n",
      "trainer/Log Pis Std                   23.3192\n",
      "trainer/Policy mu Mean                 0.231949\n",
      "trainer/Policy mu Std                  3.00764\n",
      "trainer/Policy log std Mean           -1.31354\n",
      "trainer/Policy log std Std             0.856453\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        49523\n",
      "exploration/num paths total          965\n",
      "evaluation/num steps total         30766\n",
      "evaluation/num paths total           400\n",
      "evaluation/path length Mean          104.7\n",
      "evaluation/path length Std            19.0948\n",
      "evaluation/path length Max           144\n",
      "evaluation/path length Min            73\n",
      "evaluation/Rewards Mean                4.88592\n",
      "evaluation/Rewards Std                 0.510091\n",
      "evaluation/Rewards Max                 6.29157\n",
      "evaluation/Rewards Min                 2.93508\n",
      "evaluation/Returns Mean              511.556\n",
      "evaluation/Returns Std                77.7605\n",
      "evaluation/Returns Max               679.509\n",
      "evaluation/Returns Min               386.862\n",
      "evaluation/Estimation Bias Mean      250.677\n",
      "evaluation/Estimation Bias Std       160.954\n",
      "evaluation/EB/Q_True Mean             19.7891\n",
      "evaluation/EB/Q_True Std              57.7344\n",
      "evaluation/EB/Q_Pred Mean            270.466\n",
      "evaluation/EB/Q_Pred Std             159.504\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           511.556\n",
      "evaluation/Actions Mean                0.165162\n",
      "evaluation/Actions Std                 0.711311\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.94674\n",
      "time/backward_zf1 (s)                  2.3286\n",
      "time/backward_zf2 (s)                  2.27472\n",
      "time/data sampling (s)                 0.30023\n",
      "time/data storing (s)                  0.0147365\n",
      "time/evaluation sampling (s)           0.376032\n",
      "time/exploration sampling (s)          0.477937\n",
      "time/logging (s)                       0.0023517\n",
      "time/preback_alpha (s)                 0.569995\n",
      "time/preback_policy (s)                1.16702\n",
      "time/preback_start (s)                 0.172191\n",
      "time/preback_zf (s)                    6.66205\n",
      "time/saving (s)                        3.50099e-06\n",
      "time/training (s)                      3.16344\n",
      "time/epoch (s)                        19.4561\n",
      "time/total (s)                       767.046\n",
      "Epoch                                 39\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:38:26.238261 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 40 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 51000\n",
      "trainer/ZF1 Loss                      21.766\n",
      "trainer/ZF2 Loss                      22.8571\n",
      "trainer/ZF Expert Reward              15.668\n",
      "trainer/ZF Policy Reward               4.93303\n",
      "trainer/ZF CHI2 Term                  33.8472\n",
      "trainer/Policy Loss                 -254.227\n",
      "trainer/Bias Loss                      9.9941\n",
      "trainer/Bias Value                    13.2868\n",
      "trainer/Policy Grad Norm              34.6358\n",
      "trainer/Policy Param Norm             32.1417\n",
      "trainer/Zf1 Grad Norm               2053.07\n",
      "trainer/Zf1 Param Norm                66.7308\n",
      "trainer/Zf2 Grad Norm               3066.18\n",
      "trainer/Zf2 Param Norm                65.2368\n",
      "trainer/Z Expert Predictions Mean    421.635\n",
      "trainer/Z Expert Predictions Std      29.5971\n",
      "trainer/Z Expert Predictions Max     550.709\n",
      "trainer/Z Expert Predictions Min     353.396\n",
      "trainer/Z Policy Predictions Mean    249.921\n",
      "trainer/Z Policy Predictions Std     158.582\n",
      "trainer/Z Policy Predictions Max     480.61\n",
      "trainer/Z Policy Predictions Min       0.426836\n",
      "trainer/Z Expert Targets Mean        405.967\n",
      "trainer/Z Expert Targets Std          31.0201\n",
      "trainer/Z Expert Targets Max         540.6\n",
      "trainer/Z Expert Targets Min         334.986\n",
      "trainer/Z Policy Targets Mean        244.988\n",
      "trainer/Z Policy Targets Std         159.841\n",
      "trainer/Z Policy Targets Max         482.761\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  47.5156\n",
      "trainer/Log Pis Std                   21.5709\n",
      "trainer/Policy mu Mean                 0.306927\n",
      "trainer/Policy mu Std                  3.29099\n",
      "trainer/Policy log std Mean           -1.31243\n",
      "trainer/Policy log std Std             0.953286\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        50478\n",
      "exploration/num paths total          975\n",
      "evaluation/num steps total         31631\n",
      "evaluation/num paths total           410\n",
      "evaluation/path length Mean           86.5\n",
      "evaluation/path length Std            15.1806\n",
      "evaluation/path length Max           121\n",
      "evaluation/path length Min            68\n",
      "evaluation/Rewards Mean                4.85559\n",
      "evaluation/Rewards Std                 0.409922\n",
      "evaluation/Rewards Max                 6.27597\n",
      "evaluation/Rewards Min                 3.51904\n",
      "evaluation/Returns Mean              420.008\n",
      "evaluation/Returns Std                87.8881\n",
      "evaluation/Returns Max               628.143\n",
      "evaluation/Returns Min               324.954\n",
      "evaluation/Estimation Bias Mean      245.07\n",
      "evaluation/Estimation Bias Std       174.245\n",
      "evaluation/EB/Q_True Mean             31.4622\n",
      "evaluation/EB/Q_True Std              86.3691\n",
      "evaluation/EB/Q_Pred Mean            276.532\n",
      "evaluation/EB/Q_Pred Std             161.652\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           420.008\n",
      "evaluation/Actions Mean                0.121242\n",
      "evaluation/Actions Std                 0.733054\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.66649\n",
      "time/backward_zf1 (s)                  2.05613\n",
      "time/backward_zf2 (s)                  1.98724\n",
      "time/data sampling (s)                 0.28679\n",
      "time/data storing (s)                  0.0142065\n",
      "time/evaluation sampling (s)           0.268302\n",
      "time/exploration sampling (s)          0.446271\n",
      "time/logging (s)                       0.00254782\n",
      "time/preback_alpha (s)                 0.55238\n",
      "time/preback_policy (s)                0.907733\n",
      "time/preback_start (s)                 0.165424\n",
      "time/preback_zf (s)                    6.58822\n",
      "time/saving (s)                        2.894e-06\n",
      "time/training (s)                      3.88203\n",
      "time/epoch (s)                        18.8238\n",
      "time/total (s)                       785.89\n",
      "Epoch                                 40\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:38:45.439634 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 41 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 52000\n",
      "trainer/ZF1 Loss                      28.4114\n",
      "trainer/ZF2 Loss                      24.9728\n",
      "trainer/ZF Expert Reward              14.1441\n",
      "trainer/ZF Policy Reward               4.80705\n",
      "trainer/ZF CHI2 Term                  36.7965\n",
      "trainer/Policy Loss                 -239.857\n",
      "trainer/Bias Loss                      3.16272\n",
      "trainer/Bias Value                    13.3698\n",
      "trainer/Policy Grad Norm              36.5158\n",
      "trainer/Policy Param Norm             32.381\n",
      "trainer/Zf1 Grad Norm               2839.04\n",
      "trainer/Zf1 Param Norm                67.2016\n",
      "trainer/Zf2 Grad Norm               3772.64\n",
      "trainer/Zf2 Param Norm                65.6804\n",
      "trainer/Z Expert Predictions Mean    411.106\n",
      "trainer/Z Expert Predictions Std      35.73\n",
      "trainer/Z Expert Predictions Max     523.84\n",
      "trainer/Z Expert Predictions Min      12.8471\n",
      "trainer/Z Policy Predictions Mean    234.988\n",
      "trainer/Z Policy Predictions Std     153.422\n",
      "trainer/Z Policy Predictions Max     493.649\n",
      "trainer/Z Policy Predictions Min      -2.07099\n",
      "trainer/Z Expert Targets Mean        396.961\n",
      "trainer/Z Expert Targets Std          35.67\n",
      "trainer/Z Expert Targets Max         509.982\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        230.181\n",
      "trainer/Z Policy Targets Std         153.875\n",
      "trainer/Z Policy Targets Max         475.307\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  49.7791\n",
      "trainer/Log Pis Std                   22.8542\n",
      "trainer/Policy mu Mean                 0.291649\n",
      "trainer/Policy mu Std                  3.39766\n",
      "trainer/Policy log std Mean           -1.26103\n",
      "trainer/Policy log std Std             0.970637\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        51387\n",
      "exploration/num paths total          985\n",
      "evaluation/num steps total         32514\n",
      "evaluation/num paths total           420\n",
      "evaluation/path length Mean           88.3\n",
      "evaluation/path length Std            17.1933\n",
      "evaluation/path length Max           121\n",
      "evaluation/path length Min            68\n",
      "evaluation/Rewards Mean                4.68581\n",
      "evaluation/Rewards Std                 0.409705\n",
      "evaluation/Rewards Max                 5.74872\n",
      "evaluation/Rewards Min                 3.2925\n",
      "evaluation/Returns Mean              413.757\n",
      "evaluation/Returns Std                94.0476\n",
      "evaluation/Returns Max               620.674\n",
      "evaluation/Returns Min               317.714\n",
      "evaluation/Estimation Bias Mean      246.95\n",
      "evaluation/Estimation Bias Std       160.604\n",
      "evaluation/EB/Q_True Mean             17.0212\n",
      "evaluation/EB/Q_True Std              49.3817\n",
      "evaluation/EB/Q_Pred Mean            263.972\n",
      "evaluation/EB/Q_Pred Std             161.376\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           413.757\n",
      "evaluation/Actions Mean                0.0984278\n",
      "evaluation/Actions Std                 0.743673\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.81798\n",
      "time/backward_zf1 (s)                  2.20887\n",
      "time/backward_zf2 (s)                  2.16034\n",
      "time/data sampling (s)                 0.298411\n",
      "time/data storing (s)                  0.0156248\n",
      "time/evaluation sampling (s)           0.358406\n",
      "time/exploration sampling (s)          0.472443\n",
      "time/logging (s)                       0.00346286\n",
      "time/preback_alpha (s)                 0.559398\n",
      "time/preback_policy (s)                1.08142\n",
      "time/preback_start (s)                 0.168652\n",
      "time/preback_zf (s)                    6.61299\n",
      "time/saving (s)                        4.565e-06\n",
      "time/training (s)                      3.37784\n",
      "time/epoch (s)                        19.1359\n",
      "time/total (s)                       805.048\n",
      "Epoch                                 41\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:39:04.591798 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 42 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 53000\n",
      "trainer/ZF1 Loss                      23.497\n",
      "trainer/ZF2 Loss                      23.5088\n",
      "trainer/ZF Expert Reward              12.6791\n",
      "trainer/ZF Policy Reward               6.14267\n",
      "trainer/ZF CHI2 Term                  32.1671\n",
      "trainer/Policy Loss                 -234.668\n",
      "trainer/Bias Loss                      3.43778\n",
      "trainer/Bias Value                    13.4527\n",
      "trainer/Policy Grad Norm              31.515\n",
      "trainer/Policy Param Norm             32.6014\n",
      "trainer/Zf1 Grad Norm               2946.33\n",
      "trainer/Zf1 Param Norm                67.6544\n",
      "trainer/Zf2 Grad Norm               3982.57\n",
      "trainer/Zf2 Param Norm                66.1025\n",
      "trainer/Z Expert Predictions Mean    410.294\n",
      "trainer/Z Expert Predictions Std      27.9898\n",
      "trainer/Z Expert Predictions Max     546.843\n",
      "trainer/Z Expert Predictions Min     337.044\n",
      "trainer/Z Policy Predictions Mean    233.605\n",
      "trainer/Z Policy Predictions Std     140.707\n",
      "trainer/Z Policy Predictions Max     468.135\n",
      "trainer/Z Policy Predictions Min      -3.59033\n",
      "trainer/Z Expert Targets Mean        397.615\n",
      "trainer/Z Expert Targets Std          28.0347\n",
      "trainer/Z Expert Targets Max         539.807\n",
      "trainer/Z Expert Targets Min         323.274\n",
      "trainer/Z Policy Targets Mean        227.462\n",
      "trainer/Z Policy Targets Std         140.929\n",
      "trainer/Z Policy Targets Max         469.377\n",
      "trainer/Z Policy Targets Min          -9.59117\n",
      "trainer/Log Pis Mean                  46.6174\n",
      "trainer/Log Pis Std                   19.4369\n",
      "trainer/Policy mu Mean                 0.136736\n",
      "trainer/Policy mu Std                  2.85226\n",
      "trainer/Policy log std Mean           -1.3001\n",
      "trainer/Policy log std Std             0.838691\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        52517\n",
      "exploration/num paths total          995\n",
      "evaluation/num steps total         33590\n",
      "evaluation/num paths total           430\n",
      "evaluation/path length Mean          107.6\n",
      "evaluation/path length Std            25.6445\n",
      "evaluation/path length Max           159\n",
      "evaluation/path length Min            75\n",
      "evaluation/Rewards Mean                5.11757\n",
      "evaluation/Rewards Std                 0.448675\n",
      "evaluation/Rewards Max                 6.46733\n",
      "evaluation/Rewards Min                 3.40188\n",
      "evaluation/Returns Mean              550.65\n",
      "evaluation/Returns Std               128.638\n",
      "evaluation/Returns Max               840.634\n",
      "evaluation/Returns Min               390.326\n",
      "evaluation/Estimation Bias Mean      230.825\n",
      "evaluation/Estimation Bias Std       184.639\n",
      "evaluation/EB/Q_True Mean             40.1458\n",
      "evaluation/EB/Q_True Std             106.173\n",
      "evaluation/EB/Q_Pred Mean            270.97\n",
      "evaluation/EB/Q_Pred Std             154.501\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           550.65\n",
      "evaluation/Actions Mean                0.060068\n",
      "evaluation/Actions Std                 0.754863\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.88781\n",
      "time/backward_zf1 (s)                  2.26449\n",
      "time/backward_zf2 (s)                  2.2268\n",
      "time/data sampling (s)                 0.289304\n",
      "time/data storing (s)                  0.014445\n",
      "time/evaluation sampling (s)           0.394653\n",
      "time/exploration sampling (s)          0.490448\n",
      "time/logging (s)                       0.00231369\n",
      "time/preback_alpha (s)                 0.553398\n",
      "time/preback_policy (s)                1.1469\n",
      "time/preback_start (s)                 0.168824\n",
      "time/preback_zf (s)                    6.57871\n",
      "time/saving (s)                        2.629e-06\n",
      "time/training (s)                      3.06702\n",
      "time/epoch (s)                        19.0851\n",
      "time/total (s)                       824.154\n",
      "Epoch                                 42\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:39:23.751139 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 43 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 54000\n",
      "trainer/ZF1 Loss                      30.634\n",
      "trainer/ZF2 Loss                      24.8662\n",
      "trainer/ZF Expert Reward              15.3666\n",
      "trainer/ZF Policy Reward               5.91025\n",
      "trainer/ZF CHI2 Term                  39.0679\n",
      "trainer/Policy Loss                 -239.541\n",
      "trainer/Bias Loss                      8.98523\n",
      "trainer/Bias Value                    13.5365\n",
      "trainer/Policy Grad Norm              34.9601\n",
      "trainer/Policy Param Norm             32.8194\n",
      "trainer/Zf1 Grad Norm               3938.35\n",
      "trainer/Zf1 Param Norm                68.1006\n",
      "trainer/Zf2 Grad Norm               3181.76\n",
      "trainer/Zf2 Param Norm                66.5251\n",
      "trainer/Z Expert Predictions Mean    410.887\n",
      "trainer/Z Expert Predictions Std      42.4226\n",
      "trainer/Z Expert Predictions Max     557.707\n",
      "trainer/Z Expert Predictions Min      19.9316\n",
      "trainer/Z Policy Predictions Mean    235.784\n",
      "trainer/Z Policy Predictions Std     145.271\n",
      "trainer/Z Policy Predictions Max     493.568\n",
      "trainer/Z Policy Predictions Min      -0.806322\n",
      "trainer/Z Expert Targets Mean        395.521\n",
      "trainer/Z Expert Targets Std          43.6784\n",
      "trainer/Z Expert Targets Max         544.47\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        229.873\n",
      "trainer/Z Policy Targets Std         145.154\n",
      "trainer/Z Policy Targets Max         478.317\n",
      "trainer/Z Policy Targets Min          -4.55086\n",
      "trainer/Log Pis Mean                  45.8731\n",
      "trainer/Log Pis Std                   19.938\n",
      "trainer/Policy mu Mean                 0.372094\n",
      "trainer/Policy mu Std                  2.75454\n",
      "trainer/Policy log std Mean           -1.41725\n",
      "trainer/Policy log std Std             0.862588\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        53278\n",
      "exploration/num paths total         1002\n",
      "evaluation/num steps total         34534\n",
      "evaluation/num paths total           440\n",
      "evaluation/path length Mean           94.4\n",
      "evaluation/path length Std            11.9599\n",
      "evaluation/path length Max           107\n",
      "evaluation/path length Min            76\n",
      "evaluation/Rewards Mean                4.89712\n",
      "evaluation/Rewards Std                 0.510846\n",
      "evaluation/Rewards Max                 6.03696\n",
      "evaluation/Rewards Min                 3.17816\n",
      "evaluation/Returns Mean              462.288\n",
      "evaluation/Returns Std                38.3575\n",
      "evaluation/Returns Max               507.08\n",
      "evaluation/Returns Min               398.523\n",
      "evaluation/Estimation Bias Mean      235.373\n",
      "evaluation/Estimation Bias Std       160.672\n",
      "evaluation/EB/Q_True Mean             19.2467\n",
      "evaluation/EB/Q_True Std              62.06\n",
      "evaluation/EB/Q_Pred Mean            254.619\n",
      "evaluation/EB/Q_Pred Std             157.583\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           462.288\n",
      "evaluation/Actions Mean                0.0289036\n",
      "evaluation/Actions Std                 0.754389\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.91409\n",
      "time/backward_zf1 (s)                  2.28756\n",
      "time/backward_zf2 (s)                  2.26452\n",
      "time/data sampling (s)                 0.291746\n",
      "time/data storing (s)                  0.0143493\n",
      "time/evaluation sampling (s)           0.292916\n",
      "time/exploration sampling (s)          0.479009\n",
      "time/logging (s)                       0.0022168\n",
      "time/preback_alpha (s)                 0.559757\n",
      "time/preback_policy (s)                1.18792\n",
      "time/preback_start (s)                 0.168477\n",
      "time/preback_zf (s)                    6.60333\n",
      "time/saving (s)                        2.784e-06\n",
      "time/training (s)                      3.02927\n",
      "time/epoch (s)                        19.0952\n",
      "time/total (s)                       843.267\n",
      "Epoch                                 43\n",
      "---------------------------------  -------------\n",
      "2024-07-28 20:39:42.995122 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 44 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 55000\n",
      "trainer/ZF1 Loss                      26.6775\n",
      "trainer/ZF2 Loss                      22.3906\n",
      "trainer/ZF Expert Reward              11.7677\n",
      "trainer/ZF Policy Reward               4.46095\n",
      "trainer/ZF CHI2 Term                  32.3274\n",
      "trainer/Policy Loss                 -244.372\n",
      "trainer/Bias Loss                      5.07993\n",
      "trainer/Bias Value                    13.6205\n",
      "trainer/Policy Grad Norm              34.7337\n",
      "trainer/Policy Param Norm             33.0491\n",
      "trainer/Zf1 Grad Norm               4199.59\n",
      "trainer/Zf1 Param Norm                68.5182\n",
      "trainer/Zf2 Grad Norm               4010.01\n",
      "trainer/Zf2 Param Norm                66.9521\n",
      "trainer/Z Expert Predictions Mean    402.926\n",
      "trainer/Z Expert Predictions Std      26.7857\n",
      "trainer/Z Expert Predictions Max     522.679\n",
      "trainer/Z Expert Predictions Min     330.682\n",
      "trainer/Z Policy Predictions Mean    238.017\n",
      "trainer/Z Policy Predictions Std     147.967\n",
      "trainer/Z Policy Predictions Max     479.01\n",
      "trainer/Z Policy Predictions Min       1.31675\n",
      "trainer/Z Expert Targets Mean        391.159\n",
      "trainer/Z Expert Targets Std          26.6161\n",
      "trainer/Z Expert Targets Max         507.408\n",
      "trainer/Z Expert Targets Min         320.928\n",
      "trainer/Z Policy Targets Mean        233.556\n",
      "trainer/Z Policy Targets Std         148.938\n",
      "trainer/Z Policy Targets Max         466.149\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  44.8262\n",
      "trainer/Log Pis Std                   17.8362\n",
      "trainer/Policy mu Mean                 0.348741\n",
      "trainer/Policy mu Std                  2.70995\n",
      "trainer/Policy log std Mean           -1.40311\n",
      "trainer/Policy log std Std             0.89604\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        54368\n",
      "exploration/num paths total         1012\n",
      "evaluation/num steps total         35750\n",
      "evaluation/num paths total           450\n",
      "evaluation/path length Mean          121.6\n",
      "evaluation/path length Std            25.6289\n",
      "evaluation/path length Max           164\n",
      "evaluation/path length Min            81\n",
      "evaluation/Rewards Mean                4.94863\n",
      "evaluation/Rewards Std                 0.434865\n",
      "evaluation/Rewards Max                 6.39858\n",
      "evaluation/Rewards Min                 3.28186\n",
      "evaluation/Returns Mean              601.754\n",
      "evaluation/Returns Std               134.085\n",
      "evaluation/Returns Max               858.116\n",
      "evaluation/Returns Min               429.413\n",
      "evaluation/Estimation Bias Mean      253.837\n",
      "evaluation/Estimation Bias Std       150.762\n",
      "evaluation/EB/Q_True Mean             24.1649\n",
      "evaluation/EB/Q_True Std              68.6096\n",
      "evaluation/EB/Q_Pred Mean            278.002\n",
      "evaluation/EB/Q_Pred Std             140.885\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           601.754\n",
      "evaluation/Actions Mean                0.182587\n",
      "evaluation/Actions Std                 0.726912\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.88519\n",
      "time/backward_zf1 (s)                  2.26628\n",
      "time/backward_zf2 (s)                  2.22061\n",
      "time/data sampling (s)                 0.290386\n",
      "time/data storing (s)                  0.0146771\n",
      "time/evaluation sampling (s)           0.448024\n",
      "time/exploration sampling (s)          0.482466\n",
      "time/logging (s)                       0.00256636\n",
      "time/preback_alpha (s)                 0.555665\n",
      "time/preback_policy (s)                1.13605\n",
      "time/preback_start (s)                 0.16695\n",
      "time/preback_zf (s)                    6.58547\n",
      "time/saving (s)                        2.67e-06\n",
      "time/training (s)                      3.12427\n",
      "time/epoch (s)                        19.1786\n",
      "time/total (s)                       862.467\n",
      "Epoch                                 44\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:40:02.144938 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 45 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 56000\n",
      "trainer/ZF1 Loss                      21.5127\n",
      "trainer/ZF2 Loss                      21.1113\n",
      "trainer/ZF Expert Reward              13.9923\n",
      "trainer/ZF Policy Reward               6.38834\n",
      "trainer/ZF CHI2 Term                  31.2595\n",
      "trainer/Policy Loss                 -251.336\n",
      "trainer/Bias Loss                      4.55786\n",
      "trainer/Bias Value                    13.7039\n",
      "trainer/Policy Grad Norm              32.2645\n",
      "trainer/Policy Param Norm             33.2921\n",
      "trainer/Zf1 Grad Norm               2582.55\n",
      "trainer/Zf1 Param Norm                68.9216\n",
      "trainer/Zf2 Grad Norm               4053.24\n",
      "trainer/Zf2 Param Norm                67.3347\n",
      "trainer/Z Expert Predictions Mean    410.562\n",
      "trainer/Z Expert Predictions Std      32.5313\n",
      "trainer/Z Expert Predictions Max     553.621\n",
      "trainer/Z Expert Predictions Min     281.517\n",
      "trainer/Z Policy Predictions Mean    248.218\n",
      "trainer/Z Policy Predictions Std     145.515\n",
      "trainer/Z Policy Predictions Max     488.818\n",
      "trainer/Z Policy Predictions Min       7.47377\n",
      "trainer/Z Expert Targets Mean        396.569\n",
      "trainer/Z Expert Targets Std          32.8878\n",
      "trainer/Z Expert Targets Max         549.026\n",
      "trainer/Z Expert Targets Min         258.873\n",
      "trainer/Z Policy Targets Mean        241.83\n",
      "trainer/Z Policy Targets Std         146.242\n",
      "trainer/Z Policy Targets Max         469.291\n",
      "trainer/Z Policy Targets Min          -1.99388\n",
      "trainer/Log Pis Mean                  43.2989\n",
      "trainer/Log Pis Std                   17.7217\n",
      "trainer/Policy mu Mean                 0.577704\n",
      "trainer/Policy mu Std                  2.46837\n",
      "trainer/Policy log std Mean           -1.4194\n",
      "trainer/Policy log std Std             0.794676\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        55317\n",
      "exploration/num paths total         1021\n",
      "evaluation/num steps total         36688\n",
      "evaluation/num paths total           460\n",
      "evaluation/path length Mean           93.8\n",
      "evaluation/path length Std            13.9556\n",
      "evaluation/path length Max           112\n",
      "evaluation/path length Min            66\n",
      "evaluation/Rewards Mean                4.9409\n",
      "evaluation/Rewards Std                 0.333911\n",
      "evaluation/Rewards Max                 6.01603\n",
      "evaluation/Rewards Min                 3.33197\n",
      "evaluation/Returns Mean              463.457\n",
      "evaluation/Returns Std                64.1939\n",
      "evaluation/Returns Max               557.5\n",
      "evaluation/Returns Min               341.343\n",
      "evaluation/Estimation Bias Mean      264.939\n",
      "evaluation/Estimation Bias Std       150.818\n",
      "evaluation/EB/Q_True Mean             15.0871\n",
      "evaluation/EB/Q_True Std              47.099\n",
      "evaluation/EB/Q_Pred Mean            280.026\n",
      "evaluation/EB/Q_Pred Std             144.054\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           463.457\n",
      "evaluation/Actions Mean                0.157727\n",
      "evaluation/Actions Std                 0.740884\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.88426\n",
      "time/backward_zf1 (s)                  2.27418\n",
      "time/backward_zf2 (s)                  2.21969\n",
      "time/data sampling (s)                 0.297382\n",
      "time/data storing (s)                  0.0142343\n",
      "time/evaluation sampling (s)           0.452683\n",
      "time/exploration sampling (s)          0.488034\n",
      "time/logging (s)                       0.00250062\n",
      "time/preback_alpha (s)                 0.557758\n",
      "time/preback_policy (s)                1.16591\n",
      "time/preback_start (s)                 0.169371\n",
      "time/preback_zf (s)                    6.58734\n",
      "time/saving (s)                        3.98e-06\n",
      "time/training (s)                      2.97094\n",
      "time/epoch (s)                        19.0843\n",
      "time/total (s)                       881.572\n",
      "Epoch                                 45\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:40:21.159998 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 46 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 57000\n",
      "trainer/ZF1 Loss                      18.7346\n",
      "trainer/ZF2 Loss                      19.6962\n",
      "trainer/ZF Expert Reward              13.6269\n",
      "trainer/ZF Policy Reward               4.94424\n",
      "trainer/ZF CHI2 Term                  28.7137\n",
      "trainer/Policy Loss                 -241.773\n",
      "trainer/Bias Loss                      3.83228\n",
      "trainer/Bias Value                    13.7866\n",
      "trainer/Policy Grad Norm              41.4873\n",
      "trainer/Policy Param Norm             33.5385\n",
      "trainer/Zf1 Grad Norm               2776.71\n",
      "trainer/Zf1 Param Norm                69.327\n",
      "trainer/Zf2 Grad Norm               3083.3\n",
      "trainer/Zf2 Param Norm                67.7424\n",
      "trainer/Z Expert Predictions Mean    418.406\n",
      "trainer/Z Expert Predictions Std      28.7901\n",
      "trainer/Z Expert Predictions Max     529.461\n",
      "trainer/Z Expert Predictions Min     314.822\n",
      "trainer/Z Policy Predictions Mean    236.364\n",
      "trainer/Z Policy Predictions Std     142.389\n",
      "trainer/Z Policy Predictions Max     475.43\n",
      "trainer/Z Policy Predictions Min       4.60592\n",
      "trainer/Z Expert Targets Mean        404.779\n",
      "trainer/Z Expert Targets Std          28.745\n",
      "trainer/Z Expert Targets Max         517.111\n",
      "trainer/Z Expert Targets Min         307.103\n",
      "trainer/Z Policy Targets Mean        231.42\n",
      "trainer/Z Policy Targets Std         141.964\n",
      "trainer/Z Policy Targets Max         459.388\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  42.7871\n",
      "trainer/Log Pis Std                   17.8022\n",
      "trainer/Policy mu Mean                 0.352151\n",
      "trainer/Policy mu Std                  2.48901\n",
      "trainer/Policy log std Mean           -1.37746\n",
      "trainer/Policy log std Std             0.834003\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        56493\n",
      "exploration/num paths total         1030\n",
      "evaluation/num steps total         37730\n",
      "evaluation/num paths total           470\n",
      "evaluation/path length Mean          104.2\n",
      "evaluation/path length Std            27.8919\n",
      "evaluation/path length Max           158\n",
      "evaluation/path length Min            74\n",
      "evaluation/Rewards Mean                5.14135\n",
      "evaluation/Rewards Std                 0.439306\n",
      "evaluation/Rewards Max                 6.64702\n",
      "evaluation/Rewards Min                 3.39327\n",
      "evaluation/Returns Mean              535.729\n",
      "evaluation/Returns Std               135.837\n",
      "evaluation/Returns Max               783.879\n",
      "evaluation/Returns Min               381.463\n",
      "evaluation/Estimation Bias Mean      229.599\n",
      "evaluation/Estimation Bias Std       152.656\n",
      "evaluation/EB/Q_True Mean             24.8071\n",
      "evaluation/EB/Q_True Std              65.9866\n",
      "evaluation/EB/Q_Pred Mean            254.406\n",
      "evaluation/EB/Q_Pred Std             142.678\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           535.729\n",
      "evaluation/Actions Mean                0.126334\n",
      "evaluation/Actions Std                 0.760381\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.6447\n",
      "time/backward_zf1 (s)                  2.02789\n",
      "time/backward_zf2 (s)                  1.94337\n",
      "time/data sampling (s)                 0.288196\n",
      "time/data storing (s)                  0.0143903\n",
      "time/evaluation sampling (s)           0.445556\n",
      "time/exploration sampling (s)          0.492689\n",
      "time/logging (s)                       0.00239239\n",
      "time/preback_alpha (s)                 0.550561\n",
      "time/preback_policy (s)                0.900463\n",
      "time/preback_start (s)                 0.166083\n",
      "time/preback_zf (s)                    6.58533\n",
      "time/saving (s)                        3.64801e-06\n",
      "time/training (s)                      3.87808\n",
      "time/epoch (s)                        18.9397\n",
      "time/total (s)                       900.543\n",
      "Epoch                                 46\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:40:40.305234 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 47 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 58000\n",
      "trainer/ZF1 Loss                      16.8536\n",
      "trainer/ZF2 Loss                      17.5459\n",
      "trainer/ZF Expert Reward              16.702\n",
      "trainer/ZF Policy Reward               5.15681\n",
      "trainer/ZF CHI2 Term                  29.6179\n",
      "trainer/Policy Loss                 -249.754\n",
      "trainer/Bias Loss                      6.93574\n",
      "trainer/Bias Value                    13.8682\n",
      "trainer/Policy Grad Norm              35.577\n",
      "trainer/Policy Param Norm             33.788\n",
      "trainer/Zf1 Grad Norm               2026.4\n",
      "trainer/Zf1 Param Norm                69.7454\n",
      "trainer/Zf2 Grad Norm               2211.08\n",
      "trainer/Zf2 Param Norm                68.1527\n",
      "trainer/Z Expert Predictions Mean    434.384\n",
      "trainer/Z Expert Predictions Std      25.2533\n",
      "trainer/Z Expert Predictions Max     515.02\n",
      "trainer/Z Expert Predictions Min     348.912\n",
      "trainer/Z Policy Predictions Mean    246.22\n",
      "trainer/Z Policy Predictions Std     142.392\n",
      "trainer/Z Policy Predictions Max     478.347\n",
      "trainer/Z Policy Predictions Min      22.0344\n",
      "trainer/Z Expert Targets Mean        417.682\n",
      "trainer/Z Expert Targets Std          26.1462\n",
      "trainer/Z Expert Targets Max         501.086\n",
      "trainer/Z Expert Targets Min         327.618\n",
      "trainer/Z Policy Targets Mean        241.064\n",
      "trainer/Z Policy Targets Std         142.471\n",
      "trainer/Z Policy Targets Max         481.259\n",
      "trainer/Z Policy Targets Min          15.9766\n",
      "trainer/Log Pis Mean                  41.7963\n",
      "trainer/Log Pis Std                   17.2162\n",
      "trainer/Policy mu Mean                 0.352951\n",
      "trainer/Policy mu Std                  2.39977\n",
      "trainer/Policy log std Mean           -1.43359\n",
      "trainer/Policy log std Std             0.802643\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        57612\n",
      "exploration/num paths total         1041\n",
      "evaluation/num steps total         38953\n",
      "evaluation/num paths total           480\n",
      "evaluation/path length Mean          122.3\n",
      "evaluation/path length Std            18.0058\n",
      "evaluation/path length Max           169\n",
      "evaluation/path length Min           103\n",
      "evaluation/Rewards Mean                5.25401\n",
      "evaluation/Rewards Std                 0.284861\n",
      "evaluation/Rewards Max                 6.35112\n",
      "evaluation/Rewards Min                 4.85145\n",
      "evaluation/Returns Mean              642.566\n",
      "evaluation/Returns Std                87.632\n",
      "evaluation/Returns Max               859.473\n",
      "evaluation/Returns Min               544.01\n",
      "evaluation/Estimation Bias Mean      264.789\n",
      "evaluation/Estimation Bias Std       181.025\n",
      "evaluation/EB/Q_True Mean             36.6969\n",
      "evaluation/EB/Q_True Std             101.349\n",
      "evaluation/EB/Q_Pred Mean            301.486\n",
      "evaluation/EB/Q_Pred Std             142.741\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           642.566\n",
      "evaluation/Actions Mean                0.167181\n",
      "evaluation/Actions Std                 0.689167\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.68365\n",
      "time/backward_zf1 (s)                  2.08279\n",
      "time/backward_zf2 (s)                  2.01205\n",
      "time/data sampling (s)                 0.291073\n",
      "time/data storing (s)                  0.0148808\n",
      "time/evaluation sampling (s)           0.448703\n",
      "time/exploration sampling (s)          0.497959\n",
      "time/logging (s)                       0.00258521\n",
      "time/preback_alpha (s)                 0.554143\n",
      "time/preback_policy (s)                0.942113\n",
      "time/preback_start (s)                 0.167938\n",
      "time/preback_zf (s)                    6.59321\n",
      "time/saving (s)                        2.736e-06\n",
      "time/training (s)                      3.79482\n",
      "time/epoch (s)                        19.0859\n",
      "time/total (s)                       919.644\n",
      "Epoch                                 47\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:40:59.774399 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 48 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 59000\n",
      "trainer/ZF1 Loss                      17.3998\n",
      "trainer/ZF2 Loss                      23.0374\n",
      "trainer/ZF Expert Reward              13.65\n",
      "trainer/ZF Policy Reward               4.61228\n",
      "trainer/ZF CHI2 Term                  29.439\n",
      "trainer/Policy Loss                 -229.708\n",
      "trainer/Bias Loss                      4.17524\n",
      "trainer/Bias Value                    13.9511\n",
      "trainer/Policy Grad Norm              41.897\n",
      "trainer/Policy Param Norm             34.0392\n",
      "trainer/Zf1 Grad Norm               3080.08\n",
      "trainer/Zf1 Param Norm                70.1978\n",
      "trainer/Zf2 Grad Norm               3897.18\n",
      "trainer/Zf2 Param Norm                68.6039\n",
      "trainer/Z Expert Predictions Mean    446.426\n",
      "trainer/Z Expert Predictions Std      35.9321\n",
      "trainer/Z Expert Predictions Max     525.465\n",
      "trainer/Z Expert Predictions Min      17.3725\n",
      "trainer/Z Policy Predictions Mean    224.774\n",
      "trainer/Z Policy Predictions Std     145.117\n",
      "trainer/Z Policy Predictions Max     496.951\n",
      "trainer/Z Policy Predictions Min      -6.93135\n",
      "trainer/Z Expert Targets Mean        432.776\n",
      "trainer/Z Expert Targets Std          35.9545\n",
      "trainer/Z Expert Targets Max         509.215\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        220.162\n",
      "trainer/Z Policy Targets Std         145.012\n",
      "trainer/Z Policy Targets Max         478.503\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  42.5117\n",
      "trainer/Log Pis Std                   16.2372\n",
      "trainer/Policy mu Mean                 0.508164\n",
      "trainer/Policy mu Std                  2.54345\n",
      "trainer/Policy log std Mean           -1.39791\n",
      "trainer/Policy log std Std             0.877978\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        58363\n",
      "exploration/num paths total         1048\n",
      "evaluation/num steps total         40308\n",
      "evaluation/num paths total           490\n",
      "evaluation/path length Mean          135.5\n",
      "evaluation/path length Std            22.2856\n",
      "evaluation/path length Max           174\n",
      "evaluation/path length Min            91\n",
      "evaluation/Rewards Mean                5.04668\n",
      "evaluation/Rewards Std                 0.507574\n",
      "evaluation/Rewards Max                 6.65039\n",
      "evaluation/Rewards Min                 2.96304\n",
      "evaluation/Returns Mean              683.825\n",
      "evaluation/Returns Std               113.224\n",
      "evaluation/Returns Max               841.491\n",
      "evaluation/Returns Min               487.929\n",
      "evaluation/Estimation Bias Mean      234.553\n",
      "evaluation/Estimation Bias Std       175.843\n",
      "evaluation/EB/Q_True Mean             32.1272\n",
      "evaluation/EB/Q_True Std              94.3583\n",
      "evaluation/EB/Q_Pred Mean            266.68\n",
      "evaluation/EB/Q_Pred Std             147.732\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           683.825\n",
      "evaluation/Actions Mean                0.12194\n",
      "evaluation/Actions Std                 0.750671\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.88327\n",
      "time/backward_zf1 (s)                  2.28512\n",
      "time/backward_zf2 (s)                  2.23586\n",
      "time/data sampling (s)                 0.298593\n",
      "time/data storing (s)                  0.0144674\n",
      "time/evaluation sampling (s)           0.463159\n",
      "time/exploration sampling (s)          0.497551\n",
      "time/logging (s)                       0.00291675\n",
      "time/preback_alpha (s)                 0.566256\n",
      "time/preback_policy (s)                1.12537\n",
      "time/preback_start (s)                 0.17101\n",
      "time/preback_zf (s)                    6.64231\n",
      "time/saving (s)                        2.82699e-06\n",
      "time/training (s)                      3.22069\n",
      "time/epoch (s)                        19.4066\n",
      "time/total (s)                       939.068\n",
      "Epoch                                 48\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:41:18.883305 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 49 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 60000\n",
      "trainer/ZF1 Loss                      28.4307\n",
      "trainer/ZF2 Loss                      28.2715\n",
      "trainer/ZF Expert Reward              16.5224\n",
      "trainer/ZF Policy Reward               5.34578\n",
      "trainer/ZF CHI2 Term                  40.2678\n",
      "trainer/Policy Loss                 -229.012\n",
      "trainer/Bias Loss                     12.0043\n",
      "trainer/Bias Value                    14.0345\n",
      "trainer/Policy Grad Norm              33.6923\n",
      "trainer/Policy Param Norm             34.3037\n",
      "trainer/Zf1 Grad Norm               3500.06\n",
      "trainer/Zf1 Param Norm                70.6691\n",
      "trainer/Zf2 Grad Norm               3950.75\n",
      "trainer/Zf2 Param Norm                69.0829\n",
      "trainer/Z Expert Predictions Mean    468.176\n",
      "trainer/Z Expert Predictions Std      27.182\n",
      "trainer/Z Expert Predictions Max     560.598\n",
      "trainer/Z Expert Predictions Min     399.949\n",
      "trainer/Z Policy Predictions Mean    221.613\n",
      "trainer/Z Policy Predictions Std     139.251\n",
      "trainer/Z Policy Predictions Max     508.966\n",
      "trainer/Z Policy Predictions Min      -4.51668\n",
      "trainer/Z Expert Targets Mean        451.653\n",
      "trainer/Z Expert Targets Std          27.8195\n",
      "trainer/Z Expert Targets Max         555.697\n",
      "trainer/Z Expert Targets Min         384.998\n",
      "trainer/Z Policy Targets Mean        216.267\n",
      "trainer/Z Policy Targets Std         139.165\n",
      "trainer/Z Policy Targets Max         487.761\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  43.3106\n",
      "trainer/Log Pis Std                   17.2438\n",
      "trainer/Policy mu Mean                 0.386656\n",
      "trainer/Policy mu Std                  2.49747\n",
      "trainer/Policy log std Mean           -1.38645\n",
      "trainer/Policy log std Std             0.821313\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        59310\n",
      "exploration/num paths total         1055\n",
      "evaluation/num steps total         41575\n",
      "evaluation/num paths total           500\n",
      "evaluation/path length Mean          126.7\n",
      "evaluation/path length Std            26.978\n",
      "evaluation/path length Max           183\n",
      "evaluation/path length Min           102\n",
      "evaluation/Rewards Mean                4.79442\n",
      "evaluation/Rewards Std                 0.401241\n",
      "evaluation/Rewards Max                 5.43975\n",
      "evaluation/Rewards Min                 3.18374\n",
      "evaluation/Returns Mean              607.452\n",
      "evaluation/Returns Std               124.446\n",
      "evaluation/Returns Max               872.583\n",
      "evaluation/Returns Min               485.142\n",
      "evaluation/Estimation Bias Mean      266.365\n",
      "evaluation/Estimation Bias Std       180.1\n",
      "evaluation/EB/Q_True Mean             36.6979\n",
      "evaluation/EB/Q_True Std             100.394\n",
      "evaluation/EB/Q_Pred Mean            303.063\n",
      "evaluation/EB/Q_Pred Std             156.026\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           607.452\n",
      "evaluation/Actions Mean                0.179289\n",
      "evaluation/Actions Std                 0.698961\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.66899\n",
      "time/backward_zf1 (s)                  2.06949\n",
      "time/backward_zf2 (s)                  1.98649\n",
      "time/data sampling (s)                 0.29531\n",
      "time/data storing (s)                  0.0144363\n",
      "time/evaluation sampling (s)           0.464632\n",
      "time/exploration sampling (s)          0.486368\n",
      "time/logging (s)                       0.00287158\n",
      "time/preback_alpha (s)                 0.552376\n",
      "time/preback_policy (s)                0.913665\n",
      "time/preback_start (s)                 0.166024\n",
      "time/preback_zf (s)                    6.56803\n",
      "time/saving (s)                        3.885e-06\n",
      "time/training (s)                      3.85633\n",
      "time/epoch (s)                        19.045\n",
      "time/total (s)                       958.133\n",
      "Epoch                                 49\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:41:38.133807 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 50 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 61000\n",
      "trainer/ZF1 Loss                      22.8574\n",
      "trainer/ZF2 Loss                      25.7831\n",
      "trainer/ZF Expert Reward              16.0333\n",
      "trainer/ZF Policy Reward               3.89821\n",
      "trainer/ZF CHI2 Term                  35.7398\n",
      "trainer/Policy Loss                 -232.861\n",
      "trainer/Bias Loss                      5.8317\n",
      "trainer/Bias Value                    14.1182\n",
      "trainer/Policy Grad Norm              34.5233\n",
      "trainer/Policy Param Norm             34.5454\n",
      "trainer/Zf1 Grad Norm               2838.19\n",
      "trainer/Zf1 Param Norm                71.148\n",
      "trainer/Zf2 Grad Norm               5097.19\n",
      "trainer/Zf2 Param Norm                69.5512\n",
      "trainer/Z Expert Predictions Mean    467.252\n",
      "trainer/Z Expert Predictions Std      44.2564\n",
      "trainer/Z Expert Predictions Max     566.963\n",
      "trainer/Z Expert Predictions Min      18.8422\n",
      "trainer/Z Policy Predictions Mean    225.85\n",
      "trainer/Z Policy Predictions Std     144.615\n",
      "trainer/Z Policy Predictions Max     471.921\n",
      "trainer/Z Policy Predictions Min     -13.8271\n",
      "trainer/Z Expert Targets Mean        451.219\n",
      "trainer/Z Expert Targets Std          45.0473\n",
      "trainer/Z Expert Targets Max         551.35\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        221.951\n",
      "trainer/Z Policy Targets Std         144.671\n",
      "trainer/Z Policy Targets Max         462.69\n",
      "trainer/Z Policy Targets Min         -11.5773\n",
      "trainer/Log Pis Mean                  43.9372\n",
      "trainer/Log Pis Std                   20.263\n",
      "trainer/Policy mu Mean                 0.367466\n",
      "trainer/Policy mu Std                  2.53238\n",
      "trainer/Policy log std Mean           -1.38369\n",
      "trainer/Policy log std Std             0.816564\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        60262\n",
      "exploration/num paths total         1062\n",
      "evaluation/num steps total         42754\n",
      "evaluation/num paths total           510\n",
      "evaluation/path length Mean          117.9\n",
      "evaluation/path length Std            18.1684\n",
      "evaluation/path length Max           152\n",
      "evaluation/path length Min            83\n",
      "evaluation/Rewards Mean                5.09041\n",
      "evaluation/Rewards Std                 0.361023\n",
      "evaluation/Rewards Max                 6.59727\n",
      "evaluation/Rewards Min                 3.48778\n",
      "evaluation/Returns Mean              600.159\n",
      "evaluation/Returns Std                94.5123\n",
      "evaluation/Returns Max               788.944\n",
      "evaluation/Returns Min               424.004\n",
      "evaluation/Estimation Bias Mean      224.439\n",
      "evaluation/Estimation Bias Std       170.733\n",
      "evaluation/EB/Q_True Mean             33.2943\n",
      "evaluation/EB/Q_True Std              95.0884\n",
      "evaluation/EB/Q_Pred Mean            257.733\n",
      "evaluation/EB/Q_Pred Std             154.766\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           600.159\n",
      "evaluation/Actions Mean                0.121091\n",
      "evaluation/Actions Std                 0.737036\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.92574\n",
      "time/backward_zf1 (s)                  2.31045\n",
      "time/backward_zf2 (s)                  2.27459\n",
      "time/data sampling (s)                 0.29208\n",
      "time/data storing (s)                  0.0143739\n",
      "time/evaluation sampling (s)           0.449202\n",
      "time/exploration sampling (s)          0.481354\n",
      "time/logging (s)                       0.00264247\n",
      "time/preback_alpha (s)                 0.555391\n",
      "time/preback_policy (s)                1.19222\n",
      "time/preback_start (s)                 0.167486\n",
      "time/preback_zf (s)                    6.59207\n",
      "time/saving (s)                        3.314e-06\n",
      "time/training (s)                      2.93063\n",
      "time/epoch (s)                        19.1882\n",
      "time/total (s)                       977.338\n",
      "Epoch                                 50\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:41:57.388653 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 51 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 62000\n",
      "trainer/ZF1 Loss                      24.1666\n",
      "trainer/ZF2 Loss                      17.5531\n",
      "trainer/ZF Expert Reward              15.8261\n",
      "trainer/ZF Policy Reward               3.7087\n",
      "trainer/ZF CHI2 Term                  31.9748\n",
      "trainer/Policy Loss                 -236.379\n",
      "trainer/Bias Loss                      4.39\n",
      "trainer/Bias Value                    14.2031\n",
      "trainer/Policy Grad Norm              37.0842\n",
      "trainer/Policy Param Norm             34.798\n",
      "trainer/Zf1 Grad Norm               3919.36\n",
      "trainer/Zf1 Param Norm                71.6242\n",
      "trainer/Zf2 Grad Norm               3023.47\n",
      "trainer/Zf2 Param Norm                70.0319\n",
      "trainer/Z Expert Predictions Mean    477.022\n",
      "trainer/Z Expert Predictions Std      42.7991\n",
      "trainer/Z Expert Predictions Max     558.306\n",
      "trainer/Z Expert Predictions Min      22.2489\n",
      "trainer/Z Policy Predictions Mean    232.471\n",
      "trainer/Z Policy Predictions Std     146.281\n",
      "trainer/Z Policy Predictions Max     497.022\n",
      "trainer/Z Policy Predictions Min       5.22669\n",
      "trainer/Z Expert Targets Mean        461.196\n",
      "trainer/Z Expert Targets Std          43.1804\n",
      "trainer/Z Expert Targets Max         546.4\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        228.762\n",
      "trainer/Z Policy Targets Std         146.686\n",
      "trainer/Z Policy Targets Max         490.738\n",
      "trainer/Z Policy Targets Min          -5.72942\n",
      "trainer/Log Pis Mean                  42.0252\n",
      "trainer/Log Pis Std                   16.3582\n",
      "trainer/Policy mu Mean                 0.338064\n",
      "trainer/Policy mu Std                  2.48644\n",
      "trainer/Policy log std Mean           -1.41101\n",
      "trainer/Policy log std Std             0.855218\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        61361\n",
      "exploration/num paths total         1070\n",
      "evaluation/num steps total         44061\n",
      "evaluation/num paths total           520\n",
      "evaluation/path length Mean          130.7\n",
      "evaluation/path length Std            24.0543\n",
      "evaluation/path length Max           163\n",
      "evaluation/path length Min            99\n",
      "evaluation/Rewards Mean                5.25309\n",
      "evaluation/Rewards Std                 0.360338\n",
      "evaluation/Rewards Max                 6.33967\n",
      "evaluation/Rewards Min                 3.7463\n",
      "evaluation/Returns Mean              686.578\n",
      "evaluation/Returns Std               123.6\n",
      "evaluation/Returns Max               872.058\n",
      "evaluation/Returns Min               534.233\n",
      "evaluation/Estimation Bias Mean      247.261\n",
      "evaluation/Estimation Bias Std       171.68\n",
      "evaluation/EB/Q_True Mean             33.695\n",
      "evaluation/EB/Q_True Std              98.9424\n",
      "evaluation/EB/Q_Pred Mean            280.956\n",
      "evaluation/EB/Q_Pred Std             145.677\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           686.578\n",
      "evaluation/Actions Mean                0.137406\n",
      "evaluation/Actions Std                 0.715975\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.8689\n",
      "time/backward_zf1 (s)                  2.247\n",
      "time/backward_zf2 (s)                  2.20696\n",
      "time/data sampling (s)                 0.294602\n",
      "time/data storing (s)                  0.0147722\n",
      "time/evaluation sampling (s)           0.424664\n",
      "time/exploration sampling (s)          0.47934\n",
      "time/logging (s)                       0.00416657\n",
      "time/preback_alpha (s)                 0.5657\n",
      "time/preback_policy (s)                1.15448\n",
      "time/preback_start (s)                 0.169898\n",
      "time/preback_zf (s)                    6.62563\n",
      "time/saving (s)                        4.301e-06\n",
      "time/training (s)                      3.13606\n",
      "time/epoch (s)                        19.1922\n",
      "time/total (s)                       996.55\n",
      "Epoch                                 51\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:42:16.813492 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 52 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 63000\n",
      "trainer/ZF1 Loss                      23.9278\n",
      "trainer/ZF2 Loss                      21.0643\n",
      "trainer/ZF Expert Reward              16.552\n",
      "trainer/ZF Policy Reward               5.39623\n",
      "trainer/ZF CHI2 Term                  34.2446\n",
      "trainer/Policy Loss                 -232.822\n",
      "trainer/Bias Loss                      6.12355\n",
      "trainer/Bias Value                    14.287\n",
      "trainer/Policy Grad Norm              33.5197\n",
      "trainer/Policy Param Norm             35.0494\n",
      "trainer/Zf1 Grad Norm               2494.62\n",
      "trainer/Zf1 Param Norm                72.1081\n",
      "trainer/Zf2 Grad Norm               2783.76\n",
      "trainer/Zf2 Param Norm                70.4916\n",
      "trainer/Z Expert Predictions Mean    486.102\n",
      "trainer/Z Expert Predictions Std      31.3432\n",
      "trainer/Z Expert Predictions Max     569.126\n",
      "trainer/Z Expert Predictions Min     399.137\n",
      "trainer/Z Policy Predictions Mean    229.065\n",
      "trainer/Z Policy Predictions Std     147.512\n",
      "trainer/Z Policy Predictions Max     462.745\n",
      "trainer/Z Policy Predictions Min       0.135324\n",
      "trainer/Z Expert Targets Mean        469.55\n",
      "trainer/Z Expert Targets Std          31.683\n",
      "trainer/Z Expert Targets Max         556.286\n",
      "trainer/Z Expert Targets Min         382.163\n",
      "trainer/Z Policy Targets Mean        223.668\n",
      "trainer/Z Policy Targets Std         146.838\n",
      "trainer/Z Policy Targets Max         448.529\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  44.3682\n",
      "trainer/Log Pis Std                   20.22\n",
      "trainer/Policy mu Mean                 0.50666\n",
      "trainer/Policy mu Std                  2.59352\n",
      "trainer/Policy log std Mean           -1.32014\n",
      "trainer/Policy log std Std             0.828547\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        62248\n",
      "exploration/num paths total         1076\n",
      "evaluation/num steps total         45418\n",
      "evaluation/num paths total           530\n",
      "evaluation/path length Mean          135.7\n",
      "evaluation/path length Std            28.4677\n",
      "evaluation/path length Max           172\n",
      "evaluation/path length Min            75\n",
      "evaluation/Rewards Mean                4.98438\n",
      "evaluation/Rewards Std                 0.445505\n",
      "evaluation/Rewards Max                 6.40998\n",
      "evaluation/Rewards Min                 3.40631\n",
      "evaluation/Returns Mean              676.38\n",
      "evaluation/Returns Std               148.448\n",
      "evaluation/Returns Max               821.989\n",
      "evaluation/Returns Min               384.629\n",
      "evaluation/Estimation Bias Mean      236.158\n",
      "evaluation/Estimation Bias Std       187.017\n",
      "evaluation/EB/Q_True Mean             30.8566\n",
      "evaluation/EB/Q_True Std              91.2875\n",
      "evaluation/EB/Q_Pred Mean            267.015\n",
      "evaluation/EB/Q_Pred Std             164.671\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           676.38\n",
      "evaluation/Actions Mean                0.121701\n",
      "evaluation/Actions Std                 0.728114\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.83859\n",
      "time/backward_zf1 (s)                  2.23438\n",
      "time/backward_zf2 (s)                  2.17895\n",
      "time/data sampling (s)                 0.298895\n",
      "time/data storing (s)                  0.0147602\n",
      "time/evaluation sampling (s)           0.429001\n",
      "time/exploration sampling (s)          0.492575\n",
      "time/logging (s)                       0.00259861\n",
      "time/preback_alpha (s)                 0.566305\n",
      "time/preback_policy (s)                1.08292\n",
      "time/preback_start (s)                 0.170198\n",
      "time/preback_zf (s)                    6.64686\n",
      "time/saving (s)                        2.99e-06\n",
      "time/training (s)                      3.39378\n",
      "time/epoch (s)                        19.3498\n",
      "time/total (s)                      1015.93\n",
      "Epoch                                 52\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:42:36.129775 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 53 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 64000\n",
      "trainer/ZF1 Loss                      17.3084\n",
      "trainer/ZF2 Loss                      18.233\n",
      "trainer/ZF Expert Reward              15.4576\n",
      "trainer/ZF Policy Reward               6.41223\n",
      "trainer/ZF CHI2 Term                  28.4229\n",
      "trainer/Policy Loss                 -250.854\n",
      "trainer/Bias Loss                      3.65457\n",
      "trainer/Bias Value                    14.3718\n",
      "trainer/Policy Grad Norm              41.8662\n",
      "trainer/Policy Param Norm             35.2794\n",
      "trainer/Zf1 Grad Norm               2807.52\n",
      "trainer/Zf1 Param Norm                72.6102\n",
      "trainer/Zf2 Grad Norm               3672.56\n",
      "trainer/Zf2 Param Norm                70.964\n",
      "trainer/Z Expert Predictions Mean    489.26\n",
      "trainer/Z Expert Predictions Std      32.6634\n",
      "trainer/Z Expert Predictions Max     582.864\n",
      "trainer/Z Expert Predictions Min     388.293\n",
      "trainer/Z Policy Predictions Mean    248.615\n",
      "trainer/Z Policy Predictions Std     143.292\n",
      "trainer/Z Policy Predictions Max     466.954\n",
      "trainer/Z Policy Predictions Min       5.44925\n",
      "trainer/Z Expert Targets Mean        473.802\n",
      "trainer/Z Expert Targets Std          33.1256\n",
      "trainer/Z Expert Targets Max         570.148\n",
      "trainer/Z Expert Targets Min         376.556\n",
      "trainer/Z Policy Targets Mean        242.203\n",
      "trainer/Z Policy Targets Std         143.177\n",
      "trainer/Z Policy Targets Max         465.627\n",
      "trainer/Z Policy Targets Min          -6.55593\n",
      "trainer/Log Pis Mean                  40.2596\n",
      "trainer/Log Pis Std                   16.087\n",
      "trainer/Policy mu Mean                 0.338439\n",
      "trainer/Policy mu Std                  2.21048\n",
      "trainer/Policy log std Mean           -1.54837\n",
      "trainer/Policy log std Std             0.803179\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        63203\n",
      "exploration/num paths total         1083\n",
      "evaluation/num steps total         46717\n",
      "evaluation/num paths total           540\n",
      "evaluation/path length Mean          129.9\n",
      "evaluation/path length Std            17.2015\n",
      "evaluation/path length Max           168\n",
      "evaluation/path length Min           104\n",
      "evaluation/Rewards Mean                5.31064\n",
      "evaluation/Rewards Std                 0.361367\n",
      "evaluation/Rewards Max                 6.46377\n",
      "evaluation/Rewards Min                 4.83713\n",
      "evaluation/Returns Mean              689.853\n",
      "evaluation/Returns Std                94.2421\n",
      "evaluation/Returns Max               896.567\n",
      "evaluation/Returns Min               547.633\n",
      "evaluation/Estimation Bias Mean      271.453\n",
      "evaluation/Estimation Bias Std       186.989\n",
      "evaluation/EB/Q_True Mean             36.81\n",
      "evaluation/EB/Q_True Std             104.286\n",
      "evaluation/EB/Q_Pred Mean            308.263\n",
      "evaluation/EB/Q_Pred Std             163.195\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           689.853\n",
      "evaluation/Actions Mean                0.114566\n",
      "evaluation/Actions Std                 0.681525\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -0.999999\n",
      "time/backward_policy (s)               1.90897\n",
      "time/backward_zf1 (s)                  2.29135\n",
      "time/backward_zf2 (s)                  2.23404\n",
      "time/data sampling (s)                 0.299591\n",
      "time/data storing (s)                  0.014262\n",
      "time/evaluation sampling (s)           0.512834\n",
      "time/exploration sampling (s)          0.467663\n",
      "time/logging (s)                       0.00354028\n",
      "time/preback_alpha (s)                 0.55639\n",
      "time/preback_policy (s)                1.17069\n",
      "time/preback_start (s)                 0.16848\n",
      "time/preback_zf (s)                    6.60219\n",
      "time/saving (s)                        2.81401e-06\n",
      "time/training (s)                      3.02187\n",
      "time/epoch (s)                        19.2519\n",
      "time/total (s)                      1035.2\n",
      "Epoch                                 53\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:42:55.263710 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 54 finished\n",
      "---------------------------------  -------------\n",
      "replay_buffer/size                 65000\n",
      "trainer/ZF1 Loss                      20.272\n",
      "trainer/ZF2 Loss                      17.694\n",
      "trainer/ZF Expert Reward              17.6161\n",
      "trainer/ZF Policy Reward               4.16043\n",
      "trainer/ZF CHI2 Term                  31.7185\n",
      "trainer/Policy Loss                 -255.35\n",
      "trainer/Bias Loss                      9.51674\n",
      "trainer/Bias Value                    14.4575\n",
      "trainer/Policy Grad Norm              38.024\n",
      "trainer/Policy Param Norm             35.5158\n",
      "trainer/Zf1 Grad Norm               3642.12\n",
      "trainer/Zf1 Param Norm                73.1291\n",
      "trainer/Zf2 Grad Norm               3135.75\n",
      "trainer/Zf2 Param Norm                71.4522\n",
      "trainer/Z Expert Predictions Mean    494.193\n",
      "trainer/Z Expert Predictions Std      35.6071\n",
      "trainer/Z Expert Predictions Max     582.568\n",
      "trainer/Z Expert Predictions Min     289.065\n",
      "trainer/Z Policy Predictions Mean    248.936\n",
      "trainer/Z Policy Predictions Std     145.257\n",
      "trainer/Z Policy Predictions Max     514.236\n",
      "trainer/Z Policy Predictions Min       4.16093\n",
      "trainer/Z Expert Targets Mean        476.577\n",
      "trainer/Z Expert Targets Std          36.2014\n",
      "trainer/Z Expert Targets Max         572.567\n",
      "trainer/Z Expert Targets Min         285.175\n",
      "trainer/Z Policy Targets Mean        244.775\n",
      "trainer/Z Policy Targets Std         145.969\n",
      "trainer/Z Policy Targets Max         489.132\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  43.3213\n",
      "trainer/Log Pis Std                   17.1144\n",
      "trainer/Policy mu Mean                 0.433505\n",
      "trainer/Policy mu Std                  2.3086\n",
      "trainer/Policy log std Mean           -1.53373\n",
      "trainer/Policy log std Std             0.819646\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        64309\n",
      "exploration/num paths total         1092\n",
      "evaluation/num steps total         47912\n",
      "evaluation/num paths total           550\n",
      "evaluation/path length Mean          119.5\n",
      "evaluation/path length Std            19.2263\n",
      "evaluation/path length Max           149\n",
      "evaluation/path length Min            83\n",
      "evaluation/Rewards Mean                5.27692\n",
      "evaluation/Rewards Std                 0.438337\n",
      "evaluation/Rewards Max                 6.46357\n",
      "evaluation/Rewards Min                 4.74023\n",
      "evaluation/Returns Mean              630.592\n",
      "evaluation/Returns Std                99.3657\n",
      "evaluation/Returns Max               778.4\n",
      "evaluation/Returns Min               430.82\n",
      "evaluation/Estimation Bias Mean      241.603\n",
      "evaluation/Estimation Bias Std       179.715\n",
      "evaluation/EB/Q_True Mean             32.3002\n",
      "evaluation/EB/Q_True Std              93.8453\n",
      "evaluation/EB/Q_Pred Mean            273.903\n",
      "evaluation/EB/Q_Pred Std             161.636\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           630.592\n",
      "evaluation/Actions Mean                0.144664\n",
      "evaluation/Actions Std                 0.70425\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.77025\n",
      "time/backward_zf1 (s)                  2.16625\n",
      "time/backward_zf2 (s)                  2.09704\n",
      "time/data sampling (s)                 0.297129\n",
      "time/data storing (s)                  0.0144714\n",
      "time/evaluation sampling (s)           0.370907\n",
      "time/exploration sampling (s)          0.479485\n",
      "time/logging (s)                       0.0024883\n",
      "time/preback_alpha (s)                 0.557973\n",
      "time/preback_policy (s)                1.00899\n",
      "time/preback_start (s)                 0.167747\n",
      "time/preback_zf (s)                    6.60041\n",
      "time/saving (s)                        3.145e-06\n",
      "time/training (s)                      3.53403\n",
      "time/epoch (s)                        19.0672\n",
      "time/total (s)                      1054.29\n",
      "Epoch                                 54\n",
      "---------------------------------  -------------\n",
      "2024-07-28 20:43:14.516228 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 55 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 66000\n",
      "trainer/ZF1 Loss                      29.2203\n",
      "trainer/ZF2 Loss                      28.3706\n",
      "trainer/ZF Expert Reward              14.9692\n",
      "trainer/ZF Policy Reward               5.21899\n",
      "trainer/ZF CHI2 Term                  38.8398\n",
      "trainer/Policy Loss                 -260.426\n",
      "trainer/Bias Loss                      5.36273\n",
      "trainer/Bias Value                    14.5432\n",
      "trainer/Policy Grad Norm              54.8996\n",
      "trainer/Policy Param Norm             35.7607\n",
      "trainer/Zf1 Grad Norm               4855.38\n",
      "trainer/Zf1 Param Norm                73.6211\n",
      "trainer/Zf2 Grad Norm               4541.28\n",
      "trainer/Zf2 Param Norm                71.9301\n",
      "trainer/Z Expert Predictions Mean    499.205\n",
      "trainer/Z Expert Predictions Std      35.9185\n",
      "trainer/Z Expert Predictions Max     574.209\n",
      "trainer/Z Expert Predictions Min     388.801\n",
      "trainer/Z Policy Predictions Mean    251.458\n",
      "trainer/Z Policy Predictions Std     147.347\n",
      "trainer/Z Policy Predictions Max     456.108\n",
      "trainer/Z Policy Predictions Min       3.09459\n",
      "trainer/Z Expert Targets Mean        484.236\n",
      "trainer/Z Expert Targets Std          34.7093\n",
      "trainer/Z Expert Targets Max         560.532\n",
      "trainer/Z Expert Targets Min         377.106\n",
      "trainer/Z Policy Targets Mean        246.239\n",
      "trainer/Z Policy Targets Std         148.058\n",
      "trainer/Z Policy Targets Max         457.002\n",
      "trainer/Z Policy Targets Min          -6.31964\n",
      "trainer/Log Pis Mean                  40.3402\n",
      "trainer/Log Pis Std                   16.1741\n",
      "trainer/Policy mu Mean                 0.401357\n",
      "trainer/Policy mu Std                  2.19818\n",
      "trainer/Policy log std Mean           -1.54007\n",
      "trainer/Policy log std Std             0.826462\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        65282\n",
      "exploration/num paths total         1100\n",
      "evaluation/num steps total         49273\n",
      "evaluation/num paths total           560\n",
      "evaluation/path length Mean          136.1\n",
      "evaluation/path length Std            32.0576\n",
      "evaluation/path length Max           187\n",
      "evaluation/path length Min           101\n",
      "evaluation/Rewards Mean                5.17598\n",
      "evaluation/Rewards Std                 0.270827\n",
      "evaluation/Rewards Max                 6.53298\n",
      "evaluation/Rewards Min                 4.56512\n",
      "evaluation/Returns Mean              704.45\n",
      "evaluation/Returns Std               160.289\n",
      "evaluation/Returns Max               956.482\n",
      "evaluation/Returns Min               518.708\n",
      "evaluation/Estimation Bias Mean      285.557\n",
      "evaluation/Estimation Bias Std       181.996\n",
      "evaluation/EB/Q_True Mean             38.7143\n",
      "evaluation/EB/Q_True Std             106.048\n",
      "evaluation/EB/Q_Pred Mean            324.271\n",
      "evaluation/EB/Q_Pred Std             160.971\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           704.45\n",
      "evaluation/Actions Mean                0.118442\n",
      "evaluation/Actions Std                 0.689702\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.86927\n",
      "time/backward_zf1 (s)                  2.25256\n",
      "time/backward_zf2 (s)                  2.20918\n",
      "time/data sampling (s)                 0.294334\n",
      "time/data storing (s)                  0.0142144\n",
      "time/evaluation sampling (s)           0.432493\n",
      "time/exploration sampling (s)          0.49057\n",
      "time/logging (s)                       0.00265609\n",
      "time/preback_alpha (s)                 0.55589\n",
      "time/preback_policy (s)                1.1192\n",
      "time/preback_start (s)                 0.171279\n",
      "time/preback_zf (s)                    6.58246\n",
      "time/saving (s)                        2.662e-06\n",
      "time/training (s)                      3.19531\n",
      "time/epoch (s)                        19.1894\n",
      "time/total (s)                      1073.49\n",
      "Epoch                                 55\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:43:33.973388 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 56 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 67000\n",
      "trainer/ZF1 Loss                      19.927\n",
      "trainer/ZF2 Loss                      20.2556\n",
      "trainer/ZF Expert Reward              17.14\n",
      "trainer/ZF Policy Reward               5.95832\n",
      "trainer/ZF CHI2 Term                  32.3183\n",
      "trainer/Policy Loss                 -261.098\n",
      "trainer/Bias Loss                      6.91924\n",
      "trainer/Bias Value                    14.6271\n",
      "trainer/Policy Grad Norm              38.7356\n",
      "trainer/Policy Param Norm             35.982\n",
      "trainer/Zf1 Grad Norm               2475.6\n",
      "trainer/Zf1 Param Norm                74.0805\n",
      "trainer/Zf2 Grad Norm               3673.13\n",
      "trainer/Zf2 Param Norm                72.3983\n",
      "trainer/Z Expert Predictions Mean    498.086\n",
      "trainer/Z Expert Predictions Std      38.2469\n",
      "trainer/Z Expert Predictions Max     605.229\n",
      "trainer/Z Expert Predictions Min     396.489\n",
      "trainer/Z Policy Predictions Mean    256.634\n",
      "trainer/Z Policy Predictions Std     145.447\n",
      "trainer/Z Policy Predictions Max     535.401\n",
      "trainer/Z Policy Predictions Min      -3.02044\n",
      "trainer/Z Expert Targets Mean        480.946\n",
      "trainer/Z Expert Targets Std          38.4729\n",
      "trainer/Z Expert Targets Max         596.23\n",
      "trainer/Z Expert Targets Min         381.126\n",
      "trainer/Z Policy Targets Mean        250.675\n",
      "trainer/Z Policy Targets Std         145.14\n",
      "trainer/Z Policy Targets Max         534.195\n",
      "trainer/Z Policy Targets Min          -4.61817\n",
      "trainer/Log Pis Mean                  40.0558\n",
      "trainer/Log Pis Std                   16.4192\n",
      "trainer/Policy mu Mean                 0.416965\n",
      "trainer/Policy mu Std                  2.11593\n",
      "trainer/Policy log std Mean           -1.62471\n",
      "trainer/Policy log std Std             0.806439\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        66358\n",
      "exploration/num paths total         1107\n",
      "evaluation/num steps total         50798\n",
      "evaluation/num paths total           570\n",
      "evaluation/path length Mean          152.5\n",
      "evaluation/path length Std            26.6805\n",
      "evaluation/path length Max           219\n",
      "evaluation/path length Min           131\n",
      "evaluation/Rewards Mean                5.15284\n",
      "evaluation/Rewards Std                 0.352593\n",
      "evaluation/Rewards Max                 6.28866\n",
      "evaluation/Rewards Min                 3.05616\n",
      "evaluation/Returns Mean              785.807\n",
      "evaluation/Returns Std               140.077\n",
      "evaluation/Returns Max              1127.8\n",
      "evaluation/Returns Min               653.531\n",
      "evaluation/Estimation Bias Mean      257.496\n",
      "evaluation/Estimation Bias Std       191.009\n",
      "evaluation/EB/Q_True Mean             44.8615\n",
      "evaluation/EB/Q_True Std             118.749\n",
      "evaluation/EB/Q_Pred Mean            302.357\n",
      "evaluation/EB/Q_Pred Std             160.064\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           785.807\n",
      "evaluation/Actions Mean                0.172999\n",
      "evaluation/Actions Std                 0.692768\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.87171\n",
      "time/backward_zf1 (s)                  2.25089\n",
      "time/backward_zf2 (s)                  2.20152\n",
      "time/data sampling (s)                 0.303722\n",
      "time/data storing (s)                  0.0142232\n",
      "time/evaluation sampling (s)           0.59432\n",
      "time/exploration sampling (s)          0.4944\n",
      "time/logging (s)                       0.00284011\n",
      "time/preback_alpha (s)                 0.555997\n",
      "time/preback_policy (s)                1.11103\n",
      "time/preback_start (s)                 0.170175\n",
      "time/preback_zf (s)                    6.58997\n",
      "time/saving (s)                        2.9e-06\n",
      "time/training (s)                      3.23423\n",
      "time/epoch (s)                        19.395\n",
      "time/total (s)                      1092.91\n",
      "Epoch                                 56\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:43:53.154361 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 57 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 68000\n",
      "trainer/ZF1 Loss                      18.9586\n",
      "trainer/ZF2 Loss                      25.4772\n",
      "trainer/ZF Expert Reward              15.924\n",
      "trainer/ZF Policy Reward               5.08331\n",
      "trainer/ZF CHI2 Term                  33.1527\n",
      "trainer/Policy Loss                 -251.012\n",
      "trainer/Bias Loss                      3.90486\n",
      "trainer/Bias Value                    14.7101\n",
      "trainer/Policy Grad Norm              38.4933\n",
      "trainer/Policy Param Norm             36.2017\n",
      "trainer/Zf1 Grad Norm               2869.61\n",
      "trainer/Zf1 Param Norm                74.5478\n",
      "trainer/Zf2 Grad Norm               3870.08\n",
      "trainer/Zf2 Param Norm                72.8368\n",
      "trainer/Z Expert Predictions Mean    507.862\n",
      "trainer/Z Expert Predictions Std      36.7599\n",
      "trainer/Z Expert Predictions Max     599.941\n",
      "trainer/Z Expert Predictions Min     397.623\n",
      "trainer/Z Policy Predictions Mean    245.83\n",
      "trainer/Z Policy Predictions Std     153.872\n",
      "trainer/Z Policy Predictions Max     481.608\n",
      "trainer/Z Policy Predictions Min      -1.9847\n",
      "trainer/Z Expert Targets Mean        491.938\n",
      "trainer/Z Expert Targets Std          37.0222\n",
      "trainer/Z Expert Targets Max         587.565\n",
      "trainer/Z Expert Targets Min         382.657\n",
      "trainer/Z Policy Targets Mean        240.747\n",
      "trainer/Z Policy Targets Std         153.829\n",
      "trainer/Z Policy Targets Max         472.777\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  40.8183\n",
      "trainer/Log Pis Std                   15.1421\n",
      "trainer/Policy mu Mean                 0.504225\n",
      "trainer/Policy mu Std                  2.1754\n",
      "trainer/Policy log std Mean           -1.45809\n",
      "trainer/Policy log std Std             0.853173\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        67100\n",
      "exploration/num paths total         1112\n",
      "evaluation/num steps total         52150\n",
      "evaluation/num paths total           580\n",
      "evaluation/path length Mean          135.2\n",
      "evaluation/path length Std            29.4408\n",
      "evaluation/path length Max           191\n",
      "evaluation/path length Min           103\n",
      "evaluation/Rewards Mean                5.03663\n",
      "evaluation/Rewards Std                 0.366539\n",
      "evaluation/Rewards Max                 6.4281\n",
      "evaluation/Rewards Min                 3.76779\n",
      "evaluation/Returns Mean              680.953\n",
      "evaluation/Returns Std               169.103\n",
      "evaluation/Returns Max               979.522\n",
      "evaluation/Returns Min               476.419\n",
      "evaluation/Estimation Bias Mean      308.789\n",
      "evaluation/Estimation Bias Std       168.126\n",
      "evaluation/EB/Q_True Mean             25.0806\n",
      "evaluation/EB/Q_True Std              69.9608\n",
      "evaluation/EB/Q_Pred Mean            333.87\n",
      "evaluation/EB/Q_Pred Std             163.329\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           680.953\n",
      "evaluation/Actions Mean                0.100165\n",
      "evaluation/Actions Std                 0.693429\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.88203\n",
      "time/backward_zf1 (s)                  2.27958\n",
      "time/backward_zf2 (s)                  2.23507\n",
      "time/data sampling (s)                 0.293265\n",
      "time/data storing (s)                  0.0142204\n",
      "time/evaluation sampling (s)           0.498757\n",
      "time/exploration sampling (s)          0.476617\n",
      "time/logging (s)                       0.00320145\n",
      "time/preback_alpha (s)                 0.547986\n",
      "time/preback_policy (s)                1.15773\n",
      "time/preback_start (s)                 0.166642\n",
      "time/preback_zf (s)                    6.55894\n",
      "time/saving (s)                        2.91e-06\n",
      "time/training (s)                      2.99956\n",
      "time/epoch (s)                        19.1136\n",
      "time/total (s)                      1112.04\n",
      "Epoch                                 57\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:44:12.498727 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 58 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 69000\n",
      "trainer/ZF1 Loss                      27.4921\n",
      "trainer/ZF2 Loss                      26.4559\n",
      "trainer/ZF Expert Reward              18.215\n",
      "trainer/ZF Policy Reward               7.9081\n",
      "trainer/ZF CHI2 Term                  40.1079\n",
      "trainer/Policy Loss                 -236.977\n",
      "trainer/Bias Loss                     15.4759\n",
      "trainer/Bias Value                    14.7932\n",
      "trainer/Policy Grad Norm              45.0773\n",
      "trainer/Policy Param Norm             36.4084\n",
      "trainer/Zf1 Grad Norm               3058.36\n",
      "trainer/Zf1 Param Norm                75.0095\n",
      "trainer/Zf2 Grad Norm               2676.3\n",
      "trainer/Zf2 Param Norm                73.271\n",
      "trainer/Z Expert Predictions Mean    514.786\n",
      "trainer/Z Expert Predictions Std      39.7514\n",
      "trainer/Z Expert Predictions Max     616.939\n",
      "trainer/Z Expert Predictions Min     334.754\n",
      "trainer/Z Policy Predictions Mean    231.843\n",
      "trainer/Z Policy Predictions Std     156.003\n",
      "trainer/Z Policy Predictions Max     543.486\n",
      "trainer/Z Policy Predictions Min      -0.534409\n",
      "trainer/Z Expert Targets Mean        496.571\n",
      "trainer/Z Expert Targets Std          40.5423\n",
      "trainer/Z Expert Targets Max         613.673\n",
      "trainer/Z Expert Targets Min         317.698\n",
      "trainer/Z Policy Targets Mean        223.935\n",
      "trainer/Z Policy Targets Std         155.021\n",
      "trainer/Z Policy Targets Max         512.878\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  42.5986\n",
      "trainer/Log Pis Std                   17.7642\n",
      "trainer/Policy mu Mean                 0.299111\n",
      "trainer/Policy mu Std                  2.3725\n",
      "trainer/Policy log std Mean           -1.4566\n",
      "trainer/Policy log std Std             0.92459\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        68332\n",
      "exploration/num paths total         1122\n",
      "evaluation/num steps total         53558\n",
      "evaluation/num paths total           590\n",
      "evaluation/path length Mean          140.8\n",
      "evaluation/path length Std            32.5877\n",
      "evaluation/path length Max           209\n",
      "evaluation/path length Min            92\n",
      "evaluation/Rewards Mean                4.93161\n",
      "evaluation/Rewards Std                 0.458543\n",
      "evaluation/Rewards Max                 6.35345\n",
      "evaluation/Rewards Min                 3.27893\n",
      "evaluation/Returns Mean              694.37\n",
      "evaluation/Returns Std               174.515\n",
      "evaluation/Returns Max              1089.57\n",
      "evaluation/Returns Min               430.878\n",
      "evaluation/Estimation Bias Mean      261.261\n",
      "evaluation/Estimation Bias Std       205.127\n",
      "evaluation/EB/Q_True Mean             45.9253\n",
      "evaluation/EB/Q_True Std             119.357\n",
      "evaluation/EB/Q_Pred Mean            307.186\n",
      "evaluation/EB/Q_Pred Std             165.501\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           694.37\n",
      "evaluation/Actions Mean                0.143674\n",
      "evaluation/Actions Std                 0.704598\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.84367\n",
      "time/backward_zf1 (s)                  2.2263\n",
      "time/backward_zf2 (s)                  2.18188\n",
      "time/data sampling (s)                 0.308578\n",
      "time/data storing (s)                  0.0142509\n",
      "time/evaluation sampling (s)           0.537199\n",
      "time/exploration sampling (s)          0.466039\n",
      "time/logging (s)                       0.00305251\n",
      "time/preback_alpha (s)                 0.562837\n",
      "time/preback_policy (s)                1.10778\n",
      "time/preback_start (s)                 0.170834\n",
      "time/preback_zf (s)                    6.62052\n",
      "time/saving (s)                        2.492e-06\n",
      "time/training (s)                      3.23767\n",
      "time/epoch (s)                        19.2806\n",
      "time/total (s)                      1131.34\n",
      "Epoch                                 58\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:44:32.929588 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 59 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 70000\n",
      "trainer/ZF1 Loss                      24.8724\n",
      "trainer/ZF2 Loss                      28.8073\n",
      "trainer/ZF Expert Reward              15.3056\n",
      "trainer/ZF Policy Reward               4.23652\n",
      "trainer/ZF CHI2 Term                  37.0518\n",
      "trainer/Policy Loss                 -264.544\n",
      "trainer/Bias Loss                      7.80429\n",
      "trainer/Bias Value                    14.8761\n",
      "trainer/Policy Grad Norm              51.9527\n",
      "trainer/Policy Param Norm             36.6194\n",
      "trainer/Zf1 Grad Norm               3007.25\n",
      "trainer/Zf1 Param Norm                75.5079\n",
      "trainer/Zf2 Grad Norm               3687.24\n",
      "trainer/Zf2 Param Norm                73.7652\n",
      "trainer/Z Expert Predictions Mean    516.182\n",
      "trainer/Z Expert Predictions Std      40.1714\n",
      "trainer/Z Expert Predictions Max     594.928\n",
      "trainer/Z Expert Predictions Min     344.626\n",
      "trainer/Z Policy Predictions Mean    257.789\n",
      "trainer/Z Policy Predictions Std     154.991\n",
      "trainer/Z Policy Predictions Max     547.871\n",
      "trainer/Z Policy Predictions Min      -1.37762\n",
      "trainer/Z Expert Targets Mean        500.877\n",
      "trainer/Z Expert Targets Std          40.2062\n",
      "trainer/Z Expert Targets Max         621.534\n",
      "trainer/Z Expert Targets Min         325.584\n",
      "trainer/Z Policy Targets Mean        253.552\n",
      "trainer/Z Policy Targets Std         154.443\n",
      "trainer/Z Policy Targets Max         541.816\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  41.6262\n",
      "trainer/Log Pis Std                   17.5973\n",
      "trainer/Policy mu Mean                 0.426503\n",
      "trainer/Policy mu Std                  2.21104\n",
      "trainer/Policy log std Mean           -1.551\n",
      "trainer/Policy log std Std             0.833666\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        69244\n",
      "exploration/num paths total         1129\n",
      "evaluation/num steps total         55282\n",
      "evaluation/num paths total           600\n",
      "evaluation/path length Mean          172.4\n",
      "evaluation/path length Std            35.7217\n",
      "evaluation/path length Max           242\n",
      "evaluation/path length Min           118\n",
      "evaluation/Rewards Mean                5.16477\n",
      "evaluation/Rewards Std                 0.327604\n",
      "evaluation/Rewards Max                 6.39545\n",
      "evaluation/Rewards Min                 3.54227\n",
      "evaluation/Returns Mean              890.405\n",
      "evaluation/Returns Std               170.848\n",
      "evaluation/Returns Max              1155.02\n",
      "evaluation/Returns Min               627.721\n",
      "evaluation/Estimation Bias Mean      308.242\n",
      "evaluation/Estimation Bias Std       185.695\n",
      "evaluation/EB/Q_True Mean             41.3083\n",
      "evaluation/EB/Q_True Std             113.082\n",
      "evaluation/EB/Q_Pred Mean            349.551\n",
      "evaluation/EB/Q_Pred Std             153.641\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           890.405\n",
      "evaluation/Actions Mean                0.127047\n",
      "evaluation/Actions Std                 0.669183\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               2.08279\n",
      "time/backward_zf1 (s)                  2.4952\n",
      "time/backward_zf2 (s)                  2.45343\n",
      "time/data sampling (s)                 0.325757\n",
      "time/data storing (s)                  0.0154847\n",
      "time/evaluation sampling (s)           0.685135\n",
      "time/exploration sampling (s)          0.508266\n",
      "time/logging (s)                       0.00447009\n",
      "time/preback_alpha (s)                 0.595139\n",
      "time/preback_policy (s)                1.24217\n",
      "time/preback_start (s)                 0.179532\n",
      "time/preback_zf (s)                    6.7544\n",
      "time/saving (s)                        3.04201e-06\n",
      "time/training (s)                      3.02482\n",
      "time/epoch (s)                        20.3666\n",
      "time/total (s)                      1151.73\n",
      "Epoch                                 59\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:44:52.713631 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 60 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 71000\n",
      "trainer/ZF1 Loss                      23.6424\n",
      "trainer/ZF2 Loss                      24.7955\n",
      "trainer/ZF Expert Reward              15.6085\n",
      "trainer/ZF Policy Reward               6.09846\n",
      "trainer/ZF CHI2 Term                  34.5711\n",
      "trainer/Policy Loss                 -269.791\n",
      "trainer/Bias Loss                      5.66599\n",
      "trainer/Bias Value                    14.9593\n",
      "trainer/Policy Grad Norm              45.7603\n",
      "trainer/Policy Param Norm             36.8316\n",
      "trainer/Zf1 Grad Norm               2430.17\n",
      "trainer/Zf1 Param Norm                75.9941\n",
      "trainer/Zf2 Grad Norm               3491.24\n",
      "trainer/Zf2 Param Norm                74.2337\n",
      "trainer/Z Expert Predictions Mean    531.006\n",
      "trainer/Z Expert Predictions Std      33.9663\n",
      "trainer/Z Expert Predictions Max     634.02\n",
      "trainer/Z Expert Predictions Min     428.044\n",
      "trainer/Z Policy Predictions Mean    266.371\n",
      "trainer/Z Policy Predictions Std     154.446\n",
      "trainer/Z Policy Predictions Max     517.722\n",
      "trainer/Z Policy Predictions Min     -15.6292\n",
      "trainer/Z Expert Targets Mean        515.398\n",
      "trainer/Z Expert Targets Std          35.069\n",
      "trainer/Z Expert Targets Max         628.748\n",
      "trainer/Z Expert Targets Min         410.204\n",
      "trainer/Z Policy Targets Mean        260.272\n",
      "trainer/Z Policy Targets Std         155.166\n",
      "trainer/Z Policy Targets Max         489.9\n",
      "trainer/Z Policy Targets Min         -14.849\n",
      "trainer/Log Pis Mean                  40.63\n",
      "trainer/Log Pis Std                   16.5187\n",
      "trainer/Policy mu Mean                 0.275107\n",
      "trainer/Policy mu Std                  2.19179\n",
      "trainer/Policy log std Mean           -1.57084\n",
      "trainer/Policy log std Std             0.831795\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        69986\n",
      "exploration/num paths total         1134\n",
      "evaluation/num steps total         56522\n",
      "evaluation/num paths total           610\n",
      "evaluation/path length Mean          124\n",
      "evaluation/path length Std            28.4253\n",
      "evaluation/path length Max           180\n",
      "evaluation/path length Min            87\n",
      "evaluation/Rewards Mean                4.87096\n",
      "evaluation/Rewards Std                 0.352364\n",
      "evaluation/Rewards Max                 5.37092\n",
      "evaluation/Rewards Min                 3.37635\n",
      "evaluation/Returns Mean              603.999\n",
      "evaluation/Returns Std               154.594\n",
      "evaluation/Returns Max               912.407\n",
      "evaluation/Returns Min               431.801\n",
      "evaluation/Estimation Bias Mean      262.433\n",
      "evaluation/Estimation Bias Std       193.196\n",
      "evaluation/EB/Q_True Mean             39.8477\n",
      "evaluation/EB/Q_True Std             106.794\n",
      "evaluation/EB/Q_Pred Mean            302.281\n",
      "evaluation/EB/Q_Pred Std             168.753\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           603.999\n",
      "evaluation/Actions Mean                0.144236\n",
      "evaluation/Actions Std                 0.710185\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               2.00428\n",
      "time/backward_zf1 (s)                  2.41666\n",
      "time/backward_zf2 (s)                  2.38278\n",
      "time/data sampling (s)                 0.314172\n",
      "time/data storing (s)                  0.0150529\n",
      "time/evaluation sampling (s)           0.422803\n",
      "time/exploration sampling (s)          0.498086\n",
      "time/logging (s)                       0.00266468\n",
      "time/preback_alpha (s)                 0.576271\n",
      "time/preback_policy (s)                1.22404\n",
      "time/preback_start (s)                 0.172963\n",
      "time/preback_zf (s)                    6.71383\n",
      "time/saving (s)                        2.789e-06\n",
      "time/training (s)                      2.97251\n",
      "time/epoch (s)                        19.7161\n",
      "time/total (s)                      1171.46\n",
      "Epoch                                 60\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:45:11.875223 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 61 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 72000\n",
      "trainer/ZF1 Loss                      25.3906\n",
      "trainer/ZF2 Loss                      31.3278\n",
      "trainer/ZF Expert Reward              16.3937\n",
      "trainer/ZF Policy Reward               3.92593\n",
      "trainer/ZF CHI2 Term                  39.4533\n",
      "trainer/Policy Loss                 -261.071\n",
      "trainer/Bias Loss                      7.27337\n",
      "trainer/Bias Value                    15.0433\n",
      "trainer/Policy Grad Norm              52.3232\n",
      "trainer/Policy Param Norm             37.0289\n",
      "trainer/Zf1 Grad Norm               2769.73\n",
      "trainer/Zf1 Param Norm                76.4719\n",
      "trainer/Zf2 Grad Norm               4431.27\n",
      "trainer/Zf2 Param Norm                74.7016\n",
      "trainer/Z Expert Predictions Mean    535.928\n",
      "trainer/Z Expert Predictions Std      35.0942\n",
      "trainer/Z Expert Predictions Max     630.978\n",
      "trainer/Z Expert Predictions Min     443.479\n",
      "trainer/Z Policy Predictions Mean    255.369\n",
      "trainer/Z Policy Predictions Std     161.773\n",
      "trainer/Z Policy Predictions Max     569.499\n",
      "trainer/Z Policy Predictions Min       3.03357\n",
      "trainer/Z Expert Targets Mean        519.534\n",
      "trainer/Z Expert Targets Std          35.2273\n",
      "trainer/Z Expert Targets Max         630.62\n",
      "trainer/Z Expert Targets Min         426.619\n",
      "trainer/Z Policy Targets Mean        251.443\n",
      "trainer/Z Policy Targets Std         162.497\n",
      "trainer/Z Policy Targets Max         538.037\n",
      "trainer/Z Policy Targets Min          -4.62124\n",
      "trainer/Log Pis Mean                  42.2634\n",
      "trainer/Log Pis Std                   17.8528\n",
      "trainer/Policy mu Mean                 0.296323\n",
      "trainer/Policy mu Std                  2.24868\n",
      "trainer/Policy log std Mean           -1.59185\n",
      "trainer/Policy log std Std             0.900711\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        70876\n",
      "exploration/num paths total         1139\n",
      "evaluation/num steps total         57774\n",
      "evaluation/num paths total           620\n",
      "evaluation/path length Mean          125.2\n",
      "evaluation/path length Std            42.9111\n",
      "evaluation/path length Max           174\n",
      "evaluation/path length Min            66\n",
      "evaluation/Rewards Mean                4.86774\n",
      "evaluation/Rewards Std                 0.395224\n",
      "evaluation/Rewards Max                 6.30265\n",
      "evaluation/Rewards Min                 3.42787\n",
      "evaluation/Returns Mean              609.441\n",
      "evaluation/Returns Std               215.033\n",
      "evaluation/Returns Max               889.721\n",
      "evaluation/Returns Min               315.721\n",
      "evaluation/Estimation Bias Mean      263.036\n",
      "evaluation/Estimation Bias Std       189.44\n",
      "evaluation/EB/Q_True Mean             34.3032\n",
      "evaluation/EB/Q_True Std              95.9176\n",
      "evaluation/EB/Q_Pred Mean            297.34\n",
      "evaluation/EB/Q_Pred Std             164.921\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           609.441\n",
      "evaluation/Actions Mean                0.106955\n",
      "evaluation/Actions Std                 0.714982\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.66471\n",
      "time/backward_zf1 (s)                  2.06319\n",
      "time/backward_zf2 (s)                  1.97956\n",
      "time/data sampling (s)                 0.300783\n",
      "time/data storing (s)                  0.0146023\n",
      "time/evaluation sampling (s)           0.506174\n",
      "time/exploration sampling (s)          0.503739\n",
      "time/logging (s)                       0.00343267\n",
      "time/preback_alpha (s)                 0.554938\n",
      "time/preback_policy (s)                0.906023\n",
      "time/preback_start (s)                 0.167537\n",
      "time/preback_zf (s)                    6.57728\n",
      "time/saving (s)                        3.077e-06\n",
      "time/training (s)                      3.85601\n",
      "time/epoch (s)                        19.098\n",
      "time/total (s)                      1190.58\n",
      "Epoch                                 61\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:45:31.895971 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 62 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 73000\n",
      "trainer/ZF1 Loss                      28.5753\n",
      "trainer/ZF2 Loss                      28.5075\n",
      "trainer/ZF Expert Reward              17.0396\n",
      "trainer/ZF Policy Reward               3.05197\n",
      "trainer/ZF CHI2 Term                  40.2242\n",
      "trainer/Policy Loss                 -277.157\n",
      "trainer/Bias Loss                     10.1374\n",
      "trainer/Bias Value                    15.1284\n",
      "trainer/Policy Grad Norm              50.2045\n",
      "trainer/Policy Param Norm             37.2196\n",
      "trainer/Zf1 Grad Norm               3967.41\n",
      "trainer/Zf1 Param Norm                76.9483\n",
      "trainer/Zf2 Grad Norm               4489.03\n",
      "trainer/Zf2 Param Norm                75.1515\n",
      "trainer/Z Expert Predictions Mean    543.046\n",
      "trainer/Z Expert Predictions Std      38.4333\n",
      "trainer/Z Expert Predictions Max     649.8\n",
      "trainer/Z Expert Predictions Min     320.095\n",
      "trainer/Z Policy Predictions Mean    270.121\n",
      "trainer/Z Policy Predictions Std     153.326\n",
      "trainer/Z Policy Predictions Max     513.312\n",
      "trainer/Z Policy Predictions Min      -1.66179\n",
      "trainer/Z Expert Targets Mean        526.006\n",
      "trainer/Z Expert Targets Std          38.7857\n",
      "trainer/Z Expert Targets Max         644.756\n",
      "trainer/Z Expert Targets Min         302.857\n",
      "trainer/Z Policy Targets Mean        267.069\n",
      "trainer/Z Policy Targets Std         154.235\n",
      "trainer/Z Policy Targets Max         510.149\n",
      "trainer/Z Policy Targets Min          -5.96267\n",
      "trainer/Log Pis Mean                  40.0286\n",
      "trainer/Log Pis Std                   15.1033\n",
      "trainer/Policy mu Mean                 0.277583\n",
      "trainer/Policy mu Std                  2.07017\n",
      "trainer/Policy log std Mean           -1.68941\n",
      "trainer/Policy log std Std             0.898006\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        72024\n",
      "exploration/num paths total         1145\n",
      "evaluation/num steps total         59393\n",
      "evaluation/num paths total           630\n",
      "evaluation/path length Mean          161.9\n",
      "evaluation/path length Std            54.9117\n",
      "evaluation/path length Max           237\n",
      "evaluation/path length Min            66\n",
      "evaluation/Rewards Mean                5.02954\n",
      "evaluation/Rewards Std                 0.326504\n",
      "evaluation/Rewards Max                 6.41331\n",
      "evaluation/Rewards Min                 3.52704\n",
      "evaluation/Returns Mean              814.283\n",
      "evaluation/Returns Std               283.54\n",
      "evaluation/Returns Max              1216.02\n",
      "evaluation/Returns Min               329.633\n",
      "evaluation/Estimation Bias Mean      284.084\n",
      "evaluation/Estimation Bias Std       165.957\n",
      "evaluation/EB/Q_True Mean             29.5817\n",
      "evaluation/EB/Q_True Std              80.9792\n",
      "evaluation/EB/Q_Pred Mean            313.666\n",
      "evaluation/EB/Q_Pred Std             155.068\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           814.283\n",
      "evaluation/Actions Mean                0.132813\n",
      "evaluation/Actions Std                 0.685249\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.91136\n",
      "time/backward_zf1 (s)                  2.31384\n",
      "time/backward_zf2 (s)                  2.25772\n",
      "time/data sampling (s)                 0.311572\n",
      "time/data storing (s)                  0.0161985\n",
      "time/evaluation sampling (s)           0.851274\n",
      "time/exploration sampling (s)          0.537961\n",
      "time/logging (s)                       0.00402406\n",
      "time/preback_alpha (s)                 0.56884\n",
      "time/preback_policy (s)                1.14651\n",
      "time/preback_start (s)                 0.17292\n",
      "time/preback_zf (s)                    6.66424\n",
      "time/saving (s)                        3.909e-06\n",
      "time/training (s)                      3.19891\n",
      "time/epoch (s)                        19.9554\n",
      "time/total (s)                      1210.56\n",
      "Epoch                                 62\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:45:51.587228 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 63 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 74000\n",
      "trainer/ZF1 Loss                      33.6913\n",
      "trainer/ZF2 Loss                      27.8248\n",
      "trainer/ZF Expert Reward              16.4605\n",
      "trainer/ZF Policy Reward               5.06967\n",
      "trainer/ZF CHI2 Term                  41.8581\n",
      "trainer/Policy Loss                 -276.534\n",
      "trainer/Bias Loss                      8.97227\n",
      "trainer/Bias Value                    15.2122\n",
      "trainer/Policy Grad Norm              58.077\n",
      "trainer/Policy Param Norm             37.4088\n",
      "trainer/Zf1 Grad Norm               4867.09\n",
      "trainer/Zf1 Param Norm                77.4024\n",
      "trainer/Zf2 Grad Norm               5011.53\n",
      "trainer/Zf2 Param Norm                75.5914\n",
      "trainer/Z Expert Predictions Mean    544.077\n",
      "trainer/Z Expert Predictions Std      35.8218\n",
      "trainer/Z Expert Predictions Max     658.757\n",
      "trainer/Z Expert Predictions Min     337.964\n",
      "trainer/Z Policy Predictions Mean    270.711\n",
      "trainer/Z Policy Predictions Std     152.434\n",
      "trainer/Z Policy Predictions Max     545.802\n",
      "trainer/Z Policy Predictions Min       6.07134\n",
      "trainer/Z Expert Targets Mean        527.616\n",
      "trainer/Z Expert Targets Std          36.407\n",
      "trainer/Z Expert Targets Max         650.643\n",
      "trainer/Z Expert Targets Min         324.573\n",
      "trainer/Z Policy Targets Mean        265.641\n",
      "trainer/Z Policy Targets Std         151.902\n",
      "trainer/Z Policy Targets Max         531.965\n",
      "trainer/Z Policy Targets Min           0.0504879\n",
      "trainer/Log Pis Mean                  39.7059\n",
      "trainer/Log Pis Std                   16.9052\n",
      "trainer/Policy mu Mean                 0.293723\n",
      "trainer/Policy mu Std                  2.15057\n",
      "trainer/Policy log std Mean           -1.62235\n",
      "trainer/Policy log std Std             0.830465\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        72944\n",
      "exploration/num paths total         1151\n",
      "evaluation/num steps total         61166\n",
      "evaluation/num paths total           640\n",
      "evaluation/path length Mean          177.3\n",
      "evaluation/path length Std            35.3498\n",
      "evaluation/path length Max           256\n",
      "evaluation/path length Min           128\n",
      "evaluation/Rewards Mean                5.0917\n",
      "evaluation/Rewards Std                 0.378753\n",
      "evaluation/Rewards Max                 6.29702\n",
      "evaluation/Rewards Min                 3.33016\n",
      "evaluation/Returns Mean              902.759\n",
      "evaluation/Returns Std               169.378\n",
      "evaluation/Returns Max              1249.54\n",
      "evaluation/Returns Min               685.355\n",
      "evaluation/Estimation Bias Mean      333.502\n",
      "evaluation/Estimation Bias Std       185.835\n",
      "evaluation/EB/Q_True Mean             33.7299\n",
      "evaluation/EB/Q_True Std              94.8648\n",
      "evaluation/EB/Q_Pred Mean            367.232\n",
      "evaluation/EB/Q_Pred Std             165.581\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           902.759\n",
      "evaluation/Actions Mean                0.0965102\n",
      "evaluation/Actions Std                 0.66971\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.85108\n",
      "time/backward_zf1 (s)                  2.2424\n",
      "time/backward_zf2 (s)                  2.19633\n",
      "time/data sampling (s)                 0.309527\n",
      "time/data storing (s)                  0.0152763\n",
      "time/evaluation sampling (s)           0.715953\n",
      "time/exploration sampling (s)          0.505967\n",
      "time/logging (s)                       0.00386324\n",
      "time/preback_alpha (s)                 0.567229\n",
      "time/preback_policy (s)                1.09461\n",
      "time/preback_start (s)                 0.173369\n",
      "time/preback_zf (s)                    6.63395\n",
      "time/saving (s)                        3.81099e-06\n",
      "time/training (s)                      3.31715\n",
      "time/epoch (s)                        19.6267\n",
      "time/total (s)                      1230.2\n",
      "Epoch                                 63\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:46:10.944455 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 64 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 75000\n",
      "trainer/ZF1 Loss                      21.7769\n",
      "trainer/ZF2 Loss                      20.4269\n",
      "trainer/ZF Expert Reward              18.9351\n",
      "trainer/ZF Policy Reward               3.91629\n",
      "trainer/ZF CHI2 Term                  34.688\n",
      "trainer/Policy Loss                 -261.696\n",
      "trainer/Bias Loss                     11.4011\n",
      "trainer/Bias Value                    15.296\n",
      "trainer/Policy Grad Norm              52.7461\n",
      "trainer/Policy Param Norm             37.5839\n",
      "trainer/Zf1 Grad Norm               3873.28\n",
      "trainer/Zf1 Param Norm                77.8572\n",
      "trainer/Zf2 Grad Norm               4262.59\n",
      "trainer/Zf2 Param Norm                76.0546\n",
      "trainer/Z Expert Predictions Mean    541.046\n",
      "trainer/Z Expert Predictions Std      39.7626\n",
      "trainer/Z Expert Predictions Max     656.618\n",
      "trainer/Z Expert Predictions Min     324.63\n",
      "trainer/Z Policy Predictions Mean    254.484\n",
      "trainer/Z Policy Predictions Std     162.08\n",
      "trainer/Z Policy Predictions Max     590.201\n",
      "trainer/Z Policy Predictions Min       8.15814\n",
      "trainer/Z Expert Targets Mean        522.111\n",
      "trainer/Z Expert Targets Std          40.6351\n",
      "trainer/Z Expert Targets Max         641.6\n",
      "trainer/Z Expert Targets Min         313.839\n",
      "trainer/Z Policy Targets Mean        250.568\n",
      "trainer/Z Policy Targets Std         163.007\n",
      "trainer/Z Policy Targets Max         569.308\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  42.0591\n",
      "trainer/Log Pis Std                   16.9073\n",
      "trainer/Policy mu Mean                 0.235319\n",
      "trainer/Policy mu Std                  2.25292\n",
      "trainer/Policy log std Mean           -1.57264\n",
      "trainer/Policy log std Std             0.875015\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        73484\n",
      "exploration/num paths total         1154\n",
      "evaluation/num steps total         63170\n",
      "evaluation/num paths total           650\n",
      "evaluation/path length Mean          200.4\n",
      "evaluation/path length Std            52.5418\n",
      "evaluation/path length Max           259\n",
      "evaluation/path length Min           105\n",
      "evaluation/Rewards Mean                4.97738\n",
      "evaluation/Rewards Std                 0.30562\n",
      "evaluation/Rewards Max                 6.35654\n",
      "evaluation/Rewards Min                 3.88625\n",
      "evaluation/Returns Mean              997.468\n",
      "evaluation/Returns Std               265.826\n",
      "evaluation/Returns Max              1317.77\n",
      "evaluation/Returns Min               505.081\n",
      "evaluation/Estimation Bias Mean      358.07\n",
      "evaluation/Estimation Bias Std       173.439\n",
      "evaluation/EB/Q_True Mean             27.1187\n",
      "evaluation/EB/Q_True Std              80.2464\n",
      "evaluation/EB/Q_Pred Mean            385.188\n",
      "evaluation/EB/Q_Pred Std             152.747\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           997.468\n",
      "evaluation/Actions Mean                0.109763\n",
      "evaluation/Actions Std                 0.645361\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.6614\n",
      "time/backward_zf1 (s)                  2.05108\n",
      "time/backward_zf2 (s)                  1.9773\n",
      "time/data sampling (s)                 0.293098\n",
      "time/data storing (s)                  0.014537\n",
      "time/evaluation sampling (s)           0.630881\n",
      "time/exploration sampling (s)          0.5057\n",
      "time/logging (s)                       0.00378737\n",
      "time/preback_alpha (s)                 0.560047\n",
      "time/preback_policy (s)                0.905464\n",
      "time/preback_start (s)                 0.168099\n",
      "time/preback_zf (s)                    6.59214\n",
      "time/saving (s)                        2.519e-06\n",
      "time/training (s)                      3.91999\n",
      "time/epoch (s)                        19.2835\n",
      "time/total (s)                      1249.51\n",
      "Epoch                                 64\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:46:30.478548 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 65 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 76000\n",
      "trainer/ZF1 Loss                      22.0854\n",
      "trainer/ZF2 Loss                      25.7633\n",
      "trainer/ZF Expert Reward              17.4149\n",
      "trainer/ZF Policy Reward               2.55353\n",
      "trainer/ZF CHI2 Term                  35.9894\n",
      "trainer/Policy Loss                 -270.541\n",
      "trainer/Bias Loss                      6.46115\n",
      "trainer/Bias Value                    15.3797\n",
      "trainer/Policy Grad Norm              51.5386\n",
      "trainer/Policy Param Norm             37.7668\n",
      "trainer/Zf1 Grad Norm               3962.07\n",
      "trainer/Zf1 Param Norm                78.3061\n",
      "trainer/Zf2 Grad Norm               5502.58\n",
      "trainer/Zf2 Param Norm                76.5137\n",
      "trainer/Z Expert Predictions Mean    539.988\n",
      "trainer/Z Expert Predictions Std      48.8722\n",
      "trainer/Z Expert Predictions Max     641.555\n",
      "trainer/Z Expert Predictions Min      12.4772\n",
      "trainer/Z Policy Predictions Mean    263.283\n",
      "trainer/Z Policy Predictions Std     164.42\n",
      "trainer/Z Policy Predictions Max     553.415\n",
      "trainer/Z Policy Predictions Min       4.45368\n",
      "trainer/Z Expert Targets Mean        522.573\n",
      "trainer/Z Expert Targets Std          49.1196\n",
      "trainer/Z Expert Targets Max         623.192\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        260.73\n",
      "trainer/Z Policy Targets Std         165.416\n",
      "trainer/Z Policy Targets Max         555.376\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  40.0049\n",
      "trainer/Log Pis Std                   14.7895\n",
      "trainer/Policy mu Mean                 0.194942\n",
      "trainer/Policy mu Std                  2.14905\n",
      "trainer/Policy log std Mean           -1.63095\n",
      "trainer/Policy log std Std             0.888377\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        75400\n",
      "exploration/num paths total         1163\n",
      "evaluation/num steps total         64832\n",
      "evaluation/num paths total           660\n",
      "evaluation/path length Mean          166.2\n",
      "evaluation/path length Std            28.1205\n",
      "evaluation/path length Max           210\n",
      "evaluation/path length Min            98\n",
      "evaluation/Rewards Mean                5.26425\n",
      "evaluation/Rewards Std                 0.285728\n",
      "evaluation/Rewards Max                 6.33242\n",
      "evaluation/Rewards Min                 4.43164\n",
      "evaluation/Returns Mean              874.919\n",
      "evaluation/Returns Std               145.933\n",
      "evaluation/Returns Max              1087.53\n",
      "evaluation/Returns Min               507.794\n",
      "evaluation/Estimation Bias Mean      319.501\n",
      "evaluation/Estimation Bias Std       206.11\n",
      "evaluation/EB/Q_True Mean             38.6049\n",
      "evaluation/EB/Q_True Std             110.842\n",
      "evaluation/EB/Q_Pred Mean            358.106\n",
      "evaluation/EB/Q_Pred Std             172.651\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           874.919\n",
      "evaluation/Actions Mean                0.0865514\n",
      "evaluation/Actions Std                 0.673039\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.8884\n",
      "time/backward_zf1 (s)                  2.25965\n",
      "time/backward_zf2 (s)                  2.2143\n",
      "time/data sampling (s)                 0.31957\n",
      "time/data storing (s)                  0.0149584\n",
      "time/evaluation sampling (s)           0.555046\n",
      "time/exploration sampling (s)          0.503268\n",
      "time/logging (s)                       0.00307701\n",
      "time/preback_alpha (s)                 0.568739\n",
      "time/preback_policy (s)                1.13993\n",
      "time/preback_start (s)                 0.17226\n",
      "time/preback_zf (s)                    6.64398\n",
      "time/saving (s)                        2.711e-06\n",
      "time/training (s)                      3.18398\n",
      "time/epoch (s)                        19.4672\n",
      "time/total (s)                      1269\n",
      "Epoch                                 65\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:46:49.444407 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 66 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 77000\n",
      "trainer/ZF1 Loss                      19.2211\n",
      "trainer/ZF2 Loss                      25.9707\n",
      "trainer/ZF Expert Reward              17.6253\n",
      "trainer/ZF Policy Reward               4.95702\n",
      "trainer/ZF CHI2 Term                  34.7807\n",
      "trainer/Policy Loss                 -278.991\n",
      "trainer/Bias Loss                      5.88917\n",
      "trainer/Bias Value                    15.4627\n",
      "trainer/Policy Grad Norm              51.5886\n",
      "trainer/Policy Param Norm             37.9472\n",
      "trainer/Zf1 Grad Norm               2840.62\n",
      "trainer/Zf1 Param Norm                78.7982\n",
      "trainer/Zf2 Grad Norm               2942.62\n",
      "trainer/Zf2 Param Norm                77.0083\n",
      "trainer/Z Expert Predictions Mean    550.762\n",
      "trainer/Z Expert Predictions Std      35.3225\n",
      "trainer/Z Expert Predictions Max     673.455\n",
      "trainer/Z Expert Predictions Min     455.11\n",
      "trainer/Z Policy Predictions Mean    274.401\n",
      "trainer/Z Policy Predictions Std     163.415\n",
      "trainer/Z Policy Predictions Max     573.264\n",
      "trainer/Z Policy Predictions Min       7.8447\n",
      "trainer/Z Expert Targets Mean        533.136\n",
      "trainer/Z Expert Targets Std          35.7757\n",
      "trainer/Z Expert Targets Max         657.161\n",
      "trainer/Z Expert Targets Min         435.689\n",
      "trainer/Z Policy Targets Mean        269.444\n",
      "trainer/Z Policy Targets Std         162.952\n",
      "trainer/Z Policy Targets Max         549.036\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  41.5717\n",
      "trainer/Log Pis Std                   16.5971\n",
      "trainer/Policy mu Mean                 0.190051\n",
      "trainer/Policy mu Std                  2.23935\n",
      "trainer/Policy log std Mean           -1.61797\n",
      "trainer/Policy log std Std             0.90048\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        76147\n",
      "exploration/num paths total         1167\n",
      "evaluation/num steps total         66170\n",
      "evaluation/num paths total           670\n",
      "evaluation/path length Mean          133.8\n",
      "evaluation/path length Std            22.2567\n",
      "evaluation/path length Max           185\n",
      "evaluation/path length Min           108\n",
      "evaluation/Rewards Mean                5.21869\n",
      "evaluation/Rewards Std                 0.368228\n",
      "evaluation/Rewards Max                 6.51771\n",
      "evaluation/Rewards Min                 3.74661\n",
      "evaluation/Returns Mean              698.261\n",
      "evaluation/Returns Std               122.013\n",
      "evaluation/Returns Max               969.457\n",
      "evaluation/Returns Min               500.15\n",
      "evaluation/Estimation Bias Mean      291.587\n",
      "evaluation/Estimation Bias Std       214.908\n",
      "evaluation/EB/Q_True Mean             40.2317\n",
      "evaluation/EB/Q_True Std             110.086\n",
      "evaluation/EB/Q_Pred Mean            331.819\n",
      "evaluation/EB/Q_Pred Std             185.224\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           698.261\n",
      "evaluation/Actions Mean                0.116356\n",
      "evaluation/Actions Std                 0.660727\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.63292\n",
      "time/backward_zf1 (s)                  2.02277\n",
      "time/backward_zf2 (s)                  1.93752\n",
      "time/data sampling (s)                 0.29881\n",
      "time/data storing (s)                  0.0143423\n",
      "time/evaluation sampling (s)           0.450724\n",
      "time/exploration sampling (s)          0.465666\n",
      "time/logging (s)                       0.00278697\n",
      "time/preback_alpha (s)                 0.551285\n",
      "time/preback_policy (s)                0.896381\n",
      "time/preback_start (s)                 0.167787\n",
      "time/preback_zf (s)                    6.56753\n",
      "time/saving (s)                        3.284e-06\n",
      "time/training (s)                      3.89767\n",
      "time/epoch (s)                        18.9062\n",
      "time/total (s)                      1287.92\n",
      "Epoch                                 66\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:47:08.383745 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 67 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 78000\n",
      "trainer/ZF1 Loss                      27.4169\n",
      "trainer/ZF2 Loss                      23.3143\n",
      "trainer/ZF Expert Reward              16.5006\n",
      "trainer/ZF Policy Reward               4.97762\n",
      "trainer/ZF CHI2 Term                  36.3066\n",
      "trainer/Policy Loss                 -264.07\n",
      "trainer/Bias Loss                      3.61859\n",
      "trainer/Bias Value                    15.5458\n",
      "trainer/Policy Grad Norm              58.2838\n",
      "trainer/Policy Param Norm             38.1185\n",
      "trainer/Zf1 Grad Norm               3038.32\n",
      "trainer/Zf1 Param Norm                79.3035\n",
      "trainer/Zf2 Grad Norm               3080.95\n",
      "trainer/Zf2 Param Norm                77.5023\n",
      "trainer/Z Expert Predictions Mean    561.056\n",
      "trainer/Z Expert Predictions Std      36.7832\n",
      "trainer/Z Expert Predictions Max     679.845\n",
      "trainer/Z Expert Predictions Min     454.894\n",
      "trainer/Z Policy Predictions Mean    257.459\n",
      "trainer/Z Policy Predictions Std     170.584\n",
      "trainer/Z Policy Predictions Max     565.308\n",
      "trainer/Z Policy Predictions Min      -5.69095\n",
      "trainer/Z Expert Targets Mean        544.555\n",
      "trainer/Z Expert Targets Std          36.5219\n",
      "trainer/Z Expert Targets Max         670.431\n",
      "trainer/Z Expert Targets Min         438.963\n",
      "trainer/Z Policy Targets Mean        252.481\n",
      "trainer/Z Policy Targets Std         169.036\n",
      "trainer/Z Policy Targets Max         550.871\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  43.4688\n",
      "trainer/Log Pis Std                   16.4936\n",
      "trainer/Policy mu Mean                 0.288008\n",
      "trainer/Policy mu Std                  2.34498\n",
      "trainer/Policy log std Mean           -1.54347\n",
      "trainer/Policy log std Std             0.925122\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        77149\n",
      "exploration/num paths total         1173\n",
      "evaluation/num steps total         67418\n",
      "evaluation/num paths total           680\n",
      "evaluation/path length Mean          124.8\n",
      "evaluation/path length Std            10.9435\n",
      "evaluation/path length Max           140\n",
      "evaluation/path length Min           100\n",
      "evaluation/Rewards Mean                5.34445\n",
      "evaluation/Rewards Std                 0.302023\n",
      "evaluation/Rewards Max                 6.3693\n",
      "evaluation/Rewards Min                 4.86183\n",
      "evaluation/Returns Mean              666.987\n",
      "evaluation/Returns Std                60.1083\n",
      "evaluation/Returns Max               756.207\n",
      "evaluation/Returns Min               536.515\n",
      "evaluation/Estimation Bias Mean      315.903\n",
      "evaluation/Estimation Bias Std       211.075\n",
      "evaluation/EB/Q_True Mean             28.9582\n",
      "evaluation/EB/Q_True Std              89.7487\n",
      "evaluation/EB/Q_Pred Mean            344.861\n",
      "evaluation/EB/Q_Pred Std             187.886\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           666.987\n",
      "evaluation/Actions Mean                0.0886833\n",
      "evaluation/Actions Std                 0.693938\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.65849\n",
      "time/backward_zf1 (s)                  2.05092\n",
      "time/backward_zf2 (s)                  1.96657\n",
      "time/data sampling (s)                 0.301494\n",
      "time/data storing (s)                  0.0141585\n",
      "time/evaluation sampling (s)           0.346031\n",
      "time/exploration sampling (s)          0.47603\n",
      "time/logging (s)                       0.00269898\n",
      "time/preback_alpha (s)                 0.551057\n",
      "time/preback_policy (s)                0.912103\n",
      "time/preback_start (s)                 0.166638\n",
      "time/preback_zf (s)                    6.57504\n",
      "time/saving (s)                        2.653e-06\n",
      "time/training (s)                      3.85286\n",
      "time/epoch (s)                        18.8741\n",
      "time/total (s)                      1306.82\n",
      "Epoch                                 67\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:47:27.666552 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 68 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 79000\n",
      "trainer/ZF1 Loss                      26.8335\n",
      "trainer/ZF2 Loss                      24.3045\n",
      "trainer/ZF Expert Reward              17.652\n",
      "trainer/ZF Policy Reward               5.40403\n",
      "trainer/ZF CHI2 Term                  37.5023\n",
      "trainer/Policy Loss                 -277.707\n",
      "trainer/Bias Loss                      8.48908\n",
      "trainer/Bias Value                    15.6281\n",
      "trainer/Policy Grad Norm              55.2768\n",
      "trainer/Policy Param Norm             38.2927\n",
      "trainer/Zf1 Grad Norm               3494.47\n",
      "trainer/Zf1 Param Norm                79.8004\n",
      "trainer/Zf2 Grad Norm               4445.42\n",
      "trainer/Zf2 Param Norm                78.0335\n",
      "trainer/Z Expert Predictions Mean    577.329\n",
      "trainer/Z Expert Predictions Std      34.6158\n",
      "trainer/Z Expert Predictions Max     681.134\n",
      "trainer/Z Expert Predictions Min     434.723\n",
      "trainer/Z Policy Predictions Mean    274.478\n",
      "trainer/Z Policy Predictions Std     169.056\n",
      "trainer/Z Policy Predictions Max     572.573\n",
      "trainer/Z Policy Predictions Min       6.47874\n",
      "trainer/Z Expert Targets Mean        559.677\n",
      "trainer/Z Expert Targets Std          35.2682\n",
      "trainer/Z Expert Targets Max         671.548\n",
      "trainer/Z Expert Targets Min         424.688\n",
      "trainer/Z Policy Targets Mean        269.074\n",
      "trainer/Z Policy Targets Std         170.009\n",
      "trainer/Z Policy Targets Max         561.249\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  43.3766\n",
      "trainer/Log Pis Std                   17.6444\n",
      "trainer/Policy mu Mean                 0.347042\n",
      "trainer/Policy mu Std                  2.29979\n",
      "trainer/Policy log std Mean           -1.61564\n",
      "trainer/Policy log std Std             0.946129\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        78140\n",
      "exploration/num paths total         1180\n",
      "evaluation/num steps total         68966\n",
      "evaluation/num paths total           690\n",
      "evaluation/path length Mean          154.8\n",
      "evaluation/path length Std             9.83667\n",
      "evaluation/path length Max           167\n",
      "evaluation/path length Min           139\n",
      "evaluation/Rewards Mean                5.25563\n",
      "evaluation/Rewards Std                 0.234162\n",
      "evaluation/Rewards Max                 6.12517\n",
      "evaluation/Rewards Min                 4.75128\n",
      "evaluation/Returns Mean              813.571\n",
      "evaluation/Returns Std                49.4576\n",
      "evaluation/Returns Max               882.654\n",
      "evaluation/Returns Min               737.577\n",
      "evaluation/Estimation Bias Mean      333.248\n",
      "evaluation/Estimation Bias Std       208.641\n",
      "evaluation/EB/Q_True Mean             30.0346\n",
      "evaluation/EB/Q_True Std              94.714\n",
      "evaluation/EB/Q_Pred Mean            363.283\n",
      "evaluation/EB/Q_Pred Std             194.827\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           813.571\n",
      "evaluation/Actions Mean                0.112485\n",
      "evaluation/Actions Std                 0.677734\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.86139\n",
      "time/backward_zf1 (s)                  2.25126\n",
      "time/backward_zf2 (s)                  2.1969\n",
      "time/data sampling (s)                 0.303905\n",
      "time/data storing (s)                  0.0147365\n",
      "time/evaluation sampling (s)           0.402929\n",
      "time/exploration sampling (s)          0.479648\n",
      "time/logging (s)                       0.00296104\n",
      "time/preback_alpha (s)                 0.566376\n",
      "time/preback_policy (s)                1.13983\n",
      "time/preback_start (s)                 0.169768\n",
      "time/preback_zf (s)                    6.65812\n",
      "time/saving (s)                        2.529e-06\n",
      "time/training (s)                      3.17452\n",
      "time/epoch (s)                        19.2224\n",
      "time/total (s)                      1326.06\n",
      "Epoch                                 68\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:47:46.885062 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 69 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 80000\n",
      "trainer/ZF1 Loss                      18.0224\n",
      "trainer/ZF2 Loss                      26.0546\n",
      "trainer/ZF Expert Reward              17.3689\n",
      "trainer/ZF Policy Reward               5.4639\n",
      "trainer/ZF CHI2 Term                  33.6503\n",
      "trainer/Policy Loss                 -277.856\n",
      "trainer/Bias Loss                      4.90146\n",
      "trainer/Bias Value                    15.7103\n",
      "trainer/Policy Grad Norm              50.8433\n",
      "trainer/Policy Param Norm             38.4679\n",
      "trainer/Zf1 Grad Norm               2712.88\n",
      "trainer/Zf1 Param Norm                80.3169\n",
      "trainer/Zf2 Grad Norm               3918.88\n",
      "trainer/Zf2 Param Norm                78.5454\n",
      "trainer/Z Expert Predictions Mean    582.207\n",
      "trainer/Z Expert Predictions Std      49.2578\n",
      "trainer/Z Expert Predictions Max     687.828\n",
      "trainer/Z Expert Predictions Min      18.7829\n",
      "trainer/Z Policy Predictions Mean    272.768\n",
      "trainer/Z Policy Predictions Std     170.959\n",
      "trainer/Z Policy Predictions Max     560.601\n",
      "trainer/Z Policy Predictions Min     -10.3627\n",
      "trainer/Z Expert Targets Mean        564.838\n",
      "trainer/Z Expert Targets Std          49.5948\n",
      "trainer/Z Expert Targets Max         674.824\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        267.304\n",
      "trainer/Z Policy Targets Std         172.41\n",
      "trainer/Z Policy Targets Max         573.867\n",
      "trainer/Z Policy Targets Min          -4.3927\n",
      "trainer/Log Pis Mean                  42.6631\n",
      "trainer/Log Pis Std                   15.991\n",
      "trainer/Policy mu Mean                 0.329817\n",
      "trainer/Policy mu Std                  2.27065\n",
      "trainer/Policy log std Mean           -1.62223\n",
      "trainer/Policy log std Std             0.92577\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        79076\n",
      "exploration/num paths total         1185\n",
      "evaluation/num steps total         70732\n",
      "evaluation/num paths total           700\n",
      "evaluation/path length Mean          176.6\n",
      "evaluation/path length Std            53.4625\n",
      "evaluation/path length Max           275\n",
      "evaluation/path length Min            99\n",
      "evaluation/Rewards Mean                5.16054\n",
      "evaluation/Rewards Std                 0.273983\n",
      "evaluation/Rewards Max                 6.25774\n",
      "evaluation/Rewards Min                 4.10221\n",
      "evaluation/Returns Mean              911.351\n",
      "evaluation/Returns Std               273.865\n",
      "evaluation/Returns Max              1437.02\n",
      "evaluation/Returns Min               516.588\n",
      "evaluation/Estimation Bias Mean      315.455\n",
      "evaluation/Estimation Bias Std       227.318\n",
      "evaluation/EB/Q_True Mean             54.2689\n",
      "evaluation/EB/Q_True Std             136.326\n",
      "evaluation/EB/Q_Pred Mean            369.724\n",
      "evaluation/EB/Q_Pred Std             179.463\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           911.351\n",
      "evaluation/Actions Mean                0.0836937\n",
      "evaluation/Actions Std                 0.664219\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.64091\n",
      "time/backward_zf1 (s)                  2.04379\n",
      "time/backward_zf2 (s)                  1.94889\n",
      "time/data sampling (s)                 0.304637\n",
      "time/data storing (s)                  0.0142593\n",
      "time/evaluation sampling (s)           0.656753\n",
      "time/exploration sampling (s)          0.468729\n",
      "time/logging (s)                       0.00345766\n",
      "time/preback_alpha (s)                 0.552998\n",
      "time/preback_policy (s)                0.894324\n",
      "time/preback_start (s)                 0.167115\n",
      "time/preback_zf (s)                    6.56706\n",
      "time/saving (s)                        3.04e-06\n",
      "time/training (s)                      3.8929\n",
      "time/epoch (s)                        19.1558\n",
      "time/total (s)                      1345.23\n",
      "Epoch                                 69\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:48:06.551905 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 70 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 81000\n",
      "trainer/ZF1 Loss                      28.4756\n",
      "trainer/ZF2 Loss                      32.0569\n",
      "trainer/ZF Expert Reward              16.5421\n",
      "trainer/ZF Policy Reward               5.12249\n",
      "trainer/ZF CHI2 Term                  40.9851\n",
      "trainer/Policy Loss                 -300.33\n",
      "trainer/Bias Loss                      6.99009\n",
      "trainer/Bias Value                    15.7918\n",
      "trainer/Policy Grad Norm              61.3612\n",
      "trainer/Policy Param Norm             38.6477\n",
      "trainer/Zf1 Grad Norm               2812.26\n",
      "trainer/Zf1 Param Norm                80.8251\n",
      "trainer/Zf2 Grad Norm               3291.4\n",
      "trainer/Zf2 Param Norm                79.0692\n",
      "trainer/Z Expert Predictions Mean    589.463\n",
      "trainer/Z Expert Predictions Std      36.4895\n",
      "trainer/Z Expert Predictions Max     690.676\n",
      "trainer/Z Expert Predictions Min     491.622\n",
      "trainer/Z Policy Predictions Mean    293.373\n",
      "trainer/Z Policy Predictions Std     177.618\n",
      "trainer/Z Policy Predictions Max     603.656\n",
      "trainer/Z Policy Predictions Min      -1.23191\n",
      "trainer/Z Expert Targets Mean        572.92\n",
      "trainer/Z Expert Targets Std          36.7058\n",
      "trainer/Z Expert Targets Max         698.843\n",
      "trainer/Z Expert Targets Min         479.473\n",
      "trainer/Z Policy Targets Mean        288.25\n",
      "trainer/Z Policy Targets Std         178.119\n",
      "trainer/Z Policy Targets Max         575.617\n",
      "trainer/Z Policy Targets Min          -1.29082\n",
      "trainer/Log Pis Mean                  41.4051\n",
      "trainer/Log Pis Std                   16.1474\n",
      "trainer/Policy mu Mean                 0.308245\n",
      "trainer/Policy mu Std                  2.16505\n",
      "trainer/Policy log std Mean           -1.71346\n",
      "trainer/Policy log std Std             0.939392\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        79748\n",
      "exploration/num paths total         1189\n",
      "evaluation/num steps total         72300\n",
      "evaluation/num paths total           710\n",
      "evaluation/path length Mean          156.8\n",
      "evaluation/path length Std            53.5963\n",
      "evaluation/path length Max           237\n",
      "evaluation/path length Min            85\n",
      "evaluation/Rewards Mean                5.10465\n",
      "evaluation/Rewards Std                 0.265887\n",
      "evaluation/Rewards Max                 6.13554\n",
      "evaluation/Rewards Min                 3.94818\n",
      "evaluation/Returns Mean              800.409\n",
      "evaluation/Returns Std               293.136\n",
      "evaluation/Returns Max              1242.03\n",
      "evaluation/Returns Min               415.665\n",
      "evaluation/Estimation Bias Mean      316.705\n",
      "evaluation/Estimation Bias Std       233.859\n",
      "evaluation/EB/Q_True Mean             49.8219\n",
      "evaluation/EB/Q_True Std             127.9\n",
      "evaluation/EB/Q_Pred Mean            366.527\n",
      "evaluation/EB/Q_Pred Std             190.092\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           800.409\n",
      "evaluation/Actions Mean                0.107755\n",
      "evaluation/Actions Std                 0.697598\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.95993\n",
      "time/backward_zf1 (s)                  2.35649\n",
      "time/backward_zf2 (s)                  2.31396\n",
      "time/data sampling (s)                 0.313147\n",
      "time/data storing (s)                  0.0144824\n",
      "time/evaluation sampling (s)           0.608803\n",
      "time/exploration sampling (s)          0.477545\n",
      "time/logging (s)                       0.00352006\n",
      "time/preback_alpha (s)                 0.568856\n",
      "time/preback_policy (s)                1.19303\n",
      "time/preback_start (s)                 0.172555\n",
      "time/preback_zf (s)                    6.6223\n",
      "time/saving (s)                        2.25e-06\n",
      "time/training (s)                      2.99392\n",
      "time/epoch (s)                        19.5985\n",
      "time/total (s)                      1364.85\n",
      "Epoch                                 70\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:48:26.789399 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 71 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 82000\n",
      "trainer/ZF1 Loss                      30.4692\n",
      "trainer/ZF2 Loss                      30.0884\n",
      "trainer/ZF Expert Reward              18.0232\n",
      "trainer/ZF Policy Reward               8.25874\n",
      "trainer/ZF CHI2 Term                  42.4072\n",
      "trainer/Policy Loss                 -250.224\n",
      "trainer/Bias Loss                      9.06267\n",
      "trainer/Bias Value                    15.8742\n",
      "trainer/Policy Grad Norm              53.1477\n",
      "trainer/Policy Param Norm             38.812\n",
      "trainer/Zf1 Grad Norm               7163.96\n",
      "trainer/Zf1 Param Norm                81.3351\n",
      "trainer/Zf2 Grad Norm               5984.93\n",
      "trainer/Zf2 Param Norm                79.5975\n",
      "trainer/Z Expert Predictions Mean    598.043\n",
      "trainer/Z Expert Predictions Std      36.593\n",
      "trainer/Z Expert Predictions Max     697.107\n",
      "trainer/Z Expert Predictions Min     486.517\n",
      "trainer/Z Policy Predictions Mean    248.645\n",
      "trainer/Z Policy Predictions Std     180.214\n",
      "trainer/Z Policy Predictions Max     612.172\n",
      "trainer/Z Policy Predictions Min       5.37324\n",
      "trainer/Z Expert Targets Mean        580.02\n",
      "trainer/Z Expert Targets Std          37.6061\n",
      "trainer/Z Expert Targets Max         696.569\n",
      "trainer/Z Expert Targets Min         448.847\n",
      "trainer/Z Policy Targets Mean        240.386\n",
      "trainer/Z Policy Targets Std         179.404\n",
      "trainer/Z Policy Targets Max         584.765\n",
      "trainer/Z Policy Targets Min          -2.59359\n",
      "trainer/Log Pis Mean                  44.3041\n",
      "trainer/Log Pis Std                   18.2839\n",
      "trainer/Policy mu Mean                 0.264194\n",
      "trainer/Policy mu Std                  2.53435\n",
      "trainer/Policy log std Mean           -1.40249\n",
      "trainer/Policy log std Std             0.977758\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        80518\n",
      "exploration/num paths total         1193\n",
      "evaluation/num steps total         74475\n",
      "evaluation/num paths total           720\n",
      "evaluation/path length Mean          217.5\n",
      "evaluation/path length Std            78.0106\n",
      "evaluation/path length Max           360\n",
      "evaluation/path length Min           138\n",
      "evaluation/Rewards Mean                5.20255\n",
      "evaluation/Rewards Std                 0.256488\n",
      "evaluation/Rewards Max                 6.47707\n",
      "evaluation/Rewards Min                 3.59754\n",
      "evaluation/Returns Mean             1131.55\n",
      "evaluation/Returns Std               416.216\n",
      "evaluation/Returns Max              1891.97\n",
      "evaluation/Returns Min               700.306\n",
      "evaluation/Estimation Bias Mean      321.202\n",
      "evaluation/Estimation Bias Std       232.79\n",
      "evaluation/EB/Q_True Mean             64.1216\n",
      "evaluation/EB/Q_True Std             153.355\n",
      "evaluation/EB/Q_Pred Mean            385.324\n",
      "evaluation/EB/Q_Pred Std             168.461\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1131.55\n",
      "evaluation/Actions Mean                0.0997552\n",
      "evaluation/Actions Std                 0.673836\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.98754\n",
      "time/backward_zf1 (s)                  2.38998\n",
      "time/backward_zf2 (s)                  2.35378\n",
      "time/data sampling (s)                 0.317603\n",
      "time/data storing (s)                  0.0147464\n",
      "time/evaluation sampling (s)           0.878175\n",
      "time/exploration sampling (s)          0.481954\n",
      "time/logging (s)                       0.00367246\n",
      "time/preback_alpha (s)                 0.577414\n",
      "time/preback_policy (s)                1.19852\n",
      "time/preback_start (s)                 0.172852\n",
      "time/preback_zf (s)                    6.69029\n",
      "time/saving (s)                        3.473e-06\n",
      "time/training (s)                      3.10339\n",
      "time/epoch (s)                        20.1699\n",
      "time/total (s)                      1385.04\n",
      "Epoch                                 71\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:48:46.481147 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 72 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 83000\n",
      "trainer/ZF1 Loss                      43.859\n",
      "trainer/ZF2 Loss                      34.6097\n",
      "trainer/ZF Expert Reward              19.386\n",
      "trainer/ZF Policy Reward               7.50798\n",
      "trainer/ZF CHI2 Term                  52.5845\n",
      "trainer/Policy Loss                 -297.584\n",
      "trainer/Bias Loss                     11.5297\n",
      "trainer/Bias Value                    15.9544\n",
      "trainer/Policy Grad Norm              65.3811\n",
      "trainer/Policy Param Norm             38.99\n",
      "trainer/Zf1 Grad Norm               7050.86\n",
      "trainer/Zf1 Param Norm                81.859\n",
      "trainer/Zf2 Grad Norm               3823.77\n",
      "trainer/Zf2 Param Norm                80.1348\n",
      "trainer/Z Expert Predictions Mean    608.868\n",
      "trainer/Z Expert Predictions Std      33.3419\n",
      "trainer/Z Expert Predictions Max     690.486\n",
      "trainer/Z Expert Predictions Min     514.867\n",
      "trainer/Z Policy Predictions Mean    292.687\n",
      "trainer/Z Policy Predictions Std     185.799\n",
      "trainer/Z Policy Predictions Max     610.927\n",
      "trainer/Z Policy Predictions Min       8.98199\n",
      "trainer/Z Expert Targets Mean        589.482\n",
      "trainer/Z Expert Targets Std          33.4962\n",
      "trainer/Z Expert Targets Max         669.952\n",
      "trainer/Z Expert Targets Min         490.145\n",
      "trainer/Z Policy Targets Mean        285.179\n",
      "trainer/Z Policy Targets Std         185.191\n",
      "trainer/Z Policy Targets Max         601.736\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  45.1833\n",
      "trainer/Log Pis Std                   18.2866\n",
      "trainer/Policy mu Mean                 0.342239\n",
      "trainer/Policy mu Std                  2.40865\n",
      "trainer/Policy log std Mean           -1.65053\n",
      "trainer/Policy log std Std             0.966327\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        80692\n",
      "exploration/num paths total         1194\n",
      "evaluation/num steps total         75999\n",
      "evaluation/num paths total           730\n",
      "evaluation/path length Mean          152.4\n",
      "evaluation/path length Std            69.2159\n",
      "evaluation/path length Max           319\n",
      "evaluation/path length Min            91\n",
      "evaluation/Rewards Mean                5.14701\n",
      "evaluation/Rewards Std                 0.293637\n",
      "evaluation/Rewards Max                 6.43386\n",
      "evaluation/Rewards Min                 4.10347\n",
      "evaluation/Returns Mean              784.404\n",
      "evaluation/Returns Std               351.12\n",
      "evaluation/Returns Max              1617.89\n",
      "evaluation/Returns Min               469.621\n",
      "evaluation/Estimation Bias Mean      282.573\n",
      "evaluation/Estimation Bias Std       267.815\n",
      "evaluation/EB/Q_True Mean             74.3024\n",
      "evaluation/EB/Q_True Std             157.507\n",
      "evaluation/EB/Q_Pred Mean            356.875\n",
      "evaluation/EB/Q_Pred Std             188.329\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           784.404\n",
      "evaluation/Actions Mean                0.114704\n",
      "evaluation/Actions Std                 0.679548\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.89267\n",
      "time/backward_zf1 (s)                  2.29613\n",
      "time/backward_zf2 (s)                  2.22409\n",
      "time/data sampling (s)                 0.301962\n",
      "time/data storing (s)                  0.014575\n",
      "time/evaluation sampling (s)           0.815018\n",
      "time/exploration sampling (s)          0.481396\n",
      "time/logging (s)                       0.00325778\n",
      "time/preback_alpha (s)                 0.564931\n",
      "time/preback_policy (s)                1.13205\n",
      "time/preback_start (s)                 0.170308\n",
      "time/preback_zf (s)                    6.61846\n",
      "time/saving (s)                        2.904e-06\n",
      "time/training (s)                      3.11373\n",
      "time/epoch (s)                        19.6286\n",
      "time/total (s)                      1404.69\n",
      "Epoch                                 72\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:49:06.540447 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 73 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 84000\n",
      "trainer/ZF1 Loss                      55.455\n",
      "trainer/ZF2 Loss                      63.0588\n",
      "trainer/ZF Expert Reward              16.661\n",
      "trainer/ZF Policy Reward               4.92107\n",
      "trainer/ZF CHI2 Term                  69.6556\n",
      "trainer/Policy Loss                 -292.522\n",
      "trainer/Bias Loss                      7.63692\n",
      "trainer/Bias Value                    16.034\n",
      "trainer/Policy Grad Norm              58.3113\n",
      "trainer/Policy Param Norm             39.1723\n",
      "trainer/Zf1 Grad Norm              10969.9\n",
      "trainer/Zf1 Param Norm                82.4187\n",
      "trainer/Zf2 Grad Norm              10980.1\n",
      "trainer/Zf2 Param Norm                80.6921\n",
      "trainer/Z Expert Predictions Mean    632.33\n",
      "trainer/Z Expert Predictions Std      30.117\n",
      "trainer/Z Expert Predictions Max     711.332\n",
      "trainer/Z Expert Predictions Min     522.64\n",
      "trainer/Z Policy Predictions Mean    284.899\n",
      "trainer/Z Policy Predictions Std     179.093\n",
      "trainer/Z Policy Predictions Max     617.433\n",
      "trainer/Z Policy Predictions Min      -2.36102\n",
      "trainer/Z Expert Targets Mean        615.669\n",
      "trainer/Z Expert Targets Std          29.8632\n",
      "trainer/Z Expert Targets Max         709.135\n",
      "trainer/Z Expert Targets Min         509.722\n",
      "trainer/Z Policy Targets Mean        279.978\n",
      "trainer/Z Policy Targets Std         181.028\n",
      "trainer/Z Policy Targets Max         611.806\n",
      "trainer/Z Policy Targets Min          -4.40425\n",
      "trainer/Log Pis Mean                  44.4312\n",
      "trainer/Log Pis Std                   19.1338\n",
      "trainer/Policy mu Mean                 0.453178\n",
      "trainer/Policy mu Std                  2.35325\n",
      "trainer/Policy log std Mean           -1.61897\n",
      "trainer/Policy log std Std             0.892505\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        80692\n",
      "exploration/num paths total         1194\n",
      "evaluation/num steps total         78312\n",
      "evaluation/num paths total           740\n",
      "evaluation/path length Mean          231.3\n",
      "evaluation/path length Std           104.868\n",
      "evaluation/path length Max           381\n",
      "evaluation/path length Min            97\n",
      "evaluation/Rewards Mean                5.10746\n",
      "evaluation/Rewards Std                 0.299983\n",
      "evaluation/Rewards Max                 6.37812\n",
      "evaluation/Rewards Min                 3.33553\n",
      "evaluation/Returns Mean             1181.36\n",
      "evaluation/Returns Std               534.738\n",
      "evaluation/Returns Max              1921.38\n",
      "evaluation/Returns Min               508.899\n",
      "evaluation/Estimation Bias Mean      319.693\n",
      "evaluation/Estimation Bias Std       227.717\n",
      "evaluation/EB/Q_True Mean             61.7944\n",
      "evaluation/EB/Q_True Std             149.01\n",
      "evaluation/EB/Q_Pred Mean            381.487\n",
      "evaluation/EB/Q_Pred Std             174.213\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1181.36\n",
      "evaluation/Actions Mean                0.0680803\n",
      "evaluation/Actions Std                 0.709352\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.94787\n",
      "time/backward_zf1 (s)                  2.36006\n",
      "time/backward_zf2 (s)                  2.31012\n",
      "time/data sampling (s)                 0.3192\n",
      "time/data storing (s)                  0.0152084\n",
      "time/evaluation sampling (s)           0.923997\n",
      "time/exploration sampling (s)          0.502434\n",
      "time/logging (s)                       0.00448931\n",
      "time/preback_alpha (s)                 0.576283\n",
      "time/preback_policy (s)                1.19486\n",
      "time/preback_start (s)                 0.173557\n",
      "time/preback_zf (s)                    6.66086\n",
      "time/saving (s)                        3.163e-06\n",
      "time/training (s)                      3.00659\n",
      "time/epoch (s)                        19.9955\n",
      "time/total (s)                      1424.7\n",
      "Epoch                                 73\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:49:27.623371 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 74 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 85000\n",
      "trainer/ZF1 Loss                      39.0662\n",
      "trainer/ZF2 Loss                      38.8665\n",
      "trainer/ZF Expert Reward              16.1022\n",
      "trainer/ZF Policy Reward               5.42802\n",
      "trainer/ZF CHI2 Term                  48.6011\n",
      "trainer/Policy Loss                 -285.382\n",
      "trainer/Bias Loss                      4.11338\n",
      "trainer/Bias Value                    16.1128\n",
      "trainer/Policy Grad Norm              66.1401\n",
      "trainer/Policy Param Norm             39.3453\n",
      "trainer/Zf1 Grad Norm               5460.16\n",
      "trainer/Zf1 Param Norm                82.9942\n",
      "trainer/Zf2 Grad Norm               4147.42\n",
      "trainer/Zf2 Param Norm                81.285\n",
      "trainer/Z Expert Predictions Mean    652.214\n",
      "trainer/Z Expert Predictions Std      27.8263\n",
      "trainer/Z Expert Predictions Max     709.861\n",
      "trainer/Z Expert Predictions Min     562.714\n",
      "trainer/Z Policy Predictions Mean    280.833\n",
      "trainer/Z Policy Predictions Std     190.902\n",
      "trainer/Z Policy Predictions Max     659.716\n",
      "trainer/Z Policy Predictions Min       0.162056\n",
      "trainer/Z Expert Targets Mean        636.112\n",
      "trainer/Z Expert Targets Std          27.793\n",
      "trainer/Z Expert Targets Max         693.624\n",
      "trainer/Z Expert Targets Min         544.632\n",
      "trainer/Z Policy Targets Mean        275.405\n",
      "trainer/Z Policy Targets Std         189.921\n",
      "trainer/Z Policy Targets Max         612.266\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  45.2032\n",
      "trainer/Log Pis Std                   18.1002\n",
      "trainer/Policy mu Mean                 0.300725\n",
      "trainer/Policy mu Std                  2.35623\n",
      "trainer/Policy log std Mean           -1.65684\n",
      "trainer/Policy log std Std             0.965164\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        80692\n",
      "exploration/num paths total         1194\n",
      "evaluation/num steps total         81265\n",
      "evaluation/num paths total           750\n",
      "evaluation/path length Mean          295.3\n",
      "evaluation/path length Std           122.162\n",
      "evaluation/path length Max           569\n",
      "evaluation/path length Min           128\n",
      "evaluation/Rewards Mean                5.06886\n",
      "evaluation/Rewards Std                 0.30943\n",
      "evaluation/Rewards Max                 6.17564\n",
      "evaluation/Rewards Min                 2.97477\n",
      "evaluation/Returns Mean             1496.84\n",
      "evaluation/Returns Std               653.519\n",
      "evaluation/Returns Max              2976.83\n",
      "evaluation/Returns Min               666.851\n",
      "evaluation/Estimation Bias Mean      361.745\n",
      "evaluation/Estimation Bias Std       243.508\n",
      "evaluation/EB/Q_True Mean             67.7363\n",
      "evaluation/EB/Q_True Std             150.107\n",
      "evaluation/EB/Q_Pred Mean            429.481\n",
      "evaluation/EB/Q_Pred Std             178.364\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1496.84\n",
      "evaluation/Actions Mean                0.0879221\n",
      "evaluation/Actions Std                 0.658324\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.99607\n",
      "time/backward_zf1 (s)                  2.40558\n",
      "time/backward_zf2 (s)                  2.3507\n",
      "time/data sampling (s)                 0.328635\n",
      "time/data storing (s)                  0.0149055\n",
      "time/evaluation sampling (s)           1.6449\n",
      "time/exploration sampling (s)          0.48646\n",
      "time/logging (s)                       0.00480707\n",
      "time/preback_alpha (s)                 0.581918\n",
      "time/preback_policy (s)                1.1823\n",
      "time/preback_start (s)                 0.175076\n",
      "time/preback_zf (s)                    6.67975\n",
      "time/saving (s)                        3.219e-06\n",
      "time/training (s)                      3.16983\n",
      "time/epoch (s)                        21.0209\n",
      "time/total (s)                      1445.74\n",
      "Epoch                                 74\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:49:47.355631 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 75 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 86000\n",
      "trainer/ZF1 Loss                      29.0197\n",
      "trainer/ZF2 Loss                      37.5342\n",
      "trainer/ZF Expert Reward              17.8331\n",
      "trainer/ZF Policy Reward               5.5418\n",
      "trainer/ZF CHI2 Term                  44.4369\n",
      "trainer/Policy Loss                 -277.803\n",
      "trainer/Bias Loss                      8.80047\n",
      "trainer/Bias Value                    16.1911\n",
      "trainer/Policy Grad Norm              60.8381\n",
      "trainer/Policy Param Norm             39.5254\n",
      "trainer/Zf1 Grad Norm               3637.06\n",
      "trainer/Zf1 Param Norm                83.5842\n",
      "trainer/Zf2 Grad Norm               4781.83\n",
      "trainer/Zf2 Param Norm                81.8954\n",
      "trainer/Z Expert Predictions Mean    673.916\n",
      "trainer/Z Expert Predictions Std      30.7763\n",
      "trainer/Z Expert Predictions Max     736.637\n",
      "trainer/Z Expert Predictions Min     541.52\n",
      "trainer/Z Policy Predictions Mean    274.341\n",
      "trainer/Z Policy Predictions Std     190.395\n",
      "trainer/Z Policy Predictions Max     638.573\n",
      "trainer/Z Policy Predictions Min       4.12507\n",
      "trainer/Z Expert Targets Mean        656.083\n",
      "trainer/Z Expert Targets Std          31.6993\n",
      "trainer/Z Expert Targets Max         740.981\n",
      "trainer/Z Expert Targets Min         520.046\n",
      "trainer/Z Policy Targets Mean        268.799\n",
      "trainer/Z Policy Targets Std         190.071\n",
      "trainer/Z Policy Targets Max         631.15\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  43.2288\n",
      "trainer/Log Pis Std                   15.3889\n",
      "trainer/Policy mu Mean                 0.279473\n",
      "trainer/Policy mu Std                  2.27126\n",
      "trainer/Policy log std Mean           -1.65267\n",
      "trainer/Policy log std Std             0.977463\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        82274\n",
      "exploration/num paths total         1197\n",
      "evaluation/num steps total         84072\n",
      "evaluation/num paths total           760\n",
      "evaluation/path length Mean          280.7\n",
      "evaluation/path length Std            71.698\n",
      "evaluation/path length Max           400\n",
      "evaluation/path length Min           166\n",
      "evaluation/Rewards Mean                5.09371\n",
      "evaluation/Rewards Std                 0.322905\n",
      "evaluation/Rewards Max                 6.84319\n",
      "evaluation/Rewards Min                 3.20636\n",
      "evaluation/Returns Mean             1429.8\n",
      "evaluation/Returns Std               359.452\n",
      "evaluation/Returns Max              2020.21\n",
      "evaluation/Returns Min               866.208\n",
      "evaluation/Estimation Bias Mean      375.874\n",
      "evaluation/Estimation Bias Std       235.741\n",
      "evaluation/EB/Q_True Mean             54.205\n",
      "evaluation/EB/Q_True Std             143.064\n",
      "evaluation/EB/Q_Pred Mean            430.079\n",
      "evaluation/EB/Q_Pred Std             171.885\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1429.8\n",
      "evaluation/Actions Mean                0.130462\n",
      "evaluation/Actions Std                 0.662405\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.68199\n",
      "time/backward_zf1 (s)                  2.06023\n",
      "time/backward_zf2 (s)                  2.00453\n",
      "time/data sampling (s)                 0.308935\n",
      "time/data storing (s)                  0.014775\n",
      "time/evaluation sampling (s)           1.03745\n",
      "time/exploration sampling (s)          0.500044\n",
      "time/logging (s)                       0.00433627\n",
      "time/preback_alpha (s)                 0.557956\n",
      "time/preback_policy (s)                0.916059\n",
      "time/preback_start (s)                 0.168184\n",
      "time/preback_zf (s)                    6.58423\n",
      "time/saving (s)                        3.129e-06\n",
      "time/training (s)                      3.82954\n",
      "time/epoch (s)                        19.6683\n",
      "time/total (s)                      1465.42\n",
      "Epoch                                 75\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:50:07.162812 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 76 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 87000\n",
      "trainer/ZF1 Loss                      30.7371\n",
      "trainer/ZF2 Loss                      34.4216\n",
      "trainer/ZF Expert Reward              18.2815\n",
      "trainer/ZF Policy Reward               5.4467\n",
      "trainer/ZF CHI2 Term                  43.9673\n",
      "trainer/Policy Loss                 -337.384\n",
      "trainer/Bias Loss                      7.64837\n",
      "trainer/Bias Value                    16.269\n",
      "trainer/Policy Grad Norm              75.0732\n",
      "trainer/Policy Param Norm             39.7058\n",
      "trainer/Zf1 Grad Norm               4013.29\n",
      "trainer/Zf1 Param Norm                84.185\n",
      "trainer/Zf2 Grad Norm               4187.97\n",
      "trainer/Zf2 Param Norm                82.5287\n",
      "trainer/Z Expert Predictions Mean    693.419\n",
      "trainer/Z Expert Predictions Std      43.6249\n",
      "trainer/Z Expert Predictions Max     760.291\n",
      "trainer/Z Expert Predictions Min     248.986\n",
      "trainer/Z Policy Predictions Mean    330.892\n",
      "trainer/Z Policy Predictions Std     197.382\n",
      "trainer/Z Policy Predictions Max     644.2\n",
      "trainer/Z Policy Predictions Min      -4.23849\n",
      "trainer/Z Expert Targets Mean        675.137\n",
      "trainer/Z Expert Targets Std          43.4841\n",
      "trainer/Z Expert Targets Max         744.875\n",
      "trainer/Z Expert Targets Min         236.422\n",
      "trainer/Z Policy Targets Mean        325.446\n",
      "trainer/Z Policy Targets Std         198.015\n",
      "trainer/Z Policy Targets Max         636.389\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  42.6511\n",
      "trainer/Log Pis Std                   18.3625\n",
      "trainer/Policy mu Mean                 0.394091\n",
      "trainer/Policy mu Std                  2.19115\n",
      "trainer/Policy log std Mean           -1.79099\n",
      "trainer/Policy log std Std             0.939373\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        82755\n",
      "exploration/num paths total         1198\n",
      "evaluation/num steps total         86131\n",
      "evaluation/num paths total           770\n",
      "evaluation/path length Mean          205.9\n",
      "evaluation/path length Std            58.7919\n",
      "evaluation/path length Max           320\n",
      "evaluation/path length Min            91\n",
      "evaluation/Rewards Mean                5.23864\n",
      "evaluation/Rewards Std                 0.210056\n",
      "evaluation/Rewards Max                 6.31219\n",
      "evaluation/Rewards Min                 4.50205\n",
      "evaluation/Returns Mean             1078.64\n",
      "evaluation/Returns Std               316.804\n",
      "evaluation/Returns Max              1679.76\n",
      "evaluation/Returns Min               440.375\n",
      "evaluation/Estimation Bias Mean      396.495\n",
      "evaluation/Estimation Bias Std       231.019\n",
      "evaluation/EB/Q_True Mean             41.5291\n",
      "evaluation/EB/Q_True Std             107.664\n",
      "evaluation/EB/Q_Pred Mean            438.024\n",
      "evaluation/EB/Q_Pred Std             219.386\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1078.64\n",
      "evaluation/Actions Mean                0.144052\n",
      "evaluation/Actions Std                 0.642131\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.92694\n",
      "time/backward_zf1 (s)                  2.32324\n",
      "time/backward_zf2 (s)                  2.27384\n",
      "time/data sampling (s)                 0.320355\n",
      "time/data storing (s)                  0.0146377\n",
      "time/evaluation sampling (s)           0.884688\n",
      "time/exploration sampling (s)          0.504913\n",
      "time/logging (s)                       0.00364869\n",
      "time/preback_alpha (s)                 0.563451\n",
      "time/preback_policy (s)                1.18471\n",
      "time/preback_start (s)                 0.171991\n",
      "time/preback_zf (s)                    6.60624\n",
      "time/saving (s)                        3.062e-06\n",
      "time/training (s)                      2.96128\n",
      "time/epoch (s)                        19.7399\n",
      "time/total (s)                      1485.19\n",
      "Epoch                                 76\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:50:27.499787 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 77 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 88000\n",
      "trainer/ZF1 Loss                      38.0165\n",
      "trainer/ZF2 Loss                      47.519\n",
      "trainer/ZF Expert Reward              16.5501\n",
      "trainer/ZF Policy Reward               3.26413\n",
      "trainer/ZF CHI2 Term                  52.2159\n",
      "trainer/Policy Loss                 -321.78\n",
      "trainer/Bias Loss                      7.75044\n",
      "trainer/Bias Value                    16.3459\n",
      "trainer/Policy Grad Norm              77.6991\n",
      "trainer/Policy Param Norm             39.8893\n",
      "trainer/Zf1 Grad Norm               6281.71\n",
      "trainer/Zf1 Param Norm                84.7715\n",
      "trainer/Zf2 Grad Norm               5333.92\n",
      "trainer/Zf2 Param Norm                83.1641\n",
      "trainer/Z Expert Predictions Mean    712.128\n",
      "trainer/Z Expert Predictions Std      60.7402\n",
      "trainer/Z Expert Predictions Max     767.333\n",
      "trainer/Z Expert Predictions Min      25.5556\n",
      "trainer/Z Policy Predictions Mean    312.848\n",
      "trainer/Z Policy Predictions Std     197.167\n",
      "trainer/Z Policy Predictions Max     630.803\n",
      "trainer/Z Policy Predictions Min      -0.68165\n",
      "trainer/Z Expert Targets Mean        695.578\n",
      "trainer/Z Expert Targets Std          61.273\n",
      "trainer/Z Expert Targets Max         784.944\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        309.583\n",
      "trainer/Z Policy Targets Std         198.487\n",
      "trainer/Z Policy Targets Max         620.654\n",
      "trainer/Z Policy Targets Min         -30.6882\n",
      "trainer/Log Pis Mean                  45.0873\n",
      "trainer/Log Pis Std                   17.3371\n",
      "trainer/Policy mu Mean                 0.342274\n",
      "trainer/Policy mu Std                  2.26392\n",
      "trainer/Policy log std Mean           -1.76516\n",
      "trainer/Policy log std Std             0.941681\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        83551\n",
      "exploration/num paths total         1200\n",
      "evaluation/num steps total         88807\n",
      "evaluation/num paths total           780\n",
      "evaluation/path length Mean          267.6\n",
      "evaluation/path length Std            60.0936\n",
      "evaluation/path length Max           379\n",
      "evaluation/path length Min           175\n",
      "evaluation/Rewards Mean                5.09209\n",
      "evaluation/Rewards Std                 0.292291\n",
      "evaluation/Rewards Max                 6.40209\n",
      "evaluation/Rewards Min                 3.29083\n",
      "evaluation/Returns Mean             1362.64\n",
      "evaluation/Returns Std               321.013\n",
      "evaluation/Returns Max              1959.62\n",
      "evaluation/Returns Min               890.176\n",
      "evaluation/Estimation Bias Mean      424.848\n",
      "evaluation/Estimation Bias Std       236.136\n",
      "evaluation/EB/Q_True Mean             40.2609\n",
      "evaluation/EB/Q_True Std             109.809\n",
      "evaluation/EB/Q_Pred Mean            465.109\n",
      "evaluation/EB/Q_Pred Std             212.953\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1362.64\n",
      "evaluation/Actions Mean                0.141978\n",
      "evaluation/Actions Std                 0.62108\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.92203\n",
      "time/backward_zf1 (s)                  2.33493\n",
      "time/backward_zf2 (s)                  2.26641\n",
      "time/data sampling (s)                 0.318644\n",
      "time/data storing (s)                  0.0144596\n",
      "time/evaluation sampling (s)           1.417\n",
      "time/exploration sampling (s)          0.488352\n",
      "time/logging (s)                       0.00824038\n",
      "time/preback_alpha (s)                 0.563973\n",
      "time/preback_policy (s)                1.17202\n",
      "time/preback_start (s)                 0.173522\n",
      "time/preback_zf (s)                    6.60221\n",
      "time/saving (s)                        4.255e-06\n",
      "time/training (s)                      2.98767\n",
      "time/epoch (s)                        20.2695\n",
      "time/total (s)                      1505.48\n",
      "Epoch                                 77\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:50:47.328432 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 78 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 89000\n",
      "trainer/ZF1 Loss                      52.4016\n",
      "trainer/ZF2 Loss                      57.863\n",
      "trainer/ZF Expert Reward              17.0715\n",
      "trainer/ZF Policy Reward               4.22041\n",
      "trainer/ZF CHI2 Term                  64.815\n",
      "trainer/Policy Loss                 -325.9\n",
      "trainer/Bias Loss                      5.51698\n",
      "trainer/Bias Value                    16.4217\n",
      "trainer/Policy Grad Norm              63.887\n",
      "trainer/Policy Param Norm             40.0863\n",
      "trainer/Zf1 Grad Norm               4649.51\n",
      "trainer/Zf1 Param Norm                85.414\n",
      "trainer/Zf2 Grad Norm               5434.16\n",
      "trainer/Zf2 Param Norm                83.8299\n",
      "trainer/Z Expert Predictions Mean    744.793\n",
      "trainer/Z Expert Predictions Std      33.3734\n",
      "trainer/Z Expert Predictions Max     796.051\n",
      "trainer/Z Expert Predictions Min     547.072\n",
      "trainer/Z Policy Predictions Mean    320.07\n",
      "trainer/Z Policy Predictions Std     205.354\n",
      "trainer/Z Policy Predictions Max     734.055\n",
      "trainer/Z Policy Predictions Min      -3.13525\n",
      "trainer/Z Expert Targets Mean        727.721\n",
      "trainer/Z Expert Targets Std          32.6643\n",
      "trainer/Z Expert Targets Max         783.205\n",
      "trainer/Z Expert Targets Min         531.113\n",
      "trainer/Z Policy Targets Mean        315.849\n",
      "trainer/Z Policy Targets Std         205.682\n",
      "trainer/Z Policy Targets Max         732.898\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  43.658\n",
      "trainer/Log Pis Std                   16.5752\n",
      "trainer/Policy mu Mean                 0.296565\n",
      "trainer/Policy mu Std                  2.23043\n",
      "trainer/Policy log std Mean           -1.76033\n",
      "trainer/Policy log std Std             1.04936\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        85142\n",
      "exploration/num paths total         1203\n",
      "evaluation/num steps total         90944\n",
      "evaluation/num paths total           790\n",
      "evaluation/path length Mean          213.7\n",
      "evaluation/path length Std            68.0368\n",
      "evaluation/path length Max           400\n",
      "evaluation/path length Min           154\n",
      "evaluation/Rewards Mean                5.11297\n",
      "evaluation/Rewards Std                 0.243313\n",
      "evaluation/Rewards Max                 5.9913\n",
      "evaluation/Rewards Min                 3.92142\n",
      "evaluation/Returns Mean             1092.64\n",
      "evaluation/Returns Std               352.016\n",
      "evaluation/Returns Max              2043.14\n",
      "evaluation/Returns Min               781.066\n",
      "evaluation/Estimation Bias Mean      428.123\n",
      "evaluation/Estimation Bias Std       301.39\n",
      "evaluation/EB/Q_True Mean             72.2397\n",
      "evaluation/EB/Q_True Std             162.181\n",
      "evaluation/EB/Q_Pred Mean            500.363\n",
      "evaluation/EB/Q_Pred Std             244.169\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1092.64\n",
      "evaluation/Actions Mean                0.154169\n",
      "evaluation/Actions Std                 0.620082\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.8271\n",
      "time/backward_zf1 (s)                  2.23151\n",
      "time/backward_zf2 (s)                  2.18349\n",
      "time/data sampling (s)                 0.316421\n",
      "time/data storing (s)                  0.0141994\n",
      "time/evaluation sampling (s)           0.941485\n",
      "time/exploration sampling (s)          0.480738\n",
      "time/logging (s)                       0.00357471\n",
      "time/preback_alpha (s)                 0.568017\n",
      "time/preback_policy (s)                1.09557\n",
      "time/preback_start (s)                 0.171111\n",
      "time/preback_zf (s)                    6.63946\n",
      "time/saving (s)                        3.46e-06\n",
      "time/training (s)                      3.28869\n",
      "time/epoch (s)                        19.7614\n",
      "time/total (s)                      1525.26\n",
      "Epoch                                 78\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:51:07.045729 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 79 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 90000\n",
      "trainer/ZF1 Loss                      38.8826\n",
      "trainer/ZF2 Loss                      48.2378\n",
      "trainer/ZF Expert Reward              19.3961\n",
      "trainer/ZF Policy Reward               6.7257\n",
      "trainer/ZF CHI2 Term                  55.2731\n",
      "trainer/Policy Loss                 -342.203\n",
      "trainer/Bias Loss                     10.0998\n",
      "trainer/Bias Value                    16.4963\n",
      "trainer/Policy Grad Norm              64.3298\n",
      "trainer/Policy Param Norm             40.2879\n",
      "trainer/Zf1 Grad Norm               4757\n",
      "trainer/Zf1 Param Norm                86.0841\n",
      "trainer/Zf2 Grad Norm               6771.94\n",
      "trainer/Zf2 Param Norm                84.5406\n",
      "trainer/Z Expert Predictions Mean    769.963\n",
      "trainer/Z Expert Predictions Std      55.5067\n",
      "trainer/Z Expert Predictions Max     820.702\n",
      "trainer/Z Expert Predictions Min      30.664\n",
      "trainer/Z Policy Predictions Mean    338.063\n",
      "trainer/Z Policy Predictions Std     213.279\n",
      "trainer/Z Policy Predictions Max     732.165\n",
      "trainer/Z Policy Predictions Min       2.58656\n",
      "trainer/Z Expert Targets Mean        750.566\n",
      "trainer/Z Expert Targets Std          56.5011\n",
      "trainer/Z Expert Targets Max         803.325\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        331.337\n",
      "trainer/Z Policy Targets Std         212.943\n",
      "trainer/Z Policy Targets Max         745.542\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  46.2466\n",
      "trainer/Log Pis Std                   19.4101\n",
      "trainer/Policy mu Mean                 0.440818\n",
      "trainer/Policy mu Std                  2.33551\n",
      "trainer/Policy log std Mean           -1.78129\n",
      "trainer/Policy log std Std             1.01399\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        88253\n",
      "exploration/num paths total         1207\n",
      "evaluation/num steps total         92870\n",
      "evaluation/num paths total           800\n",
      "evaluation/path length Mean          192.6\n",
      "evaluation/path length Std            37.1543\n",
      "evaluation/path length Max           278\n",
      "evaluation/path length Min           139\n",
      "evaluation/Rewards Mean                5.15048\n",
      "evaluation/Rewards Std                 0.244373\n",
      "evaluation/Rewards Max                 6.30526\n",
      "evaluation/Rewards Min                 3.97316\n",
      "evaluation/Returns Mean              991.983\n",
      "evaluation/Returns Std               210.177\n",
      "evaluation/Returns Max              1477.43\n",
      "evaluation/Returns Min               706.787\n",
      "evaluation/Estimation Bias Mean      434.603\n",
      "evaluation/Estimation Bias Std       268.291\n",
      "evaluation/EB/Q_True Mean             51.5561\n",
      "evaluation/EB/Q_True Std             135.276\n",
      "evaluation/EB/Q_Pred Mean            486.159\n",
      "evaluation/EB/Q_Pred Std             234.338\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns           991.983\n",
      "evaluation/Actions Mean                0.156732\n",
      "evaluation/Actions Std                 0.627047\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.92298\n",
      "time/backward_zf1 (s)                  2.33768\n",
      "time/backward_zf2 (s)                  2.28328\n",
      "time/data sampling (s)                 0.337037\n",
      "time/data storing (s)                  0.0142879\n",
      "time/evaluation sampling (s)           0.680352\n",
      "time/exploration sampling (s)          0.496258\n",
      "time/logging (s)                       0.00369852\n",
      "time/preback_alpha (s)                 0.571325\n",
      "time/preback_policy (s)                1.18976\n",
      "time/preback_start (s)                 0.17546\n",
      "time/preback_zf (s)                    6.62986\n",
      "time/saving (s)                        2.728e-06\n",
      "time/training (s)                      3.01395\n",
      "time/epoch (s)                        19.6559\n",
      "time/total (s)                      1544.93\n",
      "Epoch                                 79\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:51:27.933640 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 80 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 91000\n",
      "trainer/ZF1 Loss                      53.7963\n",
      "trainer/ZF2 Loss                      57.8431\n",
      "trainer/ZF Expert Reward              17.7171\n",
      "trainer/ZF Policy Reward               5.87048\n",
      "trainer/ZF CHI2 Term                  65.5671\n",
      "trainer/Policy Loss                 -356.739\n",
      "trainer/Bias Loss                      7.35863\n",
      "trainer/Bias Value                    16.5703\n",
      "trainer/Policy Grad Norm              79.8532\n",
      "trainer/Policy Param Norm             40.5014\n",
      "trainer/Zf1 Grad Norm               7533.6\n",
      "trainer/Zf1 Param Norm                86.7679\n",
      "trainer/Zf2 Grad Norm               6606.07\n",
      "trainer/Zf2 Param Norm                85.2603\n",
      "trainer/Z Expert Predictions Mean    800.782\n",
      "trainer/Z Expert Predictions Std      30.6862\n",
      "trainer/Z Expert Predictions Max     842.672\n",
      "trainer/Z Expert Predictions Min     692.261\n",
      "trainer/Z Policy Predictions Mean    348.747\n",
      "trainer/Z Policy Predictions Std     226.271\n",
      "trainer/Z Policy Predictions Max     769.585\n",
      "trainer/Z Policy Predictions Min       7.789\n",
      "trainer/Z Expert Targets Mean        783.065\n",
      "trainer/Z Expert Targets Std          31.3966\n",
      "trainer/Z Expert Targets Max         824.531\n",
      "trainer/Z Expert Targets Min         668.88\n",
      "trainer/Z Policy Targets Mean        342.877\n",
      "trainer/Z Policy Targets Std         226.505\n",
      "trainer/Z Policy Targets Max         785.838\n",
      "trainer/Z Policy Targets Min         -12.8505\n",
      "trainer/Log Pis Mean                  47.1533\n",
      "trainer/Log Pis Std                   17.7082\n",
      "trainer/Policy mu Mean                 0.428958\n",
      "trainer/Policy mu Std                  2.36508\n",
      "trainer/Policy log std Mean           -1.79313\n",
      "trainer/Policy log std Std             1.06055\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        88945\n",
      "exploration/num paths total         1210\n",
      "evaluation/num steps total         95269\n",
      "evaluation/num paths total           810\n",
      "evaluation/path length Mean          239.9\n",
      "evaluation/path length Std            63.4578\n",
      "evaluation/path length Max           326\n",
      "evaluation/path length Min           119\n",
      "evaluation/Rewards Mean                5.12017\n",
      "evaluation/Rewards Std                 0.316744\n",
      "evaluation/Rewards Max                 6.39258\n",
      "evaluation/Rewards Min                 3.5843\n",
      "evaluation/Returns Mean             1228.33\n",
      "evaluation/Returns Std               354.258\n",
      "evaluation/Returns Max              1674.06\n",
      "evaluation/Returns Min               575.049\n",
      "evaluation/Estimation Bias Mean      497.16\n",
      "evaluation/Estimation Bias Std       261.952\n",
      "evaluation/EB/Q_True Mean             36.5079\n",
      "evaluation/EB/Q_True Std             103.096\n",
      "evaluation/EB/Q_Pred Mean            533.668\n",
      "evaluation/EB/Q_Pred Std             247.919\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          1228.33\n",
      "evaluation/Actions Mean                0.122444\n",
      "evaluation/Actions Std                 0.630834\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               2.02975\n",
      "time/backward_zf1 (s)                  2.44504\n",
      "time/backward_zf2 (s)                  2.399\n",
      "time/data sampling (s)                 0.342597\n",
      "time/data storing (s)                  0.0154736\n",
      "time/evaluation sampling (s)           1.34452\n",
      "time/exploration sampling (s)          0.508396\n",
      "time/logging (s)                       0.00586434\n",
      "time/preback_alpha (s)                 0.588817\n",
      "time/preback_policy (s)                1.23085\n",
      "time/preback_start (s)                 0.179837\n",
      "time/preback_zf (s)                    6.70652\n",
      "time/saving (s)                        5.234e-06\n",
      "time/training (s)                      3.02535\n",
      "time/epoch (s)                        20.822\n",
      "time/total (s)                      1565.77\n",
      "Epoch                                 80\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:51:48.214122 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 81 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 92000\n",
      "trainer/ZF1 Loss                      47.7422\n",
      "trainer/ZF2 Loss                      56.5449\n",
      "trainer/ZF Expert Reward              18.2288\n",
      "trainer/ZF Policy Reward               5.69255\n",
      "trainer/ZF CHI2 Term                  62.1072\n",
      "trainer/Policy Loss                 -360.915\n",
      "trainer/Bias Loss                      8.09402\n",
      "trainer/Bias Value                    16.6448\n",
      "trainer/Policy Grad Norm              78.7042\n",
      "trainer/Policy Param Norm             40.7197\n",
      "trainer/Zf1 Grad Norm               4729.92\n",
      "trainer/Zf1 Param Norm                87.4724\n",
      "trainer/Zf2 Grad Norm               5026.78\n",
      "trainer/Zf2 Param Norm                85.9827\n",
      "trainer/Z Expert Predictions Mean    828.437\n",
      "trainer/Z Expert Predictions Std      56.6496\n",
      "trainer/Z Expert Predictions Max     870.953\n",
      "trainer/Z Expert Predictions Min      31.7459\n",
      "trainer/Z Policy Predictions Mean    351.724\n",
      "trainer/Z Policy Predictions Std     224.332\n",
      "trainer/Z Policy Predictions Max     775.937\n",
      "trainer/Z Policy Predictions Min       8.73218\n",
      "trainer/Z Expert Targets Mean        810.208\n",
      "trainer/Z Expert Targets Std          57.8104\n",
      "trainer/Z Expert Targets Max         852.733\n",
      "trainer/Z Expert Targets Min           0\n",
      "trainer/Z Policy Targets Mean        346.032\n",
      "trainer/Z Policy Targets Std         224.071\n",
      "trainer/Z Policy Targets Max         789.221\n",
      "trainer/Z Policy Targets Min           0\n",
      "trainer/Log Pis Mean                  47.3186\n",
      "trainer/Log Pis Std                   19.0642\n",
      "trainer/Policy mu Mean                 0.332521\n",
      "trainer/Policy mu Std                  2.43653\n",
      "trainer/Policy log std Mean           -1.77341\n",
      "trainer/Policy log std Std             1.06358\n",
      "trainer/Alpha                          0.01\n",
      "exploration/num steps total        88945\n",
      "exploration/num paths total         1210\n",
      "evaluation/num steps total         99478\n",
      "evaluation/num paths total           820\n",
      "evaluation/path length Mean          420.9\n",
      "evaluation/path length Std           105.117\n",
      "evaluation/path length Max           559\n",
      "evaluation/path length Min           215\n",
      "evaluation/Rewards Mean                5.10445\n",
      "evaluation/Rewards Std                 0.311641\n",
      "evaluation/Rewards Max                 6.23576\n",
      "evaluation/Rewards Min                 3.60659\n",
      "evaluation/Returns Mean             2148.46\n",
      "evaluation/Returns Std               545.516\n",
      "evaluation/Returns Max              2855.44\n",
      "evaluation/Returns Min              1037.38\n",
      "evaluation/Estimation Bias Mean      568.288\n",
      "evaluation/Estimation Bias Std       285.257\n",
      "evaluation/EB/Q_True Mean             55.7921\n",
      "evaluation/EB/Q_True Std             151.111\n",
      "evaluation/EB/Q_Pred Mean            624.08\n",
      "evaluation/EB/Q_Pred Std             225.752\n",
      "evaluation/Num Paths                  10\n",
      "evaluation/Average Returns          2148.46\n",
      "evaluation/Actions Mean                0.095344\n",
      "evaluation/Actions Std                 0.603787\n",
      "evaluation/Actions Max                 1\n",
      "evaluation/Actions Min                -1\n",
      "time/backward_policy (s)               1.84739\n",
      "time/backward_zf1 (s)                  2.22716\n",
      "time/backward_zf2 (s)                  2.18172\n",
      "time/data sampling (s)                 0.306231\n",
      "time/data storing (s)                  0.0145695\n",
      "time/evaluation sampling (s)           1.34963\n",
      "time/exploration sampling (s)          0.494308\n",
      "time/logging (s)                       0.00643655\n",
      "time/preback_alpha (s)                 0.569142\n",
      "time/preback_policy (s)                1.0953\n",
      "time/preback_start (s)                 0.172629\n",
      "time/preback_zf (s)                    6.62815\n",
      "time/saving (s)                        2.575e-06\n",
      "time/training (s)                      3.32638\n",
      "time/epoch (s)                        20.219\n",
      "time/total (s)                      1586.01\n",
      "Epoch                                 81\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:52:09.157491 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 82 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  93000\n",
      "trainer/ZF1 Loss                       68.4877\n",
      "trainer/ZF2 Loss                       64.6354\n",
      "trainer/ZF Expert Reward               17.3106\n",
      "trainer/ZF Policy Reward                2.12985\n",
      "trainer/ZF CHI2 Term                   75.304\n",
      "trainer/Policy Loss                  -341.969\n",
      "trainer/Bias Loss                       8.97555\n",
      "trainer/Bias Value                     16.7196\n",
      "trainer/Policy Grad Norm               90.3806\n",
      "trainer/Policy Param Norm              40.9482\n",
      "trainer/Zf1 Grad Norm                7433\n",
      "trainer/Zf1 Param Norm                 88.1711\n",
      "trainer/Zf2 Grad Norm                9501.51\n",
      "trainer/Zf2 Param Norm                 86.712\n",
      "trainer/Z Expert Predictions Mean     856.832\n",
      "trainer/Z Expert Predictions Std       78.8525\n",
      "trainer/Z Expert Predictions Max      898.235\n",
      "trainer/Z Expert Predictions Min       33.1328\n",
      "trainer/Z Policy Predictions Mean     331.772\n",
      "trainer/Z Policy Predictions Std      246.776\n",
      "trainer/Z Policy Predictions Max      849.556\n",
      "trainer/Z Policy Predictions Min      -11.9684\n",
      "trainer/Z Expert Targets Mean         839.521\n",
      "trainer/Z Expert Targets Std           80.7536\n",
      "trainer/Z Expert Targets Max          882.303\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         329.642\n",
      "trainer/Z Policy Targets Std          247.453\n",
      "trainer/Z Policy Targets Max          855.09\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   51.6384\n",
      "trainer/Log Pis Std                    23.2188\n",
      "trainer/Policy mu Mean                  0.266718\n",
      "trainer/Policy mu Std                   2.7779\n",
      "trainer/Policy log std Mean            -1.64064\n",
      "trainer/Policy log std Std              1.07603\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         89243\n",
      "exploration/num paths total          1211\n",
      "evaluation/num steps total         105899\n",
      "evaluation/num paths total            833\n",
      "evaluation/path length Mean           493.923\n",
      "evaluation/path length Std            410.927\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             87\n",
      "evaluation/Rewards Mean                 5.13524\n",
      "evaluation/Rewards Std                  0.212055\n",
      "evaluation/Rewards Max                  6.10778\n",
      "evaluation/Rewards Min                  3.51994\n",
      "evaluation/Returns Mean              2536.41\n",
      "evaluation/Returns Std               2143.25\n",
      "evaluation/Returns Max               5195.68\n",
      "evaluation/Returns Min                395.208\n",
      "evaluation/Estimation Bias Mean       611.638\n",
      "evaluation/Estimation Bias Std        314.235\n",
      "evaluation/EB/Q_True Mean              73.0696\n",
      "evaluation/EB/Q_True Std              174.968\n",
      "evaluation/EB/Q_Pred Mean             684.708\n",
      "evaluation/EB/Q_Pred Std              187.575\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2536.41\n",
      "evaluation/Actions Mean                 0.0777207\n",
      "evaluation/Actions Std                  0.546903\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.68023\n",
      "time/backward_zf1 (s)                   2.10526\n",
      "time/backward_zf2 (s)                   2.01347\n",
      "time/data sampling (s)                  0.322072\n",
      "time/data storing (s)                   0.0142557\n",
      "time/evaluation sampling (s)            2.25621\n",
      "time/exploration sampling (s)           0.475188\n",
      "time/logging (s)                        0.00906973\n",
      "time/preback_alpha (s)                  0.556337\n",
      "time/preback_policy (s)                 0.93155\n",
      "time/preback_start (s)                  0.166611\n",
      "time/preback_zf (s)                     6.56822\n",
      "time/saving (s)                         2.801e-06\n",
      "time/training (s)                       3.78428\n",
      "time/epoch (s)                         20.8827\n",
      "time/total (s)                       1606.91\n",
      "Epoch                                  82\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:52:29.157000 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 83 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  94000\n",
      "trainer/ZF1 Loss                       63.0997\n",
      "trainer/ZF2 Loss                       80.8922\n",
      "trainer/ZF Expert Reward               19.3799\n",
      "trainer/ZF Policy Reward                6.31596\n",
      "trainer/ZF CHI2 Term                   82.5087\n",
      "trainer/Policy Loss                  -433.456\n",
      "trainer/Bias Loss                      10.5338\n",
      "trainer/Bias Value                     16.7933\n",
      "trainer/Policy Grad Norm               87.8211\n",
      "trainer/Policy Param Norm              41.1827\n",
      "trainer/Zf1 Grad Norm                6627.93\n",
      "trainer/Zf1 Param Norm                 88.887\n",
      "trainer/Zf2 Grad Norm                8225.51\n",
      "trainer/Zf2 Param Norm                 87.4527\n",
      "trainer/Z Expert Predictions Mean     891.744\n",
      "trainer/Z Expert Predictions Std       38.2332\n",
      "trainer/Z Expert Predictions Max      937.486\n",
      "trainer/Z Expert Predictions Min      479.462\n",
      "trainer/Z Policy Predictions Mean     425.956\n",
      "trainer/Z Policy Predictions Std      254.54\n",
      "trainer/Z Policy Predictions Max      871.324\n",
      "trainer/Z Policy Predictions Min       -8.42584\n",
      "trainer/Z Expert Targets Mean         872.364\n",
      "trainer/Z Expert Targets Std           38.5339\n",
      "trainer/Z Expert Targets Max          921.325\n",
      "trainer/Z Expert Targets Min          459.466\n",
      "trainer/Z Policy Targets Mean         419.64\n",
      "trainer/Z Policy Targets Std          253.679\n",
      "trainer/Z Policy Targets Max          851.434\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   47.7858\n",
      "trainer/Log Pis Std                    19.5548\n",
      "trainer/Policy mu Mean                  0.199951\n",
      "trainer/Policy mu Std                   2.33439\n",
      "trainer/Policy log std Mean            -2.04082\n",
      "trainer/Policy log std Std              1.0687\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         90421\n",
      "exploration/num paths total          1213\n",
      "evaluation/num steps total         107619\n",
      "evaluation/num paths total            843\n",
      "evaluation/path length Mean           172\n",
      "evaluation/path length Std             44.7258\n",
      "evaluation/path length Max            233\n",
      "evaluation/path length Min            100\n",
      "evaluation/Rewards Mean                 4.94871\n",
      "evaluation/Rewards Std                  0.345267\n",
      "evaluation/Rewards Max                  6.24673\n",
      "evaluation/Rewards Min                  3.67598\n",
      "evaluation/Returns Mean               851.179\n",
      "evaluation/Returns Std                231.946\n",
      "evaluation/Returns Max               1177.54\n",
      "evaluation/Returns Min                477.54\n",
      "evaluation/Estimation Bias Mean       443.588\n",
      "evaluation/Estimation Bias Std        292.526\n",
      "evaluation/EB/Q_True Mean              28.0264\n",
      "evaluation/EB/Q_True Std               84.8737\n",
      "evaluation/EB/Q_Pred Mean             471.615\n",
      "evaluation/EB/Q_Pred Std              271.588\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            851.179\n",
      "evaluation/Actions Mean                 0.15194\n",
      "evaluation/Actions Std                  0.696595\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78077\n",
      "time/backward_zf1 (s)                   2.18712\n",
      "time/backward_zf2 (s)                   2.11899\n",
      "time/data sampling (s)                  0.349985\n",
      "time/data storing (s)                   0.0142741\n",
      "time/evaluation sampling (s)            0.986575\n",
      "time/exploration sampling (s)           0.485128\n",
      "time/logging (s)                        0.00580885\n",
      "time/preback_alpha (s)                  0.574514\n",
      "time/preback_policy (s)                 1.0103\n",
      "time/preback_start (s)                  0.171308\n",
      "time/preback_zf (s)                     6.66262\n",
      "time/saving (s)                         5.01e-06\n",
      "time/training (s)                       3.58436\n",
      "time/epoch (s)                         19.9318\n",
      "time/total (s)                       1626.86\n",
      "Epoch                                  83\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:52:50.180536 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 84 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  95000\n",
      "trainer/ZF1 Loss                       68.6811\n",
      "trainer/ZF2 Loss                       80.2214\n",
      "trainer/ZF Expert Reward               19.9598\n",
      "trainer/ZF Policy Reward                5.81142\n",
      "trainer/ZF CHI2 Term                   85.1959\n",
      "trainer/Policy Loss                  -406.486\n",
      "trainer/Bias Loss                      16.8901\n",
      "trainer/Bias Value                     16.8695\n",
      "trainer/Policy Grad Norm               97.7931\n",
      "trainer/Policy Param Norm              41.4117\n",
      "trainer/Zf1 Grad Norm                8564.36\n",
      "trainer/Zf1 Param Norm                 89.6144\n",
      "trainer/Zf2 Grad Norm                7867.84\n",
      "trainer/Zf2 Param Norm                 88.1733\n",
      "trainer/Z Expert Predictions Mean     924.498\n",
      "trainer/Z Expert Predictions Std       36.34\n",
      "trainer/Z Expert Predictions Max      966.277\n",
      "trainer/Z Expert Predictions Min      530.634\n",
      "trainer/Z Policy Predictions Mean     400.163\n",
      "trainer/Z Policy Predictions Std      258.135\n",
      "trainer/Z Policy Predictions Max      927.826\n",
      "trainer/Z Policy Predictions Min        9.20322\n",
      "trainer/Z Expert Targets Mean         904.538\n",
      "trainer/Z Expert Targets Std           39.1821\n",
      "trainer/Z Expert Targets Max          950.948\n",
      "trainer/Z Expert Targets Min          467.603\n",
      "trainer/Z Policy Targets Mean         394.351\n",
      "trainer/Z Policy Targets Std          256.992\n",
      "trainer/Z Policy Targets Max          900.068\n",
      "trainer/Z Policy Targets Min           -3.20645\n",
      "trainer/Log Pis Mean                   50.0042\n",
      "trainer/Log Pis Std                    19.8402\n",
      "trainer/Policy mu Mean                  0.372743\n",
      "trainer/Policy mu Std                   2.4839\n",
      "trainer/Policy log std Mean            -1.90808\n",
      "trainer/Policy log std Std              1.08046\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         90974\n",
      "exploration/num paths total          1214\n",
      "evaluation/num steps total         111128\n",
      "evaluation/num paths total            853\n",
      "evaluation/path length Mean           350.9\n",
      "evaluation/path length Std            106.936\n",
      "evaluation/path length Max            512\n",
      "evaluation/path length Min            181\n",
      "evaluation/Rewards Mean                 5.10254\n",
      "evaluation/Rewards Std                  0.275272\n",
      "evaluation/Rewards Max                  6.36692\n",
      "evaluation/Rewards Min                  3.24869\n",
      "evaluation/Returns Mean              1790.48\n",
      "evaluation/Returns Std                575.966\n",
      "evaluation/Returns Max               2656.51\n",
      "evaluation/Returns Min                879.545\n",
      "evaluation/Estimation Bias Mean       645.398\n",
      "evaluation/Estimation Bias Std        308.645\n",
      "evaluation/EB/Q_True Mean              61.2664\n",
      "evaluation/EB/Q_True Std              155.809\n",
      "evaluation/EB/Q_Pred Mean             706.664\n",
      "evaluation/EB/Q_Pred Std              252.999\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1790.48\n",
      "evaluation/Actions Mean                 0.106616\n",
      "evaluation/Actions Std                  0.607124\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86816\n",
      "time/backward_zf1 (s)                   2.28109\n",
      "time/backward_zf2 (s)                   2.21476\n",
      "time/data sampling (s)                  0.328014\n",
      "time/data storing (s)                   0.0156848\n",
      "time/evaluation sampling (s)            1.71918\n",
      "time/exploration sampling (s)           0.491451\n",
      "time/logging (s)                        0.00578088\n",
      "time/preback_alpha (s)                  0.578839\n",
      "time/preback_policy (s)                 1.06031\n",
      "time/preback_start (s)                  0.174847\n",
      "time/preback_zf (s)                     6.68694\n",
      "time/saving (s)                         3.002e-06\n",
      "time/training (s)                       3.5294\n",
      "time/epoch (s)                         20.9545\n",
      "time/total (s)                       1647.84\n",
      "Epoch                                  84\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:53:09.905687 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 85 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  96000\n",
      "trainer/ZF1 Loss                       70.835\n",
      "trainer/ZF2 Loss                       65.5323\n",
      "trainer/ZF Expert Reward               17.5259\n",
      "trainer/ZF Policy Reward                6.97033\n",
      "trainer/ZF CHI2 Term                   76.1802\n",
      "trainer/Policy Loss                  -415.658\n",
      "trainer/Bias Loss                       7.28051\n",
      "trainer/Bias Value                     16.942\n",
      "trainer/Policy Grad Norm               84.3865\n",
      "trainer/Policy Param Norm              41.6263\n",
      "trainer/Zf1 Grad Norm                8622.84\n",
      "trainer/Zf1 Param Norm                 90.33\n",
      "trainer/Zf2 Grad Norm                9468.82\n",
      "trainer/Zf2 Param Norm                 88.8931\n",
      "trainer/Z Expert Predictions Mean     956.847\n",
      "trainer/Z Expert Predictions Std       25.982\n",
      "trainer/Z Expert Predictions Max      995.99\n",
      "trainer/Z Expert Predictions Min      855.452\n",
      "trainer/Z Policy Predictions Mean     408.596\n",
      "trainer/Z Policy Predictions Std      284.873\n",
      "trainer/Z Policy Predictions Max      956.263\n",
      "trainer/Z Policy Predictions Min        7.80899\n",
      "trainer/Z Expert Targets Mean         939.321\n",
      "trainer/Z Expert Targets Std           26.3918\n",
      "trainer/Z Expert Targets Max          978.07\n",
      "trainer/Z Expert Targets Min          837.955\n",
      "trainer/Z Policy Targets Mean         401.626\n",
      "trainer/Z Policy Targets Std          284.536\n",
      "trainer/Z Policy Targets Max          940.095\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   52.289\n",
      "trainer/Log Pis Std                    22.6773\n",
      "trainer/Policy mu Mean                  0.189348\n",
      "trainer/Policy mu Std                   2.82083\n",
      "trainer/Policy log std Mean            -1.75603\n",
      "trainer/Policy log std Std              1.19846\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         93051\n",
      "exploration/num paths total          1219\n",
      "evaluation/num steps total         113167\n",
      "evaluation/num paths total            863\n",
      "evaluation/path length Mean           203.9\n",
      "evaluation/path length Std             52.6544\n",
      "evaluation/path length Max            307\n",
      "evaluation/path length Min            124\n",
      "evaluation/Rewards Mean                 5.12692\n",
      "evaluation/Rewards Std                  0.226397\n",
      "evaluation/Rewards Max                  5.96257\n",
      "evaluation/Rewards Min                  3.95213\n",
      "evaluation/Returns Mean              1045.38\n",
      "evaluation/Returns Std                287.984\n",
      "evaluation/Returns Max               1599.09\n",
      "evaluation/Returns Min                613.424\n",
      "evaluation/Estimation Bias Mean       587.579\n",
      "evaluation/Estimation Bias Std        346.018\n",
      "evaluation/EB/Q_True Mean              39.3118\n",
      "evaluation/EB/Q_True Std              104.207\n",
      "evaluation/EB/Q_Pred Mean             626.891\n",
      "evaluation/EB/Q_Pred Std              325.366\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1045.38\n",
      "evaluation/Actions Mean                 0.117361\n",
      "evaluation/Actions Std                  0.640852\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81693\n",
      "time/backward_zf1 (s)                   2.21827\n",
      "time/backward_zf2 (s)                   2.14405\n",
      "time/data sampling (s)                  0.327861\n",
      "time/data storing (s)                   0.0147968\n",
      "time/evaluation sampling (s)            0.819671\n",
      "time/exploration sampling (s)           0.502954\n",
      "time/logging (s)                        0.00392434\n",
      "time/preback_alpha (s)                  0.56639\n",
      "time/preback_policy (s)                 1.07068\n",
      "time/preback_start (s)                  0.171079\n",
      "time/preback_zf (s)                     6.64492\n",
      "time/saving (s)                         2.48e-06\n",
      "time/training (s)                       3.35208\n",
      "time/epoch (s)                         19.6536\n",
      "time/total (s)                       1667.51\n",
      "Epoch                                  85\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:53:29.337988 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 86 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  97000\n",
      "trainer/ZF1 Loss                       91.2844\n",
      "trainer/ZF2 Loss                       76.6023\n",
      "trainer/ZF Expert Reward               18.0824\n",
      "trainer/ZF Policy Reward                1.10212\n",
      "trainer/ZF CHI2 Term                   92.191\n",
      "trainer/Policy Loss                  -453.44\n",
      "trainer/Bias Loss                       7.55293\n",
      "trainer/Bias Value                     17.0141\n",
      "trainer/Policy Grad Norm               82.8759\n",
      "trainer/Policy Param Norm              41.8269\n",
      "trainer/Zf1 Grad Norm               13801\n",
      "trainer/Zf1 Param Norm                 91.0405\n",
      "trainer/Zf2 Grad Norm                9323.65\n",
      "trainer/Zf2 Param Norm                 89.6526\n",
      "trainer/Z Expert Predictions Mean     986.819\n",
      "trainer/Z Expert Predictions Std       24.1552\n",
      "trainer/Z Expert Predictions Max     1023.83\n",
      "trainer/Z Expert Predictions Min      858.781\n",
      "trainer/Z Policy Predictions Mean     438.856\n",
      "trainer/Z Policy Predictions Std      280.985\n",
      "trainer/Z Policy Predictions Max      950.981\n",
      "trainer/Z Policy Predictions Min        3.02179\n",
      "trainer/Z Expert Targets Mean         968.737\n",
      "trainer/Z Expert Targets Std           24.5689\n",
      "trainer/Z Expert Targets Max         1006.75\n",
      "trainer/Z Expert Targets Min          833.36\n",
      "trainer/Z Policy Targets Mean         437.753\n",
      "trainer/Z Policy Targets Std          282.919\n",
      "trainer/Z Policy Targets Max          946.961\n",
      "trainer/Z Policy Targets Min          -18.7742\n",
      "trainer/Log Pis Mean                   49.382\n",
      "trainer/Log Pis Std                    19.7559\n",
      "trainer/Policy mu Mean                  0.333973\n",
      "trainer/Policy mu Std                   2.47898\n",
      "trainer/Policy log std Mean            -1.90474\n",
      "trainer/Policy log std Std              1.10627\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         94792\n",
      "exploration/num paths total          1222\n",
      "evaluation/num steps total         115070\n",
      "evaluation/num paths total            873\n",
      "evaluation/path length Mean           190.3\n",
      "evaluation/path length Std             23.6434\n",
      "evaluation/path length Max            221\n",
      "evaluation/path length Min            155\n",
      "evaluation/Rewards Mean                 5.15911\n",
      "evaluation/Rewards Std                  0.255519\n",
      "evaluation/Rewards Max                  5.88167\n",
      "evaluation/Rewards Min                  3.93566\n",
      "evaluation/Returns Mean               981.778\n",
      "evaluation/Returns Std                119.143\n",
      "evaluation/Returns Max               1163.45\n",
      "evaluation/Returns Min                800.301\n",
      "evaluation/Estimation Bias Mean       601.213\n",
      "evaluation/Estimation Bias Std        344.361\n",
      "evaluation/EB/Q_True Mean              37.1268\n",
      "evaluation/EB/Q_True Std              111.198\n",
      "evaluation/EB/Q_Pred Mean             638.34\n",
      "evaluation/EB/Q_Pred Std              333.005\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            981.778\n",
      "evaluation/Actions Mean                 0.11287\n",
      "evaluation/Actions Std                  0.648495\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84289\n",
      "time/backward_zf1 (s)                   2.23036\n",
      "time/backward_zf2 (s)                   2.16903\n",
      "time/data sampling (s)                  0.336822\n",
      "time/data storing (s)                   0.0147306\n",
      "time/evaluation sampling (s)            0.60322\n",
      "time/exploration sampling (s)           0.512346\n",
      "time/logging (s)                        0.00357953\n",
      "time/preback_alpha (s)                  0.56274\n",
      "time/preback_policy (s)                 1.09503\n",
      "time/preback_start (s)                  0.176759\n",
      "time/preback_zf (s)                     6.59824\n",
      "time/saving (s)                         3.723e-06\n",
      "time/training (s)                       3.22072\n",
      "time/epoch (s)                         19.3665\n",
      "time/total (s)                       1686.9\n",
      "Epoch                                  86\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:53:49.916021 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 87 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                  98000\n",
      "trainer/ZF1 Loss                      108.207\n",
      "trainer/ZF2 Loss                      119.72\n",
      "trainer/ZF Expert Reward               21.1778\n",
      "trainer/ZF Policy Reward               10.1693\n",
      "trainer/ZF CHI2 Term                  124.999\n",
      "trainer/Policy Loss                  -459.94\n",
      "trainer/Bias Loss                      15.6844\n",
      "trainer/Bias Value                     17.0861\n",
      "trainer/Policy Grad Norm               99.955\n",
      "trainer/Policy Param Norm              42.0409\n",
      "trainer/Zf1 Grad Norm                8986.64\n",
      "trainer/Zf1 Param Norm                 91.7961\n",
      "trainer/Zf2 Grad Norm               12393.2\n",
      "trainer/Zf2 Param Norm                 90.3898\n",
      "trainer/Z Expert Predictions Mean    1018.4\n",
      "trainer/Z Expert Predictions Std       26.2113\n",
      "trainer/Z Expert Predictions Max     1057.03\n",
      "trainer/Z Expert Predictions Min      893.52\n",
      "trainer/Z Policy Predictions Mean     451.374\n",
      "trainer/Z Policy Predictions Std      280.088\n",
      "trainer/Z Policy Predictions Max      995.312\n",
      "trainer/Z Policy Predictions Min      -12.4147\n",
      "trainer/Z Expert Targets Mean         997.218\n",
      "trainer/Z Expert Targets Std           26.8634\n",
      "trainer/Z Expert Targets Max         1041.78\n",
      "trainer/Z Expert Targets Min          868.831\n",
      "trainer/Z Policy Targets Mean         441.204\n",
      "trainer/Z Policy Targets Std          276.845\n",
      "trainer/Z Policy Targets Max          991.177\n",
      "trainer/Z Policy Targets Min          -12.7618\n",
      "trainer/Log Pis Mean                   50.8942\n",
      "trainer/Log Pis Std                    18.8873\n",
      "trainer/Policy mu Mean                  0.528642\n",
      "trainer/Policy mu Std                   2.4706\n",
      "trainer/Policy log std Mean            -1.92353\n",
      "trainer/Policy log std Std              1.08517\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         97116\n",
      "exploration/num paths total          1229\n",
      "evaluation/num steps total         118448\n",
      "evaluation/num paths total            883\n",
      "evaluation/path length Mean           337.8\n",
      "evaluation/path length Std             91.4022\n",
      "evaluation/path length Max            534\n",
      "evaluation/path length Min            166\n",
      "evaluation/Rewards Mean                 5.20034\n",
      "evaluation/Rewards Std                  0.207029\n",
      "evaluation/Rewards Max                  6.33157\n",
      "evaluation/Rewards Min                  4.19741\n",
      "evaluation/Returns Mean              1756.68\n",
      "evaluation/Returns Std                491.202\n",
      "evaluation/Returns Max               2834.2\n",
      "evaluation/Returns Min                830.32\n",
      "evaluation/Estimation Bias Mean       704.629\n",
      "evaluation/Estimation Bias Std        367.565\n",
      "evaluation/EB/Q_True Mean              54.1258\n",
      "evaluation/EB/Q_True Std              135.888\n",
      "evaluation/EB/Q_Pred Mean             758.755\n",
      "evaluation/EB/Q_Pred Std              348.726\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1756.68\n",
      "evaluation/Actions Mean                 0.0902071\n",
      "evaluation/Actions Std                  0.630148\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84682\n",
      "time/backward_zf1 (s)                   2.24497\n",
      "time/backward_zf2 (s)                   2.17621\n",
      "time/data sampling (s)                  0.334064\n",
      "time/data storing (s)                   0.0146094\n",
      "time/evaluation sampling (s)            1.70079\n",
      "time/exploration sampling (s)           0.487403\n",
      "time/logging (s)                        0.00533164\n",
      "time/preback_alpha (s)                  0.565365\n",
      "time/preback_policy (s)                 1.11273\n",
      "time/preback_start (s)                  0.176385\n",
      "time/preback_zf (s)                     6.60651\n",
      "time/saving (s)                         3.588e-06\n",
      "time/training (s)                       3.24358\n",
      "time/epoch (s)                         20.5148\n",
      "time/total (s)                       1707.43\n",
      "Epoch                                  87\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:54:11.302329 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 88 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                  99000\n",
      "trainer/ZF1 Loss                      105.716\n",
      "trainer/ZF2 Loss                       89.2342\n",
      "trainer/ZF Expert Reward               19.7424\n",
      "trainer/ZF Policy Reward                5.61828\n",
      "trainer/ZF CHI2 Term                  106.725\n",
      "trainer/Policy Loss                  -457.716\n",
      "trainer/Bias Loss                      13.7461\n",
      "trainer/Bias Value                     17.1578\n",
      "trainer/Policy Grad Norm              152.119\n",
      "trainer/Policy Param Norm              42.2302\n",
      "trainer/Zf1 Grad Norm               14092.8\n",
      "trainer/Zf1 Param Norm                 92.4858\n",
      "trainer/Zf2 Grad Norm                9749.14\n",
      "trainer/Zf2 Param Norm                 91.1029\n",
      "trainer/Z Expert Predictions Mean    1051.27\n",
      "trainer/Z Expert Predictions Std       22.1311\n",
      "trainer/Z Expert Predictions Max     1085.2\n",
      "trainer/Z Expert Predictions Min      958.996\n",
      "trainer/Z Policy Predictions Mean     447.183\n",
      "trainer/Z Policy Predictions Std      309.227\n",
      "trainer/Z Policy Predictions Max     1073.78\n",
      "trainer/Z Policy Predictions Min       -8.87518\n",
      "trainer/Z Expert Targets Mean        1031.53\n",
      "trainer/Z Expert Targets Std           22.5394\n",
      "trainer/Z Expert Targets Max         1064.28\n",
      "trainer/Z Expert Targets Min          933.394\n",
      "trainer/Z Policy Targets Mean         441.565\n",
      "trainer/Z Policy Targets Std          306.875\n",
      "trainer/Z Policy Targets Max         1060.14\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   51.7629\n",
      "trainer/Log Pis Std                    20.2538\n",
      "trainer/Policy mu Mean                  0.501023\n",
      "trainer/Policy mu Std                   2.63605\n",
      "trainer/Policy log std Mean            -1.82128\n",
      "trainer/Policy log std Std              1.2062\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         97116\n",
      "exploration/num paths total          1229\n",
      "evaluation/num steps total         127432\n",
      "evaluation/num paths total            894\n",
      "evaluation/path length Mean           816.727\n",
      "evaluation/path length Std            257.654\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            364\n",
      "evaluation/Rewards Mean                 5.30883\n",
      "evaluation/Rewards Std                  0.12254\n",
      "evaluation/Rewards Max                  6.71986\n",
      "evaluation/Rewards Min                  4.82158\n",
      "evaluation/Returns Mean              4335.86\n",
      "evaluation/Returns Std               1364.73\n",
      "evaluation/Returns Max               5326.5\n",
      "evaluation/Returns Min               1931.67\n",
      "evaluation/Estimation Bias Mean       916.001\n",
      "evaluation/Estimation Bias Std        276.493\n",
      "evaluation/EB/Q_True Mean              53.4474\n",
      "evaluation/EB/Q_True Std              155.05\n",
      "evaluation/EB/Q_Pred Mean             969.449\n",
      "evaluation/EB/Q_Pred Std              189.543\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4335.86\n",
      "evaluation/Actions Mean                 0.0758306\n",
      "evaluation/Actions Std                  0.555272\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93329\n",
      "time/backward_zf1 (s)                   2.3666\n",
      "time/backward_zf2 (s)                   2.292\n",
      "time/data sampling (s)                  0.30794\n",
      "time/data storing (s)                   0.0147631\n",
      "time/evaluation sampling (s)            2.3883\n",
      "time/exploration sampling (s)           0.490164\n",
      "time/logging (s)                        0.0118408\n",
      "time/preback_alpha (s)                  0.569518\n",
      "time/preback_policy (s)                 1.17673\n",
      "time/preback_start (s)                  0.174142\n",
      "time/preback_zf (s)                     6.64462\n",
      "time/saving (s)                         3.136e-06\n",
      "time/training (s)                       2.95877\n",
      "time/epoch (s)                         21.3287\n",
      "time/total (s)                       1728.78\n",
      "Epoch                                  88\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:54:32.888905 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 89 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 100000\n",
      "trainer/ZF1 Loss                      109.025\n",
      "trainer/ZF2 Loss                       93.9744\n",
      "trainer/ZF Expert Reward               19.6214\n",
      "trainer/ZF Policy Reward                8.83294\n",
      "trainer/ZF CHI2 Term                  110.372\n",
      "trainer/Policy Loss                  -493.935\n",
      "trainer/Bias Loss                      12.3566\n",
      "trainer/Bias Value                     17.2273\n",
      "trainer/Policy Grad Norm               97.4524\n",
      "trainer/Policy Param Norm              42.4321\n",
      "trainer/Zf1 Grad Norm               13949\n",
      "trainer/Zf1 Param Norm                 93.1761\n",
      "trainer/Zf2 Grad Norm                8896.3\n",
      "trainer/Zf2 Param Norm                 91.815\n",
      "trainer/Z Expert Predictions Mean    1076.62\n",
      "trainer/Z Expert Predictions Std       37.2777\n",
      "trainer/Z Expert Predictions Max     1115.54\n",
      "trainer/Z Expert Predictions Min      673.929\n",
      "trainer/Z Policy Predictions Mean     483.796\n",
      "trainer/Z Policy Predictions Std      317.415\n",
      "trainer/Z Policy Predictions Max     1071.79\n",
      "trainer/Z Policy Predictions Min       -5.80552\n",
      "trainer/Z Expert Targets Mean        1056.99\n",
      "trainer/Z Expert Targets Std           38.4965\n",
      "trainer/Z Expert Targets Max         1098.33\n",
      "trainer/Z Expert Targets Min          631.229\n",
      "trainer/Z Policy Targets Mean         474.963\n",
      "trainer/Z Policy Targets Std          318.004\n",
      "trainer/Z Policy Targets Max         1048.86\n",
      "trainer/Z Policy Targets Min          -14.0879\n",
      "trainer/Log Pis Mean                   50.5935\n",
      "trainer/Log Pis Std                    20.9456\n",
      "trainer/Policy mu Mean                  0.3205\n",
      "trainer/Policy mu Std                   2.62548\n",
      "trainer/Policy log std Mean            -1.90921\n",
      "trainer/Policy log std Std              1.16028\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         97116\n",
      "exploration/num paths total          1229\n",
      "evaluation/num steps total         137432\n",
      "evaluation/num paths total            904\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.27434\n",
      "evaluation/Rewards Std                  0.0743953\n",
      "evaluation/Rewards Max                  5.45474\n",
      "evaluation/Rewards Min                  4.82653\n",
      "evaluation/Returns Mean              5274.34\n",
      "evaluation/Returns Std                  7.45469\n",
      "evaluation/Returns Max               5284.06\n",
      "evaluation/Returns Min               5261.64\n",
      "evaluation/Estimation Bias Mean      1009.6\n",
      "evaluation/Estimation Bias Std        163.677\n",
      "evaluation/EB/Q_True Mean              47.7144\n",
      "evaluation/EB/Q_True Std              146.956\n",
      "evaluation/EB/Q_Pred Mean            1057.32\n",
      "evaluation/EB/Q_Pred Std               79.1859\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5274.34\n",
      "evaluation/Actions Mean                 0.0751426\n",
      "evaluation/Actions Std                  0.498624\n",
      "evaluation/Actions Max                  0.999978\n",
      "evaluation/Actions Min                 -0.999023\n",
      "time/backward_policy (s)                1.90751\n",
      "time/backward_zf1 (s)                   2.3114\n",
      "time/backward_zf2 (s)                   2.2528\n",
      "time/data sampling (s)                  0.343318\n",
      "time/data storing (s)                   0.0145823\n",
      "time/evaluation sampling (s)            2.52201\n",
      "time/exploration sampling (s)           0.50208\n",
      "time/logging (s)                        0.0129178\n",
      "time/preback_alpha (s)                  0.57184\n",
      "time/preback_policy (s)                 1.15594\n",
      "time/preback_start (s)                  0.172216\n",
      "time/preback_zf (s)                     6.63564\n",
      "time/saving (s)                         2.988e-06\n",
      "time/training (s)                       3.1163\n",
      "time/epoch (s)                         21.5185\n",
      "time/total (s)                       1750.32\n",
      "Epoch                                  89\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:54:54.708019 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 90 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 101000\n",
      "trainer/ZF1 Loss                      105.02\n",
      "trainer/ZF2 Loss                       85.1218\n",
      "trainer/ZF Expert Reward               18.3443\n",
      "trainer/ZF Policy Reward                3.00783\n",
      "trainer/ZF CHI2 Term                  102.391\n",
      "trainer/Policy Loss                  -467.829\n",
      "trainer/Bias Loss                       8.45826\n",
      "trainer/Bias Value                     17.2937\n",
      "trainer/Policy Grad Norm              117.295\n",
      "trainer/Policy Param Norm              42.6408\n",
      "trainer/Zf1 Grad Norm               15836.8\n",
      "trainer/Zf1 Param Norm                 93.8645\n",
      "trainer/Zf2 Grad Norm               11032.7\n",
      "trainer/Zf2 Param Norm                 92.5187\n",
      "trainer/Z Expert Predictions Mean    1103.17\n",
      "trainer/Z Expert Predictions Std       72.19\n",
      "trainer/Z Expert Predictions Max     1142.33\n",
      "trainer/Z Expert Predictions Min       28.2983\n",
      "trainer/Z Policy Predictions Mean     460.196\n",
      "trainer/Z Policy Predictions Std      329.348\n",
      "trainer/Z Policy Predictions Max     1119.38\n",
      "trainer/Z Policy Predictions Min       -0.694627\n",
      "trainer/Z Expert Targets Mean        1084.82\n",
      "trainer/Z Expert Targets Std           72.8199\n",
      "trainer/Z Expert Targets Max         1127.36\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         457.188\n",
      "trainer/Z Policy Targets Std          330.809\n",
      "trainer/Z Policy Targets Max         1105.98\n",
      "trainer/Z Policy Targets Min           -7.76175\n",
      "trainer/Log Pis Mean                   51.511\n",
      "trainer/Log Pis Std                    20.9198\n",
      "trainer/Policy mu Mean                  0.470482\n",
      "trainer/Policy mu Std                   2.70329\n",
      "trainer/Policy log std Mean            -1.77797\n",
      "trainer/Policy log std Std              1.20013\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         97381\n",
      "exploration/num paths total          1230\n",
      "evaluation/num steps total         144241\n",
      "evaluation/num paths total            917\n",
      "evaluation/path length Mean           523.769\n",
      "evaluation/path length Std            346.217\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            141\n",
      "evaluation/Rewards Mean                 5.27532\n",
      "evaluation/Rewards Std                  0.215421\n",
      "evaluation/Rewards Max                  6.396\n",
      "evaluation/Rewards Min                  3.45399\n",
      "evaluation/Returns Mean              2763.05\n",
      "evaluation/Returns Std               1849.35\n",
      "evaluation/Returns Max               5324.18\n",
      "evaluation/Returns Min                764.734\n",
      "evaluation/Estimation Bias Mean       907.63\n",
      "evaluation/Estimation Bias Std        347.199\n",
      "evaluation/EB/Q_True Mean              70.4587\n",
      "evaluation/EB/Q_True Std              174.552\n",
      "evaluation/EB/Q_Pred Mean             978.089\n",
      "evaluation/EB/Q_Pred Std              261.141\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           2763.05\n",
      "evaluation/Actions Mean                 0.0972614\n",
      "evaluation/Actions Std                  0.543614\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92788\n",
      "time/backward_zf1 (s)                   2.32053\n",
      "time/backward_zf2 (s)                   2.26651\n",
      "time/data sampling (s)                  0.340535\n",
      "time/data storing (s)                   0.0158663\n",
      "time/evaluation sampling (s)            2.51246\n",
      "time/exploration sampling (s)           0.500543\n",
      "time/logging (s)                        0.00933432\n",
      "time/preback_alpha (s)                  0.585072\n",
      "time/preback_policy (s)                 1.15041\n",
      "time/preback_start (s)                  0.184671\n",
      "time/preback_zf (s)                     6.71361\n",
      "time/saving (s)                         3.188e-06\n",
      "time/training (s)                       3.20976\n",
      "time/epoch (s)                         21.7372\n",
      "time/total (s)                       1772.09\n",
      "Epoch                                  90\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 20:55:16.044299 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 91 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 102000\n",
      "trainer/ZF1 Loss                      106.353\n",
      "trainer/ZF2 Loss                      117.734\n",
      "trainer/ZF Expert Reward               18.6101\n",
      "trainer/ZF Policy Reward                8.43973\n",
      "trainer/ZF CHI2 Term                  119.286\n",
      "trainer/Policy Loss                  -516.726\n",
      "trainer/Bias Loss                       6.99824\n",
      "trainer/Bias Value                     17.359\n",
      "trainer/Policy Grad Norm              121.691\n",
      "trainer/Policy Param Norm              42.841\n",
      "trainer/Zf1 Grad Norm               13728.6\n",
      "trainer/Zf1 Param Norm                 94.546\n",
      "trainer/Zf2 Grad Norm               12059.7\n",
      "trainer/Zf2 Param Norm                 93.1878\n",
      "trainer/Z Expert Predictions Mean    1138.52\n",
      "trainer/Z Expert Predictions Std       23.5785\n",
      "trainer/Z Expert Predictions Max     1173.17\n",
      "trainer/Z Expert Predictions Min     1058.48\n",
      "trainer/Z Policy Predictions Mean     503.862\n",
      "trainer/Z Policy Predictions Std      357.388\n",
      "trainer/Z Policy Predictions Max     1160.96\n",
      "trainer/Z Policy Predictions Min       -8.20323\n",
      "trainer/Z Expert Targets Mean        1119.91\n",
      "trainer/Z Expert Targets Std           24.0936\n",
      "trainer/Z Expert Targets Max         1157.55\n",
      "trainer/Z Expert Targets Min         1032.56\n",
      "trainer/Z Policy Targets Mean         495.422\n",
      "trainer/Z Policy Targets Std          356.475\n",
      "trainer/Z Policy Targets Max         1140.63\n",
      "trainer/Z Policy Targets Min           -1.97304\n",
      "trainer/Log Pis Mean                   53.6612\n",
      "trainer/Log Pis Std                    21.9322\n",
      "trainer/Policy mu Mean                  0.585009\n",
      "trainer/Policy mu Std                   2.76736\n",
      "trainer/Policy log std Mean            -1.89383\n",
      "trainer/Policy log std Std              1.15929\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         97381\n",
      "exploration/num paths total          1230\n",
      "evaluation/num steps total         153259\n",
      "evaluation/num paths total            927\n",
      "evaluation/path length Mean           901.8\n",
      "evaluation/path length Std            162.61\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            518\n",
      "evaluation/Rewards Mean                 5.31941\n",
      "evaluation/Rewards Std                  0.143632\n",
      "evaluation/Rewards Max                  6.48636\n",
      "evaluation/Rewards Min                  3.08804\n",
      "evaluation/Returns Mean              4797.05\n",
      "evaluation/Returns Std                875.29\n",
      "evaluation/Returns Max               5355.86\n",
      "evaluation/Returns Min               2771.34\n",
      "evaluation/Estimation Bias Mean      1021.42\n",
      "evaluation/Estimation Bias Std        251.754\n",
      "evaluation/EB/Q_True Mean              53.6257\n",
      "evaluation/EB/Q_True Std              156.039\n",
      "evaluation/EB/Q_Pred Mean            1075.05\n",
      "evaluation/EB/Q_Pred Std              178.089\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4797.05\n",
      "evaluation/Actions Mean                 0.0790113\n",
      "evaluation/Actions Std                  0.534221\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90988\n",
      "time/backward_zf1 (s)                   2.3139\n",
      "time/backward_zf2 (s)                   2.2452\n",
      "time/data sampling (s)                  0.349735\n",
      "time/data storing (s)                   0.0150224\n",
      "time/evaluation sampling (s)            2.40382\n",
      "time/exploration sampling (s)           0.489316\n",
      "time/logging (s)                        0.0119672\n",
      "time/preback_alpha (s)                  0.571453\n",
      "time/preback_policy (s)                 1.16411\n",
      "time/preback_start (s)                  0.172692\n",
      "time/preback_zf (s)                     6.6057\n",
      "time/saving (s)                         3.856e-06\n",
      "time/training (s)                       3.01949\n",
      "time/epoch (s)                         21.2723\n",
      "time/total (s)                       1793.38\n",
      "Epoch                                  91\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:55:37.627227 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 92 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 103000\n",
      "trainer/ZF1 Loss                      114.409\n",
      "trainer/ZF2 Loss                      106.337\n",
      "trainer/ZF Expert Reward               17.28\n",
      "trainer/ZF Policy Reward                4.85758\n",
      "trainer/ZF CHI2 Term                  116.046\n",
      "trainer/Policy Loss                  -550.703\n",
      "trainer/Bias Loss                      15.4267\n",
      "trainer/Bias Value                     17.4219\n",
      "trainer/Policy Grad Norm              111.745\n",
      "trainer/Policy Param Norm              43.0451\n",
      "trainer/Zf1 Grad Norm               17859.9\n",
      "trainer/Zf1 Param Norm                 95.1831\n",
      "trainer/Zf2 Grad Norm               16847.6\n",
      "trainer/Zf2 Param Norm                 93.8178\n",
      "trainer/Z Expert Predictions Mean    1161.8\n",
      "trainer/Z Expert Predictions Std       43.6923\n",
      "trainer/Z Expert Predictions Max     1201.98\n",
      "trainer/Z Expert Predictions Min      618.423\n",
      "trainer/Z Policy Predictions Mean     534.531\n",
      "trainer/Z Policy Predictions Std      354.155\n",
      "trainer/Z Policy Predictions Max     1164.63\n",
      "trainer/Z Policy Predictions Min        6.4914\n",
      "trainer/Z Expert Targets Mean        1144.52\n",
      "trainer/Z Expert Targets Std           41.2984\n",
      "trainer/Z Expert Targets Max         1181.76\n",
      "trainer/Z Expert Targets Min          651.134\n",
      "trainer/Z Policy Targets Mean         529.674\n",
      "trainer/Z Policy Targets Std          353.665\n",
      "trainer/Z Policy Targets Max         1156.02\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   53.8174\n",
      "trainer/Log Pis Std                    20.4311\n",
      "trainer/Policy mu Mean                  0.57046\n",
      "trainer/Policy mu Std                   2.62548\n",
      "trainer/Policy log std Mean            -2.03118\n",
      "trainer/Policy log std Std              1.09051\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         97853\n",
      "exploration/num paths total          1231\n",
      "evaluation/num steps total         163259\n",
      "evaluation/num paths total            937\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.25792\n",
      "evaluation/Rewards Std                  0.0690018\n",
      "evaluation/Rewards Max                  5.43738\n",
      "evaluation/Rewards Min                  4.84979\n",
      "evaluation/Returns Mean              5257.92\n",
      "evaluation/Returns Std                  7.57414\n",
      "evaluation/Returns Max               5271.06\n",
      "evaluation/Returns Min               5248.28\n",
      "evaluation/Estimation Bias Mean      1084.86\n",
      "evaluation/Estimation Bias Std        158.989\n",
      "evaluation/EB/Q_True Mean              47.5331\n",
      "evaluation/EB/Q_True Std              146.389\n",
      "evaluation/EB/Q_Pred Mean            1132.39\n",
      "evaluation/EB/Q_Pred Std               65.3278\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5257.92\n",
      "evaluation/Actions Mean                 0.0774365\n",
      "evaluation/Actions Std                  0.528253\n",
      "evaluation/Actions Max                  0.999925\n",
      "evaluation/Actions Min                 -0.999476\n",
      "time/backward_policy (s)                1.93847\n",
      "time/backward_zf1 (s)                   2.34822\n",
      "time/backward_zf2 (s)                   2.29556\n",
      "time/data sampling (s)                  0.355094\n",
      "time/data storing (s)                   0.015441\n",
      "time/evaluation sampling (s)            2.46847\n",
      "time/exploration sampling (s)           0.503592\n",
      "time/logging (s)                        0.0130642\n",
      "time/preback_alpha (s)                  0.574314\n",
      "time/preback_policy (s)                 1.18136\n",
      "time/preback_start (s)                  0.174494\n",
      "time/preback_zf (s)                     6.64739\n",
      "time/saving (s)                         2.894e-06\n",
      "time/training (s)                       3.00201\n",
      "time/epoch (s)                         21.5175\n",
      "time/total (s)                       1814.92\n",
      "Epoch                                  92\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:55:59.017779 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 93 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 104000\n",
      "trainer/ZF1 Loss                      106.215\n",
      "trainer/ZF2 Loss                      101.021\n",
      "trainer/ZF Expert Reward               17.7836\n",
      "trainer/ZF Policy Reward                4.53444\n",
      "trainer/ZF CHI2 Term                  109.505\n",
      "trainer/Policy Loss                  -533.096\n",
      "trainer/Bias Loss                       9.31145\n",
      "trainer/Bias Value                     17.483\n",
      "trainer/Policy Grad Norm              118.329\n",
      "trainer/Policy Param Norm              43.2382\n",
      "trainer/Zf1 Grad Norm               16094.1\n",
      "trainer/Zf1 Param Norm                 95.8324\n",
      "trainer/Zf2 Grad Norm               12817.3\n",
      "trainer/Zf2 Param Norm                 94.4842\n",
      "trainer/Z Expert Predictions Mean    1191.97\n",
      "trainer/Z Expert Predictions Std       28.6348\n",
      "trainer/Z Expert Predictions Max     1229.59\n",
      "trainer/Z Expert Predictions Min     1041.79\n",
      "trainer/Z Policy Predictions Mean     516.281\n",
      "trainer/Z Policy Predictions Std      361.015\n",
      "trainer/Z Policy Predictions Max     1180.44\n",
      "trainer/Z Policy Predictions Min        2.76501\n",
      "trainer/Z Expert Targets Mean        1174.19\n",
      "trainer/Z Expert Targets Std           28.5118\n",
      "trainer/Z Expert Targets Max         1212.56\n",
      "trainer/Z Expert Targets Min         1011.42\n",
      "trainer/Z Policy Targets Mean         511.747\n",
      "trainer/Z Policy Targets Std          362.355\n",
      "trainer/Z Policy Targets Max         1173.37\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   53.5039\n",
      "trainer/Log Pis Std                    20.123\n",
      "trainer/Policy mu Mean                  0.36581\n",
      "trainer/Policy mu Std                   2.74209\n",
      "trainer/Policy log std Mean            -1.89161\n",
      "trainer/Policy log std Std              1.13629\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         98166\n",
      "exploration/num paths total          1232\n",
      "evaluation/num steps total         171758\n",
      "evaluation/num paths total            947\n",
      "evaluation/path length Mean           849.9\n",
      "evaluation/path length Std            303.269\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            123\n",
      "evaluation/Rewards Mean                 5.25486\n",
      "evaluation/Rewards Std                  0.1395\n",
      "evaluation/Rewards Max                  5.97743\n",
      "evaluation/Rewards Min                  3.38343\n",
      "evaluation/Returns Mean              4466.11\n",
      "evaluation/Returns Std               1605.78\n",
      "evaluation/Returns Max               5283.94\n",
      "evaluation/Returns Min                604.293\n",
      "evaluation/Estimation Bias Mean      1062.35\n",
      "evaluation/Estimation Bias Std        271.2\n",
      "evaluation/EB/Q_True Mean              56.0804\n",
      "evaluation/EB/Q_True Std              157.763\n",
      "evaluation/EB/Q_Pred Mean            1118.43\n",
      "evaluation/EB/Q_Pred Std              179.914\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4466.11\n",
      "evaluation/Actions Mean                 0.0905259\n",
      "evaluation/Actions Std                  0.525462\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.70814\n",
      "time/backward_zf1 (s)                   2.1547\n",
      "time/backward_zf2 (s)                   2.0218\n",
      "time/data sampling (s)                  0.334881\n",
      "time/data storing (s)                   0.0149048\n",
      "time/evaluation sampling (s)            2.45345\n",
      "time/exploration sampling (s)           0.47937\n",
      "time/logging (s)                        0.0115602\n",
      "time/preback_alpha (s)                  0.570113\n",
      "time/preback_policy (s)                 0.93852\n",
      "time/preback_start (s)                  0.171735\n",
      "time/preback_zf (s)                     6.65135\n",
      "time/saving (s)                         2.816e-06\n",
      "time/training (s)                       3.81036\n",
      "time/epoch (s)                         21.3209\n",
      "time/total (s)                       1836.26\n",
      "Epoch                                  93\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:56:20.294759 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 94 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 105000\n",
      "trainer/ZF1 Loss                      111.232\n",
      "trainer/ZF2 Loss                      101.694\n",
      "trainer/ZF Expert Reward               16.4286\n",
      "trainer/ZF Policy Reward                2.10647\n",
      "trainer/ZF CHI2 Term                  110.742\n",
      "trainer/Policy Loss                  -575.157\n",
      "trainer/Bias Loss                      10.4306\n",
      "trainer/Bias Value                     17.5414\n",
      "trainer/Policy Grad Norm              118.276\n",
      "trainer/Policy Param Norm              43.453\n",
      "trainer/Zf1 Grad Norm               23509.2\n",
      "trainer/Zf1 Param Norm                 96.4654\n",
      "trainer/Zf2 Grad Norm               11449.6\n",
      "trainer/Zf2 Param Norm                 95.1272\n",
      "trainer/Z Expert Predictions Mean    1213.91\n",
      "trainer/Z Expert Predictions Std       77.9538\n",
      "trainer/Z Expert Predictions Max     1258.87\n",
      "trainer/Z Expert Predictions Min       46.1083\n",
      "trainer/Z Policy Predictions Mean     563.697\n",
      "trainer/Z Policy Predictions Std      385.492\n",
      "trainer/Z Policy Predictions Max     1206.67\n",
      "trainer/Z Policy Predictions Min        6.96735\n",
      "trainer/Z Expert Targets Mean        1197.48\n",
      "trainer/Z Expert Targets Std           79.5289\n",
      "trainer/Z Expert Targets Max         1242.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         561.59\n",
      "trainer/Z Policy Targets Std          386.068\n",
      "trainer/Z Policy Targets Max         1203.41\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   53.5734\n",
      "trainer/Log Pis Std                    18.1011\n",
      "trainer/Policy mu Mean                  0.465144\n",
      "trainer/Policy mu Std                   2.58717\n",
      "trainer/Policy log std Mean            -2.05184\n",
      "trainer/Policy log std Std              1.18569\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         98166\n",
      "exploration/num paths total          1232\n",
      "evaluation/num steps total         179791\n",
      "evaluation/num paths total            957\n",
      "evaluation/path length Mean           803.3\n",
      "evaluation/path length Std            323.267\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            140\n",
      "evaluation/Rewards Mean                 5.23721\n",
      "evaluation/Rewards Std                  0.15174\n",
      "evaluation/Rewards Max                  6.44626\n",
      "evaluation/Rewards Min                  3.80857\n",
      "evaluation/Returns Mean              4207.05\n",
      "evaluation/Returns Std               1720.14\n",
      "evaluation/Returns Max               5268.23\n",
      "evaluation/Returns Min                664.43\n",
      "evaluation/Estimation Bias Mean      1093.35\n",
      "evaluation/Estimation Bias Std        292.289\n",
      "evaluation/EB/Q_True Mean              59.2304\n",
      "evaluation/EB/Q_True Std              161.39\n",
      "evaluation/EB/Q_Pred Mean            1152.58\n",
      "evaluation/EB/Q_Pred Std              191.253\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4207.05\n",
      "evaluation/Actions Mean                 0.0856168\n",
      "evaluation/Actions Std                  0.543144\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86271\n",
      "time/backward_zf1 (s)                   2.31095\n",
      "time/backward_zf2 (s)                   2.22867\n",
      "time/data sampling (s)                  0.360712\n",
      "time/data storing (s)                   0.014491\n",
      "time/evaluation sampling (s)            2.19004\n",
      "time/exploration sampling (s)           0.482938\n",
      "time/logging (s)                        0.0107647\n",
      "time/preback_alpha (s)                  0.577113\n",
      "time/preback_policy (s)                 1.12924\n",
      "time/preback_start (s)                  0.174315\n",
      "time/preback_zf (s)                     6.66375\n",
      "time/saving (s)                         3.182e-06\n",
      "time/training (s)                       3.20443\n",
      "time/epoch (s)                         21.2101\n",
      "time/total (s)                       1857.49\n",
      "Epoch                                  94\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:56:41.507615 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 95 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 106000\n",
      "trainer/ZF1 Loss                      134.591\n",
      "trainer/ZF2 Loss                      123.653\n",
      "trainer/ZF Expert Reward               20.7112\n",
      "trainer/ZF Policy Reward                8.52614\n",
      "trainer/ZF CHI2 Term                  137.341\n",
      "trainer/Policy Loss                  -611.44\n",
      "trainer/Bias Loss                      14.35\n",
      "trainer/Bias Value                     17.5981\n",
      "trainer/Policy Grad Norm              134.22\n",
      "trainer/Policy Param Norm              43.6367\n",
      "trainer/Zf1 Grad Norm               19147.7\n",
      "trainer/Zf1 Param Norm                 97.0802\n",
      "trainer/Zf2 Grad Norm               14756.6\n",
      "trainer/Zf2 Param Norm                 95.7528\n",
      "trainer/Z Expert Predictions Mean    1251.7\n",
      "trainer/Z Expert Predictions Std       21.3822\n",
      "trainer/Z Expert Predictions Max     1287.33\n",
      "trainer/Z Expert Predictions Min     1176.77\n",
      "trainer/Z Policy Predictions Mean     595.77\n",
      "trainer/Z Policy Predictions Std      401.451\n",
      "trainer/Z Policy Predictions Max     1232.19\n",
      "trainer/Z Policy Predictions Min       -0.440399\n",
      "trainer/Z Expert Targets Mean        1230.99\n",
      "trainer/Z Expert Targets Std           22.8837\n",
      "trainer/Z Expert Targets Max         1266.43\n",
      "trainer/Z Expert Targets Min         1157.4\n",
      "trainer/Z Policy Targets Mean         587.244\n",
      "trainer/Z Policy Targets Std          398.333\n",
      "trainer/Z Policy Targets Max         1224.4\n",
      "trainer/Z Policy Targets Min          -17.405\n",
      "trainer/Log Pis Mean                   53.1346\n",
      "trainer/Log Pis Std                    20.184\n",
      "trainer/Policy mu Mean                  0.461181\n",
      "trainer/Policy mu Std                   2.5637\n",
      "trainer/Policy log std Mean            -2.05436\n",
      "trainer/Policy log std Std              1.18433\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total         98166\n",
      "exploration/num paths total          1232\n",
      "evaluation/num steps total         187675\n",
      "evaluation/num paths total            967\n",
      "evaluation/path length Mean           788.4\n",
      "evaluation/path length Std            269.229\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            319\n",
      "evaluation/Rewards Mean                 5.23779\n",
      "evaluation/Rewards Std                  0.167458\n",
      "evaluation/Rewards Max                  6.14126\n",
      "evaluation/Rewards Min                  3.81642\n",
      "evaluation/Returns Mean              4129.47\n",
      "evaluation/Returns Std               1437.09\n",
      "evaluation/Returns Max               5274.49\n",
      "evaluation/Returns Min               1650.18\n",
      "evaluation/Estimation Bias Mean      1076.44\n",
      "evaluation/Estimation Bias Std        316.588\n",
      "evaluation/EB/Q_True Mean              60.3051\n",
      "evaluation/EB/Q_True Std              162.529\n",
      "evaluation/EB/Q_Pred Mean            1136.75\n",
      "evaluation/EB/Q_Pred Std              229.985\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4129.47\n",
      "evaluation/Actions Mean                 0.112146\n",
      "evaluation/Actions Std                  0.554827\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.69044\n",
      "time/backward_zf1 (s)                   2.12114\n",
      "time/backward_zf2 (s)                   2.02764\n",
      "time/data sampling (s)                  0.359417\n",
      "time/data storing (s)                   0.0140753\n",
      "time/evaluation sampling (s)            2.26576\n",
      "time/exploration sampling (s)           0.469152\n",
      "time/logging (s)                        0.011465\n",
      "time/preback_alpha (s)                  0.57007\n",
      "time/preback_policy (s)                 0.924646\n",
      "time/preback_start (s)                  0.1735\n",
      "time/preback_zf (s)                     6.66447\n",
      "time/saving (s)                         3.525e-06\n",
      "time/training (s)                       3.8546\n",
      "time/epoch (s)                         21.1464\n",
      "time/total (s)                       1878.66\n",
      "Epoch                                  95\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:57:03.278355 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 96 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 107000\n",
      "trainer/ZF1 Loss                      164.039\n",
      "trainer/ZF2 Loss                      167.409\n",
      "trainer/ZF Expert Reward               19.2979\n",
      "trainer/ZF Policy Reward                9.11002\n",
      "trainer/ZF CHI2 Term                  172.313\n",
      "trainer/Policy Loss                  -619.948\n",
      "trainer/Bias Loss                      12.0938\n",
      "trainer/Bias Value                     17.6527\n",
      "trainer/Policy Grad Norm              131.069\n",
      "trainer/Policy Param Norm              43.8206\n",
      "trainer/Zf1 Grad Norm               19406.6\n",
      "trainer/Zf1 Param Norm                 97.7078\n",
      "trainer/Zf2 Grad Norm               19391.4\n",
      "trainer/Zf2 Param Norm                 96.3557\n",
      "trainer/Z Expert Predictions Mean    1270.26\n",
      "trainer/Z Expert Predictions Std       80.0774\n",
      "trainer/Z Expert Predictions Max     1309.98\n",
      "trainer/Z Expert Predictions Min       29.9337\n",
      "trainer/Z Policy Predictions Mean     612.325\n",
      "trainer/Z Policy Predictions Std      423.421\n",
      "trainer/Z Policy Predictions Max     1273.85\n",
      "trainer/Z Policy Predictions Min       -4.75249\n",
      "trainer/Z Expert Targets Mean        1250.96\n",
      "trainer/Z Expert Targets Std           81.1095\n",
      "trainer/Z Expert Targets Max         1288.89\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         603.215\n",
      "trainer/Z Policy Targets Std          421.473\n",
      "trainer/Z Policy Targets Max         1264.43\n",
      "trainer/Z Policy Targets Min           -1.53937\n",
      "trainer/Log Pis Mean                   53.3736\n",
      "trainer/Log Pis Std                    18.2888\n",
      "trainer/Policy mu Mean                  0.551648\n",
      "trainer/Policy mu Std                   2.64593\n",
      "trainer/Policy log std Mean            -2.04342\n",
      "trainer/Policy log std Std              1.24065\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        101166\n",
      "exploration/num paths total          1235\n",
      "evaluation/num steps total         194512\n",
      "evaluation/num paths total            978\n",
      "evaluation/path length Mean           621.545\n",
      "evaluation/path length Std            343.457\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            134\n",
      "evaluation/Rewards Mean                 5.26526\n",
      "evaluation/Rewards Std                  0.187877\n",
      "evaluation/Rewards Max                  6.49361\n",
      "evaluation/Rewards Min                  3.49331\n",
      "evaluation/Returns Mean              3272.6\n",
      "evaluation/Returns Std               1846.79\n",
      "evaluation/Returns Max               5315.04\n",
      "evaluation/Returns Min                630.654\n",
      "evaluation/Estimation Bias Mean      1066.48\n",
      "evaluation/Estimation Bias Std        413.105\n",
      "evaluation/EB/Q_True Mean              69.6768\n",
      "evaluation/EB/Q_True Std              173.005\n",
      "evaluation/EB/Q_Pred Mean            1136.16\n",
      "evaluation/EB/Q_Pred Std              291.324\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3272.6\n",
      "evaluation/Actions Mean                 0.0888819\n",
      "evaluation/Actions Std                  0.550663\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.01484\n",
      "time/backward_zf1 (s)                   2.43712\n",
      "time/backward_zf2 (s)                   2.41499\n",
      "time/data sampling (s)                  0.378422\n",
      "time/data storing (s)                   0.0149749\n",
      "time/evaluation sampling (s)            2.29685\n",
      "time/exploration sampling (s)           0.487426\n",
      "time/logging (s)                        0.0102136\n",
      "time/preback_alpha (s)                  0.58298\n",
      "time/preback_policy (s)                 1.226\n",
      "time/preback_start (s)                  0.176268\n",
      "time/preback_zf (s)                     6.66733\n",
      "time/saving (s)                         3.384e-06\n",
      "time/training (s)                       2.98987\n",
      "time/epoch (s)                         21.6973\n",
      "time/total (s)                       1900.39\n",
      "Epoch                                  96\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:57:24.770115 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 97 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 108000\n",
      "trainer/ZF1 Loss                      118.951\n",
      "trainer/ZF2 Loss                      131.356\n",
      "trainer/ZF Expert Reward               16.5634\n",
      "trainer/ZF Policy Reward                6.32314\n",
      "trainer/ZF CHI2 Term                  128.77\n",
      "trainer/Policy Loss                  -616.089\n",
      "trainer/Bias Loss                      12.5052\n",
      "trainer/Bias Value                     17.7049\n",
      "trainer/Policy Grad Norm              119.172\n",
      "trainer/Policy Param Norm              43.9913\n",
      "trainer/Zf1 Grad Norm               14633.2\n",
      "trainer/Zf1 Param Norm                 98.2878\n",
      "trainer/Zf2 Grad Norm               15097.4\n",
      "trainer/Zf2 Param Norm                 96.9576\n",
      "trainer/Z Expert Predictions Mean    1293.43\n",
      "trainer/Z Expert Predictions Std       44.5189\n",
      "trainer/Z Expert Predictions Max     1332.8\n",
      "trainer/Z Expert Predictions Min      699.002\n",
      "trainer/Z Policy Predictions Mean     600.332\n",
      "trainer/Z Policy Predictions Std      433.148\n",
      "trainer/Z Policy Predictions Max     1298.21\n",
      "trainer/Z Policy Predictions Min       -4.13661\n",
      "trainer/Z Expert Targets Mean        1276.86\n",
      "trainer/Z Expert Targets Std           42.9531\n",
      "trainer/Z Expert Targets Max         1315.21\n",
      "trainer/Z Expert Targets Min          698.175\n",
      "trainer/Z Policy Targets Mean         594.008\n",
      "trainer/Z Policy Targets Std          433.012\n",
      "trainer/Z Policy Targets Max         1292.1\n",
      "trainer/Z Policy Targets Min           -4.77634\n",
      "trainer/Log Pis Mean                   55.8623\n",
      "trainer/Log Pis Std                    21.6739\n",
      "trainer/Policy mu Mean                  0.415037\n",
      "trainer/Policy mu Std                   2.85249\n",
      "trainer/Policy log std Mean            -1.99886\n",
      "trainer/Policy log std Std              1.15846\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        106166\n",
      "exploration/num paths total          1240\n",
      "evaluation/num steps total         201910\n",
      "evaluation/num paths total            989\n",
      "evaluation/path length Mean           672.545\n",
      "evaluation/path length Std            307.16\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            175\n",
      "evaluation/Rewards Mean                 5.2948\n",
      "evaluation/Rewards Std                  0.229442\n",
      "evaluation/Rewards Max                  6.24412\n",
      "evaluation/Rewards Min                  3.47619\n",
      "evaluation/Returns Mean              3560.99\n",
      "evaluation/Returns Std               1663.13\n",
      "evaluation/Returns Max               5367.62\n",
      "evaluation/Returns Min                923.601\n",
      "evaluation/Estimation Bias Mean      1072.45\n",
      "evaluation/Estimation Bias Std        382.417\n",
      "evaluation/EB/Q_True Mean              65.2821\n",
      "evaluation/EB/Q_True Std              169.688\n",
      "evaluation/EB/Q_Pred Mean            1137.73\n",
      "evaluation/EB/Q_Pred Std              312.955\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3560.99\n",
      "evaluation/Actions Mean                 0.0976654\n",
      "evaluation/Actions Std                  0.562796\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72111\n",
      "time/backward_zf1 (s)                   2.14432\n",
      "time/backward_zf2 (s)                   2.05323\n",
      "time/data sampling (s)                  0.355857\n",
      "time/data storing (s)                   0.0143448\n",
      "time/evaluation sampling (s)            2.47031\n",
      "time/exploration sampling (s)           0.485277\n",
      "time/logging (s)                        0.0101199\n",
      "time/preback_alpha (s)                  0.57293\n",
      "time/preback_policy (s)                 0.978139\n",
      "time/preback_start (s)                  0.172069\n",
      "time/preback_zf (s)                     6.67218\n",
      "time/saving (s)                         3.079e-06\n",
      "time/training (s)                       3.77368\n",
      "time/epoch (s)                         21.4236\n",
      "time/total (s)                       1921.83\n",
      "Epoch                                  97\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:57:46.231866 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 98 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 109000\n",
      "trainer/ZF1 Loss                      170.931\n",
      "trainer/ZF2 Loss                      175.765\n",
      "trainer/ZF Expert Reward               17.0493\n",
      "trainer/ZF Policy Reward                7.85165\n",
      "trainer/ZF CHI2 Term                  177.28\n",
      "trainer/Policy Loss                  -651.024\n",
      "trainer/Bias Loss                      10.8304\n",
      "trainer/Bias Value                     17.7511\n",
      "trainer/Policy Grad Norm              140.384\n",
      "trainer/Policy Param Norm              44.1629\n",
      "trainer/Zf1 Grad Norm               26380\n",
      "trainer/Zf1 Param Norm                 98.8793\n",
      "trainer/Zf2 Grad Norm               21126.4\n",
      "trainer/Zf2 Param Norm                 97.5631\n",
      "trainer/Z Expert Predictions Mean    1308.69\n",
      "trainer/Z Expert Predictions Std      114.845\n",
      "trainer/Z Expert Predictions Max     1353.93\n",
      "trainer/Z Expert Predictions Min       36.067\n",
      "trainer/Z Policy Predictions Mean     640.691\n",
      "trainer/Z Policy Predictions Std      426.588\n",
      "trainer/Z Policy Predictions Max     1330.81\n",
      "trainer/Z Policy Predictions Min        3.29797\n",
      "trainer/Z Expert Targets Mean        1291.64\n",
      "trainer/Z Expert Targets Std          116.835\n",
      "trainer/Z Expert Targets Max         1339.51\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         632.84\n",
      "trainer/Z Policy Targets Std          427.928\n",
      "trainer/Z Policy Targets Max         1322.08\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   55.0518\n",
      "trainer/Log Pis Std                    21.9529\n",
      "trainer/Policy mu Mean                  0.452562\n",
      "trainer/Policy mu Std                   2.90151\n",
      "trainer/Policy log std Mean            -2.08155\n",
      "trainer/Policy log std Std              1.18823\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        106297\n",
      "exploration/num paths total          1241\n",
      "evaluation/num steps total         210945\n",
      "evaluation/num paths total            999\n",
      "evaluation/path length Mean           903.5\n",
      "evaluation/path length Std            173.158\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            519\n",
      "evaluation/Rewards Mean                 5.29779\n",
      "evaluation/Rewards Std                  0.137673\n",
      "evaluation/Rewards Max                  6.11004\n",
      "evaluation/Rewards Min                  4.1997\n",
      "evaluation/Returns Mean              4786.56\n",
      "evaluation/Returns Std                913.971\n",
      "evaluation/Returns Max               5322.49\n",
      "evaluation/Returns Min               2757.02\n",
      "evaluation/Estimation Bias Mean      1138.81\n",
      "evaluation/Estimation Bias Std        281.183\n",
      "evaluation/EB/Q_True Mean              53.1633\n",
      "evaluation/EB/Q_True Std              154.795\n",
      "evaluation/EB/Q_Pred Mean            1191.97\n",
      "evaluation/EB/Q_Pred Std              221.126\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4786.56\n",
      "evaluation/Actions Mean                 0.0961728\n",
      "evaluation/Actions Std                  0.559896\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79454\n",
      "time/backward_zf1 (s)                   2.22964\n",
      "time/backward_zf2 (s)                   2.14451\n",
      "time/data sampling (s)                  0.349271\n",
      "time/data storing (s)                   0.0149924\n",
      "time/evaluation sampling (s)            2.40074\n",
      "time/exploration sampling (s)           0.481986\n",
      "time/logging (s)                        0.0120538\n",
      "time/preback_alpha (s)                  0.573627\n",
      "time/preback_policy (s)                 1.0435\n",
      "time/preback_start (s)                  0.173757\n",
      "time/preback_zf (s)                     6.66165\n",
      "time/saving (s)                         3.089e-06\n",
      "time/training (s)                       3.51522\n",
      "time/epoch (s)                         21.3955\n",
      "time/total (s)                       1943.25\n",
      "Epoch                                  98\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:58:07.956629 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 99 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 110000\n",
      "trainer/ZF1 Loss                      128.402\n",
      "trainer/ZF2 Loss                      164.189\n",
      "trainer/ZF Expert Reward               16.6988\n",
      "trainer/ZF Policy Reward                4.71289\n",
      "trainer/ZF CHI2 Term                  149.596\n",
      "trainer/Policy Loss                  -645.056\n",
      "trainer/Bias Loss                      13.1355\n",
      "trainer/Bias Value                     17.7909\n",
      "trainer/Policy Grad Norm              142.245\n",
      "trainer/Policy Param Norm              44.3284\n",
      "trainer/Zf1 Grad Norm               11452.1\n",
      "trainer/Zf1 Param Norm                 99.501\n",
      "trainer/Zf2 Grad Norm               15187.5\n",
      "trainer/Zf2 Param Norm                 98.1592\n",
      "trainer/Z Expert Predictions Mean    1338.65\n",
      "trainer/Z Expert Predictions Std       84.162\n",
      "trainer/Z Expert Predictions Max     1381.7\n",
      "trainer/Z Expert Predictions Min       43.7419\n",
      "trainer/Z Policy Predictions Mean     634.736\n",
      "trainer/Z Policy Predictions Std      441.951\n",
      "trainer/Z Policy Predictions Max     1348.64\n",
      "trainer/Z Policy Predictions Min        1.01062\n",
      "trainer/Z Expert Targets Mean        1321.96\n",
      "trainer/Z Expert Targets Std           85.8506\n",
      "trainer/Z Expert Targets Max         1366.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         630.023\n",
      "trainer/Z Policy Targets Std          442.268\n",
      "trainer/Z Policy Targets Max         1322.65\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   57.9708\n",
      "trainer/Log Pis Std                    23.1988\n",
      "trainer/Policy mu Mean                  0.489365\n",
      "trainer/Policy mu Std                   3.00982\n",
      "trainer/Policy log std Mean            -1.97601\n",
      "trainer/Policy log std Std              1.24524\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        106980\n",
      "exploration/num paths total          1242\n",
      "evaluation/num steps total         220307\n",
      "evaluation/num paths total           1009\n",
      "evaluation/path length Mean           936.2\n",
      "evaluation/path length Std            191.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            362\n",
      "evaluation/Rewards Mean                 5.30868\n",
      "evaluation/Rewards Std                  0.106475\n",
      "evaluation/Rewards Max                  5.52722\n",
      "evaluation/Rewards Min                  4.31126\n",
      "evaluation/Returns Mean              4969.99\n",
      "evaluation/Returns Std               1040.13\n",
      "evaluation/Returns Max               5335.18\n",
      "evaluation/Returns Min               1849.69\n",
      "evaluation/Estimation Bias Mean      1272.66\n",
      "evaluation/Estimation Bias Std        229.822\n",
      "evaluation/EB/Q_True Mean              51.3481\n",
      "evaluation/EB/Q_True Std              152.547\n",
      "evaluation/EB/Q_Pred Mean            1324.01\n",
      "evaluation/EB/Q_Pred Std              128.007\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4969.99\n",
      "evaluation/Actions Mean                 0.0708742\n",
      "evaluation/Actions Std                  0.505634\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92597\n",
      "time/backward_zf1 (s)                   2.3458\n",
      "time/backward_zf2 (s)                   2.2895\n",
      "time/data sampling (s)                  0.361482\n",
      "time/data storing (s)                   0.0146378\n",
      "time/evaluation sampling (s)            2.49595\n",
      "time/exploration sampling (s)           0.4844\n",
      "time/logging (s)                        0.0128855\n",
      "time/preback_alpha (s)                  0.577049\n",
      "time/preback_policy (s)                 1.17276\n",
      "time/preback_start (s)                  0.176738\n",
      "time/preback_zf (s)                     6.66673\n",
      "time/saving (s)                         3.339e-06\n",
      "time/training (s)                       3.13108\n",
      "time/epoch (s)                         21.655\n",
      "time/total (s)                       1964.93\n",
      "Epoch                                  99\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:58:29.466174 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 100 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 111000\n",
      "trainer/ZF1 Loss                      198.439\n",
      "trainer/ZF2 Loss                      209.097\n",
      "trainer/ZF Expert Reward               18.9677\n",
      "trainer/ZF Policy Reward                6.83482\n",
      "trainer/ZF CHI2 Term                  209.064\n",
      "trainer/Policy Loss                  -745.327\n",
      "trainer/Bias Loss                      10.8541\n",
      "trainer/Bias Value                     17.8263\n",
      "trainer/Policy Grad Norm              153.043\n",
      "trainer/Policy Param Norm              44.4867\n",
      "trainer/Zf1 Grad Norm               31323.5\n",
      "trainer/Zf1 Param Norm                100.058\n",
      "trainer/Zf2 Grad Norm               20840.4\n",
      "trainer/Zf2 Param Norm                 98.7233\n",
      "trainer/Z Expert Predictions Mean    1368.51\n",
      "trainer/Z Expert Predictions Std       25.6279\n",
      "trainer/Z Expert Predictions Max     1406.88\n",
      "trainer/Z Expert Predictions Min     1167.76\n",
      "trainer/Z Policy Predictions Mean     733.995\n",
      "trainer/Z Policy Predictions Std      435.567\n",
      "trainer/Z Policy Predictions Max     1349.53\n",
      "trainer/Z Policy Predictions Min       -5.00473\n",
      "trainer/Z Expert Targets Mean        1349.54\n",
      "trainer/Z Expert Targets Std           25.823\n",
      "trainer/Z Expert Targets Max         1390.16\n",
      "trainer/Z Expert Targets Min         1148.54\n",
      "trainer/Z Policy Targets Mean         727.161\n",
      "trainer/Z Policy Targets Std          434.574\n",
      "trainer/Z Policy Targets Max         1335.48\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   51.5308\n",
      "trainer/Log Pis Std                    18.3322\n",
      "trainer/Policy mu Mean                  0.457832\n",
      "trainer/Policy mu Std                   2.58395\n",
      "trainer/Policy log std Mean            -2.21097\n",
      "trainer/Policy log std Std              1.16542\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        106980\n",
      "exploration/num paths total          1242\n",
      "evaluation/num steps total         230307\n",
      "evaluation/num paths total           1019\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.34665\n",
      "evaluation/Rewards Std                  0.0810732\n",
      "evaluation/Rewards Max                  5.60995\n",
      "evaluation/Rewards Min                  4.80377\n",
      "evaluation/Returns Mean              5346.65\n",
      "evaluation/Returns Std                  6.85969\n",
      "evaluation/Returns Max               5356.42\n",
      "evaluation/Returns Min               5334.72\n",
      "evaluation/Estimation Bias Mean      1322.11\n",
      "evaluation/Estimation Bias Std        156.367\n",
      "evaluation/EB/Q_True Mean              48.1976\n",
      "evaluation/EB/Q_True Std              148.403\n",
      "evaluation/EB/Q_Pred Mean            1370.3\n",
      "evaluation/EB/Q_Pred Std               56.7669\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5346.65\n",
      "evaluation/Actions Mean                 0.067392\n",
      "evaluation/Actions Std                  0.499263\n",
      "evaluation/Actions Max                  0.999987\n",
      "evaluation/Actions Min                 -0.998293\n",
      "time/backward_policy (s)                1.75517\n",
      "time/backward_zf1 (s)                   2.18753\n",
      "time/backward_zf2 (s)                   2.08421\n",
      "time/data sampling (s)                  0.361777\n",
      "time/data storing (s)                   0.0147518\n",
      "time/evaluation sampling (s)            2.35814\n",
      "time/exploration sampling (s)           0.485177\n",
      "time/logging (s)                        0.0134384\n",
      "time/preback_alpha (s)                  0.57771\n",
      "time/preback_policy (s)                 0.963932\n",
      "time/preback_start (s)                  0.174369\n",
      "time/preback_zf (s)                     6.68793\n",
      "time/saving (s)                         3.519e-06\n",
      "time/training (s)                       3.77853\n",
      "time/epoch (s)                         21.4427\n",
      "time/total (s)                       1986.39\n",
      "Epoch                                 100\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:58:50.751950 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 101 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 112000\n",
      "trainer/ZF1 Loss                      171.164\n",
      "trainer/ZF2 Loss                      178.787\n",
      "trainer/ZF Expert Reward               17.876\n",
      "trainer/ZF Policy Reward                4.35585\n",
      "trainer/ZF CHI2 Term                  178.932\n",
      "trainer/Policy Loss                  -660.119\n",
      "trainer/Bias Loss                      11.0713\n",
      "trainer/Bias Value                     17.8554\n",
      "trainer/Policy Grad Norm              142.677\n",
      "trainer/Policy Param Norm              44.641\n",
      "trainer/Zf1 Grad Norm               16546.2\n",
      "trainer/Zf1 Param Norm                100.647\n",
      "trainer/Zf2 Grad Norm               15510.6\n",
      "trainer/Zf2 Param Norm                 99.3034\n",
      "trainer/Z Expert Predictions Mean    1393.09\n",
      "trainer/Z Expert Predictions Std       22.7211\n",
      "trainer/Z Expert Predictions Max     1431.05\n",
      "trainer/Z Expert Predictions Min     1278.74\n",
      "trainer/Z Policy Predictions Mean     648.094\n",
      "trainer/Z Policy Predictions Std      472.168\n",
      "trainer/Z Policy Predictions Max     1412.86\n",
      "trainer/Z Policy Predictions Min      -24.0967\n",
      "trainer/Z Expert Targets Mean        1375.21\n",
      "trainer/Z Expert Targets Std           22.7804\n",
      "trainer/Z Expert Targets Max         1414.03\n",
      "trainer/Z Expert Targets Min         1251.33\n",
      "trainer/Z Policy Targets Mean         643.738\n",
      "trainer/Z Policy Targets Std          469.531\n",
      "trainer/Z Policy Targets Max         1383.25\n",
      "trainer/Z Policy Targets Min           -6.54785\n",
      "trainer/Log Pis Mean                   56.6932\n",
      "trainer/Log Pis Std                    22.6775\n",
      "trainer/Policy mu Mean                  0.514302\n",
      "trainer/Policy mu Std                   2.87612\n",
      "trainer/Policy log std Mean            -2.02095\n",
      "trainer/Policy log std Std              1.19761\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        106980\n",
      "exploration/num paths total          1242\n",
      "evaluation/num steps total         239200\n",
      "evaluation/num paths total           1029\n",
      "evaluation/path length Mean           889.3\n",
      "evaluation/path length Std            240.351\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            223\n",
      "evaluation/Rewards Mean                 5.28489\n",
      "evaluation/Rewards Std                  0.104294\n",
      "evaluation/Rewards Max                  5.65181\n",
      "evaluation/Rewards Min                  4.30196\n",
      "evaluation/Returns Mean              4699.85\n",
      "evaluation/Returns Std               1275.89\n",
      "evaluation/Returns Max               5305.83\n",
      "evaluation/Returns Min               1169.04\n",
      "evaluation/Estimation Bias Mean      1272.22\n",
      "evaluation/Estimation Bias Std        254.376\n",
      "evaluation/EB/Q_True Mean              53.6373\n",
      "evaluation/EB/Q_True Std              154.738\n",
      "evaluation/EB/Q_Pred Mean            1325.86\n",
      "evaluation/EB/Q_Pred Std              166.422\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4699.85\n",
      "evaluation/Actions Mean                 0.0810579\n",
      "evaluation/Actions Std                  0.514237\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71356\n",
      "time/backward_zf1 (s)                   2.11863\n",
      "time/backward_zf2 (s)                   2.01956\n",
      "time/data sampling (s)                  0.340704\n",
      "time/data storing (s)                   0.0150193\n",
      "time/evaluation sampling (s)            2.42038\n",
      "time/exploration sampling (s)           0.493391\n",
      "time/logging (s)                        0.0116528\n",
      "time/preback_alpha (s)                  0.565873\n",
      "time/preback_policy (s)                 0.927751\n",
      "time/preback_start (s)                  0.175261\n",
      "time/preback_zf (s)                     6.59455\n",
      "time/saving (s)                         3.159e-06\n",
      "time/training (s)                       3.82343\n",
      "time/epoch (s)                         21.2198\n",
      "time/total (s)                       2007.63\n",
      "Epoch                                 101\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:59:12.287633 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 102 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 113000\n",
      "trainer/ZF1 Loss                      178.64\n",
      "trainer/ZF2 Loss                      168.693\n",
      "trainer/ZF Expert Reward               19.4941\n",
      "trainer/ZF Policy Reward                4.88226\n",
      "trainer/ZF CHI2 Term                  178.993\n",
      "trainer/Policy Loss                  -762.357\n",
      "trainer/Bias Loss                      10.8849\n",
      "trainer/Bias Value                     17.8814\n",
      "trainer/Policy Grad Norm              124.609\n",
      "trainer/Policy Param Norm              44.8147\n",
      "trainer/Zf1 Grad Norm               17274.4\n",
      "trainer/Zf1 Param Norm                101.22\n",
      "trainer/Zf2 Grad Norm               22713\n",
      "trainer/Zf2 Param Norm                 99.8727\n",
      "trainer/Z Expert Predictions Mean    1418.28\n",
      "trainer/Z Expert Predictions Std       21.5138\n",
      "trainer/Z Expert Predictions Max     1459.44\n",
      "trainer/Z Expert Predictions Min     1350.38\n",
      "trainer/Z Policy Predictions Mean     751.288\n",
      "trainer/Z Policy Predictions Std      489.952\n",
      "trainer/Z Policy Predictions Max     1423.89\n",
      "trainer/Z Policy Predictions Min       -7.30332\n",
      "trainer/Z Expert Targets Mean        1398.79\n",
      "trainer/Z Expert Targets Std           21.1906\n",
      "trainer/Z Expert Targets Max         1440.41\n",
      "trainer/Z Expert Targets Min         1335.78\n",
      "trainer/Z Policy Targets Mean         746.406\n",
      "trainer/Z Policy Targets Std          489.041\n",
      "trainer/Z Policy Targets Max         1417.75\n",
      "trainer/Z Policy Targets Min          -21.1987\n",
      "trainer/Log Pis Mean                   51.5947\n",
      "trainer/Log Pis Std                    18.3097\n",
      "trainer/Policy mu Mean                  0.355628\n",
      "trainer/Policy mu Std                   2.46563\n",
      "trainer/Policy log std Mean            -2.21116\n",
      "trainer/Policy log std Std              1.18604\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        106980\n",
      "exploration/num paths total          1242\n",
      "evaluation/num steps total         248631\n",
      "evaluation/num paths total           1039\n",
      "evaluation/path length Mean           943.1\n",
      "evaluation/path length Std            170.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            431\n",
      "evaluation/Rewards Mean                 5.28968\n",
      "evaluation/Rewards Std                  0.0806702\n",
      "evaluation/Rewards Max                  6.21563\n",
      "evaluation/Rewards Min                  4.82169\n",
      "evaluation/Returns Mean              4988.7\n",
      "evaluation/Returns Std                903.126\n",
      "evaluation/Returns Max               5297.37\n",
      "evaluation/Returns Min               2279.38\n",
      "evaluation/Estimation Bias Mean      1322.69\n",
      "evaluation/Estimation Bias Std        221.006\n",
      "evaluation/EB/Q_True Mean              50.6808\n",
      "evaluation/EB/Q_True Std              151.043\n",
      "evaluation/EB/Q_Pred Mean            1373.37\n",
      "evaluation/EB/Q_Pred Std              119.202\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4988.7\n",
      "evaluation/Actions Mean                 0.0755403\n",
      "evaluation/Actions Std                  0.514173\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85637\n",
      "time/backward_zf1 (s)                   2.27683\n",
      "time/backward_zf2 (s)                   2.20146\n",
      "time/data sampling (s)                  0.358981\n",
      "time/data storing (s)                   0.0145217\n",
      "time/evaluation sampling (s)            2.48565\n",
      "time/exploration sampling (s)           0.492184\n",
      "time/logging (s)                        0.0129032\n",
      "time/preback_alpha (s)                  0.575289\n",
      "time/preback_policy (s)                 1.12827\n",
      "time/preback_start (s)                  0.175338\n",
      "time/preback_zf (s)                     6.63746\n",
      "time/saving (s)                         3.019e-06\n",
      "time/training (s)                       3.25041\n",
      "time/epoch (s)                         21.4657\n",
      "time/total (s)                       2029.12\n",
      "Epoch                                 102\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:59:33.790558 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 103 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 114000\n",
      "trainer/ZF1 Loss                      158.954\n",
      "trainer/ZF2 Loss                      176.824\n",
      "trainer/ZF Expert Reward               18.9819\n",
      "trainer/ZF Policy Reward                9.6715\n",
      "trainer/ZF CHI2 Term                  172.51\n",
      "trainer/Policy Loss                  -751.701\n",
      "trainer/Bias Loss                      11.6663\n",
      "trainer/Bias Value                     17.9085\n",
      "trainer/Policy Grad Norm              143.821\n",
      "trainer/Policy Param Norm              44.9763\n",
      "trainer/Zf1 Grad Norm               15561\n",
      "trainer/Zf1 Param Norm                101.76\n",
      "trainer/Zf2 Grad Norm               18460.7\n",
      "trainer/Zf2 Param Norm                100.41\n",
      "trainer/Z Expert Predictions Mean    1437.01\n",
      "trainer/Z Expert Predictions Std       27.4038\n",
      "trainer/Z Expert Predictions Max     1477.5\n",
      "trainer/Z Expert Predictions Min     1203.97\n",
      "trainer/Z Policy Predictions Mean     737.185\n",
      "trainer/Z Policy Predictions Std      485.07\n",
      "trainer/Z Policy Predictions Max     1452.48\n",
      "trainer/Z Policy Predictions Min      -15.3208\n",
      "trainer/Z Expert Targets Mean        1418.03\n",
      "trainer/Z Expert Targets Std           26.1533\n",
      "trainer/Z Expert Targets Max         1456.52\n",
      "trainer/Z Expert Targets Min         1215.2\n",
      "trainer/Z Policy Targets Mean         727.514\n",
      "trainer/Z Policy Targets Std          484.442\n",
      "trainer/Z Policy Targets Max         1422.73\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   55.6905\n",
      "trainer/Log Pis Std                    20.5967\n",
      "trainer/Policy mu Mean                  0.317975\n",
      "trainer/Policy mu Std                   2.84184\n",
      "trainer/Policy log std Mean            -2.15029\n",
      "trainer/Policy log std Std              1.23042\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        107980\n",
      "exploration/num paths total          1243\n",
      "evaluation/num steps total         257392\n",
      "evaluation/num paths total           1050\n",
      "evaluation/path length Mean           796.455\n",
      "evaluation/path length Std            233.539\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            365\n",
      "evaluation/Rewards Mean                 5.22897\n",
      "evaluation/Rewards Std                  0.191693\n",
      "evaluation/Rewards Max                  6.4017\n",
      "evaluation/Rewards Min                  2.96103\n",
      "evaluation/Returns Mean              4164.64\n",
      "evaluation/Returns Std               1255.22\n",
      "evaluation/Returns Max               5275.6\n",
      "evaluation/Returns Min               1917.21\n",
      "evaluation/Estimation Bias Mean      1206.39\n",
      "evaluation/Estimation Bias Std        363.809\n",
      "evaluation/EB/Q_True Mean              54.3457\n",
      "evaluation/EB/Q_True Std              155.488\n",
      "evaluation/EB/Q_Pred Mean            1260.74\n",
      "evaluation/EB/Q_Pred Std              284.19\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4164.64\n",
      "evaluation/Actions Mean                 0.0786456\n",
      "evaluation/Actions Std                  0.551594\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76581\n",
      "time/backward_zf1 (s)                   2.20631\n",
      "time/backward_zf2 (s)                   2.12359\n",
      "time/data sampling (s)                  0.360768\n",
      "time/data storing (s)                   0.0150207\n",
      "time/evaluation sampling (s)            2.31987\n",
      "time/exploration sampling (s)           0.489858\n",
      "time/logging (s)                        0.0140582\n",
      "time/preback_alpha (s)                  0.576159\n",
      "time/preback_policy (s)                 0.976386\n",
      "time/preback_start (s)                  0.174068\n",
      "time/preback_zf (s)                     6.65696\n",
      "time/saving (s)                         3.057e-06\n",
      "time/training (s)                       3.75938\n",
      "time/epoch (s)                         21.4382\n",
      "time/total (s)                       2050.58\n",
      "Epoch                                 103\n",
      "---------------------------------  --------------\n",
      "2024-07-28 20:59:55.152956 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 104 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 115000\n",
      "trainer/ZF1 Loss                      196.124\n",
      "trainer/ZF2 Loss                      177.183\n",
      "trainer/ZF Expert Reward               17.4879\n",
      "trainer/ZF Policy Reward                4.97226\n",
      "trainer/ZF CHI2 Term                  189.525\n",
      "trainer/Policy Loss                  -732.005\n",
      "trainer/Bias Loss                      16.5063\n",
      "trainer/Bias Value                     17.9251\n",
      "trainer/Policy Grad Norm              200.135\n",
      "trainer/Policy Param Norm              45.121\n",
      "trainer/Zf1 Grad Norm               24174.7\n",
      "trainer/Zf1 Param Norm                102.351\n",
      "trainer/Zf2 Grad Norm               16353.6\n",
      "trainer/Zf2 Param Norm                100.981\n",
      "trainer/Z Expert Predictions Mean    1462.13\n",
      "trainer/Z Expert Predictions Std       27.0495\n",
      "trainer/Z Expert Predictions Max     1506.9\n",
      "trainer/Z Expert Predictions Min     1218.5\n",
      "trainer/Z Policy Predictions Mean     721.626\n",
      "trainer/Z Policy Predictions Std      494.759\n",
      "trainer/Z Policy Predictions Max     1489.48\n",
      "trainer/Z Policy Predictions Min        9.91532\n",
      "trainer/Z Expert Targets Mean        1444.64\n",
      "trainer/Z Expert Targets Std           26.7472\n",
      "trainer/Z Expert Targets Max         1486.82\n",
      "trainer/Z Expert Targets Min         1190.62\n",
      "trainer/Z Policy Targets Mean         716.654\n",
      "trainer/Z Policy Targets Std          493.174\n",
      "trainer/Z Policy Targets Max         1460.6\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   58.1155\n",
      "trainer/Log Pis Std                    23.939\n",
      "trainer/Policy mu Mean                  0.426936\n",
      "trainer/Policy mu Std                   3.00078\n",
      "trainer/Policy log std Mean            -2.1441\n",
      "trainer/Policy log std Std              1.21283\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        107980\n",
      "exploration/num paths total          1243\n",
      "evaluation/num steps total         265643\n",
      "evaluation/num paths total           1060\n",
      "evaluation/path length Mean           825.1\n",
      "evaluation/path length Std            287.744\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            142\n",
      "evaluation/Rewards Mean                 5.2409\n",
      "evaluation/Rewards Std                  0.168762\n",
      "evaluation/Rewards Max                  6.56075\n",
      "evaluation/Rewards Min                  3.79292\n",
      "evaluation/Returns Mean              4324.27\n",
      "evaluation/Returns Std               1526.72\n",
      "evaluation/Returns Max               5272.53\n",
      "evaluation/Returns Min                732.585\n",
      "evaluation/Estimation Bias Mean      1218.44\n",
      "evaluation/Estimation Bias Std        316.378\n",
      "evaluation/EB/Q_True Mean              57.683\n",
      "evaluation/EB/Q_True Std              159.586\n",
      "evaluation/EB/Q_Pred Mean            1276.13\n",
      "evaluation/EB/Q_Pred Std              245.588\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4324.27\n",
      "evaluation/Actions Mean                 0.10657\n",
      "evaluation/Actions Std                  0.559828\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.7169\n",
      "time/backward_zf1 (s)                   2.14915\n",
      "time/backward_zf2 (s)                   2.04005\n",
      "time/data sampling (s)                  0.357033\n",
      "time/data storing (s)                   0.0148808\n",
      "time/evaluation sampling (s)            2.36057\n",
      "time/exploration sampling (s)           0.489913\n",
      "time/logging (s)                        0.0115475\n",
      "time/preback_alpha (s)                  0.575524\n",
      "time/preback_policy (s)                 0.937535\n",
      "time/preback_start (s)                  0.172987\n",
      "time/preback_zf (s)                     6.63466\n",
      "time/saving (s)                         3.437e-06\n",
      "time/training (s)                       3.83434\n",
      "time/epoch (s)                         21.2951\n",
      "time/total (s)                       2071.89\n",
      "Epoch                                 104\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:00:17.338459 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 105 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 116000\n",
      "trainer/ZF1 Loss                      236.731\n",
      "trainer/ZF2 Loss                      261.042\n",
      "trainer/ZF Expert Reward               17.5454\n",
      "trainer/ZF Policy Reward                9.19259\n",
      "trainer/ZF CHI2 Term                  251.582\n",
      "trainer/Policy Loss                  -812.469\n",
      "trainer/Bias Loss                      14.5724\n",
      "trainer/Bias Value                     17.9422\n",
      "trainer/Policy Grad Norm              181.067\n",
      "trainer/Policy Param Norm              45.265\n",
      "trainer/Zf1 Grad Norm               28141.1\n",
      "trainer/Zf1 Param Norm                102.922\n",
      "trainer/Zf2 Grad Norm               30357\n",
      "trainer/Zf2 Param Norm                101.569\n",
      "trainer/Z Expert Predictions Mean    1486.4\n",
      "trainer/Z Expert Predictions Std       24.2249\n",
      "trainer/Z Expert Predictions Max     1527.14\n",
      "trainer/Z Expert Predictions Min     1278.22\n",
      "trainer/Z Policy Predictions Mean     796.87\n",
      "trainer/Z Policy Predictions Std      502.568\n",
      "trainer/Z Policy Predictions Max     1492.01\n",
      "trainer/Z Policy Predictions Min      -11.3372\n",
      "trainer/Z Expert Targets Mean        1468.86\n",
      "trainer/Z Expert Targets Std           23.4852\n",
      "trainer/Z Expert Targets Max         1506.73\n",
      "trainer/Z Expert Targets Min         1289.71\n",
      "trainer/Z Policy Targets Mean         787.677\n",
      "trainer/Z Policy Targets Std          500.146\n",
      "trainer/Z Policy Targets Max         1478.26\n",
      "trainer/Z Policy Targets Min           -9.72994\n",
      "trainer/Log Pis Mean                   56.4574\n",
      "trainer/Log Pis Std                    23.1014\n",
      "trainer/Policy mu Mean                  0.342007\n",
      "trainer/Policy mu Std                   2.90369\n",
      "trainer/Policy log std Mean            -2.24143\n",
      "trainer/Policy log std Std              1.2086\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        107980\n",
      "exploration/num paths total          1243\n",
      "evaluation/num steps total         272706\n",
      "evaluation/num paths total           1072\n",
      "evaluation/path length Mean           588.583\n",
      "evaluation/path length Std            379.042\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            168\n",
      "evaluation/Rewards Mean                 5.29025\n",
      "evaluation/Rewards Std                  0.164304\n",
      "evaluation/Rewards Max                  6.24771\n",
      "evaluation/Rewards Min                  4.1904\n",
      "evaluation/Returns Mean              3113.75\n",
      "evaluation/Returns Std               2033.68\n",
      "evaluation/Returns Max               5340.98\n",
      "evaluation/Returns Min                894.829\n",
      "evaluation/Estimation Bias Mean      1274.37\n",
      "evaluation/Estimation Bias Std        446.946\n",
      "evaluation/EB/Q_True Mean              68.1752\n",
      "evaluation/EB/Q_True Std              172.551\n",
      "evaluation/EB/Q_Pred Mean            1342.55\n",
      "evaluation/EB/Q_Pred Std              335.51\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3113.75\n",
      "evaluation/Actions Mean                 0.0766889\n",
      "evaluation/Actions Std                  0.551416\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.02849\n",
      "time/backward_zf1 (s)                   2.48034\n",
      "time/backward_zf2 (s)                   2.41879\n",
      "time/data sampling (s)                  0.378866\n",
      "time/data storing (s)                   0.015118\n",
      "time/evaluation sampling (s)            2.62777\n",
      "time/exploration sampling (s)           0.488565\n",
      "time/logging (s)                        0.0115067\n",
      "time/preback_alpha (s)                  0.587562\n",
      "time/preback_policy (s)                 1.24083\n",
      "time/preback_start (s)                  0.177083\n",
      "time/preback_zf (s)                     6.70227\n",
      "time/saving (s)                         3.538e-06\n",
      "time/training (s)                       2.95149\n",
      "time/epoch (s)                         22.1087\n",
      "time/total (s)                       2094.03\n",
      "Epoch                                 105\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:00:39.157296 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 106 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 117000\n",
      "trainer/ZF1 Loss                      191.866\n",
      "trainer/ZF2 Loss                      215.047\n",
      "trainer/ZF Expert Reward               17.9973\n",
      "trainer/ZF Policy Reward                8.44871\n",
      "trainer/ZF CHI2 Term                  206.438\n",
      "trainer/Policy Loss                  -892.869\n",
      "trainer/Bias Loss                      10.5915\n",
      "trainer/Bias Value                     17.9583\n",
      "trainer/Policy Grad Norm              161.356\n",
      "trainer/Policy Param Norm              45.4111\n",
      "trainer/Zf1 Grad Norm               22493.3\n",
      "trainer/Zf1 Param Norm                103.476\n",
      "trainer/Zf2 Grad Norm               22646.7\n",
      "trainer/Zf2 Param Norm                102.101\n",
      "trainer/Z Expert Predictions Mean    1497.01\n",
      "trainer/Z Expert Predictions Std      131.323\n",
      "trainer/Z Expert Predictions Max     1551.5\n",
      "trainer/Z Expert Predictions Min       35.3988\n",
      "trainer/Z Policy Predictions Mean     876.902\n",
      "trainer/Z Policy Predictions Std      512.913\n",
      "trainer/Z Policy Predictions Max     1513.67\n",
      "trainer/Z Policy Predictions Min        6.55256\n",
      "trainer/Z Expert Targets Mean        1479.01\n",
      "trainer/Z Expert Targets Std          132.897\n",
      "trainer/Z Expert Targets Max         1533.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         868.453\n",
      "trainer/Z Policy Targets Std          512.923\n",
      "trainer/Z Policy Targets Max         1491.91\n",
      "trainer/Z Policy Targets Min           -0.617144\n",
      "trainer/Log Pis Mean                   54.8888\n",
      "trainer/Log Pis Std                    22.0629\n",
      "trainer/Policy mu Mean                  0.35257\n",
      "trainer/Policy mu Std                   2.50734\n",
      "trainer/Policy log std Mean            -2.41187\n",
      "trainer/Policy log std Std              1.13127\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        110980\n",
      "exploration/num paths total          1246\n",
      "evaluation/num steps total         279878\n",
      "evaluation/num paths total           1082\n",
      "evaluation/path length Mean           717.2\n",
      "evaluation/path length Std            268.623\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            266\n",
      "evaluation/Rewards Mean                 5.30702\n",
      "evaluation/Rewards Std                  0.149623\n",
      "evaluation/Rewards Max                  6.48168\n",
      "evaluation/Rewards Min                  4.33594\n",
      "evaluation/Returns Mean              3806.2\n",
      "evaluation/Returns Std               1434.14\n",
      "evaluation/Returns Max               5326.48\n",
      "evaluation/Returns Min               1423.21\n",
      "evaluation/Estimation Bias Mean      1296.81\n",
      "evaluation/Estimation Bias Std        423.516\n",
      "evaluation/EB/Q_True Mean              66.9496\n",
      "evaluation/EB/Q_True Std              170.909\n",
      "evaluation/EB/Q_Pred Mean            1363.76\n",
      "evaluation/EB/Q_Pred Std              339.299\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3806.2\n",
      "evaluation/Actions Mean                 0.0827347\n",
      "evaluation/Actions Std                  0.550712\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8796\n",
      "time/backward_zf1 (s)                   2.31469\n",
      "time/backward_zf2 (s)                   2.23613\n",
      "time/data sampling (s)                  0.37843\n",
      "time/data storing (s)                   0.0151932\n",
      "time/evaluation sampling (s)            2.31896\n",
      "time/exploration sampling (s)           0.499693\n",
      "time/logging (s)                        0.0107882\n",
      "time/preback_alpha (s)                  0.589259\n",
      "time/preback_policy (s)                 1.09039\n",
      "time/preback_start (s)                  0.177269\n",
      "time/preback_zf (s)                     6.73066\n",
      "time/saving (s)                         3.972e-06\n",
      "time/training (s)                       3.50989\n",
      "time/epoch (s)                         21.7509\n",
      "time/total (s)                       2115.8\n",
      "Epoch                                 106\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:01:00.843814 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 107 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 118000\n",
      "trainer/ZF1 Loss                     1572.26\n",
      "trainer/ZF2 Loss                     1878.01\n",
      "trainer/ZF Expert Reward               19.9614\n",
      "trainer/ZF Policy Reward               18.9319\n",
      "trainer/ZF CHI2 Term                 1729.79\n",
      "trainer/Policy Loss                  -855.168\n",
      "trainer/Bias Loss                      16.5339\n",
      "trainer/Bias Value                     17.9691\n",
      "trainer/Policy Grad Norm              195.956\n",
      "trainer/Policy Param Norm              45.5463\n",
      "trainer/Zf1 Grad Norm               47406.7\n",
      "trainer/Zf1 Param Norm                104.034\n",
      "trainer/Zf2 Grad Norm               45013\n",
      "trainer/Zf2 Param Norm                102.664\n",
      "trainer/Z Expert Predictions Mean    1527.43\n",
      "trainer/Z Expert Predictions Std       95.8669\n",
      "trainer/Z Expert Predictions Max     1574.37\n",
      "trainer/Z Expert Predictions Min       40.7816\n",
      "trainer/Z Policy Predictions Mean     846.676\n",
      "trainer/Z Policy Predictions Std      547.075\n",
      "trainer/Z Policy Predictions Max     1537.46\n",
      "trainer/Z Policy Predictions Min      -11.2845\n",
      "trainer/Z Expert Targets Mean        1507.47\n",
      "trainer/Z Expert Targets Std           97.2393\n",
      "trainer/Z Expert Targets Max         1555.44\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         827.744\n",
      "trainer/Z Policy Targets Std          546.045\n",
      "trainer/Z Policy Targets Max         1532.51\n",
      "trainer/Z Policy Targets Min          -10.844\n",
      "trainer/Log Pis Mean                   56.6321\n",
      "trainer/Log Pis Std                    23.0291\n",
      "trainer/Policy mu Mean                  0.217454\n",
      "trainer/Policy mu Std                   3.12574\n",
      "trainer/Policy log std Mean            -2.21252\n",
      "trainer/Policy log std Std              1.32449\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        114980\n",
      "exploration/num paths total          1250\n",
      "evaluation/num steps total         287640\n",
      "evaluation/num paths total           1093\n",
      "evaluation/path length Mean           705.636\n",
      "evaluation/path length Std            341.824\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            198\n",
      "evaluation/Rewards Mean                 5.22025\n",
      "evaluation/Rewards Std                  0.204563\n",
      "evaluation/Rewards Max                  5.55416\n",
      "evaluation/Rewards Min                  3.51604\n",
      "evaluation/Returns Mean              3683.6\n",
      "evaluation/Returns Std               1836.89\n",
      "evaluation/Returns Max               5292.38\n",
      "evaluation/Returns Min                979.475\n",
      "evaluation/Estimation Bias Mean      1342.14\n",
      "evaluation/Estimation Bias Std        373.902\n",
      "evaluation/EB/Q_True Mean              61.5472\n",
      "evaluation/EB/Q_True Std              164.459\n",
      "evaluation/EB/Q_Pred Mean            1403.69\n",
      "evaluation/EB/Q_Pred Std              278.382\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3683.6\n",
      "evaluation/Actions Mean                 0.077294\n",
      "evaluation/Actions Std                  0.536215\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81781\n",
      "time/backward_zf1 (s)                   2.26588\n",
      "time/backward_zf2 (s)                   2.16715\n",
      "time/data sampling (s)                  0.365864\n",
      "time/data storing (s)                   0.0146264\n",
      "time/evaluation sampling (s)            2.4024\n",
      "time/exploration sampling (s)           0.498992\n",
      "time/logging (s)                        0.0106514\n",
      "time/preback_alpha (s)                  0.584532\n",
      "time/preback_policy (s)                 1.05105\n",
      "time/preback_start (s)                  0.177002\n",
      "time/preback_zf (s)                     6.72643\n",
      "time/saving (s)                         3.654e-06\n",
      "time/training (s)                       3.53505\n",
      "time/epoch (s)                         21.6174\n",
      "time/total (s)                       2137.44\n",
      "Epoch                                 107\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:01:23.257222 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 108 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 119000\n",
      "trainer/ZF1 Loss                      205.819\n",
      "trainer/ZF2 Loss                      199.839\n",
      "trainer/ZF Expert Reward               19.9697\n",
      "trainer/ZF Policy Reward                9.92567\n",
      "trainer/ZF CHI2 Term                  207.253\n",
      "trainer/Policy Loss                  -905.8\n",
      "trainer/Bias Loss                      16.7094\n",
      "trainer/Bias Value                     17.9723\n",
      "trainer/Policy Grad Norm              239.316\n",
      "trainer/Policy Param Norm              45.682\n",
      "trainer/Zf1 Grad Norm               23579.8\n",
      "trainer/Zf1 Param Norm                104.596\n",
      "trainer/Zf2 Grad Norm               19174.4\n",
      "trainer/Zf2 Param Norm                103.219\n",
      "trainer/Z Expert Predictions Mean    1552.07\n",
      "trainer/Z Expert Predictions Std       64.692\n",
      "trainer/Z Expert Predictions Max     1597.89\n",
      "trainer/Z Expert Predictions Min      862.77\n",
      "trainer/Z Policy Predictions Mean     889.6\n",
      "trainer/Z Policy Predictions Std      528.032\n",
      "trainer/Z Policy Predictions Max     1564.68\n",
      "trainer/Z Policy Predictions Min       -2.60567\n",
      "trainer/Z Expert Targets Mean        1532.1\n",
      "trainer/Z Expert Targets Std           62.5133\n",
      "trainer/Z Expert Targets Max         1578.58\n",
      "trainer/Z Expert Targets Min          858.013\n",
      "trainer/Z Policy Targets Mean         879.674\n",
      "trainer/Z Policy Targets Std          526.135\n",
      "trainer/Z Policy Targets Max         1541.79\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   55.1314\n",
      "trainer/Log Pis Std                    22.9342\n",
      "trainer/Policy mu Mean                  0.299887\n",
      "trainer/Policy mu Std                   2.76297\n",
      "trainer/Policy log std Mean            -2.24994\n",
      "trainer/Policy log std Std              1.1342\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        115980\n",
      "exploration/num paths total          1251\n",
      "evaluation/num steps total         295796\n",
      "evaluation/num paths total           1104\n",
      "evaluation/path length Mean           741.455\n",
      "evaluation/path length Std            295.881\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            271\n",
      "evaluation/Rewards Mean                 5.26613\n",
      "evaluation/Rewards Std                  0.188335\n",
      "evaluation/Rewards Max                  6.44214\n",
      "evaluation/Rewards Min                  3.8076\n",
      "evaluation/Returns Mean              3904.59\n",
      "evaluation/Returns Std               1589.26\n",
      "evaluation/Returns Max               5314.5\n",
      "evaluation/Returns Min               1437.81\n",
      "evaluation/Estimation Bias Mean      1370.1\n",
      "evaluation/Estimation Bias Std        348.329\n",
      "evaluation/EB/Q_True Mean              58.907\n",
      "evaluation/EB/Q_True Std              161.889\n",
      "evaluation/EB/Q_Pred Mean            1429\n",
      "evaluation/EB/Q_Pred Std              274.046\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3904.59\n",
      "evaluation/Actions Mean                 0.0815571\n",
      "evaluation/Actions Std                  0.54545\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.03432\n",
      "time/backward_zf1 (s)                   2.49294\n",
      "time/backward_zf2 (s)                   2.4283\n",
      "time/data sampling (s)                  0.390684\n",
      "time/data storing (s)                   0.0155117\n",
      "time/evaluation sampling (s)            2.61911\n",
      "time/exploration sampling (s)           0.506694\n",
      "time/logging (s)                        0.012104\n",
      "time/preback_alpha (s)                  0.598837\n",
      "time/preback_policy (s)                 1.25489\n",
      "time/preback_start (s)                  0.182421\n",
      "time/preback_zf (s)                     6.80998\n",
      "time/saving (s)                         3.545e-06\n",
      "time/training (s)                       2.99924\n",
      "time/epoch (s)                         22.345\n",
      "time/total (s)                       2159.81\n",
      "Epoch                                 108\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:01:43.676253 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 109 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 120000\n",
      "trainer/ZF1 Loss                      195.96\n",
      "trainer/ZF2 Loss                      228.676\n",
      "trainer/ZF Expert Reward               22.0112\n",
      "trainer/ZF Policy Reward               11.2808\n",
      "trainer/ZF CHI2 Term                  218.575\n",
      "trainer/Policy Loss                  -851.209\n",
      "trainer/Bias Loss                      33.1991\n",
      "trainer/Bias Value                     17.9714\n",
      "trainer/Policy Grad Norm              176.638\n",
      "trainer/Policy Param Norm              45.8112\n",
      "trainer/Zf1 Grad Norm               19391.1\n",
      "trainer/Zf1 Param Norm                105.172\n",
      "trainer/Zf2 Grad Norm               31517.6\n",
      "trainer/Zf2 Param Norm                103.809\n",
      "trainer/Z Expert Predictions Mean    1566.66\n",
      "trainer/Z Expert Predictions Std      141.506\n",
      "trainer/Z Expert Predictions Max     1626.65\n",
      "trainer/Z Expert Predictions Min       50.4163\n",
      "trainer/Z Policy Predictions Mean     835.532\n",
      "trainer/Z Policy Predictions Std      545.143\n",
      "trainer/Z Policy Predictions Max     1579.67\n",
      "trainer/Z Policy Predictions Min      -20.3198\n",
      "trainer/Z Expert Targets Mean        1544.65\n",
      "trainer/Z Expert Targets Std          144.639\n",
      "trainer/Z Expert Targets Max         1603.58\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         824.251\n",
      "trainer/Z Policy Targets Std          542.891\n",
      "trainer/Z Policy Targets Max         1553.8\n",
      "trainer/Z Policy Targets Min           -5.42579\n",
      "trainer/Log Pis Mean                   59.0737\n",
      "trainer/Log Pis Std                    23.773\n",
      "trainer/Policy mu Mean                  0.192155\n",
      "trainer/Policy mu Std                   2.9312\n",
      "trainer/Policy log std Mean            -2.19947\n",
      "trainer/Policy log std Std              1.20806\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        116980\n",
      "exploration/num paths total          1252\n",
      "evaluation/num steps total         298851\n",
      "evaluation/num paths total           1114\n",
      "evaluation/path length Mean           305.5\n",
      "evaluation/path length Std            102.248\n",
      "evaluation/path length Max            529\n",
      "evaluation/path length Min            173\n",
      "evaluation/Rewards Mean                 5.09882\n",
      "evaluation/Rewards Std                  0.331318\n",
      "evaluation/Rewards Max                  5.86064\n",
      "evaluation/Rewards Min                  3.65387\n",
      "evaluation/Returns Mean              1557.69\n",
      "evaluation/Returns Std                554.271\n",
      "evaluation/Returns Max               2780.34\n",
      "evaluation/Returns Min                840.896\n",
      "evaluation/Estimation Bias Mean      1104.5\n",
      "evaluation/Estimation Bias Std        482.377\n",
      "evaluation/EB/Q_True Mean              59.6335\n",
      "evaluation/EB/Q_True Std              142.691\n",
      "evaluation/EB/Q_Pred Mean            1164.13\n",
      "evaluation/EB/Q_Pred Std              463.053\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1557.69\n",
      "evaluation/Actions Mean                 0.108646\n",
      "evaluation/Actions Std                  0.629385\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.71271\n",
      "time/backward_zf1 (s)                   2.13629\n",
      "time/backward_zf2 (s)                   2.04622\n",
      "time/data sampling (s)                  0.370488\n",
      "time/data storing (s)                   0.0144767\n",
      "time/evaluation sampling (s)            1.40133\n",
      "time/exploration sampling (s)           0.479146\n",
      "time/logging (s)                        0.00470394\n",
      "time/preback_alpha (s)                  0.573\n",
      "time/preback_policy (s)                 0.973686\n",
      "time/preback_start (s)                  0.173785\n",
      "time/preback_zf (s)                     6.66002\n",
      "time/saving (s)                         3.368e-06\n",
      "time/training (s)                       3.80208\n",
      "time/epoch (s)                         20.348\n",
      "time/total (s)                       2180.17\n",
      "Epoch                                 109\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:02:04.937181 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 110 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 121000\n",
      "trainer/ZF1 Loss                      224.179\n",
      "trainer/ZF2 Loss                      252.909\n",
      "trainer/ZF Expert Reward               16.8061\n",
      "trainer/ZF Policy Reward                8.52073\n",
      "trainer/ZF CHI2 Term                  239.43\n",
      "trainer/Policy Loss                  -882.162\n",
      "trainer/Bias Loss                      18.1009\n",
      "trainer/Bias Value                     17.9721\n",
      "trainer/Policy Grad Norm              172.306\n",
      "trainer/Policy Param Norm              45.9367\n",
      "trainer/Zf1 Grad Norm               21138.3\n",
      "trainer/Zf1 Param Norm                105.694\n",
      "trainer/Zf2 Grad Norm               22587.4\n",
      "trainer/Zf2 Param Norm                104.324\n",
      "trainer/Z Expert Predictions Mean    1593.23\n",
      "trainer/Z Expert Predictions Std       27.1425\n",
      "trainer/Z Expert Predictions Max     1642.97\n",
      "trainer/Z Expert Predictions Min     1512.46\n",
      "trainer/Z Policy Predictions Mean     868.663\n",
      "trainer/Z Policy Predictions Std      576.697\n",
      "trainer/Z Policy Predictions Max     1614.92\n",
      "trainer/Z Policy Predictions Min       -6.06242\n",
      "trainer/Z Expert Targets Mean        1576.42\n",
      "trainer/Z Expert Targets Std           26.5871\n",
      "trainer/Z Expert Targets Max         1625.61\n",
      "trainer/Z Expert Targets Min         1479.74\n",
      "trainer/Z Policy Targets Mean         860.142\n",
      "trainer/Z Policy Targets Std          574.752\n",
      "trainer/Z Policy Targets Max         1586.93\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   56.4815\n",
      "trainer/Log Pis Std                    22.8153\n",
      "trainer/Policy mu Mean                  0.228223\n",
      "trainer/Policy mu Std                   3.01757\n",
      "trainer/Policy log std Mean            -2.23046\n",
      "trainer/Policy log std Std              1.2748\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        116980\n",
      "exploration/num paths total          1252\n",
      "evaluation/num steps total         305951\n",
      "evaluation/num paths total           1124\n",
      "evaluation/path length Mean           710\n",
      "evaluation/path length Std            357.643\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             92\n",
      "evaluation/Rewards Mean                 5.2418\n",
      "evaluation/Rewards Std                  0.185441\n",
      "evaluation/Rewards Max                  5.95056\n",
      "evaluation/Rewards Min                  3.42682\n",
      "evaluation/Returns Mean              3721.68\n",
      "evaluation/Returns Std               1910.52\n",
      "evaluation/Returns Max               5293.97\n",
      "evaluation/Returns Min                462.202\n",
      "evaluation/Estimation Bias Mean      1384.31\n",
      "evaluation/Estimation Bias Std        386.7\n",
      "evaluation/EB/Q_True Mean              67.1377\n",
      "evaluation/EB/Q_True Std              170.418\n",
      "evaluation/EB/Q_Pred Mean            1451.44\n",
      "evaluation/EB/Q_Pred Std              287.243\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3721.68\n",
      "evaluation/Actions Mean                 0.0969554\n",
      "evaluation/Actions Std                  0.539575\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76709\n",
      "time/backward_zf1 (s)                   2.19223\n",
      "time/backward_zf2 (s)                   2.09827\n",
      "time/data sampling (s)                  0.343469\n",
      "time/data storing (s)                   0.0160447\n",
      "time/evaluation sampling (s)            2.33446\n",
      "time/exploration sampling (s)           0.487469\n",
      "time/logging (s)                        0.0104022\n",
      "time/preback_alpha (s)                  0.576723\n",
      "time/preback_policy (s)                 1.02837\n",
      "time/preback_start (s)                  0.177872\n",
      "time/preback_zf (s)                     6.64449\n",
      "time/saving (s)                         3.276e-06\n",
      "time/training (s)                       3.52236\n",
      "time/epoch (s)                         21.1992\n",
      "time/total (s)                       2201.39\n",
      "Epoch                                 110\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:02:26.612110 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 111 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 122000\n",
      "trainer/ZF1 Loss                      231.289\n",
      "trainer/ZF2 Loss                      243.101\n",
      "trainer/ZF Expert Reward               16.5407\n",
      "trainer/ZF Policy Reward                4.8877\n",
      "trainer/ZF CHI2 Term                  237.63\n",
      "trainer/Policy Loss                  -938.545\n",
      "trainer/Bias Loss                      17.498\n",
      "trainer/Bias Value                     17.9712\n",
      "trainer/Policy Grad Norm              179.346\n",
      "trainer/Policy Param Norm              46.0676\n",
      "trainer/Zf1 Grad Norm               22658.8\n",
      "trainer/Zf1 Param Norm                106.218\n",
      "trainer/Zf2 Grad Norm               19117.3\n",
      "trainer/Zf2 Param Norm                104.84\n",
      "trainer/Z Expert Predictions Mean    1607.08\n",
      "trainer/Z Expert Predictions Std      103.737\n",
      "trainer/Z Expert Predictions Max     1660.13\n",
      "trainer/Z Expert Predictions Min       24.3021\n",
      "trainer/Z Policy Predictions Mean     922.92\n",
      "trainer/Z Policy Predictions Std      542.699\n",
      "trainer/Z Policy Predictions Max     1598.91\n",
      "trainer/Z Policy Predictions Min      -13.0077\n",
      "trainer/Z Expert Targets Mean        1590.54\n",
      "trainer/Z Expert Targets Std          104.252\n",
      "trainer/Z Expert Targets Max         1638.09\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         918.032\n",
      "trainer/Z Policy Targets Std          539.921\n",
      "trainer/Z Policy Targets Max         1603.84\n",
      "trainer/Z Policy Targets Min           -9.57733\n",
      "trainer/Log Pis Mean                   57.7897\n",
      "trainer/Log Pis Std                    24.3414\n",
      "trainer/Policy mu Mean                  0.380857\n",
      "trainer/Policy mu Std                   2.94571\n",
      "trainer/Policy log std Mean            -2.33814\n",
      "trainer/Policy log std Std              1.21649\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        116980\n",
      "exploration/num paths total          1252\n",
      "evaluation/num steps total         312839\n",
      "evaluation/num paths total           1135\n",
      "evaluation/path length Mean           626.182\n",
      "evaluation/path length Std            271.236\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            259\n",
      "evaluation/Rewards Mean                 5.17346\n",
      "evaluation/Rewards Std                  0.248112\n",
      "evaluation/Rewards Max                  5.47799\n",
      "evaluation/Rewards Min                  3.21818\n",
      "evaluation/Returns Mean              3239.53\n",
      "evaluation/Returns Std               1453.28\n",
      "evaluation/Returns Max               5269.54\n",
      "evaluation/Returns Min               1293.64\n",
      "evaluation/Estimation Bias Mean      1365.53\n",
      "evaluation/Estimation Bias Std        411.863\n",
      "evaluation/EB/Q_True Mean              68.9403\n",
      "evaluation/EB/Q_True Std              172\n",
      "evaluation/EB/Q_Pred Mean            1434.47\n",
      "evaluation/EB/Q_Pred Std              352.785\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3239.53\n",
      "evaluation/Actions Mean                 0.104483\n",
      "evaluation/Actions Std                  0.544792\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86139\n",
      "time/backward_zf1 (s)                   2.29049\n",
      "time/backward_zf2 (s)                   2.21658\n",
      "time/data sampling (s)                  0.361914\n",
      "time/data storing (s)                   0.0152091\n",
      "time/evaluation sampling (s)            2.54852\n",
      "time/exploration sampling (s)           0.482078\n",
      "time/logging (s)                        0.00986573\n",
      "time/preback_alpha (s)                  0.578152\n",
      "time/preback_policy (s)                 1.10911\n",
      "time/preback_start (s)                  0.177019\n",
      "time/preback_zf (s)                     6.65875\n",
      "time/saving (s)                         3.426e-06\n",
      "time/training (s)                       3.30059\n",
      "time/epoch (s)                         21.6097\n",
      "time/total (s)                       2223.02\n",
      "Epoch                                 111\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:02:48.098322 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 112 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 123000\n",
      "trainer/ZF1 Loss                      195.969\n",
      "trainer/ZF2 Loss                      267.378\n",
      "trainer/ZF Expert Reward               17.1773\n",
      "trainer/ZF Policy Reward                2.72475\n",
      "trainer/ZF CHI2 Term                  232.571\n",
      "trainer/Policy Loss                  -955.386\n",
      "trainer/Bias Loss                      25.6512\n",
      "trainer/Bias Value                     17.9714\n",
      "trainer/Policy Grad Norm              174.873\n",
      "trainer/Policy Param Norm              46.1911\n",
      "trainer/Zf1 Grad Norm               21336.1\n",
      "trainer/Zf1 Param Norm                106.722\n",
      "trainer/Zf2 Grad Norm               35462.2\n",
      "trainer/Zf2 Param Norm                105.339\n",
      "trainer/Z Expert Predictions Mean    1629.43\n",
      "trainer/Z Expert Predictions Std       26.675\n",
      "trainer/Z Expert Predictions Max     1677.43\n",
      "trainer/Z Expert Predictions Min     1552.58\n",
      "trainer/Z Policy Predictions Mean     940.491\n",
      "trainer/Z Policy Predictions Std      565.022\n",
      "trainer/Z Policy Predictions Max     1635.48\n",
      "trainer/Z Policy Predictions Min        1.7341\n",
      "trainer/Z Expert Targets Mean        1612.25\n",
      "trainer/Z Expert Targets Std           27.5714\n",
      "trainer/Z Expert Targets Max         1659.67\n",
      "trainer/Z Expert Targets Min         1531.46\n",
      "trainer/Z Policy Targets Mean         937.766\n",
      "trainer/Z Policy Targets Std          564.976\n",
      "trainer/Z Policy Targets Max         1622.34\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   55.9697\n",
      "trainer/Log Pis Std                    21.7722\n",
      "trainer/Policy mu Mean                  0.34424\n",
      "trainer/Policy mu Std                   2.69447\n",
      "trainer/Policy log std Mean            -2.39254\n",
      "trainer/Policy log std Std              1.1873\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        116980\n",
      "exploration/num paths total          1252\n",
      "evaluation/num steps total         320272\n",
      "evaluation/num paths total           1148\n",
      "evaluation/path length Mean           571.769\n",
      "evaluation/path length Std            334.19\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            152\n",
      "evaluation/Rewards Mean                 5.2588\n",
      "evaluation/Rewards Std                  0.172782\n",
      "evaluation/Rewards Max                  6.28157\n",
      "evaluation/Rewards Min                  4.02762\n",
      "evaluation/Returns Mean              3006.82\n",
      "evaluation/Returns Std               1771.38\n",
      "evaluation/Returns Max               5305.1\n",
      "evaluation/Returns Min                780.213\n",
      "evaluation/Estimation Bias Mean      1305.57\n",
      "evaluation/Estimation Bias Std        447.25\n",
      "evaluation/EB/Q_True Mean              64.3155\n",
      "evaluation/EB/Q_True Std              167.602\n",
      "evaluation/EB/Q_Pred Mean            1369.89\n",
      "evaluation/EB/Q_Pred Std              367.834\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           3006.82\n",
      "evaluation/Actions Mean                 0.0914812\n",
      "evaluation/Actions Std                  0.57518\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.83141\n",
      "time/backward_zf1 (s)                   2.24131\n",
      "time/backward_zf2 (s)                   2.17459\n",
      "time/data sampling (s)                  0.36482\n",
      "time/data storing (s)                   0.0145616\n",
      "time/evaluation sampling (s)            2.35738\n",
      "time/exploration sampling (s)           0.477181\n",
      "time/logging (s)                        0.0111257\n",
      "time/preback_alpha (s)                  0.57617\n",
      "time/preback_policy (s)                 1.06144\n",
      "time/preback_start (s)                  0.175643\n",
      "time/preback_zf (s)                     6.68363\n",
      "time/saving (s)                         3.651e-06\n",
      "time/training (s)                       3.45446\n",
      "time/epoch (s)                         21.4237\n",
      "time/total (s)                       2244.46\n",
      "Epoch                                 112\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:03:09.892569 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 113 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 124000\n",
      "trainer/ZF1 Loss                      257.693\n",
      "trainer/ZF2 Loss                      232.56\n",
      "trainer/ZF Expert Reward               13.9539\n",
      "trainer/ZF Policy Reward                4.18565\n",
      "trainer/ZF CHI2 Term                  242.645\n",
      "trainer/Policy Loss                  -874.025\n",
      "trainer/Bias Loss                      28.4744\n",
      "trainer/Bias Value                     17.9694\n",
      "trainer/Policy Grad Norm              156.744\n",
      "trainer/Policy Param Norm              46.3112\n",
      "trainer/Zf1 Grad Norm               29511.3\n",
      "trainer/Zf1 Param Norm                107.216\n",
      "trainer/Zf2 Grad Norm               25628.1\n",
      "trainer/Zf2 Param Norm                105.831\n",
      "trainer/Z Expert Predictions Mean    1643.27\n",
      "trainer/Z Expert Predictions Std       30.1964\n",
      "trainer/Z Expert Predictions Max     1694.74\n",
      "trainer/Z Expert Predictions Min     1560.79\n",
      "trainer/Z Policy Predictions Mean     856.081\n",
      "trainer/Z Policy Predictions Std      592.46\n",
      "trainer/Z Policy Predictions Max     1667.28\n",
      "trainer/Z Policy Predictions Min      -17.1222\n",
      "trainer/Z Expert Targets Mean        1629.31\n",
      "trainer/Z Expert Targets Std           29.7749\n",
      "trainer/Z Expert Targets Max         1683.9\n",
      "trainer/Z Expert Targets Min         1534.92\n",
      "trainer/Z Policy Targets Mean         851.895\n",
      "trainer/Z Policy Targets Std          592.957\n",
      "trainer/Z Policy Targets Max         1628.28\n",
      "trainer/Z Policy Targets Min           -7.54745\n",
      "trainer/Log Pis Mean                   59.7103\n",
      "trainer/Log Pis Std                    23.9189\n",
      "trainer/Policy mu Mean                  0.35641\n",
      "trainer/Policy mu Std                   3.04053\n",
      "trainer/Policy log std Mean            -2.18168\n",
      "trainer/Policy log std Std              1.27586\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        117980\n",
      "exploration/num paths total          1253\n",
      "evaluation/num steps total         328821\n",
      "evaluation/num paths total           1161\n",
      "evaluation/path length Mean           657.615\n",
      "evaluation/path length Std            379.408\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            134\n",
      "evaluation/Rewards Mean                 5.28739\n",
      "evaluation/Rewards Std                  0.19585\n",
      "evaluation/Rewards Max                  5.92096\n",
      "evaluation/Rewards Min                  3.57458\n",
      "evaluation/Returns Mean              3477.07\n",
      "evaluation/Returns Std               2046.42\n",
      "evaluation/Returns Max               5340.76\n",
      "evaluation/Returns Min                695.591\n",
      "evaluation/Estimation Bias Mean      1470.95\n",
      "evaluation/Estimation Bias Std        404.957\n",
      "evaluation/EB/Q_True Mean              56.2326\n",
      "evaluation/EB/Q_True Std              158.643\n",
      "evaluation/EB/Q_Pred Mean            1527.18\n",
      "evaluation/EB/Q_Pred Std              293.487\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           3477.07\n",
      "evaluation/Actions Mean                 0.0808911\n",
      "evaluation/Actions Std                  0.536776\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95211\n",
      "time/backward_zf1 (s)                   2.38918\n",
      "time/backward_zf2 (s)                   2.32743\n",
      "time/data sampling (s)                  0.37652\n",
      "time/data storing (s)                   0.0144871\n",
      "time/evaluation sampling (s)            2.50628\n",
      "time/exploration sampling (s)           0.487597\n",
      "time/logging (s)                        0.0120715\n",
      "time/preback_alpha (s)                  0.581625\n",
      "time/preback_policy (s)                 1.21013\n",
      "time/preback_start (s)                  0.177027\n",
      "time/preback_zf (s)                     6.68902\n",
      "time/saving (s)                         3.403e-06\n",
      "time/training (s)                       3.00028\n",
      "time/epoch (s)                         21.7238\n",
      "time/total (s)                       2266.21\n",
      "Epoch                                 113\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:03:31.292346 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 114 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 125000\n",
      "trainer/ZF1 Loss                      279.015\n",
      "trainer/ZF2 Loss                      248.803\n",
      "trainer/ZF Expert Reward               18.0061\n",
      "trainer/ZF Policy Reward                5.12671\n",
      "trainer/ZF CHI2 Term                  265.283\n",
      "trainer/Policy Loss                  -993.887\n",
      "trainer/Bias Loss                      40.4424\n",
      "trainer/Bias Value                     17.9677\n",
      "trainer/Policy Grad Norm              237.657\n",
      "trainer/Policy Param Norm              46.4385\n",
      "trainer/Zf1 Grad Norm               24234.8\n",
      "trainer/Zf1 Param Norm                107.722\n",
      "trainer/Zf2 Grad Norm               18817.8\n",
      "trainer/Zf2 Param Norm                106.329\n",
      "trainer/Z Expert Predictions Mean    1663.62\n",
      "trainer/Z Expert Predictions Std       31.9812\n",
      "trainer/Z Expert Predictions Max     1716.86\n",
      "trainer/Z Expert Predictions Min     1551.83\n",
      "trainer/Z Policy Predictions Mean     980.698\n",
      "trainer/Z Policy Predictions Std      576.757\n",
      "trainer/Z Policy Predictions Max     1702.75\n",
      "trainer/Z Policy Predictions Min      -10.1843\n",
      "trainer/Z Expert Targets Mean        1645.61\n",
      "trainer/Z Expert Targets Std           30.2136\n",
      "trainer/Z Expert Targets Max         1700.85\n",
      "trainer/Z Expert Targets Min         1561.77\n",
      "trainer/Z Policy Targets Mean         975.571\n",
      "trainer/Z Policy Targets Std          573.162\n",
      "trainer/Z Policy Targets Max         1672.12\n",
      "trainer/Z Policy Targets Min           -2.00424\n",
      "trainer/Log Pis Mean                   56.135\n",
      "trainer/Log Pis Std                    22.3025\n",
      "trainer/Policy mu Mean                  0.16396\n",
      "trainer/Policy mu Std                   3.01917\n",
      "trainer/Policy log std Mean            -2.39663\n",
      "trainer/Policy log std Std              1.26284\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        117980\n",
      "exploration/num paths total          1253\n",
      "evaluation/num steps total         336360\n",
      "evaluation/num paths total           1174\n",
      "evaluation/path length Mean           579.923\n",
      "evaluation/path length Std            342.328\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            137\n",
      "evaluation/Rewards Mean                 5.24012\n",
      "evaluation/Rewards Std                  0.242919\n",
      "evaluation/Rewards Max                  6.35071\n",
      "evaluation/Rewards Min                  3.11602\n",
      "evaluation/Returns Mean              3038.86\n",
      "evaluation/Returns Std               1829.64\n",
      "evaluation/Returns Max               5316.13\n",
      "evaluation/Returns Min                704.794\n",
      "evaluation/Estimation Bias Mean      1398.79\n",
      "evaluation/Estimation Bias Std        450.758\n",
      "evaluation/EB/Q_True Mean              62.9122\n",
      "evaluation/EB/Q_True Std              165.548\n",
      "evaluation/EB/Q_Pred Mean            1461.7\n",
      "evaluation/EB/Q_Pred Std              367.213\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           3038.86\n",
      "evaluation/Actions Mean                 0.0926959\n",
      "evaluation/Actions Std                  0.560707\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95478\n",
      "time/backward_zf1 (s)                   2.35234\n",
      "time/backward_zf2 (s)                   2.29317\n",
      "time/data sampling (s)                  0.382765\n",
      "time/data storing (s)                   0.015795\n",
      "time/evaluation sampling (s)            2.24347\n",
      "time/exploration sampling (s)           0.496842\n",
      "time/logging (s)                        0.0107513\n",
      "time/preback_alpha (s)                  0.583203\n",
      "time/preback_policy (s)                 1.21507\n",
      "time/preback_start (s)                  0.182105\n",
      "time/preback_zf (s)                     6.66383\n",
      "time/saving (s)                         2.941e-06\n",
      "time/training (s)                       2.9352\n",
      "time/epoch (s)                         21.3293\n",
      "time/total (s)                       2287.56\n",
      "Epoch                                 114\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:03:52.549243 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 115 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 126000\n",
      "trainer/ZF1 Loss                      268.26\n",
      "trainer/ZF2 Loss                      264.624\n",
      "trainer/ZF Expert Reward               19.4981\n",
      "trainer/ZF Policy Reward                7.72694\n",
      "trainer/ZF CHI2 Term                  269.18\n",
      "trainer/Policy Loss                 -1032.38\n",
      "trainer/Bias Loss                      15.7106\n",
      "trainer/Bias Value                     17.9632\n",
      "trainer/Policy Grad Norm              152.547\n",
      "trainer/Policy Param Norm              46.5693\n",
      "trainer/Zf1 Grad Norm               17071.3\n",
      "trainer/Zf1 Param Norm                108.209\n",
      "trainer/Zf2 Grad Norm               22086.3\n",
      "trainer/Zf2 Param Norm                106.829\n",
      "trainer/Z Expert Predictions Mean    1671.32\n",
      "trainer/Z Expert Predictions Std      111.74\n",
      "trainer/Z Expert Predictions Max     1736.31\n",
      "trainer/Z Expert Predictions Min       45.5119\n",
      "trainer/Z Policy Predictions Mean    1017.18\n",
      "trainer/Z Policy Predictions Std      573.139\n",
      "trainer/Z Policy Predictions Max     1704.2\n",
      "trainer/Z Policy Predictions Min        3.73766\n",
      "trainer/Z Expert Targets Mean        1651.82\n",
      "trainer/Z Expert Targets Std          114.14\n",
      "trainer/Z Expert Targets Max         1717.98\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1009.45\n",
      "trainer/Z Policy Targets Std          571.964\n",
      "trainer/Z Policy Targets Max         1677.9\n",
      "trainer/Z Policy Targets Min           -1.46607\n",
      "trainer/Log Pis Mean                   55.6111\n",
      "trainer/Log Pis Std                    22.6363\n",
      "trainer/Policy mu Mean                  0.431361\n",
      "trainer/Policy mu Std                   2.82927\n",
      "trainer/Policy log std Mean            -2.35023\n",
      "trainer/Policy log std Std              1.21444\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        119466\n",
      "exploration/num paths total          1255\n",
      "evaluation/num steps total         339221\n",
      "evaluation/num paths total           1184\n",
      "evaluation/path length Mean           286.1\n",
      "evaluation/path length Std             83.966\n",
      "evaluation/path length Max            424\n",
      "evaluation/path length Min            181\n",
      "evaluation/Rewards Mean                 5.15204\n",
      "evaluation/Rewards Std                  0.331432\n",
      "evaluation/Rewards Max                  6.42176\n",
      "evaluation/Rewards Min                  3.47987\n",
      "evaluation/Returns Mean              1474\n",
      "evaluation/Returns Std                415.243\n",
      "evaluation/Returns Max               2182.43\n",
      "evaluation/Returns Min                964.156\n",
      "evaluation/Estimation Bias Mean      1060.89\n",
      "evaluation/Estimation Bias Std        531.69\n",
      "evaluation/EB/Q_True Mean              52.0278\n",
      "evaluation/EB/Q_True Std              138.661\n",
      "evaluation/EB/Q_Pred Mean            1112.92\n",
      "evaluation/EB/Q_Pred Std              513.576\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1474\n",
      "evaluation/Actions Mean                 0.141886\n",
      "evaluation/Actions Std                  0.681619\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.04982\n",
      "time/backward_zf1 (s)                   2.47889\n",
      "time/backward_zf2 (s)                   2.41668\n",
      "time/data sampling (s)                  0.377369\n",
      "time/data storing (s)                   0.0148214\n",
      "time/evaluation sampling (s)            1.45746\n",
      "time/exploration sampling (s)           0.499392\n",
      "time/logging (s)                        0.00465301\n",
      "time/preback_alpha (s)                  0.599857\n",
      "time/preback_policy (s)                 1.22574\n",
      "time/preback_start (s)                  0.180736\n",
      "time/preback_zf (s)                     6.76231\n",
      "time/saving (s)                         3.052e-06\n",
      "time/training (s)                       3.1131\n",
      "time/epoch (s)                         21.1808\n",
      "time/total (s)                       2308.76\n",
      "Epoch                                 115\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:04:13.282179 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 116 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 127000\n",
      "trainer/ZF1 Loss                      262.515\n",
      "trainer/ZF2 Loss                      258.678\n",
      "trainer/ZF Expert Reward               18.9077\n",
      "trainer/ZF Policy Reward                8.0333\n",
      "trainer/ZF CHI2 Term                  262.545\n",
      "trainer/Policy Loss                 -1009.26\n",
      "trainer/Bias Loss                      13.0786\n",
      "trainer/Bias Value                     17.9564\n",
      "trainer/Policy Grad Norm              184.077\n",
      "trainer/Policy Param Norm              46.6976\n",
      "trainer/Zf1 Grad Norm               35464.6\n",
      "trainer/Zf1 Param Norm                108.704\n",
      "trainer/Zf2 Grad Norm               25957.9\n",
      "trainer/Zf2 Param Norm                107.33\n",
      "trainer/Z Expert Predictions Mean    1689.9\n",
      "trainer/Z Expert Predictions Std      114.716\n",
      "trainer/Z Expert Predictions Max     1756.85\n",
      "trainer/Z Expert Predictions Min       35.0442\n",
      "trainer/Z Policy Predictions Mean     995.542\n",
      "trainer/Z Policy Predictions Std      568.869\n",
      "trainer/Z Policy Predictions Max     1715.39\n",
      "trainer/Z Policy Predictions Min      -10.0988\n",
      "trainer/Z Expert Targets Mean        1670.99\n",
      "trainer/Z Expert Targets Std          115.635\n",
      "trainer/Z Expert Targets Max         1735.62\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         987.509\n",
      "trainer/Z Policy Targets Std          568.126\n",
      "trainer/Z Policy Targets Max         1692.77\n",
      "trainer/Z Policy Targets Min          -11.1286\n",
      "trainer/Log Pis Mean                   56.5752\n",
      "trainer/Log Pis Std                    21.6506\n",
      "trainer/Policy mu Mean                  0.382627\n",
      "trainer/Policy mu Std                   2.75681\n",
      "trainer/Policy log std Mean            -2.4032\n",
      "trainer/Policy log std Std              1.16178\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        122466\n",
      "exploration/num paths total          1258\n",
      "evaluation/num steps total         341475\n",
      "evaluation/num paths total           1194\n",
      "evaluation/path length Mean           225.4\n",
      "evaluation/path length Std             67.4718\n",
      "evaluation/path length Max            344\n",
      "evaluation/path length Min            160\n",
      "evaluation/Rewards Mean                 5.21541\n",
      "evaluation/Rewards Std                  0.248109\n",
      "evaluation/Rewards Max                  6.30067\n",
      "evaluation/Rewards Min                  4.04151\n",
      "evaluation/Returns Mean              1175.55\n",
      "evaluation/Returns Std                336.313\n",
      "evaluation/Returns Max               1763.57\n",
      "evaluation/Returns Min                844.17\n",
      "evaluation/Estimation Bias Mean       949.261\n",
      "evaluation/Estimation Bias Std        561.78\n",
      "evaluation/EB/Q_True Mean              51.95\n",
      "evaluation/EB/Q_True Std              135.829\n",
      "evaluation/EB/Q_Pred Mean            1001.21\n",
      "evaluation/EB/Q_Pred Std              561.387\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1175.55\n",
      "evaluation/Actions Mean                 0.117374\n",
      "evaluation/Actions Std                  0.710985\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.00197\n",
      "time/backward_zf1 (s)                   2.46049\n",
      "time/backward_zf2 (s)                   2.40362\n",
      "time/data sampling (s)                  0.354131\n",
      "time/data storing (s)                   0.015359\n",
      "time/evaluation sampling (s)            1.3284\n",
      "time/exploration sampling (s)           0.512947\n",
      "time/logging (s)                        0.00434858\n",
      "time/preback_alpha (s)                  0.578502\n",
      "time/preback_policy (s)                 1.22386\n",
      "time/preback_start (s)                  0.17997\n",
      "time/preback_zf (s)                     6.66768\n",
      "time/saving (s)                         2.945e-06\n",
      "time/training (s)                       2.9356\n",
      "time/epoch (s)                         20.6669\n",
      "time/total (s)                       2329.45\n",
      "Epoch                                 116\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:04:34.199692 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 117 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 128000\n",
      "trainer/ZF1 Loss                      281.865\n",
      "trainer/ZF2 Loss                      271.53\n",
      "trainer/ZF Expert Reward               18.045\n",
      "trainer/ZF Policy Reward                9.8564\n",
      "trainer/ZF CHI2 Term                  277.663\n",
      "trainer/Policy Loss                 -1030.16\n",
      "trainer/Bias Loss                      11.2226\n",
      "trainer/Bias Value                     17.9545\n",
      "trainer/Policy Grad Norm              192.714\n",
      "trainer/Policy Param Norm              46.8296\n",
      "trainer/Zf1 Grad Norm               41546.2\n",
      "trainer/Zf1 Param Norm                109.16\n",
      "trainer/Zf2 Grad Norm               33153.4\n",
      "trainer/Zf2 Param Norm                107.808\n",
      "trainer/Z Expert Predictions Mean    1708.5\n",
      "trainer/Z Expert Predictions Std       33.6551\n",
      "trainer/Z Expert Predictions Max     1765.03\n",
      "trainer/Z Expert Predictions Min     1610.11\n",
      "trainer/Z Policy Predictions Mean    1012.47\n",
      "trainer/Z Policy Predictions Std      587.932\n",
      "trainer/Z Policy Predictions Max     1733.18\n",
      "trainer/Z Policy Predictions Min        2.5953\n",
      "trainer/Z Expert Targets Mean        1690.46\n",
      "trainer/Z Expert Targets Std           34.0441\n",
      "trainer/Z Expert Targets Max         1749.62\n",
      "trainer/Z Expert Targets Min         1590.82\n",
      "trainer/Z Policy Targets Mean        1002.61\n",
      "trainer/Z Policy Targets Std          587.8\n",
      "trainer/Z Policy Targets Max         1704.85\n",
      "trainer/Z Policy Targets Min           -3.377\n",
      "trainer/Log Pis Mean                   57.6453\n",
      "trainer/Log Pis Std                    22.5565\n",
      "trainer/Policy mu Mean                  0.335481\n",
      "trainer/Policy mu Std                   2.83778\n",
      "trainer/Policy log std Mean            -2.41515\n",
      "trainer/Policy log std Std              1.24181\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        125466\n",
      "exploration/num paths total          1261\n",
      "evaluation/num steps total         344838\n",
      "evaluation/num paths total           1204\n",
      "evaluation/path length Mean           336.3\n",
      "evaluation/path length Std            206.269\n",
      "evaluation/path length Max            777\n",
      "evaluation/path length Min            111\n",
      "evaluation/Rewards Mean                 5.20003\n",
      "evaluation/Rewards Std                  0.247177\n",
      "evaluation/Rewards Max                  6.78333\n",
      "evaluation/Rewards Min                  4.06755\n",
      "evaluation/Returns Mean              1748.77\n",
      "evaluation/Returns Std               1097.59\n",
      "evaluation/Returns Max               4092.94\n",
      "evaluation/Returns Min                526.524\n",
      "evaluation/Estimation Bias Mean      1140.64\n",
      "evaluation/Estimation Bias Std        547.577\n",
      "evaluation/EB/Q_True Mean             106.446\n",
      "evaluation/EB/Q_True Std              201.821\n",
      "evaluation/EB/Q_Pred Mean            1247.09\n",
      "evaluation/EB/Q_Pred Std              469.345\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1748.77\n",
      "evaluation/Actions Mean                 0.121853\n",
      "evaluation/Actions Std                  0.633391\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78361\n",
      "time/backward_zf1 (s)                   2.22964\n",
      "time/backward_zf2 (s)                   2.13826\n",
      "time/data sampling (s)                  0.355078\n",
      "time/data storing (s)                   0.0143899\n",
      "time/evaluation sampling (s)            1.88844\n",
      "time/exploration sampling (s)           0.490083\n",
      "time/logging (s)                        0.00594715\n",
      "time/preback_alpha (s)                  0.57265\n",
      "time/preback_policy (s)                 1.02881\n",
      "time/preback_start (s)                  0.178906\n",
      "time/preback_zf (s)                     6.64448\n",
      "time/saving (s)                         3.805e-06\n",
      "time/training (s)                       3.51825\n",
      "time/epoch (s)                         20.8486\n",
      "time/total (s)                       2350.32\n",
      "Epoch                                 117\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:04:55.553492 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 118 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 129000\n",
      "trainer/ZF1 Loss                      269.398\n",
      "trainer/ZF2 Loss                      225.584\n",
      "trainer/ZF Expert Reward               21.7298\n",
      "trainer/ZF Policy Reward                9.58137\n",
      "trainer/ZF CHI2 Term                  251.973\n",
      "trainer/Policy Loss                 -1090.01\n",
      "trainer/Bias Loss                      22.3574\n",
      "trainer/Bias Value                     17.9475\n",
      "trainer/Policy Grad Norm              190.516\n",
      "trainer/Policy Param Norm              46.9545\n",
      "trainer/Zf1 Grad Norm               32193.4\n",
      "trainer/Zf1 Param Norm                109.668\n",
      "trainer/Zf2 Grad Norm               34011.5\n",
      "trainer/Zf2 Param Norm                108.292\n",
      "trainer/Z Expert Predictions Mean    1723.21\n",
      "trainer/Z Expert Predictions Std       51.8263\n",
      "trainer/Z Expert Predictions Max     1784.34\n",
      "trainer/Z Expert Predictions Min     1099.62\n",
      "trainer/Z Policy Predictions Mean    1074.97\n",
      "trainer/Z Policy Predictions Std      563.623\n",
      "trainer/Z Policy Predictions Max     1746.04\n",
      "trainer/Z Policy Predictions Min      -10.1395\n",
      "trainer/Z Expert Targets Mean        1701.48\n",
      "trainer/Z Expert Targets Std           53.1689\n",
      "trainer/Z Expert Targets Max         1768.14\n",
      "trainer/Z Expert Targets Min         1057.2\n",
      "trainer/Z Policy Targets Mean        1065.39\n",
      "trainer/Z Policy Targets Std          561.289\n",
      "trainer/Z Policy Targets Max         1726.34\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   55.2386\n",
      "trainer/Log Pis Std                    22.9047\n",
      "trainer/Policy mu Mean                  0.312096\n",
      "trainer/Policy mu Std                   2.62989\n",
      "trainer/Policy log std Mean            -2.51545\n",
      "trainer/Policy log std Std              1.14981\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        127218\n",
      "exploration/num paths total          1265\n",
      "evaluation/num steps total         354751\n",
      "evaluation/num paths total           1214\n",
      "evaluation/path length Mean           991.3\n",
      "evaluation/path length Std             26.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            913\n",
      "evaluation/Rewards Mean                 5.30486\n",
      "evaluation/Rewards Std                  0.0951885\n",
      "evaluation/Rewards Max                  5.51221\n",
      "evaluation/Rewards Min                  4.68085\n",
      "evaluation/Returns Mean              5258.71\n",
      "evaluation/Returns Std                142.474\n",
      "evaluation/Returns Max               5314.34\n",
      "evaluation/Returns Min               4831.68\n",
      "evaluation/Estimation Bias Mean      1646.8\n",
      "evaluation/Estimation Bias Std        215.036\n",
      "evaluation/EB/Q_True Mean              48.2922\n",
      "evaluation/EB/Q_True Std              147.984\n",
      "evaluation/EB/Q_Pred Mean            1695.1\n",
      "evaluation/EB/Q_Pred Std              137.909\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5258.71\n",
      "evaluation/Actions Mean                 0.0665082\n",
      "evaluation/Actions Std                  0.509329\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89558\n",
      "time/backward_zf1 (s)                   2.28575\n",
      "time/backward_zf2 (s)                   2.21799\n",
      "time/data sampling (s)                  0.347362\n",
      "time/data storing (s)                   0.0145091\n",
      "time/evaluation sampling (s)            2.30315\n",
      "time/exploration sampling (s)           0.486607\n",
      "time/logging (s)                        0.0131399\n",
      "time/preback_alpha (s)                  0.5792\n",
      "time/preback_policy (s)                 1.11805\n",
      "time/preback_start (s)                  0.181263\n",
      "time/preback_zf (s)                     6.63816\n",
      "time/saving (s)                         3.34e-06\n",
      "time/training (s)                       3.20821\n",
      "time/epoch (s)                         21.289\n",
      "time/total (s)                       2371.64\n",
      "Epoch                                 118\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:05:16.445154 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 119 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 130000\n",
      "trainer/ZF1 Loss                      275.146\n",
      "trainer/ZF2 Loss                      277.145\n",
      "trainer/ZF Expert Reward               16.4293\n",
      "trainer/ZF Policy Reward                6.05918\n",
      "trainer/ZF CHI2 Term                  275.185\n",
      "trainer/Policy Loss                 -1004.29\n",
      "trainer/Bias Loss                      27.4844\n",
      "trainer/Bias Value                     17.9387\n",
      "trainer/Policy Grad Norm              192.097\n",
      "trainer/Policy Param Norm              47.0838\n",
      "trainer/Zf1 Grad Norm               43972.3\n",
      "trainer/Zf1 Param Norm                110.175\n",
      "trainer/Zf2 Grad Norm               32548\n",
      "trainer/Zf2 Param Norm                108.813\n",
      "trainer/Z Expert Predictions Mean    1738.86\n",
      "trainer/Z Expert Predictions Std       36.462\n",
      "trainer/Z Expert Predictions Max     1802.75\n",
      "trainer/Z Expert Predictions Min     1646.47\n",
      "trainer/Z Policy Predictions Mean     983.537\n",
      "trainer/Z Policy Predictions Std      608.729\n",
      "trainer/Z Policy Predictions Max     1746.46\n",
      "trainer/Z Policy Predictions Min       -8.15514\n",
      "trainer/Z Expert Targets Mean        1722.43\n",
      "trainer/Z Expert Targets Std           36.8405\n",
      "trainer/Z Expert Targets Max         1784.09\n",
      "trainer/Z Expert Targets Min         1623.02\n",
      "trainer/Z Policy Targets Mean         977.478\n",
      "trainer/Z Policy Targets Std          610.39\n",
      "trainer/Z Policy Targets Max         1754.35\n",
      "trainer/Z Policy Targets Min          -17.3078\n",
      "trainer/Log Pis Mean                   60.8906\n",
      "trainer/Log Pis Std                    27.3427\n",
      "trainer/Policy mu Mean                  0.368961\n",
      "trainer/Policy mu Std                   3.31003\n",
      "trainer/Policy log std Mean            -2.33505\n",
      "trainer/Policy log std Std              1.30609\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        127439\n",
      "exploration/num paths total          1266\n",
      "evaluation/num steps total         358022\n",
      "evaluation/num paths total           1224\n",
      "evaluation/path length Mean           327.1\n",
      "evaluation/path length Std            151.072\n",
      "evaluation/path length Max            615\n",
      "evaluation/path length Min            201\n",
      "evaluation/Rewards Mean                 5.10563\n",
      "evaluation/Rewards Std                  0.335757\n",
      "evaluation/Rewards Max                  6.29784\n",
      "evaluation/Rewards Min                  3.3512\n",
      "evaluation/Returns Mean              1670.05\n",
      "evaluation/Returns Std                787.425\n",
      "evaluation/Returns Max               3125.52\n",
      "evaluation/Returns Min                989.1\n",
      "evaluation/Estimation Bias Mean      1248.19\n",
      "evaluation/Estimation Bias Std        514.137\n",
      "evaluation/EB/Q_True Mean              66.3107\n",
      "evaluation/EB/Q_True Std              150.906\n",
      "evaluation/EB/Q_Pred Mean            1314.5\n",
      "evaluation/EB/Q_Pred Std              491.641\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1670.05\n",
      "evaluation/Actions Mean                 0.123626\n",
      "evaluation/Actions Std                  0.627845\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.96299\n",
      "time/backward_zf1 (s)                   2.38251\n",
      "time/backward_zf2 (s)                   2.33131\n",
      "time/data sampling (s)                  0.357491\n",
      "time/data storing (s)                   0.0153909\n",
      "time/evaluation sampling (s)            1.61877\n",
      "time/exploration sampling (s)           0.500988\n",
      "time/logging (s)                        0.00487348\n",
      "time/preback_alpha (s)                  0.584727\n",
      "time/preback_policy (s)                 1.21342\n",
      "time/preback_start (s)                  0.182416\n",
      "time/preback_zf (s)                     6.65875\n",
      "time/saving (s)                         2.664e-06\n",
      "time/training (s)                       2.9939\n",
      "time/epoch (s)                         20.8075\n",
      "time/total (s)                       2392.47\n",
      "Epoch                                 119\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:05:38.006200 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 120 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 131000\n",
      "trainer/ZF1 Loss                      325.869\n",
      "trainer/ZF2 Loss                      343.503\n",
      "trainer/ZF Expert Reward               16.4171\n",
      "trainer/ZF Policy Reward                8.73183\n",
      "trainer/ZF CHI2 Term                  333.591\n",
      "trainer/Policy Loss                 -1041.54\n",
      "trainer/Bias Loss                      56.3616\n",
      "trainer/Bias Value                     17.9313\n",
      "trainer/Policy Grad Norm              185.884\n",
      "trainer/Policy Param Norm              47.2099\n",
      "trainer/Zf1 Grad Norm               23165.9\n",
      "trainer/Zf1 Param Norm                110.667\n",
      "trainer/Zf2 Grad Norm               32183.8\n",
      "trainer/Zf2 Param Norm                109.299\n",
      "trainer/Z Expert Predictions Mean    1751.28\n",
      "trainer/Z Expert Predictions Std       40.5053\n",
      "trainer/Z Expert Predictions Max     1823.49\n",
      "trainer/Z Expert Predictions Min     1622.92\n",
      "trainer/Z Policy Predictions Mean    1024.25\n",
      "trainer/Z Policy Predictions Std      597.173\n",
      "trainer/Z Policy Predictions Max     1758.37\n",
      "trainer/Z Policy Predictions Min      -20.6531\n",
      "trainer/Z Expert Targets Mean        1734.87\n",
      "trainer/Z Expert Targets Std           39.4899\n",
      "trainer/Z Expert Targets Max         1803.29\n",
      "trainer/Z Expert Targets Min         1628.32\n",
      "trainer/Z Policy Targets Mean        1015.52\n",
      "trainer/Z Policy Targets Std          597.921\n",
      "trainer/Z Policy Targets Max         1758.76\n",
      "trainer/Z Policy Targets Min          -13.5205\n",
      "trainer/Log Pis Mean                   58.8244\n",
      "trainer/Log Pis Std                    24.4966\n",
      "trainer/Policy mu Mean                  0.369431\n",
      "trainer/Policy mu Std                   3.11991\n",
      "trainer/Policy log std Mean            -2.36606\n",
      "trainer/Policy log std Std              1.2972\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        127913\n",
      "exploration/num paths total          1267\n",
      "evaluation/num steps total         368022\n",
      "evaluation/num paths total           1234\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31538\n",
      "evaluation/Rewards Std                  0.0830813\n",
      "evaluation/Rewards Max                  5.51071\n",
      "evaluation/Rewards Min                  4.80186\n",
      "evaluation/Returns Mean              5315.38\n",
      "evaluation/Returns Std                  4.72481\n",
      "evaluation/Returns Max               5322.34\n",
      "evaluation/Returns Min               5307.53\n",
      "evaluation/Estimation Bias Mean      1660.65\n",
      "evaluation/Estimation Bias Std        164.99\n",
      "evaluation/EB/Q_True Mean              48.0471\n",
      "evaluation/EB/Q_True Std              147.983\n",
      "evaluation/EB/Q_Pred Mean            1708.69\n",
      "evaluation/EB/Q_Pred Std               60.5088\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5315.38\n",
      "evaluation/Actions Mean                 0.0875752\n",
      "evaluation/Actions Std                  0.533312\n",
      "evaluation/Actions Max                  0.999887\n",
      "evaluation/Actions Min                 -0.998968\n",
      "time/backward_policy (s)                1.84894\n",
      "time/backward_zf1 (s)                   2.2835\n",
      "time/backward_zf2 (s)                   2.19409\n",
      "time/data sampling (s)                  0.330627\n",
      "time/data storing (s)                   0.0151739\n",
      "time/evaluation sampling (s)            2.42098\n",
      "time/exploration sampling (s)           0.476444\n",
      "time/logging (s)                        0.013667\n",
      "time/preback_alpha (s)                  0.58102\n",
      "time/preback_policy (s)                 1.07326\n",
      "time/preback_start (s)                  0.181512\n",
      "time/preback_zf (s)                     6.67221\n",
      "time/saving (s)                         3.385e-06\n",
      "time/training (s)                       3.41151\n",
      "time/epoch (s)                         21.5029\n",
      "time/total (s)                       2413.99\n",
      "Epoch                                 120\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:05:59.236653 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 121 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 132000\n",
      "trainer/ZF1 Loss                      288.744\n",
      "trainer/ZF2 Loss                      330.518\n",
      "trainer/ZF Expert Reward               14.4044\n",
      "trainer/ZF Policy Reward               -0.511507\n",
      "trainer/ZF CHI2 Term                  306.466\n",
      "trainer/Policy Loss                 -1047.85\n",
      "trainer/Bias Loss                      28.9265\n",
      "trainer/Bias Value                     17.9263\n",
      "trainer/Policy Grad Norm              216.715\n",
      "trainer/Policy Param Norm              47.3115\n",
      "trainer/Zf1 Grad Norm               25721.2\n",
      "trainer/Zf1 Param Norm                111.122\n",
      "trainer/Zf2 Grad Norm               41538.9\n",
      "trainer/Zf2 Param Norm                109.765\n",
      "trainer/Z Expert Predictions Mean    1752.75\n",
      "trainer/Z Expert Predictions Std      120.69\n",
      "trainer/Z Expert Predictions Max     1835.15\n",
      "trainer/Z Expert Predictions Min       36.6191\n",
      "trainer/Z Policy Predictions Mean    1026.86\n",
      "trainer/Z Policy Predictions Std      607.141\n",
      "trainer/Z Policy Predictions Max     1765.83\n",
      "trainer/Z Policy Predictions Min       -8.32322\n",
      "trainer/Z Expert Targets Mean        1738.35\n",
      "trainer/Z Expert Targets Std          123.045\n",
      "trainer/Z Expert Targets Max         1816.14\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1027.37\n",
      "trainer/Z Policy Targets Std          609.209\n",
      "trainer/Z Policy Targets Max         1760.29\n",
      "trainer/Z Policy Targets Min          -17.8995\n",
      "trainer/Log Pis Mean                   59.3129\n",
      "trainer/Log Pis Std                    23.7569\n",
      "trainer/Policy mu Mean                  0.24772\n",
      "trainer/Policy mu Std                   2.90418\n",
      "trainer/Policy log std Mean            -2.45098\n",
      "trainer/Policy log std Std              1.24833\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        128158\n",
      "exploration/num paths total          1268\n",
      "evaluation/num steps total         376627\n",
      "evaluation/num paths total           1244\n",
      "evaluation/path length Mean           860.5\n",
      "evaluation/path length Std            292.378\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            107\n",
      "evaluation/Rewards Mean                 5.30251\n",
      "evaluation/Rewards Std                  0.108688\n",
      "evaluation/Rewards Max                  6.49436\n",
      "evaluation/Rewards Min                  4.77479\n",
      "evaluation/Returns Mean              4562.81\n",
      "evaluation/Returns Std               1558.93\n",
      "evaluation/Returns Max               5319.08\n",
      "evaluation/Returns Min                555.369\n",
      "evaluation/Estimation Bias Mean      1631.43\n",
      "evaluation/Estimation Bias Std        354.359\n",
      "evaluation/EB/Q_True Mean              55.6581\n",
      "evaluation/EB/Q_True Std              157.588\n",
      "evaluation/EB/Q_Pred Mean            1687.08\n",
      "evaluation/EB/Q_Pred Std              231.619\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4562.81\n",
      "evaluation/Actions Mean                 0.0891396\n",
      "evaluation/Actions Std                  0.536494\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.72606\n",
      "time/backward_zf1 (s)                   2.13354\n",
      "time/backward_zf2 (s)                   2.04541\n",
      "time/data sampling (s)                  0.347481\n",
      "time/data storing (s)                   0.014719\n",
      "time/evaluation sampling (s)            2.29315\n",
      "time/exploration sampling (s)           0.474829\n",
      "time/logging (s)                        0.0109982\n",
      "time/preback_alpha (s)                  0.569908\n",
      "time/preback_policy (s)                 0.947462\n",
      "time/preback_start (s)                  0.17482\n",
      "time/preback_zf (s)                     6.61473\n",
      "time/saving (s)                         3.528e-06\n",
      "time/training (s)                       3.80207\n",
      "time/epoch (s)                         21.1552\n",
      "time/total (s)                       2435.18\n",
      "Epoch                                 121\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:06:20.699320 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 122 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 133000\n",
      "trainer/ZF1 Loss                      272.57\n",
      "trainer/ZF2 Loss                      277.581\n",
      "trainer/ZF Expert Reward               17.8319\n",
      "trainer/ZF Policy Reward                6.03549\n",
      "trainer/ZF CHI2 Term                  275.073\n",
      "trainer/Policy Loss                 -1111.48\n",
      "trainer/Bias Loss                      23.7695\n",
      "trainer/Bias Value                     17.9232\n",
      "trainer/Policy Grad Norm              199.72\n",
      "trainer/Policy Param Norm              47.4171\n",
      "trainer/Zf1 Grad Norm               30612\n",
      "trainer/Zf1 Param Norm                111.6\n",
      "trainer/Zf2 Grad Norm               33048.4\n",
      "trainer/Zf2 Param Norm                110.225\n",
      "trainer/Z Expert Predictions Mean    1784.64\n",
      "trainer/Z Expert Predictions Std       37.6215\n",
      "trainer/Z Expert Predictions Max     1846.06\n",
      "trainer/Z Expert Predictions Min     1670.03\n",
      "trainer/Z Policy Predictions Mean    1099.65\n",
      "trainer/Z Policy Predictions Std      610.663\n",
      "trainer/Z Policy Predictions Max     1812.43\n",
      "trainer/Z Policy Predictions Min        5.42043\n",
      "trainer/Z Expert Targets Mean        1766.8\n",
      "trainer/Z Expert Targets Std           37.1309\n",
      "trainer/Z Expert Targets Max         1830.99\n",
      "trainer/Z Expert Targets Min         1650.27\n",
      "trainer/Z Policy Targets Mean        1093.62\n",
      "trainer/Z Policy Targets Std          608.683\n",
      "trainer/Z Policy Targets Max         1788.99\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   58.4189\n",
      "trainer/Log Pis Std                    24.0578\n",
      "trainer/Policy mu Mean                  0.351585\n",
      "trainer/Policy mu Std                   2.88942\n",
      "trainer/Policy log std Mean            -2.54811\n",
      "trainer/Policy log std Std              1.20444\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        128253\n",
      "exploration/num paths total          1269\n",
      "evaluation/num steps total         384285\n",
      "evaluation/num paths total           1254\n",
      "evaluation/path length Mean           765.8\n",
      "evaluation/path length Std            367.294\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            105\n",
      "evaluation/Rewards Mean                 5.28812\n",
      "evaluation/Rewards Std                  0.125071\n",
      "evaluation/Rewards Max                  6.0054\n",
      "evaluation/Rewards Min                  4.05351\n",
      "evaluation/Returns Mean              4049.64\n",
      "evaluation/Returns Std               1949.8\n",
      "evaluation/Returns Max               5300.98\n",
      "evaluation/Returns Min                561.961\n",
      "evaluation/Estimation Bias Mean      1616.63\n",
      "evaluation/Estimation Bias Std        374.511\n",
      "evaluation/EB/Q_True Mean              62.3813\n",
      "evaluation/EB/Q_True Std              165.461\n",
      "evaluation/EB/Q_Pred Mean            1679.01\n",
      "evaluation/EB/Q_Pred Std              254.621\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4049.64\n",
      "evaluation/Actions Mean                 0.0788098\n",
      "evaluation/Actions Std                  0.522659\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80259\n",
      "time/backward_zf1 (s)                   2.22231\n",
      "time/backward_zf2 (s)                   2.13598\n",
      "time/data sampling (s)                  0.372063\n",
      "time/data storing (s)                   0.0146018\n",
      "time/evaluation sampling (s)            2.28589\n",
      "time/exploration sampling (s)           0.483687\n",
      "time/logging (s)                        0.0128294\n",
      "time/preback_alpha (s)                  0.589313\n",
      "time/preback_policy (s)                 1.0461\n",
      "time/preback_start (s)                  0.179468\n",
      "time/preback_zf (s)                     6.68704\n",
      "time/saving (s)                         4.368e-06\n",
      "time/training (s)                       3.56895\n",
      "time/epoch (s)                         21.4008\n",
      "time/total (s)                       2456.59\n",
      "Epoch                                 122\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:06:40.591656 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 123 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 134000\n",
      "trainer/ZF1 Loss                      254.913\n",
      "trainer/ZF2 Loss                      288.76\n",
      "trainer/ZF Expert Reward               19.0169\n",
      "trainer/ZF Policy Reward                9.32722\n",
      "trainer/ZF CHI2 Term                  272.985\n",
      "trainer/Policy Loss                 -1050.3\n",
      "trainer/Bias Loss                      28.9608\n",
      "trainer/Bias Value                     17.9172\n",
      "trainer/Policy Grad Norm              252.608\n",
      "trainer/Policy Param Norm              47.5338\n",
      "trainer/Zf1 Grad Norm               19176.4\n",
      "trainer/Zf1 Param Norm                112.074\n",
      "trainer/Zf2 Grad Norm               23647\n",
      "trainer/Zf2 Param Norm                110.708\n",
      "trainer/Z Expert Predictions Mean    1790.76\n",
      "trainer/Z Expert Predictions Std       42.109\n",
      "trainer/Z Expert Predictions Max     1863.27\n",
      "trainer/Z Expert Predictions Min     1678.41\n",
      "trainer/Z Policy Predictions Mean    1038.68\n",
      "trainer/Z Policy Predictions Std      661.594\n",
      "trainer/Z Policy Predictions Max     1810.95\n",
      "trainer/Z Policy Predictions Min      -25.2586\n",
      "trainer/Z Expert Targets Mean        1771.74\n",
      "trainer/Z Expert Targets Std           41.1902\n",
      "trainer/Z Expert Targets Max         1843.87\n",
      "trainer/Z Expert Targets Min         1664.08\n",
      "trainer/Z Policy Targets Mean        1029.35\n",
      "trainer/Z Policy Targets Std          659.892\n",
      "trainer/Z Policy Targets Max         1781.86\n",
      "trainer/Z Policy Targets Min          -23.1285\n",
      "trainer/Log Pis Mean                   59.7089\n",
      "trainer/Log Pis Std                    24.9707\n",
      "trainer/Policy mu Mean                  0.28108\n",
      "trainer/Policy mu Std                   3.27402\n",
      "trainer/Policy log std Mean            -2.41159\n",
      "trainer/Policy log std Std              1.30721\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        129253\n",
      "exploration/num paths total          1270\n",
      "evaluation/num steps total         385918\n",
      "evaluation/num paths total           1264\n",
      "evaluation/path length Mean           163.3\n",
      "evaluation/path length Std             83.7783\n",
      "evaluation/path length Max            353\n",
      "evaluation/path length Min             74\n",
      "evaluation/Rewards Mean                 5.23798\n",
      "evaluation/Rewards Std                  0.371353\n",
      "evaluation/Rewards Max                  6.7276\n",
      "evaluation/Rewards Min                  3.71335\n",
      "evaluation/Returns Mean               855.362\n",
      "evaluation/Returns Std                448.599\n",
      "evaluation/Returns Max               1867.24\n",
      "evaluation/Returns Min                378.7\n",
      "evaluation/Estimation Bias Mean       955.617\n",
      "evaluation/Estimation Bias Std        654.75\n",
      "evaluation/EB/Q_True Mean              83.9308\n",
      "evaluation/EB/Q_True Std              170.97\n",
      "evaluation/EB/Q_Pred Mean            1039.55\n",
      "evaluation/EB/Q_Pred Std              631.893\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            855.362\n",
      "evaluation/Actions Mean                 0.119115\n",
      "evaluation/Actions Std                  0.697721\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.6981\n",
      "time/backward_zf1 (s)                   2.11851\n",
      "time/backward_zf2 (s)                   2.03455\n",
      "time/data sampling (s)                  0.377301\n",
      "time/data storing (s)                   0.0147534\n",
      "time/evaluation sampling (s)            0.909249\n",
      "time/exploration sampling (s)           0.494568\n",
      "time/logging (s)                        0.00321593\n",
      "time/preback_alpha (s)                  0.576992\n",
      "time/preback_policy (s)                 0.965552\n",
      "time/preback_start (s)                  0.174158\n",
      "time/preback_zf (s)                     6.67745\n",
      "time/saving (s)                         3.99e-06\n",
      "time/training (s)                       3.7748\n",
      "time/epoch (s)                         19.8192\n",
      "time/total (s)                       2476.43\n",
      "Epoch                                 123\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:07:02.027442 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 124 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 135000\n",
      "trainer/ZF1 Loss                      271.728\n",
      "trainer/ZF2 Loss                      383.166\n",
      "trainer/ZF Expert Reward               17.6806\n",
      "trainer/ZF Policy Reward                6.61022\n",
      "trainer/ZF CHI2 Term                  326.986\n",
      "trainer/Policy Loss                 -1083.39\n",
      "trainer/Bias Loss                      20.9764\n",
      "trainer/Bias Value                     17.9051\n",
      "trainer/Policy Grad Norm              272.361\n",
      "trainer/Policy Param Norm              47.6376\n",
      "trainer/Zf1 Grad Norm               31812\n",
      "trainer/Zf1 Param Norm                112.572\n",
      "trainer/Zf2 Grad Norm               35793.2\n",
      "trainer/Zf2 Param Norm                111.195\n",
      "trainer/Z Expert Predictions Mean    1813.7\n",
      "trainer/Z Expert Predictions Std       53.6772\n",
      "trainer/Z Expert Predictions Max     1873.2\n",
      "trainer/Z Expert Predictions Min     1206.81\n",
      "trainer/Z Policy Predictions Mean    1067.24\n",
      "trainer/Z Policy Predictions Std      639.136\n",
      "trainer/Z Policy Predictions Max     1823.78\n",
      "trainer/Z Policy Predictions Min        7.87886\n",
      "trainer/Z Expert Targets Mean        1796.02\n",
      "trainer/Z Expert Targets Std           53.8019\n",
      "trainer/Z Expert Targets Max         1863.91\n",
      "trainer/Z Expert Targets Min         1173.87\n",
      "trainer/Z Policy Targets Mean        1060.63\n",
      "trainer/Z Policy Targets Std          638.044\n",
      "trainer/Z Policy Targets Max         1793.4\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   58.803\n",
      "trainer/Log Pis Std                    26.4863\n",
      "trainer/Policy mu Mean                  0.365687\n",
      "trainer/Policy mu Std                   3.10377\n",
      "trainer/Policy log std Mean            -2.40528\n",
      "trainer/Policy log std Std              1.24769\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        129979\n",
      "exploration/num paths total          1271\n",
      "evaluation/num steps total         389290\n",
      "evaluation/num paths total           1274\n",
      "evaluation/path length Mean           337.2\n",
      "evaluation/path length Std            283.305\n",
      "evaluation/path length Max            869\n",
      "evaluation/path length Min             82\n",
      "evaluation/Rewards Mean                 5.23686\n",
      "evaluation/Rewards Std                  0.244169\n",
      "evaluation/Rewards Max                  6.60753\n",
      "evaluation/Rewards Min                  3.66793\n",
      "evaluation/Returns Mean              1765.87\n",
      "evaluation/Returns Std               1502.7\n",
      "evaluation/Returns Max               4590.08\n",
      "evaluation/Returns Min                397.836\n",
      "evaluation/Estimation Bias Mean      1347.22\n",
      "evaluation/Estimation Bias Std        577.951\n",
      "evaluation/EB/Q_True Mean             105.304\n",
      "evaluation/EB/Q_True Std              192.914\n",
      "evaluation/EB/Q_Pred Mean            1452.52\n",
      "evaluation/EB/Q_Pred Std              500.155\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1765.87\n",
      "evaluation/Actions Mean                 0.0945528\n",
      "evaluation/Actions Std                  0.609041\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.81412\n",
      "time/backward_zf1 (s)                   2.20836\n",
      "time/backward_zf2 (s)                   2.13628\n",
      "time/data sampling (s)                  0.34448\n",
      "time/data storing (s)                   0.0147099\n",
      "time/evaluation sampling (s)            2.42282\n",
      "time/exploration sampling (s)           0.487716\n",
      "time/logging (s)                        0.00620119\n",
      "time/preback_alpha (s)                  0.571989\n",
      "time/preback_policy (s)                 1.03712\n",
      "time/preback_start (s)                  0.179296\n",
      "time/preback_zf (s)                     6.63329\n",
      "time/saving (s)                         2.925e-06\n",
      "time/training (s)                       3.52073\n",
      "time/epoch (s)                         21.3771\n",
      "time/total (s)                       2497.82\n",
      "Epoch                                 124\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:07:23.521103 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 125 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 136000\n",
      "trainer/ZF1 Loss                      238.126\n",
      "trainer/ZF2 Loss                      259.733\n",
      "trainer/ZF Expert Reward               15.0254\n",
      "trainer/ZF Policy Reward                6.35951\n",
      "trainer/ZF CHI2 Term                  245.812\n",
      "trainer/Policy Loss                 -1069.72\n",
      "trainer/Bias Loss                      25.0777\n",
      "trainer/Bias Value                     17.897\n",
      "trainer/Policy Grad Norm              187.3\n",
      "trainer/Policy Param Norm              47.7471\n",
      "trainer/Zf1 Grad Norm               24060.5\n",
      "trainer/Zf1 Param Norm                113.038\n",
      "trainer/Zf2 Grad Norm               21560.8\n",
      "trainer/Zf2 Param Norm                111.643\n",
      "trainer/Z Expert Predictions Mean    1816.14\n",
      "trainer/Z Expert Predictions Std       41.7631\n",
      "trainer/Z Expert Predictions Max     1886.03\n",
      "trainer/Z Expert Predictions Min     1679.59\n",
      "trainer/Z Policy Predictions Mean    1058.44\n",
      "trainer/Z Policy Predictions Std      657.408\n",
      "trainer/Z Policy Predictions Max     1819.9\n",
      "trainer/Z Policy Predictions Min      -11.596\n",
      "trainer/Z Expert Targets Mean        1801.11\n",
      "trainer/Z Expert Targets Std           40.9682\n",
      "trainer/Z Expert Targets Max         1870.56\n",
      "trainer/Z Expert Targets Min         1679.53\n",
      "trainer/Z Policy Targets Mean        1052.08\n",
      "trainer/Z Policy Targets Std          656.714\n",
      "trainer/Z Policy Targets Max         1821.4\n",
      "trainer/Z Policy Targets Min           -5.48689\n",
      "trainer/Log Pis Mean                   60.848\n",
      "trainer/Log Pis Std                    28.2436\n",
      "trainer/Policy mu Mean                  0.249567\n",
      "trainer/Policy mu Std                   3.33746\n",
      "trainer/Policy log std Mean            -2.36889\n",
      "trainer/Policy log std Std              1.32807\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        129979\n",
      "exploration/num paths total          1271\n",
      "evaluation/num steps total         397164\n",
      "evaluation/num paths total           1284\n",
      "evaluation/path length Mean           787.4\n",
      "evaluation/path length Std            189.083\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            434\n",
      "evaluation/Rewards Mean                 5.27143\n",
      "evaluation/Rewards Std                  0.141707\n",
      "evaluation/Rewards Max                  6.3577\n",
      "evaluation/Rewards Min                  4.43008\n",
      "evaluation/Returns Mean              4150.73\n",
      "evaluation/Returns Std               1003.51\n",
      "evaluation/Returns Max               5287.76\n",
      "evaluation/Returns Min               2294.19\n",
      "evaluation/Estimation Bias Mean      1600.99\n",
      "evaluation/Estimation Bias Std        408.629\n",
      "evaluation/EB/Q_True Mean              60.6191\n",
      "evaluation/EB/Q_True Std              163.274\n",
      "evaluation/EB/Q_Pred Mean            1661.61\n",
      "evaluation/EB/Q_Pred Std              360.454\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4150.73\n",
      "evaluation/Actions Mean                 0.0873205\n",
      "evaluation/Actions Std                  0.540491\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73368\n",
      "time/backward_zf1 (s)                   2.14176\n",
      "time/backward_zf2 (s)                   2.04178\n",
      "time/data sampling (s)                  0.315857\n",
      "time/data storing (s)                   0.0143327\n",
      "time/evaluation sampling (s)            2.63374\n",
      "time/exploration sampling (s)           0.482567\n",
      "time/logging (s)                        0.0111533\n",
      "time/preback_alpha (s)                  0.568488\n",
      "time/preback_policy (s)                 0.961056\n",
      "time/preback_start (s)                  0.172348\n",
      "time/preback_zf (s)                     6.6259\n",
      "time/saving (s)                         3.397e-06\n",
      "time/training (s)                       3.7152\n",
      "time/epoch (s)                         21.4179\n",
      "time/total (s)                       2519.27\n",
      "Epoch                                 125\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:07:44.882943 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 126 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 137000\n",
      "trainer/ZF1 Loss                      362.164\n",
      "trainer/ZF2 Loss                      303.97\n",
      "trainer/ZF Expert Reward               15.7731\n",
      "trainer/ZF Policy Reward               12.3561\n",
      "trainer/ZF CHI2 Term                  330.516\n",
      "trainer/Policy Loss                 -1110.28\n",
      "trainer/Bias Loss                      20.9349\n",
      "trainer/Bias Value                     17.8857\n",
      "trainer/Policy Grad Norm              216.666\n",
      "trainer/Policy Param Norm              47.8592\n",
      "trainer/Zf1 Grad Norm               31848.2\n",
      "trainer/Zf1 Param Norm                113.533\n",
      "trainer/Zf2 Grad Norm               20763.3\n",
      "trainer/Zf2 Param Norm                112.122\n",
      "trainer/Z Expert Predictions Mean    1831.6\n",
      "trainer/Z Expert Predictions Std       39.7794\n",
      "trainer/Z Expert Predictions Max     1896.51\n",
      "trainer/Z Expert Predictions Min     1692.64\n",
      "trainer/Z Policy Predictions Mean    1096.3\n",
      "trainer/Z Policy Predictions Std      652.236\n",
      "trainer/Z Policy Predictions Max     1836.85\n",
      "trainer/Z Policy Predictions Min       -3.75826\n",
      "trainer/Z Expert Targets Mean        1815.83\n",
      "trainer/Z Expert Targets Std           38.6638\n",
      "trainer/Z Expert Targets Max         1881.7\n",
      "trainer/Z Expert Targets Min         1679.98\n",
      "trainer/Z Policy Targets Mean        1083.94\n",
      "trainer/Z Policy Targets Std          652.271\n",
      "trainer/Z Policy Targets Max         1826.33\n",
      "trainer/Z Policy Targets Min           -3.49627\n",
      "trainer/Log Pis Mean                   59.0402\n",
      "trainer/Log Pis Std                    25.9669\n",
      "trainer/Policy mu Mean                  0.210246\n",
      "trainer/Policy mu Std                   3.29751\n",
      "trainer/Policy log std Mean            -2.45435\n",
      "trainer/Policy log std Std              1.309\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        131193\n",
      "exploration/num paths total          1273\n",
      "evaluation/num steps total         406704\n",
      "evaluation/num paths total           1294\n",
      "evaluation/path length Mean           954\n",
      "evaluation/path length Std            138\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            540\n",
      "evaluation/Rewards Mean                 5.31629\n",
      "evaluation/Rewards Std                  0.101872\n",
      "evaluation/Rewards Max                  6.39937\n",
      "evaluation/Rewards Min                  4.79261\n",
      "evaluation/Returns Mean              5071.74\n",
      "evaluation/Returns Std                736.764\n",
      "evaluation/Returns Max               5335.4\n",
      "evaluation/Returns Min               2861.71\n",
      "evaluation/Estimation Bias Mean      1696.94\n",
      "evaluation/Estimation Bias Std        308.423\n",
      "evaluation/EB/Q_True Mean              50.2793\n",
      "evaluation/EB/Q_True Std              150.845\n",
      "evaluation/EB/Q_Pred Mean            1747.22\n",
      "evaluation/EB/Q_Pred Std              211.167\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5071.74\n",
      "evaluation/Actions Mean                 0.0786518\n",
      "evaluation/Actions Std                  0.517267\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.73472\n",
      "time/backward_zf1 (s)                   2.15648\n",
      "time/backward_zf2 (s)                   2.06799\n",
      "time/data sampling (s)                  0.368507\n",
      "time/data storing (s)                   0.0152344\n",
      "time/evaluation sampling (s)            2.30852\n",
      "time/exploration sampling (s)           0.492527\n",
      "time/logging (s)                        0.0136966\n",
      "time/preback_alpha (s)                  0.578748\n",
      "time/preback_policy (s)                 0.96897\n",
      "time/preback_start (s)                  0.177818\n",
      "time/preback_zf (s)                     6.67705\n",
      "time/saving (s)                         3.505e-06\n",
      "time/training (s)                       3.73718\n",
      "time/epoch (s)                         21.2974\n",
      "time/total (s)                       2540.59\n",
      "Epoch                                 126\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:08:06.532510 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 127 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 138000\n",
      "trainer/ZF1 Loss                      291.678\n",
      "trainer/ZF2 Loss                      268.476\n",
      "trainer/ZF Expert Reward               14.2312\n",
      "trainer/ZF Policy Reward                4.56347\n",
      "trainer/ZF CHI2 Term                  275.901\n",
      "trainer/Policy Loss                 -1136.63\n",
      "trainer/Bias Loss                      61.5105\n",
      "trainer/Bias Value                     17.873\n",
      "trainer/Policy Grad Norm              239.837\n",
      "trainer/Policy Param Norm              47.9587\n",
      "trainer/Zf1 Grad Norm               24851.5\n",
      "trainer/Zf1 Param Norm                114.008\n",
      "trainer/Zf2 Grad Norm               24234\n",
      "trainer/Zf2 Param Norm                112.591\n",
      "trainer/Z Expert Predictions Mean    1835.64\n",
      "trainer/Z Expert Predictions Std      122.463\n",
      "trainer/Z Expert Predictions Max     1917.78\n",
      "trainer/Z Expert Predictions Min       -1.86666\n",
      "trainer/Z Policy Predictions Mean    1114.32\n",
      "trainer/Z Policy Predictions Std      621.418\n",
      "trainer/Z Policy Predictions Max     1844.01\n",
      "trainer/Z Policy Predictions Min      -11.608\n",
      "trainer/Z Expert Targets Mean        1821.4\n",
      "trainer/Z Expert Targets Std          122.004\n",
      "trainer/Z Expert Targets Max         1898.73\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1109.75\n",
      "trainer/Z Policy Targets Std          623.089\n",
      "trainer/Z Policy Targets Max         1824.9\n",
      "trainer/Z Policy Targets Min          -11.4889\n",
      "trainer/Log Pis Mean                   59.0383\n",
      "trainer/Log Pis Std                    26.3337\n",
      "trainer/Policy mu Mean                  0.39344\n",
      "trainer/Policy mu Std                   3.31279\n",
      "trainer/Policy log std Mean            -2.43737\n",
      "trainer/Policy log std Std              1.28988\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        132193\n",
      "exploration/num paths total          1274\n",
      "evaluation/num steps total         416704\n",
      "evaluation/num paths total           1304\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.28159\n",
      "evaluation/Rewards Std                  0.0825033\n",
      "evaluation/Rewards Max                  5.50793\n",
      "evaluation/Rewards Min                  4.80615\n",
      "evaluation/Returns Mean              5281.59\n",
      "evaluation/Returns Std                 14.3285\n",
      "evaluation/Returns Max               5296.15\n",
      "evaluation/Returns Min               5254.99\n",
      "evaluation/Estimation Bias Mean      1723.02\n",
      "evaluation/Estimation Bias Std        175.7\n",
      "evaluation/EB/Q_True Mean              47.5698\n",
      "evaluation/EB/Q_True Std              146.527\n",
      "evaluation/EB/Q_Pred Mean            1770.59\n",
      "evaluation/EB/Q_Pred Std              100.223\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5281.59\n",
      "evaluation/Actions Mean                 0.0821431\n",
      "evaluation/Actions Std                  0.529917\n",
      "evaluation/Actions Max                  0.999939\n",
      "evaluation/Actions Min                 -0.999412\n",
      "time/backward_policy (s)                1.75382\n",
      "time/backward_zf1 (s)                   2.19626\n",
      "time/backward_zf2 (s)                   2.10259\n",
      "time/data sampling (s)                  0.377275\n",
      "time/data storing (s)                   0.0154094\n",
      "time/evaluation sampling (s)            2.52205\n",
      "time/exploration sampling (s)           0.504257\n",
      "time/logging (s)                        0.013005\n",
      "time/preback_alpha (s)                  0.577813\n",
      "time/preback_policy (s)                 0.970204\n",
      "time/preback_start (s)                  0.175425\n",
      "time/preback_zf (s)                     6.6341\n",
      "time/saving (s)                         2.957e-06\n",
      "time/training (s)                       3.7402\n",
      "time/epoch (s)                         21.5824\n",
      "time/total (s)                       2562.19\n",
      "Epoch                                 127\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:08:27.967650 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 128 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 139000\n",
      "trainer/ZF1 Loss                      459.82\n",
      "trainer/ZF2 Loss                      372.799\n",
      "trainer/ZF Expert Reward               12.6346\n",
      "trainer/ZF Policy Reward                0.359456\n",
      "trainer/ZF CHI2 Term                  410.43\n",
      "trainer/Policy Loss                 -1095.87\n",
      "trainer/Bias Loss                      47.5936\n",
      "trainer/Bias Value                     17.8579\n",
      "trainer/Policy Grad Norm              195.104\n",
      "trainer/Policy Param Norm              48.0562\n",
      "trainer/Zf1 Grad Norm               43485.1\n",
      "trainer/Zf1 Param Norm                114.483\n",
      "trainer/Zf2 Grad Norm               29479.7\n",
      "trainer/Zf2 Param Norm                113.054\n",
      "trainer/Z Expert Predictions Mean    1844.91\n",
      "trainer/Z Expert Predictions Std      123.181\n",
      "trainer/Z Expert Predictions Max     1920.36\n",
      "trainer/Z Expert Predictions Min       -0.0221748\n",
      "trainer/Z Policy Predictions Mean    1076.9\n",
      "trainer/Z Policy Predictions Std      608.666\n",
      "trainer/Z Policy Predictions Max     1877.43\n",
      "trainer/Z Policy Predictions Min       -0.537786\n",
      "trainer/Z Expert Targets Mean        1832.28\n",
      "trainer/Z Expert Targets Std          122.341\n",
      "trainer/Z Expert Targets Max         1904.68\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1076.54\n",
      "trainer/Z Policy Targets Std          606.111\n",
      "trainer/Z Policy Targets Max         1839.91\n",
      "trainer/Z Policy Targets Min          -10.0811\n",
      "trainer/Log Pis Mean                   61.3259\n",
      "trainer/Log Pis Std                    27.5408\n",
      "trainer/Policy mu Mean                  0.410589\n",
      "trainer/Policy mu Std                   3.37552\n",
      "trainer/Policy log std Mean            -2.40107\n",
      "trainer/Policy log std Std              1.2738\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        135119\n",
      "exploration/num paths total          1277\n",
      "evaluation/num steps total         424897\n",
      "evaluation/num paths total           1314\n",
      "evaluation/path length Mean           819.3\n",
      "evaluation/path length Std            361.425\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             87\n",
      "evaluation/Rewards Mean                 5.29266\n",
      "evaluation/Rewards Std                  0.0898845\n",
      "evaluation/Rewards Max                  5.85868\n",
      "evaluation/Rewards Min                  4.59357\n",
      "evaluation/Returns Mean              4336.28\n",
      "evaluation/Returns Std               1919.06\n",
      "evaluation/Returns Max               5311.23\n",
      "evaluation/Returns Min                434.168\n",
      "evaluation/Estimation Bias Mean      1742.41\n",
      "evaluation/Estimation Bias Std        286.198\n",
      "evaluation/EB/Q_True Mean              58.2785\n",
      "evaluation/EB/Q_True Std              160.541\n",
      "evaluation/EB/Q_Pred Mean            1800.69\n",
      "evaluation/EB/Q_Pred Std              187.455\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4336.28\n",
      "evaluation/Actions Mean                 0.079014\n",
      "evaluation/Actions Std                  0.490856\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92146\n",
      "time/backward_zf1 (s)                   2.36193\n",
      "time/backward_zf2 (s)                   2.28996\n",
      "time/data sampling (s)                  0.368895\n",
      "time/data storing (s)                   0.0149868\n",
      "time/evaluation sampling (s)            2.2649\n",
      "time/exploration sampling (s)           0.498068\n",
      "time/logging (s)                        0.0114897\n",
      "time/preback_alpha (s)                  0.582092\n",
      "time/preback_policy (s)                 1.1808\n",
      "time/preback_start (s)                  0.178695\n",
      "time/preback_zf (s)                     6.66708\n",
      "time/saving (s)                         2.92101e-06\n",
      "time/training (s)                       3.02659\n",
      "time/epoch (s)                         21.3669\n",
      "time/total (s)                       2583.58\n",
      "Epoch                                 128\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:08:48.932801 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 129 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 140000\n",
      "trainer/ZF1 Loss                      324.522\n",
      "trainer/ZF2 Loss                      321.767\n",
      "trainer/ZF Expert Reward               14.4122\n",
      "trainer/ZF Policy Reward                6.95801\n",
      "trainer/ZF CHI2 Term                  318.909\n",
      "trainer/Policy Loss                 -1174.55\n",
      "trainer/Bias Loss                      54.78\n",
      "trainer/Bias Value                     17.8433\n",
      "trainer/Policy Grad Norm              251.154\n",
      "trainer/Policy Param Norm              48.1384\n",
      "trainer/Zf1 Grad Norm               29957.7\n",
      "trainer/Zf1 Param Norm                114.951\n",
      "trainer/Zf2 Grad Norm               33519.8\n",
      "trainer/Zf2 Param Norm                113.499\n",
      "trainer/Z Expert Predictions Mean    1862.93\n",
      "trainer/Z Expert Predictions Std       52.5878\n",
      "trainer/Z Expert Predictions Max     1936.46\n",
      "trainer/Z Expert Predictions Min     1322.81\n",
      "trainer/Z Policy Predictions Mean    1160.92\n",
      "trainer/Z Policy Predictions Std      663.705\n",
      "trainer/Z Policy Predictions Max     1883.76\n",
      "trainer/Z Policy Predictions Min       10.6403\n",
      "trainer/Z Expert Targets Mean        1848.52\n",
      "trainer/Z Expert Targets Std           51.9038\n",
      "trainer/Z Expert Targets Max         1923.46\n",
      "trainer/Z Expert Targets Min         1311.56\n",
      "trainer/Z Policy Targets Mean        1153.96\n",
      "trainer/Z Policy Targets Std          663.662\n",
      "trainer/Z Policy Targets Max         1875.71\n",
      "trainer/Z Policy Targets Min           -1.15765\n",
      "trainer/Log Pis Mean                   56.8263\n",
      "trainer/Log Pis Std                    23.6543\n",
      "trainer/Policy mu Mean                  0.352044\n",
      "trainer/Policy mu Std                   2.93489\n",
      "trainer/Policy log std Mean            -2.4812\n",
      "trainer/Policy log std Std              1.28473\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        136119\n",
      "exploration/num paths total          1278\n",
      "evaluation/num steps total         427908\n",
      "evaluation/num paths total           1324\n",
      "evaluation/path length Mean           301.1\n",
      "evaluation/path length Std            132.564\n",
      "evaluation/path length Max            521\n",
      "evaluation/path length Min            147\n",
      "evaluation/Rewards Mean                 5.20489\n",
      "evaluation/Rewards Std                  0.329119\n",
      "evaluation/Rewards Max                  6.60826\n",
      "evaluation/Rewards Min                  3.07931\n",
      "evaluation/Returns Mean              1567.19\n",
      "evaluation/Returns Std                722.267\n",
      "evaluation/Returns Max               2751.11\n",
      "evaluation/Returns Min                673.116\n",
      "evaluation/Estimation Bias Mean      1323.34\n",
      "evaluation/Estimation Bias Std        615.872\n",
      "evaluation/EB/Q_True Mean              74.4113\n",
      "evaluation/EB/Q_True Std              171.11\n",
      "evaluation/EB/Q_Pred Mean            1397.75\n",
      "evaluation/EB/Q_Pred Std              566.553\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1567.19\n",
      "evaluation/Actions Mean                 0.121311\n",
      "evaluation/Actions Std                  0.622049\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.06299\n",
      "time/backward_zf1 (s)                   2.48525\n",
      "time/backward_zf2 (s)                   2.43405\n",
      "time/data sampling (s)                  0.393681\n",
      "time/data storing (s)                   0.0149535\n",
      "time/evaluation sampling (s)            1.26349\n",
      "time/exploration sampling (s)           0.493532\n",
      "time/logging (s)                        0.00517005\n",
      "time/preback_alpha (s)                  0.596749\n",
      "time/preback_policy (s)                 1.2368\n",
      "time/preback_start (s)                  0.181649\n",
      "time/preback_zf (s)                     6.69471\n",
      "time/saving (s)                         3.591e-06\n",
      "time/training (s)                       3.02387\n",
      "time/epoch (s)                         20.8869\n",
      "time/total (s)                       2604.49\n",
      "Epoch                                 129\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:09:10.792169 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 130 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 141000\n",
      "trainer/ZF1 Loss                      312.616\n",
      "trainer/ZF2 Loss                      333.822\n",
      "trainer/ZF Expert Reward               20.7296\n",
      "trainer/ZF Policy Reward                7.41792\n",
      "trainer/ZF CHI2 Term                  325.147\n",
      "trainer/Policy Loss                 -1185.27\n",
      "trainer/Bias Loss                      43.6066\n",
      "trainer/Bias Value                     17.8247\n",
      "trainer/Policy Grad Norm              199.446\n",
      "trainer/Policy Param Norm              48.2248\n",
      "trainer/Zf1 Grad Norm               40053.3\n",
      "trainer/Zf1 Param Norm                115.431\n",
      "trainer/Zf2 Grad Norm               59160.4\n",
      "trainer/Zf2 Param Norm                113.973\n",
      "trainer/Z Expert Predictions Mean    1878.71\n",
      "trainer/Z Expert Predictions Std       53.1742\n",
      "trainer/Z Expert Predictions Max     1949.11\n",
      "trainer/Z Expert Predictions Min     1358.89\n",
      "trainer/Z Policy Predictions Mean    1160.03\n",
      "trainer/Z Policy Predictions Std      625.697\n",
      "trainer/Z Policy Predictions Max     1881.04\n",
      "trainer/Z Policy Predictions Min      -15.6686\n",
      "trainer/Z Expert Targets Mean        1857.98\n",
      "trainer/Z Expert Targets Std           55.303\n",
      "trainer/Z Expert Targets Max         1932.85\n",
      "trainer/Z Expert Targets Min         1343.2\n",
      "trainer/Z Policy Targets Mean        1152.61\n",
      "trainer/Z Policy Targets Std          623.115\n",
      "trainer/Z Policy Targets Max         1872.45\n",
      "trainer/Z Policy Targets Min          -32.3824\n",
      "trainer/Log Pis Mean                   61.2377\n",
      "trainer/Log Pis Std                    28.9266\n",
      "trainer/Policy mu Mean                  0.294939\n",
      "trainer/Policy mu Std                   3.08852\n",
      "trainer/Policy log std Mean            -2.56176\n",
      "trainer/Policy log std Std              1.1893\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        137119\n",
      "exploration/num paths total          1279\n",
      "evaluation/num steps total         430630\n",
      "evaluation/num paths total           1334\n",
      "evaluation/path length Mean           272.2\n",
      "evaluation/path length Std            118.733\n",
      "evaluation/path length Max            507\n",
      "evaluation/path length Min            127\n",
      "evaluation/Rewards Mean                 5.27463\n",
      "evaluation/Rewards Std                  0.265107\n",
      "evaluation/Rewards Max                  6.86943\n",
      "evaluation/Rewards Min                  4.12996\n",
      "evaluation/Returns Mean              1435.75\n",
      "evaluation/Returns Std                638.167\n",
      "evaluation/Returns Max               2709.88\n",
      "evaluation/Returns Min                656.168\n",
      "evaluation/Estimation Bias Mean      1351.45\n",
      "evaluation/Estimation Bias Std        629.054\n",
      "evaluation/EB/Q_True Mean              70.8354\n",
      "evaluation/EB/Q_True Std              162.252\n",
      "evaluation/EB/Q_Pred Mean            1422.28\n",
      "evaluation/EB/Q_Pred Std              576.898\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1435.75\n",
      "evaluation/Actions Mean                 0.106625\n",
      "evaluation/Actions Std                  0.629945\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99725\n",
      "time/backward_zf1 (s)                   2.43195\n",
      "time/backward_zf2 (s)                   2.39532\n",
      "time/data sampling (s)                  0.366173\n",
      "time/data storing (s)                   0.0148301\n",
      "time/evaluation sampling (s)            2.36416\n",
      "time/exploration sampling (s)           0.491314\n",
      "time/logging (s)                        0.00478001\n",
      "time/preback_alpha (s)                  0.588698\n",
      "time/preback_policy (s)                 1.21497\n",
      "time/preback_start (s)                  0.185929\n",
      "time/preback_zf (s)                     6.72104\n",
      "time/saving (s)                         3.577e-06\n",
      "time/training (s)                       3.01386\n",
      "time/epoch (s)                         21.7903\n",
      "time/total (s)                       2626.3\n",
      "Epoch                                 130\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:09:32.394556 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 131 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 142000\n",
      "trainer/ZF1 Loss                      309.641\n",
      "trainer/ZF2 Loss                      252.48\n",
      "trainer/ZF Expert Reward               21.5632\n",
      "trainer/ZF Policy Reward                4.43821\n",
      "trainer/ZF CHI2 Term                  283.579\n",
      "trainer/Policy Loss                 -1231.27\n",
      "trainer/Bias Loss                      30.6581\n",
      "trainer/Bias Value                     17.8044\n",
      "trainer/Policy Grad Norm              237.568\n",
      "trainer/Policy Param Norm              48.3241\n",
      "trainer/Zf1 Grad Norm               29323.4\n",
      "trainer/Zf1 Param Norm                115.913\n",
      "trainer/Zf2 Grad Norm               25521.6\n",
      "trainer/Zf2 Param Norm                114.43\n",
      "trainer/Z Expert Predictions Mean    1904.62\n",
      "trainer/Z Expert Predictions Std       39.5127\n",
      "trainer/Z Expert Predictions Max     1973.75\n",
      "trainer/Z Expert Predictions Min     1769.26\n",
      "trainer/Z Policy Predictions Mean    1213.6\n",
      "trainer/Z Policy Predictions Std      629.85\n",
      "trainer/Z Policy Predictions Max     1917.09\n",
      "trainer/Z Policy Predictions Min      -26.2219\n",
      "trainer/Z Expert Targets Mean        1883.06\n",
      "trainer/Z Expert Targets Std           40.9061\n",
      "trainer/Z Expert Targets Max         1960.09\n",
      "trainer/Z Expert Targets Min         1739.58\n",
      "trainer/Z Policy Targets Mean        1209.16\n",
      "trainer/Z Policy Targets Std          624.706\n",
      "trainer/Z Policy Targets Max         1896.54\n",
      "trainer/Z Policy Targets Min           -2.00432\n",
      "trainer/Log Pis Mean                   57.9336\n",
      "trainer/Log Pis Std                    23.4605\n",
      "trainer/Policy mu Mean                  0.393727\n",
      "trainer/Policy mu Std                   2.73857\n",
      "trainer/Policy log std Mean            -2.62415\n",
      "trainer/Policy log std Std              1.15232\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        137119\n",
      "exploration/num paths total          1279\n",
      "evaluation/num steps total         439399\n",
      "evaluation/num paths total           1344\n",
      "evaluation/path length Mean           876.9\n",
      "evaluation/path length Std            262.173\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            183\n",
      "evaluation/Rewards Mean                 5.32207\n",
      "evaluation/Rewards Std                  0.0925242\n",
      "evaluation/Rewards Max                  6.04365\n",
      "evaluation/Rewards Min                  4.80065\n",
      "evaluation/Returns Mean              4666.93\n",
      "evaluation/Returns Std               1399.24\n",
      "evaluation/Returns Max               5333.81\n",
      "evaluation/Returns Min                970.419\n",
      "evaluation/Estimation Bias Mean      1758.17\n",
      "evaluation/Estimation Bias Std        305.506\n",
      "evaluation/EB/Q_True Mean              54.8727\n",
      "evaluation/EB/Q_True Std              157.073\n",
      "evaluation/EB/Q_Pred Mean            1813.04\n",
      "evaluation/EB/Q_Pred Std              201.957\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4666.93\n",
      "evaluation/Actions Mean                 0.0855658\n",
      "evaluation/Actions Std                  0.506717\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93213\n",
      "time/backward_zf1 (s)                   2.34051\n",
      "time/backward_zf2 (s)                   2.27701\n",
      "time/data sampling (s)                  0.322779\n",
      "time/data storing (s)                   0.0145246\n",
      "time/evaluation sampling (s)            2.53379\n",
      "time/exploration sampling (s)           0.48937\n",
      "time/logging (s)                        0.0116602\n",
      "time/preback_alpha (s)                  0.570125\n",
      "time/preback_policy (s)                 1.17642\n",
      "time/preback_start (s)                  0.173635\n",
      "time/preback_zf (s)                     6.6214\n",
      "time/saving (s)                         3.101e-06\n",
      "time/training (s)                       3.07919\n",
      "time/epoch (s)                         21.5426\n",
      "time/total (s)                       2647.86\n",
      "Epoch                                 131\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:09:53.978640 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 132 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 143000\n",
      "trainer/ZF1 Loss                      306.945\n",
      "trainer/ZF2 Loss                      308.574\n",
      "trainer/ZF Expert Reward               11.7723\n",
      "trainer/ZF Policy Reward                5.06151\n",
      "trainer/ZF CHI2 Term                  300.528\n",
      "trainer/Policy Loss                 -1210.82\n",
      "trainer/Bias Loss                      50.8514\n",
      "trainer/Bias Value                     17.7865\n",
      "trainer/Policy Grad Norm              273.918\n",
      "trainer/Policy Param Norm              48.4276\n",
      "trainer/Zf1 Grad Norm               40039.7\n",
      "trainer/Zf1 Param Norm                116.366\n",
      "trainer/Zf2 Grad Norm               32678.7\n",
      "trainer/Zf2 Param Norm                114.867\n",
      "trainer/Z Expert Predictions Mean    1894.31\n",
      "trainer/Z Expert Predictions Std      126.906\n",
      "trainer/Z Expert Predictions Max     1979.52\n",
      "trainer/Z Expert Predictions Min        1.86179\n",
      "trainer/Z Policy Predictions Mean    1196.58\n",
      "trainer/Z Policy Predictions Std      642.054\n",
      "trainer/Z Policy Predictions Max     1897.86\n",
      "trainer/Z Policy Predictions Min      -19.0627\n",
      "trainer/Z Expert Targets Mean        1882.54\n",
      "trainer/Z Expert Targets Std          126.448\n",
      "trainer/Z Expert Targets Max         1967.26\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1191.52\n",
      "trainer/Z Policy Targets Std          645.951\n",
      "trainer/Z Policy Targets Max         1943.23\n",
      "trainer/Z Policy Targets Min           -9.76059\n",
      "trainer/Log Pis Mean                   59.1581\n",
      "trainer/Log Pis Std                    27.3745\n",
      "trainer/Policy mu Mean                  0.360106\n",
      "trainer/Policy mu Std                   3.12166\n",
      "trainer/Policy log std Mean            -2.58362\n",
      "trainer/Policy log std Std              1.2725\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        138119\n",
      "exploration/num paths total          1280\n",
      "evaluation/num steps total         448549\n",
      "evaluation/num paths total           1354\n",
      "evaluation/path length Mean           915\n",
      "evaluation/path length Std            255\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            150\n",
      "evaluation/Rewards Mean                 5.31255\n",
      "evaluation/Rewards Std                  0.115639\n",
      "evaluation/Rewards Max                  5.58563\n",
      "evaluation/Rewards Min                  3.45532\n",
      "evaluation/Returns Mean              4860.99\n",
      "evaluation/Returns Std               1374.14\n",
      "evaluation/Returns Max               5328.05\n",
      "evaluation/Returns Min                738.594\n",
      "evaluation/Estimation Bias Mean      1781.84\n",
      "evaluation/Estimation Bias Std        239.05\n",
      "evaluation/EB/Q_True Mean              52.4605\n",
      "evaluation/EB/Q_True Std              153.828\n",
      "evaluation/EB/Q_Pred Mean            1834.3\n",
      "evaluation/EB/Q_Pred Std              151.738\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4860.99\n",
      "evaluation/Actions Mean                 0.0664576\n",
      "evaluation/Actions Std                  0.491805\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76342\n",
      "time/backward_zf1 (s)                   2.18764\n",
      "time/backward_zf2 (s)                   2.09885\n",
      "time/data sampling (s)                  0.376208\n",
      "time/data storing (s)                   0.0155535\n",
      "time/evaluation sampling (s)            2.46213\n",
      "time/exploration sampling (s)           0.504057\n",
      "time/logging (s)                        0.0130067\n",
      "time/preback_alpha (s)                  0.576303\n",
      "time/preback_policy (s)                 0.985147\n",
      "time/preback_start (s)                  0.175439\n",
      "time/preback_zf (s)                     6.64642\n",
      "time/saving (s)                         3.123e-06\n",
      "time/training (s)                       3.71206\n",
      "time/epoch (s)                         21.5162\n",
      "time/total (s)                       2669.4\n",
      "Epoch                                 132\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:10:15.585955 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 133 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 144000\n",
      "trainer/ZF1 Loss                      320.504\n",
      "trainer/ZF2 Loss                      361.15\n",
      "trainer/ZF Expert Reward               17.1039\n",
      "trainer/ZF Policy Reward               -3.38576\n",
      "trainer/ZF CHI2 Term                  338.704\n",
      "trainer/Policy Loss                 -1152.58\n",
      "trainer/Bias Loss                      27.1862\n",
      "trainer/Bias Value                     17.7648\n",
      "trainer/Policy Grad Norm              230.069\n",
      "trainer/Policy Param Norm              48.5175\n",
      "trainer/Zf1 Grad Norm               45060.5\n",
      "trainer/Zf1 Param Norm                116.844\n",
      "trainer/Zf2 Grad Norm               33631.4\n",
      "trainer/Zf2 Param Norm                115.343\n",
      "trainer/Z Expert Predictions Mean    1923.93\n",
      "trainer/Z Expert Predictions Std       43.5185\n",
      "trainer/Z Expert Predictions Max     1987.31\n",
      "trainer/Z Expert Predictions Min     1750.88\n",
      "trainer/Z Policy Predictions Mean    1134.4\n",
      "trainer/Z Policy Predictions Std      694.937\n",
      "trainer/Z Policy Predictions Max     1933.05\n",
      "trainer/Z Policy Predictions Min      -22.1216\n",
      "trainer/Z Expert Targets Mean        1906.83\n",
      "trainer/Z Expert Targets Std           43.7969\n",
      "trainer/Z Expert Targets Max         1974.96\n",
      "trainer/Z Expert Targets Min         1723.8\n",
      "trainer/Z Policy Targets Mean        1137.78\n",
      "trainer/Z Policy Targets Std          692.945\n",
      "trainer/Z Policy Targets Max         1925.25\n",
      "trainer/Z Policy Targets Min          -11.7903\n",
      "trainer/Log Pis Mean                   61.4245\n",
      "trainer/Log Pis Std                    26.3375\n",
      "trainer/Policy mu Mean                  0.403437\n",
      "trainer/Policy mu Std                   3.1917\n",
      "trainer/Policy log std Mean            -2.44123\n",
      "trainer/Policy log std Std              1.34799\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        139119\n",
      "exploration/num paths total          1281\n",
      "evaluation/num steps total         458549\n",
      "evaluation/num paths total           1364\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.28795\n",
      "evaluation/Rewards Std                  0.0782197\n",
      "evaluation/Rewards Max                  5.47983\n",
      "evaluation/Rewards Min                  4.75446\n",
      "evaluation/Returns Mean              5287.95\n",
      "evaluation/Returns Std                  6.83565\n",
      "evaluation/Returns Max               5301.42\n",
      "evaluation/Returns Min               5276.91\n",
      "evaluation/Estimation Bias Mean      1816.27\n",
      "evaluation/Estimation Bias Std        172.09\n",
      "evaluation/EB/Q_True Mean              47.7316\n",
      "evaluation/EB/Q_True Std              146.995\n",
      "evaluation/EB/Q_Pred Mean            1864\n",
      "evaluation/EB/Q_Pred Std               86.4233\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5287.95\n",
      "evaluation/Actions Mean                 0.0858062\n",
      "evaluation/Actions Std                  0.507813\n",
      "evaluation/Actions Max                  0.999978\n",
      "evaluation/Actions Min                 -0.999321\n",
      "time/backward_policy (s)                1.7625\n",
      "time/backward_zf1 (s)                   2.23045\n",
      "time/backward_zf2 (s)                   2.12164\n",
      "time/data sampling (s)                  0.383565\n",
      "time/data storing (s)                   0.0146278\n",
      "time/evaluation sampling (s)            2.34142\n",
      "time/exploration sampling (s)           0.488666\n",
      "time/logging (s)                        0.0154241\n",
      "time/preback_alpha (s)                  0.581783\n",
      "time/preback_policy (s)                 0.994917\n",
      "time/preback_start (s)                  0.175616\n",
      "time/preback_zf (s)                     6.69676\n",
      "time/saving (s)                         3.89e-06\n",
      "time/training (s)                       3.72999\n",
      "time/epoch (s)                         21.5374\n",
      "time/total (s)                       2690.96\n",
      "Epoch                                 133\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:10:38.098865 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 134 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 145000\n",
      "trainer/ZF1 Loss                      420.524\n",
      "trainer/ZF2 Loss                      329.31\n",
      "trainer/ZF Expert Reward               10.2065\n",
      "trainer/ZF Policy Reward                2.9438\n",
      "trainer/ZF CHI2 Term                  365.927\n",
      "trainer/Policy Loss                 -1101.72\n",
      "trainer/Bias Loss                      86.3474\n",
      "trainer/Bias Value                     17.7463\n",
      "trainer/Policy Grad Norm              206.473\n",
      "trainer/Policy Param Norm              48.5979\n",
      "trainer/Zf1 Grad Norm               38002.8\n",
      "trainer/Zf1 Param Norm                117.31\n",
      "trainer/Zf2 Grad Norm               31214.3\n",
      "trainer/Zf2 Param Norm                115.776\n",
      "trainer/Z Expert Predictions Mean    1918.12\n",
      "trainer/Z Expert Predictions Std       54.8348\n",
      "trainer/Z Expert Predictions Max     1992.48\n",
      "trainer/Z Expert Predictions Min     1339.53\n",
      "trainer/Z Policy Predictions Mean    1083.86\n",
      "trainer/Z Policy Predictions Std      708.949\n",
      "trainer/Z Policy Predictions Max     1922.82\n",
      "trainer/Z Policy Predictions Min      -10.4934\n",
      "trainer/Z Expert Targets Mean        1907.91\n",
      "trainer/Z Expert Targets Std           57.0581\n",
      "trainer/Z Expert Targets Max         1985.2\n",
      "trainer/Z Expert Targets Min         1331.67\n",
      "trainer/Z Policy Targets Mean        1080.91\n",
      "trainer/Z Policy Targets Std          706.069\n",
      "trainer/Z Policy Targets Max         1936.32\n",
      "trainer/Z Policy Targets Min          -17.4559\n",
      "trainer/Log Pis Mean                   62.6746\n",
      "trainer/Log Pis Std                    29.1018\n",
      "trainer/Policy mu Mean                  0.392312\n",
      "trainer/Policy mu Std                   3.34913\n",
      "trainer/Policy log std Mean            -2.3597\n",
      "trainer/Policy log std Std              1.30403\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        139119\n",
      "exploration/num paths total          1281\n",
      "evaluation/num steps total         467918\n",
      "evaluation/num paths total           1375\n",
      "evaluation/path length Mean           851.727\n",
      "evaluation/path length Std            314.603\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            169\n",
      "evaluation/Rewards Mean                 5.28428\n",
      "evaluation/Rewards Std                  0.0966239\n",
      "evaluation/Rewards Max                  6.24056\n",
      "evaluation/Rewards Min                  4.76936\n",
      "evaluation/Returns Mean              4500.77\n",
      "evaluation/Returns Std               1663.51\n",
      "evaluation/Returns Max               5296.67\n",
      "evaluation/Returns Min                891.343\n",
      "evaluation/Estimation Bias Mean      1761.25\n",
      "evaluation/Estimation Bias Std        319.909\n",
      "evaluation/EB/Q_True Mean              51.053\n",
      "evaluation/EB/Q_True Std              151.666\n",
      "evaluation/EB/Q_Pred Mean            1812.3\n",
      "evaluation/EB/Q_Pred Std              218.966\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4500.77\n",
      "evaluation/Actions Mean                 0.0988644\n",
      "evaluation/Actions Std                  0.534678\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.96792\n",
      "time/backward_zf1 (s)                   2.44311\n",
      "time/backward_zf2 (s)                   2.34864\n",
      "time/data sampling (s)                  0.386305\n",
      "time/data storing (s)                   0.0162107\n",
      "time/evaluation sampling (s)            2.74971\n",
      "time/exploration sampling (s)           0.503793\n",
      "time/logging (s)                        0.0122677\n",
      "time/preback_alpha (s)                  0.602131\n",
      "time/preback_policy (s)                 1.17623\n",
      "time/preback_start (s)                  0.186448\n",
      "time/preback_zf (s)                     6.77167\n",
      "time/saving (s)                         2.833e-06\n",
      "time/training (s)                       3.27477\n",
      "time/epoch (s)                         22.4392\n",
      "time/total (s)                       2713.43\n",
      "Epoch                                 134\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:10:59.967321 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 135 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 146000\n",
      "trainer/ZF1 Loss                      346.393\n",
      "trainer/ZF2 Loss                      282.525\n",
      "trainer/ZF Expert Reward               17.5195\n",
      "trainer/ZF Policy Reward               10.4795\n",
      "trainer/ZF CHI2 Term                  312.583\n",
      "trainer/Policy Loss                 -1284.82\n",
      "trainer/Bias Loss                      20.83\n",
      "trainer/Bias Value                     17.727\n",
      "trainer/Policy Grad Norm              265.173\n",
      "trainer/Policy Param Norm              48.6876\n",
      "trainer/Zf1 Grad Norm               68148.2\n",
      "trainer/Zf1 Param Norm                117.759\n",
      "trainer/Zf2 Grad Norm               32487.1\n",
      "trainer/Zf2 Param Norm                116.243\n",
      "trainer/Z Expert Predictions Mean    1938.42\n",
      "trainer/Z Expert Predictions Std       48.8743\n",
      "trainer/Z Expert Predictions Max     2020.34\n",
      "trainer/Z Expert Predictions Min     1778.27\n",
      "trainer/Z Policy Predictions Mean    1272.87\n",
      "trainer/Z Policy Predictions Std      625.269\n",
      "trainer/Z Policy Predictions Max     1954.21\n",
      "trainer/Z Policy Predictions Min      -11.493\n",
      "trainer/Z Expert Targets Mean        1920.9\n",
      "trainer/Z Expert Targets Std           49.7369\n",
      "trainer/Z Expert Targets Max         1999.29\n",
      "trainer/Z Expert Targets Min         1762.6\n",
      "trainer/Z Policy Targets Mean        1262.39\n",
      "trainer/Z Policy Targets Std          626.764\n",
      "trainer/Z Policy Targets Max         1933.97\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   57.2576\n",
      "trainer/Log Pis Std                    24.4618\n",
      "trainer/Policy mu Mean                  0.365438\n",
      "trainer/Policy mu Std                   2.97003\n",
      "trainer/Policy log std Mean            -2.60465\n",
      "trainer/Policy log std Std              1.26052\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        139119\n",
      "exploration/num paths total          1281\n",
      "evaluation/num steps total         477902\n",
      "evaluation/num paths total           1386\n",
      "evaluation/path length Mean           907.636\n",
      "evaluation/path length Std            201.873\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            378\n",
      "evaluation/Rewards Mean                 5.28671\n",
      "evaluation/Rewards Std                  0.100325\n",
      "evaluation/Rewards Max                  6.46674\n",
      "evaluation/Rewards Min                  4.59303\n",
      "evaluation/Returns Mean              4798.41\n",
      "evaluation/Returns Std               1069.75\n",
      "evaluation/Returns Max               5301.81\n",
      "evaluation/Returns Min               2009.86\n",
      "evaluation/Estimation Bias Mean      1823.6\n",
      "evaluation/Estimation Bias Std        278.94\n",
      "evaluation/EB/Q_True Mean              47.9584\n",
      "evaluation/EB/Q_True Std              147.591\n",
      "evaluation/EB/Q_Pred Mean            1871.56\n",
      "evaluation/EB/Q_Pred Std              203.266\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4798.41\n",
      "evaluation/Actions Mean                 0.0738521\n",
      "evaluation/Actions Std                  0.502967\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.96429\n",
      "time/backward_zf1 (s)                   2.45306\n",
      "time/backward_zf2 (s)                   2.36155\n",
      "time/data sampling (s)                  0.362319\n",
      "time/data storing (s)                   0.014708\n",
      "time/evaluation sampling (s)            2.44608\n",
      "time/exploration sampling (s)           0.486483\n",
      "time/logging (s)                        0.0132751\n",
      "time/preback_alpha (s)                  0.583424\n",
      "time/preback_policy (s)                 1.20736\n",
      "time/preback_start (s)                  0.17756\n",
      "time/preback_zf (s)                     6.68923\n",
      "time/saving (s)                         2.742e-06\n",
      "time/training (s)                       3.03722\n",
      "time/epoch (s)                         21.7966\n",
      "time/total (s)                       2735.25\n",
      "Epoch                                 135\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:11:21.717510 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 136 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 147000\n",
      "trainer/ZF1 Loss                      334.983\n",
      "trainer/ZF2 Loss                      287.683\n",
      "trainer/ZF Expert Reward               19.3047\n",
      "trainer/ZF Policy Reward               12.097\n",
      "trainer/ZF CHI2 Term                  311.175\n",
      "trainer/Policy Loss                 -1259.85\n",
      "trainer/Bias Loss                      23.4309\n",
      "trainer/Bias Value                     17.7088\n",
      "trainer/Policy Grad Norm              258.072\n",
      "trainer/Policy Param Norm              48.7715\n",
      "trainer/Zf1 Grad Norm               35301.5\n",
      "trainer/Zf1 Param Norm                118.199\n",
      "trainer/Zf2 Grad Norm               36290.7\n",
      "trainer/Zf2 Param Norm                116.653\n",
      "trainer/Z Expert Predictions Mean    1940.73\n",
      "trainer/Z Expert Predictions Std      127.218\n",
      "trainer/Z Expert Predictions Max     2020.56\n",
      "trainer/Z Expert Predictions Min       41.8645\n",
      "trainer/Z Policy Predictions Mean    1246.9\n",
      "trainer/Z Policy Predictions Std      639.232\n",
      "trainer/Z Policy Predictions Max     1977.06\n",
      "trainer/Z Policy Predictions Min       17.4994\n",
      "trainer/Z Expert Targets Mean        1921.43\n",
      "trainer/Z Expert Targets Std          128.582\n",
      "trainer/Z Expert Targets Max         2010.51\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1234.8\n",
      "trainer/Z Policy Targets Std          638.056\n",
      "trainer/Z Policy Targets Max         1973.57\n",
      "trainer/Z Policy Targets Min           12.4931\n",
      "trainer/Log Pis Mean                   56.7225\n",
      "trainer/Log Pis Std                    23.2426\n",
      "trainer/Policy mu Mean                  0.309873\n",
      "trainer/Policy mu Std                   2.79535\n",
      "trainer/Policy log std Mean            -2.63219\n",
      "trainer/Policy log std Std              1.16636\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        141119\n",
      "exploration/num paths total          1283\n",
      "evaluation/num steps total         487902\n",
      "evaluation/num paths total           1396\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29727\n",
      "evaluation/Rewards Std                  0.0864496\n",
      "evaluation/Rewards Max                  5.56251\n",
      "evaluation/Rewards Min                  4.78422\n",
      "evaluation/Returns Mean              5297.27\n",
      "evaluation/Returns Std                  5.69645\n",
      "evaluation/Returns Max               5308.66\n",
      "evaluation/Returns Min               5289.32\n",
      "evaluation/Estimation Bias Mean      1857.3\n",
      "evaluation/Estimation Bias Std        166.494\n",
      "evaluation/EB/Q_True Mean              47.9426\n",
      "evaluation/EB/Q_True Std              147.656\n",
      "evaluation/EB/Q_Pred Mean            1905.24\n",
      "evaluation/EB/Q_Pred Std               78.2502\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5297.27\n",
      "evaluation/Actions Mean                 0.0690342\n",
      "evaluation/Actions Std                  0.49097\n",
      "evaluation/Actions Max                  0.999766\n",
      "evaluation/Actions Min                 -0.993372\n",
      "time/backward_policy (s)                1.97183\n",
      "time/backward_zf1 (s)                   2.40205\n",
      "time/backward_zf2 (s)                   2.33467\n",
      "time/data sampling (s)                  0.367973\n",
      "time/data storing (s)                   0.015227\n",
      "time/evaluation sampling (s)            2.36982\n",
      "time/exploration sampling (s)           0.50512\n",
      "time/logging (s)                        0.0137663\n",
      "time/preback_alpha (s)                  0.584158\n",
      "time/preback_policy (s)                 1.19255\n",
      "time/preback_start (s)                  0.179753\n",
      "time/preback_zf (s)                     6.68684\n",
      "time/saving (s)                         3.211e-06\n",
      "time/training (s)                       3.0596\n",
      "time/epoch (s)                         21.6834\n",
      "time/total (s)                       2756.95\n",
      "Epoch                                 136\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:11:43.449646 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 137 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 148000\n",
      "trainer/ZF1 Loss                      370.978\n",
      "trainer/ZF2 Loss                      381.29\n",
      "trainer/ZF Expert Reward               13.6639\n",
      "trainer/ZF Policy Reward                4.36339\n",
      "trainer/ZF CHI2 Term                  370.309\n",
      "trainer/Policy Loss                 -1272.75\n",
      "trainer/Bias Loss                      47.154\n",
      "trainer/Bias Value                     17.6856\n",
      "trainer/Policy Grad Norm              218.735\n",
      "trainer/Policy Param Norm              48.8489\n",
      "trainer/Zf1 Grad Norm               44105.7\n",
      "trainer/Zf1 Param Norm                118.634\n",
      "trainer/Zf2 Grad Norm               38280.9\n",
      "trainer/Zf2 Param Norm                117.072\n",
      "trainer/Z Expert Predictions Mean    1941.14\n",
      "trainer/Z Expert Predictions Std      134.391\n",
      "trainer/Z Expert Predictions Max     2039.37\n",
      "trainer/Z Expert Predictions Min       16.2088\n",
      "trainer/Z Policy Predictions Mean    1254.67\n",
      "trainer/Z Policy Predictions Std      640.86\n",
      "trainer/Z Policy Predictions Max     1955.39\n",
      "trainer/Z Policy Predictions Min        1.56675\n",
      "trainer/Z Expert Targets Mean        1927.48\n",
      "trainer/Z Expert Targets Std          134.795\n",
      "trainer/Z Expert Targets Max         2020.35\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1250.3\n",
      "trainer/Z Policy Targets Std          640.257\n",
      "trainer/Z Policy Targets Max         1966.36\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   57.8429\n",
      "trainer/Log Pis Std                    26.322\n",
      "trainer/Policy mu Mean                  0.346858\n",
      "trainer/Policy mu Std                   3.11742\n",
      "trainer/Policy log std Mean            -2.66509\n",
      "trainer/Policy log std Std              1.25719\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        142119\n",
      "exploration/num paths total          1284\n",
      "evaluation/num steps total         496696\n",
      "evaluation/num paths total           1406\n",
      "evaluation/path length Mean           879.4\n",
      "evaluation/path length Std            252.764\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            228\n",
      "evaluation/Rewards Mean                 5.3123\n",
      "evaluation/Rewards Std                  0.0956173\n",
      "evaluation/Rewards Max                  6.03466\n",
      "evaluation/Rewards Min                  4.77419\n",
      "evaluation/Returns Mean              4671.64\n",
      "evaluation/Returns Std               1350.39\n",
      "evaluation/Returns Max               5324.62\n",
      "evaluation/Returns Min               1196.07\n",
      "evaluation/Estimation Bias Mean      1817.21\n",
      "evaluation/Estimation Bias Std        310.012\n",
      "evaluation/EB/Q_True Mean              54.6984\n",
      "evaluation/EB/Q_True Std              156.811\n",
      "evaluation/EB/Q_Pred Mean            1871.91\n",
      "evaluation/EB/Q_Pred Std              213.482\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4671.64\n",
      "evaluation/Actions Mean                 0.0794021\n",
      "evaluation/Actions Std                  0.527987\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85846\n",
      "time/backward_zf1 (s)                   2.28498\n",
      "time/backward_zf2 (s)                   2.19672\n",
      "time/data sampling (s)                  0.380485\n",
      "time/data storing (s)                   0.0154701\n",
      "time/evaluation sampling (s)            2.48973\n",
      "time/exploration sampling (s)           0.495898\n",
      "time/logging (s)                        0.0130215\n",
      "time/preback_alpha (s)                  0.584487\n",
      "time/preback_policy (s)                 1.08053\n",
      "time/preback_start (s)                  0.181751\n",
      "time/preback_zf (s)                     6.69462\n",
      "time/saving (s)                         3.49e-06\n",
      "time/training (s)                       3.38395\n",
      "time/epoch (s)                         21.6601\n",
      "time/total (s)                       2778.64\n",
      "Epoch                                 137\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:12:05.013049 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 138 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 149000\n",
      "trainer/ZF1 Loss                      322.729\n",
      "trainer/ZF2 Loss                      421.185\n",
      "trainer/ZF Expert Reward               16.5003\n",
      "trainer/ZF Policy Reward                7.59452\n",
      "trainer/ZF CHI2 Term                  368.816\n",
      "trainer/Policy Loss                 -1211.96\n",
      "trainer/Bias Loss                      21.6604\n",
      "trainer/Bias Value                     17.6604\n",
      "trainer/Policy Grad Norm              246.694\n",
      "trainer/Policy Param Norm              48.9372\n",
      "trainer/Zf1 Grad Norm               24424\n",
      "trainer/Zf1 Param Norm                119.055\n",
      "trainer/Zf2 Grad Norm               27780.4\n",
      "trainer/Zf2 Param Norm                117.497\n",
      "trainer/Z Expert Predictions Mean    1958.32\n",
      "trainer/Z Expert Predictions Std      129.438\n",
      "trainer/Z Expert Predictions Max     2055.36\n",
      "trainer/Z Expert Predictions Min       29.8745\n",
      "trainer/Z Policy Predictions Mean    1197.7\n",
      "trainer/Z Policy Predictions Std      679.786\n",
      "trainer/Z Policy Predictions Max     1978.43\n",
      "trainer/Z Policy Predictions Min        2.27138\n",
      "trainer/Z Expert Targets Mean        1941.82\n",
      "trainer/Z Expert Targets Std          130.049\n",
      "trainer/Z Expert Targets Max         2033.04\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1190.1\n",
      "trainer/Z Policy Targets Std          679.39\n",
      "trainer/Z Policy Targets Max         1976.1\n",
      "trainer/Z Policy Targets Min           -5.00805\n",
      "trainer/Log Pis Mean                   59.4685\n",
      "trainer/Log Pis Std                    24.5562\n",
      "trainer/Policy mu Mean                  0.261536\n",
      "trainer/Policy mu Std                   3.22669\n",
      "trainer/Policy log std Mean            -2.49308\n",
      "trainer/Policy log std Std              1.29333\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        145119\n",
      "exploration/num paths total          1287\n",
      "evaluation/num steps total         506652\n",
      "evaluation/num paths total           1417\n",
      "evaluation/path length Mean           905.091\n",
      "evaluation/path length Std            246.859\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            143\n",
      "evaluation/Rewards Mean                 5.3246\n",
      "evaluation/Rewards Std                  0.117133\n",
      "evaluation/Rewards Max                  6.32399\n",
      "evaluation/Rewards Min                  4.7183\n",
      "evaluation/Returns Mean              4819.25\n",
      "evaluation/Returns Std               1320.51\n",
      "evaluation/Returns Max               5338.63\n",
      "evaluation/Returns Min                743.01\n",
      "evaluation/Estimation Bias Mean      1805.03\n",
      "evaluation/Estimation Bias Std        312.812\n",
      "evaluation/EB/Q_True Mean              48.327\n",
      "evaluation/EB/Q_True Std              148.485\n",
      "evaluation/EB/Q_Pred Mean            1853.36\n",
      "evaluation/EB/Q_Pred Std              232.171\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4819.25\n",
      "evaluation/Actions Mean                 0.0757983\n",
      "evaluation/Actions Std                  0.524114\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.76511\n",
      "time/backward_zf1 (s)                   2.21878\n",
      "time/backward_zf2 (s)                   2.11837\n",
      "time/data sampling (s)                  0.384925\n",
      "time/data storing (s)                   0.0162073\n",
      "time/evaluation sampling (s)            2.31536\n",
      "time/exploration sampling (s)           0.523733\n",
      "time/logging (s)                        0.0137492\n",
      "time/preback_alpha (s)                  0.582193\n",
      "time/preback_policy (s)                 0.99005\n",
      "time/preback_start (s)                  0.178291\n",
      "time/preback_zf (s)                     6.69634\n",
      "time/saving (s)                         3.944e-06\n",
      "time/training (s)                       3.69077\n",
      "time/epoch (s)                         21.4939\n",
      "time/total (s)                       2800.15\n",
      "Epoch                                 138\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:12:26.978306 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 139 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 150000\n",
      "trainer/ZF1 Loss                      298.337\n",
      "trainer/ZF2 Loss                      349.46\n",
      "trainer/ZF Expert Reward               15.0461\n",
      "trainer/ZF Policy Reward                4.31767\n",
      "trainer/ZF CHI2 Term                  319.206\n",
      "trainer/Policy Loss                 -1195.38\n",
      "trainer/Bias Loss                      30.3021\n",
      "trainer/Bias Value                     17.6384\n",
      "trainer/Policy Grad Norm              174.927\n",
      "trainer/Policy Param Norm              49.0153\n",
      "trainer/Zf1 Grad Norm               29863.8\n",
      "trainer/Zf1 Param Norm                119.48\n",
      "trainer/Zf2 Grad Norm               38007.8\n",
      "trainer/Zf2 Param Norm                117.919\n",
      "trainer/Z Expert Predictions Mean    1974.41\n",
      "trainer/Z Expert Predictions Std       44.8005\n",
      "trainer/Z Expert Predictions Max     2060.38\n",
      "trainer/Z Expert Predictions Min     1807.58\n",
      "trainer/Z Policy Predictions Mean    1175.3\n",
      "trainer/Z Policy Predictions Std      707.559\n",
      "trainer/Z Policy Predictions Max     2002.75\n",
      "trainer/Z Policy Predictions Min      -16.8325\n",
      "trainer/Z Expert Targets Mean        1959.37\n",
      "trainer/Z Expert Targets Std           44.8957\n",
      "trainer/Z Expert Targets Max         2041.58\n",
      "trainer/Z Expert Targets Min         1791.62\n",
      "trainer/Z Policy Targets Mean        1170.98\n",
      "trainer/Z Policy Targets Std          705.08\n",
      "trainer/Z Policy Targets Max         1970.94\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   62.3256\n",
      "trainer/Log Pis Std                    29.7227\n",
      "trainer/Policy mu Mean                  0.410486\n",
      "trainer/Policy mu Std                   3.53802\n",
      "trainer/Policy log std Mean            -2.43375\n",
      "trainer/Policy log std Std              1.39642\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        146119\n",
      "exploration/num paths total          1288\n",
      "evaluation/num steps total         516652\n",
      "evaluation/num paths total           1427\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.32269\n",
      "evaluation/Rewards Std                  0.0904251\n",
      "evaluation/Rewards Max                  5.55544\n",
      "evaluation/Rewards Min                  4.76201\n",
      "evaluation/Returns Mean              5322.69\n",
      "evaluation/Returns Std                  7.45379\n",
      "evaluation/Returns Max               5332.91\n",
      "evaluation/Returns Min               5309.66\n",
      "evaluation/Estimation Bias Mean      1849.51\n",
      "evaluation/Estimation Bias Std        175.381\n",
      "evaluation/EB/Q_True Mean              48.1159\n",
      "evaluation/EB/Q_True Std              148.195\n",
      "evaluation/EB/Q_Pred Mean            1897.62\n",
      "evaluation/EB/Q_Pred Std              101.525\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5322.69\n",
      "evaluation/Actions Mean                 0.0848527\n",
      "evaluation/Actions Std                  0.526994\n",
      "evaluation/Actions Max                  0.999992\n",
      "evaluation/Actions Min                 -0.99975\n",
      "time/backward_policy (s)                1.93377\n",
      "time/backward_zf1 (s)                   2.39196\n",
      "time/backward_zf2 (s)                   2.32634\n",
      "time/data sampling (s)                  0.377412\n",
      "time/data storing (s)                   0.0165089\n",
      "time/evaluation sampling (s)            2.28062\n",
      "time/exploration sampling (s)           0.522223\n",
      "time/logging (s)                        0.0131919\n",
      "time/preback_alpha (s)                  0.594361\n",
      "time/preback_policy (s)                 1.11871\n",
      "time/preback_start (s)                  0.181627\n",
      "time/preback_zf (s)                     6.72001\n",
      "time/saving (s)                         2.687e-06\n",
      "time/training (s)                       3.41828\n",
      "time/epoch (s)                         21.895\n",
      "time/total (s)                       2822.07\n",
      "Epoch                                 139\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:12:48.495731 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 140 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 151000\n",
      "trainer/ZF1 Loss                      325.008\n",
      "trainer/ZF2 Loss                      300.506\n",
      "trainer/ZF Expert Reward               19.2368\n",
      "trainer/ZF Policy Reward                3.68508\n",
      "trainer/ZF CHI2 Term                  312.125\n",
      "trainer/Policy Loss                 -1313.38\n",
      "trainer/Bias Loss                      45.1119\n",
      "trainer/Bias Value                     17.6153\n",
      "trainer/Policy Grad Norm              303.243\n",
      "trainer/Policy Param Norm              49.0881\n",
      "trainer/Zf1 Grad Norm               23977\n",
      "trainer/Zf1 Param Norm                119.902\n",
      "trainer/Zf2 Grad Norm               22544.5\n",
      "trainer/Zf2 Param Norm                118.333\n",
      "trainer/Z Expert Predictions Mean    1985.92\n",
      "trainer/Z Expert Predictions Std       44.2722\n",
      "trainer/Z Expert Predictions Max     2064.1\n",
      "trainer/Z Expert Predictions Min     1808.87\n",
      "trainer/Z Policy Predictions Mean    1297.9\n",
      "trainer/Z Policy Predictions Std      677.383\n",
      "trainer/Z Policy Predictions Max     1995.73\n",
      "trainer/Z Policy Predictions Min       -2.20232\n",
      "trainer/Z Expert Targets Mean        1966.69\n",
      "trainer/Z Expert Targets Std           44.8785\n",
      "trainer/Z Expert Targets Max         2045.03\n",
      "trainer/Z Expert Targets Min         1787.63\n",
      "trainer/Z Policy Targets Mean        1294.21\n",
      "trainer/Z Policy Targets Std          674.224\n",
      "trainer/Z Policy Targets Max         1984.03\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   57.9734\n",
      "trainer/Log Pis Std                    24.9504\n",
      "trainer/Policy mu Mean                  0.336248\n",
      "trainer/Policy mu Std                   3.04149\n",
      "trainer/Policy log std Mean            -2.65231\n",
      "trainer/Policy log std Std              1.33062\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        147119\n",
      "exploration/num paths total          1289\n",
      "evaluation/num steps total         526652\n",
      "evaluation/num paths total           1437\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29771\n",
      "evaluation/Rewards Std                  0.0772009\n",
      "evaluation/Rewards Max                  5.5229\n",
      "evaluation/Rewards Min                  4.76681\n",
      "evaluation/Returns Mean              5297.71\n",
      "evaluation/Returns Std                  7.41853\n",
      "evaluation/Returns Max               5313.3\n",
      "evaluation/Returns Min               5286.6\n",
      "evaluation/Estimation Bias Mean      1857.7\n",
      "evaluation/Estimation Bias Std        174.971\n",
      "evaluation/EB/Q_True Mean              47.8297\n",
      "evaluation/EB/Q_True Std              147.327\n",
      "evaluation/EB/Q_Pred Mean            1905.53\n",
      "evaluation/EB/Q_Pred Std               92.3619\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5297.71\n",
      "evaluation/Actions Mean                 0.0805483\n",
      "evaluation/Actions Std                  0.511537\n",
      "evaluation/Actions Max                  0.999988\n",
      "evaluation/Actions Min                 -0.999996\n",
      "time/backward_policy (s)                1.8879\n",
      "time/backward_zf1 (s)                   2.31837\n",
      "time/backward_zf2 (s)                   2.23381\n",
      "time/data sampling (s)                  0.358533\n",
      "time/data storing (s)                   0.0147789\n",
      "time/evaluation sampling (s)            2.34066\n",
      "time/exploration sampling (s)           0.491202\n",
      "time/logging (s)                        0.0130024\n",
      "time/preback_alpha (s)                  0.5809\n",
      "time/preback_policy (s)                 1.10874\n",
      "time/preback_start (s)                  0.178351\n",
      "time/preback_zf (s)                     6.65551\n",
      "time/saving (s)                         3.26399e-06\n",
      "time/training (s)                       3.25217\n",
      "time/epoch (s)                         21.4339\n",
      "time/total (s)                       2843.54\n",
      "Epoch                                 140\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:13:10.661422 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 141 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 152000\n",
      "trainer/ZF1 Loss                      362.686\n",
      "trainer/ZF2 Loss                      357.926\n",
      "trainer/ZF Expert Reward               18.7087\n",
      "trainer/ZF Policy Reward                7.49471\n",
      "trainer/ZF CHI2 Term                  359.05\n",
      "trainer/Policy Loss                 -1236.51\n",
      "trainer/Bias Loss                      66.2132\n",
      "trainer/Bias Value                     17.5866\n",
      "trainer/Policy Grad Norm              190.84\n",
      "trainer/Policy Param Norm              49.161\n",
      "trainer/Zf1 Grad Norm               29629.1\n",
      "trainer/Zf1 Param Norm                120.333\n",
      "trainer/Zf2 Grad Norm               42467.2\n",
      "trainer/Zf2 Param Norm                118.755\n",
      "trainer/Z Expert Predictions Mean    1989.03\n",
      "trainer/Z Expert Predictions Std      135.588\n",
      "trainer/Z Expert Predictions Max     2075.72\n",
      "trainer/Z Expert Predictions Min       10.5885\n",
      "trainer/Z Policy Predictions Mean    1219.78\n",
      "trainer/Z Policy Predictions Std      685.262\n",
      "trainer/Z Policy Predictions Max     2051.37\n",
      "trainer/Z Policy Predictions Min      -22.1214\n",
      "trainer/Z Expert Targets Mean        1970.32\n",
      "trainer/Z Expert Targets Std          134.92\n",
      "trainer/Z Expert Targets Max         2060.49\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1212.29\n",
      "trainer/Z Policy Targets Std          683.418\n",
      "trainer/Z Policy Targets Max         2018.61\n",
      "trainer/Z Policy Targets Min           -2.91044\n",
      "trainer/Log Pis Mean                   61.8441\n",
      "trainer/Log Pis Std                    30.5424\n",
      "trainer/Policy mu Mean                  0.243168\n",
      "trainer/Policy mu Std                   3.52992\n",
      "trainer/Policy log std Mean            -2.5354\n",
      "trainer/Policy log std Std              1.2857\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        147119\n",
      "exploration/num paths total          1289\n",
      "evaluation/num steps total         535301\n",
      "evaluation/num paths total           1447\n",
      "evaluation/path length Mean           864.9\n",
      "evaluation/path length Std            175.582\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            570\n",
      "evaluation/Rewards Mean                 5.28265\n",
      "evaluation/Rewards Std                  0.106574\n",
      "evaluation/Rewards Max                  6.28578\n",
      "evaluation/Rewards Min                  4.80217\n",
      "evaluation/Returns Mean              4568.97\n",
      "evaluation/Returns Std                925.379\n",
      "evaluation/Returns Max               5288.4\n",
      "evaluation/Returns Min               3004.99\n",
      "evaluation/Estimation Bias Mean      1810.74\n",
      "evaluation/Estimation Bias Std        344.517\n",
      "evaluation/EB/Q_True Mean              55.1936\n",
      "evaluation/EB/Q_True Std              156.769\n",
      "evaluation/EB/Q_Pred Mean            1865.93\n",
      "evaluation/EB/Q_Pred Std              303.232\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4568.97\n",
      "evaluation/Actions Mean                 0.0918369\n",
      "evaluation/Actions Std                  0.529946\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98967\n",
      "time/backward_zf1 (s)                   2.41644\n",
      "time/backward_zf2 (s)                   2.35035\n",
      "time/data sampling (s)                  0.358081\n",
      "time/data storing (s)                   0.0152526\n",
      "time/evaluation sampling (s)            2.63491\n",
      "time/exploration sampling (s)           0.508979\n",
      "time/logging (s)                        0.0110817\n",
      "time/preback_alpha (s)                  0.590255\n",
      "time/preback_policy (s)                 1.19366\n",
      "time/preback_start (s)                  0.181211\n",
      "time/preback_zf (s)                     6.6979\n",
      "time/saving (s)                         3.056e-06\n",
      "time/training (s)                       3.14131\n",
      "time/epoch (s)                         22.0891\n",
      "time/total (s)                       2865.65\n",
      "Epoch                                 141\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:13:32.596820 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 142 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 153000\n",
      "trainer/ZF1 Loss                      389.945\n",
      "trainer/ZF2 Loss                      336.785\n",
      "trainer/ZF Expert Reward               17.688\n",
      "trainer/ZF Policy Reward                6.9398\n",
      "trainer/ZF CHI2 Term                  360.975\n",
      "trainer/Policy Loss                 -1239.32\n",
      "trainer/Bias Loss                      27.4636\n",
      "trainer/Bias Value                     17.562\n",
      "trainer/Policy Grad Norm              246.936\n",
      "trainer/Policy Param Norm              49.2333\n",
      "trainer/Zf1 Grad Norm               23212.8\n",
      "trainer/Zf1 Param Norm                120.772\n",
      "trainer/Zf2 Grad Norm               27016.9\n",
      "trainer/Zf2 Param Norm                119.167\n",
      "trainer/Z Expert Predictions Mean    2009.47\n",
      "trainer/Z Expert Predictions Std       42.2186\n",
      "trainer/Z Expert Predictions Max     2084.12\n",
      "trainer/Z Expert Predictions Min     1796.96\n",
      "trainer/Z Policy Predictions Mean    1220.5\n",
      "trainer/Z Policy Predictions Std      709.987\n",
      "trainer/Z Policy Predictions Max     2028.25\n",
      "trainer/Z Policy Predictions Min      -11.7167\n",
      "trainer/Z Expert Targets Mean        1991.78\n",
      "trainer/Z Expert Targets Std           43.6049\n",
      "trainer/Z Expert Targets Max         2071.59\n",
      "trainer/Z Expert Targets Min         1782.34\n",
      "trainer/Z Policy Targets Mean        1213.56\n",
      "trainer/Z Policy Targets Std          706.144\n",
      "trainer/Z Policy Targets Max         1996.85\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   62.7367\n",
      "trainer/Log Pis Std                    30.1391\n",
      "trainer/Policy mu Mean                  0.349275\n",
      "trainer/Policy mu Std                   3.72826\n",
      "trainer/Policy log std Mean            -2.43058\n",
      "trainer/Policy log std Std              1.40704\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        148119\n",
      "exploration/num paths total          1290\n",
      "evaluation/num steps total         544542\n",
      "evaluation/num paths total           1457\n",
      "evaluation/path length Mean           924.1\n",
      "evaluation/path length Std            227.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            241\n",
      "evaluation/Rewards Mean                 5.32477\n",
      "evaluation/Rewards Std                  0.132587\n",
      "evaluation/Rewards Max                  5.54755\n",
      "evaluation/Rewards Min                  3.05796\n",
      "evaluation/Returns Mean              4920.62\n",
      "evaluation/Returns Std               1239.29\n",
      "evaluation/Returns Max               5340.85\n",
      "evaluation/Returns Min               1202.74\n",
      "evaluation/Estimation Bias Mean      1854.83\n",
      "evaluation/Estimation Bias Std        252.17\n",
      "evaluation/EB/Q_True Mean              52.1683\n",
      "evaluation/EB/Q_True Std              153.779\n",
      "evaluation/EB/Q_Pred Mean            1907\n",
      "evaluation/EB/Q_Pred Std              156.988\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4920.62\n",
      "evaluation/Actions Mean                 0.0692765\n",
      "evaluation/Actions Std                  0.530427\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92607\n",
      "time/backward_zf1 (s)                   2.3299\n",
      "time/backward_zf2 (s)                   2.26842\n",
      "time/data sampling (s)                  0.378829\n",
      "time/data storing (s)                   0.0157174\n",
      "time/evaluation sampling (s)            2.41273\n",
      "time/exploration sampling (s)           0.509692\n",
      "time/logging (s)                        0.012348\n",
      "time/preback_alpha (s)                  0.594789\n",
      "time/preback_policy (s)                 1.12436\n",
      "time/preback_start (s)                  0.179487\n",
      "time/preback_zf (s)                     6.71551\n",
      "time/saving (s)                         2.66601e-06\n",
      "time/training (s)                       3.39407\n",
      "time/epoch (s)                         21.8619\n",
      "time/total (s)                       2887.54\n",
      "Epoch                                 142\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:13:54.400234 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 143 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 154000\n",
      "trainer/ZF1 Loss                      357.541\n",
      "trainer/ZF2 Loss                      313.281\n",
      "trainer/ZF Expert Reward               19.2183\n",
      "trainer/ZF Policy Reward                5.17477\n",
      "trainer/ZF CHI2 Term                  334.527\n",
      "trainer/Policy Loss                 -1270.22\n",
      "trainer/Bias Loss                      48.3686\n",
      "trainer/Bias Value                     17.5419\n",
      "trainer/Policy Grad Norm              243.391\n",
      "trainer/Policy Param Norm              49.3121\n",
      "trainer/Zf1 Grad Norm               32860.1\n",
      "trainer/Zf1 Param Norm                121.172\n",
      "trainer/Zf2 Grad Norm               24094\n",
      "trainer/Zf2 Param Norm                119.565\n",
      "trainer/Z Expert Predictions Mean    2011.5\n",
      "trainer/Z Expert Predictions Std       50.7013\n",
      "trainer/Z Expert Predictions Max     2087.42\n",
      "trainer/Z Expert Predictions Min     1782.92\n",
      "trainer/Z Policy Predictions Mean    1260.04\n",
      "trainer/Z Policy Predictions Std      701.765\n",
      "trainer/Z Policy Predictions Max     2021.75\n",
      "trainer/Z Policy Predictions Min       -7.42133\n",
      "trainer/Z Expert Targets Mean        1992.28\n",
      "trainer/Z Expert Targets Std           49.2242\n",
      "trainer/Z Expert Targets Max         2076.99\n",
      "trainer/Z Expert Targets Min         1779.89\n",
      "trainer/Z Policy Targets Mean        1254.87\n",
      "trainer/Z Policy Targets Std          700.833\n",
      "trainer/Z Policy Targets Max         2021.41\n",
      "trainer/Z Policy Targets Min           -6.46698\n",
      "trainer/Log Pis Mean                   61.0302\n",
      "trainer/Log Pis Std                    28.7721\n",
      "trainer/Policy mu Mean                  0.195632\n",
      "trainer/Policy mu Std                   3.68404\n",
      "trainer/Policy log std Mean            -2.63353\n",
      "trainer/Policy log std Std              1.35525\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        149119\n",
      "exploration/num paths total          1291\n",
      "evaluation/num steps total         553073\n",
      "evaluation/num paths total           1467\n",
      "evaluation/path length Mean           853.1\n",
      "evaluation/path length Std            295.003\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            206\n",
      "evaluation/Rewards Mean                 5.31033\n",
      "evaluation/Rewards Std                  0.110292\n",
      "evaluation/Rewards Max                  6.58205\n",
      "evaluation/Rewards Min                  4.77128\n",
      "evaluation/Returns Mean              4530.25\n",
      "evaluation/Returns Std               1564.78\n",
      "evaluation/Returns Max               5316.55\n",
      "evaluation/Returns Min               1102.73\n",
      "evaluation/Estimation Bias Mean      1841.75\n",
      "evaluation/Estimation Bias Std        327.116\n",
      "evaluation/EB/Q_True Mean              56.2794\n",
      "evaluation/EB/Q_True Std              158.645\n",
      "evaluation/EB/Q_Pred Mean            1898.03\n",
      "evaluation/EB/Q_Pred Std              224.1\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4530.25\n",
      "evaluation/Actions Mean                 0.0866483\n",
      "evaluation/Actions Std                  0.523124\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.97982\n",
      "time/backward_zf1 (s)                   2.43517\n",
      "time/backward_zf2 (s)                   2.35503\n",
      "time/data sampling (s)                  0.375772\n",
      "time/data storing (s)                   0.0148049\n",
      "time/evaluation sampling (s)            2.44885\n",
      "time/exploration sampling (s)           0.490012\n",
      "time/logging (s)                        0.0122441\n",
      "time/preback_alpha (s)                  0.582816\n",
      "time/preback_policy (s)                 1.22419\n",
      "time/preback_start (s)                  0.177709\n",
      "time/preback_zf (s)                     6.6715\n",
      "time/saving (s)                         3.226e-06\n",
      "time/training (s)                       2.95909\n",
      "time/epoch (s)                         21.727\n",
      "time/total (s)                       2909.3\n",
      "Epoch                                 143\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:14:16.286264 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 144 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 155000\n",
      "trainer/ZF1 Loss                      469.934\n",
      "trainer/ZF2 Loss                      374.731\n",
      "trainer/ZF Expert Reward               15.9258\n",
      "trainer/ZF Policy Reward               10.8285\n",
      "trainer/ZF CHI2 Term                  418.15\n",
      "trainer/Policy Loss                 -1311.27\n",
      "trainer/Bias Loss                      53.0774\n",
      "trainer/Bias Value                     17.518\n",
      "trainer/Policy Grad Norm              320.257\n",
      "trainer/Policy Param Norm              49.3873\n",
      "trainer/Zf1 Grad Norm               39762.4\n",
      "trainer/Zf1 Param Norm                121.58\n",
      "trainer/Zf2 Grad Norm               32679.1\n",
      "trainer/Zf2 Param Norm                119.973\n",
      "trainer/Z Expert Predictions Mean    2011.56\n",
      "trainer/Z Expert Predictions Std       56.9841\n",
      "trainer/Z Expert Predictions Max     2105.04\n",
      "trainer/Z Expert Predictions Min     1493.84\n",
      "trainer/Z Policy Predictions Mean    1297.69\n",
      "trainer/Z Policy Predictions Std      679.528\n",
      "trainer/Z Policy Predictions Max     2008.52\n",
      "trainer/Z Policy Predictions Min        2.12534\n",
      "trainer/Z Expert Targets Mean        1995.63\n",
      "trainer/Z Expert Targets Std           53.7965\n",
      "trainer/Z Expert Targets Max         2083.24\n",
      "trainer/Z Expert Targets Min         1590.9\n",
      "trainer/Z Policy Targets Mean        1286.87\n",
      "trainer/Z Policy Targets Std          681.63\n",
      "trainer/Z Policy Targets Max         2028.5\n",
      "trainer/Z Policy Targets Min            3.59168\n",
      "trainer/Log Pis Mean                   60.2492\n",
      "trainer/Log Pis Std                    27.9528\n",
      "trainer/Policy mu Mean                  0.415496\n",
      "trainer/Policy mu Std                   3.18314\n",
      "trainer/Policy log std Mean            -2.5803\n",
      "trainer/Policy log std Std              1.35453\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        149119\n",
      "exploration/num paths total          1291\n",
      "evaluation/num steps total         562186\n",
      "evaluation/num paths total           1477\n",
      "evaluation/path length Mean           911.3\n",
      "evaluation/path length Std            257.55\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            139\n",
      "evaluation/Rewards Mean                 5.31057\n",
      "evaluation/Rewards Std                  0.11948\n",
      "evaluation/Rewards Max                  6.29711\n",
      "evaluation/Rewards Min                  4.39341\n",
      "evaluation/Returns Mean              4839.52\n",
      "evaluation/Returns Std               1394.4\n",
      "evaluation/Returns Max               5336.55\n",
      "evaluation/Returns Min                658.693\n",
      "evaluation/Estimation Bias Mean      1820.74\n",
      "evaluation/Estimation Bias Std        301.532\n",
      "evaluation/EB/Q_True Mean              52.7667\n",
      "evaluation/EB/Q_True Std              154.342\n",
      "evaluation/EB/Q_Pred Mean            1873.51\n",
      "evaluation/EB/Q_Pred Std              219.924\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4839.52\n",
      "evaluation/Actions Mean                 0.0973649\n",
      "evaluation/Actions Std                  0.557118\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92957\n",
      "time/backward_zf1 (s)                   2.384\n",
      "time/backward_zf2 (s)                   2.30509\n",
      "time/data sampling (s)                  0.376172\n",
      "time/data storing (s)                   0.0151025\n",
      "time/evaluation sampling (s)            2.46413\n",
      "time/exploration sampling (s)           0.498954\n",
      "time/logging (s)                        0.012548\n",
      "time/preback_alpha (s)                  0.586487\n",
      "time/preback_policy (s)                 1.1497\n",
      "time/preback_start (s)                  0.17863\n",
      "time/preback_zf (s)                     6.69121\n",
      "time/saving (s)                         2.752e-06\n",
      "time/training (s)                       3.21226\n",
      "time/epoch (s)                         21.8039\n",
      "time/total (s)                       2931.14\n",
      "Epoch                                 144\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:14:38.087568 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 145 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 156000\n",
      "trainer/ZF1 Loss                      447.356\n",
      "trainer/ZF2 Loss                      498.456\n",
      "trainer/ZF Expert Reward               21.5363\n",
      "trainer/ZF Policy Reward               12.2913\n",
      "trainer/ZF CHI2 Term                  474.145\n",
      "trainer/Policy Loss                 -1288.3\n",
      "trainer/Bias Loss                      50.5793\n",
      "trainer/Bias Value                     17.4895\n",
      "trainer/Policy Grad Norm              409.2\n",
      "trainer/Policy Param Norm              49.4667\n",
      "trainer/Zf1 Grad Norm               32052.8\n",
      "trainer/Zf1 Param Norm                122.028\n",
      "trainer/Zf2 Grad Norm               37528.6\n",
      "trainer/Zf2 Param Norm                120.423\n",
      "trainer/Z Expert Predictions Mean    2029.07\n",
      "trainer/Z Expert Predictions Std       56.6509\n",
      "trainer/Z Expert Predictions Max     2138.04\n",
      "trainer/Z Expert Predictions Min     1587.91\n",
      "trainer/Z Policy Predictions Mean    1274.48\n",
      "trainer/Z Policy Predictions Std      698.52\n",
      "trainer/Z Policy Predictions Max     2047.53\n",
      "trainer/Z Policy Predictions Min       -5.41617\n",
      "trainer/Z Expert Targets Mean        2007.53\n",
      "trainer/Z Expert Targets Std           57.6246\n",
      "trainer/Z Expert Targets Max         2121.66\n",
      "trainer/Z Expert Targets Min         1568.74\n",
      "trainer/Z Policy Targets Mean        1262.18\n",
      "trainer/Z Policy Targets Std          696.526\n",
      "trainer/Z Policy Targets Max         2033.74\n",
      "trainer/Z Policy Targets Min          -29.7706\n",
      "trainer/Log Pis Mean                   60.0609\n",
      "trainer/Log Pis Std                    25.7092\n",
      "trainer/Policy mu Mean                  0.340268\n",
      "trainer/Policy mu Std                   3.16271\n",
      "trainer/Policy log std Mean            -2.57055\n",
      "trainer/Policy log std Std              1.32974\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        149119\n",
      "exploration/num paths total          1291\n",
      "evaluation/num steps total         572186\n",
      "evaluation/num paths total           1487\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.34994\n",
      "evaluation/Rewards Std                  0.0876171\n",
      "evaluation/Rewards Max                  5.55755\n",
      "evaluation/Rewards Min                  4.78965\n",
      "evaluation/Returns Mean              5349.94\n",
      "evaluation/Returns Std                  6.28849\n",
      "evaluation/Returns Max               5359.91\n",
      "evaluation/Returns Min               5335.75\n",
      "evaluation/Estimation Bias Mean      1900.11\n",
      "evaluation/Estimation Bias Std        168.288\n",
      "evaluation/EB/Q_True Mean              48.3281\n",
      "evaluation/EB/Q_True Std              148.831\n",
      "evaluation/EB/Q_Pred Mean            1948.44\n",
      "evaluation/EB/Q_Pred Std               80.9889\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5349.94\n",
      "evaluation/Actions Mean                 0.0655184\n",
      "evaluation/Actions Std                  0.531111\n",
      "evaluation/Actions Max                  0.999989\n",
      "evaluation/Actions Min                 -0.9974\n",
      "time/backward_policy (s)                1.95001\n",
      "time/backward_zf1 (s)                   2.38951\n",
      "time/backward_zf2 (s)                   2.32237\n",
      "time/data sampling (s)                  0.371817\n",
      "time/data storing (s)                   0.0146797\n",
      "time/evaluation sampling (s)            2.52687\n",
      "time/exploration sampling (s)           0.492552\n",
      "time/logging (s)                        0.0128998\n",
      "time/preback_alpha (s)                  0.581749\n",
      "time/preback_policy (s)                 1.18997\n",
      "time/preback_start (s)                  0.177431\n",
      "time/preback_zf (s)                     6.67432\n",
      "time/saving (s)                         2.81e-06\n",
      "time/training (s)                       3.02743\n",
      "time/epoch (s)                         21.7316\n",
      "time/total (s)                       2952.89\n",
      "Epoch                                 145\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:14:59.699721 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 146 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 157000\n",
      "trainer/ZF1 Loss                      429.607\n",
      "trainer/ZF2 Loss                      399.373\n",
      "trainer/ZF Expert Reward               10.4624\n",
      "trainer/ZF Policy Reward                4.13195\n",
      "trainer/ZF CHI2 Term                  404.769\n",
      "trainer/Policy Loss                 -1288.8\n",
      "trainer/Bias Loss                      82.0452\n",
      "trainer/Bias Value                     17.4726\n",
      "trainer/Policy Grad Norm              296.565\n",
      "trainer/Policy Param Norm              49.5366\n",
      "trainer/Zf1 Grad Norm               33064.9\n",
      "trainer/Zf1 Param Norm                122.392\n",
      "trainer/Zf2 Grad Norm               34096.9\n",
      "trainer/Zf2 Param Norm                120.778\n",
      "trainer/Z Expert Predictions Mean    2020.28\n",
      "trainer/Z Expert Predictions Std       58.6451\n",
      "trainer/Z Expert Predictions Max     2123.56\n",
      "trainer/Z Expert Predictions Min     1777.18\n",
      "trainer/Z Policy Predictions Mean    1275.71\n",
      "trainer/Z Policy Predictions Std      703.366\n",
      "trainer/Z Policy Predictions Max     2029.35\n",
      "trainer/Z Policy Predictions Min        4.41755\n",
      "trainer/Z Expert Targets Mean        2009.81\n",
      "trainer/Z Expert Targets Std           56.036\n",
      "trainer/Z Expert Targets Max         2119.43\n",
      "trainer/Z Expert Targets Min         1786.65\n",
      "trainer/Z Policy Targets Mean        1271.58\n",
      "trainer/Z Policy Targets Std          703.305\n",
      "trainer/Z Policy Targets Max         2019.19\n",
      "trainer/Z Policy Targets Min           -0.967322\n",
      "trainer/Log Pis Mean                   62.2555\n",
      "trainer/Log Pis Std                    29.7967\n",
      "trainer/Policy mu Mean                  0.259382\n",
      "trainer/Policy mu Std                   3.58591\n",
      "trainer/Policy log std Mean            -2.58889\n",
      "trainer/Policy log std Std              1.36965\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        151119\n",
      "exploration/num paths total          1293\n",
      "evaluation/num steps total         580664\n",
      "evaluation/num paths total           1499\n",
      "evaluation/path length Mean           706.5\n",
      "evaluation/path length Std            296.434\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            166\n",
      "evaluation/Rewards Mean                 5.2995\n",
      "evaluation/Rewards Std                  0.161551\n",
      "evaluation/Rewards Max                  6.52377\n",
      "evaluation/Rewards Min                  3.64841\n",
      "evaluation/Returns Mean              3744.1\n",
      "evaluation/Returns Std               1584.63\n",
      "evaluation/Returns Max               5315.39\n",
      "evaluation/Returns Min                874.825\n",
      "evaluation/Estimation Bias Mean      1733.97\n",
      "evaluation/Estimation Bias Std        445.669\n",
      "evaluation/EB/Q_True Mean              56.6039\n",
      "evaluation/EB/Q_True Std              159.009\n",
      "evaluation/EB/Q_Pred Mean            1790.57\n",
      "evaluation/EB/Q_Pred Std              377.669\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3744.1\n",
      "evaluation/Actions Mean                 0.093648\n",
      "evaluation/Actions Std                  0.575548\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86607\n",
      "time/backward_zf1 (s)                   2.29311\n",
      "time/backward_zf2 (s)                   2.20728\n",
      "time/data sampling (s)                  0.372678\n",
      "time/data storing (s)                   0.0152553\n",
      "time/evaluation sampling (s)            2.28463\n",
      "time/exploration sampling (s)           0.510983\n",
      "time/logging (s)                        0.0118978\n",
      "time/preback_alpha (s)                  0.582967\n",
      "time/preback_policy (s)                 1.04263\n",
      "time/preback_start (s)                  0.178663\n",
      "time/preback_zf (s)                     6.66072\n",
      "time/saving (s)                         3.27299e-06\n",
      "time/training (s)                       3.51486\n",
      "time/epoch (s)                         21.5417\n",
      "time/total (s)                       2974.45\n",
      "Epoch                                 146\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:15:21.382708 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 147 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 158000\n",
      "trainer/ZF1 Loss                      334.445\n",
      "trainer/ZF2 Loss                      376.074\n",
      "trainer/ZF Expert Reward               20.0938\n",
      "trainer/ZF Policy Reward                7.81124\n",
      "trainer/ZF CHI2 Term                  355.009\n",
      "trainer/Policy Loss                 -1328.23\n",
      "trainer/Bias Loss                      46.3574\n",
      "trainer/Bias Value                     17.4478\n",
      "trainer/Policy Grad Norm              290.534\n",
      "trainer/Policy Param Norm              49.6157\n",
      "trainer/Zf1 Grad Norm               18415.7\n",
      "trainer/Zf1 Param Norm                122.813\n",
      "trainer/Zf2 Grad Norm               21237.9\n",
      "trainer/Zf2 Param Norm                121.194\n",
      "trainer/Z Expert Predictions Mean    2032.99\n",
      "trainer/Z Expert Predictions Std       61.8136\n",
      "trainer/Z Expert Predictions Max     2144.75\n",
      "trainer/Z Expert Predictions Min     1814\n",
      "trainer/Z Policy Predictions Mean    1311.75\n",
      "trainer/Z Policy Predictions Std      680.88\n",
      "trainer/Z Policy Predictions Max     2065.09\n",
      "trainer/Z Policy Predictions Min       -4.07041\n",
      "trainer/Z Expert Targets Mean        2012.9\n",
      "trainer/Z Expert Targets Std           62.6085\n",
      "trainer/Z Expert Targets Max         2128.48\n",
      "trainer/Z Expert Targets Min         1798.83\n",
      "trainer/Z Policy Targets Mean        1303.94\n",
      "trainer/Z Policy Targets Std          675.612\n",
      "trainer/Z Policy Targets Max         2035.31\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   59.0858\n",
      "trainer/Log Pis Std                    26.56\n",
      "trainer/Policy mu Mean                  0.332633\n",
      "trainer/Policy mu Std                   3.12814\n",
      "trainer/Policy log std Mean            -2.59192\n",
      "trainer/Policy log std Std              1.27754\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        152119\n",
      "exploration/num paths total          1294\n",
      "evaluation/num steps total         589053\n",
      "evaluation/num paths total           1509\n",
      "evaluation/path length Mean           838.9\n",
      "evaluation/path length Std            322.66\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            156\n",
      "evaluation/Rewards Mean                 5.28026\n",
      "evaluation/Rewards Std                  0.144869\n",
      "evaluation/Rewards Max                  5.7609\n",
      "evaluation/Rewards Min                  3.96665\n",
      "evaluation/Returns Mean              4429.61\n",
      "evaluation/Returns Std               1743.95\n",
      "evaluation/Returns Max               5313.05\n",
      "evaluation/Returns Min                727.724\n",
      "evaluation/Estimation Bias Mean      1871.56\n",
      "evaluation/Estimation Bias Std        367.611\n",
      "evaluation/EB/Q_True Mean              57.1001\n",
      "evaluation/EB/Q_True Std              159.415\n",
      "evaluation/EB/Q_Pred Mean            1928.66\n",
      "evaluation/EB/Q_Pred Std              256.289\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4429.61\n",
      "evaluation/Actions Mean                 0.0786279\n",
      "evaluation/Actions Std                  0.52732\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.77214\n",
      "time/backward_zf1 (s)                   2.21932\n",
      "time/backward_zf2 (s)                   2.10395\n",
      "time/data sampling (s)                  0.385073\n",
      "time/data storing (s)                   0.015005\n",
      "time/evaluation sampling (s)            2.50643\n",
      "time/exploration sampling (s)           0.494197\n",
      "time/logging (s)                        0.0122173\n",
      "time/preback_alpha (s)                  0.582881\n",
      "time/preback_policy (s)                 0.990183\n",
      "time/preback_start (s)                  0.17606\n",
      "time/preback_zf (s)                     6.67308\n",
      "time/saving (s)                         3.346e-06\n",
      "time/training (s)                       3.68043\n",
      "time/epoch (s)                         21.611\n",
      "time/total (s)                       2996.09\n",
      "Epoch                                 147\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:15:43.146092 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 148 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 159000\n",
      "trainer/ZF1 Loss                      327.313\n",
      "trainer/ZF2 Loss                      369.45\n",
      "trainer/ZF Expert Reward               19.8479\n",
      "trainer/ZF Policy Reward               11.9343\n",
      "trainer/ZF CHI2 Term                  347.852\n",
      "trainer/Policy Loss                 -1314.33\n",
      "trainer/Bias Loss                      31.7064\n",
      "trainer/Bias Value                     17.4253\n",
      "trainer/Policy Grad Norm              232.058\n",
      "trainer/Policy Param Norm              49.6848\n",
      "trainer/Zf1 Grad Norm               21461.2\n",
      "trainer/Zf1 Param Norm                123.191\n",
      "trainer/Zf2 Grad Norm               28204.7\n",
      "trainer/Zf2 Param Norm                121.533\n",
      "trainer/Z Expert Predictions Mean    2036.36\n",
      "trainer/Z Expert Predictions Std       63.3045\n",
      "trainer/Z Expert Predictions Max     2139.76\n",
      "trainer/Z Expert Predictions Min     1657.24\n",
      "trainer/Z Policy Predictions Mean    1303.94\n",
      "trainer/Z Policy Predictions Std      704.138\n",
      "trainer/Z Policy Predictions Max     2054.89\n",
      "trainer/Z Policy Predictions Min        7.43292\n",
      "trainer/Z Expert Targets Mean        2016.51\n",
      "trainer/Z Expert Targets Std           65.3415\n",
      "trainer/Z Expert Targets Max         2127.98\n",
      "trainer/Z Expert Targets Min         1609.91\n",
      "trainer/Z Policy Targets Mean        1292\n",
      "trainer/Z Policy Targets Std          704.185\n",
      "trainer/Z Policy Targets Max         2039.24\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   60.8176\n",
      "trainer/Log Pis Std                    27.7995\n",
      "trainer/Policy mu Mean                  0.298064\n",
      "trainer/Policy mu Std                   3.62777\n",
      "trainer/Policy log std Mean            -2.65677\n",
      "trainer/Policy log std Std              1.37286\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        155119\n",
      "exploration/num paths total          1297\n",
      "evaluation/num steps total         599053\n",
      "evaluation/num paths total           1519\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31407\n",
      "evaluation/Rewards Std                  0.0851446\n",
      "evaluation/Rewards Max                  5.57314\n",
      "evaluation/Rewards Min                  4.80814\n",
      "evaluation/Returns Mean              5314.07\n",
      "evaluation/Returns Std                  6.78491\n",
      "evaluation/Returns Max               5322.28\n",
      "evaluation/Returns Min               5302.07\n",
      "evaluation/Estimation Bias Mean      1898.64\n",
      "evaluation/Estimation Bias Std        183.887\n",
      "evaluation/EB/Q_True Mean              48.0488\n",
      "evaluation/EB/Q_True Std              147.987\n",
      "evaluation/EB/Q_Pred Mean            1946.69\n",
      "evaluation/EB/Q_Pred Std               98.8287\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5314.07\n",
      "evaluation/Actions Mean                 0.0758691\n",
      "evaluation/Actions Std                  0.505687\n",
      "evaluation/Actions Max                  0.999972\n",
      "evaluation/Actions Min                 -0.999191\n",
      "time/backward_policy (s)                1.88438\n",
      "time/backward_zf1 (s)                   2.30933\n",
      "time/backward_zf2 (s)                   2.24426\n",
      "time/data sampling (s)                  0.388564\n",
      "time/data storing (s)                   0.0147674\n",
      "time/evaluation sampling (s)            2.52346\n",
      "time/exploration sampling (s)           0.511449\n",
      "time/logging (s)                        0.0164762\n",
      "time/preback_alpha (s)                  0.586789\n",
      "time/preback_policy (s)                 1.13444\n",
      "time/preback_start (s)                  0.179488\n",
      "time/preback_zf (s)                     6.66179\n",
      "time/saving (s)                         2.951e-06\n",
      "time/training (s)                       3.24403\n",
      "time/epoch (s)                         21.6992\n",
      "time/total (s)                       3017.81\n",
      "Epoch                                 148\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:16:04.879115 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 149 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 160000\n",
      "trainer/ZF1 Loss                      341.134\n",
      "trainer/ZF2 Loss                      387.852\n",
      "trainer/ZF Expert Reward               12.6966\n",
      "trainer/ZF Policy Reward               10.7094\n",
      "trainer/ZF CHI2 Term                  356.802\n",
      "trainer/Policy Loss                 -1423.61\n",
      "trainer/Bias Loss                      33.0434\n",
      "trainer/Bias Value                     17.4008\n",
      "trainer/Policy Grad Norm              184.565\n",
      "trainer/Policy Param Norm              49.7597\n",
      "trainer/Zf1 Grad Norm               41287.7\n",
      "trainer/Zf1 Param Norm                123.58\n",
      "trainer/Zf2 Grad Norm               39464\n",
      "trainer/Zf2 Param Norm                121.929\n",
      "trainer/Z Expert Predictions Mean    2039\n",
      "trainer/Z Expert Predictions Std       52.6283\n",
      "trainer/Z Expert Predictions Max     2147.31\n",
      "trainer/Z Expert Predictions Min     1807.88\n",
      "trainer/Z Policy Predictions Mean    1414.12\n",
      "trainer/Z Policy Predictions Std      687.001\n",
      "trainer/Z Policy Predictions Max     2067.41\n",
      "trainer/Z Policy Predictions Min        3.67639\n",
      "trainer/Z Expert Targets Mean        2026.31\n",
      "trainer/Z Expert Targets Std           52.8638\n",
      "trainer/Z Expert Targets Max         2123.84\n",
      "trainer/Z Expert Targets Min         1788.31\n",
      "trainer/Z Policy Targets Mean        1403.41\n",
      "trainer/Z Policy Targets Std          689.824\n",
      "trainer/Z Policy Targets Max         2037.35\n",
      "trainer/Z Policy Targets Min          -17.0646\n",
      "trainer/Log Pis Mean                   57.0178\n",
      "trainer/Log Pis Std                    27.4962\n",
      "trainer/Policy mu Mean                  0.326461\n",
      "trainer/Policy mu Std                   3.10717\n",
      "trainer/Policy log std Mean            -2.74573\n",
      "trainer/Policy log std Std              1.28022\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        156119\n",
      "exploration/num paths total          1298\n",
      "evaluation/num steps total         608338\n",
      "evaluation/num paths total           1529\n",
      "evaluation/path length Mean           928.5\n",
      "evaluation/path length Std            201.52\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            325\n",
      "evaluation/Rewards Mean                 5.33194\n",
      "evaluation/Rewards Std                  0.105475\n",
      "evaluation/Rewards Max                  6.48061\n",
      "evaluation/Rewards Min                  4.81222\n",
      "evaluation/Returns Mean              4950.71\n",
      "evaluation/Returns Std               1068.23\n",
      "evaluation/Returns Max               5342.98\n",
      "evaluation/Returns Min               1750.65\n",
      "evaluation/Estimation Bias Mean      1886.19\n",
      "evaluation/Estimation Bias Std        312.599\n",
      "evaluation/EB/Q_True Mean              51.8981\n",
      "evaluation/EB/Q_True Std              153.402\n",
      "evaluation/EB/Q_Pred Mean            1938.09\n",
      "evaluation/EB/Q_Pred Std              237.735\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4950.71\n",
      "evaluation/Actions Mean                 0.0720112\n",
      "evaluation/Actions Std                  0.531335\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.9326\n",
      "time/backward_zf1 (s)                   2.35437\n",
      "time/backward_zf2 (s)                   2.28961\n",
      "time/data sampling (s)                  0.374455\n",
      "time/data storing (s)                   0.015611\n",
      "time/evaluation sampling (s)            2.46247\n",
      "time/exploration sampling (s)           0.494755\n",
      "time/logging (s)                        0.0127983\n",
      "time/preback_alpha (s)                  0.589876\n",
      "time/preback_policy (s)                 1.18481\n",
      "time/preback_start (s)                  0.183248\n",
      "time/preback_zf (s)                     6.67821\n",
      "time/saving (s)                         3.681e-06\n",
      "time/training (s)                       3.08623\n",
      "time/epoch (s)                         21.659\n",
      "time/total (s)                       3039.49\n",
      "Epoch                                 149\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:16:26.239609 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 150 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 161000\n",
      "trainer/ZF1 Loss                      386.554\n",
      "trainer/ZF2 Loss                      348.701\n",
      "trainer/ZF Expert Reward               15.5779\n",
      "trainer/ZF Policy Reward                5.08456\n",
      "trainer/ZF CHI2 Term                  362.703\n",
      "trainer/Policy Loss                 -1390.96\n",
      "trainer/Bias Loss                      31.9484\n",
      "trainer/Bias Value                     17.3721\n",
      "trainer/Policy Grad Norm              236.848\n",
      "trainer/Policy Param Norm              49.8233\n",
      "trainer/Zf1 Grad Norm               34764.3\n",
      "trainer/Zf1 Param Norm                123.988\n",
      "trainer/Zf2 Grad Norm               32944.9\n",
      "trainer/Zf2 Param Norm                122.335\n",
      "trainer/Z Expert Predictions Mean    2050.72\n",
      "trainer/Z Expert Predictions Std       56.7644\n",
      "trainer/Z Expert Predictions Max     2137.32\n",
      "trainer/Z Expert Predictions Min     1813.37\n",
      "trainer/Z Policy Predictions Mean    1373.8\n",
      "trainer/Z Policy Predictions Std      649.195\n",
      "trainer/Z Policy Predictions Max     2059.83\n",
      "trainer/Z Policy Predictions Min      -14.6794\n",
      "trainer/Z Expert Targets Mean        2035.14\n",
      "trainer/Z Expert Targets Std           56.7194\n",
      "trainer/Z Expert Targets Max         2124.57\n",
      "trainer/Z Expert Targets Min         1799.87\n",
      "trainer/Z Policy Targets Mean        1368.72\n",
      "trainer/Z Policy Targets Std          647.886\n",
      "trainer/Z Policy Targets Max         2033.52\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   58.7311\n",
      "trainer/Log Pis Std                    28.1615\n",
      "trainer/Policy mu Mean                  0.453356\n",
      "trainer/Policy mu Std                   3.12598\n",
      "trainer/Policy log std Mean            -2.711\n",
      "trainer/Policy log std Std              1.22741\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        157119\n",
      "exploration/num paths total          1299\n",
      "evaluation/num steps total         611944\n",
      "evaluation/num paths total           1539\n",
      "evaluation/path length Mean           360.6\n",
      "evaluation/path length Std            258.517\n",
      "evaluation/path length Max            805\n",
      "evaluation/path length Min             83\n",
      "evaluation/Rewards Mean                 5.19595\n",
      "evaluation/Rewards Std                  0.326609\n",
      "evaluation/Rewards Max                  6.57854\n",
      "evaluation/Rewards Min                  3.18973\n",
      "evaluation/Returns Mean              1873.66\n",
      "evaluation/Returns Std               1396.31\n",
      "evaluation/Returns Max               4255.21\n",
      "evaluation/Returns Min                380.789\n",
      "evaluation/Estimation Bias Mean      1496.48\n",
      "evaluation/Estimation Bias Std        709.908\n",
      "evaluation/EB/Q_True Mean             103.856\n",
      "evaluation/EB/Q_True Std              200.654\n",
      "evaluation/EB/Q_Pred Mean            1600.33\n",
      "evaluation/EB/Q_Pred Std              613.183\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1873.66\n",
      "evaluation/Actions Mean                 0.0953801\n",
      "evaluation/Actions Std                  0.609832\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85193\n",
      "time/backward_zf1 (s)                   2.30878\n",
      "time/backward_zf2 (s)                   2.22916\n",
      "time/data sampling (s)                  0.381992\n",
      "time/data storing (s)                   0.0154894\n",
      "time/evaluation sampling (s)            1.99873\n",
      "time/exploration sampling (s)           0.511654\n",
      "time/logging (s)                        0.00733801\n",
      "time/preback_alpha (s)                  0.582446\n",
      "time/preback_policy (s)                 1.07271\n",
      "time/preback_start (s)                  0.180685\n",
      "time/preback_zf (s)                     6.66985\n",
      "time/saving (s)                         3.14099e-06\n",
      "time/training (s)                       3.47575\n",
      "time/epoch (s)                         21.2865\n",
      "time/total (s)                       3060.8\n",
      "Epoch                                 150\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:16:48.479380 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 151 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 162000\n",
      "trainer/ZF1 Loss                      344.023\n",
      "trainer/ZF2 Loss                      419.132\n",
      "trainer/ZF Expert Reward               12.2612\n",
      "trainer/ZF Policy Reward                5.2323\n",
      "trainer/ZF CHI2 Term                  373.291\n",
      "trainer/Policy Loss                 -1316.17\n",
      "trainer/Bias Loss                      51.8504\n",
      "trainer/Bias Value                     17.3458\n",
      "trainer/Policy Grad Norm              291.75\n",
      "trainer/Policy Param Norm              49.8919\n",
      "trainer/Zf1 Grad Norm               27396.1\n",
      "trainer/Zf1 Param Norm                124.389\n",
      "trainer/Zf2 Grad Norm               30925.9\n",
      "trainer/Zf2 Param Norm                122.736\n",
      "trainer/Z Expert Predictions Mean    2052.27\n",
      "trainer/Z Expert Predictions Std       62.379\n",
      "trainer/Z Expert Predictions Max     2157.15\n",
      "trainer/Z Expert Predictions Min     1600.37\n",
      "trainer/Z Policy Predictions Mean    1299.91\n",
      "trainer/Z Policy Predictions Std      732.053\n",
      "trainer/Z Policy Predictions Max     2082.45\n",
      "trainer/Z Policy Predictions Min       -6.9773\n",
      "trainer/Z Expert Targets Mean        2040.01\n",
      "trainer/Z Expert Targets Std           64.2646\n",
      "trainer/Z Expert Targets Max         2133.19\n",
      "trainer/Z Expert Targets Min         1564.05\n",
      "trainer/Z Policy Targets Mean        1294.68\n",
      "trainer/Z Policy Targets Std          728.652\n",
      "trainer/Z Policy Targets Max         2057.06\n",
      "trainer/Z Policy Targets Min           -5.0959\n",
      "trainer/Log Pis Mean                   62.2278\n",
      "trainer/Log Pis Std                    29.0606\n",
      "trainer/Policy mu Mean                  0.235187\n",
      "trainer/Policy mu Std                   3.50088\n",
      "trainer/Policy log std Mean            -2.62518\n",
      "trainer/Policy log std Std              1.40728\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        157119\n",
      "exploration/num paths total          1299\n",
      "evaluation/num steps total         621332\n",
      "evaluation/num paths total           1549\n",
      "evaluation/path length Mean           938.8\n",
      "evaluation/path length Std            183.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            388\n",
      "evaluation/Rewards Mean                 5.28084\n",
      "evaluation/Rewards Std                  0.088262\n",
      "evaluation/Rewards Max                  6.48019\n",
      "evaluation/Rewards Min                  4.78697\n",
      "evaluation/Returns Mean              4957.65\n",
      "evaluation/Returns Std                966.272\n",
      "evaluation/Returns Max               5299.48\n",
      "evaluation/Returns Min               2058.97\n",
      "evaluation/Estimation Bias Mean      1920.17\n",
      "evaluation/Estimation Bias Std        269.756\n",
      "evaluation/EB/Q_True Mean              50.757\n",
      "evaluation/EB/Q_True Std              150.963\n",
      "evaluation/EB/Q_Pred Mean            1970.93\n",
      "evaluation/EB/Q_Pred Std              180.238\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4957.65\n",
      "evaluation/Actions Mean                 0.0776847\n",
      "evaluation/Actions Std                  0.51058\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.01254\n",
      "time/backward_zf1 (s)                   2.46619\n",
      "time/backward_zf2 (s)                   2.38223\n",
      "time/data sampling (s)                  0.367284\n",
      "time/data storing (s)                   0.0162943\n",
      "time/evaluation sampling (s)            2.56172\n",
      "time/exploration sampling (s)           0.506216\n",
      "time/logging (s)                        0.0129881\n",
      "time/preback_alpha (s)                  0.593286\n",
      "time/preback_policy (s)                 1.20818\n",
      "time/preback_start (s)                  0.180436\n",
      "time/preback_zf (s)                     6.73535\n",
      "time/saving (s)                         3.722e-06\n",
      "time/training (s)                       3.13606\n",
      "time/epoch (s)                         22.1788\n",
      "time/total (s)                       3082.99\n",
      "Epoch                                 151\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:17:11.040203 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 152 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 163000\n",
      "trainer/ZF1 Loss                      465.753\n",
      "trainer/ZF2 Loss                      446.674\n",
      "trainer/ZF Expert Reward               12.8899\n",
      "trainer/ZF Policy Reward                0.82927\n",
      "trainer/ZF CHI2 Term                  448.563\n",
      "trainer/Policy Loss                 -1404.93\n",
      "trainer/Bias Loss                      46.0153\n",
      "trainer/Bias Value                     17.3234\n",
      "trainer/Policy Grad Norm              236.734\n",
      "trainer/Policy Param Norm              49.9597\n",
      "trainer/Zf1 Grad Norm               45438.1\n",
      "trainer/Zf1 Param Norm                124.741\n",
      "trainer/Zf2 Grad Norm               39435.9\n",
      "trainer/Zf2 Param Norm                123.087\n",
      "trainer/Z Expert Predictions Mean    2053.21\n",
      "trainer/Z Expert Predictions Std       51.8603\n",
      "trainer/Z Expert Predictions Max     2142.89\n",
      "trainer/Z Expert Predictions Min     1808.9\n",
      "trainer/Z Policy Predictions Mean    1384.84\n",
      "trainer/Z Policy Predictions Std      680.168\n",
      "trainer/Z Policy Predictions Max     2098.96\n",
      "trainer/Z Policy Predictions Min       -7.77958\n",
      "trainer/Z Expert Targets Mean        2040.32\n",
      "trainer/Z Expert Targets Std           53.4897\n",
      "trainer/Z Expert Targets Max         2141.47\n",
      "trainer/Z Expert Targets Min         1794.07\n",
      "trainer/Z Policy Targets Mean        1384.01\n",
      "trainer/Z Policy Targets Std          674.004\n",
      "trainer/Z Policy Targets Max         2113.78\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   58.4668\n",
      "trainer/Log Pis Std                    26.2227\n",
      "trainer/Policy mu Mean                  0.313108\n",
      "trainer/Policy mu Std                   3.10983\n",
      "trainer/Policy log std Mean            -2.68332\n",
      "trainer/Policy log std Std              1.29893\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        158119\n",
      "exploration/num paths total          1300\n",
      "evaluation/num steps total         630280\n",
      "evaluation/num paths total           1559\n",
      "evaluation/path length Mean           894.8\n",
      "evaluation/path length Std            223.412\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            306\n",
      "evaluation/Rewards Mean                 5.321\n",
      "evaluation/Rewards Std                  0.100327\n",
      "evaluation/Rewards Max                  5.70931\n",
      "evaluation/Rewards Min                  4.76166\n",
      "evaluation/Returns Mean              4761.23\n",
      "evaluation/Returns Std               1204.68\n",
      "evaluation/Returns Max               5341.67\n",
      "evaluation/Returns Min               1578.42\n",
      "evaluation/Estimation Bias Mean      1885.82\n",
      "evaluation/Estimation Bias Std        327.034\n",
      "evaluation/EB/Q_True Mean              53.6766\n",
      "evaluation/EB/Q_True Std              155.393\n",
      "evaluation/EB/Q_Pred Mean            1939.49\n",
      "evaluation/EB/Q_Pred Std              228.557\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4761.23\n",
      "evaluation/Actions Mean                 0.0848693\n",
      "evaluation/Actions Std                  0.533079\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.05559\n",
      "time/backward_zf1 (s)                   2.517\n",
      "time/backward_zf2 (s)                   2.4329\n",
      "time/data sampling (s)                  0.40832\n",
      "time/data storing (s)                   0.0159123\n",
      "time/evaluation sampling (s)            2.54616\n",
      "time/exploration sampling (s)           0.51815\n",
      "time/logging (s)                        0.0112083\n",
      "time/preback_alpha (s)                  0.61932\n",
      "time/preback_policy (s)                 1.25139\n",
      "time/preback_start (s)                  0.190307\n",
      "time/preback_zf (s)                     6.84288\n",
      "time/saving (s)                         3.894e-06\n",
      "time/training (s)                       3.07619\n",
      "time/epoch (s)                         22.4853\n",
      "time/total (s)                       3105.5\n",
      "Epoch                                 152\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:17:31.691620 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 153 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 164000\n",
      "trainer/ZF1 Loss                      350.403\n",
      "trainer/ZF2 Loss                      446.404\n",
      "trainer/ZF Expert Reward               19.3206\n",
      "trainer/ZF Policy Reward                9.40997\n",
      "trainer/ZF CHI2 Term                  397.058\n",
      "trainer/Policy Loss                 -1404.38\n",
      "trainer/Bias Loss                      68.105\n",
      "trainer/Bias Value                     17.2983\n",
      "trainer/Policy Grad Norm              304.412\n",
      "trainer/Policy Param Norm              50.0337\n",
      "trainer/Zf1 Grad Norm               21115.8\n",
      "trainer/Zf1 Param Norm                125.151\n",
      "trainer/Zf2 Grad Norm               24203.1\n",
      "trainer/Zf2 Param Norm                123.478\n",
      "trainer/Z Expert Predictions Mean    2065.62\n",
      "trainer/Z Expert Predictions Std       65.9117\n",
      "trainer/Z Expert Predictions Max     2153.69\n",
      "trainer/Z Expert Predictions Min     1517.92\n",
      "trainer/Z Policy Predictions Mean    1395.96\n",
      "trainer/Z Policy Predictions Std      692.627\n",
      "trainer/Z Policy Predictions Max     2069.99\n",
      "trainer/Z Policy Predictions Min       -1.89115\n",
      "trainer/Z Expert Targets Mean        2046.29\n",
      "trainer/Z Expert Targets Std           65.8031\n",
      "trainer/Z Expert Targets Max         2145.66\n",
      "trainer/Z Expert Targets Min         1488.83\n",
      "trainer/Z Policy Targets Mean        1386.55\n",
      "trainer/Z Policy Targets Std          689.105\n",
      "trainer/Z Policy Targets Max         2064.83\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   60.1163\n",
      "trainer/Log Pis Std                    26.1404\n",
      "trainer/Policy mu Mean                  0.226681\n",
      "trainer/Policy mu Std                   3.257\n",
      "trainer/Policy log std Mean            -2.78346\n",
      "trainer/Policy log std Std              1.28424\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        159119\n",
      "exploration/num paths total          1301\n",
      "evaluation/num steps total         632894\n",
      "evaluation/num paths total           1569\n",
      "evaluation/path length Mean           261.4\n",
      "evaluation/path length Std            107.387\n",
      "evaluation/path length Max            489\n",
      "evaluation/path length Min            143\n",
      "evaluation/Rewards Mean                 5.3493\n",
      "evaluation/Rewards Std                  0.239567\n",
      "evaluation/Rewards Max                  6.61212\n",
      "evaluation/Rewards Min                  4.80127\n",
      "evaluation/Returns Mean              1398.31\n",
      "evaluation/Returns Std                579.431\n",
      "evaluation/Returns Max               2642.37\n",
      "evaluation/Returns Min                766.16\n",
      "evaluation/Estimation Bias Mean      1474.69\n",
      "evaluation/Estimation Bias Std        674.222\n",
      "evaluation/EB/Q_True Mean              64.699\n",
      "evaluation/EB/Q_True Std              146.166\n",
      "evaluation/EB/Q_Pred Mean            1539.39\n",
      "evaluation/EB/Q_Pred Std              642.8\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1398.31\n",
      "evaluation/Actions Mean                 0.125087\n",
      "evaluation/Actions Std                  0.630516\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90268\n",
      "time/backward_zf1 (s)                   2.41476\n",
      "time/backward_zf2 (s)                   2.28937\n",
      "time/data sampling (s)                  0.39367\n",
      "time/data storing (s)                   0.0158869\n",
      "time/evaluation sampling (s)            1.14886\n",
      "time/exploration sampling (s)           0.507621\n",
      "time/logging (s)                        0.00413694\n",
      "time/preback_alpha (s)                  0.59287\n",
      "time/preback_policy (s)                 1.13163\n",
      "time/preback_start (s)                  0.178959\n",
      "time/preback_zf (s)                     6.71826\n",
      "time/saving (s)                         2.784e-06\n",
      "time/training (s)                       3.27909\n",
      "time/epoch (s)                         20.5778\n",
      "time/total (s)                       3126.1\n",
      "Epoch                                 153\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:17:53.281957 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 154 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 165000\n",
      "trainer/ZF1 Loss                      301.865\n",
      "trainer/ZF2 Loss                      449.577\n",
      "trainer/ZF Expert Reward               14.1947\n",
      "trainer/ZF Policy Reward               10.731\n",
      "trainer/ZF CHI2 Term                  369.228\n",
      "trainer/Policy Loss                 -1443.27\n",
      "trainer/Bias Loss                      40.8729\n",
      "trainer/Bias Value                     17.2712\n",
      "trainer/Policy Grad Norm              235.415\n",
      "trainer/Policy Param Norm              50.0974\n",
      "trainer/Zf1 Grad Norm               19907.6\n",
      "trainer/Zf1 Param Norm                125.534\n",
      "trainer/Zf2 Grad Norm               29860.4\n",
      "trainer/Zf2 Param Norm                123.868\n",
      "trainer/Z Expert Predictions Mean    2063.64\n",
      "trainer/Z Expert Predictions Std       76.0425\n",
      "trainer/Z Expert Predictions Max     2151.04\n",
      "trainer/Z Expert Predictions Min     1578.11\n",
      "trainer/Z Policy Predictions Mean    1430.67\n",
      "trainer/Z Policy Predictions Std      643.92\n",
      "trainer/Z Policy Predictions Max     2071.4\n",
      "trainer/Z Policy Predictions Min        2.95502\n",
      "trainer/Z Expert Targets Mean        2049.45\n",
      "trainer/Z Expert Targets Std           76.4376\n",
      "trainer/Z Expert Targets Max         2146.11\n",
      "trainer/Z Expert Targets Min         1540.49\n",
      "trainer/Z Policy Targets Mean        1419.94\n",
      "trainer/Z Policy Targets Std          640.496\n",
      "trainer/Z Policy Targets Max         2059.06\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   58.1087\n",
      "trainer/Log Pis Std                    27.7666\n",
      "trainer/Policy mu Mean                  0.377006\n",
      "trainer/Policy mu Std                   3.05235\n",
      "trainer/Policy log std Mean            -2.85428\n",
      "trainer/Policy log std Std              1.20602\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        159119\n",
      "exploration/num paths total          1301\n",
      "evaluation/num steps total         642894\n",
      "evaluation/num paths total           1579\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.3108\n",
      "evaluation/Rewards Std                  0.0857453\n",
      "evaluation/Rewards Max                  5.49719\n",
      "evaluation/Rewards Min                  4.7933\n",
      "evaluation/Returns Mean              5310.8\n",
      "evaluation/Returns Std                 10.2867\n",
      "evaluation/Returns Max               5324.72\n",
      "evaluation/Returns Min               5290.7\n",
      "evaluation/Estimation Bias Mean      1972.74\n",
      "evaluation/Estimation Bias Std        170.785\n",
      "evaluation/EB/Q_True Mean              48.0416\n",
      "evaluation/EB/Q_True Std              147.935\n",
      "evaluation/EB/Q_Pred Mean            2020.78\n",
      "evaluation/EB/Q_Pred Std               89.5945\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5310.8\n",
      "evaluation/Actions Mean                 0.0747027\n",
      "evaluation/Actions Std                  0.495529\n",
      "evaluation/Actions Max                  0.999862\n",
      "evaluation/Actions Min                 -0.994426\n",
      "time/backward_policy (s)                1.79424\n",
      "time/backward_zf1 (s)                   2.2389\n",
      "time/backward_zf2 (s)                   2.13646\n",
      "time/data sampling (s)                  0.359316\n",
      "time/data storing (s)                   0.0157639\n",
      "time/evaluation sampling (s)            2.40903\n",
      "time/exploration sampling (s)           0.505473\n",
      "time/logging (s)                        0.0133599\n",
      "time/preback_alpha (s)                  0.584311\n",
      "time/preback_policy (s)                 1.01079\n",
      "time/preback_start (s)                  0.179546\n",
      "time/preback_zf (s)                     6.66311\n",
      "time/saving (s)                         3.289e-06\n",
      "time/training (s)                       3.62375\n",
      "time/epoch (s)                         21.534\n",
      "time/total (s)                       3147.65\n",
      "Epoch                                 154\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:18:14.761138 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 155 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 166000\n",
      "trainer/ZF1 Loss                      356.43\n",
      "trainer/ZF2 Loss                      342.12\n",
      "trainer/ZF Expert Reward               17.082\n",
      "trainer/ZF Policy Reward               12.5413\n",
      "trainer/ZF CHI2 Term                  345.595\n",
      "trainer/Policy Loss                 -1395.28\n",
      "trainer/Bias Loss                      20.9752\n",
      "trainer/Bias Value                     17.2454\n",
      "trainer/Policy Grad Norm              196.958\n",
      "trainer/Policy Param Norm              50.1571\n",
      "trainer/Zf1 Grad Norm               32686.6\n",
      "trainer/Zf1 Param Norm                125.875\n",
      "trainer/Zf2 Grad Norm               28806\n",
      "trainer/Zf2 Param Norm                124.222\n",
      "trainer/Z Expert Predictions Mean    2076.17\n",
      "trainer/Z Expert Predictions Std       62.8446\n",
      "trainer/Z Expert Predictions Max     2176.22\n",
      "trainer/Z Expert Predictions Min     1811.23\n",
      "trainer/Z Policy Predictions Mean    1384.66\n",
      "trainer/Z Policy Predictions Std      684.468\n",
      "trainer/Z Policy Predictions Max     2090.08\n",
      "trainer/Z Policy Predictions Min        5.03472\n",
      "trainer/Z Expert Targets Mean        2059.09\n",
      "trainer/Z Expert Targets Std           62.2293\n",
      "trainer/Z Expert Targets Max         2159.42\n",
      "trainer/Z Expert Targets Min         1801.98\n",
      "trainer/Z Policy Targets Mean        1372.12\n",
      "trainer/Z Policy Targets Std          686.857\n",
      "trainer/Z Policy Targets Max         2059.45\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   59.5424\n",
      "trainer/Log Pis Std                    28.2789\n",
      "trainer/Policy mu Mean                  0.314294\n",
      "trainer/Policy mu Std                   3.06252\n",
      "trainer/Policy log std Mean            -2.72552\n",
      "trainer/Policy log std Std              1.25855\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        159119\n",
      "exploration/num paths total          1301\n",
      "evaluation/num steps total         645434\n",
      "evaluation/num paths total           1589\n",
      "evaluation/path length Mean           254\n",
      "evaluation/path length Std            172.095\n",
      "evaluation/path length Max            744\n",
      "evaluation/path length Min            153\n",
      "evaluation/Rewards Mean                 5.17006\n",
      "evaluation/Rewards Std                  0.390263\n",
      "evaluation/Rewards Max                  6.47985\n",
      "evaluation/Rewards Min                  3.16369\n",
      "evaluation/Returns Mean              1313.2\n",
      "evaluation/Returns Std                937.311\n",
      "evaluation/Returns Max               3974.83\n",
      "evaluation/Returns Min                770.195\n",
      "evaluation/Estimation Bias Mean      1205.72\n",
      "evaluation/Estimation Bias Std        732.261\n",
      "evaluation/EB/Q_True Mean             119.945\n",
      "evaluation/EB/Q_True Std              201.607\n",
      "evaluation/EB/Q_Pred Mean            1325.66\n",
      "evaluation/EB/Q_Pred Std              663.434\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1313.2\n",
      "evaluation/Actions Mean                 0.119802\n",
      "evaluation/Actions Std                  0.695407\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89822\n",
      "time/backward_zf1 (s)                   2.35251\n",
      "time/backward_zf2 (s)                   2.2758\n",
      "time/data sampling (s)                  0.373352\n",
      "time/data storing (s)                   0.014941\n",
      "time/evaluation sampling (s)            2.23251\n",
      "time/exploration sampling (s)           0.485822\n",
      "time/logging (s)                        0.0041693\n",
      "time/preback_alpha (s)                  0.585072\n",
      "time/preback_policy (s)                 1.15599\n",
      "time/preback_start (s)                  0.178856\n",
      "time/preback_zf (s)                     6.66513\n",
      "time/saving (s)                         3.57701e-06\n",
      "time/training (s)                       3.17139\n",
      "time/epoch (s)                         21.3938\n",
      "time/total (s)                       3169.07\n",
      "Epoch                                 155\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:18:37.039245 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 156 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 167000\n",
      "trainer/ZF1 Loss                      328.555\n",
      "trainer/ZF2 Loss                      364.051\n",
      "trainer/ZF Expert Reward               11.5995\n",
      "trainer/ZF Policy Reward               10.901\n",
      "trainer/ZF CHI2 Term                  337.162\n",
      "trainer/Policy Loss                 -1336.61\n",
      "trainer/Bias Loss                      56.5516\n",
      "trainer/Bias Value                     17.2186\n",
      "trainer/Policy Grad Norm              276.394\n",
      "trainer/Policy Param Norm              50.2264\n",
      "trainer/Zf1 Grad Norm               23597.6\n",
      "trainer/Zf1 Param Norm                126.256\n",
      "trainer/Zf2 Grad Norm               29171.8\n",
      "trainer/Zf2 Param Norm                124.577\n",
      "trainer/Z Expert Predictions Mean    2075.56\n",
      "trainer/Z Expert Predictions Std       57.8438\n",
      "trainer/Z Expert Predictions Max     2171.43\n",
      "trainer/Z Expert Predictions Min     1802.58\n",
      "trainer/Z Policy Predictions Mean    1324.6\n",
      "trainer/Z Policy Predictions Std      700.585\n",
      "trainer/Z Policy Predictions Max     2092.46\n",
      "trainer/Z Policy Predictions Min       -9.10256\n",
      "trainer/Z Expert Targets Mean        2063.96\n",
      "trainer/Z Expert Targets Std           56.0735\n",
      "trainer/Z Expert Targets Max         2154.01\n",
      "trainer/Z Expert Targets Min         1795.6\n",
      "trainer/Z Policy Targets Mean        1313.7\n",
      "trainer/Z Policy Targets Std          701.504\n",
      "trainer/Z Policy Targets Max         2069.22\n",
      "trainer/Z Policy Targets Min          -27.418\n",
      "trainer/Log Pis Mean                   60.5816\n",
      "trainer/Log Pis Std                    28.8542\n",
      "trainer/Policy mu Mean                  0.319013\n",
      "trainer/Policy mu Std                   3.33429\n",
      "trainer/Policy log std Mean            -2.59799\n",
      "trainer/Policy log std Std              1.29526\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        161119\n",
      "exploration/num paths total          1303\n",
      "evaluation/num steps total         654730\n",
      "evaluation/num paths total           1599\n",
      "evaluation/path length Mean           929.6\n",
      "evaluation/path length Std            171.004\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            431\n",
      "evaluation/Rewards Mean                 5.25735\n",
      "evaluation/Rewards Std                  0.131077\n",
      "evaluation/Rewards Max                  5.84817\n",
      "evaluation/Rewards Min                  3.47368\n",
      "evaluation/Returns Mean              4887.23\n",
      "evaluation/Returns Std                926.682\n",
      "evaluation/Returns Max               5277.86\n",
      "evaluation/Returns Min               2185.49\n",
      "evaluation/Estimation Bias Mean      1908.06\n",
      "evaluation/Estimation Bias Std        293.745\n",
      "evaluation/EB/Q_True Mean              51.2361\n",
      "evaluation/EB/Q_True Std              151.517\n",
      "evaluation/EB/Q_Pred Mean            1959.29\n",
      "evaluation/EB/Q_Pred Std              219.395\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4887.23\n",
      "evaluation/Actions Mean                 0.0850118\n",
      "evaluation/Actions Std                  0.514872\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.99843\n",
      "time/backward_zf1 (s)                   2.46487\n",
      "time/backward_zf2 (s)                   2.37886\n",
      "time/data sampling (s)                  0.351575\n",
      "time/data storing (s)                   0.0154134\n",
      "time/evaluation sampling (s)            2.37082\n",
      "time/exploration sampling (s)           0.513581\n",
      "time/logging (s)                        0.0126043\n",
      "time/preback_alpha (s)                  0.603061\n",
      "time/preback_policy (s)                 1.17831\n",
      "time/preback_start (s)                  0.181939\n",
      "time/preback_zf (s)                     6.80288\n",
      "time/saving (s)                         4.004e-06\n",
      "time/training (s)                       3.3419\n",
      "time/epoch (s)                         22.2142\n",
      "time/total (s)                       3191.31\n",
      "Epoch                                 156\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:18:58.895147 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 157 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 168000\n",
      "trainer/ZF1 Loss                      413.556\n",
      "trainer/ZF2 Loss                      469.521\n",
      "trainer/ZF Expert Reward               21.066\n",
      "trainer/ZF Policy Reward               12.9994\n",
      "trainer/ZF CHI2 Term                  441.728\n",
      "trainer/Policy Loss                 -1407.14\n",
      "trainer/Bias Loss                      44.0461\n",
      "trainer/Bias Value                     17.1911\n",
      "trainer/Policy Grad Norm              215.798\n",
      "trainer/Policy Param Norm              50.3002\n",
      "trainer/Zf1 Grad Norm               31346.8\n",
      "trainer/Zf1 Param Norm                126.627\n",
      "trainer/Zf2 Grad Norm               25759.6\n",
      "trainer/Zf2 Param Norm                124.934\n",
      "trainer/Z Expert Predictions Mean    2087.4\n",
      "trainer/Z Expert Predictions Std       65.3365\n",
      "trainer/Z Expert Predictions Max     2183.52\n",
      "trainer/Z Expert Predictions Min     1820.87\n",
      "trainer/Z Policy Predictions Mean    1387.78\n",
      "trainer/Z Policy Predictions Std      709.194\n",
      "trainer/Z Policy Predictions Max     2108.84\n",
      "trainer/Z Policy Predictions Min       -9.8368\n",
      "trainer/Z Expert Targets Mean        2066.34\n",
      "trainer/Z Expert Targets Std           65.3963\n",
      "trainer/Z Expert Targets Max         2163.9\n",
      "trainer/Z Expert Targets Min         1798.4\n",
      "trainer/Z Policy Targets Mean        1374.78\n",
      "trainer/Z Policy Targets Std          707.34\n",
      "trainer/Z Policy Targets Max         2100.92\n",
      "trainer/Z Policy Targets Min          -16.01\n",
      "trainer/Log Pis Mean                   60.7381\n",
      "trainer/Log Pis Std                    30.5703\n",
      "trainer/Policy mu Mean                  0.0929361\n",
      "trainer/Policy mu Std                   3.80445\n",
      "trainer/Policy log std Mean            -2.67776\n",
      "trainer/Policy log std Std              1.34414\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        163148\n",
      "exploration/num paths total          1306\n",
      "evaluation/num steps total         662047\n",
      "evaluation/num paths total           1609\n",
      "evaluation/path length Mean           731.7\n",
      "evaluation/path length Std            410.309\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             60\n",
      "evaluation/Rewards Mean                 5.35413\n",
      "evaluation/Rewards Std                  0.153743\n",
      "evaluation/Rewards Max                  6.24303\n",
      "evaluation/Rewards Min                  3.47038\n",
      "evaluation/Returns Mean              3917.62\n",
      "evaluation/Returns Std               2217.69\n",
      "evaluation/Returns Max               5373.4\n",
      "evaluation/Returns Min                308.75\n",
      "evaluation/Estimation Bias Mean      1853.98\n",
      "evaluation/Estimation Bias Std        366.579\n",
      "evaluation/EB/Q_True Mean              66.3409\n",
      "evaluation/EB/Q_True Std              171.354\n",
      "evaluation/EB/Q_Pred Mean            1920.32\n",
      "evaluation/EB/Q_Pred Std              256.961\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3917.62\n",
      "evaluation/Actions Mean                 0.0664697\n",
      "evaluation/Actions Std                  0.534798\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93754\n",
      "time/backward_zf1 (s)                   2.40638\n",
      "time/backward_zf2 (s)                   2.31726\n",
      "time/data sampling (s)                  0.396272\n",
      "time/data storing (s)                   0.0151503\n",
      "time/evaluation sampling (s)            2.46203\n",
      "time/exploration sampling (s)           0.517565\n",
      "time/logging (s)                        0.010589\n",
      "time/preback_alpha (s)                  0.590979\n",
      "time/preback_policy (s)                 1.19062\n",
      "time/preback_start (s)                  0.185793\n",
      "time/preback_zf (s)                     6.71704\n",
      "time/saving (s)                         2.745e-06\n",
      "time/training (s)                       3.03847\n",
      "time/epoch (s)                         21.7857\n",
      "time/total (s)                       3213.12\n",
      "Epoch                                 157\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:19:21.045620 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 158 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 169000\n",
      "trainer/ZF1 Loss                      452.433\n",
      "trainer/ZF2 Loss                      496.402\n",
      "trainer/ZF Expert Reward               16.2145\n",
      "trainer/ZF Policy Reward                9.83404\n",
      "trainer/ZF CHI2 Term                  469.841\n",
      "trainer/Policy Loss                 -1370.65\n",
      "trainer/Bias Loss                      38.8414\n",
      "trainer/Bias Value                     17.1621\n",
      "trainer/Policy Grad Norm              256.519\n",
      "trainer/Policy Param Norm              50.3682\n",
      "trainer/Zf1 Grad Norm               26007.8\n",
      "trainer/Zf1 Param Norm                126.995\n",
      "trainer/Zf2 Grad Norm               29643.3\n",
      "trainer/Zf2 Param Norm                125.311\n",
      "trainer/Z Expert Predictions Mean    2077.55\n",
      "trainer/Z Expert Predictions Std       70.7931\n",
      "trainer/Z Expert Predictions Max     2168.66\n",
      "trainer/Z Expert Predictions Min     1509.79\n",
      "trainer/Z Policy Predictions Mean    1358.94\n",
      "trainer/Z Policy Predictions Std      727.307\n",
      "trainer/Z Policy Predictions Max     2100.43\n",
      "trainer/Z Policy Predictions Min      -17.1659\n",
      "trainer/Z Expert Targets Mean        2061.33\n",
      "trainer/Z Expert Targets Std           69.5965\n",
      "trainer/Z Expert Targets Max         2160.94\n",
      "trainer/Z Expert Targets Min         1491.48\n",
      "trainer/Z Policy Targets Mean        1349.11\n",
      "trainer/Z Policy Targets Std          730.163\n",
      "trainer/Z Policy Targets Max         2075.3\n",
      "trainer/Z Policy Targets Min          -20.4414\n",
      "trainer/Log Pis Mean                   62.439\n",
      "trainer/Log Pis Std                    26.9469\n",
      "trainer/Policy mu Mean                  0.322522\n",
      "trainer/Policy mu Std                   3.43787\n",
      "trainer/Policy log std Mean            -2.64963\n",
      "trainer/Policy log std Std              1.39986\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        166047\n",
      "exploration/num paths total          1309\n",
      "evaluation/num steps total         671180\n",
      "evaluation/num paths total           1619\n",
      "evaluation/path length Mean           913.3\n",
      "evaluation/path length Std            260.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            133\n",
      "evaluation/Rewards Mean                 5.31534\n",
      "evaluation/Rewards Std                  0.134125\n",
      "evaluation/Rewards Max                  5.53029\n",
      "evaluation/Rewards Min                  3.52784\n",
      "evaluation/Returns Mean              4854.5\n",
      "evaluation/Returns Std               1415.39\n",
      "evaluation/Returns Max               5331.54\n",
      "evaluation/Returns Min                608.352\n",
      "evaluation/Estimation Bias Mean      1887.79\n",
      "evaluation/Estimation Bias Std        249.049\n",
      "evaluation/EB/Q_True Mean              52.6822\n",
      "evaluation/EB/Q_True Std              154.251\n",
      "evaluation/EB/Q_Pred Mean            1940.47\n",
      "evaluation/EB/Q_Pred Std              155.64\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4854.5\n",
      "evaluation/Actions Mean                 0.079731\n",
      "evaluation/Actions Std                  0.506086\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91641\n",
      "time/backward_zf1 (s)                   2.37264\n",
      "time/backward_zf2 (s)                   2.31661\n",
      "time/data sampling (s)                  0.393723\n",
      "time/data storing (s)                   0.0150339\n",
      "time/evaluation sampling (s)            2.42621\n",
      "time/exploration sampling (s)           0.513833\n",
      "time/logging (s)                        0.0143598\n",
      "time/preback_alpha (s)                  0.600822\n",
      "time/preback_policy (s)                 1.13203\n",
      "time/preback_start (s)                  0.182273\n",
      "time/preback_zf (s)                     6.75228\n",
      "time/saving (s)                         2.905e-06\n",
      "time/training (s)                       3.43982\n",
      "time/epoch (s)                         22.076\n",
      "time/total (s)                       3235.22\n",
      "Epoch                                 158\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:19:42.610710 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 159 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 170000\n",
      "trainer/ZF1 Loss                      318.037\n",
      "trainer/ZF2 Loss                      291.503\n",
      "trainer/ZF Expert Reward               16.2949\n",
      "trainer/ZF Policy Reward                6.46475\n",
      "trainer/ZF CHI2 Term                  300.161\n",
      "trainer/Policy Loss                 -1392.29\n",
      "trainer/Bias Loss                      30.0755\n",
      "trainer/Bias Value                     17.1333\n",
      "trainer/Policy Grad Norm              201.624\n",
      "trainer/Policy Param Norm              50.4347\n",
      "trainer/Zf1 Grad Norm               23340.8\n",
      "trainer/Zf1 Param Norm                127.35\n",
      "trainer/Zf2 Grad Norm               18630.8\n",
      "trainer/Zf2 Param Norm                125.664\n",
      "trainer/Z Expert Predictions Mean    2091.78\n",
      "trainer/Z Expert Predictions Std       53.5004\n",
      "trainer/Z Expert Predictions Max     2187.51\n",
      "trainer/Z Expert Predictions Min     1819.71\n",
      "trainer/Z Policy Predictions Mean    1375.86\n",
      "trainer/Z Policy Predictions Std      696.018\n",
      "trainer/Z Policy Predictions Max     2111.26\n",
      "trainer/Z Policy Predictions Min      -11.9034\n",
      "trainer/Z Expert Targets Mean        2075.49\n",
      "trainer/Z Expert Targets Std           53.7354\n",
      "trainer/Z Expert Targets Max         2167.94\n",
      "trainer/Z Expert Targets Min         1809.11\n",
      "trainer/Z Policy Targets Mean        1369.39\n",
      "trainer/Z Policy Targets Std          696.155\n",
      "trainer/Z Policy Targets Max         2067.59\n",
      "trainer/Z Policy Targets Min          -16.802\n",
      "trainer/Log Pis Mean                   61.483\n",
      "trainer/Log Pis Std                    28.0155\n",
      "trainer/Policy mu Mean                  0.262876\n",
      "trainer/Policy mu Std                   3.54321\n",
      "trainer/Policy log std Mean            -2.6863\n",
      "trainer/Policy log std Std              1.35204\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        166047\n",
      "exploration/num paths total          1309\n",
      "evaluation/num steps total         676262\n",
      "evaluation/num paths total           1629\n",
      "evaluation/path length Mean           508.2\n",
      "evaluation/path length Std            411.369\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             97\n",
      "evaluation/Rewards Mean                 5.31079\n",
      "evaluation/Rewards Std                  0.14905\n",
      "evaluation/Rewards Max                  6.40331\n",
      "evaluation/Rewards Min                  4.74538\n",
      "evaluation/Returns Mean              2698.95\n",
      "evaluation/Returns Std               2198.67\n",
      "evaluation/Returns Max               5339.98\n",
      "evaluation/Returns Min                512.825\n",
      "evaluation/Estimation Bias Mean      1732.33\n",
      "evaluation/Estimation Bias Std        570.244\n",
      "evaluation/EB/Q_True Mean              94.7026\n",
      "evaluation/EB/Q_True Std              197.079\n",
      "evaluation/EB/Q_Pred Mean            1827.03\n",
      "evaluation/EB/Q_Pred Std              429.129\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2698.95\n",
      "evaluation/Actions Mean                 0.0778093\n",
      "evaluation/Actions Std                  0.572317\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.82802\n",
      "time/backward_zf1 (s)                   2.27049\n",
      "time/backward_zf2 (s)                   2.1926\n",
      "time/data sampling (s)                  0.386187\n",
      "time/data storing (s)                   0.0148648\n",
      "time/evaluation sampling (s)            2.33301\n",
      "time/exploration sampling (s)           0.492155\n",
      "time/logging (s)                        0.00756032\n",
      "time/preback_alpha (s)                  0.583392\n",
      "time/preback_policy (s)                 1.06939\n",
      "time/preback_start (s)                  0.182255\n",
      "time/preback_zf (s)                     6.67732\n",
      "time/saving (s)                         2.756e-06\n",
      "time/training (s)                       3.4547\n",
      "time/epoch (s)                         21.4919\n",
      "time/total (s)                       3256.73\n",
      "Epoch                                 159\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:20:04.688168 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 160 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 171000\n",
      "trainer/ZF1 Loss                      343.297\n",
      "trainer/ZF2 Loss                      481.861\n",
      "trainer/ZF Expert Reward               12.9245\n",
      "trainer/ZF Policy Reward                3.13017\n",
      "trainer/ZF CHI2 Term                  404.611\n",
      "trainer/Policy Loss                 -1338.52\n",
      "trainer/Bias Loss                      46.1876\n",
      "trainer/Bias Value                     17.1089\n",
      "trainer/Policy Grad Norm              211.159\n",
      "trainer/Policy Param Norm              50.4976\n",
      "trainer/Zf1 Grad Norm               25673.4\n",
      "trainer/Zf1 Param Norm                127.694\n",
      "trainer/Zf2 Grad Norm               38033\n",
      "trainer/Zf2 Param Norm                126.024\n",
      "trainer/Z Expert Predictions Mean    2081.7\n",
      "trainer/Z Expert Predictions Std      142.687\n",
      "trainer/Z Expert Predictions Max     2192.68\n",
      "trainer/Z Expert Predictions Min        0.726624\n",
      "trainer/Z Policy Predictions Mean    1320.48\n",
      "trainer/Z Policy Predictions Std      704.651\n",
      "trainer/Z Policy Predictions Max     2086.83\n",
      "trainer/Z Policy Predictions Min      -13.1968\n",
      "trainer/Z Expert Targets Mean        2068.77\n",
      "trainer/Z Expert Targets Std          142.037\n",
      "trainer/Z Expert Targets Max         2167.56\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1317.35\n",
      "trainer/Z Policy Targets Std          704.348\n",
      "trainer/Z Policy Targets Max         2057.37\n",
      "trainer/Z Policy Targets Min           -0.50839\n",
      "trainer/Log Pis Mean                   62.3929\n",
      "trainer/Log Pis Std                    28.3013\n",
      "trainer/Policy mu Mean                  0.121445\n",
      "trainer/Policy mu Std                   3.23875\n",
      "trainer/Policy log std Mean            -2.63642\n",
      "trainer/Policy log std Std              1.29812\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        167047\n",
      "exploration/num paths total          1310\n",
      "evaluation/num steps total         685531\n",
      "evaluation/num paths total           1640\n",
      "evaluation/path length Mean           842.636\n",
      "evaluation/path length Std            333.83\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            128\n",
      "evaluation/Rewards Mean                 5.30186\n",
      "evaluation/Rewards Std                  0.115593\n",
      "evaluation/Rewards Max                  6.24797\n",
      "evaluation/Rewards Min                  4.33357\n",
      "evaluation/Returns Mean              4467.54\n",
      "evaluation/Returns Std               1783.67\n",
      "evaluation/Returns Max               5315.89\n",
      "evaluation/Returns Min                679.445\n",
      "evaluation/Estimation Bias Mean      1927.38\n",
      "evaluation/Estimation Bias Std        316.286\n",
      "evaluation/EB/Q_True Mean              51.7308\n",
      "evaluation/EB/Q_True Std              152.735\n",
      "evaluation/EB/Q_Pred Mean            1979.11\n",
      "evaluation/EB/Q_Pred Std              221.594\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4467.54\n",
      "evaluation/Actions Mean                 0.0710048\n",
      "evaluation/Actions Std                  0.513012\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93238\n",
      "time/backward_zf1 (s)                   2.38877\n",
      "time/backward_zf2 (s)                   2.31013\n",
      "time/data sampling (s)                  0.368107\n",
      "time/data storing (s)                   0.0158074\n",
      "time/evaluation sampling (s)            2.69227\n",
      "time/exploration sampling (s)           0.497374\n",
      "time/logging (s)                        0.0131501\n",
      "time/preback_alpha (s)                  0.583515\n",
      "time/preback_policy (s)                 1.15837\n",
      "time/preback_start (s)                  0.176567\n",
      "time/preback_zf (s)                     6.67821\n",
      "time/saving (s)                         2.783e-06\n",
      "time/training (s)                       3.19685\n",
      "time/epoch (s)                         22.0115\n",
      "time/total (s)                       3278.77\n",
      "Epoch                                 160\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:20:25.965093 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 161 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 172000\n",
      "trainer/ZF1 Loss                      339.459\n",
      "trainer/ZF2 Loss                      356.939\n",
      "trainer/ZF Expert Reward               19.617\n",
      "trainer/ZF Policy Reward                9.11511\n",
      "trainer/ZF CHI2 Term                  346.74\n",
      "trainer/Policy Loss                 -1504.72\n",
      "trainer/Bias Loss                      35.2867\n",
      "trainer/Bias Value                     17.0839\n",
      "trainer/Policy Grad Norm              288.21\n",
      "trainer/Policy Param Norm              50.5599\n",
      "trainer/Zf1 Grad Norm               24302.8\n",
      "trainer/Zf1 Param Norm                128.056\n",
      "trainer/Zf2 Grad Norm               27943.7\n",
      "trainer/Zf2 Param Norm                126.366\n",
      "trainer/Z Expert Predictions Mean    2107.24\n",
      "trainer/Z Expert Predictions Std       46.866\n",
      "trainer/Z Expert Predictions Max     2184.18\n",
      "trainer/Z Expert Predictions Min     1817.15\n",
      "trainer/Z Policy Predictions Mean    1491.92\n",
      "trainer/Z Policy Predictions Std      689.8\n",
      "trainer/Z Policy Predictions Max     2113.67\n",
      "trainer/Z Policy Predictions Min        3.37779\n",
      "trainer/Z Expert Targets Mean        2087.62\n",
      "trainer/Z Expert Targets Std           46.2113\n",
      "trainer/Z Expert Targets Max         2170.28\n",
      "trainer/Z Expert Targets Min         1816.75\n",
      "trainer/Z Policy Targets Mean        1482.8\n",
      "trainer/Z Policy Targets Std          684.914\n",
      "trainer/Z Policy Targets Max         2097.41\n",
      "trainer/Z Policy Targets Min           -4.68666\n",
      "trainer/Log Pis Mean                   58.8589\n",
      "trainer/Log Pis Std                    27.5221\n",
      "trainer/Policy mu Mean                  0.181715\n",
      "trainer/Policy mu Std                   3.3199\n",
      "trainer/Policy log std Mean            -2.92264\n",
      "trainer/Policy log std Std              1.31181\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        167342\n",
      "exploration/num paths total          1311\n",
      "evaluation/num steps total         687362\n",
      "evaluation/num paths total           1650\n",
      "evaluation/path length Mean           183.1\n",
      "evaluation/path length Std             86.9867\n",
      "evaluation/path length Max            360\n",
      "evaluation/path length Min            101\n",
      "evaluation/Rewards Mean                 5.30842\n",
      "evaluation/Rewards Std                  0.391088\n",
      "evaluation/Rewards Max                  7.2835\n",
      "evaluation/Rewards Min                  3.3992\n",
      "evaluation/Returns Mean               971.972\n",
      "evaluation/Returns Std                482.565\n",
      "evaluation/Returns Max               1927.45\n",
      "evaluation/Returns Min                473.519\n",
      "evaluation/Estimation Bias Mean      1236.7\n",
      "evaluation/Estimation Bias Std        688.491\n",
      "evaluation/EB/Q_True Mean              60.2756\n",
      "evaluation/EB/Q_True Std              137.192\n",
      "evaluation/EB/Q_Pred Mean            1296.98\n",
      "evaluation/EB/Q_Pred Std              672.127\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns            971.972\n",
      "evaluation/Actions Mean                 0.112416\n",
      "evaluation/Actions Std                  0.688495\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.901\n",
      "time/backward_zf1 (s)                   2.34475\n",
      "time/backward_zf2 (s)                   2.25209\n",
      "time/data sampling (s)                  0.396708\n",
      "time/data storing (s)                   0.0147618\n",
      "time/evaluation sampling (s)            1.71148\n",
      "time/exploration sampling (s)           0.486685\n",
      "time/logging (s)                        0.00372759\n",
      "time/preback_alpha (s)                  0.600953\n",
      "time/preback_policy (s)                 1.07432\n",
      "time/preback_start (s)                  0.182861\n",
      "time/preback_zf (s)                     6.78526\n",
      "time/saving (s)                         3.217e-06\n",
      "time/training (s)                       3.43863\n",
      "time/epoch (s)                         21.1932\n",
      "time/total (s)                       3299.99\n",
      "Epoch                                 161\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:20:46.406722 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 162 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 173000\n",
      "trainer/ZF1 Loss                     4182.88\n",
      "trainer/ZF2 Loss                     3917.57\n",
      "trainer/ZF Expert Reward               13.5714\n",
      "trainer/ZF Policy Reward               15.3644\n",
      "trainer/ZF CHI2 Term                 4042.86\n",
      "trainer/Policy Loss                 -1361.07\n",
      "trainer/Bias Loss                      81.7274\n",
      "trainer/Bias Value                     17.0555\n",
      "trainer/Policy Grad Norm              253.255\n",
      "trainer/Policy Param Norm              50.6197\n",
      "trainer/Zf1 Grad Norm               63985.3\n",
      "trainer/Zf1 Param Norm                128.426\n",
      "trainer/Zf2 Grad Norm               76711\n",
      "trainer/Zf2 Param Norm                126.75\n",
      "trainer/Z Expert Predictions Mean    2086.74\n",
      "trainer/Z Expert Predictions Std      140.1\n",
      "trainer/Z Expert Predictions Max     2186.96\n",
      "trainer/Z Expert Predictions Min       50.43\n",
      "trainer/Z Policy Predictions Mean    1347.39\n",
      "trainer/Z Policy Predictions Std      750.201\n",
      "trainer/Z Policy Predictions Max     2133.05\n",
      "trainer/Z Policy Predictions Min      -22.7496\n",
      "trainer/Z Expert Targets Mean        2073.17\n",
      "trainer/Z Expert Targets Std          142.702\n",
      "trainer/Z Expert Targets Max         2178.83\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1332.02\n",
      "trainer/Z Policy Targets Std          752.33\n",
      "trainer/Z Policy Targets Max         2095.11\n",
      "trainer/Z Policy Targets Min           -1.1064\n",
      "trainer/Log Pis Mean                   64.0956\n",
      "trainer/Log Pis Std                    31.41\n",
      "trainer/Policy mu Mean                  0.339258\n",
      "trainer/Policy mu Std                   3.75133\n",
      "trainer/Policy log std Mean            -2.62707\n",
      "trainer/Policy log std Std              1.42355\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        168473\n",
      "exploration/num paths total          1313\n",
      "evaluation/num steps total         689590\n",
      "evaluation/num paths total           1660\n",
      "evaluation/path length Mean           222.8\n",
      "evaluation/path length Std            104.313\n",
      "evaluation/path length Max            386\n",
      "evaluation/path length Min             93\n",
      "evaluation/Rewards Mean                 5.20644\n",
      "evaluation/Rewards Std                  0.393651\n",
      "evaluation/Rewards Max                  6.54926\n",
      "evaluation/Rewards Min                  3.21994\n",
      "evaluation/Returns Mean              1159.99\n",
      "evaluation/Returns Std                583.021\n",
      "evaluation/Returns Max               2061.58\n",
      "evaluation/Returns Min                415.174\n",
      "evaluation/Estimation Bias Mean      1389.93\n",
      "evaluation/Estimation Bias Std        716.684\n",
      "evaluation/EB/Q_True Mean              53.1271\n",
      "evaluation/EB/Q_True Std              127.085\n",
      "evaluation/EB/Q_Pred Mean            1443.06\n",
      "evaluation/EB/Q_Pred Std              690.702\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1159.99\n",
      "evaluation/Actions Mean                 0.132299\n",
      "evaluation/Actions Std                  0.642953\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.92499\n",
      "time/backward_zf1 (s)                   2.33139\n",
      "time/backward_zf2 (s)                   2.2769\n",
      "time/data sampling (s)                  0.347864\n",
      "time/data storing (s)                   0.0152532\n",
      "time/evaluation sampling (s)            1.28555\n",
      "time/exploration sampling (s)           0.504063\n",
      "time/logging (s)                        0.0038249\n",
      "time/preback_alpha (s)                  0.578723\n",
      "time/preback_policy (s)                 1.18767\n",
      "time/preback_start (s)                  0.17945\n",
      "time/preback_zf (s)                     6.65307\n",
      "time/saving (s)                         2.921e-06\n",
      "time/training (s)                       3.08258\n",
      "time/epoch (s)                         20.3713\n",
      "time/total (s)                       3320.38\n",
      "Epoch                                 162\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:21:08.223546 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 163 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 174000\n",
      "trainer/ZF1 Loss                      319.843\n",
      "trainer/ZF2 Loss                      249.756\n",
      "trainer/ZF Expert Reward               18.6707\n",
      "trainer/ZF Policy Reward               12.6378\n",
      "trainer/ZF CHI2 Term                  282.388\n",
      "trainer/Policy Loss                 -1452.22\n",
      "trainer/Bias Loss                      34.0805\n",
      "trainer/Bias Value                     17.032\n",
      "trainer/Policy Grad Norm              229.977\n",
      "trainer/Policy Param Norm              50.6796\n",
      "trainer/Zf1 Grad Norm               20040.8\n",
      "trainer/Zf1 Param Norm                128.757\n",
      "trainer/Zf2 Grad Norm               14630.2\n",
      "trainer/Zf2 Param Norm                127.093\n",
      "trainer/Z Expert Predictions Mean    2106.34\n",
      "trainer/Z Expert Predictions Std       45.1549\n",
      "trainer/Z Expert Predictions Max     2185.35\n",
      "trainer/Z Expert Predictions Min     1853.62\n",
      "trainer/Z Policy Predictions Mean    1437.68\n",
      "trainer/Z Policy Predictions Std      699.101\n",
      "trainer/Z Policy Predictions Max     2126.12\n",
      "trainer/Z Policy Predictions Min       -5.56026\n",
      "trainer/Z Expert Targets Mean        2087.67\n",
      "trainer/Z Expert Targets Std           46.1914\n",
      "trainer/Z Expert Targets Max         2174.4\n",
      "trainer/Z Expert Targets Min         1835.63\n",
      "trainer/Z Policy Targets Mean        1425.04\n",
      "trainer/Z Policy Targets Std          696.911\n",
      "trainer/Z Policy Targets Max         2117.95\n",
      "trainer/Z Policy Targets Min           -7.86494\n",
      "trainer/Log Pis Mean                   59.3533\n",
      "trainer/Log Pis Std                    26.8547\n",
      "trainer/Policy mu Mean                  0.311199\n",
      "trainer/Policy mu Std                   3.19689\n",
      "trainer/Policy log std Mean            -2.80241\n",
      "trainer/Policy log std Std              1.32714\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        169565\n",
      "exploration/num paths total          1315\n",
      "evaluation/num steps total         697906\n",
      "evaluation/num paths total           1673\n",
      "evaluation/path length Mean           639.692\n",
      "evaluation/path length Std            299.101\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            166\n",
      "evaluation/Rewards Mean                 5.32672\n",
      "evaluation/Rewards Std                  0.141859\n",
      "evaluation/Rewards Max                  6.5961\n",
      "evaluation/Rewards Min                  4.82556\n",
      "evaluation/Returns Mean              3407.46\n",
      "evaluation/Returns Std               1595.09\n",
      "evaluation/Returns Max               5340.04\n",
      "evaluation/Returns Min                872.676\n",
      "evaluation/Estimation Bias Mean      1833.77\n",
      "evaluation/Estimation Bias Std        438.426\n",
      "evaluation/EB/Q_True Mean              57.98\n",
      "evaluation/EB/Q_True Std              161.117\n",
      "evaluation/EB/Q_Pred Mean            1891.75\n",
      "evaluation/EB/Q_Pred Std              389.122\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           3407.46\n",
      "evaluation/Actions Mean                 0.0799279\n",
      "evaluation/Actions Std                  0.545829\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.96657\n",
      "time/backward_zf1 (s)                   2.39298\n",
      "time/backward_zf2 (s)                   2.32648\n",
      "time/data sampling (s)                  0.367798\n",
      "time/data storing (s)                   0.0154786\n",
      "time/evaluation sampling (s)            2.42247\n",
      "time/exploration sampling (s)           0.504175\n",
      "time/logging (s)                        0.0113655\n",
      "time/preback_alpha (s)                  0.591061\n",
      "time/preback_policy (s)                 1.18633\n",
      "time/preback_start (s)                  0.182942\n",
      "time/preback_zf (s)                     6.71855\n",
      "time/saving (s)                         3.218e-06\n",
      "time/training (s)                       3.07445\n",
      "time/epoch (s)                         21.7607\n",
      "time/total (s)                       3342.16\n",
      "Epoch                                 163\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:21:30.065191 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 164 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 175000\n",
      "trainer/ZF1 Loss                      407.64\n",
      "trainer/ZF2 Loss                      398.811\n",
      "trainer/ZF Expert Reward               15.544\n",
      "trainer/ZF Policy Reward                6.75926\n",
      "trainer/ZF CHI2 Term                  397.752\n",
      "trainer/Policy Loss                 -1573.02\n",
      "trainer/Bias Loss                      47.4747\n",
      "trainer/Bias Value                     17.0056\n",
      "trainer/Policy Grad Norm              321.579\n",
      "trainer/Policy Param Norm              50.741\n",
      "trainer/Zf1 Grad Norm               26416\n",
      "trainer/Zf1 Param Norm                129.146\n",
      "trainer/Zf2 Grad Norm               30325.6\n",
      "trainer/Zf2 Param Norm                127.478\n",
      "trainer/Z Expert Predictions Mean    2089.21\n",
      "trainer/Z Expert Predictions Std      190.329\n",
      "trainer/Z Expert Predictions Max     2188.33\n",
      "trainer/Z Expert Predictions Min       20.266\n",
      "trainer/Z Policy Predictions Mean    1557.24\n",
      "trainer/Z Policy Predictions Std      596.726\n",
      "trainer/Z Policy Predictions Max     2097.41\n",
      "trainer/Z Policy Predictions Min      -13.4398\n",
      "trainer/Z Expert Targets Mean        2073.67\n",
      "trainer/Z Expert Targets Std          191.372\n",
      "trainer/Z Expert Targets Max         2172.83\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1550.48\n",
      "trainer/Z Policy Targets Std          592.496\n",
      "trainer/Z Policy Targets Max         2112\n",
      "trainer/Z Policy Targets Min          -20.4221\n",
      "trainer/Log Pis Mean                   56.1498\n",
      "trainer/Log Pis Std                    26.6766\n",
      "trainer/Policy mu Mean                  0.267525\n",
      "trainer/Policy mu Std                   3.03748\n",
      "trainer/Policy log std Mean            -2.94689\n",
      "trainer/Policy log std Std              1.16022\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        169713\n",
      "exploration/num paths total          1316\n",
      "evaluation/num steps total         707906\n",
      "evaluation/num paths total           1683\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.32325\n",
      "evaluation/Rewards Std                  0.0762715\n",
      "evaluation/Rewards Max                  5.50547\n",
      "evaluation/Rewards Min                  4.78314\n",
      "evaluation/Returns Mean              5323.25\n",
      "evaluation/Returns Std                  6.94759\n",
      "evaluation/Returns Max               5330\n",
      "evaluation/Returns Min               5307.28\n",
      "evaluation/Estimation Bias Mean      1983.3\n",
      "evaluation/Estimation Bias Std        176.379\n",
      "evaluation/EB/Q_True Mean              48.0634\n",
      "evaluation/EB/Q_True Std              148.042\n",
      "evaluation/EB/Q_Pred Mean            2031.37\n",
      "evaluation/EB/Q_Pred Std               93.1802\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5323.25\n",
      "evaluation/Actions Mean                 0.0785391\n",
      "evaluation/Actions Std                  0.510663\n",
      "evaluation/Actions Max                  0.99998\n",
      "evaluation/Actions Min                 -0.999573\n",
      "time/backward_policy (s)                1.94803\n",
      "time/backward_zf1 (s)                   2.40494\n",
      "time/backward_zf2 (s)                   2.3266\n",
      "time/data sampling (s)                  0.387605\n",
      "time/data storing (s)                   0.015001\n",
      "time/evaluation sampling (s)            2.31041\n",
      "time/exploration sampling (s)           0.488463\n",
      "time/logging (s)                        0.0129857\n",
      "time/preback_alpha (s)                  0.590592\n",
      "time/preback_policy (s)                 1.15558\n",
      "time/preback_start (s)                  0.177589\n",
      "time/preback_zf (s)                     6.73786\n",
      "time/saving (s)                         2.949e-06\n",
      "time/training (s)                       3.22024\n",
      "time/epoch (s)                         21.7759\n",
      "time/total (s)                       3363.95\n",
      "Epoch                                 164\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:21:51.635944 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 165 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 176000\n",
      "trainer/ZF1 Loss                      367.586\n",
      "trainer/ZF2 Loss                      318.407\n",
      "trainer/ZF Expert Reward               20.2738\n",
      "trainer/ZF Policy Reward               11.0865\n",
      "trainer/ZF CHI2 Term                  342.122\n",
      "trainer/Policy Loss                 -1378.33\n",
      "trainer/Bias Loss                      31.3239\n",
      "trainer/Bias Value                     16.9828\n",
      "trainer/Policy Grad Norm              216.821\n",
      "trainer/Policy Param Norm              50.8075\n",
      "trainer/Zf1 Grad Norm               26972.9\n",
      "trainer/Zf1 Param Norm                129.498\n",
      "trainer/Zf2 Grad Norm               17553.8\n",
      "trainer/Zf2 Param Norm                127.83\n",
      "trainer/Z Expert Predictions Mean    2112.77\n",
      "trainer/Z Expert Predictions Std       60.6853\n",
      "trainer/Z Expert Predictions Max     2202.81\n",
      "trainer/Z Expert Predictions Min     1558.15\n",
      "trainer/Z Policy Predictions Mean    1367.08\n",
      "trainer/Z Policy Predictions Std      755.165\n",
      "trainer/Z Policy Predictions Max     2129.85\n",
      "trainer/Z Policy Predictions Min       -5.50505\n",
      "trainer/Z Expert Targets Mean        2092.5\n",
      "trainer/Z Expert Targets Std           62.0249\n",
      "trainer/Z Expert Targets Max         2183.43\n",
      "trainer/Z Expert Targets Min         1533.01\n",
      "trainer/Z Policy Targets Mean        1356\n",
      "trainer/Z Policy Targets Std          752.562\n",
      "trainer/Z Policy Targets Max         2106.2\n",
      "trainer/Z Policy Targets Min           -2.78824\n",
      "trainer/Log Pis Mean                   61.5326\n",
      "trainer/Log Pis Std                    28.234\n",
      "trainer/Policy mu Mean                  0.203244\n",
      "trainer/Policy mu Std                   3.90822\n",
      "trainer/Policy log std Mean            -2.57102\n",
      "trainer/Policy log std Std              1.48865\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        169713\n",
      "exploration/num paths total          1316\n",
      "evaluation/num steps total         717052\n",
      "evaluation/num paths total           1693\n",
      "evaluation/path length Mean           914.6\n",
      "evaluation/path length Std            256.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            146\n",
      "evaluation/Rewards Mean                 5.2947\n",
      "evaluation/Rewards Std                  0.140068\n",
      "evaluation/Rewards Max                  5.51249\n",
      "evaluation/Rewards Min                  3.48697\n",
      "evaluation/Returns Mean              4842.53\n",
      "evaluation/Returns Std               1395.4\n",
      "evaluation/Returns Max               5317.02\n",
      "evaluation/Returns Min                656.372\n",
      "evaluation/Estimation Bias Mean      1968.7\n",
      "evaluation/Estimation Bias Std        275.352\n",
      "evaluation/EB/Q_True Mean              52.3524\n",
      "evaluation/EB/Q_True Std              153.437\n",
      "evaluation/EB/Q_Pred Mean            2021.05\n",
      "evaluation/EB/Q_Pred Std              187.18\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4842.53\n",
      "evaluation/Actions Mean                 0.0729233\n",
      "evaluation/Actions Std                  0.502315\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75192\n",
      "time/backward_zf1 (s)                   2.20341\n",
      "time/backward_zf2 (s)                   2.09584\n",
      "time/data sampling (s)                  0.36965\n",
      "time/data storing (s)                   0.0151916\n",
      "time/evaluation sampling (s)            2.47254\n",
      "time/exploration sampling (s)           0.482766\n",
      "time/logging (s)                        0.0122729\n",
      "time/preback_alpha (s)                  0.578786\n",
      "time/preback_policy (s)                 0.98513\n",
      "time/preback_start (s)                  0.175295\n",
      "time/preback_zf (s)                     6.63679\n",
      "time/saving (s)                         3.189e-06\n",
      "time/training (s)                       3.72449\n",
      "time/epoch (s)                         21.5041\n",
      "time/total (s)                       3385.47\n",
      "Epoch                                 165\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:22:13.372133 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 166 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 177000\n",
      "trainer/ZF1 Loss                      388.202\n",
      "trainer/ZF2 Loss                      393.278\n",
      "trainer/ZF Expert Reward               16.8961\n",
      "trainer/ZF Policy Reward               11.3916\n",
      "trainer/ZF CHI2 Term                  386.572\n",
      "trainer/Policy Loss                 -1473.71\n",
      "trainer/Bias Loss                      53.4792\n",
      "trainer/Bias Value                     16.9603\n",
      "trainer/Policy Grad Norm              262.946\n",
      "trainer/Policy Param Norm              50.8704\n",
      "trainer/Zf1 Grad Norm               23757.2\n",
      "trainer/Zf1 Param Norm                129.862\n",
      "trainer/Zf2 Grad Norm               26115.2\n",
      "trainer/Zf2 Param Norm                128.184\n",
      "trainer/Z Expert Predictions Mean    2104.58\n",
      "trainer/Z Expert Predictions Std       73.0513\n",
      "trainer/Z Expert Predictions Max     2199.5\n",
      "trainer/Z Expert Predictions Min     1367.36\n",
      "trainer/Z Policy Predictions Mean    1465.76\n",
      "trainer/Z Policy Predictions Std      682.267\n",
      "trainer/Z Policy Predictions Max     2102.77\n",
      "trainer/Z Policy Predictions Min       -4.1441\n",
      "trainer/Z Expert Targets Mean        2087.69\n",
      "trainer/Z Expert Targets Std           68.1081\n",
      "trainer/Z Expert Targets Max         2197.3\n",
      "trainer/Z Expert Targets Min         1464\n",
      "trainer/Z Policy Targets Mean        1454.37\n",
      "trainer/Z Policy Targets Std          678.334\n",
      "trainer/Z Policy Targets Max         2091.14\n",
      "trainer/Z Policy Targets Min           -3.5067\n",
      "trainer/Log Pis Mean                   56.5902\n",
      "trainer/Log Pis Std                    23.6322\n",
      "trainer/Policy mu Mean                  0.255831\n",
      "trainer/Policy mu Std                   3.09053\n",
      "trainer/Policy log std Mean            -2.80166\n",
      "trainer/Policy log std Std              1.31544\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        170713\n",
      "exploration/num paths total          1317\n",
      "evaluation/num steps total         725645\n",
      "evaluation/num paths total           1703\n",
      "evaluation/path length Mean           859.3\n",
      "evaluation/path length Std            225.826\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            375\n",
      "evaluation/Rewards Mean                 5.32315\n",
      "evaluation/Rewards Std                  0.107498\n",
      "evaluation/Rewards Max                  6.16337\n",
      "evaluation/Rewards Min                  4.82444\n",
      "evaluation/Returns Mean              4574.19\n",
      "evaluation/Returns Std               1198.46\n",
      "evaluation/Returns Max               5332.19\n",
      "evaluation/Returns Min               1990.33\n",
      "evaluation/Estimation Bias Mean      1896.1\n",
      "evaluation/Estimation Bias Std        395.785\n",
      "evaluation/EB/Q_True Mean              56.0022\n",
      "evaluation/EB/Q_True Std              158.5\n",
      "evaluation/EB/Q_Pred Mean            1952.1\n",
      "evaluation/EB/Q_Pred Std              306.737\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4574.19\n",
      "evaluation/Actions Mean                 0.0798472\n",
      "evaluation/Actions Std                  0.529858\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.94118\n",
      "time/backward_zf1 (s)                   2.40373\n",
      "time/backward_zf2 (s)                   2.32268\n",
      "time/data sampling (s)                  0.386781\n",
      "time/data storing (s)                   0.0150402\n",
      "time/evaluation sampling (s)            2.5076\n",
      "time/exploration sampling (s)           0.499247\n",
      "time/logging (s)                        0.0120751\n",
      "time/preback_alpha (s)                  0.580185\n",
      "time/preback_policy (s)                 1.19707\n",
      "time/preback_start (s)                  0.178334\n",
      "time/preback_zf (s)                     6.62081\n",
      "time/saving (s)                         3.597e-06\n",
      "time/training (s)                       3.00241\n",
      "time/epoch (s)                         21.6671\n",
      "time/total (s)                       3407.16\n",
      "Epoch                                 166\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:22:35.396296 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 167 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 178000\n",
      "trainer/ZF1 Loss                      383.503\n",
      "trainer/ZF2 Loss                      375.932\n",
      "trainer/ZF Expert Reward               14.8657\n",
      "trainer/ZF Policy Reward                4.13952\n",
      "trainer/ZF CHI2 Term                  373.556\n",
      "trainer/Policy Loss                 -1471.96\n",
      "trainer/Bias Loss                      37.2575\n",
      "trainer/Bias Value                     16.937\n",
      "trainer/Policy Grad Norm              250.905\n",
      "trainer/Policy Param Norm              50.9311\n",
      "trainer/Zf1 Grad Norm               19135.2\n",
      "trainer/Zf1 Param Norm                130.212\n",
      "trainer/Zf2 Grad Norm               23372.1\n",
      "trainer/Zf2 Param Norm                128.544\n",
      "trainer/Z Expert Predictions Mean    2103.15\n",
      "trainer/Z Expert Predictions Std       47.6237\n",
      "trainer/Z Expert Predictions Max     2195.29\n",
      "trainer/Z Expert Predictions Min     1881.28\n",
      "trainer/Z Policy Predictions Mean    1449.9\n",
      "trainer/Z Policy Predictions Std      662.217\n",
      "trainer/Z Policy Predictions Max     2073.06\n",
      "trainer/Z Policy Predictions Min      -10.7598\n",
      "trainer/Z Expert Targets Mean        2088.29\n",
      "trainer/Z Expert Targets Std           47.8232\n",
      "trainer/Z Expert Targets Max         2187.64\n",
      "trainer/Z Expert Targets Min         1863.16\n",
      "trainer/Z Policy Targets Mean        1445.76\n",
      "trainer/Z Policy Targets Std          664.144\n",
      "trainer/Z Policy Targets Max         2077.79\n",
      "trainer/Z Policy Targets Min          -20.5561\n",
      "trainer/Log Pis Mean                   59.2447\n",
      "trainer/Log Pis Std                    27.4534\n",
      "trainer/Policy mu Mean                  0.221526\n",
      "trainer/Policy mu Std                   3.62662\n",
      "trainer/Policy log std Mean            -2.78193\n",
      "trainer/Policy log std Std              1.35465\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        173713\n",
      "exploration/num paths total          1320\n",
      "evaluation/num steps total         735645\n",
      "evaluation/num paths total           1713\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29926\n",
      "evaluation/Rewards Std                  0.0781802\n",
      "evaluation/Rewards Max                  5.50897\n",
      "evaluation/Rewards Min                  4.79249\n",
      "evaluation/Returns Mean              5299.26\n",
      "evaluation/Returns Std                  5.81349\n",
      "evaluation/Returns Max               5308.25\n",
      "evaluation/Returns Min               5290.22\n",
      "evaluation/Estimation Bias Mean      1978.61\n",
      "evaluation/Estimation Bias Std        172.77\n",
      "evaluation/EB/Q_True Mean              47.8982\n",
      "evaluation/EB/Q_True Std              147.503\n",
      "evaluation/EB/Q_Pred Mean            2026.5\n",
      "evaluation/EB/Q_Pred Std               77.8726\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5299.26\n",
      "evaluation/Actions Mean                 0.0719992\n",
      "evaluation/Actions Std                  0.522506\n",
      "evaluation/Actions Max                  0.999813\n",
      "evaluation/Actions Min                 -0.996619\n",
      "time/backward_policy (s)                2.00324\n",
      "time/backward_zf1 (s)                   2.44813\n",
      "time/backward_zf2 (s)                   2.37983\n",
      "time/data sampling (s)                  0.393257\n",
      "time/data storing (s)                   0.0150971\n",
      "time/evaluation sampling (s)            2.53969\n",
      "time/exploration sampling (s)           0.503339\n",
      "time/logging (s)                        0.0139643\n",
      "time/preback_alpha (s)                  0.59007\n",
      "time/preback_policy (s)                 1.21621\n",
      "time/preback_start (s)                  0.181436\n",
      "time/preback_zf (s)                     6.68734\n",
      "time/saving (s)                         3.319e-06\n",
      "time/training (s)                       2.98343\n",
      "time/epoch (s)                         21.955\n",
      "time/total (s)                       3429.14\n",
      "Epoch                                 167\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:22:57.112667 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 168 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 179000\n",
      "trainer/ZF1 Loss                      352.679\n",
      "trainer/ZF2 Loss                      303.64\n",
      "trainer/ZF Expert Reward               11.0779\n",
      "trainer/ZF Policy Reward                3.60709\n",
      "trainer/ZF CHI2 Term                  318.203\n",
      "trainer/Policy Loss                 -1491.75\n",
      "trainer/Bias Loss                      72.0201\n",
      "trainer/Bias Value                     16.9094\n",
      "trainer/Policy Grad Norm              319.6\n",
      "trainer/Policy Param Norm              50.9984\n",
      "trainer/Zf1 Grad Norm               22576.2\n",
      "trainer/Zf1 Param Norm                130.583\n",
      "trainer/Zf2 Grad Norm               21557.2\n",
      "trainer/Zf2 Param Norm                128.935\n",
      "trainer/Z Expert Predictions Mean    2100.51\n",
      "trainer/Z Expert Predictions Std      141.061\n",
      "trainer/Z Expert Predictions Max     2204.57\n",
      "trainer/Z Expert Predictions Min      -11.2207\n",
      "trainer/Z Policy Predictions Mean    1475.41\n",
      "trainer/Z Policy Predictions Std      638.099\n",
      "trainer/Z Policy Predictions Max     2099.15\n",
      "trainer/Z Policy Predictions Min       25.0199\n",
      "trainer/Z Expert Targets Mean        2089.43\n",
      "trainer/Z Expert Targets Std          139.683\n",
      "trainer/Z Expert Targets Max         2187.15\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1471.81\n",
      "trainer/Z Policy Targets Std          638.147\n",
      "trainer/Z Policy Targets Max         2084.54\n",
      "trainer/Z Policy Targets Min           14.918\n",
      "trainer/Log Pis Mean                   58.9338\n",
      "trainer/Log Pis Std                    23.976\n",
      "trainer/Policy mu Mean                  0.188763\n",
      "trainer/Policy mu Std                   2.87021\n",
      "trainer/Policy log std Mean            -2.92486\n",
      "trainer/Policy log std Std              1.13282\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        175713\n",
      "exploration/num paths total          1322\n",
      "evaluation/num steps total         743776\n",
      "evaluation/num paths total           1725\n",
      "evaluation/path length Mean           677.583\n",
      "evaluation/path length Std            352.886\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            126\n",
      "evaluation/Rewards Mean                 5.30045\n",
      "evaluation/Rewards Std                  0.124013\n",
      "evaluation/Rewards Max                  6.39793\n",
      "evaluation/Rewards Min                  4.36377\n",
      "evaluation/Returns Mean              3591.5\n",
      "evaluation/Returns Std               1888.47\n",
      "evaluation/Returns Max               5329.14\n",
      "evaluation/Returns Min                601.404\n",
      "evaluation/Estimation Bias Mean      1862.85\n",
      "evaluation/Estimation Bias Std        448.683\n",
      "evaluation/EB/Q_True Mean              59.109\n",
      "evaluation/EB/Q_True Std              162.173\n",
      "evaluation/EB/Q_Pred Mean            1921.96\n",
      "evaluation/EB/Q_Pred Std              366.726\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3591.5\n",
      "evaluation/Actions Mean                 0.0800424\n",
      "evaluation/Actions Std                  0.548987\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95966\n",
      "time/backward_zf1 (s)                   2.40406\n",
      "time/backward_zf2 (s)                   2.34572\n",
      "time/data sampling (s)                  0.378802\n",
      "time/data storing (s)                   0.015673\n",
      "time/evaluation sampling (s)            2.26934\n",
      "time/exploration sampling (s)           0.495221\n",
      "time/logging (s)                        0.0109855\n",
      "time/preback_alpha (s)                  0.589047\n",
      "time/preback_policy (s)                 1.19075\n",
      "time/preback_start (s)                  0.184615\n",
      "time/preback_zf (s)                     6.69948\n",
      "time/saving (s)                         2.573e-06\n",
      "time/training (s)                       3.09422\n",
      "time/epoch (s)                         21.6376\n",
      "time/total (s)                       3450.81\n",
      "Epoch                                 168\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:23:18.877123 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 169 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 180000\n",
      "trainer/ZF1 Loss                      389.133\n",
      "trainer/ZF2 Loss                      424.191\n",
      "trainer/ZF Expert Reward               10.4707\n",
      "trainer/ZF Policy Reward               -1.5997\n",
      "trainer/ZF CHI2 Term                  396.111\n",
      "trainer/Policy Loss                 -1423.81\n",
      "trainer/Bias Loss                      54.1439\n",
      "trainer/Bias Value                     16.8859\n",
      "trainer/Policy Grad Norm              324.431\n",
      "trainer/Policy Param Norm              51.0681\n",
      "trainer/Zf1 Grad Norm               30388.1\n",
      "trainer/Zf1 Param Norm                130.937\n",
      "trainer/Zf2 Grad Norm               33783.2\n",
      "trainer/Zf2 Param Norm                129.282\n",
      "trainer/Z Expert Predictions Mean    2100.82\n",
      "trainer/Z Expert Predictions Std       50.5555\n",
      "trainer/Z Expert Predictions Max     2192.41\n",
      "trainer/Z Expert Predictions Min     1883.77\n",
      "trainer/Z Policy Predictions Mean    1401.98\n",
      "trainer/Z Policy Predictions Std      708.693\n",
      "trainer/Z Policy Predictions Max     2087.28\n",
      "trainer/Z Policy Predictions Min        4.83263\n",
      "trainer/Z Expert Targets Mean        2090.35\n",
      "trainer/Z Expert Targets Std           50.6979\n",
      "trainer/Z Expert Targets Max         2189.17\n",
      "trainer/Z Expert Targets Min         1871.95\n",
      "trainer/Z Policy Targets Mean        1403.58\n",
      "trainer/Z Policy Targets Std          709.006\n",
      "trainer/Z Policy Targets Max         2128.74\n",
      "trainer/Z Policy Targets Min           -5.63924\n",
      "trainer/Log Pis Mean                   60.8068\n",
      "trainer/Log Pis Std                    26.7788\n",
      "trainer/Policy mu Mean                  0.282363\n",
      "trainer/Policy mu Std                   3.10093\n",
      "trainer/Policy log std Mean            -2.82577\n",
      "trainer/Policy log std Std              1.22976\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        175713\n",
      "exploration/num paths total          1322\n",
      "evaluation/num steps total         753776\n",
      "evaluation/num paths total           1735\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33108\n",
      "evaluation/Rewards Std                  0.0863347\n",
      "evaluation/Rewards Max                  5.49769\n",
      "evaluation/Rewards Min                  4.7972\n",
      "evaluation/Returns Mean              5331.08\n",
      "evaluation/Returns Std                  7.3779\n",
      "evaluation/Returns Max               5338.84\n",
      "evaluation/Returns Min               5312.84\n",
      "evaluation/Estimation Bias Mean      2001.28\n",
      "evaluation/Estimation Bias Std        173.629\n",
      "evaluation/EB/Q_True Mean              48.1759\n",
      "evaluation/EB/Q_True Std              148.37\n",
      "evaluation/EB/Q_Pred Mean            2049.46\n",
      "evaluation/EB/Q_Pred Std               88.6328\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5331.08\n",
      "evaluation/Actions Mean                 0.0685866\n",
      "evaluation/Actions Std                  0.507366\n",
      "evaluation/Actions Max                  0.99922\n",
      "evaluation/Actions Min                 -0.997967\n",
      "time/backward_policy (s)                1.86922\n",
      "time/backward_zf1 (s)                   2.31932\n",
      "time/backward_zf2 (s)                   2.23357\n",
      "time/data sampling (s)                  0.389989\n",
      "time/data storing (s)                   0.0147838\n",
      "time/evaluation sampling (s)            2.47647\n",
      "time/exploration sampling (s)           0.472403\n",
      "time/logging (s)                        0.0135118\n",
      "time/preback_alpha (s)                  0.582407\n",
      "time/preback_policy (s)                 1.07819\n",
      "time/preback_start (s)                  0.178346\n",
      "time/preback_zf (s)                     6.66139\n",
      "time/saving (s)                         2.829e-06\n",
      "time/training (s)                       3.40625\n",
      "time/epoch (s)                         21.6959\n",
      "time/total (s)                       3472.53\n",
      "Epoch                                 169\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:23:41.109165 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 170 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 181000\n",
      "trainer/ZF1 Loss                      360.193\n",
      "trainer/ZF2 Loss                      393.836\n",
      "trainer/ZF Expert Reward               13.6004\n",
      "trainer/ZF Policy Reward                6.44689\n",
      "trainer/ZF CHI2 Term                  369.554\n",
      "trainer/Policy Loss                 -1404.64\n",
      "trainer/Bias Loss                      48.0286\n",
      "trainer/Bias Value                     16.8566\n",
      "trainer/Policy Grad Norm              245.74\n",
      "trainer/Policy Param Norm              51.1368\n",
      "trainer/Zf1 Grad Norm               23129.9\n",
      "trainer/Zf1 Param Norm                131.312\n",
      "trainer/Zf2 Grad Norm               32062.7\n",
      "trainer/Zf2 Param Norm                129.658\n",
      "trainer/Z Expert Predictions Mean    2099.72\n",
      "trainer/Z Expert Predictions Std      142.1\n",
      "trainer/Z Expert Predictions Max     2209.07\n",
      "trainer/Z Expert Predictions Min      -13.0827\n",
      "trainer/Z Policy Predictions Mean    1393.75\n",
      "trainer/Z Policy Predictions Std      729.467\n",
      "trainer/Z Policy Predictions Max     2092.69\n",
      "trainer/Z Policy Predictions Min      -17.8454\n",
      "trainer/Z Expert Targets Mean        2086.12\n",
      "trainer/Z Expert Targets Std          141.197\n",
      "trainer/Z Expert Targets Max         2191.01\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1387.3\n",
      "trainer/Z Policy Targets Std          732.847\n",
      "trainer/Z Policy Targets Max         2090.58\n",
      "trainer/Z Policy Targets Min          -14.2808\n",
      "trainer/Log Pis Mean                   62.2134\n",
      "trainer/Log Pis Std                    29.4075\n",
      "trainer/Policy mu Mean                  0.236249\n",
      "trainer/Policy mu Std                   3.74464\n",
      "trainer/Policy log std Mean            -2.65538\n",
      "trainer/Policy log std Std              1.3967\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        176713\n",
      "exploration/num paths total          1323\n",
      "evaluation/num steps total         763339\n",
      "evaluation/num paths total           1745\n",
      "evaluation/path length Mean           956.3\n",
      "evaluation/path length Std            131.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            563\n",
      "evaluation/Rewards Mean                 5.31387\n",
      "evaluation/Rewards Std                  0.0904141\n",
      "evaluation/Rewards Max                  5.59765\n",
      "evaluation/Rewards Min                  4.5267\n",
      "evaluation/Returns Mean              5081.65\n",
      "evaluation/Returns Std                698.817\n",
      "evaluation/Returns Max               5324.48\n",
      "evaluation/Returns Min               2985.29\n",
      "evaluation/Estimation Bias Mean      1956.52\n",
      "evaluation/Estimation Bias Std        269.252\n",
      "evaluation/EB/Q_True Mean              50.1716\n",
      "evaluation/EB/Q_True Std              150.732\n",
      "evaluation/EB/Q_Pred Mean            2006.69\n",
      "evaluation/EB/Q_Pred Std              189.051\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5081.65\n",
      "evaluation/Actions Mean                 0.0755752\n",
      "evaluation/Actions Std                  0.528538\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91818\n",
      "time/backward_zf1 (s)                   2.39915\n",
      "time/backward_zf2 (s)                   2.29136\n",
      "time/data sampling (s)                  0.38154\n",
      "time/data storing (s)                   0.0162709\n",
      "time/evaluation sampling (s)            2.76304\n",
      "time/exploration sampling (s)           0.51212\n",
      "time/logging (s)                        0.0129285\n",
      "time/preback_alpha (s)                  0.591615\n",
      "time/preback_policy (s)                 1.15788\n",
      "time/preback_start (s)                  0.184031\n",
      "time/preback_zf (s)                     6.72935\n",
      "time/saving (s)                         3.824e-06\n",
      "time/training (s)                       3.20092\n",
      "time/epoch (s)                         22.1584\n",
      "time/total (s)                       3494.71\n",
      "Epoch                                 170\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:24:03.054915 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 171 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 182000\n",
      "trainer/ZF1 Loss                      387.425\n",
      "trainer/ZF2 Loss                      387.38\n",
      "trainer/ZF Expert Reward               12.9423\n",
      "trainer/ZF Policy Reward                6.59296\n",
      "trainer/ZF CHI2 Term                  379.248\n",
      "trainer/Policy Loss                 -1484.69\n",
      "trainer/Bias Loss                      41.8032\n",
      "trainer/Bias Value                     16.8288\n",
      "trainer/Policy Grad Norm              215.259\n",
      "trainer/Policy Param Norm              51.2011\n",
      "trainer/Zf1 Grad Norm               24976.7\n",
      "trainer/Zf1 Param Norm                131.681\n",
      "trainer/Zf2 Grad Norm               23743.8\n",
      "trainer/Zf2 Param Norm                130.025\n",
      "trainer/Z Expert Predictions Mean    2103.03\n",
      "trainer/Z Expert Predictions Std      138.606\n",
      "trainer/Z Expert Predictions Max     2215.93\n",
      "trainer/Z Expert Predictions Min       38.1809\n",
      "trainer/Z Policy Predictions Mean    1472.02\n",
      "trainer/Z Policy Predictions Std      693.771\n",
      "trainer/Z Policy Predictions Max     2120.77\n",
      "trainer/Z Policy Predictions Min       -5.78475\n",
      "trainer/Z Expert Targets Mean        2090.09\n",
      "trainer/Z Expert Targets Std          140.39\n",
      "trainer/Z Expert Targets Max         2203.02\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1465.42\n",
      "trainer/Z Policy Targets Std          693.743\n",
      "trainer/Z Policy Targets Max         2139.75\n",
      "trainer/Z Policy Targets Min          -14.2801\n",
      "trainer/Log Pis Mean                   58.4194\n",
      "trainer/Log Pis Std                    26.7682\n",
      "trainer/Policy mu Mean                  0.253755\n",
      "trainer/Policy mu Std                   3.738\n",
      "trainer/Policy log std Mean            -2.76417\n",
      "trainer/Policy log std Std              1.43751\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        176713\n",
      "exploration/num paths total          1323\n",
      "evaluation/num steps total         773339\n",
      "evaluation/num paths total           1755\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30607\n",
      "evaluation/Rewards Std                  0.0777448\n",
      "evaluation/Rewards Max                  5.55291\n",
      "evaluation/Rewards Min                  4.82901\n",
      "evaluation/Returns Mean              5306.07\n",
      "evaluation/Returns Std                  3.62809\n",
      "evaluation/Returns Max               5310.48\n",
      "evaluation/Returns Min               5299.5\n",
      "evaluation/Estimation Bias Mean      1947.92\n",
      "evaluation/Estimation Bias Std        186.365\n",
      "evaluation/EB/Q_True Mean              47.9509\n",
      "evaluation/EB/Q_True Std              147.678\n",
      "evaluation/EB/Q_Pred Mean            1995.87\n",
      "evaluation/EB/Q_Pred Std              129.449\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5306.07\n",
      "evaluation/Actions Mean                 0.0521013\n",
      "evaluation/Actions Std                  0.511814\n",
      "evaluation/Actions Max                  0.999965\n",
      "evaluation/Actions Min                 -0.999525\n",
      "time/backward_policy (s)                1.82614\n",
      "time/backward_zf1 (s)                   2.2953\n",
      "time/backward_zf2 (s)                   2.19308\n",
      "time/data sampling (s)                  0.370502\n",
      "time/data storing (s)                   0.0153948\n",
      "time/evaluation sampling (s)            2.6781\n",
      "time/exploration sampling (s)           0.494485\n",
      "time/logging (s)                        0.0128593\n",
      "time/preback_alpha (s)                  0.588386\n",
      "time/preback_policy (s)                 1.06244\n",
      "time/preback_start (s)                  0.181038\n",
      "time/preback_zf (s)                     6.67023\n",
      "time/saving (s)                         3.41e-06\n",
      "time/training (s)                       3.48543\n",
      "time/epoch (s)                         21.8734\n",
      "time/total (s)                       3516.61\n",
      "Epoch                                 171\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:24:24.671357 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 172 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 183000\n",
      "trainer/ZF1 Loss                      403.416\n",
      "trainer/ZF2 Loss                      425.494\n",
      "trainer/ZF Expert Reward               13.2106\n",
      "trainer/ZF Policy Reward                0.131704\n",
      "trainer/ZF CHI2 Term                  406.585\n",
      "trainer/Policy Loss                 -1396.04\n",
      "trainer/Bias Loss                      46.7423\n",
      "trainer/Bias Value                     16.8026\n",
      "trainer/Policy Grad Norm              231.91\n",
      "trainer/Policy Param Norm              51.2652\n",
      "trainer/Zf1 Grad Norm               35874\n",
      "trainer/Zf1 Param Norm                132.044\n",
      "trainer/Zf2 Grad Norm               26666.9\n",
      "trainer/Zf2 Param Norm                130.387\n",
      "trainer/Z Expert Predictions Mean    2108.39\n",
      "trainer/Z Expert Predictions Std       46.7284\n",
      "trainer/Z Expert Predictions Max     2212.17\n",
      "trainer/Z Expert Predictions Min     1887.24\n",
      "trainer/Z Policy Predictions Mean    1380.27\n",
      "trainer/Z Policy Predictions Std      722.077\n",
      "trainer/Z Policy Predictions Max     2120.83\n",
      "trainer/Z Policy Predictions Min      -28.1685\n",
      "trainer/Z Expert Targets Mean        2095.18\n",
      "trainer/Z Expert Targets Std           46.4236\n",
      "trainer/Z Expert Targets Max         2200.73\n",
      "trainer/Z Expert Targets Min         1881.19\n",
      "trainer/Z Policy Targets Mean        1380.14\n",
      "trainer/Z Policy Targets Std          720.283\n",
      "trainer/Z Policy Targets Max         2126.18\n",
      "trainer/Z Policy Targets Min          -16.9623\n",
      "trainer/Log Pis Mean                   60.9906\n",
      "trainer/Log Pis Std                    28.5128\n",
      "trainer/Policy mu Mean                  0.20805\n",
      "trainer/Policy mu Std                   3.67988\n",
      "trainer/Policy log std Mean            -2.68102\n",
      "trainer/Policy log std Std              1.41255\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        177713\n",
      "exploration/num paths total          1324\n",
      "evaluation/num steps total         783339\n",
      "evaluation/num paths total           1765\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.36349\n",
      "evaluation/Rewards Std                  0.0939775\n",
      "evaluation/Rewards Max                  5.56744\n",
      "evaluation/Rewards Min                  4.78589\n",
      "evaluation/Returns Mean              5363.49\n",
      "evaluation/Returns Std                  7.73635\n",
      "evaluation/Returns Max               5372.85\n",
      "evaluation/Returns Min               5347.1\n",
      "evaluation/Estimation Bias Mean      1957.02\n",
      "evaluation/Estimation Bias Std        176.063\n",
      "evaluation/EB/Q_True Mean              48.4545\n",
      "evaluation/EB/Q_True Std              149.215\n",
      "evaluation/EB/Q_Pred Mean            2005.48\n",
      "evaluation/EB/Q_Pred Std              100.384\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5363.49\n",
      "evaluation/Actions Mean                 0.0835443\n",
      "evaluation/Actions Std                  0.537903\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999999\n",
      "time/backward_policy (s)                1.87588\n",
      "time/backward_zf1 (s)                   2.32303\n",
      "time/backward_zf2 (s)                   2.22731\n",
      "time/data sampling (s)                  0.367288\n",
      "time/data storing (s)                   0.0153331\n",
      "time/evaluation sampling (s)            2.37755\n",
      "time/exploration sampling (s)           0.505899\n",
      "time/logging (s)                        0.0130665\n",
      "time/preback_alpha (s)                  0.581651\n",
      "time/preback_policy (s)                 1.09202\n",
      "time/preback_start (s)                  0.181654\n",
      "time/preback_zf (s)                     6.66226\n",
      "time/saving (s)                         3.478e-06\n",
      "time/training (s)                       3.32149\n",
      "time/epoch (s)                         21.5444\n",
      "time/total (s)                       3538.17\n",
      "Epoch                                 172\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:24:46.375280 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 173 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 184000\n",
      "trainer/ZF1 Loss                     4095.47\n",
      "trainer/ZF2 Loss                     4076.65\n",
      "trainer/ZF Expert Reward               20.8006\n",
      "trainer/ZF Policy Reward               17.1499\n",
      "trainer/ZF CHI2 Term                 4085.69\n",
      "trainer/Policy Loss                 -1564.26\n",
      "trainer/Bias Loss                      61.9329\n",
      "trainer/Bias Value                     16.7783\n",
      "trainer/Policy Grad Norm              289.108\n",
      "trainer/Policy Param Norm              51.3252\n",
      "trainer/Zf1 Grad Norm               45733\n",
      "trainer/Zf1 Param Norm                132.384\n",
      "trainer/Zf2 Grad Norm               52808.8\n",
      "trainer/Zf2 Param Norm                130.729\n",
      "trainer/Z Expert Predictions Mean    2118.65\n",
      "trainer/Z Expert Predictions Std       50.5682\n",
      "trainer/Z Expert Predictions Max     2216.2\n",
      "trainer/Z Expert Predictions Min     1886.32\n",
      "trainer/Z Policy Predictions Mean    1557.49\n",
      "trainer/Z Policy Predictions Std      628.258\n",
      "trainer/Z Policy Predictions Max     2141.03\n",
      "trainer/Z Policy Predictions Min       -0.0822698\n",
      "trainer/Z Expert Targets Mean        2097.85\n",
      "trainer/Z Expert Targets Std           50.031\n",
      "trainer/Z Expert Targets Max         2195.83\n",
      "trainer/Z Expert Targets Min         1881.06\n",
      "trainer/Z Policy Targets Mean        1540.34\n",
      "trainer/Z Policy Targets Std          636.108\n",
      "trainer/Z Policy Targets Max         2118.61\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   57.5687\n",
      "trainer/Log Pis Std                    24.3606\n",
      "trainer/Policy mu Mean                  0.241948\n",
      "trainer/Policy mu Std                   3.14761\n",
      "trainer/Policy log std Mean            -2.98184\n",
      "trainer/Policy log std Std              1.22664\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        178713\n",
      "exploration/num paths total          1325\n",
      "evaluation/num steps total         792619\n",
      "evaluation/num paths total           1775\n",
      "evaluation/path length Mean           928\n",
      "evaluation/path length Std            216\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            280\n",
      "evaluation/Rewards Mean                 5.31671\n",
      "evaluation/Rewards Std                  0.0848532\n",
      "evaluation/Rewards Max                  6.15348\n",
      "evaluation/Rewards Min                  4.80741\n",
      "evaluation/Returns Mean              4933.9\n",
      "evaluation/Returns Std               1148.58\n",
      "evaluation/Returns Max               5326.78\n",
      "evaluation/Returns Min               1488.23\n",
      "evaluation/Estimation Bias Mean      1937.57\n",
      "evaluation/Estimation Bias Std        239.055\n",
      "evaluation/EB/Q_True Mean              51.8289\n",
      "evaluation/EB/Q_True Std              153.137\n",
      "evaluation/EB/Q_Pred Mean            1989.39\n",
      "evaluation/EB/Q_Pred Std              154.816\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4933.9\n",
      "evaluation/Actions Mean                 0.0804408\n",
      "evaluation/Actions Std                  0.525294\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.87353\n",
      "time/backward_zf1 (s)                   2.30563\n",
      "time/backward_zf2 (s)                   2.20991\n",
      "time/data sampling (s)                  0.362375\n",
      "time/data storing (s)                   0.0161232\n",
      "time/evaluation sampling (s)            2.32617\n",
      "time/exploration sampling (s)           0.507817\n",
      "time/logging (s)                        0.0125575\n",
      "time/preback_alpha (s)                  0.591488\n",
      "time/preback_policy (s)                 1.09645\n",
      "time/preback_start (s)                  0.183836\n",
      "time/preback_zf (s)                     6.7179\n",
      "time/saving (s)                         3.16501e-06\n",
      "time/training (s)                       3.43174\n",
      "time/epoch (s)                         21.6355\n",
      "time/total (s)                       3559.83\n",
      "Epoch                                 173\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:25:07.722695 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 174 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 185000\n",
      "trainer/ZF1 Loss                      314.447\n",
      "trainer/ZF2 Loss                      371.464\n",
      "trainer/ZF Expert Reward               15.8506\n",
      "trainer/ZF Policy Reward                6.01503\n",
      "trainer/ZF CHI2 Term                  337.754\n",
      "trainer/Policy Loss                 -1467.46\n",
      "trainer/Bias Loss                      23.0328\n",
      "trainer/Bias Value                     16.7572\n",
      "trainer/Policy Grad Norm              236.451\n",
      "trainer/Policy Param Norm              51.397\n",
      "trainer/Zf1 Grad Norm               33050.6\n",
      "trainer/Zf1 Param Norm                132.719\n",
      "trainer/Zf2 Grad Norm               27657.3\n",
      "trainer/Zf2 Param Norm                131.052\n",
      "trainer/Z Expert Predictions Mean    2104.06\n",
      "trainer/Z Expert Predictions Std       56.7393\n",
      "trainer/Z Expert Predictions Max     2204.36\n",
      "trainer/Z Expert Predictions Min     1880.52\n",
      "trainer/Z Policy Predictions Mean    1451.41\n",
      "trainer/Z Policy Predictions Std      700.262\n",
      "trainer/Z Policy Predictions Max     2086.74\n",
      "trainer/Z Policy Predictions Min      -19.5685\n",
      "trainer/Z Expert Targets Mean        2088.21\n",
      "trainer/Z Expert Targets Std           55.9664\n",
      "trainer/Z Expert Targets Max         2188.89\n",
      "trainer/Z Expert Targets Min         1873.83\n",
      "trainer/Z Policy Targets Mean        1445.39\n",
      "trainer/Z Policy Targets Std          700.534\n",
      "trainer/Z Policy Targets Max         2083.14\n",
      "trainer/Z Policy Targets Min          -27.3474\n",
      "trainer/Log Pis Mean                   60.3345\n",
      "trainer/Log Pis Std                    27.73\n",
      "trainer/Policy mu Mean                  0.414714\n",
      "trainer/Policy mu Std                   3.18997\n",
      "trainer/Policy log std Mean            -2.85806\n",
      "trainer/Policy log std Std              1.2983\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        179713\n",
      "exploration/num paths total          1326\n",
      "evaluation/num steps total         802619\n",
      "evaluation/num paths total           1785\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30806\n",
      "evaluation/Rewards Std                  0.0743523\n",
      "evaluation/Rewards Max                  5.46784\n",
      "evaluation/Rewards Min                  4.74434\n",
      "evaluation/Returns Mean              5308.06\n",
      "evaluation/Returns Std                  3.23561\n",
      "evaluation/Returns Max               5313.03\n",
      "evaluation/Returns Min               5303.36\n",
      "evaluation/Estimation Bias Mean      1936.99\n",
      "evaluation/Estimation Bias Std        170.182\n",
      "evaluation/EB/Q_True Mean              47.928\n",
      "evaluation/EB/Q_True Std              147.608\n",
      "evaluation/EB/Q_Pred Mean            1984.92\n",
      "evaluation/EB/Q_Pred Std               80.897\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5308.06\n",
      "evaluation/Actions Mean                 0.0585837\n",
      "evaluation/Actions Std                  0.518601\n",
      "evaluation/Actions Max                  0.999682\n",
      "evaluation/Actions Min                 -0.997761\n",
      "time/backward_policy (s)                1.77665\n",
      "time/backward_zf1 (s)                   2.20694\n",
      "time/backward_zf2 (s)                   2.10215\n",
      "time/data sampling (s)                  0.370874\n",
      "time/data storing (s)                   0.0144927\n",
      "time/evaluation sampling (s)            2.26608\n",
      "time/exploration sampling (s)           0.490596\n",
      "time/logging (s)                        0.0130301\n",
      "time/preback_alpha (s)                  0.577617\n",
      "time/preback_policy (s)                 0.994142\n",
      "time/preback_start (s)                  0.179989\n",
      "time/preback_zf (s)                     6.64245\n",
      "time/saving (s)                         3.523e-06\n",
      "time/training (s)                       3.63931\n",
      "time/epoch (s)                         21.2743\n",
      "time/total (s)                       3581.13\n",
      "Epoch                                 174\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:25:29.632537 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 175 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 186000\n",
      "trainer/ZF1 Loss                      543.987\n",
      "trainer/ZF2 Loss                      548.903\n",
      "trainer/ZF Expert Reward               14.9888\n",
      "trainer/ZF Policy Reward                8.0404\n",
      "trainer/ZF CHI2 Term                  540.358\n",
      "trainer/Policy Loss                 -1531.18\n",
      "trainer/Bias Loss                      56.3019\n",
      "trainer/Bias Value                     16.7304\n",
      "trainer/Policy Grad Norm              228.374\n",
      "trainer/Policy Param Norm              51.4768\n",
      "trainer/Zf1 Grad Norm               38222.8\n",
      "trainer/Zf1 Param Norm                133.065\n",
      "trainer/Zf2 Grad Norm               65286.9\n",
      "trainer/Zf2 Param Norm                131.4\n",
      "trainer/Z Expert Predictions Mean    2107.42\n",
      "trainer/Z Expert Predictions Std       52.416\n",
      "trainer/Z Expert Predictions Max     2204.37\n",
      "trainer/Z Expert Predictions Min     1896.77\n",
      "trainer/Z Policy Predictions Mean    1522.9\n",
      "trainer/Z Policy Predictions Std      655.496\n",
      "trainer/Z Policy Predictions Max     2131.84\n",
      "trainer/Z Policy Predictions Min        5.6869\n",
      "trainer/Z Expert Targets Mean        2092.43\n",
      "trainer/Z Expert Targets Std           51.8993\n",
      "trainer/Z Expert Targets Max         2194.03\n",
      "trainer/Z Expert Targets Min         1893.07\n",
      "trainer/Z Policy Targets Mean        1514.86\n",
      "trainer/Z Policy Targets Std          647.284\n",
      "trainer/Z Policy Targets Max         2099.61\n",
      "trainer/Z Policy Targets Min            9.1217\n",
      "trainer/Log Pis Mean                   55.8213\n",
      "trainer/Log Pis Std                    24.7604\n",
      "trainer/Policy mu Mean                  0.258308\n",
      "trainer/Policy mu Std                   2.98526\n",
      "trainer/Policy log std Mean            -2.86231\n",
      "trainer/Policy log std Std              1.19661\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        179713\n",
      "exploration/num paths total          1326\n",
      "evaluation/num steps total         812619\n",
      "evaluation/num paths total           1795\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31981\n",
      "evaluation/Rewards Std                  0.0828619\n",
      "evaluation/Rewards Max                  5.50322\n",
      "evaluation/Rewards Min                  4.77113\n",
      "evaluation/Returns Mean              5319.81\n",
      "evaluation/Returns Std                  4.4933\n",
      "evaluation/Returns Max               5327.38\n",
      "evaluation/Returns Min               5310.58\n",
      "evaluation/Estimation Bias Mean      1968.75\n",
      "evaluation/Estimation Bias Std        164.894\n",
      "evaluation/EB/Q_True Mean              48.0978\n",
      "evaluation/EB/Q_True Std              148.116\n",
      "evaluation/EB/Q_Pred Mean            2016.84\n",
      "evaluation/EB/Q_Pred Std               72.5721\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5319.81\n",
      "evaluation/Actions Mean                 0.070721\n",
      "evaluation/Actions Std                  0.505865\n",
      "evaluation/Actions Max                  0.999343\n",
      "evaluation/Actions Min                 -0.996618\n",
      "time/backward_policy (s)                1.80698\n",
      "time/backward_zf1 (s)                   2.28244\n",
      "time/backward_zf2 (s)                   2.16212\n",
      "time/data sampling (s)                  0.379338\n",
      "time/data storing (s)                   0.0153492\n",
      "time/evaluation sampling (s)            2.57777\n",
      "time/exploration sampling (s)           0.490894\n",
      "time/logging (s)                        0.0131389\n",
      "time/preback_alpha (s)                  0.582467\n",
      "time/preback_policy (s)                 0.990865\n",
      "time/preback_start (s)                  0.185469\n",
      "time/preback_zf (s)                     6.66456\n",
      "time/saving (s)                         3.114e-06\n",
      "time/training (s)                       3.68741\n",
      "time/epoch (s)                         21.8388\n",
      "time/total (s)                       3602.99\n",
      "Epoch                                 175\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:25:51.226422 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 176 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 187000\n",
      "trainer/ZF1 Loss                      279.874\n",
      "trainer/ZF2 Loss                      263.622\n",
      "trainer/ZF Expert Reward               18.3646\n",
      "trainer/ZF Policy Reward                5.82216\n",
      "trainer/ZF CHI2 Term                  269.136\n",
      "trainer/Policy Loss                 -1434.83\n",
      "trainer/Bias Loss                      32.4475\n",
      "trainer/Bias Value                     16.7103\n",
      "trainer/Policy Grad Norm              288.386\n",
      "trainer/Policy Param Norm              51.5491\n",
      "trainer/Zf1 Grad Norm               29897.4\n",
      "trainer/Zf1 Param Norm                133.393\n",
      "trainer/Zf2 Grad Norm               16592.2\n",
      "trainer/Zf2 Param Norm                131.707\n",
      "trainer/Z Expert Predictions Mean    2098.87\n",
      "trainer/Z Expert Predictions Std       54.0994\n",
      "trainer/Z Expert Predictions Max     2221.31\n",
      "trainer/Z Expert Predictions Min     1905.71\n",
      "trainer/Z Policy Predictions Mean    1421.81\n",
      "trainer/Z Policy Predictions Std      735.07\n",
      "trainer/Z Policy Predictions Max     2116.72\n",
      "trainer/Z Policy Predictions Min        2.55709\n",
      "trainer/Z Expert Targets Mean        2080.51\n",
      "trainer/Z Expert Targets Std           53.5303\n",
      "trainer/Z Expert Targets Max         2197.69\n",
      "trainer/Z Expert Targets Min         1889.91\n",
      "trainer/Z Policy Targets Mean        1415.98\n",
      "trainer/Z Policy Targets Std          731.985\n",
      "trainer/Z Policy Targets Max         2075.91\n",
      "trainer/Z Policy Targets Min           -2.84039\n",
      "trainer/Log Pis Mean                   61.4396\n",
      "trainer/Log Pis Std                    28.4318\n",
      "trainer/Policy mu Mean                  0.322988\n",
      "trainer/Policy mu Std                   4.2872\n",
      "trainer/Policy log std Mean            -2.6892\n",
      "trainer/Policy log std Std              1.52369\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        180713\n",
      "exploration/num paths total          1327\n",
      "evaluation/num steps total         820771\n",
      "evaluation/num paths total           1805\n",
      "evaluation/path length Mean           815.2\n",
      "evaluation/path length Std            331.769\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            152\n",
      "evaluation/Rewards Mean                 5.29871\n",
      "evaluation/Rewards Std                  0.118029\n",
      "evaluation/Rewards Max                  5.89223\n",
      "evaluation/Rewards Min                  3.85288\n",
      "evaluation/Returns Mean              4319.51\n",
      "evaluation/Returns Std               1769.82\n",
      "evaluation/Returns Max               5319.85\n",
      "evaluation/Returns Min                792.331\n",
      "evaluation/Estimation Bias Mean      1897.88\n",
      "evaluation/Estimation Bias Std        333.785\n",
      "evaluation/EB/Q_True Mean              58.825\n",
      "evaluation/EB/Q_True Std              161.616\n",
      "evaluation/EB/Q_Pred Mean            1956.7\n",
      "evaluation/EB/Q_Pred Std              244.215\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4319.51\n",
      "evaluation/Actions Mean                 0.0814125\n",
      "evaluation/Actions Std                  0.533727\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8668\n",
      "time/backward_zf1 (s)                   2.27718\n",
      "time/backward_zf2 (s)                   2.19897\n",
      "time/data sampling (s)                  0.368288\n",
      "time/data storing (s)                   0.0149201\n",
      "time/evaluation sampling (s)            2.50407\n",
      "time/exploration sampling (s)           0.497877\n",
      "time/logging (s)                        0.0126065\n",
      "time/preback_alpha (s)                  0.578457\n",
      "time/preback_policy (s)                 1.09357\n",
      "time/preback_start (s)                  0.187832\n",
      "time/preback_zf (s)                     6.63297\n",
      "time/saving (s)                         3.148e-06\n",
      "time/training (s)                       3.28396\n",
      "time/epoch (s)                         21.5175\n",
      "time/total (s)                       3624.54\n",
      "Epoch                                 176\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:26:13.128647 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 177 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 188000\n",
      "trainer/ZF1 Loss                      340.417\n",
      "trainer/ZF2 Loss                      360.529\n",
      "trainer/ZF Expert Reward               14.1207\n",
      "trainer/ZF Policy Reward               10.5939\n",
      "trainer/ZF CHI2 Term                  343.744\n",
      "trainer/Policy Loss                 -1511.92\n",
      "trainer/Bias Loss                      37.5732\n",
      "trainer/Bias Value                     16.6916\n",
      "trainer/Policy Grad Norm              210.34\n",
      "trainer/Policy Param Norm              51.615\n",
      "trainer/Zf1 Grad Norm               24855.4\n",
      "trainer/Zf1 Param Norm                133.757\n",
      "trainer/Zf2 Grad Norm               17912.4\n",
      "trainer/Zf2 Param Norm                132.037\n",
      "trainer/Z Expert Predictions Mean    2083.38\n",
      "trainer/Z Expert Predictions Std       58.6815\n",
      "trainer/Z Expert Predictions Max     2192.78\n",
      "trainer/Z Expert Predictions Min     1902.78\n",
      "trainer/Z Policy Predictions Mean    1497.49\n",
      "trainer/Z Policy Predictions Std      675.05\n",
      "trainer/Z Policy Predictions Max     2113.6\n",
      "trainer/Z Policy Predictions Min      -13.1508\n",
      "trainer/Z Expert Targets Mean        2069.26\n",
      "trainer/Z Expert Targets Std           59.86\n",
      "trainer/Z Expert Targets Max         2178.77\n",
      "trainer/Z Expert Targets Min         1881.59\n",
      "trainer/Z Policy Targets Mean        1486.89\n",
      "trainer/Z Policy Targets Std          674.973\n",
      "trainer/Z Policy Targets Max         2100\n",
      "trainer/Z Policy Targets Min          -14.5907\n",
      "trainer/Log Pis Mean                   58.1316\n",
      "trainer/Log Pis Std                    26.3956\n",
      "trainer/Policy mu Mean                  0.400618\n",
      "trainer/Policy mu Std                   3.22709\n",
      "trainer/Policy log std Mean            -2.87263\n",
      "trainer/Policy log std Std              1.2822\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        183713\n",
      "exploration/num paths total          1330\n",
      "evaluation/num steps total         830771\n",
      "evaluation/num paths total           1815\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31039\n",
      "evaluation/Rewards Std                  0.080843\n",
      "evaluation/Rewards Max                  5.55111\n",
      "evaluation/Rewards Min                  4.79684\n",
      "evaluation/Returns Mean              5310.39\n",
      "evaluation/Returns Std                  5.23529\n",
      "evaluation/Returns Max               5319.45\n",
      "evaluation/Returns Min               5301.45\n",
      "evaluation/Estimation Bias Mean      1929.37\n",
      "evaluation/Estimation Bias Std        183.104\n",
      "evaluation/EB/Q_True Mean              47.9594\n",
      "evaluation/EB/Q_True Std              147.69\n",
      "evaluation/EB/Q_Pred Mean            1977.33\n",
      "evaluation/EB/Q_Pred Std               94.9548\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5310.39\n",
      "evaluation/Actions Mean                 0.0732369\n",
      "evaluation/Actions Std                  0.513096\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -0.999984\n",
      "time/backward_policy (s)                1.73149\n",
      "time/backward_zf1 (s)                   2.15762\n",
      "time/backward_zf2 (s)                   2.08672\n",
      "time/data sampling (s)                  0.38122\n",
      "time/data storing (s)                   0.0145255\n",
      "time/evaluation sampling (s)            2.91032\n",
      "time/exploration sampling (s)           0.494532\n",
      "time/logging (s)                        0.0137633\n",
      "time/preback_alpha (s)                  0.574552\n",
      "time/preback_policy (s)                 0.973827\n",
      "time/preback_start (s)                  0.175779\n",
      "time/preback_zf (s)                     6.62742\n",
      "time/saving (s)                         3.325e-06\n",
      "time/training (s)                       3.69452\n",
      "time/epoch (s)                         21.8363\n",
      "time/total (s)                       3646.4\n",
      "Epoch                                 177\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:26:35.364158 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 178 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 189000\n",
      "trainer/ZF1 Loss                      341.061\n",
      "trainer/ZF2 Loss                      374.589\n",
      "trainer/ZF Expert Reward               17.4171\n",
      "trainer/ZF Policy Reward                8.81007\n",
      "trainer/ZF CHI2 Term                  354.336\n",
      "trainer/Policy Loss                 -1418.42\n",
      "trainer/Bias Loss                      36.1487\n",
      "trainer/Bias Value                     16.6653\n",
      "trainer/Policy Grad Norm              261.048\n",
      "trainer/Policy Param Norm              51.6911\n",
      "trainer/Zf1 Grad Norm               20733.9\n",
      "trainer/Zf1 Param Norm                134.1\n",
      "trainer/Zf2 Grad Norm               36033.2\n",
      "trainer/Zf2 Param Norm                132.387\n",
      "trainer/Z Expert Predictions Mean    2089.55\n",
      "trainer/Z Expert Predictions Std       47.8264\n",
      "trainer/Z Expert Predictions Max     2214.83\n",
      "trainer/Z Expert Predictions Min     1907.61\n",
      "trainer/Z Policy Predictions Mean    1403.31\n",
      "trainer/Z Policy Predictions Std      705.816\n",
      "trainer/Z Policy Predictions Max     2064.98\n",
      "trainer/Z Policy Predictions Min       -0.351985\n",
      "trainer/Z Expert Targets Mean        2072.14\n",
      "trainer/Z Expert Targets Std           48.5989\n",
      "trainer/Z Expert Targets Max         2198.69\n",
      "trainer/Z Expert Targets Min         1896.49\n",
      "trainer/Z Policy Targets Mean        1394.5\n",
      "trainer/Z Policy Targets Std          707.109\n",
      "trainer/Z Policy Targets Max         2050.46\n",
      "trainer/Z Policy Targets Min           -6.15046\n",
      "trainer/Log Pis Mean                   60.0235\n",
      "trainer/Log Pis Std                    27.7007\n",
      "trainer/Policy mu Mean                  0.353931\n",
      "trainer/Policy mu Std                   3.71246\n",
      "trainer/Policy log std Mean            -2.6898\n",
      "trainer/Policy log std Std              1.31825\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        185713\n",
      "exploration/num paths total          1332\n",
      "evaluation/num steps total         840295\n",
      "evaluation/num paths total           1825\n",
      "evaluation/path length Mean           952.4\n",
      "evaluation/path length Std            142.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            524\n",
      "evaluation/Rewards Mean                 5.29939\n",
      "evaluation/Rewards Std                  0.0788888\n",
      "evaluation/Rewards Max                  5.54068\n",
      "evaluation/Rewards Min                  4.80779\n",
      "evaluation/Returns Mean              5047.14\n",
      "evaluation/Returns Std                760.642\n",
      "evaluation/Returns Max               5309.63\n",
      "evaluation/Returns Min               2765.29\n",
      "evaluation/Estimation Bias Mean      1913.64\n",
      "evaluation/Estimation Bias Std        212.835\n",
      "evaluation/EB/Q_True Mean              50.1941\n",
      "evaluation/EB/Q_True Std              150.484\n",
      "evaluation/EB/Q_Pred Mean            1963.84\n",
      "evaluation/EB/Q_Pred Std              130.044\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5047.14\n",
      "evaluation/Actions Mean                 0.0807272\n",
      "evaluation/Actions Std                  0.521478\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.00119\n",
      "time/backward_zf1 (s)                   2.45623\n",
      "time/backward_zf2 (s)                   2.3765\n",
      "time/data sampling (s)                  0.391452\n",
      "time/data storing (s)                   0.016626\n",
      "time/evaluation sampling (s)            2.59242\n",
      "time/exploration sampling (s)           0.520501\n",
      "time/logging (s)                        0.0125846\n",
      "time/preback_alpha (s)                  0.605189\n",
      "time/preback_policy (s)                 1.2159\n",
      "time/preback_start (s)                  0.188984\n",
      "time/preback_zf (s)                     6.73505\n",
      "time/saving (s)                         3.621e-06\n",
      "time/training (s)                       3.05105\n",
      "time/epoch (s)                         22.1637\n",
      "time/total (s)                       3668.58\n",
      "Epoch                                 178\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:26:57.360133 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 179 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 190000\n",
      "trainer/ZF1 Loss                      367.631\n",
      "trainer/ZF2 Loss                      426.627\n",
      "trainer/ZF Expert Reward               18.1499\n",
      "trainer/ZF Policy Reward               12.8036\n",
      "trainer/ZF CHI2 Term                  394.415\n",
      "trainer/Policy Loss                 -1513.61\n",
      "trainer/Bias Loss                      33.1038\n",
      "trainer/Bias Value                     16.6424\n",
      "trainer/Policy Grad Norm              254.017\n",
      "trainer/Policy Param Norm              51.7627\n",
      "trainer/Zf1 Grad Norm               21837.8\n",
      "trainer/Zf1 Param Norm                134.426\n",
      "trainer/Zf2 Grad Norm               31738.7\n",
      "trainer/Zf2 Param Norm                132.713\n",
      "trainer/Z Expert Predictions Mean    2088.6\n",
      "trainer/Z Expert Predictions Std       47.3631\n",
      "trainer/Z Expert Predictions Max     2207.28\n",
      "trainer/Z Expert Predictions Min     1863.02\n",
      "trainer/Z Policy Predictions Mean    1500.71\n",
      "trainer/Z Policy Predictions Std      647.973\n",
      "trainer/Z Policy Predictions Max     2079.38\n",
      "trainer/Z Policy Predictions Min      -11.6361\n",
      "trainer/Z Expert Targets Mean        2070.45\n",
      "trainer/Z Expert Targets Std           48.2303\n",
      "trainer/Z Expert Targets Max         2189.99\n",
      "trainer/Z Expert Targets Min         1833.45\n",
      "trainer/Z Policy Targets Mean        1487.91\n",
      "trainer/Z Policy Targets Std          647.217\n",
      "trainer/Z Policy Targets Max         2059.4\n",
      "trainer/Z Policy Targets Min          -26.8614\n",
      "trainer/Log Pis Mean                   59.5358\n",
      "trainer/Log Pis Std                    25.7807\n",
      "trainer/Policy mu Mean                  0.379366\n",
      "trainer/Policy mu Std                   3.22344\n",
      "trainer/Policy log std Mean            -2.84773\n",
      "trainer/Policy log std Std              1.32075\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        185713\n",
      "exploration/num paths total          1332\n",
      "evaluation/num steps total         850295\n",
      "evaluation/num paths total           1835\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.36443\n",
      "evaluation/Rewards Std                  0.0865735\n",
      "evaluation/Rewards Max                  5.5933\n",
      "evaluation/Rewards Min                  4.79417\n",
      "evaluation/Returns Mean              5364.43\n",
      "evaluation/Returns Std                  5.36979\n",
      "evaluation/Returns Max               5372.29\n",
      "evaluation/Returns Min               5356.38\n",
      "evaluation/Estimation Bias Mean      1892.32\n",
      "evaluation/Estimation Bias Std        169.661\n",
      "evaluation/EB/Q_True Mean              48.45\n",
      "evaluation/EB/Q_True Std              149.199\n",
      "evaluation/EB/Q_Pred Mean            1940.77\n",
      "evaluation/EB/Q_Pred Std               77.1143\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5364.43\n",
      "evaluation/Actions Mean                 0.0753648\n",
      "evaluation/Actions Std                  0.529256\n",
      "evaluation/Actions Max                  0.999945\n",
      "evaluation/Actions Min                 -0.999158\n",
      "time/backward_policy (s)                1.99723\n",
      "time/backward_zf1 (s)                   2.44717\n",
      "time/backward_zf2 (s)                   2.3855\n",
      "time/data sampling (s)                  0.374188\n",
      "time/data storing (s)                   0.0161323\n",
      "time/evaluation sampling (s)            2.52732\n",
      "time/exploration sampling (s)           0.491696\n",
      "time/logging (s)                        0.0135455\n",
      "time/preback_alpha (s)                  0.59172\n",
      "time/preback_policy (s)                 1.21983\n",
      "time/preback_start (s)                  0.181832\n",
      "time/preback_zf (s)                     6.69418\n",
      "time/saving (s)                         2.951e-06\n",
      "time/training (s)                       2.98146\n",
      "time/epoch (s)                         21.9218\n",
      "time/total (s)                       3690.53\n",
      "Epoch                                 179\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:27:19.322071 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 180 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 191000\n",
      "trainer/ZF1 Loss                      381.125\n",
      "trainer/ZF2 Loss                      441.619\n",
      "trainer/ZF Expert Reward               16.9755\n",
      "trainer/ZF Policy Reward                8.34508\n",
      "trainer/ZF CHI2 Term                  407.479\n",
      "trainer/Policy Loss                 -1510.08\n",
      "trainer/Bias Loss                      31.1088\n",
      "trainer/Bias Value                     16.6155\n",
      "trainer/Policy Grad Norm              266.396\n",
      "trainer/Policy Param Norm              51.8186\n",
      "trainer/Zf1 Grad Norm               27727.7\n",
      "trainer/Zf1 Param Norm                134.776\n",
      "trainer/Zf2 Grad Norm               31611.3\n",
      "trainer/Zf2 Param Norm                133.047\n",
      "trainer/Z Expert Predictions Mean    2088.6\n",
      "trainer/Z Expert Predictions Std       47.5608\n",
      "trainer/Z Expert Predictions Max     2209.96\n",
      "trainer/Z Expert Predictions Min     1919.58\n",
      "trainer/Z Policy Predictions Mean    1495.86\n",
      "trainer/Z Policy Predictions Std      641.04\n",
      "trainer/Z Policy Predictions Max     2088.41\n",
      "trainer/Z Policy Predictions Min      -23.4683\n",
      "trainer/Z Expert Targets Mean        2071.63\n",
      "trainer/Z Expert Targets Std           48.2397\n",
      "trainer/Z Expert Targets Max         2185.49\n",
      "trainer/Z Expert Targets Min         1898.07\n",
      "trainer/Z Policy Targets Mean        1487.51\n",
      "trainer/Z Policy Targets Std          642.926\n",
      "trainer/Z Policy Targets Max         2068.44\n",
      "trainer/Z Policy Targets Min          -27.7259\n",
      "trainer/Log Pis Mean                   57.8108\n",
      "trainer/Log Pis Std                    25.9379\n",
      "trainer/Policy mu Mean                  0.2973\n",
      "trainer/Policy mu Std                   2.90484\n",
      "trainer/Policy log std Mean            -2.89565\n",
      "trainer/Policy log std Std              1.18313\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        186713\n",
      "exploration/num paths total          1333\n",
      "evaluation/num steps total         860295\n",
      "evaluation/num paths total           1845\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33046\n",
      "evaluation/Rewards Std                  0.0846981\n",
      "evaluation/Rewards Max                  5.56359\n",
      "evaluation/Rewards Min                  4.79082\n",
      "evaluation/Returns Mean              5330.46\n",
      "evaluation/Returns Std                  5.80098\n",
      "evaluation/Returns Max               5339.62\n",
      "evaluation/Returns Min               5322.27\n",
      "evaluation/Estimation Bias Mean      1877.68\n",
      "evaluation/Estimation Bias Std        180.312\n",
      "evaluation/EB/Q_True Mean              48.0539\n",
      "evaluation/EB/Q_True Std              148.004\n",
      "evaluation/EB/Q_Pred Mean            1925.73\n",
      "evaluation/EB/Q_Pred Std               93.5336\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5330.46\n",
      "evaluation/Actions Mean                 0.0903762\n",
      "evaluation/Actions Std                  0.530618\n",
      "evaluation/Actions Max                  0.99998\n",
      "evaluation/Actions Min                 -0.999969\n",
      "time/backward_policy (s)                1.95712\n",
      "time/backward_zf1 (s)                   2.37959\n",
      "time/backward_zf2 (s)                   2.31937\n",
      "time/data sampling (s)                  0.373239\n",
      "time/data storing (s)                   0.0148881\n",
      "time/evaluation sampling (s)            2.55206\n",
      "time/exploration sampling (s)           0.49364\n",
      "time/logging (s)                        0.013218\n",
      "time/preback_alpha (s)                  0.593831\n",
      "time/preback_policy (s)                 1.19397\n",
      "time/preback_start (s)                  0.184002\n",
      "time/preback_zf (s)                     6.71844\n",
      "time/saving (s)                         2.653e-06\n",
      "time/training (s)                       3.09872\n",
      "time/epoch (s)                         21.8921\n",
      "time/total (s)                       3712.44\n",
      "Epoch                                 180\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:27:40.856412 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 181 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 192000\n",
      "trainer/ZF1 Loss                      410.52\n",
      "trainer/ZF2 Loss                      376.395\n",
      "trainer/ZF Expert Reward               12.7916\n",
      "trainer/ZF Policy Reward                0.0691298\n",
      "trainer/ZF CHI2 Term                  385.521\n",
      "trainer/Policy Loss                 -1415.52\n",
      "trainer/Bias Loss                      89.1782\n",
      "trainer/Bias Value                     16.593\n",
      "trainer/Policy Grad Norm              217.349\n",
      "trainer/Policy Param Norm              51.8901\n",
      "trainer/Zf1 Grad Norm               29866.5\n",
      "trainer/Zf1 Param Norm                135.104\n",
      "trainer/Zf2 Grad Norm               20444.5\n",
      "trainer/Zf2 Param Norm                133.376\n",
      "trainer/Z Expert Predictions Mean    2074.54\n",
      "trainer/Z Expert Predictions Std       61.7205\n",
      "trainer/Z Expert Predictions Max     2196.83\n",
      "trainer/Z Expert Predictions Min     1442.12\n",
      "trainer/Z Policy Predictions Mean    1405.76\n",
      "trainer/Z Policy Predictions Std      679.667\n",
      "trainer/Z Policy Predictions Max     2070.8\n",
      "trainer/Z Policy Predictions Min      -10.6638\n",
      "trainer/Z Expert Targets Mean        2061.75\n",
      "trainer/Z Expert Targets Std           68.0185\n",
      "trainer/Z Expert Targets Max         2184.66\n",
      "trainer/Z Expert Targets Min         1270\n",
      "trainer/Z Policy Targets Mean        1405.69\n",
      "trainer/Z Policy Targets Std          682.083\n",
      "trainer/Z Policy Targets Max         2064.32\n",
      "trainer/Z Policy Targets Min          -12.8621\n",
      "trainer/Log Pis Mean                   59.9508\n",
      "trainer/Log Pis Std                    28.9698\n",
      "trainer/Policy mu Mean                  0.457938\n",
      "trainer/Policy mu Std                   3.38845\n",
      "trainer/Policy log std Mean            -2.71635\n",
      "trainer/Policy log std Std              1.31486\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        186713\n",
      "exploration/num paths total          1333\n",
      "evaluation/num steps total         868308\n",
      "evaluation/num paths total           1856\n",
      "evaluation/path length Mean           728.455\n",
      "evaluation/path length Std            310.501\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            183\n",
      "evaluation/Rewards Mean                 5.33782\n",
      "evaluation/Rewards Std                  0.121917\n",
      "evaluation/Rewards Max                  6.47619\n",
      "evaluation/Rewards Min                  4.76592\n",
      "evaluation/Returns Mean              3888.36\n",
      "evaluation/Returns Std               1655.2\n",
      "evaluation/Returns Max               5345.48\n",
      "evaluation/Returns Min                967.18\n",
      "evaluation/Estimation Bias Mean      1748.6\n",
      "evaluation/Estimation Bias Std        407.845\n",
      "evaluation/EB/Q_True Mean              60.1357\n",
      "evaluation/EB/Q_True Std              163.608\n",
      "evaluation/EB/Q_Pred Mean            1808.74\n",
      "evaluation/EB/Q_Pred Std              333.864\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3888.36\n",
      "evaluation/Actions Mean                 0.0949409\n",
      "evaluation/Actions Std                  0.556743\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.85839\n",
      "time/backward_zf1 (s)                   2.27562\n",
      "time/backward_zf2 (s)                   2.20293\n",
      "time/data sampling (s)                  0.363311\n",
      "time/data storing (s)                   0.0146312\n",
      "time/evaluation sampling (s)            2.29012\n",
      "time/exploration sampling (s)           0.48274\n",
      "time/logging (s)                        0.010517\n",
      "time/preback_alpha (s)                  0.59058\n",
      "time/preback_policy (s)                 1.0986\n",
      "time/preback_start (s)                  0.184376\n",
      "time/preback_zf (s)                     6.68252\n",
      "time/saving (s)                         3.38499e-06\n",
      "time/training (s)                       3.40756\n",
      "time/epoch (s)                         21.4619\n",
      "time/total (s)                       3733.92\n",
      "Epoch                                 181\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:28:02.874532 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 182 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 193000\n",
      "trainer/ZF1 Loss                      335.122\n",
      "trainer/ZF2 Loss                      384.401\n",
      "trainer/ZF Expert Reward               14.7938\n",
      "trainer/ZF Policy Reward                3.20655\n",
      "trainer/ZF CHI2 Term                  353.953\n",
      "trainer/Policy Loss                 -1465.79\n",
      "trainer/Bias Loss                      43.8327\n",
      "trainer/Bias Value                     16.5717\n",
      "trainer/Policy Grad Norm              251.209\n",
      "trainer/Policy Param Norm              51.9459\n",
      "trainer/Zf1 Grad Norm               19917.8\n",
      "trainer/Zf1 Param Norm                135.403\n",
      "trainer/Zf2 Grad Norm               24137.8\n",
      "trainer/Zf2 Param Norm                133.682\n",
      "trainer/Z Expert Predictions Mean    2054.9\n",
      "trainer/Z Expert Predictions Std      135.991\n",
      "trainer/Z Expert Predictions Max     2159.7\n",
      "trainer/Z Expert Predictions Min       35.4277\n",
      "trainer/Z Policy Predictions Mean    1452.69\n",
      "trainer/Z Policy Predictions Std      692.957\n",
      "trainer/Z Policy Predictions Max     2077.9\n",
      "trainer/Z Policy Predictions Min      -28.9326\n",
      "trainer/Z Expert Targets Mean        2040.11\n",
      "trainer/Z Expert Targets Std          137.464\n",
      "trainer/Z Expert Targets Max         2149\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1449.49\n",
      "trainer/Z Policy Targets Std          693.711\n",
      "trainer/Z Policy Targets Max         2045.53\n",
      "trainer/Z Policy Targets Min          -32.0347\n",
      "trainer/Log Pis Mean                   61.8509\n",
      "trainer/Log Pis Std                    29.6754\n",
      "trainer/Policy mu Mean                  0.295004\n",
      "trainer/Policy mu Std                   3.97789\n",
      "trainer/Policy log std Mean            -2.92407\n",
      "trainer/Policy log std Std              1.32012\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        187713\n",
      "exploration/num paths total          1334\n",
      "evaluation/num steps total         878308\n",
      "evaluation/num paths total           1866\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.3132\n",
      "evaluation/Rewards Std                  0.0845302\n",
      "evaluation/Rewards Max                  5.56307\n",
      "evaluation/Rewards Min                  4.79417\n",
      "evaluation/Returns Mean              5313.2\n",
      "evaluation/Returns Std                  5.65617\n",
      "evaluation/Returns Max               5321.81\n",
      "evaluation/Returns Min               5303.08\n",
      "evaluation/Estimation Bias Mean      1906.97\n",
      "evaluation/Estimation Bias Std        177.664\n",
      "evaluation/EB/Q_True Mean              48.06\n",
      "evaluation/EB/Q_True Std              148.018\n",
      "evaluation/EB/Q_Pred Mean            1955.03\n",
      "evaluation/EB/Q_Pred Std              114\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5313.2\n",
      "evaluation/Actions Mean                 0.0763109\n",
      "evaluation/Actions Std                  0.530882\n",
      "evaluation/Actions Max                  0.999985\n",
      "evaluation/Actions Min                 -0.99999\n",
      "time/backward_policy (s)                2.04088\n",
      "time/backward_zf1 (s)                   2.54569\n",
      "time/backward_zf2 (s)                   2.43354\n",
      "time/data sampling (s)                  0.411006\n",
      "time/data storing (s)                   0.0156791\n",
      "time/evaluation sampling (s)            2.24803\n",
      "time/exploration sampling (s)           0.505247\n",
      "time/logging (s)                        0.0129676\n",
      "time/preback_alpha (s)                  0.601591\n",
      "time/preback_policy (s)                 1.23029\n",
      "time/preback_start (s)                  0.182392\n",
      "time/preback_zf (s)                     6.74472\n",
      "time/saving (s)                         3.293e-06\n",
      "time/training (s)                       2.97853\n",
      "time/epoch (s)                         21.9506\n",
      "time/total (s)                       3755.9\n",
      "Epoch                                 182\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:28:24.735346 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 183 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 194000\n",
      "trainer/ZF1 Loss                      492.177\n",
      "trainer/ZF2 Loss                      406.312\n",
      "trainer/ZF Expert Reward                8.1357\n",
      "trainer/ZF Policy Reward                9.1496\n",
      "trainer/ZF CHI2 Term                  436.813\n",
      "trainer/Policy Loss                 -1469.37\n",
      "trainer/Bias Loss                      83.7132\n",
      "trainer/Bias Value                     16.5455\n",
      "trainer/Policy Grad Norm              299.511\n",
      "trainer/Policy Param Norm              52.0076\n",
      "trainer/Zf1 Grad Norm               28622.6\n",
      "trainer/Zf1 Param Norm                135.748\n",
      "trainer/Zf2 Grad Norm               29706.8\n",
      "trainer/Zf2 Param Norm                134.025\n",
      "trainer/Z Expert Predictions Mean    2056.75\n",
      "trainer/Z Expert Predictions Std       65.7493\n",
      "trainer/Z Expert Predictions Max     2181.28\n",
      "trainer/Z Expert Predictions Min     1335.8\n",
      "trainer/Z Policy Predictions Mean    1457.88\n",
      "trainer/Z Policy Predictions Std      657.779\n",
      "trainer/Z Policy Predictions Max     2054.03\n",
      "trainer/Z Policy Predictions Min      -14.5255\n",
      "trainer/Z Expert Targets Mean        2048.62\n",
      "trainer/Z Expert Targets Std           64.9503\n",
      "trainer/Z Expert Targets Max         2176.05\n",
      "trainer/Z Expert Targets Min         1351.61\n",
      "trainer/Z Policy Targets Mean        1448.73\n",
      "trainer/Z Policy Targets Std          663.096\n",
      "trainer/Z Policy Targets Max         2023.17\n",
      "trainer/Z Policy Targets Min           -3.70865\n",
      "trainer/Log Pis Mean                   59.8029\n",
      "trainer/Log Pis Std                    27.2049\n",
      "trainer/Policy mu Mean                  0.451091\n",
      "trainer/Policy mu Std                   3.3175\n",
      "trainer/Policy log std Mean            -2.84071\n",
      "trainer/Policy log std Std              1.23218\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        188713\n",
      "exploration/num paths total          1335\n",
      "evaluation/num steps total         886898\n",
      "evaluation/num paths total           1876\n",
      "evaluation/path length Mean           859\n",
      "evaluation/path length Std            284.671\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            208\n",
      "evaluation/Rewards Mean                 5.29337\n",
      "evaluation/Rewards Std                  0.103982\n",
      "evaluation/Rewards Max                  6.3501\n",
      "evaluation/Rewards Min                  4.78614\n",
      "evaluation/Returns Mean              4547\n",
      "evaluation/Returns Std               1513.19\n",
      "evaluation/Returns Max               5308.82\n",
      "evaluation/Returns Min               1068.78\n",
      "evaluation/Estimation Bias Mean      1829.18\n",
      "evaluation/Estimation Bias Std        313.073\n",
      "evaluation/EB/Q_True Mean              55.6407\n",
      "evaluation/EB/Q_True Std              157.446\n",
      "evaluation/EB/Q_Pred Mean            1884.82\n",
      "evaluation/EB/Q_Pred Std              210.565\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4547\n",
      "evaluation/Actions Mean                 0.0894384\n",
      "evaluation/Actions Std                  0.552369\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90878\n",
      "time/backward_zf1 (s)                   2.35289\n",
      "time/backward_zf2 (s)                   2.292\n",
      "time/data sampling (s)                  0.372117\n",
      "time/data storing (s)                   0.0149266\n",
      "time/evaluation sampling (s)            2.43755\n",
      "time/exploration sampling (s)           0.484772\n",
      "time/logging (s)                        0.0118611\n",
      "time/preback_alpha (s)                  0.592823\n",
      "time/preback_policy (s)                 1.11904\n",
      "time/preback_start (s)                  0.183604\n",
      "time/preback_zf (s)                     6.69732\n",
      "time/saving (s)                         3.636e-06\n",
      "time/training (s)                       3.31897\n",
      "time/epoch (s)                         21.7867\n",
      "time/total (s)                       3777.71\n",
      "Epoch                                 183\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:28:46.196536 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 184 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 195000\n",
      "trainer/ZF1 Loss                      443.852\n",
      "trainer/ZF2 Loss                      431.553\n",
      "trainer/ZF Expert Reward               16.0294\n",
      "trainer/ZF Policy Reward                5.73922\n",
      "trainer/ZF CHI2 Term                  433.116\n",
      "trainer/Policy Loss                 -1533.38\n",
      "trainer/Bias Loss                      54.8809\n",
      "trainer/Bias Value                     16.5193\n",
      "trainer/Policy Grad Norm              238.685\n",
      "trainer/Policy Param Norm              52.0712\n",
      "trainer/Zf1 Grad Norm               25564.3\n",
      "trainer/Zf1 Param Norm                136.071\n",
      "trainer/Zf2 Grad Norm               28813.3\n",
      "trainer/Zf2 Param Norm                134.347\n",
      "trainer/Z Expert Predictions Mean    2055.68\n",
      "trainer/Z Expert Predictions Std      132.338\n",
      "trainer/Z Expert Predictions Max     2163.37\n",
      "trainer/Z Expert Predictions Min       78.2618\n",
      "trainer/Z Policy Predictions Mean    1520.81\n",
      "trainer/Z Policy Predictions Std      605.378\n",
      "trainer/Z Policy Predictions Max     2069.94\n",
      "trainer/Z Policy Predictions Min       -9.43673\n",
      "trainer/Z Expert Targets Mean        2039.65\n",
      "trainer/Z Expert Targets Std          136.179\n",
      "trainer/Z Expert Targets Max         2165.56\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1515.07\n",
      "trainer/Z Policy Targets Std          604.679\n",
      "trainer/Z Policy Targets Max         2075.12\n",
      "trainer/Z Policy Targets Min          -11.778\n",
      "trainer/Log Pis Mean                   57.5387\n",
      "trainer/Log Pis Std                    25.5499\n",
      "trainer/Policy mu Mean                  0.437445\n",
      "trainer/Policy mu Std                   3.03891\n",
      "trainer/Policy log std Mean            -2.95309\n",
      "trainer/Policy log std Std              1.17125\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        190282\n",
      "exploration/num paths total          1337\n",
      "evaluation/num steps total         890700\n",
      "evaluation/num paths total           1886\n",
      "evaluation/path length Mean           380.2\n",
      "evaluation/path length Std            213.035\n",
      "evaluation/path length Max            818\n",
      "evaluation/path length Min            133\n",
      "evaluation/Rewards Mean                 5.29614\n",
      "evaluation/Rewards Std                  0.171127\n",
      "evaluation/Rewards Max                  6.39935\n",
      "evaluation/Rewards Min                  4.75166\n",
      "evaluation/Returns Mean              2013.59\n",
      "evaluation/Returns Std               1140.81\n",
      "evaluation/Returns Max               4354.87\n",
      "evaluation/Returns Min                666.219\n",
      "evaluation/Estimation Bias Mean      1502.12\n",
      "evaluation/Estimation Bias Std        575.731\n",
      "evaluation/EB/Q_True Mean             100.978\n",
      "evaluation/EB/Q_True Std              199.846\n",
      "evaluation/EB/Q_Pred Mean            1603.1\n",
      "evaluation/EB/Q_Pred Std              512.713\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           2013.59\n",
      "evaluation/Actions Mean                 0.10951\n",
      "evaluation/Actions Std                  0.621624\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.80927\n",
      "time/backward_zf1 (s)                   2.25755\n",
      "time/backward_zf2 (s)                   2.15456\n",
      "time/data sampling (s)                  0.390461\n",
      "time/data storing (s)                   0.0146587\n",
      "time/evaluation sampling (s)            2.19742\n",
      "time/exploration sampling (s)           0.486317\n",
      "time/logging (s)                        0.0057022\n",
      "time/preback_alpha (s)                  0.588109\n",
      "time/preback_policy (s)                 1.02554\n",
      "time/preback_start (s)                  0.176916\n",
      "time/preback_zf (s)                     6.67344\n",
      "time/saving (s)                         3.034e-06\n",
      "time/training (s)                       3.60575\n",
      "time/epoch (s)                         21.3857\n",
      "time/total (s)                       3799.11\n",
      "Epoch                                 184\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:29:07.566689 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 185 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 196000\n",
      "trainer/ZF1 Loss                      363.497\n",
      "trainer/ZF2 Loss                      319.15\n",
      "trainer/ZF Expert Reward               15.8158\n",
      "trainer/ZF Policy Reward                9.16034\n",
      "trainer/ZF CHI2 Term                  336.534\n",
      "trainer/Policy Loss                 -1497.92\n",
      "trainer/Bias Loss                      28.8237\n",
      "trainer/Bias Value                     16.4969\n",
      "trainer/Policy Grad Norm              233.529\n",
      "trainer/Policy Param Norm              52.1372\n",
      "trainer/Zf1 Grad Norm               15676.9\n",
      "trainer/Zf1 Param Norm                136.387\n",
      "trainer/Zf2 Grad Norm               15125.6\n",
      "trainer/Zf2 Param Norm                134.672\n",
      "trainer/Z Expert Predictions Mean    2060.54\n",
      "trainer/Z Expert Predictions Std       42.1023\n",
      "trainer/Z Expert Predictions Max     2173.16\n",
      "trainer/Z Expert Predictions Min     1893.88\n",
      "trainer/Z Policy Predictions Mean    1486.88\n",
      "trainer/Z Policy Predictions Std      637.988\n",
      "trainer/Z Policy Predictions Max     2052.26\n",
      "trainer/Z Policy Predictions Min      -31.6925\n",
      "trainer/Z Expert Targets Mean        2044.73\n",
      "trainer/Z Expert Targets Std           42.7123\n",
      "trainer/Z Expert Targets Max         2156.59\n",
      "trainer/Z Expert Targets Min         1896.31\n",
      "trainer/Z Policy Targets Mean        1477.72\n",
      "trainer/Z Policy Targets Std          634.231\n",
      "trainer/Z Policy Targets Max         2011.37\n",
      "trainer/Z Policy Targets Min          -32.8553\n",
      "trainer/Log Pis Mean                   61.2786\n",
      "trainer/Log Pis Std                    29.9889\n",
      "trainer/Policy mu Mean                  0.377398\n",
      "trainer/Policy mu Std                   3.99724\n",
      "trainer/Policy log std Mean            -2.87784\n",
      "trainer/Policy log std Std              1.33874\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        190282\n",
      "exploration/num paths total          1337\n",
      "evaluation/num steps total         899537\n",
      "evaluation/num paths total           1896\n",
      "evaluation/path length Mean           883.7\n",
      "evaluation/path length Std            262.591\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            146\n",
      "evaluation/Rewards Mean                 5.2879\n",
      "evaluation/Rewards Std                  0.0946729\n",
      "evaluation/Rewards Max                  5.97934\n",
      "evaluation/Rewards Min                  4.78453\n",
      "evaluation/Returns Mean              4672.92\n",
      "evaluation/Returns Std               1395.5\n",
      "evaluation/Returns Max               5298.36\n",
      "evaluation/Returns Min                754.692\n",
      "evaluation/Estimation Bias Mean      1822.83\n",
      "evaluation/Estimation Bias Std        282.504\n",
      "evaluation/EB/Q_True Mean              54.06\n",
      "evaluation/EB/Q_True Std              155.422\n",
      "evaluation/EB/Q_Pred Mean            1876.89\n",
      "evaluation/EB/Q_Pred Std              192.792\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4672.92\n",
      "evaluation/Actions Mean                 0.0939492\n",
      "evaluation/Actions Std                  0.530659\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.74232\n",
      "time/backward_zf1 (s)                   2.1924\n",
      "time/backward_zf2 (s)                   2.08886\n",
      "time/data sampling (s)                  0.336715\n",
      "time/data storing (s)                   0.0153033\n",
      "time/evaluation sampling (s)            2.29279\n",
      "time/exploration sampling (s)           0.482412\n",
      "time/logging (s)                        0.0125928\n",
      "time/preback_alpha (s)                  0.580891\n",
      "time/preback_policy (s)                 0.966313\n",
      "time/preback_start (s)                  0.175105\n",
      "time/preback_zf (s)                     6.67252\n",
      "time/saving (s)                         4.088e-06\n",
      "time/training (s)                       3.75026\n",
      "time/epoch (s)                         21.3085\n",
      "time/total (s)                       3820.44\n",
      "Epoch                                 185\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:29:29.107982 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 186 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 197000\n",
      "trainer/ZF1 Loss                      339.928\n",
      "trainer/ZF2 Loss                      323.032\n",
      "trainer/ZF Expert Reward               17.4021\n",
      "trainer/ZF Policy Reward                8.16204\n",
      "trainer/ZF CHI2 Term                  328.361\n",
      "trainer/Policy Loss                 -1462.81\n",
      "trainer/Bias Loss                      65.7138\n",
      "trainer/Bias Value                     16.4727\n",
      "trainer/Policy Grad Norm              383.302\n",
      "trainer/Policy Param Norm              52.1991\n",
      "trainer/Zf1 Grad Norm               16897.7\n",
      "trainer/Zf1 Param Norm                136.736\n",
      "trainer/Zf2 Grad Norm               14964\n",
      "trainer/Zf2 Param Norm                134.988\n",
      "trainer/Z Expert Predictions Mean    2057.68\n",
      "trainer/Z Expert Predictions Std       51.5897\n",
      "trainer/Z Expert Predictions Max     2178.31\n",
      "trainer/Z Expert Predictions Min     1874.36\n",
      "trainer/Z Policy Predictions Mean    1457.24\n",
      "trainer/Z Policy Predictions Std      671.614\n",
      "trainer/Z Policy Predictions Max     2062.17\n",
      "trainer/Z Policy Predictions Min      -30.1945\n",
      "trainer/Z Expert Targets Mean        2040.27\n",
      "trainer/Z Expert Targets Std           48.736\n",
      "trainer/Z Expert Targets Max         2149.5\n",
      "trainer/Z Expert Targets Min         1881.84\n",
      "trainer/Z Policy Targets Mean        1449.08\n",
      "trainer/Z Policy Targets Std          671.621\n",
      "trainer/Z Policy Targets Max         2044.65\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   59.9039\n",
      "trainer/Log Pis Std                    27.286\n",
      "trainer/Policy mu Mean                  0.306139\n",
      "trainer/Policy mu Std                   3.90839\n",
      "trainer/Policy log std Mean            -2.90344\n",
      "trainer/Policy log std Std              1.35474\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        191263\n",
      "exploration/num paths total          1338\n",
      "evaluation/num steps total         905631\n",
      "evaluation/num paths total           1907\n",
      "evaluation/path length Mean           554\n",
      "evaluation/path length Std            329.876\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            156\n",
      "evaluation/Rewards Mean                 5.29495\n",
      "evaluation/Rewards Std                  0.148356\n",
      "evaluation/Rewards Max                  6.20012\n",
      "evaluation/Rewards Min                  3.9849\n",
      "evaluation/Returns Mean              2933.4\n",
      "evaluation/Returns Std               1758.31\n",
      "evaluation/Returns Max               5313.44\n",
      "evaluation/Returns Min                784.079\n",
      "evaluation/Estimation Bias Mean      1685.08\n",
      "evaluation/Estimation Bias Std        460.307\n",
      "evaluation/EB/Q_True Mean              78.7219\n",
      "evaluation/EB/Q_True Std              182.782\n",
      "evaluation/EB/Q_Pred Mean            1763.8\n",
      "evaluation/EB/Q_Pred Std              371.064\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           2933.4\n",
      "evaluation/Actions Mean                 0.0873887\n",
      "evaluation/Actions Std                  0.575731\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.96069\n",
      "time/backward_zf1 (s)                   2.39423\n",
      "time/backward_zf2 (s)                   2.3222\n",
      "time/data sampling (s)                  0.384546\n",
      "time/data storing (s)                   0.0144879\n",
      "time/evaluation sampling (s)            2.26202\n",
      "time/exploration sampling (s)           0.47742\n",
      "time/logging (s)                        0.00881233\n",
      "time/preback_alpha (s)                  0.58216\n",
      "time/preback_policy (s)                 1.17673\n",
      "time/preback_start (s)                  0.177043\n",
      "time/preback_zf (s)                     6.64676\n",
      "time/saving (s)                         2.932e-06\n",
      "time/training (s)                       3.0625\n",
      "time/epoch (s)                         21.4696\n",
      "time/total (s)                       3841.93\n",
      "Epoch                                 186\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:29:51.095544 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 187 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 198000\n",
      "trainer/ZF1 Loss                      480.579\n",
      "trainer/ZF2 Loss                      394.391\n",
      "trainer/ZF Expert Reward                7.55454\n",
      "trainer/ZF Policy Reward                7.80068\n",
      "trainer/ZF CHI2 Term                  424.682\n",
      "trainer/Policy Loss                 -1432.33\n",
      "trainer/Bias Loss                     110.708\n",
      "trainer/Bias Value                     16.4461\n",
      "trainer/Policy Grad Norm              407.748\n",
      "trainer/Policy Param Norm              52.2635\n",
      "trainer/Zf1 Grad Norm               35606\n",
      "trainer/Zf1 Param Norm                137.074\n",
      "trainer/Zf2 Grad Norm               35802.7\n",
      "trainer/Zf2 Param Norm                135.311\n",
      "trainer/Z Expert Predictions Mean    2040.59\n",
      "trainer/Z Expert Predictions Std       51.532\n",
      "trainer/Z Expert Predictions Max     2156.62\n",
      "trainer/Z Expert Predictions Min     1859.84\n",
      "trainer/Z Policy Predictions Mean    1419.25\n",
      "trainer/Z Policy Predictions Std      662.795\n",
      "trainer/Z Policy Predictions Max     1995.69\n",
      "trainer/Z Policy Predictions Min       -1.89282\n",
      "trainer/Z Expert Targets Mean        2033.04\n",
      "trainer/Z Expert Targets Std           49.9483\n",
      "trainer/Z Expert Targets Max         2141.47\n",
      "trainer/Z Expert Targets Min         1872.4\n",
      "trainer/Z Policy Targets Mean        1411.45\n",
      "trainer/Z Policy Targets Std          669.062\n",
      "trainer/Z Policy Targets Max         2001.42\n",
      "trainer/Z Policy Targets Min           -2.83514\n",
      "trainer/Log Pis Mean                   61.51\n",
      "trainer/Log Pis Std                    28.7992\n",
      "trainer/Policy mu Mean                  0.281703\n",
      "trainer/Policy mu Std                   3.86363\n",
      "trainer/Policy log std Mean            -2.835\n",
      "trainer/Policy log std Std              1.31068\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        194556\n",
      "exploration/num paths total          1342\n",
      "evaluation/num steps total         913668\n",
      "evaluation/num paths total           1918\n",
      "evaluation/path length Mean           730.636\n",
      "evaluation/path length Std            364.867\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            152\n",
      "evaluation/Rewards Mean                 5.30819\n",
      "evaluation/Rewards Std                  0.106371\n",
      "evaluation/Rewards Max                  6.11598\n",
      "evaluation/Rewards Min                  4.77027\n",
      "evaluation/Returns Mean              3878.36\n",
      "evaluation/Returns Std               1941.46\n",
      "evaluation/Returns Max               5319.28\n",
      "evaluation/Returns Min                797.498\n",
      "evaluation/Estimation Bias Mean      1793.38\n",
      "evaluation/Estimation Bias Std        370.266\n",
      "evaluation/EB/Q_True Mean              59.7037\n",
      "evaluation/EB/Q_True Std              162.712\n",
      "evaluation/EB/Q_Pred Mean            1853.09\n",
      "evaluation/EB/Q_Pred Std              262.195\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3878.36\n",
      "evaluation/Actions Mean                 0.0811306\n",
      "evaluation/Actions Std                  0.54753\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.90406\n",
      "time/backward_zf1 (s)                   2.36914\n",
      "time/backward_zf2 (s)                   2.27857\n",
      "time/data sampling (s)                  0.382965\n",
      "time/data storing (s)                   0.0162091\n",
      "time/evaluation sampling (s)            2.56779\n",
      "time/exploration sampling (s)           0.516949\n",
      "time/logging (s)                        0.0110999\n",
      "time/preback_alpha (s)                  0.590387\n",
      "time/preback_policy (s)                 1.11689\n",
      "time/preback_start (s)                  0.181243\n",
      "time/preback_zf (s)                     6.71934\n",
      "time/saving (s)                         3.033e-06\n",
      "time/training (s)                       3.26514\n",
      "time/epoch (s)                         21.9198\n",
      "time/total (s)                       3863.87\n",
      "Epoch                                 187\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:30:12.866987 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 188 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 199000\n",
      "trainer/ZF1 Loss                      398.619\n",
      "trainer/ZF2 Loss                      377.887\n",
      "trainer/ZF Expert Reward               15.8897\n",
      "trainer/ZF Policy Reward                7.15223\n",
      "trainer/ZF CHI2 Term                  383.725\n",
      "trainer/Policy Loss                 -1454.13\n",
      "trainer/Bias Loss                      42.7565\n",
      "trainer/Bias Value                     16.4245\n",
      "trainer/Policy Grad Norm              274.547\n",
      "trainer/Policy Param Norm              52.3338\n",
      "trainer/Zf1 Grad Norm               23789.7\n",
      "trainer/Zf1 Param Norm                137.387\n",
      "trainer/Zf2 Grad Norm               20583\n",
      "trainer/Zf2 Param Norm                135.643\n",
      "trainer/Z Expert Predictions Mean    2043.22\n",
      "trainer/Z Expert Predictions Std       47.9084\n",
      "trainer/Z Expert Predictions Max     2168.01\n",
      "trainer/Z Expert Predictions Min     1860.46\n",
      "trainer/Z Policy Predictions Mean    1442.91\n",
      "trainer/Z Policy Predictions Std      643.533\n",
      "trainer/Z Policy Predictions Max     2017.46\n",
      "trainer/Z Policy Predictions Min      -12.9549\n",
      "trainer/Z Expert Targets Mean        2027.33\n",
      "trainer/Z Expert Targets Std           47.5089\n",
      "trainer/Z Expert Targets Max         2147.54\n",
      "trainer/Z Expert Targets Min         1865.58\n",
      "trainer/Z Policy Targets Mean        1435.76\n",
      "trainer/Z Policy Targets Std          641.084\n",
      "trainer/Z Policy Targets Max         2005.66\n",
      "trainer/Z Policy Targets Min          -10.6897\n",
      "trainer/Log Pis Mean                   59.6458\n",
      "trainer/Log Pis Std                    27.3088\n",
      "trainer/Policy mu Mean                  0.361978\n",
      "trainer/Policy mu Std                   3.25782\n",
      "trainer/Policy log std Mean            -2.90496\n",
      "trainer/Policy log std Std              1.29637\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        195556\n",
      "exploration/num paths total          1343\n",
      "evaluation/num steps total         921352\n",
      "evaluation/num paths total           1929\n",
      "evaluation/path length Mean           698.545\n",
      "evaluation/path length Std            292.217\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            231\n",
      "evaluation/Rewards Mean                 5.2931\n",
      "evaluation/Rewards Std                  0.125341\n",
      "evaluation/Rewards Max                  6.21063\n",
      "evaluation/Rewards Min                  4.6787\n",
      "evaluation/Returns Mean              3697.47\n",
      "evaluation/Returns Std               1547.52\n",
      "evaluation/Returns Max               5308.5\n",
      "evaluation/Returns Min               1219.23\n",
      "evaluation/Estimation Bias Mean      1679.96\n",
      "evaluation/Estimation Bias Std        420.885\n",
      "evaluation/EB/Q_True Mean              62.3435\n",
      "evaluation/EB/Q_True Std              165.579\n",
      "evaluation/EB/Q_Pred Mean            1742.3\n",
      "evaluation/EB/Q_Pred Std              357.448\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3697.47\n",
      "evaluation/Actions Mean                 0.093966\n",
      "evaluation/Actions Std                  0.573198\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84557\n",
      "time/backward_zf1 (s)                   2.29792\n",
      "time/backward_zf2 (s)                   2.21272\n",
      "time/data sampling (s)                  0.390591\n",
      "time/data storing (s)                   0.0145789\n",
      "time/evaluation sampling (s)            2.52794\n",
      "time/exploration sampling (s)           0.483198\n",
      "time/logging (s)                        0.0113782\n",
      "time/preback_alpha (s)                  0.580881\n",
      "time/preback_policy (s)                 1.084\n",
      "time/preback_start (s)                  0.177458\n",
      "time/preback_zf (s)                     6.67549\n",
      "time/saving (s)                         2.917e-06\n",
      "time/training (s)                       3.39977\n",
      "time/epoch (s)                         21.7015\n",
      "time/total (s)                       3885.6\n",
      "Epoch                                 188\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:30:33.687512 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 189 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 200000\n",
      "trainer/ZF1 Loss                      335.689\n",
      "trainer/ZF2 Loss                      385.251\n",
      "trainer/ZF Expert Reward               12.9227\n",
      "trainer/ZF Policy Reward                4.64312\n",
      "trainer/ZF CHI2 Term                  352.983\n",
      "trainer/Policy Loss                 -1537.92\n",
      "trainer/Bias Loss                      38.5916\n",
      "trainer/Bias Value                     16.3962\n",
      "trainer/Policy Grad Norm              279.915\n",
      "trainer/Policy Param Norm              52.3986\n",
      "trainer/Zf1 Grad Norm               17776.8\n",
      "trainer/Zf1 Param Norm                137.74\n",
      "trainer/Zf2 Grad Norm               21115.3\n",
      "trainer/Zf2 Param Norm                135.993\n",
      "trainer/Z Expert Predictions Mean    2038.35\n",
      "trainer/Z Expert Predictions Std      134.932\n",
      "trainer/Z Expert Predictions Max     2177.51\n",
      "trainer/Z Expert Predictions Min       14.9431\n",
      "trainer/Z Policy Predictions Mean    1525.93\n",
      "trainer/Z Policy Predictions Std      607.003\n",
      "trainer/Z Policy Predictions Max     2037.92\n",
      "trainer/Z Policy Predictions Min       -7.78367\n",
      "trainer/Z Expert Targets Mean        2025.43\n",
      "trainer/Z Expert Targets Std          135.303\n",
      "trainer/Z Expert Targets Max         2158.05\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1521.28\n",
      "trainer/Z Policy Targets Std          605.379\n",
      "trainer/Z Policy Targets Max         2009.6\n",
      "trainer/Z Policy Targets Min          -20.5686\n",
      "trainer/Log Pis Mean                   55.0429\n",
      "trainer/Log Pis Std                    24.5434\n",
      "trainer/Policy mu Mean                  0.207316\n",
      "trainer/Policy mu Std                   2.95327\n",
      "trainer/Policy log std Mean            -2.97338\n",
      "trainer/Policy log std Std              1.16034\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        195731\n",
      "exploration/num paths total          1344\n",
      "evaluation/num steps total         924758\n",
      "evaluation/num paths total           1939\n",
      "evaluation/path length Mean           340.6\n",
      "evaluation/path length Std            106.48\n",
      "evaluation/path length Max            559\n",
      "evaluation/path length Min            161\n",
      "evaluation/Rewards Mean                 5.3309\n",
      "evaluation/Rewards Std                  0.209569\n",
      "evaluation/Rewards Max                  6.23171\n",
      "evaluation/Rewards Min                  4.28607\n",
      "evaluation/Returns Mean              1815.7\n",
      "evaluation/Returns Std                581.587\n",
      "evaluation/Returns Max               3004.76\n",
      "evaluation/Returns Min                815.59\n",
      "evaluation/Estimation Bias Mean      1427.93\n",
      "evaluation/Estimation Bias Std        565.891\n",
      "evaluation/EB/Q_True Mean              59.2472\n",
      "evaluation/EB/Q_True Std              144.35\n",
      "evaluation/EB/Q_Pred Mean            1487.17\n",
      "evaluation/EB/Q_Pred Std              543.382\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1815.7\n",
      "evaluation/Actions Mean                 0.104393\n",
      "evaluation/Actions Std                  0.641768\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.84441\n",
      "time/backward_zf1 (s)                   2.31141\n",
      "time/backward_zf2 (s)                   2.2076\n",
      "time/data sampling (s)                  0.386572\n",
      "time/data storing (s)                   0.015436\n",
      "time/evaluation sampling (s)            1.29374\n",
      "time/exploration sampling (s)           0.481739\n",
      "time/logging (s)                        0.00529918\n",
      "time/preback_alpha (s)                  0.592843\n",
      "time/preback_policy (s)                 1.05063\n",
      "time/preback_start (s)                  0.184545\n",
      "time/preback_zf (s)                     6.73123\n",
      "time/saving (s)                         2.721e-06\n",
      "time/training (s)                       3.64032\n",
      "time/epoch (s)                         20.7458\n",
      "time/total (s)                       3906.36\n",
      "Epoch                                 189\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:30:55.666771 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 190 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 201000\n",
      "trainer/ZF1 Loss                      399.975\n",
      "trainer/ZF2 Loss                      377.937\n",
      "trainer/ZF Expert Reward               13.4293\n",
      "trainer/ZF Policy Reward               -0.0699894\n",
      "trainer/ZF CHI2 Term                  382.003\n",
      "trainer/Policy Loss                 -1449.14\n",
      "trainer/Bias Loss                      50.6111\n",
      "trainer/Bias Value                     16.3759\n",
      "trainer/Policy Grad Norm              266.767\n",
      "trainer/Policy Param Norm              52.4602\n",
      "trainer/Zf1 Grad Norm               21406.6\n",
      "trainer/Zf1 Param Norm                138.074\n",
      "trainer/Zf2 Grad Norm               25709.6\n",
      "trainer/Zf2 Param Norm                136.319\n",
      "trainer/Z Expert Predictions Mean    2040.06\n",
      "trainer/Z Expert Predictions Std       47.4877\n",
      "trainer/Z Expert Predictions Max     2161.11\n",
      "trainer/Z Expert Predictions Min     1830.71\n",
      "trainer/Z Policy Predictions Mean    1435.97\n",
      "trainer/Z Policy Predictions Std      649.217\n",
      "trainer/Z Policy Predictions Max     2030.32\n",
      "trainer/Z Policy Predictions Min      -19.5028\n",
      "trainer/Z Expert Targets Mean        2026.63\n",
      "trainer/Z Expert Targets Std           47.743\n",
      "trainer/Z Expert Targets Max         2157.17\n",
      "trainer/Z Expert Targets Min         1823.73\n",
      "trainer/Z Policy Targets Mean        1436.04\n",
      "trainer/Z Policy Targets Std          652.02\n",
      "trainer/Z Policy Targets Max         2002.72\n",
      "trainer/Z Policy Targets Min          -10.9974\n",
      "trainer/Log Pis Mean                   60.1745\n",
      "trainer/Log Pis Std                    26.8472\n",
      "trainer/Policy mu Mean                  0.401632\n",
      "trainer/Policy mu Std                   3.20313\n",
      "trainer/Policy log std Mean            -2.86426\n",
      "trainer/Policy log std Std              1.2446\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        196731\n",
      "exploration/num paths total          1345\n",
      "evaluation/num steps total         932902\n",
      "evaluation/num paths total           1949\n",
      "evaluation/path length Mean           814.4\n",
      "evaluation/path length Std            277.566\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            223\n",
      "evaluation/Rewards Mean                 5.30481\n",
      "evaluation/Rewards Std                  0.101026\n",
      "evaluation/Rewards Max                  6.53129\n",
      "evaluation/Rewards Min                  4.77187\n",
      "evaluation/Returns Mean              4320.24\n",
      "evaluation/Returns Std               1479.28\n",
      "evaluation/Returns Max               5315.82\n",
      "evaluation/Returns Min               1161.67\n",
      "evaluation/Estimation Bias Mean      1785.92\n",
      "evaluation/Estimation Bias Std        383.226\n",
      "evaluation/EB/Q_True Mean              58.8428\n",
      "evaluation/EB/Q_True Std              161.563\n",
      "evaluation/EB/Q_Pred Mean            1844.76\n",
      "evaluation/EB/Q_Pred Std              303.31\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4320.24\n",
      "evaluation/Actions Mean                 0.0869606\n",
      "evaluation/Actions Std                  0.537592\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.96804\n",
      "time/backward_zf1 (s)                   2.43428\n",
      "time/backward_zf2 (s)                   2.35072\n",
      "time/data sampling (s)                  0.388666\n",
      "time/data storing (s)                   0.0153746\n",
      "time/evaluation sampling (s)            2.53876\n",
      "time/exploration sampling (s)           0.484076\n",
      "time/logging (s)                        0.0120368\n",
      "time/preback_alpha (s)                  0.591141\n",
      "time/preback_policy (s)                 1.19047\n",
      "time/preback_start (s)                  0.184025\n",
      "time/preback_zf (s)                     6.69583\n",
      "time/saving (s)                         2.764e-06\n",
      "time/training (s)                       3.06139\n",
      "time/epoch (s)                         21.9148\n",
      "time/total (s)                       3928.3\n",
      "Epoch                                 190\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:31:16.924106 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 191 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 202000\n",
      "trainer/ZF1 Loss                      325.627\n",
      "trainer/ZF2 Loss                      353.766\n",
      "trainer/ZF Expert Reward               16.5231\n",
      "trainer/ZF Policy Reward                7.90932\n",
      "trainer/ZF CHI2 Term                  335.878\n",
      "trainer/Policy Loss                 -1505.76\n",
      "trainer/Bias Loss                      31.9626\n",
      "trainer/Bias Value                     16.3516\n",
      "trainer/Policy Grad Norm              256.689\n",
      "trainer/Policy Param Norm              52.5192\n",
      "trainer/Zf1 Grad Norm               17881\n",
      "trainer/Zf1 Param Norm                138.397\n",
      "trainer/Zf2 Grad Norm               15496.7\n",
      "trainer/Zf2 Param Norm                136.668\n",
      "trainer/Z Expert Predictions Mean    2031.87\n",
      "trainer/Z Expert Predictions Std       47.1948\n",
      "trainer/Z Expert Predictions Max     2144.85\n",
      "trainer/Z Expert Predictions Min     1906.49\n",
      "trainer/Z Policy Predictions Mean    1497.41\n",
      "trainer/Z Policy Predictions Std      595.569\n",
      "trainer/Z Policy Predictions Max     2013.03\n",
      "trainer/Z Policy Predictions Min        1.78748\n",
      "trainer/Z Expert Targets Mean        2015.35\n",
      "trainer/Z Expert Targets Std           45.9457\n",
      "trainer/Z Expert Targets Max         2123.33\n",
      "trainer/Z Expert Targets Min         1897.57\n",
      "trainer/Z Policy Targets Mean        1489.5\n",
      "trainer/Z Policy Targets Std          593.693\n",
      "trainer/Z Policy Targets Max         2004.61\n",
      "trainer/Z Policy Targets Min           -1.32027\n",
      "trainer/Log Pis Mean                   56.9574\n",
      "trainer/Log Pis Std                    27.1095\n",
      "trainer/Policy mu Mean                  0.425121\n",
      "trainer/Policy mu Std                   2.97133\n",
      "trainer/Policy log std Mean            -2.93689\n",
      "trainer/Policy log std Std              1.18043\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        196731\n",
      "exploration/num paths total          1345\n",
      "evaluation/num steps total         935885\n",
      "evaluation/num paths total           1959\n",
      "evaluation/path length Mean           298.3\n",
      "evaluation/path length Std             94.7038\n",
      "evaluation/path length Max            495\n",
      "evaluation/path length Min            213\n",
      "evaluation/Rewards Mean                 5.17687\n",
      "evaluation/Rewards Std                  0.230685\n",
      "evaluation/Rewards Max                  6.72026\n",
      "evaluation/Rewards Min                  4.20591\n",
      "evaluation/Returns Mean              1544.26\n",
      "evaluation/Returns Std                486.212\n",
      "evaluation/Returns Max               2530.4\n",
      "evaluation/Returns Min               1059.95\n",
      "evaluation/Estimation Bias Mean      1229.24\n",
      "evaluation/Estimation Bias Std        544.418\n",
      "evaluation/EB/Q_True Mean              47.3737\n",
      "evaluation/EB/Q_True Std              119.942\n",
      "evaluation/EB/Q_Pred Mean            1276.61\n",
      "evaluation/EB/Q_Pred Std              524.747\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1544.26\n",
      "evaluation/Actions Mean                 0.0969186\n",
      "evaluation/Actions Std                  0.703979\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.86275\n",
      "time/backward_zf1 (s)                   2.30284\n",
      "time/backward_zf2 (s)                   2.25079\n",
      "time/data sampling (s)                  0.389268\n",
      "time/data storing (s)                   0.0154719\n",
      "time/evaluation sampling (s)            1.80213\n",
      "time/exploration sampling (s)           0.483546\n",
      "time/logging (s)                        0.00455133\n",
      "time/preback_alpha (s)                  0.591162\n",
      "time/preback_policy (s)                 1.09519\n",
      "time/preback_start (s)                  0.178284\n",
      "time/preback_zf (s)                     6.70937\n",
      "time/saving (s)                         2.794e-06\n",
      "time/training (s)                       3.49045\n",
      "time/epoch (s)                         21.1758\n",
      "time/total (s)                       3949.5\n",
      "Epoch                                 191\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:31:38.687119 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 192 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 203000\n",
      "trainer/ZF1 Loss                      533.514\n",
      "trainer/ZF2 Loss                      510.733\n",
      "trainer/ZF Expert Reward                6.05778\n",
      "trainer/ZF Policy Reward                6.76479\n",
      "trainer/ZF CHI2 Term                  507.9\n",
      "trainer/Policy Loss                 -1428.48\n",
      "trainer/Bias Loss                     155.979\n",
      "trainer/Bias Value                     16.3257\n",
      "trainer/Policy Grad Norm              277.353\n",
      "trainer/Policy Param Norm              52.5936\n",
      "trainer/Zf1 Grad Norm               35735.8\n",
      "trainer/Zf1 Param Norm                138.744\n",
      "trainer/Zf2 Grad Norm               38722.1\n",
      "trainer/Zf2 Param Norm                137.023\n",
      "trainer/Z Expert Predictions Mean    2026.94\n",
      "trainer/Z Expert Predictions Std       53.5014\n",
      "trainer/Z Expert Predictions Max     2156.84\n",
      "trainer/Z Expert Predictions Min     1644.14\n",
      "trainer/Z Policy Predictions Mean    1417.09\n",
      "trainer/Z Policy Predictions Std      635.5\n",
      "trainer/Z Policy Predictions Max     2018.23\n",
      "trainer/Z Policy Predictions Min      -12.8157\n",
      "trainer/Z Expert Targets Mean        2020.88\n",
      "trainer/Z Expert Targets Std           52.8903\n",
      "trainer/Z Expert Targets Max         2144.27\n",
      "trainer/Z Expert Targets Min         1675.92\n",
      "trainer/Z Policy Targets Mean        1410.33\n",
      "trainer/Z Policy Targets Std          636.819\n",
      "trainer/Z Policy Targets Max         2022.09\n",
      "trainer/Z Policy Targets Min          -18.2668\n",
      "trainer/Log Pis Mean                   61.1411\n",
      "trainer/Log Pis Std                    29.2524\n",
      "trainer/Policy mu Mean                  0.353685\n",
      "trainer/Policy mu Std                   3.73972\n",
      "trainer/Policy log std Mean            -2.86651\n",
      "trainer/Policy log std Std              1.2663\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        197731\n",
      "exploration/num paths total          1346\n",
      "evaluation/num steps total         945057\n",
      "evaluation/num paths total           1969\n",
      "evaluation/path length Mean           917.2\n",
      "evaluation/path length Std            248.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            172\n",
      "evaluation/Rewards Mean                 5.26829\n",
      "evaluation/Rewards Std                  0.0891857\n",
      "evaluation/Rewards Max                  5.57784\n",
      "evaluation/Rewards Min                  4.72626\n",
      "evaluation/Returns Mean              4832.08\n",
      "evaluation/Returns Std               1318.97\n",
      "evaluation/Returns Max               5280.31\n",
      "evaluation/Returns Min                875.191\n",
      "evaluation/Estimation Bias Mean      1844.56\n",
      "evaluation/Estimation Bias Std        226.794\n",
      "evaluation/EB/Q_True Mean              51.9026\n",
      "evaluation/EB/Q_True Std              152.335\n",
      "evaluation/EB/Q_Pred Mean            1896.47\n",
      "evaluation/EB/Q_Pred Std              143.023\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4832.08\n",
      "evaluation/Actions Mean                 0.0867383\n",
      "evaluation/Actions Std                  0.507149\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.95475\n",
      "time/backward_zf1 (s)                   2.42288\n",
      "time/backward_zf2 (s)                   2.33708\n",
      "time/data sampling (s)                  0.368333\n",
      "time/data storing (s)                   0.0160351\n",
      "time/evaluation sampling (s)            2.34653\n",
      "time/exploration sampling (s)           0.508234\n",
      "time/logging (s)                        0.0127809\n",
      "time/preback_alpha (s)                  0.588498\n",
      "time/preback_policy (s)                 1.17954\n",
      "time/preback_start (s)                  0.184014\n",
      "time/preback_zf (s)                     6.69942\n",
      "time/saving (s)                         3.809e-06\n",
      "time/training (s)                       3.08573\n",
      "time/epoch (s)                         21.7038\n",
      "time/total (s)                       3971.22\n",
      "Epoch                                 192\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:32:00.960428 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 193 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 204000\n",
      "trainer/ZF1 Loss                      425.957\n",
      "trainer/ZF2 Loss                      397.3\n",
      "trainer/ZF Expert Reward               19.7393\n",
      "trainer/ZF Policy Reward                6.96527\n",
      "trainer/ZF CHI2 Term                  410.938\n",
      "trainer/Policy Loss                 -1426.62\n",
      "trainer/Bias Loss                      37.1917\n",
      "trainer/Bias Value                     16.3037\n",
      "trainer/Policy Grad Norm              288.414\n",
      "trainer/Policy Param Norm              52.6617\n",
      "trainer/Zf1 Grad Norm               24516.3\n",
      "trainer/Zf1 Param Norm                139.099\n",
      "trainer/Zf2 Grad Norm               21269.5\n",
      "trainer/Zf2 Param Norm                137.366\n",
      "trainer/Z Expert Predictions Mean    2041.66\n",
      "trainer/Z Expert Predictions Std       50.2162\n",
      "trainer/Z Expert Predictions Max     2149.72\n",
      "trainer/Z Expert Predictions Min     1894.21\n",
      "trainer/Z Policy Predictions Mean    1413.5\n",
      "trainer/Z Policy Predictions Std      668.75\n",
      "trainer/Z Policy Predictions Max     2066.6\n",
      "trainer/Z Policy Predictions Min       -2.99551\n",
      "trainer/Z Expert Targets Mean        2021.92\n",
      "trainer/Z Expert Targets Std           50.5964\n",
      "trainer/Z Expert Targets Max         2141.78\n",
      "trainer/Z Expert Targets Min         1869.21\n",
      "trainer/Z Policy Targets Mean        1406.53\n",
      "trainer/Z Policy Targets Std          662.622\n",
      "trainer/Z Policy Targets Max         2034.71\n",
      "trainer/Z Policy Targets Min           -3.66775\n",
      "trainer/Log Pis Mean                   61.3901\n",
      "trainer/Log Pis Std                    29.1174\n",
      "trainer/Policy mu Mean                  0.322012\n",
      "trainer/Policy mu Std                   3.90693\n",
      "trainer/Policy log std Mean            -2.83964\n",
      "trainer/Policy log std Std              1.44508\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        198731\n",
      "exploration/num paths total          1347\n",
      "evaluation/num steps total         954545\n",
      "evaluation/num paths total           1980\n",
      "evaluation/path length Mean           862.545\n",
      "evaluation/path length Std            291.59\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            240\n",
      "evaluation/Rewards Mean                 5.29524\n",
      "evaluation/Rewards Std                  0.104123\n",
      "evaluation/Rewards Max                  6.93767\n",
      "evaluation/Rewards Min                  4.80278\n",
      "evaluation/Returns Mean              4567.39\n",
      "evaluation/Returns Std               1543.51\n",
      "evaluation/Returns Max               5308.55\n",
      "evaluation/Returns Min               1260.15\n",
      "evaluation/Estimation Bias Mean      1826.77\n",
      "evaluation/Estimation Bias Std        294.667\n",
      "evaluation/EB/Q_True Mean              50.4257\n",
      "evaluation/EB/Q_True Std              150.841\n",
      "evaluation/EB/Q_Pred Mean            1877.19\n",
      "evaluation/EB/Q_Pred Std              194.658\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4567.39\n",
      "evaluation/Actions Mean                 0.077396\n",
      "evaluation/Actions Std                  0.514118\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.02767\n",
      "time/backward_zf1 (s)                   2.4681\n",
      "time/backward_zf2 (s)                   2.3973\n",
      "time/data sampling (s)                  0.404373\n",
      "time/data storing (s)                   0.0145128\n",
      "time/evaluation sampling (s)            2.50302\n",
      "time/exploration sampling (s)           0.483197\n",
      "time/logging (s)                        0.0132123\n",
      "time/preback_alpha (s)                  0.600632\n",
      "time/preback_policy (s)                 1.18797\n",
      "time/preback_start (s)                  0.183676\n",
      "time/preback_zf (s)                     6.70836\n",
      "time/saving (s)                         3.281e-06\n",
      "time/training (s)                       3.19514\n",
      "time/epoch (s)                         22.1872\n",
      "time/total (s)                       3993.45\n",
      "Epoch                                 193\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:32:22.788813 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 194 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 205000\n",
      "trainer/ZF1 Loss                     1917.73\n",
      "trainer/ZF2 Loss                     2758.16\n",
      "trainer/ZF Expert Reward               15.6617\n",
      "trainer/ZF Policy Reward               13.707\n",
      "trainer/ZF CHI2 Term                 2333.33\n",
      "trainer/Policy Loss                 -1481.57\n",
      "trainer/Bias Loss                      49.4095\n",
      "trainer/Bias Value                     16.2811\n",
      "trainer/Policy Grad Norm              280.115\n",
      "trainer/Policy Param Norm              52.7176\n",
      "trainer/Zf1 Grad Norm               83091.1\n",
      "trainer/Zf1 Param Norm                139.44\n",
      "trainer/Zf2 Grad Norm               66695.7\n",
      "trainer/Zf2 Param Norm                137.72\n",
      "trainer/Z Expert Predictions Mean    2027.13\n",
      "trainer/Z Expert Predictions Std       71.0585\n",
      "trainer/Z Expert Predictions Max     2146.7\n",
      "trainer/Z Expert Predictions Min     1258.94\n",
      "trainer/Z Policy Predictions Mean    1473\n",
      "trainer/Z Policy Predictions Std      611.711\n",
      "trainer/Z Policy Predictions Max     2037.84\n",
      "trainer/Z Policy Predictions Min      -18.9622\n",
      "trainer/Z Expert Targets Mean        2011.47\n",
      "trainer/Z Expert Targets Std           71.7041\n",
      "trainer/Z Expert Targets Max         2131.46\n",
      "trainer/Z Expert Targets Min         1251.98\n",
      "trainer/Z Policy Targets Mean        1459.29\n",
      "trainer/Z Policy Targets Std          618.066\n",
      "trainer/Z Policy Targets Max         2018.17\n",
      "trainer/Z Policy Targets Min          -35.4522\n",
      "trainer/Log Pis Mean                   57.5917\n",
      "trainer/Log Pis Std                    24.4129\n",
      "trainer/Policy mu Mean                  0.331612\n",
      "trainer/Policy mu Std                   2.92535\n",
      "trainer/Policy log std Mean            -3.02417\n",
      "trainer/Policy log std Std              1.17715\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        199731\n",
      "exploration/num paths total          1348\n",
      "evaluation/num steps total         963976\n",
      "evaluation/num paths total           1990\n",
      "evaluation/path length Mean           943.1\n",
      "evaluation/path length Std            170.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            431\n",
      "evaluation/Rewards Mean                 5.29864\n",
      "evaluation/Rewards Std                  0.0835707\n",
      "evaluation/Rewards Max                  5.49694\n",
      "evaluation/Rewards Min                  4.78794\n",
      "evaluation/Returns Mean              4997.14\n",
      "evaluation/Returns Std                911.317\n",
      "evaluation/Returns Max               5305.39\n",
      "evaluation/Returns Min               2263.21\n",
      "evaluation/Estimation Bias Mean      1864.97\n",
      "evaluation/Estimation Bias Std        226.771\n",
      "evaluation/EB/Q_True Mean              50.8005\n",
      "evaluation/EB/Q_True Std              151.438\n",
      "evaluation/EB/Q_Pred Mean            1915.77\n",
      "evaluation/EB/Q_Pred Std              137.891\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4997.14\n",
      "evaluation/Actions Mean                 0.0836843\n",
      "evaluation/Actions Std                  0.50223\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89518\n",
      "time/backward_zf1 (s)                   2.32085\n",
      "time/backward_zf2 (s)                   2.264\n",
      "time/data sampling (s)                  0.39431\n",
      "time/data storing (s)                   0.0159239\n",
      "time/evaluation sampling (s)            2.53007\n",
      "time/exploration sampling (s)           0.495983\n",
      "time/logging (s)                        0.0132118\n",
      "time/preback_alpha (s)                  0.591884\n",
      "time/preback_policy (s)                 1.15211\n",
      "time/preback_start (s)                  0.181432\n",
      "time/preback_zf (s)                     6.70684\n",
      "time/saving (s)                         3.388e-06\n",
      "time/training (s)                       3.19734\n",
      "time/epoch (s)                         21.7591\n",
      "time/total (s)                       4015.23\n",
      "Epoch                                 194\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:32:44.681837 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 195 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 206000\n",
      "trainer/ZF1 Loss                      389.826\n",
      "trainer/ZF2 Loss                      451.669\n",
      "trainer/ZF Expert Reward               23.3046\n",
      "trainer/ZF Policy Reward               13.9745\n",
      "trainer/ZF CHI2 Term                  423.703\n",
      "trainer/Policy Loss                 -1421.39\n",
      "trainer/Bias Loss                      54.7279\n",
      "trainer/Bias Value                     16.2613\n",
      "trainer/Policy Grad Norm              296.032\n",
      "trainer/Policy Param Norm              52.7793\n",
      "trainer/Zf1 Grad Norm               25671.7\n",
      "trainer/Zf1 Param Norm                139.769\n",
      "trainer/Zf2 Grad Norm               29577\n",
      "trainer/Zf2 Param Norm                138.04\n",
      "trainer/Z Expert Predictions Mean    2027.59\n",
      "trainer/Z Expert Predictions Std      141.627\n",
      "trainer/Z Expert Predictions Max     2160.72\n",
      "trainer/Z Expert Predictions Min      -10.8653\n",
      "trainer/Z Policy Predictions Mean    1410.5\n",
      "trainer/Z Policy Predictions Std      650.153\n",
      "trainer/Z Policy Predictions Max     2022.6\n",
      "trainer/Z Policy Predictions Min       -5.22176\n",
      "trainer/Z Expert Targets Mean        2004.28\n",
      "trainer/Z Expert Targets Std          140.021\n",
      "trainer/Z Expert Targets Max         2132.68\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1396.53\n",
      "trainer/Z Policy Targets Std          645.738\n",
      "trainer/Z Policy Targets Max         2019.52\n",
      "trainer/Z Policy Targets Min          -20.6829\n",
      "trainer/Log Pis Mean                   61.5361\n",
      "trainer/Log Pis Std                    29.7632\n",
      "trainer/Policy mu Mean                  0.376522\n",
      "trainer/Policy mu Std                   3.55831\n",
      "trainer/Policy log std Mean            -2.92242\n",
      "trainer/Policy log std Std              1.21849\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        199731\n",
      "exploration/num paths total          1348\n",
      "evaluation/num steps total         973976\n",
      "evaluation/num paths total           2000\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.3273\n",
      "evaluation/Rewards Std                  0.0859869\n",
      "evaluation/Rewards Max                  5.63393\n",
      "evaluation/Rewards Min                  4.77174\n",
      "evaluation/Returns Mean              5327.3\n",
      "evaluation/Returns Std                  8.68481\n",
      "evaluation/Returns Max               5336.81\n",
      "evaluation/Returns Min               5307.27\n",
      "evaluation/Estimation Bias Mean      1838.6\n",
      "evaluation/Estimation Bias Std        170.861\n",
      "evaluation/EB/Q_True Mean              48.0627\n",
      "evaluation/EB/Q_True Std              148.024\n",
      "evaluation/EB/Q_Pred Mean            1886.66\n",
      "evaluation/EB/Q_Pred Std               83.717\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5327.3\n",
      "evaluation/Actions Mean                 0.061265\n",
      "evaluation/Actions Std                  0.52198\n",
      "evaluation/Actions Max                  0.999982\n",
      "evaluation/Actions Min                 -0.999919\n",
      "time/backward_policy (s)                1.85705\n",
      "time/backward_zf1 (s)                   2.32466\n",
      "time/backward_zf2 (s)                   2.21597\n",
      "time/data sampling (s)                  0.395314\n",
      "time/data storing (s)                   0.0152428\n",
      "time/evaluation sampling (s)            2.32974\n",
      "time/exploration sampling (s)           0.480469\n",
      "time/logging (s)                        0.0129113\n",
      "time/preback_alpha (s)                  0.6049\n",
      "time/preback_policy (s)                 1.07894\n",
      "time/preback_start (s)                  0.185292\n",
      "time/preback_zf (s)                     6.77595\n",
      "time/saving (s)                         3.08e-06\n",
      "time/training (s)                       3.54003\n",
      "time/epoch (s)                         21.8165\n",
      "time/total (s)                       4037.07\n",
      "Epoch                                 195\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:33:06.242514 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 196 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 207000\n",
      "trainer/ZF1 Loss                     3260.05\n",
      "trainer/ZF2 Loss                     3534.66\n",
      "trainer/ZF Expert Reward               20.3898\n",
      "trainer/ZF Policy Reward               26.2366\n",
      "trainer/ZF CHI2 Term                 3397.46\n",
      "trainer/Policy Loss                 -1572.34\n",
      "trainer/Bias Loss                      56.7152\n",
      "trainer/Bias Value                     16.2394\n",
      "trainer/Policy Grad Norm              355.574\n",
      "trainer/Policy Param Norm              52.8443\n",
      "trainer/Zf1 Grad Norm               50359.2\n",
      "trainer/Zf1 Param Norm                140.134\n",
      "trainer/Zf2 Grad Norm               37984.3\n",
      "trainer/Zf2 Param Norm                138.41\n",
      "trainer/Z Expert Predictions Mean    2032.99\n",
      "trainer/Z Expert Predictions Std       53.2927\n",
      "trainer/Z Expert Predictions Max     2158.47\n",
      "trainer/Z Expert Predictions Min     1885.53\n",
      "trainer/Z Policy Predictions Mean    1571.23\n",
      "trainer/Z Policy Predictions Std      535.886\n",
      "trainer/Z Policy Predictions Max     2028.85\n",
      "trainer/Z Policy Predictions Min       -5.73186\n",
      "trainer/Z Expert Targets Mean        2012.6\n",
      "trainer/Z Expert Targets Std           53.1864\n",
      "trainer/Z Expert Targets Max         2140.09\n",
      "trainer/Z Expert Targets Min         1858.19\n",
      "trainer/Z Policy Targets Mean        1545\n",
      "trainer/Z Policy Targets Std          539.438\n",
      "trainer/Z Policy Targets Max         2007.22\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   55.9424\n",
      "trainer/Log Pis Std                    21.7641\n",
      "trainer/Policy mu Mean                  0.337508\n",
      "trainer/Policy mu Std                   2.64637\n",
      "trainer/Policy log std Mean            -3.15125\n",
      "trainer/Policy log std Std              1.11515\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        200701\n",
      "exploration/num paths total          1349\n",
      "evaluation/num steps total         983976\n",
      "evaluation/num paths total           2010\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31231\n",
      "evaluation/Rewards Std                  0.0756707\n",
      "evaluation/Rewards Max                  5.51804\n",
      "evaluation/Rewards Min                  4.82497\n",
      "evaluation/Returns Mean              5312.31\n",
      "evaluation/Returns Std                  6.76697\n",
      "evaluation/Returns Max               5321.23\n",
      "evaluation/Returns Min               5299.49\n",
      "evaluation/Estimation Bias Mean      1854.29\n",
      "evaluation/Estimation Bias Std        177.59\n",
      "evaluation/EB/Q_True Mean              47.9304\n",
      "evaluation/EB/Q_True Std              147.614\n",
      "evaluation/EB/Q_Pred Mean            1902.22\n",
      "evaluation/EB/Q_Pred Std              100.161\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5312.31\n",
      "evaluation/Actions Mean                 0.0827178\n",
      "evaluation/Actions Std                  0.513214\n",
      "evaluation/Actions Max                  0.99996\n",
      "evaluation/Actions Min                 -0.999471\n",
      "time/backward_policy (s)                1.78467\n",
      "time/backward_zf1 (s)                   2.23903\n",
      "time/backward_zf2 (s)                   2.11491\n",
      "time/data sampling (s)                  0.391322\n",
      "time/data storing (s)                   0.0167911\n",
      "time/evaluation sampling (s)            2.23969\n",
      "time/exploration sampling (s)           0.510169\n",
      "time/logging (s)                        0.0127781\n",
      "time/preback_alpha (s)                  0.599012\n",
      "time/preback_policy (s)                 1.03065\n",
      "time/preback_start (s)                  0.184899\n",
      "time/preback_zf (s)                     6.74196\n",
      "time/saving (s)                         3.088e-06\n",
      "time/training (s)                       3.62485\n",
      "time/epoch (s)                         21.4907\n",
      "time/total (s)                       4058.58\n",
      "Epoch                                 196\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:33:28.353190 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 197 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 208000\n",
      "trainer/ZF1 Loss                      350.944\n",
      "trainer/ZF2 Loss                      352.675\n",
      "trainer/ZF Expert Reward               14.7073\n",
      "trainer/ZF Policy Reward                7.72173\n",
      "trainer/ZF CHI2 Term                  346.308\n",
      "trainer/Policy Loss                 -1476.36\n",
      "trainer/Bias Loss                      37.6507\n",
      "trainer/Bias Value                     16.2204\n",
      "trainer/Policy Grad Norm              258.574\n",
      "trainer/Policy Param Norm              52.9159\n",
      "trainer/Zf1 Grad Norm               20000.2\n",
      "trainer/Zf1 Param Norm                140.462\n",
      "trainer/Zf2 Grad Norm               22625.1\n",
      "trainer/Zf2 Param Norm                138.751\n",
      "trainer/Z Expert Predictions Mean    2010.89\n",
      "trainer/Z Expert Predictions Std      157.043\n",
      "trainer/Z Expert Predictions Max     2151.2\n",
      "trainer/Z Expert Predictions Min       28.0253\n",
      "trainer/Z Policy Predictions Mean    1462.95\n",
      "trainer/Z Policy Predictions Std      592.096\n",
      "trainer/Z Policy Predictions Max     2054.18\n",
      "trainer/Z Policy Predictions Min      -28.6049\n",
      "trainer/Z Expert Targets Mean        1996.18\n",
      "trainer/Z Expert Targets Std          159.834\n",
      "trainer/Z Expert Targets Max         2140.42\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1455.22\n",
      "trainer/Z Policy Targets Std          591.703\n",
      "trainer/Z Policy Targets Max         2023.65\n",
      "trainer/Z Policy Targets Min           -8.09207\n",
      "trainer/Log Pis Mean                   56.8509\n",
      "trainer/Log Pis Std                    24.4831\n",
      "trainer/Policy mu Mean                  0.29771\n",
      "trainer/Policy mu Std                   3.02553\n",
      "trainer/Policy log std Mean            -2.9674\n",
      "trainer/Policy log std Std              1.1883\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        204701\n",
      "exploration/num paths total          1353\n",
      "evaluation/num steps total         991954\n",
      "evaluation/num paths total           2023\n",
      "evaluation/path length Mean           613.692\n",
      "evaluation/path length Std            418.932\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            101\n",
      "evaluation/Rewards Mean                 5.25875\n",
      "evaluation/Rewards Std                  0.148933\n",
      "evaluation/Rewards Max                  6.30095\n",
      "evaluation/Rewards Min                  3.69487\n",
      "evaluation/Returns Mean              3227.25\n",
      "evaluation/Returns Std               2229.02\n",
      "evaluation/Returns Max               5295.64\n",
      "evaluation/Returns Min                486.752\n",
      "evaluation/Estimation Bias Mean      1734.44\n",
      "evaluation/Estimation Bias Std        464.593\n",
      "evaluation/EB/Q_True Mean              59.7613\n",
      "evaluation/EB/Q_True Std              162.163\n",
      "evaluation/EB/Q_Pred Mean            1794.2\n",
      "evaluation/EB/Q_Pred Std              339.533\n",
      "evaluation/Num Paths                   13\n",
      "evaluation/Average Returns           3227.25\n",
      "evaluation/Actions Mean                 0.0822994\n",
      "evaluation/Actions Std                  0.531873\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.89283\n",
      "time/backward_zf1 (s)                   2.35577\n",
      "time/backward_zf2 (s)                   2.26492\n",
      "time/data sampling (s)                  0.382743\n",
      "time/data storing (s)                   0.0158701\n",
      "time/evaluation sampling (s)            2.54353\n",
      "time/exploration sampling (s)           0.513803\n",
      "time/logging (s)                        0.0108678\n",
      "time/preback_alpha (s)                  0.595712\n",
      "time/preback_policy (s)                 1.11918\n",
      "time/preback_start (s)                  0.18439\n",
      "time/preback_zf (s)                     6.74769\n",
      "time/saving (s)                         2.992e-06\n",
      "time/training (s)                       3.41087\n",
      "time/epoch (s)                         22.0382\n",
      "time/total (s)                       4080.64\n",
      "Epoch                                 197\n",
      "---------------------------------  --------------\n",
      "2024-07-28 21:33:50.188426 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 198 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 209000\n",
      "trainer/ZF1 Loss                     3327.77\n",
      "trainer/ZF2 Loss                     2762.61\n",
      "trainer/ZF Expert Reward               11.4368\n",
      "trainer/ZF Policy Reward               12.152\n",
      "trainer/ZF CHI2 Term                 3036.5\n",
      "trainer/Policy Loss                 -1467.2\n",
      "trainer/Bias Loss                      51.4462\n",
      "trainer/Bias Value                     16.2019\n",
      "trainer/Policy Grad Norm              325.704\n",
      "trainer/Policy Param Norm              52.9737\n",
      "trainer/Zf1 Grad Norm               33446.7\n",
      "trainer/Zf1 Param Norm                140.802\n",
      "trainer/Zf2 Grad Norm               46236.8\n",
      "trainer/Zf2 Param Norm                139.09\n",
      "trainer/Z Expert Predictions Mean    2016.69\n",
      "trainer/Z Expert Predictions Std       51.1866\n",
      "trainer/Z Expert Predictions Max     2150.29\n",
      "trainer/Z Expert Predictions Min     1890.45\n",
      "trainer/Z Policy Predictions Mean    1456.45\n",
      "trainer/Z Policy Predictions Std      607.449\n",
      "trainer/Z Policy Predictions Max     1989.53\n",
      "trainer/Z Policy Predictions Min      -41.1018\n",
      "trainer/Z Expert Targets Mean        2005.25\n",
      "trainer/Z Expert Targets Std           52.2848\n",
      "trainer/Z Expert Targets Max         2137.19\n",
      "trainer/Z Expert Targets Min         1875.01\n",
      "trainer/Z Policy Targets Mean        1444.3\n",
      "trainer/Z Policy Targets Std          613.372\n",
      "trainer/Z Policy Targets Max         1985.06\n",
      "trainer/Z Policy Targets Min          -68.8409\n",
      "trainer/Log Pis Mean                   59.1143\n",
      "trainer/Log Pis Std                    28.6049\n",
      "trainer/Policy mu Mean                  0.302875\n",
      "trainer/Policy mu Std                   3.94306\n",
      "trainer/Policy log std Mean            -2.9671\n",
      "trainer/Policy log std Std              1.31927\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        204701\n",
      "exploration/num paths total          1353\n",
      "evaluation/num steps total              1.00041e+06\n",
      "evaluation/num paths total           2033\n",
      "evaluation/path length Mean           845.7\n",
      "evaluation/path length Std            311.921\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            127\n",
      "evaluation/Rewards Mean                 5.2877\n",
      "evaluation/Rewards Std                  0.0910868\n",
      "evaluation/Rewards Max                  6.05408\n",
      "evaluation/Rewards Min                  4.65669\n",
      "evaluation/Returns Mean              4471.81\n",
      "evaluation/Returns Std               1656.7\n",
      "evaluation/Returns Max               5302.82\n",
      "evaluation/Returns Min                672.531\n",
      "evaluation/Estimation Bias Mean      1786.43\n",
      "evaluation/Estimation Bias Std        332.996\n",
      "evaluation/EB/Q_True Mean              56.3639\n",
      "evaluation/EB/Q_True Std              158.159\n",
      "evaluation/EB/Q_Pred Mean            1842.8\n",
      "evaluation/EB/Q_Pred Std              231.257\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4471.81\n",
      "evaluation/Actions Mean                 0.093232\n",
      "evaluation/Actions Std                  0.508508\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.98814\n",
      "time/backward_zf1 (s)                   2.4457\n",
      "time/backward_zf2 (s)                   2.36049\n",
      "time/data sampling (s)                  0.38944\n",
      "time/data storing (s)                   0.0150157\n",
      "time/evaluation sampling (s)            2.37357\n",
      "time/exploration sampling (s)           0.486034\n",
      "time/logging (s)                        0.0120565\n",
      "time/preback_alpha (s)                  0.590644\n",
      "time/preback_policy (s)                 1.21241\n",
      "time/preback_start (s)                  0.179637\n",
      "time/preback_zf (s)                     6.69692\n",
      "time/saving (s)                         2.994e-06\n",
      "time/training (s)                       3.0164\n",
      "time/epoch (s)                         21.7665\n",
      "time/total (s)                       4102.43\n",
      "Epoch                                 198\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:34:12.199020 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 199 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 210000\n",
      "trainer/ZF1 Loss                      436.758\n",
      "trainer/ZF2 Loss                      443.766\n",
      "trainer/ZF Expert Reward               19.6856\n",
      "trainer/ZF Policy Reward               14.3442\n",
      "trainer/ZF CHI2 Term                  439.689\n",
      "trainer/Policy Loss                 -1436.57\n",
      "trainer/Bias Loss                      58.4526\n",
      "trainer/Bias Value                     16.1821\n",
      "trainer/Policy Grad Norm              230.215\n",
      "trainer/Policy Param Norm              53.0406\n",
      "trainer/Zf1 Grad Norm               23707.1\n",
      "trainer/Zf1 Param Norm                141.173\n",
      "trainer/Zf2 Grad Norm               21978.9\n",
      "trainer/Zf2 Param Norm                139.441\n",
      "trainer/Z Expert Predictions Mean    2025.65\n",
      "trainer/Z Expert Predictions Std       58.3457\n",
      "trainer/Z Expert Predictions Max     2161.65\n",
      "trainer/Z Expert Predictions Min     1858.3\n",
      "trainer/Z Policy Predictions Mean    1424.53\n",
      "trainer/Z Policy Predictions Std      638.634\n",
      "trainer/Z Policy Predictions Max     2018.41\n",
      "trainer/Z Policy Predictions Min      -26.8681\n",
      "trainer/Z Expert Targets Mean        2005.97\n",
      "trainer/Z Expert Targets Std           60.121\n",
      "trainer/Z Expert Targets Max         2135.45\n",
      "trainer/Z Expert Targets Min         1832.82\n",
      "trainer/Z Policy Targets Mean        1410.19\n",
      "trainer/Z Policy Targets Std          630.804\n",
      "trainer/Z Policy Targets Max         1987.78\n",
      "trainer/Z Policy Targets Min          -17.9442\n",
      "trainer/Log Pis Mean                   59.576\n",
      "trainer/Log Pis Std                    25.3392\n",
      "trainer/Policy mu Mean                  0.385518\n",
      "trainer/Policy mu Std                   3.69089\n",
      "trainer/Policy log std Mean            -2.9097\n",
      "trainer/Policy log std Std              1.33405\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        205701\n",
      "exploration/num paths total          1354\n",
      "evaluation/num steps total              1.01041e+06\n",
      "evaluation/num paths total           2043\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30714\n",
      "evaluation/Rewards Std                  0.0795927\n",
      "evaluation/Rewards Max                  5.49401\n",
      "evaluation/Rewards Min                  4.7984\n",
      "evaluation/Returns Mean              5307.14\n",
      "evaluation/Returns Std                  5.49906\n",
      "evaluation/Returns Max               5316.48\n",
      "evaluation/Returns Min               5295.8\n",
      "evaluation/Estimation Bias Mean      1856.53\n",
      "evaluation/Estimation Bias Std        175.411\n",
      "evaluation/EB/Q_True Mean              47.9309\n",
      "evaluation/EB/Q_True Std              147.599\n",
      "evaluation/EB/Q_Pred Mean            1904.46\n",
      "evaluation/EB/Q_Pred Std               90.7404\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5307.14\n",
      "evaluation/Actions Mean                 0.0774894\n",
      "evaluation/Actions Std                  0.504185\n",
      "evaluation/Actions Max                  0.999953\n",
      "evaluation/Actions Min                 -0.997103\n",
      "time/backward_policy (s)                1.98026\n",
      "time/backward_zf1 (s)                   2.41219\n",
      "time/backward_zf2 (s)                   2.3252\n",
      "time/data sampling (s)                  0.399263\n",
      "time/data storing (s)                   0.0154637\n",
      "time/evaluation sampling (s)            2.48901\n",
      "time/exploration sampling (s)           0.500343\n",
      "time/logging (s)                        0.0133233\n",
      "time/preback_alpha (s)                  0.595714\n",
      "time/preback_policy (s)                 1.18383\n",
      "time/preback_start (s)                  0.181491\n",
      "time/preback_zf (s)                     6.72323\n",
      "time/saving (s)                         3.375e-06\n",
      "time/training (s)                       3.12202\n",
      "time/epoch (s)                         21.9413\n",
      "time/total (s)                       4124.39\n",
      "Epoch                                 199\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:34:33.824923 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 200 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 211000\n",
      "trainer/ZF1 Loss                      356.523\n",
      "trainer/ZF2 Loss                      306.936\n",
      "trainer/ZF Expert Reward               15.055\n",
      "trainer/ZF Policy Reward                5.16834\n",
      "trainer/ZF CHI2 Term                  326.659\n",
      "trainer/Policy Loss                 -1350.98\n",
      "trainer/Bias Loss                      33.1492\n",
      "trainer/Bias Value                     16.1592\n",
      "trainer/Policy Grad Norm              205.833\n",
      "trainer/Policy Param Norm              53.1078\n",
      "trainer/Zf1 Grad Norm               20446.9\n",
      "trainer/Zf1 Param Norm                141.516\n",
      "trainer/Zf2 Grad Norm               17353.3\n",
      "trainer/Zf2 Param Norm                139.782\n",
      "trainer/Z Expert Predictions Mean    2007.28\n",
      "trainer/Z Expert Predictions Std      140.882\n",
      "trainer/Z Expert Predictions Max     2158.46\n",
      "trainer/Z Expert Predictions Min       19.3831\n",
      "trainer/Z Policy Predictions Mean    1337.99\n",
      "trainer/Z Policy Predictions Std      674.113\n",
      "trainer/Z Policy Predictions Max     2013.69\n",
      "trainer/Z Policy Predictions Min      -30.8321\n",
      "trainer/Z Expert Targets Mean        1992.23\n",
      "trainer/Z Expert Targets Std          142.147\n",
      "trainer/Z Expert Targets Max         2136.87\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1332.82\n",
      "trainer/Z Policy Targets Std          674.754\n",
      "trainer/Z Policy Targets Max         2029.73\n",
      "trainer/Z Policy Targets Min          -29.0251\n",
      "trainer/Log Pis Mean                   64.2254\n",
      "trainer/Log Pis Std                    30.7544\n",
      "trainer/Policy mu Mean                  0.50404\n",
      "trainer/Policy mu Std                   4.19956\n",
      "trainer/Policy log std Mean            -2.80107\n",
      "trainer/Policy log std Std              1.39649\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        206701\n",
      "exploration/num paths total          1355\n",
      "evaluation/num steps total              1.01962e+06\n",
      "evaluation/num paths total           2053\n",
      "evaluation/path length Mean           920.6\n",
      "evaluation/path length Std            238.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            206\n",
      "evaluation/Rewards Mean                 5.32286\n",
      "evaluation/Rewards Std                  0.090662\n",
      "evaluation/Rewards Max                  6.23392\n",
      "evaluation/Rewards Min                  4.80205\n",
      "evaluation/Returns Mean              4900.22\n",
      "evaluation/Returns Std               1267.68\n",
      "evaluation/Returns Max               5329.2\n",
      "evaluation/Returns Min               1097.22\n",
      "evaluation/Estimation Bias Mean      1803.99\n",
      "evaluation/Estimation Bias Std        248.879\n",
      "evaluation/EB/Q_True Mean              52.1665\n",
      "evaluation/EB/Q_True Std              153.469\n",
      "evaluation/EB/Q_Pred Mean            1856.16\n",
      "evaluation/EB/Q_Pred Std              165.727\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4900.22\n",
      "evaluation/Actions Mean                 0.0631335\n",
      "evaluation/Actions Std                  0.511341\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.78661\n",
      "time/backward_zf1 (s)                   2.23316\n",
      "time/backward_zf2 (s)                   2.14061\n",
      "time/data sampling (s)                  0.380699\n",
      "time/data storing (s)                   0.015152\n",
      "time/evaluation sampling (s)            2.35441\n",
      "time/exploration sampling (s)           0.490741\n",
      "time/logging (s)                        0.0125078\n",
      "time/preback_alpha (s)                  0.590156\n",
      "time/preback_policy (s)                 1.0159\n",
      "time/preback_start (s)                  0.179306\n",
      "time/preback_zf (s)                     6.70683\n",
      "time/saving (s)                         3.257e-06\n",
      "time/training (s)                       3.64652\n",
      "time/epoch (s)                         21.5526\n",
      "time/total (s)                       4145.97\n",
      "Epoch                                 200\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:34:56.127168 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 201 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 212000\n",
      "trainer/ZF1 Loss                      462.457\n",
      "trainer/ZF2 Loss                      432.185\n",
      "trainer/ZF Expert Reward               15.9391\n",
      "trainer/ZF Policy Reward                0.419911\n",
      "trainer/ZF CHI2 Term                  443.104\n",
      "trainer/Policy Loss                 -1421.09\n",
      "trainer/Bias Loss                      52.3849\n",
      "trainer/Bias Value                     16.1423\n",
      "trainer/Policy Grad Norm              237.424\n",
      "trainer/Policy Param Norm              53.1733\n",
      "trainer/Zf1 Grad Norm               25615.8\n",
      "trainer/Zf1 Param Norm                141.846\n",
      "trainer/Zf2 Grad Norm               19234\n",
      "trainer/Zf2 Param Norm                140.12\n",
      "trainer/Z Expert Predictions Mean    2009.81\n",
      "trainer/Z Expert Predictions Std      150.273\n",
      "trainer/Z Expert Predictions Max     2156.48\n",
      "trainer/Z Expert Predictions Min       -3.26629\n",
      "trainer/Z Policy Predictions Mean    1408.14\n",
      "trainer/Z Policy Predictions Std      637.162\n",
      "trainer/Z Policy Predictions Max     2007.19\n",
      "trainer/Z Policy Predictions Min       -5.72875\n",
      "trainer/Z Expert Targets Mean        1993.87\n",
      "trainer/Z Expert Targets Std          148.967\n",
      "trainer/Z Expert Targets Max         2137.61\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1407.72\n",
      "trainer/Z Policy Targets Std          634.757\n",
      "trainer/Z Policy Targets Max         2035.19\n",
      "trainer/Z Policy Targets Min          -11.7759\n",
      "trainer/Log Pis Mean                   61.2147\n",
      "trainer/Log Pis Std                    27.1557\n",
      "trainer/Policy mu Mean                  0.333269\n",
      "trainer/Policy mu Std                   3.87847\n",
      "trainer/Policy log std Mean            -2.8948\n",
      "trainer/Policy log std Std              1.38594\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        206847\n",
      "exploration/num paths total          1356\n",
      "evaluation/num steps total              1.02962e+06\n",
      "evaluation/num paths total           2063\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33658\n",
      "evaluation/Rewards Std                  0.0869457\n",
      "evaluation/Rewards Max                  5.53899\n",
      "evaluation/Rewards Min                  4.72986\n",
      "evaluation/Returns Mean              5336.58\n",
      "evaluation/Returns Std                  6.2173\n",
      "evaluation/Returns Max               5345.98\n",
      "evaluation/Returns Min               5326.94\n",
      "evaluation/Estimation Bias Mean      1851.06\n",
      "evaluation/Estimation Bias Std        173.372\n",
      "evaluation/EB/Q_True Mean              48.1233\n",
      "evaluation/EB/Q_True Std              148.202\n",
      "evaluation/EB/Q_Pred Mean            1899.18\n",
      "evaluation/EB/Q_Pred Std               92.7277\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5336.58\n",
      "evaluation/Actions Mean                 0.0762426\n",
      "evaluation/Actions Std                  0.526738\n",
      "evaluation/Actions Max                  0.999906\n",
      "evaluation/Actions Min                 -0.999925\n",
      "time/backward_policy (s)                1.92452\n",
      "time/backward_zf1 (s)                   2.43625\n",
      "time/backward_zf2 (s)                   2.32112\n",
      "time/data sampling (s)                  0.395129\n",
      "time/data storing (s)                   0.0157508\n",
      "time/evaluation sampling (s)            2.48797\n",
      "time/exploration sampling (s)           0.490595\n",
      "time/logging (s)                        0.0137201\n",
      "time/preback_alpha (s)                  0.609814\n",
      "time/preback_policy (s)                 1.1308\n",
      "time/preback_start (s)                  0.184541\n",
      "time/preback_zf (s)                     6.83055\n",
      "time/saving (s)                         3.897e-06\n",
      "time/training (s)                       3.38857\n",
      "time/epoch (s)                         22.2293\n",
      "time/total (s)                       4168.22\n",
      "Epoch                                 201\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:35:18.175490 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 202 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 213000\n",
      "trainer/ZF1 Loss                     2681.35\n",
      "trainer/ZF2 Loss                     2014.51\n",
      "trainer/ZF Expert Reward               20.8226\n",
      "trainer/ZF Policy Reward               13.7742\n",
      "trainer/ZF CHI2 Term                 2348.67\n",
      "trainer/Policy Loss                 -1384.29\n",
      "trainer/Bias Loss                      42.0082\n",
      "trainer/Bias Value                     16.1266\n",
      "trainer/Policy Grad Norm              225.824\n",
      "trainer/Policy Param Norm              53.2369\n",
      "trainer/Zf1 Grad Norm               53018.6\n",
      "trainer/Zf1 Param Norm                142.149\n",
      "trainer/Zf2 Grad Norm               63031.8\n",
      "trainer/Zf2 Param Norm                140.449\n",
      "trainer/Z Expert Predictions Mean    2010.49\n",
      "trainer/Z Expert Predictions Std       64.8814\n",
      "trainer/Z Expert Predictions Max     2154.86\n",
      "trainer/Z Expert Predictions Min     1848.64\n",
      "trainer/Z Policy Predictions Mean    1375.98\n",
      "trainer/Z Policy Predictions Std      658.798\n",
      "trainer/Z Policy Predictions Max     1982.87\n",
      "trainer/Z Policy Predictions Min       -7.55663\n",
      "trainer/Z Expert Targets Mean        1989.66\n",
      "trainer/Z Expert Targets Std           64.3985\n",
      "trainer/Z Expert Targets Max         2133.39\n",
      "trainer/Z Expert Targets Min         1830.88\n",
      "trainer/Z Policy Targets Mean        1362.21\n",
      "trainer/Z Policy Targets Std          661.75\n",
      "trainer/Z Policy Targets Max         2004.42\n",
      "trainer/Z Policy Targets Min          -16.2716\n",
      "trainer/Log Pis Mean                   60.7291\n",
      "trainer/Log Pis Std                    25.2787\n",
      "trainer/Policy mu Mean                  0.365634\n",
      "trainer/Policy mu Std                   3.3098\n",
      "trainer/Policy log std Mean            -2.93701\n",
      "trainer/Policy log std Std              1.34863\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        207847\n",
      "exploration/num paths total          1357\n",
      "evaluation/num steps total              1.03806e+06\n",
      "evaluation/num paths total           2075\n",
      "evaluation/path length Mean           703.167\n",
      "evaluation/path length Std            378.168\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            144\n",
      "evaluation/Rewards Mean                 5.31834\n",
      "evaluation/Rewards Std                  0.117193\n",
      "evaluation/Rewards Max                  6.56808\n",
      "evaluation/Rewards Min                  4.57322\n",
      "evaluation/Returns Mean              3739.68\n",
      "evaluation/Returns Std               2026.47\n",
      "evaluation/Returns Max               5331.97\n",
      "evaluation/Returns Min                736.147\n",
      "evaluation/Estimation Bias Mean      1743.76\n",
      "evaluation/Estimation Bias Std        411.919\n",
      "evaluation/EB/Q_True Mean              57.0516\n",
      "evaluation/EB/Q_True Std              159.82\n",
      "evaluation/EB/Q_Pred Mean            1800.81\n",
      "evaluation/EB/Q_Pred Std              300.032\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3739.68\n",
      "evaluation/Actions Mean                 0.0620632\n",
      "evaluation/Actions Std                  0.546451\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.01217\n",
      "time/backward_zf1 (s)                   2.47958\n",
      "time/backward_zf2 (s)                   2.4068\n",
      "time/data sampling (s)                  0.394421\n",
      "time/data storing (s)                   0.0169088\n",
      "time/evaluation sampling (s)            2.37155\n",
      "time/exploration sampling (s)           0.514244\n",
      "time/logging (s)                        0.0118588\n",
      "time/preback_alpha (s)                  0.599423\n",
      "time/preback_policy (s)                 1.2023\n",
      "time/preback_start (s)                  0.194575\n",
      "time/preback_zf (s)                     6.72695\n",
      "time/saving (s)                         2.92699e-06\n",
      "time/training (s)                       3.04567\n",
      "time/epoch (s)                         21.9764\n",
      "time/total (s)                       4190.22\n",
      "Epoch                                 202\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:35:39.894113 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 203 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 214000\n",
      "trainer/ZF1 Loss                      300.21\n",
      "trainer/ZF2 Loss                      390.441\n",
      "trainer/ZF Expert Reward               18.5048\n",
      "trainer/ZF Policy Reward                5.00821\n",
      "trainer/ZF CHI2 Term                  343.775\n",
      "trainer/Policy Loss                 -1417.22\n",
      "trainer/Bias Loss                      56.2552\n",
      "trainer/Bias Value                     16.1076\n",
      "trainer/Policy Grad Norm              334.37\n",
      "trainer/Policy Param Norm              53.3104\n",
      "trainer/Zf1 Grad Norm               20168.4\n",
      "trainer/Zf1 Param Norm                142.491\n",
      "trainer/Zf2 Grad Norm               18943.2\n",
      "trainer/Zf2 Param Norm                140.795\n",
      "trainer/Z Expert Predictions Mean    2008.03\n",
      "trainer/Z Expert Predictions Std       66.0956\n",
      "trainer/Z Expert Predictions Max     2154.74\n",
      "trainer/Z Expert Predictions Min     1841.25\n",
      "trainer/Z Policy Predictions Mean    1405.06\n",
      "trainer/Z Policy Predictions Std      608.916\n",
      "trainer/Z Policy Predictions Max     1987.66\n",
      "trainer/Z Policy Predictions Min       -9.64801\n",
      "trainer/Z Expert Targets Mean        1989.53\n",
      "trainer/Z Expert Targets Std           67.2111\n",
      "trainer/Z Expert Targets Max         2140\n",
      "trainer/Z Expert Targets Min         1825.92\n",
      "trainer/Z Policy Targets Mean        1400.05\n",
      "trainer/Z Policy Targets Std          608.23\n",
      "trainer/Z Policy Targets Max         1981.42\n",
      "trainer/Z Policy Targets Min          -12.8825\n",
      "trainer/Log Pis Mean                   59.5384\n",
      "trainer/Log Pis Std                    26.8221\n",
      "trainer/Policy mu Mean                  0.331225\n",
      "trainer/Policy mu Std                   3.72424\n",
      "trainer/Policy log std Mean            -2.90307\n",
      "trainer/Policy log std Std              1.37272\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        208847\n",
      "exploration/num paths total          1358\n",
      "evaluation/num steps total              1.04716e+06\n",
      "evaluation/num paths total           2085\n",
      "evaluation/path length Mean           910.1\n",
      "evaluation/path length Std            269.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            101\n",
      "evaluation/Rewards Mean                 5.33555\n",
      "evaluation/Rewards Std                  0.10613\n",
      "evaluation/Rewards Max                  5.63484\n",
      "evaluation/Rewards Min                  3.79369\n",
      "evaluation/Returns Mean              4855.88\n",
      "evaluation/Returns Std               1454.34\n",
      "evaluation/Returns Max               5357.01\n",
      "evaluation/Returns Min                492.955\n",
      "evaluation/Estimation Bias Mean      1760.02\n",
      "evaluation/Estimation Bias Std        222.086\n",
      "evaluation/EB/Q_True Mean              52.9951\n",
      "evaluation/EB/Q_True Std              154.908\n",
      "evaluation/EB/Q_Pred Mean            1813.01\n",
      "evaluation/EB/Q_Pred Std              141.747\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4855.88\n",
      "evaluation/Actions Mean                 0.0749684\n",
      "evaluation/Actions Std                  0.54182\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.79181\n",
      "time/backward_zf1 (s)                   2.24981\n",
      "time/backward_zf2 (s)                   2.13014\n",
      "time/data sampling (s)                  0.396033\n",
      "time/data storing (s)                   0.0157227\n",
      "time/evaluation sampling (s)            2.40688\n",
      "time/exploration sampling (s)           0.504331\n",
      "time/logging (s)                        0.0121737\n",
      "time/preback_alpha (s)                  0.587963\n",
      "time/preback_policy (s)                 1.02956\n",
      "time/preback_start (s)                  0.181011\n",
      "time/preback_zf (s)                     6.68749\n",
      "time/saving (s)                         3.312e-06\n",
      "time/training (s)                       3.65766\n",
      "time/epoch (s)                         21.6506\n",
      "time/total (s)                       4211.89\n",
      "Epoch                                 203\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:36:01.966639 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 204 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 215000\n",
      "trainer/ZF1 Loss                      365.303\n",
      "trainer/ZF2 Loss                      358.817\n",
      "trainer/ZF Expert Reward               16.1326\n",
      "trainer/ZF Policy Reward                6.10413\n",
      "trainer/ZF CHI2 Term                  358.19\n",
      "trainer/Policy Loss                 -1458.44\n",
      "trainer/Bias Loss                      37.8078\n",
      "trainer/Bias Value                     16.0925\n",
      "trainer/Policy Grad Norm              242.601\n",
      "trainer/Policy Param Norm              53.3815\n",
      "trainer/Zf1 Grad Norm               19568.5\n",
      "trainer/Zf1 Param Norm                142.842\n",
      "trainer/Zf2 Grad Norm               18880\n",
      "trainer/Zf2 Param Norm                141.16\n",
      "trainer/Z Expert Predictions Mean    2001.52\n",
      "trainer/Z Expert Predictions Std       69.0918\n",
      "trainer/Z Expert Predictions Max     2130.61\n",
      "trainer/Z Expert Predictions Min     1782.57\n",
      "trainer/Z Policy Predictions Mean    1448.55\n",
      "trainer/Z Policy Predictions Std      586.274\n",
      "trainer/Z Policy Predictions Max     1987.08\n",
      "trainer/Z Policy Predictions Min      -11.9394\n",
      "trainer/Z Expert Targets Mean        1985.38\n",
      "trainer/Z Expert Targets Std           70.4463\n",
      "trainer/Z Expert Targets Max         2129.59\n",
      "trainer/Z Expert Targets Min         1772.81\n",
      "trainer/Z Policy Targets Mean        1442.45\n",
      "trainer/Z Policy Targets Std          586.947\n",
      "trainer/Z Policy Targets Max         1968.52\n",
      "trainer/Z Policy Targets Min          -10.6584\n",
      "trainer/Log Pis Mean                   58.2815\n",
      "trainer/Log Pis Std                    26.9033\n",
      "trainer/Policy mu Mean                  0.364462\n",
      "trainer/Policy mu Std                   3.06478\n",
      "trainer/Policy log std Mean            -3.03066\n",
      "trainer/Policy log std Std              1.19984\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        209847\n",
      "exploration/num paths total          1359\n",
      "evaluation/num steps total              1.05467e+06\n",
      "evaluation/num paths total           2095\n",
      "evaluation/path length Mean           751.8\n",
      "evaluation/path length Std            333.919\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            135\n",
      "evaluation/Rewards Mean                 5.29701\n",
      "evaluation/Rewards Std                  0.141168\n",
      "evaluation/Rewards Max                  6.02048\n",
      "evaluation/Rewards Min                  3.49639\n",
      "evaluation/Returns Mean              3982.29\n",
      "evaluation/Returns Std               1793.02\n",
      "evaluation/Returns Max               5331.39\n",
      "evaluation/Returns Min                713.225\n",
      "evaluation/Estimation Bias Mean      1729.75\n",
      "evaluation/Estimation Bias Std        373.477\n",
      "evaluation/EB/Q_True Mean              63.7534\n",
      "evaluation/EB/Q_True Std              167.233\n",
      "evaluation/EB/Q_Pred Mean            1793.51\n",
      "evaluation/EB/Q_Pred Std              277.999\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3982.29\n",
      "evaluation/Actions Mean                 0.0741378\n",
      "evaluation/Actions Std                  0.515355\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.00402\n",
      "time/backward_zf1 (s)                   2.46727\n",
      "time/backward_zf2 (s)                   2.39877\n",
      "time/data sampling (s)                  0.401563\n",
      "time/data storing (s)                   0.0149744\n",
      "time/evaluation sampling (s)            2.38443\n",
      "time/exploration sampling (s)           0.492293\n",
      "time/logging (s)                        0.0109783\n",
      "time/preback_alpha (s)                  0.599944\n",
      "time/preback_policy (s)                 1.20747\n",
      "time/preback_start (s)                  0.183594\n",
      "time/preback_zf (s)                     6.77248\n",
      "time/saving (s)                         3.256e-06\n",
      "time/training (s)                       3.05922\n",
      "time/epoch (s)                         21.997\n",
      "time/total (s)                       4233.91\n",
      "Epoch                                 204\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:36:23.704131 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 205 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 216000\n",
      "trainer/ZF1 Loss                      355.056\n",
      "trainer/ZF2 Loss                      355.846\n",
      "trainer/ZF Expert Reward               17.321\n",
      "trainer/ZF Policy Reward               12.9449\n",
      "trainer/ZF CHI2 Term                  352.755\n",
      "trainer/Policy Loss                 -1448.99\n",
      "trainer/Bias Loss                      48.2956\n",
      "trainer/Bias Value                     16.0748\n",
      "trainer/Policy Grad Norm              270.882\n",
      "trainer/Policy Param Norm              53.4512\n",
      "trainer/Zf1 Grad Norm               27810.4\n",
      "trainer/Zf1 Param Norm                143.156\n",
      "trainer/Zf2 Grad Norm               18596.5\n",
      "trainer/Zf2 Param Norm                141.483\n",
      "trainer/Z Expert Predictions Mean    2001.76\n",
      "trainer/Z Expert Predictions Std       69.3724\n",
      "trainer/Z Expert Predictions Max     2135.77\n",
      "trainer/Z Expert Predictions Min     1816.06\n",
      "trainer/Z Policy Predictions Mean    1429.74\n",
      "trainer/Z Policy Predictions Std      568.643\n",
      "trainer/Z Policy Predictions Max     2015.77\n",
      "trainer/Z Policy Predictions Min      -35.7755\n",
      "trainer/Z Expert Targets Mean        1984.44\n",
      "trainer/Z Expert Targets Std           70.8462\n",
      "trainer/Z Expert Targets Max         2118.37\n",
      "trainer/Z Expert Targets Min         1787.69\n",
      "trainer/Z Policy Targets Mean        1416.8\n",
      "trainer/Z Policy Targets Std          567.077\n",
      "trainer/Z Policy Targets Max         1976.85\n",
      "trainer/Z Policy Targets Min          -39.6233\n",
      "trainer/Log Pis Mean                   56.9277\n",
      "trainer/Log Pis Std                    24.45\n",
      "trainer/Policy mu Mean                  0.367586\n",
      "trainer/Policy mu Std                   3.02452\n",
      "trainer/Policy log std Mean            -3.00056\n",
      "trainer/Policy log std Std              1.1328\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        209847\n",
      "exploration/num paths total          1359\n",
      "evaluation/num steps total              1.06365e+06\n",
      "evaluation/num paths total           2105\n",
      "evaluation/path length Mean           897.2\n",
      "evaluation/path length Std            263.356\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            118\n",
      "evaluation/Rewards Mean                 5.33488\n",
      "evaluation/Rewards Std                  0.0968293\n",
      "evaluation/Rewards Max                  6.27024\n",
      "evaluation/Rewards Min                  4.32468\n",
      "evaluation/Returns Mean              4786.46\n",
      "evaluation/Returns Std               1418.04\n",
      "evaluation/Returns Max               5344.98\n",
      "evaluation/Returns Min                589.078\n",
      "evaluation/Estimation Bias Mean      1812.2\n",
      "evaluation/Estimation Bias Std        308.019\n",
      "evaluation/EB/Q_True Mean              53.6493\n",
      "evaluation/EB/Q_True Std              155.531\n",
      "evaluation/EB/Q_Pred Mean            1865.85\n",
      "evaluation/EB/Q_Pred Std              223.12\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4786.46\n",
      "evaluation/Actions Mean                 0.0668952\n",
      "evaluation/Actions Std                  0.506945\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.93561\n",
      "time/backward_zf1 (s)                   2.39267\n",
      "time/backward_zf2 (s)                   2.33471\n",
      "time/data sampling (s)                  0.40615\n",
      "time/data storing (s)                   0.0154525\n",
      "time/evaluation sampling (s)            2.32533\n",
      "time/exploration sampling (s)           0.505003\n",
      "time/logging (s)                        0.0127869\n",
      "time/preback_alpha (s)                  0.594227\n",
      "time/preback_policy (s)                 1.19908\n",
      "time/preback_start (s)                  0.179247\n",
      "time/preback_zf (s)                     6.6989\n",
      "time/saving (s)                         3.406e-06\n",
      "time/training (s)                       3.06768\n",
      "time/epoch (s)                         21.6668\n",
      "time/total (s)                       4255.6\n",
      "Epoch                                 205\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:36:45.984089 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 206 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 217000\n",
      "trainer/ZF1 Loss                     3528.17\n",
      "trainer/ZF2 Loss                     3323.2\n",
      "trainer/ZF Expert Reward               16.5568\n",
      "trainer/ZF Policy Reward               20.1085\n",
      "trainer/ZF CHI2 Term                 3422.29\n",
      "trainer/Policy Loss                 -1529.37\n",
      "trainer/Bias Loss                      33.7337\n",
      "trainer/Bias Value                     16.0585\n",
      "trainer/Policy Grad Norm              249.083\n",
      "trainer/Policy Param Norm              53.5186\n",
      "trainer/Zf1 Grad Norm               33567\n",
      "trainer/Zf1 Param Norm                143.475\n",
      "trainer/Zf2 Grad Norm               32739.5\n",
      "trainer/Zf2 Param Norm                141.788\n",
      "trainer/Z Expert Predictions Mean    1995.87\n",
      "trainer/Z Expert Predictions Std       69.2691\n",
      "trainer/Z Expert Predictions Max     2127.29\n",
      "trainer/Z Expert Predictions Min     1791.37\n",
      "trainer/Z Policy Predictions Mean    1523.98\n",
      "trainer/Z Policy Predictions Std      541.705\n",
      "trainer/Z Policy Predictions Max     1983.61\n",
      "trainer/Z Policy Predictions Min       15.7188\n",
      "trainer/Z Expert Targets Mean        1979.31\n",
      "trainer/Z Expert Targets Std           70.4869\n",
      "trainer/Z Expert Targets Max         2110.67\n",
      "trainer/Z Expert Targets Min         1770.94\n",
      "trainer/Z Policy Targets Mean        1503.87\n",
      "trainer/Z Policy Targets Std          549.587\n",
      "trainer/Z Policy Targets Max         1971.12\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   54.3915\n",
      "trainer/Log Pis Std                    22.2818\n",
      "trainer/Policy mu Mean                  0.378126\n",
      "trainer/Policy mu Std                   2.6109\n",
      "trainer/Policy log std Mean            -3.16912\n",
      "trainer/Policy log std Std              1.13304\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        210847\n",
      "exploration/num paths total          1360\n",
      "evaluation/num steps total              1.07365e+06\n",
      "evaluation/num paths total           2115\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.32599\n",
      "evaluation/Rewards Std                  0.0831893\n",
      "evaluation/Rewards Max                  5.50021\n",
      "evaluation/Rewards Min                  4.81268\n",
      "evaluation/Returns Mean              5325.99\n",
      "evaluation/Returns Std                  3.30226\n",
      "evaluation/Returns Max               5330.45\n",
      "evaluation/Returns Min               5318.95\n",
      "evaluation/Estimation Bias Mean      1862.74\n",
      "evaluation/Estimation Bias Std        169.3\n",
      "evaluation/EB/Q_True Mean              48.1551\n",
      "evaluation/EB/Q_True Std              148.306\n",
      "evaluation/EB/Q_Pred Mean            1910.9\n",
      "evaluation/EB/Q_Pred Std               79.6018\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5325.99\n",
      "evaluation/Actions Mean                 0.0822264\n",
      "evaluation/Actions Std                  0.511145\n",
      "evaluation/Actions Max                  0.999916\n",
      "evaluation/Actions Min                 -0.997651\n",
      "time/backward_policy (s)                2.03918\n",
      "time/backward_zf1 (s)                   2.49502\n",
      "time/backward_zf2 (s)                   2.45094\n",
      "time/data sampling (s)                  0.412328\n",
      "time/data storing (s)                   0.015665\n",
      "time/evaluation sampling (s)            2.53359\n",
      "time/exploration sampling (s)           0.51217\n",
      "time/logging (s)                        0.0140625\n",
      "time/preback_alpha (s)                  0.602984\n",
      "time/preback_policy (s)                 1.21683\n",
      "time/preback_start (s)                  0.182775\n",
      "time/preback_zf (s)                     6.72423\n",
      "time/saving (s)                         3.021e-06\n",
      "time/training (s)                       3.00638\n",
      "time/epoch (s)                         22.2062\n",
      "time/total (s)                       4277.84\n",
      "Epoch                                 206\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:37:08.037260 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 207 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 218000\n",
      "trainer/ZF1 Loss                      464.454\n",
      "trainer/ZF2 Loss                      374.503\n",
      "trainer/ZF Expert Reward               16.3641\n",
      "trainer/ZF Policy Reward                8.77196\n",
      "trainer/ZF CHI2 Term                  416.025\n",
      "trainer/Policy Loss                 -1368.85\n",
      "trainer/Bias Loss                      37.649\n",
      "trainer/Bias Value                     16.0447\n",
      "trainer/Policy Grad Norm              291.245\n",
      "trainer/Policy Param Norm              53.5886\n",
      "trainer/Zf1 Grad Norm               26928.1\n",
      "trainer/Zf1 Param Norm                143.788\n",
      "trainer/Zf2 Grad Norm               24859.4\n",
      "trainer/Zf2 Param Norm                142.091\n",
      "trainer/Z Expert Predictions Mean    1983.66\n",
      "trainer/Z Expert Predictions Std       69.2973\n",
      "trainer/Z Expert Predictions Max     2111.87\n",
      "trainer/Z Expert Predictions Min     1519.09\n",
      "trainer/Z Policy Predictions Mean    1362.52\n",
      "trainer/Z Policy Predictions Std      647.003\n",
      "trainer/Z Policy Predictions Max     1978.81\n",
      "trainer/Z Policy Predictions Min      -36.8736\n",
      "trainer/Z Expert Targets Mean        1967.3\n",
      "trainer/Z Expert Targets Std           70.3785\n",
      "trainer/Z Expert Targets Max         2093.22\n",
      "trainer/Z Expert Targets Min         1507.81\n",
      "trainer/Z Policy Targets Mean        1353.75\n",
      "trainer/Z Policy Targets Std          647.439\n",
      "trainer/Z Policy Targets Max         1977.76\n",
      "trainer/Z Policy Targets Min          -38.6264\n",
      "trainer/Log Pis Mean                   60.7496\n",
      "trainer/Log Pis Std                    29.1749\n",
      "trainer/Policy mu Mean                  0.352049\n",
      "trainer/Policy mu Std                   3.95859\n",
      "trainer/Policy log std Mean            -2.85397\n",
      "trainer/Policy log std Std              1.35145\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        214847\n",
      "exploration/num paths total          1364\n",
      "evaluation/num steps total              1.0821e+06\n",
      "evaluation/num paths total           2126\n",
      "evaluation/path length Mean           768.909\n",
      "evaluation/path length Std            377.985\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            107\n",
      "evaluation/Rewards Mean                 5.31888\n",
      "evaluation/Rewards Std                  0.0976321\n",
      "evaluation/Rewards Max                  6.18697\n",
      "evaluation/Rewards Min                  4.81017\n",
      "evaluation/Returns Mean              4089.73\n",
      "evaluation/Returns Std               2020.8\n",
      "evaluation/Returns Max               5331.43\n",
      "evaluation/Returns Min                550.636\n",
      "evaluation/Estimation Bias Mean      1789.05\n",
      "evaluation/Estimation Bias Std        349.315\n",
      "evaluation/EB/Q_True Mean              56.8558\n",
      "evaluation/EB/Q_True Std              159.492\n",
      "evaluation/EB/Q_Pred Mean            1845.9\n",
      "evaluation/EB/Q_Pred Std              238.477\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4089.73\n",
      "evaluation/Actions Mean                 0.0843413\n",
      "evaluation/Actions Std                  0.522928\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.8992\n",
      "time/backward_zf1 (s)                   2.38037\n",
      "time/backward_zf2 (s)                   2.25601\n",
      "time/data sampling (s)                  0.407235\n",
      "time/data storing (s)                   0.0153727\n",
      "time/evaluation sampling (s)            2.41097\n",
      "time/exploration sampling (s)           0.512375\n",
      "time/logging (s)                        0.0115827\n",
      "time/preback_alpha (s)                  0.603228\n",
      "time/preback_policy (s)                 1.07466\n",
      "time/preback_start (s)                  0.189992\n",
      "time/preback_zf (s)                     6.75637\n",
      "time/saving (s)                         3.36301e-06\n",
      "time/training (s)                       3.46036\n",
      "time/epoch (s)                         21.9777\n",
      "time/total (s)                       4299.84\n",
      "Epoch                                 207\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:37:29.880257 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 208 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 219000\n",
      "trainer/ZF1 Loss                      313.924\n",
      "trainer/ZF2 Loss                      378.887\n",
      "trainer/ZF Expert Reward               16.6109\n",
      "trainer/ZF Policy Reward                8.59989\n",
      "trainer/ZF CHI2 Term                  343.14\n",
      "trainer/Policy Loss                 -1379.15\n",
      "trainer/Bias Loss                      29.2083\n",
      "trainer/Bias Value                     16.0275\n",
      "trainer/Policy Grad Norm              228.6\n",
      "trainer/Policy Param Norm              53.6628\n",
      "trainer/Zf1 Grad Norm               18096.9\n",
      "trainer/Zf1 Param Norm                144.105\n",
      "trainer/Zf2 Grad Norm               21507.9\n",
      "trainer/Zf2 Param Norm                142.426\n",
      "trainer/Z Expert Predictions Mean    1988.02\n",
      "trainer/Z Expert Predictions Std       93.5165\n",
      "trainer/Z Expert Predictions Max     2130.65\n",
      "trainer/Z Expert Predictions Min     1016.35\n",
      "trainer/Z Policy Predictions Mean    1364.99\n",
      "trainer/Z Policy Predictions Std      623.762\n",
      "trainer/Z Policy Predictions Max     1999.38\n",
      "trainer/Z Policy Predictions Min      -14.0464\n",
      "trainer/Z Expert Targets Mean        1971.41\n",
      "trainer/Z Expert Targets Std           91.9232\n",
      "trainer/Z Expert Targets Max         2099.33\n",
      "trainer/Z Expert Targets Min         1027.79\n",
      "trainer/Z Policy Targets Mean        1356.39\n",
      "trainer/Z Policy Targets Std          621.517\n",
      "trainer/Z Policy Targets Max         1964.27\n",
      "trainer/Z Policy Targets Min           -7.94089\n",
      "trainer/Log Pis Mean                   58.191\n",
      "trainer/Log Pis Std                    24.9833\n",
      "trainer/Policy mu Mean                  0.333012\n",
      "trainer/Policy mu Std                   3.45322\n",
      "trainer/Policy log std Mean            -2.86359\n",
      "trainer/Policy log std Std              1.31329\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        214847\n",
      "exploration/num paths total          1364\n",
      "evaluation/num steps total              1.08884e+06\n",
      "evaluation/num paths total           2136\n",
      "evaluation/path length Mean           674.1\n",
      "evaluation/path length Std            401.565\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             92\n",
      "evaluation/Rewards Mean                 5.30041\n",
      "evaluation/Rewards Std                  0.105787\n",
      "evaluation/Rewards Max                  5.85765\n",
      "evaluation/Rewards Min                  4.45628\n",
      "evaluation/Returns Mean              3573.01\n",
      "evaluation/Returns Std               2140.52\n",
      "evaluation/Returns Max               5315.74\n",
      "evaluation/Returns Min                442.982\n",
      "evaluation/Estimation Bias Mean      1744.51\n",
      "evaluation/Estimation Bias Std        441.421\n",
      "evaluation/EB/Q_True Mean              71.1448\n",
      "evaluation/EB/Q_True Std              175.24\n",
      "evaluation/EB/Q_Pred Mean            1815.65\n",
      "evaluation/EB/Q_Pred Std              299.167\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3573.01\n",
      "evaluation/Actions Mean                 0.0764504\n",
      "evaluation/Actions Std                  0.524313\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.91781\n",
      "time/backward_zf1 (s)                   2.39899\n",
      "time/backward_zf2 (s)                   2.30579\n",
      "time/data sampling (s)                  0.398019\n",
      "time/data storing (s)                   0.0145023\n",
      "time/evaluation sampling (s)            2.5155\n",
      "time/exploration sampling (s)           0.479354\n",
      "time/logging (s)                        0.00979879\n",
      "time/preback_alpha (s)                  0.584754\n",
      "time/preback_policy (s)                 1.16303\n",
      "time/preback_start (s)                  0.177358\n",
      "time/preback_zf (s)                     6.67574\n",
      "time/saving (s)                         3.091e-06\n",
      "time/training (s)                       3.13083\n",
      "time/epoch (s)                         21.7715\n",
      "time/total (s)                       4321.63\n",
      "Epoch                                 208\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:37:52.244741 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 209 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 220000\n",
      "trainer/ZF1 Loss                      462.149\n",
      "trainer/ZF2 Loss                      458.261\n",
      "trainer/ZF Expert Reward               10.6474\n",
      "trainer/ZF Policy Reward                3.09512\n",
      "trainer/ZF CHI2 Term                  451.069\n",
      "trainer/Policy Loss                 -1392.43\n",
      "trainer/Bias Loss                     111.269\n",
      "trainer/Bias Value                     16.0097\n",
      "trainer/Policy Grad Norm              302.102\n",
      "trainer/Policy Param Norm              53.7369\n",
      "trainer/Zf1 Grad Norm               39269.7\n",
      "trainer/Zf1 Param Norm                144.425\n",
      "trainer/Zf2 Grad Norm               39091.9\n",
      "trainer/Zf2 Param Norm                142.757\n",
      "trainer/Z Expert Predictions Mean    1978.6\n",
      "trainer/Z Expert Predictions Std       70.2798\n",
      "trainer/Z Expert Predictions Max     2136.02\n",
      "trainer/Z Expert Predictions Min     1484.11\n",
      "trainer/Z Policy Predictions Mean    1382.5\n",
      "trainer/Z Policy Predictions Std      638.902\n",
      "trainer/Z Policy Predictions Max     1995.4\n",
      "trainer/Z Policy Predictions Min      -21.1297\n",
      "trainer/Z Expert Targets Mean        1967.95\n",
      "trainer/Z Expert Targets Std           70.1226\n",
      "trainer/Z Expert Targets Max         2112.03\n",
      "trainer/Z Expert Targets Min         1492.23\n",
      "trainer/Z Policy Targets Mean        1379.4\n",
      "trainer/Z Policy Targets Std          640.831\n",
      "trainer/Z Policy Targets Max         1955.76\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   59.813\n",
      "trainer/Log Pis Std                    27.8452\n",
      "trainer/Policy mu Mean                  0.294396\n",
      "trainer/Policy mu Std                   3.24429\n",
      "trainer/Policy log std Mean            -3.01174\n",
      "trainer/Policy log std Std              1.27832\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        215847\n",
      "exploration/num paths total          1365\n",
      "evaluation/num steps total              1.09884e+06\n",
      "evaluation/num paths total           2146\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.32854\n",
      "evaluation/Rewards Std                  0.0745443\n",
      "evaluation/Rewards Max                  5.56984\n",
      "evaluation/Rewards Min                  4.83205\n",
      "evaluation/Returns Mean              5328.54\n",
      "evaluation/Returns Std                  6.9927\n",
      "evaluation/Returns Max               5346.71\n",
      "evaluation/Returns Min               5320.06\n",
      "evaluation/Estimation Bias Mean      1840.62\n",
      "evaluation/Estimation Bias Std        169.63\n",
      "evaluation/EB/Q_True Mean              48.0745\n",
      "evaluation/EB/Q_True Std              148.05\n",
      "evaluation/EB/Q_Pred Mean            1888.69\n",
      "evaluation/EB/Q_Pred Std               74.3125\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5328.54\n",
      "evaluation/Actions Mean                 0.0864101\n",
      "evaluation/Actions Std                  0.497229\n",
      "evaluation/Actions Max                  0.999968\n",
      "evaluation/Actions Min                 -0.998563\n",
      "time/backward_policy (s)                1.95134\n",
      "time/backward_zf1 (s)                   2.43351\n",
      "time/backward_zf2 (s)                   2.34444\n",
      "time/data sampling (s)                  0.398994\n",
      "time/data storing (s)                   0.0153368\n",
      "time/evaluation sampling (s)            2.69358\n",
      "time/exploration sampling (s)           0.507012\n",
      "time/logging (s)                        0.0159578\n",
      "time/preback_alpha (s)                  0.605961\n",
      "time/preback_policy (s)                 1.14631\n",
      "time/preback_start (s)                  0.185525\n",
      "time/preback_zf (s)                     6.72325\n",
      "time/saving (s)                         4.323e-06\n",
      "time/training (s)                       3.28076\n",
      "time/epoch (s)                         22.302\n",
      "time/total (s)                       4343.95\n",
      "Epoch                                 209\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:38:14.960338 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 210 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 221000\n",
      "trainer/ZF1 Loss                      339.884\n",
      "trainer/ZF2 Loss                      348.73\n",
      "trainer/ZF Expert Reward               19.5908\n",
      "trainer/ZF Policy Reward               11.3731\n",
      "trainer/ZF CHI2 Term                  344.237\n",
      "trainer/Policy Loss                 -1456.31\n",
      "trainer/Bias Loss                      38.3141\n",
      "trainer/Bias Value                     15.9959\n",
      "trainer/Policy Grad Norm              214.445\n",
      "trainer/Policy Param Norm              53.8081\n",
      "trainer/Zf1 Grad Norm               23060.6\n",
      "trainer/Zf1 Param Norm                144.717\n",
      "trainer/Zf2 Grad Norm               20365.4\n",
      "trainer/Zf2 Param Norm                143.063\n",
      "trainer/Z Expert Predictions Mean    1960.21\n",
      "trainer/Z Expert Predictions Std      141.452\n",
      "trainer/Z Expert Predictions Max     2103.25\n",
      "trainer/Z Expert Predictions Min       21.6566\n",
      "trainer/Z Policy Predictions Mean    1447.87\n",
      "trainer/Z Policy Predictions Std      590.96\n",
      "trainer/Z Policy Predictions Max     1987.14\n",
      "trainer/Z Policy Predictions Min      -11.2245\n",
      "trainer/Z Expert Targets Mean        1940.62\n",
      "trainer/Z Expert Targets Std          142.68\n",
      "trainer/Z Expert Targets Max         2090.17\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1436.5\n",
      "trainer/Z Policy Targets Std          589.373\n",
      "trainer/Z Policy Targets Max         1944.9\n",
      "trainer/Z Policy Targets Min          -20.3696\n",
      "trainer/Log Pis Mean                   57.4102\n",
      "trainer/Log Pis Std                    25.5062\n",
      "trainer/Policy mu Mean                  0.281566\n",
      "trainer/Policy mu Std                   3.76329\n",
      "trainer/Policy log std Mean            -3.01535\n",
      "trainer/Policy log std Std              1.24703\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        216118\n",
      "exploration/num paths total          1366\n",
      "evaluation/num steps total              1.10884e+06\n",
      "evaluation/num paths total           2156\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33775\n",
      "evaluation/Rewards Std                  0.0724061\n",
      "evaluation/Rewards Max                  5.5169\n",
      "evaluation/Rewards Min                  4.88776\n",
      "evaluation/Returns Mean              5337.75\n",
      "evaluation/Returns Std                  1.91437\n",
      "evaluation/Returns Max               5340.96\n",
      "evaluation/Returns Min               5334.55\n",
      "evaluation/Estimation Bias Mean      1831.42\n",
      "evaluation/Estimation Bias Std        167.66\n",
      "evaluation/EB/Q_True Mean              48.1841\n",
      "evaluation/EB/Q_True Std              148.383\n",
      "evaluation/EB/Q_Pred Mean            1879.61\n",
      "evaluation/EB/Q_Pred Std               76.4205\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5337.75\n",
      "evaluation/Actions Mean                 0.0734576\n",
      "evaluation/Actions Std                  0.488571\n",
      "evaluation/Actions Max                  0.999791\n",
      "evaluation/Actions Min                 -0.998749\n",
      "time/backward_policy (s)                2.0184\n",
      "time/backward_zf1 (s)                   2.58338\n",
      "time/backward_zf2 (s)                   2.41696\n",
      "time/data sampling (s)                  0.423953\n",
      "time/data storing (s)                   0.0158351\n",
      "time/evaluation sampling (s)            2.57663\n",
      "time/exploration sampling (s)           0.503115\n",
      "time/logging (s)                        0.0137759\n",
      "time/preback_alpha (s)                  0.630916\n",
      "time/preback_policy (s)                 1.19\n",
      "time/preback_start (s)                  0.196966\n",
      "time/preback_zf (s)                     6.86987\n",
      "time/saving (s)                         3.414e-06\n",
      "time/training (s)                       3.19738\n",
      "time/epoch (s)                         22.6372\n",
      "time/total (s)                       4366.61\n",
      "Epoch                                 210\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:38:36.070915 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 211 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 222000\n",
      "trainer/ZF1 Loss                      435.971\n",
      "trainer/ZF2 Loss                      395.816\n",
      "trainer/ZF Expert Reward               15.0604\n",
      "trainer/ZF Policy Reward                8.2955\n",
      "trainer/ZF CHI2 Term                  411.316\n",
      "trainer/Policy Loss                 -1452.17\n",
      "trainer/Bias Loss                      29.2153\n",
      "trainer/Bias Value                     15.9817\n",
      "trainer/Policy Grad Norm              247.616\n",
      "trainer/Policy Param Norm              53.8833\n",
      "trainer/Zf1 Grad Norm               19650.5\n",
      "trainer/Zf1 Param Norm                145.026\n",
      "trainer/Zf2 Grad Norm               18037.6\n",
      "trainer/Zf2 Param Norm                143.357\n",
      "trainer/Z Expert Predictions Mean    1963.31\n",
      "trainer/Z Expert Predictions Std       67.5982\n",
      "trainer/Z Expert Predictions Max     2081.34\n",
      "trainer/Z Expert Predictions Min     1663.23\n",
      "trainer/Z Policy Predictions Mean    1442.65\n",
      "trainer/Z Policy Predictions Std      582.795\n",
      "trainer/Z Policy Predictions Max     1952.65\n",
      "trainer/Z Policy Predictions Min      -10.9925\n",
      "trainer/Z Expert Targets Mean        1948.25\n",
      "trainer/Z Expert Targets Std           67.7937\n",
      "trainer/Z Expert Targets Max         2070.84\n",
      "trainer/Z Expert Targets Min         1642.04\n",
      "trainer/Z Policy Targets Mean        1434.36\n",
      "trainer/Z Policy Targets Std          580.777\n",
      "trainer/Z Policy Targets Max         1934.55\n",
      "trainer/Z Policy Targets Min          -24.9495\n",
      "trainer/Log Pis Mean                   56.7151\n",
      "trainer/Log Pis Std                    26.8239\n",
      "trainer/Policy mu Mean                  0.317169\n",
      "trainer/Policy mu Std                   3.32518\n",
      "trainer/Policy log std Mean            -2.98744\n",
      "trainer/Policy log std Std              1.25073\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        217118\n",
      "exploration/num paths total          1367\n",
      "evaluation/num steps total              1.11798e+06\n",
      "evaluation/num paths total           2166\n",
      "evaluation/path length Mean           913.7\n",
      "evaluation/path length Std            258.9\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            137\n",
      "evaluation/Rewards Mean                 5.28217\n",
      "evaluation/Rewards Std                  0.125607\n",
      "evaluation/Rewards Max                  5.47709\n",
      "evaluation/Rewards Min                  3.3595\n",
      "evaluation/Returns Mean              4826.32\n",
      "evaluation/Returns Std               1399.18\n",
      "evaluation/Returns Max               5300.63\n",
      "evaluation/Returns Min                628.796\n",
      "evaluation/Estimation Bias Mean      1799.54\n",
      "evaluation/Estimation Bias Std        249.594\n",
      "evaluation/EB/Q_True Mean              52.3109\n",
      "evaluation/EB/Q_True Std              153.215\n",
      "evaluation/EB/Q_Pred Mean            1851.85\n",
      "evaluation/EB/Q_Pred Std              159.282\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4826.32\n",
      "evaluation/Actions Mean                 0.0681574\n",
      "evaluation/Actions Std                  0.507857\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.6811\n",
      "time/backward_zf1 (s)                   2.08233\n",
      "time/backward_zf2 (s)                   1.98959\n",
      "time/data sampling (s)                  0.343414\n",
      "time/data storing (s)                   0.0146026\n",
      "time/evaluation sampling (s)            2.45704\n",
      "time/exploration sampling (s)           0.482636\n",
      "time/logging (s)                        0.0126082\n",
      "time/preback_alpha (s)                  0.562375\n",
      "time/preback_policy (s)                 0.946544\n",
      "time/preback_start (s)                  0.171966\n",
      "time/preback_zf (s)                     6.57533\n",
      "time/saving (s)                         2.63e-06\n",
      "time/training (s)                       3.71974\n",
      "time/epoch (s)                         21.0393\n",
      "time/total (s)                       4387.68\n",
      "Epoch                                 211\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:38:57.487805 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 212 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 223000\n",
      "trainer/ZF1 Loss                      441.87\n",
      "trainer/ZF2 Loss                      450.728\n",
      "trainer/ZF Expert Reward               16.8109\n",
      "trainer/ZF Policy Reward                2.75252\n",
      "trainer/ZF CHI2 Term                  443.558\n",
      "trainer/Policy Loss                 -1406.36\n",
      "trainer/Bias Loss                      65.4272\n",
      "trainer/Bias Value                     15.966\n",
      "trainer/Policy Grad Norm              338.702\n",
      "trainer/Policy Param Norm              53.9565\n",
      "trainer/Zf1 Grad Norm               26290.5\n",
      "trainer/Zf1 Param Norm                145.317\n",
      "trainer/Zf2 Grad Norm               27580.3\n",
      "trainer/Zf2 Param Norm                143.684\n",
      "trainer/Z Expert Predictions Mean    1957.73\n",
      "trainer/Z Expert Predictions Std       74.6861\n",
      "trainer/Z Expert Predictions Max     2081.09\n",
      "trainer/Z Expert Predictions Min     1631.47\n",
      "trainer/Z Policy Predictions Mean    1396.56\n",
      "trainer/Z Policy Predictions Std      612.168\n",
      "trainer/Z Policy Predictions Max     1930.84\n",
      "trainer/Z Policy Predictions Min      -14.4846\n",
      "trainer/Z Expert Targets Mean        1940.92\n",
      "trainer/Z Expert Targets Std           74.0478\n",
      "trainer/Z Expert Targets Max         2066.99\n",
      "trainer/Z Expert Targets Min         1633.05\n",
      "trainer/Z Policy Targets Mean        1393.81\n",
      "trainer/Z Policy Targets Std          614.534\n",
      "trainer/Z Policy Targets Max         1943.88\n",
      "trainer/Z Policy Targets Min          -18.8677\n",
      "trainer/Log Pis Mean                   58.584\n",
      "trainer/Log Pis Std                    28.4149\n",
      "trainer/Policy mu Mean                  0.346158\n",
      "trainer/Policy mu Std                   3.95829\n",
      "trainer/Policy log std Mean            -2.97737\n",
      "trainer/Policy log std Std              1.28796\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        218118\n",
      "exploration/num paths total          1368\n",
      "evaluation/num steps total              1.12723e+06\n",
      "evaluation/num paths total           2176\n",
      "evaluation/path length Mean           924.9\n",
      "evaluation/path length Std            225.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            249\n",
      "evaluation/Rewards Mean                 5.3331\n",
      "evaluation/Rewards Std                  0.0813882\n",
      "evaluation/Rewards Max                  5.5682\n",
      "evaluation/Rewards Min                  4.89387\n",
      "evaluation/Returns Mean              4932.59\n",
      "evaluation/Returns Std               1210.03\n",
      "evaluation/Returns Max               5345.18\n",
      "evaluation/Returns Min               1302.53\n",
      "evaluation/Estimation Bias Mean      1766.46\n",
      "evaluation/Estimation Bias Std        263.099\n",
      "evaluation/EB/Q_True Mean              52.1895\n",
      "evaluation/EB/Q_True Std              153.911\n",
      "evaluation/EB/Q_Pred Mean            1818.65\n",
      "evaluation/EB/Q_Pred Std              158.44\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4932.59\n",
      "evaluation/Actions Mean                 0.0660621\n",
      "evaluation/Actions Std                  0.512298\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                1.75504\n",
      "time/backward_zf1 (s)                   2.17815\n",
      "time/backward_zf2 (s)                   2.09543\n",
      "time/data sampling (s)                  0.369795\n",
      "time/data storing (s)                   0.0145575\n",
      "time/evaluation sampling (s)            2.52958\n",
      "time/exploration sampling (s)           0.489844\n",
      "time/logging (s)                        0.0126468\n",
      "time/preback_alpha (s)                  0.572701\n",
      "time/preback_policy (s)                 1.0257\n",
      "time/preback_start (s)                  0.174471\n",
      "time/preback_zf (s)                     6.63561\n",
      "time/saving (s)                         3.57599e-06\n",
      "time/training (s)                       3.49785\n",
      "time/epoch (s)                         21.3514\n",
      "time/total (s)                       4409.05\n",
      "Epoch                                 212\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:39:20.133547 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 213 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 224000\n",
      "trainer/ZF1 Loss                      482.091\n",
      "trainer/ZF2 Loss                      380.653\n",
      "trainer/ZF Expert Reward                8.65146\n",
      "trainer/ZF Policy Reward                3.66831\n",
      "trainer/ZF CHI2 Term                  420.601\n",
      "trainer/Policy Loss                 -1469.3\n",
      "trainer/Bias Loss                     143.886\n",
      "trainer/Bias Value                     15.9519\n",
      "trainer/Policy Grad Norm              305.456\n",
      "trainer/Policy Param Norm              54.0314\n",
      "trainer/Zf1 Grad Norm               76546.5\n",
      "trainer/Zf1 Param Norm                145.636\n",
      "trainer/Zf2 Grad Norm               33066.5\n",
      "trainer/Zf2 Param Norm                143.999\n",
      "trainer/Z Expert Predictions Mean    1945.9\n",
      "trainer/Z Expert Predictions Std       70.3093\n",
      "trainer/Z Expert Predictions Max     2080.39\n",
      "trainer/Z Expert Predictions Min     1714.36\n",
      "trainer/Z Policy Predictions Mean    1456.19\n",
      "trainer/Z Policy Predictions Std      530.878\n",
      "trainer/Z Policy Predictions Max     1931.76\n",
      "trainer/Z Policy Predictions Min       -7.28297\n",
      "trainer/Z Expert Targets Mean        1937.25\n",
      "trainer/Z Expert Targets Std           70.7623\n",
      "trainer/Z Expert Targets Max         2085.68\n",
      "trainer/Z Expert Targets Min         1703.57\n",
      "trainer/Z Policy Targets Mean        1452.52\n",
      "trainer/Z Policy Targets Std          532.902\n",
      "trainer/Z Policy Targets Max         1923.35\n",
      "trainer/Z Policy Targets Min          -11.1131\n",
      "trainer/Log Pis Mean                   54.2953\n",
      "trainer/Log Pis Std                    23.2129\n",
      "trainer/Policy mu Mean                  0.332186\n",
      "trainer/Policy mu Std                   2.85961\n",
      "trainer/Policy log std Mean            -3.0346\n",
      "trainer/Policy log std Std              1.13206\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        219278\n",
      "exploration/num paths total          1370\n",
      "evaluation/num steps total              1.13723e+06\n",
      "evaluation/num paths total           2186\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30844\n",
      "evaluation/Rewards Std                  0.0737847\n",
      "evaluation/Rewards Max                  5.50652\n",
      "evaluation/Rewards Min                  4.88597\n",
      "evaluation/Returns Mean              5308.44\n",
      "evaluation/Returns Std                  4.69571\n",
      "evaluation/Returns Max               5316.21\n",
      "evaluation/Returns Min               5302.61\n",
      "evaluation/Estimation Bias Mean      1777.29\n",
      "evaluation/Estimation Bias Std        171.794\n",
      "evaluation/EB/Q_True Mean              47.9921\n",
      "evaluation/EB/Q_True Std              147.813\n",
      "evaluation/EB/Q_Pred Mean            1825.28\n",
      "evaluation/EB/Q_Pred Std               83.8374\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5308.44\n",
      "evaluation/Actions Mean                 0.0713757\n",
      "evaluation/Actions Std                  0.488108\n",
      "evaluation/Actions Max                  0.999688\n",
      "evaluation/Actions Min                 -0.996874\n",
      "time/backward_policy (s)                1.99312\n",
      "time/backward_zf1 (s)                   2.47539\n",
      "time/backward_zf2 (s)                   2.34574\n",
      "time/data sampling (s)                  0.423118\n",
      "time/data storing (s)                   0.0159384\n",
      "time/evaluation sampling (s)            2.57387\n",
      "time/exploration sampling (s)           0.514082\n",
      "time/logging (s)                        0.015149\n",
      "time/preback_alpha (s)                  0.623461\n",
      "time/preback_policy (s)                 1.14615\n",
      "time/preback_start (s)                  0.191095\n",
      "time/preback_zf (s)                     6.81319\n",
      "time/saving (s)                         4.892e-06\n",
      "time/training (s)                       3.44034\n",
      "time/epoch (s)                         22.5707\n",
      "time/total (s)                       4431.64\n",
      "Epoch                                 213\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:39:44.592974 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 214 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 225000\n",
      "trainer/ZF1 Loss                      437.212\n",
      "trainer/ZF2 Loss                      383.566\n",
      "trainer/ZF Expert Reward               10.7636\n",
      "trainer/ZF Policy Reward                3.81712\n",
      "trainer/ZF CHI2 Term                  401.757\n",
      "trainer/Policy Loss                 -1392.35\n",
      "trainer/Bias Loss                      61.9674\n",
      "trainer/Bias Value                     15.935\n",
      "trainer/Policy Grad Norm              329.992\n",
      "trainer/Policy Param Norm              54.11\n",
      "trainer/Zf1 Grad Norm               32202.9\n",
      "trainer/Zf1 Param Norm                145.973\n",
      "trainer/Zf2 Grad Norm               25970.1\n",
      "trainer/Zf2 Param Norm                144.335\n",
      "trainer/Z Expert Predictions Mean    1938.32\n",
      "trainer/Z Expert Predictions Std       97.0882\n",
      "trainer/Z Expert Predictions Max     2080.85\n",
      "trainer/Z Expert Predictions Min      786.12\n",
      "trainer/Z Policy Predictions Mean    1378.44\n",
      "trainer/Z Policy Predictions Std      571.002\n",
      "trainer/Z Policy Predictions Max     1963.35\n",
      "trainer/Z Policy Predictions Min      -10.3243\n",
      "trainer/Z Expert Targets Mean        1927.56\n",
      "trainer/Z Expert Targets Std           98.1673\n",
      "trainer/Z Expert Targets Max         2072.18\n",
      "trainer/Z Expert Targets Min          771.551\n",
      "trainer/Z Policy Targets Mean        1374.62\n",
      "trainer/Z Policy Targets Std          575.937\n",
      "trainer/Z Policy Targets Max         1917.12\n",
      "trainer/Z Policy Targets Min          -19.1674\n",
      "trainer/Log Pis Mean                   56.5872\n",
      "trainer/Log Pis Std                    24.2658\n",
      "trainer/Policy mu Mean                  0.337791\n",
      "trainer/Policy mu Std                   3.21952\n",
      "trainer/Policy log std Mean            -2.96219\n",
      "trainer/Policy log std Std              1.21322\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        220278\n",
      "exploration/num paths total          1371\n",
      "evaluation/num steps total              1.14723e+06\n",
      "evaluation/num paths total           2196\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33278\n",
      "evaluation/Rewards Std                  0.0779434\n",
      "evaluation/Rewards Max                  5.52949\n",
      "evaluation/Rewards Min                  4.84966\n",
      "evaluation/Returns Mean              5332.78\n",
      "evaluation/Returns Std                  5.08367\n",
      "evaluation/Returns Max               5342.18\n",
      "evaluation/Returns Min               5325.29\n",
      "evaluation/Estimation Bias Mean      1799.54\n",
      "evaluation/Estimation Bias Std        167.526\n",
      "evaluation/EB/Q_True Mean              48.1358\n",
      "evaluation/EB/Q_True Std              148.251\n",
      "evaluation/EB/Q_Pred Mean            1847.67\n",
      "evaluation/EB/Q_Pred Std               81.8832\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5332.78\n",
      "evaluation/Actions Mean                 0.0783055\n",
      "evaluation/Actions Std                  0.524939\n",
      "evaluation/Actions Max                  0.999882\n",
      "evaluation/Actions Min                 -0.998861\n",
      "time/backward_policy (s)                2.12301\n",
      "time/backward_zf1 (s)                   2.68828\n",
      "time/backward_zf2 (s)                   2.51832\n",
      "time/data sampling (s)                  0.467269\n",
      "time/data storing (s)                   0.0162891\n",
      "time/evaluation sampling (s)            3.61017\n",
      "time/exploration sampling (s)           0.516179\n",
      "time/logging (s)                        0.0161996\n",
      "time/preback_alpha (s)                  0.676552\n",
      "time/preback_policy (s)                 1.27067\n",
      "time/preback_start (s)                  0.210916\n",
      "time/preback_zf (s)                     7.03305\n",
      "time/saving (s)                         6.781e-06\n",
      "time/training (s)                       3.2318\n",
      "time/epoch (s)                         24.3787\n",
      "time/total (s)                       4456.05\n",
      "Epoch                                 214\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:40:12.135648 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 215 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 226000\n",
      "trainer/ZF1 Loss                      507.147\n",
      "trainer/ZF2 Loss                      509.106\n",
      "trainer/ZF Expert Reward               10.7872\n",
      "trainer/ZF Policy Reward                7.88706\n",
      "trainer/ZF CHI2 Term                  499.573\n",
      "trainer/Policy Loss                 -1387.81\n",
      "trainer/Bias Loss                      68.3719\n",
      "trainer/Bias Value                     15.9171\n",
      "trainer/Policy Grad Norm              318.489\n",
      "trainer/Policy Param Norm              54.1814\n",
      "trainer/Zf1 Grad Norm               21049.9\n",
      "trainer/Zf1 Param Norm                146.303\n",
      "trainer/Zf2 Grad Norm               32078.8\n",
      "trainer/Zf2 Param Norm                144.653\n",
      "trainer/Z Expert Predictions Mean    1937.95\n",
      "trainer/Z Expert Predictions Std       64.8205\n",
      "trainer/Z Expert Predictions Max     2083.63\n",
      "trainer/Z Expert Predictions Min     1707.99\n",
      "trainer/Z Policy Predictions Mean    1377.16\n",
      "trainer/Z Policy Predictions Std      605.749\n",
      "trainer/Z Policy Predictions Max     1968.03\n",
      "trainer/Z Policy Predictions Min       20.6558\n",
      "trainer/Z Expert Targets Mean        1927.16\n",
      "trainer/Z Expert Targets Std           64.3592\n",
      "trainer/Z Expert Targets Max         2073.19\n",
      "trainer/Z Expert Targets Min         1687.39\n",
      "trainer/Z Policy Targets Mean        1369.27\n",
      "trainer/Z Policy Targets Std          607.312\n",
      "trainer/Z Policy Targets Max         1933.94\n",
      "trainer/Z Policy Targets Min            8.22786\n",
      "trainer/Log Pis Mean                   57.5186\n",
      "trainer/Log Pis Std                    24.2698\n",
      "trainer/Policy mu Mean                  0.355364\n",
      "trainer/Policy mu Std                   2.83033\n",
      "trainer/Policy log std Mean            -2.95188\n",
      "trainer/Policy log std Std              1.23101\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        220278\n",
      "exploration/num paths total          1371\n",
      "evaluation/num steps total              1.15723e+06\n",
      "evaluation/num paths total           2206\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30471\n",
      "evaluation/Rewards Std                  0.0740164\n",
      "evaluation/Rewards Max                  5.5443\n",
      "evaluation/Rewards Min                  4.88808\n",
      "evaluation/Returns Mean              5304.71\n",
      "evaluation/Returns Std                  9.67979\n",
      "evaluation/Returns Max               5315.11\n",
      "evaluation/Returns Min               5277.75\n",
      "evaluation/Estimation Bias Mean      1777.96\n",
      "evaluation/Estimation Bias Std        176.089\n",
      "evaluation/EB/Q_True Mean              47.9055\n",
      "evaluation/EB/Q_True Std              147.523\n",
      "evaluation/EB/Q_Pred Mean            1825.87\n",
      "evaluation/EB/Q_Pred Std               94.9489\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5304.71\n",
      "evaluation/Actions Mean                 0.0759888\n",
      "evaluation/Actions Std                  0.524343\n",
      "evaluation/Actions Max                  0.99996\n",
      "evaluation/Actions Min                 -0.999825\n",
      "time/backward_policy (s)                2.41919\n",
      "time/backward_zf1 (s)                   3.36068\n",
      "time/backward_zf2 (s)                   3.04628\n",
      "time/data sampling (s)                  0.565154\n",
      "time/data storing (s)                   0.0242203\n",
      "time/evaluation sampling (s)            3.70862\n",
      "time/exploration sampling (s)           0.646652\n",
      "time/logging (s)                        0.0150065\n",
      "time/preback_alpha (s)                  0.842069\n",
      "time/preback_policy (s)                 1.45279\n",
      "time/preback_start (s)                  0.251371\n",
      "time/preback_zf (s)                     7.81597\n",
      "time/saving (s)                         5.356e-06\n",
      "time/training (s)                       3.29779\n",
      "time/epoch (s)                         27.4458\n",
      "time/total (s)                       4483.52\n",
      "Epoch                                 215\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:40:37.966436 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 216 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 227000\n",
      "trainer/ZF1 Loss                     1506.88\n",
      "trainer/ZF2 Loss                     2227.63\n",
      "trainer/ZF Expert Reward               16.9758\n",
      "trainer/ZF Policy Reward               16.6219\n",
      "trainer/ZF CHI2 Term                 1864.77\n",
      "trainer/Policy Loss                 -1362.66\n",
      "trainer/Bias Loss                      58.9561\n",
      "trainer/Bias Value                     15.8989\n",
      "trainer/Policy Grad Norm              320.242\n",
      "trainer/Policy Param Norm              54.2516\n",
      "trainer/Zf1 Grad Norm               68734.8\n",
      "trainer/Zf1 Param Norm                146.634\n",
      "trainer/Zf2 Grad Norm               47591.1\n",
      "trainer/Zf2 Param Norm                144.98\n",
      "trainer/Z Expert Predictions Mean    1948.58\n",
      "trainer/Z Expert Predictions Std       62.6693\n",
      "trainer/Z Expert Predictions Max     2083.08\n",
      "trainer/Z Expert Predictions Min     1690.34\n",
      "trainer/Z Policy Predictions Mean    1355.11\n",
      "trainer/Z Policy Predictions Std      594.478\n",
      "trainer/Z Policy Predictions Max     1905.41\n",
      "trainer/Z Policy Predictions Min      -24.7625\n",
      "trainer/Z Expert Targets Mean        1931.6\n",
      "trainer/Z Expert Targets Std           62.5507\n",
      "trainer/Z Expert Targets Max         2067.92\n",
      "trainer/Z Expert Targets Min         1687.08\n",
      "trainer/Z Policy Targets Mean        1338.48\n",
      "trainer/Z Policy Targets Std          599.484\n",
      "trainer/Z Policy Targets Max         1905.89\n",
      "trainer/Z Policy Targets Min          -32.9933\n",
      "trainer/Log Pis Mean                   57.7276\n",
      "trainer/Log Pis Std                    23.2143\n",
      "trainer/Policy mu Mean                  0.284108\n",
      "trainer/Policy mu Std                   3.04897\n",
      "trainer/Policy log std Mean            -2.99187\n",
      "trainer/Policy log std Std              1.2048\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        221278\n",
      "exploration/num paths total          1372\n",
      "evaluation/num steps total              1.1662e+06\n",
      "evaluation/num paths total           2216\n",
      "evaluation/path length Mean           897.3\n",
      "evaluation/path length Std            207.963\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            313\n",
      "evaluation/Rewards Mean                 5.3228\n",
      "evaluation/Rewards Std                  0.0901303\n",
      "evaluation/Rewards Max                  6.17596\n",
      "evaluation/Rewards Min                  4.89474\n",
      "evaluation/Returns Mean              4776.15\n",
      "evaluation/Returns Std               1105.23\n",
      "evaluation/Returns Max               5325.02\n",
      "evaluation/Returns Min               1670.3\n",
      "evaluation/Estimation Bias Mean      1710.09\n",
      "evaluation/Estimation Bias Std        280.148\n",
      "evaluation/EB/Q_True Mean              53.4951\n",
      "evaluation/EB/Q_True Std              155.166\n",
      "evaluation/EB/Q_Pred Mean            1763.59\n",
      "evaluation/EB/Q_Pred Std              206.934\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4776.15\n",
      "evaluation/Actions Mean                 0.0734163\n",
      "evaluation/Actions Std                  0.502976\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.29548\n",
      "time/backward_zf1 (s)                   3.13352\n",
      "time/backward_zf2 (s)                   2.92455\n",
      "time/data sampling (s)                  0.563512\n",
      "time/data storing (s)                   0.0199395\n",
      "time/evaluation sampling (s)            2.98739\n",
      "time/exploration sampling (s)           0.60721\n",
      "time/logging (s)                        0.0123032\n",
      "time/preback_alpha (s)                  0.799598\n",
      "time/preback_policy (s)                 1.38275\n",
      "time/preback_start (s)                  0.241149\n",
      "time/preback_zf (s)                     7.50253\n",
      "time/saving (s)                         3.746e-06\n",
      "time/training (s)                       3.26188\n",
      "time/epoch (s)                         25.7318\n",
      "time/total (s)                       4509.27\n",
      "Epoch                                 216\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:41:04.496562 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 217 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 228000\n",
      "trainer/ZF1 Loss                      325.838\n",
      "trainer/ZF2 Loss                      332.56\n",
      "trainer/ZF Expert Reward               17.2337\n",
      "trainer/ZF Policy Reward                6.11589\n",
      "trainer/ZF CHI2 Term                  327.16\n",
      "trainer/Policy Loss                 -1463.95\n",
      "trainer/Bias Loss                      23.1361\n",
      "trainer/Bias Value                     15.8852\n",
      "trainer/Policy Grad Norm              208.02\n",
      "trainer/Policy Param Norm              54.3196\n",
      "trainer/Zf1 Grad Norm               14668.4\n",
      "trainer/Zf1 Param Norm                146.914\n",
      "trainer/Zf2 Grad Norm               19001.8\n",
      "trainer/Zf2 Param Norm                145.292\n",
      "trainer/Z Expert Predictions Mean    1923.1\n",
      "trainer/Z Expert Predictions Std      137.487\n",
      "trainer/Z Expert Predictions Max     2060.08\n",
      "trainer/Z Expert Predictions Min       21.3458\n",
      "trainer/Z Policy Predictions Mean    1456.83\n",
      "trainer/Z Policy Predictions Std      516.56\n",
      "trainer/Z Policy Predictions Max     1892.29\n",
      "trainer/Z Policy Predictions Min       -1.64216\n",
      "trainer/Z Expert Targets Mean        1905.87\n",
      "trainer/Z Expert Targets Std          137.937\n",
      "trainer/Z Expert Targets Max         2035.49\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1450.71\n",
      "trainer/Z Policy Targets Std          516.34\n",
      "trainer/Z Policy Targets Max         1866.09\n",
      "trainer/Z Policy Targets Min           -7.30345\n",
      "trainer/Log Pis Mean                   54.5584\n",
      "trainer/Log Pis Std                    21.9257\n",
      "trainer/Policy mu Mean                  0.299362\n",
      "trainer/Policy mu Std                   2.80849\n",
      "trainer/Policy log std Mean            -3.13946\n",
      "trainer/Policy log std Std              1.09947\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        224278\n",
      "exploration/num paths total          1375\n",
      "evaluation/num steps total              1.1762e+06\n",
      "evaluation/num paths total           2226\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.32948\n",
      "evaluation/Rewards Std                  0.0785041\n",
      "evaluation/Rewards Max                  5.51018\n",
      "evaluation/Rewards Min                  4.84685\n",
      "evaluation/Returns Mean              5329.48\n",
      "evaluation/Returns Std                  5.48433\n",
      "evaluation/Returns Max               5336.58\n",
      "evaluation/Returns Min               5318.75\n",
      "evaluation/Estimation Bias Mean      1766.44\n",
      "evaluation/Estimation Bias Std        159.172\n",
      "evaluation/EB/Q_True Mean              48.1735\n",
      "evaluation/EB/Q_True Std              148.357\n",
      "evaluation/EB/Q_Pred Mean            1814.62\n",
      "evaluation/EB/Q_Pred Std               63.5407\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5329.48\n",
      "evaluation/Actions Mean                 0.0888526\n",
      "evaluation/Actions Std                  0.502712\n",
      "evaluation/Actions Max                  0.999762\n",
      "evaluation/Actions Min                 -0.998005\n",
      "time/backward_policy (s)                2.34261\n",
      "time/backward_zf1 (s)                   3.30607\n",
      "time/backward_zf2 (s)                   2.99962\n",
      "time/data sampling (s)                  0.616343\n",
      "time/data storing (s)                   0.0231534\n",
      "time/evaluation sampling (s)            2.96445\n",
      "time/exploration sampling (s)           0.629791\n",
      "time/logging (s)                        0.0147154\n",
      "time/preback_alpha (s)                  0.833145\n",
      "time/preback_policy (s)                 1.44559\n",
      "time/preback_start (s)                  0.243267\n",
      "time/preback_zf (s)                     7.71325\n",
      "time/saving (s)                         2.933e-06\n",
      "time/training (s)                       3.29873\n",
      "time/epoch (s)                         26.4307\n",
      "time/total (s)                       4535.73\n",
      "Epoch                                 217\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:41:28.950581 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 218 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 229000\n",
      "trainer/ZF1 Loss                     2157.1\n",
      "trainer/ZF2 Loss                     2378.13\n",
      "trainer/ZF Expert Reward               16.7919\n",
      "trainer/ZF Policy Reward               14.5922\n",
      "trainer/ZF CHI2 Term                 2265.19\n",
      "trainer/Policy Loss                 -1379\n",
      "trainer/Bias Loss                      29.5222\n",
      "trainer/Bias Value                     15.8731\n",
      "trainer/Policy Grad Norm              305.874\n",
      "trainer/Policy Param Norm              54.387\n",
      "trainer/Zf1 Grad Norm               29083.7\n",
      "trainer/Zf1 Param Norm                147.184\n",
      "trainer/Zf2 Grad Norm               21273.1\n",
      "trainer/Zf2 Param Norm                145.597\n",
      "trainer/Z Expert Predictions Mean    1921.65\n",
      "trainer/Z Expert Predictions Std       85.7308\n",
      "trainer/Z Expert Predictions Max     2080.16\n",
      "trainer/Z Expert Predictions Min     1049.59\n",
      "trainer/Z Policy Predictions Mean    1374.19\n",
      "trainer/Z Policy Predictions Std      600.514\n",
      "trainer/Z Policy Predictions Max     1912.66\n",
      "trainer/Z Policy Predictions Min       -2.41325\n",
      "trainer/Z Expert Targets Mean        1904.86\n",
      "trainer/Z Expert Targets Std           84.8882\n",
      "trainer/Z Expert Targets Max         2049.18\n",
      "trainer/Z Expert Targets Min         1028.48\n",
      "trainer/Z Policy Targets Mean        1359.59\n",
      "trainer/Z Policy Targets Std          605.9\n",
      "trainer/Z Policy Targets Max         1915.16\n",
      "trainer/Z Policy Targets Min           -8.67697\n",
      "trainer/Log Pis Mean                   57.4748\n",
      "trainer/Log Pis Std                    25.7709\n",
      "trainer/Policy mu Mean                  0.285588\n",
      "trainer/Policy mu Std                   3.79857\n",
      "trainer/Policy log std Mean            -2.97285\n",
      "trainer/Policy log std Std              1.29929\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        224278\n",
      "exploration/num paths total          1375\n",
      "evaluation/num steps total              1.1847e+06\n",
      "evaluation/num paths total           2236\n",
      "evaluation/path length Mean           849.9\n",
      "evaluation/path length Std            300.643\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            213\n",
      "evaluation/Rewards Mean                 5.3342\n",
      "evaluation/Rewards Std                  0.0796531\n",
      "evaluation/Rewards Max                  5.74063\n",
      "evaluation/Rewards Min                  4.87371\n",
      "evaluation/Returns Mean              4533.54\n",
      "evaluation/Returns Std               1604.18\n",
      "evaluation/Returns Max               5337.8\n",
      "evaluation/Returns Min               1136.1\n",
      "evaluation/Estimation Bias Mean      1722.97\n",
      "evaluation/Estimation Bias Std        303.276\n",
      "evaluation/EB/Q_True Mean              56.6961\n",
      "evaluation/EB/Q_True Std              159.454\n",
      "evaluation/EB/Q_Pred Mean            1779.67\n",
      "evaluation/EB/Q_Pred Std              193.052\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4533.54\n",
      "evaluation/Actions Mean                 0.0850082\n",
      "evaluation/Actions Std                  0.513977\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.1926\n",
      "time/backward_zf1 (s)                   2.87487\n",
      "time/backward_zf2 (s)                   2.69049\n",
      "time/data sampling (s)                  0.507797\n",
      "time/data storing (s)                   0.0200189\n",
      "time/evaluation sampling (s)            2.86394\n",
      "time/exploration sampling (s)           0.542417\n",
      "time/logging (s)                        0.0113135\n",
      "time/preback_alpha (s)                  0.718151\n",
      "time/preback_policy (s)                 1.24948\n",
      "time/preback_start (s)                  0.220789\n",
      "time/preback_zf (s)                     7.08592\n",
      "time/saving (s)                         2.487e-06\n",
      "time/training (s)                       3.38492\n",
      "time/epoch (s)                         24.3627\n",
      "time/total (s)                       4560.12\n",
      "Epoch                                 218\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:41:52.404134 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 219 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 230000\n",
      "trainer/ZF1 Loss                      320.901\n",
      "trainer/ZF2 Loss                      338.033\n",
      "trainer/ZF Expert Reward               15.4509\n",
      "trainer/ZF Policy Reward               11.3931\n",
      "trainer/ZF CHI2 Term                  325.873\n",
      "trainer/Policy Loss                 -1378.19\n",
      "trainer/Bias Loss                      26.3776\n",
      "trainer/Bias Value                     15.8592\n",
      "trainer/Policy Grad Norm              213.768\n",
      "trainer/Policy Param Norm              54.4594\n",
      "trainer/Zf1 Grad Norm               17951.3\n",
      "trainer/Zf1 Param Norm                147.487\n",
      "trainer/Zf2 Grad Norm               16903.7\n",
      "trainer/Zf2 Param Norm                145.896\n",
      "trainer/Z Expert Predictions Mean    1904.67\n",
      "trainer/Z Expert Predictions Std       73.9152\n",
      "trainer/Z Expert Predictions Max     2072.12\n",
      "trainer/Z Expert Predictions Min     1405.68\n",
      "trainer/Z Policy Predictions Mean    1368.62\n",
      "trainer/Z Policy Predictions Std      580.361\n",
      "trainer/Z Policy Predictions Max     1898.33\n",
      "trainer/Z Policy Predictions Min      -21.5932\n",
      "trainer/Z Expert Targets Mean        1889.22\n",
      "trainer/Z Expert Targets Std           75.507\n",
      "trainer/Z Expert Targets Max         2046.81\n",
      "trainer/Z Expert Targets Min         1379.81\n",
      "trainer/Z Policy Targets Mean        1357.23\n",
      "trainer/Z Policy Targets Std          577.712\n",
      "trainer/Z Policy Targets Max         1868.86\n",
      "trainer/Z Policy Targets Min          -24.3628\n",
      "trainer/Log Pis Mean                   58.9074\n",
      "trainer/Log Pis Std                    25.3939\n",
      "trainer/Policy mu Mean                  0.370313\n",
      "trainer/Policy mu Std                   3.4893\n",
      "trainer/Policy log std Mean            -3.04126\n",
      "trainer/Policy log std Std              1.2368\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        225278\n",
      "exploration/num paths total          1376\n",
      "evaluation/num steps total              1.19309e+06\n",
      "evaluation/num paths total           2247\n",
      "evaluation/path length Mean           762.364\n",
      "evaluation/path length Std            301.529\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            118\n",
      "evaluation/Rewards Mean                 5.31266\n",
      "evaluation/Rewards Std                  0.115919\n",
      "evaluation/Rewards Max                  6.13514\n",
      "evaluation/Rewards Min                  4.35794\n",
      "evaluation/Returns Mean              4050.18\n",
      "evaluation/Returns Std               1613.39\n",
      "evaluation/Returns Max               5322.84\n",
      "evaluation/Returns Min                571.922\n",
      "evaluation/Estimation Bias Mean      1626.17\n",
      "evaluation/Estimation Bias Std        361.551\n",
      "evaluation/EB/Q_True Mean              57.2587\n",
      "evaluation/EB/Q_True Std              159.834\n",
      "evaluation/EB/Q_Pred Mean            1683.43\n",
      "evaluation/EB/Q_Pred Std              289.278\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4050.18\n",
      "evaluation/Actions Mean                 0.0736655\n",
      "evaluation/Actions Std                  0.536796\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.08793\n",
      "time/backward_zf1 (s)                   2.72822\n",
      "time/backward_zf2 (s)                   2.53411\n",
      "time/data sampling (s)                  0.477978\n",
      "time/data storing (s)                   0.0168756\n",
      "time/evaluation sampling (s)            2.45348\n",
      "time/exploration sampling (s)           0.527985\n",
      "time/logging (s)                        0.0115247\n",
      "time/preback_alpha (s)                  0.672904\n",
      "time/preback_policy (s)                 1.20323\n",
      "time/preback_start (s)                  0.205852\n",
      "time/preback_zf (s)                     7.01749\n",
      "time/saving (s)                         2.655e-06\n",
      "time/training (s)                       3.43456\n",
      "time/epoch (s)                         23.3721\n",
      "time/total (s)                       4583.52\n",
      "Epoch                                 219\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:42:16.352891 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 220 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 231000\n",
      "trainer/ZF1 Loss                      380.549\n",
      "trainer/ZF2 Loss                      402.105\n",
      "trainer/ZF Expert Reward               22.9586\n",
      "trainer/ZF Policy Reward                6.55\n",
      "trainer/ZF CHI2 Term                  395.11\n",
      "trainer/Policy Loss                 -1360.85\n",
      "trainer/Bias Loss                      96.2744\n",
      "trainer/Bias Value                     15.8436\n",
      "trainer/Policy Grad Norm              239.504\n",
      "trainer/Policy Param Norm              54.5339\n",
      "trainer/Zf1 Grad Norm               27549.4\n",
      "trainer/Zf1 Param Norm                147.805\n",
      "trainer/Zf2 Grad Norm               25331.8\n",
      "trainer/Zf2 Param Norm                146.194\n",
      "trainer/Z Expert Predictions Mean    1919.5\n",
      "trainer/Z Expert Predictions Std       59.2915\n",
      "trainer/Z Expert Predictions Max     2076.82\n",
      "trainer/Z Expert Predictions Min     1677.99\n",
      "trainer/Z Policy Predictions Mean    1353.83\n",
      "trainer/Z Policy Predictions Std      607.844\n",
      "trainer/Z Policy Predictions Max     1892\n",
      "trainer/Z Policy Predictions Min      -17.9958\n",
      "trainer/Z Expert Targets Mean        1896.54\n",
      "trainer/Z Expert Targets Std           57.0998\n",
      "trainer/Z Expert Targets Max         2042.62\n",
      "trainer/Z Expert Targets Min         1669.12\n",
      "trainer/Z Policy Targets Mean        1347.28\n",
      "trainer/Z Policy Targets Std          602.825\n",
      "trainer/Z Policy Targets Max         1881.34\n",
      "trainer/Z Policy Targets Min          -30.704\n",
      "trainer/Log Pis Mean                   59.2368\n",
      "trainer/Log Pis Std                    27.0519\n",
      "trainer/Policy mu Mean                  0.402804\n",
      "trainer/Policy mu Std                   3.81691\n",
      "trainer/Policy log std Mean            -2.94557\n",
      "trainer/Policy log std Std              1.32956\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        226278\n",
      "exploration/num paths total          1377\n",
      "evaluation/num steps total              1.20288e+06\n",
      "evaluation/num paths total           2257\n",
      "evaluation/path length Mean           979.4\n",
      "evaluation/path length Std             61.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            794\n",
      "evaluation/Rewards Mean                 5.32087\n",
      "evaluation/Rewards Std                  0.0760166\n",
      "evaluation/Rewards Max                  5.55648\n",
      "evaluation/Rewards Min                  4.83487\n",
      "evaluation/Returns Mean              5211.26\n",
      "evaluation/Returns Std                329.035\n",
      "evaluation/Returns Max               5326.66\n",
      "evaluation/Returns Min               4224.21\n",
      "evaluation/Estimation Bias Mean      1729.73\n",
      "evaluation/Estimation Bias Std        222.684\n",
      "evaluation/EB/Q_True Mean              49.0522\n",
      "evaluation/EB/Q_True Std              149.344\n",
      "evaluation/EB/Q_Pred Mean            1778.78\n",
      "evaluation/EB/Q_Pred Std              133.927\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5211.26\n",
      "evaluation/Actions Mean                 0.0779264\n",
      "evaluation/Actions Std                  0.504988\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.18854\n",
      "time/backward_zf1 (s)                   2.81603\n",
      "time/backward_zf2 (s)                   2.65282\n",
      "time/data sampling (s)                  0.492418\n",
      "time/data storing (s)                   0.0172418\n",
      "time/evaluation sampling (s)            2.50726\n",
      "time/exploration sampling (s)           0.526592\n",
      "time/logging (s)                        0.0132677\n",
      "time/preback_alpha (s)                  0.692052\n",
      "time/preback_policy (s)                 1.28024\n",
      "time/preback_start (s)                  0.209349\n",
      "time/preback_zf (s)                     7.09828\n",
      "time/saving (s)                         3.692e-06\n",
      "time/training (s)                       3.37994\n",
      "time/epoch (s)                         23.874\n",
      "time/total (s)                       4607.41\n",
      "Epoch                                 220\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:42:40.175809 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 221 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 232000\n",
      "trainer/ZF1 Loss                      240.673\n",
      "trainer/ZF2 Loss                      269.189\n",
      "trainer/ZF Expert Reward               13.8013\n",
      "trainer/ZF Policy Reward                5.99129\n",
      "trainer/ZF CHI2 Term                  249.87\n",
      "trainer/Policy Loss                 -1393.71\n",
      "trainer/Bias Loss                      22.1146\n",
      "trainer/Bias Value                     15.8318\n",
      "trainer/Policy Grad Norm              197.951\n",
      "trainer/Policy Param Norm              54.6006\n",
      "trainer/Zf1 Grad Norm               15726.3\n",
      "trainer/Zf1 Param Norm                148.112\n",
      "trainer/Zf2 Grad Norm               15774.1\n",
      "trainer/Zf2 Param Norm                146.492\n",
      "trainer/Z Expert Predictions Mean    1881.33\n",
      "trainer/Z Expert Predictions Std      118.098\n",
      "trainer/Z Expert Predictions Max     2039.43\n",
      "trainer/Z Expert Predictions Min      720.78\n",
      "trainer/Z Policy Predictions Mean    1383.81\n",
      "trainer/Z Policy Predictions Std      574.219\n",
      "trainer/Z Policy Predictions Max     1892.4\n",
      "trainer/Z Policy Predictions Min      -19.5348\n",
      "trainer/Z Expert Targets Mean        1867.53\n",
      "trainer/Z Expert Targets Std          119.436\n",
      "trainer/Z Expert Targets Max         2018.24\n",
      "trainer/Z Expert Targets Min          684.074\n",
      "trainer/Z Policy Targets Mean        1377.82\n",
      "trainer/Z Policy Targets Std          572.415\n",
      "trainer/Z Policy Targets Max         1865.75\n",
      "trainer/Z Policy Targets Min          -14.0382\n",
      "trainer/Log Pis Mean                   56.9737\n",
      "trainer/Log Pis Std                    25.2353\n",
      "trainer/Policy mu Mean                  0.262526\n",
      "trainer/Policy mu Std                   3.91062\n",
      "trainer/Policy log std Mean            -2.99981\n",
      "trainer/Policy log std Std              1.30616\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        227278\n",
      "exploration/num paths total          1378\n",
      "evaluation/num steps total              1.21209e+06\n",
      "evaluation/num paths total           2267\n",
      "evaluation/path length Mean           921.1\n",
      "evaluation/path length Std            236.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            211\n",
      "evaluation/Rewards Mean                 5.34077\n",
      "evaluation/Rewards Std                  0.0952963\n",
      "evaluation/Rewards Max                  5.931\n",
      "evaluation/Rewards Min                  4.5695\n",
      "evaluation/Returns Mean              4919.38\n",
      "evaluation/Returns Std               1267.12\n",
      "evaluation/Returns Max               5349.96\n",
      "evaluation/Returns Min               1118.03\n",
      "evaluation/Estimation Bias Mean      1700.05\n",
      "evaluation/Estimation Bias Std        246.95\n",
      "evaluation/EB/Q_True Mean              52.3795\n",
      "evaluation/EB/Q_True Std              154.097\n",
      "evaluation/EB/Q_Pred Mean            1752.43\n",
      "evaluation/EB/Q_Pred Std              151.953\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4919.38\n",
      "evaluation/Actions Mean                 0.0796315\n",
      "evaluation/Actions Std                  0.526724\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.1403\n",
      "time/backward_zf1 (s)                   2.79384\n",
      "time/backward_zf2 (s)                   2.59858\n",
      "time/data sampling (s)                  0.485065\n",
      "time/data storing (s)                   0.0188627\n",
      "time/evaluation sampling (s)            2.4996\n",
      "time/exploration sampling (s)           0.548669\n",
      "time/logging (s)                        0.012605\n",
      "time/preback_alpha (s)                  0.686814\n",
      "time/preback_policy (s)                 1.21004\n",
      "time/preback_start (s)                  0.209877\n",
      "time/preback_zf (s)                     7.05366\n",
      "time/saving (s)                         4.08e-06\n",
      "time/training (s)                       3.48362\n",
      "time/epoch (s)                         23.7415\n",
      "time/total (s)                       4631.17\n",
      "Epoch                                 221\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:43:03.807039 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 222 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 233000\n",
      "trainer/ZF1 Loss                     2834.46\n",
      "trainer/ZF2 Loss                     2878.79\n",
      "trainer/ZF Expert Reward               19.2217\n",
      "trainer/ZF Policy Reward               13.2319\n",
      "trainer/ZF CHI2 Term                 2856.97\n",
      "trainer/Policy Loss                 -1355.91\n",
      "trainer/Bias Loss                      52.8104\n",
      "trainer/Bias Value                     15.8154\n",
      "trainer/Policy Grad Norm              258.425\n",
      "trainer/Policy Param Norm              54.6742\n",
      "trainer/Zf1 Grad Norm               33253.5\n",
      "trainer/Zf1 Param Norm                148.423\n",
      "trainer/Zf2 Grad Norm               33133.4\n",
      "trainer/Zf2 Param Norm                146.802\n",
      "trainer/Z Expert Predictions Mean    1891.09\n",
      "trainer/Z Expert Predictions Std       60.448\n",
      "trainer/Z Expert Predictions Max     2051.04\n",
      "trainer/Z Expert Predictions Min     1529.94\n",
      "trainer/Z Policy Predictions Mean    1351.37\n",
      "trainer/Z Policy Predictions Std      588.506\n",
      "trainer/Z Policy Predictions Max     1876.06\n",
      "trainer/Z Policy Predictions Min      -20.6155\n",
      "trainer/Z Expert Targets Mean        1871.87\n",
      "trainer/Z Expert Targets Std           62.2486\n",
      "trainer/Z Expert Targets Max         2050.15\n",
      "trainer/Z Expert Targets Min         1509.23\n",
      "trainer/Z Policy Targets Mean        1338.14\n",
      "trainer/Z Policy Targets Std          594.143\n",
      "trainer/Z Policy Targets Max         1879.03\n",
      "trainer/Z Policy Targets Min          -12.3517\n",
      "trainer/Log Pis Mean                   58.9133\n",
      "trainer/Log Pis Std                    27.7645\n",
      "trainer/Policy mu Mean                  0.192118\n",
      "trainer/Policy mu Std                   3.61805\n",
      "trainer/Policy log std Mean            -2.9777\n",
      "trainer/Policy log std Std              1.27353\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        227278\n",
      "exploration/num paths total          1378\n",
      "evaluation/num steps total              1.22171e+06\n",
      "evaluation/num paths total           2277\n",
      "evaluation/path length Mean           961.5\n",
      "evaluation/path length Std            115.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            615\n",
      "evaluation/Rewards Mean                 5.31723\n",
      "evaluation/Rewards Std                  0.0868698\n",
      "evaluation/Rewards Max                  6.03576\n",
      "evaluation/Rewards Min                  4.79893\n",
      "evaluation/Returns Mean              5112.52\n",
      "evaluation/Returns Std                615.233\n",
      "evaluation/Returns Max               5329.92\n",
      "evaluation/Returns Min               3267.14\n",
      "evaluation/Estimation Bias Mean      1693.38\n",
      "evaluation/Estimation Bias Std        243.905\n",
      "evaluation/EB/Q_True Mean              49.9392\n",
      "evaluation/EB/Q_True Std              150.5\n",
      "evaluation/EB/Q_Pred Mean            1743.32\n",
      "evaluation/EB/Q_Pred Std              145.127\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5112.52\n",
      "evaluation/Actions Mean                 0.0902839\n",
      "evaluation/Actions Std                  0.517891\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.04371\n",
      "time/backward_zf1 (s)                   2.65369\n",
      "time/backward_zf2 (s)                   2.458\n",
      "time/data sampling (s)                  0.476808\n",
      "time/data storing (s)                   0.017621\n",
      "time/evaluation sampling (s)            2.71015\n",
      "time/exploration sampling (s)           0.535102\n",
      "time/logging (s)                        0.0204892\n",
      "time/preback_alpha (s)                  0.677834\n",
      "time/preback_policy (s)                 1.17837\n",
      "time/preback_start (s)                  0.206759\n",
      "time/preback_zf (s)                     7.03225\n",
      "time/saving (s)                         5.513e-06\n",
      "time/training (s)                       3.54664\n",
      "time/epoch (s)                         23.5574\n",
      "time/total (s)                       4654.76\n",
      "Epoch                                 222\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:43:27.575154 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 223 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 234000\n",
      "trainer/ZF1 Loss                     2746.39\n",
      "trainer/ZF2 Loss                     2646.77\n",
      "trainer/ZF Expert Reward               14.4433\n",
      "trainer/ZF Policy Reward               14.3201\n",
      "trainer/ZF CHI2 Term                 2692.23\n",
      "trainer/Policy Loss                 -1389.94\n",
      "trainer/Bias Loss                      39.3235\n",
      "trainer/Bias Value                     15.7992\n",
      "trainer/Policy Grad Norm              293.528\n",
      "trainer/Policy Param Norm              54.7359\n",
      "trainer/Zf1 Grad Norm               36985.8\n",
      "trainer/Zf1 Param Norm                148.746\n",
      "trainer/Zf2 Grad Norm               45227.1\n",
      "trainer/Zf2 Param Norm                147.111\n",
      "trainer/Z Expert Predictions Mean    1879.75\n",
      "trainer/Z Expert Predictions Std       51.6218\n",
      "trainer/Z Expert Predictions Max     2006.91\n",
      "trainer/Z Expert Predictions Min     1627.89\n",
      "trainer/Z Policy Predictions Mean    1384.17\n",
      "trainer/Z Policy Predictions Std      561.605\n",
      "trainer/Z Policy Predictions Max     1861.7\n",
      "trainer/Z Policy Predictions Min       -4.76388\n",
      "trainer/Z Expert Targets Mean        1865.31\n",
      "trainer/Z Expert Targets Std           53.2812\n",
      "trainer/Z Expert Targets Max         1982.77\n",
      "trainer/Z Expert Targets Min         1606.6\n",
      "trainer/Z Policy Targets Mean        1369.85\n",
      "trainer/Z Policy Targets Std          567.049\n",
      "trainer/Z Policy Targets Max         1864.74\n",
      "trainer/Z Policy Targets Min           -3.44656\n",
      "trainer/Log Pis Mean                   57.1149\n",
      "trainer/Log Pis Std                    24.9566\n",
      "trainer/Policy mu Mean                  0.252251\n",
      "trainer/Policy mu Std                   3.72988\n",
      "trainer/Policy log std Mean            -3.0004\n",
      "trainer/Policy log std Std              1.30512\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        229278\n",
      "exploration/num paths total          1380\n",
      "evaluation/num steps total              1.23011e+06\n",
      "evaluation/num paths total           2287\n",
      "evaluation/path length Mean           840.4\n",
      "evaluation/path length Std            304.481\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            116\n",
      "evaluation/Rewards Mean                 5.28285\n",
      "evaluation/Rewards Std                  0.125597\n",
      "evaluation/Rewards Max                  5.84554\n",
      "evaluation/Rewards Min                  3.41939\n",
      "evaluation/Returns Mean              4439.71\n",
      "evaluation/Returns Std               1627.88\n",
      "evaluation/Returns Max               5290.84\n",
      "evaluation/Returns Min                542.285\n",
      "evaluation/Estimation Bias Mean      1646.27\n",
      "evaluation/Estimation Bias Std        316.773\n",
      "evaluation/EB/Q_True Mean              56.8329\n",
      "evaluation/EB/Q_True Std              158.845\n",
      "evaluation/EB/Q_Pred Mean            1703.1\n",
      "evaluation/EB/Q_Pred Std              233.376\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4439.71\n",
      "evaluation/Actions Mean                 0.0715526\n",
      "evaluation/Actions Std                  0.517051\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.16329\n",
      "time/backward_zf1 (s)                   2.77189\n",
      "time/backward_zf2 (s)                   2.63689\n",
      "time/data sampling (s)                  0.486119\n",
      "time/data storing (s)                   0.0173689\n",
      "time/evaluation sampling (s)            2.50862\n",
      "time/exploration sampling (s)           0.537923\n",
      "time/logging (s)                        0.0121868\n",
      "time/preback_alpha (s)                  0.689998\n",
      "time/preback_policy (s)                 1.31792\n",
      "time/preback_start (s)                  0.210202\n",
      "time/preback_zf (s)                     7.11696\n",
      "time/saving (s)                         3.476e-06\n",
      "time/training (s)                       3.20631\n",
      "time/epoch (s)                         23.6757\n",
      "time/total (s)                       4678.46\n",
      "Epoch                                 223\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:43:51.060403 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 224 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 235000\n",
      "trainer/ZF1 Loss                      373.433\n",
      "trainer/ZF2 Loss                      313.067\n",
      "trainer/ZF Expert Reward               13.7131\n",
      "trainer/ZF Policy Reward                9.4678\n",
      "trainer/ZF CHI2 Term                  338.331\n",
      "trainer/Policy Loss                 -1318.58\n",
      "trainer/Bias Loss                      37.7572\n",
      "trainer/Bias Value                     15.7854\n",
      "trainer/Policy Grad Norm              256.055\n",
      "trainer/Policy Param Norm              54.8044\n",
      "trainer/Zf1 Grad Norm               19609.8\n",
      "trainer/Zf1 Param Norm                149.056\n",
      "trainer/Zf2 Grad Norm               17695.7\n",
      "trainer/Zf2 Param Norm                147.41\n",
      "trainer/Z Expert Predictions Mean    1868.54\n",
      "trainer/Z Expert Predictions Std       61.3875\n",
      "trainer/Z Expert Predictions Max     2036.44\n",
      "trainer/Z Expert Predictions Min     1610.18\n",
      "trainer/Z Policy Predictions Mean    1307.09\n",
      "trainer/Z Policy Predictions Std      584.561\n",
      "trainer/Z Policy Predictions Max     1847.04\n",
      "trainer/Z Policy Predictions Min      -26.5269\n",
      "trainer/Z Expert Targets Mean        1854.83\n",
      "trainer/Z Expert Targets Std           60.4053\n",
      "trainer/Z Expert Targets Max         2005.64\n",
      "trainer/Z Expert Targets Min         1608.74\n",
      "trainer/Z Policy Targets Mean        1297.62\n",
      "trainer/Z Policy Targets Std          588.618\n",
      "trainer/Z Policy Targets Max         1837.84\n",
      "trainer/Z Policy Targets Min          -38.5847\n",
      "trainer/Log Pis Mean                   60.1954\n",
      "trainer/Log Pis Std                    28.9053\n",
      "trainer/Policy mu Mean                  0.333837\n",
      "trainer/Policy mu Std                   3.38121\n",
      "trainer/Policy log std Mean            -2.88963\n",
      "trainer/Policy log std Std              1.24389\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        230278\n",
      "exploration/num paths total          1381\n",
      "evaluation/num steps total              1.23841e+06\n",
      "evaluation/num paths total           2298\n",
      "evaluation/path length Mean           754.091\n",
      "evaluation/path length Std            358.329\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             90\n",
      "evaluation/Rewards Mean                 5.28992\n",
      "evaluation/Rewards Std                  0.123027\n",
      "evaluation/Rewards Max                  6.30768\n",
      "evaluation/Rewards Min                  3.95352\n",
      "evaluation/Returns Mean              3989.08\n",
      "evaluation/Returns Std               1907.59\n",
      "evaluation/Returns Max               5304.39\n",
      "evaluation/Returns Min                470.887\n",
      "evaluation/Estimation Bias Mean      1650.91\n",
      "evaluation/Estimation Bias Std        330.499\n",
      "evaluation/EB/Q_True Mean              57.6742\n",
      "evaluation/EB/Q_True Std              160.02\n",
      "evaluation/EB/Q_Pred Mean            1708.58\n",
      "evaluation/EB/Q_Pred Std              235.415\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3989.08\n",
      "evaluation/Actions Mean                 0.0916796\n",
      "evaluation/Actions Std                  0.523503\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.08384\n",
      "time/backward_zf1 (s)                   2.68746\n",
      "time/backward_zf2 (s)                   2.53643\n",
      "time/data sampling (s)                  0.484499\n",
      "time/data storing (s)                   0.0160769\n",
      "time/evaluation sampling (s)            2.63284\n",
      "time/exploration sampling (s)           0.533383\n",
      "time/logging (s)                        0.0127836\n",
      "time/preback_alpha (s)                  0.668486\n",
      "time/preback_policy (s)                 1.2263\n",
      "time/preback_start (s)                  0.203091\n",
      "time/preback_zf (s)                     6.96141\n",
      "time/saving (s)                         3.279e-06\n",
      "time/training (s)                       3.35013\n",
      "time/epoch (s)                         23.3967\n",
      "time/total (s)                       4701.89\n",
      "Epoch                                 224\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:44:14.561908 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 225 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 236000\n",
      "trainer/ZF1 Loss                      358.03\n",
      "trainer/ZF2 Loss                      387.044\n",
      "trainer/ZF Expert Reward               13.1969\n",
      "trainer/ZF Policy Reward                5.33193\n",
      "trainer/ZF CHI2 Term                  367.122\n",
      "trainer/Policy Loss                 -1386.17\n",
      "trainer/Bias Loss                      40.6455\n",
      "trainer/Bias Value                     15.7702\n",
      "trainer/Policy Grad Norm              238.524\n",
      "trainer/Policy Param Norm              54.8725\n",
      "trainer/Zf1 Grad Norm               16837.5\n",
      "trainer/Zf1 Param Norm                149.362\n",
      "trainer/Zf2 Grad Norm               21352.6\n",
      "trainer/Zf2 Param Norm                147.712\n",
      "trainer/Z Expert Predictions Mean    1865.14\n",
      "trainer/Z Expert Predictions Std       59.7174\n",
      "trainer/Z Expert Predictions Max     2031.79\n",
      "trainer/Z Expert Predictions Min     1643.06\n",
      "trainer/Z Policy Predictions Mean    1374.51\n",
      "trainer/Z Policy Predictions Std      546.269\n",
      "trainer/Z Policy Predictions Max     1851.57\n",
      "trainer/Z Policy Predictions Min       -4.86327\n",
      "trainer/Z Expert Targets Mean        1851.95\n",
      "trainer/Z Expert Targets Std           59.5777\n",
      "trainer/Z Expert Targets Max         2004.77\n",
      "trainer/Z Expert Targets Min         1614.58\n",
      "trainer/Z Policy Targets Mean        1369.18\n",
      "trainer/Z Policy Targets Std          548.144\n",
      "trainer/Z Policy Targets Max         1805.15\n",
      "trainer/Z Policy Targets Min           -1.32296\n",
      "trainer/Log Pis Mean                   57.1\n",
      "trainer/Log Pis Std                    24.6375\n",
      "trainer/Policy mu Mean                  0.390245\n",
      "trainer/Policy mu Std                   3.08033\n",
      "trainer/Policy log std Mean            -3.02249\n",
      "trainer/Policy log std Std              1.21512\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        230278\n",
      "exploration/num paths total          1381\n",
      "evaluation/num steps total              1.24724e+06\n",
      "evaluation/num paths total           2309\n",
      "evaluation/path length Mean           802.818\n",
      "evaluation/path length Std            322.321\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            115\n",
      "evaluation/Rewards Mean                 5.29756\n",
      "evaluation/Rewards Std                  0.10528\n",
      "evaluation/Rewards Max                  6.13498\n",
      "evaluation/Rewards Min                  4.85363\n",
      "evaluation/Returns Mean              4252.98\n",
      "evaluation/Returns Std               1704.65\n",
      "evaluation/Returns Max               5301.24\n",
      "evaluation/Returns Min                615.389\n",
      "evaluation/Estimation Bias Mean      1585.46\n",
      "evaluation/Estimation Bias Std        349.609\n",
      "evaluation/EB/Q_True Mean              54.1524\n",
      "evaluation/EB/Q_True Std              155.635\n",
      "evaluation/EB/Q_Pred Mean            1639.62\n",
      "evaluation/EB/Q_Pred Std              293.182\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4252.98\n",
      "evaluation/Actions Mean                 0.0884305\n",
      "evaluation/Actions Std                  0.53164\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.14686\n",
      "time/backward_zf1 (s)                   2.69877\n",
      "time/backward_zf2 (s)                   2.54657\n",
      "time/data sampling (s)                  0.506735\n",
      "time/data storing (s)                   0.0170767\n",
      "time/evaluation sampling (s)            2.48182\n",
      "time/exploration sampling (s)           0.536766\n",
      "time/logging (s)                        0.0143638\n",
      "time/preback_alpha (s)                  0.683396\n",
      "time/preback_policy (s)                 1.23939\n",
      "time/preback_start (s)                  0.206593\n",
      "time/preback_zf (s)                     7.01843\n",
      "time/saving (s)                         2.936e-06\n",
      "time/training (s)                       3.32257\n",
      "time/epoch (s)                         23.4194\n",
      "time/total (s)                       4725.33\n",
      "Epoch                                 225\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:44:38.312446 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 226 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 237000\n",
      "trainer/ZF1 Loss                      263.973\n",
      "trainer/ZF2 Loss                      300.635\n",
      "trainer/ZF Expert Reward               17.9867\n",
      "trainer/ZF Policy Reward                7.59518\n",
      "trainer/ZF CHI2 Term                  281.683\n",
      "trainer/Policy Loss                 -1381.05\n",
      "trainer/Bias Loss                      35.4572\n",
      "trainer/Bias Value                     15.7531\n",
      "trainer/Policy Grad Norm              297.071\n",
      "trainer/Policy Param Norm              54.9364\n",
      "trainer/Zf1 Grad Norm               15333.4\n",
      "trainer/Zf1 Param Norm                149.696\n",
      "trainer/Zf2 Grad Norm               22661.6\n",
      "trainer/Zf2 Param Norm                148.009\n",
      "trainer/Z Expert Predictions Mean    1863.49\n",
      "trainer/Z Expert Predictions Std       56.69\n",
      "trainer/Z Expert Predictions Max     1990.27\n",
      "trainer/Z Expert Predictions Min     1638.72\n",
      "trainer/Z Policy Predictions Mean    1372.52\n",
      "trainer/Z Policy Predictions Std      541.255\n",
      "trainer/Z Policy Predictions Max     1865.3\n",
      "trainer/Z Policy Predictions Min       -0.964936\n",
      "trainer/Z Expert Targets Mean        1845.5\n",
      "trainer/Z Expert Targets Std           57.079\n",
      "trainer/Z Expert Targets Max         1982.47\n",
      "trainer/Z Expert Targets Min         1619.52\n",
      "trainer/Z Policy Targets Mean        1364.93\n",
      "trainer/Z Policy Targets Std          538.939\n",
      "trainer/Z Policy Targets Max         1850.42\n",
      "trainer/Z Policy Targets Min           -7.51714\n",
      "trainer/Log Pis Mean                   55.6864\n",
      "trainer/Log Pis Std                    23.1096\n",
      "trainer/Policy mu Mean                  0.322015\n",
      "trainer/Policy mu Std                   3.32608\n",
      "trainer/Policy log std Mean            -2.95769\n",
      "trainer/Policy log std Std              1.27353\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        231278\n",
      "exploration/num paths total          1382\n",
      "evaluation/num steps total              1.25477e+06\n",
      "evaluation/num paths total           2319\n",
      "evaluation/path length Mean           753.2\n",
      "evaluation/path length Std            249.138\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            273\n",
      "evaluation/Rewards Mean                 5.2418\n",
      "evaluation/Rewards Std                  0.133768\n",
      "evaluation/Rewards Max                  5.62303\n",
      "evaluation/Rewards Min                  3.85315\n",
      "evaluation/Returns Mean              3948.12\n",
      "evaluation/Returns Std               1324.65\n",
      "evaluation/Returns Max               5277.36\n",
      "evaluation/Returns Min               1402.78\n",
      "evaluation/Estimation Bias Mean      1505.93\n",
      "evaluation/Estimation Bias Std        355.577\n",
      "evaluation/EB/Q_True Mean              63.0347\n",
      "evaluation/EB/Q_True Std              165.561\n",
      "evaluation/EB/Q_Pred Mean            1568.96\n",
      "evaluation/EB/Q_Pred Std              289.357\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3948.12\n",
      "evaluation/Actions Mean                 0.0902334\n",
      "evaluation/Actions Std                  0.555218\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.22081\n",
      "time/backward_zf1 (s)                   2.77032\n",
      "time/backward_zf2 (s)                   2.63789\n",
      "time/data sampling (s)                  0.488232\n",
      "time/data storing (s)                   0.0191254\n",
      "time/evaluation sampling (s)            2.68021\n",
      "time/exploration sampling (s)           0.546023\n",
      "time/logging (s)                        0.0104426\n",
      "time/preback_alpha (s)                  0.676071\n",
      "time/preback_policy (s)                 1.30317\n",
      "time/preback_start (s)                  0.207459\n",
      "time/preback_zf (s)                     7.01815\n",
      "time/saving (s)                         2.918e-06\n",
      "time/training (s)                       3.08953\n",
      "time/epoch (s)                         23.6674\n",
      "time/total (s)                       4749.02\n",
      "Epoch                                 226\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:45:02.601039 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 227 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 238000\n",
      "trainer/ZF1 Loss                      310.127\n",
      "trainer/ZF2 Loss                      274.103\n",
      "trainer/ZF Expert Reward               18.345\n",
      "trainer/ZF Policy Reward                9.14512\n",
      "trainer/ZF CHI2 Term                  291.987\n",
      "trainer/Policy Loss                 -1322.14\n",
      "trainer/Bias Loss                      40.6948\n",
      "trainer/Bias Value                     15.741\n",
      "trainer/Policy Grad Norm              266.287\n",
      "trainer/Policy Param Norm              54.998\n",
      "trainer/Zf1 Grad Norm               14283\n",
      "trainer/Zf1 Param Norm                149.967\n",
      "trainer/Zf2 Grad Norm               10599.2\n",
      "trainer/Zf2 Param Norm                148.295\n",
      "trainer/Z Expert Predictions Mean    1849.68\n",
      "trainer/Z Expert Predictions Std       59.0214\n",
      "trainer/Z Expert Predictions Max     1970.55\n",
      "trainer/Z Expert Predictions Min     1590.5\n",
      "trainer/Z Policy Predictions Mean    1315.93\n",
      "trainer/Z Policy Predictions Std      601.094\n",
      "trainer/Z Policy Predictions Max     1862.55\n",
      "trainer/Z Policy Predictions Min      -16.1738\n",
      "trainer/Z Expert Targets Mean        1831.33\n",
      "trainer/Z Expert Targets Std           60.1415\n",
      "trainer/Z Expert Targets Max         1964\n",
      "trainer/Z Expert Targets Min         1564.5\n",
      "trainer/Z Policy Targets Mean        1306.78\n",
      "trainer/Z Policy Targets Std          602.634\n",
      "trainer/Z Policy Targets Max         1842.45\n",
      "trainer/Z Policy Targets Min          -17.364\n",
      "trainer/Log Pis Mean                   58.353\n",
      "trainer/Log Pis Std                    27.4293\n",
      "trainer/Policy mu Mean                  0.293873\n",
      "trainer/Policy mu Std                   3.71986\n",
      "trainer/Policy log std Mean            -2.85491\n",
      "trainer/Policy log std Std              1.3306\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        234278\n",
      "exploration/num paths total          1385\n",
      "evaluation/num steps total              1.26234e+06\n",
      "evaluation/num paths total           2329\n",
      "evaluation/path length Mean           756.6\n",
      "evaluation/path length Std            305.868\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            206\n",
      "evaluation/Rewards Mean                 5.26767\n",
      "evaluation/Rewards Std                  0.110908\n",
      "evaluation/Rewards Max                  6.21282\n",
      "evaluation/Rewards Min                  4.56599\n",
      "evaluation/Returns Mean              3985.52\n",
      "evaluation/Returns Std               1621.39\n",
      "evaluation/Returns Max               5292.12\n",
      "evaluation/Returns Min               1085.79\n",
      "evaluation/Estimation Bias Mean      1550.46\n",
      "evaluation/Estimation Bias Std        385.854\n",
      "evaluation/EB/Q_True Mean              63.1247\n",
      "evaluation/EB/Q_True Std              166.203\n",
      "evaluation/EB/Q_Pred Mean            1613.59\n",
      "evaluation/EB/Q_Pred Std              297.958\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3985.52\n",
      "evaluation/Actions Mean                 0.0801143\n",
      "evaluation/Actions Std                  0.521156\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.2797\n",
      "time/backward_zf1 (s)                   2.90396\n",
      "time/backward_zf2 (s)                   2.74314\n",
      "time/data sampling (s)                  0.503848\n",
      "time/data storing (s)                   0.0169689\n",
      "time/evaluation sampling (s)            2.62991\n",
      "time/exploration sampling (s)           0.560229\n",
      "time/logging (s)                        0.0111956\n",
      "time/preback_alpha (s)                  0.707614\n",
      "time/preback_policy (s)                 1.33157\n",
      "time/preback_start (s)                  0.214469\n",
      "time/preback_zf (s)                     7.12844\n",
      "time/saving (s)                         3.896e-06\n",
      "time/training (s)                       3.1795\n",
      "time/epoch (s)                         24.2106\n",
      "time/total (s)                       4773.25\n",
      "Epoch                                 227\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:45:26.368671 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 228 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 239000\n",
      "trainer/ZF1 Loss                      724.974\n",
      "trainer/ZF2 Loss                      704.265\n",
      "trainer/ZF Expert Reward                7.19441\n",
      "trainer/ZF Policy Reward                4.86465\n",
      "trainer/ZF CHI2 Term                  703.657\n",
      "trainer/Policy Loss                 -1426.21\n",
      "trainer/Bias Loss                      94.0373\n",
      "trainer/Bias Value                     15.7262\n",
      "trainer/Policy Grad Norm              251.318\n",
      "trainer/Policy Param Norm              55.0638\n",
      "trainer/Zf1 Grad Norm               30726.6\n",
      "trainer/Zf1 Param Norm                150.273\n",
      "trainer/Zf2 Grad Norm               28013.7\n",
      "trainer/Zf2 Param Norm                148.596\n",
      "trainer/Z Expert Predictions Mean    1814.21\n",
      "trainer/Z Expert Predictions Std      136.094\n",
      "trainer/Z Expert Predictions Max     1960.56\n",
      "trainer/Z Expert Predictions Min       -0.286707\n",
      "trainer/Z Policy Predictions Mean    1411.17\n",
      "trainer/Z Policy Predictions Std      494.86\n",
      "trainer/Z Policy Predictions Max     1792.88\n",
      "trainer/Z Policy Predictions Min       -7.02844\n",
      "trainer/Z Expert Targets Mean        1807.02\n",
      "trainer/Z Expert Targets Std          137.613\n",
      "trainer/Z Expert Targets Max         1968.32\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1406.3\n",
      "trainer/Z Policy Targets Std          496.894\n",
      "trainer/Z Policy Targets Max         1819.73\n",
      "trainer/Z Policy Targets Min          -11.7224\n",
      "trainer/Log Pis Mean                   54.795\n",
      "trainer/Log Pis Std                    23.7715\n",
      "trainer/Policy mu Mean                  0.247462\n",
      "trainer/Policy mu Std                   2.86559\n",
      "trainer/Policy log std Mean            -3.14311\n",
      "trainer/Policy log std Std              1.07639\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        234278\n",
      "exploration/num paths total          1385\n",
      "evaluation/num steps total              1.27069e+06\n",
      "evaluation/num paths total           2340\n",
      "evaluation/path length Mean           759.364\n",
      "evaluation/path length Std            284.012\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            220\n",
      "evaluation/Rewards Mean                 5.29924\n",
      "evaluation/Rewards Std                  0.106177\n",
      "evaluation/Rewards Max                  5.79882\n",
      "evaluation/Rewards Min                  4.30131\n",
      "evaluation/Returns Mean              4024.05\n",
      "evaluation/Returns Std               1520.02\n",
      "evaluation/Returns Max               5314.58\n",
      "evaluation/Returns Min               1120.12\n",
      "evaluation/Estimation Bias Mean      1531.96\n",
      "evaluation/Estimation Bias Std        349.751\n",
      "evaluation/EB/Q_True Mean              57.331\n",
      "evaluation/EB/Q_True Std              159.72\n",
      "evaluation/EB/Q_Pred Mean            1589.29\n",
      "evaluation/EB/Q_Pred Std              275.098\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4024.05\n",
      "evaluation/Actions Mean                 0.103118\n",
      "evaluation/Actions Std                  0.549701\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.11459\n",
      "time/backward_zf1 (s)                   2.77331\n",
      "time/backward_zf2 (s)                   2.58633\n",
      "time/data sampling (s)                  0.472185\n",
      "time/data storing (s)                   0.0176196\n",
      "time/evaluation sampling (s)            2.60848\n",
      "time/exploration sampling (s)           0.527767\n",
      "time/logging (s)                        0.0120093\n",
      "time/preback_alpha (s)                  0.678954\n",
      "time/preback_policy (s)                 1.21792\n",
      "time/preback_start (s)                  0.204709\n",
      "time/preback_zf (s)                     7.07918\n",
      "time/saving (s)                         3.563e-06\n",
      "time/training (s)                       3.39702\n",
      "time/epoch (s)                         23.6901\n",
      "time/total (s)                       4796.97\n",
      "Epoch                                 228\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:45:48.912984 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 229 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 240000\n",
      "trainer/ZF1 Loss                      364.041\n",
      "trainer/ZF2 Loss                      347.94\n",
      "trainer/ZF Expert Reward                8.41844\n",
      "trainer/ZF Policy Reward                5.20899\n",
      "trainer/ZF CHI2 Term                  346.229\n",
      "trainer/Policy Loss                 -1314.3\n",
      "trainer/Bias Loss                      77.3183\n",
      "trainer/Bias Value                     15.7136\n",
      "trainer/Policy Grad Norm              253.059\n",
      "trainer/Policy Param Norm              55.1338\n",
      "trainer/Zf1 Grad Norm               21826\n",
      "trainer/Zf1 Param Norm                150.584\n",
      "trainer/Zf2 Grad Norm               18465.4\n",
      "trainer/Zf2 Param Norm                148.899\n",
      "trainer/Z Expert Predictions Mean    1823.04\n",
      "trainer/Z Expert Predictions Std       56.8237\n",
      "trainer/Z Expert Predictions Max     1982.64\n",
      "trainer/Z Expert Predictions Min     1661.98\n",
      "trainer/Z Policy Predictions Mean    1307.74\n",
      "trainer/Z Policy Predictions Std      558.315\n",
      "trainer/Z Policy Predictions Max     1810.38\n",
      "trainer/Z Policy Predictions Min      -33.7207\n",
      "trainer/Z Expert Targets Mean        1814.62\n",
      "trainer/Z Expert Targets Std           56.4868\n",
      "trainer/Z Expert Targets Max         1965.85\n",
      "trainer/Z Expert Targets Min         1662.19\n",
      "trainer/Z Policy Targets Mean        1302.54\n",
      "trainer/Z Policy Targets Std          559.433\n",
      "trainer/Z Policy Targets Max         1788.55\n",
      "trainer/Z Policy Targets Min          -35.0567\n",
      "trainer/Log Pis Mean                   57.1835\n",
      "trainer/Log Pis Std                    27.8664\n",
      "trainer/Policy mu Mean                  0.339897\n",
      "trainer/Policy mu Std                   3.80738\n",
      "trainer/Policy log std Mean            -2.83007\n",
      "trainer/Policy log std Std              1.28389\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        235278\n",
      "exploration/num paths total          1386\n",
      "evaluation/num steps total              1.2736e+06\n",
      "evaluation/num paths total           2350\n",
      "evaluation/path length Mean           291.3\n",
      "evaluation/path length Std            128.557\n",
      "evaluation/path length Max            524\n",
      "evaluation/path length Min            138\n",
      "evaluation/Rewards Mean                 5.27974\n",
      "evaluation/Rewards Std                  0.157076\n",
      "evaluation/Rewards Max                  6.36971\n",
      "evaluation/Rewards Min                  4.83153\n",
      "evaluation/Returns Mean              1537.99\n",
      "evaluation/Returns Std                688.222\n",
      "evaluation/Returns Max               2787.3\n",
      "evaluation/Returns Min                713.742\n",
      "evaluation/Estimation Bias Mean      1238.32\n",
      "evaluation/Estimation Bias Std        528.415\n",
      "evaluation/EB/Q_True Mean              63.3888\n",
      "evaluation/EB/Q_True Std              147.344\n",
      "evaluation/EB/Q_Pred Mean            1301.71\n",
      "evaluation/EB/Q_Pred Std              498.805\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1537.99\n",
      "evaluation/Actions Mean                 0.100254\n",
      "evaluation/Actions Std                  0.643259\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.12149\n",
      "time/backward_zf1 (s)                   2.74451\n",
      "time/backward_zf2 (s)                   2.55082\n",
      "time/data sampling (s)                  0.475838\n",
      "time/data storing (s)                   0.0175194\n",
      "time/evaluation sampling (s)            1.50124\n",
      "time/exploration sampling (s)           0.543246\n",
      "time/logging (s)                        0.0047155\n",
      "time/preback_alpha (s)                  0.67046\n",
      "time/preback_policy (s)                 1.20229\n",
      "time/preback_start (s)                  0.202429\n",
      "time/preback_zf (s)                     7.01459\n",
      "time/saving (s)                         3.326e-06\n",
      "time/training (s)                       3.40756\n",
      "time/epoch (s)                         22.4567\n",
      "time/total (s)                       4819.45\n",
      "Epoch                                 229\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 21:46:12.275973 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 230 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 241000\n",
      "trainer/ZF1 Loss                      306.611\n",
      "trainer/ZF2 Loss                      316.606\n",
      "trainer/ZF Expert Reward               11.9983\n",
      "trainer/ZF Policy Reward                8.15949\n",
      "trainer/ZF CHI2 Term                  305.479\n",
      "trainer/Policy Loss                 -1305.18\n",
      "trainer/Bias Loss                      37.3564\n",
      "trainer/Bias Value                     15.6938\n",
      "trainer/Policy Grad Norm              272.957\n",
      "trainer/Policy Param Norm              55.2025\n",
      "trainer/Zf1 Grad Norm               16883.4\n",
      "trainer/Zf1 Param Norm                150.915\n",
      "trainer/Zf2 Grad Norm               18699.5\n",
      "trainer/Zf2 Param Norm                149.201\n",
      "trainer/Z Expert Predictions Mean    1810.89\n",
      "trainer/Z Expert Predictions Std      124.185\n",
      "trainer/Z Expert Predictions Max     1950.57\n",
      "trainer/Z Expert Predictions Min       27.4088\n",
      "trainer/Z Policy Predictions Mean    1293.02\n",
      "trainer/Z Policy Predictions Std      563.865\n",
      "trainer/Z Policy Predictions Max     1817.89\n",
      "trainer/Z Policy Predictions Min       -3.99893\n",
      "trainer/Z Expert Targets Mean        1798.89\n",
      "trainer/Z Expert Targets Std          125.925\n",
      "trainer/Z Expert Targets Max         1952.71\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1284.86\n",
      "trainer/Z Policy Targets Std          564.667\n",
      "trainer/Z Policy Targets Max         1843.17\n",
      "trainer/Z Policy Targets Min          -15.3815\n",
      "trainer/Log Pis Mean                   59.3927\n",
      "trainer/Log Pis Std                    27.5906\n",
      "trainer/Policy mu Mean                  0.491081\n",
      "trainer/Policy mu Std                   3.4559\n",
      "trainer/Policy log std Mean            -2.86635\n",
      "trainer/Policy log std Std              1.29258\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        236278\n",
      "exploration/num paths total          1387\n",
      "evaluation/num steps total              1.27704e+06\n",
      "evaluation/num paths total           2360\n",
      "evaluation/path length Mean           343.9\n",
      "evaluation/path length Std            203.474\n",
      "evaluation/path length Max            867\n",
      "evaluation/path length Min            127\n",
      "evaluation/Rewards Mean                 5.23111\n",
      "evaluation/Rewards Std                  0.225102\n",
      "evaluation/Rewards Max                  5.72055\n",
      "evaluation/Rewards Min                  3.34906\n",
      "evaluation/Returns Mean              1798.98\n",
      "evaluation/Returns Std               1070.8\n",
      "evaluation/Returns Max               4550.41\n",
      "evaluation/Returns Min                646.212\n",
      "evaluation/Estimation Bias Mean      1293.02\n",
      "evaluation/Estimation Bias Std        523.305\n",
      "evaluation/EB/Q_True Mean             105.859\n",
      "evaluation/EB/Q_True Std              196.45\n",
      "evaluation/EB/Q_Pred Mean            1398.88\n",
      "evaluation/EB/Q_Pred Std              485.822\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1798.98\n",
      "evaluation/Actions Mean                 0.0850524\n",
      "evaluation/Actions Std                  0.604038\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.13938\n",
      "time/backward_zf1 (s)                   2.73895\n",
      "time/backward_zf2 (s)                   2.54179\n",
      "time/data sampling (s)                  0.467549\n",
      "time/data storing (s)                   0.0179597\n",
      "time/evaluation sampling (s)            2.21154\n",
      "time/exploration sampling (s)           0.540946\n",
      "time/logging (s)                        0.00580473\n",
      "time/preback_alpha (s)                  0.679392\n",
      "time/preback_policy (s)                 1.21906\n",
      "time/preback_start (s)                  0.210451\n",
      "time/preback_zf (s)                     7.05382\n",
      "time/saving (s)                         2.483e-06\n",
      "time/training (s)                       3.46201\n",
      "time/epoch (s)                         23.2886\n",
      "time/total (s)                       4842.75\n",
      "Epoch                                 230\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:46:36.053186 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 231 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 242000\n",
      "trainer/ZF1 Loss                      314.296\n",
      "trainer/ZF2 Loss                      303.156\n",
      "trainer/ZF Expert Reward               19.1372\n",
      "trainer/ZF Policy Reward               12.007\n",
      "trainer/ZF CHI2 Term                  309.674\n",
      "trainer/Policy Loss                 -1356.81\n",
      "trainer/Bias Loss                      42.6328\n",
      "trainer/Bias Value                     15.6794\n",
      "trainer/Policy Grad Norm              273.455\n",
      "trainer/Policy Param Norm              55.2766\n",
      "trainer/Zf1 Grad Norm               15353.8\n",
      "trainer/Zf1 Param Norm                151.225\n",
      "trainer/Zf2 Grad Norm               13886.6\n",
      "trainer/Zf2 Param Norm                149.472\n",
      "trainer/Z Expert Predictions Mean    1819.19\n",
      "trainer/Z Expert Predictions Std       58.0392\n",
      "trainer/Z Expert Predictions Max     1966.37\n",
      "trainer/Z Expert Predictions Min     1639.43\n",
      "trainer/Z Policy Predictions Mean    1349.06\n",
      "trainer/Z Policy Predictions Std      508.477\n",
      "trainer/Z Policy Predictions Max     1790.98\n",
      "trainer/Z Policy Predictions Min      -35.2783\n",
      "trainer/Z Expert Targets Mean        1800.05\n",
      "trainer/Z Expert Targets Std           58.6627\n",
      "trainer/Z Expert Targets Max         1944.35\n",
      "trainer/Z Expert Targets Min         1618.35\n",
      "trainer/Z Policy Targets Mean        1337.06\n",
      "trainer/Z Policy Targets Std          508.199\n",
      "trainer/Z Policy Targets Max         1767.88\n",
      "trainer/Z Policy Targets Min          -15.1611\n",
      "trainer/Log Pis Mean                   55.893\n",
      "trainer/Log Pis Std                    24.6327\n",
      "trainer/Policy mu Mean                  0.336121\n",
      "trainer/Policy mu Std                   3.10552\n",
      "trainer/Policy log std Mean            -3.03562\n",
      "trainer/Policy log std Std              1.12345\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        237278\n",
      "exploration/num paths total          1388\n",
      "evaluation/num steps total              1.28704e+06\n",
      "evaluation/num paths total           2370\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29758\n",
      "evaluation/Rewards Std                  0.0842706\n",
      "evaluation/Rewards Max                  5.56195\n",
      "evaluation/Rewards Min                  4.79412\n",
      "evaluation/Returns Mean              5297.58\n",
      "evaluation/Returns Std                  5.73833\n",
      "evaluation/Returns Max               5304.56\n",
      "evaluation/Returns Min               5283.02\n",
      "evaluation/Estimation Bias Mean      1626.47\n",
      "evaluation/Estimation Bias Std        175.453\n",
      "evaluation/EB/Q_True Mean              47.9066\n",
      "evaluation/EB/Q_True Std              147.543\n",
      "evaluation/EB/Q_Pred Mean            1674.38\n",
      "evaluation/EB/Q_Pred Std               90.5893\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5297.58\n",
      "evaluation/Actions Mean                 0.0719549\n",
      "evaluation/Actions Std                  0.506017\n",
      "evaluation/Actions Max                  0.999959\n",
      "evaluation/Actions Min                 -0.9991\n",
      "time/backward_policy (s)                2.21168\n",
      "time/backward_zf1 (s)                   2.86723\n",
      "time/backward_zf2 (s)                   2.68382\n",
      "time/data sampling (s)                  0.426254\n",
      "time/data storing (s)                   0.0182457\n",
      "time/evaluation sampling (s)            2.55392\n",
      "time/exploration sampling (s)           0.531685\n",
      "time/logging (s)                        0.0139296\n",
      "time/preback_alpha (s)                  0.676526\n",
      "time/preback_policy (s)                 1.30163\n",
      "time/preback_start (s)                  0.209429\n",
      "time/preback_zf (s)                     7.03756\n",
      "time/saving (s)                         3.958e-06\n",
      "time/training (s)                       3.17167\n",
      "time/epoch (s)                         23.7036\n",
      "time/total (s)                       4866.48\n",
      "Epoch                                 231\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:47:00.358000 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 232 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 243000\n",
      "trainer/ZF1 Loss                      336.632\n",
      "trainer/ZF2 Loss                      387.725\n",
      "trainer/ZF Expert Reward               12.9975\n",
      "trainer/ZF Policy Reward                6.79571\n",
      "trainer/ZF CHI2 Term                  357.175\n",
      "trainer/Policy Loss                 -1344.62\n",
      "trainer/Bias Loss                      42.66\n",
      "trainer/Bias Value                     15.6653\n",
      "trainer/Policy Grad Norm              225.779\n",
      "trainer/Policy Param Norm              55.3527\n",
      "trainer/Zf1 Grad Norm               13389.4\n",
      "trainer/Zf1 Param Norm                151.508\n",
      "trainer/Zf2 Grad Norm               19932.7\n",
      "trainer/Zf2 Param Norm                149.762\n",
      "trainer/Z Expert Predictions Mean    1796.39\n",
      "trainer/Z Expert Predictions Std       90.1413\n",
      "trainer/Z Expert Predictions Max     1964.63\n",
      "trainer/Z Expert Predictions Min      794.111\n",
      "trainer/Z Policy Predictions Mean    1335.07\n",
      "trainer/Z Policy Predictions Std      516.149\n",
      "trainer/Z Policy Predictions Max     1783.93\n",
      "trainer/Z Policy Predictions Min      -18.3763\n",
      "trainer/Z Expert Targets Mean        1783.39\n",
      "trainer/Z Expert Targets Std           87.633\n",
      "trainer/Z Expert Targets Max         1938.77\n",
      "trainer/Z Expert Targets Min          803.775\n",
      "trainer/Z Policy Targets Mean        1328.28\n",
      "trainer/Z Policy Targets Std          516.281\n",
      "trainer/Z Policy Targets Max         1786.19\n",
      "trainer/Z Policy Targets Min           -7.0388\n",
      "trainer/Log Pis Mean                   57.1921\n",
      "trainer/Log Pis Std                    26.75\n",
      "trainer/Policy mu Mean                  0.223284\n",
      "trainer/Policy mu Std                   3.47864\n",
      "trainer/Policy log std Mean            -3.03025\n",
      "trainer/Policy log std Std              1.19625\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        237278\n",
      "exploration/num paths total          1388\n",
      "evaluation/num steps total              1.29704e+06\n",
      "evaluation/num paths total           2380\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30142\n",
      "evaluation/Rewards Std                  0.0808186\n",
      "evaluation/Rewards Max                  5.50773\n",
      "evaluation/Rewards Min                  4.79228\n",
      "evaluation/Returns Mean              5301.42\n",
      "evaluation/Returns Std                  7.13894\n",
      "evaluation/Returns Max               5317.08\n",
      "evaluation/Returns Min               5288.26\n",
      "evaluation/Estimation Bias Mean      1646.67\n",
      "evaluation/Estimation Bias Std        164.905\n",
      "evaluation/EB/Q_True Mean              47.8398\n",
      "evaluation/EB/Q_True Std              147.35\n",
      "evaluation/EB/Q_Pred Mean            1694.51\n",
      "evaluation/EB/Q_Pred Std               71.0571\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5301.42\n",
      "evaluation/Actions Mean                 0.0731918\n",
      "evaluation/Actions Std                  0.499023\n",
      "evaluation/Actions Max                  0.999971\n",
      "evaluation/Actions Min                 -0.997925\n",
      "time/backward_policy (s)                2.28387\n",
      "time/backward_zf1 (s)                   2.94206\n",
      "time/backward_zf2 (s)                   2.75964\n",
      "time/data sampling (s)                  0.513625\n",
      "time/data storing (s)                   0.0177128\n",
      "time/evaluation sampling (s)            2.61477\n",
      "time/exploration sampling (s)           0.525747\n",
      "time/logging (s)                        0.012836\n",
      "time/preback_alpha (s)                  0.699395\n",
      "time/preback_policy (s)                 1.34577\n",
      "time/preback_start (s)                  0.215368\n",
      "time/preback_zf (s)                     7.12047\n",
      "time/saving (s)                         3.159e-06\n",
      "time/training (s)                       3.16634\n",
      "time/epoch (s)                         24.2176\n",
      "time/total (s)                       4890.72\n",
      "Epoch                                 232\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:47:23.836659 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 233 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 244000\n",
      "trainer/ZF1 Loss                      293.829\n",
      "trainer/ZF2 Loss                      272.945\n",
      "trainer/ZF Expert Reward               15.22\n",
      "trainer/ZF Policy Reward               10.959\n",
      "trainer/ZF CHI2 Term                  280.711\n",
      "trainer/Policy Loss                 -1314.82\n",
      "trainer/Bias Loss                      25.1633\n",
      "trainer/Bias Value                     15.6512\n",
      "trainer/Policy Grad Norm              271.403\n",
      "trainer/Policy Param Norm              55.4142\n",
      "trainer/Zf1 Grad Norm               13777.4\n",
      "trainer/Zf1 Param Norm                151.841\n",
      "trainer/Zf2 Grad Norm               15153.5\n",
      "trainer/Zf2 Param Norm                150.076\n",
      "trainer/Z Expert Predictions Mean    1787.01\n",
      "trainer/Z Expert Predictions Std      128.489\n",
      "trainer/Z Expert Predictions Max     1938.12\n",
      "trainer/Z Expert Predictions Min        3.2595\n",
      "trainer/Z Policy Predictions Mean    1310.49\n",
      "trainer/Z Policy Predictions Std      546.702\n",
      "trainer/Z Policy Predictions Max     1803.84\n",
      "trainer/Z Policy Predictions Min      -17.2595\n",
      "trainer/Z Expert Targets Mean        1771.79\n",
      "trainer/Z Expert Targets Std          128.499\n",
      "trainer/Z Expert Targets Max         1921.59\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1299.53\n",
      "trainer/Z Policy Targets Std          542.056\n",
      "trainer/Z Policy Targets Max         1767.38\n",
      "trainer/Z Policy Targets Min          -16.203\n",
      "trainer/Log Pis Mean                   59.8533\n",
      "trainer/Log Pis Std                    28.3412\n",
      "trainer/Policy mu Mean                  0.27961\n",
      "trainer/Policy mu Std                   4.40985\n",
      "trainer/Policy log std Mean            -2.96811\n",
      "trainer/Policy log std Std              1.328\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        239278\n",
      "exploration/num paths total          1390\n",
      "evaluation/num steps total              1.30674e+06\n",
      "evaluation/num paths total           2391\n",
      "evaluation/path length Mean           881.818\n",
      "evaluation/path length Std            267.827\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            129\n",
      "evaluation/Rewards Mean                 5.30888\n",
      "evaluation/Rewards Std                  0.0848927\n",
      "evaluation/Rewards Max                  5.93639\n",
      "evaluation/Rewards Min                  4.81226\n",
      "evaluation/Returns Mean              4681.46\n",
      "evaluation/Returns Std               1425.68\n",
      "evaluation/Returns Max               5316.28\n",
      "evaluation/Returns Min                677.264\n",
      "evaluation/Estimation Bias Mean      1553.15\n",
      "evaluation/Estimation Bias Std        257.725\n",
      "evaluation/EB/Q_True Mean              49.4276\n",
      "evaluation/EB/Q_True Std              149.697\n",
      "evaluation/EB/Q_Pred Mean            1602.58\n",
      "evaluation/EB/Q_Pred Std              164.406\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4681.46\n",
      "evaluation/Actions Mean                 0.0763465\n",
      "evaluation/Actions Std                  0.519782\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.08669\n",
      "time/backward_zf1 (s)                   2.71337\n",
      "time/backward_zf2 (s)                   2.53754\n",
      "time/data sampling (s)                  0.45466\n",
      "time/data storing (s)                   0.0176417\n",
      "time/evaluation sampling (s)            2.29407\n",
      "time/exploration sampling (s)           0.529039\n",
      "time/logging (s)                        0.013121\n",
      "time/preback_alpha (s)                  0.664251\n",
      "time/preback_policy (s)                 1.21752\n",
      "time/preback_start (s)                  0.203599\n",
      "time/preback_zf (s)                     7.05647\n",
      "time/saving (s)                         3.339e-06\n",
      "time/training (s)                       3.61446\n",
      "time/epoch (s)                         23.4024\n",
      "time/total (s)                       4914.14\n",
      "Epoch                                 233\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:47:47.420920 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 234 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 245000\n",
      "trainer/ZF1 Loss                      292.661\n",
      "trainer/ZF2 Loss                      315.376\n",
      "trainer/ZF Expert Reward                9.99931\n",
      "trainer/ZF Policy Reward                2.39947\n",
      "trainer/ZF CHI2 Term                  296.216\n",
      "trainer/Policy Loss                 -1306.97\n",
      "trainer/Bias Loss                      54.3268\n",
      "trainer/Bias Value                     15.6403\n",
      "trainer/Policy Grad Norm              273.473\n",
      "trainer/Policy Param Norm              55.4715\n",
      "trainer/Zf1 Grad Norm               17844.4\n",
      "trainer/Zf1 Param Norm                152.128\n",
      "trainer/Zf2 Grad Norm               16503.6\n",
      "trainer/Zf2 Param Norm                150.344\n",
      "trainer/Z Expert Predictions Mean    1783.11\n",
      "trainer/Z Expert Predictions Std       86.6469\n",
      "trainer/Z Expert Predictions Max     1923.61\n",
      "trainer/Z Expert Predictions Min      755.72\n",
      "trainer/Z Policy Predictions Mean    1298.91\n",
      "trainer/Z Policy Predictions Std      547.591\n",
      "trainer/Z Policy Predictions Max     1783.24\n",
      "trainer/Z Policy Predictions Min      -34.5586\n",
      "trainer/Z Expert Targets Mean        1773.11\n",
      "trainer/Z Expert Targets Std           84.987\n",
      "trainer/Z Expert Targets Max         1921.72\n",
      "trainer/Z Expert Targets Min          789.626\n",
      "trainer/Z Policy Targets Mean        1296.51\n",
      "trainer/Z Policy Targets Std          546.059\n",
      "trainer/Z Policy Targets Max         1746.16\n",
      "trainer/Z Policy Targets Min          -57.4337\n",
      "trainer/Log Pis Mean                   58.7275\n",
      "trainer/Log Pis Std                    28.765\n",
      "trainer/Policy mu Mean                  0.228352\n",
      "trainer/Policy mu Std                   3.62557\n",
      "trainer/Policy log std Mean            -2.90377\n",
      "trainer/Policy log std Std              1.30809\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        240278\n",
      "exploration/num paths total          1391\n",
      "evaluation/num steps total              1.31353e+06\n",
      "evaluation/num paths total           2401\n",
      "evaluation/path length Mean           678.7\n",
      "evaluation/path length Std            394.255\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            136\n",
      "evaluation/Rewards Mean                 5.30454\n",
      "evaluation/Rewards Std                  0.124887\n",
      "evaluation/Rewards Max                  6.36287\n",
      "evaluation/Rewards Min                  4.76432\n",
      "evaluation/Returns Mean              3600.19\n",
      "evaluation/Returns Std               2096.42\n",
      "evaluation/Returns Max               5334.14\n",
      "evaluation/Returns Min                737.021\n",
      "evaluation/Estimation Bias Mean      1447.46\n",
      "evaluation/Estimation Bias Std        417.263\n",
      "evaluation/EB/Q_True Mean              70.8532\n",
      "evaluation/EB/Q_True Std              175.313\n",
      "evaluation/EB/Q_Pred Mean            1518.31\n",
      "evaluation/EB/Q_Pred Std              288.293\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3600.19\n",
      "evaluation/Actions Mean                 0.0838393\n",
      "evaluation/Actions Std                  0.558645\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.18209\n",
      "time/backward_zf1 (s)                   2.78602\n",
      "time/backward_zf2 (s)                   2.64572\n",
      "time/data sampling (s)                  0.464913\n",
      "time/data storing (s)                   0.0174975\n",
      "time/evaluation sampling (s)            2.26679\n",
      "time/exploration sampling (s)           0.541476\n",
      "time/logging (s)                        0.011308\n",
      "time/preback_alpha (s)                  0.671526\n",
      "time/preback_policy (s)                 1.25471\n",
      "time/preback_start (s)                  0.204315\n",
      "time/preback_zf (s)                     7.02953\n",
      "time/saving (s)                         3.24e-06\n",
      "time/training (s)                       3.42045\n",
      "time/epoch (s)                         23.4963\n",
      "time/total (s)                       4937.67\n",
      "Epoch                                 234\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:48:10.991544 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 235 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 246000\n",
      "trainer/ZF1 Loss                      285.849\n",
      "trainer/ZF2 Loss                      313.128\n",
      "trainer/ZF Expert Reward               11.7275\n",
      "trainer/ZF Policy Reward                6.32112\n",
      "trainer/ZF CHI2 Term                  293.395\n",
      "trainer/Policy Loss                 -1369.04\n",
      "trainer/Bias Loss                      34.4834\n",
      "trainer/Bias Value                     15.6257\n",
      "trainer/Policy Grad Norm              201.491\n",
      "trainer/Policy Param Norm              55.5231\n",
      "trainer/Zf1 Grad Norm               15537\n",
      "trainer/Zf1 Param Norm                152.43\n",
      "trainer/Zf2 Grad Norm               15292.1\n",
      "trainer/Zf2 Param Norm                150.649\n",
      "trainer/Z Expert Predictions Mean    1784.62\n",
      "trainer/Z Expert Predictions Std       61.2849\n",
      "trainer/Z Expert Predictions Max     1915.04\n",
      "trainer/Z Expert Predictions Min     1631.58\n",
      "trainer/Z Policy Predictions Mean    1359.66\n",
      "trainer/Z Policy Predictions Std      462.936\n",
      "trainer/Z Policy Predictions Max     1758.86\n",
      "trainer/Z Policy Predictions Min      -16.1715\n",
      "trainer/Z Expert Targets Mean        1772.89\n",
      "trainer/Z Expert Targets Std           62.9949\n",
      "trainer/Z Expert Targets Max         1919.49\n",
      "trainer/Z Expert Targets Min         1620.88\n",
      "trainer/Z Policy Targets Mean        1353.34\n",
      "trainer/Z Policy Targets Std          460.718\n",
      "trainer/Z Policy Targets Max         1750.79\n",
      "trainer/Z Policy Targets Min          -10.7134\n",
      "trainer/Log Pis Mean                   56.6331\n",
      "trainer/Log Pis Std                    25.8397\n",
      "trainer/Policy mu Mean                  0.24919\n",
      "trainer/Policy mu Std                   3.60591\n",
      "trainer/Policy log std Mean            -3.1108\n",
      "trainer/Policy log std Std              1.17372\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        240278\n",
      "exploration/num paths total          1391\n",
      "evaluation/num steps total              1.32335e+06\n",
      "evaluation/num paths total           2412\n",
      "evaluation/path length Mean           892.545\n",
      "evaluation/path length Std            243.376\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            209\n",
      "evaluation/Rewards Mean                 5.30843\n",
      "evaluation/Rewards Std                  0.11566\n",
      "evaluation/Rewards Max                  5.77487\n",
      "evaluation/Rewards Min                  3.72827\n",
      "evaluation/Returns Mean              4738.02\n",
      "evaluation/Returns Std               1299.62\n",
      "evaluation/Returns Max               5323.36\n",
      "evaluation/Returns Min               1112.81\n",
      "evaluation/Estimation Bias Mean      1578.05\n",
      "evaluation/Estimation Bias Std        280.311\n",
      "evaluation/EB/Q_True Mean              48.8326\n",
      "evaluation/EB/Q_True Std              148.859\n",
      "evaluation/EB/Q_Pred Mean            1626.89\n",
      "evaluation/EB/Q_Pred Std              179.297\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4738.02\n",
      "evaluation/Actions Mean                 0.0681243\n",
      "evaluation/Actions Std                  0.500353\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.21411\n",
      "time/backward_zf1 (s)                   2.80898\n",
      "time/backward_zf2 (s)                   2.67336\n",
      "time/data sampling (s)                  0.456844\n",
      "time/data storing (s)                   0.0169957\n",
      "time/evaluation sampling (s)            2.64547\n",
      "time/exploration sampling (s)           0.510695\n",
      "time/logging (s)                        0.0139939\n",
      "time/preback_alpha (s)                  0.652134\n",
      "time/preback_policy (s)                 1.31525\n",
      "time/preback_start (s)                  0.19434\n",
      "time/preback_zf (s)                     6.93485\n",
      "time/saving (s)                         3.287e-06\n",
      "time/training (s)                       3.05774\n",
      "time/epoch (s)                         23.4948\n",
      "time/total (s)                       4961.19\n",
      "Epoch                                 235\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:48:34.338345 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 236 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 247000\n",
      "trainer/ZF1 Loss                     1639.56\n",
      "trainer/ZF2 Loss                     2006.08\n",
      "trainer/ZF Expert Reward               16.8473\n",
      "trainer/ZF Policy Reward               10.8148\n",
      "trainer/ZF CHI2 Term                 1821.86\n",
      "trainer/Policy Loss                 -1305.53\n",
      "trainer/Bias Loss                      29.9198\n",
      "trainer/Bias Value                     15.6126\n",
      "trainer/Policy Grad Norm              338.93\n",
      "trainer/Policy Param Norm              55.5776\n",
      "trainer/Zf1 Grad Norm               48774.5\n",
      "trainer/Zf1 Param Norm                152.717\n",
      "trainer/Zf2 Grad Norm               56607.3\n",
      "trainer/Zf2 Param Norm                150.933\n",
      "trainer/Z Expert Predictions Mean    1784.26\n",
      "trainer/Z Expert Predictions Std       59.5932\n",
      "trainer/Z Expert Predictions Max     1921.65\n",
      "trainer/Z Expert Predictions Min     1630.62\n",
      "trainer/Z Policy Predictions Mean    1299.11\n",
      "trainer/Z Policy Predictions Std      523.894\n",
      "trainer/Z Policy Predictions Max     1747.15\n",
      "trainer/Z Policy Predictions Min      -23.2698\n",
      "trainer/Z Expert Targets Mean        1767.41\n",
      "trainer/Z Expert Targets Std           59.6499\n",
      "trainer/Z Expert Targets Max         1893.15\n",
      "trainer/Z Expert Targets Min         1614.68\n",
      "trainer/Z Policy Targets Mean        1288.29\n",
      "trainer/Z Policy Targets Std          527.046\n",
      "trainer/Z Policy Targets Max         1753.55\n",
      "trainer/Z Policy Targets Min          -25.5168\n",
      "trainer/Log Pis Mean                   56.0506\n",
      "trainer/Log Pis Std                    25.8897\n",
      "trainer/Policy mu Mean                  0.350771\n",
      "trainer/Policy mu Std                   3.00241\n",
      "trainer/Policy log std Mean            -2.99285\n",
      "trainer/Policy log std Std              1.19168\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        241278\n",
      "exploration/num paths total          1392\n",
      "evaluation/num steps total              1.33035e+06\n",
      "evaluation/num paths total           2426\n",
      "evaluation/path length Mean           500.5\n",
      "evaluation/path length Std            433.99\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             73\n",
      "evaluation/Rewards Mean                 5.22495\n",
      "evaluation/Rewards Std                  0.20715\n",
      "evaluation/Rewards Max                  5.49322\n",
      "evaluation/Rewards Min                  3.70321\n",
      "evaluation/Returns Mean              2615.09\n",
      "evaluation/Returns Std               2324.17\n",
      "evaluation/Returns Max               5301.57\n",
      "evaluation/Returns Min                359.532\n",
      "evaluation/Estimation Bias Mean      1469.09\n",
      "evaluation/Estimation Bias Std        412.086\n",
      "evaluation/EB/Q_True Mean              68.1958\n",
      "evaluation/EB/Q_True Std              171.799\n",
      "evaluation/EB/Q_Pred Mean            1537.29\n",
      "evaluation/EB/Q_Pred Std              278.993\n",
      "evaluation/Num Paths                   14\n",
      "evaluation/Average Returns           2615.09\n",
      "evaluation/Actions Mean                 0.0789492\n",
      "evaluation/Actions Std                  0.5238\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.18536\n",
      "time/backward_zf1 (s)                   2.75143\n",
      "time/backward_zf2 (s)                   2.61853\n",
      "time/data sampling (s)                  0.469334\n",
      "time/data storing (s)                   0.0169925\n",
      "time/evaluation sampling (s)            2.44874\n",
      "time/exploration sampling (s)           0.522611\n",
      "time/logging (s)                        0.00985559\n",
      "time/preback_alpha (s)                  0.65756\n",
      "time/preback_policy (s)                 1.28188\n",
      "time/preback_start (s)                  0.200829\n",
      "time/preback_zf (s)                     6.95386\n",
      "time/saving (s)                         2.735e-06\n",
      "time/training (s)                       3.14553\n",
      "time/epoch (s)                         23.2625\n",
      "time/total (s)                       4984.48\n",
      "Epoch                                 236\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:48:57.698987 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 237 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 248000\n",
      "trainer/ZF1 Loss                      262.681\n",
      "trainer/ZF2 Loss                      279.386\n",
      "trainer/ZF Expert Reward                9.15999\n",
      "trainer/ZF Policy Reward                6.29744\n",
      "trainer/ZF CHI2 Term                  262.554\n",
      "trainer/Policy Loss                 -1310.6\n",
      "trainer/Bias Loss                      64.1439\n",
      "trainer/Bias Value                     15.6017\n",
      "trainer/Policy Grad Norm              249.42\n",
      "trainer/Policy Param Norm              55.635\n",
      "trainer/Zf1 Grad Norm               14800.7\n",
      "trainer/Zf1 Param Norm                153.009\n",
      "trainer/Zf2 Grad Norm               14076.6\n",
      "trainer/Zf2 Param Norm                151.229\n",
      "trainer/Z Expert Predictions Mean    1759.95\n",
      "trainer/Z Expert Predictions Std      138.446\n",
      "trainer/Z Expert Predictions Max     1897.26\n",
      "trainer/Z Expert Predictions Min       15.7822\n",
      "trainer/Z Policy Predictions Mean    1298.84\n",
      "trainer/Z Policy Predictions Std      523.67\n",
      "trainer/Z Policy Predictions Max     1768.87\n",
      "trainer/Z Policy Predictions Min      -25.3448\n",
      "trainer/Z Expert Targets Mean        1750.79\n",
      "trainer/Z Expert Targets Std          139.44\n",
      "trainer/Z Expert Targets Max         1878\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1292.54\n",
      "trainer/Z Policy Targets Std          522.912\n",
      "trainer/Z Policy Targets Max         1724.24\n",
      "trainer/Z Policy Targets Min          -25.0139\n",
      "trainer/Log Pis Mean                   57.5707\n",
      "trainer/Log Pis Std                    26.4663\n",
      "trainer/Policy mu Mean                  0.327704\n",
      "trainer/Policy mu Std                   3.64973\n",
      "trainer/Policy log std Mean            -2.96046\n",
      "trainer/Policy log std Std              1.22259\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        244278\n",
      "exploration/num paths total          1395\n",
      "evaluation/num steps total              1.34035e+06\n",
      "evaluation/num paths total           2436\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33542\n",
      "evaluation/Rewards Std                  0.080513\n",
      "evaluation/Rewards Max                  5.53993\n",
      "evaluation/Rewards Min                  4.82722\n",
      "evaluation/Returns Mean              5335.42\n",
      "evaluation/Returns Std                  3.22165\n",
      "evaluation/Returns Max               5339.54\n",
      "evaluation/Returns Min               5330.09\n",
      "evaluation/Estimation Bias Mean      1621.69\n",
      "evaluation/Estimation Bias Std        162.374\n",
      "evaluation/EB/Q_True Mean              48.1963\n",
      "evaluation/EB/Q_True Std              148.417\n",
      "evaluation/EB/Q_Pred Mean            1669.89\n",
      "evaluation/EB/Q_Pred Std               68.2699\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5335.42\n",
      "evaluation/Actions Mean                 0.0684555\n",
      "evaluation/Actions Std                  0.521986\n",
      "evaluation/Actions Max                  0.999966\n",
      "evaluation/Actions Min                 -0.999091\n",
      "time/backward_policy (s)                2.19888\n",
      "time/backward_zf1 (s)                   2.75485\n",
      "time/backward_zf2 (s)                   2.66171\n",
      "time/data sampling (s)                  0.465969\n",
      "time/data storing (s)                   0.017046\n",
      "time/evaluation sampling (s)            2.37744\n",
      "time/exploration sampling (s)           0.533102\n",
      "time/logging (s)                        0.0134193\n",
      "time/preback_alpha (s)                  0.659532\n",
      "time/preback_policy (s)                 1.32156\n",
      "time/preback_start (s)                  0.198159\n",
      "time/preback_zf (s)                     6.98427\n",
      "time/saving (s)                         3.455e-06\n",
      "time/training (s)                       3.10028\n",
      "time/epoch (s)                         23.2862\n",
      "time/total (s)                       5007.78\n",
      "Epoch                                 237\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:49:21.446601 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 238 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 249000\n",
      "trainer/ZF1 Loss                      277.911\n",
      "trainer/ZF2 Loss                      299.119\n",
      "trainer/ZF Expert Reward               18.6524\n",
      "trainer/ZF Policy Reward               10.5336\n",
      "trainer/ZF CHI2 Term                  289.533\n",
      "trainer/Policy Loss                 -1298.85\n",
      "trainer/Bias Loss                      50.5083\n",
      "trainer/Bias Value                     15.5914\n",
      "trainer/Policy Grad Norm              322.11\n",
      "trainer/Policy Param Norm              55.6986\n",
      "trainer/Zf1 Grad Norm               12906.6\n",
      "trainer/Zf1 Param Norm                153.282\n",
      "trainer/Zf2 Grad Norm               13088.5\n",
      "trainer/Zf2 Param Norm                151.513\n",
      "trainer/Z Expert Predictions Mean    1768.08\n",
      "trainer/Z Expert Predictions Std       58.5624\n",
      "trainer/Z Expert Predictions Max     1883.34\n",
      "trainer/Z Expert Predictions Min     1599.38\n",
      "trainer/Z Policy Predictions Mean    1294.78\n",
      "trainer/Z Policy Predictions Std      534.733\n",
      "trainer/Z Policy Predictions Max     1758.39\n",
      "trainer/Z Policy Predictions Min       -1.40627\n",
      "trainer/Z Expert Targets Mean        1749.43\n",
      "trainer/Z Expert Targets Std           58.9786\n",
      "trainer/Z Expert Targets Max         1871.03\n",
      "trainer/Z Expert Targets Min         1576.3\n",
      "trainer/Z Policy Targets Mean        1284.25\n",
      "trainer/Z Policy Targets Std          531.379\n",
      "trainer/Z Policy Targets Max         1728.54\n",
      "trainer/Z Policy Targets Min          -10.9077\n",
      "trainer/Log Pis Mean                   56.6403\n",
      "trainer/Log Pis Std                    27.2978\n",
      "trainer/Policy mu Mean                  0.294924\n",
      "trainer/Policy mu Std                   3.3795\n",
      "trainer/Policy log std Mean            -2.88077\n",
      "trainer/Policy log std Std              1.26986\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        244278\n",
      "exploration/num paths total          1395\n",
      "evaluation/num steps total              1.35031e+06\n",
      "evaluation/num paths total           2446\n",
      "evaluation/path length Mean           995.5\n",
      "evaluation/path length Std             13.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            955\n",
      "evaluation/Rewards Mean                 5.32231\n",
      "evaluation/Rewards Std                  0.0779356\n",
      "evaluation/Rewards Max                  5.53081\n",
      "evaluation/Rewards Min                  4.82437\n",
      "evaluation/Returns Mean              5298.36\n",
      "evaluation/Returns Std                 72.9069\n",
      "evaluation/Returns Max               5325.73\n",
      "evaluation/Returns Min               5079.76\n",
      "evaluation/Estimation Bias Mean      1595.86\n",
      "evaluation/Estimation Bias Std        190.989\n",
      "evaluation/EB/Q_True Mean              48.2991\n",
      "evaluation/EB/Q_True Std              148.409\n",
      "evaluation/EB/Q_Pred Mean            1644.16\n",
      "evaluation/EB/Q_Pred Std              106.836\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5298.36\n",
      "evaluation/Actions Mean                 0.0766256\n",
      "evaluation/Actions Std                  0.500612\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.22404\n",
      "time/backward_zf1 (s)                   2.81761\n",
      "time/backward_zf2 (s)                   2.68667\n",
      "time/data sampling (s)                  0.455325\n",
      "time/data storing (s)                   0.0164312\n",
      "time/evaluation sampling (s)            2.60204\n",
      "time/exploration sampling (s)           0.520426\n",
      "time/logging (s)                        0.0128401\n",
      "time/preback_alpha (s)                  0.665805\n",
      "time/preback_policy (s)                 1.33292\n",
      "time/preback_start (s)                  0.203531\n",
      "time/preback_zf (s)                     7.01622\n",
      "time/saving (s)                         3.476e-06\n",
      "time/training (s)                       3.10797\n",
      "time/epoch (s)                         23.6618\n",
      "time/total (s)                       5031.47\n",
      "Epoch                                 238\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:49:44.865132 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 239 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 250000\n",
      "trainer/ZF1 Loss                      233.196\n",
      "trainer/ZF2 Loss                      285.022\n",
      "trainer/ZF Expert Reward               16.6032\n",
      "trainer/ZF Policy Reward                8.20827\n",
      "trainer/ZF CHI2 Term                  258.204\n",
      "trainer/Policy Loss                 -1317.67\n",
      "trainer/Bias Loss                      26.1877\n",
      "trainer/Bias Value                     15.5789\n",
      "trainer/Policy Grad Norm              227.792\n",
      "trainer/Policy Param Norm              55.7556\n",
      "trainer/Zf1 Grad Norm               12293.3\n",
      "trainer/Zf1 Param Norm                153.574\n",
      "trainer/Zf2 Grad Norm               14835.5\n",
      "trainer/Zf2 Param Norm                151.807\n",
      "trainer/Z Expert Predictions Mean    1748.34\n",
      "trainer/Z Expert Predictions Std      127.573\n",
      "trainer/Z Expert Predictions Max     1878.29\n",
      "trainer/Z Expert Predictions Min        3.03751\n",
      "trainer/Z Policy Predictions Mean    1312.7\n",
      "trainer/Z Policy Predictions Std      507.018\n",
      "trainer/Z Policy Predictions Max     1797.5\n",
      "trainer/Z Policy Predictions Min      -33.5385\n",
      "trainer/Z Expert Targets Mean        1731.74\n",
      "trainer/Z Expert Targets Std          128.093\n",
      "trainer/Z Expert Targets Max         1881.5\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1304.49\n",
      "trainer/Z Policy Targets Std          502.938\n",
      "trainer/Z Policy Targets Max         1794.2\n",
      "trainer/Z Policy Targets Min          -29.8644\n",
      "trainer/Log Pis Mean                   56.0069\n",
      "trainer/Log Pis Std                    25.1346\n",
      "trainer/Policy mu Mean                  0.359403\n",
      "trainer/Policy mu Std                   3.24976\n",
      "trainer/Policy log std Mean            -2.99767\n",
      "trainer/Policy log std Std              1.18092\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        245265\n",
      "exploration/num paths total          1396\n",
      "evaluation/num steps total              1.36031e+06\n",
      "evaluation/num paths total           2456\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31847\n",
      "evaluation/Rewards Std                  0.0791316\n",
      "evaluation/Rewards Max                  5.50398\n",
      "evaluation/Rewards Min                  4.80414\n",
      "evaluation/Returns Mean              5318.47\n",
      "evaluation/Returns Std                  4.83971\n",
      "evaluation/Returns Max               5325.91\n",
      "evaluation/Returns Min               5307.71\n",
      "evaluation/Estimation Bias Mean      1577.98\n",
      "evaluation/Estimation Bias Std        167.156\n",
      "evaluation/EB/Q_True Mean              47.9528\n",
      "evaluation/EB/Q_True Std              147.684\n",
      "evaluation/EB/Q_Pred Mean            1625.94\n",
      "evaluation/EB/Q_Pred Std               79.6586\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5318.47\n",
      "evaluation/Actions Mean                 0.0750965\n",
      "evaluation/Actions Std                  0.495935\n",
      "evaluation/Actions Max                  0.999873\n",
      "evaluation/Actions Min                 -0.999602\n",
      "time/backward_policy (s)                2.18842\n",
      "time/backward_zf1 (s)                   2.74153\n",
      "time/backward_zf2 (s)                   2.61946\n",
      "time/data sampling (s)                  0.439361\n",
      "time/data storing (s)                   0.0174302\n",
      "time/evaluation sampling (s)            2.51399\n",
      "time/exploration sampling (s)           0.536321\n",
      "time/logging (s)                        0.0131893\n",
      "time/preback_alpha (s)                  0.661227\n",
      "time/preback_policy (s)                 1.28616\n",
      "time/preback_start (s)                  0.203849\n",
      "time/preback_zf (s)                     6.98769\n",
      "time/saving (s)                         3.401e-06\n",
      "time/training (s)                       3.13194\n",
      "time/epoch (s)                         23.3406\n",
      "time/total (s)                       5054.84\n",
      "Epoch                                 239\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:50:08.407896 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 240 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 251000\n",
      "trainer/ZF1 Loss                      269.178\n",
      "trainer/ZF2 Loss                      279.438\n",
      "trainer/ZF Expert Reward               15.6869\n",
      "trainer/ZF Policy Reward                9.3201\n",
      "trainer/ZF CHI2 Term                  272.621\n",
      "trainer/Policy Loss                 -1352.69\n",
      "trainer/Bias Loss                      25.0664\n",
      "trainer/Bias Value                     15.5727\n",
      "trainer/Policy Grad Norm              260.748\n",
      "trainer/Policy Param Norm              55.8075\n",
      "trainer/Zf1 Grad Norm               17940.4\n",
      "trainer/Zf1 Param Norm                153.861\n",
      "trainer/Zf2 Grad Norm               16706.8\n",
      "trainer/Zf2 Param Norm                152.072\n",
      "trainer/Z Expert Predictions Mean    1735.44\n",
      "trainer/Z Expert Predictions Std       88.5503\n",
      "trainer/Z Expert Predictions Max     1863.56\n",
      "trainer/Z Expert Predictions Min      687.809\n",
      "trainer/Z Policy Predictions Mean    1340.75\n",
      "trainer/Z Policy Predictions Std      461.326\n",
      "trainer/Z Policy Predictions Max     1743.38\n",
      "trainer/Z Policy Predictions Min       -8.76197\n",
      "trainer/Z Expert Targets Mean        1719.76\n",
      "trainer/Z Expert Targets Std           86.8032\n",
      "trainer/Z Expert Targets Max         1851.68\n",
      "trainer/Z Expert Targets Min          710.809\n",
      "trainer/Z Policy Targets Mean        1331.43\n",
      "trainer/Z Policy Targets Std          462.752\n",
      "trainer/Z Policy Targets Max         1725.44\n",
      "trainer/Z Policy Targets Min          -12.4718\n",
      "trainer/Log Pis Mean                   52.4927\n",
      "trainer/Log Pis Std                    21.7004\n",
      "trainer/Policy mu Mean                  0.287824\n",
      "trainer/Policy mu Std                   2.8527\n",
      "trainer/Policy log std Mean            -3.14031\n",
      "trainer/Policy log std Std              1.08232\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        246265\n",
      "exploration/num paths total          1397\n",
      "evaluation/num steps total              1.37031e+06\n",
      "evaluation/num paths total           2466\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33934\n",
      "evaluation/Rewards Std                  0.0801092\n",
      "evaluation/Rewards Max                  5.51538\n",
      "evaluation/Rewards Min                  4.79573\n",
      "evaluation/Returns Mean              5339.34\n",
      "evaluation/Returns Std                  3.34876\n",
      "evaluation/Returns Max               5344.66\n",
      "evaluation/Returns Min               5334.45\n",
      "evaluation/Estimation Bias Mean      1587.42\n",
      "evaluation/Estimation Bias Std        161.926\n",
      "evaluation/EB/Q_True Mean              48.2446\n",
      "evaluation/EB/Q_True Std              148.587\n",
      "evaluation/EB/Q_Pred Mean            1635.67\n",
      "evaluation/EB/Q_Pred Std               69.5273\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5339.34\n",
      "evaluation/Actions Mean                 0.0766229\n",
      "evaluation/Actions Std                  0.53215\n",
      "evaluation/Actions Max                  0.999953\n",
      "evaluation/Actions Min                 -0.997891\n",
      "time/backward_policy (s)                2.12003\n",
      "time/backward_zf1 (s)                   2.67821\n",
      "time/backward_zf2 (s)                   2.54392\n",
      "time/data sampling (s)                  0.454838\n",
      "time/data storing (s)                   0.0177743\n",
      "time/evaluation sampling (s)            2.64012\n",
      "time/exploration sampling (s)           0.545832\n",
      "time/logging (s)                        0.0131375\n",
      "time/preback_alpha (s)                  0.660198\n",
      "time/preback_policy (s)                 1.20666\n",
      "time/preback_start (s)                  0.205796\n",
      "time/preback_zf (s)                     6.97417\n",
      "time/saving (s)                         2.867e-06\n",
      "time/training (s)                       3.39665\n",
      "time/epoch (s)                         23.4573\n",
      "time/total (s)                       5078.32\n",
      "Epoch                                 240\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:50:32.107221 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 241 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 252000\n",
      "trainer/ZF1 Loss                      332.432\n",
      "trainer/ZF2 Loss                      312.363\n",
      "trainer/ZF Expert Reward               15.7379\n",
      "trainer/ZF Policy Reward               10.6543\n",
      "trainer/ZF CHI2 Term                  320.718\n",
      "trainer/Policy Loss                 -1313.84\n",
      "trainer/Bias Loss                      46.2991\n",
      "trainer/Bias Value                     15.5624\n",
      "trainer/Policy Grad Norm              207.789\n",
      "trainer/Policy Param Norm              55.8677\n",
      "trainer/Zf1 Grad Norm               13577.1\n",
      "trainer/Zf1 Param Norm                154.173\n",
      "trainer/Zf2 Grad Norm               15378.5\n",
      "trainer/Zf2 Param Norm                152.36\n",
      "trainer/Z Expert Predictions Mean    1744.92\n",
      "trainer/Z Expert Predictions Std       57.6592\n",
      "trainer/Z Expert Predictions Max     1883.88\n",
      "trainer/Z Expert Predictions Min     1583.64\n",
      "trainer/Z Policy Predictions Mean    1306.82\n",
      "trainer/Z Policy Predictions Std      480.085\n",
      "trainer/Z Policy Predictions Max     1756.26\n",
      "trainer/Z Policy Predictions Min      -24.2698\n",
      "trainer/Z Expert Targets Mean        1729.18\n",
      "trainer/Z Expert Targets Std           57.7988\n",
      "trainer/Z Expert Targets Max         1864.56\n",
      "trainer/Z Expert Targets Min         1569.27\n",
      "trainer/Z Policy Targets Mean        1296.17\n",
      "trainer/Z Policy Targets Std          475.622\n",
      "trainer/Z Policy Targets Max         1715.2\n",
      "trainer/Z Policy Targets Min          -28.6142\n",
      "trainer/Log Pis Mean                   57.5512\n",
      "trainer/Log Pis Std                    26.3498\n",
      "trainer/Policy mu Mean                  0.332064\n",
      "trainer/Policy mu Std                   3.51766\n",
      "trainer/Policy log std Mean            -3.10096\n",
      "trainer/Policy log std Std              1.11381\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        247614\n",
      "exploration/num paths total          1399\n",
      "evaluation/num steps total              1.37943e+06\n",
      "evaluation/num paths total           2476\n",
      "evaluation/path length Mean           911.9\n",
      "evaluation/path length Std            264.3\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            119\n",
      "evaluation/Rewards Mean                 5.31599\n",
      "evaluation/Rewards Std                  0.0923733\n",
      "evaluation/Rewards Max                  5.52605\n",
      "evaluation/Rewards Min                  4.55097\n",
      "evaluation/Returns Mean              4847.65\n",
      "evaluation/Returns Std               1414.64\n",
      "evaluation/Returns Max               5324.31\n",
      "evaluation/Returns Min                603.734\n",
      "evaluation/Estimation Bias Mean      1532.94\n",
      "evaluation/Estimation Bias Std        226.317\n",
      "evaluation/EB/Q_True Mean              52.6881\n",
      "evaluation/EB/Q_True Std              154.154\n",
      "evaluation/EB/Q_Pred Mean            1585.62\n",
      "evaluation/EB/Q_Pred Std              131.277\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4847.65\n",
      "evaluation/Actions Mean                 0.0731039\n",
      "evaluation/Actions Std                  0.502608\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.24812\n",
      "time/backward_zf1 (s)                   2.80818\n",
      "time/backward_zf2 (s)                   2.66865\n",
      "time/data sampling (s)                  0.452809\n",
      "time/data storing (s)                   0.0178071\n",
      "time/evaluation sampling (s)            2.35539\n",
      "time/exploration sampling (s)           0.547181\n",
      "time/logging (s)                        0.0125166\n",
      "time/preback_alpha (s)                  0.677468\n",
      "time/preback_policy (s)                 1.28969\n",
      "time/preback_start (s)                  0.209769\n",
      "time/preback_zf (s)                     7.05933\n",
      "time/saving (s)                         2.565e-06\n",
      "time/training (s)                       3.2657\n",
      "time/epoch (s)                         23.6126\n",
      "time/total (s)                       5101.97\n",
      "Epoch                                 241\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:50:55.945456 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 242 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 253000\n",
      "trainer/ZF1 Loss                      243.136\n",
      "trainer/ZF2 Loss                      233.483\n",
      "trainer/ZF Expert Reward               16.4153\n",
      "trainer/ZF Policy Reward                3.86447\n",
      "trainer/ZF CHI2 Term                  237.478\n",
      "trainer/Policy Loss                 -1314.54\n",
      "trainer/Bias Loss                      25.1702\n",
      "trainer/Bias Value                     15.5574\n",
      "trainer/Policy Grad Norm              206.867\n",
      "trainer/Policy Param Norm              55.9302\n",
      "trainer/Zf1 Grad Norm               11010.2\n",
      "trainer/Zf1 Param Norm                154.438\n",
      "trainer/Zf2 Grad Norm               13799.4\n",
      "trainer/Zf2 Param Norm                152.638\n",
      "trainer/Z Expert Predictions Mean    1727.23\n",
      "trainer/Z Expert Predictions Std       64.9522\n",
      "trainer/Z Expert Predictions Max     1850.89\n",
      "trainer/Z Expert Predictions Min     1448.22\n",
      "trainer/Z Policy Predictions Mean    1306.93\n",
      "trainer/Z Policy Predictions Std      500.033\n",
      "trainer/Z Policy Predictions Max     1750.81\n",
      "trainer/Z Policy Predictions Min      -28.4971\n",
      "trainer/Z Expert Targets Mean        1710.81\n",
      "trainer/Z Expert Targets Std           64.307\n",
      "trainer/Z Expert Targets Max         1836.18\n",
      "trainer/Z Expert Targets Min         1431.37\n",
      "trainer/Z Policy Targets Mean        1303.07\n",
      "trainer/Z Policy Targets Std          501.348\n",
      "trainer/Z Policy Targets Max         1693.24\n",
      "trainer/Z Policy Targets Min          -29.8572\n",
      "trainer/Log Pis Mean                   55.1937\n",
      "trainer/Log Pis Std                    24.4758\n",
      "trainer/Policy mu Mean                  0.184773\n",
      "trainer/Policy mu Std                   3.3779\n",
      "trainer/Policy log std Mean            -3.07707\n",
      "trainer/Policy log std Std              1.20962\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        247614\n",
      "exploration/num paths total          1399\n",
      "evaluation/num steps total              1.38943e+06\n",
      "evaluation/num paths total           2486\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.32689\n",
      "evaluation/Rewards Std                  0.0842008\n",
      "evaluation/Rewards Max                  5.51578\n",
      "evaluation/Rewards Min                  4.79983\n",
      "evaluation/Returns Mean              5326.89\n",
      "evaluation/Returns Std                  5.11998\n",
      "evaluation/Returns Max               5336.63\n",
      "evaluation/Returns Min               5318.1\n",
      "evaluation/Estimation Bias Mean      1570.91\n",
      "evaluation/Estimation Bias Std        162.08\n",
      "evaluation/EB/Q_True Mean              48.0919\n",
      "evaluation/EB/Q_True Std              148.113\n",
      "evaluation/EB/Q_Pred Mean            1619\n",
      "evaluation/EB/Q_Pred Std               69.8029\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5326.89\n",
      "evaluation/Actions Mean                 0.0762914\n",
      "evaluation/Actions Std                  0.50496\n",
      "evaluation/Actions Max                  0.999966\n",
      "evaluation/Actions Min                 -0.99809\n",
      "time/backward_policy (s)                2.18082\n",
      "time/backward_zf1 (s)                   2.81029\n",
      "time/backward_zf2 (s)                   2.67391\n",
      "time/data sampling (s)                  0.464424\n",
      "time/data storing (s)                   0.0166334\n",
      "time/evaluation sampling (s)            2.40661\n",
      "time/exploration sampling (s)           0.51688\n",
      "time/logging (s)                        0.0133638\n",
      "time/preback_alpha (s)                  0.666751\n",
      "time/preback_policy (s)                 1.24069\n",
      "time/preback_start (s)                  0.204007\n",
      "time/preback_zf (s)                     7.05869\n",
      "time/saving (s)                         3.219e-06\n",
      "time/training (s)                       3.50312\n",
      "time/epoch (s)                         23.7562\n",
      "time/total (s)                       5125.75\n",
      "Epoch                                 242\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:51:19.257627 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 243 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 254000\n",
      "trainer/ZF1 Loss                      287.336\n",
      "trainer/ZF2 Loss                      268.514\n",
      "trainer/ZF Expert Reward               14.3552\n",
      "trainer/ZF Policy Reward                2.51501\n",
      "trainer/ZF CHI2 Term                  275.138\n",
      "trainer/Policy Loss                 -1216.85\n",
      "trainer/Bias Loss                      29.1992\n",
      "trainer/Bias Value                     15.5492\n",
      "trainer/Policy Grad Norm              209.795\n",
      "trainer/Policy Param Norm              55.9879\n",
      "trainer/Zf1 Grad Norm               15119.7\n",
      "trainer/Zf1 Param Norm                154.72\n",
      "trainer/Zf2 Grad Norm               11259.3\n",
      "trainer/Zf2 Param Norm                152.894\n",
      "trainer/Z Expert Predictions Mean    1716.62\n",
      "trainer/Z Expert Predictions Std       64.6336\n",
      "trainer/Z Expert Predictions Max     1840.42\n",
      "trainer/Z Expert Predictions Min     1536.01\n",
      "trainer/Z Policy Predictions Mean    1205.69\n",
      "trainer/Z Policy Predictions Std      510.93\n",
      "trainer/Z Policy Predictions Max     1683.64\n",
      "trainer/Z Policy Predictions Min      -21.8162\n",
      "trainer/Z Expert Targets Mean        1702.26\n",
      "trainer/Z Expert Targets Std           64.4351\n",
      "trainer/Z Expert Targets Max         1822.2\n",
      "trainer/Z Expert Targets Min         1525.19\n",
      "trainer/Z Policy Targets Mean        1203.18\n",
      "trainer/Z Policy Targets Std          507.828\n",
      "trainer/Z Policy Targets Max         1690.1\n",
      "trainer/Z Policy Targets Min          -35.5617\n",
      "trainer/Log Pis Mean                   59.5702\n",
      "trainer/Log Pis Std                    29.1057\n",
      "trainer/Policy mu Mean                  0.395863\n",
      "trainer/Policy mu Std                   3.71556\n",
      "trainer/Policy log std Mean            -2.82417\n",
      "trainer/Policy log std Std              1.27707\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        249614\n",
      "exploration/num paths total          1401\n",
      "evaluation/num steps total              1.39943e+06\n",
      "evaluation/num paths total           2496\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33458\n",
      "evaluation/Rewards Std                  0.0855811\n",
      "evaluation/Rewards Max                  5.52001\n",
      "evaluation/Rewards Min                  4.78222\n",
      "evaluation/Returns Mean              5334.58\n",
      "evaluation/Returns Std                  6.5786\n",
      "evaluation/Returns Max               5343.65\n",
      "evaluation/Returns Min               5323.43\n",
      "evaluation/Estimation Bias Mean      1545.58\n",
      "evaluation/Estimation Bias Std        167.667\n",
      "evaluation/EB/Q_True Mean              48.1638\n",
      "evaluation/EB/Q_True Std              148.321\n",
      "evaluation/EB/Q_Pred Mean            1593.74\n",
      "evaluation/EB/Q_Pred Std               83.8856\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5334.58\n",
      "evaluation/Actions Mean                 0.0740965\n",
      "evaluation/Actions Std                  0.513142\n",
      "evaluation/Actions Max                  0.999956\n",
      "evaluation/Actions Min                 -0.998891\n",
      "time/backward_policy (s)                2.18235\n",
      "time/backward_zf1 (s)                   2.74373\n",
      "time/backward_zf2 (s)                   2.60813\n",
      "time/data sampling (s)                  0.454477\n",
      "time/data storing (s)                   0.0173019\n",
      "time/evaluation sampling (s)            2.30539\n",
      "time/exploration sampling (s)           0.538278\n",
      "time/logging (s)                        0.0134363\n",
      "time/preback_alpha (s)                  0.666231\n",
      "time/preback_policy (s)                 1.25459\n",
      "time/preback_start (s)                  0.205172\n",
      "time/preback_zf (s)                     7.02218\n",
      "time/saving (s)                         3.425e-06\n",
      "time/training (s)                       3.22151\n",
      "time/epoch (s)                         23.2328\n",
      "time/total (s)                       5149\n",
      "Epoch                                 243\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:51:42.777115 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 244 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 255000\n",
      "trainer/ZF1 Loss                      220.699\n",
      "trainer/ZF2 Loss                      240.386\n",
      "trainer/ZF Expert Reward               12.7496\n",
      "trainer/ZF Policy Reward                5.9454\n",
      "trainer/ZF CHI2 Term                  226.347\n",
      "trainer/Policy Loss                 -1262.76\n",
      "trainer/Bias Loss                      30.7473\n",
      "trainer/Bias Value                     15.5458\n",
      "trainer/Policy Grad Norm              230.752\n",
      "trainer/Policy Param Norm              56.0401\n",
      "trainer/Zf1 Grad Norm               11288\n",
      "trainer/Zf1 Param Norm                154.979\n",
      "trainer/Zf2 Grad Norm               13974.5\n",
      "trainer/Zf2 Param Norm                153.167\n",
      "trainer/Z Expert Predictions Mean    1694.58\n",
      "trainer/Z Expert Predictions Std      118.642\n",
      "trainer/Z Expert Predictions Max     1820.67\n",
      "trainer/Z Expert Predictions Min       36.6816\n",
      "trainer/Z Policy Predictions Mean    1256.86\n",
      "trainer/Z Policy Predictions Std      497.338\n",
      "trainer/Z Policy Predictions Max     1670.94\n",
      "trainer/Z Policy Predictions Min      -12.4651\n",
      "trainer/Z Expert Targets Mean        1681.83\n",
      "trainer/Z Expert Targets Std          120.305\n",
      "trainer/Z Expert Targets Max         1806.91\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1250.91\n",
      "trainer/Z Policy Targets Std          496.687\n",
      "trainer/Z Policy Targets Max         1670.5\n",
      "trainer/Z Policy Targets Min          -14.5595\n",
      "trainer/Log Pis Mean                   55.7098\n",
      "trainer/Log Pis Std                    26.088\n",
      "trainer/Policy mu Mean                  0.218644\n",
      "trainer/Policy mu Std                   3.62994\n",
      "trainer/Policy log std Mean            -2.96367\n",
      "trainer/Policy log std Std              1.23714\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        250614\n",
      "exploration/num paths total          1402\n",
      "evaluation/num steps total              1.40909e+06\n",
      "evaluation/num paths total           2506\n",
      "evaluation/path length Mean           966.4\n",
      "evaluation/path length Std            100.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            664\n",
      "evaluation/Rewards Mean                 5.30446\n",
      "evaluation/Rewards Std                  0.0846454\n",
      "evaluation/Rewards Max                  6.21464\n",
      "evaluation/Rewards Min                  4.79269\n",
      "evaluation/Returns Mean              5126.23\n",
      "evaluation/Returns Std                533.212\n",
      "evaluation/Returns Max               5309.12\n",
      "evaluation/Returns Min               3526.61\n",
      "evaluation/Estimation Bias Mean      1531.75\n",
      "evaluation/Estimation Bias Std        241.26\n",
      "evaluation/EB/Q_True Mean              49.5317\n",
      "evaluation/EB/Q_True Std              149.698\n",
      "evaluation/EB/Q_Pred Mean            1581.28\n",
      "evaluation/EB/Q_Pred Std              137.859\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5126.23\n",
      "evaluation/Actions Mean                 0.0655095\n",
      "evaluation/Actions Std                  0.515467\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.24574\n",
      "time/backward_zf1 (s)                   2.81738\n",
      "time/backward_zf2 (s)                   2.69704\n",
      "time/data sampling (s)                  0.453155\n",
      "time/data storing (s)                   0.0171004\n",
      "time/evaluation sampling (s)            2.35473\n",
      "time/exploration sampling (s)           0.515991\n",
      "time/logging (s)                        0.0128717\n",
      "time/preback_alpha (s)                  0.658246\n",
      "time/preback_policy (s)                 1.28418\n",
      "time/preback_start (s)                  0.20725\n",
      "time/preback_zf (s)                     6.99333\n",
      "time/saving (s)                         3.349e-06\n",
      "time/training (s)                       3.18555\n",
      "time/epoch (s)                         23.4426\n",
      "time/total (s)                       5172.47\n",
      "Epoch                                 244\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:52:06.046524 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 245 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 256000\n",
      "trainer/ZF1 Loss                      319.029\n",
      "trainer/ZF2 Loss                      268.018\n",
      "trainer/ZF Expert Reward               13.7033\n",
      "trainer/ZF Policy Reward               10.7467\n",
      "trainer/ZF CHI2 Term                  290.323\n",
      "trainer/Policy Loss                 -1292.71\n",
      "trainer/Bias Loss                      34\n",
      "trainer/Bias Value                     15.5341\n",
      "trainer/Policy Grad Norm              271.825\n",
      "trainer/Policy Param Norm              56.1028\n",
      "trainer/Zf1 Grad Norm               15941.1\n",
      "trainer/Zf1 Param Norm                155.293\n",
      "trainer/Zf2 Grad Norm               10918.3\n",
      "trainer/Zf2 Param Norm                153.454\n",
      "trainer/Z Expert Predictions Mean    1690.4\n",
      "trainer/Z Expert Predictions Std      122.288\n",
      "trainer/Z Expert Predictions Max     1832.66\n",
      "trainer/Z Expert Predictions Min       11.4426\n",
      "trainer/Z Policy Predictions Mean    1286.21\n",
      "trainer/Z Policy Predictions Std      464.778\n",
      "trainer/Z Policy Predictions Max     1696.76\n",
      "trainer/Z Policy Predictions Min      -39.3456\n",
      "trainer/Z Expert Targets Mean        1676.7\n",
      "trainer/Z Expert Targets Std          122.869\n",
      "trainer/Z Expert Targets Max         1815.38\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1275.46\n",
      "trainer/Z Policy Targets Std          469.627\n",
      "trainer/Z Policy Targets Max         1697.47\n",
      "trainer/Z Policy Targets Min          -41.1152\n",
      "trainer/Log Pis Mean                   54.6447\n",
      "trainer/Log Pis Std                    22.236\n",
      "trainer/Policy mu Mean                  0.169996\n",
      "trainer/Policy mu Std                   2.81294\n",
      "trainer/Policy log std Mean            -3.0682\n",
      "trainer/Policy log std Std              1.18667\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        250614\n",
      "exploration/num paths total          1402\n",
      "evaluation/num steps total              1.41909e+06\n",
      "evaluation/num paths total           2516\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33929\n",
      "evaluation/Rewards Std                  0.0809757\n",
      "evaluation/Rewards Max                  5.57045\n",
      "evaluation/Rewards Min                  4.87121\n",
      "evaluation/Returns Mean              5339.29\n",
      "evaluation/Returns Std                  4.97302\n",
      "evaluation/Returns Max               5344.96\n",
      "evaluation/Returns Min               5327.12\n",
      "evaluation/Estimation Bias Mean      1527.24\n",
      "evaluation/Estimation Bias Std        165.168\n",
      "evaluation/EB/Q_True Mean              48.2497\n",
      "evaluation/EB/Q_True Std              148.572\n",
      "evaluation/EB/Q_Pred Mean            1575.49\n",
      "evaluation/EB/Q_Pred Std               74.0222\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5339.29\n",
      "evaluation/Actions Mean                 0.0669584\n",
      "evaluation/Actions Std                  0.506896\n",
      "evaluation/Actions Max                  0.99988\n",
      "evaluation/Actions Min                 -0.996307\n",
      "time/backward_policy (s)                2.13362\n",
      "time/backward_zf1 (s)                   2.70242\n",
      "time/backward_zf2 (s)                   2.54519\n",
      "time/data sampling (s)                  0.437147\n",
      "time/data storing (s)                   0.0174922\n",
      "time/evaluation sampling (s)            2.2616\n",
      "time/exploration sampling (s)           0.531383\n",
      "time/logging (s)                        0.0132305\n",
      "time/preback_alpha (s)                  0.659797\n",
      "time/preback_policy (s)                 1.19524\n",
      "time/preback_start (s)                  0.201309\n",
      "time/preback_zf (s)                     7.00039\n",
      "time/saving (s)                         3.39e-06\n",
      "time/training (s)                       3.49054\n",
      "time/epoch (s)                         23.1894\n",
      "time/total (s)                       5195.68\n",
      "Epoch                                 245\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:52:29.265436 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 246 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 257000\n",
      "trainer/ZF1 Loss                      313.898\n",
      "trainer/ZF2 Loss                      287.554\n",
      "trainer/ZF Expert Reward               13.671\n",
      "trainer/ZF Policy Reward                7.288\n",
      "trainer/ZF CHI2 Term                  297.542\n",
      "trainer/Policy Loss                 -1246.19\n",
      "trainer/Bias Loss                      27.7309\n",
      "trainer/Bias Value                     15.5254\n",
      "trainer/Policy Grad Norm              244.005\n",
      "trainer/Policy Param Norm              56.1697\n",
      "trainer/Zf1 Grad Norm               15453.1\n",
      "trainer/Zf1 Param Norm                155.567\n",
      "trainer/Zf2 Grad Norm               12237.7\n",
      "trainer/Zf2 Param Norm                153.734\n",
      "trainer/Z Expert Predictions Mean    1688.41\n",
      "trainer/Z Expert Predictions Std       67.1911\n",
      "trainer/Z Expert Predictions Max     1798.54\n",
      "trainer/Z Expert Predictions Min     1513.33\n",
      "trainer/Z Policy Predictions Mean    1238.04\n",
      "trainer/Z Policy Predictions Std      497.929\n",
      "trainer/Z Policy Predictions Max     1635.35\n",
      "trainer/Z Policy Predictions Min      -19.7486\n",
      "trainer/Z Expert Targets Mean        1674.74\n",
      "trainer/Z Expert Targets Std           67.9879\n",
      "trainer/Z Expert Targets Max         1789.98\n",
      "trainer/Z Expert Targets Min         1503.9\n",
      "trainer/Z Policy Targets Mean        1230.75\n",
      "trainer/Z Policy Targets Std          500.281\n",
      "trainer/Z Policy Targets Max         1653.04\n",
      "trainer/Z Policy Targets Min          -33.1606\n",
      "trainer/Log Pis Mean                   55.7563\n",
      "trainer/Log Pis Std                    24.3729\n",
      "trainer/Policy mu Mean                  0.281305\n",
      "trainer/Policy mu Std                   3.4135\n",
      "trainer/Policy log std Mean            -2.95772\n",
      "trainer/Policy log std Std              1.18792\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        251614\n",
      "exploration/num paths total          1403\n",
      "evaluation/num steps total              1.42831e+06\n",
      "evaluation/num paths total           2526\n",
      "evaluation/path length Mean           922.2\n",
      "evaluation/path length Std            233.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            222\n",
      "evaluation/Rewards Mean                 5.27207\n",
      "evaluation/Rewards Std                  0.140941\n",
      "evaluation/Rewards Max                  5.51068\n",
      "evaluation/Rewards Min                  3.24369\n",
      "evaluation/Returns Mean              4861.9\n",
      "evaluation/Returns Std               1276.17\n",
      "evaluation/Returns Max               5293.29\n",
      "evaluation/Returns Min               1033.39\n",
      "evaluation/Estimation Bias Mean      1498.11\n",
      "evaluation/Estimation Bias Std        240.368\n",
      "evaluation/EB/Q_True Mean              51.6913\n",
      "evaluation/EB/Q_True Std              152.18\n",
      "evaluation/EB/Q_Pred Mean            1549.8\n",
      "evaluation/EB/Q_Pred Std              140.899\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4861.9\n",
      "evaluation/Actions Mean                 0.0602961\n",
      "evaluation/Actions Std                  0.510515\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.07759\n",
      "time/backward_zf1 (s)                   2.6346\n",
      "time/backward_zf2 (s)                   2.47112\n",
      "time/data sampling (s)                  0.433606\n",
      "time/data storing (s)                   0.0156884\n",
      "time/evaluation sampling (s)            2.46138\n",
      "time/exploration sampling (s)           0.513154\n",
      "time/logging (s)                        0.0125859\n",
      "time/preback_alpha (s)                  0.654323\n",
      "time/preback_policy (s)                 1.17692\n",
      "time/preback_start (s)                  0.206124\n",
      "time/preback_zf (s)                     6.95668\n",
      "time/saving (s)                         2.892e-06\n",
      "time/training (s)                       3.52771\n",
      "time/epoch (s)                         23.1415\n",
      "time/total (s)                       5218.84\n",
      "Epoch                                 246\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:52:52.646853 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 247 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 258000\n",
      "trainer/ZF1 Loss                      278.473\n",
      "trainer/ZF2 Loss                      276.695\n",
      "trainer/ZF Expert Reward               18.006\n",
      "trainer/ZF Policy Reward               11.9055\n",
      "trainer/ZF CHI2 Term                  278.829\n",
      "trainer/Policy Loss                 -1235.79\n",
      "trainer/Bias Loss                      32.52\n",
      "trainer/Bias Value                     15.5182\n",
      "trainer/Policy Grad Norm              257.374\n",
      "trainer/Policy Param Norm              56.2245\n",
      "trainer/Zf1 Grad Norm               13361.5\n",
      "trainer/Zf1 Param Norm                155.817\n",
      "trainer/Zf2 Grad Norm               11777.2\n",
      "trainer/Zf2 Param Norm                153.981\n",
      "trainer/Z Expert Predictions Mean    1673.19\n",
      "trainer/Z Expert Predictions Std      129.532\n",
      "trainer/Z Expert Predictions Max     1791.15\n",
      "trainer/Z Expert Predictions Min       23.6733\n",
      "trainer/Z Policy Predictions Mean    1229.61\n",
      "trainer/Z Policy Predictions Std      492.244\n",
      "trainer/Z Policy Predictions Max     1665.18\n",
      "trainer/Z Policy Predictions Min      -13.9754\n",
      "trainer/Z Expert Targets Mean        1655.18\n",
      "trainer/Z Expert Targets Std          130.063\n",
      "trainer/Z Expert Targets Max         1766.19\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1217.7\n",
      "trainer/Z Policy Targets Std          490.89\n",
      "trainer/Z Policy Targets Max         1657.97\n",
      "trainer/Z Policy Targets Min          -12.1839\n",
      "trainer/Log Pis Mean                   57.694\n",
      "trainer/Log Pis Std                    27.7904\n",
      "trainer/Policy mu Mean                  0.2302\n",
      "trainer/Policy mu Std                   3.69866\n",
      "trainer/Policy log std Mean            -2.92405\n",
      "trainer/Policy log std Std              1.26378\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        253614\n",
      "exploration/num paths total          1405\n",
      "evaluation/num steps total              1.43788e+06\n",
      "evaluation/num paths total           2536\n",
      "evaluation/path length Mean           957.1\n",
      "evaluation/path length Std            128.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            571\n",
      "evaluation/Rewards Mean                 5.31048\n",
      "evaluation/Rewards Std                  0.10074\n",
      "evaluation/Rewards Max                  5.49577\n",
      "evaluation/Rewards Min                  4.10415\n",
      "evaluation/Returns Mean              5082.66\n",
      "evaluation/Returns Std                700.578\n",
      "evaluation/Returns Max               5325.95\n",
      "evaluation/Returns Min               2981.02\n",
      "evaluation/Estimation Bias Mean      1481.65\n",
      "evaluation/Estimation Bias Std        216.602\n",
      "evaluation/EB/Q_True Mean              50.0635\n",
      "evaluation/EB/Q_True Std              150.502\n",
      "evaluation/EB/Q_Pred Mean            1531.71\n",
      "evaluation/EB/Q_Pred Std              118.595\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5082.66\n",
      "evaluation/Actions Mean                 0.0784199\n",
      "evaluation/Actions Std                  0.504637\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.0804\n",
      "time/backward_zf1 (s)                   2.71248\n",
      "time/backward_zf2 (s)                   2.57372\n",
      "time/data sampling (s)                  0.486102\n",
      "time/data storing (s)                   0.0176638\n",
      "time/evaluation sampling (s)            2.47286\n",
      "time/exploration sampling (s)           0.544928\n",
      "time/logging (s)                        0.0130874\n",
      "time/preback_alpha (s)                  0.672117\n",
      "time/preback_policy (s)                 1.21219\n",
      "time/preback_start (s)                  0.200606\n",
      "time/preback_zf (s)                     7.03998\n",
      "time/saving (s)                         3.167e-06\n",
      "time/training (s)                       3.26996\n",
      "time/epoch (s)                         23.2961\n",
      "time/total (s)                       5242.17\n",
      "Epoch                                 247\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:53:16.244975 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 248 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 259000\n",
      "trainer/ZF1 Loss                      393.801\n",
      "trainer/ZF2 Loss                      317.309\n",
      "trainer/ZF Expert Reward               17.8555\n",
      "trainer/ZF Policy Reward                4.22052\n",
      "trainer/ZF CHI2 Term                  356.776\n",
      "trainer/Policy Loss                 -1246.76\n",
      "trainer/Bias Loss                      36.3354\n",
      "trainer/Bias Value                     15.5119\n",
      "trainer/Policy Grad Norm              240.465\n",
      "trainer/Policy Param Norm              56.279\n",
      "trainer/Zf1 Grad Norm               17195.5\n",
      "trainer/Zf1 Param Norm                156.077\n",
      "trainer/Zf2 Grad Norm               16896.3\n",
      "trainer/Zf2 Param Norm                154.25\n",
      "trainer/Z Expert Predictions Mean    1662.83\n",
      "trainer/Z Expert Predictions Std      119.491\n",
      "trainer/Z Expert Predictions Max     1789.17\n",
      "trainer/Z Expert Predictions Min       22.211\n",
      "trainer/Z Policy Predictions Mean    1239.88\n",
      "trainer/Z Policy Predictions Std      473.961\n",
      "trainer/Z Policy Predictions Max     1695.46\n",
      "trainer/Z Policy Predictions Min      -23.4361\n",
      "trainer/Z Expert Targets Mean        1644.97\n",
      "trainer/Z Expert Targets Std          119.932\n",
      "trainer/Z Expert Targets Max         1757.95\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1235.66\n",
      "trainer/Z Policy Targets Std          473.527\n",
      "trainer/Z Policy Targets Max         1668.19\n",
      "trainer/Z Policy Targets Min          -20.1765\n",
      "trainer/Log Pis Mean                   56.0357\n",
      "trainer/Log Pis Std                    23.0577\n",
      "trainer/Policy mu Mean                  0.245642\n",
      "trainer/Policy mu Std                   3.32616\n",
      "trainer/Policy log std Mean            -3.03159\n",
      "trainer/Policy log std Std              1.2109\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        253614\n",
      "exploration/num paths total          1405\n",
      "evaluation/num steps total              1.44788e+06\n",
      "evaluation/num paths total           2546\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29068\n",
      "evaluation/Rewards Std                  0.0789848\n",
      "evaluation/Rewards Max                  5.47638\n",
      "evaluation/Rewards Min                  4.78752\n",
      "evaluation/Returns Mean              5290.68\n",
      "evaluation/Returns Std                  6.20473\n",
      "evaluation/Returns Max               5300.8\n",
      "evaluation/Returns Min               5278.25\n",
      "evaluation/Estimation Bias Mean      1487.14\n",
      "evaluation/Estimation Bias Std        165.753\n",
      "evaluation/EB/Q_True Mean              47.7477\n",
      "evaluation/EB/Q_True Std              147.026\n",
      "evaluation/EB/Q_Pred Mean            1534.89\n",
      "evaluation/EB/Q_Pred Std               68.424\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5290.68\n",
      "evaluation/Actions Mean                 0.0688486\n",
      "evaluation/Actions Std                  0.504956\n",
      "evaluation/Actions Max                  0.999896\n",
      "evaluation/Actions Min                 -0.998472\n",
      "time/backward_policy (s)                2.1488\n",
      "time/backward_zf1 (s)                   2.71127\n",
      "time/backward_zf2 (s)                   2.55954\n",
      "time/data sampling (s)                  0.461376\n",
      "time/data storing (s)                   0.0182063\n",
      "time/evaluation sampling (s)            2.50731\n",
      "time/exploration sampling (s)           0.524271\n",
      "time/logging (s)                        0.0153118\n",
      "time/preback_alpha (s)                  0.670704\n",
      "time/preback_policy (s)                 1.20395\n",
      "time/preback_start (s)                  0.206588\n",
      "time/preback_zf (s)                     7.00499\n",
      "time/saving (s)                         3.76299e-06\n",
      "time/training (s)                       3.48345\n",
      "time/epoch (s)                         23.5158\n",
      "time/total (s)                       5265.71\n",
      "Epoch                                 248\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:53:39.595398 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 249 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 260000\n",
      "trainer/ZF1 Loss                      254.665\n",
      "trainer/ZF2 Loss                      278.263\n",
      "trainer/ZF Expert Reward               16.5269\n",
      "trainer/ZF Policy Reward               11.7911\n",
      "trainer/ZF CHI2 Term                  266.406\n",
      "trainer/Policy Loss                 -1260.86\n",
      "trainer/Bias Loss                      50.635\n",
      "trainer/Bias Value                     15.5029\n",
      "trainer/Policy Grad Norm              292.014\n",
      "trainer/Policy Param Norm              56.3383\n",
      "trainer/Zf1 Grad Norm               13377.1\n",
      "trainer/Zf1 Param Norm                156.354\n",
      "trainer/Zf2 Grad Norm               15528.1\n",
      "trainer/Zf2 Param Norm                154.523\n",
      "trainer/Z Expert Predictions Mean    1662.81\n",
      "trainer/Z Expert Predictions Std       64.2995\n",
      "trainer/Z Expert Predictions Max     1786.46\n",
      "trainer/Z Expert Predictions Min     1419.01\n",
      "trainer/Z Policy Predictions Mean    1256.49\n",
      "trainer/Z Policy Predictions Std      459.51\n",
      "trainer/Z Policy Predictions Max     1624.74\n",
      "trainer/Z Policy Predictions Min      -12.8073\n",
      "trainer/Z Expert Targets Mean        1646.28\n",
      "trainer/Z Expert Targets Std           64.2825\n",
      "trainer/Z Expert Targets Max         1770.32\n",
      "trainer/Z Expert Targets Min         1400.91\n",
      "trainer/Z Policy Targets Mean        1244.7\n",
      "trainer/Z Policy Targets Std          459.547\n",
      "trainer/Z Policy Targets Max         1597.75\n",
      "trainer/Z Policy Targets Min          -11.3624\n",
      "trainer/Log Pis Mean                   56.5063\n",
      "trainer/Log Pis Std                    24.2329\n",
      "trainer/Policy mu Mean                  0.2401\n",
      "trainer/Policy mu Std                   3.11641\n",
      "trainer/Policy log std Mean            -3.13307\n",
      "trainer/Policy log std Std              1.11002\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        254614\n",
      "exploration/num paths total          1406\n",
      "evaluation/num steps total              1.45661e+06\n",
      "evaluation/num paths total           2557\n",
      "evaluation/path length Mean           793.182\n",
      "evaluation/path length Std            273.874\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            247\n",
      "evaluation/Rewards Mean                 5.25222\n",
      "evaluation/Rewards Std                  0.179198\n",
      "evaluation/Rewards Max                  5.82323\n",
      "evaluation/Rewards Min                  3.32854\n",
      "evaluation/Returns Mean              4165.96\n",
      "evaluation/Returns Std               1479.01\n",
      "evaluation/Returns Max               5292.4\n",
      "evaluation/Returns Min               1212.51\n",
      "evaluation/Estimation Bias Mean      1362.48\n",
      "evaluation/Estimation Bias Std        311.657\n",
      "evaluation/EB/Q_True Mean              54.6873\n",
      "evaluation/EB/Q_True Std              156.07\n",
      "evaluation/EB/Q_Pred Mean            1417.16\n",
      "evaluation/EB/Q_Pred Std              240.49\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4165.96\n",
      "evaluation/Actions Mean                 0.0720563\n",
      "evaluation/Actions Std                  0.509025\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.09989\n",
      "time/backward_zf1 (s)                   2.67395\n",
      "time/backward_zf2 (s)                   2.52658\n",
      "time/data sampling (s)                  0.4276\n",
      "time/data storing (s)                   0.0172295\n",
      "time/evaluation sampling (s)            2.42917\n",
      "time/exploration sampling (s)           0.515842\n",
      "time/logging (s)                        0.0121561\n",
      "time/preback_alpha (s)                  0.66206\n",
      "time/preback_policy (s)                 1.19862\n",
      "time/preback_start (s)                  0.206349\n",
      "time/preback_zf (s)                     7.02848\n",
      "time/saving (s)                         3.969e-06\n",
      "time/training (s)                       3.47222\n",
      "time/epoch (s)                         23.2702\n",
      "time/total (s)                       5289\n",
      "Epoch                                 249\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:54:03.079285 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 250 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 261000\n",
      "trainer/ZF1 Loss                      290.011\n",
      "trainer/ZF2 Loss                      304.606\n",
      "trainer/ZF Expert Reward               15.0601\n",
      "trainer/ZF Policy Reward               10.39\n",
      "trainer/ZF CHI2 Term                  295.901\n",
      "trainer/Policy Loss                 -1228.2\n",
      "trainer/Bias Loss                      35.8615\n",
      "trainer/Bias Value                     15.4954\n",
      "trainer/Policy Grad Norm              261.98\n",
      "trainer/Policy Param Norm              56.3982\n",
      "trainer/Zf1 Grad Norm               13228.6\n",
      "trainer/Zf1 Param Norm                156.625\n",
      "trainer/Zf2 Grad Norm               12887.7\n",
      "trainer/Zf2 Param Norm                154.78\n",
      "trainer/Z Expert Predictions Mean    1646.14\n",
      "trainer/Z Expert Predictions Std       77.7366\n",
      "trainer/Z Expert Predictions Max     1786.01\n",
      "trainer/Z Expert Predictions Min      868.163\n",
      "trainer/Z Policy Predictions Mean    1223.17\n",
      "trainer/Z Policy Predictions Std      479.737\n",
      "trainer/Z Policy Predictions Max     1625.11\n",
      "trainer/Z Policy Predictions Min      -37.9034\n",
      "trainer/Z Expert Targets Mean        1631.08\n",
      "trainer/Z Expert Targets Std           79.0856\n",
      "trainer/Z Expert Targets Max         1756.52\n",
      "trainer/Z Expert Targets Min          857.669\n",
      "trainer/Z Policy Targets Mean        1212.78\n",
      "trainer/Z Policy Targets Std          475.022\n",
      "trainer/Z Policy Targets Max         1597.57\n",
      "trainer/Z Policy Targets Min          -32.322\n",
      "trainer/Log Pis Mean                   53.4237\n",
      "trainer/Log Pis Std                    24.6628\n",
      "trainer/Policy mu Mean                  0.102502\n",
      "trainer/Policy mu Std                   3.36004\n",
      "trainer/Policy log std Mean            -2.98598\n",
      "trainer/Policy log std Std              1.16464\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        255614\n",
      "exploration/num paths total          1407\n",
      "evaluation/num steps total              1.46577e+06\n",
      "evaluation/num paths total           2567\n",
      "evaluation/path length Mean           916.2\n",
      "evaluation/path length Std            251.4\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            162\n",
      "evaluation/Rewards Mean                 5.30556\n",
      "evaluation/Rewards Std                  0.0914194\n",
      "evaluation/Rewards Max                  5.54092\n",
      "evaluation/Rewards Min                  4.66375\n",
      "evaluation/Returns Mean              4860.95\n",
      "evaluation/Returns Std               1345.89\n",
      "evaluation/Returns Max               5319.51\n",
      "evaluation/Returns Min                823.324\n",
      "evaluation/Estimation Bias Mean      1457.04\n",
      "evaluation/Estimation Bias Std        233.44\n",
      "evaluation/EB/Q_True Mean              52.4245\n",
      "evaluation/EB/Q_True Std              153.805\n",
      "evaluation/EB/Q_Pred Mean            1509.46\n",
      "evaluation/EB/Q_Pred Std              131.212\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4860.95\n",
      "evaluation/Actions Mean                 0.0766039\n",
      "evaluation/Actions Std                  0.510143\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.07919\n",
      "time/backward_zf1 (s)                   2.69052\n",
      "time/backward_zf2 (s)                   2.52694\n",
      "time/data sampling (s)                  0.482327\n",
      "time/data storing (s)                   0.0181674\n",
      "time/evaluation sampling (s)            2.36769\n",
      "time/exploration sampling (s)           0.559934\n",
      "time/logging (s)                        0.0126233\n",
      "time/preback_alpha (s)                  0.669909\n",
      "time/preback_policy (s)                 1.20529\n",
      "time/preback_start (s)                  0.206763\n",
      "time/preback_zf (s)                     7.07511\n",
      "time/saving (s)                         2.928e-06\n",
      "time/training (s)                       3.51322\n",
      "time/epoch (s)                         23.4077\n",
      "time/total (s)                       5312.43\n",
      "Epoch                                 250\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:54:26.907847 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 251 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 262000\n",
      "trainer/ZF1 Loss                      520.8\n",
      "trainer/ZF2 Loss                      540.067\n",
      "trainer/ZF Expert Reward               19.7854\n",
      "trainer/ZF Policy Reward               12.2283\n",
      "trainer/ZF CHI2 Term                  533.847\n",
      "trainer/Policy Loss                 -1188.71\n",
      "trainer/Bias Loss                      44.3017\n",
      "trainer/Bias Value                     15.4875\n",
      "trainer/Policy Grad Norm              257.894\n",
      "trainer/Policy Param Norm              56.4544\n",
      "trainer/Zf1 Grad Norm               18279.2\n",
      "trainer/Zf1 Param Norm                156.92\n",
      "trainer/Zf2 Grad Norm               18661.5\n",
      "trainer/Zf2 Param Norm                155.047\n",
      "trainer/Z Expert Predictions Mean    1636.64\n",
      "trainer/Z Expert Predictions Std      124.006\n",
      "trainer/Z Expert Predictions Max     1787.89\n",
      "trainer/Z Expert Predictions Min       47.8895\n",
      "trainer/Z Policy Predictions Mean    1187.6\n",
      "trainer/Z Policy Predictions Std      489.46\n",
      "trainer/Z Policy Predictions Max     1644.54\n",
      "trainer/Z Policy Predictions Min       -2.50894\n",
      "trainer/Z Expert Targets Mean        1616.86\n",
      "trainer/Z Expert Targets Std          124.434\n",
      "trainer/Z Expert Targets Max         1762.45\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1175.37\n",
      "trainer/Z Policy Targets Std          489.437\n",
      "trainer/Z Policy Targets Max         1587.13\n",
      "trainer/Z Policy Targets Min           -7.49312\n",
      "trainer/Log Pis Mean                   57.1367\n",
      "trainer/Log Pis Std                    25.9729\n",
      "trainer/Policy mu Mean                  0.313308\n",
      "trainer/Policy mu Std                   3.58503\n",
      "trainer/Policy log std Mean            -2.93276\n",
      "trainer/Policy log std Std              1.22574\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        257614\n",
      "exploration/num paths total          1409\n",
      "evaluation/num steps total              1.47577e+06\n",
      "evaluation/num paths total           2577\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30663\n",
      "evaluation/Rewards Std                  0.0832883\n",
      "evaluation/Rewards Max                  5.53402\n",
      "evaluation/Rewards Min                  4.71723\n",
      "evaluation/Returns Mean              5306.63\n",
      "evaluation/Returns Std                  4.40251\n",
      "evaluation/Returns Max               5315.49\n",
      "evaluation/Returns Min               5299.72\n",
      "evaluation/Estimation Bias Mean      1462.42\n",
      "evaluation/Estimation Bias Std        163.073\n",
      "evaluation/EB/Q_True Mean              47.9002\n",
      "evaluation/EB/Q_True Std              147.51\n",
      "evaluation/EB/Q_Pred Mean            1510.32\n",
      "evaluation/EB/Q_Pred Std               64.5088\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5306.63\n",
      "evaluation/Actions Mean                 0.0803464\n",
      "evaluation/Actions Std                  0.515789\n",
      "evaluation/Actions Max                  0.99999\n",
      "evaluation/Actions Min                 -0.998216\n",
      "time/backward_policy (s)                2.18687\n",
      "time/backward_zf1 (s)                   2.79265\n",
      "time/backward_zf2 (s)                   2.67671\n",
      "time/data sampling (s)                  0.485861\n",
      "time/data storing (s)                   0.017986\n",
      "time/evaluation sampling (s)            2.37959\n",
      "time/exploration sampling (s)           0.553209\n",
      "time/logging (s)                        0.0133444\n",
      "time/preback_alpha (s)                  0.679198\n",
      "time/preback_policy (s)                 1.26429\n",
      "time/preback_start (s)                  0.206104\n",
      "time/preback_zf (s)                     7.14894\n",
      "time/saving (s)                         3.11399e-06\n",
      "time/training (s)                       3.34644\n",
      "time/epoch (s)                         23.7512\n",
      "time/total (s)                       5336.2\n",
      "Epoch                                 251\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:54:50.607093 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 252 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 263000\n",
      "trainer/ZF1 Loss                      310.402\n",
      "trainer/ZF2 Loss                      249.619\n",
      "trainer/ZF Expert Reward               16.4796\n",
      "trainer/ZF Policy Reward                4.96998\n",
      "trainer/ZF CHI2 Term                  280.29\n",
      "trainer/Policy Loss                 -1227.86\n",
      "trainer/Bias Loss                      36.4669\n",
      "trainer/Bias Value                     15.4802\n",
      "trainer/Policy Grad Norm              255.463\n",
      "trainer/Policy Param Norm              56.5085\n",
      "trainer/Zf1 Grad Norm               12863.3\n",
      "trainer/Zf1 Param Norm                157.18\n",
      "trainer/Zf2 Grad Norm               10921.9\n",
      "trainer/Zf2 Param Norm                155.304\n",
      "trainer/Z Expert Predictions Mean    1624.02\n",
      "trainer/Z Expert Predictions Std       71.035\n",
      "trainer/Z Expert Predictions Max     1737.42\n",
      "trainer/Z Expert Predictions Min     1186.47\n",
      "trainer/Z Policy Predictions Mean    1222.06\n",
      "trainer/Z Policy Predictions Std      439.151\n",
      "trainer/Z Policy Predictions Max     1613.04\n",
      "trainer/Z Policy Predictions Min      -28.1567\n",
      "trainer/Z Expert Targets Mean        1607.54\n",
      "trainer/Z Expert Targets Std           73.2777\n",
      "trainer/Z Expert Targets Max         1728.5\n",
      "trainer/Z Expert Targets Min         1147.29\n",
      "trainer/Z Policy Targets Mean        1217.09\n",
      "trainer/Z Policy Targets Std          439.344\n",
      "trainer/Z Policy Targets Max         1578.79\n",
      "trainer/Z Policy Targets Min          -27.074\n",
      "trainer/Log Pis Mean                   53.4934\n",
      "trainer/Log Pis Std                    21.996\n",
      "trainer/Policy mu Mean                  0.259782\n",
      "trainer/Policy mu Std                   2.90244\n",
      "trainer/Policy log std Mean            -3.02173\n",
      "trainer/Policy log std Std              1.11602\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        257614\n",
      "exploration/num paths total          1409\n",
      "evaluation/num steps total              1.48492e+06\n",
      "evaluation/num paths total           2587\n",
      "evaluation/path length Mean           914.8\n",
      "evaluation/path length Std            255.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            148\n",
      "evaluation/Rewards Mean                 5.32599\n",
      "evaluation/Rewards Std                  0.100085\n",
      "evaluation/Rewards Max                  5.53175\n",
      "evaluation/Rewards Min                  4.07331\n",
      "evaluation/Returns Mean              4872.21\n",
      "evaluation/Returns Std               1379.87\n",
      "evaluation/Returns Max               5336.75\n",
      "evaluation/Returns Min                732.631\n",
      "evaluation/Estimation Bias Mean      1441.92\n",
      "evaluation/Estimation Bias Std        212.624\n",
      "evaluation/EB/Q_True Mean              52.6564\n",
      "evaluation/EB/Q_True Std              154.342\n",
      "evaluation/EB/Q_Pred Mean            1494.57\n",
      "evaluation/EB/Q_Pred Std              110.426\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4872.21\n",
      "evaluation/Actions Mean                 0.0734489\n",
      "evaluation/Actions Std                  0.510286\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.18818\n",
      "time/backward_zf1 (s)                   2.79828\n",
      "time/backward_zf2 (s)                   2.61912\n",
      "time/data sampling (s)                  0.445713\n",
      "time/data storing (s)                   0.0186737\n",
      "time/evaluation sampling (s)            2.57827\n",
      "time/exploration sampling (s)           0.549103\n",
      "time/logging (s)                        0.0119308\n",
      "time/preback_alpha (s)                  0.662379\n",
      "time/preback_policy (s)                 1.27223\n",
      "time/preback_start (s)                  0.207501\n",
      "time/preback_zf (s)                     7.06298\n",
      "time/saving (s)                         3.253e-06\n",
      "time/training (s)                       3.20617\n",
      "time/epoch (s)                         23.6205\n",
      "time/total (s)                       5359.85\n",
      "Epoch                                 252\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:55:14.299585 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 253 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 264000\n",
      "trainer/ZF1 Loss                      215.362\n",
      "trainer/ZF2 Loss                      217.703\n",
      "trainer/ZF Expert Reward               15.657\n",
      "trainer/ZF Policy Reward                8.28566\n",
      "trainer/ZF CHI2 Term                  216.048\n",
      "trainer/Policy Loss                 -1210.51\n",
      "trainer/Bias Loss                      28.3285\n",
      "trainer/Bias Value                     15.4746\n",
      "trainer/Policy Grad Norm              302.361\n",
      "trainer/Policy Param Norm              56.5605\n",
      "trainer/Zf1 Grad Norm               11204.5\n",
      "trainer/Zf1 Param Norm                157.43\n",
      "trainer/Zf2 Grad Norm               10876\n",
      "trainer/Zf2 Param Norm                155.535\n",
      "trainer/Z Expert Predictions Mean    1621.48\n",
      "trainer/Z Expert Predictions Std       55.0882\n",
      "trainer/Z Expert Predictions Max     1748.38\n",
      "trainer/Z Expert Predictions Min     1450.5\n",
      "trainer/Z Policy Predictions Mean    1207.35\n",
      "trainer/Z Policy Predictions Std      460.671\n",
      "trainer/Z Policy Predictions Max     1577.66\n",
      "trainer/Z Policy Predictions Min      -44.9101\n",
      "trainer/Z Expert Targets Mean        1605.82\n",
      "trainer/Z Expert Targets Std           55.778\n",
      "trainer/Z Expert Targets Max         1728.46\n",
      "trainer/Z Expert Targets Min         1449.15\n",
      "trainer/Z Policy Targets Mean        1199.06\n",
      "trainer/Z Policy Targets Std          458.796\n",
      "trainer/Z Policy Targets Max         1574.94\n",
      "trainer/Z Policy Targets Min          -39.7923\n",
      "trainer/Log Pis Mean                   56.4616\n",
      "trainer/Log Pis Std                    24.933\n",
      "trainer/Policy mu Mean                  0.326083\n",
      "trainer/Policy mu Std                   3.45546\n",
      "trainer/Policy log std Mean            -3.02348\n",
      "trainer/Policy log std Std              1.19597\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        259614\n",
      "exploration/num paths total          1411\n",
      "evaluation/num steps total              1.49492e+06\n",
      "evaluation/num paths total           2597\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29573\n",
      "evaluation/Rewards Std                  0.0890631\n",
      "evaluation/Rewards Max                  5.50024\n",
      "evaluation/Rewards Min                  4.55869\n",
      "evaluation/Returns Mean              5295.73\n",
      "evaluation/Returns Std                  6.86074\n",
      "evaluation/Returns Max               5303.88\n",
      "evaluation/Returns Min               5281.71\n",
      "evaluation/Estimation Bias Mean      1446.54\n",
      "evaluation/Estimation Bias Std        170.418\n",
      "evaluation/EB/Q_True Mean              47.8594\n",
      "evaluation/EB/Q_True Std              147.4\n",
      "evaluation/EB/Q_Pred Mean            1494.4\n",
      "evaluation/EB/Q_Pred Std               74.3518\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5295.73\n",
      "evaluation/Actions Mean                 0.0599661\n",
      "evaluation/Actions Std                  0.486061\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999704\n",
      "time/backward_policy (s)                2.13026\n",
      "time/backward_zf1 (s)                   2.75587\n",
      "time/backward_zf2 (s)                   2.56819\n",
      "time/data sampling (s)                  0.485493\n",
      "time/data storing (s)                   0.0162696\n",
      "time/evaluation sampling (s)            2.51827\n",
      "time/exploration sampling (s)           0.537486\n",
      "time/logging (s)                        0.0135192\n",
      "time/preback_alpha (s)                  0.674423\n",
      "time/preback_policy (s)                 1.19719\n",
      "time/preback_start (s)                  0.202978\n",
      "time/preback_zf (s)                     7.06132\n",
      "time/saving (s)                         3.111e-06\n",
      "time/training (s)                       3.45003\n",
      "time/epoch (s)                         23.6113\n",
      "time/total (s)                       5383.48\n",
      "Epoch                                 253\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:55:38.035934 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 254 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 265000\n",
      "trainer/ZF1 Loss                      272.269\n",
      "trainer/ZF2 Loss                      239.744\n",
      "trainer/ZF Expert Reward               18.9993\n",
      "trainer/ZF Policy Reward               10.3355\n",
      "trainer/ZF CHI2 Term                  258.923\n",
      "trainer/Policy Loss                 -1202.9\n",
      "trainer/Bias Loss                      50.0499\n",
      "trainer/Bias Value                     15.471\n",
      "trainer/Policy Grad Norm              287.266\n",
      "trainer/Policy Param Norm              56.6154\n",
      "trainer/Zf1 Grad Norm               14131.5\n",
      "trainer/Zf1 Param Norm                157.69\n",
      "trainer/Zf2 Grad Norm               12051.4\n",
      "trainer/Zf2 Param Norm                155.767\n",
      "trainer/Z Expert Predictions Mean    1608.04\n",
      "trainer/Z Expert Predictions Std      116.722\n",
      "trainer/Z Expert Predictions Max     1726.99\n",
      "trainer/Z Expert Predictions Min      -11.4837\n",
      "trainer/Z Policy Predictions Mean    1196.63\n",
      "trainer/Z Policy Predictions Std      452.289\n",
      "trainer/Z Policy Predictions Max     1594.73\n",
      "trainer/Z Policy Predictions Min      -21.4262\n",
      "trainer/Z Expert Targets Mean        1589.04\n",
      "trainer/Z Expert Targets Std          115.071\n",
      "trainer/Z Expert Targets Max         1707.38\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1186.3\n",
      "trainer/Z Policy Targets Std          449.674\n",
      "trainer/Z Policy Targets Max         1554.93\n",
      "trainer/Z Policy Targets Min          -14.3404\n",
      "trainer/Log Pis Mean                   55.15\n",
      "trainer/Log Pis Std                    25.5665\n",
      "trainer/Policy mu Mean                  0.300694\n",
      "trainer/Policy mu Std                   3.56806\n",
      "trainer/Policy log std Mean            -2.91703\n",
      "trainer/Policy log std Std              1.24927\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        260614\n",
      "exploration/num paths total          1412\n",
      "evaluation/num steps total              1.50492e+06\n",
      "evaluation/num paths total           2607\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29907\n",
      "evaluation/Rewards Std                  0.0918705\n",
      "evaluation/Rewards Max                  5.62794\n",
      "evaluation/Rewards Min                  4.77965\n",
      "evaluation/Returns Mean              5299.07\n",
      "evaluation/Returns Std                  7.40448\n",
      "evaluation/Returns Max               5312.26\n",
      "evaluation/Returns Min               5286.97\n",
      "evaluation/Estimation Bias Mean      1398.73\n",
      "evaluation/Estimation Bias Std        165.51\n",
      "evaluation/EB/Q_True Mean              47.7497\n",
      "evaluation/EB/Q_True Std              147.03\n",
      "evaluation/EB/Q_Pred Mean            1446.48\n",
      "evaluation/EB/Q_Pred Std               91.6111\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5299.07\n",
      "evaluation/Actions Mean                 0.0799169\n",
      "evaluation/Actions Std                  0.524148\n",
      "evaluation/Actions Max                  0.999997\n",
      "evaluation/Actions Min                 -0.999998\n",
      "time/backward_policy (s)                2.22224\n",
      "time/backward_zf1 (s)                   2.77801\n",
      "time/backward_zf2 (s)                   2.66942\n",
      "time/data sampling (s)                  0.479647\n",
      "time/data storing (s)                   0.0183153\n",
      "time/evaluation sampling (s)            2.53428\n",
      "time/exploration sampling (s)           0.543234\n",
      "time/logging (s)                        0.0134639\n",
      "time/preback_alpha (s)                  0.670614\n",
      "time/preback_policy (s)                 1.30575\n",
      "time/preback_start (s)                  0.209103\n",
      "time/preback_zf (s)                     7.01832\n",
      "time/saving (s)                         3.602e-06\n",
      "time/training (s)                       3.1916\n",
      "time/epoch (s)                         23.654\n",
      "time/total (s)                       5407.16\n",
      "Epoch                                 254\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:56:01.740248 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 255 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 266000\n",
      "trainer/ZF1 Loss                      274.457\n",
      "trainer/ZF2 Loss                      286.134\n",
      "trainer/ZF Expert Reward               14.8483\n",
      "trainer/ZF Policy Reward                7.70374\n",
      "trainer/ZF CHI2 Term                  279.186\n",
      "trainer/Policy Loss                 -1162.84\n",
      "trainer/Bias Loss                      44.963\n",
      "trainer/Bias Value                     15.464\n",
      "trainer/Policy Grad Norm              215.354\n",
      "trainer/Policy Param Norm              56.6703\n",
      "trainer/Zf1 Grad Norm               12531.7\n",
      "trainer/Zf1 Param Norm                157.98\n",
      "trainer/Zf2 Grad Norm               11784.2\n",
      "trainer/Zf2 Param Norm                156.035\n",
      "trainer/Z Expert Predictions Mean    1597.21\n",
      "trainer/Z Expert Predictions Std       58.9021\n",
      "trainer/Z Expert Predictions Max     1719.23\n",
      "trainer/Z Expert Predictions Min     1437.72\n",
      "trainer/Z Policy Predictions Mean    1155.53\n",
      "trainer/Z Policy Predictions Std      478.9\n",
      "trainer/Z Policy Predictions Max     1580.55\n",
      "trainer/Z Policy Predictions Min      -19.0915\n",
      "trainer/Z Expert Targets Mean        1582.36\n",
      "trainer/Z Expert Targets Std           60.3224\n",
      "trainer/Z Expert Targets Max         1705.14\n",
      "trainer/Z Expert Targets Min         1418.55\n",
      "trainer/Z Policy Targets Mean        1147.83\n",
      "trainer/Z Policy Targets Std          475.596\n",
      "trainer/Z Policy Targets Max         1583.31\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   56.6045\n",
      "trainer/Log Pis Std                    24.8457\n",
      "trainer/Policy mu Mean                  0.337397\n",
      "trainer/Policy mu Std                   3.23952\n",
      "trainer/Policy log std Mean            -2.87677\n",
      "trainer/Policy log std Std              1.20319\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        260614\n",
      "exploration/num paths total          1412\n",
      "evaluation/num steps total              1.51492e+06\n",
      "evaluation/num paths total           2617\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29844\n",
      "evaluation/Rewards Std                  0.0903932\n",
      "evaluation/Rewards Max                  5.57331\n",
      "evaluation/Rewards Min                  4.81126\n",
      "evaluation/Returns Mean              5298.44\n",
      "evaluation/Returns Std                  9.63693\n",
      "evaluation/Returns Max               5310.64\n",
      "evaluation/Returns Min               5278.7\n",
      "evaluation/Estimation Bias Mean      1409.86\n",
      "evaluation/Estimation Bias Std        167.618\n",
      "evaluation/EB/Q_True Mean              47.7897\n",
      "evaluation/EB/Q_True Std              147.165\n",
      "evaluation/EB/Q_Pred Mean            1457.65\n",
      "evaluation/EB/Q_Pred Std               81.2301\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5298.44\n",
      "evaluation/Actions Mean                 0.0804824\n",
      "evaluation/Actions Std                  0.512701\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.999777\n",
      "time/backward_policy (s)                2.22203\n",
      "time/backward_zf1 (s)                   2.81959\n",
      "time/backward_zf2 (s)                   2.66194\n",
      "time/data sampling (s)                  0.455276\n",
      "time/data storing (s)                   0.0175408\n",
      "time/evaluation sampling (s)            2.61511\n",
      "time/exploration sampling (s)           0.523552\n",
      "time/logging (s)                        0.0166628\n",
      "time/preback_alpha (s)                  0.675657\n",
      "time/preback_policy (s)                 1.30676\n",
      "time/preback_start (s)                  0.213003\n",
      "time/preback_zf (s)                     7.01617\n",
      "time/saving (s)                         3.366e-06\n",
      "time/training (s)                       3.07897\n",
      "time/epoch (s)                         23.6223\n",
      "time/total (s)                       5430.81\n",
      "Epoch                                 255\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:56:25.491732 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 256 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 267000\n",
      "trainer/ZF1 Loss                      231.99\n",
      "trainer/ZF2 Loss                      228.415\n",
      "trainer/ZF Expert Reward               15.0081\n",
      "trainer/ZF Policy Reward               11.9524\n",
      "trainer/ZF CHI2 Term                  229.357\n",
      "trainer/Policy Loss                 -1181.59\n",
      "trainer/Bias Loss                      25.9743\n",
      "trainer/Bias Value                     15.4524\n",
      "trainer/Policy Grad Norm              244.087\n",
      "trainer/Policy Param Norm              56.7317\n",
      "trainer/Zf1 Grad Norm               10613.4\n",
      "trainer/Zf1 Param Norm                158.267\n",
      "trainer/Zf2 Grad Norm               10168.2\n",
      "trainer/Zf2 Param Norm                156.303\n",
      "trainer/Z Expert Predictions Mean    1584.77\n",
      "trainer/Z Expert Predictions Std      119.708\n",
      "trainer/Z Expert Predictions Max     1729.12\n",
      "trainer/Z Expert Predictions Min       20.0842\n",
      "trainer/Z Policy Predictions Mean    1179.22\n",
      "trainer/Z Policy Predictions Std      466.939\n",
      "trainer/Z Policy Predictions Max     1567.78\n",
      "trainer/Z Policy Predictions Min      -20.7449\n",
      "trainer/Z Expert Targets Mean        1569.76\n",
      "trainer/Z Expert Targets Std          121.656\n",
      "trainer/Z Expert Targets Max         1717.84\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1167.27\n",
      "trainer/Z Policy Targets Std          465.88\n",
      "trainer/Z Policy Targets Max         1579.69\n",
      "trainer/Z Policy Targets Min          -22.0223\n",
      "trainer/Log Pis Mean                   55.4871\n",
      "trainer/Log Pis Std                    24.9559\n",
      "trainer/Policy mu Mean                  0.297641\n",
      "trainer/Policy mu Std                   3.63397\n",
      "trainer/Policy log std Mean            -2.99712\n",
      "trainer/Policy log std Std              1.23455\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        261614\n",
      "exploration/num paths total          1413\n",
      "evaluation/num steps total              1.52492e+06\n",
      "evaluation/num paths total           2627\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30663\n",
      "evaluation/Rewards Std                  0.0866746\n",
      "evaluation/Rewards Max                  5.54896\n",
      "evaluation/Rewards Min                  4.76796\n",
      "evaluation/Returns Mean              5306.63\n",
      "evaluation/Returns Std                  3.91378\n",
      "evaluation/Returns Max               5313.49\n",
      "evaluation/Returns Min               5299.64\n",
      "evaluation/Estimation Bias Mean      1389.8\n",
      "evaluation/Estimation Bias Std        166.184\n",
      "evaluation/EB/Q_True Mean              47.8931\n",
      "evaluation/EB/Q_True Std              147.471\n",
      "evaluation/EB/Q_Pred Mean            1437.69\n",
      "evaluation/EB/Q_Pred Std               80.4018\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5306.63\n",
      "evaluation/Actions Mean                 0.0829527\n",
      "evaluation/Actions Std                  0.525889\n",
      "evaluation/Actions Max                  0.999935\n",
      "evaluation/Actions Min                 -0.998926\n",
      "time/backward_policy (s)                2.2302\n",
      "time/backward_zf1 (s)                   2.79311\n",
      "time/backward_zf2 (s)                   2.65241\n",
      "time/data sampling (s)                  0.460582\n",
      "time/data storing (s)                   0.0192058\n",
      "time/evaluation sampling (s)            2.61416\n",
      "time/exploration sampling (s)           0.552646\n",
      "time/logging (s)                        0.0128207\n",
      "time/preback_alpha (s)                  0.6646\n",
      "time/preback_policy (s)                 1.26585\n",
      "time/preback_start (s)                  0.21606\n",
      "time/preback_zf (s)                     6.99157\n",
      "time/saving (s)                         3.13e-06\n",
      "time/training (s)                       3.19426\n",
      "time/epoch (s)                         23.6675\n",
      "time/total (s)                       5454.5\n",
      "Epoch                                 256\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:56:49.290392 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 257 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 268000\n",
      "trainer/ZF1 Loss                     2461.97\n",
      "trainer/ZF2 Loss                     2421.97\n",
      "trainer/ZF Expert Reward                8.75269\n",
      "trainer/ZF Policy Reward                9.55322\n",
      "trainer/ZF CHI2 Term                 2434.98\n",
      "trainer/Policy Loss                 -1163.77\n",
      "trainer/Bias Loss                      44.2625\n",
      "trainer/Bias Value                     15.4501\n",
      "trainer/Policy Grad Norm              197.906\n",
      "trainer/Policy Param Norm              56.7833\n",
      "trainer/Zf1 Grad Norm               20547.6\n",
      "trainer/Zf1 Param Norm                158.519\n",
      "trainer/Zf2 Grad Norm               28439\n",
      "trainer/Zf2 Param Norm                156.53\n",
      "trainer/Z Expert Predictions Mean    1575.71\n",
      "trainer/Z Expert Predictions Std       67.6183\n",
      "trainer/Z Expert Predictions Max     1707.3\n",
      "trainer/Z Expert Predictions Min     1128.13\n",
      "trainer/Z Policy Predictions Mean    1158.66\n",
      "trainer/Z Policy Predictions Std      452.226\n",
      "trainer/Z Policy Predictions Max     1574.74\n",
      "trainer/Z Policy Predictions Min      -39.4387\n",
      "trainer/Z Expert Targets Mean        1566.96\n",
      "trainer/Z Expert Targets Std           67.3017\n",
      "trainer/Z Expert Targets Max         1699.84\n",
      "trainer/Z Expert Targets Min         1113.74\n",
      "trainer/Z Policy Targets Mean        1149.11\n",
      "trainer/Z Policy Targets Std          458.316\n",
      "trainer/Z Policy Targets Max         1583.74\n",
      "trainer/Z Policy Targets Min          -22.0497\n",
      "trainer/Log Pis Mean                   56.1999\n",
      "trainer/Log Pis Std                    23.767\n",
      "trainer/Policy mu Mean                  0.364964\n",
      "trainer/Policy mu Std                   2.95824\n",
      "trainer/Policy log std Mean            -2.95828\n",
      "trainer/Policy log std Std              1.18172\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        263614\n",
      "exploration/num paths total          1415\n",
      "evaluation/num steps total              1.53183e+06\n",
      "evaluation/num paths total           2639\n",
      "evaluation/path length Mean           575.917\n",
      "evaluation/path length Std            310.225\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            159\n",
      "evaluation/Rewards Mean                 5.24338\n",
      "evaluation/Rewards Std                  0.191415\n",
      "evaluation/Rewards Max                  6.41317\n",
      "evaluation/Rewards Min                  3.60577\n",
      "evaluation/Returns Mean              3019.75\n",
      "evaluation/Returns Std               1665.22\n",
      "evaluation/Returns Max               5299.32\n",
      "evaluation/Returns Min                758.545\n",
      "evaluation/Estimation Bias Mean      1249.76\n",
      "evaluation/Estimation Bias Std        375.413\n",
      "evaluation/EB/Q_True Mean              69.2507\n",
      "evaluation/EB/Q_True Std              173.068\n",
      "evaluation/EB/Q_Pred Mean            1319.01\n",
      "evaluation/EB/Q_Pred Std              280.349\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3019.75\n",
      "evaluation/Actions Mean                 0.0901837\n",
      "evaluation/Actions Std                  0.564447\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.2586\n",
      "time/backward_zf1 (s)                   2.85089\n",
      "time/backward_zf2 (s)                   2.72241\n",
      "time/data sampling (s)                  0.461407\n",
      "time/data storing (s)                   0.0181519\n",
      "time/evaluation sampling (s)            2.29964\n",
      "time/exploration sampling (s)           0.559685\n",
      "time/logging (s)                        0.00975633\n",
      "time/preback_alpha (s)                  0.6851\n",
      "time/preback_policy (s)                 1.32562\n",
      "time/preback_start (s)                  0.214983\n",
      "time/preback_zf (s)                     7.12192\n",
      "time/saving (s)                         2.638e-06\n",
      "time/training (s)                       3.1835\n",
      "time/epoch (s)                         23.7117\n",
      "time/total (s)                       5478.24\n",
      "Epoch                                 257\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:57:12.939939 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 258 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 269000\n",
      "trainer/ZF1 Loss                      320.972\n",
      "trainer/ZF2 Loss                      280.811\n",
      "trainer/ZF Expert Reward               17.6661\n",
      "trainer/ZF Policy Reward               12.6478\n",
      "trainer/ZF CHI2 Term                  302.885\n",
      "trainer/Policy Loss                 -1187.75\n",
      "trainer/Bias Loss                      34.5891\n",
      "trainer/Bias Value                     15.4413\n",
      "trainer/Policy Grad Norm              244.349\n",
      "trainer/Policy Param Norm              56.836\n",
      "trainer/Zf1 Grad Norm               17770.9\n",
      "trainer/Zf1 Param Norm                158.802\n",
      "trainer/Zf2 Grad Norm               11180.8\n",
      "trainer/Zf2 Param Norm                156.803\n",
      "trainer/Z Expert Predictions Mean    1573.02\n",
      "trainer/Z Expert Predictions Std       67.9055\n",
      "trainer/Z Expert Predictions Max     1705.62\n",
      "trainer/Z Expert Predictions Min     1189.17\n",
      "trainer/Z Policy Predictions Mean    1184.54\n",
      "trainer/Z Policy Predictions Std      421.952\n",
      "trainer/Z Policy Predictions Max     1543.23\n",
      "trainer/Z Policy Predictions Min      -12.3247\n",
      "trainer/Z Expert Targets Mean        1555.35\n",
      "trainer/Z Expert Targets Std           68.7703\n",
      "trainer/Z Expert Targets Max         1700.61\n",
      "trainer/Z Expert Targets Min         1177.96\n",
      "trainer/Z Policy Targets Mean        1171.89\n",
      "trainer/Z Policy Targets Std          421.595\n",
      "trainer/Z Policy Targets Max         1523.54\n",
      "trainer/Z Policy Targets Min          -10.196\n",
      "trainer/Log Pis Mean                   54.2086\n",
      "trainer/Log Pis Std                    24.155\n",
      "trainer/Policy mu Mean                  0.313101\n",
      "trainer/Policy mu Std                   2.86211\n",
      "trainer/Policy log std Mean            -3.01425\n",
      "trainer/Policy log std Std              1.10629\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        263614\n",
      "exploration/num paths total          1415\n",
      "evaluation/num steps total              1.54183e+06\n",
      "evaluation/num paths total           2649\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30422\n",
      "evaluation/Rewards Std                  0.0916274\n",
      "evaluation/Rewards Max                  5.51448\n",
      "evaluation/Rewards Min                  4.7826\n",
      "evaluation/Returns Mean              5304.22\n",
      "evaluation/Returns Std                  6.55875\n",
      "evaluation/Returns Max               5312.51\n",
      "evaluation/Returns Min               5289.9\n",
      "evaluation/Estimation Bias Mean      1413.91\n",
      "evaluation/Estimation Bias Std        162.677\n",
      "evaluation/EB/Q_True Mean              47.9857\n",
      "evaluation/EB/Q_True Std              147.797\n",
      "evaluation/EB/Q_Pred Mean            1461.89\n",
      "evaluation/EB/Q_Pred Std               78.1161\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5304.22\n",
      "evaluation/Actions Mean                 0.0845888\n",
      "evaluation/Actions Std                  0.514848\n",
      "evaluation/Actions Max                  0.999889\n",
      "evaluation/Actions Min                 -0.999594\n",
      "time/backward_policy (s)                2.1391\n",
      "time/backward_zf1 (s)                   2.73173\n",
      "time/backward_zf2 (s)                   2.5801\n",
      "time/data sampling (s)                  0.464968\n",
      "time/data storing (s)                   0.0184472\n",
      "time/evaluation sampling (s)            2.55058\n",
      "time/exploration sampling (s)           0.538371\n",
      "time/logging (s)                        0.0133853\n",
      "time/preback_alpha (s)                  0.668785\n",
      "time/preback_policy (s)                 1.21292\n",
      "time/preback_start (s)                  0.20426\n",
      "time/preback_zf (s)                     7.02409\n",
      "time/saving (s)                         2.968e-06\n",
      "time/training (s)                       3.42836\n",
      "time/epoch (s)                         23.5751\n",
      "time/total (s)                       5501.84\n",
      "Epoch                                 258\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:57:36.409397 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 259 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 270000\n",
      "trainer/ZF1 Loss                      240.69\n",
      "trainer/ZF2 Loss                      254.569\n",
      "trainer/ZF Expert Reward               21.9564\n",
      "trainer/ZF Policy Reward                6.91272\n",
      "trainer/ZF CHI2 Term                  253.815\n",
      "trainer/Policy Loss                 -1182.52\n",
      "trainer/Bias Loss                      57.7271\n",
      "trainer/Bias Value                     15.4317\n",
      "trainer/Policy Grad Norm              296.848\n",
      "trainer/Policy Param Norm              56.891\n",
      "trainer/Zf1 Grad Norm               10655\n",
      "trainer/Zf1 Param Norm                159.083\n",
      "trainer/Zf2 Grad Norm               13633.4\n",
      "trainer/Zf2 Param Norm                157.064\n",
      "trainer/Z Expert Predictions Mean    1580.58\n",
      "trainer/Z Expert Predictions Std       63.5065\n",
      "trainer/Z Expert Predictions Max     1728.85\n",
      "trainer/Z Expert Predictions Min     1379.22\n",
      "trainer/Z Policy Predictions Mean    1178.96\n",
      "trainer/Z Policy Predictions Std      434.198\n",
      "trainer/Z Policy Predictions Max     1549.51\n",
      "trainer/Z Policy Predictions Min      -19.5888\n",
      "trainer/Z Expert Targets Mean        1558.62\n",
      "trainer/Z Expert Targets Std           62.2855\n",
      "trainer/Z Expert Targets Max         1698.38\n",
      "trainer/Z Expert Targets Min         1355.86\n",
      "trainer/Z Policy Targets Mean        1172.04\n",
      "trainer/Z Policy Targets Std          433.292\n",
      "trainer/Z Policy Targets Max         1542.94\n",
      "trainer/Z Policy Targets Min          -23.0328\n",
      "trainer/Log Pis Mean                   53.2384\n",
      "trainer/Log Pis Std                    25.5026\n",
      "trainer/Policy mu Mean                  0.281763\n",
      "trainer/Policy mu Std                   3.55038\n",
      "trainer/Policy log std Mean            -2.91541\n",
      "trainer/Policy log std Std              1.22469\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        264614\n",
      "exploration/num paths total          1416\n",
      "evaluation/num steps total              1.55153e+06\n",
      "evaluation/num paths total           2663\n",
      "evaluation/path length Mean           692.643\n",
      "evaluation/path length Std            413.962\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             81\n",
      "evaluation/Rewards Mean                 5.29007\n",
      "evaluation/Rewards Std                  0.148363\n",
      "evaluation/Rewards Max                  6.2064\n",
      "evaluation/Rewards Min                  3.85854\n",
      "evaluation/Returns Mean              3664.13\n",
      "evaluation/Returns Std               2218.22\n",
      "evaluation/Returns Max               5321.17\n",
      "evaluation/Returns Min                384.227\n",
      "evaluation/Estimation Bias Mean      1323.23\n",
      "evaluation/Estimation Bias Std        314.978\n",
      "evaluation/EB/Q_True Mean              49.4228\n",
      "evaluation/EB/Q_True Std              149.616\n",
      "evaluation/EB/Q_Pred Mean            1372.65\n",
      "evaluation/EB/Q_Pred Std              198.274\n",
      "evaluation/Num Paths                   14\n",
      "evaluation/Average Returns           3664.13\n",
      "evaluation/Actions Mean                 0.0848935\n",
      "evaluation/Actions Std                  0.532799\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.13839\n",
      "time/backward_zf1 (s)                   2.76418\n",
      "time/backward_zf2 (s)                   2.58915\n",
      "time/data sampling (s)                  0.468729\n",
      "time/data storing (s)                   0.0169821\n",
      "time/evaluation sampling (s)            2.33852\n",
      "time/exploration sampling (s)           0.524837\n",
      "time/logging (s)                        0.0129452\n",
      "time/preback_alpha (s)                  0.670162\n",
      "time/preback_policy (s)                 1.21551\n",
      "time/preback_start (s)                  0.207549\n",
      "time/preback_zf (s)                     7.05652\n",
      "time/saving (s)                         3.486e-06\n",
      "time/training (s)                       3.38338\n",
      "time/epoch (s)                         23.3869\n",
      "time/total (s)                       5525.25\n",
      "Epoch                                 259\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:58:00.782188 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 260 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 271000\n",
      "trainer/ZF1 Loss                     1338.47\n",
      "trainer/ZF2 Loss                      991.757\n",
      "trainer/ZF Expert Reward               11.9885\n",
      "trainer/ZF Policy Reward                8.60664\n",
      "trainer/ZF CHI2 Term                 1161.56\n",
      "trainer/Policy Loss                 -1228.34\n",
      "trainer/Bias Loss                      37.479\n",
      "trainer/Bias Value                     15.4243\n",
      "trainer/Policy Grad Norm              242.087\n",
      "trainer/Policy Param Norm              56.9442\n",
      "trainer/Zf1 Grad Norm               38429.8\n",
      "trainer/Zf1 Param Norm                159.32\n",
      "trainer/Zf2 Grad Norm               37343.9\n",
      "trainer/Zf2 Param Norm                157.338\n",
      "trainer/Z Expert Predictions Mean    1556.7\n",
      "trainer/Z Expert Predictions Std       62.1066\n",
      "trainer/Z Expert Predictions Max     1681.28\n",
      "trainer/Z Expert Predictions Min     1287.43\n",
      "trainer/Z Policy Predictions Mean    1223.15\n",
      "trainer/Z Policy Predictions Std      367.254\n",
      "trainer/Z Policy Predictions Max     1525.05\n",
      "trainer/Z Policy Predictions Min       10.2493\n",
      "trainer/Z Expert Targets Mean        1544.71\n",
      "trainer/Z Expert Targets Std           63.0774\n",
      "trainer/Z Expert Targets Max         1674.51\n",
      "trainer/Z Expert Targets Min         1268.73\n",
      "trainer/Z Policy Targets Mean        1214.54\n",
      "trainer/Z Policy Targets Std          373.729\n",
      "trainer/Z Policy Targets Max         1516.74\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   52.4857\n",
      "trainer/Log Pis Std                    19.2553\n",
      "trainer/Policy mu Mean                  0.249355\n",
      "trainer/Policy mu Std                   2.09666\n",
      "trainer/Policy log std Mean            -3.2379\n",
      "trainer/Policy log std Std              0.998977\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        265614\n",
      "exploration/num paths total          1417\n",
      "evaluation/num steps total              1.56153e+06\n",
      "evaluation/num paths total           2673\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30878\n",
      "evaluation/Rewards Std                  0.087338\n",
      "evaluation/Rewards Max                  5.54616\n",
      "evaluation/Rewards Min                  4.82872\n",
      "evaluation/Returns Mean              5308.78\n",
      "evaluation/Returns Std                 15.5549\n",
      "evaluation/Returns Max               5327.47\n",
      "evaluation/Returns Min               5267.97\n",
      "evaluation/Estimation Bias Mean      1364.01\n",
      "evaluation/Estimation Bias Std        175.341\n",
      "evaluation/EB/Q_True Mean              47.953\n",
      "evaluation/EB/Q_True Std              147.682\n",
      "evaluation/EB/Q_Pred Mean            1411.96\n",
      "evaluation/EB/Q_Pred Std               87.3864\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5308.78\n",
      "evaluation/Actions Mean                 0.0725201\n",
      "evaluation/Actions Std                  0.507822\n",
      "evaluation/Actions Max                  0.999959\n",
      "evaluation/Actions Min                 -0.999544\n",
      "time/backward_policy (s)                2.35605\n",
      "time/backward_zf1 (s)                   2.99182\n",
      "time/backward_zf2 (s)                   2.8448\n",
      "time/data sampling (s)                  0.481231\n",
      "time/data storing (s)                   0.0177447\n",
      "time/evaluation sampling (s)            2.52652\n",
      "time/exploration sampling (s)           0.54279\n",
      "time/logging (s)                        0.0155536\n",
      "time/preback_alpha (s)                  0.691034\n",
      "time/preback_policy (s)                 1.36308\n",
      "time/preback_start (s)                  0.209813\n",
      "time/preback_zf (s)                     7.14542\n",
      "time/saving (s)                         3.508e-06\n",
      "time/training (s)                       3.10714\n",
      "time/epoch (s)                         24.293\n",
      "time/total (s)                       5549.57\n",
      "Epoch                                 260\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:58:24.605432 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 261 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 272000\n",
      "trainer/ZF1 Loss                      232.594\n",
      "trainer/ZF2 Loss                      275.292\n",
      "trainer/ZF Expert Reward               12.3001\n",
      "trainer/ZF Policy Reward                6.43206\n",
      "trainer/ZF CHI2 Term                  250.761\n",
      "trainer/Policy Loss                 -1164.61\n",
      "trainer/Bias Loss                      30.2676\n",
      "trainer/Bias Value                     15.4218\n",
      "trainer/Policy Grad Norm              257.577\n",
      "trainer/Policy Param Norm              56.9827\n",
      "trainer/Zf1 Grad Norm                9967.92\n",
      "trainer/Zf1 Param Norm                159.57\n",
      "trainer/Zf2 Grad Norm               11764.8\n",
      "trainer/Zf2 Param Norm                157.588\n",
      "trainer/Z Expert Predictions Mean    1551.57\n",
      "trainer/Z Expert Predictions Std       75.0344\n",
      "trainer/Z Expert Predictions Max     1689.89\n",
      "trainer/Z Expert Predictions Min      858.16\n",
      "trainer/Z Policy Predictions Mean    1157.09\n",
      "trainer/Z Policy Predictions Std      433.79\n",
      "trainer/Z Policy Predictions Max     1533.87\n",
      "trainer/Z Policy Predictions Min      -15.6171\n",
      "trainer/Z Expert Targets Mean        1539.27\n",
      "trainer/Z Expert Targets Std           75.9135\n",
      "trainer/Z Expert Targets Max         1675.86\n",
      "trainer/Z Expert Targets Min          836.856\n",
      "trainer/Z Policy Targets Mean        1150.66\n",
      "trainer/Z Policy Targets Std          431.605\n",
      "trainer/Z Policy Targets Max         1551.08\n",
      "trainer/Z Policy Targets Min          -20.9973\n",
      "trainer/Log Pis Mean                   55.1954\n",
      "trainer/Log Pis Std                    23.6285\n",
      "trainer/Policy mu Mean                  0.30422\n",
      "trainer/Policy mu Std                   3.08935\n",
      "trainer/Policy log std Mean            -3.09666\n",
      "trainer/Policy log std Std              1.14306\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        267614\n",
      "exploration/num paths total          1419\n",
      "evaluation/num steps total              1.57002e+06\n",
      "evaluation/num paths total           2685\n",
      "evaluation/path length Mean           707.833\n",
      "evaluation/path length Std            413.212\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            113\n",
      "evaluation/Rewards Mean                 5.25836\n",
      "evaluation/Rewards Std                  0.163182\n",
      "evaluation/Rewards Max                  5.51718\n",
      "evaluation/Rewards Min                  3.73586\n",
      "evaluation/Returns Mean              3722.04\n",
      "evaluation/Returns Std               2217.96\n",
      "evaluation/Returns Max               5298.72\n",
      "evaluation/Returns Min                546.851\n",
      "evaluation/Estimation Bias Mean      1326.81\n",
      "evaluation/Estimation Bias Std        294.438\n",
      "evaluation/EB/Q_True Mean              56.0619\n",
      "evaluation/EB/Q_True Std              157.603\n",
      "evaluation/EB/Q_Pred Mean            1382.87\n",
      "evaluation/EB/Q_Pred Std              178.409\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3722.04\n",
      "evaluation/Actions Mean                 0.0851903\n",
      "evaluation/Actions Std                  0.509935\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.27607\n",
      "time/backward_zf1 (s)                   2.87299\n",
      "time/backward_zf2 (s)                   2.77752\n",
      "time/data sampling (s)                  0.468492\n",
      "time/data storing (s)                   0.0199279\n",
      "time/evaluation sampling (s)            2.3632\n",
      "time/exploration sampling (s)           0.565925\n",
      "time/logging (s)                        0.0115542\n",
      "time/preback_alpha (s)                  0.675998\n",
      "time/preback_policy (s)                 1.33145\n",
      "time/preback_start (s)                  0.208744\n",
      "time/preback_zf (s)                     7.05117\n",
      "time/saving (s)                         3.79699e-06\n",
      "time/training (s)                       3.11144\n",
      "time/epoch (s)                         23.7345\n",
      "time/total (s)                       5573.33\n",
      "Epoch                                 261\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:58:48.434638 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 262 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 273000\n",
      "trainer/ZF1 Loss                      235.85\n",
      "trainer/ZF2 Loss                      265.541\n",
      "trainer/ZF Expert Reward               12.5934\n",
      "trainer/ZF Policy Reward                8.63769\n",
      "trainer/ZF CHI2 Term                  247.953\n",
      "trainer/Policy Loss                 -1158.36\n",
      "trainer/Bias Loss                      35.8808\n",
      "trainer/Bias Value                     15.4137\n",
      "trainer/Policy Grad Norm              223.122\n",
      "trainer/Policy Param Norm              57.0329\n",
      "trainer/Zf1 Grad Norm               11491.2\n",
      "trainer/Zf1 Param Norm                159.858\n",
      "trainer/Zf2 Grad Norm               13436.6\n",
      "trainer/Zf2 Param Norm                157.892\n",
      "trainer/Z Expert Predictions Mean    1532.43\n",
      "trainer/Z Expert Predictions Std      125.93\n",
      "trainer/Z Expert Predictions Max     1713.19\n",
      "trainer/Z Expert Predictions Min        4.01314\n",
      "trainer/Z Policy Predictions Mean    1154.83\n",
      "trainer/Z Policy Predictions Std      418.56\n",
      "trainer/Z Policy Predictions Max     1507.59\n",
      "trainer/Z Policy Predictions Min      -16.3607\n",
      "trainer/Z Expert Targets Mean        1519.83\n",
      "trainer/Z Expert Targets Std          126.5\n",
      "trainer/Z Expert Targets Max         1704.05\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1146.19\n",
      "trainer/Z Policy Targets Std          418.608\n",
      "trainer/Z Policy Targets Max         1520.3\n",
      "trainer/Z Policy Targets Min          -17.8963\n",
      "trainer/Log Pis Mean                   54.8504\n",
      "trainer/Log Pis Std                    24.4526\n",
      "trainer/Policy mu Mean                  0.323303\n",
      "trainer/Policy mu Std                   3.20918\n",
      "trainer/Policy log std Mean            -2.99276\n",
      "trainer/Policy log std Std              1.19309\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        267614\n",
      "exploration/num paths total          1419\n",
      "evaluation/num steps total              1.57913e+06\n",
      "evaluation/num paths total           2695\n",
      "evaluation/path length Mean           910.5\n",
      "evaluation/path length Std            268.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            105\n",
      "evaluation/Rewards Mean                 5.30216\n",
      "evaluation/Rewards Std                  0.104528\n",
      "evaluation/Rewards Max                  5.61665\n",
      "evaluation/Rewards Min                  3.7369\n",
      "evaluation/Returns Mean              4827.61\n",
      "evaluation/Returns Std               1444.08\n",
      "evaluation/Returns Max               5322.27\n",
      "evaluation/Returns Min                495.42\n",
      "evaluation/Estimation Bias Mean      1360.83\n",
      "evaluation/Estimation Bias Std        200.705\n",
      "evaluation/EB/Q_True Mean              52.6605\n",
      "evaluation/EB/Q_True Std              153.965\n",
      "evaluation/EB/Q_Pred Mean            1413.49\n",
      "evaluation/EB/Q_Pred Std              102.531\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4827.61\n",
      "evaluation/Actions Mean                 0.0794441\n",
      "evaluation/Actions Std                  0.499699\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.23093\n",
      "time/backward_zf1 (s)                   2.83097\n",
      "time/backward_zf2 (s)                   2.67074\n",
      "time/data sampling (s)                  0.476964\n",
      "time/data storing (s)                   0.0183641\n",
      "time/evaluation sampling (s)            2.59185\n",
      "time/exploration sampling (s)           0.526104\n",
      "time/logging (s)                        0.0121663\n",
      "time/preback_alpha (s)                  0.67796\n",
      "time/preback_policy (s)                 1.32928\n",
      "time/preback_start (s)                  0.204245\n",
      "time/preback_zf (s)                     7.09072\n",
      "time/saving (s)                         2.974e-06\n",
      "time/training (s)                       3.08929\n",
      "time/epoch (s)                         23.7496\n",
      "time/total (s)                       5597.1\n",
      "Epoch                                 262\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:59:12.274220 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 263 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 274000\n",
      "trainer/ZF1 Loss                      218.467\n",
      "trainer/ZF2 Loss                      225.093\n",
      "trainer/ZF Expert Reward               13.8835\n",
      "trainer/ZF Policy Reward                4.70122\n",
      "trainer/ZF CHI2 Term                  220.418\n",
      "trainer/Policy Loss                 -1130.35\n",
      "trainer/Bias Loss                      32.5341\n",
      "trainer/Bias Value                     15.4094\n",
      "trainer/Policy Grad Norm              240.431\n",
      "trainer/Policy Param Norm              57.0849\n",
      "trainer/Zf1 Grad Norm               12021.8\n",
      "trainer/Zf1 Param Norm                160.132\n",
      "trainer/Zf2 Grad Norm               15254.5\n",
      "trainer/Zf2 Param Norm                158.146\n",
      "trainer/Z Expert Predictions Mean    1528.1\n",
      "trainer/Z Expert Predictions Std       73.696\n",
      "trainer/Z Expert Predictions Max     1701.74\n",
      "trainer/Z Expert Predictions Min     1095.04\n",
      "trainer/Z Policy Predictions Mean    1125.54\n",
      "trainer/Z Policy Predictions Std      445.269\n",
      "trainer/Z Policy Predictions Max     1483.13\n",
      "trainer/Z Policy Predictions Min       -9.52223\n",
      "trainer/Z Expert Targets Mean        1514.21\n",
      "trainer/Z Expert Targets Std           73.5805\n",
      "trainer/Z Expert Targets Max         1702.93\n",
      "trainer/Z Expert Targets Min         1102.72\n",
      "trainer/Z Policy Targets Mean        1120.84\n",
      "trainer/Z Policy Targets Std          446.105\n",
      "trainer/Z Policy Targets Max         1464.8\n",
      "trainer/Z Policy Targets Min          -15.0496\n",
      "trainer/Log Pis Mean                   55.56\n",
      "trainer/Log Pis Std                    25.6308\n",
      "trainer/Policy mu Mean                  0.357492\n",
      "trainer/Policy mu Std                   3.53922\n",
      "trainer/Policy log std Mean            -2.94576\n",
      "trainer/Policy log std Std              1.24756\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        269614\n",
      "exploration/num paths total          1421\n",
      "evaluation/num steps total              1.58913e+06\n",
      "evaluation/num paths total           2705\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29303\n",
      "evaluation/Rewards Std                  0.0785598\n",
      "evaluation/Rewards Max                  5.49313\n",
      "evaluation/Rewards Min                  4.82576\n",
      "evaluation/Returns Mean              5293.03\n",
      "evaluation/Returns Std                  7.90757\n",
      "evaluation/Returns Max               5301.99\n",
      "evaluation/Returns Min               5277.07\n",
      "evaluation/Estimation Bias Mean      1363.59\n",
      "evaluation/Estimation Bias Std        163.509\n",
      "evaluation/EB/Q_True Mean              47.8547\n",
      "evaluation/EB/Q_True Std              147.403\n",
      "evaluation/EB/Q_Pred Mean            1411.45\n",
      "evaluation/EB/Q_Pred Std               67.9431\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5293.03\n",
      "evaluation/Actions Mean                 0.084867\n",
      "evaluation/Actions Std                  0.504013\n",
      "evaluation/Actions Max                  0.999849\n",
      "evaluation/Actions Min                 -0.99956\n",
      "time/backward_policy (s)                2.20753\n",
      "time/backward_zf1 (s)                   2.81724\n",
      "time/backward_zf2 (s)                   2.64901\n",
      "time/data sampling (s)                  0.483544\n",
      "time/data storing (s)                   0.0180366\n",
      "time/evaluation sampling (s)            2.43735\n",
      "time/exploration sampling (s)           0.534336\n",
      "time/logging (s)                        0.0135906\n",
      "time/preback_alpha (s)                  0.682697\n",
      "time/preback_policy (s)                 1.30539\n",
      "time/preback_start (s)                  0.20574\n",
      "time/preback_zf (s)                     7.15286\n",
      "time/saving (s)                         2.934e-06\n",
      "time/training (s)                       3.25142\n",
      "time/epoch (s)                         23.7587\n",
      "time/total (s)                       5620.89\n",
      "Epoch                                 263\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:59:35.835026 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 264 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 275000\n",
      "trainer/ZF1 Loss                      266.131\n",
      "trainer/ZF2 Loss                      254.935\n",
      "trainer/ZF Expert Reward               12.4781\n",
      "trainer/ZF Policy Reward                2.14928\n",
      "trainer/ZF CHI2 Term                  257.796\n",
      "trainer/Policy Loss                 -1107.09\n",
      "trainer/Bias Loss                      36.7772\n",
      "trainer/Bias Value                     15.403\n",
      "trainer/Policy Grad Norm              214.866\n",
      "trainer/Policy Param Norm              57.1325\n",
      "trainer/Zf1 Grad Norm               14323\n",
      "trainer/Zf1 Param Norm                160.412\n",
      "trainer/Zf2 Grad Norm               12260.1\n",
      "trainer/Zf2 Param Norm                158.411\n",
      "trainer/Z Expert Predictions Mean    1527.43\n",
      "trainer/Z Expert Predictions Std       64.6296\n",
      "trainer/Z Expert Predictions Max     1667.58\n",
      "trainer/Z Expert Predictions Min     1358.9\n",
      "trainer/Z Policy Predictions Mean    1102.04\n",
      "trainer/Z Policy Predictions Std      428.663\n",
      "trainer/Z Policy Predictions Max     1476.86\n",
      "trainer/Z Policy Predictions Min       -9.01212\n",
      "trainer/Z Expert Targets Mean        1514.95\n",
      "trainer/Z Expert Targets Std           64.7369\n",
      "trainer/Z Expert Targets Max         1647.38\n",
      "trainer/Z Expert Targets Min         1327.98\n",
      "trainer/Z Policy Targets Mean        1099.89\n",
      "trainer/Z Policy Targets Std          429.608\n",
      "trainer/Z Policy Targets Max         1510.21\n",
      "trainer/Z Policy Targets Min           -3.87971\n",
      "trainer/Log Pis Mean                   55.8238\n",
      "trainer/Log Pis Std                    23.5816\n",
      "trainer/Policy mu Mean                  0.357875\n",
      "trainer/Policy mu Std                   3.11105\n",
      "trainer/Policy log std Mean            -2.95375\n",
      "trainer/Policy log std Std              1.26346\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        270614\n",
      "exploration/num paths total          1422\n",
      "evaluation/num steps total              1.59818e+06\n",
      "evaluation/num paths total           2715\n",
      "evaluation/path length Mean           905.6\n",
      "evaluation/path length Std            283.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             56\n",
      "evaluation/Rewards Mean                 5.2995\n",
      "evaluation/Rewards Std                  0.0925349\n",
      "evaluation/Rewards Max                  5.50514\n",
      "evaluation/Rewards Min                  4.34746\n",
      "evaluation/Returns Mean              4799.23\n",
      "evaluation/Returns Std               1512.44\n",
      "evaluation/Returns Max               5313.11\n",
      "evaluation/Returns Min                261.916\n",
      "evaluation/Estimation Bias Mean      1356.88\n",
      "evaluation/Estimation Bias Std        181.53\n",
      "evaluation/EB/Q_True Mean              52.8341\n",
      "evaluation/EB/Q_True Std              153.986\n",
      "evaluation/EB/Q_Pred Mean            1409.71\n",
      "evaluation/EB/Q_Pred Std               74.421\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4799.23\n",
      "evaluation/Actions Mean                 0.0859366\n",
      "evaluation/Actions Std                  0.509759\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.19363\n",
      "time/backward_zf1 (s)                   2.79384\n",
      "time/backward_zf2 (s)                   2.62686\n",
      "time/data sampling (s)                  0.460817\n",
      "time/data storing (s)                   0.0175254\n",
      "time/evaluation sampling (s)            2.49376\n",
      "time/exploration sampling (s)           0.52915\n",
      "time/logging (s)                        0.0125334\n",
      "time/preback_alpha (s)                  0.667635\n",
      "time/preback_policy (s)                 1.30082\n",
      "time/preback_start (s)                  0.2018\n",
      "time/preback_zf (s)                     7.01243\n",
      "time/saving (s)                         3.439e-06\n",
      "time/training (s)                       3.16638\n",
      "time/epoch (s)                         23.4772\n",
      "time/total (s)                       5644.39\n",
      "Epoch                                 264\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 21:59:59.273659 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 265 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 276000\n",
      "trainer/ZF1 Loss                      203.717\n",
      "trainer/ZF2 Loss                      245.204\n",
      "trainer/ZF Expert Reward               14.3452\n",
      "trainer/ZF Policy Reward                5.9749\n",
      "trainer/ZF CHI2 Term                  223.645\n",
      "trainer/Policy Loss                 -1193.39\n",
      "trainer/Bias Loss                      15.9572\n",
      "trainer/Bias Value                     15.3992\n",
      "trainer/Policy Grad Norm              218.71\n",
      "trainer/Policy Param Norm              57.1832\n",
      "trainer/Zf1 Grad Norm                8734.38\n",
      "trainer/Zf1 Param Norm                160.68\n",
      "trainer/Zf2 Grad Norm               10345.3\n",
      "trainer/Zf2 Param Norm                158.677\n",
      "trainer/Z Expert Predictions Mean    1518.38\n",
      "trainer/Z Expert Predictions Std       75.4431\n",
      "trainer/Z Expert Predictions Max     1677.83\n",
      "trainer/Z Expert Predictions Min      865.317\n",
      "trainer/Z Policy Predictions Mean    1189.62\n",
      "trainer/Z Policy Predictions Std      350.896\n",
      "trainer/Z Policy Predictions Max     1498.07\n",
      "trainer/Z Policy Predictions Min        0.544674\n",
      "trainer/Z Expert Targets Mean        1504.04\n",
      "trainer/Z Expert Targets Std           74.632\n",
      "trainer/Z Expert Targets Max         1654.73\n",
      "trainer/Z Expert Targets Min          850.6\n",
      "trainer/Z Policy Targets Mean        1183.65\n",
      "trainer/Z Policy Targets Std          349.813\n",
      "trainer/Z Policy Targets Max         1473.91\n",
      "trainer/Z Policy Targets Min           -2.89827\n",
      "trainer/Log Pis Mean                   52.117\n",
      "trainer/Log Pis Std                    21.5718\n",
      "trainer/Policy mu Mean                  0.199635\n",
      "trainer/Policy mu Std                   2.84745\n",
      "trainer/Policy log std Mean            -3.19083\n",
      "trainer/Policy log std Std              1.05368\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        270614\n",
      "exploration/num paths total          1422\n",
      "evaluation/num steps total              1.60818e+06\n",
      "evaluation/num paths total           2725\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31415\n",
      "evaluation/Rewards Std                  0.0772052\n",
      "evaluation/Rewards Max                  5.5064\n",
      "evaluation/Rewards Min                  4.79155\n",
      "evaluation/Returns Mean              5314.15\n",
      "evaluation/Returns Std                  6.02716\n",
      "evaluation/Returns Max               5323.61\n",
      "evaluation/Returns Min               5303.69\n",
      "evaluation/Estimation Bias Mean      1356.45\n",
      "evaluation/Estimation Bias Std        165.148\n",
      "evaluation/EB/Q_True Mean              47.966\n",
      "evaluation/EB/Q_True Std              147.738\n",
      "evaluation/EB/Q_Pred Mean            1404.41\n",
      "evaluation/EB/Q_Pred Std               65.0952\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5314.15\n",
      "evaluation/Actions Mean                 0.0883821\n",
      "evaluation/Actions Std                  0.513784\n",
      "evaluation/Actions Max                  0.999854\n",
      "evaluation/Actions Min                 -0.99976\n",
      "time/backward_policy (s)                2.20325\n",
      "time/backward_zf1 (s)                   2.78278\n",
      "time/backward_zf2 (s)                   2.62234\n",
      "time/data sampling (s)                  0.4716\n",
      "time/data storing (s)                   0.0163416\n",
      "time/evaluation sampling (s)            2.32773\n",
      "time/exploration sampling (s)           0.524624\n",
      "time/logging (s)                        0.0133884\n",
      "time/preback_alpha (s)                  0.670054\n",
      "time/preback_policy (s)                 1.24526\n",
      "time/preback_start (s)                  0.20089\n",
      "time/preback_zf (s)                     6.99953\n",
      "time/saving (s)                         3.144e-06\n",
      "time/training (s)                       3.28222\n",
      "time/epoch (s)                         23.36\n",
      "time/total (s)                       5667.77\n",
      "Epoch                                 265\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:00:22.663390 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 266 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 277000\n",
      "trainer/ZF1 Loss                      200.369\n",
      "trainer/ZF2 Loss                      267.46\n",
      "trainer/ZF Expert Reward               19.7598\n",
      "trainer/ZF Policy Reward                8.07607\n",
      "trainer/ZF CHI2 Term                  238.574\n",
      "trainer/Policy Loss                 -1112.35\n",
      "trainer/Bias Loss                      44.5824\n",
      "trainer/Bias Value                     15.3965\n",
      "trainer/Policy Grad Norm              196.789\n",
      "trainer/Policy Param Norm              57.2383\n",
      "trainer/Zf1 Grad Norm                8041.95\n",
      "trainer/Zf1 Param Norm                160.943\n",
      "trainer/Zf2 Grad Norm               19113.8\n",
      "trainer/Zf2 Param Norm                158.927\n",
      "trainer/Z Expert Predictions Mean    1515.41\n",
      "trainer/Z Expert Predictions Std       62.2976\n",
      "trainer/Z Expert Predictions Max     1659.59\n",
      "trainer/Z Expert Predictions Min     1378.78\n",
      "trainer/Z Policy Predictions Mean    1112.56\n",
      "trainer/Z Policy Predictions Std      440.686\n",
      "trainer/Z Policy Predictions Max     1481.21\n",
      "trainer/Z Policy Predictions Min       -5.62666\n",
      "trainer/Z Expert Targets Mean        1495.65\n",
      "trainer/Z Expert Targets Std           61.3053\n",
      "trainer/Z Expert Targets Max         1634.31\n",
      "trainer/Z Expert Targets Min         1358.1\n",
      "trainer/Z Policy Targets Mean        1104.48\n",
      "trainer/Z Policy Targets Std          437.165\n",
      "trainer/Z Policy Targets Max         1458.79\n",
      "trainer/Z Policy Targets Min           -8.5591\n",
      "trainer/Log Pis Mean                   56.1754\n",
      "trainer/Log Pis Std                    25.2595\n",
      "trainer/Policy mu Mean                  0.356823\n",
      "trainer/Policy mu Std                   3.53814\n",
      "trainer/Policy log std Mean            -2.98833\n",
      "trainer/Policy log std Std              1.3142\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        271614\n",
      "exploration/num paths total          1423\n",
      "evaluation/num steps total              1.61565e+06\n",
      "evaluation/num paths total           2736\n",
      "evaluation/path length Mean           678.636\n",
      "evaluation/path length Std            425.239\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            101\n",
      "evaluation/Rewards Mean                 5.26183\n",
      "evaluation/Rewards Std                  0.190963\n",
      "evaluation/Rewards Max                  5.49626\n",
      "evaluation/Rewards Min                  3.42925\n",
      "evaluation/Returns Mean              3570.87\n",
      "evaluation/Returns Std               2288.32\n",
      "evaluation/Returns Max               5317.21\n",
      "evaluation/Returns Min                470.194\n",
      "evaluation/Estimation Bias Mean      1259.38\n",
      "evaluation/Estimation Bias Std        332.744\n",
      "evaluation/EB/Q_True Mean              64.1625\n",
      "evaluation/EB/Q_True Std              167.651\n",
      "evaluation/EB/Q_Pred Mean            1323.55\n",
      "evaluation/EB/Q_Pred Std              210.123\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3570.87\n",
      "evaluation/Actions Mean                 0.083558\n",
      "evaluation/Actions Std                  0.527858\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.14289\n",
      "time/backward_zf1 (s)                   2.72502\n",
      "time/backward_zf2 (s)                   2.58428\n",
      "time/data sampling (s)                  0.466748\n",
      "time/data storing (s)                   0.0184879\n",
      "time/evaluation sampling (s)            2.37951\n",
      "time/exploration sampling (s)           0.559775\n",
      "time/logging (s)                        0.0103383\n",
      "time/preback_alpha (s)                  0.66609\n",
      "time/preback_policy (s)                 1.29611\n",
      "time/preback_start (s)                  0.206257\n",
      "time/preback_zf (s)                     7.02925\n",
      "time/saving (s)                         3.533e-06\n",
      "time/training (s)                       3.22016\n",
      "time/epoch (s)                         23.3049\n",
      "time/total (s)                       5691.1\n",
      "Epoch                                 266\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:00:46.228281 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 267 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 278000\n",
      "trainer/ZF1 Loss                      264.537\n",
      "trainer/ZF2 Loss                      265.004\n",
      "trainer/ZF Expert Reward               13.4107\n",
      "trainer/ZF Policy Reward                2.08623\n",
      "trainer/ZF CHI2 Term                  263.244\n",
      "trainer/Policy Loss                 -1146.06\n",
      "trainer/Bias Loss                      43.7052\n",
      "trainer/Bias Value                     15.3927\n",
      "trainer/Policy Grad Norm              257.819\n",
      "trainer/Policy Param Norm              57.2887\n",
      "trainer/Zf1 Grad Norm               13087.2\n",
      "trainer/Zf1 Param Norm                161.194\n",
      "trainer/Zf2 Grad Norm               14165.1\n",
      "trainer/Zf2 Param Norm                159.189\n",
      "trainer/Z Expert Predictions Mean    1502.86\n",
      "trainer/Z Expert Predictions Std       62.4751\n",
      "trainer/Z Expert Predictions Max     1674.96\n",
      "trainer/Z Expert Predictions Min     1273.06\n",
      "trainer/Z Policy Predictions Mean    1139.97\n",
      "trainer/Z Policy Predictions Std      385.574\n",
      "trainer/Z Policy Predictions Max     1508.96\n",
      "trainer/Z Policy Predictions Min        8.45926\n",
      "trainer/Z Expert Targets Mean        1489.45\n",
      "trainer/Z Expert Targets Std           61.8134\n",
      "trainer/Z Expert Targets Max         1668.18\n",
      "trainer/Z Expert Targets Min         1261.54\n",
      "trainer/Z Policy Targets Mean        1137.88\n",
      "trainer/Z Policy Targets Std          384.909\n",
      "trainer/Z Policy Targets Max         1488.2\n",
      "trainer/Z Policy Targets Min            5.94714\n",
      "trainer/Log Pis Mean                   52.4418\n",
      "trainer/Log Pis Std                    21.9275\n",
      "trainer/Policy mu Mean                  0.226498\n",
      "trainer/Policy mu Std                   2.7911\n",
      "trainer/Policy log std Mean            -3.08115\n",
      "trainer/Policy log std Std              1.12577\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        273614\n",
      "exploration/num paths total          1425\n",
      "evaluation/num steps total              1.62293e+06\n",
      "evaluation/num paths total           2746\n",
      "evaluation/path length Mean           728.4\n",
      "evaluation/path length Std            415.206\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             52\n",
      "evaluation/Rewards Mean                 5.28657\n",
      "evaluation/Rewards Std                  0.138663\n",
      "evaluation/Rewards Max                  5.51954\n",
      "evaluation/Rewards Min                  3.53915\n",
      "evaluation/Returns Mean              3850.74\n",
      "evaluation/Returns Std               2223.1\n",
      "evaluation/Returns Max               5314.39\n",
      "evaluation/Returns Min                249.737\n",
      "evaluation/Estimation Bias Mean      1292.26\n",
      "evaluation/Estimation Bias Std        279.445\n",
      "evaluation/EB/Q_True Mean              65.7331\n",
      "evaluation/EB/Q_True Std              169.328\n",
      "evaluation/EB/Q_Pred Mean            1357.99\n",
      "evaluation/EB/Q_Pred Std              158.255\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3850.74\n",
      "evaluation/Actions Mean                 0.0732153\n",
      "evaluation/Actions Std                  0.512408\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.12833\n",
      "time/backward_zf1 (s)                   2.7648\n",
      "time/backward_zf2 (s)                   2.58191\n",
      "time/data sampling (s)                  0.493759\n",
      "time/data storing (s)                   0.0177482\n",
      "time/evaluation sampling (s)            2.37975\n",
      "time/exploration sampling (s)           0.540625\n",
      "time/logging (s)                        0.0128276\n",
      "time/preback_alpha (s)                  0.673157\n",
      "time/preback_policy (s)                 1.18877\n",
      "time/preback_start (s)                  0.20094\n",
      "time/preback_zf (s)                     7.03775\n",
      "time/saving (s)                         3.27e-06\n",
      "time/training (s)                       3.46614\n",
      "time/epoch (s)                         23.4865\n",
      "time/total (s)                       5714.61\n",
      "Epoch                                 267\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:01:09.737475 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 268 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 279000\n",
      "trainer/ZF1 Loss                     1699.74\n",
      "trainer/ZF2 Loss                     1772.07\n",
      "trainer/ZF Expert Reward               13.0729\n",
      "trainer/ZF Policy Reward               11.174\n",
      "trainer/ZF CHI2 Term                 1734\n",
      "trainer/Policy Loss                 -1091.6\n",
      "trainer/Bias Loss                      30.9757\n",
      "trainer/Bias Value                     15.3872\n",
      "trainer/Policy Grad Norm              227.6\n",
      "trainer/Policy Param Norm              57.3485\n",
      "trainer/Zf1 Grad Norm               27976.2\n",
      "trainer/Zf1 Param Norm                161.476\n",
      "trainer/Zf2 Grad Norm               21343.5\n",
      "trainer/Zf2 Param Norm                159.437\n",
      "trainer/Z Expert Predictions Mean    1502.24\n",
      "trainer/Z Expert Predictions Std       58.3119\n",
      "trainer/Z Expert Predictions Max     1627.1\n",
      "trainer/Z Expert Predictions Min     1335.62\n",
      "trainer/Z Policy Predictions Mean    1083.21\n",
      "trainer/Z Policy Predictions Std      420.394\n",
      "trainer/Z Policy Predictions Max     1456.2\n",
      "trainer/Z Policy Predictions Min       -0.260334\n",
      "trainer/Z Expert Targets Mean        1489.17\n",
      "trainer/Z Expert Targets Std           57.5326\n",
      "trainer/Z Expert Targets Max         1612.25\n",
      "trainer/Z Expert Targets Min         1333.49\n",
      "trainer/Z Policy Targets Mean        1072.04\n",
      "trainer/Z Policy Targets Std          428.299\n",
      "trainer/Z Policy Targets Max         1454.86\n",
      "trainer/Z Policy Targets Min          -11.1726\n",
      "trainer/Log Pis Mean                   54.2001\n",
      "trainer/Log Pis Std                    24.6975\n",
      "trainer/Policy mu Mean                  0.308781\n",
      "trainer/Policy mu Std                   3.25756\n",
      "trainer/Policy log std Mean            -2.89697\n",
      "trainer/Policy log std Std              1.22049\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        273840\n",
      "exploration/num paths total          1427\n",
      "evaluation/num steps total              1.63145e+06\n",
      "evaluation/num paths total           2758\n",
      "evaluation/path length Mean           709.75\n",
      "evaluation/path length Std            410.552\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            113\n",
      "evaluation/Rewards Mean                 5.24093\n",
      "evaluation/Rewards Std                  0.200836\n",
      "evaluation/Rewards Max                  5.61934\n",
      "evaluation/Rewards Min                  3.39172\n",
      "evaluation/Returns Mean              3719.75\n",
      "evaluation/Returns Std               2209.13\n",
      "evaluation/Returns Max               5296.66\n",
      "evaluation/Returns Min                517.075\n",
      "evaluation/Estimation Bias Mean      1259.19\n",
      "evaluation/Estimation Bias Std        318.389\n",
      "evaluation/EB/Q_True Mean              56.0304\n",
      "evaluation/EB/Q_True Std              157.79\n",
      "evaluation/EB/Q_Pred Mean            1315.22\n",
      "evaluation/EB/Q_Pred Std              197.194\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           3719.75\n",
      "evaluation/Actions Mean                 0.0829715\n",
      "evaluation/Actions Std                  0.529375\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.12053\n",
      "time/backward_zf1 (s)                   2.74172\n",
      "time/backward_zf2 (s)                   2.57213\n",
      "time/data sampling (s)                  0.491082\n",
      "time/data storing (s)                   0.0176907\n",
      "time/evaluation sampling (s)            2.37326\n",
      "time/exploration sampling (s)           0.534094\n",
      "time/logging (s)                        0.0128295\n",
      "time/preback_alpha (s)                  0.675204\n",
      "time/preback_policy (s)                 1.2301\n",
      "time/preback_start (s)                  0.2006\n",
      "time/preback_zf (s)                     7.06789\n",
      "time/saving (s)                         3.343e-06\n",
      "time/training (s)                       3.39163\n",
      "time/epoch (s)                         23.4288\n",
      "time/total (s)                       5738.06\n",
      "Epoch                                 268\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:01:33.253473 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 269 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 280000\n",
      "trainer/ZF1 Loss                      228.52\n",
      "trainer/ZF2 Loss                      238.506\n",
      "trainer/ZF Expert Reward               15.2243\n",
      "trainer/ZF Policy Reward               11.4758\n",
      "trainer/ZF CHI2 Term                  233.924\n",
      "trainer/Policy Loss                 -1129.29\n",
      "trainer/Bias Loss                      23.7255\n",
      "trainer/Bias Value                     15.3866\n",
      "trainer/Policy Grad Norm              236.634\n",
      "trainer/Policy Param Norm              57.4037\n",
      "trainer/Zf1 Grad Norm               10372.3\n",
      "trainer/Zf1 Param Norm                161.74\n",
      "trainer/Zf2 Grad Norm               10180.9\n",
      "trainer/Zf2 Param Norm                159.703\n",
      "trainer/Z Expert Predictions Mean    1481.55\n",
      "trainer/Z Expert Predictions Std      110.509\n",
      "trainer/Z Expert Predictions Max     1679.9\n",
      "trainer/Z Expert Predictions Min        9.41948\n",
      "trainer/Z Policy Predictions Mean    1124.36\n",
      "trainer/Z Policy Predictions Std      403.77\n",
      "trainer/Z Policy Predictions Max     1443.05\n",
      "trainer/Z Policy Predictions Min      -18.8012\n",
      "trainer/Z Expert Targets Mean        1466.33\n",
      "trainer/Z Expert Targets Std          111.247\n",
      "trainer/Z Expert Targets Max         1661.62\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1112.88\n",
      "trainer/Z Policy Targets Std          400.703\n",
      "trainer/Z Policy Targets Max         1465.77\n",
      "trainer/Z Policy Targets Min           -2.20542\n",
      "trainer/Log Pis Mean                   53.2279\n",
      "trainer/Log Pis Std                    26.2932\n",
      "trainer/Policy mu Mean                  0.314774\n",
      "trainer/Policy mu Std                   3.16398\n",
      "trainer/Policy log std Mean            -3.0022\n",
      "trainer/Policy log std Std              1.16253\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        274840\n",
      "exploration/num paths total          1428\n",
      "evaluation/num steps total              1.63868e+06\n",
      "evaluation/num paths total           2768\n",
      "evaluation/path length Mean           723\n",
      "evaluation/path length Std            423.221\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             64\n",
      "evaluation/Rewards Mean                 5.26698\n",
      "evaluation/Rewards Std                  0.129921\n",
      "evaluation/Rewards Max                  5.46166\n",
      "evaluation/Rewards Min                  3.84144\n",
      "evaluation/Returns Mean              3808.03\n",
      "evaluation/Returns Std               2255.5\n",
      "evaluation/Returns Max               5296.21\n",
      "evaluation/Returns Min                303.209\n",
      "evaluation/Estimation Bias Mean      1281.32\n",
      "evaluation/Estimation Bias Std        256.013\n",
      "evaluation/EB/Q_True Mean              66.0855\n",
      "evaluation/EB/Q_True Std              169.526\n",
      "evaluation/EB/Q_Pred Mean            1347.41\n",
      "evaluation/EB/Q_Pred Std              135.826\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           3808.03\n",
      "evaluation/Actions Mean                 0.0760447\n",
      "evaluation/Actions Std                  0.510302\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.11229\n",
      "time/backward_zf1 (s)                   2.74144\n",
      "time/backward_zf2 (s)                   2.57069\n",
      "time/data sampling (s)                  0.492151\n",
      "time/data storing (s)                   0.0170029\n",
      "time/evaluation sampling (s)            2.50078\n",
      "time/exploration sampling (s)           0.530955\n",
      "time/logging (s)                        0.0104698\n",
      "time/preback_alpha (s)                  0.675554\n",
      "time/preback_policy (s)                 1.22589\n",
      "time/preback_start (s)                  0.200947\n",
      "time/preback_zf (s)                     7.03894\n",
      "time/saving (s)                         3.067e-06\n",
      "time/training (s)                       3.31743\n",
      "time/epoch (s)                         23.4345\n",
      "time/total (s)                       5761.52\n",
      "Epoch                                 269\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:01:56.776112 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 270 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 281000\n",
      "trainer/ZF1 Loss                     1602.25\n",
      "trainer/ZF2 Loss                     1435.77\n",
      "trainer/ZF Expert Reward                7.31545\n",
      "trainer/ZF Policy Reward               10.1851\n",
      "trainer/ZF CHI2 Term                 1511.67\n",
      "trainer/Policy Loss                 -1088.87\n",
      "trainer/Bias Loss                      78.131\n",
      "trainer/Bias Value                     15.387\n",
      "trainer/Policy Grad Norm              210.054\n",
      "trainer/Policy Param Norm              57.4605\n",
      "trainer/Zf1 Grad Norm               19464.4\n",
      "trainer/Zf1 Param Norm                161.989\n",
      "trainer/Zf2 Grad Norm               26793.6\n",
      "trainer/Zf2 Param Norm                159.953\n",
      "trainer/Z Expert Predictions Mean    1467.37\n",
      "trainer/Z Expert Predictions Std      114.299\n",
      "trainer/Z Expert Predictions Max     1642.79\n",
      "trainer/Z Expert Predictions Min       47.7332\n",
      "trainer/Z Policy Predictions Mean    1083.24\n",
      "trainer/Z Policy Predictions Std      409.125\n",
      "trainer/Z Policy Predictions Max     1433.4\n",
      "trainer/Z Policy Predictions Min       -2.60799\n",
      "trainer/Z Expert Targets Mean        1460.06\n",
      "trainer/Z Expert Targets Std          117.553\n",
      "trainer/Z Expert Targets Max         1639.05\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1073.05\n",
      "trainer/Z Policy Targets Std          416.207\n",
      "trainer/Z Policy Targets Max         1441.29\n",
      "trainer/Z Policy Targets Min           -7.63561\n",
      "trainer/Log Pis Mean                   54.9082\n",
      "trainer/Log Pis Std                    25.9186\n",
      "trainer/Policy mu Mean                  0.240392\n",
      "trainer/Policy mu Std                   3.12366\n",
      "trainer/Policy log std Mean            -2.96774\n",
      "trainer/Policy log std Std              1.15821\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        275840\n",
      "exploration/num paths total          1429\n",
      "evaluation/num steps total              1.64868e+06\n",
      "evaluation/num paths total           2778\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30607\n",
      "evaluation/Rewards Std                  0.0814882\n",
      "evaluation/Rewards Max                  5.52447\n",
      "evaluation/Rewards Min                  4.76282\n",
      "evaluation/Returns Mean              5306.07\n",
      "evaluation/Returns Std                  6.82164\n",
      "evaluation/Returns Max               5317.11\n",
      "evaluation/Returns Min               5296.09\n",
      "evaluation/Estimation Bias Mean      1304.5\n",
      "evaluation/Estimation Bias Std        158.589\n",
      "evaluation/EB/Q_True Mean              47.8714\n",
      "evaluation/EB/Q_True Std              147.414\n",
      "evaluation/EB/Q_Pred Mean            1352.37\n",
      "evaluation/EB/Q_Pred Std               60.8392\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5306.07\n",
      "evaluation/Actions Mean                 0.0905292\n",
      "evaluation/Actions Std                  0.519804\n",
      "evaluation/Actions Max                  0.999941\n",
      "evaluation/Actions Min                 -0.998744\n",
      "time/backward_policy (s)                2.18489\n",
      "time/backward_zf1 (s)                   2.79423\n",
      "time/backward_zf2 (s)                   2.62663\n",
      "time/data sampling (s)                  0.484938\n",
      "time/data storing (s)                   0.0172692\n",
      "time/evaluation sampling (s)            2.383\n",
      "time/exploration sampling (s)           0.535553\n",
      "time/logging (s)                        0.0135364\n",
      "time/preback_alpha (s)                  0.678212\n",
      "time/preback_policy (s)                 1.29155\n",
      "time/preback_start (s)                  0.203024\n",
      "time/preback_zf (s)                     7.03877\n",
      "time/saving (s)                         4.122e-06\n",
      "time/training (s)                       3.1971\n",
      "time/epoch (s)                         23.4487\n",
      "time/total (s)                       5784.99\n",
      "Epoch                                 270\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:02:20.051873 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 271 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 282000\n",
      "trainer/ZF1 Loss                      236.799\n",
      "trainer/ZF2 Loss                      309.654\n",
      "trainer/ZF Expert Reward               13.7795\n",
      "trainer/ZF Policy Reward                7.64255\n",
      "trainer/ZF CHI2 Term                  272.312\n",
      "trainer/Policy Loss                 -1082.2\n",
      "trainer/Bias Loss                      24.4607\n",
      "trainer/Bias Value                     15.3853\n",
      "trainer/Policy Grad Norm              207.24\n",
      "trainer/Policy Param Norm              57.513\n",
      "trainer/Zf1 Grad Norm               10305.8\n",
      "trainer/Zf1 Param Norm                162.261\n",
      "trainer/Zf2 Grad Norm               14194.8\n",
      "trainer/Zf2 Param Norm                160.213\n",
      "trainer/Z Expert Predictions Mean    1474.75\n",
      "trainer/Z Expert Predictions Std       65.403\n",
      "trainer/Z Expert Predictions Max     1637.25\n",
      "trainer/Z Expert Predictions Min     1105.98\n",
      "trainer/Z Policy Predictions Mean    1073.43\n",
      "trainer/Z Policy Predictions Std      422.545\n",
      "trainer/Z Policy Predictions Max     1430.72\n",
      "trainer/Z Policy Predictions Min       -8.53983\n",
      "trainer/Z Expert Targets Mean        1460.97\n",
      "trainer/Z Expert Targets Std           65.9002\n",
      "trainer/Z Expert Targets Max         1631.61\n",
      "trainer/Z Expert Targets Min         1096.59\n",
      "trainer/Z Policy Targets Mean        1065.79\n",
      "trainer/Z Policy Targets Std          424.714\n",
      "trainer/Z Policy Targets Max         1433.29\n",
      "trainer/Z Policy Targets Min          -28.3575\n",
      "trainer/Log Pis Mean                   55.9667\n",
      "trainer/Log Pis Std                    25.8904\n",
      "trainer/Policy mu Mean                  0.333533\n",
      "trainer/Policy mu Std                   3.47855\n",
      "trainer/Policy log std Mean            -2.93776\n",
      "trainer/Policy log std Std              1.24196\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        277840\n",
      "exploration/num paths total          1431\n",
      "evaluation/num steps total              1.65774e+06\n",
      "evaluation/num paths total           2788\n",
      "evaluation/path length Mean           906.6\n",
      "evaluation/path length Std            280.2\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             66\n",
      "evaluation/Rewards Mean                 5.27753\n",
      "evaluation/Rewards Std                  0.0965225\n",
      "evaluation/Rewards Max                  5.48182\n",
      "evaluation/Rewards Min                  4.37992\n",
      "evaluation/Returns Mean              4784.61\n",
      "evaluation/Returns Std               1488.57\n",
      "evaluation/Returns Max               5288.54\n",
      "evaluation/Returns Min                318.989\n",
      "evaluation/Estimation Bias Mean      1281.93\n",
      "evaluation/Estimation Bias Std        182.702\n",
      "evaluation/EB/Q_True Mean              52.7094\n",
      "evaluation/EB/Q_True Std              153.71\n",
      "evaluation/EB/Q_Pred Mean            1334.64\n",
      "evaluation/EB/Q_Pred Std               84.6005\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4784.61\n",
      "evaluation/Actions Mean                 0.0756599\n",
      "evaluation/Actions Std                  0.495281\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.15364\n",
      "time/backward_zf1 (s)                   2.71923\n",
      "time/backward_zf2 (s)                   2.56975\n",
      "time/data sampling (s)                  0.484801\n",
      "time/data storing (s)                   0.0181405\n",
      "time/evaluation sampling (s)            2.37424\n",
      "time/exploration sampling (s)           0.544781\n",
      "time/logging (s)                        0.012046\n",
      "time/preback_alpha (s)                  0.669037\n",
      "time/preback_policy (s)                 1.28029\n",
      "time/preback_start (s)                  0.205943\n",
      "time/preback_zf (s)                     7.01538\n",
      "time/saving (s)                         2.893e-06\n",
      "time/training (s)                       3.14805\n",
      "time/epoch (s)                         23.1953\n",
      "time/total (s)                       5808.2\n",
      "Epoch                                 271\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:02:43.300063 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 272 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 283000\n",
      "trainer/ZF1 Loss                      239.536\n",
      "trainer/ZF2 Loss                      293.468\n",
      "trainer/ZF Expert Reward               15.1416\n",
      "trainer/ZF Policy Reward                7.85265\n",
      "trainer/ZF CHI2 Term                  267.012\n",
      "trainer/Policy Loss                 -1095\n",
      "trainer/Bias Loss                      37.1104\n",
      "trainer/Bias Value                     15.3802\n",
      "trainer/Policy Grad Norm              210.19\n",
      "trainer/Policy Param Norm              57.5698\n",
      "trainer/Zf1 Grad Norm                9233.67\n",
      "trainer/Zf1 Param Norm                162.545\n",
      "trainer/Zf2 Grad Norm               20388.8\n",
      "trainer/Zf2 Param Norm                160.479\n",
      "trainer/Z Expert Predictions Mean    1464.44\n",
      "trainer/Z Expert Predictions Std       81.7909\n",
      "trainer/Z Expert Predictions Max     1626.37\n",
      "trainer/Z Expert Predictions Min      682.02\n",
      "trainer/Z Policy Predictions Mean    1090.89\n",
      "trainer/Z Policy Predictions Std      409.051\n",
      "trainer/Z Policy Predictions Max     1437.28\n",
      "trainer/Z Policy Predictions Min      -22.1356\n",
      "trainer/Z Expert Targets Mean        1449.3\n",
      "trainer/Z Expert Targets Std           82.2228\n",
      "trainer/Z Expert Targets Max         1629.35\n",
      "trainer/Z Expert Targets Min          691.534\n",
      "trainer/Z Policy Targets Mean        1083.04\n",
      "trainer/Z Policy Targets Std          406.368\n",
      "trainer/Z Policy Targets Max         1422.36\n",
      "trainer/Z Policy Targets Min          -25.1252\n",
      "trainer/Log Pis Mean                   55.7961\n",
      "trainer/Log Pis Std                    26.7819\n",
      "trainer/Policy mu Mean                  0.401321\n",
      "trainer/Policy mu Std                   3.55253\n",
      "trainer/Policy log std Mean            -2.95311\n",
      "trainer/Policy log std Std              1.20777\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        277840\n",
      "exploration/num paths total          1431\n",
      "evaluation/num steps total              1.66594e+06\n",
      "evaluation/num paths total           2798\n",
      "evaluation/path length Mean           819.6\n",
      "evaluation/path length Std            360.871\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             82\n",
      "evaluation/Rewards Mean                 5.28673\n",
      "evaluation/Rewards Std                  0.141992\n",
      "evaluation/Rewards Max                  5.50968\n",
      "evaluation/Rewards Min                  3.31099\n",
      "evaluation/Returns Mean              4333.01\n",
      "evaluation/Returns Std               1933.62\n",
      "evaluation/Returns Max               5304.99\n",
      "evaluation/Returns Min                351.391\n",
      "evaluation/Estimation Bias Mean      1271.27\n",
      "evaluation/Estimation Bias Std        248.316\n",
      "evaluation/EB/Q_True Mean              58.3661\n",
      "evaluation/EB/Q_True Std              160.878\n",
      "evaluation/EB/Q_Pred Mean            1329.64\n",
      "evaluation/EB/Q_Pred Std              140.473\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4333.01\n",
      "evaluation/Actions Mean                 0.0691711\n",
      "evaluation/Actions Std                  0.517074\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.0385\n",
      "time/backward_zf1 (s)                   2.65508\n",
      "time/backward_zf2 (s)                   2.45797\n",
      "time/data sampling (s)                  0.478191\n",
      "time/data storing (s)                   0.0185831\n",
      "time/evaluation sampling (s)            2.41887\n",
      "time/exploration sampling (s)           0.530352\n",
      "time/logging (s)                        0.0145039\n",
      "time/preback_alpha (s)                  0.671302\n",
      "time/preback_policy (s)                 1.1661\n",
      "time/preback_start (s)                  0.205032\n",
      "time/preback_zf (s)                     7.02868\n",
      "time/saving (s)                         3.245e-06\n",
      "time/training (s)                       3.48984\n",
      "time/epoch (s)                         23.173\n",
      "time/total (s)                       5831.4\n",
      "Epoch                                 272\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:03:06.810169 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 273 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 284000\n",
      "trainer/ZF1 Loss                      186.585\n",
      "trainer/ZF2 Loss                      202.506\n",
      "trainer/ZF Expert Reward               17.941\n",
      "trainer/ZF Policy Reward                6.53252\n",
      "trainer/ZF CHI2 Term                  197.97\n",
      "trainer/Policy Loss                 -1063.53\n",
      "trainer/Bias Loss                      26.0245\n",
      "trainer/Bias Value                     15.3771\n",
      "trainer/Policy Grad Norm              263.129\n",
      "trainer/Policy Param Norm              57.6258\n",
      "trainer/Zf1 Grad Norm               10625.5\n",
      "trainer/Zf1 Param Norm                162.805\n",
      "trainer/Zf2 Grad Norm                9294.59\n",
      "trainer/Zf2 Param Norm                160.749\n",
      "trainer/Z Expert Predictions Mean    1455.75\n",
      "trainer/Z Expert Predictions Std      108.587\n",
      "trainer/Z Expert Predictions Max     1630.37\n",
      "trainer/Z Expert Predictions Min       22.2657\n",
      "trainer/Z Policy Predictions Mean    1061.24\n",
      "trainer/Z Policy Predictions Std      414.987\n",
      "trainer/Z Policy Predictions Max     1463.76\n",
      "trainer/Z Policy Predictions Min       -0.528911\n",
      "trainer/Z Expert Targets Mean        1437.81\n",
      "trainer/Z Expert Targets Std          109.538\n",
      "trainer/Z Expert Targets Max         1629.77\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1054.71\n",
      "trainer/Z Policy Targets Std          412.702\n",
      "trainer/Z Policy Targets Max         1426.73\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   54.9782\n",
      "trainer/Log Pis Std                    25.9021\n",
      "trainer/Policy mu Mean                  0.22534\n",
      "trainer/Policy mu Std                   3.55468\n",
      "trainer/Policy log std Mean            -2.97675\n",
      "trainer/Policy log std Std              1.22101\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        279840\n",
      "exploration/num paths total          1433\n",
      "evaluation/num steps total              1.67594e+06\n",
      "evaluation/num paths total           2808\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.3137\n",
      "evaluation/Rewards Std                  0.0794666\n",
      "evaluation/Rewards Max                  5.54056\n",
      "evaluation/Rewards Min                  4.76097\n",
      "evaluation/Returns Mean              5313.7\n",
      "evaluation/Returns Std                  7.02543\n",
      "evaluation/Returns Max               5325.26\n",
      "evaluation/Returns Min               5300.43\n",
      "evaluation/Estimation Bias Mean      1288.38\n",
      "evaluation/Estimation Bias Std        164.058\n",
      "evaluation/EB/Q_True Mean              48.0823\n",
      "evaluation/EB/Q_True Std              148.096\n",
      "evaluation/EB/Q_Pred Mean            1336.46\n",
      "evaluation/EB/Q_Pred Std               71.7132\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5313.7\n",
      "evaluation/Actions Mean                 0.0773429\n",
      "evaluation/Actions Std                  0.514969\n",
      "evaluation/Actions Max                  0.999987\n",
      "evaluation/Actions Min                 -0.99989\n",
      "time/backward_policy (s)                2.15658\n",
      "time/backward_zf1 (s)                   2.76536\n",
      "time/backward_zf2 (s)                   2.63054\n",
      "time/data sampling (s)                  0.499026\n",
      "time/data storing (s)                   0.0174858\n",
      "time/evaluation sampling (s)            2.27294\n",
      "time/exploration sampling (s)           0.550983\n",
      "time/logging (s)                        0.0136808\n",
      "time/preback_alpha (s)                  0.687157\n",
      "time/preback_policy (s)                 1.27888\n",
      "time/preback_start (s)                  0.206179\n",
      "time/preback_zf (s)                     7.068\n",
      "time/saving (s)                         3.263e-06\n",
      "time/training (s)                       3.28674\n",
      "time/epoch (s)                         23.4336\n",
      "time/total (s)                       5854.85\n",
      "Epoch                                 273\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:03:30.291219 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 274 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 285000\n",
      "trainer/ZF1 Loss                     1766.09\n",
      "trainer/ZF2 Loss                     1690.85\n",
      "trainer/ZF Expert Reward               17.768\n",
      "trainer/ZF Policy Reward               12.6314\n",
      "trainer/ZF CHI2 Term                 1731.71\n",
      "trainer/Policy Loss                 -1093.86\n",
      "trainer/Bias Loss                      32.0035\n",
      "trainer/Bias Value                     15.3782\n",
      "trainer/Policy Grad Norm              226.034\n",
      "trainer/Policy Param Norm              57.6746\n",
      "trainer/Zf1 Grad Norm               22408.5\n",
      "trainer/Zf1 Param Norm                163.055\n",
      "trainer/Zf2 Grad Norm               24292.5\n",
      "trainer/Zf2 Param Norm                161.002\n",
      "trainer/Z Expert Predictions Mean    1456.71\n",
      "trainer/Z Expert Predictions Std       55.9271\n",
      "trainer/Z Expert Predictions Max     1647.67\n",
      "trainer/Z Expert Predictions Min     1312.29\n",
      "trainer/Z Policy Predictions Mean    1091.34\n",
      "trainer/Z Policy Predictions Std      386.008\n",
      "trainer/Z Policy Predictions Max     1432.45\n",
      "trainer/Z Policy Predictions Min       -0.465861\n",
      "trainer/Z Expert Targets Mean        1438.94\n",
      "trainer/Z Expert Targets Std           55.2482\n",
      "trainer/Z Expert Targets Max         1615.47\n",
      "trainer/Z Expert Targets Min         1295.97\n",
      "trainer/Z Policy Targets Mean        1078.71\n",
      "trainer/Z Policy Targets Std          389.7\n",
      "trainer/Z Policy Targets Max         1437.82\n",
      "trainer/Z Policy Targets Min           -1.4372\n",
      "trainer/Log Pis Mean                   54.4252\n",
      "trainer/Log Pis Std                    25.2612\n",
      "trainer/Policy mu Mean                  0.251044\n",
      "trainer/Policy mu Std                   3.11612\n",
      "trainer/Policy log std Mean            -3.12754\n",
      "trainer/Policy log std Std              1.03661\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        280927\n",
      "exploration/num paths total          1435\n",
      "evaluation/num steps total              1.685e+06\n",
      "evaluation/num paths total           2818\n",
      "evaluation/path length Mean           906.4\n",
      "evaluation/path length Std            280.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             64\n",
      "evaluation/Rewards Mean                 5.30661\n",
      "evaluation/Rewards Std                  0.0930281\n",
      "evaluation/Rewards Max                  5.50126\n",
      "evaluation/Rewards Min                  4.5285\n",
      "evaluation/Returns Mean              4809.91\n",
      "evaluation/Returns Std               1500.2\n",
      "evaluation/Returns Max               5323.46\n",
      "evaluation/Returns Min                309.388\n",
      "evaluation/Estimation Bias Mean      1265.01\n",
      "evaluation/Estimation Bias Std        183.473\n",
      "evaluation/EB/Q_True Mean              52.9977\n",
      "evaluation/EB/Q_True Std              154.551\n",
      "evaluation/EB/Q_Pred Mean            1318\n",
      "evaluation/EB/Q_Pred Std               68.4232\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4809.91\n",
      "evaluation/Actions Mean                 0.0776838\n",
      "evaluation/Actions Std                  0.511217\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.14444\n",
      "time/backward_zf1 (s)                   2.76818\n",
      "time/backward_zf2 (s)                   2.61131\n",
      "time/data sampling (s)                  0.484953\n",
      "time/data storing (s)                   0.0174546\n",
      "time/evaluation sampling (s)            2.54025\n",
      "time/exploration sampling (s)           0.528654\n",
      "time/logging (s)                        0.0143462\n",
      "time/preback_alpha (s)                  0.674882\n",
      "time/preback_policy (s)                 1.25702\n",
      "time/preback_start (s)                  0.209471\n",
      "time/preback_zf (s)                     7.02133\n",
      "time/saving (s)                         3.20699e-06\n",
      "time/training (s)                       3.11816\n",
      "time/epoch (s)                         23.3905\n",
      "time/total (s)                       5878.27\n",
      "Epoch                                 274\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:03:53.934527 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 275 finished\n",
      "---------------------------------  --------------\n",
      "replay_buffer/size                 286000\n",
      "trainer/ZF1 Loss                      198.08\n",
      "trainer/ZF2 Loss                      181.645\n",
      "trainer/ZF Expert Reward               15.1818\n",
      "trainer/ZF Policy Reward                4.39168\n",
      "trainer/ZF CHI2 Term                  190.703\n",
      "trainer/Policy Loss                 -1050.46\n",
      "trainer/Bias Loss                      21.1972\n",
      "trainer/Bias Value                     15.3786\n",
      "trainer/Policy Grad Norm              212.923\n",
      "trainer/Policy Param Norm              57.7215\n",
      "trainer/Zf1 Grad Norm               10172.9\n",
      "trainer/Zf1 Param Norm                163.318\n",
      "trainer/Zf2 Grad Norm                7566.43\n",
      "trainer/Zf2 Param Norm                161.248\n",
      "trainer/Z Expert Predictions Mean    1437.51\n",
      "trainer/Z Expert Predictions Std       82.8092\n",
      "trainer/Z Expert Predictions Max     1621.77\n",
      "trainer/Z Expert Predictions Min      517.149\n",
      "trainer/Z Policy Predictions Mean    1043.8\n",
      "trainer/Z Policy Predictions Std      422.998\n",
      "trainer/Z Policy Predictions Max     1403.39\n",
      "trainer/Z Policy Predictions Min       -1.15067\n",
      "trainer/Z Expert Targets Mean        1422.32\n",
      "trainer/Z Expert Targets Std           82.2755\n",
      "trainer/Z Expert Targets Max         1599.91\n",
      "trainer/Z Expert Targets Min          503.976\n",
      "trainer/Z Policy Targets Mean        1039.4\n",
      "trainer/Z Policy Targets Std          422.923\n",
      "trainer/Z Policy Targets Max         1422.75\n",
      "trainer/Z Policy Targets Min           -6.96447\n",
      "trainer/Log Pis Mean                   55.1282\n",
      "trainer/Log Pis Std                    22.5278\n",
      "trainer/Policy mu Mean                  0.345672\n",
      "trainer/Policy mu Std                   3.37826\n",
      "trainer/Policy log std Mean            -3.00087\n",
      "trainer/Policy log std Std              1.26651\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        280927\n",
      "exploration/num paths total          1435\n",
      "evaluation/num steps total              1.695e+06\n",
      "evaluation/num paths total           2828\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31784\n",
      "evaluation/Rewards Std                  0.075141\n",
      "evaluation/Rewards Max                  5.52212\n",
      "evaluation/Rewards Min                  4.84128\n",
      "evaluation/Returns Mean              5317.84\n",
      "evaluation/Returns Std                  8.58925\n",
      "evaluation/Returns Max               5335.52\n",
      "evaluation/Returns Min               5302.32\n",
      "evaluation/Estimation Bias Mean      1274.83\n",
      "evaluation/Estimation Bias Std        160.476\n",
      "evaluation/EB/Q_True Mean              47.921\n",
      "evaluation/EB/Q_True Std              147.582\n",
      "evaluation/EB/Q_Pred Mean            1322.75\n",
      "evaluation/EB/Q_Pred Std               59.5854\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5317.84\n",
      "evaluation/Actions Mean                 0.0796175\n",
      "evaluation/Actions Std                  0.512905\n",
      "evaluation/Actions Max                  0.999902\n",
      "evaluation/Actions Min                 -0.998582\n",
      "time/backward_policy (s)                2.2419\n",
      "time/backward_zf1 (s)                   2.81438\n",
      "time/backward_zf2 (s)                   2.65814\n",
      "time/data sampling (s)                  0.492998\n",
      "time/data storing (s)                   0.0164833\n",
      "time/evaluation sampling (s)            2.44985\n",
      "time/exploration sampling (s)           0.509888\n",
      "time/logging (s)                        0.0131171\n",
      "time/preback_alpha (s)                  0.681593\n",
      "time/preback_policy (s)                 1.31746\n",
      "time/preback_start (s)                  0.207315\n",
      "time/preback_zf (s)                     7.02617\n",
      "time/saving (s)                         2.741e-06\n",
      "time/training (s)                       3.12123\n",
      "time/epoch (s)                         23.5505\n",
      "time/total (s)                       5901.86\n",
      "Epoch                                 275\n",
      "---------------------------------  --------------\n",
      "2024-07-28 22:04:17.952336 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 276 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 287000\n",
      "trainer/ZF1 Loss                      178.308\n",
      "trainer/ZF2 Loss                      230.959\n",
      "trainer/ZF Expert Reward               18.2502\n",
      "trainer/ZF Policy Reward                7.40898\n",
      "trainer/ZF CHI2 Term                  208.609\n",
      "trainer/Policy Loss                 -1077.1\n",
      "trainer/Bias Loss                      59.7304\n",
      "trainer/Bias Value                     15.3797\n",
      "trainer/Policy Grad Norm              205.625\n",
      "trainer/Policy Param Norm              57.7649\n",
      "trainer/Zf1 Grad Norm                8587.88\n",
      "trainer/Zf1 Param Norm                163.568\n",
      "trainer/Zf2 Grad Norm               11656.8\n",
      "trainer/Zf2 Param Norm                161.49\n",
      "trainer/Z Expert Predictions Mean    1432.66\n",
      "trainer/Z Expert Predictions Std       61.7999\n",
      "trainer/Z Expert Predictions Max     1609.76\n",
      "trainer/Z Expert Predictions Min     1072.22\n",
      "trainer/Z Policy Predictions Mean    1071.47\n",
      "trainer/Z Policy Predictions Std      380.788\n",
      "trainer/Z Policy Predictions Max     1400.7\n",
      "trainer/Z Policy Predictions Min       10.608\n",
      "trainer/Z Expert Targets Mean        1414.41\n",
      "trainer/Z Expert Targets Std           61.7935\n",
      "trainer/Z Expert Targets Max         1582.23\n",
      "trainer/Z Expert Targets Min         1077.52\n",
      "trainer/Z Policy Targets Mean        1064.06\n",
      "trainer/Z Policy Targets Std          379.071\n",
      "trainer/Z Policy Targets Max         1413.37\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   53.3287\n",
      "trainer/Log Pis Std                    24.1529\n",
      "trainer/Policy mu Mean                  0.370417\n",
      "trainer/Policy mu Std                   3.18733\n",
      "trainer/Policy log std Mean            -2.89713\n",
      "trainer/Policy log std Std              1.24973\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        281927\n",
      "exploration/num paths total          1436\n",
      "evaluation/num steps total              1.70351e+06\n",
      "evaluation/num paths total           2839\n",
      "evaluation/path length Mean           773.091\n",
      "evaluation/path length Std            371.141\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            111\n",
      "evaluation/Rewards Mean                 5.30498\n",
      "evaluation/Rewards Std                  0.139475\n",
      "evaluation/Rewards Max                  5.84004\n",
      "evaluation/Rewards Min                  3.93227\n",
      "evaluation/Returns Mean              4101.24\n",
      "evaluation/Returns Std               2000.83\n",
      "evaluation/Returns Max               5333.21\n",
      "evaluation/Returns Min                521.107\n",
      "evaluation/Estimation Bias Mean      1218.62\n",
      "evaluation/Estimation Bias Std        292.167\n",
      "evaluation/EB/Q_True Mean              56.6353\n",
      "evaluation/EB/Q_True Std              159.352\n",
      "evaluation/EB/Q_Pred Mean            1275.26\n",
      "evaluation/EB/Q_Pred Std              170.705\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4101.24\n",
      "evaluation/Actions Mean                 0.0721449\n",
      "evaluation/Actions Std                  0.536689\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.14796\n",
      "time/backward_zf1 (s)                   2.79973\n",
      "time/backward_zf2 (s)                   2.62372\n",
      "time/data sampling (s)                  0.473184\n",
      "time/data storing (s)                   0.0184773\n",
      "time/evaluation sampling (s)            2.69581\n",
      "time/exploration sampling (s)           0.540304\n",
      "time/logging (s)                        0.0139991\n",
      "time/preback_alpha (s)                  0.672441\n",
      "time/preback_policy (s)                 1.2644\n",
      "time/preback_start (s)                  0.207347\n",
      "time/preback_zf (s)                     7.0657\n",
      "time/saving (s)                         3.64e-06\n",
      "time/training (s)                       3.41877\n",
      "time/epoch (s)                         23.9418\n",
      "time/total (s)                       5925.82\n",
      "Epoch                                 276\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:04:41.728348 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 277 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 288000\n",
      "trainer/ZF1 Loss                     1590.74\n",
      "trainer/ZF2 Loss                     1328.2\n",
      "trainer/ZF Expert Reward               14.6076\n",
      "trainer/ZF Policy Reward                9.17359\n",
      "trainer/ZF CHI2 Term                 1459.97\n",
      "trainer/Policy Loss                 -1034.22\n",
      "trainer/Bias Loss                      51.3403\n",
      "trainer/Bias Value                     15.3809\n",
      "trainer/Policy Grad Norm              189.792\n",
      "trainer/Policy Param Norm              57.8151\n",
      "trainer/Zf1 Grad Norm               48768.6\n",
      "trainer/Zf1 Param Norm                163.855\n",
      "trainer/Zf2 Grad Norm               28996.1\n",
      "trainer/Zf2 Param Norm                161.744\n",
      "trainer/Z Expert Predictions Mean    1416.16\n",
      "trainer/Z Expert Predictions Std       65.0073\n",
      "trainer/Z Expert Predictions Max     1603.92\n",
      "trainer/Z Expert Predictions Min      869.512\n",
      "trainer/Z Policy Predictions Mean    1028.96\n",
      "trainer/Z Policy Predictions Std      388.815\n",
      "trainer/Z Policy Predictions Max     1376.19\n",
      "trainer/Z Policy Predictions Min       -7.62798\n",
      "trainer/Z Expert Targets Mean        1401.55\n",
      "trainer/Z Expert Targets Std           66.8284\n",
      "trainer/Z Expert Targets Max         1574.17\n",
      "trainer/Z Expert Targets Min          799.557\n",
      "trainer/Z Policy Targets Mean        1019.79\n",
      "trainer/Z Policy Targets Std          388.768\n",
      "trainer/Z Policy Targets Max         1372.87\n",
      "trainer/Z Policy Targets Min           -9.1891\n",
      "trainer/Log Pis Mean                   54.0157\n",
      "trainer/Log Pis Std                    23.326\n",
      "trainer/Policy mu Mean                  0.298073\n",
      "trainer/Policy mu Std                   2.87168\n",
      "trainer/Policy log std Mean            -2.9101\n",
      "trainer/Policy log std Std              1.15276\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        281927\n",
      "exploration/num paths total          1436\n",
      "evaluation/num steps total              1.71351e+06\n",
      "evaluation/num paths total           2849\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30016\n",
      "evaluation/Rewards Std                  0.082048\n",
      "evaluation/Rewards Max                  5.47437\n",
      "evaluation/Rewards Min                  4.78951\n",
      "evaluation/Returns Mean              5300.16\n",
      "evaluation/Returns Std                  8.68991\n",
      "evaluation/Returns Max               5312.9\n",
      "evaluation/Returns Min               5280.08\n",
      "evaluation/Estimation Bias Mean      1258.65\n",
      "evaluation/Estimation Bias Std        165.487\n",
      "evaluation/EB/Q_True Mean              47.854\n",
      "evaluation/EB/Q_True Std              147.381\n",
      "evaluation/EB/Q_Pred Mean            1306.5\n",
      "evaluation/EB/Q_Pred Std               65.5368\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5300.16\n",
      "evaluation/Actions Mean                 0.0788279\n",
      "evaluation/Actions Std                  0.518065\n",
      "evaluation/Actions Max                  0.999887\n",
      "evaluation/Actions Min                 -0.999762\n",
      "time/backward_policy (s)                2.16031\n",
      "time/backward_zf1 (s)                   2.83146\n",
      "time/backward_zf2 (s)                   2.63145\n",
      "time/data sampling (s)                  0.48484\n",
      "time/data storing (s)                   0.0177883\n",
      "time/evaluation sampling (s)            2.6836\n",
      "time/exploration sampling (s)           0.524679\n",
      "time/logging (s)                        0.0139279\n",
      "time/preback_alpha (s)                  0.681506\n",
      "time/preback_policy (s)                 1.29465\n",
      "time/preback_start (s)                  0.203802\n",
      "time/preback_zf (s)                     7.05682\n",
      "time/saving (s)                         3.741e-06\n",
      "time/training (s)                       3.11359\n",
      "time/epoch (s)                         23.6984\n",
      "time/total (s)                       5949.54\n",
      "Epoch                                 277\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:05:05.830783 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 278 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 289000\n",
      "trainer/ZF1 Loss                      188.657\n",
      "trainer/ZF2 Loss                      206.024\n",
      "trainer/ZF Expert Reward               14.8896\n",
      "trainer/ZF Policy Reward                8.43624\n",
      "trainer/ZF CHI2 Term                  198.054\n",
      "trainer/Policy Loss                 -1053.53\n",
      "trainer/Bias Loss                      20.5467\n",
      "trainer/Bias Value                     15.3761\n",
      "trainer/Policy Grad Norm              207.368\n",
      "trainer/Policy Param Norm              57.8657\n",
      "trainer/Zf1 Grad Norm                8901.1\n",
      "trainer/Zf1 Param Norm                164.115\n",
      "trainer/Zf2 Grad Norm                9423.77\n",
      "trainer/Zf2 Param Norm                162.02\n",
      "trainer/Z Expert Predictions Mean    1422.46\n",
      "trainer/Z Expert Predictions Std       56.8245\n",
      "trainer/Z Expert Predictions Max     1564.65\n",
      "trainer/Z Expert Predictions Min     1139.86\n",
      "trainer/Z Policy Predictions Mean    1052.81\n",
      "trainer/Z Policy Predictions Std      396.388\n",
      "trainer/Z Policy Predictions Max     1382.73\n",
      "trainer/Z Policy Predictions Min        1.28689\n",
      "trainer/Z Expert Targets Mean        1407.57\n",
      "trainer/Z Expert Targets Std           55.9326\n",
      "trainer/Z Expert Targets Max         1556.12\n",
      "trainer/Z Expert Targets Min         1125.92\n",
      "trainer/Z Policy Targets Mean        1044.37\n",
      "trainer/Z Policy Targets Std          398.061\n",
      "trainer/Z Policy Targets Max         1387.86\n",
      "trainer/Z Policy Targets Min           -5.09874\n",
      "trainer/Log Pis Mean                   54.6642\n",
      "trainer/Log Pis Std                    27.0809\n",
      "trainer/Policy mu Mean                  0.28802\n",
      "trainer/Policy mu Std                   3.16248\n",
      "trainer/Policy log std Mean            -2.9649\n",
      "trainer/Policy log std Std              1.15836\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        283927\n",
      "exploration/num paths total          1438\n",
      "evaluation/num steps total              1.72262e+06\n",
      "evaluation/num paths total           2859\n",
      "evaluation/path length Mean           910.8\n",
      "evaluation/path length Std            267.6\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            108\n",
      "evaluation/Rewards Mean                 5.31484\n",
      "evaluation/Rewards Std                  0.119778\n",
      "evaluation/Rewards Max                  5.53951\n",
      "evaluation/Rewards Min                  3.82899\n",
      "evaluation/Returns Mean              4840.76\n",
      "evaluation/Returns Std               1448.79\n",
      "evaluation/Returns Max               5336.6\n",
      "evaluation/Returns Min                494.44\n",
      "evaluation/Estimation Bias Mean      1226.71\n",
      "evaluation/Estimation Bias Std        204.257\n",
      "evaluation/EB/Q_True Mean              52.7323\n",
      "evaluation/EB/Q_True Std              154.188\n",
      "evaluation/EB/Q_Pred Mean            1279.44\n",
      "evaluation/EB/Q_Pred Std              105.37\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4840.76\n",
      "evaluation/Actions Mean                 0.0773866\n",
      "evaluation/Actions Std                  0.520811\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.27767\n",
      "time/backward_zf1 (s)                   2.91662\n",
      "time/backward_zf2 (s)                   2.75992\n",
      "time/data sampling (s)                  0.498292\n",
      "time/data storing (s)                   0.0185414\n",
      "time/evaluation sampling (s)            2.6403\n",
      "time/exploration sampling (s)           0.545758\n",
      "time/logging (s)                        0.0122824\n",
      "time/preback_alpha (s)                  0.687523\n",
      "time/preback_policy (s)                 1.3324\n",
      "time/preback_start (s)                  0.213261\n",
      "time/preback_zf (s)                     7.00017\n",
      "time/saving (s)                         3.116e-06\n",
      "time/training (s)                       3.12103\n",
      "time/epoch (s)                         24.0238\n",
      "time/total (s)                       5973.58\n",
      "Epoch                                 278\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:05:29.302538 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 279 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 290000\n",
      "trainer/ZF1 Loss                      227.131\n",
      "trainer/ZF2 Loss                      296.691\n",
      "trainer/ZF Expert Reward               11.1265\n",
      "trainer/ZF Policy Reward                1.22938\n",
      "trainer/ZF CHI2 Term                  259.05\n",
      "trainer/Policy Loss                 -1063.62\n",
      "trainer/Bias Loss                      53.9574\n",
      "trainer/Bias Value                     15.3812\n",
      "trainer/Policy Grad Norm              182.779\n",
      "trainer/Policy Param Norm              57.9119\n",
      "trainer/Zf1 Grad Norm               13111.6\n",
      "trainer/Zf1 Param Norm                164.376\n",
      "trainer/Zf2 Grad Norm               18673.5\n",
      "trainer/Zf2 Param Norm                162.258\n",
      "trainer/Z Expert Predictions Mean    1404.54\n",
      "trainer/Z Expert Predictions Std       55.9409\n",
      "trainer/Z Expert Predictions Max     1570.52\n",
      "trainer/Z Expert Predictions Min     1201.17\n",
      "trainer/Z Policy Predictions Mean    1056.76\n",
      "trainer/Z Policy Predictions Std      365.455\n",
      "trainer/Z Policy Predictions Max     1376.26\n",
      "trainer/Z Policy Predictions Min      -20.0867\n",
      "trainer/Z Expert Targets Mean        1393.41\n",
      "trainer/Z Expert Targets Std           56.5729\n",
      "trainer/Z Expert Targets Max         1553.31\n",
      "trainer/Z Expert Targets Min         1182.68\n",
      "trainer/Z Policy Targets Mean        1055.53\n",
      "trainer/Z Policy Targets Std          365.714\n",
      "trainer/Z Policy Targets Max         1401.06\n",
      "trainer/Z Policy Targets Min          -15.9587\n",
      "trainer/Log Pis Mean                   53.7752\n",
      "trainer/Log Pis Std                    23.7222\n",
      "trainer/Policy mu Mean                  0.289492\n",
      "trainer/Policy mu Std                   3.20605\n",
      "trainer/Policy log std Mean            -2.9701\n",
      "trainer/Policy log std Std              1.18171\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        284927\n",
      "exploration/num paths total          1439\n",
      "evaluation/num steps total              1.73262e+06\n",
      "evaluation/num paths total           2869\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.34308\n",
      "evaluation/Rewards Std                  0.0917198\n",
      "evaluation/Rewards Max                  5.54957\n",
      "evaluation/Rewards Min                  4.80829\n",
      "evaluation/Returns Mean              5343.08\n",
      "evaluation/Returns Std                 10.3666\n",
      "evaluation/Returns Max               5352.89\n",
      "evaluation/Returns Min               5319.37\n",
      "evaluation/Estimation Bias Mean      1238.83\n",
      "evaluation/Estimation Bias Std        160.792\n",
      "evaluation/EB/Q_True Mean              48.2546\n",
      "evaluation/EB/Q_True Std              148.6\n",
      "evaluation/EB/Q_Pred Mean            1287.08\n",
      "evaluation/EB/Q_Pred Std               67.2574\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5343.08\n",
      "evaluation/Actions Mean                 0.0762369\n",
      "evaluation/Actions Std                  0.534221\n",
      "evaluation/Actions Max                  0.999924\n",
      "evaluation/Actions Min                 -0.998721\n",
      "time/backward_policy (s)                2.17643\n",
      "time/backward_zf1 (s)                   2.81765\n",
      "time/backward_zf2 (s)                   2.61942\n",
      "time/data sampling (s)                  0.499992\n",
      "time/data storing (s)                   0.0181563\n",
      "time/evaluation sampling (s)            2.2762\n",
      "time/exploration sampling (s)           0.54453\n",
      "time/logging (s)                        0.0137668\n",
      "time/preback_alpha (s)                  0.66903\n",
      "time/preback_policy (s)                 1.22236\n",
      "time/preback_start (s)                  0.204392\n",
      "time/preback_zf (s)                     6.99154\n",
      "time/saving (s)                         2.774e-06\n",
      "time/training (s)                       3.33715\n",
      "time/epoch (s)                         23.3906\n",
      "time/total (s)                       5996.99\n",
      "Epoch                                 279\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:05:52.697661 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 280 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 291000\n",
      "trainer/ZF1 Loss                      204.472\n",
      "trainer/ZF2 Loss                      197.167\n",
      "trainer/ZF Expert Reward               21.0436\n",
      "trainer/ZF Policy Reward                8.61131\n",
      "trainer/ZF CHI2 Term                  207.801\n",
      "trainer/Policy Loss                 -1054.88\n",
      "trainer/Bias Loss                      49.5952\n",
      "trainer/Bias Value                     15.3795\n",
      "trainer/Policy Grad Norm              269.031\n",
      "trainer/Policy Param Norm              57.96\n",
      "trainer/Zf1 Grad Norm               10999.8\n",
      "trainer/Zf1 Param Norm                164.633\n",
      "trainer/Zf2 Grad Norm                9873.15\n",
      "trainer/Zf2 Param Norm                162.525\n",
      "trainer/Z Expert Predictions Mean    1413.04\n",
      "trainer/Z Expert Predictions Std       58.8207\n",
      "trainer/Z Expert Predictions Max     1563.23\n",
      "trainer/Z Expert Predictions Min     1274.14\n",
      "trainer/Z Policy Predictions Mean    1054.73\n",
      "trainer/Z Policy Predictions Std      366.714\n",
      "trainer/Z Policy Predictions Max     1392.72\n",
      "trainer/Z Policy Predictions Min        0.235091\n",
      "trainer/Z Expert Targets Mean        1392\n",
      "trainer/Z Expert Targets Std           57.2761\n",
      "trainer/Z Expert Targets Max         1544.28\n",
      "trainer/Z Expert Targets Min         1259.57\n",
      "trainer/Z Policy Targets Mean        1046.12\n",
      "trainer/Z Policy Targets Std          365.857\n",
      "trainer/Z Policy Targets Max         1366.14\n",
      "trainer/Z Policy Targets Min           -1.87382\n",
      "trainer/Log Pis Mean                   52.3023\n",
      "trainer/Log Pis Std                    24.0662\n",
      "trainer/Policy mu Mean                  0.33225\n",
      "trainer/Policy mu Std                   2.98666\n",
      "trainer/Policy log std Mean            -2.96553\n",
      "trainer/Policy log std Std              1.11522\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        285927\n",
      "exploration/num paths total          1440\n",
      "evaluation/num steps total              1.74177e+06\n",
      "evaluation/num paths total           2879\n",
      "evaluation/path length Mean           915.4\n",
      "evaluation/path length Std            253.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            154\n",
      "evaluation/Rewards Mean                 5.31432\n",
      "evaluation/Rewards Std                  0.11968\n",
      "evaluation/Rewards Max                  5.49601\n",
      "evaluation/Rewards Min                  3.67952\n",
      "evaluation/Returns Mean              4864.73\n",
      "evaluation/Returns Std               1380.3\n",
      "evaluation/Returns Max               5328.92\n",
      "evaluation/Returns Min                723.831\n",
      "evaluation/Estimation Bias Mean      1213.64\n",
      "evaluation/Estimation Bias Std        212.884\n",
      "evaluation/EB/Q_True Mean              52.4842\n",
      "evaluation/EB/Q_True Std              153.875\n",
      "evaluation/EB/Q_Pred Mean            1266.13\n",
      "evaluation/EB/Q_Pred Std              104.839\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4864.73\n",
      "evaluation/Actions Mean                 0.081625\n",
      "evaluation/Actions Std                  0.519861\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.14719\n",
      "time/backward_zf1 (s)                   2.7522\n",
      "time/backward_zf2 (s)                   2.53498\n",
      "time/data sampling (s)                  0.47973\n",
      "time/data storing (s)                   0.017355\n",
      "time/evaluation sampling (s)            2.34852\n",
      "time/exploration sampling (s)           0.517107\n",
      "time/logging (s)                        0.0120029\n",
      "time/preback_alpha (s)                  0.675387\n",
      "time/preback_policy (s)                 1.2031\n",
      "time/preback_start (s)                  0.206008\n",
      "time/preback_zf (s)                     7.03372\n",
      "time/saving (s)                         3.181e-06\n",
      "time/training (s)                       3.38083\n",
      "time/epoch (s)                         23.3082\n",
      "time/total (s)                       6020.33\n",
      "Epoch                                 280\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:06:16.378903 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 281 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 292000\n",
      "trainer/ZF1 Loss                      225.665\n",
      "trainer/ZF2 Loss                      209.233\n",
      "trainer/ZF Expert Reward               15.1439\n",
      "trainer/ZF Policy Reward                3.88095\n",
      "trainer/ZF CHI2 Term                  218.75\n",
      "trainer/Policy Loss                 -1005.72\n",
      "trainer/Bias Loss                      24.9728\n",
      "trainer/Bias Value                     15.3805\n",
      "trainer/Policy Grad Norm              229.412\n",
      "trainer/Policy Param Norm              58.0057\n",
      "trainer/Zf1 Grad Norm               12092.5\n",
      "trainer/Zf1 Param Norm                164.906\n",
      "trainer/Zf2 Grad Norm               10190.1\n",
      "trainer/Zf2 Param Norm                162.759\n",
      "trainer/Z Expert Predictions Mean    1388.13\n",
      "trainer/Z Expert Predictions Std       70.0784\n",
      "trainer/Z Expert Predictions Max     1554.38\n",
      "trainer/Z Expert Predictions Min      634.924\n",
      "trainer/Z Policy Predictions Mean     999.624\n",
      "trainer/Z Policy Predictions Std      397.381\n",
      "trainer/Z Policy Predictions Max     1365.67\n",
      "trainer/Z Policy Predictions Min      -11.6497\n",
      "trainer/Z Expert Targets Mean        1372.98\n",
      "trainer/Z Expert Targets Std           70.1669\n",
      "trainer/Z Expert Targets Max         1542.74\n",
      "trainer/Z Expert Targets Min          631.135\n",
      "trainer/Z Policy Targets Mean         995.743\n",
      "trainer/Z Policy Targets Std          393.934\n",
      "trainer/Z Policy Targets Max         1340.91\n",
      "trainer/Z Policy Targets Min          -14.0031\n",
      "trainer/Log Pis Mean                   54.9941\n",
      "trainer/Log Pis Std                    27.6398\n",
      "trainer/Policy mu Mean                  0.343035\n",
      "trainer/Policy mu Std                   3.57016\n",
      "trainer/Policy log std Mean            -2.78818\n",
      "trainer/Policy log std Std              1.26662\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        287927\n",
      "exploration/num paths total          1442\n",
      "evaluation/num steps total              1.74841e+06\n",
      "evaluation/num paths total           2891\n",
      "evaluation/path length Mean           553.25\n",
      "evaluation/path length Std            446.802\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min             95\n",
      "evaluation/Rewards Mean                 5.28379\n",
      "evaluation/Rewards Std                  0.20276\n",
      "evaluation/Rewards Max                  5.90049\n",
      "evaluation/Rewards Min                  3.83154\n",
      "evaluation/Returns Mean              2923.26\n",
      "evaluation/Returns Std               2408.77\n",
      "evaluation/Returns Max               5339.89\n",
      "evaluation/Returns Min                450.408\n",
      "evaluation/Estimation Bias Mean      1144.95\n",
      "evaluation/Estimation Bias Std        334.305\n",
      "evaluation/EB/Q_True Mean              72.4448\n",
      "evaluation/EB/Q_True Std              176.833\n",
      "evaluation/EB/Q_Pred Mean            1217.4\n",
      "evaluation/EB/Q_Pred Std              187.73\n",
      "evaluation/Num Paths                   12\n",
      "evaluation/Average Returns           2923.26\n",
      "evaluation/Actions Mean                 0.0853417\n",
      "evaluation/Actions Std                  0.541231\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.19336\n",
      "time/backward_zf1 (s)                   2.82456\n",
      "time/backward_zf2 (s)                   2.67548\n",
      "time/data sampling (s)                  0.497665\n",
      "time/data storing (s)                   0.0170858\n",
      "time/evaluation sampling (s)            2.42958\n",
      "time/exploration sampling (s)           0.528782\n",
      "time/logging (s)                        0.00970277\n",
      "time/preback_alpha (s)                  0.679702\n",
      "time/preback_policy (s)                 1.30996\n",
      "time/preback_start (s)                  0.208902\n",
      "time/preback_zf (s)                     7.05138\n",
      "time/saving (s)                         2.786e-06\n",
      "time/training (s)                       3.17183\n",
      "time/epoch (s)                         23.598\n",
      "time/total (s)                       6043.95\n",
      "Epoch                                 281\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:06:40.175259 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 282 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 293000\n",
      "trainer/ZF1 Loss                      756.028\n",
      "trainer/ZF2 Loss                      995.569\n",
      "trainer/ZF Expert Reward               12.4365\n",
      "trainer/ZF Policy Reward                7.57423\n",
      "trainer/ZF CHI2 Term                  874.435\n",
      "trainer/Policy Loss                 -1061.75\n",
      "trainer/Bias Loss                      24.1432\n",
      "trainer/Bias Value                     15.3829\n",
      "trainer/Policy Grad Norm              241.225\n",
      "trainer/Policy Param Norm              58.0553\n",
      "trainer/Zf1 Grad Norm               27144.4\n",
      "trainer/Zf1 Param Norm                165.129\n",
      "trainer/Zf2 Grad Norm               23313.8\n",
      "trainer/Zf2 Param Norm                163.032\n",
      "trainer/Z Expert Predictions Mean    1381.7\n",
      "trainer/Z Expert Predictions Std      103.385\n",
      "trainer/Z Expert Predictions Max     1536.29\n",
      "trainer/Z Expert Predictions Min       10.6193\n",
      "trainer/Z Policy Predictions Mean    1054.64\n",
      "trainer/Z Policy Predictions Std      345.36\n",
      "trainer/Z Policy Predictions Max     1378.82\n",
      "trainer/Z Policy Predictions Min        2.334\n",
      "trainer/Z Expert Targets Mean        1369.26\n",
      "trainer/Z Expert Targets Std          103.74\n",
      "trainer/Z Expert Targets Max         1534.04\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1047.06\n",
      "trainer/Z Policy Targets Std          352.449\n",
      "trainer/Z Policy Targets Max         1376.81\n",
      "trainer/Z Policy Targets Min           -3.74296\n",
      "trainer/Log Pis Mean                   52.658\n",
      "trainer/Log Pis Std                    20.3021\n",
      "trainer/Policy mu Mean                  0.2726\n",
      "trainer/Policy mu Std                   2.88913\n",
      "trainer/Policy log std Mean            -3.08633\n",
      "trainer/Policy log std Std              1.11259\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        287927\n",
      "exploration/num paths total          1442\n",
      "evaluation/num steps total              1.75707e+06\n",
      "evaluation/num paths total           2901\n",
      "evaluation/path length Mean           866\n",
      "evaluation/path length Std            269.252\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            272\n",
      "evaluation/Rewards Mean                 5.29463\n",
      "evaluation/Rewards Std                  0.146683\n",
      "evaluation/Rewards Max                  5.91666\n",
      "evaluation/Rewards Min                  3.09634\n",
      "evaluation/Returns Mean              4585.15\n",
      "evaluation/Returns Std               1462.2\n",
      "evaluation/Returns Max               5317\n",
      "evaluation/Returns Min               1309.21\n",
      "evaluation/Estimation Bias Mean      1166.75\n",
      "evaluation/Estimation Bias Std        259.26\n",
      "evaluation/EB/Q_True Mean              55.4303\n",
      "evaluation/EB/Q_True Std              157.548\n",
      "evaluation/EB/Q_Pred Mean            1222.18\n",
      "evaluation/EB/Q_Pred Std              145.826\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4585.15\n",
      "evaluation/Actions Mean                 0.0859997\n",
      "evaluation/Actions Std                  0.531895\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.1711\n",
      "time/backward_zf1 (s)                   2.8011\n",
      "time/backward_zf2 (s)                   2.63411\n",
      "time/data sampling (s)                  0.475978\n",
      "time/data storing (s)                   0.0193258\n",
      "time/evaluation sampling (s)            2.49444\n",
      "time/exploration sampling (s)           0.551427\n",
      "time/logging (s)                        0.011777\n",
      "time/preback_alpha (s)                  0.678949\n",
      "time/preback_policy (s)                 1.24201\n",
      "time/preback_start (s)                  0.20563\n",
      "time/preback_zf (s)                     7.04803\n",
      "time/saving (s)                         3.561e-06\n",
      "time/training (s)                       3.38392\n",
      "time/epoch (s)                         23.7178\n",
      "time/total (s)                       6067.69\n",
      "Epoch                                 282\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:07:03.800665 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 283 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 294000\n",
      "trainer/ZF1 Loss                      789.135\n",
      "trainer/ZF2 Loss                      997.169\n",
      "trainer/ZF Expert Reward               12.2533\n",
      "trainer/ZF Policy Reward                5.82925\n",
      "trainer/ZF CHI2 Term                  891.728\n",
      "trainer/Policy Loss                 -1035.77\n",
      "trainer/Bias Loss                      19.3362\n",
      "trainer/Bias Value                     15.3886\n",
      "trainer/Policy Grad Norm              206.073\n",
      "trainer/Policy Param Norm              58.0944\n",
      "trainer/Zf1 Grad Norm               10363.1\n",
      "trainer/Zf1 Param Norm                165.386\n",
      "trainer/Zf2 Grad Norm               11679.9\n",
      "trainer/Zf2 Param Norm                163.273\n",
      "trainer/Z Expert Predictions Mean    1372.14\n",
      "trainer/Z Expert Predictions Std       54.2353\n",
      "trainer/Z Expert Predictions Max     1524.67\n",
      "trainer/Z Expert Predictions Min      978.649\n",
      "trainer/Z Policy Predictions Mean    1031.01\n",
      "trainer/Z Policy Predictions Std      365.736\n",
      "trainer/Z Policy Predictions Max     1353.33\n",
      "trainer/Z Policy Predictions Min       -0.338837\n",
      "trainer/Z Expert Targets Mean        1359.88\n",
      "trainer/Z Expert Targets Std           55.0895\n",
      "trainer/Z Expert Targets Max         1514.13\n",
      "trainer/Z Expert Targets Min          968.935\n",
      "trainer/Z Policy Targets Mean        1025.18\n",
      "trainer/Z Policy Targets Std          370.053\n",
      "trainer/Z Policy Targets Max         1334.07\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   53.1183\n",
      "trainer/Log Pis Std                    24.134\n",
      "trainer/Policy mu Mean                  0.25184\n",
      "trainer/Policy mu Std                   3.22914\n",
      "trainer/Policy log std Mean            -3.00179\n",
      "trainer/Policy log std Std              1.14115\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        288927\n",
      "exploration/num paths total          1443\n",
      "evaluation/num steps total              1.76707e+06\n",
      "evaluation/num paths total           2911\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.33124\n",
      "evaluation/Rewards Std                  0.0877006\n",
      "evaluation/Rewards Max                  5.52825\n",
      "evaluation/Rewards Min                  4.81927\n",
      "evaluation/Returns Mean              5331.24\n",
      "evaluation/Returns Std                  7.16846\n",
      "evaluation/Returns Max               5342.12\n",
      "evaluation/Returns Min               5317.36\n",
      "evaluation/Estimation Bias Mean      1212.27\n",
      "evaluation/Estimation Bias Std        157.387\n",
      "evaluation/EB/Q_True Mean              48.1081\n",
      "evaluation/EB/Q_True Std              148.138\n",
      "evaluation/EB/Q_Pred Mean            1260.38\n",
      "evaluation/EB/Q_Pred Std               55.1043\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5331.24\n",
      "evaluation/Actions Mean                 0.0860202\n",
      "evaluation/Actions Std                  0.517237\n",
      "evaluation/Actions Max                  0.999676\n",
      "evaluation/Actions Min                 -0.999414\n",
      "time/backward_policy (s)                2.20101\n",
      "time/backward_zf1 (s)                   2.83857\n",
      "time/backward_zf2 (s)                   2.67075\n",
      "time/data sampling (s)                  0.498104\n",
      "time/data storing (s)                   0.0164884\n",
      "time/evaluation sampling (s)            2.36821\n",
      "time/exploration sampling (s)           0.517818\n",
      "time/logging (s)                        0.0134403\n",
      "time/preback_alpha (s)                  0.677746\n",
      "time/preback_policy (s)                 1.29953\n",
      "time/preback_start (s)                  0.210655\n",
      "time/preback_zf (s)                     7.0544\n",
      "time/saving (s)                         2.606e-06\n",
      "time/training (s)                       3.18305\n",
      "time/epoch (s)                         23.5498\n",
      "time/total (s)                       6091.26\n",
      "Epoch                                 283\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:07:27.113178 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 284 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 295000\n",
      "trainer/ZF1 Loss                      168.07\n",
      "trainer/ZF2 Loss                      167.322\n",
      "trainer/ZF Expert Reward               16.8612\n",
      "trainer/ZF Policy Reward                7.23956\n",
      "trainer/ZF CHI2 Term                  170.846\n",
      "trainer/Policy Loss                 -1042.74\n",
      "trainer/Bias Loss                      19.3657\n",
      "trainer/Bias Value                     15.3947\n",
      "trainer/Policy Grad Norm              187.503\n",
      "trainer/Policy Param Norm              58.1387\n",
      "trainer/Zf1 Grad Norm                7926.81\n",
      "trainer/Zf1 Param Norm                165.641\n",
      "trainer/Zf2 Grad Norm                9980.95\n",
      "trainer/Zf2 Param Norm                163.51\n",
      "trainer/Z Expert Predictions Mean    1378.12\n",
      "trainer/Z Expert Predictions Std       57.6558\n",
      "trainer/Z Expert Predictions Max     1529.49\n",
      "trainer/Z Expert Predictions Min     1115.68\n",
      "trainer/Z Policy Predictions Mean    1039.28\n",
      "trainer/Z Policy Predictions Std      345.952\n",
      "trainer/Z Policy Predictions Max     1338.51\n",
      "trainer/Z Policy Predictions Min        3.46149\n",
      "trainer/Z Expert Targets Mean        1361.26\n",
      "trainer/Z Expert Targets Std           57.7588\n",
      "trainer/Z Expert Targets Max         1511.89\n",
      "trainer/Z Expert Targets Min         1091.58\n",
      "trainer/Z Policy Targets Mean        1032.04\n",
      "trainer/Z Policy Targets Std          344.673\n",
      "trainer/Z Policy Targets Max         1327.85\n",
      "trainer/Z Policy Targets Min           -6.65723\n",
      "trainer/Log Pis Mean                   52.717\n",
      "trainer/Log Pis Std                    24.1167\n",
      "trainer/Policy mu Mean                  0.300071\n",
      "trainer/Policy mu Std                   2.9477\n",
      "trainer/Policy log std Mean            -2.98205\n",
      "trainer/Policy log std Std              1.08612\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        290927\n",
      "exploration/num paths total          1445\n",
      "evaluation/num steps total              1.77707e+06\n",
      "evaluation/num paths total           2921\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.34859\n",
      "evaluation/Rewards Std                  0.102604\n",
      "evaluation/Rewards Max                  5.55932\n",
      "evaluation/Rewards Min                  4.82358\n",
      "evaluation/Returns Mean              5348.59\n",
      "evaluation/Returns Std                  9.34576\n",
      "evaluation/Returns Max               5363.02\n",
      "evaluation/Returns Min               5331.65\n",
      "evaluation/Estimation Bias Mean      1188.3\n",
      "evaluation/Estimation Bias Std        163.524\n",
      "evaluation/EB/Q_True Mean              48.4268\n",
      "evaluation/EB/Q_True Std              149.16\n",
      "evaluation/EB/Q_Pred Mean            1236.73\n",
      "evaluation/EB/Q_Pred Std               72.6595\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5348.59\n",
      "evaluation/Actions Mean                 0.0861829\n",
      "evaluation/Actions Std                  0.535044\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999509\n",
      "time/backward_policy (s)                2.15094\n",
      "time/backward_zf1 (s)                   2.70019\n",
      "time/backward_zf2 (s)                   2.55849\n",
      "time/data sampling (s)                  0.474134\n",
      "time/data storing (s)                   0.0177546\n",
      "time/evaluation sampling (s)            2.43087\n",
      "time/exploration sampling (s)           0.532345\n",
      "time/logging (s)                        0.0134118\n",
      "time/preback_alpha (s)                  0.667\n",
      "time/preback_policy (s)                 1.26158\n",
      "time/preback_start (s)                  0.207693\n",
      "time/preback_zf (s)                     7.00391\n",
      "time/saving (s)                         3.661e-06\n",
      "time/training (s)                       3.21108\n",
      "time/epoch (s)                         23.2294\n",
      "time/total (s)                       6114.52\n",
      "Epoch                                 284\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:07:50.482450 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 285 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 296000\n",
      "trainer/ZF1 Loss                      266.844\n",
      "trainer/ZF2 Loss                      193.405\n",
      "trainer/ZF Expert Reward               17.0713\n",
      "trainer/ZF Policy Reward                4.8863\n",
      "trainer/ZF CHI2 Term                  233.609\n",
      "trainer/Policy Loss                 -1033.46\n",
      "trainer/Bias Loss                      53.1608\n",
      "trainer/Bias Value                     15.397\n",
      "trainer/Policy Grad Norm              196.662\n",
      "trainer/Policy Param Norm              58.1835\n",
      "trainer/Zf1 Grad Norm               22543.5\n",
      "trainer/Zf1 Param Norm                165.889\n",
      "trainer/Zf2 Grad Norm               11579.1\n",
      "trainer/Zf2 Param Norm                163.766\n",
      "trainer/Z Expert Predictions Mean    1361.32\n",
      "trainer/Z Expert Predictions Std       98.2439\n",
      "trainer/Z Expert Predictions Max     1502.86\n",
      "trainer/Z Expert Predictions Min       56.1857\n",
      "trainer/Z Policy Predictions Mean    1026.45\n",
      "trainer/Z Policy Predictions Std      346.588\n",
      "trainer/Z Policy Predictions Max     1345.84\n",
      "trainer/Z Policy Predictions Min      -22.1234\n",
      "trainer/Z Expert Targets Mean        1344.25\n",
      "trainer/Z Expert Targets Std          100.466\n",
      "trainer/Z Expert Targets Max         1478.71\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1021.57\n",
      "trainer/Z Policy Targets Std          347.433\n",
      "trainer/Z Policy Targets Max         1341.58\n",
      "trainer/Z Policy Targets Min          -21.8902\n",
      "trainer/Log Pis Mean                   51.5162\n",
      "trainer/Log Pis Std                    20.629\n",
      "trainer/Policy mu Mean                  0.367376\n",
      "trainer/Policy mu Std                   2.9343\n",
      "trainer/Policy log std Mean            -2.95258\n",
      "trainer/Policy log std Std              1.14271\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        291004\n",
      "exploration/num paths total          1446\n",
      "evaluation/num steps total              1.78661e+06\n",
      "evaluation/num paths total           2931\n",
      "evaluation/path length Mean           954\n",
      "evaluation/path length Std            138\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            540\n",
      "evaluation/Rewards Mean                 5.32165\n",
      "evaluation/Rewards Std                  0.091751\n",
      "evaluation/Rewards Max                  6.35227\n",
      "evaluation/Rewards Min                  4.83677\n",
      "evaluation/Returns Mean              5076.85\n",
      "evaluation/Returns Std                736.028\n",
      "evaluation/Returns Max               5337.91\n",
      "evaluation/Returns Min               2868.9\n",
      "evaluation/Estimation Bias Mean      1168.9\n",
      "evaluation/Estimation Bias Std        224.668\n",
      "evaluation/EB/Q_True Mean              50.4648\n",
      "evaluation/EB/Q_True Std              151.451\n",
      "evaluation/EB/Q_Pred Mean            1219.36\n",
      "evaluation/EB/Q_Pred Std              113.382\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5076.85\n",
      "evaluation/Actions Mean                 0.0818067\n",
      "evaluation/Actions Std                  0.51924\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.18361\n",
      "time/backward_zf1 (s)                   2.8352\n",
      "time/backward_zf2 (s)                   2.64191\n",
      "time/data sampling (s)                  0.468138\n",
      "time/data storing (s)                   0.0185841\n",
      "time/evaluation sampling (s)            2.31324\n",
      "time/exploration sampling (s)           0.535127\n",
      "time/logging (s)                        0.0138407\n",
      "time/preback_alpha (s)                  0.671459\n",
      "time/preback_policy (s)                 1.26259\n",
      "time/preback_start (s)                  0.20615\n",
      "time/preback_zf (s)                     6.9957\n",
      "time/saving (s)                         3.891e-06\n",
      "time/training (s)                       3.14187\n",
      "time/epoch (s)                         23.2874\n",
      "time/total (s)                       6137.83\n",
      "Epoch                                 285\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:08:13.946352 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 286 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 297000\n",
      "trainer/ZF1 Loss                      173.402\n",
      "trainer/ZF2 Loss                      149.631\n",
      "trainer/ZF Expert Reward               18.6039\n",
      "trainer/ZF Policy Reward                6.10783\n",
      "trainer/ZF CHI2 Term                  166.603\n",
      "trainer/Policy Loss                 -1018.56\n",
      "trainer/Bias Loss                      23.8202\n",
      "trainer/Bias Value                     15.4024\n",
      "trainer/Policy Grad Norm              183.946\n",
      "trainer/Policy Param Norm              58.2333\n",
      "trainer/Zf1 Grad Norm                7610.1\n",
      "trainer/Zf1 Param Norm                166.142\n",
      "trainer/Zf2 Grad Norm                9082.16\n",
      "trainer/Zf2 Param Norm                164.018\n",
      "trainer/Z Expert Predictions Mean    1353.45\n",
      "trainer/Z Expert Predictions Std       98.2905\n",
      "trainer/Z Expert Predictions Max     1464.54\n",
      "trainer/Z Expert Predictions Min        3.93363\n",
      "trainer/Z Policy Predictions Mean    1015.96\n",
      "trainer/Z Policy Predictions Std      343.107\n",
      "trainer/Z Policy Predictions Max     1313.22\n",
      "trainer/Z Policy Predictions Min        1.21907\n",
      "trainer/Z Expert Targets Mean        1334.85\n",
      "trainer/Z Expert Targets Std           97.8749\n",
      "trainer/Z Expert Targets Max         1455.48\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean        1009.85\n",
      "trainer/Z Policy Targets Std          343.095\n",
      "trainer/Z Policy Targets Max         1328.29\n",
      "trainer/Z Policy Targets Min          -11.8265\n",
      "trainer/Log Pis Mean                   52.5089\n",
      "trainer/Log Pis Std                    24.861\n",
      "trainer/Policy mu Mean                  0.285769\n",
      "trainer/Policy mu Std                   3.01671\n",
      "trainer/Policy log std Mean            -2.94383\n",
      "trainer/Policy log std Std              1.10981\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        292004\n",
      "exploration/num paths total          1447\n",
      "evaluation/num steps total              1.79661e+06\n",
      "evaluation/num paths total           2941\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31248\n",
      "evaluation/Rewards Std                  0.0877375\n",
      "evaluation/Rewards Max                  5.55376\n",
      "evaluation/Rewards Min                  4.82435\n",
      "evaluation/Returns Mean              5312.48\n",
      "evaluation/Returns Std                 10.7187\n",
      "evaluation/Returns Max               5324.88\n",
      "evaluation/Returns Min               5291.34\n",
      "evaluation/Estimation Bias Mean      1186.13\n",
      "evaluation/Estimation Bias Std        164.981\n",
      "evaluation/EB/Q_True Mean              47.8527\n",
      "evaluation/EB/Q_True Std              147.36\n",
      "evaluation/EB/Q_Pred Mean            1233.98\n",
      "evaluation/EB/Q_Pred Std               61.7991\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5312.48\n",
      "evaluation/Actions Mean                 0.0755249\n",
      "evaluation/Actions Std                  0.506822\n",
      "evaluation/Actions Max                  0.999851\n",
      "evaluation/Actions Min                 -0.999164\n",
      "time/backward_policy (s)                2.11026\n",
      "time/backward_zf1 (s)                   2.76956\n",
      "time/backward_zf2 (s)                   2.58683\n",
      "time/data sampling (s)                  0.481006\n",
      "time/data storing (s)                   0.0173673\n",
      "time/evaluation sampling (s)            2.34882\n",
      "time/exploration sampling (s)           0.526039\n",
      "time/logging (s)                        0.0126842\n",
      "time/preback_alpha (s)                  0.68245\n",
      "time/preback_policy (s)                 1.24723\n",
      "time/preback_start (s)                  0.208906\n",
      "time/preback_zf (s)                     7.02627\n",
      "time/saving (s)                         2.735e-06\n",
      "time/training (s)                       3.36252\n",
      "time/epoch (s)                         23.3799\n",
      "time/total (s)                       6161.24\n",
      "Epoch                                 286\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:08:37.812432 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 287 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 298000\n",
      "trainer/ZF1 Loss                      182.482\n",
      "trainer/ZF2 Loss                      215.671\n",
      "trainer/ZF Expert Reward               13.6247\n",
      "trainer/ZF Policy Reward                6.33853\n",
      "trainer/ZF CHI2 Term                  199.326\n",
      "trainer/Policy Loss                  -982.216\n",
      "trainer/Bias Loss                      15.6278\n",
      "trainer/Bias Value                     15.41\n",
      "trainer/Policy Grad Norm              174.792\n",
      "trainer/Policy Param Norm              58.2833\n",
      "trainer/Zf1 Grad Norm                8834.58\n",
      "trainer/Zf1 Param Norm                166.386\n",
      "trainer/Zf2 Grad Norm               10494\n",
      "trainer/Zf2 Param Norm                164.255\n",
      "trainer/Z Expert Predictions Mean    1343.33\n",
      "trainer/Z Expert Predictions Std       47.7583\n",
      "trainer/Z Expert Predictions Max     1465.13\n",
      "trainer/Z Expert Predictions Min     1163.01\n",
      "trainer/Z Policy Predictions Mean     975.697\n",
      "trainer/Z Policy Predictions Std      379.606\n",
      "trainer/Z Policy Predictions Max     1304.18\n",
      "trainer/Z Policy Predictions Min       -3.03239\n",
      "trainer/Z Expert Targets Mean        1329.71\n",
      "trainer/Z Expert Targets Std           48.7172\n",
      "trainer/Z Expert Targets Max         1449.1\n",
      "trainer/Z Expert Targets Min         1142.21\n",
      "trainer/Z Policy Targets Mean         969.359\n",
      "trainer/Z Policy Targets Std          379.767\n",
      "trainer/Z Policy Targets Max         1320.94\n",
      "trainer/Z Policy Targets Min          -14.2561\n",
      "trainer/Log Pis Mean                   54.4744\n",
      "trainer/Log Pis Std                    24.8073\n",
      "trainer/Policy mu Mean                  0.370708\n",
      "trainer/Policy mu Std                   3.32973\n",
      "trainer/Policy log std Mean            -2.88081\n",
      "trainer/Policy log std Std              1.17647\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        292548\n",
      "exploration/num paths total          1448\n",
      "evaluation/num steps total              1.80491e+06\n",
      "evaluation/num paths total           2951\n",
      "evaluation/path length Mean           829.6\n",
      "evaluation/path length Std            341.42\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            102\n",
      "evaluation/Rewards Mean                 5.31272\n",
      "evaluation/Rewards Std                  0.110065\n",
      "evaluation/Rewards Max                  5.61841\n",
      "evaluation/Rewards Min                  4.41233\n",
      "evaluation/Returns Mean              4407.43\n",
      "evaluation/Returns Std               1835.69\n",
      "evaluation/Returns Max               5332.78\n",
      "evaluation/Returns Min                498.971\n",
      "evaluation/Estimation Bias Mean      1141.22\n",
      "evaluation/Estimation Bias Std        245.224\n",
      "evaluation/EB/Q_True Mean              57.877\n",
      "evaluation/EB/Q_True Std              160.595\n",
      "evaluation/EB/Q_Pred Mean            1199.1\n",
      "evaluation/EB/Q_Pred Std              118.28\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4407.43\n",
      "evaluation/Actions Mean                 0.0873162\n",
      "evaluation/Actions Std                  0.528763\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.25431\n",
      "time/backward_zf1 (s)                   2.94798\n",
      "time/backward_zf2 (s)                   2.72391\n",
      "time/data sampling (s)                  0.473418\n",
      "time/data storing (s)                   0.0184195\n",
      "time/evaluation sampling (s)            2.51158\n",
      "time/exploration sampling (s)           0.540381\n",
      "time/logging (s)                        0.0117574\n",
      "time/preback_alpha (s)                  0.677878\n",
      "time/preback_policy (s)                 1.28955\n",
      "time/preback_start (s)                  0.213599\n",
      "time/preback_zf (s)                     6.99105\n",
      "time/saving (s)                         3.083e-06\n",
      "time/training (s)                       3.12869\n",
      "time/epoch (s)                         23.7825\n",
      "time/total (s)                       6185.04\n",
      "Epoch                                 287\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:09:01.235767 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 288 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 299000\n",
      "trainer/ZF1 Loss                      145.733\n",
      "trainer/ZF2 Loss                      151.447\n",
      "trainer/ZF Expert Reward               11.355\n",
      "trainer/ZF Policy Reward                2.42118\n",
      "trainer/ZF CHI2 Term                  146.661\n",
      "trainer/Policy Loss                 -1003.31\n",
      "trainer/Bias Loss                      29.1307\n",
      "trainer/Bias Value                     15.4154\n",
      "trainer/Policy Grad Norm              191.879\n",
      "trainer/Policy Param Norm              58.3221\n",
      "trainer/Zf1 Grad Norm               11777\n",
      "trainer/Zf1 Param Norm                166.642\n",
      "trainer/Zf2 Grad Norm                9592.4\n",
      "trainer/Zf2 Param Norm                164.494\n",
      "trainer/Z Expert Predictions Mean    1334.64\n",
      "trainer/Z Expert Predictions Std       48.3304\n",
      "trainer/Z Expert Predictions Max     1449.06\n",
      "trainer/Z Expert Predictions Min     1196.65\n",
      "trainer/Z Policy Predictions Mean     998.788\n",
      "trainer/Z Policy Predictions Std      370.754\n",
      "trainer/Z Policy Predictions Max     1288.88\n",
      "trainer/Z Policy Predictions Min       -6.18169\n",
      "trainer/Z Expert Targets Mean        1323.29\n",
      "trainer/Z Expert Targets Std           48.6024\n",
      "trainer/Z Expert Targets Max         1450.97\n",
      "trainer/Z Expert Targets Min         1184.71\n",
      "trainer/Z Policy Targets Mean         996.367\n",
      "trainer/Z Policy Targets Std          371.692\n",
      "trainer/Z Policy Targets Max         1284.3\n",
      "trainer/Z Policy Targets Min          -14.5416\n",
      "trainer/Log Pis Mean                   53.3507\n",
      "trainer/Log Pis Std                    23.9155\n",
      "trainer/Policy mu Mean                  0.321812\n",
      "trainer/Policy mu Std                   3.30636\n",
      "trainer/Policy log std Mean            -2.97253\n",
      "trainer/Policy log std Std              1.2074\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        294635\n",
      "exploration/num paths total          1451\n",
      "evaluation/num steps total              1.81491e+06\n",
      "evaluation/num paths total           2961\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31249\n",
      "evaluation/Rewards Std                  0.0822761\n",
      "evaluation/Rewards Max                  5.51042\n",
      "evaluation/Rewards Min                  4.82513\n",
      "evaluation/Returns Mean              5312.49\n",
      "evaluation/Returns Std                  7.26356\n",
      "evaluation/Returns Max               5322.26\n",
      "evaluation/Returns Min               5295.29\n",
      "evaluation/Estimation Bias Mean      1160.75\n",
      "evaluation/Estimation Bias Std        164.115\n",
      "evaluation/EB/Q_True Mean              48.0856\n",
      "evaluation/EB/Q_True Std              148.094\n",
      "evaluation/EB/Q_Pred Mean            1208.83\n",
      "evaluation/EB/Q_Pred Std               62.5938\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5312.49\n",
      "evaluation/Actions Mean                 0.0805508\n",
      "evaluation/Actions Std                  0.522128\n",
      "evaluation/Actions Max                  0.999996\n",
      "evaluation/Actions Min                 -0.998467\n",
      "time/backward_policy (s)                2.19686\n",
      "time/backward_zf1 (s)                   2.80909\n",
      "time/backward_zf2 (s)                   2.63617\n",
      "time/data sampling (s)                  0.502465\n",
      "time/data storing (s)                   0.0182894\n",
      "time/evaluation sampling (s)            2.32319\n",
      "time/exploration sampling (s)           0.542517\n",
      "time/logging (s)                        0.0134183\n",
      "time/preback_alpha (s)                  0.677824\n",
      "time/preback_policy (s)                 1.29848\n",
      "time/preback_start (s)                  0.204636\n",
      "time/preback_zf (s)                     6.98656\n",
      "time/saving (s)                         2.92e-06\n",
      "time/training (s)                       3.13465\n",
      "time/epoch (s)                         23.3441\n",
      "time/total (s)                       6208.41\n",
      "Epoch                                 288\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:09:24.910637 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 289 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 300000\n",
      "trainer/ZF1 Loss                      158.329\n",
      "trainer/ZF2 Loss                      200.069\n",
      "trainer/ZF Expert Reward               14.7306\n",
      "trainer/ZF Policy Reward                6.00847\n",
      "trainer/ZF CHI2 Term                  180.809\n",
      "trainer/Policy Loss                 -1016.98\n",
      "trainer/Bias Loss                      18.8421\n",
      "trainer/Bias Value                     15.4217\n",
      "trainer/Policy Grad Norm              183.696\n",
      "trainer/Policy Param Norm              58.3718\n",
      "trainer/Zf1 Grad Norm                5742.9\n",
      "trainer/Zf1 Param Norm                166.913\n",
      "trainer/Zf2 Grad Norm               11563.8\n",
      "trainer/Zf2 Param Norm                164.731\n",
      "trainer/Z Expert Predictions Mean    1320.13\n",
      "trainer/Z Expert Predictions Std       50.8017\n",
      "trainer/Z Expert Predictions Max     1430.2\n",
      "trainer/Z Expert Predictions Min     1089.18\n",
      "trainer/Z Policy Predictions Mean    1015.03\n",
      "trainer/Z Policy Predictions Std      345.511\n",
      "trainer/Z Policy Predictions Max     1286.66\n",
      "trainer/Z Policy Predictions Min       13.2484\n",
      "trainer/Z Expert Targets Mean        1305.4\n",
      "trainer/Z Expert Targets Std           50.9937\n",
      "trainer/Z Expert Targets Max         1424.48\n",
      "trainer/Z Expert Targets Min         1078.25\n",
      "trainer/Z Policy Targets Mean        1009.02\n",
      "trainer/Z Policy Targets Std          345.083\n",
      "trainer/Z Policy Targets Max         1275.13\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   51.5319\n",
      "trainer/Log Pis Std                    21.7634\n",
      "trainer/Policy mu Mean                  0.282546\n",
      "trainer/Policy mu Std                   3.01543\n",
      "trainer/Policy log std Mean            -2.957\n",
      "trainer/Policy log std Std              1.21975\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        295635\n",
      "exploration/num paths total          1452\n",
      "evaluation/num steps total              1.82318e+06\n",
      "evaluation/num paths total           2971\n",
      "evaluation/path length Mean           827.9\n",
      "evaluation/path length Std            344.299\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            121\n",
      "evaluation/Rewards Mean                 5.28876\n",
      "evaluation/Rewards Std                  0.172825\n",
      "evaluation/Rewards Max                  5.92527\n",
      "evaluation/Rewards Min                  3.36944\n",
      "evaluation/Returns Mean              4378.56\n",
      "evaluation/Returns Std               1860.63\n",
      "evaluation/Returns Max               5319.58\n",
      "evaluation/Returns Min                627.294\n",
      "evaluation/Estimation Bias Mean      1120.41\n",
      "evaluation/Estimation Bias Std        251.681\n",
      "evaluation/EB/Q_True Mean              57.8929\n",
      "evaluation/EB/Q_True Std              160.428\n",
      "evaluation/EB/Q_Pred Mean            1178.3\n",
      "evaluation/EB/Q_Pred Std              138.594\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4378.56\n",
      "evaluation/Actions Mean                 0.0875643\n",
      "evaluation/Actions Std                  0.522702\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.21785\n",
      "time/backward_zf1 (s)                   2.85532\n",
      "time/backward_zf2 (s)                   2.70335\n",
      "time/data sampling (s)                  0.487309\n",
      "time/data storing (s)                   0.0176939\n",
      "time/evaluation sampling (s)            2.45673\n",
      "time/exploration sampling (s)           0.531667\n",
      "time/logging (s)                        0.0184582\n",
      "time/preback_alpha (s)                  0.668041\n",
      "time/preback_policy (s)                 1.30887\n",
      "time/preback_start (s)                  0.215453\n",
      "time/preback_zf (s)                     6.97705\n",
      "time/saving (s)                         2.461e-06\n",
      "time/training (s)                       3.14323\n",
      "time/epoch (s)                         23.601\n",
      "time/total (s)                       6232.03\n",
      "Epoch                                 289\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:09:48.807580 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 290 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 301000\n",
      "trainer/ZF1 Loss                      143.683\n",
      "trainer/ZF2 Loss                      149.755\n",
      "trainer/ZF Expert Reward               17.4255\n",
      "trainer/ZF Policy Reward                6.25727\n",
      "trainer/ZF CHI2 Term                  151.041\n",
      "trainer/Policy Loss                 -1005.68\n",
      "trainer/Bias Loss                      20.4271\n",
      "trainer/Bias Value                     15.4278\n",
      "trainer/Policy Grad Norm              223.028\n",
      "trainer/Policy Param Norm              58.4245\n",
      "trainer/Zf1 Grad Norm                6684.74\n",
      "trainer/Zf1 Param Norm                167.155\n",
      "trainer/Zf2 Grad Norm                8621.73\n",
      "trainer/Zf2 Param Norm                164.974\n",
      "trainer/Z Expert Predictions Mean    1317.22\n",
      "trainer/Z Expert Predictions Std       48.3914\n",
      "trainer/Z Expert Predictions Max     1428.14\n",
      "trainer/Z Expert Predictions Min     1130.79\n",
      "trainer/Z Policy Predictions Mean    1001.36\n",
      "trainer/Z Policy Predictions Std      342.508\n",
      "trainer/Z Policy Predictions Max     1296.88\n",
      "trainer/Z Policy Predictions Min       -9.27107\n",
      "trainer/Z Expert Targets Mean        1299.79\n",
      "trainer/Z Expert Targets Std           48.3897\n",
      "trainer/Z Expert Targets Max         1401.76\n",
      "trainer/Z Expert Targets Min         1103.59\n",
      "trainer/Z Policy Targets Mean         995.102\n",
      "trainer/Z Policy Targets Std          341.309\n",
      "trainer/Z Policy Targets Max         1284.31\n",
      "trainer/Z Policy Targets Min           -4.7625\n",
      "trainer/Log Pis Mean                   53.2278\n",
      "trainer/Log Pis Std                    25.2626\n",
      "trainer/Policy mu Mean                  0.36837\n",
      "trainer/Policy mu Std                   3.2784\n",
      "trainer/Policy log std Mean            -2.98453\n",
      "trainer/Policy log std Std              1.20326\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        296635\n",
      "exploration/num paths total          1453\n",
      "evaluation/num steps total              1.83318e+06\n",
      "evaluation/num paths total           2981\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31761\n",
      "evaluation/Rewards Std                  0.0920737\n",
      "evaluation/Rewards Max                  5.61268\n",
      "evaluation/Rewards Min                  4.82368\n",
      "evaluation/Returns Mean              5317.61\n",
      "evaluation/Returns Std                  8.46722\n",
      "evaluation/Returns Max               5329.2\n",
      "evaluation/Returns Min               5301.17\n",
      "evaluation/Estimation Bias Mean      1132.11\n",
      "evaluation/Estimation Bias Std        166.94\n",
      "evaluation/EB/Q_True Mean              47.9873\n",
      "evaluation/EB/Q_True Std              147.784\n",
      "evaluation/EB/Q_Pred Mean            1180.1\n",
      "evaluation/EB/Q_Pred Std               68.9387\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5317.61\n",
      "evaluation/Actions Mean                 0.0786861\n",
      "evaluation/Actions Std                  0.523492\n",
      "evaluation/Actions Max                  0.999981\n",
      "evaluation/Actions Min                 -0.999072\n",
      "time/backward_policy (s)                2.27954\n",
      "time/backward_zf1 (s)                   2.89869\n",
      "time/backward_zf2 (s)                   2.7467\n",
      "time/data sampling (s)                  0.492068\n",
      "time/data storing (s)                   0.0173411\n",
      "time/evaluation sampling (s)            2.51619\n",
      "time/exploration sampling (s)           0.541639\n",
      "time/logging (s)                        0.0134463\n",
      "time/preback_alpha (s)                  0.690734\n",
      "time/preback_policy (s)                 1.32615\n",
      "time/preback_start (s)                  0.20534\n",
      "time/preback_zf (s)                     6.9928\n",
      "time/saving (s)                         3.005e-06\n",
      "time/training (s)                       3.08482\n",
      "time/epoch (s)                         23.8055\n",
      "time/total (s)                       6255.86\n",
      "Epoch                                 290\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:10:11.592939 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 291 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 302000\n",
      "trainer/ZF1 Loss                      176.679\n",
      "trainer/ZF2 Loss                      184.455\n",
      "trainer/ZF Expert Reward               15.2307\n",
      "trainer/ZF Policy Reward                7.16652\n",
      "trainer/ZF CHI2 Term                  182.858\n",
      "trainer/Policy Loss                  -994.053\n",
      "trainer/Bias Loss                      22.2672\n",
      "trainer/Bias Value                     15.4351\n",
      "trainer/Policy Grad Norm              188.027\n",
      "trainer/Policy Param Norm              58.4765\n",
      "trainer/Zf1 Grad Norm               16440.1\n",
      "trainer/Zf1 Param Norm                167.421\n",
      "trainer/Zf2 Grad Norm               19491.4\n",
      "trainer/Zf2 Param Norm                165.228\n",
      "trainer/Z Expert Predictions Mean    1297.95\n",
      "trainer/Z Expert Predictions Std       70.4644\n",
      "trainer/Z Expert Predictions Max     1431.32\n",
      "trainer/Z Expert Predictions Min      560.719\n",
      "trainer/Z Policy Predictions Mean     989.053\n",
      "trainer/Z Policy Predictions Std      345.851\n",
      "trainer/Z Policy Predictions Max     1267.18\n",
      "trainer/Z Policy Predictions Min        5.5259\n",
      "trainer/Z Expert Targets Mean        1282.72\n",
      "trainer/Z Expert Targets Std           70.2431\n",
      "trainer/Z Expert Targets Max         1410.52\n",
      "trainer/Z Expert Targets Min          560.944\n",
      "trainer/Z Policy Targets Mean         981.886\n",
      "trainer/Z Policy Targets Std          346.916\n",
      "trainer/Z Policy Targets Max         1265.2\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   53.5623\n",
      "trainer/Log Pis Std                    24.9417\n",
      "trainer/Policy mu Mean                  0.375514\n",
      "trainer/Policy mu Std                   3.09195\n",
      "trainer/Policy log std Mean            -2.96742\n",
      "trainer/Policy log std Std              1.13549\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        297635\n",
      "exploration/num paths total          1454\n",
      "evaluation/num steps total              1.83614e+06\n",
      "evaluation/num paths total           2991\n",
      "evaluation/path length Mean           295.4\n",
      "evaluation/path length Std            108.438\n",
      "evaluation/path length Max            480\n",
      "evaluation/path length Min            183\n",
      "evaluation/Rewards Mean                 5.2082\n",
      "evaluation/Rewards Std                  0.207017\n",
      "evaluation/Rewards Max                  6.22117\n",
      "evaluation/Rewards Min                  4.30112\n",
      "evaluation/Returns Mean              1538.5\n",
      "evaluation/Returns Std                579.067\n",
      "evaluation/Returns Max               2523.1\n",
      "evaluation/Returns Min                933.157\n",
      "evaluation/Estimation Bias Mean       884.945\n",
      "evaluation/Estimation Bias Std        306.973\n",
      "evaluation/EB/Q_True Mean              44.627\n",
      "evaluation/EB/Q_True Std              114.394\n",
      "evaluation/EB/Q_Pred Mean             929.572\n",
      "evaluation/EB/Q_Pred Std              292.74\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1538.5\n",
      "evaluation/Actions Mean                 0.109245\n",
      "evaluation/Actions Std                  0.649201\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.19056\n",
      "time/backward_zf1 (s)                   2.78521\n",
      "time/backward_zf2 (s)                   2.60592\n",
      "time/data sampling (s)                  0.489877\n",
      "time/data storing (s)                   0.0189691\n",
      "time/evaluation sampling (s)            1.51022\n",
      "time/exploration sampling (s)           0.560342\n",
      "time/logging (s)                        0.00943165\n",
      "time/preback_alpha (s)                  0.680857\n",
      "time/preback_policy (s)                 1.26381\n",
      "time/preback_start (s)                  0.21378\n",
      "time/preback_zf (s)                     7.08627\n",
      "time/saving (s)                         4.61e-06\n",
      "time/training (s)                       3.28474\n",
      "time/epoch (s)                         22.7\n",
      "time/total (s)                       6278.59\n",
      "Epoch                                 291\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:10:35.183612 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 292 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 303000\n",
      "trainer/ZF1 Loss                      181.617\n",
      "trainer/ZF2 Loss                      181.532\n",
      "trainer/ZF Expert Reward               17.122\n",
      "trainer/ZF Policy Reward               11.7084\n",
      "trainer/ZF CHI2 Term                  185.756\n",
      "trainer/Policy Loss                 -1040.27\n",
      "trainer/Bias Loss                      27.5554\n",
      "trainer/Bias Value                     15.4438\n",
      "trainer/Policy Grad Norm              240.506\n",
      "trainer/Policy Param Norm              58.5388\n",
      "trainer/Zf1 Grad Norm                6930.94\n",
      "trainer/Zf1 Param Norm                167.642\n",
      "trainer/Zf2 Grad Norm                7862.86\n",
      "trainer/Zf2 Param Norm                165.456\n",
      "trainer/Z Expert Predictions Mean    1299.06\n",
      "trainer/Z Expert Predictions Std       43.5644\n",
      "trainer/Z Expert Predictions Max     1419.39\n",
      "trainer/Z Expert Predictions Min     1187.86\n",
      "trainer/Z Policy Predictions Mean    1041.5\n",
      "trainer/Z Policy Predictions Std      284.911\n",
      "trainer/Z Policy Predictions Max     1271.53\n",
      "trainer/Z Policy Predictions Min        5.84419\n",
      "trainer/Z Expert Targets Mean        1281.94\n",
      "trainer/Z Expert Targets Std           44.0786\n",
      "trainer/Z Expert Targets Max         1401.64\n",
      "trainer/Z Expert Targets Min         1165.09\n",
      "trainer/Z Policy Targets Mean        1029.79\n",
      "trainer/Z Policy Targets Std          285.8\n",
      "trainer/Z Policy Targets Max         1237.22\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   49.1885\n",
      "trainer/Log Pis Std                    20.681\n",
      "trainer/Policy mu Mean                  0.271244\n",
      "trainer/Policy mu Std                   2.44728\n",
      "trainer/Policy log std Mean            -3.10361\n",
      "trainer/Policy log std Std              0.946804\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        297817\n",
      "exploration/num paths total          1455\n",
      "evaluation/num steps total              1.84612e+06\n",
      "evaluation/num paths total           3002\n",
      "evaluation/path length Mean           907.818\n",
      "evaluation/path length Std            225.111\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            231\n",
      "evaluation/Rewards Mean                 5.31031\n",
      "evaluation/Rewards Std                  0.0950749\n",
      "evaluation/Rewards Max                  6.24409\n",
      "evaluation/Rewards Min                  4.83646\n",
      "evaluation/Returns Mean              4820.79\n",
      "evaluation/Returns Std               1194.63\n",
      "evaluation/Returns Max               5323.31\n",
      "evaluation/Returns Min               1228.49\n",
      "evaluation/Estimation Bias Mean      1100.43\n",
      "evaluation/Estimation Bias Std        211.423\n",
      "evaluation/EB/Q_True Mean              47.9955\n",
      "evaluation/EB/Q_True Std              147.696\n",
      "evaluation/EB/Q_Pred Mean            1148.42\n",
      "evaluation/EB/Q_Pred Std              129.574\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4820.79\n",
      "evaluation/Actions Mean                 0.0912834\n",
      "evaluation/Actions Std                  0.529096\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.21601\n",
      "time/backward_zf1 (s)                   2.83779\n",
      "time/backward_zf2 (s)                   2.66176\n",
      "time/data sampling (s)                  0.42699\n",
      "time/data storing (s)                   0.0184245\n",
      "time/evaluation sampling (s)            2.55555\n",
      "time/exploration sampling (s)           0.516171\n",
      "time/logging (s)                        0.0128551\n",
      "time/preback_alpha (s)                  0.669726\n",
      "time/preback_policy (s)                 1.27712\n",
      "time/preback_start (s)                  0.216639\n",
      "time/preback_zf (s)                     6.97535\n",
      "time/saving (s)                         2.718e-06\n",
      "time/training (s)                       3.134\n",
      "time/epoch (s)                         23.5184\n",
      "time/total (s)                       6302.12\n",
      "Epoch                                 292\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:10:58.277585 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 293 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 304000\n",
      "trainer/ZF1 Loss                      166.185\n",
      "trainer/ZF2 Loss                      177.843\n",
      "trainer/ZF Expert Reward               16.537\n",
      "trainer/ZF Policy Reward                9.43531\n",
      "trainer/ZF CHI2 Term                  175.692\n",
      "trainer/Policy Loss                  -983.562\n",
      "trainer/Bias Loss                      22.1533\n",
      "trainer/Bias Value                     15.4491\n",
      "trainer/Policy Grad Norm              185.306\n",
      "trainer/Policy Param Norm              58.5927\n",
      "trainer/Zf1 Grad Norm                6988.36\n",
      "trainer/Zf1 Param Norm                167.905\n",
      "trainer/Zf2 Grad Norm                6574.54\n",
      "trainer/Zf2 Param Norm                165.693\n",
      "trainer/Z Expert Predictions Mean    1294.36\n",
      "trainer/Z Expert Predictions Std       44.8094\n",
      "trainer/Z Expert Predictions Max     1402.45\n",
      "trainer/Z Expert Predictions Min     1149.44\n",
      "trainer/Z Policy Predictions Mean     979.84\n",
      "trainer/Z Policy Predictions Std      355.584\n",
      "trainer/Z Policy Predictions Max     1255.04\n",
      "trainer/Z Policy Predictions Min        7.58442\n",
      "trainer/Z Expert Targets Mean        1277.82\n",
      "trainer/Z Expert Targets Std           43.4467\n",
      "trainer/Z Expert Targets Max         1387.52\n",
      "trainer/Z Expert Targets Min         1135.86\n",
      "trainer/Z Policy Targets Mean         970.404\n",
      "trainer/Z Policy Targets Std          355.43\n",
      "trainer/Z Policy Targets Max         1236.32\n",
      "trainer/Z Policy Targets Min            7.91797\n",
      "trainer/Log Pis Mean                   53.3261\n",
      "trainer/Log Pis Std                    25.7224\n",
      "trainer/Policy mu Mean                  0.323615\n",
      "trainer/Policy mu Std                   3.06541\n",
      "trainer/Policy log std Mean            -2.95503\n",
      "trainer/Policy log std Std              1.2302\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        299077\n",
      "exploration/num paths total          1457\n",
      "evaluation/num steps total              1.84948e+06\n",
      "evaluation/num paths total           3012\n",
      "evaluation/path length Mean           335.8\n",
      "evaluation/path length Std            143.716\n",
      "evaluation/path length Max            553\n",
      "evaluation/path length Min            118\n",
      "evaluation/Rewards Mean                 5.21845\n",
      "evaluation/Rewards Std                  0.2527\n",
      "evaluation/Rewards Max                  6.49894\n",
      "evaluation/Rewards Min                  3.6926\n",
      "evaluation/Returns Mean              1752.36\n",
      "evaluation/Returns Std                787.832\n",
      "evaluation/Returns Max               2917.73\n",
      "evaluation/Returns Min                542.737\n",
      "evaluation/Estimation Bias Mean       881.071\n",
      "evaluation/Estimation Bias Std        362.304\n",
      "evaluation/EB/Q_True Mean              58.6619\n",
      "evaluation/EB/Q_True Std              143.935\n",
      "evaluation/EB/Q_Pred Mean             939.733\n",
      "evaluation/EB/Q_Pred Std              315.976\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1752.36\n",
      "evaluation/Actions Mean                 0.12178\n",
      "evaluation/Actions Std                  0.642103\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.17301\n",
      "time/backward_zf1 (s)                   2.84266\n",
      "time/backward_zf2 (s)                   2.68\n",
      "time/data sampling (s)                  0.493061\n",
      "time/data storing (s)                   0.017991\n",
      "time/evaluation sampling (s)            1.83225\n",
      "time/exploration sampling (s)           0.539192\n",
      "time/logging (s)                        0.00779446\n",
      "time/preback_alpha (s)                  0.686452\n",
      "time/preback_policy (s)                 1.26776\n",
      "time/preback_start (s)                  0.216543\n",
      "time/preback_zf (s)                     7.06162\n",
      "time/saving (s)                         3.57399e-06\n",
      "time/training (s)                       3.19236\n",
      "time/epoch (s)                         23.0107\n",
      "time/total (s)                       6325.15\n",
      "Epoch                                 293\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:11:21.251172 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 294 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 305000\n",
      "trainer/ZF1 Loss                      704.528\n",
      "trainer/ZF2 Loss                      248.764\n",
      "trainer/ZF Expert Reward               18.4425\n",
      "trainer/ZF Policy Reward               12.3647\n",
      "trainer/ZF CHI2 Term                  482.325\n",
      "trainer/Policy Loss                  -928.149\n",
      "trainer/Bias Loss                      18.8549\n",
      "trainer/Bias Value                     15.4546\n",
      "trainer/Policy Grad Norm              244.494\n",
      "trainer/Policy Param Norm              58.6437\n",
      "trainer/Zf1 Grad Norm               24084.3\n",
      "trainer/Zf1 Param Norm                168.166\n",
      "trainer/Zf2 Grad Norm               19670.6\n",
      "trainer/Zf2 Param Norm                165.947\n",
      "trainer/Z Expert Predictions Mean    1274.89\n",
      "trainer/Z Expert Predictions Std      118.137\n",
      "trainer/Z Expert Predictions Max     1401.43\n",
      "trainer/Z Expert Predictions Min       28.6087\n",
      "trainer/Z Policy Predictions Mean     925.274\n",
      "trainer/Z Policy Predictions Std      363.061\n",
      "trainer/Z Policy Predictions Max     1251.9\n",
      "trainer/Z Policy Predictions Min        6.79767\n",
      "trainer/Z Expert Targets Mean        1256.44\n",
      "trainer/Z Expert Targets Std          119.303\n",
      "trainer/Z Expert Targets Max         1383.79\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         912.909\n",
      "trainer/Z Policy Targets Std          365.376\n",
      "trainer/Z Policy Targets Max         1216.36\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   53.5963\n",
      "trainer/Log Pis Std                    26.1729\n",
      "trainer/Policy mu Mean                  0.280382\n",
      "trainer/Policy mu Std                   3.59926\n",
      "trainer/Policy log std Mean            -2.82\n",
      "trainer/Policy log std Std              1.21189\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        300077\n",
      "exploration/num paths total          1458\n",
      "evaluation/num steps total              1.85316e+06\n",
      "evaluation/num paths total           3022\n",
      "evaluation/path length Mean           367.2\n",
      "evaluation/path length Std             93.3839\n",
      "evaluation/path length Max            502\n",
      "evaluation/path length Min            230\n",
      "evaluation/Rewards Mean                 5.30081\n",
      "evaluation/Rewards Std                  0.200152\n",
      "evaluation/Rewards Max                  6.74743\n",
      "evaluation/Rewards Min                  4.51324\n",
      "evaluation/Returns Mean              1946.46\n",
      "evaluation/Returns Std                498.528\n",
      "evaluation/Returns Max               2662.93\n",
      "evaluation/Returns Min               1215.11\n",
      "evaluation/Estimation Bias Mean       916.875\n",
      "evaluation/Estimation Bias Std        291.853\n",
      "evaluation/EB/Q_True Mean              39.2256\n",
      "evaluation/EB/Q_True Std              110.528\n",
      "evaluation/EB/Q_Pred Mean             956.101\n",
      "evaluation/EB/Q_Pred Std              276.867\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1946.46\n",
      "evaluation/Actions Mean                 0.0957137\n",
      "evaluation/Actions Std                  0.615098\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.26108\n",
      "time/backward_zf1 (s)                   2.84735\n",
      "time/backward_zf2 (s)                   2.73108\n",
      "time/data sampling (s)                  0.420737\n",
      "time/data storing (s)                   0.0165844\n",
      "time/evaluation sampling (s)            1.69564\n",
      "time/exploration sampling (s)           0.532189\n",
      "time/logging (s)                        0.00562968\n",
      "time/preback_alpha (s)                  0.665648\n",
      "time/preback_policy (s)                 1.32951\n",
      "time/preback_start (s)                  0.204119\n",
      "time/preback_zf (s)                     6.98129\n",
      "time/saving (s)                         2.697e-06\n",
      "time/training (s)                       3.20522\n",
      "time/epoch (s)                         22.8961\n",
      "time/total (s)                       6348.07\n",
      "Epoch                                 294\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:11:44.408158 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 295 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 306000\n",
      "trainer/ZF1 Loss                      149.729\n",
      "trainer/ZF2 Loss                      150.795\n",
      "trainer/ZF Expert Reward               15.5966\n",
      "trainer/ZF Policy Reward                6.00164\n",
      "trainer/ZF CHI2 Term                  153.195\n",
      "trainer/Policy Loss                  -955.173\n",
      "trainer/Bias Loss                      23.1247\n",
      "trainer/Bias Value                     15.4592\n",
      "trainer/Policy Grad Norm              180.996\n",
      "trainer/Policy Param Norm              58.6984\n",
      "trainer/Zf1 Grad Norm                7718.03\n",
      "trainer/Zf1 Param Norm                168.413\n",
      "trainer/Zf2 Grad Norm                7394.41\n",
      "trainer/Zf2 Param Norm                166.173\n",
      "trainer/Z Expert Predictions Mean    1274.24\n",
      "trainer/Z Expert Predictions Std       43.0527\n",
      "trainer/Z Expert Predictions Max     1377\n",
      "trainer/Z Expert Predictions Min     1162.61\n",
      "trainer/Z Policy Predictions Mean     954.129\n",
      "trainer/Z Policy Predictions Std      348.755\n",
      "trainer/Z Policy Predictions Max     1255.24\n",
      "trainer/Z Policy Predictions Min       -7.11537\n",
      "trainer/Z Expert Targets Mean        1258.64\n",
      "trainer/Z Expert Targets Std           44.4138\n",
      "trainer/Z Expert Targets Max         1373.09\n",
      "trainer/Z Expert Targets Min         1151.59\n",
      "trainer/Z Policy Targets Mean         948.127\n",
      "trainer/Z Policy Targets Std          347.759\n",
      "trainer/Z Policy Targets Max         1222.69\n",
      "trainer/Z Policy Targets Min          -14.5032\n",
      "trainer/Log Pis Mean                   52.2761\n",
      "trainer/Log Pis Std                    23.0254\n",
      "trainer/Policy mu Mean                  0.279623\n",
      "trainer/Policy mu Std                   2.95658\n",
      "trainer/Policy log std Mean            -2.86415\n",
      "trainer/Policy log std Std              1.23586\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        301077\n",
      "exploration/num paths total          1459\n",
      "evaluation/num steps total              1.86316e+06\n",
      "evaluation/num paths total           3032\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.31248\n",
      "evaluation/Rewards Std                  0.0919779\n",
      "evaluation/Rewards Max                  5.61661\n",
      "evaluation/Rewards Min                  4.78211\n",
      "evaluation/Returns Mean              5312.48\n",
      "evaluation/Returns Std                  6.54057\n",
      "evaluation/Returns Max               5322.79\n",
      "evaluation/Returns Min               5303.04\n",
      "evaluation/Estimation Bias Mean      1091.03\n",
      "evaluation/Estimation Bias Std        160.982\n",
      "evaluation/EB/Q_True Mean              47.8911\n",
      "evaluation/EB/Q_True Std              147.479\n",
      "evaluation/EB/Q_Pred Mean            1138.92\n",
      "evaluation/EB/Q_Pred Std               73.4272\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5312.48\n",
      "evaluation/Actions Mean                 0.0758424\n",
      "evaluation/Actions Std                  0.517771\n",
      "evaluation/Actions Max                  0.999998\n",
      "evaluation/Actions Min                 -0.999988\n",
      "time/backward_policy (s)                2.08898\n",
      "time/backward_zf1 (s)                   2.68343\n",
      "time/backward_zf2 (s)                   2.50913\n",
      "time/data sampling (s)                  0.441131\n",
      "time/data storing (s)                   0.0172436\n",
      "time/evaluation sampling (s)            2.25232\n",
      "time/exploration sampling (s)           0.530302\n",
      "time/logging (s)                        0.0163142\n",
      "time/preback_alpha (s)                  0.673499\n",
      "time/preback_policy (s)                 1.20507\n",
      "time/preback_start (s)                  0.207887\n",
      "time/preback_zf (s)                     7.04648\n",
      "time/saving (s)                         2.666e-06\n",
      "time/training (s)                       3.41729\n",
      "time/epoch (s)                         23.0891\n",
      "time/total (s)                       6371.18\n",
      "Epoch                                 295\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:12:07.901388 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 296 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 307000\n",
      "trainer/ZF1 Loss                      148.034\n",
      "trainer/ZF2 Loss                      163.783\n",
      "trainer/ZF Expert Reward               20.6011\n",
      "trainer/ZF Policy Reward                8.9941\n",
      "trainer/ZF CHI2 Term                  163.939\n",
      "trainer/Policy Loss                  -984.393\n",
      "trainer/Bias Loss                      32.1501\n",
      "trainer/Bias Value                     15.4632\n",
      "trainer/Policy Grad Norm              188.674\n",
      "trainer/Policy Param Norm              58.7562\n",
      "trainer/Zf1 Grad Norm                6812.23\n",
      "trainer/Zf1 Param Norm                168.669\n",
      "trainer/Zf2 Grad Norm               10398.3\n",
      "trainer/Zf2 Param Norm                166.422\n",
      "trainer/Z Expert Predictions Mean    1259.71\n",
      "trainer/Z Expert Predictions Std       94.648\n",
      "trainer/Z Expert Predictions Max     1383.73\n",
      "trainer/Z Expert Predictions Min       32.9372\n",
      "trainer/Z Policy Predictions Mean     980.476\n",
      "trainer/Z Policy Predictions Std      323.163\n",
      "trainer/Z Policy Predictions Max     1252.87\n",
      "trainer/Z Policy Predictions Min        9.11668\n",
      "trainer/Z Expert Targets Mean        1239.11\n",
      "trainer/Z Expert Targets Std           96.0056\n",
      "trainer/Z Expert Targets Max         1369.34\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         971.482\n",
      "trainer/Z Policy Targets Std          322.158\n",
      "trainer/Z Policy Targets Max         1247.54\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   51.6957\n",
      "trainer/Log Pis Std                    22.5834\n",
      "trainer/Policy mu Mean                  0.367363\n",
      "trainer/Policy mu Std                   3.05212\n",
      "trainer/Policy log std Mean            -3.01161\n",
      "trainer/Policy log std Std              1.19552\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        302077\n",
      "exploration/num paths total          1460\n",
      "evaluation/num steps total              1.87306e+06\n",
      "evaluation/num paths total           3042\n",
      "evaluation/path length Mean           990.4\n",
      "evaluation/path length Std             28.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            904\n",
      "evaluation/Rewards Mean                 5.30661\n",
      "evaluation/Rewards Std                  0.0861541\n",
      "evaluation/Rewards Max                  5.64534\n",
      "evaluation/Rewards Min                  4.79559\n",
      "evaluation/Returns Mean              5255.67\n",
      "evaluation/Returns Std                150.843\n",
      "evaluation/Returns Max               5321.55\n",
      "evaluation/Returns Min               4803.9\n",
      "evaluation/Estimation Bias Mean      1095.43\n",
      "evaluation/Estimation Bias Std        181.491\n",
      "evaluation/EB/Q_True Mean              48.4177\n",
      "evaluation/EB/Q_True Std              148.309\n",
      "evaluation/EB/Q_Pred Mean            1143.85\n",
      "evaluation/EB/Q_Pred Std               88.2763\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5255.67\n",
      "evaluation/Actions Mean                 0.0732358\n",
      "evaluation/Actions Std                  0.50869\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.22263\n",
      "time/backward_zf1 (s)                   2.85578\n",
      "time/backward_zf2 (s)                   2.69069\n",
      "time/data sampling (s)                  0.483111\n",
      "time/data storing (s)                   0.0169127\n",
      "time/evaluation sampling (s)            2.353\n",
      "time/exploration sampling (s)           0.527276\n",
      "time/logging (s)                        0.0155851\n",
      "time/preback_alpha (s)                  0.674954\n",
      "time/preback_policy (s)                 1.32357\n",
      "time/preback_start (s)                  0.207693\n",
      "time/preback_zf (s)                     6.9825\n",
      "time/saving (s)                         4.173e-06\n",
      "time/training (s)                       3.05647\n",
      "time/epoch (s)                         23.4102\n",
      "time/total (s)                       6394.61\n",
      "Epoch                                 296\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:12:31.653895 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 297 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 308000\n",
      "trainer/ZF1 Loss                      667.225\n",
      "trainer/ZF2 Loss                      660.888\n",
      "trainer/ZF Expert Reward               14.8696\n",
      "trainer/ZF Policy Reward                9.19653\n",
      "trainer/ZF CHI2 Term                  666.398\n",
      "trainer/Policy Loss                  -968.171\n",
      "trainer/Bias Loss                      18.1687\n",
      "trainer/Bias Value                     15.4724\n",
      "trainer/Policy Grad Norm              173.526\n",
      "trainer/Policy Param Norm              58.8093\n",
      "trainer/Zf1 Grad Norm               49453.6\n",
      "trainer/Zf1 Param Norm                168.902\n",
      "trainer/Zf2 Grad Norm               26059.7\n",
      "trainer/Zf2 Param Norm                166.652\n",
      "trainer/Z Expert Predictions Mean    1254.67\n",
      "trainer/Z Expert Predictions Std       87.5165\n",
      "trainer/Z Expert Predictions Max     1376.24\n",
      "trainer/Z Expert Predictions Min       27.0612\n",
      "trainer/Z Policy Predictions Mean     967.931\n",
      "trainer/Z Policy Predictions Std      330.042\n",
      "trainer/Z Policy Predictions Max     1232.76\n",
      "trainer/Z Policy Predictions Min        2.34855\n",
      "trainer/Z Expert Targets Mean        1239.8\n",
      "trainer/Z Expert Targets Std           88.2654\n",
      "trainer/Z Expert Targets Max         1350.88\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         958.734\n",
      "trainer/Z Policy Targets Std          334.087\n",
      "trainer/Z Policy Targets Max         1223.58\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   52.9407\n",
      "trainer/Log Pis Std                    23.6296\n",
      "trainer/Policy mu Mean                  0.393722\n",
      "trainer/Policy mu Std                   2.9356\n",
      "trainer/Policy log std Mean            -3.00324\n",
      "trainer/Policy log std Std              1.21249\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        302077\n",
      "exploration/num paths total          1460\n",
      "evaluation/num steps total              1.8816e+06\n",
      "evaluation/num paths total           3052\n",
      "evaluation/path length Mean           853.9\n",
      "evaluation/path length Std            292.44\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            243\n",
      "evaluation/Rewards Mean                 5.28499\n",
      "evaluation/Rewards Std                  0.126037\n",
      "evaluation/Rewards Max                  6.02344\n",
      "evaluation/Rewards Min                  4.34724\n",
      "evaluation/Returns Mean              4512.86\n",
      "evaluation/Returns Std               1570.95\n",
      "evaluation/Returns Max               5306.2\n",
      "evaluation/Returns Min               1217.45\n",
      "evaluation/Estimation Bias Mean      1046.14\n",
      "evaluation/Estimation Bias Std        257.684\n",
      "evaluation/EB/Q_True Mean              55.9496\n",
      "evaluation/EB/Q_True Std              157.806\n",
      "evaluation/EB/Q_Pred Mean            1102.09\n",
      "evaluation/EB/Q_Pred Std              130.204\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4512.86\n",
      "evaluation/Actions Mean                 0.0813061\n",
      "evaluation/Actions Std                  0.539735\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.25285\n",
      "time/backward_zf1 (s)                   2.87064\n",
      "time/backward_zf2 (s)                   2.68885\n",
      "time/data sampling (s)                  0.465228\n",
      "time/data storing (s)                   0.0172987\n",
      "time/evaluation sampling (s)            2.50259\n",
      "time/exploration sampling (s)           0.503649\n",
      "time/logging (s)                        0.0117448\n",
      "time/preback_alpha (s)                  0.675456\n",
      "time/preback_policy (s)                 1.29837\n",
      "time/preback_start (s)                  0.211246\n",
      "time/preback_zf (s)                     7.03933\n",
      "time/saving (s)                         3.257e-06\n",
      "time/training (s)                       3.13031\n",
      "time/epoch (s)                         23.6676\n",
      "time/total (s)                       6418.3\n",
      "Epoch                                 297\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 22:12:54.344711 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 298 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 309000\n",
      "trainer/ZF1 Loss                      142.443\n",
      "trainer/ZF2 Loss                      144.05\n",
      "trainer/ZF Expert Reward               18.7386\n",
      "trainer/ZF Policy Reward                8.13073\n",
      "trainer/ZF CHI2 Term                  149.53\n",
      "trainer/Policy Loss                  -931.481\n",
      "trainer/Bias Loss                      25.9118\n",
      "trainer/Bias Value                     15.4775\n",
      "trainer/Policy Grad Norm              230.599\n",
      "trainer/Policy Param Norm              58.8645\n",
      "trainer/Zf1 Grad Norm                8555.84\n",
      "trainer/Zf1 Param Norm                169.182\n",
      "trainer/Zf2 Grad Norm                6868.83\n",
      "trainer/Zf2 Param Norm                166.899\n",
      "trainer/Z Expert Predictions Mean    1254.58\n",
      "trainer/Z Expert Predictions Std       42.77\n",
      "trainer/Z Expert Predictions Max     1363.46\n",
      "trainer/Z Expert Predictions Min     1102.24\n",
      "trainer/Z Policy Predictions Mean     930.336\n",
      "trainer/Z Policy Predictions Std      339.987\n",
      "trainer/Z Policy Predictions Max     1204.47\n",
      "trainer/Z Policy Predictions Min        9.8151\n",
      "trainer/Z Expert Targets Mean        1235.84\n",
      "trainer/Z Expert Targets Std           41.8069\n",
      "trainer/Z Expert Targets Max         1349.65\n",
      "trainer/Z Expert Targets Min         1086.32\n",
      "trainer/Z Policy Targets Mean         922.205\n",
      "trainer/Z Policy Targets Std          339.542\n",
      "trainer/Z Policy Targets Max         1212.42\n",
      "trainer/Z Policy Targets Min            1.90225\n",
      "trainer/Log Pis Mean                   54.1971\n",
      "trainer/Log Pis Std                    24.883\n",
      "trainer/Policy mu Mean                  0.335429\n",
      "trainer/Policy mu Std                   3.1863\n",
      "trainer/Policy log std Mean            -2.88319\n",
      "trainer/Policy log std Std              1.17639\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        305077\n",
      "exploration/num paths total          1463\n",
      "evaluation/num steps total              1.88459e+06\n",
      "evaluation/num paths total           3062\n",
      "evaluation/path length Mean           299.4\n",
      "evaluation/path length Std            109.303\n",
      "evaluation/path length Max            546\n",
      "evaluation/path length Min            167\n",
      "evaluation/Rewards Mean                 5.22626\n",
      "evaluation/Rewards Std                  0.242241\n",
      "evaluation/Rewards Max                  6.48635\n",
      "evaluation/Rewards Min                  4.30262\n",
      "evaluation/Returns Mean              1564.74\n",
      "evaluation/Returns Std                575.969\n",
      "evaluation/Returns Max               2837.75\n",
      "evaluation/Returns Min                851.778\n",
      "evaluation/Estimation Bias Mean       809.434\n",
      "evaluation/Estimation Bias Std        322.606\n",
      "evaluation/EB/Q_True Mean              61.7144\n",
      "evaluation/EB/Q_True Std              143.792\n",
      "evaluation/EB/Q_Pred Mean             871.149\n",
      "evaluation/EB/Q_Pred Std              283.046\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           1564.74\n",
      "evaluation/Actions Mean                 0.130557\n",
      "evaluation/Actions Std                  0.651646\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.23395\n",
      "time/backward_zf1 (s)                   2.87413\n",
      "time/backward_zf2 (s)                   2.70787\n",
      "time/data sampling (s)                  0.49264\n",
      "time/data storing (s)                   0.0162988\n",
      "time/evaluation sampling (s)            1.49403\n",
      "time/exploration sampling (s)           0.529946\n",
      "time/logging (s)                        0.00476634\n",
      "time/preback_alpha (s)                  0.671961\n",
      "time/preback_policy (s)                 1.28488\n",
      "time/preback_start (s)                  0.205322\n",
      "time/preback_zf (s)                     6.99644\n",
      "time/saving (s)                         3.17e-06\n",
      "time/training (s)                       3.09013\n",
      "time/epoch (s)                         22.6024\n",
      "time/total (s)                       6440.93\n",
      "Epoch                                 298\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:13:17.729879 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 299 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 310000\n",
      "trainer/ZF1 Loss                      160.985\n",
      "trainer/ZF2 Loss                      173.891\n",
      "trainer/ZF Expert Reward               15.607\n",
      "trainer/ZF Policy Reward                6.67312\n",
      "trainer/ZF CHI2 Term                  170.748\n",
      "trainer/Policy Loss                  -891.856\n",
      "trainer/Bias Loss                      26.7135\n",
      "trainer/Bias Value                     15.4861\n",
      "trainer/Policy Grad Norm              207.933\n",
      "trainer/Policy Param Norm              58.9126\n",
      "trainer/Zf1 Grad Norm                7207.3\n",
      "trainer/Zf1 Param Norm                169.385\n",
      "trainer/Zf2 Grad Norm                9076.63\n",
      "trainer/Zf2 Param Norm                167.142\n",
      "trainer/Z Expert Predictions Mean    1236.37\n",
      "trainer/Z Expert Predictions Std       45.9957\n",
      "trainer/Z Expert Predictions Max     1350.49\n",
      "trainer/Z Expert Predictions Min      880.324\n",
      "trainer/Z Policy Predictions Mean     887.89\n",
      "trainer/Z Policy Predictions Std      363.173\n",
      "trainer/Z Policy Predictions Max     1210.4\n",
      "trainer/Z Policy Predictions Min        2.71898\n",
      "trainer/Z Expert Targets Mean        1220.76\n",
      "trainer/Z Expert Targets Std           48.6447\n",
      "trainer/Z Expert Targets Max         1336.94\n",
      "trainer/Z Expert Targets Min          800.307\n",
      "trainer/Z Policy Targets Mean         881.217\n",
      "trainer/Z Policy Targets Std          362.393\n",
      "trainer/Z Policy Targets Max         1187.68\n",
      "trainer/Z Policy Targets Min           -6.83876\n",
      "trainer/Log Pis Mean                   55.0626\n",
      "trainer/Log Pis Std                    28.2098\n",
      "trainer/Policy mu Mean                  0.351044\n",
      "trainer/Policy mu Std                   3.54637\n",
      "trainer/Policy log std Mean            -2.83013\n",
      "trainer/Policy log std Std              1.21056\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        306077\n",
      "exploration/num paths total          1464\n",
      "evaluation/num steps total              1.89406e+06\n",
      "evaluation/num paths total           3072\n",
      "evaluation/path length Mean           946.3\n",
      "evaluation/path length Std            161.1\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            463\n",
      "evaluation/Rewards Mean                 5.29903\n",
      "evaluation/Rewards Std                  0.104871\n",
      "evaluation/Rewards Max                  5.53786\n",
      "evaluation/Rewards Min                  4.50917\n",
      "evaluation/Returns Mean              5014.47\n",
      "evaluation/Returns Std                870.051\n",
      "evaluation/Returns Max               5316.37\n",
      "evaluation/Returns Min               2404.48\n",
      "evaluation/Estimation Bias Mean      1020.82\n",
      "evaluation/Estimation Bias Std        205.86\n",
      "evaluation/EB/Q_True Mean              50.6674\n",
      "evaluation/EB/Q_True Std              151.335\n",
      "evaluation/EB/Q_Pred Mean            1071.49\n",
      "evaluation/EB/Q_Pred Std              102.421\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5014.47\n",
      "evaluation/Actions Mean                 0.0840989\n",
      "evaluation/Actions Std                  0.532701\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.233\n",
      "time/backward_zf1 (s)                   2.83987\n",
      "time/backward_zf2 (s)                   2.69074\n",
      "time/data sampling (s)                  0.438237\n",
      "time/data storing (s)                   0.0178936\n",
      "time/evaluation sampling (s)            2.26549\n",
      "time/exploration sampling (s)           0.538652\n",
      "time/logging (s)                        0.0130183\n",
      "time/preback_alpha (s)                  0.672018\n",
      "time/preback_policy (s)                 1.26364\n",
      "time/preback_start (s)                  0.207261\n",
      "time/preback_zf (s)                     6.97936\n",
      "time/saving (s)                         3.615e-06\n",
      "time/training (s)                       3.15891\n",
      "time/epoch (s)                         23.3181\n",
      "time/total (s)                       6464.26\n",
      "Epoch                                 299\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:13:41.670593 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 300 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 311000\n",
      "trainer/ZF1 Loss                      142.382\n",
      "trainer/ZF2 Loss                      133.699\n",
      "trainer/ZF Expert Reward               13.95\n",
      "trainer/ZF Policy Reward                4.11117\n",
      "trainer/ZF CHI2 Term                  139.706\n",
      "trainer/Policy Loss                  -954.881\n",
      "trainer/Bias Loss                      13.4598\n",
      "trainer/Bias Value                     15.4941\n",
      "trainer/Policy Grad Norm              203.093\n",
      "trainer/Policy Param Norm              58.965\n",
      "trainer/Zf1 Grad Norm                7872.94\n",
      "trainer/Zf1 Param Norm                169.639\n",
      "trainer/Zf2 Grad Norm                6642.68\n",
      "trainer/Zf2 Param Norm                167.381\n",
      "trainer/Z Expert Predictions Mean    1236.52\n",
      "trainer/Z Expert Predictions Std       39.9501\n",
      "trainer/Z Expert Predictions Max     1333.03\n",
      "trainer/Z Expert Predictions Min     1121.08\n",
      "trainer/Z Policy Predictions Mean     951.649\n",
      "trainer/Z Policy Predictions Std      301.163\n",
      "trainer/Z Policy Predictions Max     1174.97\n",
      "trainer/Z Policy Predictions Min       -0.0837859\n",
      "trainer/Z Expert Targets Mean        1222.57\n",
      "trainer/Z Expert Targets Std           40.538\n",
      "trainer/Z Expert Targets Max         1322.06\n",
      "trainer/Z Expert Targets Min         1100.58\n",
      "trainer/Z Policy Targets Mean         947.538\n",
      "trainer/Z Policy Targets Std          301.992\n",
      "trainer/Z Policy Targets Max         1182.77\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   50.1935\n",
      "trainer/Log Pis Std                    22.9358\n",
      "trainer/Policy mu Mean                  0.23829\n",
      "trainer/Policy mu Std                   3.12878\n",
      "trainer/Policy log std Mean            -3.03359\n",
      "trainer/Policy log std Std              1.07441\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        306077\n",
      "exploration/num paths total          1464\n",
      "evaluation/num steps total              1.90384e+06\n",
      "evaluation/num paths total           3083\n",
      "evaluation/path length Mean           890\n",
      "evaluation/path length Std            250.089\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            184\n",
      "evaluation/Rewards Mean                 5.29518\n",
      "evaluation/Rewards Std                  0.094842\n",
      "evaluation/Rewards Max                  5.63311\n",
      "evaluation/Rewards Min                  4.69574\n",
      "evaluation/Returns Mean              4712.71\n",
      "evaluation/Returns Std               1332.6\n",
      "evaluation/Returns Max               5310.75\n",
      "evaluation/Returns Min                959.832\n",
      "evaluation/Estimation Bias Mean      1049.11\n",
      "evaluation/Estimation Bias Std        229.757\n",
      "evaluation/EB/Q_True Mean              48.9191\n",
      "evaluation/EB/Q_True Std              148.895\n",
      "evaluation/EB/Q_Pred Mean            1098.03\n",
      "evaluation/EB/Q_Pred Std              124.037\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4712.71\n",
      "evaluation/Actions Mean                 0.0803191\n",
      "evaluation/Actions Std                  0.512726\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.2157\n",
      "time/backward_zf1 (s)                   2.84872\n",
      "time/backward_zf2 (s)                   2.64418\n",
      "time/data sampling (s)                  0.503686\n",
      "time/data storing (s)                   0.0171677\n",
      "time/evaluation sampling (s)            2.61527\n",
      "time/exploration sampling (s)           0.519579\n",
      "time/logging (s)                        0.0130706\n",
      "time/preback_alpha (s)                  0.689054\n",
      "time/preback_policy (s)                 1.27134\n",
      "time/preback_start (s)                  0.207752\n",
      "time/preback_zf (s)                     7.04866\n",
      "time/saving (s)                         4.111e-06\n",
      "time/training (s)                       3.26337\n",
      "time/epoch (s)                         23.8576\n",
      "time/total (s)                       6488.14\n",
      "Epoch                                 300\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:14:05.458625 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 301 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 312000\n",
      "trainer/ZF1 Loss                      168.499\n",
      "trainer/ZF2 Loss                      158.859\n",
      "trainer/ZF Expert Reward               15.0161\n",
      "trainer/ZF Policy Reward                3.24245\n",
      "trainer/ZF CHI2 Term                  166.545\n",
      "trainer/Policy Loss                  -943.735\n",
      "trainer/Bias Loss                      24.5677\n",
      "trainer/Bias Value                     15.506\n",
      "trainer/Policy Grad Norm              225.141\n",
      "trainer/Policy Param Norm              59.018\n",
      "trainer/Zf1 Grad Norm               11639.2\n",
      "trainer/Zf1 Param Norm                169.862\n",
      "trainer/Zf2 Grad Norm                8611.26\n",
      "trainer/Zf2 Param Norm                167.621\n",
      "trainer/Z Expert Predictions Mean    1221.51\n",
      "trainer/Z Expert Predictions Std       38.4634\n",
      "trainer/Z Expert Predictions Max     1343.47\n",
      "trainer/Z Expert Predictions Min     1096.53\n",
      "trainer/Z Policy Predictions Mean     939.106\n",
      "trainer/Z Policy Predictions Std      306.843\n",
      "trainer/Z Policy Predictions Max     1165.07\n",
      "trainer/Z Policy Predictions Min       -5.84544\n",
      "trainer/Z Expert Targets Mean        1206.49\n",
      "trainer/Z Expert Targets Std           39.427\n",
      "trainer/Z Expert Targets Max         1313.04\n",
      "trainer/Z Expert Targets Min         1079.64\n",
      "trainer/Z Policy Targets Mean         935.863\n",
      "trainer/Z Policy Targets Std          306.037\n",
      "trainer/Z Policy Targets Max         1159.04\n",
      "trainer/Z Policy Targets Min           -3.24597\n",
      "trainer/Log Pis Mean                   50.9888\n",
      "trainer/Log Pis Std                    24.071\n",
      "trainer/Policy mu Mean                  0.3124\n",
      "trainer/Policy mu Std                   3.01817\n",
      "trainer/Policy log std Mean            -3.00328\n",
      "trainer/Policy log std Std              1.10985\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        306077\n",
      "exploration/num paths total          1464\n",
      "evaluation/num steps total              1.91384e+06\n",
      "evaluation/num paths total           3093\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.32264\n",
      "evaluation/Rewards Std                  0.0858994\n",
      "evaluation/Rewards Max                  5.64896\n",
      "evaluation/Rewards Min                  4.84632\n",
      "evaluation/Returns Mean              5322.64\n",
      "evaluation/Returns Std                  3.79403\n",
      "evaluation/Returns Max               5328.77\n",
      "evaluation/Returns Min               5316.35\n",
      "evaluation/Estimation Bias Mean      1034.99\n",
      "evaluation/Estimation Bias Std        171.148\n",
      "evaluation/EB/Q_True Mean              48.0116\n",
      "evaluation/EB/Q_True Std              147.85\n",
      "evaluation/EB/Q_Pred Mean            1083\n",
      "evaluation/EB/Q_Pred Std               69.0708\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5322.64\n",
      "evaluation/Actions Mean                 0.0768482\n",
      "evaluation/Actions Std                  0.515698\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.22142\n",
      "time/backward_zf1 (s)                   2.84127\n",
      "time/backward_zf2 (s)                   2.68869\n",
      "time/data sampling (s)                  0.47701\n",
      "time/data storing (s)                   0.0185062\n",
      "time/evaluation sampling (s)            2.44536\n",
      "time/exploration sampling (s)           0.528572\n",
      "time/logging (s)                        0.0131244\n",
      "time/preback_alpha (s)                  0.680781\n",
      "time/preback_policy (s)                 1.32313\n",
      "time/preback_start (s)                  0.216503\n",
      "time/preback_zf (s)                     7.08547\n",
      "time/saving (s)                         3.352e-06\n",
      "time/training (s)                       3.16654\n",
      "time/epoch (s)                         23.7064\n",
      "time/total (s)                       6511.87\n",
      "Epoch                                 301\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:14:29.090284 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 302 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 313000\n",
      "trainer/ZF1 Loss                      140.671\n",
      "trainer/ZF2 Loss                      155.871\n",
      "trainer/ZF Expert Reward               12.5787\n",
      "trainer/ZF Policy Reward                4.97755\n",
      "trainer/ZF CHI2 Term                  148.77\n",
      "trainer/Policy Loss                  -881.812\n",
      "trainer/Bias Loss                      30.4413\n",
      "trainer/Bias Value                     15.5145\n",
      "trainer/Policy Grad Norm              167.503\n",
      "trainer/Policy Param Norm              59.0731\n",
      "trainer/Zf1 Grad Norm                8190.91\n",
      "trainer/Zf1 Param Norm                170.101\n",
      "trainer/Zf2 Grad Norm                9263\n",
      "trainer/Zf2 Param Norm                167.878\n",
      "trainer/Z Expert Predictions Mean    1216.45\n",
      "trainer/Z Expert Predictions Std       39.8933\n",
      "trainer/Z Expert Predictions Max     1315.87\n",
      "trainer/Z Expert Predictions Min     1119.08\n",
      "trainer/Z Policy Predictions Mean     878.703\n",
      "trainer/Z Policy Predictions Std      359.831\n",
      "trainer/Z Policy Predictions Max     1172.08\n",
      "trainer/Z Policy Predictions Min        3.06071\n",
      "trainer/Z Expert Targets Mean        1203.87\n",
      "trainer/Z Expert Targets Std           39.695\n",
      "trainer/Z Expert Targets Max         1306.58\n",
      "trainer/Z Expert Targets Min         1110.26\n",
      "trainer/Z Policy Targets Mean         873.726\n",
      "trainer/Z Policy Targets Std          360.345\n",
      "trainer/Z Policy Targets Max         1165.65\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   53.9486\n",
      "trainer/Log Pis Std                    25.2953\n",
      "trainer/Policy mu Mean                  0.336403\n",
      "trainer/Policy mu Std                   3.50907\n",
      "trainer/Policy log std Mean            -2.85233\n",
      "trainer/Policy log std Std              1.2842\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        307077\n",
      "exploration/num paths total          1465\n",
      "evaluation/num steps total              1.92355e+06\n",
      "evaluation/num paths total           3104\n",
      "evaluation/path length Mean           882\n",
      "evaluation/path length Std            223.304\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            265\n",
      "evaluation/Rewards Mean                 5.27227\n",
      "evaluation/Rewards Std                  0.136842\n",
      "evaluation/Rewards Max                  6.34446\n",
      "evaluation/Rewards Min                  4.01556\n",
      "evaluation/Returns Mean              4650.15\n",
      "evaluation/Returns Std               1200.26\n",
      "evaluation/Returns Max               5297.84\n",
      "evaluation/Returns Min               1329.83\n",
      "evaluation/Estimation Bias Mean      1026.39\n",
      "evaluation/Estimation Bias Std        199.541\n",
      "evaluation/EB/Q_True Mean              49.2357\n",
      "evaluation/EB/Q_True Std              149.128\n",
      "evaluation/EB/Q_Pred Mean            1075.62\n",
      "evaluation/EB/Q_Pred Std              122.734\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4650.15\n",
      "evaluation/Actions Mean                 0.0888552\n",
      "evaluation/Actions Std                  0.524227\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.16308\n",
      "time/backward_zf1 (s)                   2.79066\n",
      "time/backward_zf2 (s)                   2.60569\n",
      "time/data sampling (s)                  0.46958\n",
      "time/data storing (s)                   0.0183636\n",
      "time/evaluation sampling (s)            2.50682\n",
      "time/exploration sampling (s)           0.535519\n",
      "time/logging (s)                        0.0134592\n",
      "time/preback_alpha (s)                  0.679496\n",
      "time/preback_policy (s)                 1.24095\n",
      "time/preback_start (s)                  0.212489\n",
      "time/preback_zf (s)                     7.01285\n",
      "time/saving (s)                         2.803e-06\n",
      "time/training (s)                       3.3016\n",
      "time/epoch (s)                         23.5505\n",
      "time/total (s)                       6535.45\n",
      "Epoch                                 302\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:14:52.764663 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 303 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 314000\n",
      "trainer/ZF1 Loss                      164.99\n",
      "trainer/ZF2 Loss                      166.312\n",
      "trainer/ZF Expert Reward               15.4089\n",
      "trainer/ZF Policy Reward                4.68851\n",
      "trainer/ZF CHI2 Term                  169.097\n",
      "trainer/Policy Loss                  -902.54\n",
      "trainer/Bias Loss                      13.6796\n",
      "trainer/Bias Value                     15.5243\n",
      "trainer/Policy Grad Norm              185.583\n",
      "trainer/Policy Param Norm              59.1229\n",
      "trainer/Zf1 Grad Norm                6201.02\n",
      "trainer/Zf1 Param Norm                170.339\n",
      "trainer/Zf2 Grad Norm                6506.74\n",
      "trainer/Zf2 Param Norm                168.102\n",
      "trainer/Z Expert Predictions Mean    1200.17\n",
      "trainer/Z Expert Predictions Std       86.0064\n",
      "trainer/Z Expert Predictions Max     1301.63\n",
      "trainer/Z Expert Predictions Min       20.1116\n",
      "trainer/Z Policy Predictions Mean     897.019\n",
      "trainer/Z Policy Predictions Std      330.057\n",
      "trainer/Z Policy Predictions Max     1168.13\n",
      "trainer/Z Policy Predictions Min        6.44328\n",
      "trainer/Z Expert Targets Mean        1184.76\n",
      "trainer/Z Expert Targets Std           86.6805\n",
      "trainer/Z Expert Targets Max         1286.39\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         892.33\n",
      "trainer/Z Policy Targets Std          329.03\n",
      "trainer/Z Policy Targets Max         1161.3\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   54.0956\n",
      "trainer/Log Pis Std                    25.123\n",
      "trainer/Policy mu Mean                  0.323962\n",
      "trainer/Policy mu Std                   3.42903\n",
      "trainer/Policy log std Mean            -2.93772\n",
      "trainer/Policy log std Std              1.20714\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        309077\n",
      "exploration/num paths total          1467\n",
      "evaluation/num steps total              1.93279e+06\n",
      "evaluation/num paths total           3114\n",
      "evaluation/path length Mean           924.2\n",
      "evaluation/path length Std            151.603\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            619\n",
      "evaluation/Rewards Mean                 5.28675\n",
      "evaluation/Rewards Std                  0.0986628\n",
      "evaluation/Rewards Max                  5.81484\n",
      "evaluation/Rewards Min                  4.7725\n",
      "evaluation/Returns Mean              4886.01\n",
      "evaluation/Returns Std                795.367\n",
      "evaluation/Returns Max               5303.32\n",
      "evaluation/Returns Min               3280.71\n",
      "evaluation/Estimation Bias Mean       977.37\n",
      "evaluation/Estimation Bias Std        193.579\n",
      "evaluation/EB/Q_True Mean              51.5005\n",
      "evaluation/EB/Q_True Std              151.907\n",
      "evaluation/EB/Q_Pred Mean            1028.87\n",
      "evaluation/EB/Q_Pred Std              112.59\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4886.01\n",
      "evaluation/Actions Mean                 0.0888664\n",
      "evaluation/Actions Std                  0.539305\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.24392\n",
      "time/backward_zf1 (s)                   2.86021\n",
      "time/backward_zf2 (s)                   2.66705\n",
      "time/data sampling (s)                  0.466481\n",
      "time/data storing (s)                   0.0188198\n",
      "time/evaluation sampling (s)            2.44017\n",
      "time/exploration sampling (s)           0.539908\n",
      "time/logging (s)                        0.0126145\n",
      "time/preback_alpha (s)                  0.682491\n",
      "time/preback_policy (s)                 1.27336\n",
      "time/preback_start (s)                  0.217296\n",
      "time/preback_zf (s)                     7.04321\n",
      "time/saving (s)                         3.644e-06\n",
      "time/training (s)                       3.12784\n",
      "time/epoch (s)                         23.5934\n",
      "time/total (s)                       6559.06\n",
      "Epoch                                 303\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:15:16.814949 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 304 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 315000\n",
      "trainer/ZF1 Loss                      142.714\n",
      "trainer/ZF2 Loss                      920.067\n",
      "trainer/ZF Expert Reward               13.2459\n",
      "trainer/ZF Policy Reward                7.15353\n",
      "trainer/ZF CHI2 Term                  532.693\n",
      "trainer/Policy Loss                  -919.59\n",
      "trainer/Bias Loss                      17.7466\n",
      "trainer/Bias Value                     15.535\n",
      "trainer/Policy Grad Norm              299.321\n",
      "trainer/Policy Param Norm              59.1755\n",
      "trainer/Zf1 Grad Norm                9620.48\n",
      "trainer/Zf1 Param Norm                170.547\n",
      "trainer/Zf2 Grad Norm               19119.4\n",
      "trainer/Zf2 Param Norm                168.32\n",
      "trainer/Z Expert Predictions Mean    1200.76\n",
      "trainer/Z Expert Predictions Std       42.0958\n",
      "trainer/Z Expert Predictions Max     1309.34\n",
      "trainer/Z Expert Predictions Min      971.403\n",
      "trainer/Z Policy Predictions Mean     914.69\n",
      "trainer/Z Policy Predictions Std      296.003\n",
      "trainer/Z Policy Predictions Max     1149.22\n",
      "trainer/Z Policy Predictions Min       18.3302\n",
      "trainer/Z Expert Targets Mean        1187.51\n",
      "trainer/Z Expert Targets Std           43.0614\n",
      "trainer/Z Expert Targets Max         1303.21\n",
      "trainer/Z Expert Targets Min          954.056\n",
      "trainer/Z Policy Targets Mean         907.536\n",
      "trainer/Z Policy Targets Std          299.518\n",
      "trainer/Z Policy Targets Max         1143.06\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   51.3109\n",
      "trainer/Log Pis Std                    21.5131\n",
      "trainer/Policy mu Mean                  0.256051\n",
      "trainer/Policy mu Std                   2.44422\n",
      "trainer/Policy log std Mean            -3.05914\n",
      "trainer/Policy log std Std              1.00227\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        310077\n",
      "exploration/num paths total          1468\n",
      "evaluation/num steps total              1.94231e+06\n",
      "evaluation/num paths total           3124\n",
      "evaluation/path length Mean           952.1\n",
      "evaluation/path length Std            143.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            521\n",
      "evaluation/Rewards Mean                 5.27361\n",
      "evaluation/Rewards Std                  0.109342\n",
      "evaluation/Rewards Max                  5.51975\n",
      "evaluation/Rewards Min                  3.86077\n",
      "evaluation/Returns Mean              5021\n",
      "evaluation/Returns Std                782.915\n",
      "evaluation/Returns Max               5289.59\n",
      "evaluation/Returns Min               2672.32\n",
      "evaluation/Estimation Bias Mean      1000.28\n",
      "evaluation/Estimation Bias Std        194.267\n",
      "evaluation/EB/Q_True Mean              49.9564\n",
      "evaluation/EB/Q_True Std              149.694\n",
      "evaluation/EB/Q_Pred Mean            1050.24\n",
      "evaluation/EB/Q_Pred Std               89.1847\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5021\n",
      "evaluation/Actions Mean                 0.0900191\n",
      "evaluation/Actions Std                  0.521039\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.26814\n",
      "time/backward_zf1 (s)                   2.90966\n",
      "time/backward_zf2 (s)                   2.74126\n",
      "time/data sampling (s)                  0.49086\n",
      "time/data storing (s)                   0.0179078\n",
      "time/evaluation sampling (s)            2.43868\n",
      "time/exploration sampling (s)           0.536143\n",
      "time/logging (s)                        0.0132478\n",
      "time/preback_alpha (s)                  0.689689\n",
      "time/preback_policy (s)                 1.35395\n",
      "time/preback_start (s)                  0.210021\n",
      "time/preback_zf (s)                     7.12916\n",
      "time/saving (s)                         4.03e-06\n",
      "time/training (s)                       3.1613\n",
      "time/epoch (s)                         23.96\n",
      "time/total (s)                       6583.06\n",
      "Epoch                                 304\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:15:40.653539 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 305 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 316000\n",
      "trainer/ZF1 Loss                      218.952\n",
      "trainer/ZF2 Loss                      170.008\n",
      "trainer/ZF Expert Reward               12.7782\n",
      "trainer/ZF Policy Reward                6.29083\n",
      "trainer/ZF CHI2 Term                  195.397\n",
      "trainer/Policy Loss                  -897.185\n",
      "trainer/Bias Loss                      36.1155\n",
      "trainer/Bias Value                     15.5458\n",
      "trainer/Policy Grad Norm              228.681\n",
      "trainer/Policy Param Norm              59.2233\n",
      "trainer/Zf1 Grad Norm               10283.9\n",
      "trainer/Zf1 Param Norm                170.787\n",
      "trainer/Zf2 Grad Norm                5815.9\n",
      "trainer/Zf2 Param Norm                168.547\n",
      "trainer/Z Expert Predictions Mean    1188.68\n",
      "trainer/Z Expert Predictions Std       87.2519\n",
      "trainer/Z Expert Predictions Max     1284.1\n",
      "trainer/Z Expert Predictions Min      -32.7365\n",
      "trainer/Z Policy Predictions Mean     893.779\n",
      "trainer/Z Policy Predictions Std      316.399\n",
      "trainer/Z Policy Predictions Max     1144.19\n",
      "trainer/Z Policy Predictions Min        7.04395\n",
      "trainer/Z Expert Targets Mean        1175.91\n",
      "trainer/Z Expert Targets Std           85.2615\n",
      "trainer/Z Expert Targets Max         1290.32\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         887.489\n",
      "trainer/Z Policy Targets Std          314.383\n",
      "trainer/Z Policy Targets Max         1156.64\n",
      "trainer/Z Policy Targets Min           -0.0104698\n",
      "trainer/Log Pis Mean                   52.9215\n",
      "trainer/Log Pis Std                    20.4777\n",
      "trainer/Policy mu Mean                  0.357252\n",
      "trainer/Policy mu Std                   2.93234\n",
      "trainer/Policy log std Mean            -2.94912\n",
      "trainer/Policy log std Std              1.15615\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        311077\n",
      "exploration/num paths total          1469\n",
      "evaluation/num steps total              1.95159e+06\n",
      "evaluation/num paths total           3134\n",
      "evaluation/path length Mean           928\n",
      "evaluation/path length Std            216\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            280\n",
      "evaluation/Rewards Mean                 5.30449\n",
      "evaluation/Rewards Std                  0.0874627\n",
      "evaluation/Rewards Max                  5.5104\n",
      "evaluation/Rewards Min                  4.80239\n",
      "evaluation/Returns Mean              4922.57\n",
      "evaluation/Returns Std               1159.26\n",
      "evaluation/Returns Max               5322.53\n",
      "evaluation/Returns Min               1444.84\n",
      "evaluation/Estimation Bias Mean      1013.03\n",
      "evaluation/Estimation Bias Std        198.564\n",
      "evaluation/EB/Q_True Mean              51.7726\n",
      "evaluation/EB/Q_True Std              152.966\n",
      "evaluation/EB/Q_Pred Mean            1064.8\n",
      "evaluation/EB/Q_Pred Std               86.6165\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4922.57\n",
      "evaluation/Actions Mean                 0.0846959\n",
      "evaluation/Actions Std                  0.523331\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.26624\n",
      "time/backward_zf1 (s)                   2.85812\n",
      "time/backward_zf2 (s)                   2.6846\n",
      "time/data sampling (s)                  0.49256\n",
      "time/data storing (s)                   0.0165896\n",
      "time/evaluation sampling (s)            2.32215\n",
      "time/exploration sampling (s)           0.509706\n",
      "time/logging (s)                        0.0122394\n",
      "time/preback_alpha (s)                  0.687854\n",
      "time/preback_policy (s)                 1.28165\n",
      "time/preback_start (s)                  0.208123\n",
      "time/preback_zf (s)                     7.09933\n",
      "time/saving (s)                         2.891e-06\n",
      "time/training (s)                       3.32132\n",
      "time/epoch (s)                         23.7605\n",
      "time/total (s)                       6606.83\n",
      "Epoch                                 305\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:16:04.359475 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 306 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 317000\n",
      "trainer/ZF1 Loss                      178.957\n",
      "trainer/ZF2 Loss                      187.578\n",
      "trainer/ZF Expert Reward               14.4273\n",
      "trainer/ZF Policy Reward                5.41792\n",
      "trainer/ZF CHI2 Term                  185.84\n",
      "trainer/Policy Loss                  -907.436\n",
      "trainer/Bias Loss                      23.2984\n",
      "trainer/Bias Value                     15.5492\n",
      "trainer/Policy Grad Norm              202.804\n",
      "trainer/Policy Param Norm              59.2764\n",
      "trainer/Zf1 Grad Norm                7551.42\n",
      "trainer/Zf1 Param Norm                171.06\n",
      "trainer/Zf2 Grad Norm                8273.29\n",
      "trainer/Zf2 Param Norm                168.822\n",
      "trainer/Z Expert Predictions Mean    1193.13\n",
      "trainer/Z Expert Predictions Std       49.1738\n",
      "trainer/Z Expert Predictions Max     1305.02\n",
      "trainer/Z Expert Predictions Min      897.656\n",
      "trainer/Z Policy Predictions Mean     905.109\n",
      "trainer/Z Policy Predictions Std      298.442\n",
      "trainer/Z Policy Predictions Max     1146.27\n",
      "trainer/Z Policy Predictions Min      -15.4048\n",
      "trainer/Z Expert Targets Mean        1178.7\n",
      "trainer/Z Expert Targets Std           49.4842\n",
      "trainer/Z Expert Targets Max         1286.39\n",
      "trainer/Z Expert Targets Min          884.514\n",
      "trainer/Z Policy Targets Mean         899.691\n",
      "trainer/Z Policy Targets Std          296.653\n",
      "trainer/Z Policy Targets Max         1132.01\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   50.5654\n",
      "trainer/Log Pis Std                    21.3819\n",
      "trainer/Policy mu Mean                  0.175535\n",
      "trainer/Policy mu Std                   2.54945\n",
      "trainer/Policy log std Mean            -2.99573\n",
      "trainer/Policy log std Std              1.04184\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        312077\n",
      "exploration/num paths total          1470\n",
      "evaluation/num steps total              1.96159e+06\n",
      "evaluation/num paths total           3144\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.30511\n",
      "evaluation/Rewards Std                  0.0793554\n",
      "evaluation/Rewards Max                  5.51104\n",
      "evaluation/Rewards Min                  4.84602\n",
      "evaluation/Returns Mean              5305.11\n",
      "evaluation/Returns Std                  7.08372\n",
      "evaluation/Returns Max               5318.06\n",
      "evaluation/Returns Min               5295.41\n",
      "evaluation/Estimation Bias Mean      1034.2\n",
      "evaluation/Estimation Bias Std        153.8\n",
      "evaluation/EB/Q_True Mean              47.9675\n",
      "evaluation/EB/Q_True Std              147.721\n",
      "evaluation/EB/Q_Pred Mean            1082.17\n",
      "evaluation/EB/Q_Pred Std               44.6705\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5305.11\n",
      "evaluation/Actions Mean                 0.0740048\n",
      "evaluation/Actions Std                  0.513222\n",
      "evaluation/Actions Max                  0.999921\n",
      "evaluation/Actions Min                 -0.999184\n",
      "time/backward_policy (s)                2.2147\n",
      "time/backward_zf1 (s)                   2.87344\n",
      "time/backward_zf2 (s)                   2.66409\n",
      "time/data sampling (s)                  0.490415\n",
      "time/data storing (s)                   0.0175406\n",
      "time/evaluation sampling (s)            2.23485\n",
      "time/exploration sampling (s)           0.534295\n",
      "time/logging (s)                        0.0128146\n",
      "time/preback_alpha (s)                  0.695041\n",
      "time/preback_policy (s)                 1.27808\n",
      "time/preback_start (s)                  0.208863\n",
      "time/preback_zf (s)                     7.12655\n",
      "time/saving (s)                         3.379e-06\n",
      "time/training (s)                       3.27669\n",
      "time/epoch (s)                         23.6274\n",
      "time/total (s)                       6630.48\n",
      "Epoch                                 306\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:16:28.399914 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 307 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 318000\n",
      "trainer/ZF1 Loss                      129.034\n",
      "trainer/ZF2 Loss                      140.173\n",
      "trainer/ZF Expert Reward               15.8055\n",
      "trainer/ZF Policy Reward                7.82965\n",
      "trainer/ZF CHI2 Term                  138.623\n",
      "trainer/Policy Loss                  -922.836\n",
      "trainer/Bias Loss                      14.1646\n",
      "trainer/Bias Value                     15.5617\n",
      "trainer/Policy Grad Norm              189.49\n",
      "trainer/Policy Param Norm              59.333\n",
      "trainer/Zf1 Grad Norm                6311.64\n",
      "trainer/Zf1 Param Norm                171.275\n",
      "trainer/Zf2 Grad Norm                8364.92\n",
      "trainer/Zf2 Param Norm                169.044\n",
      "trainer/Z Expert Predictions Mean    1186.51\n",
      "trainer/Z Expert Predictions Std       40.8397\n",
      "trainer/Z Expert Predictions Max     1296.42\n",
      "trainer/Z Expert Predictions Min     1069.79\n",
      "trainer/Z Policy Predictions Mean     919.342\n",
      "trainer/Z Policy Predictions Std      284.092\n",
      "trainer/Z Policy Predictions Max     1116.22\n",
      "trainer/Z Policy Predictions Min        6.57654\n",
      "trainer/Z Expert Targets Mean        1170.71\n",
      "trainer/Z Expert Targets Std           41.8952\n",
      "trainer/Z Expert Targets Max         1290.03\n",
      "trainer/Z Expert Targets Min         1046.09\n",
      "trainer/Z Policy Targets Mean         911.512\n",
      "trainer/Z Policy Targets Std          282.977\n",
      "trainer/Z Policy Targets Max         1120.97\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   50.7438\n",
      "trainer/Log Pis Std                    20.1975\n",
      "trainer/Policy mu Mean                  0.217433\n",
      "trainer/Policy mu Std                   2.50799\n",
      "trainer/Policy log std Mean            -3.07468\n",
      "trainer/Policy log std Std              1.06508\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        312317\n",
      "exploration/num paths total          1471\n",
      "evaluation/num steps total              1.97159e+06\n",
      "evaluation/num paths total           3154\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29715\n",
      "evaluation/Rewards Std                  0.0794378\n",
      "evaluation/Rewards Max                  5.50409\n",
      "evaluation/Rewards Min                  4.79817\n",
      "evaluation/Returns Mean              5297.15\n",
      "evaluation/Returns Std                  4.9847\n",
      "evaluation/Returns Max               5304.82\n",
      "evaluation/Returns Min               5287.28\n",
      "evaluation/Estimation Bias Mean      1002.95\n",
      "evaluation/Estimation Bias Std        160.954\n",
      "evaluation/EB/Q_True Mean              47.8987\n",
      "evaluation/EB/Q_True Std              147.528\n",
      "evaluation/EB/Q_Pred Mean            1050.85\n",
      "evaluation/EB/Q_Pred Std               47.0541\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5297.15\n",
      "evaluation/Actions Mean                 0.0854687\n",
      "evaluation/Actions Std                  0.521371\n",
      "evaluation/Actions Max                  0.999967\n",
      "evaluation/Actions Min                 -0.999167\n",
      "time/backward_policy (s)                2.26769\n",
      "time/backward_zf1 (s)                   2.91464\n",
      "time/backward_zf2 (s)                   2.73141\n",
      "time/data sampling (s)                  0.456572\n",
      "time/data storing (s)                   0.0187794\n",
      "time/evaluation sampling (s)            2.62249\n",
      "time/exploration sampling (s)           0.562588\n",
      "time/logging (s)                        0.0204059\n",
      "time/preback_alpha (s)                  0.678423\n",
      "time/preback_policy (s)                 1.31687\n",
      "time/preback_start (s)                  0.208386\n",
      "time/preback_zf (s)                     7.05694\n",
      "time/saving (s)                         4.36199e-06\n",
      "time/training (s)                       3.11384\n",
      "time/epoch (s)                         23.969\n",
      "time/total (s)                       6654.47\n",
      "Epoch                                 307\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:16:52.174148 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 308 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 319000\n",
      "trainer/ZF1 Loss                      146.687\n",
      "trainer/ZF2 Loss                      194.27\n",
      "trainer/ZF Expert Reward               11.6578\n",
      "trainer/ZF Policy Reward                5.5052\n",
      "trainer/ZF CHI2 Term                  170.497\n",
      "trainer/Policy Loss                  -888.819\n",
      "trainer/Bias Loss                      31.6479\n",
      "trainer/Bias Value                     15.5711\n",
      "trainer/Policy Grad Norm              225.326\n",
      "trainer/Policy Param Norm              59.3846\n",
      "trainer/Zf1 Grad Norm                8847.88\n",
      "trainer/Zf1 Param Norm                171.529\n",
      "trainer/Zf2 Grad Norm               10739.4\n",
      "trainer/Zf2 Param Norm                169.257\n",
      "trainer/Z Expert Predictions Mean    1174.5\n",
      "trainer/Z Expert Predictions Std       42.7636\n",
      "trainer/Z Expert Predictions Max     1275.56\n",
      "trainer/Z Expert Predictions Min     1049.52\n",
      "trainer/Z Policy Predictions Mean     884.679\n",
      "trainer/Z Policy Predictions Std      314.532\n",
      "trainer/Z Policy Predictions Max     1131.03\n",
      "trainer/Z Policy Predictions Min      -13.0756\n",
      "trainer/Z Expert Targets Mean        1162.84\n",
      "trainer/Z Expert Targets Std           42.5124\n",
      "trainer/Z Expert Targets Max         1255.22\n",
      "trainer/Z Expert Targets Min         1035.04\n",
      "trainer/Z Policy Targets Mean         879.174\n",
      "trainer/Z Policy Targets Std          314.768\n",
      "trainer/Z Policy Targets Max         1124.03\n",
      "trainer/Z Policy Targets Min          -20.85\n",
      "trainer/Log Pis Mean                   53.1711\n",
      "trainer/Log Pis Std                    25.0923\n",
      "trainer/Policy mu Mean                  0.315302\n",
      "trainer/Policy mu Std                   2.69517\n",
      "trainer/Policy log std Mean            -3.01937\n",
      "trainer/Policy log std Std              1.07171\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        315317\n",
      "exploration/num paths total          1474\n",
      "evaluation/num steps total              1.98078e+06\n",
      "evaluation/num paths total           3164\n",
      "evaluation/path length Mean           919.4\n",
      "evaluation/path length Std            241.8\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            194\n",
      "evaluation/Rewards Mean                 5.28444\n",
      "evaluation/Rewards Std                  0.0881358\n",
      "evaluation/Rewards Max                  5.63825\n",
      "evaluation/Rewards Min                  4.85893\n",
      "evaluation/Returns Mean              4858.51\n",
      "evaluation/Returns Std               1281.07\n",
      "evaluation/Returns Max               5294.03\n",
      "evaluation/Returns Min               1015.35\n",
      "evaluation/Estimation Bias Mean       974.222\n",
      "evaluation/Estimation Bias Std        192.977\n",
      "evaluation/EB/Q_True Mean              51.9633\n",
      "evaluation/EB/Q_True Std              152.736\n",
      "evaluation/EB/Q_Pred Mean            1026.19\n",
      "evaluation/EB/Q_Pred Std               91.8345\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4858.51\n",
      "evaluation/Actions Mean                 0.0842283\n",
      "evaluation/Actions Std                  0.520397\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.22976\n",
      "time/backward_zf1 (s)                   2.87588\n",
      "time/backward_zf2 (s)                   2.69836\n",
      "time/data sampling (s)                  0.488192\n",
      "time/data storing (s)                   0.0165761\n",
      "time/evaluation sampling (s)            2.40537\n",
      "time/exploration sampling (s)           0.540919\n",
      "time/logging (s)                        0.011781\n",
      "time/preback_alpha (s)                  0.671451\n",
      "time/preback_policy (s)                 1.25566\n",
      "time/preback_start (s)                  0.211299\n",
      "time/preback_zf (s)                     7.03351\n",
      "time/saving (s)                         3.201e-06\n",
      "time/training (s)                       3.24544\n",
      "time/epoch (s)                         23.6842\n",
      "time/total (s)                       6678.18\n",
      "Epoch                                 308\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:17:15.869972 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 309 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 320000\n",
      "trainer/ZF1 Loss                      141.684\n",
      "trainer/ZF2 Loss                      151.921\n",
      "trainer/ZF Expert Reward               16.8557\n",
      "trainer/ZF Policy Reward                3.52035\n",
      "trainer/ZF CHI2 Term                  152.002\n",
      "trainer/Policy Loss                  -851.289\n",
      "trainer/Bias Loss                      13.4232\n",
      "trainer/Bias Value                     15.5845\n",
      "trainer/Policy Grad Norm              209.768\n",
      "trainer/Policy Param Norm              59.4362\n",
      "trainer/Zf1 Grad Norm                5887.32\n",
      "trainer/Zf1 Param Norm                171.737\n",
      "trainer/Zf2 Grad Norm                6802.12\n",
      "trainer/Zf2 Param Norm                169.491\n",
      "trainer/Z Expert Predictions Mean    1173.67\n",
      "trainer/Z Expert Predictions Std       43.4823\n",
      "trainer/Z Expert Predictions Max     1284.88\n",
      "trainer/Z Expert Predictions Min     1082.13\n",
      "trainer/Z Policy Predictions Mean     847.021\n",
      "trainer/Z Policy Predictions Std      325.33\n",
      "trainer/Z Policy Predictions Max     1144.92\n",
      "trainer/Z Policy Predictions Min       -3.26599\n",
      "trainer/Z Expert Targets Mean        1156.81\n",
      "trainer/Z Expert Targets Std           43.6156\n",
      "trainer/Z Expert Targets Max         1271.41\n",
      "trainer/Z Expert Targets Min         1060.26\n",
      "trainer/Z Policy Targets Mean         843.5\n",
      "trainer/Z Policy Targets Std          325.363\n",
      "trainer/Z Policy Targets Max         1109.6\n",
      "trainer/Z Policy Targets Min           -8.52923\n",
      "trainer/Log Pis Mean                   55.253\n",
      "trainer/Log Pis Std                    24.8237\n",
      "trainer/Policy mu Mean                  0.269513\n",
      "trainer/Policy mu Std                   3.16977\n",
      "trainer/Policy log std Mean            -2.95492\n",
      "trainer/Policy log std Std              1.23879\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        316317\n",
      "exploration/num paths total          1475\n",
      "evaluation/num steps total              1.99078e+06\n",
      "evaluation/num paths total           3174\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.27591\n",
      "evaluation/Rewards Std                  0.0768315\n",
      "evaluation/Rewards Max                  5.62776\n",
      "evaluation/Rewards Min                  4.77595\n",
      "evaluation/Returns Mean              5275.91\n",
      "evaluation/Returns Std                  6.0503\n",
      "evaluation/Returns Max               5285.26\n",
      "evaluation/Returns Min               5262.93\n",
      "evaluation/Estimation Bias Mean      1009.02\n",
      "evaluation/Estimation Bias Std        152.139\n",
      "evaluation/EB/Q_True Mean              47.6695\n",
      "evaluation/EB/Q_True Std              146.791\n",
      "evaluation/EB/Q_Pred Mean            1056.69\n",
      "evaluation/EB/Q_Pred Std               48.9187\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5275.91\n",
      "evaluation/Actions Mean                 0.0828583\n",
      "evaluation/Actions Std                  0.509178\n",
      "evaluation/Actions Max                  0.999973\n",
      "evaluation/Actions Min                 -0.999684\n",
      "time/backward_policy (s)                2.25793\n",
      "time/backward_zf1 (s)                   2.89559\n",
      "time/backward_zf2 (s)                   2.73528\n",
      "time/data sampling (s)                  0.490378\n",
      "time/data storing (s)                   0.0177914\n",
      "time/evaluation sampling (s)            2.43822\n",
      "time/exploration sampling (s)           0.527684\n",
      "time/logging (s)                        0.0136124\n",
      "time/preback_alpha (s)                  0.672518\n",
      "time/preback_policy (s)                 1.31552\n",
      "time/preback_start (s)                  0.204875\n",
      "time/preback_zf (s)                     6.99123\n",
      "time/saving (s)                         3.32e-06\n",
      "time/training (s)                       3.05961\n",
      "time/epoch (s)                         23.6202\n",
      "time/total (s)                       6701.82\n",
      "Epoch                                 309\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:17:39.704853 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 310 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 321000\n",
      "trainer/ZF1 Loss                      182.643\n",
      "trainer/ZF2 Loss                      173.001\n",
      "trainer/ZF Expert Reward               16.0559\n",
      "trainer/ZF Policy Reward                8.60669\n",
      "trainer/ZF CHI2 Term                  182.278\n",
      "trainer/Policy Loss                  -903.058\n",
      "trainer/Bias Loss                      28.027\n",
      "trainer/Bias Value                     15.5998\n",
      "trainer/Policy Grad Norm              309.614\n",
      "trainer/Policy Param Norm              59.4914\n",
      "trainer/Zf1 Grad Norm               15936.6\n",
      "trainer/Zf1 Param Norm                171.953\n",
      "trainer/Zf2 Grad Norm               10388.6\n",
      "trainer/Zf2 Param Norm                169.741\n",
      "trainer/Z Expert Predictions Mean    1166.85\n",
      "trainer/Z Expert Predictions Std       43.4812\n",
      "trainer/Z Expert Predictions Max     1283.72\n",
      "trainer/Z Expert Predictions Min     1008.93\n",
      "trainer/Z Policy Predictions Mean     897.62\n",
      "trainer/Z Policy Predictions Std      285.617\n",
      "trainer/Z Policy Predictions Max     1138.6\n",
      "trainer/Z Policy Predictions Min        0.920612\n",
      "trainer/Z Expert Targets Mean        1150.79\n",
      "trainer/Z Expert Targets Std           43.4982\n",
      "trainer/Z Expert Targets Max         1273.98\n",
      "trainer/Z Expert Targets Min          996.966\n",
      "trainer/Z Policy Targets Mean         889.014\n",
      "trainer/Z Policy Targets Std          287.213\n",
      "trainer/Z Policy Targets Max         1103.33\n",
      "trainer/Z Policy Targets Min           -5.25236\n",
      "trainer/Log Pis Mean                   48.2048\n",
      "trainer/Log Pis Std                    19.3466\n",
      "trainer/Policy mu Mean                  0.197862\n",
      "trainer/Policy mu Std                   2.51821\n",
      "trainer/Policy log std Mean            -2.99807\n",
      "trainer/Policy log std Std              1.02867\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        316317\n",
      "exploration/num paths total          1475\n",
      "evaluation/num steps total              2.00078e+06\n",
      "evaluation/num paths total           3184\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.27004\n",
      "evaluation/Rewards Std                  0.0782958\n",
      "evaluation/Rewards Max                  5.48602\n",
      "evaluation/Rewards Min                  4.84374\n",
      "evaluation/Returns Mean              5270.04\n",
      "evaluation/Returns Std                  6.96008\n",
      "evaluation/Returns Max               5283.55\n",
      "evaluation/Returns Min               5262.03\n",
      "evaluation/Estimation Bias Mean       978.631\n",
      "evaluation/Estimation Bias Std        157.359\n",
      "evaluation/EB/Q_True Mean              47.6437\n",
      "evaluation/EB/Q_True Std              146.748\n",
      "evaluation/EB/Q_Pred Mean            1026.27\n",
      "evaluation/EB/Q_Pred Std               45.3472\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5270.04\n",
      "evaluation/Actions Mean                 0.087827\n",
      "evaluation/Actions Std                  0.506411\n",
      "evaluation/Actions Max                  0.99998\n",
      "evaluation/Actions Min                 -0.999679\n",
      "time/backward_policy (s)                2.21005\n",
      "time/backward_zf1 (s)                   2.86518\n",
      "time/backward_zf2 (s)                   2.68366\n",
      "time/data sampling (s)                  0.474473\n",
      "time/data storing (s)                   0.0183436\n",
      "time/evaluation sampling (s)            2.54396\n",
      "time/exploration sampling (s)           0.51451\n",
      "time/logging (s)                        0.0129953\n",
      "time/preback_alpha (s)                  0.680345\n",
      "time/preback_policy (s)                 1.289\n",
      "time/preback_start (s)                  0.215594\n",
      "time/preback_zf (s)                     7.09478\n",
      "time/saving (s)                         2.948e-06\n",
      "time/training (s)                       3.14854\n",
      "time/epoch (s)                         23.7514\n",
      "time/total (s)                       6725.6\n",
      "Epoch                                 310\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:18:03.538657 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 311 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 322000\n",
      "trainer/ZF1 Loss                      142.609\n",
      "trainer/ZF2 Loss                      130.897\n",
      "trainer/ZF Expert Reward               18.3293\n",
      "trainer/ZF Policy Reward                5.95193\n",
      "trainer/ZF CHI2 Term                  143.604\n",
      "trainer/Policy Loss                  -895.303\n",
      "trainer/Bias Loss                      19.4375\n",
      "trainer/Bias Value                     15.6157\n",
      "trainer/Policy Grad Norm              179.33\n",
      "trainer/Policy Param Norm              59.5476\n",
      "trainer/Zf1 Grad Norm                6179.98\n",
      "trainer/Zf1 Param Norm                172.171\n",
      "trainer/Zf2 Grad Norm                5688.86\n",
      "trainer/Zf2 Param Norm                169.962\n",
      "trainer/Z Expert Predictions Mean    1152.41\n",
      "trainer/Z Expert Predictions Std       81.4852\n",
      "trainer/Z Expert Predictions Max     1253.29\n",
      "trainer/Z Expert Predictions Min       -9.45424\n",
      "trainer/Z Policy Predictions Mean     894.928\n",
      "trainer/Z Policy Predictions Std      253.79\n",
      "trainer/Z Policy Predictions Max     1118.31\n",
      "trainer/Z Policy Predictions Min        3.44134\n",
      "trainer/Z Expert Targets Mean        1134.08\n",
      "trainer/Z Expert Targets Std           80.1851\n",
      "trainer/Z Expert Targets Max         1236.56\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         888.976\n",
      "trainer/Z Policy Targets Std          252.822\n",
      "trainer/Z Policy Targets Max         1087.89\n",
      "trainer/Z Policy Targets Min            4.23859\n",
      "trainer/Log Pis Mean                   49.6529\n",
      "trainer/Log Pis Std                    20.6045\n",
      "trainer/Policy mu Mean                  0.229227\n",
      "trainer/Policy mu Std                   2.42461\n",
      "trainer/Policy log std Mean            -3.01714\n",
      "trainer/Policy log std Std              1.02761\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        316317\n",
      "exploration/num paths total          1475\n",
      "evaluation/num steps total              2.01016e+06\n",
      "evaluation/num paths total           3195\n",
      "evaluation/path length Mean           852.182\n",
      "evaluation/path length Std            281.822\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            201\n",
      "evaluation/Rewards Mean                 5.25888\n",
      "evaluation/Rewards Std                  0.122298\n",
      "evaluation/Rewards Max                  6.44562\n",
      "evaluation/Rewards Min                  4.18332\n",
      "evaluation/Returns Mean              4481.52\n",
      "evaluation/Returns Std               1508.22\n",
      "evaluation/Returns Max               5285\n",
      "evaluation/Returns Min               1004.3\n",
      "evaluation/Estimation Bias Mean       929.766\n",
      "evaluation/Estimation Bias Std        225.574\n",
      "evaluation/EB/Q_True Mean              50.8329\n",
      "evaluation/EB/Q_True Std              151.029\n",
      "evaluation/EB/Q_Pred Mean             980.599\n",
      "evaluation/EB/Q_Pred Std              117.53\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4481.52\n",
      "evaluation/Actions Mean                 0.0967257\n",
      "evaluation/Actions Std                  0.524013\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.2105\n",
      "time/backward_zf1 (s)                   2.8511\n",
      "time/backward_zf2 (s)                   2.69494\n",
      "time/data sampling (s)                  0.454491\n",
      "time/data storing (s)                   0.0176663\n",
      "time/evaluation sampling (s)            2.4188\n",
      "time/exploration sampling (s)           0.529519\n",
      "time/logging (s)                        0.0117958\n",
      "time/preback_alpha (s)                  0.693434\n",
      "time/preback_policy (s)                 1.33324\n",
      "time/preback_start (s)                  0.21324\n",
      "time/preback_zf (s)                     7.13527\n",
      "time/saving (s)                         2.488e-06\n",
      "time/training (s)                       3.17507\n",
      "time/epoch (s)                         23.7391\n",
      "time/total (s)                       6749.37\n",
      "Epoch                                 311\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:18:27.570615 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 312 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 323000\n",
      "trainer/ZF1 Loss                      130.22\n",
      "trainer/ZF2 Loss                      165.258\n",
      "trainer/ZF Expert Reward               18.6962\n",
      "trainer/ZF Policy Reward                4.89588\n",
      "trainer/ZF CHI2 Term                  154.991\n",
      "trainer/Policy Loss                  -852.199\n",
      "trainer/Bias Loss                      22.0746\n",
      "trainer/Bias Value                     15.6278\n",
      "trainer/Policy Grad Norm              185.577\n",
      "trainer/Policy Param Norm              59.5994\n",
      "trainer/Zf1 Grad Norm                5969.74\n",
      "trainer/Zf1 Param Norm                172.396\n",
      "trainer/Zf2 Grad Norm                9154.09\n",
      "trainer/Zf2 Param Norm                170.184\n",
      "trainer/Z Expert Predictions Mean    1151.91\n",
      "trainer/Z Expert Predictions Std       45.1751\n",
      "trainer/Z Expert Predictions Max     1260.54\n",
      "trainer/Z Expert Predictions Min      990.294\n",
      "trainer/Z Policy Predictions Mean     850.168\n",
      "trainer/Z Policy Predictions Std      298.344\n",
      "trainer/Z Policy Predictions Max     1088.82\n",
      "trainer/Z Policy Predictions Min      -34.6896\n",
      "trainer/Z Expert Targets Mean        1133.21\n",
      "trainer/Z Expert Targets Std           44.6536\n",
      "trainer/Z Expert Targets Max         1244.58\n",
      "trainer/Z Expert Targets Min          979.049\n",
      "trainer/Z Policy Targets Mean         845.272\n",
      "trainer/Z Policy Targets Std          294.938\n",
      "trainer/Z Policy Targets Max         1101.82\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   52.5322\n",
      "trainer/Log Pis Std                    23.2315\n",
      "trainer/Policy mu Mean                  0.238094\n",
      "trainer/Policy mu Std                   3.16854\n",
      "trainer/Policy log std Mean            -2.9156\n",
      "trainer/Policy log std Std              1.24855\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        317317\n",
      "exploration/num paths total          1476\n",
      "evaluation/num steps total              2.01968e+06\n",
      "evaluation/num paths total           3205\n",
      "evaluation/path length Mean           951.7\n",
      "evaluation/path length Std            114.752\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            620\n",
      "evaluation/Rewards Mean                 5.29376\n",
      "evaluation/Rewards Std                  0.0964625\n",
      "evaluation/Rewards Max                  5.92353\n",
      "evaluation/Rewards Min                  4.62392\n",
      "evaluation/Returns Mean              5038.07\n",
      "evaluation/Returns Std                607.525\n",
      "evaluation/Returns Max               5305.74\n",
      "evaluation/Returns Min               3285.07\n",
      "evaluation/Estimation Bias Mean       946.99\n",
      "evaluation/Estimation Bias Std        200.454\n",
      "evaluation/EB/Q_True Mean              50.3261\n",
      "evaluation/EB/Q_True Std              150.784\n",
      "evaluation/EB/Q_Pred Mean             997.316\n",
      "evaluation/EB/Q_Pred Std              110.679\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5038.07\n",
      "evaluation/Actions Mean                 0.0823246\n",
      "evaluation/Actions Std                  0.509467\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.2455\n",
      "time/backward_zf1 (s)                   2.84249\n",
      "time/backward_zf2 (s)                   2.67258\n",
      "time/data sampling (s)                  0.489277\n",
      "time/data storing (s)                   0.0184301\n",
      "time/evaluation sampling (s)            2.63879\n",
      "time/exploration sampling (s)           0.562865\n",
      "time/logging (s)                        0.012994\n",
      "time/preback_alpha (s)                  0.685349\n",
      "time/preback_policy (s)                 1.31532\n",
      "time/preback_start (s)                  0.213052\n",
      "time/preback_zf (s)                     7.0388\n",
      "time/saving (s)                         3.498e-06\n",
      "time/training (s)                       3.2171\n",
      "time/epoch (s)                         23.9526\n",
      "time/total (s)                       6773.34\n",
      "Epoch                                 312\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:18:51.421435 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 313 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 324000\n",
      "trainer/ZF1 Loss                      206.153\n",
      "trainer/ZF2 Loss                      199.94\n",
      "trainer/ZF Expert Reward               14.164\n",
      "trainer/ZF Policy Reward                9.69374\n",
      "trainer/ZF CHI2 Term                  205.823\n",
      "trainer/Policy Loss                  -887.568\n",
      "trainer/Bias Loss                      30.0883\n",
      "trainer/Bias Value                     15.6404\n",
      "trainer/Policy Grad Norm              204.719\n",
      "trainer/Policy Param Norm              59.6511\n",
      "trainer/Zf1 Grad Norm                7805.43\n",
      "trainer/Zf1 Param Norm                172.626\n",
      "trainer/Zf2 Grad Norm                6985.67\n",
      "trainer/Zf2 Param Norm                170.397\n",
      "trainer/Z Expert Predictions Mean    1146.74\n",
      "trainer/Z Expert Predictions Std       46.5689\n",
      "trainer/Z Expert Predictions Max     1295.18\n",
      "trainer/Z Expert Predictions Min     1038.69\n",
      "trainer/Z Policy Predictions Mean     885.972\n",
      "trainer/Z Policy Predictions Std      253.986\n",
      "trainer/Z Policy Predictions Max     1089.17\n",
      "trainer/Z Policy Predictions Min       29.5316\n",
      "trainer/Z Expert Targets Mean        1132.57\n",
      "trainer/Z Expert Targets Std           47.6614\n",
      "trainer/Z Expert Targets Max         1282.99\n",
      "trainer/Z Expert Targets Min         1020.16\n",
      "trainer/Z Policy Targets Mean         876.279\n",
      "trainer/Z Policy Targets Std          252.646\n",
      "trainer/Z Policy Targets Max         1102.84\n",
      "trainer/Z Policy Targets Min           20.0895\n",
      "trainer/Log Pis Mean                   47.5934\n",
      "trainer/Log Pis Std                    20.254\n",
      "trainer/Policy mu Mean                  0.323377\n",
      "trainer/Policy mu Std                   2.16963\n",
      "trainer/Policy log std Mean            -2.96362\n",
      "trainer/Policy log std Std              0.986436\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        319317\n",
      "exploration/num paths total          1478\n",
      "evaluation/num steps total              2.02968e+06\n",
      "evaluation/num paths total           3215\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29639\n",
      "evaluation/Rewards Std                  0.0790587\n",
      "evaluation/Rewards Max                  5.4868\n",
      "evaluation/Rewards Min                  4.84496\n",
      "evaluation/Returns Mean              5296.39\n",
      "evaluation/Returns Std                  2.81804\n",
      "evaluation/Returns Max               5300.74\n",
      "evaluation/Returns Min               5291.97\n",
      "evaluation/Estimation Bias Mean       965.974\n",
      "evaluation/Estimation Bias Std        154.197\n",
      "evaluation/EB/Q_True Mean              47.828\n",
      "evaluation/EB/Q_True Std              147.289\n",
      "evaluation/EB/Q_Pred Mean            1013.8\n",
      "evaluation/EB/Q_Pred Std               43.7295\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5296.39\n",
      "evaluation/Actions Mean                 0.0671275\n",
      "evaluation/Actions Std                  0.495808\n",
      "evaluation/Actions Max                  0.999787\n",
      "evaluation/Actions Min                 -0.999391\n",
      "time/backward_policy (s)                2.22398\n",
      "time/backward_zf1 (s)                   2.85975\n",
      "time/backward_zf2 (s)                   2.648\n",
      "time/data sampling (s)                  0.491911\n",
      "time/data storing (s)                   0.0188447\n",
      "time/evaluation sampling (s)            2.45225\n",
      "time/exploration sampling (s)           0.549441\n",
      "time/logging (s)                        0.0134869\n",
      "time/preback_alpha (s)                  0.689214\n",
      "time/preback_policy (s)                 1.25701\n",
      "time/preback_start (s)                  0.213021\n",
      "time/preback_zf (s)                     7.06749\n",
      "time/saving (s)                         3.287e-06\n",
      "time/training (s)                       3.28128\n",
      "time/epoch (s)                         23.7657\n",
      "time/total (s)                       6797.14\n",
      "Epoch                                 313\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:19:15.314043 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 314 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 325000\n",
      "trainer/ZF1 Loss                      141.863\n",
      "trainer/ZF2 Loss                      936.802\n",
      "trainer/ZF Expert Reward               16.3819\n",
      "trainer/ZF Policy Reward                5.68998\n",
      "trainer/ZF CHI2 Term                  544.385\n",
      "trainer/Policy Loss                  -870.104\n",
      "trainer/Bias Loss                      14.928\n",
      "trainer/Bias Value                     15.6504\n",
      "trainer/Policy Grad Norm              268.73\n",
      "trainer/Policy Param Norm              59.6998\n",
      "trainer/Zf1 Grad Norm               10652.2\n",
      "trainer/Zf1 Param Norm                172.865\n",
      "trainer/Zf2 Grad Norm               10246.7\n",
      "trainer/Zf2 Param Norm                170.665\n",
      "trainer/Z Expert Predictions Mean    1141.92\n",
      "trainer/Z Expert Predictions Std       45.0895\n",
      "trainer/Z Expert Predictions Max     1289.4\n",
      "trainer/Z Expert Predictions Min     1023.1\n",
      "trainer/Z Policy Predictions Mean     866.749\n",
      "trainer/Z Policy Predictions Std      275.863\n",
      "trainer/Z Policy Predictions Max     1077.12\n",
      "trainer/Z Policy Predictions Min       18.7926\n",
      "trainer/Z Expert Targets Mean        1125.54\n",
      "trainer/Z Expert Targets Std           45.5641\n",
      "trainer/Z Expert Targets Max         1286.16\n",
      "trainer/Z Expert Targets Min         1002.76\n",
      "trainer/Z Policy Targets Mean         861.059\n",
      "trainer/Z Policy Targets Std          281.404\n",
      "trainer/Z Policy Targets Max         1094.53\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   50.2692\n",
      "trainer/Log Pis Std                    21.3079\n",
      "trainer/Policy mu Mean                  0.244504\n",
      "trainer/Policy mu Std                   2.45732\n",
      "trainer/Policy log std Mean            -2.97596\n",
      "trainer/Policy log std Std              1.06152\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        319317\n",
      "exploration/num paths total          1478\n",
      "evaluation/num steps total              2.03779e+06\n",
      "evaluation/num paths total           3226\n",
      "evaluation/path length Mean           737.364\n",
      "evaluation/path length Std            303.465\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            103\n",
      "evaluation/Rewards Mean                 5.29981\n",
      "evaluation/Rewards Std                  0.161554\n",
      "evaluation/Rewards Max                  6.34894\n",
      "evaluation/Rewards Min                  2.92547\n",
      "evaluation/Returns Mean              3907.88\n",
      "evaluation/Returns Std               1617.69\n",
      "evaluation/Returns Max               5315.58\n",
      "evaluation/Returns Min                547.778\n",
      "evaluation/Estimation Bias Mean       910.597\n",
      "evaluation/Estimation Bias Std        252.73\n",
      "evaluation/EB/Q_True Mean              59.1308\n",
      "evaluation/EB/Q_True Std              162.004\n",
      "evaluation/EB/Q_Pred Mean             969.728\n",
      "evaluation/EB/Q_Pred Std              171.022\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           3907.88\n",
      "evaluation/Actions Mean                 0.0670699\n",
      "evaluation/Actions Std                  0.523762\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.22105\n",
      "time/backward_zf1 (s)                   2.91931\n",
      "time/backward_zf2 (s)                   2.68129\n",
      "time/data sampling (s)                  0.48577\n",
      "time/data storing (s)                   0.0175487\n",
      "time/evaluation sampling (s)            2.53125\n",
      "time/exploration sampling (s)           0.517565\n",
      "time/logging (s)                        0.0110459\n",
      "time/preback_alpha (s)                  0.679503\n",
      "time/preback_policy (s)                 1.26559\n",
      "time/preback_start (s)                  0.211484\n",
      "time/preback_zf (s)                     7.00422\n",
      "time/saving (s)                         3.284e-06\n",
      "time/training (s)                       3.26414\n",
      "time/epoch (s)                         23.8098\n",
      "time/total (s)                       6820.97\n",
      "Epoch                                 314\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:19:39.206121 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 315 finished\n",
      "---------------------------------  ---------------\n",
      "replay_buffer/size                 326000\n",
      "trainer/ZF1 Loss                      133.364\n",
      "trainer/ZF2 Loss                      143.092\n",
      "trainer/ZF Expert Reward               16.4595\n",
      "trainer/ZF Policy Reward                5.48873\n",
      "trainer/ZF CHI2 Term                  143.364\n",
      "trainer/Policy Loss                  -842.753\n",
      "trainer/Bias Loss                      17.7776\n",
      "trainer/Bias Value                     15.6635\n",
      "trainer/Policy Grad Norm              192.614\n",
      "trainer/Policy Param Norm              59.7467\n",
      "trainer/Zf1 Grad Norm                6444.68\n",
      "trainer/Zf1 Param Norm                173.092\n",
      "trainer/Zf2 Grad Norm                5807.2\n",
      "trainer/Zf2 Param Norm                170.899\n",
      "trainer/Z Expert Predictions Mean    1133.85\n",
      "trainer/Z Expert Predictions Std       90.2812\n",
      "trainer/Z Expert Predictions Max     1322.12\n",
      "trainer/Z Expert Predictions Min       -6.61675\n",
      "trainer/Z Policy Predictions Mean     840.913\n",
      "trainer/Z Policy Predictions Std      291.198\n",
      "trainer/Z Policy Predictions Max     1078.18\n",
      "trainer/Z Policy Predictions Min        8.38733\n",
      "trainer/Z Expert Targets Mean        1117.39\n",
      "trainer/Z Expert Targets Std           89.5684\n",
      "trainer/Z Expert Targets Max         1300.58\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         835.424\n",
      "trainer/Z Policy Targets Std          289.736\n",
      "trainer/Z Policy Targets Max         1071.49\n",
      "trainer/Z Policy Targets Min            9.187\n",
      "trainer/Log Pis Mean                   50.9619\n",
      "trainer/Log Pis Std                    23.9991\n",
      "trainer/Policy mu Mean                  0.220797\n",
      "trainer/Policy mu Std                   2.7091\n",
      "trainer/Policy log std Mean            -2.92448\n",
      "trainer/Policy log std Std              1.09653\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        320317\n",
      "exploration/num paths total          1479\n",
      "evaluation/num steps total              2.0472e+06\n",
      "evaluation/num paths total           3236\n",
      "evaluation/path length Mean           941.5\n",
      "evaluation/path length Std            175.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            415\n",
      "evaluation/Rewards Mean                 5.31501\n",
      "evaluation/Rewards Std                  0.0895663\n",
      "evaluation/Rewards Max                  6.12481\n",
      "evaluation/Rewards Min                  4.83685\n",
      "evaluation/Returns Mean              5004.09\n",
      "evaluation/Returns Std                933.224\n",
      "evaluation/Returns Max               5327.38\n",
      "evaluation/Returns Min               2204.47\n",
      "evaluation/Estimation Bias Mean       928.009\n",
      "evaluation/Estimation Bias Std        189.116\n",
      "evaluation/EB/Q_True Mean              50.9299\n",
      "evaluation/EB/Q_True Std              151.667\n",
      "evaluation/EB/Q_Pred Mean             978.939\n",
      "evaluation/EB/Q_Pred Std               78.7219\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5004.09\n",
      "evaluation/Actions Mean                 0.0747169\n",
      "evaluation/Actions Std                  0.515906\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.2524\n",
      "time/backward_zf1 (s)                   2.85915\n",
      "time/backward_zf2 (s)                   2.7068\n",
      "time/data sampling (s)                  0.490125\n",
      "time/data storing (s)                   0.0176236\n",
      "time/evaluation sampling (s)            2.52671\n",
      "time/exploration sampling (s)           0.534076\n",
      "time/logging (s)                        0.0139485\n",
      "time/preback_alpha (s)                  0.683523\n",
      "time/preback_policy (s)                 1.31619\n",
      "time/preback_start (s)                  0.205401\n",
      "time/preback_zf (s)                     7.05631\n",
      "time/saving (s)                         3.157e-06\n",
      "time/training (s)                       3.1509\n",
      "time/epoch (s)                         23.8132\n",
      "time/total (s)                       6844.81\n",
      "Epoch                                 315\n",
      "---------------------------------  ---------------\n",
      "2024-07-28 22:20:02.887731 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 316 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 327000\n",
      "trainer/ZF1 Loss                      120.639\n",
      "trainer/ZF2 Loss                      160.442\n",
      "trainer/ZF Expert Reward               14.6426\n",
      "trainer/ZF Policy Reward                6.49118\n",
      "trainer/ZF CHI2 Term                  144.027\n",
      "trainer/Policy Loss                  -837.644\n",
      "trainer/Bias Loss                      28.3049\n",
      "trainer/Bias Value                     15.6808\n",
      "trainer/Policy Grad Norm              197.721\n",
      "trainer/Policy Param Norm              59.794\n",
      "trainer/Zf1 Grad Norm                4904.6\n",
      "trainer/Zf1 Param Norm                173.301\n",
      "trainer/Zf2 Grad Norm               11300.1\n",
      "trainer/Zf2 Param Norm                171.106\n",
      "trainer/Z Expert Predictions Mean    1121.69\n",
      "trainer/Z Expert Predictions Std       80.9043\n",
      "trainer/Z Expert Predictions Max     1312.33\n",
      "trainer/Z Expert Predictions Min       25.5735\n",
      "trainer/Z Policy Predictions Mean     834.901\n",
      "trainer/Z Policy Predictions Std      287.373\n",
      "trainer/Z Policy Predictions Max     1073.42\n",
      "trainer/Z Policy Predictions Min       19.6793\n",
      "trainer/Z Expert Targets Mean        1107.05\n",
      "trainer/Z Expert Targets Std           81.8811\n",
      "trainer/Z Expert Targets Max         1287.27\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         828.409\n",
      "trainer/Z Policy Targets Std          285.96\n",
      "trainer/Z Policy Targets Max         1083.74\n",
      "trainer/Z Policy Targets Min           13.8718\n",
      "trainer/Log Pis Mean                   50.8385\n",
      "trainer/Log Pis Std                    23.2012\n",
      "trainer/Policy mu Mean                  0.345041\n",
      "trainer/Policy mu Std                   2.79998\n",
      "trainer/Policy log std Mean            -2.86189\n",
      "trainer/Policy log std Std              1.19324\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        321317\n",
      "exploration/num paths total          1480\n",
      "evaluation/num steps total              2.05559e+06\n",
      "evaluation/num paths total           3246\n",
      "evaluation/path length Mean           839.1\n",
      "evaluation/path length Std            322.387\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            152\n",
      "evaluation/Rewards Mean                 5.29098\n",
      "evaluation/Rewards Std                  0.124497\n",
      "evaluation/Rewards Max                  5.63181\n",
      "evaluation/Rewards Min                  4.19305\n",
      "evaluation/Returns Mean              4439.66\n",
      "evaluation/Returns Std               1731.88\n",
      "evaluation/Returns Max               5315.35\n",
      "evaluation/Returns Min                759.016\n",
      "evaluation/Estimation Bias Mean       918.014\n",
      "evaluation/Estimation Bias Std        235.196\n",
      "evaluation/EB/Q_True Mean              57.2229\n",
      "evaluation/EB/Q_True Std              159.802\n",
      "evaluation/EB/Q_Pred Mean             975.237\n",
      "evaluation/EB/Q_Pred Std              111.648\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4439.66\n",
      "evaluation/Actions Mean                 0.0769716\n",
      "evaluation/Actions Std                  0.517598\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.17043\n",
      "time/backward_zf1 (s)                   2.8216\n",
      "time/backward_zf2 (s)                   2.66349\n",
      "time/data sampling (s)                  0.506979\n",
      "time/data storing (s)                   0.0189006\n",
      "time/evaluation sampling (s)            2.49035\n",
      "time/exploration sampling (s)           0.550391\n",
      "time/logging (s)                        0.0126261\n",
      "time/preback_alpha (s)                  0.679048\n",
      "time/preback_policy (s)                 1.28587\n",
      "time/preback_start (s)                  0.211137\n",
      "time/preback_zf (s)                     7.00036\n",
      "time/saving (s)                         3.522e-06\n",
      "time/training (s)                       3.1842\n",
      "time/epoch (s)                         23.5954\n",
      "time/total (s)                       6868.43\n",
      "Epoch                                 316\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:20:26.515344 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 317 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 328000\n",
      "trainer/ZF1 Loss                      249.853\n",
      "trainer/ZF2 Loss                      258.961\n",
      "trainer/ZF Expert Reward               19.7385\n",
      "trainer/ZF Policy Reward               11.1429\n",
      "trainer/ZF CHI2 Term                  262.946\n",
      "trainer/Policy Loss                  -853.558\n",
      "trainer/Bias Loss                      32.1545\n",
      "trainer/Bias Value                     15.6923\n",
      "trainer/Policy Grad Norm              180.45\n",
      "trainer/Policy Param Norm              59.849\n",
      "trainer/Zf1 Grad Norm                7290.36\n",
      "trainer/Zf1 Param Norm                173.525\n",
      "trainer/Zf2 Grad Norm                9569.37\n",
      "trainer/Zf2 Param Norm                171.315\n",
      "trainer/Z Expert Predictions Mean    1126.85\n",
      "trainer/Z Expert Predictions Std       47.9866\n",
      "trainer/Z Expert Predictions Max     1327.73\n",
      "trainer/Z Expert Predictions Min      978.266\n",
      "trainer/Z Policy Predictions Mean     851.768\n",
      "trainer/Z Policy Predictions Std      285.638\n",
      "trainer/Z Policy Predictions Max     1121.7\n",
      "trainer/Z Policy Predictions Min        9.05789\n",
      "trainer/Z Expert Targets Mean        1107.11\n",
      "trainer/Z Expert Targets Std           48.8071\n",
      "trainer/Z Expert Targets Max         1314.14\n",
      "trainer/Z Expert Targets Min          954.841\n",
      "trainer/Z Policy Targets Mean         840.625\n",
      "trainer/Z Policy Targets Std          286.007\n",
      "trainer/Z Policy Targets Max         1080.22\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   51.8148\n",
      "trainer/Log Pis Std                    22.9837\n",
      "trainer/Policy mu Mean                  0.243001\n",
      "trainer/Policy mu Std                   2.80463\n",
      "trainer/Policy log std Mean            -3.09634\n",
      "trainer/Policy log std Std              1.10618\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        322317\n",
      "exploration/num paths total          1481\n",
      "evaluation/num steps total              2.06491e+06\n",
      "evaluation/num paths total           3257\n",
      "evaluation/path length Mean           846.818\n",
      "evaluation/path length Std            269.457\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            212\n",
      "evaluation/Rewards Mean                 5.28355\n",
      "evaluation/Rewards Std                  0.103455\n",
      "evaluation/Rewards Max                  6.04631\n",
      "evaluation/Rewards Min                  4.54157\n",
      "evaluation/Returns Mean              4474.2\n",
      "evaluation/Returns Std               1433.47\n",
      "evaluation/Returns Max               5296.31\n",
      "evaluation/Returns Min               1070.46\n",
      "evaluation/Estimation Bias Mean       927.585\n",
      "evaluation/Estimation Bias Std        216.116\n",
      "evaluation/EB/Q_True Mean              51.3611\n",
      "evaluation/EB/Q_True Std              152.099\n",
      "evaluation/EB/Q_Pred Mean             978.946\n",
      "evaluation/EB/Q_Pred Std              114.36\n",
      "evaluation/Num Paths                   11\n",
      "evaluation/Average Returns           4474.2\n",
      "evaluation/Actions Mean                 0.0732514\n",
      "evaluation/Actions Std                  0.513896\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.15016\n",
      "time/backward_zf1 (s)                   2.76387\n",
      "time/backward_zf2 (s)                   2.62303\n",
      "time/data sampling (s)                  0.493496\n",
      "time/data storing (s)                   0.0186471\n",
      "time/evaluation sampling (s)            2.27645\n",
      "time/exploration sampling (s)           0.535286\n",
      "time/logging (s)                        0.0134213\n",
      "time/preback_alpha (s)                  0.687146\n",
      "time/preback_policy (s)                 1.25678\n",
      "time/preback_start (s)                  0.207786\n",
      "time/preback_zf (s)                     7.17035\n",
      "time/saving (s)                         3.519e-06\n",
      "time/training (s)                       3.34723\n",
      "time/epoch (s)                         23.5437\n",
      "time/total (s)                       6892\n",
      "Epoch                                 317\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:20:50.499761 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 318 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 329000\n",
      "trainer/ZF1 Loss                      121.53\n",
      "trainer/ZF2 Loss                      131.941\n",
      "trainer/ZF Expert Reward               19.1418\n",
      "trainer/ZF Policy Reward                9.12964\n",
      "trainer/ZF CHI2 Term                  134.811\n",
      "trainer/Policy Loss                  -834.093\n",
      "trainer/Bias Loss                      24.8131\n",
      "trainer/Bias Value                     15.706\n",
      "trainer/Policy Grad Norm              211.538\n",
      "trainer/Policy Param Norm              59.9065\n",
      "trainer/Zf1 Grad Norm                6357.97\n",
      "trainer/Zf1 Param Norm                173.763\n",
      "trainer/Zf2 Grad Norm                5557.59\n",
      "trainer/Zf2 Param Norm                171.529\n",
      "trainer/Z Expert Predictions Mean    1112.88\n",
      "trainer/Z Expert Predictions Std       83.3629\n",
      "trainer/Z Expert Predictions Max     1337.48\n",
      "trainer/Z Expert Predictions Min        1.16153\n",
      "trainer/Z Policy Predictions Mean     829.718\n",
      "trainer/Z Policy Predictions Std      278.666\n",
      "trainer/Z Policy Predictions Max     1068.34\n",
      "trainer/Z Policy Predictions Min       17.277\n",
      "trainer/Z Expert Targets Mean        1093.73\n",
      "trainer/Z Expert Targets Std           82.857\n",
      "trainer/Z Expert Targets Max         1316.96\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         820.589\n",
      "trainer/Z Policy Targets Std          280.169\n",
      "trainer/Z Policy Targets Max         1100.02\n",
      "trainer/Z Policy Targets Min            0\n",
      "trainer/Log Pis Mean                   51.1971\n",
      "trainer/Log Pis Std                    23.5716\n",
      "trainer/Policy mu Mean                  0.237584\n",
      "trainer/Policy mu Std                   2.44482\n",
      "trainer/Policy log std Mean            -2.98956\n",
      "trainer/Policy log std Std              1.04961\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        325317\n",
      "exploration/num paths total          1484\n",
      "evaluation/num steps total              2.07249e+06\n",
      "evaluation/num paths total           3267\n",
      "evaluation/path length Mean           758.7\n",
      "evaluation/path length Std            290.485\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            162\n",
      "evaluation/Rewards Mean                 5.30479\n",
      "evaluation/Rewards Std                  0.187007\n",
      "evaluation/Rewards Max                  6.74623\n",
      "evaluation/Rewards Min                  3.16531\n",
      "evaluation/Returns Mean              4024.75\n",
      "evaluation/Returns Std               1560.97\n",
      "evaluation/Returns Max               5330.66\n",
      "evaluation/Returns Min                824.772\n",
      "evaluation/Estimation Bias Mean       858.489\n",
      "evaluation/Estimation Bias Std        262.645\n",
      "evaluation/EB/Q_True Mean              63.3596\n",
      "evaluation/EB/Q_True Std              167.097\n",
      "evaluation/EB/Q_Pred Mean             921.849\n",
      "evaluation/EB/Q_Pred Std              171.632\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4024.75\n",
      "evaluation/Actions Mean                 0.0658211\n",
      "evaluation/Actions Std                  0.541263\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.21148\n",
      "time/backward_zf1 (s)                   2.87461\n",
      "time/backward_zf2 (s)                   2.67114\n",
      "time/data sampling (s)                  0.50919\n",
      "time/data storing (s)                   0.0172419\n",
      "time/evaluation sampling (s)            2.43176\n",
      "time/exploration sampling (s)           0.552115\n",
      "time/logging (s)                        0.0108507\n",
      "time/preback_alpha (s)                  0.689063\n",
      "time/preback_policy (s)                 1.27937\n",
      "time/preback_start (s)                  0.211159\n",
      "time/preback_zf (s)                     7.07228\n",
      "time/saving (s)                         3.601e-06\n",
      "time/training (s)                       3.36921\n",
      "time/epoch (s)                         23.8995\n",
      "time/total (s)                       6915.92\n",
      "Epoch                                 318\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:21:14.119452 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 319 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 330000\n",
      "trainer/ZF1 Loss                      175.058\n",
      "trainer/ZF2 Loss                      155.285\n",
      "trainer/ZF Expert Reward               13.8503\n",
      "trainer/ZF Policy Reward                3.37404\n",
      "trainer/ZF CHI2 Term                  167.946\n",
      "trainer/Policy Loss                  -810.341\n",
      "trainer/Bias Loss                      30.8644\n",
      "trainer/Bias Value                     15.7204\n",
      "trainer/Policy Grad Norm              193.728\n",
      "trainer/Policy Param Norm              59.9506\n",
      "trainer/Zf1 Grad Norm                8657.32\n",
      "trainer/Zf1 Param Norm                174.005\n",
      "trainer/Zf2 Grad Norm                9206.68\n",
      "trainer/Zf2 Param Norm                171.742\n",
      "trainer/Z Expert Predictions Mean    1116.16\n",
      "trainer/Z Expert Predictions Std       51.2155\n",
      "trainer/Z Expert Predictions Max     1339.49\n",
      "trainer/Z Expert Predictions Min      988.838\n",
      "trainer/Z Policy Predictions Mean     802.752\n",
      "trainer/Z Policy Predictions Std      300.002\n",
      "trainer/Z Policy Predictions Max     1082.59\n",
      "trainer/Z Policy Predictions Min        7.4334\n",
      "trainer/Z Expert Targets Mean        1102.31\n",
      "trainer/Z Expert Targets Std           49.8352\n",
      "trainer/Z Expert Targets Max         1306.1\n",
      "trainer/Z Expert Targets Min          972.168\n",
      "trainer/Z Policy Targets Mean         799.378\n",
      "trainer/Z Policy Targets Std          302.079\n",
      "trainer/Z Policy Targets Max         1062.1\n",
      "trainer/Z Policy Targets Min            4.7981\n",
      "trainer/Log Pis Mean                   52.7243\n",
      "trainer/Log Pis Std                    25.6818\n",
      "trainer/Policy mu Mean                  0.219176\n",
      "trainer/Policy mu Std                   3.00233\n",
      "trainer/Policy log std Mean            -2.81802\n",
      "trainer/Policy log std Std              1.1398\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        326317\n",
      "exploration/num paths total          1485\n",
      "evaluation/num steps total              2.08249e+06\n",
      "evaluation/num paths total           3277\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.29467\n",
      "evaluation/Rewards Std                  0.0802667\n",
      "evaluation/Rewards Max                  5.51307\n",
      "evaluation/Rewards Min                  4.82854\n",
      "evaluation/Returns Mean              5294.67\n",
      "evaluation/Returns Std                  5.95657\n",
      "evaluation/Returns Max               5305.58\n",
      "evaluation/Returns Min               5284.4\n",
      "evaluation/Estimation Bias Mean       933.746\n",
      "evaluation/Estimation Bias Std        156.257\n",
      "evaluation/EB/Q_True Mean              47.8489\n",
      "evaluation/EB/Q_True Std              147.383\n",
      "evaluation/EB/Q_Pred Mean             981.595\n",
      "evaluation/EB/Q_Pred Std               46.7447\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5294.67\n",
      "evaluation/Actions Mean                 0.0805382\n",
      "evaluation/Actions Std                  0.488568\n",
      "evaluation/Actions Max                  0.99993\n",
      "evaluation/Actions Min                 -0.999557\n",
      "time/backward_policy (s)                2.15005\n",
      "time/backward_zf1 (s)                   2.814\n",
      "time/backward_zf2 (s)                   2.64549\n",
      "time/data sampling (s)                  0.489619\n",
      "time/data storing (s)                   0.0166786\n",
      "time/evaluation sampling (s)            2.48957\n",
      "time/exploration sampling (s)           0.520633\n",
      "time/logging (s)                        0.0136411\n",
      "time/preback_alpha (s)                  0.679815\n",
      "time/preback_policy (s)                 1.25316\n",
      "time/preback_start (s)                  0.206849\n",
      "time/preback_zf (s)                     6.99248\n",
      "time/saving (s)                         2.751e-06\n",
      "time/training (s)                       3.27198\n",
      "time/epoch (s)                         23.544\n",
      "time/total (s)                       6939.48\n",
      "Epoch                                 319\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:21:37.850342 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 320 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 331000\n",
      "trainer/ZF1 Loss                      139.539\n",
      "trainer/ZF2 Loss                      144.639\n",
      "trainer/ZF Expert Reward               10.8392\n",
      "trainer/ZF Policy Reward                0.00697914\n",
      "trainer/ZF CHI2 Term                  142.048\n",
      "trainer/Policy Loss                  -835.377\n",
      "trainer/Bias Loss                      31.8157\n",
      "trainer/Bias Value                     15.7405\n",
      "trainer/Policy Grad Norm              196.312\n",
      "trainer/Policy Param Norm              59.9996\n",
      "trainer/Zf1 Grad Norm               10044.1\n",
      "trainer/Zf1 Param Norm                174.222\n",
      "trainer/Zf2 Grad Norm               12954.7\n",
      "trainer/Zf2 Param Norm                171.942\n",
      "trainer/Z Expert Predictions Mean    1092.72\n",
      "trainer/Z Expert Predictions Std       84.2742\n",
      "trainer/Z Expert Predictions Max     1265.73\n",
      "trainer/Z Expert Predictions Min      -20.3679\n",
      "trainer/Z Policy Predictions Mean     833.342\n",
      "trainer/Z Policy Predictions Std      261.043\n",
      "trainer/Z Policy Predictions Max     1060.31\n",
      "trainer/Z Policy Predictions Min       20.9636\n",
      "trainer/Z Expert Targets Mean        1081.88\n",
      "trainer/Z Expert Targets Std           83.0446\n",
      "trainer/Z Expert Targets Max         1253\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         833.335\n",
      "trainer/Z Policy Targets Std          261.232\n",
      "trainer/Z Policy Targets Max         1072.67\n",
      "trainer/Z Policy Targets Min           14.2949\n",
      "trainer/Log Pis Mean                   49.7841\n",
      "trainer/Log Pis Std                    19.9726\n",
      "trainer/Policy mu Mean                  0.246263\n",
      "trainer/Policy mu Std                   2.54106\n",
      "trainer/Policy log std Mean            -2.9076\n",
      "trainer/Policy log std Std              1.1196\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        326317\n",
      "exploration/num paths total          1485\n",
      "evaluation/num steps total              2.09185e+06\n",
      "evaluation/num paths total           3287\n",
      "evaluation/path length Mean           935.5\n",
      "evaluation/path length Std            193.5\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            355\n",
      "evaluation/Rewards Mean                 5.30897\n",
      "evaluation/Rewards Std                  0.0969303\n",
      "evaluation/Rewards Max                  5.66796\n",
      "evaluation/Rewards Min                  4.33421\n",
      "evaluation/Returns Mean              4966.54\n",
      "evaluation/Returns Std               1039.59\n",
      "evaluation/Returns Max               5324.73\n",
      "evaluation/Returns Min               1847.83\n",
      "evaluation/Estimation Bias Mean       930.134\n",
      "evaluation/Estimation Bias Std        183.208\n",
      "evaluation/EB/Q_True Mean              51.3867\n",
      "evaluation/EB/Q_True Std              152.52\n",
      "evaluation/EB/Q_Pred Mean             981.521\n",
      "evaluation/EB/Q_Pred Std               77.2632\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4966.54\n",
      "evaluation/Actions Mean                 0.0696122\n",
      "evaluation/Actions Std                  0.512706\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.15915\n",
      "time/backward_zf1 (s)                   2.79276\n",
      "time/backward_zf2 (s)                   2.59687\n",
      "time/data sampling (s)                  0.471886\n",
      "time/data storing (s)                   0.0179729\n",
      "time/evaluation sampling (s)            2.57522\n",
      "time/exploration sampling (s)           0.52909\n",
      "time/logging (s)                        0.012575\n",
      "time/preback_alpha (s)                  0.685055\n",
      "time/preback_policy (s)                 1.2443\n",
      "time/preback_start (s)                  0.208257\n",
      "time/preback_zf (s)                     7.06995\n",
      "time/saving (s)                         3.271e-06\n",
      "time/training (s)                       3.28673\n",
      "time/epoch (s)                         23.6498\n",
      "time/total (s)                       6963.16\n",
      "Epoch                                 320\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:22:00.927865 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 321 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 332000\n",
      "trainer/ZF1 Loss                      162.834\n",
      "trainer/ZF2 Loss                      162.547\n",
      "trainer/ZF Expert Reward               14.592\n",
      "trainer/ZF Policy Reward                3.56911\n",
      "trainer/ZF CHI2 Term                  166.369\n",
      "trainer/Policy Loss                  -834.529\n",
      "trainer/Bias Loss                      23.6326\n",
      "trainer/Bias Value                     15.753\n",
      "trainer/Policy Grad Norm              197.508\n",
      "trainer/Policy Param Norm              60.0426\n",
      "trainer/Zf1 Grad Norm                8728.89\n",
      "trainer/Zf1 Param Norm                174.443\n",
      "trainer/Zf2 Grad Norm                8895.71\n",
      "trainer/Zf2 Param Norm                172.168\n",
      "trainer/Z Expert Predictions Mean    1092.43\n",
      "trainer/Z Expert Predictions Std      111.108\n",
      "trainer/Z Expert Predictions Max     1331.58\n",
      "trainer/Z Expert Predictions Min        0.38863\n",
      "trainer/Z Policy Predictions Mean     831.142\n",
      "trainer/Z Policy Predictions Std      265.797\n",
      "trainer/Z Policy Predictions Max     1043.62\n",
      "trainer/Z Policy Predictions Min       11.7099\n",
      "trainer/Z Expert Targets Mean        1077.84\n",
      "trainer/Z Expert Targets Std          110.099\n",
      "trainer/Z Expert Targets Max         1310\n",
      "trainer/Z Expert Targets Min            0\n",
      "trainer/Z Policy Targets Mean         827.573\n",
      "trainer/Z Policy Targets Std          266.959\n",
      "trainer/Z Policy Targets Max         1053.81\n",
      "trainer/Z Policy Targets Min           10.4602\n",
      "trainer/Log Pis Mean                   49.2053\n",
      "trainer/Log Pis Std                    20.8365\n",
      "trainer/Policy mu Mean                  0.21399\n",
      "trainer/Policy mu Std                   2.63257\n",
      "trainer/Policy log std Mean            -2.94947\n",
      "trainer/Policy log std Std              1.11151\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        326317\n",
      "exploration/num paths total          1485\n",
      "evaluation/num steps total              2.10122e+06\n",
      "evaluation/num paths total           3297\n",
      "evaluation/path length Mean           937.1\n",
      "evaluation/path length Std            188.7\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min            371\n",
      "evaluation/Rewards Mean                 5.30029\n",
      "evaluation/Rewards Std                  0.0966746\n",
      "evaluation/Rewards Max                  5.52263\n",
      "evaluation/Rewards Min                  4.66033\n",
      "evaluation/Returns Mean              4966.9\n",
      "evaluation/Returns Std               1010.59\n",
      "evaluation/Returns Max               5311.73\n",
      "evaluation/Returns Min               1935.2\n",
      "evaluation/Estimation Bias Mean       926.63\n",
      "evaluation/Estimation Bias Std        188.747\n",
      "evaluation/EB/Q_True Mean              51.1307\n",
      "evaluation/EB/Q_True Std              151.882\n",
      "evaluation/EB/Q_Pred Mean             977.761\n",
      "evaluation/EB/Q_Pred Std               77.7141\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           4966.9\n",
      "evaluation/Actions Mean                 0.0772886\n",
      "evaluation/Actions Std                  0.526771\n",
      "evaluation/Actions Max                  1\n",
      "evaluation/Actions Min                 -1\n",
      "time/backward_policy (s)                2.13618\n",
      "time/backward_zf1 (s)                   2.71835\n",
      "time/backward_zf2 (s)                   2.55947\n",
      "time/data sampling (s)                  0.478186\n",
      "time/data storing (s)                   0.0158847\n",
      "time/evaluation sampling (s)            2.26523\n",
      "time/exploration sampling (s)           0.496386\n",
      "time/logging (s)                        0.0126431\n",
      "time/preback_alpha (s)                  0.676844\n",
      "time/preback_policy (s)                 1.25212\n",
      "time/preback_start (s)                  0.204291\n",
      "time/preback_zf (s)                     7.00077\n",
      "time/saving (s)                         2.975e-06\n",
      "time/training (s)                       3.17926\n",
      "time/epoch (s)                         22.9956\n",
      "time/total (s)                       6986.18\n",
      "Epoch                                 321\n",
      "---------------------------------  ----------------\n",
      "2024-07-28 22:22:24.512153 +0330 | [humanoid_2024_07_28_20_25_22_0000--s-1] Epoch 322 finished\n",
      "---------------------------------  ----------------\n",
      "replay_buffer/size                 333000\n",
      "trainer/ZF1 Loss                      150.98\n",
      "trainer/ZF2 Loss                      144.355\n",
      "trainer/ZF Expert Reward               14.2572\n",
      "trainer/ZF Policy Reward                6.70272\n",
      "trainer/ZF CHI2 Term                  151.096\n",
      "trainer/Policy Loss                  -848.657\n",
      "trainer/Bias Loss                      23.9603\n",
      "trainer/Bias Value                     15.7716\n",
      "trainer/Policy Grad Norm              182.074\n",
      "trainer/Policy Param Norm              60.0909\n",
      "trainer/Zf1 Grad Norm                7735.48\n",
      "trainer/Zf1 Param Norm                174.645\n",
      "trainer/Zf2 Grad Norm                6568.74\n",
      "trainer/Zf2 Param Norm                172.377\n",
      "trainer/Z Expert Predictions Mean    1092\n",
      "trainer/Z Expert Predictions Std       46.3082\n",
      "trainer/Z Expert Predictions Max     1256.84\n",
      "trainer/Z Expert Predictions Min      994.649\n",
      "trainer/Z Policy Predictions Mean     848.736\n",
      "trainer/Z Policy Predictions Std      238.327\n",
      "trainer/Z Policy Predictions Max     1084.72\n",
      "trainer/Z Policy Predictions Min        9.76635\n",
      "trainer/Z Expert Targets Mean        1077.74\n",
      "trainer/Z Expert Targets Std           47.0329\n",
      "trainer/Z Expert Targets Max         1270.88\n",
      "trainer/Z Expert Targets Min          971.026\n",
      "trainer/Z Policy Targets Mean         842.033\n",
      "trainer/Z Policy Targets Std          238.822\n",
      "trainer/Z Policy Targets Max         1040.19\n",
      "trainer/Z Policy Targets Min          -23.3401\n",
      "trainer/Log Pis Mean                   48.6458\n",
      "trainer/Log Pis Std                    21.9371\n",
      "trainer/Policy mu Mean                  0.232644\n",
      "trainer/Policy mu Std                   2.59555\n",
      "trainer/Policy log std Mean            -2.98643\n",
      "trainer/Policy log std Std              1.08685\n",
      "trainer/Alpha                           0.01\n",
      "exploration/num steps total        327317\n",
      "exploration/num paths total          1486\n",
      "evaluation/num steps total              2.11122e+06\n",
      "evaluation/num paths total           3307\n",
      "evaluation/path length Mean          1000\n",
      "evaluation/path length Std              0\n",
      "evaluation/path length Max           1000\n",
      "evaluation/path length Min           1000\n",
      "evaluation/Rewards Mean                 5.3107\n",
      "evaluation/Rewards Std                  0.086275\n",
      "evaluation/Rewards Max                  5.54288\n",
      "evaluation/Rewards Min                  4.80864\n",
      "evaluation/Returns Mean              5310.7\n",
      "evaluation/Returns Std                  7.50191\n",
      "evaluation/Returns Max               5319.1\n",
      "evaluation/Returns Min               5291.68\n",
      "evaluation/Estimation Bias Mean       928.434\n",
      "evaluation/Estimation Bias Std        157.794\n",
      "evaluation/EB/Q_True Mean              48.0359\n",
      "evaluation/EB/Q_True Std              147.926\n",
      "evaluation/EB/Q_Pred Mean             976.469\n",
      "evaluation/EB/Q_Pred Std               50.8124\n",
      "evaluation/Num Paths                   10\n",
      "evaluation/Average Returns           5310.7\n",
      "evaluation/Actions Mean                 0.0752402\n",
      "evaluation/Actions Std                  0.514586\n",
      "evaluation/Actions Max                  0.999995\n",
      "evaluation/Actions Min                 -0.998403\n",
      "time/backward_policy (s)                2.25326\n",
      "time/backward_zf1 (s)                   2.85479\n",
      "time/backward_zf2 (s)                   2.71939\n",
      "time/data sampling (s)                  0.51236\n",
      "time/data storing (s)                   0.0176801\n",
      "time/evaluation sampling (s)            2.1881\n",
      "time/exploration sampling (s)           0.535246\n",
      "time/logging (s)                        0.0133309\n",
      "time/preback_alpha (s)                  0.69307\n",
      "time/preback_policy (s)                 1.29446\n",
      "time/preback_start (s)                  0.207441\n",
      "time/preback_zf (s)                     7.06121\n",
      "time/saving (s)                         2.69699e-06\n",
      "time/training (s)                       3.15554\n",
      "time/epoch (s)                         23.5059\n",
      "time/total (s)                       7009.7\n",
      "Epoch                                 322\n",
      "---------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    experiment(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada1e39-e2f6-4481-9e81-5708bef3ae3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ffaaae-4896-4492-890f-ffae6067362d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0c3c3-4c36-4b56-9309-fa4449a241d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CQL (new mate)\n",
    "\"\"\"\n",
    "if self.use_cql:\n",
    "    presum_tauom_actions = torch.FloatTensor(policy_actions.shape[0] * self.num_presum_tauom,\n",
    "                                       policy_actions.shape[-1]).uniform_(-1,1).to(self.device)\n",
    "    \n",
    "    _, tau_hat, _ = self.get_tau(policy_obs, policy_actions, fp=self.fp)\n",
    "    tau_index = np.presum_tauom.presum_tauint(0, self.num_quantiles)\n",
    "    presum_tauom_tau_hat = tau_hat[:, tau_index:tau_index+1]\n",
    "    \n",
    "    z1_presum_tau, z2_presum_tau = self._get_tensor_values(policy_obs, presum_tauom_actions, presum_tauom_tau_hat)\n",
    "\n",
    "    z1_presum_tau = torch.logsumexp(z1_presum_tau, dim=1).mean()\n",
    "    z2_presum_tau = torch.logsumexp(z2_presum_tau, dim=1).mean()\n",
    "    cql_z1_loss = (z1_presum_tau - expert_z1_pred.mean()) * self.cql_weight\n",
    "    cql_z2_loss = (z2_presum_tau - expert_z2_pred.mean()) * self.cql_weight\n",
    "    \n",
    "    zf1_loss += cql_z1_loss\n",
    "    zf2_loss += cql_z2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e417f-bfa2-4c6c-8bf3-f1a094016be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CQL (old mate)\n",
    "\"\"\"\n",
    "if self.use_cql:\n",
    "    presum_tauom_actions = torch.FloatTensor(policy_actions.shape[0] * self.num_presum_tauom,\n",
    "                                       policy_actions.shape[-1]).uniform_(-1,1).to(self.device)\n",
    "    current_actions, current_log_pi = self._get_policy_actions(policy_obs, \n",
    "                                                               num_actions=self.num_presum_tauom,\n",
    "                                                               network=self.policy)\n",
    "    next_actions, next_log_pi = self._get_policy_actions(policy_next_obs, \n",
    "                                                         num_actions=self.num_presum_tauom,\n",
    "                                                         network=self.policy)\n",
    "    \n",
    "    _, tau_hat, _ = self.get_tau(policy_obs, policy_actions, fp=self.fp)\n",
    "    tau_index = np.presum_tauom.presum_tauint(0, self.num_quantiles)\n",
    "    presum_tauom_tau_hat = tau_hat[:, tau_index:tau_index+1]\n",
    "\n",
    "    z1_presum_tau, z2_presum_tau = self._get_tensor_values(policy_obs, presum_tauom_actions, presum_tauom_tau_hat)\n",
    "    z1_current, z2_current = self._get_tensor_values(policy_obs, current_actions, presum_tauom_tau_hat)\n",
    "    z1_next, z2_next = self._get_tensor_values(policy_obs, next_actions, presum_tauom_tau_hat)\n",
    "\n",
    "    presum_tauom_density = np.log(0.5 ** current_actions.shape[-1])\n",
    "    cat_z1 = torch.cat(\n",
    "        [z1_presum_tau - alpha * presum_tauom_density, \n",
    "         z1_next - alpha * next_log_pi.detach(),\n",
    "         z1_current - alpha * current_log_pi.detach()], 1\n",
    "    )\n",
    "    cat_z2 = torch.cat(\n",
    "        [z2_presum_tau - alpha * presum_tauom_density, \n",
    "         z2_next - alpha * next_log_pi.detach(),\n",
    "         z2_current - alpha * current_log_pi.detach()], 1\n",
    "    )\n",
    "    min_zf1_loss = torch.logsumexp(cat_z1, dim=1).mean()\n",
    "    min_zf2_loss = torch.logsumexp(cat_z2, dim=1).mean()\n",
    "    min_zf1_loss = (min_zf1_loss - expert_z1_pred.mean()) * self.min_z_weight\n",
    "    min_zf2_loss = (min_zf2_loss - expert_z2_pred.mean()) * self.min_z_weight\n",
    "    \n",
    "    if self.with_lagrange:\n",
    "        alpha_prime = torch.clamp(self.log_alpha_prime.exp(), min=0.0, max=1000000.0)\n",
    "        min_zf1_loss = alpha_prime * (min_zf1_loss - self.target_action_gap)\n",
    "        min_zf2_loss = alpha_prime * (min_zf2_loss - self.target_action_gap)\n",
    "\n",
    "        self.alpha_prime_optimizer.zero_grad()\n",
    "        alpha_prime_loss = (-min_zf1_loss - min_zf2_loss) * 0.5\n",
    "        alpha_prime_loss.backward(retain_graph=True)\n",
    "        self.alpha_prime_optimizer.step()\n",
    "\n",
    "    zf1_loss += min_zf1_loss\n",
    "    zf2_loss += min_zf2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17f747-28a7-4dc3-afdd-167e30b1c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \"\"\"\n",
    "        CQL (std!)\n",
    "        \"\"\"\n",
    "        if self.use_cql:\n",
    "            # q1_pred = torch.sum(presum_tau * policy_z1_pred, dim=1, keepdims=True)\n",
    "            # q2_pred = torch.sum(presum_tau * policy_z2_pred, dim=1, keepdims=True)\n",
    "            # q1_std = presum_tau * (policy_z1_pred - q1_pred).pow(2)\n",
    "            # q2_std = presum_tau * (policy_z2_pred - q2_pred).pow(2)\n",
    "            # cql1_term = self.cql_weight * q1_std.sum(dim=1).sqrt().mean()\n",
    "            # cql2_term = self.cql_weight * q2_std.sum(dim=1).sqrt().mean()\n",
    "\n",
    "            cql1_term = 4.5 - self.cql_weight * policy_z1_pred.std()\n",
    "            cql2_term = 4.5 - self.cql_weight * policy_z2_pred.std()\n",
    "            \n",
    "            zf1_loss += cql1_term\n",
    "            zf2_loss += cql2_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd879f-190b-4c06-84c4-bb61e80e6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CQL (old mate; expert observations with policy actions)\n",
    "\"\"\"\n",
    "if self.use_cql:\n",
    "    presum_tauom_actions = torch.FloatTensor(policy_actions.shape[0] * self.num_presum_tauom,\n",
    "                                       policy_actions.shape[-1]).uniform_(-1,1).to(self.device)\n",
    "    current_actions, current_log_pi = self._get_policy_actions(expert_obs, \n",
    "                                                               num_actions=self.num_presum_tauom,\n",
    "                                                               network=self.policy)\n",
    "    next_actions, next_log_pi = self._get_policy_actions(expert_next_obs, \n",
    "                                                         num_actions=self.num_presum_tauom,\n",
    "                                                         network=self.policy)\n",
    "    \n",
    "    _, tau_hat, _ = self.get_tau(expert_obs, policy_actions, fp=self.fp)\n",
    "    tau_index = np.presum_tauom.presum_tauint(0, self.num_quantiles)\n",
    "    presum_tauom_tau_hat = tau_hat[:, tau_index:tau_index+1]\n",
    "\n",
    "    z1_presum_tau, z2_presum_tau = self._get_tensor_values(expert_obs, presum_tauom_actions, presum_tauom_tau_hat)\n",
    "    z1_current, z2_current = self._get_tensor_values(expert_obs, current_actions, presum_tauom_tau_hat)\n",
    "    z1_next, z2_next = self._get_tensor_values(expert_obs, next_actions, presum_tauom_tau_hat)\n",
    "\n",
    "    presum_tauom_density = np.log(0.5 ** current_actions.shape[-1])\n",
    "    cat_z1 = torch.cat(\n",
    "        [z1_presum_tau - alpha * presum_tauom_density, \n",
    "         z1_next - alpha * next_log_pi.detach(),\n",
    "         z1_current - alpha * current_log_pi.detach()], 1\n",
    "    )\n",
    "    cat_z2 = torch.cat(\n",
    "        [z2_presum_tau - alpha * presum_tauom_density, \n",
    "         z2_next - alpha * next_log_pi.detach(),\n",
    "         z2_current - alpha * current_log_pi.detach()], 1\n",
    "    )\n",
    "    min_zf1_loss = torch.logsumexp(cat_z1, dim=1).mean() * self.cql_weight\n",
    "    min_zf2_loss = torch.logsumexp(cat_z2, dim=1).mean() * self.cql_weight\n",
    "\n",
    "    zf1_loss += min_zf1_loss\n",
    "    zf2_loss += min_zf2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427a802-08e5-44b4-be99-f8042aaeb0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f1ee30d-094c-4a0a-ae59-7ceb9559a9a7",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9a96c6-976d-45e7-8fd5-1c24ab784e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import csv\n",
    "from rlkit.envs import make_env\n",
    "from rlkit.envs.vecenv import SubprocVectorEnv, VectorEnv\n",
    "from rlkit.torch.idsac.networks import QuantileMlp, Critic\n",
    "from rlkit.torch.idsac.policies import TanhGaussianPolicy\n",
    "from rlkit.data_management.torch_replay_buffer import TorchReplayBuffer\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.torch.core import eval_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f976d60-f9f2-4579-bc7c-57ece766a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([10], dtype=torch.float, requires_grad=True).to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a81dcd4-7d82-4313-813e-84dc8061876a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.], device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7925026a-4990-4bf7-99f4-9ecba0cbec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1011.], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce979ec-578a-401c-99d1-5d34011bdcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
